{"code": "function prependTildesToImports(styles) {\n  styles.eachAtRule(function (atRule) {\n    if (atRule.name !== 'import')\n      return;\n\n    var stripped = stripQuotes(unwrapUrl(atRule.params));\n    if (stripped[0] !== '.' && stripped[0] !== '~' && stripped[0] !== '/') {\n      atRule.params = '\"~' + stripped + '\"';\n    }\n\n  });\n}", "label": 3}
{"code": "async function getReleaseInfo(context, childTags) {\n  const tagShas = [];\n\n  const releasesBySha = await fetchAllReleases(context, release => {\n    if (childTags.has(release.tag_name)) {\n      // put in reverse order\n      // later releases come first,\n      // but we want to iterate beginning oldest releases first\n      tagShas.unshift(release.target_commitish);\n      // tagSha.push(release.target_commitish);\n    }\n  });\n\n  return {releasesBySha, tagShas};\n}", "label": 3}
{"code": "func SetNoCacheHeaders(h http.Header) {\n\th.Set(\"Cache-Control\", \"no-cache, no-store, must-revalidate\")\n\th.Set(\"Pragma\", \"no-cache\")\n\th.Set(\"Expires\", \"0\")\n}", "label": 5}
{"code": "func (a *HistoricalApi) namespaceList(request *restful.Request, response *restful.Response) {\n\tif resp, err := a.historicalSource.GetNamespaces(); err != nil {\n\t\tresponse.WriteError(http.StatusInternalServerError, err)\n\t} else {\n\t\tresponse.WriteEntity(resp)\n\t}\n}", "label": 5}
{"code": "func NewGithubConnector(name string, spec GithubConnectorSpecV3) GithubConnector {\n\treturn &GithubConnectorV3{\n\t\tKind:    KindGithubConnector,\n\t\tVersion: V3,\n\t\tMetadata: Metadata{\n\t\t\tName:      name,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: spec,\n\t}\n}", "label": 5}
{"code": "def set_save_directory(base, source):\n    \"\"\"Sets the root save directory for saving screenshots.\n    \n    Screenshots will be saved in subdirectories under this directory by\n    browser window size. \"\"\"\n    root = os.path.join(base, source)\n    if not os.path.isdir(root):\n        os.makedirs(root)\n\n    world.screenshot_root = root", "label": 1}
{"code": "func createVlanLink(parentName string) error {\n\tif strings.Contains(parentName, \".\") {\n\t\tparent, vidInt, err := parseVlan(parentName)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// VLAN identifier or VID is a 12-bit field specifying the VLAN to which the frame belongs\n\t\tif vidInt > 4094 || vidInt < 1 {\n\t\t\treturn fmt.Errorf(\"vlan id must be between 1-4094, received: %d\", vidInt)\n\t\t}\n\t\t// get the parent link to attach a vlan subinterface\n\t\tparentLink, err := ns.NlHandle().LinkByName(parent)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to find master interface %s on the Docker host: %v\", parent, err)\n\t\t}\n\t\tvlanLink := &netlink.Vlan{\n\t\t\tLinkAttrs: netlink.LinkAttrs{\n\t\t\t\tName:        parentName,\n\t\t\t\tParentIndex: parentLink.Attrs().Index,\n\t\t\t},\n\t\t\tVlanId: vidInt,\n\t\t}\n\t\t// create the subinterface\n\t\tif err := ns.NlHandle().LinkAdd(vlanLink); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to create %s vlan link: %v\", vlanLink.Name, err)\n\t\t}\n\t\t// Bring the new netlink iface up\n\t\tif err := ns.NlHandle().LinkSetUp(vlanLink); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to enable %s the ipvlan parent link %v\", vlanLink.Name, err)\n\t\t}\n\t\tlogrus.Debugf(\"Added a vlan tagged netlink subinterface: %s with a vlan id: %d\", parentName, vidInt)\n\t\treturn nil\n\t}\n\n\treturn fmt.Errorf(\"invalid subinterface vlan name %s, example formatting is eth0.10\", parentName)\n}", "label": 5}
{"code": "function combineErrors(errPrev, errNew) {\n  if (!errPrev) {\n    return errNew;\n  }\n\n  let errCombined;\n  if (errPrev instanceof AggregateError) {\n    errCombined = errPrev;\n  } else {\n    errCombined = new AggregateError();\n    errCombined.push(errPrev);\n  }\n\n  errCombined.push(errNew);\n  return errCombined;\n}", "label": 3}
{"code": "function (fileName) {\n        var result = new _File(fileName),\n            fileData = this._data[fileName];\n        [{\n            type: \"statements\",\n            data: \"s\",\n            map: \"statementMap\"\n        }, {\n            type: \"functions\",\n            data: \"f\",\n            map: \"fnMap\"\n        }, {\n            type: \"branches\",\n            data: \"b\",\n            map: \"branchMap\"\n        }].forEach(function (part) {\n            var map = fileData[part.map],\n                data = fileData[part.data],\n                statistics = result[part.type],\n                index = 1;\n            while (undefined !== data[index]) {\n                statistics.processCoverage(data[index], map[index]);\n                ++index;\n            }\n        });\n        return result;\n    }", "label": 3}
{"code": "def members_entries(self, all_are_optional: Optional[bool] = False) -> List[Tuple[str, str]]:\n        \"\"\" Generate a list quoted raw name, signature type entries for this pairdef, recursively traversing\n        reference types\n\n        :param all_are_optional: If true, all types are forced optional\n        :return: raw name/ signature type for all elements in this pair\n        \"\"\"\n        if self._type_reference:\n            rval: List[Tuple[str, str]] = []\n            for n, t in self._context.reference(self._type_reference).members_entries(all_are_optional):\n                rval.append((n, self._ebnf.signature_cardinality(t, all_are_optional).format(name=n)))\n            return rval\n        else:\n            sig = self._ebnf.signature_cardinality(self._typ.reference_type(), all_are_optional)\n            return [(name, sig.format(name=name)) for name in self._names]", "label": 1}
{"code": "def _full_path(self, path_info):\n        \"\"\"Return the full path from which to read.\"\"\"\n        full_path = self.root + path_info\n        if path.exists(full_path):\n            return full_path\n        else:\n            for magic in self.magics:\n                if path.exists(magic.new_path(full_path)):\n                    return magic.new_path(full_path)\n            else:\n                return full_path", "label": 1}
{"code": "func (s *Server) forgetConn(c net.Conn) {\n\tif _, ok := s.conns[c]; ok {\n\t\tdelete(s.conns, c)\n\t\ts.wg.Done()\n\t}\n}", "label": 5}
{"code": "public long removeAll(final String... members) {\n        return doWithJedis(new JedisCallable<Long>() {\n            @Override\n            public Long call(Jedis jedis) {\n                return jedis.srem(getKey(), members);\n            }\n        });\n    }", "label": 0}
{"code": "public static vpnvserver_appcontroller_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_appcontroller_binding obj = new vpnvserver_appcontroller_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_appcontroller_binding response[] = (vpnvserver_appcontroller_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static base_responses update(nitro_service client, responderpolicy resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tresponderpolicy updateresources[] = new responderpolicy[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new responderpolicy();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].rule = resources[i].rule;\n\t\t\t\tupdateresources[i].action = resources[i].action;\n\t\t\t\tupdateresources[i].undefaction = resources[i].undefaction;\n\t\t\t\tupdateresources[i].comment = resources[i].comment;\n\t\t\t\tupdateresources[i].logaction = resources[i].logaction;\n\t\t\t\tupdateresources[i].appflowaction = resources[i].appflowaction;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "async function deleteDeploymentFolder() {\n  del.sync(deploymentTmpFolder, { force: true });\n  del.sync(deploymentFolder, { force: true });\n}", "label": 3}
{"code": "def aasm(*args, &block)\n      if args[0].is_a?(Symbol) || args[0].is_a?(String)\n        # using custom name\n        state_machine_name = args[0].to_sym\n        options = args[1] || {}\n      else\n        # using the default state_machine_name\n        state_machine_name = :default\n        options = args[0] || {}\n      end\n\n      AASM::StateMachineStore.fetch(self, true).register(state_machine_name, AASM::StateMachine.new(state_machine_name))\n\n      # use a default despite the DSL configuration default.\n      # this is because configuration hasn't been setup for the AASM class but we are accessing a DSL option already for the class.\n      aasm_klass = options[:with_klass] || AASM::Base\n\n      raise ArgumentError, \"The class #{aasm_klass} must inherit from AASM::Base!\" unless aasm_klass.ancestors.include?(AASM::Base)\n\n      @aasm ||= Concurrent::Map.new\n      if @aasm[state_machine_name]\n        # make sure to use provided options\n        options.each do |key, value|\n          @aasm[state_machine_name].state_machine.config.send(\"#{key}=\", value)\n        end\n      else\n        # create a new base\n        @aasm[state_machine_name] = aasm_klass.new(\n          self,\n          state_machine_name,\n          AASM::StateMachineStore.fetch(self, true).machine(state_machine_name),\n          options\n        )\n      end\n      @aasm[state_machine_name].instance_eval(&block) if block # new DSL\n      @aasm[state_machine_name]\n    end", "label": 4}
{"code": "public function deleteMutation($table, KeySet $keySet)\n    {\n        return [\n            self::OP_DELETE => [\n                'table' => $table,\n                'keySet' => $this->flattenKeySet($keySet),\n            ]\n        ];\n    }", "label": 2}
{"code": "func (p *ProcessStorage) GetState(role teleport.Role) (*StateV2, error) {\n\titem, err := p.Get(context.TODO(), backend.Key(statesPrefix, strings.ToLower(role.String()), stateName))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar res StateV2\n\tif err := utils.UnmarshalWithSchema(GetStateSchema(), &res, item.Value); err != nil {\n\t\treturn nil, trace.BadParameter(err.Error())\n\t}\n\treturn &res, nil\n}", "label": 5}
{"code": "function (model, filter, value) {\n\n    if (!_.isString(filter)) {\n        return null;\n    }\n\n    if (model.data) {\n        var list = findKeys(model.data, filter)\n            , values = [];\n\n        for (var res in list) {\n\n            if (value === undefined || list[res][filter] === value) {\n                values.push(res);\n            }\n        }\n    }\n    //return _.isEmpty(values) ? undefined : values;\n    //Changed to return empty array instead of 'undefined'. Do not change back, otherwise some functions working with arrays do not work properly.\n    return values;\n}", "label": 3}
{"code": "def env_config\n      @app_env_config ||= begin\n        super.merge(\n          \"action_dispatch.parameter_filter\" => config.filter_parameters,\n          \"action_dispatch.redirect_filter\" => config.filter_redirect,\n          \"action_dispatch.secret_key_base\" => secret_key_base,\n          \"action_dispatch.show_exceptions\" => config.action_dispatch.show_exceptions,\n          \"action_dispatch.show_detailed_exceptions\" => config.consider_all_requests_local,\n          \"action_dispatch.logger\" => Rails.logger,\n          \"action_dispatch.backtrace_cleaner\" => Rails.backtrace_cleaner,\n          \"action_dispatch.key_generator\" => key_generator,\n          \"action_dispatch.http_auth_salt\" => config.action_dispatch.http_auth_salt,\n          \"action_dispatch.signed_cookie_salt\" => config.action_dispatch.signed_cookie_salt,\n          \"action_dispatch.encrypted_cookie_salt\" => config.action_dispatch.encrypted_cookie_salt,\n          \"action_dispatch.encrypted_signed_cookie_salt\" => config.action_dispatch.encrypted_signed_cookie_salt,\n          \"action_dispatch.authenticated_encrypted_cookie_salt\" => config.action_dispatch.authenticated_encrypted_cookie_salt,\n          \"action_dispatch.use_authenticated_cookie_encryption\" => config.action_dispatch.use_authenticated_cookie_encryption,\n          \"action_dispatch.encrypted_cookie_cipher\" => config.action_dispatch.encrypted_cookie_cipher,\n          \"action_dispatch.signed_cookie_digest\" => config.action_dispatch.signed_cookie_digest,\n          \"action_dispatch.cookies_serializer\" => config.action_dispatch.cookies_serializer,\n          \"action_dispatch.cookies_digest\" => config.action_dispatch.cookies_digest,\n          \"action_dispatch.cookies_rotations\" => config.action_dispatch.cookies_rotations,\n          \"action_dispatch.use_cookies_with_metadata\" => config.action_dispatch.use_cookies_with_metadata,\n          \"action_dispatch.content_security_policy\" => config.content_security_policy,\n          \"action_dispatch.content_security_policy_report_only\" => config.content_security_policy_report_only,\n          \"action_dispatch.content_security_policy_nonce_generator\" => config.content_security_policy_nonce_generator\n        )\n      end\n    end", "label": 4}
{"code": "public function move($new_x, $new_y)\n    {\n        $this->x = $new_x;\n        $this->y = $new_y;\n\n        return $this;\n    }", "label": 2}
{"code": "func (d Datastore) AttachedClusterHosts(ctx context.Context, cluster *ComputeResource) ([]*HostSystem, error) {\n\tvar hosts []*HostSystem\n\n\tclusterHosts, err := cluster.Hosts(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tattachedHosts, err := d.AttachedHosts(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trefs := make(map[types.ManagedObjectReference]bool)\n\tfor _, host := range attachedHosts {\n\t\trefs[host.Reference()] = true\n\t}\n\n\tfor _, host := range clusterHosts {\n\t\tif refs[host.Reference()] {\n\t\t\thosts = append(hosts, host)\n\t\t}\n\t}\n\n\treturn hosts, nil\n}", "label": 5}
{"code": "def process_chunk(members)\n      process_members(members)\n      @processed_chunk_members += members.length\n      LOGGER.debug(\"Processed one chunk on server #{@id} - length #{members.length}\")\n\n      # Don't bother with the rest of the method if it's not truly the last packet\n      return unless @processed_chunk_members == @member_count\n\n      LOGGER.debug(\"Finished chunking server #{@id}\")\n\n      # Reset everything to normal\n      @chunked = true\n      @processed_chunk_members = 0\n    end", "label": 4}
{"code": "@Override\n\tprotected final void subAppend(final LoggingEvent event) {\n\t\tif (event instanceof ScheduledFileRollEvent) {\n\t\t\t// the scheduled append() call has been made by a different thread\n\t\t\tsynchronized (this) {\n\t\t\t\tif (this.closed) {\n\t\t\t\t\t// just consume the event\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tthis.rollFile(event);\n\t\t\t}\n\t\t} else if (event instanceof FileRollEvent) {\n\t\t\t// definitely want to avoid rolling here whilst a file roll event is still being handled\n\t\t\tsuper.subAppend(event);\n\t\t} else {\n\n\t\t\tif(event instanceof FoundationLof4jLoggingEvent){\n\t\t\t\tFoundationLof4jLoggingEvent foundationLof4jLoggingEvent = (FoundationLof4jLoggingEvent)event;\n\t\t\t\tfoundationLof4jLoggingEvent.setAppenderName(this.getName());\n\t\t\t}\n\t\t\t\n\t\t\tthis.rollFile(event);\n\t\t\tsuper.subAppend(event);\n\t\t}\n\t}", "label": 0}
{"code": "public function signedUrlUploader($uri, $data, array $options = [])\n    {\n        return new SignedUrlUploader($this->connection->requestWrapper(), $data, $uri, $options);\n    }", "label": 2}
{"code": "public static function findingSecurityMarksName($organization, $source, $finding)\n    {\n        return self::getFindingSecurityMarksNameTemplate()->render([\n            'organization' => $organization,\n            'source' => $source,\n            'finding' => $finding,\n        ]);\n    }", "label": 2}
{"code": "def run(self, host, port, **options):\n        \"\"\"For debugging purposes, you can run this as a standalone server.\n\n        .. WARNING:: **Security vulnerability**\n\n            This uses :class:`DebuggedJsonRpcApplication` to assist debugging. If you want to use\n            this in production, you should run :class:`Server` as a standard WSGI app with\n            `uWSGI <https://uwsgi-docs.readthedocs.org/en/latest/>`_ or another similar WSGI server.\n\n        .. versionadded:: 0.1.0\n        \"\"\"\n        self.registry.debug = True\n        debugged = DebuggedJsonRpcApplication(self, evalex=True)\n        run_simple(host, port, debugged, use_reloader=True, **options)", "label": 1}
{"code": "def upgrade_v1_dotfile(path)\n      @logger.info(\"Upgrading V1 dotfile to V2 directory structure...\")\n\n      # First, verify the file isn't empty. If it is an empty file, we\n      # just delete it and go on with life.\n      contents = path.read.strip\n      if contents.strip == \"\"\n        @logger.info(\"V1 dotfile was empty. Removing and moving on.\")\n        path.delete\n        return\n      end\n\n      # Otherwise, verify there is valid JSON in here since a Vagrant\n      # environment would always ensure valid JSON. This is a sanity check\n      # to make sure we don't nuke a dotfile that is not ours...\n      @logger.debug(\"Attempting to parse JSON of V1 file\")\n      json_data = nil\n      begin\n        json_data = JSON.parse(contents)\n        @logger.debug(\"JSON parsed successfully. Things are okay.\")\n      rescue JSON::ParserError\n        # The file could've been tampered with since Vagrant 1.0.x is\n        # supposed to ensure that the contents are valid JSON. Show an error.\n        raise Errors::DotfileUpgradeJSONError,\n          state_file: path.to_s\n      end\n\n      # Alright, let's upgrade this guy to the new structure. Start by\n      # backing up the old dotfile.\n      backup_file = path.dirname.join(\".vagrant.v1.#{Time.now.to_i}\")\n      @logger.info(\"Renaming old dotfile to: #{backup_file}\")\n      path.rename(backup_file)\n\n      # Now, we create the actual local data directory. This should succeed\n      # this time since we renamed the old conflicting V1.\n      setup_local_data_path(true)\n\n      if json_data[\"active\"]\n        @logger.debug(\"Upgrading to V2 style for each active VM\")\n        json_data[\"active\"].each do |name, id|\n          @logger.info(\"Upgrading dotfile: #{name} (#{id})\")\n\n          # Create the machine configuration directory\n          directory = @local_data_path.join(\"machines/#{name}/virtualbox\")\n          FileUtils.mkdir_p(directory)\n\n          # Write the ID file\n          directory.join(\"id\").open(\"w+\") do |f|\n            f.write(id)\n          end\n        end\n      end\n\n      # Upgrade complete! Let the user know\n      @ui.info(I18n.t(\"vagrant.general.upgraded_v1_dotfile\",\n                      backup_path: backup_file.to_s))\n    end", "label": 4}
{"code": "function(data, options) {\n    var configs = [];\n\n    if (_.isArray(data)) {\n      data.forEach(function(block) {\n        configs.push(new BlockConfig(block.name, block, options));\n      });\n    } else if (_.isPlainObject(data)) {\n      _.forOwn(data, function(value, name) {\n        configs.push(new BlockConfig(name, value, options));\n      });\n    } else {\n      grunt.warn('Block configuration must be an array or object.');\n    }\n\n    return configs;\n  }", "label": 3}
{"code": "def geom_reflect(g, nv):\n    \"\"\" Reflection symmetry operation.\n\n    nv is normal vector to reflection plane\n    g is assumed already translated to center of mass @ origin\n\n    .. todo:: Complete geom_reflect docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Force g to n-vector\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n\n    # Transform the geometry and return\n    refl_g = np.dot(mtx_refl(nv, reps=(g.shape[0] // 3)), g) \\\n                .reshape((g.shape[0],1))\n    return refl_g", "label": 1}
{"code": "func (c *Client) ExtendWebSession(user string, prevSessionID string) (services.WebSession, error) {\n\tout, err := c.PostJSON(\n\t\tc.Endpoint(\"users\", user, \"web\", \"sessions\"),\n\t\tcreateWebSessionReq{\n\t\t\tPrevSessionID: prevSessionID,\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.GetWebSessionMarshaler().UnmarshalWebSession(out.Bytes())\n}", "label": 5}
{"code": "func ParseEvent(data []byte) Event {\n\t// Not supported\n\treturn Event{Type: EventError, Err: errors.New(\"no raw events\")}\n}", "label": 5}
{"code": "def log_exception(exception)\n      # Event log is being used here to propagate the error.\n      # It's up to event log renderer to find the error and\n      # signal it properly.\n      director_error = DirectorError.create_from_exception(exception)\n      Config.event_log.log_error(director_error)\n    end", "label": 4}
{"code": "public function setAction($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Container\\V1\\SetMasterAuthRequest_Action::class);\n        $this->action = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def shelve(self, changelist=None):\n        \"\"\"Shelves the file if it is in a changelist\n\n        :param changelist: Changelist to add the move to\n        :type changelist: :class:`.Changelist`\n        \"\"\"\n        if changelist is None and self.changelist.description == 'default':\n            raise errors.ShelveError('Unabled to shelve files in the default changelist')\n\n        cmd = ['shelve']\n        if changelist:\n            cmd += ['-c', str(changelist)]\n\n        cmd.append(self.depotFile)\n\n        self._connection.run(cmd)\n\n        self.query()", "label": 1}
{"code": "def validate_hour_lock(time, start_time)\n      h0 = starting_unit(start_time)\n      h1 = time.hour\n      if h0 >= h1\n        h0 - h1\n      else\n        if dst_offset = TimeUtil.dst_change(time)\n          h0 - h1 + dst_offset\n        else\n          24 - h1 + h0\n        end\n      end\n    end", "label": 4}
{"code": "public void identifyNode(int nodeId) throws SerialInterfaceException {\n\t\tSerialMessage newMessage = new SerialMessage(nodeId, SerialMessage.SerialMessageClass.IdentifyNode, SerialMessage.SerialMessageType.Request, SerialMessage.SerialMessageClass.IdentifyNode, SerialMessage.SerialMessagePriority.High);\n    \tbyte[] newPayload = { (byte) nodeId };\n    \tnewMessage.setMessagePayload(newPayload);\n    \tthis.enqueue(newMessage);\n\t}", "label": 0}
{"code": "def split_fusion_transcript(annotation_path, transcripts):\n    \"\"\"\n    Finds the breakpoint in the fusion transcript and splits the 5' donor from the 3' acceptor\n\n    :param str annotation_path: Path to transcript annotation file\n    :param dict transcripts: Dictionary of fusion transcripts\n    :return: 5' donor sequences and 3' acceptor sequences\n    :rtype: tuple\n    \"\"\"\n    annotation = collections.defaultdict(dict)\n\n    forward = 'ACGTN'\n    reverse = 'TGCAN'\n    trans = string.maketrans(forward, reverse)\n\n    # Pull in assembled transcript annotation\n    five_pr_splits = collections.defaultdict(dict)\n    three_pr_splits = collections.defaultdict(dict)\n\n    regex = re.compile(r'ID=(?P<ID>.*);Name=(?P<Name>.*);Target=(?P<Target>.*)\\s(?P<start>\\d+)\\s(?P<stop>\\d+)')\n\n    with open(annotation_path, 'r') as gff:\n        for line in gff:\n            print(line)\n            if line.startswith('#'):\n                _, eyd, fusion = line.strip().split()\n                fusion, start_stop = fusion.split(':')\n                left_break, right_break = start_stop.split('-')\n\n                annotation[fusion][eyd] = {}\n                annotation[fusion][eyd]['left_break'] = left_break\n                annotation[fusion][eyd]['right_break'] = right_break\n\n            else:\n                line = line.strip().split('\\t')\n                fusion = line[0]\n                strand = line[6]\n                block_start = line[3]\n                block_stop = line[4]\n                attr = line[8]\n                m = regex.search(attr)\n                if m:\n                    transcript_id = m.group('Name')\n\n                    rb = any([block_start == annotation[fusion][transcript_id]['right_break'],\n                              block_stop == annotation[fusion][transcript_id]['right_break']])\n\n                    lb = any([block_start == annotation[fusion][transcript_id]['left_break'],\n                              block_stop == annotation[fusion][transcript_id]['left_break']])\n\n                    if strand == '-' and rb:\n                        transcript_split = int(m.group('stop')) + 1   # Off by one\n                        # Take the reverse complement to orient transcripts from 5' to 3'\n                        five_seq = transcripts[transcript_id][transcript_split:]\n                        five_pr_splits[fusion][transcript_id] = five_seq.translate(trans)[::-1]\n                        three_seq = transcripts[transcript_id][:transcript_split]\n                        three_pr_splits[fusion][transcript_id] = three_seq.translate(trans)[::-1]\n\n                    elif strand == '+' and lb:\n                        transcript_split = int(m.group('stop'))\n                        s1 = transcripts[transcript_id][:transcript_split]\n                        five_pr_splits[fusion][transcript_id] = s1\n                        s2 = transcripts[transcript_id][transcript_split:]\n                        three_pr_splits[fusion][transcript_id] = s2\n\n    return five_pr_splits, three_pr_splits", "label": 1}
{"code": "def positionally(selector, operations, processed = {})\n      if selector.size == 1 || selector.values.any? { |val| val.nil? }\n        return operations\n      end\n      keys = selector.keys.map{ |m| m.sub('._id','') } - ['_id']\n      keys = keys.sort_by { |s| s.length*-1 }\n      process_operations(keys, operations, processed)\n    end", "label": 4}
{"code": "public static ComplexNumber Pow(ComplexNumber z1, double n) {\r\n\r\n        double norm = Math.pow(z1.getMagnitude(), n);\r\n        double angle = 360 - Math.abs(Math.toDegrees(Math.atan(z1.imaginary / z1.real)));\r\n\r\n        double common = n * angle;\r\n\r\n        double r = norm * Math.cos(Math.toRadians(common));\r\n        double i = norm * Math.sin(Math.toRadians(common));\r\n\r\n        return new ComplexNumber(r, i);\r\n\r\n    }", "label": 0}
{"code": "func (f *Fpdf) GetFontDesc(familyStr, styleStr string) FontDescType {\n\tif familyStr == \"\" {\n\t\treturn f.currentFont.Desc\n\t}\n\treturn f.fonts[getFontKey(familyStr, styleStr)].Desc\n}", "label": 5}
{"code": "def score(self, X, y):\n        \"\"\"\n        Calculate accuracy score.\n\n        Needed because of bug in metrics.accuracy_score when comparing\n        list with numpy array.\n        \"\"\"\n        predictions = self.predict(X)\n        true = 0.0\n        total = 0.0\n        for i in range(len(predictions)):\n            total += 1\n            if predictions[i] == y[i]:\n                true += 1\n        return true/total", "label": 1}
{"code": "function mix (receiver, supplier) {\n  for (var key in supplier) {\n    receiver[key] = supplier[key];\n  }\n  return receiver;\n}", "label": 3}
{"code": "public int sharedSegments(Triangle t2) {\n\t\tint counter = 0;\n\n\t\tif(a.equals(t2.a)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(a.equals(t2.b)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(a.equals(t2.c)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(b.equals(t2.a)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(b.equals(t2.b)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(b.equals(t2.c)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(c.equals(t2.a)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(c.equals(t2.b)) {\n\t\t\tcounter++;\n\t\t}\n\t\tif(c.equals(t2.c)) {\n\t\t\tcounter++;\n\t\t}\n\n\t\treturn counter;\n\t}", "label": 0}
{"code": "func EarliestExpiry(times ...time.Time) time.Time {\n\tif len(times) == 0 {\n\t\treturn time.Time{}\n\t}\n\tsort.Sort(earliest(times))\n\treturn times[0]\n}", "label": 5}
{"code": "protected function setupRowVariables($data, $row)\n    {\n        $processor = new RowProcessor($data, $row);\n\n        return $processor\n            ->rowValue('DT_RowId', $this->templates['DT_RowId'])\n            ->rowValue('DT_RowClass', $this->templates['DT_RowClass'])\n            ->rowData('DT_RowData', $this->templates['DT_RowData'])\n            ->rowData('DT_RowAttr', $this->templates['DT_RowAttr'])\n            ->getData();\n    }", "label": 2}
{"code": "def register(self, name, function, description=None):\n        \"\"\"\n        Register a new thread.\n\n        :param function: Function, which gets called for the new thread\n        :type function: function\n        :param name: Unique name of the thread for documentation purposes.\n        :param description: Short description of the thread\n        \"\"\"\n        return self.__app.threads.register(name, function, self._plugin, description)", "label": 1}
{"code": "private function getOrCreateClassMetadataDefinition(string $className, ?ClassMetadata $parent) : ClassMetadataDefinition\n    {\n        if (! isset($this->definitions[$className])) {\n            $this->definitions[$className] = $this->definitionFactory->build($className, $parent);\n        }\n\n        return $this->definitions[$className];\n    }", "label": 2}
{"code": "func (f *FileName) Path() string {\n\tcp := strings.Split(f.Name, \"\\x00\")\n\n\tif len(cp) == 0 || cp[0] != serverPolicyRootShareName {\n\t\treturn \"\" // TODO: not happening until if/when we handle Windows shares\n\t}\n\n\tcp[0] = \"\"\n\n\treturn strings.Join(cp, \"/\")\n}", "label": 5}
{"code": "function hide(id) {\n    $('#ah' + id).hide();\n    $('#ao' + id).show();\n    var div = $('#sc' + id);\n    div.slideUp('fast', function() {\n      div.remove();\n    });\n  }", "label": 3}
{"code": "function undefinedOrNullToEmptyArray(valueToConvert) {\n    if (_.isUndefined(valueToConvert) || _.isNull(valueToConvert)) {\n      valueToConvert = [];\n    }\n    return valueToConvert;\n  }", "label": 3}
{"code": "func (s *handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\taction := r.Header.Get(\"SOAPAction\")\n\tenv := soap.Envelope{}\n\tnow := time.Now()\n\tlifetime := &internal.Lifetime{\n\t\tCreated: now.Format(internal.Time),\n\t\tExpires: now.Add(5 * time.Minute).Format(internal.Time),\n\t}\n\n\tswitch path.Base(action) {\n\tcase \"Issue\":\n\t\tbody := internal.RequestSecurityTokenBody{\n\t\t\tRes: &internal.RequestSecurityTokenResponseCollection{\n\t\t\t\tRequestSecurityTokenResponse: internal.RequestSecurityTokenResponse{\n\t\t\t\t\tRequestedSecurityToken: internal.RequestedSecurityToken{\n\t\t\t\t\t\tAssertion: token,\n\t\t\t\t\t},\n\t\t\t\t\tLifetime: lifetime,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tenv.Body = body\n\tcase \"Renew\":\n\t\tbody := internal.RenewSecurityTokenBody{\n\t\t\tRes: &internal.RequestSecurityTokenResponse{\n\t\t\t\tRequestedSecurityToken: internal.RequestedSecurityToken{\n\t\t\t\t\tAssertion: token,\n\t\t\t\t},\n\t\t\t\tLifetime: lifetime,\n\t\t\t},\n\t\t}\n\t\tenv.Body = body\n\tdefault:\n\t\tlog.Printf(\"sts: unsupported action=%s\", action)\n\t\tw.WriteHeader(http.StatusNotFound)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusOK)\n\tfmt.Fprint(w, internal.Marshal(env))\n}", "label": 5}
{"code": "function validateObject(job, object, callback) {\n\t\tif (typeof object.value === 'undefined') {\n\t\t\tvar onLoad = function (err, obj) {\n\t\t\t\tif (err) {\n\t\t\t\t\tjob.error = err;\n\t\t\t\t\treturn callback(err);\n\t\t\t\t}\n\t\t\t\tobject.value = obj;\n\t\t\t\tdoValidateObject(job, object, callback);\n\t\t\t};\n\t\t\tvar opts = {\n\t\t\t\ttimeout: (job.context.options.timeout || 5000)\n\t\t\t};\n\t\t\t//TODO verify http:, file: and plain paths all load properly\n\t\t\tif (object.path) {\n\t\t\t\tloader.loadPath(object.path, opts, onLoad);\n\t\t\t}\n\t\t\telse if (object.url) {\n\t\t\t\tloader.load(object.url, opts, onLoad);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcallback(new Error('object missing value, path or url'));\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tdoValidateObject(job, object, callback);\n\t\t}\n\t}", "label": 3}
{"code": "protected function handleChangedParameters()\n    {\n        if (($this->getOptions() & static::IMMUTABLE) && $this->dateClass === Carbon::class) {\n            $this->setDateClass(CarbonImmutable::class);\n        } elseif (!($this->getOptions() & static::IMMUTABLE) && $this->dateClass === CarbonImmutable::class) {\n            $this->setDateClass(Carbon::class);\n        }\n\n        $this->validationResult = null;\n    }", "label": 2}
{"code": "def color_point(x, y, fill)\n      f = copy\n      f.pixel_color(x, y, fill)\n      f\n    end", "label": 4}
{"code": "public static base_responses kill(nitro_service client, systemsession resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsystemsession killresources[] = new systemsession[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tkillresources[i] = new systemsession();\n\t\t\t\tkillresources[i].sid = resources[i].sid;\n\t\t\t\tkillresources[i].all = resources[i].all;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, killresources,\"kill\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected function updateTags($entry)\n    {\n        if (! empty($entry->tagsChanges['added'])) {\n            $this->table('telescope_entries_tags')->insert(\n                collect($entry->tagsChanges['added'])->map(function ($tag) use ($entry) {\n                    return [\n                        'entry_uuid' => $entry->uuid,\n                        'tag' => $tag,\n                    ];\n                })->toArray()\n            );\n        }\n\n        collect($entry->tagsChanges['removed'])->each(function ($tag) use ($entry) {\n            $this->table('telescope_entries_tags')->where([\n                'entry_uuid' => $entry->uuid,\n                'tag' => $tag,\n            ])->delete();\n        });\n    }", "label": 2}
{"code": "def render_hashes(tags, **opts)\n      meta_tags.meta_tags.each_key do |property|\n        render_hash(tags, property, **opts)\n      end\n    end", "label": 4}
{"code": "func (s *AuthServer) AuthenticateUser(req AuthenticateUserRequest) error {\n\terr := s.authenticateUser(req)\n\tif err != nil {\n\t\ts.EmitAuditEvent(events.UserLocalLoginFailure, events.EventFields{\n\t\t\tevents.EventUser:          req.Username,\n\t\t\tevents.LoginMethod:        events.LoginMethodLocal,\n\t\t\tevents.AuthAttemptSuccess: false,\n\t\t\tevents.AuthAttemptErr:     err.Error(),\n\t\t})\n\t} else {\n\t\ts.EmitAuditEvent(events.UserLocalLogin, events.EventFields{\n\t\t\tevents.EventUser:          req.Username,\n\t\t\tevents.LoginMethod:        events.LoginMethodLocal,\n\t\t\tevents.AuthAttemptSuccess: true,\n\t\t})\n\t}\n\treturn err\n}", "label": 5}
{"code": "func (m *DatastoreFileManager) Move(ctx context.Context, src string, dst string) error {\n\tsrcp := m.Path(src)\n\tdstp := m.Path(dst)\n\n\tf := m.FileManager.MoveDatastoreFile\n\n\tif srcp.IsVMDK() {\n\t\tf = m.VirtualDiskManager.MoveVirtualDisk\n\t}\n\n\ttask, err := f(ctx, srcp.String(), m.Datacenter, dstp.String(), m.DatacenterTarget, m.Force)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn m.wait(ctx, task)\n}", "label": 5}
{"code": "def convertDate(self, date, prefix=\"\", weekday=False):\n        \"\"\"Convert a datetime object representing into a human-ready\n        string that can be read, spoken aloud, etc. In effect, runs\n        both convertDay and convertTime on the input, merging the results.\n\n        Args:\n            date (datetime.date): A datetime object to be converted into text.\n            prefix (str): An optional argument that prefixes the converted\n                string. For example, if prefix=\"in\", you'd receive \"in two\n                days\", rather than \"two days\", while the method would still\n                return \"tomorrow\" (rather than \"in tomorrow\").\n            weekday (bool): An optional argument that returns \"Monday, Oct. 1\"\n                if True, rather than \"Oct. 1\".\n\n        Returns:\n            A string representation of the input day and time.\n        \"\"\"\n        dayString = self.convertDay(\n            date, prefix=prefix, weekday=weekday)\n        timeString = self.convertTime(date)\n        return dayString + \" at \" + timeString", "label": 1}
{"code": "function init() {\n\t\t\t/* jshint validthis: true */\n\t\t\t// All construction is actually done in the init method.\n\t\t\tif (!initializing) {\n\t\t\t\t//!steal-remove-start\n\t\t\t\tif(process.env.NODE_ENV !== 'production') {\n\t\t\t\t\tif(!this || (this.constructor !== Constructor) &&\n\t\t\t\t\t// We are being called without `new` or we are extending.\n\t\t\t\t\targuments.length && Constructor.constructorExtends) {\n\t\t\t\t\t\tdev.warn('can/construct/construct.js: extending a Construct without calling extend');\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//!steal-remove-end\n\n\t\t\t\treturn (!this || this.constructor !== Constructor) &&\n\t\t\t\t// We are being called without `new` or we are extending.\n\t\t\t\targuments.length && Constructor.constructorExtends ? Constructor.extend.apply(Constructor, arguments) :\n\t\t\t\t// We are being called with `new`.\n\t\t\t\tConstructor.newInstance.apply(Constructor, arguments);\n\t\t\t}\n\t\t}", "label": 3}
{"code": "def oauth_authenticate(client_id, user, require_existing_link=False):\n    \"\"\"Authenticate an oauth authorized callback.\n\n    :param client_id: The client id.\n    :param user: A user instance.\n    :param require_existing_link: If ``True``, check if remote account exists.\n        (Default: ``False``)\n    :returns: ``True`` if the user is successfully authenticated.\n    \"\"\"\n    # Authenticate via the access token (access token used to get user_id)\n    if not requires_confirmation(user):\n        after_this_request(_commit)\n        if login_user(user, remember=False):\n            if require_existing_link:\n                account = RemoteAccount.get(user.id, client_id)\n                if account is None:\n                    logout_user()\n                    return False\n            return True\n    return False", "label": 1}
{"code": "def any?(*candidates)\n      if candidates.none?\n        super\n      else\n        candidates.any? do |candidate|\n          include?(candidate.to_sym) || include?(candidate.to_s)\n        end\n      end\n    end", "label": 4}
{"code": "def cmd_namespace(self):\n        \"\"\"\n            A read-only property that gives the namespace of the system for evaluating commands.\n        \"\"\"\n        import automate\n        ns = dict(list(automate.__dict__.items()) + list(self.namespace.items()))\n        return ns", "label": 1}
{"code": "function(dir) {\n      var results = [];\n\n      var list = fs.readdirSync(dir);\n\n      list.forEach(function(file) {\n        // Check for every given pattern, regardless of whether it is an array or a string\n        var matchesSomeExclude = [].concat(options.exclude).some(function(regexp) {\n          return file.match(regexp) != null;\n        });\n\n        if(!matchesSomeExclude) {\n          var matchesSomePattern = [].concat(options.match).some(function(regexp) {\n            return file.match(regexp) != null;\n          });\n\n          file = path.resolve(dir, file);\n          var stat = fs.statSync(file);\n\n          if (stat && stat.isDirectory()) {\n            if(matchesSomePattern) {\n              results = results.concat(file);\n            }\n            results = results.concat(walk(file));\n          }\n        }\n      });\n\n      return results;\n    }", "label": 3}
{"code": "public function restore()\n    {\n        if ($this->hidden_at !== null) {\n            $this->hidden_at = null;\n            $this->hidden_user_id = null;\n\n            $this->raise(new Restored($this));\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "public function setOutputVersionFormat($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Logging\\V2\\LogSink_VersionFormat::class);\n        $this->output_version_format = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def can(action = nil, subject = nil, *attributes_and_conditions, &block)\n      add_rule(Rule.new(true, action, subject, *attributes_and_conditions, &block))\n    end", "label": 4}
{"code": "public static auditsyslogpolicy_vpnglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauditsyslogpolicy_vpnglobal_binding obj = new auditsyslogpolicy_vpnglobal_binding();\n\t\tobj.set_name(name);\n\t\tauditsyslogpolicy_vpnglobal_binding response[] = (auditsyslogpolicy_vpnglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getAnnotationInfo(name, fn, isArray) {\n\n    if (!fn) { return null; }\n\n    var str = fn.toString();\n    var rgx = new RegExp('(?:@' + name + '\\\\()(.*)(?:\\\\))');\n\n    var matches = rgx.exec(str);\n\n    if (!matches || matches.length < 2) {\n        return null;\n    }\n\n    var annotation = matches[1];\n    if (isArray) {\n        annotation = '{ \"data\": ' + annotation + '}';\n    }\n\n    // we want all double quotes in our string\n    annotation = annotation.replace(/'/g, '\"');\n\n    // parse out the object from the string\n    var obj = null;\n    try {\n        obj = JSON.parse(annotation);\n    }\n    catch (ex) {\n        /* eslint no-console:0 */\n        console.log('Annotation parse error with ' + annotation);\n        throw ex;\n    }\n\n    if (isArray) {\n        obj = obj.data;\n    }\n\n    return obj;\n}", "label": 3}
{"code": "function ScrapinodeError(message){\n   Error.call(this);\n   Error.captureStackTrace(this,arguments.callee);\n   this.name = 'ScrapinodeError';\n   this.message = message;\n}", "label": 3}
{"code": "func (n *network) destroySandbox() {\n\tif n.sbox != nil {\n\t\tfor _, iface := range n.sbox.Info().Interfaces() {\n\t\t\tif err := iface.Remove(); err != nil {\n\t\t\t\tlogrus.Debugf(\"Remove interface %s failed: %v\", iface.SrcName(), err)\n\t\t\t}\n\t\t}\n\n\t\tfor _, s := range n.subnets {\n\t\t\tif hostMode {\n\t\t\t\tif err := removeFilters(n.id[:12], s.brName); err != nil {\n\t\t\t\t\tlogrus.Warnf(\"Could not remove overlay filters: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif s.vxlanName != \"\" {\n\t\t\t\terr := deleteInterface(s.vxlanName)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogrus.Warnf(\"could not cleanup sandbox properly: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif hostMode {\n\t\t\tif err := removeNetworkChain(n.id[:12]); err != nil {\n\t\t\t\tlogrus.Warnf(\"could not remove network chain: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\t// Close the netlink socket, this will also release the watchMiss goroutine that is using it\n\t\tif n.nlSocket != nil {\n\t\t\tn.nlSocket.Close()\n\t\t\tn.nlSocket = nil\n\t\t}\n\n\t\tn.sbox.Destroy()\n\t\tn.sbox = nil\n\t}\n}", "label": 5}
{"code": "public function reset()\n    {\n        $migrations = $this->getMigrations(true);\n\n        $this->requireFiles($migrations);\n\n        $migrated = [];\n\n        foreach ($migrations as $migration) {\n            $data = $this->find($migration);\n\n            if ($data->count()) {\n                $migrated[] = $migration;\n\n                $this->down($migration);\n\n                $data->delete();\n            }\n        }\n\n        return $migrated;\n    }", "label": 2}
{"code": "public List<Dependency> getModuleDependencies(final String moduleName, final String moduleVersion, final Boolean fullRecursive, final Boolean corporate, final Boolean thirdParty) throws GrapesCommunicationException {\n        final Client client = getClient();\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.getArtifactDependencies(moduleName, moduleVersion));\n        final ClientResponse response = resource.queryParam(ServerAPI.SCOPE_COMPILE_PARAM, \"true\")\n                .queryParam(ServerAPI.SCOPE_PROVIDED_PARAM, \"true\")\n                .queryParam(ServerAPI.SCOPE_RUNTIME_PARAM, \"true\")\n                .queryParam(ServerAPI.SCOPE_TEST_PARAM, \"true\")\n                .queryParam(ServerAPI.RECURSIVE_PARAM, fullRecursive.toString())\n                .queryParam(ServerAPI.SHOW_CORPORATE_PARAM, corporate.toString())\n                .queryParam(ServerAPI.SHOW_THIRPARTY_PARAM, thirdParty.toString())\n                .accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);\n\n        client.destroy();\n        if(ClientResponse.Status.OK.getStatusCode() != response.getStatus()){\n            final String message = String.format(FAILED_TO_GET_MODULE, \"get module ancestors \", moduleName, moduleVersion);\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n\n        return response.getEntity(new GenericType<List<Dependency>>(){});\n    }", "label": 0}
{"code": "function(input, delaySort, remoteData)\n  {\n    var model = this.parseModel( input, remoteData );\n    var key = model.$key();\n\n    this.map.put( key, model );\n    this.trigger( Collection.Events.Add, [this, model, this.map.indices[ key ]] );\n\n    if ( !delaySort )\n    {\n      this.sort();\n    }\n\n    return this;\n  }", "label": 3}
{"code": "def remove_modifier_list(location_id, modifier_list_id, item_id, opts = {})\n      data, _status_code, _headers = remove_modifier_list_with_http_info(location_id, modifier_list_id, item_id, opts)\n      return data\n    end", "label": 4}
{"code": "func (cli *NetworkCli) CmdNetwork(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"network\", \"COMMAND [OPTIONS] [arg...]\", networkUsage(chain), false)\n\tcmd.Require(flag.Min, 1)\n\terr := cmd.ParseFlags(args, true)\n\tif err == nil {\n\t\tcmd.Usage()\n\t\treturn fmt.Errorf(\"invalid command : %v\", args)\n\t}\n\treturn err\n}", "label": 5}
{"code": "def bibitem_as_plaintext(bibitem):\n    \"\"\"\n    Return a plaintext representation of a bibitem from the ``.bbl`` file.\n\n    .. note::\n\n        This plaintext representation can be super ugly, contain URLs and so \\\n        on.\n\n    .. note::\n\n        You need to have ``delatex`` installed system-wide, or to build it in \\\n                this repo, according to the ``README.md`` before using this \\\n                function.\n\n    :param bibitem: The text content of the bibitem.\n    :returns: A cleaned plaintext citation from the bibitem.\n    \"\"\"\n    try:\n        output = subprocess.check_output([\"delatex\",\n                                          \"-s\"],\n                                         input=bibitem.encode(\"utf-8\"))\n    except FileNotFoundError:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        output = subprocess.check_output([\"%s/../external/opendetex/delatex\" %\n                                          (script_dir,),\n                                          \"-s\"],\n                                         input=bibitem.encode(\"utf-8\"))\n    output = output.decode(\"utf-8\")\n    output = tools.clean_whitespaces(output)\n    return output", "label": 1}
{"code": "public function sendDeleteBroadcastLists($lists)\n    {\n        $msgId = $this->createIqId();\n        $listNode = [];\n        if ($lists != null && count($lists) > 0) {\n            for ($i = 0; $i < count($lists); $i++) {\n                $listNode[$i] = new ProtocolNode('list', ['id' => $lists[$i]], null, null);\n            }\n        } else {\n            $listNode = null;\n        }\n        $deleteNode = new ProtocolNode('delete', null, $listNode, null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'w:b',\n                'type'  => 'set',\n                'to'    => Constants::WHATSAPP_SERVER,\n            ], [$deleteNode], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "func isNil(object interface{}) bool {\n\tif object == nil {\n\t\treturn true\n\t}\n\n\tvalue := reflect.ValueOf(object)\n\tkind := value.Kind()\n\tisNilableKind := containsKind(\n\t\t[]reflect.Kind{\n\t\t\treflect.Chan, reflect.Func,\n\t\t\treflect.Interface, reflect.Map,\n\t\t\treflect.Ptr, reflect.Slice},\n\t\tkind)\n\n\tif isNilableKind && value.IsNil() {\n\t\treturn true\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "public function prependBuild(callable $middleware, $name = null)\n    {\n        $this->add(self::BUILD, $name, $middleware, true);\n    }", "label": 2}
{"code": "public Object lookup(String name) throws ObjectNameNotFoundException\r\n    {\r\n        /**\r\n         * Is DB open? ODMG 3.0 says it has to be to call bind.\r\n         */\r\n        if (!this.isOpen())\r\n        {\r\n            throw new DatabaseClosedException(\"Database is not open. Must have an open DB to call lookup\");\r\n        }\r\n        /**\r\n         * Is Tx open? ODMG 3.0 says it has to be to call bind.\r\n         */\r\n        TransactionImpl tx = getTransaction();\r\n        if (tx == null || !tx.isOpen())\r\n        {\r\n            throw new TransactionNotInProgressException(\"Tx is not open. Must have an open TX to call lookup.\");\r\n        }\r\n\r\n        return tx.getNamedRootsMap().lookup(name);\r\n    }", "label": 0}
{"code": "function createTempFile(options) {\n  options = _.opts(options, {cleanup: true});\n  return _createTemporaryPath((f) => fs.writeFileSync(f, ''), options.cleanup);\n}", "label": 3}
{"code": "public static base_response update(nitro_service client, snmpmanager resource) throws Exception {\n\t\tsnmpmanager updateresource = new snmpmanager();\n\t\tupdateresource.ipaddress = resource.ipaddress;\n\t\tupdateresource.netmask = resource.netmask;\n\t\tupdateresource.domainresolveretry = resource.domainresolveretry;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "private function getRetryOptions(array $options)\n    {\n        return [\n            'retries' => isset($options['retries'])\n                ? $options['retries']\n                : $this->retries,\n            'retryFunction' => isset($options['restRetryFunction'])\n                ? $options['restRetryFunction']\n                : $this->retryFunction,\n            'delayFunction' => isset($options['restDelayFunction'])\n                ? $options['restDelayFunction']\n                : $this->delayFunction,\n            'calcDelayFunction' => isset($options['restCalcDelayFunction'])\n                ? $options['restCalcDelayFunction']\n                : $this->calcDelayFunction\n        ];\n    }", "label": 2}
{"code": "def only(*args)\n      return clone if args.flatten.empty?\n      args = args.flatten\n      if (args & Fields::IDS).empty?\n        args.unshift(:_id)\n      end\n      if klass.hereditary?\n        super(*args.push(:_type))\n      else\n        super(*args)\n      end\n    end", "label": 4}
{"code": "public function receive(&$header)\n    {\n        $body = $this->relay->receiveSync($flags);\n\n        if ($flags & Relay::PAYLOAD_CONTROL) {\n            if ($this->handleControl($body, $header, $flags)) {\n                // wait for the next command\n                return $this->receive($header);\n            }\n\n            // no context for the termination.\n            $header = null;\n\n            // Expect process termination\n            return null;\n        }\n\n        if ($flags & Relay::PAYLOAD_ERROR) {\n            return new \\Error($body);\n        }\n\n        return $body;\n    }", "label": 2}
{"code": "function exportThemes(req, res, next) {\n  var options = req.connectionOptions;\n\n  forms.exportThemes(options, resultHandler(constants.resultTypes.themes, req, next));\n}", "label": 3}
{"code": "function setDefaults(model, defaults) {\n    if (!defaults) { return; }\n\n    _.each(defaults, function (value, key) {\n        if (model[key] === undefined) {\n            model[key] = value;\n        }\n    });\n}", "label": 3}
{"code": "def enqueue(options = {})\n      self.scheduled_at = options[:wait].seconds.from_now.to_f if options[:wait]\n      self.scheduled_at = options[:wait_until].to_f if options[:wait_until]\n      self.queue_name   = self.class.queue_name_from_part(options[:queue]) if options[:queue]\n      self.priority     = options[:priority].to_i if options[:priority]\n      successfully_enqueued = false\n\n      run_callbacks :enqueue do\n        if scheduled_at\n          self.class.queue_adapter.enqueue_at self, scheduled_at\n        else\n          self.class.queue_adapter.enqueue self\n        end\n\n        successfully_enqueued = true\n      end\n\n      if successfully_enqueued\n        self\n      else\n        if self.class.return_false_on_aborted_enqueue\n          false\n        else\n          ActiveSupport::Deprecation.warn(\n            \"Rails 6.1 will return false when the enqueuing is aborted. Make sure your code doesn't depend on it\" \\\n            \" returning the instance of the job and set `config.active_job.return_false_on_aborted_enqueue = true`\" \\\n            \" to remove the deprecations.\"\n          )\n\n          self\n        end\n      end\n    end", "label": 4}
{"code": "private void addEdgesForVertex(Vertex vertex)\r\n    {\r\n        ClassDescriptor cld = vertex.getEnvelope().getClassDescriptor();\r\n        Iterator rdsIter = cld.getObjectReferenceDescriptors(true).iterator();\r\n        while (rdsIter.hasNext())\r\n        {\r\n            ObjectReferenceDescriptor rds = (ObjectReferenceDescriptor) rdsIter.next();\r\n            addObjectReferenceEdges(vertex, rds);\r\n        }\r\n        Iterator cdsIter = cld.getCollectionDescriptors(true).iterator();\r\n        while (cdsIter.hasNext())\r\n        {\r\n            CollectionDescriptor cds = (CollectionDescriptor) cdsIter.next();\r\n            addCollectionEdges(vertex, cds);\r\n        }\r\n    }", "label": 0}
{"code": "func templateChainDependencies(template Template) []Template {\n\trequires := template.Templates()\n\tchain := make([]Template, len(requires)*2)\n\tfor _, req := range requires {\n\t\tchain = append(chain, templateChainDependencies(req)...)\n\t}\n\tchain = append(chain, template)\n\treturn chain\n}", "label": 5}
{"code": "func SqTableColumns(db models.XODB, schema string, table string) ([]*models.Column, error) {\n\tvar err error\n\n\t// grab\n\trows, err := models.SqTableColumns(db, table)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// fix columns\n\tvar cols []*models.Column\n\tfor _, row := range rows {\n\t\tcols = append(cols, &models.Column{\n\t\t\tFieldOrdinal: row.FieldOrdinal,\n\t\t\tColumnName:   row.ColumnName,\n\t\t\tDataType:     row.DataType,\n\t\t\tNotNull:      row.NotNull,\n\t\t\tDefaultValue: row.DefaultValue,\n\t\t\tIsPrimaryKey: row.PkColIndex != 0,\n\t\t})\n\t}\n\n\treturn cols, nil\n}", "label": 5}
{"code": "function (numeral) {\n  var matches = numeral.match(/([b#]?)([iIvV]+)/);\n  var halfSteps = interval.parse(_.indexOf(romanNumeral, matches[2]).toString()).halfSteps();\n\n  if (matches[1] === 'b') halfSteps -= 1;\n  if (matches[1] === '#') halfSteps += 1;\n\n  return halfSteps;\n}", "label": 3}
{"code": "def checkvalid(s, m, pk):\n    \"\"\"\n    Not safe to use when any argument is secret.\n    See module docstring.  This function should be used only for\n    verifying public signatures of public messages.\n    \"\"\"\n    if len(s) != b // 4:\n        raise ValueError(\"signature length is wrong\")\n\n    if len(pk) != b // 8:\n        raise ValueError(\"public-key length is wrong\")\n\n    s = bytearray(s)\n    m = bytearray(m)\n    pk = bytearray(pk)\n\n    R = decodepoint(s[: b // 8])\n    A = decodepoint(pk)\n    S = decodeint(s[b // 8 : b // 4])\n    h = Hint(encodepoint(R) + pk + m)\n\n    (x1, y1, z1, t1) = P = scalarmult_B(S)\n    (x2, y2, z2, t2) = Q = edwards_add(R, scalarmult(A, h))\n\n    if (\n        not isoncurve(P)\n        or not isoncurve(Q)\n        or (x1 * z2 - x2 * z1) % q != 0\n        or (y1 * z2 - y2 * z1) % q != 0\n    ):\n        raise SignatureMismatch(\"signature does not pass verification\")", "label": 1}
{"code": "func (v *validate) ExtractType(field reflect.Value) (reflect.Value, reflect.Kind, bool) {\n\treturn v.extractTypeInternal(field, false)\n}", "label": 5}
{"code": "public function readRows(array $options = [])\n    {\n        $rowKeys = $this->pluck('rowKeys', $options, false) ?: [];\n        $ranges = $this->pluck('rowRanges', $options, false) ?: [];\n        $filter = $this->pluck('filter', $options, false) ?: null;\n\n        array_walk($ranges, function (&$range) {\n            $range = $this->serializer->decodeMessage(\n                new RowRange(),\n                $range\n            );\n        });\n        if (!is_array($rowKeys)) {\n            throw new \\InvalidArgumentException(\n                sprintf(\n                    'Expected rowKeys to be of type array, instead got \\'%s\\'.',\n                    gettype($rowKeys)\n                )\n            );\n        }\n        if ($ranges || $rowKeys) {\n            $options['rows'] = $this->serializer->decodeMessage(\n                new RowSet,\n                [\n                    'rowKeys' => $rowKeys,\n                    'rowRanges' => $ranges\n                ]\n            );\n        }\n        if ($filter !== null) {\n            if (!$filter instanceof FilterInterface) {\n                throw new \\InvalidArgumentException(\n                    sprintf(\n                        'Expected filter to be of type \\'%s\\', instead got \\'%s\\'.',\n                        FilterInterface::class,\n                        gettype($filter)\n                    )\n                );\n            }\n            $options['filter'] = $filter->toProto();\n        }\n        return new ChunkFormatter(\n            [$this->gapicClient, 'readRows'],\n            $this->tableName,\n            $options + $this->options\n        );\n    }", "label": 2}
{"code": "def point_displ(pt1, pt2):\n    \"\"\" Calculate the displacement vector between two n-D points.\n\n    pt1 - pt2\n\n    .. todo:: Complete point_disp docstring\n\n    \"\"\"\n\n    #Imports\n    import numpy as np\n\n    # Make iterable\n    if not np.iterable(pt1):\n        pt1 = np.float64(np.array([pt1]))\n    else:\n        pt1 = np.float64(np.array(pt1).squeeze())\n    ## end if\n    if not np.iterable(pt2):\n        pt2 = np.float64(np.array([pt2]))\n    else:\n        pt2 = np.float64(np.array(pt2).squeeze())\n    ## end if\n\n    # Calculate the displacement vector and return\n    displ = np.matrix(np.subtract(pt2, pt1)).reshape(3,1)\n    return displ", "label": 1}
{"code": "def load(self, lemmatizer_path):\n        \"\"\"\n        This methods load the IWNLP.Lemmatizer json file and creates a dictionary\n         of lowercased forms which maps each form to its possible lemmas.\n        \"\"\"\n        self.lemmatizer = {}\n        with io.open(lemmatizer_path, encoding='utf-8') as data_file:\n            raw = json.load(data_file)\n            for entry in raw:\n                self.lemmatizer[entry[\"Form\"]] = entry[\"Lemmas\"]\n        self.apply_blacklist()", "label": 1}
{"code": "func (a *Allocator) ReleasePool(poolID string) error {\n\tlogrus.Debugf(\"ReleasePool(%s)\", poolID)\n\tk := SubnetKey{}\n\tif err := k.FromString(poolID); err != nil {\n\t\treturn types.BadRequestErrorf(\"invalid pool id: %s\", poolID)\n\t}\n\nretry:\n\tif err := a.refresh(k.AddressSpace); err != nil {\n\t\treturn err\n\t}\n\n\taSpace, err := a.getAddrSpace(k.AddressSpace)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tremove, err := aSpace.updatePoolDBOnRemoval(k)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err = a.writeToStore(aSpace); err != nil {\n\t\tif _, ok := err.(types.RetryError); !ok {\n\t\t\treturn types.InternalErrorf(\"pool (%s) removal failed because of %v\", poolID, err)\n\t\t}\n\t\tgoto retry\n\t}\n\n\treturn remove()\n}", "label": 5}
{"code": "def remove_urls(text_string):\n    '''\n    Removes all URLs within text_string and returns the new string as type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a non-string argument be passed\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        return \" \".join(re.sub(r'http\\S+', \"\", text_string).split())\n    else:\n        raise InputError(\"string not passed as argument\")", "label": 1}
{"code": "def deep_update(other_hash, &blk)\n      other_hash.each_pair do |k, v|\n        key = convert_key(k)\n        if v.is_a?(::Hash) && key?(key) && regular_reader(key).is_a?(Mash)\n          custom_reader(key).deep_update(v, &blk)\n        else\n          value = convert_value(v, true)\n          value = convert_value(yield(key, self[k], value), true) if blk && key?(k)\n          custom_writer(key, value, false)\n        end\n      end\n      self\n    end", "label": 4}
{"code": "def process(exp)\n      exp.children.grep(AST::Node).each { |child| build(child, exp) }\n    end", "label": 4}
{"code": "def body_lazy(value)\n      process_body_raw if @body_raw && value\n      case\n      when value == nil || value.length<=0\n        @body = Mail::Body.new('')\n        @body_raw = nil\n        add_encoding_to_body\n      when @body && @body.multipart?\n        self.text_part = value\n      else\n        @body_raw = value\n      end\n    end", "label": 4}
{"code": "function resolveAppBuild(appTsConfigPath) {\n  const outDir = getAppBuildFolder(appTsConfigPath);\n  const buildPath = path.join(path.dirname(appTsConfigPath), outDir);\n  return buildPath;\n}", "label": 3}
{"code": "def retry_until_true(wait=0.5, &block)\n      EM::Timer.new(wait) do\n        unless block.call\n          retry_until_true(wait, &block)\n        end\n      end\n    end", "label": 4}
{"code": "public function setDocuments($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Firestore\\V1\\Document::class);\n        $this->documents = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func NewClient(ctx context.Context, c *vim25.Client) (*Client, error) {\n\tsc := c.Client.NewServiceClient(Path, Namespace)\n\tsc.Version = Version\n\n\treq := types.RetrieveServiceContent{\n\t\tThis: ServiceInstance,\n\t}\n\n\tres, err := methods.RetrieveServiceContent(ctx, sc, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Client{sc, res.Returnval}, nil\n}", "label": 5}
{"code": "def start\n      if defined?(JRUBY_VERSION)\n        unless options[:no_interactions]\n          abort \"\\nSorry, JRuby and interactive mode are incompatible.\\n\"\\\n            \"As a workaround, use the '-i' option instead.\\n\\n\"\\\n            \"More info: \\n\"\\\n            \" * https://github.com/guard/guard/issues/754\\n\"\\\n            \" * https://github.com/jruby/jruby/issues/2383\\n\\n\"\n        end\n      end\n      exit(Cli::Environments::Valid.new(options).start_guard)\n    end", "label": 4}
{"code": "function _connect() {\n        if (!_isDisconnected()) {\n            var bayeuxMessage = {\n                id: _nextMessageId(),\n                channel: '/meta/connect',\n                connectionType: _transport.getType()\n            };\n\n            // In case of reload or temporary loss of connection\n            // we want the next successful connect to return immediately\n            // instead of being held by the server, so that connect listeners\n            // can be notified that the connection has been re-established\n            if (!_connected) {\n                bayeuxMessage.advice = { timeout: 0 };\n            }\n\n            _setStatus('connecting');\n            _cometd._debug('Connect sent', bayeuxMessage);\n            _send(false, [bayeuxMessage], true, 'connect');\n            _setStatus('connected');\n        }\n    }", "label": 3}
{"code": "def add_conditional_formatting(cells, rules)\n      cf = ConditionalFormatting.new( :sqref => cells )\n      cf.add_rules rules\n      conditional_formattings << cf\n      conditional_formattings\n    end", "label": 4}
{"code": "func (c Color) Hex() int32 {\n\tif c&ColorIsRGB != 0 {\n\t\treturn (int32(c) & 0xffffff)\n\t}\n\tif v, ok := ColorValues[c]; ok {\n\t\treturn v\n\t}\n\treturn -1\n}", "label": 5}
{"code": "function getQueueEntry(zipfile) {\n    return function queueEntry(entry) {\n      queue.push({\n        zipfile: zipfile,\n        workingDir: params.workingDir,\n        entry: entry\n      }, function(err) {\n        if (err) {\n          logger.debug(\"Error unzipping file params.zipFilePath\", err);\n          //If one of the files has failed to unzip correctly. No point in continuing to unzip. Close the zip file.\n          zipfile.close();\n        }\n      });\n    };\n  }", "label": 3}
{"code": "function AssociationAttribute() {\n  /**\n   * It is a readonly property with the Entity that is associated with the\n   * current AssociationAttribute.\n   * @name\n   * module:back4app-entity/models/attributes/types.AssociationAttribute#Entity\n   * @type {!Class}\n   * @readonly\n   * @throws {module:back4app-entity/models/errors.EntityNotFoundError}\n   * @example\n   * var associationAttribute = new AssociationAttribute(\n   *   'associationAttribute',\n   *   MyEntity\n   * );\n   * console.log(associationAttribute.Entity == MyEntity) // Logs \"true\"\n   */\n  this.Entity = null;\n\n  var _Entity = null;\n  Object.defineProperty(this, 'Entity', {\n    get: function () {\n      if (typeof _Entity === 'string') {\n        _Entity = models.Entity.getSpecialization(_Entity);\n      }\n\n      return _Entity;\n    },\n    set: function () {\n      throw new Error(\n        'Entity property of an AssociationAttribute instance cannot be changed'\n      );\n    },\n    enumerable: true,\n    configurable: false\n  });\n\n  var argumentsArray = Array.prototype.slice.call(arguments);\n\n  expect(argumentsArray).to.have.length.within(\n    1,\n    5,\n    'Invalid arguments length when creating an AssociationAttribute (it has ' +\n    'to be passed from 1 to 5 arguments)'\n  );\n\n  if (argumentsArray.length === 1) {\n    var associationAttribute = argumentsArray[0];\n\n    expect(associationAttribute).to.be.an(\n      'object',\n      'Invalid argument type when creating an Attribute (it has to be an ' +\n      'object)'\n    );\n\n    associationAttribute = objects.copy(associationAttribute);\n\n    _Entity = associationAttribute.entity;\n    if (_Entity) {\n      delete associationAttribute.entity;\n    } else {\n      expect(associationAttribute).to.have.ownProperty(\n        'Entity',\n        'Property \"entity\" or \"Entity\" is required when creating an ' +\n        'AssociationAttribute'\n      );\n\n      _Entity = associationAttribute.Entity;\n      delete associationAttribute.Entity;\n    }\n\n    argumentsArray[0] = associationAttribute;\n  } else {\n    _Entity = argumentsArray.splice(1, 1)[0];\n  }\n\n  if (typeof _Entity !== 'string') {\n    expect(_Entity).to.be.a(\n      'function',\n      'Invalid argument \"entity\" when creating an AssociationAttribute (it ' +\n      'has to be a Class)'\n    );\n\n    expect(classes.isGeneral(models.Entity, _Entity)).to.equal(\n      true,\n      'Invalid argument \"entity\" when creating an AssociationAttribute (it ' +\n      'has to be a subclass of Entity)'\n    );\n  }\n\n  Attribute.apply(this, argumentsArray);\n}", "label": 3}
{"code": "func (h *Handle) Unselected() uint64 {\n\th.Lock()\n\tdefer h.Unlock()\n\treturn h.unselected\n}", "label": 5}
{"code": "public static File getJNLPLocalScratch()  {\r\n    try {\r\n      String machineName = InetAddress.getLocalHost().getHostName().split(\"\\\\.\")[0];\r\n      String username = System.getProperty(\"user.name\");\r\n      return new File(\"/\"+machineName+\"/scr1/\"+username);\r\n    } catch (Exception e) {\r\n      return new File(\"./scr/\"); // default scratch\r\n    }\r\n  }", "label": 0}
{"code": "public function setMutationResults($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Datastore\\V1\\MutationResult::class);\n        $this->mutation_results = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public Map<String, Object> getArtifactFieldsFilters() {\n\t\tfinal Map<String, Object> params = new HashMap<String, Object>();\n\n        for(final Filter filter: filters){\n            params.putAll(filter.artifactFilterFields());\n        }\n\n\t\treturn params;\n\t}", "label": 0}
{"code": "def extract_files_from(patterns) # rubocop:disable MethodLength\n      files = []\n\n      patterns.each do |pattern|\n        if File.file?(pattern)\n          files << pattern\n        else\n          begin\n            ::Find.find(pattern) do |file|\n              files << file if haml_file?(file)\n            end\n          rescue ::Errno::ENOENT\n            # File didn't exist; it might be a file glob pattern\n            matches = ::Dir.glob(pattern)\n            if matches.any?\n              files += matches\n            else\n              # One of the paths specified does not exist; raise a more\n              # descriptive exception so we know which one\n              raise HamlLint::Exceptions::InvalidFilePath,\n                    \"File path '#{pattern}' does not exist\"\n            end\n          end\n        end\n      end\n\n      files.uniq.sort.map { |file| normalize_path(file) }\n    end", "label": 4}
{"code": "def skip_child(self, child, ancestry):\n        \"\"\" get whether or not to skip the specified child \"\"\"\n        if child.any(): return True\n        for x in ancestry:\n            if x.choice():\n                return True\n        return False", "label": 1}
{"code": "func (a *AuthServer) createReverseTunnel(t services.TrustedCluster) error {\n\treverseTunnel := services.NewReverseTunnel(\n\t\tt.GetName(),\n\t\t[]string{t.GetReverseTunnelAddress()},\n\t)\n\treturn trace.Wrap(a.UpsertReverseTunnel(reverseTunnel))\n}", "label": 5}
{"code": "def numBlast_sort(blast, numHits, evalueT, bitT):\n    \"\"\"\n    parse b6 output with sorting\n    \"\"\"\n    header = ['#query', 'target', 'pident', 'alen', 'mismatch', 'gapopen',\n              'qstart', 'qend', 'tstart', 'tend', 'evalue', 'bitscore']\n    yield header\n    hmm = {h:[] for h in header}\n    for line in blast:\n        if line.startswith('#'):\n            continue\n        line = line.strip().split('\\t')\n        # Evalue and Bitscore thresholds\n        line[10], line[11] = float(line[10]), float(line[11])\n        evalue, bit = line[10], line[11]\n        if evalueT is not False and evalue > evalueT:\n            continue\n        if bitT is not False and bit < bitT:\n            continue\n        for i, h in zip(line, header):\n            hmm[h].append(i)\n    hmm = pd.DataFrame(hmm)\n    for query, df in hmm.groupby(by = ['#query']):\n        df = df.sort_values(by = ['bitscore'], ascending = False)\n        for hit in df[header].values[0:numHits]:\n            yield hit", "label": 1}
{"code": "public static vrid6 get(nitro_service service, Long id) throws Exception{\n\t\tvrid6 obj = new vrid6();\n\t\tobj.set_id(id);\n\t\tvrid6 response = (vrid6) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function parseHeader(authHeader, callback){\n        try {\n            var parts=authHeader.split(/:/),\n                username=parts[0],\n                password=parts[1];\n\n            callback(null, {username: username, password: password});\n        }\n        catch(ex){\n            callback(ex);\n        }\n    }", "label": 3}
{"code": "function skip(ignoreRouteUrls) {\n    return function ignoreUrl(req) {\n        const url = req.originalUrl || req.url;\n        return ignoreRouteUrls.includes(url);\n    };\n}", "label": 3}
{"code": "function buildSubmissionReceivedMessage(subscribers, formName, formSubmission) {\n  var msg = {};\n  msg.subscribers = subscribers;\n  msg.formId = formSubmission.formId;\n  msg.appId = formSubmission.appId;\n  msg.attachmentUrl = getAttachmentUrl(formSubmission);\n  msg.formName = formName || \"UNKNOWN FORM NAME\";\n  msg.submissionStatus = formSubmission.status;\n  msg.appEnvironment = formSubmission.appEnvironment;\n  msg.submissionStarted = formSubmission.submissionStartedTimestamp;\n  msg.submissionCompleted = formSubmission.submissionCompletedTimestamp;\n  msg.submissionId = formSubmission._id;\n  msg.deviceIPAddress = formSubmission.deviceIPAddress;\n  msg.deviceId = formSubmission.deviceId;\n  msg.submittedFields = [];\n\n  var form = formSubmission.formSubmittedAgainst;\n\n  // build helper structures\n  var fieldPageMap = {};\n  var fieldSectionMap = {};\n  var sectionsInPage = {};\n  form.pages.forEach(function(page) {\n    var currentSectionId = 'initial';\n    sectionsInPage[page._id] = [currentSectionId];\n    page.fields.forEach(function(field) {\n      fieldPageMap[field._id] = page._id;\n      if (field.type === 'sectionBreak') {\n        currentSectionId = field._id;\n        sectionsInPage[page._id].push(currentSectionId);\n      } else {\n        fieldSectionMap[field._id] = currentSectionId;\n      }\n    });\n  });\n\n  // get structured form fields\n  var pages = getStructuredFields(formSubmission, fieldPageMap, fieldSectionMap);\n\n  // construct message\n  form.pages.forEach(function(page) {\n    //is this page in submission?\n    if (pages[page._id]) {\n      var sections = sectionsInPage[page._id];\n      sections.forEach(function(section) {\n        var repSections = pages[page._id][section];\n        if (repSections) {\n          if (repSections.length === 1) {\n            repSections[0].forEach(function(formField) {\n              msg.submittedFields.push(getFieldMsg(formField, formSubmission));\n            });\n          } else {\n            repSections.forEach(function(repSection, index) {\n              msg.submittedFields.push(getField(section, formSubmission).name + ' - ' + (index + 1) + ':');\n              repSection.forEach(function(formField) {\n                msg.submittedFields.push(getFieldMsg(formField, formSubmission));\n              });\n            });\n          }\n        }\n      });\n    }\n  });\n\n  return msg;\n}", "label": 3}
{"code": "public void updateProvider(final String gavc, final String provider) {\n        final DbArtifact artifact = getArtifact(gavc);\n        repositoryHandler.updateProvider(artifact, provider);\n    }", "label": 0}
{"code": "private InputStream connect(String url) throws IOException {\n\t\tURLConnection conn = new URL(URL_BASE + url).openConnection();\n\t\tconn.setConnectTimeout(CONNECT_TIMEOUT);\n\t\tconn.setReadTimeout(READ_TIMEOUT);\n\t\tconn.setRequestProperty(\"User-Agent\", USER_AGENT);\n\t\treturn conn.getInputStream();\n\t}", "label": 0}
{"code": "def _costfcn(self, x):\n        \"\"\" Evaluates the objective function, gradient and Hessian for OPF.\n        \"\"\"\n        f = self._f(x)\n        df = self._df(x)\n        d2f = self._d2f(x)\n\n        return f, df, d2f", "label": 1}
{"code": "func (ta *TextArea) SetContent(text string) {\n\tta.Init()\n\tlines := strings.Split(strings.Trim(text, \"\\n\"), \"\\n\")\n\tta.SetLines(lines)\n}", "label": 5}
{"code": "public function setTextClassificationModelMetadata($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\TextClassificationModelMetadata::class);\n        $this->writeOneof(14, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def inputindex(input):\r\n    \"\"\"Handler for showing keyboard or mouse page with day and total links.\"\"\"\r\n    stats = {}\r\n    countminmax = \"SUM(count) AS count, MIN(day) AS first, MAX(day) AS last\"\r\n    tables = (\"moves\", \"clicks\", \"scrolls\") if \"mouse\" == input else (\"keys\", \"combos\")\r\n    for table in tables:\r\n        stats[table] = db.fetchone(\"counts\", countminmax, type=table)\r\n        stats[table][\"days\"] = db.fetch(\"counts\", order=\"day DESC\", type=table)\r\n    return bottle.template(\"input.tpl\", locals(), conf=conf)", "label": 1}
{"code": "func (proxy *ProxyClient) isRecordingProxy() (bool, error) {\n\tresponseCh := make(chan proxyResponse)\n\n\t// we have to run this in a goroutine because older version of Teleport handled\n\t// global out-of-band requests incorrectly: Teleport would ignore requests it\n\t// does not know about and never reply to them. So if we wait a second and\n\t// don't hear anything back, most likley we are trying to connect to an older\n\t// version of Teleport and we should not try and forward our agent.\n\tgo func() {\n\t\tok, responseBytes, err := proxy.Client.SendRequest(teleport.RecordingProxyReqType, true, nil)\n\t\tif err != nil {\n\t\t\tresponseCh <- proxyResponse{isRecord: false, err: trace.Wrap(err)}\n\t\t\treturn\n\t\t}\n\t\tif !ok {\n\t\t\tresponseCh <- proxyResponse{isRecord: false, err: trace.AccessDenied(\"unable to determine proxy type\")}\n\t\t\treturn\n\t\t}\n\n\t\trecordingProxy, err := strconv.ParseBool(string(responseBytes))\n\t\tif err != nil {\n\t\t\tresponseCh <- proxyResponse{isRecord: false, err: trace.Wrap(err)}\n\t\t\treturn\n\t\t}\n\n\t\tresponseCh <- proxyResponse{isRecord: recordingProxy, err: nil}\n\t}()\n\n\tselect {\n\tcase resp := <-responseCh:\n\t\tif resp.err != nil {\n\t\t\treturn false, trace.Wrap(resp.err)\n\t\t}\n\t\treturn resp.isRecord, nil\n\tcase <-time.After(1 * time.Second):\n\t\t// probably the older version of the proxy or at least someone that is\n\t\t// responding incorrectly, don't forward agent to it\n\t\treturn false, nil\n\t}\n}", "label": 5}
{"code": "public function release(Session $session)\n    {\n        $this->config['lock']->synchronize(function () use ($session) {\n            $item = $this->cacheItemPool->getItem($this->cacheKey);\n            $data = $item->get();\n            $name = $session->name();\n\n            if (isset($data['inUse'][$name])) {\n                unset($data['inUse'][$name]);\n                array_push($data['queue'], [\n                    'name' => $name,\n                    'expiration' => $session->expiration()\n                        ?: $this->time() + SessionPoolInterface::SESSION_EXPIRATION_SECONDS\n                ]);\n                $this->cacheItemPool->save($item->set($data));\n            }\n        });\n    }", "label": 2}
{"code": "function renameClassName(ast, oldName, newName) {\n  let defNode = null;\n  // Find the definition node of the class\n  traverse(ast, {\n    ClassDeclaration(path) {\n      if (path.node.id && path.node.id.name === oldName) {\n        defNode = path.node.id;\n      }\n    }\n  });\n\n  if (defNode) {\n    return identifier.renameIdentifier(ast, oldName, newName, defNode);\n  }\n  return [];\n}", "label": 3}
{"code": "public static base_responses flush(nitro_service client, cachecontentgroup resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcachecontentgroup flushresources[] = new cachecontentgroup[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tflushresources[i] = new cachecontentgroup();\n\t\t\t\tflushresources[i].name = resources[i].name;\n\t\t\t\tflushresources[i].query = resources[i].query;\n\t\t\t\tflushresources[i].host = resources[i].host;\n\t\t\t\tflushresources[i].selectorvalue = resources[i].selectorvalue;\n\t\t\t\tflushresources[i].force = resources[i].force;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, flushresources,\"flush\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (tl TypeLoader) LoadTableForeignKeys(args *ArgType, tableMap map[string]*Type, typeTpl *Type, fkMap map[string]*ForeignKey) error {\n\tvar err error\n\n\t// load foreign keys\n\tforeignKeyList, err := tl.ForeignKeyList(args.DB, args.Schema, typeTpl.Table.TableName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// loop over foreign keys for table\n\tfor _, fk := range foreignKeyList {\n\t\tvar refTpl *Type\n\t\tvar col, refCol *Field\n\n\tcolLoop:\n\t\t// find column\n\t\tfor _, f := range typeTpl.Fields {\n\t\t\tif f.Col.ColumnName == fk.ColumnName {\n\t\t\t\tcol = f\n\t\t\t\tbreak colLoop\n\t\t\t}\n\t\t}\n\n\trefTplLoop:\n\t\t// find ref table\n\t\tfor _, t := range tableMap {\n\t\t\tif t.Table.TableName == fk.RefTableName {\n\t\t\t\trefTpl = t\n\t\t\t\tbreak refTplLoop\n\t\t\t}\n\t\t}\n\n\trefColLoop:\n\t\t// find ref column\n\t\tfor _, f := range refTpl.Fields {\n\t\t\tif f.Col.ColumnName == fk.RefColumnName {\n\t\t\t\trefCol = f\n\t\t\t\tbreak refColLoop\n\t\t\t}\n\t\t}\n\n\t\t// no ref col, but have ref tpl, so use primary key\n\t\tif refTpl != nil && refCol == nil {\n\t\t\trefCol = refTpl.PrimaryKey\n\t\t}\n\n\t\t// check everything was found\n\t\tif col == nil || refTpl == nil || refCol == nil {\n\t\t\treturn errors.New(\"could not find col, refTpl, or refCol\")\n\t\t}\n\n\t\t// foreign key name\n\t\tif fk.ForeignKeyName == \"\" {\n\t\t\tfk.ForeignKeyName = typeTpl.Table.TableName + \"_\" + col.Col.ColumnName + \"_fkey\"\n\t\t}\n\n\t\t// create foreign key template\n\t\tfkMap[fk.ForeignKeyName] = &ForeignKey{\n\t\t\tSchema:     args.Schema,\n\t\t\tType:       typeTpl,\n\t\t\tField:      col,\n\t\t\tRefType:    refTpl,\n\t\t\tRefField:   refCol,\n\t\t\tForeignKey: fk,\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "protected static void statistics(int from, int to) {\r\n\t// check that primes contain no accidental errors\r\n\tfor (int i=0; i<primeCapacities.length-1; i++) {\r\n\t\tif (primeCapacities[i] >= primeCapacities[i+1]) throw new RuntimeException(\"primes are unsorted or contain duplicates; detected at \"+i+\"@\"+primeCapacities[i]);\r\n\t}\r\n\t\r\n\tdouble accDeviation = 0.0;\r\n\tdouble maxDeviation = - 1.0;\r\n\r\n\tfor (int i=from; i<=to; i++) {\r\n\t\tint primeCapacity = nextPrime(i);\r\n\t\t//System.out.println(primeCapacity);\r\n\t\tdouble deviation = (primeCapacity - i) / (double)i;\r\n\t\t\r\n\t\tif (deviation > maxDeviation) {\r\n\t\t\tmaxDeviation = deviation;\r\n\t\t\tSystem.out.println(\"new maxdev @\"+i+\"@dev=\"+maxDeviation);\r\n\t\t}\r\n\r\n\t\taccDeviation += deviation;\r\n\t}\r\n\tlong width = 1 + (long)to - (long)from;\r\n\t\r\n\tdouble meanDeviation = accDeviation/width;\r\n\tSystem.out.println(\"Statistics for [\"+ from + \",\"+to+\"] are as follows\");\r\n\tSystem.out.println(\"meanDeviation = \"+(float)meanDeviation*100+\" %\");\r\n\tSystem.out.println(\"maxDeviation = \"+(float)maxDeviation*100+\" %\");\r\n}", "label": 0}
{"code": "public function setLastPost(Post $post)\n    {\n        $this->last_posted_at = $post->created_at;\n        $this->last_posted_user_id = $post->user_id;\n        $this->last_post_id = $post->id;\n        $this->last_post_number = $post->number;\n\n        return $this;\n    }", "label": 2}
{"code": "def process(self, form, post):\n        \"\"\" Process the given WTForm Form object.\n\n        Itterate over the POST values and check each field\n        against the configuration that was made.\n\n        For each field that is valid, check all the validator\n        parameters for possible %field% replacement, then bind\n        these parameters to their validator.\n\n        Finally, add the field together with their validators\n        to the form.\n\n        :param form:\n            A valid WTForm Form object\n        :param post:\n            A MultiDict with the POST variables\n        \"\"\"\n\n        if not isinstance(form, FormMeta):\n            raise TypeError('Given form is not a valid WTForm.')\n\n        re_field_name = re.compile(r'\\%([a-zA-Z0-9_]*)\\%')\n\n        class F(form):\n            pass\n\n        for field, data in post.iteritems():\n            if field in F():\n                # Skip it if the POST field is one of the standard form fields.\n                continue\n            else:\n                if field in self._dyn_fields:\n                    # If we can find the field name directly, it means the field\n                    # is not a set so just set the canonical name and go on.\n                    field_cname = field\n                    # Since we are not in a set, (re)set the current set.\n                    current_set_number = None\n                elif (field.split('_')[-1].isdigit()\n                      and field[:-(len(field.split('_')[-1]))-1] in self._dyn_fields.keys()):\n                    # If the field can be split on underscore characters,\n                    # the last part contains only digits and the \n                    # everything *but* the last part is found in the\n                    # field configuration, we are good to go.\n                    # (Cowardly refusing to use regex here).\n                    field_cname = field[:-(len(field.split('_')[-1]))-1]\n                    # Since we apparently are in a set, remember the\n                    # the set number we are at.\n                    current_set_number = str(field.split('_')[-1])\n                else:\n                    # The field did not match to a canonical name\n                    # from the fields dictionary or the name\n                    # was malformed, throw it out.\n                    continue\n\n            # Since the field seems to be a valid one, let us\n            # prepare the validator arguments and, if we are in a set\n            # replace the %field_name% convention where we find it.\n            validators = []\n            if 'validators' in self._dyn_fields[field_cname]:\n                for validator in self._dyn_fields[field_cname]['validators']:\n                    args = []\n                    kwargs = {}\n                    if 'args' in self._dyn_fields[field_cname]\\\n                       [validator.__name__]:\n                        if not current_set_number:\n                            args = self._dyn_fields[field_cname]\\\n                                   [validator.__name__]['args']\n                        else:\n                            # If we are currently in a set, append the set number\n                            # to all the words that are decorated with %'s within\n                            # the arguments.\n                            for arg in self._dyn_fields[field_cname]\\\n                                [validator.__name__]['args']:\n                                try:\n                                    arg = re_field_name.sub(r'\\1'+'_'+current_set_number,\n                                                            arg)\n                                except:\n                                    # The argument does not seem to be regex-able\n                                    # Probably not a string, thus we can skip it.\n                                    pass\n                                args.append(arg)\n                    if 'kwargs' in self._dyn_fields[field_cname]\\\n                       [validator.__name__]:\n                        if not current_set_number:\n                            kwargs = self._dyn_fields[field_cname]\\\n                                     [validator.__name__]['kwargs']\n                        else:\n                            # If we are currently in a set, append the set number\n                            # to all the words that are decorated with %'s within\n                            # the arguments.\n                            for key, arg in self.iteritems(self._dyn_fields[field_cname]\\\n                                [validator.__name__]['kwargs']):\n                                try:\n                                    arg = re_field_name.sub(r'\\1'+'_'+current_set_number,\n                                                            arg)\n                                except:\n                                    # The argument does not seem to be regex-able\n                                    # Probably not a string, thus we can skip it.\n                                    pass\n                                kwargs[key] = arg\n                    # Finally, bind arguments to the validator\n                    # and add it to the list\n                    validators.append(validator(*args, **kwargs))\n\n            # The field is setup, it is time to add it to the form.\n            field_type = self._dyn_fields[field_cname]['type']\n            field_label = self._dyn_fields[field_cname]['label']\n            field_args = self._dyn_fields[field_cname]['args']\n            field_kwargs = self._dyn_fields[field_cname]['kwargs']\n\n            setattr(F, field, field_type(field_label,\n                                         validators=validators,\n                                         *field_args,\n                                         **field_kwargs))\n\n        # Create an instance of the form with the newly\n        # created fields and give it back to the caller.\n        if self.flask_wtf:\n            # Flask WTF overrides the form initialization\n            # and already injects the POST variables.\n            form = F()\n        else:\n            form = F(post)\n        return form", "label": 1}
{"code": "public static base_responses add(nitro_service client, cachepolicylabel resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcachepolicylabel addresources[] = new cachepolicylabel[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new cachepolicylabel();\n\t\t\t\taddresources[i].labelname = resources[i].labelname;\n\t\t\t\taddresources[i].evaluates = resources[i].evaluates;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def download_catalog(name, url)\n      catalogs_local_path = Pathname.new(ENV['HOME'])\n                               .join(GENERAMBA_HOME_DIR)\n                               .join(CATALOGS_DIR)\n      current_catalog_path = catalogs_local_path\n                                 .join(name)\n\n      if File.exists?(current_catalog_path)\n        g = Git.open(current_catalog_path)\n        g.pull\n      else\n        Git.clone(url, name, :path => catalogs_local_path)\n      end\n\n      return current_catalog_path\n    end", "label": 4}
{"code": "public function keys($kind, array $options = [])\n    {\n        $options += [\n            'number' => 1,\n            'ancestors' => [],\n            'id' => null,\n            'name' => null\n        ];\n\n        if ($options['number'] < 1) {\n            throw new \\InvalidArgumentException('Number of keys cannot be less than 1.');\n        }\n\n        $path = [];\n        if (count($options['ancestors']) > 0) {\n            $path = $options['ancestors'];\n        }\n\n        $path[] = array_filter([\n            'kind' => $kind,\n            'id' => $options['id'],\n            'name' => $options['name']\n        ]);\n\n        $key = new Key($this->projectId, [\n            'path' => $path,\n            'namespaceId' => $this->namespaceId\n        ]);\n\n        $keys = [$key];\n\n        for ($i = 1; $i < $options['number']; $i++) {\n            $keys[] = clone $key;\n        }\n\n        return $keys;\n    }", "label": 2}
{"code": "def select!(*str_or_rx)\n      results = str_or_rx.flatten.map { |v| select_by!(v, :single) }\n      results.first\n    end", "label": 4}
{"code": "def stack(new_scope = nil)\n      old_stack_used = @this_stack_used\n      if new_scope\n        push(new_scope)\n        @this_stack_used = true\n      else\n        @this_stack_used = false\n      end\n\n      yield\n    ensure\n      pop if @this_stack_used\n      @this_stack_used = old_stack_used\n    end", "label": 4}
{"code": "public function results(array $options = [])\n    {\n        $info = $this->info($options);\n        $results = [];\n\n        if (!isset($info['response']['results'])) {\n            return $results;\n        }\n\n        foreach ($info['response']['results'] as $result) {\n            $results[] = new Result($result);\n        }\n\n        return $results;\n    }", "label": 2}
{"code": "function remove(req, res, next) {\n  var params = {\n    appId: req.params.id\n  };\n\n  forms.deleteAppReferences(req.connectionOptions, params, formsResultHandlers(constants.resultTypes.formProjects, req, next));\n}", "label": 3}
{"code": "public static Object newInstance(Class target, Class[] types, Object[] args) throws InstantiationException,\r\n                                                                                        IllegalAccessException,\r\n                                                                                        IllegalArgumentException,\r\n                                                                                        InvocationTargetException,\r\n                                                                                        NoSuchMethodException,\r\n                                                                                        SecurityException\r\n    {\r\n        return newInstance(target, types, args, false);\r\n    }", "label": 0}
{"code": "function() {\n      this.trigger('before-dispose');\n      this.trigger('before-dispose-callback');\n      this._dispose();\n\n      // Detach DOM and deactivate the view\n      this.detach();\n      this.deactivate();\n\n      // Clean up child views first\n      this.__disposeChildViews();\n\n      // Remove view from DOM\n      if (this.$el) {\n        this.remove();\n      }\n\n      // Unbind all local event bindings\n      this.off();\n      this.stopListening();\n      if (this.viewState) {\n        this.viewState.off();\n        this.viewState.stopListening();\n      }\n      if (this.feedbackCell) {\n        this.feedbackCell.off();\n        this.feedbackCell.stopListening();\n      }\n      // Delete the dom references\n      delete this.$el;\n      delete this.el;\n\n      this.__isDisposed = true;\n      this.trigger('after-dispose');\n    }", "label": 3}
{"code": "func (m *MockIndex) ForeignFour(arg0 imp4.Imp4) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"ForeignFour\", arg0)\n}", "label": 5}
{"code": "func (capRes GetCapabilityResponse) ToCapability() *ipamapi.Capability {\n\treturn &ipamapi.Capability{\n\t\tRequiresMACAddress:    capRes.RequiresMACAddress,\n\t\tRequiresRequestReplay: capRes.RequiresRequestReplay,\n\t}\n}", "label": 5}
{"code": "public void updateIntegerBelief(String name, int value) {\n        introspector.storeBeliefValue(this, name, getIntegerBelief(name) + value);\n    }", "label": 0}
{"code": "function is_utf8(&$string)\n\t{\n\t\tif ($string === mb_convert_encoding(mb_convert_encoding($string, \"UTF-32\", \"UTF-8\"), \"UTF-8\", \"UTF-32\")) {\n\t\t\treturn true;\n\t\t}\n\n\t\tif ($this->ignore_invalid_utf8) {\n\t\t\t$string = mb_convert_encoding(mb_convert_encoding($string, \"UTF-32\", \"UTF-8\"), \"UTF-8\", \"UTF-32\");\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}", "label": 2}
{"code": "protected function wait()\n    {\n        $timeout = $this->getTimeout();\n        if (null === $timeout) {\n            // timeout=null just poll state and return instantly\n            $sec = 0;\n            $usec = 0;\n        } elseif ($timeout > 0) {\n            list($sec, $usec) = MiscHelper::splitSecondsMicroseconds($this->getTimeout());\n        } else {\n            // wait indefinitely for data if timeout=0\n            $sec = null;\n            $usec = 0;\n        }\n\n        $result = $this->io->select($sec, $usec);\n\n        if ($result === false) {\n            throw new AMQPIOWaitException('A network error occurred while awaiting for incoming data');\n        }\n\n        if ($result === 0) {\n            if ($timeout > 0) {\n                throw new AMQPTimeoutException(sprintf(\n                    'The connection timed out after %s sec while awaiting incoming data',\n                    $timeout\n                ));\n            } else {\n                throw new AMQPNoDataException('No data is ready to read');\n            }\n        }\n    }", "label": 2}
{"code": "public function setEvents($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->events = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def texture_fill_to_border(x, y, texture)\n      texture_flood_fill(border_color, texture, x, y, FillToBorderMethod)\n    end", "label": 4}
{"code": "private function fullName($projectId, $database, $relativeName = null)\n    {\n        return $relativeName !== null\n            ? FirestoreGapicClient::documentPathName($projectId, $database, $relativeName)\n            : FirestoreGapicClient::documentRootName($projectId, $database);\n    }", "label": 2}
{"code": "func GenerateRandomName(prefix string, size int) (string, error) {\n\tid := make([]byte, 32)\n\tif _, err := io.ReadFull(rand.Reader, id); err != nil {\n\t\treturn \"\", err\n\t}\n\treturn prefix + hex.EncodeToString(id)[:size], nil\n}", "label": 5}
{"code": "function(resolver, validator, process, getResult)\n  {\n    for (var i = 0; i < this.length; i++)\n    {\n      var resolved = resolver( this[ i ] );\n\n      if ( validator( resolved ) )\n      {\n        process( resolved );\n      }\n    }\n\n    return getResult();\n  }", "label": 3}
{"code": "protected function querySentinelForSlaves(NodeConnectionInterface $sentinel, $service)\n    {\n        $slaves = array();\n\n        $payload = $sentinel->executeCommand(\n            RawCommand::create('SENTINEL', 'slaves', $service)\n        );\n\n        if ($payload instanceof ErrorResponseInterface) {\n            $this->handleSentinelErrorResponse($sentinel, $payload);\n        }\n\n        foreach ($payload as $slave) {\n            $flags = explode(',', $slave[9]);\n\n            if (array_intersect($flags, array('s_down', 'o_down', 'disconnected'))) {\n                continue;\n            }\n\n            $slaves[] = array(\n                'host' => $slave[3],\n                'port' => $slave[5],\n                'alias' => \"slave-$slave[1]\",\n            );\n        }\n\n        return $slaves;\n    }", "label": 2}
{"code": "func (c *controller) defaultGwNetwork() (Network, error) {\n\tprocGwNetwork <- true\n\tdefer func() { <-procGwNetwork }()\n\n\tn, err := c.NetworkByName(libnGWNetwork)\n\tif _, ok := err.(types.NotFoundError); ok {\n\t\tn, err = c.createGWNetwork()\n\t}\n\treturn n, err\n}", "label": 5}
{"code": "def acquire_reader(self):\n        \"\"\"\n        Acquire a read lock, several threads can hold this type of lock.\n        \"\"\"\n        with self.mutex:\n            while self.rwlock < 0 or self.rwlock == self.max_reader_concurrency or self.writers_waiting:\n                self.readers_ok.wait()\n            self.rwlock += 1", "label": 1}
{"code": "func (d Datastore) AttachedHosts(ctx context.Context) ([]*HostSystem, error) {\n\tvar ds mo.Datastore\n\tvar hosts []*HostSystem\n\n\tpc := property.DefaultCollector(d.Client())\n\terr := pc.RetrieveOne(ctx, d.Reference(), []string{\"host\"}, &ds)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmounts := make(map[types.ManagedObjectReference]types.DatastoreHostMount)\n\tvar refs []types.ManagedObjectReference\n\tfor _, host := range ds.Host {\n\t\trefs = append(refs, host.Key)\n\t\tmounts[host.Key] = host\n\t}\n\n\tvar hs []mo.HostSystem\n\terr = pc.Retrieve(ctx, refs, []string{\"runtime.connectionState\", \"runtime.powerState\"}, &hs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, host := range hs {\n\t\tif host.Runtime.ConnectionState == types.HostSystemConnectionStateConnected &&\n\t\t\thost.Runtime.PowerState == types.HostSystemPowerStatePoweredOn {\n\n\t\t\tmount := mounts[host.Reference()]\n\t\t\tinfo := mount.MountInfo\n\n\t\t\tif *info.Mounted && *info.Accessible && info.AccessMode == string(types.HostMountModeReadWrite) {\n\t\t\t\thosts = append(hosts, NewHostSystem(d.Client(), mount.Key))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn hosts, nil\n}", "label": 5}
{"code": "def color(out_string, color='grn'):\n    \"\"\" Highlight string for terminal color coding.\n\n    Purpose: We use this utility function to insert a ANSI/win32 color code\n           | and Bright style marker before a string, and reset the color and\n           | style after the string. We then return the string with these\n           | codes inserted.\n\n    @param out_string: the string to be colored\n    @type out_string: str\n    @param color: a string signifying which color to use. Defaults to 'grn'.\n                | Accepts the following colors:\n                |     ['blk', 'blu', 'cyn', 'grn', 'mag', 'red', 'wht', 'yel']\n    @type color: str\n\n    @returns: the modified string, including the ANSI/win32 color codes.\n    @rtype: str\n    \"\"\"\n    c = {\n        'blk': Fore.BLACK,\n        'blu': Fore.BLUE,\n        'cyn': Fore.CYAN,\n        'grn': Fore.GREEN,\n        'mag': Fore.MAGENTA,\n        'red': Fore.RED,\n        'wht': Fore.WHITE,\n        'yel': Fore.YELLOW,\n    }\n    try:\n        init()\n        return (c[color] + Style.BRIGHT + out_string + Fore.RESET + Style.NORMAL)\n    except AttributeError:\n        return out_string", "label": 1}
{"code": "function Storage(mongoURI, mongoOptions, storageOptions) {\n  if (!(this instanceof Storage)) {\n    return new Storage(mongoURI, mongoOptions, storageOptions);\n  }\n\n  assert(typeof mongoOptions === 'object', 'Invalid mongo options supplied');\n\n  this._uri = mongoURI;\n  this._options = mongoOptions;\n\n  const defaultLogger = {\n    info: console.log,\n    debug: console.log,\n    error: console.error,\n    warn: console.warn\n  };\n  this._log = defaultLogger;\n  if (storageOptions && storageOptions.logger) {\n    this._log = storageOptions.logger;\n  }\n\n  // connect to the database\n  this._connect();\n}", "label": 3}
{"code": "def _load_file(self, f):\n        \"\"\"Get values from config file\"\"\"\n        try:\n            with open(f, 'r') as _fo:\n                _seria_in = seria.load(_fo)\n                _y = _seria_in.dump('yaml')\n        except IOError:\n            raise FiggypyError(\"could not open configuration file\")\n        self.values.update(yaml.load(_y))", "label": 1}
{"code": "public static long count(nitro_service service, String groupname) throws Exception{\n\t\tsystemgroup_systemcmdpolicy_binding obj = new systemgroup_systemcmdpolicy_binding();\n\t\tobj.set_groupname(groupname);\n\t\toptions option = new options();\n\t\toption.set_count(true);\n\t\tsystemgroup_systemcmdpolicy_binding response[] = (systemgroup_systemcmdpolicy_binding[]) obj.get_resources(service,option);\n\t\tif (response != null) {\n\t\t\treturn response[0].__count;\n\t\t}\n\t\treturn 0;\n\t}", "label": 0}
{"code": "func PgShdescriptionByObjoidClassoid(db XODB, objoid pgtypes.Oid, classoid pgtypes.Oid) (*PgShdescription, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, objoid, classoid, description ` +\n\t\t`FROM pg_catalog.pg_shdescription ` +\n\t\t`WHERE objoid = $1 AND classoid = $2`\n\n\t// run query\n\tXOLog(sqlstr, objoid, classoid)\n\tps := PgShdescription{}\n\n\terr = db.QueryRow(sqlstr, objoid, classoid).Scan(&ps.Tableoid, &ps.Cmax, &ps.Xmax, &ps.Cmin, &ps.Xmin, &ps.Ctid, &ps.Objoid, &ps.Classoid, &ps.Description)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ps, nil\n}", "label": 5}
{"code": "def http_url(full_name, prefix)\n      path = full_name.dup\n      path.gsub!(/<<\\s*(\\w*)/) { \"from-#$1\" } if path['<<']\n      File.join(prefix, path.split(\"::\").collect { |p| Digest::MD5.hexdigest(p) }) + \".html\"\n    end", "label": 4}
{"code": "def createResource(self, resource_type, title, resource_file=None, resource_filename=None,\n                       abstract=None, keywords=None,\n                       edit_users=None, view_users=None, edit_groups=None, view_groups=None,\n                       metadata=None, extra_metadata=None, progress_callback=None):\n        \"\"\" Create a new resource.\n\n        :param resource_type: string representing the a HydroShare resource type recognized by this\n            server.\n        :param title: string representing the title of the new resource\n        :param resource_file: a read-only binary file-like object (i.e. opened with the flag 'rb') or a string\n            representing path to file to be uploaded as part of the new resource\n        :param resource_filename: string representing the filename of the resource file.  Must be specified\n            if resource_file is a file-like object.  If resource_file is a string representing a valid file path,\n            and resource_filename is not specified, resource_filename will be equal to os.path.basename(resource_file).\n            is a string\n        :param abstract: string representing abstract of resource\n        :param keywords: list of strings representing keywords to associate with the resource\n        :param edit_users: list of HydroShare usernames who will be given edit permissions\n        :param view_users: list of HydroShare usernames who will be given view permissions\n        :param edit_groups: list of HydroShare group names that will be given edit permissions\n        :param view_groups: list of HydroShare group names that will be given view permissions\n        :param metadata: json string data for each of the metadata elements\n        :param extra_metadata: json string data for key/value pair metadata elements defined by user\n        :param progress_callback: user-defined function to provide feedback to the user about the progress\n            of the upload of resource_file.  For more information, see:\n            http://toolbelt.readthedocs.org/en/latest/uploading-data.html#monitoring-your-streaming-multipart-upload\n\n        :return: string representing ID of newly created resource.\n\n        :raises: HydroShareArgumentException if any parameters are invalid.\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n\n        \"\"\"\n        url = \"{url_base}/resource/\".format(url_base=self.url_base)\n\n        close_fd = False\n\n        if resource_type not in self.resource_types:\n            raise HydroShareArgumentException(\"Resource type {0} is not among known resources: {1}\".format(resource_type,\n                                                                                                           \", \".join([r for r in self.resource_types])))\n\n        # Prepare request\n        params = {'resource_type': resource_type, 'title': title}\n        if abstract:\n            params['abstract'] = abstract\n        if keywords:\n            # Put keywords in a format that django-rest's serializer will understand\n            for (i, kw) in enumerate(keywords):\n                key = \"keywords[{index}]\".format(index=i)\n                params[key] = kw\n        if edit_users:\n            params['edit_users'] = edit_users\n        if view_users:\n            params['view_users'] = view_users\n        if edit_groups:\n            params['edit_groups'] = edit_groups\n        if view_groups:\n            params['view_groups'] = view_groups\n\n        if metadata:\n            params['metadata'] = metadata\n\n        if extra_metadata:\n            params['extra_metadata'] = extra_metadata\n\n        if resource_file:\n            close_fd = self._prepareFileForUpload(params, resource_file, resource_filename)\n\n        encoder = MultipartEncoder(params)\n        if progress_callback is None:\n            progress_callback = default_progress_callback\n        monitor = MultipartEncoderMonitor(encoder, progress_callback)\n\n        r = self._request('POST', url, data=monitor, headers={'Content-Type': monitor.content_type})\n\n        if close_fd:\n            fd = params['file'][1]\n            fd.close()\n\n        if r.status_code != 201:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('POST', url))\n            else:\n                raise HydroShareHTTPException((url, 'POST', r.status_code, params))\n\n        response = r.json()\n        new_resource_id = response['resource_id']\n\n        return new_resource_id", "label": 1}
{"code": "function trimTrailingWhitespacesForRemainingRange() {\n                var startPosition = previousRange ? previousRange.end : originalRange.pos;\n                var startLine = sourceFile.getLineAndCharacterOfPosition(startPosition).line;\n                var endLine = sourceFile.getLineAndCharacterOfPosition(originalRange.end).line;\n                trimTrailingWhitespacesForLines(startLine, endLine + 1, previousRange);\n            }", "label": 3}
{"code": "function resolveRef(schemaObj, resolvedValues) {\n            // the array store referenced value\n            var refVal = schemaObj.refVal;\n            // the map store full ref id and index of the referenced value in refVal\n            // example: { 'test#definitions/option' : 1, 'test#definitions/repo' : 2 }\n            var refs = schemaObj.refs;\n            // the map to store schema value with sub reference\n            var subRefs = {};\n\n            _.forEach(refs, function (index, refId) {\n                // if reference id already resolved then continue the loop\n                if (refId in resolvedValues) {\n                    return true; // continue\n                }\n\n                var refValue = refVal[index];\n                // if no further nested reference, add to resolved map\n                if (_.isEmpty(refValue.refs)) {\n                    resolvedValues[refId] = refValue;\n                    return true;\n                }\n\n                // add schema value with sub reference to map to resolve later\n                subRefs[refId] = refValue;\n            });\n\n            // resolve sub reference recursively\n            _.forEach(subRefs, function (subRef, refId) {\n                resolvedValues[refId] = 1;\n                resolvedValues[refId] = resolveRef(subRef, resolvedValues);\n            });\n\n            return schemaObj.schema;\n        }", "label": 3}
{"code": "def handle_specific_source_data_criteria_reference(criteria)\n      original_sdc = find(@source_data_criteria, :id, criteria.source_data_criteria)\n      updated_sdc = find(@source_data_criteria, :id, criteria.id)\n      if !updated_sdc.nil? && !criteria.specific_occurrence.nil? && (original_sdc.nil? || original_sdc.specific_occurrence.nil?)\n        criteria.instance_variable_set(:@source_data_criteria, criteria.id)\n      end\n      return if original_sdc.nil?\n      if (criteria.specific_occurrence && !original_sdc.specific_occurrence)\n        original_sdc.instance_variable_set(:@specific_occurrence, criteria.specific_occurrence)\n        original_sdc.instance_variable_set(:@specific_occurrence_const, criteria.specific_occurrence_const)\n        original_sdc.instance_variable_set(:@code_list_id, criteria.code_list_id)\n      end\n    end", "label": 4}
{"code": "def default_options(options = {})\n      headers = default_headers.merge(options[:headers] || {})\n      headers.merge!({USER_AGENT => options[:user_agent]})\n      {\n        headers: headers,\n        ssl: options[:ssl],\n        url: options[:endpoint]\n      }\n    end", "label": 4}
{"code": "public static <T> Set<T> getSet(Collection<T> collection) {\n    Set<T> set = new LinkedHashSet<T>();\n    set.addAll(collection);\n\n    return set;\n  }", "label": 0}
{"code": "public static base_response unset(nitro_service client, nsrpcnode resource, String[] args) throws Exception{\n\t\tnsrpcnode unsetresource = new nsrpcnode();\n\t\tunsetresource.ipaddress = resource.ipaddress;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public function setQuantileValues($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\Value::class);\n        $this->quantile_values = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setGroup($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\Group::class);\n        $this->group = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function prepareResponse(validDataSources, invalidDataSources, cb) {\n  //There Were Errors Updating Data Sources, should return an error\n\n  logger.debug(\"prepareResponse Before\", validDataSources);\n  //For The Valid Data Sources, Just want the updated Document JSON\n  validDataSources = _.map(validDataSources, function(validDataSourceData) {\n    return processDataSourceResponse(validDataSourceData.document.toJSON());\n  });\n\n  logger.debug(\"prepareResponse After\", validDataSources);\n\n  var returnError;\n  if (invalidDataSources.length > 0) {\n    returnError = buildErrorResponse({\n      error: new Error(\"Error Updating Data Sources\"),\n      code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n    });\n  }\n\n  return cb(returnError, {\n    validDataSourceUpdates: validDataSources,\n    invalidDataSourceUpdates: invalidDataSources\n  });\n}", "label": 3}
{"code": "public static function resolveFile(string $metadataDir, string $metadataNamespace, string $className) : string\n    {\n        if (strpos($className, $metadataNamespace) !== 0) {\n            throw new InvalidArgumentException(\n                sprintf('The class \"%s\" is not part of the metadata namespace \"%s\"', $className, $metadataNamespace)\n            );\n        }\n\n        // remove metadata namespace from class name\n        $classNameRelativeToMetadataNamespace = substr($className, strlen($metadataNamespace));\n\n        // remove namespace separators from remaining class name\n        $fileName = str_replace('\\\\', '', $classNameRelativeToMetadataNamespace);\n\n        return $metadataDir . DIRECTORY_SEPARATOR . $fileName . '.php';\n    }", "label": 2}
{"code": "func (c *Client) DeleteCertAuthority(id services.CertAuthID) error {\n\tif err := id.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err := c.Delete(c.Endpoint(\"authorities\", string(id.Type), id.DomainName))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def postMetricsPointsByID(self, id, value, **kwargs):\n        '''Add a metric point to a given metric.\n\n        :param id: Metric ID\n        :param value: Value to plot on the metric graph\n        :param timestamp: Unix timestamp of the point was measured\n        :return: :class:`Response <Response>` object\n        :rtype: requests.Response\n        '''\n\n        kwargs['value'] = value\n        return self.__postRequest('/metrics/%s/points' % id, kwargs)", "label": 1}
{"code": "def password_too_old?\n      return false if new_record?\n      return false unless password_expiration_enabled?\n      return false if expire_password_on_demand?\n\n      password_changed_at < expire_password_after.seconds.ago\n    end", "label": 4}
{"code": "func (ta *TextArea) EnableCursor(on bool) {\n\tta.Init()\n\tta.model.cursor = on\n}", "label": 5}
{"code": "public function orderColumns(array $columns, $sql, $bindings = [])\n    {\n        foreach ($columns as $column) {\n            $this->orderColumn($column, str_replace(':column', $column, $sql), $bindings);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function(obj) {\n            var rest = slice.call(arguments, 1);\n\n            for (var i = 0; i < rest.length; i++) {\n                var source = rest[i];\n\n                if (source) {\n                    for (var prop in source) {\n                        obj[prop] = source[prop];\n                    }\n                }\n            }\n\n            return obj;\n        }", "label": 3}
{"code": "public static auditsyslogpolicy_authenticationvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauditsyslogpolicy_authenticationvserver_binding obj = new auditsyslogpolicy_authenticationvserver_binding();\n\t\tobj.set_name(name);\n\t\tauditsyslogpolicy_authenticationvserver_binding response[] = (auditsyslogpolicy_authenticationvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function restore(fn, advisor) {\n    var origin, index, len;\n\n    if (fn && fn === fn[WRAPPER]) {\n      if ( !advisor) {\n        origin = fn[ORIGIN];\n        delete fn[ORIGIN];\n        delete fn[ADVISOR];\n        delete fn[BEFORE];\n        delete fn[AFTER];\n        delete fn[WRAPPER];\n      } else {\n        index = len = fn[ADVISOR].length;\n        while (index--) {\n          if (fn[ADVISOR][index] === advisor) { break; }\n        }\n        if (index >= 0) {\n          if (len === 1) { return restore(fn); }\n          fn[ADVISOR].splice(index, 1);\n          fn[BEFORE].splice(index, 1);\n          fn[AFTER].splice(index, 1);\n        }\n      }\n    }\n    return origin;\n  }", "label": 3}
{"code": "func parseFilters(v []string) ([]Filter, error) {\n\tfs := make([]Filter, 0, len(v))\n\tfor _, s := range v {\n\t\tp := strings.Index(s, \"(\")\n\t\tif p < 0 {\n\t\t\treturn nil, fmt.Errorf(\"Incorrect syntax in filter parameters, missing (\")\n\t\t}\n\n\t\tif strings.Index(s, \")\") != len(s)-1 {\n\t\t\treturn nil, fmt.Errorf(\"Incorrect syntax in filter parameters, missing )\")\n\t\t}\n\n\t\tt := Unknown.From(s[:p])\n\t\tif t == Unknown {\n\t\t\treturn nil, fmt.Errorf(\"Unknown filter type\")\n\t\t}\n\n\t\tcommand := s[p+1 : len(s)-1]\n\n\t\tswitch t {\n\t\tcase Label:\n\t\t\tproto := strings.SplitN(command, \":\", 2)\n\t\t\tif len(proto) < 2 {\n\t\t\t\treturn nil, fmt.Errorf(\"Missing : from label filter\")\n\t\t\t}\n\t\t\tr, err := regexp.Compile(proto[1])\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tfs = append(fs, labelFilter(proto[0], r))\n\t\t\tbreak\n\t\tcase Name:\n\t\t\tr, err := regexp.Compile(command)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tfs = append(fs, nameFilter(r))\n\t\t\tbreak\n\t\t}\n\t}\n\treturn fs, nil\n}", "label": 5}
{"code": "public static <T> T mode(Collection<T> values) {\r\n    Set<T> modes = modes(values);\r\n    return modes.iterator().next();\r\n  }", "label": 0}
{"code": "public static vpnvserver_aaapreauthenticationpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_aaapreauthenticationpolicy_binding obj = new vpnvserver_aaapreauthenticationpolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_aaapreauthenticationpolicy_binding response[] = (vpnvserver_aaapreauthenticationpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def get_function_signature(func):\n    \"\"\"\n    Return the signature string of the specified function.\n\n    >>> def foo(name): pass\n    >>> get_function_signature(foo)\n    'foo(name)'\n    >>> something = 'Hello'\n    >>> get_function_signature(something)\n    Traceback (most recent call last):\n        ...\n    TypeError: The argument must be a function object: None type is <class 'str'>\n    \"\"\"\n    if func is None:\n        return 'Function is None'\n\n    try:\n        func_name = func.__name__\n    except AttributeError:\n        func_name = 'None'\n\n    if not inspect.isfunction(func):\n        raise TypeError('The argument must be a function object: %s type is %s' % (func_name, type(func)))\n\n    return func_name + str(inspect.signature(func))", "label": 1}
{"code": "func (t *Torrent) Info() *metainfo.Info {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\treturn t.info\n}", "label": 5}
{"code": "func NewPresenceService(b backend.Backend) *PresenceService {\n\treturn &PresenceService{\n\t\tlog:     logrus.WithFields(logrus.Fields{trace.Component: \"Presence\"}),\n\t\tBackend: b,\n\t}\n}", "label": 5}
{"code": "def _handle_linux(self, keycode, character, press):\r\n        \"\"\"Linux key event handler.\"\"\"\r\n        if character is None: return\r\n        key = self._keyname(character, keycode)\r\n        if key in self.MODIFIERNAMES:\r\n            self._modifiers[self.MODIFIERNAMES[key]] = press\r\n            self._realmodifiers[key] = press\r\n        if press:\r\n            self._output(type=\"keys\", key=key, realkey=key)\r\n        if press and key not in self.MODIFIERNAMES:\r\n            modifier = \"-\".join(k for k in [\"Ctrl\", \"Alt\", \"Shift\", \"Win\"]\r\n                                if self._modifiers[k])\r\n            if modifier and modifier != \"Shift\": # Shift-X is not a combo\r\n                realmodifier = \"-\".join(k for k, v in self._realmodifiers.items() if v)\r\n                realkey = \"%s-%s\" % (realmodifier, key)\r\n                key = \"%s-%s\" % (modifier, key)\r\n                if DEBUG: print(\"Adding combo %s (real %s)\" % (key.encode(\"utf-8\"), realkey.encode(\"utf-8\")))\r\n                self._output(type=\"combos\", key=key, realkey=realkey)", "label": 1}
{"code": "def normalize_description(description)\n      # description could be another object not a string, but since it probably\n      # serves the same purpose we could just as it to convert itself to str\n      # and continue from there\n      description = cleanup_string(description)\n      return '' if description.blank?\n\n      truncate(description, MetaTags.config.description_limit)\n    end", "label": 4}
{"code": "public static java.sql.Date rollYears(java.util.Date startDate, int years) {\n        return rollDate(startDate, Calendar.YEAR, years);\n    }", "label": 0}
{"code": "public function registerViews(): self\n    {\n        $this->loadViewsFrom(PLATFORM_PATH.'/resources/views', 'platform');\n\n        $this->publishes([\n            PLATFORM_PATH.'/resources/views' => resource_path('views/vendor/platform'),\n        ], 'views');\n\n        return $this;\n    }", "label": 2}
{"code": "func (app *Application) PostFunc(fn func()) {\n\tev := &eventAppFunc{fn: fn}\n\tev.SetEventNow()\n\tif scr := app.screen; scr != nil {\n\t\tgo func() { scr.PostEventWait(ev) }()\n\t}\n}", "label": 5}
{"code": "func processRotationRequest(req rotationReq) (services.CertAuthority, error) {\n\trotation := req.ca.GetRotation()\n\tca := req.ca.Clone()\n\n\tswitch req.targetPhase {\n\tcase services.RotationPhaseInit:\n\t\t// This is the first stage of the rotation - new certificate authorities\n\t\t// are being generated, but no components are using them yet\n\t\tswitch rotation.State {\n\t\tcase services.RotationStateStandby, \"\":\n\t\tdefault:\n\t\t\treturn nil, trace.BadParameter(\"can not initate rotation while another is in progress\")\n\t\t}\n\t\tif err := startNewRotation(req, ca); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn ca, nil\n\tcase services.RotationPhaseUpdateClients:\n\t\t// Update client phase clients will start using new credentials\n\t\t// and servers will use the existing credentials, but will trust clients\n\t\t// with both old and new credentials.\n\t\tif rotation.Phase != services.RotationPhaseInit {\n\t\t\treturn nil, trace.BadParameter(\n\t\t\t\t\"can only switch to phase %v from %v, current phase is %v\",\n\t\t\t\tservices.RotationPhaseUpdateClients,\n\t\t\t\tservices.RotationPhaseInit,\n\t\t\t\trotation.Phase)\n\t\t}\n\t\tif err := updateClients(ca, req.mode); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn ca, nil\n\tcase services.RotationPhaseUpdateServers:\n\t\t// Update server phase uses the new credentials both for servers\n\t\t// and clients, but still trusts clients with old credentials.\n\t\tif rotation.Phase != services.RotationPhaseUpdateClients {\n\t\t\treturn nil, trace.BadParameter(\n\t\t\t\t\"can only switch to phase %v from %v, current phase is %v\",\n\t\t\t\tservices.RotationPhaseUpdateServers,\n\t\t\t\tservices.RotationPhaseUpdateClients,\n\t\t\t\trotation.Phase)\n\t\t}\n\t\t// Signal nodes to restart and start serving new signatures\n\t\t// by updating the phase.\n\t\trotation.Phase = req.targetPhase\n\t\trotation.Mode = req.mode\n\t\tca.SetRotation(rotation)\n\t\treturn ca, nil\n\tcase services.RotationPhaseRollback:\n\t\t// Rollback moves back both clients and servers to use the old credentials\n\t\t// but will trust new credentials.\n\t\tswitch rotation.Phase {\n\t\tcase services.RotationPhaseInit, services.RotationPhaseUpdateClients, services.RotationPhaseUpdateServers:\n\t\t\tif err := startRollingBackRotation(ca); err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\treturn ca, nil\n\t\tdefault:\n\t\t\treturn nil, trace.BadParameter(\"can not transition to phase %q from %q phase.\", req.targetPhase, rotation.Phase)\n\t\t}\n\tcase services.RotationPhaseStandby:\n\t\t// Transition to the standby phase moves rotation process\n\t\t// to standby, servers will only trust one certificate authority.\n\t\tswitch rotation.Phase {\n\t\tcase services.RotationPhaseUpdateServers, services.RotationPhaseRollback:\n\t\t\tif err := completeRotation(req.clock, ca); err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\treturn ca, nil\n\t\tdefault:\n\t\t\treturn nil, trace.BadParameter(\n\t\t\t\t\"can only switch to phase %v from %v, current phase is %v\",\n\t\t\t\tservices.RotationPhaseUpdateServers,\n\t\t\t\tservices.RotationPhaseUpdateClients,\n\t\t\t\trotation.Phase)\n\t\t}\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"unsupported phase: %q\", req.targetPhase)\n\t}\n}", "label": 5}
{"code": "private double goldenMean(double a, double b) {\r\n    if (geometric) {\r\n      return a * Math.pow(b / a, GOLDEN_SECTION);\r\n    } else {\r\n      return a + (b - a) * GOLDEN_SECTION;\r\n    }\r\n  }", "label": 0}
{"code": "public static responderpolicy_stats[] get(nitro_service service) throws Exception{\n\t\tresponderpolicy_stats obj = new responderpolicy_stats();\n\t\tresponderpolicy_stats[] response = (responderpolicy_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function queue_unbind(\n        $queue,\n        $exchange,\n        $routing_key = '',\n        $arguments = array(),\n        $ticket = null\n    ) {\n        $ticket = $this->getTicket($ticket);\n\n        list($class_id, $method_id, $args) = $this->protocolWriter->queueUnbind(\n            $ticket,\n            $queue,\n            $exchange,\n            $routing_key,\n            $arguments\n        );\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('queue.unbind_ok')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "func (u *UUID) UnmarshalBinary(data []byte) (err error) {\n\tif len(data) != Size {\n\t\terr = fmt.Errorf(\"uuid: UUID must be exactly 16 bytes long, got %d bytes\", len(data))\n\t\treturn\n\t}\n\tcopy(u[:], data)\n\n\treturn\n}", "label": 5}
{"code": "public static base_response disable(nitro_service client, String name) throws Exception {\n\t\tvserver disableresource = new vserver();\n\t\tdisableresource.name = name;\n\t\treturn disableresource.perform_operation(client,\"disable\");\n\t}", "label": 0}
{"code": "func (c *TrustedClusterV2) CanChangeStateTo(t TrustedCluster) error {\n\tif c.GetToken() != t.GetToken() {\n\t\treturn trace.BadParameter(\"can not update token for existing trusted cluster\")\n\t}\n\tif c.GetProxyAddress() != t.GetProxyAddress() {\n\t\treturn trace.BadParameter(\"can not update proxy address for existing trusted cluster\")\n\t}\n\tif c.GetReverseTunnelAddress() != t.GetReverseTunnelAddress() {\n\t\treturn trace.BadParameter(\"can not update proxy address for existing trusted cluster\")\n\t}\n\tif !utils.StringSlicesEqual(c.GetRoles(), t.GetRoles()) {\n\t\treturn trace.BadParameter(\"can not update roles for existing trusted cluster\")\n\t}\n\tif !c.GetRoleMap().Equals(t.GetRoleMap()) {\n\t\treturn trace.BadParameter(\"can not update role map for existing trusted cluster\")\n\t}\n\n\tif c.GetEnabled() == t.GetEnabled() {\n\t\tif t.GetEnabled() == true {\n\t\t\treturn trace.AlreadyExists(\"trusted cluster is already enabled\")\n\t\t}\n\t\treturn trace.AlreadyExists(\"trusted cluster state is already disabled\")\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func (m *MuxBroker) AcceptAndServe(id uint32, v interface{}) {\n\tconn, err := m.Accept(id)\n\tif err != nil {\n\t\tlog.Printf(\"[ERR] plugin: plugin acceptAndServe error: %s\", err)\n\t\treturn\n\t}\n\n\tserve(conn, \"Plugin\", v)\n}", "label": 5}
{"code": "def populate_page_with(data)\n      data.to_h.each do |key, value|\n        populate_section(key, value) if value.respond_to?(:to_h)\n        populate_value(self, key, value)\n      end\n    end", "label": 4}
{"code": "def layer(self, queryset, stylename=None):\n        \"\"\"Returns a map Layer.\n\n        Arguments:\n        queryset -- QuerySet for Layer\n        Keyword args:\n        stylename -- str name of style to apply\n        \"\"\"\n        cls = RasterLayer if hasattr(queryset, 'image') else VectorLayer\n        layer = cls(queryset, style=stylename)\n        try:\n            style = self.map.find_style(layer.stylename)\n        except KeyError:\n            self.map.append_style(layer.stylename, layer.style())\n        layer.styles.append(layer.stylename)\n        self.map.layers.append(layer._layer)\n        return layer", "label": 1}
{"code": "def delete_customer_card(customer_id, card_id, opts = {})\n      data, _status_code, _headers = delete_customer_card_with_http_info(customer_id, card_id, opts)\n      return data\n    end", "label": 4}
{"code": "private void executeResult() throws Exception {\n\t\tresult = createResult();\n\n\t\tString timerKey = \"executeResult: \" + getResultCode();\n\t\ttry {\n\t\t\tUtilTimerStack.push(timerKey);\n\t\t\tif (result != null) {\n\t\t\t\tresult.execute(this);\n\t\t\t} else if (resultCode != null && !Action.NONE.equals(resultCode)) {\n\t\t\t\tthrow new ConfigurationException(\"No result defined for action \" + getAction().getClass().getName()\n\t\t\t\t\t\t+ \" and result \" + getResultCode(), proxy.getConfig());\n\t\t\t} else {\n\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\tLOG.debug(\"No result returned for action \" + getAction().getClass().getName() + \" at \"\n\t\t\t\t\t\t\t+ proxy.getConfig().getLocation());\n\t\t\t\t}\n\t\t\t}\n\t\t} finally {\n\t\t\tUtilTimerStack.pop(timerKey);\n\t\t}\n\t}", "label": 0}
{"code": "def send(self):\n        \"\"\"\n        this handles the message transmission\n        \"\"\"\n        #print('sending message to ' + self.receiver)\n        if self.prepare():\n            ## TODO - send message via library\n            print('sending message')\n            lg.record_process('comms.py', 'Sending message ' + self.title)\n\n            return True\n        else:\n            return False", "label": 1}
{"code": "public double Function2D(double x, double y) {\n        return Math.exp(-(x * x + y * y) / (2 * sqrSigma)) / (2 * Math.PI * sqrSigma);\n    }", "label": 0}
{"code": "function getAxesPosition(axes, buttons) {\n  if (axes.length === 10) {\n    return Math.round(axes[9] / (2 / 7) + 3.5);\n  }\n  const [right, left, down, up] = [...buttons].reverse();\n  const buttonValues = [up, right, down, left]\n    .map((pressed, i) => (pressed.value ? i * 2 : false))\n    .filter(val => val !== false);\n  if (buttonValues.length === 0) return 8;\n  if (buttonValues.length === 2 && buttonValues[0] === 0 && buttonValues[1] === 6) return 7;\n  return buttonValues.reduce((prev, curr) => prev + curr, 0) / buttonValues.length;\n}", "label": 3}
{"code": "func Build(path string, dns, dnsSearch, dnsOptions []string) (*File, error) {\n\tcontent := bytes.NewBuffer(nil)\n\tif len(dnsSearch) > 0 {\n\t\tif searchString := strings.Join(dnsSearch, \" \"); strings.Trim(searchString, \" \") != \".\" {\n\t\t\tif _, err := content.WriteString(\"search \" + searchString + \"\\n\"); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\tfor _, dns := range dns {\n\t\tif _, err := content.WriteString(\"nameserver \" + dns + \"\\n\"); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif len(dnsOptions) > 0 {\n\t\tif optsString := strings.Join(dnsOptions, \" \"); strings.Trim(optsString, \" \") != \"\" {\n\t\t\tif _, err := content.WriteString(\"options \" + optsString + \"\\n\"); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\thash, err := ioutils.HashData(bytes.NewReader(content.Bytes()))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &File{Content: content.Bytes(), Hash: hash}, ioutil.WriteFile(path, content.Bytes(), 0644)\n}", "label": 5}
{"code": "@DELETE\n    @Path(\"/{name}\" + ServerAPI.GET_CORPORATE_GROUPIDS)\n    public Response removeCorporateGroupIdPrefix(@Auth final DbCredential credential, @PathParam(\"name\") final String organizationId, final String corporateGroupId){\n        LOG.info(\"Got an remove a corporate groupId prefix request for organization \" + organizationId +\".\");\n        if(!credential.getRoles().contains(DbCredential.AvailableRoles.DATA_UPDATER)){\n            throw new WebApplicationException(Response.status(Response.Status.UNAUTHORIZED).build());\n        }\n\n        if(corporateGroupId == null || corporateGroupId.isEmpty()){\n            LOG.error(\"No corporate GroupId to remove!\");\n            return Response.serverError().status(HttpStatus.BAD_REQUEST_400).build();\n        }\n\n        getOrganizationHandler().removeCorporateGroupId(organizationId, corporateGroupId);\n\n        return Response.ok(\"done\").build();\n    }", "label": 0}
{"code": "function processEddystone(advertiserData) {\n  var data = advertiserData.serviceData.data;\n  var eddystone = {};\n\n  var frameType = data.substr(0,2);\n\n  switch(frameType) {\n\n    // UID\n    case '00':\n      eddystone.type = 'UID';\n      eddystone.txPower = pdu.convertTxPower(data.substr(2,2));\n      eddystone.uid = {};\n      eddystone.uid.namespace = data.substr(4,20);\n      eddystone.uid.instance = data.substr(24,12);\n      break;\n\n    // URI\n    case '10':\n      eddystone.type = 'URL';\n      eddystone.txPower = pdu.convertTxPower(data.substr(2,2));\n      eddystone.url = parseSchemePrefix(data.substr(4,2));\n      eddystone.url += parseEncodedUrl(data.substr(6));\n      break;\n\n    // TLM\n    case '20':\n      eddystone.type = 'TLM';\n      eddystone.version = data.substr(2,2);\n      if(eddystone.version === '00') {\n        eddystone.batteryVoltage = parseInt(data.substr(4,4),16) + 'mV';\n        // TODO: export 8:8 fixed point representation interpreter to pdu\n        eddystone.temperature = parseInt(data.substr(8,4),16);\n        if(eddystone.temperature > 0x7fff) {\n          eddystone.temperature = 0x7fff - eddystone.temperature;\n        }\n        eddystone.temperature = (eddystone.temperature / 256) + 'C';\n        eddystone.advertisingCount = parseInt(data.substr(12,8),16);\n        eddystone.uptime = (parseInt(data.substr(20,8),16) / 10) + 's';\n      }\n      else if(eddystone.version === '01') {\n        eddystone.etlm = data.substr(4,24);\n        eddystone.salt = data.substr(28,4);\n        eddystone.mic = data.substr(32,4);\n      }\n      break;\n\n    // EID\n    case '30':\n      eddystone.type = 'EID';\n      eddystone.txPower = pdu.convertTxPower(data.substr(2,2));\n      eddystone.eid = data.substr(4,16);\n      break;\n  }\n\n  advertiserData.serviceData.eddystone = eddystone;\n}", "label": 3}
{"code": "def wait_for_signal(self, timeout=None):\n\t\t\"\"\"\n\t\twait for the signal; return after the signal has occurred or the\n\t\ttimeout in seconds elapses.\n\t\t\"\"\"\n\t\ttimeout_ms = int(timeout * 1000) if timeout else win32event.INFINITE\n\t\twin32event.WaitForSingleObject(self.signal_event, timeout_ms)", "label": 1}
{"code": "def _calc_size_stats(self):\n        \"\"\"\n        get the size in bytes and num records of the content\n        \"\"\"\n        self.total_records = 0\n        self.total_length = 0\n        self.total_nodes = 0\n        if type(self.content['data']) is dict:\n            self.total_length += len(str(self.content['data']))\n            self.total_records += 1\n            self.total_nodes = sum(len(x) for x in self.content['data'].values())\n                               \n        elif hasattr(self.content['data'], '__iter__') and type(self.content['data']) is not str:\n            self._get_size_recursive(self.content['data'])\n        else:\n            self.total_records += 1\n            self.total_length += len(str(self.content['data']))\n            \n        return str(self.total_records) + ' records [or ' +  str(self.total_nodes) + ' nodes], taking ' + str(self.total_length) + ' bytes'", "label": 1}
{"code": "function verifyDataTargets(dataTargetIds, cb) {\n    findMatchingDocuments(models.MODELNAMES.DATA_TARGET, dataTargetIds, dataTargetModel, cb);\n  }", "label": 3}
{"code": "public function AliasIdentificationVariable()\n    {\n        $this->match(Lexer::T_IDENTIFIER);\n\n        $aliasIdentVariable = $this->lexer->token['value'];\n        $exists             = isset($this->queryComponents[$aliasIdentVariable]);\n\n        if ($exists) {\n            $this->semanticalError(sprintf(\"'%s' is already defined.\", $aliasIdentVariable), $this->lexer->token);\n        }\n\n        return $aliasIdentVariable;\n    }", "label": 2}
{"code": "private void appendParameter(Object value, StringBuffer buf)\r\n    {\r\n        if (value instanceof Query)\r\n        {\r\n            appendSubQuery((Query) value, buf);\r\n        }\r\n        else\r\n        {\r\n            buf.append(\"?\");\r\n        }\r\n    }", "label": 0}
{"code": "def no_sleep():\n\t\"\"\"\n\tContext that prevents the computer from going to sleep.\n\t\"\"\"\n\tmode = power.ES.continuous | power.ES.system_required\n\thandle_nonzero_success(power.SetThreadExecutionState(mode))\n\ttry:\n\t\tyield\n\tfinally:\n\t\thandle_nonzero_success(power.SetThreadExecutionState(power.ES.continuous))", "label": 1}
{"code": "function Process(properties) {\n                if (properties)\n                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n                        if (properties[keys[i]] != null)\n                            this[keys[i]] = properties[keys[i]];\n            }", "label": 3}
{"code": "def logging scope: nil, timeout: nil, client_config: nil\n      timeout ||= @timeout\n      Google::Cloud.logging @project, @keyfile, scope:         scope,\n                                                timeout:       timeout,\n                                                client_config: client_config\n    end", "label": 4}
{"code": "public void clipTile(InternalTile tile, double scale, Coordinate panOrigin) throws GeomajasException {\n\t\tlog.debug(\"clipTile before {}\", tile);\n\t\tList<InternalFeature> orgFeatures = tile.getFeatures();\n\t\ttile.setFeatures(new ArrayList<InternalFeature>());\n\t\tGeometry maxScreenBbox = null; // The tile's maximum bounds in screen space. Used for clipping.\n\t\tfor (InternalFeature feature : orgFeatures) {\n\t\t\t// clip feature if necessary\n\t\t\tif (exceedsScreenDimensions(feature, scale)) {\n\t\t\t\tlog.debug(\"feature {} exceeds screen dimensions\", feature);\n\t\t\t\tInternalFeatureImpl vectorFeature = (InternalFeatureImpl) feature.clone();\n\t\t\t\ttile.setClipped(true);\n\t\t\t\tvectorFeature.setClipped(true);\n\t\t\t\tif (null == maxScreenBbox) {\n\t\t\t\t\tmaxScreenBbox = JTS.toGeometry(getMaxScreenEnvelope(tile, panOrigin));\n\t\t\t\t}\n\t\t\t\tGeometry clipped = maxScreenBbox.intersection(feature.getGeometry());\n\t\t\t\tvectorFeature.setClippedGeometry(clipped);\n\t\t\t\ttile.addFeature(vectorFeature);\n\t\t\t} else {\n\t\t\t\ttile.addFeature(feature);\n\t\t\t}\n\t\t}\n\t\tlog.debug(\"clipTile after {}\", tile);\n\t}", "label": 0}
{"code": "def js_for_has_many(class_string, &form_block)\n      assoc_name       = assoc_klass.model_name\n      placeholder      = \"NEW_#{assoc_name.to_s.underscore.upcase.gsub(/\\//, '_')}_RECORD\"\n      opts = {\n        for: [assoc, assoc_klass.new],\n        class: class_string,\n        for_options: { child_index: placeholder }\n      }\n      html = template.capture { __getobj__.send(:inputs_for_nested_attributes, opts, &form_block) }\n      text = new_record.is_a?(String) ? new_record : I18n.t('active_admin.has_many_new', model: assoc_name.human)\n\n      template.link_to text, '#', class: \"button has_many_add\", data: {\n        html: CGI.escapeHTML(html).html_safe, placeholder: placeholder\n      }\n    end", "label": 4}
{"code": "function convertToZStream(stream, options) {\n\tif(stream._isZStream) return stream;\n\n\tif(isRequestStream(stream)) {\n\t\t// Request Stream\n\t\treturn new RequestStream(stream, options);\n\t}\n\n\tif(isClassicStream(stream)) {\n\t\tif(stream.readable && stream.writable) {\n\t\t\t// Duplex\n\t\t\treturn new ClassicDuplex(stream, options);\n\t\t} else if(stream.readable) {\n\t\t\t// Readable\n\t\t\treturn new ClassicReadable(stream, options);\n\t\t} else {\n\t\t\t// Writable\n\t\t\treturn new ClassicWritable(stream, options);\n\t\t}\n\t}\n\n\tvar origFuncs = {};\n\tfor(var key in stream) {\n\t\torigFuncs[key] = stream[key];\n\t}\n\t// Use duck typing in case of multiple stream implementations\n\textend(stream, streamMixins.prototype);\n\tstreamMixins.call(stream, origFuncs);\n\tif(stream.read) {\n\t\textend(stream, readableMixins.prototype);\n\t\treadableMixins.call(stream);\n\t}\n\tif(stream.write) {\n\t\textend(stream, writableMixins.prototype);\n\t\twritableMixins.call(stream);\n\t}\n\tif(typeof process === 'object' && (stream === process.stdout || stream === process.stderr)) {\n\t\t// Don't abort stdio streams on error\n\t\tstream._zNoAbort = true;\n\t}\n\treturn stream;\n}", "label": 3}
{"code": "def permit_params(*args, &block)\n      param_key = config.param_key.to_sym\n      belongs_to_param = config.belongs_to_param\n      create_another_param = :create_another if config.create_another\n\n      controller do\n        define_method :permitted_params do\n          permitted_params =\n            active_admin_namespace.permitted_params +\n              Array.wrap(belongs_to_param) +\n              Array.wrap(create_another_param)\n\n          params.permit(*permitted_params, param_key => block ? instance_exec(&block) : args)\n        end\n\n        private :permitted_params\n      end\n    end", "label": 4}
{"code": "public static int cudnnCreatePersistentRNNPlan(\n        cudnnRNNDescriptor rnnDesc, \n        int minibatch, \n        int dataType, \n        cudnnPersistentRNNPlan plan)\n    {\n        return checkResult(cudnnCreatePersistentRNNPlanNative(rnnDesc, minibatch, dataType, plan));\n    }", "label": 0}
{"code": "public function setState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dlp\\V2\\DlpJob_JobState::class);\n        $this->state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private function formatDestinationRequest($destination, array $options)\n    {\n        if (!is_string($destination) && !($destination instanceof Bucket)) {\n            throw new \\InvalidArgumentException(\n                '$destination must be either a string or an instance of Bucket.'\n            );\n        }\n\n        $destAcl = isset($options['predefinedAcl']) ? $options['predefinedAcl'] : null;\n        $destObject = isset($options['name']) ? $options['name'] : $this->identity['object'];\n\n        unset($options['name']);\n        unset($options['predefinedAcl']);\n\n        return array_filter([\n            'destinationBucket' => $destination instanceof Bucket ? $destination->name() : $destination,\n            'destinationObject' => $destObject,\n            'destinationPredefinedAcl' => $destAcl,\n            'sourceBucket' => $this->identity['bucket'],\n            'sourceObject' => $this->identity['object'],\n            'sourceGeneration' => $this->identity['generation'],\n            'userProject' => $this->identity['userProject'],\n        ]) + $this->formatEncryptionHeaders($options + $this->encryptionData);\n    }", "label": 2}
{"code": "public function setPublicKeyCertificate($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Iot\\V1\\PublicKeyCertificate::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (n *networkNamespace) ApplyOSTweaks(types []SandboxType) {\n\tfor _, t := range types {\n\t\tswitch t {\n\t\tcase SandboxTypeLoadBalancer:\n\t\t\tkernel.ApplyOSTweaks(loadBalancerConfig)\n\t\t}\n\t}\n}", "label": 5}
{"code": "public String getPrefixStatsSinglePositionPrefixAttribute(String field) {\n    return String.join(MtasToken.DELIMITER, singlePositionPrefix.get(field));\n  }", "label": 0}
{"code": "func lookupHandler(handlerIndex int) (handler, error) {\n\thandlerMu.Lock()\n\tdefer handlerMu.Unlock()\n\n\thandle, ok := handlers[handlerIndex]\n\tif !ok {\n\t\treturn nil, trace.BadParameter(\"handler with index %v not registered\", handlerIndex)\n\t}\n\n\treturn handle, nil\n}", "label": 5}
{"code": "def setup_spawn\n      @logger.info(\"configuring sensu spawn\", :settings => @settings[:sensu][:spawn])\n      threadpool_size = @settings[:sensu][:spawn][:limit] + 10\n      @logger.debug(\"setting eventmachine threadpool size\", :size => threadpool_size)\n      EM::threadpool_size = threadpool_size\n      Spawn.setup(@settings[:sensu][:spawn])\n    end", "label": 4}
{"code": "public static base_responses unset(nitro_service client, gslbservice resources[],  String[] args) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tgslbservice unsetresources[] = new gslbservice[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tunsetresources[i] = new gslbservice();\n\t\t\t\tunsetresources[i].servicename = resources[i].servicename;\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static transformpolicylabel_binding get(nitro_service service, String labelname) throws Exception{\n\t\ttransformpolicylabel_binding obj = new transformpolicylabel_binding();\n\t\tobj.set_labelname(labelname);\n\t\ttransformpolicylabel_binding response = (transformpolicylabel_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getDataName(adapterName) {\n  expect(arguments).to.have.length.below(\n    2,\n    'Invalid arguments length when getting the data name of an Attribute ' +\n    '(it has to be passed less than 2 arguments)');\n\n  if (adapterName) {\n    expect(adapterName).to.be.a(\n      'string',\n      'Invalid argument \"adapterName\" when getting the data name of an ' +\n      'Attribute (it has to be a string)'\n    );\n\n    if (\n      this.dataName &&\n      typeof this.dataName === 'object' &&\n      this.dataName.hasOwnProperty(adapterName)\n    ) {\n      return this.dataName[adapterName];\n    }\n  }\n\n  if (this.dataName && typeof this.dataName === 'string') {\n    return this.dataName;\n  } else {\n    return this.name;\n  }\n}", "label": 3}
{"code": "function findMatchingDocuments(type, documentIDs, modelToSearch, cb) {\n\n    var errorTextDataType = type === models.MODELNAMES.DATA_SOURCE ? \"Data Sources\" : \"Data Targets\";\n\n    //If the form contains no data sources, then no need to verify\n    if (documentIDs.length === 0) {\n      return cb(undefined, []);\n    }\n\n    var query = {_id: {\n      \"$in\": documentIDs\n    }};\n\n    modelToSearch.find(query).exec(function(err, foundModels) {\n      if (err) {\n        return cb(buildErrorResponse({\n          error: err,\n          userDetail: \"Unexpected Error Finding \" + errorTextDataType\n        }));\n      }\n\n      //There should be the same number of data source documents\n      if (documentIDs.length !== foundModels.length) {\n\n        var missingDocumentId = _.find(documentIDs, function(documentId) {\n          return !_.findWhere(foundModels, {_id: documentId});\n        });\n\n        //If there is no missing data source, then something is wrong..\n        if (!missingDocumentId) {\n          return cb(buildErrorResponse({\n            error: new Error(\"Unexpected Error When Finding \" + errorTextDataType),\n            systemDetail: \"Expected A Missing \" + errorTextDataType + \" But Could Not Find It\"\n          }));\n        }\n\n        return cb(buildErrorResponse({\n          userDetail: \"A \" + errorTextDataType + \" Contained In The Form Could Not Be Found\",\n          systemDetail: \"Expected \" + errorTextDataType + \" With ID \" + missingDocumentId + \" To Be Found\",\n          code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS\n        }));\n      }\n\n      //All documents found -- checking for cache if needed\n      if (options.expectDataSourceCache && type === models.MODELNAMES.DATA_SOURCE) {\n        var missingCache = _.find(foundModels, function(dataSource) {\n          return dataSource.cache.length === 0;\n        });\n\n        if (missingCache) {\n          return cb(buildErrorResponse({\n            error: new Error(\"Expected \" + errorTextDataType + \" Cached Data To Be Set\"),\n            systemDetail: \"Expected Cache For \" + errorTextDataType + \" ID \" + missingCache._id + \" To Be Set\",\n            code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS\n          }));\n        }\n      }\n\n      //Checking that only one real time data target is assigned.\n      if (type === models.MODELNAMES.DATA_TARGET) {\n        var realTimeDataTargets = _.filter(foundModels, function(foundModel) {\n          return foundModel.type === models.CONSTANTS.DATA_TARGET_TYPE_REAL_TIME;\n        });\n\n        if (realTimeDataTargets.length > 1) {\n          return cb(buildErrorResponse({\n            error: new Error(\"Only One Real Time Data Target Can Be Assigned To A Form\"),\n            code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS\n          }\n                                      ));\n        }\n      }\n\n      return cb(undefined, foundModels);\n    });\n  }", "label": 3}
{"code": "public static auditmessages[] get(nitro_service service) throws Exception{\n\t\tauditmessages obj = new auditmessages();\n\t\tauditmessages[] response = (auditmessages[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setGroup($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\ErrorReporting\\V1beta1\\ErrorGroup::class);\n        $this->group = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def format national_number, options = {}\n      type         = options[:format]       || @format\n      space        = options[:spaces]       || @space       || @@default_space\n      local_space  = options[:local_spaces] || @local_space || space           || @@default_local_space\n      parentheses  = options[:parentheses]\n      parentheses  = @parentheses || @@default_parentheses if parentheses.nil?\n      use_trunk    = options[:trunk]\n      \n      trunk, ndc, *local_pieces = split national_number\n      \n      local = format_local local_pieces, local_space\n      \n      format_cc_ndc trunk, ndc, local, type, space, parentheses, use_trunk\n    end", "label": 4}
{"code": "def process_file(file, report)\n      lints = collect_lints(file, linter_selector, config)\n      lints.each { |lint| report.add_lint(lint) }\n      report.finish_file(file, lints)\n    end", "label": 4}
{"code": "function extend(dest, src) {\n    var result = dest;\n    for(var n in src) {\n        result[n] = src[n];\n    }\n    return result;\n}", "label": 3}
{"code": "def _make_phylesystem_cache_region(**kwargs):\n    \"\"\"Only intended to be called by the Phylesystem singleton.\n    \"\"\"\n    global _CACHE_REGION_CONFIGURED, _REGION\n    if _CACHE_REGION_CONFIGURED:\n        return _REGION\n    _CACHE_REGION_CONFIGURED = True\n    try:\n        # noinspection PyPackageRequirements\n        from dogpile.cache import make_region\n    except:\n        _LOG.debug('dogpile.cache not available')\n        return\n    region = None\n    trial_key = 'test_key'\n    trial_val = {'test_val': [4, 3]}\n    trying_redis = True\n    if trying_redis:\n        try:\n            a = {\n                'host': 'localhost',\n                'port': 6379,\n                'db': 0,  # default is 0\n                'redis_expiration_time': 60 * 60 * 24 * 2,  # 2 days\n                'distributed_lock': False  # True if multiple processes will use redis\n            }\n            region = make_region().configure('dogpile.cache.redis', arguments=a)\n            _LOG.debug('cache region set up with cache.redis.')\n            _LOG.debug('testing redis caching...')\n            region.set(trial_key, trial_val)\n            assert trial_val == region.get(trial_key)\n            _LOG.debug('redis caching works')\n            region.delete(trial_key)\n            _REGION = region\n            return region\n        except:\n            _LOG.debug('redis cache set up failed.')\n            region = None\n    trying_file_dbm = False\n    if trying_file_dbm:\n        _LOG.debug('Going to try dogpile.cache.dbm ...')\n        first_par = _get_phylesystem_parent(**kwargs)[0]\n        cache_db_dir = os.path.split(first_par)[0]\n        cache_db = os.path.join(cache_db_dir, 'phylesystem-cachefile.dbm')\n        _LOG.debug('dogpile.cache region using \"{}\"'.format(cache_db))\n        try:\n            a = {'filename': cache_db}\n            region = make_region().configure('dogpile.cache.dbm',\n                                             expiration_time=36000,\n                                             arguments=a)\n            _LOG.debug('cache region set up with cache.dbm.')\n            _LOG.debug('testing anydbm caching...')\n            region.set(trial_key, trial_val)\n            assert trial_val == region.get(trial_key)\n            _LOG.debug('anydbm caching works')\n            region.delete(trial_key)\n            _REGION = region\n            return region\n        except:\n            _LOG.debug('anydbm cache set up failed')\n            _LOG.debug('exception in the configuration of the cache.')\n    _LOG.debug('Phylesystem will not use caching')\n    return None", "label": 1}
{"code": "def ncx(indentarray)\n      @ncx_isbn = ncx_isbn\n      @ncx_doctitle = ncx_doctitle\n      @ncx_navmap = ncx_navmap(indentarray)\n\n      tmplfile = File.expand_path('./ncx/epubv2.ncx.erb', ReVIEW::Template::TEMPLATE_DIR)\n      ReVIEW::Template.load(tmplfile).result(binding)\n    end", "label": 4}
{"code": "function addPointToDomain( point, x, y, domainId ){\n\n        var domain = domains[ domainId ];\n        var newPoint = {\n            value: point,\n            x: x,\n            y: y,\n            identifier: domain.identifier,\n            domainId: domainId\n        };\n\n        pointsHash[ x + '_' + y ] = {\n            value: point,\n            identifier: domain.identifier,\n            domainId: domainId\n        };\n\n        domain.points.push( newPoint );\n    }", "label": 3}
{"code": "function error() {\n                reject(new TypeError());\n                doc.removeEventListener(api.events.error, error, false);\n            }", "label": 3}
{"code": "function(global, refreshToken) {\n    return new Promise((resolve, reject) => {\n      this._start()\n          .uri('/api/logout')\n          .urlParameter('global', global)\n          .urlParameter('refreshToken', refreshToken)\n          .post()\n          .go(this._responseHandler(resolve, reject));\n    });\n  }", "label": 3}
{"code": "func (r *Rotation) String() string {\n\tswitch r.State {\n\tcase \"\", RotationStateStandby:\n\t\tif r.LastRotated.IsZero() {\n\t\t\treturn \"never updated\"\n\t\t}\n\t\treturn fmt.Sprintf(\"rotated %v\", r.LastRotated.Format(teleport.HumanDateFormatSeconds))\n\tcase RotationStateInProgress:\n\t\treturn fmt.Sprintf(\"%v (mode: %v, started: %v, ending: %v)\",\n\t\t\tr.PhaseDescription(),\n\t\t\tr.Mode,\n\t\t\tr.Started.Format(teleport.HumanDateFormatSeconds),\n\t\t\tr.Started.Add(r.GracePeriod.Duration()).Format(teleport.HumanDateFormatSeconds),\n\t\t)\n\tdefault:\n\t\treturn \"unknown\"\n\t}\n}", "label": 5}
{"code": "def run\n      program :name, 'CredentialsManager'\n      program :version, Fastlane::VERSION\n      program :description, 'Manage credentials for fastlane tools.'\n\n      # Command to add entry to Keychain\n      command :add do |c|\n        c.syntax = 'fastlane fastlane-credentials add'\n        c.description = 'Adds a fastlane credential to the keychain.'\n\n        c.option('--username username', String, 'Username to add.')\n        c.option('--password password', String, 'Password to add.')\n\n        c.action do |args, options|\n          username = options.username || ask('Username: ')\n          password = options.password || ask('Password: ') { |q| q.echo = '*' }\n\n          add(username, password)\n\n          puts(\"Credential #{username}:#{'*' * password.length} added to keychain.\")\n        end\n      end\n\n      # Command to remove credential from Keychain\n      command :remove do |c|\n        c.syntax = 'fastlane fastlane-credentials remove'\n        c.description = 'Removes a fastlane credential from the keychain.'\n\n        c.option('--username username', String, 'Username to remove.')\n\n        c.action do |args, options|\n          username = options.username || ask('Username: ')\n\n          remove(username)\n        end\n      end\n\n      run!\n    end", "label": 4}
{"code": "def message\n      @message ||= begin\n        description, stacktrace = parse.values_at(:description, :stacktrace)\n\n        msg = description\n        msg = msg.red if msg.respond_to?(:red)\n        msg << stacktrace if stacktrace\n        msg\n      end\n    end", "label": 4}
{"code": "function completeSpecFiles(argv, _filters) {\n        // if user manually defined an empty specFiles array, do not add specFiles from folder\n        if (Object.keys(_filters.specFiles).length === 0 && !argv.specFiles) {\n            io_1.getAllFiles(specsDir, '.spec.ts').forEach(specFile => _filters.specFiles[specFile] = true);\n            return true;\n        }\n        else {\n            let removeOnly = true;\n            const removeSpecFiles = {};\n            for (const specFile in _filters.specFiles) {\n                let remove = false;\n                let matchStr = specFile;\n                if (specFile.substr(0, 1) === '-') {\n                    remove = true;\n                    matchStr = specFile.substr(1, specFile.length - 1);\n                }\n                else {\n                    removeOnly = false;\n                }\n                if (remove) {\n                    delete _filters.specFiles[specFile];\n                    removeSpecFiles[matchStr] = true;\n                }\n            }\n            if (removeOnly) {\n                io_1.getAllFiles(specsDir, '.spec.ts')\n                    .filter(specFile => !(specFile in removeSpecFiles))\n                    .forEach(specFile => _filters.specFiles[specFile] = true);\n            }\n        }\n        return false;\n    }", "label": 3}
{"code": "def BROKER_URL(self):\n        \"\"\"Sets BROKER_URL depending on redis or rabbitmq settings\"\"\"\n\n        # also allow specify broker_url\n        broker_url = get('BROKER_URL', None)\n        if broker_url:\n            log.info(\"Using BROKER_URL setting: {}\".format(broker_url))\n            return broker_url\n\n        redis_available = self._redis_available()\n        broker_type = self.BROKER_TYPE\n\n        if broker_type == 'redis' and not redis_available:\n            log.warn(\"Choosed broker type is redis, but redis not available. \\\n                    Check redis package, and REDIS_HOST, REDIS_PORT settings\")\n\n        if broker_type == 'redis' and redis_available:\n\n            return 'redis://{host}:{port}/{db}'.format(\n                    host=self.REDIS_HOST,\n                    port=self.REDIS_PORT,\n                    db=self.CELERY_REDIS_BROKER_DB)\n        elif broker_type == 'rabbitmq':\n            return 'amqp://{user}:{passwd}@{host}:{port}/{vhost}'.format(\n                    user=self.RABBITMQ_USER,\n                    passwd=self.RABBITMQ_PASSWD,\n                    host=self.RABBITMQ_HOST,\n                    port=self.RABBITMQ_PORT,\n                    vhost=self.RABBITMQ_VHOST)\n        else:\n            return DEFAULT_BROKER_URL", "label": 1}
{"code": "def list_topics\n      response = random_broker.fetch_metadata(topics: nil)\n      response.topics.select do |topic|\n        topic.topic_error_code == 0\n      end.map(&:topic_name)\n    end", "label": 4}
{"code": "protected function addManipulationsFromDb(Media $media)\n    {\n        collect($media->manipulations)->each(function ($manipulations, $conversionName) {\n            $this->addManipulationToConversion(new Manipulations([$manipulations]), $conversionName);\n        });\n    }", "label": 2}
{"code": "func (r *Packet) Reply(payload interface{}, err error) ([]byte, error) {\n\tp := new(Packet)\n\n\tstatus := uint32(StatusSuccess)\n\n\tif err != nil {\n\t\tstatus = errorStatus(err)\n\t} else {\n\t\tp.Payload, err = MarshalBinary(payload)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tp.Header = Header{\n\t\tVersion:     HeaderVersion,\n\t\tDummy:       OpNewHeader,\n\t\tPacketSize:  headerSize + uint32(len(p.Payload)),\n\t\tHeaderSize:  headerSize,\n\t\tRequestID:   r.RequestID,\n\t\tOp:          r.Op,\n\t\tStatus:      status,\n\t\tFlags:       PacketFlagReply,\n\t\tInformation: 0,\n\t\tSessionID:   r.SessionID,\n\t}\n\n\tif Trace {\n\t\trc := \"OK\"\n\t\tif err != nil {\n\t\t\trc = err.Error()\n\t\t}\n\t\tfmt.Fprintf(os.Stderr, \"[hgfs] response %#v [%s]\\n\", p.Header, rc)\n\t} else if err != nil {\n\t\tlog.Printf(\"[hgfs] op=%d error: %s\", r.Op, err)\n\t}\n\n\treturn p.MarshalBinary()\n}", "label": 5}
{"code": "function encodeError(err, header) {\n  return Buffer.concat([\n    header || new Buffer([0]), // Recover the header if possible.\n    new Buffer([1, 0]), // Error flag and first union index.\n    STRING_TYPE.toBuffer(err.message)\n  ]);\n}", "label": 3}
{"code": "def create_file_for(self, script):\n        \"\"\"\n        Create a temporary, executable bash file.\n\n        It also does render given script (string) with the model and\n        the provided environment variables and optional also an item\n        when using the B{with} field.\n\n        Args:\n            script (str): either pather and filename or Bash code.\n\n        Returns:\n            str: path and filename of a temporary file.\n        \"\"\"\n        temp = tempfile.NamedTemporaryFile(\n            prefix=\"pipeline-script-\", mode='w+t', suffix=\".sh\", delete=False,\n            dir=self.get_temporary_scripts_path())\n\n        self.update_environment_variables(temp.name)\n        rendered_script = render(script, model=self.config.model, env=self.env, item=self.config.item,\n                                 variables=self.config.variables)\n        if rendered_script is None:\n            self.success = False\n            temp.close()\n            os.remove(temp.name)\n            return None\n\n        to_file_map = {2: lambda s: s.encode('utf-8'), 3: lambda s: s}\n\n        if all(ord(ch) < 128 for ch in rendered_script) and os.path.isfile(rendered_script):\n            with open(rendered_script) as handle:\n                content = str(handle.read())\n                temp.writelines(content)\n        else:\n            temp.write(u\"#!/bin/bash\\n%s\" % self.render_bash_options())\n            temp.write(to_file_map[sys.version_info.major](rendered_script))\n        temp.close()\n        # make Bash script executable\n        os.chmod(temp.name, 0o700)\n        return temp.name", "label": 1}
{"code": "def read_attribute_for_validation(attr)\n      attribute = database_field_name(attr)\n      if relations.key?(attribute)\n        begin_validate\n        relation = without_autobuild { send(attr) }\n        exit_validate\n        relation.do_or_do_not(:in_memory) || relation\n      elsif fields[attribute].try(:localized?)\n        attributes[attribute]\n      else\n        send(attr)\n      end\n    end", "label": 4}
{"code": "function hasFileWithHigherPriorityExtension(file, literalFiles, wildcardFiles, extensions, keyMapper) {\n        var extensionPriority = ts.getExtensionPriority(file, extensions);\n        var adjustedExtensionPriority = ts.adjustExtensionPriority(extensionPriority);\n        for (var i = 0 /* Highest */; i < adjustedExtensionPriority; i++) {\n            var higherPriorityExtension = extensions[i];\n            var higherPriorityPath = keyMapper(ts.changeExtension(file, higherPriorityExtension));\n            if (higherPriorityPath in literalFiles || higherPriorityPath in wildcardFiles) {\n                return true;\n            }\n        }\n        return false;\n    }", "label": 3}
{"code": "public function getItems()\n    {\n        return [\n            'items' => array_map(function ($item) {\n                return $item->fill()->attributes;\n            }, array_merge($this->lfm->folders(), $this->lfm->files())),\n            'display' => $this->helper->getDisplayMode(),\n            'working_dir' => $this->lfm->path('working_dir'),\n        ];\n    }", "label": 2}
{"code": "public function setGcsSource($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\GcsSource::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response add(nitro_service client, dnspolicylabel resource) throws Exception {\n\t\tdnspolicylabel addresource = new dnspolicylabel();\n\t\taddresource.labelname = resource.labelname;\n\t\taddresource.transform = resource.transform;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "private function formatField($label, $value)\n    {\n        if ($value === null) {\n            $value = '<comment>None</comment>';\n        }\n\n        return [sprintf('<info>%s</info>', $label), $this->formatValue($value)];\n    }", "label": 2}
{"code": "public function setCloudStorageOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CloudStorageOptions::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static function psrBatchLogger($name, array $options = [])\n    {\n        $client = array_key_exists('clientConfig', $options)\n            ? new self($options['clientConfig'])\n            : new self();\n        // Force enabling batch.\n        $options['batchEnabled'] = true;\n        return $client->psrLogger($name, $options);\n    }", "label": 2}
{"code": "def cell_type_from_value(v)\n      if v.is_a?(Date)\n        :date\n      elsif v.is_a?(Time)\n        :time\n      elsif v.is_a?(TrueClass) || v.is_a?(FalseClass)\n        :boolean\n      elsif v.to_s =~ Axlsx::NUMERIC_REGEX\n        :integer\n      elsif v.to_s =~ Axlsx::FLOAT_REGEX\n        :float\n      elsif v.to_s =~ Axlsx::ISO_8601_REGEX\n        :iso_8601\n      elsif v.is_a? RichText\n        :richtext\n      else\n        :string\n      end\n    end", "label": 4}
{"code": "function instrumental_send(payload) {\n  var state = \"cold\";\n  var tlsOptionsVariation = selectTlsOptionsVariation();\n\n  var client = instrumental_connection(host, port, tlsOptionsVariation, function(_client){\n    state = \"connected\";\n\n    var cleanString = function(value) {\n      return String(value).replace(/\\s+/g, \"_\");\n    }\n\n    // Write the authentication header\n    _client.write(\n      \"hello version node/statsd-instrumental-backend/\" + cleanString(package.version) +\n        \" hostname \" + cleanString(hostname) +\n        \" pid \" + cleanString(process.pid) +\n        \" runtime \" + cleanString(\"node/\" + process.versions.node) +\n        \" platform \" + cleanString(process.platform + \"-\" + process.arch) + \"\\n\" +\n      \"authenticate \" + key + \"\\n\"\n    );\n  });\n\n  // We need to handle the timeout. I think we should only care about read\n  // timeouts. That is we write out data, if we don't hear back in timeout\n  // seconds then the data probably hasn't reached the server.\n  client.setTimeout(timeout, function() {\n    // ZOMG FAILED WRITING WE ARE BAD AT COMPUTER SCIENCE\n    if(state == \"connected\") {\n      // We're waiting to hear back from the server and it has timed out. It's\n      // unlikely that the server will suddenly wake up and send us our data so\n      // lets disconnect and go shopping.\n      client.end();\n    }\n  });\n\n  // HOW WE HANDLE ERRORS. We should probably reconnect, maybe retry.\n  client.addListener(\"error\", function(exception){\n    if(debug) {\n      log(\"Client error:\", exception);\n    }\n    instrumentalStats.last_exception = Math.round(new Date().getTime() / 1000);\n  });\n\n  // What do we do when instrumental talks to us\n  var totalBuffer = \"\";\n  client.on(\"data\", function(buffer) {\n    totalBuffer = totalBuffer + buffer;\n\n    if(debug) {\n      log(\"Received:\", buffer);\n    }\n\n    // Authorization success\n    if(totalBuffer == \"ok\\nok\\n\") {\n      error = false;\n\n      if(debug) {\n        log(\"Sending:\", payload.join(\"\\n\"));\n      }\n\n      client.end(payload.join(\"\\n\") + \"\\n\", function() {\n        tlsOptionsVariation.lastSuccessAt = new Date();\n        if (debug) log(\"payload sent, tlsOptionsVariation: \", tlsOptionsVariation);\n        state = \"sent\";\n      });\n\n      instrumentalStats.last_flush = Math.round(new Date().getTime() / 1000);\n\n    // Authorization failure\n    } else if(totalBuffer.length >= \"ok\\nok\\n\".length) {\n      // TODO: Actually do something with this\n      error = true;\n\n      instrumentalStats.last_exception = Math.round(new Date().getTime() / 1000);\n    }\n  });\n}", "label": 3}
{"code": "public static base_response unset(nitro_service client, aaacertparams resource, String[] args) throws Exception{\n\t\taaacertparams unsetresource = new aaacertparams();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public function setFormat($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Iot\\V1\\PublicKeyFormat::class);\n        $this->format = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (i *TeleInstance) StopNodes() error {\n\tvar errors []error\n\tfor _, node := range i.Nodes {\n\t\tif err := node.Close(); err != nil {\n\t\t\terrors = append(errors, err)\n\t\t\tlog.Errorf(\"failed closing extra node %v\", err)\n\t\t}\n\t\tif err := node.Wait(); err != nil {\n\t\t\terrors = append(errors, err)\n\t\t\tlog.Errorf(\"failed stopping extra node %v\", err)\n\t\t}\n\t}\n\treturn trace.NewAggregate(errors...)\n}", "label": 5}
{"code": "private function fourBytesToInt($s)\n\t{\n\t\treturn (ord($s[0]) << 24) + (ord($s[1]) << 16) + (ord($s[2]) << 8) + ord($s[3]);\n\t}", "label": 2}
{"code": "def append(label, block)\n      if store.key?(label.to_sym) && store[label.to_sym].respond_to?(:<<)\n        store[label.to_sym] << block\n      else\n        store[label.to_sym] = []\n        store[label.to_sym] << block\n      end\n    end", "label": 4}
{"code": "public String getPrototypeName() {\n\t\tString name = getClass().getName();\n\t\tif (name.startsWith(ORG_GEOMAJAS)) {\n\t\t\tname = name.substring(ORG_GEOMAJAS.length());\n\t\t}\n\t\tname = name.replace(\".dto.\", \".impl.\");\n\t\treturn name.substring(0, name.length() - 4) + \"Impl\";\n\t}", "label": 0}
{"code": "func (c *Client) Run(ctx context.Context, cmd *exec.Cmd) error {\n\tvc := c.ProcessManager.Client()\n\n\tspec := types.GuestProgramSpec{\n\t\tProgramPath:      cmd.Path,\n\t\tArguments:        strings.Join(cmd.Args, \" \"),\n\t\tEnvVariables:     cmd.Env,\n\t\tWorkingDirectory: cmd.Dir,\n\t}\n\n\tpid, serr := c.ProcessManager.StartProgram(ctx, c.Authentication, &spec)\n\tif serr != nil {\n\t\treturn serr\n\t}\n\n\tif cmd.Stdin != nil {\n\t\tdst := fmt.Sprintf(\"/proc/%d/stdin\", pid)\n\n\t\tvar buf bytes.Buffer\n\t\tsize, err := io.Copy(&buf, cmd.Stdin)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tattr := new(types.GuestPosixFileAttributes)\n\n\t\turl, err := c.FileManager.InitiateFileTransferToGuest(ctx, c.Authentication, dst, attr, size, true)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tu, err := c.FileManager.TransferURL(ctx, url)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tp := soap.DefaultUpload\n\t\tp.ContentLength = size\n\n\t\terr = vc.Client.Upload(ctx, &buf, u, &p)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tnames := []string{\"out\", \"err\"}\n\n\tfor i, w := range []io.Writer{cmd.Stdout, cmd.Stderr} {\n\t\tif w == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tsrc := fmt.Sprintf(\"/proc/%d/std%s\", pid, names[i])\n\n\t\tinfo, err := c.procReader(ctx, src)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tu, err := c.FileManager.TransferURL(ctx, info.Url)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tf, _, err := vc.Client.Download(ctx, u, &soap.DefaultDownload)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t_, err = io.Copy(w, f)\n\t\t_ = f.Close()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tprocs, err := c.ProcessManager.ListProcesses(ctx, c.Authentication, []int64{pid})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(procs) == 1 {\n\t\trc := procs[0].ExitCode\n\t\tif rc != 0 {\n\t\t\treturn fmt.Errorf(\"%s: exit %d\", cmd.Path, rc)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def _slugify_internal_collection_name(self, json_repr):\n        \"\"\"Parse the JSON, find its name, return a slug of its name\"\"\"\n        collection = self._coerce_json_to_collection(json_repr)\n        if collection is None:\n            return None\n        internal_name = collection['name']\n        return slugify(internal_name)", "label": 1}
{"code": "def create_and_run_collector(document, options):\n        \"\"\"Create and run collector process for report data.\"\"\"\n        collector = None\n        if not options.report == 'off':\n            collector = Collector()\n            collector.store.configure(document)\n            Event.configure(collector_queue=collector.queue)\n            collector.start()\n        return collector", "label": 1}
{"code": "List getOrderby()\r\n    {\r\n        List result = _getOrderby();\r\n        Iterator iter = getCriteria().iterator();\r\n        Object crit;\r\n\r\n        while (iter.hasNext())\r\n        {\r\n            crit = iter.next();\r\n            if (crit instanceof Criteria)\r\n            {\r\n                result.addAll(((Criteria) crit).getOrderby());\r\n            }\r\n        }\r\n\r\n        return result;\r\n    }", "label": 0}
{"code": "def compare_settings(produced, expected, params)\n      it 'should match build settings' do\n        # Find faulty settings in different categories\n        missing_settings    = expected.keys.reject { |k| produced.key?(k) }\n        unexpected_settings = produced.keys.reject { |k| expected.key?(k) }\n        wrong_settings      = (expected.keys - missing_settings).select do |k|\n          produced_setting = produced[k]\n          produced_setting = produced_setting.join(' ') if produced_setting.respond_to? :join\n          produced_setting != expected[k]\n        end\n\n        # Build pretty description for what is going on\n        description = []\n        description << \"Doesn't match build settings for \\e[1m#{params}\\e[0m\"\n\n        if wrong_settings.count > 0\n          description << 'Wrong build settings:'\n          description += wrong_settings.map { |s| \"* #{s.to_s.yellow} is #{produced[s].to_s.red}, but should be #{expected[s].to_s.green}\" }\n          description << ''\n        end\n\n        if missing_settings.count > 0\n          description << 'Missing build settings:'\n          description << missing_settings.map { |s| \"* #{s.to_s.red} (#{expected[s]})\" }\n          description << ''\n        end\n\n        if unexpected_settings.count > 0\n          description << 'Unexpected additional build settings:'\n          description += unexpected_settings.map { |s| \"* #{s.to_s.green} (#{produced[s]})\" }\n          description << ''\n        end\n\n        # Expect\n        faulty_settings = missing_settings + unexpected_settings + wrong_settings\n        faulty_settings.should.satisfy(description * \"\\n\") do\n          faulty_settings.length == 0\n        end\n      end\n    end", "label": 4}
{"code": "func NewResolver(address string, proxyDNS bool, resolverKey string, backend DNSBackend) Resolver {\n\treturn &resolver{\n\t\tbackend:       backend,\n\t\tproxyDNS:      proxyDNS,\n\t\tlistenAddress: address,\n\t\tresolverKey:   resolverKey,\n\t\terr:           fmt.Errorf(\"setup not done yet\"),\n\t\tstartCh:       make(chan struct{}, 1),\n\t}\n}", "label": 5}
{"code": "public function setInfoTypeTransformations($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\InfoTypeTransformations::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def create_modifier_list(location_id, body, opts = {})\n      data, _status_code, _headers = create_modifier_list_with_http_info(location_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "public function setWords($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\Word::class);\n        $this->words = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private String addAndEncode(String originalValue, String newType,\n      String newValue, boolean encode) {\n    if (newValue == null) {\n      return originalValue;\n    } else {\n      String finalNewValue;\n      if (encode) {\n        if (newType == null) {\n          finalNewValue = new String(\n              enc.encode(newValue.getBytes(StandardCharsets.UTF_8)),\n              StandardCharsets.UTF_8);\n        } else {\n          finalNewValue = new String(\n              enc.encode(newType.getBytes(StandardCharsets.UTF_8)),\n              StandardCharsets.UTF_8)\n              + \":\"\n              + new String(\n                  enc.encode(newValue.getBytes(StandardCharsets.UTF_8)),\n                  StandardCharsets.UTF_8);\n        }\n      } else {\n        finalNewValue = newValue;\n      }\n      if (originalValue == null || originalValue.isEmpty()) {\n        return finalNewValue;\n      } else {\n        return originalValue + (encode ? \" \" : \"\") + finalNewValue;\n      }\n    }\n  }", "label": 0}
{"code": "public function setTimezone($value)\n    {\n        /** @var static $date */\n        $date = parent::setTimezone(static::safeCreateDateTimeZone($value));\n        // https://bugs.php.net/bug.php?id=72338\n        // just workaround on this bug\n        $date->getTimestamp();\n\n        return $date;\n    }", "label": 2}
{"code": "public function setProfile($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\Profile::class);\n        $this->profile = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static void compress(File dir, File zipFile) throws IOException {\n\n    FileOutputStream fos = new FileOutputStream(zipFile);\n    ZipOutputStream zos = new ZipOutputStream(fos);\n\n    recursiveAddZip(dir, zos, dir);\n\n    zos.finish();\n    zos.close();\n\n  }", "label": 0}
{"code": "def as_view(cls, *args, **kwargs):\n        \"\"\"\n        This method is used within urls.py to create unique formwizard\n        instances for every request. We need to override this method because\n        we add some kwargs which are needed to make the formwizard usable.\n        \"\"\"\n        initkwargs = cls.get_initkwargs(*args, **kwargs)\n        return super(WizardView, cls).as_view(**initkwargs)", "label": 1}
{"code": "def cull(self, delta: bool) -> None:\n        \"\"\"\n        Cull cache entry frame list to size, favouring most recent query time.\n\n        :param delta: True to operate on rev reg deltas, False for rev reg states\n        \"\"\"\n\n        LOGGER.debug('RevoCacheEntry.cull >>> delta: %s', delta)\n\n        rr_frames = self.rr_delta_frames if delta else self.rr_state_frames\n        mark = 4096**0.5  # max rev reg size = 4096; heuristic: hover max around sqrt(4096) = 64\n        if len(rr_frames) > int(mark * 1.25):\n            rr_frames.sort(key=lambda x: -x.qtime)  # order by descending query time\n            del rr_frames[int(mark * 0.75):]  # retain most recent, grow again from here\n            LOGGER.info(\n                'Pruned revocation cache entry %s to %s %s frames',\n                self.rev_reg_def['id'],\n                len(rr_frames),\n                'delta' if delta else 'state')\n\n        LOGGER.debug('RevoCacheEntry.cull <<<')", "label": 1}
{"code": "func (a *ArgType) getstartcount(fields []*Field, pkFields []*Field) int {\n\treturn len(fields) - len(pkFields)\n}", "label": 5}
{"code": "func AuthoritiesToTrustedCerts(authorities []services.CertAuthority) []TrustedCerts {\n\tout := make([]TrustedCerts, len(authorities))\n\tfor i, ca := range authorities {\n\t\tout[i] = TrustedCerts{\n\t\t\tClusterName:      ca.GetClusterName(),\n\t\t\tHostCertificates: ca.GetCheckingKeys(),\n\t\t\tTLSCertificates:  services.TLSCerts(ca),\n\t\t}\n\t}\n\treturn out\n}", "label": 5}
{"code": "def raw_national\n      return nil if sanitized.nil? || sanitized.empty?\n      if valid?\n        @national_number\n      elsif country_code && sanitized.start_with?(country_code)\n        sanitized[country_code.size..-1]\n      else\n        sanitized\n      end\n    end", "label": 4}
{"code": "function track(property, thisArg){\n    if(!(property in trackedProperties)){\n      trackedProperties[property] = true;\n      values[property] = model[property];\n      Object.defineProperty(model, property, {\n        get: function () { return values[property]; },\n        set: function(newValue) {\n          var oldValue = values[property];\n          values[property] = newValue;\n          getListeners(property).forEach(function(callback){\n            callback.call(thisArg, newValue, oldValue);\n          });\n        }\n      });\n    }\n  }", "label": 3}
{"code": "public function error_handler($errno, $errstr, $errfile, $errline, $errcontext = null)\n    {\n        // throwing an exception in an error handler will halt execution\n        //   set the last error and continue\n        $this->last_error = compact('errno', 'errstr', 'errfile', 'errline', 'errcontext');\n    }", "label": 2}
{"code": "function find(id, type, sourcedir, options) {\n  const { cache, fileExtensions, nativeModules } = options;\n  const pkgDetails = pkg.getDetails(sourcedir, options);\n  let filepath = isRelativeFilepath(id) ? path.join(sourcedir, id) : id;\n\n  filepath = alias.resolve(filepath, pkgDetails && pkgDetails.aliases);\n  if (filepath === false || nativeModules.includes(filepath)) return false;\n\n  if (isAbsoluteFilepath(filepath)) {\n    filepath = findFilepath(filepath, type, fileExtensions);\n    filepath = alias.resolve(filepath, pkgDetails && pkgDetails.aliases);\n    // File doesn't exist or is disabled\n    if (filepath === '' || filepath === false) return filepath;\n    // File found\n    if (isAbsoluteFilepath(filepath)) {\n      // Cache\n      cache.setFile(\n        {\n          id: pkg.resolveId(pkgDetails, filepath),\n          path: filepath,\n          version: pkgDetails.version\n        },\n        versionDelimiter\n      );\n\n      return filepath;\n    }\n  }\n\n  // Update id if it has been resolved as package\n  if (!isFilepath(filepath)) id = filepath;\n\n  // Search paths for matches\n  pkgDetails.paths.some(sourcepath => {\n    if (id && sourcedir != sourcepath) {\n      let fp = path.join(sourcepath, id);\n\n      fp = find(fp, type, fp, options);\n      if (fp !== '') {\n        filepath = fp;\n        return true;\n      }\n      filepath = '';\n    }\n  });\n\n  return filepath;\n}", "label": 3}
{"code": "func runAPIService(cmd *cobra.Command, args []string) (exit int) {\n\t// Set up the signal handler here so we can make sure the\n\t// signals are caught after print the starting message.\n\tsignal.Notify(exitCh, syscall.SIGINT, syscall.SIGTERM)\n\n\tstderr.Print(\"API service starting...\")\n\n\tlisteners, err := openAPISockets()\n\tif err != nil {\n\t\tstderr.PrintE(\"Failed to open sockets\", err)\n\t\treturn 254\n\t}\n\tif len(listeners) == 0 { // This is unlikely...\n\t\tstderr.Println(\"No sockets to listen to. Quitting.\")\n\t\treturn 254\n\t}\n\n\tpublicServer := grpc.NewServer() // TODO(yifan): Add TLS credential option.\n\n\tv1AlphaAPIServer, err := newV1AlphaAPIServer()\n\tif err != nil {\n\t\tstderr.PrintE(\"failed to create API service\", err)\n\t\treturn 254\n\t}\n\n\tv1alpha.RegisterPublicAPIServer(publicServer, v1AlphaAPIServer)\n\n\tfor _, l := range listeners {\n\t\tdefer l.Close()\n\t\tgo publicServer.Serve(l)\n\t}\n\n\tstderr.Printf(\"API service running\")\n\n\t<-exitCh\n\n\tstderr.Print(\"API service exiting...\")\n\n\treturn\n}", "label": 5}
{"code": "protected Object doInvoke(Object proxy, Method methodToBeInvoked, Object[] args)\r\n\t\tthrows Throwable\r\n\t{\r\n\t\tMethod m =\r\n\t\t\tgetRealSubject().getClass().getMethod(\r\n\t\t\t\tmethodToBeInvoked.getName(),\r\n\t\t\t\tmethodToBeInvoked.getParameterTypes());\r\n\t\treturn m.invoke(getRealSubject(), args);\r\n\t}", "label": 0}
{"code": "func (t *TeleportClusterConfigMarshaler) Marshal(c ClusterConfig, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch resource := c.(type) {\n\tcase *ClusterConfigV3:\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *resource\n\t\t\tcopy.SetResourceID(0)\n\t\t\tresource = &copy\n\t\t}\n\t\treturn utils.FastMarshal(resource)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"unrecognized resource version %T\", c)\n\t}\n}", "label": 5}
{"code": "public static base_response delete(nitro_service client, lbroute resource) throws Exception {\n\t\tlbroute deleteresource = new lbroute();\n\t\tdeleteresource.network = resource.network;\n\t\tdeleteresource.netmask = resource.netmask;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "func (l VirtualDeviceList) Select(f func(device types.BaseVirtualDevice) bool) VirtualDeviceList {\n\tvar found VirtualDeviceList\n\n\tfor _, device := range l {\n\t\tif f(device) {\n\t\t\tfound = append(found, device)\n\t\t}\n\t}\n\n\treturn found\n}", "label": 5}
{"code": "func initSelfSignedHTTPSCert(cfg *Config) (err error) {\n\tlog.Warningf(\"No TLS Keys provided, using self signed certificate.\")\n\n\tkeyPath := filepath.Join(cfg.DataDir, defaults.SelfSignedKeyPath)\n\tcertPath := filepath.Join(cfg.DataDir, defaults.SelfSignedCertPath)\n\n\tcfg.Proxy.TLSKey = keyPath\n\tcfg.Proxy.TLSCert = certPath\n\n\t// return the existing pair if they have already been generated:\n\t_, err = tls.LoadX509KeyPair(certPath, keyPath)\n\tif err == nil {\n\t\treturn nil\n\t}\n\tif !os.IsNotExist(err) {\n\t\treturn trace.Wrap(err, \"unrecognized error reading certs\")\n\t}\n\tlog.Warningf(\"Generating self signed key and cert to %v %v.\", keyPath, certPath)\n\n\tcreds, err := utils.GenerateSelfSignedCert([]string{cfg.Hostname, \"localhost\"})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tif err := ioutil.WriteFile(keyPath, creds.PrivateKey, 0600); err != nil {\n\t\treturn trace.Wrap(err, \"error writing key PEM\")\n\t}\n\tif err := ioutil.WriteFile(certPath, creds.Cert, 0600); err != nil {\n\t\treturn trace.Wrap(err, \"error writing key PEM\")\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function createBoundary(data) {\n  while (true) {\n    var boundary = `----IPFSMini${Math.random() * 100000}.${Math.random() * 100000}`;\n    if (data.indexOf(boundary) === -1) {\n      return boundary;\n    }\n  }\n}", "label": 3}
{"code": "public static base_responses update(nitro_service client, nd6ravariables resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnd6ravariables updateresources[] = new nd6ravariables[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new nd6ravariables();\n\t\t\t\tupdateresources[i].vlan = resources[i].vlan;\n\t\t\t\tupdateresources[i].ceaserouteradv = resources[i].ceaserouteradv;\n\t\t\t\tupdateresources[i].sendrouteradv = resources[i].sendrouteradv;\n\t\t\t\tupdateresources[i].srclinklayeraddroption = resources[i].srclinklayeraddroption;\n\t\t\t\tupdateresources[i].onlyunicastrtadvresponse = resources[i].onlyunicastrtadvresponse;\n\t\t\t\tupdateresources[i].managedaddrconfig = resources[i].managedaddrconfig;\n\t\t\t\tupdateresources[i].otheraddrconfig = resources[i].otheraddrconfig;\n\t\t\t\tupdateresources[i].currhoplimit = resources[i].currhoplimit;\n\t\t\t\tupdateresources[i].maxrtadvinterval = resources[i].maxrtadvinterval;\n\t\t\t\tupdateresources[i].minrtadvinterval = resources[i].minrtadvinterval;\n\t\t\t\tupdateresources[i].linkmtu = resources[i].linkmtu;\n\t\t\t\tupdateresources[i].reachabletime = resources[i].reachabletime;\n\t\t\t\tupdateresources[i].retranstime = resources[i].retranstime;\n\t\t\t\tupdateresources[i].defaultlifetime = resources[i].defaultlifetime;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "@Programmatic\n    public <T> Blob toExcelPivot(\n            final List<T> domainObjects,\n            final Class<T> cls,\n            final String fileName) throws ExcelService.Exception {\n        return toExcelPivot(domainObjects, cls, null, fileName);\n    }", "label": 0}
{"code": "def main(argv=None):\n    \"\"\"\n    The entry point of the script.\n    \"\"\"\n    from vsgen import VSGSuite\n    from vsgen import VSGLogger\n\n    # Special case to use the sys.argv when main called without a list.\n    if argv is None:\n        argv = sys.argv\n\n    # Initialize the application logger\n    pylogger = VSGLogger()\n\n    # Construct a command line parser and parse the command line\n    args = VSGSuite.make_parser(description='Executes the vsgen package as an application.').parse_args(argv[1:])\n    for s in VSGSuite.from_args(**vars(args)):\n        s.write(False)\n    return 0", "label": 1}
{"code": "public void ifDoesntHaveMemberTag(String template, Properties attributes) throws XDocletException\r\n    {\r\n        boolean result = false;\r\n\r\n        if (getCurrentField() != null) {\r\n            if (!hasTag(attributes, FOR_FIELD)) {\r\n                result = true;\r\n                generate(template);\r\n            }\r\n        }\r\n        else if (getCurrentMethod() != null) {\r\n            if (!hasTag(attributes, FOR_METHOD)) {\r\n                result = true;\r\n                generate(template);\r\n            }\r\n        }\r\n        if (!result) {\r\n            String error = attributes.getProperty(\"error\");\r\n\r\n            if (error != null) {\r\n                getEngine().print(error);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def parse(data):\n    \"\"\" Parses a raw datagram and return the right type of message \"\"\"\n\n    # convert to string\n    data = data.decode(\"ascii\")\n\n    if len(data) == 2 and data == \"A5\":\n        return AckMessage()\n\n    # split into bytes\n    raw = [data[i:i+2] for i in range(len(data)) if i % 2 == 0]\n\n    if len(raw) != 7:\n        return UnknownMessage(raw)\n\n    if raw[1] == \"B8\":\n        return StateMessage(raw)\n    elif raw[3] == \"12\":\n        return CommandMessage(raw)\n    elif raw[3] == \"14\":\n        return ScenarioTriggeredMessage(raw)\n    elif raw[3] == \"15\":\n        return RequestStatusMessage(raw)\n    else:\n        return UnknownMessage(raw)", "label": 1}
{"code": "def attachment_cache_field(object_name, method, object:, **options)\n      options[:data] ||= {}\n      options[:data][:reference] ||= SecureRandom.hex\n\n      attacher_value = object.send(\"#{method}_data\")\n\n      hidden_options = {\n        multiple: options[:multiple],\n        value: attacher_value.try(:to_json),\n        object: object,\n        disabled: attacher_value.blank?,\n        id: nil,\n        data: { reference: options[:data][:reference] }\n      }\n      hidden_options.merge!(index: options[:index]) if options.key?(:index)\n\n      hidden_field(object_name, method, hidden_options)\n    end", "label": 4}
{"code": "function _getCoefficientsFromMaterials(materials) {\n  // Initialize coefficients to use defaults.\n  let coefficients = {};\n  for (let property in Utils.DEFAULT_ROOM_MATERIALS) {\n    if (Utils.DEFAULT_ROOM_MATERIALS.hasOwnProperty(property)) {\n      coefficients[property] = Utils.ROOM_MATERIAL_COEFFICIENTS[\n        Utils.DEFAULT_ROOM_MATERIALS[property]];\n    }\n  }\n\n  // Sanitize materials.\n  if (materials == undefined) {\n    materials = {};\n    Object.assign(materials, Utils.DEFAULT_ROOM_MATERIALS);\n  }\n\n  // Assign coefficients using provided materials.\n  for (let property in Utils.DEFAULT_ROOM_MATERIALS) {\n    if (Utils.DEFAULT_ROOM_MATERIALS.hasOwnProperty(property) &&\n        materials.hasOwnProperty(property)) {\n      if (materials[property] in Utils.ROOM_MATERIAL_COEFFICIENTS) {\n        coefficients[property] =\n          Utils.ROOM_MATERIAL_COEFFICIENTS[materials[property]];\n      } else {\n        Utils.log('Material \\\"' + materials[property] + '\\\" on wall \\\"' +\n          property + '\\\" not found. Using \\\"' +\n          Utils.DEFAULT_ROOM_MATERIALS[property] + '\\\".');\n      }\n    } else {\n      Utils.log('Wall \\\"' + property + '\\\" is not defined. Default used.');\n    }\n  }\n  return coefficients;\n}", "label": 3}
{"code": "private function getConnectionInternal(CommandInterface $command)\n    {\n        if (!$this->current) {\n            if ($this->strategy->isReadOperation($command) && $slave = $this->pickSlave()) {\n                $this->current = $slave;\n            } else {\n                $this->current = $this->getMaster();\n            }\n\n            return $this->current;\n        }\n\n        if ($this->current === $this->master) {\n            return $this->current;\n        }\n\n        if (!$this->strategy->isReadOperation($command)) {\n            $this->current = $this->getMaster();\n        }\n\n        return $this->current;\n    }", "label": 2}
{"code": "function (newPrototype, memberName, value) {\n            if (typeof value === \"function\") {\n                this._addMethodToPrototype(newPrototype, memberName, value);\n            } else {\n                newPrototype[memberName] = value;\n            }\n        }", "label": 3}
{"code": "def truncate(string, limit = nil, natural_separator = ' ')\n      return string if limit.to_i == 0 # rubocop:disable Lint/NumberConversion\n\n      helpers.truncate(\n        string,\n        length:    limit,\n        separator: natural_separator,\n        omission:  '',\n        escape:    true,\n      )\n    end", "label": 4}
{"code": "func OptionDomainname(name string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.domainName = name\n\t}\n}", "label": 5}
{"code": "def normalize_language_keys(options)\n      (LOCALISED_VERSION_VALUES + LOCALISED_APP_VALUES).each do |key|\n        current = options[key]\n        next unless current && current.kind_of?(Hash)\n\n        current.keys.each do |language|\n          current[language.to_s] = current.delete(language)\n        end\n      end\n\n      options\n    end", "label": 4}
{"code": "def serializable_hash(options = nil)\n      options ||= {}\n      attrs = {}\n\n      names = field_names(options)\n\n      method_names = Array.wrap(options[:methods]).map do |name|\n        name.to_s if respond_to?(name)\n      end.compact\n\n      (names + method_names).each do |name|\n        without_autobuild do\n          serialize_attribute(attrs, name, names, options)\n        end\n      end\n      serialize_relations(attrs, options) if options[:include]\n      attrs\n    end", "label": 4}
{"code": "function reach (curr, next, reachable) {\n  if (!next) return false\n  if (!curr) return true\n\n  const here = reachable[curr]\n  if (!here || !here[next]) return false\n  return here[next].length === 1\n}", "label": 3}
{"code": "public static sslciphersuite[] get(nitro_service service, String ciphername[]) throws Exception{\n\t\tif (ciphername !=null && ciphername.length>0) {\n\t\t\tsslciphersuite response[] = new sslciphersuite[ciphername.length];\n\t\t\tsslciphersuite obj[] = new sslciphersuite[ciphername.length];\n\t\t\tfor (int i=0;i<ciphername.length;i++) {\n\t\t\t\tobj[i] = new sslciphersuite();\n\t\t\t\tobj[i].set_ciphername(ciphername[i]);\n\t\t\t\tresponse[i] = (sslciphersuite) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "func (v *ViewPort) Center(x, y int) {\n\tif x < 0 || y < 0 || x >= v.limx || y >= v.limy || v.v == nil {\n\t\treturn\n\t}\n\tv.viewx = x - (v.width / 2)\n\tv.viewy = y - (v.height / 2)\n\tv.ValidateView()\n}", "label": 5}
{"code": "function createWhere(properties, value, equals)\n{\n  var equality = equals || equalsStrict;\n\n  if ( isFunction( properties ) )\n  {\n    return properties;\n  }\n  else if ( isArray( properties ) )\n  {\n    var parsed = [];\n\n    for (var i = 0; i < properties.length; i++)\n    {\n      var where = properties[ i ];\n\n      parsed.push( isArray( where ) ? createWhere.apply( this, where ) : createWhere( where ) );\n    }\n\n    return function whereMultiple(model)\n    {\n      for (var i = 0; i < parsed.length; i++)\n      {\n        if ( !parsed[ i ]( model ) )\n        {\n          return false;\n        }\n      }\n\n      return true;\n    };\n  }\n  else if ( isObject( properties ) )\n  {\n    var props = [];\n\n    for (var prop in properties)\n    {\n      props.push({\n        tester:   exprEqualsTester( properties[ prop ], equality ),\n        resolver: createPropertyResolver( prop )\n      });\n    }\n\n    return function whereEqualsObject(model)\n    {\n      for (var i = 0; i < props.length; i++)\n      {\n        var prop = props[ i ];\n\n        if ( !prop.tester( prop.resolver( model ) ) )\n        {\n          return false;\n        }\n      }\n\n      return true;\n    };\n  }\n  else if ( isString( properties ) )\n  {\n    if ( properties in Wheres )\n    {\n      return Wheres[ properties ];\n    }\n\n    var resolver = createPropertyResolver( properties );\n\n    if ( isValue( value ) )\n    {\n      var tester = exprEqualsTester( value, equality );\n\n      return function whereEqualsValue(model)\n      {\n        return tester( resolver( model ) );\n      };\n    }\n    else\n    {\n      return function whereHasValue(model)\n      {\n        return isValue( resolver( model ) );\n      };\n    }\n  }\n  else\n  {\n    return function whereAll(model)\n    {\n      return true;\n    };\n  }\n}", "label": 3}
{"code": "def subscribe(channel, last_message_id: nil, &callback)\n      raise InvalidChannel unless channel.to_s.start_with?(\"/\")\n      raise MissingBlock unless block_given?\n\n      last_message_id = -1 if last_message_id && !last_message_id.is_a?(Integer)\n\n      @channels[channel] ||= Channel.new\n      channel = @channels[channel]\n      channel.last_message_id = last_message_id if last_message_id\n      channel.callbacks.push(callback)\n      start if stopped?\n    end", "label": 4}
{"code": "func (t *TextBar) Draw() {\n\n\tt.initialize()\n\tif t.changed {\n\t\tt.layout()\n\t}\n\tw, h := t.view.Size()\n\tfor y := 0; y < h; y++ {\n\t\tfor x := 0; x < w; x++ {\n\t\t\tt.view.SetContent(x, y, ' ', nil, t.style)\n\t\t}\n\t}\n\n\t// Draw in reverse order -- if we clip, we will clip at the\n\t// right side.\n\tt.right.Draw()\n\tt.center.Draw()\n\tt.left.Draw()\n}", "label": 5}
{"code": "func hasPathPrefix(s, prefix string) bool {\n\tswitch {\n\tdefault:\n\t\treturn false\n\tcase len(s) == len(prefix):\n\t\treturn s == prefix\n\tcase len(s) > len(prefix):\n\t\tif prefix != \"\" && prefix[len(prefix)-1] == '/' {\n\t\t\treturn strings.HasPrefix(s, prefix)\n\t\t}\n\t\treturn s[len(prefix)] == '/' && s[:len(prefix)] == prefix\n\t}\n}", "label": 5}
{"code": "def cleanup_string(string, strip: true)\n      return '' if string.nil?\n      raise ArgumentError, 'Expected a string or an object that implements #to_str' unless string.respond_to?(:to_str)\n\n      strip_tags(string.to_str).tap do |s|\n        s.gsub!(/\\s+/, ' ')\n        s.strip! if strip\n      end\n    end", "label": 4}
{"code": "def performAction(self, action):\n        \"\"\" Perform an action on the world that changes it's internal state.\n        \"\"\"\n        gs = [g for g in self.case.online_generators if g.bus.type !=REFERENCE]\n\n        assert len(action) == len(gs)\n\n        logger.info(\"Action: %s\" % list(action))\n\n        # Set the output of each (non-reference) generator.\n        for i, g in enumerate(gs):\n            g.p = action[i]\n\n        # Compute power flows and slack generator set-point.\n        NewtonPF(self.case, verbose=False).solve()\n        #FastDecoupledPF(self.case, verbose=False).solve()\n\n        # Store all generator set-points (only used for plotting).\n        self._Pg[:, self._step] = [g.p for g in self.case.online_generators]\n\n        # Apply the next load profile value to the original demand at each bus.\n        if self._step != len(self.profile) - 1:\n            pq_buses = [b for b in self.case.buses if b.type == PQ]\n            for i, b in enumerate(pq_buses):\n                b.p_demand = self._Pd0[i] * self.profile[self._step + 1]\n\n        self._step += 1\n\n        logger.info(\"Entering step %d.\" % self._step)", "label": 1}
{"code": "function filterAncestor(item) {\n  return item.nodeType === 1 && item.tagName.toLowerCase() !== 'body' && item.tagName.toLowerCase() !== 'html';\n}", "label": 3}
{"code": "def add(self, filename, change=None):\n        \"\"\"Adds a new file to a changelist\n\n        :param filename: File path to add\n        :type filename: str\n        :param change: Changelist to add the file to\n        :type change: int\n        :returns: :class:`.Revision`\n        \"\"\"\n        try:\n            if not self.canAdd(filename):\n                raise errors.RevisionError('File is not under client path')\n\n            if change is None:\n                self.run(['add', filename])\n            else:\n                self.run(['add', '-c', str(change.change), filename])\n\n            data = self.run(['fstat', filename])[0]\n        except errors.CommandError as err:\n            LOGGER.debug(err)\n            raise errors.RevisionError('File is not under client path')\n\n        rev = Revision(data, self)\n\n        if isinstance(change, Changelist):\n            change.append(rev)\n\n        return rev", "label": 1}
{"code": "public function setGroupIndexes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::INT32);\n        $this->group_indexes = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static function getTruthsFromFormula(\n        array $clauses,\n        array &$cond_referenced_var_ids = []\n    ) {\n        $truths = [];\n\n        if (empty($clauses)) {\n            return [];\n        }\n\n        foreach ($clauses as $clause) {\n            if (!$clause->reconcilable) {\n                continue;\n            }\n\n            foreach ($clause->possibilities as $var => $possible_types) {\n                // if there's only one possible type, return it\n                if (count($clause->possibilities) === 1 && count($possible_types) === 1) {\n                    if (isset($truths[$var])) {\n                        $truths[$var][] = [array_pop($possible_types)];\n                    } else {\n                        $truths[$var] = [[array_pop($possible_types)]];\n                    }\n                } elseif (count($clause->possibilities) === 1) {\n                    // if there's only one active clause, return all the non-negation clause members ORed together\n                    $things_that_can_be_said = array_filter(\n                        $possible_types,\n                        /**\n                         * @param  string $possible_type\n                         *\n                         * @return bool\n                         *\n                         * @psalm-suppress MixedOperand\n                         */\n                        function ($possible_type) {\n                            return $possible_type[0] !== '!';\n                        }\n                    );\n\n                    if ($things_that_can_be_said && count($things_that_can_be_said) === count($possible_types)) {\n                        $things_that_can_be_said = array_unique($things_that_can_be_said);\n\n                        if ($clause->generated && count($possible_types) > 1) {\n                            unset($cond_referenced_var_ids[$var]);\n                        }\n\n                        /** @var array<int, string> $things_that_can_be_said */\n                        $truths[$var] = [$things_that_can_be_said];\n                    }\n                }\n            }\n        }\n\n        return $truths;\n    }", "label": 2}
{"code": "func (t *terminal) SetTermType(term string) {\n\tif term == \"\" {\n\t\tterm = defaultTerm\n\t}\n\tt.termType = term\n}", "label": 5}
{"code": "public function walkArithmeticPrimary($primary)\n    {\n        if ($primary instanceof AST\\SimpleArithmeticExpression) {\n            return '(' . $this->walkSimpleArithmeticExpression($primary) . ')';\n        }\n\n        if ($primary instanceof AST\\Node) {\n            return $primary->dispatch($this);\n        }\n\n        return $this->walkEntityIdentificationVariable($primary);\n    }", "label": 2}
{"code": "def instantiate_subclasses(klass)\n      klass.descendants.select { |c| !safe || c.safe }.sort.map do |c|\n        c.new(config)\n      end\n    end", "label": 4}
{"code": "func (i *TeleInstance) StartNodeAndProxy(name string, sshPort, proxyWebPort, proxySSHPort int) error {\n\tdataDir, err := ioutil.TempDir(\"\", \"cluster-\"+i.Secrets.SiteName)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\ttconf := service.MakeDefaultConfig()\n\n\tauthServer := utils.MustParseAddr(net.JoinHostPort(i.Hostname, i.GetPortAuth()))\n\ttconf.AuthServers = append(tconf.AuthServers, *authServer)\n\ttconf.Token = \"token\"\n\ttconf.HostUUID = name\n\ttconf.Hostname = name\n\ttconf.UploadEventsC = i.UploadEventsC\n\ttconf.DataDir = dataDir\n\tvar ttl time.Duration\n\ttconf.CachePolicy = service.CachePolicy{\n\t\tEnabled:   true,\n\t\tRecentTTL: &ttl,\n\t}\n\n\ttconf.Auth.Enabled = false\n\n\ttconf.Proxy.Enabled = true\n\ttconf.Proxy.SSHAddr.Addr = net.JoinHostPort(i.Hostname, fmt.Sprintf(\"%v\", proxySSHPort))\n\ttconf.Proxy.WebAddr.Addr = net.JoinHostPort(i.Hostname, fmt.Sprintf(\"%v\", proxyWebPort))\n\ttconf.Proxy.DisableReverseTunnel = true\n\ttconf.Proxy.DisableWebService = true\n\n\ttconf.SSH.Enabled = true\n\ttconf.SSH.Addr.Addr = net.JoinHostPort(i.Hostname, fmt.Sprintf(\"%v\", sshPort))\n\ttconf.SSH.PublicAddrs = []utils.NetAddr{\n\t\tutils.NetAddr{\n\t\t\tAddrNetwork: \"tcp\",\n\t\t\tAddr:        Loopback,\n\t\t},\n\t\tutils.NetAddr{\n\t\t\tAddrNetwork: \"tcp\",\n\t\t\tAddr:        Host,\n\t\t},\n\t}\n\n\t// Create a new Teleport process and add it to the list of nodes that\n\t// compose this \"cluster\".\n\tprocess, err := service.NewTeleport(tconf)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\ti.Nodes = append(i.Nodes, process)\n\n\t// Build a list of expected events to wait for before unblocking based off\n\t// the configuration passed in.\n\texpectedEvents := []string{\n\t\tservice.ProxySSHReady,\n\t\tservice.NodeSSHReady,\n\t}\n\n\t// Start the process and block until the expected events have arrived.\n\treceivedEvents, err := startAndWait(process, expectedEvents)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tlog.Debugf(\"Teleport node and proxy (in instance %v) started: %v/%v events received.\",\n\t\ti.Secrets.SiteName, len(expectedEvents), len(receivedEvents))\n\treturn nil\n}", "label": 5}
{"code": "func (r *router) MethodsFor(path string) []string {\n\tmethods := []string{}\n\tfor _, route := range r.getRoutes() {\n\t\tmatches := route.regex.FindStringSubmatch(path)\n\t\tif len(matches) > 0 && matches[0] == path && !hasMethod(methods, route.method) {\n\t\t\tmethods = append(methods, route.method)\n\t\t}\n\t}\n\treturn methods\n}", "label": 5}
{"code": "def _copy(self):\n        \"\"\"\n        Called during a PUT request where the action specifies\n        a copy operation. Returns resource URI of the new file.\n        \"\"\"\n        copypath = self.action['copypath']\n        try:\n            self.fs.copy(self.fp,copypath)\n        except OSError:\n            raise tornado.web.HTTPError(400)\n        return copypath", "label": 1}
{"code": "def delete(self, id, attid): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Delete a device's attachment.\n\n        :param id: Device ID as an int.\n        :param attid: Attachment ID as an int.\n        \"\"\"\n        return self.service.edit(self._base(id), attid)", "label": 1}
{"code": "function(gameId, relayServer, options) {\n  options = options || {};\n  this.options = options;\n  this.gameId = gameId;\n  this.relayServer = relayServer;\n  this.games = [];  // first game is the \"master\"\n  this.nextGameId = 0;  // start at 0 because it's easy to switch games with (gameNum + numGames + dir) % numGames\n}", "label": 3}
{"code": "private function getComponentManifest($manifestPath, $componentId)\n    {\n        $manifest = $this->getManifest($manifestPath);\n        $index = $this->getManifestComponentModuleIndex($manifest, $componentId);\n\n        return $manifest['modules'][$index];\n    }", "label": 2}
{"code": "def dynamic_info(self):\n\t\t\"Return a map that for a given year will return the correct Info\"\n\t\tif self.key_name:\n\t\t\tdyn_key = self.get_key().subkey('Dynamic DST')\n\t\t\tdel dyn_key['FirstEntry']\n\t\t\tdel dyn_key['LastEntry']\n\t\t\tyears = map(int, dyn_key.keys())\n\t\t\tvalues = map(Info, dyn_key.values())\n\t\t\t# create a range mapping that searches by descending year and matches\n\t\t\t# if the target year is greater or equal.\n\t\t\treturn RangeMap(zip(years, values), RangeMap.descending, operator.ge)\n\t\telse:\n\t\t\treturn AnyDict(self)", "label": 1}
{"code": "function off(property, callback){\n    listeners[property] = listeners[property].filter(function (listener) {\n      return listener !== callback;\n    });\n  }", "label": 3}
{"code": "function trimNumericField(input) {\n\t\twhile (input.length > 1 && input.charAt(0) === '0') {\n\t\t\tinput = input.substring(1);\n\t\t}\n\n\t\treturn input;\n\t}", "label": 3}
{"code": "public static gslbsite_stats[] get(nitro_service service, options option) throws Exception{\n\t\tgslbsite_stats obj = new gslbsite_stats();\n\t\tgslbsite_stats[] response = (gslbsite_stats[])obj.stat_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def scan_for_lints(options)\n      reporter = reporter_from_options(options)\n      report = Runner.new.run(options.merge(reporter: reporter))\n      report.display\n      report.failed? ? Sysexits::EX_DATAERR : Sysexits::EX_OK\n    end", "label": 4}
{"code": "func (ss StringSlice) Value() (driver.Value, error) {\n\tv := make([]string, len(ss))\n\tfor i, s := range ss {\n\t\tv[i] = `\"` + strings.Replace(strings.Replace(s, `\\`, `\\\\\\`, -1), `\"`, `\\\"`, -1) + `\"`\n\t}\n\treturn \"{\" + strings.Join(v, \",\") + \"}\", nil\n}", "label": 5}
{"code": "func (tl TypeLoader) LoadEnumValues(args *ArgType, enumTpl *Enum) error {\n\tvar err error\n\n\t// load enum values\n\tenumValues, err := tl.EnumValueList(args.DB, args.Schema, enumTpl.Enum.EnumName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// process enum values\n\tfor _, ev := range enumValues {\n\t\t// chop off redundant enum name if applicable\n\t\tname := snaker.SnakeToCamelIdentifier(ev.EnumValue)\n\t\tif strings.HasSuffix(strings.ToLower(name), strings.ToLower(enumTpl.Name)) {\n\t\t\tn := name[:len(name)-len(enumTpl.Name)]\n\t\t\tif len(n) > 0 {\n\t\t\t\tname = n\n\t\t\t}\n\t\t}\n\n\t\tenumTpl.Values = append(enumTpl.Values, &EnumValue{\n\t\t\tName: name,\n\t\t\tVal:  ev,\n\t\t})\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func GetLogs(bee string) []LogMessage {\n\tr := []LogMessage{}\n\n\tlogMutex.RLock()\n\tfor b, ls := range logs {\n\t\tif len(bee) == 0 || bee == b {\n\t\t\tfor _, l := range ls {\n\t\t\t\tr = append(r, l)\n\t\t\t}\n\t\t}\n\t}\n\tlogMutex.RUnlock()\n\n\tsort.Sort(LogSorter(r))\n\treturn r\n}", "label": 5}
{"code": "def convert_to_e164(phone, data)\n      match = phone.match full_regex_for_data(data, Core::VALID_PATTERN, !original_starts_with_plus?)\n      case\n      when match\n        \"#{data[Core::COUNTRY_CODE]}#{match.to_a.last}\"\n      when phone.match(cr(\"^#{data[Core::INTERNATIONAL_PREFIX]}\"))\n        phone.sub(cr(\"^#{data[Core::INTERNATIONAL_PREFIX]}\"), Core::PLUS_SIGN)\n      when original_starts_with_plus? && phone.start_with?(data[Core::COUNTRY_CODE])\n        phone\n      else\n        \"#{data[Core::COUNTRY_CODE]}#{phone}\"\n      end\n    end", "label": 4}
{"code": "private function buildNestedParams($nestedParams, $origParam, $isProto = false)\n    {\n        $paramsArray = [];\n\n        foreach ($nestedParams as $param) {\n            $nestedParam = explode(' ', trim($param), 3);\n\n            // START proto nested arg missing description workaround\n            if (count($nestedParam) < 3 && !$isProto) {\n                throw new \\Exception('nested param is in an invalid format: '. $param);\n            }\n            // END proto nested arg missing description workaround\n\n            list($type, $name, $description) = $nestedParam;\n            $name = substr($name, 1);\n            $description = preg_replace('/\\s+/', ' ', $description);\n\n            $types = new Collection(\n                array($type),\n                $origParam->getDocBlock() ? $origParam->getDocBlock()->getContext() : null\n            );\n\n            $paramsArray[] = [\n                'name' => substr($origParam->getVariableName(), 1) . '.' . $name,\n                'description' => $this->buildDescription($origParam->getDocBlock(), $description, $origParam),\n                'types' => $this->handleTypes($types),\n                'optional' => null, // @todo\n                'nullable' => null //@todo\n            ];\n        }\n\n        return $paramsArray;\n    }", "label": 2}
{"code": "function _filter (node, expr, resultSet) {\n        var\n            selectedNodes,\n            conditions,\n            type,\n            idx,\n            condition;\n        if (expr.and) {\n            conditions = expr.and;\n            type = 0;\n        } else if (expr.or) {\n            conditions = expr.or;\n            type = 1;\n        }\n        for (idx = 0; idx < conditions.length; ++idx) {\n            condition = conditions[idx];\n            if (condition.and || condition.or) {\n                selectedNodes = [];\n                _filter(node, condition, selectedNodes);\n            } else {\n                selectedNodes = _select(node, condition);\n            }\n            if (0 === type && selectedNodes.length === 0) {\n                return;\n            }\n            if (1 === type && selectedNodes.length !== 0) {\n                resultSet.push(node);\n                return;\n            }\n        }\n        if (0 === type) {\n            resultSet.push(node);\n        }\n    }", "label": 3}
{"code": "def tinymce(config=:default, options={})\n      javascript_tag(nonce: true) do\n        unless @_tinymce_configurations_added\n          concat tinymce_configurations_javascript\n          concat \"\\n\"\n          @_tinymce_configurations_added = true\n        end\n\n        concat tinymce_javascript(config, options)\n      end\n    end", "label": 4}
{"code": "function (config, mockSrc) {\n    var dataWithContext = readMockManifest(config, mockSrc);\n\n    // log('readScenarioData config', config);\n    if (config.plugins) {\n      dataWithContext = runPlugins(dataWithContext, config.plugins);\n    }\n\n    return removeContext(dataWithContext);\n  }", "label": 3}
{"code": "public SerialMessage getValueMessage() {\r\n\t\tlogger.debug(\"Creating new message for application command BASIC_GET for node {}\", this.getNode().getNodeId());\r\n\t\tSerialMessage result = new SerialMessage(this.getNode().getNodeId(), SerialMessageClass.SendData, SerialMessageType.Request, SerialMessageClass.ApplicationCommandHandler, SerialMessagePriority.Get);\r\n    \tbyte[] newPayload = { \t(byte) this.getNode().getNodeId(), \r\n    \t\t\t\t\t\t\t2, \r\n\t\t\t\t\t\t\t\t(byte) getCommandClass().getKey(), \r\n\t\t\t\t\t\t\t\t(byte) BASIC_GET };\r\n    \tresult.setMessagePayload(newPayload);\r\n    \treturn result;\t\t\r\n\t}", "label": 0}
{"code": "func CreateUserAndRoleWithoutRoles(clt clt, username string, allowedLogins []string) (services.User, services.Role, error) {\n\tuser, err := services.NewUser(username)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\trole := services.RoleForUser(user)\n\tset := services.MakeRuleSet(role.GetRules(services.Allow))\n\tdelete(set, services.KindRole)\n\trole.SetRules(services.Allow, set.Slice())\n\trole.SetLogins(services.Allow, []string{user.GetName()})\n\terr = clt.UpsertRole(role)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\tuser.AddRole(role.GetName())\n\terr = clt.UpsertUser(user)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\treturn user, role, nil\n}", "label": 5}
{"code": "public static <E> Map<E, Double> asMap(final Counter<E> counter) {\r\n    return new AbstractMap<E, Double>() {\r\n      @Override\r\n      public int size() {\r\n        return counter.size();\r\n      }\r\n\r\n      @Override\r\n      public Set<Entry<E, Double>> entrySet() {\r\n        return counter.entrySet();\r\n      }\r\n\r\n      @Override\r\n      @SuppressWarnings(\"unchecked\")\r\n      public boolean containsKey(Object key) {\r\n        return counter.containsKey((E) key);\r\n      }\r\n\r\n      @Override\r\n      @SuppressWarnings(\"unchecked\")\r\n      public Double get(Object key) {\r\n        return counter.getCount((E) key);\r\n      }\r\n\r\n      @Override\r\n      public Double put(E key, Double value) {\r\n        double last = counter.getCount(key);\r\n        counter.setCount(key, value);\r\n        return last;\r\n      }\r\n\r\n      @Override\r\n      @SuppressWarnings(\"unchecked\")\r\n      public Double remove(Object key) {\r\n        return counter.remove((E) key);\r\n      }\r\n\r\n      @Override\r\n      public Set<E> keySet() {\r\n        return counter.keySet();\r\n      }\r\n    };\r\n  }", "label": 0}
{"code": "public float conditionalLogProb(int[] given, int of) {\r\n    if (given.length != windowSize - 1) {\r\n      System.err.println(\"error computing conditional log prob\");\r\n      System.exit(0);\r\n    }\r\n    int[] label = indicesFront(given);\r\n    float[] masses = new float[label.length];\r\n    for (int i = 0; i < masses.length; i++) {\r\n      masses[i] = table[label[i]];\r\n    }\r\n    float z = ArrayMath.logSum(masses);\r\n\r\n    return table[indexOf(given, of)] - z;\r\n  }", "label": 0}
{"code": "def _get(self, ip):\n        \"\"\"\n        Get information about an IP.\n\n        Args:\n            ip (str): an IP (xxx.xxx.xxx.xxx).\n\n        Returns:\n            dict: see http://ipinfo.io/developers/getting-started\n        \"\"\"\n        # Geoloc updated up to once a week:\n        # http://ipinfo.io/developers/data#geolocation-data\n        retries = 10\n        for retry in range(retries):\n            try:\n                response = requests.get('http://ipinfo.io/%s/json' % ip,\n                                        verify=False, timeout=1)  # nosec\n                if response.status_code == 429:\n                    raise RateExceededError\n                return response.json()\n            except (requests.ReadTimeout, requests.ConnectTimeout):\n                pass\n        return {}", "label": 1}
{"code": "def check_for_libraries\n      output = []\n\n      required_libraries.each do |library|\n        begin\n          require library\n        rescue LoadError\n          install_command = @config['install_command']\n          install_command = \" -- install via #{install_command}\" if install_command\n\n          output << \"Unable to load '#{library}'#{install_command}\"\n        end\n      end\n\n      return if output.empty?\n\n      output.join(\"\\n\")\n    end", "label": 4}
{"code": "def DEFAULT_NULLVALUE(test):\n    \"\"\"\n    Returns a null value for each of various kinds of test values.\n\n    **Parameters**\n\n            **test** :  bool, int, float or string\n\n                    Value to test.\n\n\n    **Returns**\n            **null** :  element in `[False, 0, 0.0, '']`\n\n                    Null value corresponding to the given test value:\n\n                    *   if `test` is a `bool`, return `False`\n                    *   else if `test` is an `int`, return `0`\n                    *   else if `test` is a `float`, return `0.0`\n                    *   else `test` is a `str`, return `''`\n\n    \"\"\"\n    return False if isinstance(test,bool) \\\n           else 0 if isinstance(test,int) \\\n           else 0.0 if isinstance(test,float) \\\n           else ''", "label": 1}
{"code": "public function read($length)\n    {\n        $data = '';\n        do {\n            $moreData = $this->stream->read($length);\n            $data .= $moreData;\n            $readLength = strlen($moreData);\n            $length -= $readLength;\n        } while ($length > 0 && $readLength > 0);\n\n        return $data;\n    }", "label": 2}
{"code": "public function getRoutes($version = null)\n    {\n        if (! is_null($version)) {\n            return $this->routes[$version];\n        }\n\n        return $this->routes;\n    }", "label": 2}
{"code": "public function checkAndMutateRow($rowKey, array $options = [])\n    {\n        $hasSetMutations = false;\n\n        if (isset($options['predicateFilter'])) {\n            $this->convertToProto($options, 'predicateFilter', FilterInterface::class);\n        }\n        if (isset($options['trueMutations'])) {\n            $this->convertToProto($options, 'trueMutations', Mutations::class);\n            $hasSetMutations = true;\n        }\n        if (isset($options['falseMutations'])) {\n            $this->convertToProto($options, 'falseMutations', Mutations::class);\n            $hasSetMutations = true;\n        }\n        if (!$hasSetMutations) {\n            throw new \\InvalidArgumentException('checkAndMutateRow must have either trueMutations or falseMutations.');\n        }\n\n        return $this->gapicClient\n            ->checkAndMutateRow(\n                $this->tableName,\n                $rowKey,\n                $options + $this->options\n            )\n            ->getPredicateMatched();\n    }", "label": 2}
{"code": "def binary_encrypt(str, random_iv: SymmetricEncryption.randomize_iv?, compress: false, header: always_add_header)\n      return if str.nil?\n\n      string = str.to_s\n      return string if string.empty?\n\n      # Header required when adding a random_iv or compressing\n      header = Header.new(version: version, compress: compress) if header || random_iv || compress\n\n      # Creates a new OpenSSL::Cipher with every call so that this call is thread-safe.\n      openssl_cipher = ::OpenSSL::Cipher.new(cipher_name)\n      openssl_cipher.encrypt\n      openssl_cipher.key = @key\n\n      result =\n        if header\n          if random_iv\n            openssl_cipher.iv = header.iv = openssl_cipher.random_iv\n          elsif iv\n            openssl_cipher.iv = iv\n          end\n          header.to_s + openssl_cipher.update(compress ? Zlib::Deflate.deflate(string) : string)\n        else\n          openssl_cipher.iv = iv if iv\n          openssl_cipher.update(string)\n        end\n      result << openssl_cipher.final\n    end", "label": 4}
{"code": "def assign(members:, topics:)\n      group_assignment = {}\n\n      members.each do |member_id|\n        group_assignment[member_id] = Protocol::MemberAssignment.new\n      end\n\n      topic_partitions = topics.flat_map do |topic|\n        begin\n          partitions = @cluster.partitions_for(topic).map(&:partition_id)\n        rescue UnknownTopicOrPartition\n          raise UnknownTopicOrPartition, \"unknown topic #{topic}\"\n        end\n        Array.new(partitions.count) { topic }.zip(partitions)\n      end\n\n      partitions_per_member = topic_partitions.group_by.with_index do |_, index|\n        index % members.count\n      end.values\n\n      members.zip(partitions_per_member).each do |member_id, member_partitions|\n        unless member_partitions.nil?\n          member_partitions.each do |topic, partition|\n            group_assignment[member_id].assign(topic, [partition])\n          end\n        end\n      end\n\n      group_assignment\n    rescue Kafka::LeaderNotAvailable\n      sleep 1\n      retry\n    end", "label": 4}
{"code": "def addrecords(self, new):\n        \"\"\"\n        Append one or more records to the end of the array.\n\n        Method wraps::\n\n                tabular.spreadsheet.addrecords(self, new)\n\n        \"\"\"\n        data = spreadsheet.addrecords(self,new)\n        data = data.view(tabarray)\n        data.coloring = self.coloring\n        return data", "label": 1}
{"code": "func (s Style) Blink(on bool) Style {\n\treturn s.setAttrs(Style(AttrBlink), on)\n}", "label": 5}
{"code": "def load_member(fqn):\n    \"\"\"Loads and returns a class for a given fully qualified name.\"\"\"\n    modulename, member_name = split_fqn(fqn)\n    module = __import__(modulename, globals(), locals(), member_name)\n    return getattr(module, member_name)", "label": 1}
{"code": "def is_active(self, name):\n        \"\"\"\n        Returns True if plugin exists and is active.\n        If plugin does not exist, it returns None\n\n        :param name: plugin name\n        :return: boolean or None\n        \"\"\"\n        if name in self._plugins.keys():\n            return self._plugins[\"name\"].active\n        return None", "label": 1}
{"code": "def origin=(new_origin)\n      if new_origin\n        if !new_origin.respond_to?(:to_str)\n          raise TypeError, \"Can't convert #{new_origin.class} into String.\"\n        end\n        new_origin = new_origin.to_str\n        new_scheme = new_origin[/^([^:\\/?#]+):\\/\\//, 1]\n        unless new_scheme\n          raise InvalidURIError, 'An origin cannot omit the scheme.'\n        end\n        new_host = new_origin[/:\\/\\/([^\\/?#:]+)/, 1]\n        unless new_host\n          raise InvalidURIError, 'An origin cannot omit the host.'\n        end\n        new_port = new_origin[/:([^:@\\[\\]\\/]*?)$/, 1]\n      end\n\n      self.scheme = defined?(new_scheme) ? new_scheme : nil\n      self.host = defined?(new_host) ? new_host : nil\n      self.port = defined?(new_port) ? new_port : nil\n      self.userinfo = nil\n\n      # Reset dependent values\n      remove_instance_variable(:@userinfo) if defined?(@userinfo)\n      remove_instance_variable(:@normalized_userinfo) if defined?(@normalized_userinfo)\n      remove_instance_variable(:@authority) if defined?(@authority)\n      remove_instance_variable(:@normalized_authority) if defined?(@normalized_authority)\n      remove_composite_values\n\n      # Ensure we haven't created an invalid URI\n      validate()\n    end", "label": 4}
{"code": "public function columnName($i)\n    {\n        $column = $this->request->input(\"columns.$i\");\n\n        return isset($column['name']) && $column['name'] != '' ? $column['name'] : $column['data'];\n    }", "label": 2}
{"code": "public static AccessorPrefix determineAccessorPrefix(@Nonnull final String methodName) {\n\t\tCheck.notEmpty(methodName, \"methodName\");\n\t\tfinal Matcher m = PATTERN.matcher(methodName);\n\t\tCheck.stateIsTrue(m.find(), \"passed method name '%s' is not applicable\", methodName);\n\t\treturn new AccessorPrefix(m.group(1));\n\t}", "label": 0}
{"code": "public static base_response disable(nitro_service client) throws Exception {\n\t\treporting disableresource = new reporting();\n\t\treturn disableresource.perform_operation(client,\"disable\");\n\t}", "label": 0}
{"code": "def format(format, page = 0, read_opts={})\n      if @tempfile\n        new_tempfile = MiniMagick::Utilities.tempfile(\".#{format}\")\n        new_path = new_tempfile.path\n      else\n        new_path = Pathname(path).sub_ext(\".#{format}\").to_s\n      end\n\n      input_path = path.dup\n      input_path << \"[#{page}]\" if page && !layer?\n\n      MiniMagick::Tool::Convert.new do |convert|\n        read_opts.each do |opt, val|\n          convert.send(opt.to_s, val)\n        end\n        convert << input_path\n        yield convert if block_given?\n        convert << new_path\n      end\n\n      if @tempfile\n        destroy!\n        @tempfile = new_tempfile\n      else\n        File.delete(path) unless path == new_path || layer?\n      end\n\n      path.replace new_path\n      @info.clear\n\n      self\n    end", "label": 4}
{"code": "def is_union(etype) -> bool:\n    \"\"\" Determine whether etype is a Union \"\"\"\n    return getattr(etype, '__origin__', None) is not None and \\\n           getattr(etype.__origin__, '_name', None) and\\\n           etype.__origin__._name == 'Union'", "label": 1}
{"code": "public static service_stats[] get(nitro_service service) throws Exception{\n\t\tservice_stats obj = new service_stats();\n\t\tservice_stats[] response = (service_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def databasesKEGG(organism,ens_ids):\n    \"\"\"\n    Finds KEGG database identifiers for a respective organism given example ensembl ids.\n\n\n    :param organism: an organism as listed in organismsKEGG()\n    :param ens_ids: a list of ensenbl ids of the respective organism\n\n    :returns: nothing if no database was found, or a string if a database was found\n\n    \"\"\"\n    all_genes=urlopen(\"http://rest.kegg.jp/list/\"+organism).read()\n    all_genes=all_genes.split(\"\\n\")\n    dbs=[]\n    while len(dbs) == 0:\n        for g in all_genes:\n            if len(dbs) == 0:\n                kid = g.split(\"\\t\")[0]\n                gene=urlopen(\"http://rest.kegg.jp/get/\"+kid).read()\n                DBLINKS=gene.split(\"\\n\")\n                DBLINKS=[ s for s in DBLINKS if \":\" in s ]\n                for d in DBLINKS:\n                    test=d.split(\" \")\n                    test=test[len(test)-1]\n                    if test in ens_ids:\n                        DBLINK=[ s for s in DBLINKS if test in s ]\n                        DBLINK=DBLINK[0].split(\":\")\n                        DBLINK=DBLINK[len(DBLINK)-2]\n                        dbs.append(DBLINK)\n            else:\n                break\n    ens_db=dbs[0].split(\" \")\n    ens_db=ens_db[len(ens_db)-1]\n    test_db=urlopen(\"http://rest.genome.jp/link/\"+ens_db+\"/\"+organism).read()\n    test_db=test_db.split(\"\\n\")\n    if len(test_db) == 1:\n        print(\"For \"+organism+\" the following db was found: \"+ens_db)\n        print(\"This database does not seem to be valid KEGG-linked database identifier\")\n        print(\"For \\n'hsa' use 'ensembl-hsa'\\n'mmu' use 'ensembl-mmu'\\n'cel' use 'EnsemblGenomes-Gn'\\n'dme' use 'FlyBase'\")\n        sys.stdout.flush()\n        ens_db = None\n    else:\n        print(\"For \"+organism+\" the following db was found: \"+ens_db)\n        sys.stdout.flush()\n    return ens_db", "label": 1}
{"code": "func (f *dockerFetcher) Hash(u *url.URL) (string, error) {\n\tensureLogger(f.Debug)\n\tdockerURL, err := d2acommon.ParseDockerURL(path.Join(u.Host, u.Path))\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(`invalid docker URL %q; expected syntax is \"docker://[REGISTRY_HOST[:REGISTRY_PORT]/]IMAGE_NAME[:TAG]\"`, u)\n\t}\n\tlatest := dockerURL.Tag == \"latest\"\n\treturn f.fetchImageFrom(u, latest)\n}", "label": 5}
{"code": "function (pattern) {\n            var\n                parser = new PatternParser();\n            parser.parse(pattern, null);\n            this._patternItem = parser.patternItem();\n        }", "label": 3}
{"code": "function expand_comment(docset) {\n  groups = {\n    \"class\": [],\n    \"cfg\": [],\n    \"Constructor\": []\n  }\n\n  // By default everything goes to :class group\n  var group_name = \"class\";\n\n  _.each(docset[\"comment\"], function (tag) {\n    tagname = tag[\"tagname\"];\n\n    if (tagname == \"cfg\" || tagname == \"Constructor\") {\n      group_name = tagname;\n      if (tagname == \"cfg\")\n        groups[\"cfg\"].push([]);\n    }\n\n    if (tagname == \"alias\")\n      groups[\"class\"].push(tag);  // For backwards compatibility allow @xtype after @constructor\n    else if (group_name == \"cfg\")\n      _.last(groups[\"cfg\"]).push(tag);\n    else\n      groups[group_name].push(tag);\n  });\n\n  return groups_to_docsets(groups, docset);\n}", "label": 3}
{"code": "public static dnspolicylabel[] get(nitro_service service) throws Exception{\n\t\tdnspolicylabel obj = new dnspolicylabel();\n\t\tdnspolicylabel[] response = (dnspolicylabel[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function getCommandClass($commandID)\n    {\n        if (isset($this->commands[$commandID = strtoupper($commandID)])) {\n            return $this->commands[$commandID];\n        }\n    }", "label": 2}
{"code": "func (s *AuthServer) AuthenticateSSHUser(req AuthenticateSSHRequest) (*SSHLoginResponse, error) {\n\tclusterName, err := s.GetClusterName()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tif err := s.AuthenticateUser(req.AuthenticateUserRequest); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tuser, err := s.GetUser(req.Username)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\troles, err := services.FetchRoles(user.GetRoles(), s, user.GetTraits())\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Return the host CA for this cluster only.\n\tauthority, err := s.GetCertAuthority(services.CertAuthID{\n\t\tType:       services.HostCA,\n\t\tDomainName: clusterName.GetClusterName(),\n\t}, false)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\thostCertAuthorities := []services.CertAuthority{\n\t\tauthority,\n\t}\n\n\tcerts, err := s.generateUserCert(certRequest{\n\t\tuser:          user,\n\t\troles:         roles,\n\t\tttl:           req.TTL,\n\t\tpublicKey:     req.PublicKey,\n\t\tcompatibility: req.CompatibilityMode,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &SSHLoginResponse{\n\t\tUsername:    req.Username,\n\t\tCert:        certs.ssh,\n\t\tTLSCert:     certs.tls,\n\t\tHostSigners: AuthoritiesToTrustedCerts(hostCertAuthorities),\n\t}, nil\n}", "label": 5}
{"code": "public function appendException()\n    {\n        foreach (func_get_args() as $value) {\n            if ($value instanceof \\Exception || $value instanceof \\Throwable) {\n                $this->queue[] = $value;\n            } else {\n                throw new \\InvalidArgumentException('Expected an \\Exception or \\Throwable.');\n            }\n        }\n    }", "label": 2}
{"code": "def _load(self):\n        \"\"\"Load values for all ConfigProperty attributes\"\"\"\n        for attr_name, config_prop in self._iter_config_props():\n            found = False\n            for loader in self._loaders:\n                if loader.exists(config_prop.property_key):\n                    raw_value = loader.get(config_prop.property_key)\n                    converted_value = config_prop.load(raw_value)\n\n                    self._set_instance_prop(attr_name, config_prop, converted_value)\n                    found = True\n                    break\n\n            if not found:\n                if not config_prop.required or config_prop.default is not None:\n                    self._set_instance_prop(attr_name, config_prop, config_prop.default)\n                else:\n                    raise ValueError('Missing required ConfigProperty {}'.format(attr_name))", "label": 1}
{"code": "def si_parse(value):\n    '''\n    Parse a value expressed using SI prefix units to a floating point number.\n\n    Parameters\n    ----------\n    value : str or unicode\n        Value expressed using SI prefix units (as returned by :func:`si_format`\n        function).\n\n\n    .. versionchanged:: 1.0\n        Use unicode string for SI unit to support micro (i.e., \u00b5) character.\n\n        .. seealso::\n\n            `Issue #4`_.\n\n    .. _`Issue #4`: https://github.com/cfobel/si-prefix/issues/4\n    '''\n    CRE_10E_NUMBER = re.compile(r'^\\s*(?P<integer>[\\+\\-]?\\d+)?'\n                                r'(?P<fraction>.\\d+)?\\s*([eE]\\s*'\n                                r'(?P<expof10>[\\+\\-]?\\d+))?$')\n    CRE_SI_NUMBER = re.compile(r'^\\s*(?P<number>(?P<integer>[\\+\\-]?\\d+)?'\n                               r'(?P<fraction>.\\d+)?)\\s*'\n                               u'(?P<si_unit>[%s])?\\s*$' % SI_PREFIX_UNITS)\n    match = CRE_10E_NUMBER.match(value)\n    if match:\n        # Can be parse using `float`.\n        assert(match.group('integer') is not None or\n               match.group('fraction') is not None)\n        return float(value)\n    match = CRE_SI_NUMBER.match(value)\n    assert(match.group('integer') is not None or\n           match.group('fraction') is not None)\n    d = match.groupdict()\n    si_unit = d['si_unit'] if d['si_unit'] else ' '\n    prefix_levels = (len(SI_PREFIX_UNITS) - 1) // 2\n    scale = 10 ** (3 * (SI_PREFIX_UNITS.index(si_unit) - prefix_levels))\n    return float(d['number']) * scale", "label": 1}
{"code": "def summarise_file_as_html(fname):\n    \"\"\" \n    takes a large data file and produces a HTML summary as html\n    \"\"\"\n    txt = '<H1>' + fname + '</H1>'\n    num_lines = 0\n    print('Reading OpenCyc file - ', fname)\n    with open(ip_folder + os.sep + fname, 'r') as f:\n        txt += '<PRE>'\n        for line in f: \n            if line.strip() != '':\n                num_lines += 1\n                if num_lines < 80:\n                    txt += str(num_lines) + ': ' + escape_html(line) + ''\n        txt += '</PRE>'\n        txt += 'Total lines = ' + str(num_lines) + '<BR><BR>'\n    \n    return txt", "label": 1}
{"code": "def convert(value, from_unit, to_unit):\n    \"\"\"\n    Converts a value from `from_unit` units to `to_unit` units\n\n    :param value: value to convert\n    :type value: int or str or decimal.Decimal\n\n    :param from_unit: unit to convert from\n    :type from_unit: str\n\n    :param to_unit: unit to convert to\n    :type to_unit: str\n\n    >>> convert(value='1.5', from_unit='xrb', to_unit='krai')\n    Decimal('0.0015')\n    \"\"\"\n\n    if isinstance(value, float):\n        raise ValueError(\n            \"float values can lead to unexpected precision loss, please use a\"\n            \" Decimal or string eg.\"\n            \" convert('%s', %r, %r)\" % (value, from_unit, to_unit)\n        )\n\n    if from_unit not in UNITS_TO_RAW:\n        raise ValueError('unknown unit: %r' % from_unit)\n\n    if to_unit not in UNITS_TO_RAW:\n        raise ValueError('unknown unit: %r' % to_unit)\n\n    try:\n        value = Decimal(value)\n    except Exception:\n        raise ValueError('not a number: %r' % value)\n\n    from_value_in_base = UNITS_TO_RAW[from_unit]\n    to_value_in_base = UNITS_TO_RAW[to_unit]\n\n    result = value * (from_value_in_base / to_value_in_base)\n\n    return result.normalize()", "label": 1}
{"code": "public function setGqlQuery($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Datastore\\V1\\GqlQuery::class);\n        $this->writeOneof(7, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (r *AddressRange) String() string {\n\treturn fmt.Sprintf(\"Sub: %s, range [%d, %d]\", r.Sub, r.Start, r.End)\n}", "label": 5}
{"code": "func LoadPodManifest(root string) (*schema.PodManifest, error) {\n\tbuf, err := ioutil.ReadFile(common.PodManifestPath(root))\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"failed reading pod manifest\"), err)\n\t}\n\n\tpm := &schema.PodManifest{}\n\tif err := json.Unmarshal(buf, pm); err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"failed unmarshalling pod manifest\"), err)\n\t}\n\treturn pm, nil\n}", "label": 5}
{"code": "func NewDetachedSignature(armoredPrivateKey string, aci io.Reader) (io.Reader, error) {\n\tentityList, err := openpgp.ReadArmoredKeyRing(bytes.NewBufferString(armoredPrivateKey))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(entityList) < 1 {\n\t\treturn nil, errors.New(\"empty entity list\")\n\t}\n\tsignature := &bytes.Buffer{}\n\tif err := openpgp.ArmoredDetachSign(signature, entityList[0], aci, nil); err != nil {\n\t\treturn nil, err\n\t}\n\treturn signature, nil\n}", "label": 5}
{"code": "def output_solution(self, fd, z, z_est, error_sqrsum):\n        \"\"\" Prints comparison of measurements and their estimations.\n        \"\"\"\n        col_width = 11\n        sep = (\"=\" * col_width + \" \") * 4 + \"\\n\"\n\n        fd.write(\"State Estimation\\n\")\n        fd.write(\"-\" * 16 + \"\\n\")\n        fd.write(sep)\n        fd.write(\"Type\".center(col_width) + \" \")\n        fd.write(\"Name\".center(col_width) + \" \")\n        fd.write(\"Measurement\".center(col_width) + \" \")\n        fd.write(\"Estimation\".center(col_width) + \" \")\n        fd.write(\"\\n\")\n        fd.write(sep)\n\n        c = 0\n        for t in [PF, PT, QF, QT, PG, QG, VM, VA]:\n            for meas in self.measurements:\n                if meas.type == t:\n                    n = meas.b_or_l.name[:col_width].ljust(col_width)\n                    fd.write(t.ljust(col_width) + \" \")\n                    fd.write(n + \" \")\n                    fd.write(\"%11.5f \" % z[c])\n                    fd.write(\"%11.5f\\n\" % z_est[c])\n#                    fd.write(\"%s\\t%s\\t%.3f\\t%.3f\\n\" % (t, n, z[c], z_est[c]))\n                    c += 1\n\n        fd.write(\"\\nWeighted sum of error squares = %.4f\\n\" % error_sqrsum)", "label": 1}
{"code": "public SerialMessage getMultiChannelCapabilityGetMessage(ZWaveEndpoint endpoint) {\r\n\t\tlogger.debug(\"Creating new message for application command MULTI_CHANNEL_CAPABILITY_GET for node {} and endpoint {}\", this.getNode().getNodeId(), endpoint.getEndpointId());\r\n\t\tSerialMessage result = new SerialMessage(this.getNode().getNodeId(), SerialMessageClass.SendData, SerialMessageType.Request, SerialMessageClass.ApplicationCommandHandler, SerialMessagePriority.Get);\r\n    \tbyte[] newPayload = { \t(byte) this.getNode().getNodeId(), \r\n    \t\t\t\t\t\t\t3, \r\n\t\t\t\t\t\t\t\t(byte) getCommandClass().getKey(), \r\n\t\t\t\t\t\t\t\t(byte) MULTI_CHANNEL_CAPABILITY_GET,\r\n\t\t\t\t\t\t\t\t(byte) endpoint.getEndpointId() };\r\n    \tresult.setMessagePayload(newPayload);\r\n    \treturn result;\r\n\t}", "label": 0}
{"code": "def ripping_of_cds():\n    '''Install the tools ripit and burnit in order to rip and burn audio cds.\n\n    More info: http://forums.debian.net/viewtopic.php?f=16&t=36826\n    '''\n    # install and configure ripit\n    install_package('ripit')\n    install_file_legacy(path='~/.ripit/config', username=env.user)\n    # install burnit\n    run('mkdir -p  ~/bin')\n    install_file_legacy('~/bin/burnit')\n    run('chmod 755 ~/bin/burnit')", "label": 1}
{"code": "func ExpectCompareFailed(c *check.C, err error) {\n\tc.Assert(trace.IsCompareFailed(err), check.Equals, true, check.Commentf(\"expected CompareFailed, got %T %v at %v\", trace.Unwrap(err), err, string(debug.Stack())))\n}", "label": 5}
{"code": "function _gpfPathJoin (path) {\n    var splitPath = _gpfPathDecompose(path);\n    _gpfArrayTail(arguments).forEach(_gpfPathAppend.bind(null, splitPath));\n    return splitPath.join(\"/\");\n}", "label": 3}
{"code": "public static base_response update(nitro_service client, rnatparam resource) throws Exception {\n\t\trnatparam updateresource = new rnatparam();\n\t\tupdateresource.tcpproxy = resource.tcpproxy;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public static base_responses update(nitro_service client, gslbservice resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tgslbservice updateresources[] = new gslbservice[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new gslbservice();\n\t\t\t\tupdateresources[i].servicename = resources[i].servicename;\n\t\t\t\tupdateresources[i].ipaddress = resources[i].ipaddress;\n\t\t\t\tupdateresources[i].publicip = resources[i].publicip;\n\t\t\t\tupdateresources[i].publicport = resources[i].publicport;\n\t\t\t\tupdateresources[i].cip = resources[i].cip;\n\t\t\t\tupdateresources[i].cipheader = resources[i].cipheader;\n\t\t\t\tupdateresources[i].sitepersistence = resources[i].sitepersistence;\n\t\t\t\tupdateresources[i].siteprefix = resources[i].siteprefix;\n\t\t\t\tupdateresources[i].maxclient = resources[i].maxclient;\n\t\t\t\tupdateresources[i].healthmonitor = resources[i].healthmonitor;\n\t\t\t\tupdateresources[i].maxbandwidth = resources[i].maxbandwidth;\n\t\t\t\tupdateresources[i].downstateflush = resources[i].downstateflush;\n\t\t\t\tupdateresources[i].maxaaausers = resources[i].maxaaausers;\n\t\t\t\tupdateresources[i].viewname = resources[i].viewname;\n\t\t\t\tupdateresources[i].viewip = resources[i].viewip;\n\t\t\t\tupdateresources[i].monthreshold = resources[i].monthreshold;\n\t\t\t\tupdateresources[i].weight = resources[i].weight;\n\t\t\t\tupdateresources[i].monitor_name_svc = resources[i].monitor_name_svc;\n\t\t\t\tupdateresources[i].hashid = resources[i].hashid;\n\t\t\t\tupdateresources[i].comment = resources[i].comment;\n\t\t\t\tupdateresources[i].appflowlog = resources[i].appflowlog;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function showError(message) {\n    $(document.createElement('div')).attr({'class': 'popup-error'})\n      .append($(document.createElement('div'))\n               .attr({'class': 'error-message'}).text(message))\n      .appendTo('body')\n      .fadeIn(\"slow\")\n      .delay(2000)\n      .fadeOut(\"slow\");\n  }", "label": 3}
{"code": "@SuppressWarnings(\"unchecked\")\r\n  public static <E, C extends Counter<E>> C tfLogScale(C c, double base) {\r\n    C scaled = (C) c.getFactory().create();\r\n    for (E key : c.keySet()) {\r\n      double cnt = c.getCount(key);\r\n      double scaledCnt = 0.0;\r\n      if (cnt > 0) {\r\n        scaledCnt = 1.0 + SloppyMath.log(cnt, base);\r\n      }\r\n      scaled.setCount(key, scaledCnt);\r\n    }\r\n    return scaled;\r\n  }", "label": 0}
{"code": "def content_without_title_and_version\n      @content_without_title_and_version ||= begin\n        @_content = nil\n        ops = %i[html hrs comments markdown_headings title version]\n        ops.each { |op| strip(op) }\n        _content\n      end\n    end", "label": 4}
{"code": "function indexPortals() {\n  const { portals = {} } = getComponentsSettings();\n\n  return index({\n    file: 'portals.js',\n    config: {\n      type: TYPE_PORTALS,\n      config: portals,\n      importsStart: 'import portalCollection from \\'@shopgate/pwa-common/helpers/portals/portalCollection\\';',\n      exportsStart: 'portalCollection.registerPortals({',\n      exportsEnd: '});',\n    },\n    ...getIndexLogTranslations(TYPE_PORTALS),\n  });\n}", "label": 3}
{"code": "def make_random_xml_file(fname, num_elements=200, depth=3):\n    \"\"\"\n    makes a random xml file mainly for testing the xml_split\n    \"\"\"\n    with open(fname, 'w') as f:\n        f.write('<?xml version=\"1.0\" ?>\\n<random>\\n')\n        for dep_num, _ in enumerate(range(1,depth)):\n            f.write(' <depth>\\n  <content>\\n')\n            #f.write('<depth' + str(dep_num) + '>\\n')\n            for num, _ in enumerate(range(1, num_elements)):\n                f.write('    <stuff>data line ' + str(num) + '</stuff>\\n')\n            #f.write('</depth' + str(dep_num) + '>\\n')\n            f.write('  </content>\\n </depth>\\n')\n    \n        f.write('</random>\\n')", "label": 1}
{"code": "function load(schema) {\n  var obj;\n  if (typeof schema == 'string' && schema !== 'null') {\n    // This last predicate is to allow `avro.parse('null')` to work similarly\n    // to `avro.parse('int')` and other primitives (null needs to be handled\n    // separately since it is also a valid JSON identifier).\n    try {\n      obj = JSON.parse(schema);\n    } catch (err) {\n      if (~schema.indexOf('/')) {\n        // This can't be a valid name, so we interpret is as a filepath. This\n        // makes is always feasible to read a file, independent of its name\n        // (i.e. even if its name is valid JSON), by prefixing it with `./`.\n        obj = JSON.parse(fs.readFileSync(schema));\n      }\n    }\n  }\n  if (obj === undefined) {\n    obj = schema;\n  }\n  return obj;\n}", "label": 3}
{"code": "function Arguable (usage, argv, options) {\n    this._usage = usage\n\n    // These are the merged defintion and invocation options provided by the\n    // user.\n    this.options = options.options\n\n    // The key used to create the `Destructible`.\n    this.identifier = options.identifier\n\n    // We'll use this for an exit code if it is set and if we exit normally.\n    this.exitCode = null\n\n    // Are we running as a main module?\n    this.isMainModule = options.isMainModule\n\n    // Use environment `LANG` or else language of first usage definition.\n    this.lang = coalesce(options.lang, this._usage.language)\n\n    // Extract argument patterns from usage.\n    var patterns = this._usage.getPattern()\n\n    // Extract the arguments that accept values, TODO maybe call `valuable`.\n    this.arguable = patterns.filter(function (pattern) {\n        return pattern.arguable\n    }).map(function (pattern) {\n        return pattern.verbose\n    })\n\n    // Parse arguments and save the remaining arguments.\n    try {\n        var gotopts = getopt(patterns, argv)\n    } catch (error) {\n        this.abend(error.abend, error.context)\n    }\n\n    // Extract an argument end sigil and note that it was there.\n    if (this.terminal = argv[0] == '--')  {\n        argv.shift()\n    }\n\n    // Slice and dice results into convenience structures.\n    this._setParameters(gotopts)\n\n    // Remaining arguments.\n    this.argv = argv\n\n    // Assign standard I/O provide in `options`.\n    this.stdout = options.stdout\n    this.stderr = options.stderr\n    this.stdin = options.stdin\n\n    // Assign pipes open to our parent.\n    this.pipes = options.pipes\n\n    // Set after we get our arguments.\n    this.scram = 0\n\n    // Called when we exit with no arguments.\n    this.exited = new Signal\n}", "label": 3}
{"code": "func (i *IpamInfo) CopyTo(dstI *IpamInfo) error {\n\tdstI.PoolID = i.PoolID\n\tif i.Meta != nil {\n\t\tdstI.Meta = make(map[string]string)\n\t\tfor k, v := range i.Meta {\n\t\t\tdstI.Meta[k] = v\n\t\t}\n\t}\n\n\tdstI.AddressSpace = i.AddressSpace\n\tdstI.Pool = types.GetIPNetCopy(i.Pool)\n\tdstI.Gateway = types.GetIPNetCopy(i.Gateway)\n\n\tif i.AuxAddresses != nil {\n\t\tdstI.AuxAddresses = make(map[string]*net.IPNet)\n\t\tfor k, v := range i.AuxAddresses {\n\t\t\tdstI.AuxAddresses[k] = types.GetIPNetCopy(v)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "private function fullyQualifiedDatabaseName($name)\n    {\n        $instance = InstanceAdminClient::parseName($this->instance->name())['instance'];\n\n        try {\n            return GapicSpannerClient::databaseName(\n                $this->projectId,\n                $instance,\n                $name\n            );\n        //@codeCoverageIgnoreStart\n        } catch (ValidationException $e) {\n            return $name;\n        }\n        //@codeCoverageIgnoreEnd\n    }", "label": 2}
{"code": "func (cn *connection) nominalMaxRequests() (ret int) {\n\tif cn.t.requestStrategy == 3 {\n\t\texpectingTime := int64(cn.totalExpectingTime())\n\t\tif expectingTime == 0 {\n\t\t\texpectingTime = math.MaxInt64\n\t\t} else {\n\t\t\texpectingTime *= 2\n\t\t}\n\t\treturn int(clamp(\n\t\t\t1,\n\t\t\tint64(cn.PeerMaxRequests),\n\t\t\tmax(\n\t\t\t\t// It makes sense to always pipeline at least one connection,\n\t\t\t\t// since latency must be non-zero.\n\t\t\t\t2,\n\t\t\t\t// Request only as many as we expect to receive in the\n\t\t\t\t// dupliateRequestTimeout window. We are trying to avoid having to\n\t\t\t\t// duplicate requests.\n\t\t\t\tcn.chunksReceivedWhileExpecting*int64(cn.t.duplicateRequestTimeout)/expectingTime,\n\t\t\t),\n\t\t))\n\t}\n\treturn int(clamp(\n\t\t1,\n\t\tint64(cn.PeerMaxRequests),\n\t\tmax(64,\n\t\t\tcn.stats.ChunksReadUseful.Int64()-(cn.stats.ChunksRead.Int64()-cn.stats.ChunksReadUseful.Int64()))))\n}", "label": 5}
{"code": "func (r *DrvRegistry) IPAMDefaultAddressSpaces(name string) (string, string, error) {\n\tr.Lock()\n\tdefer r.Unlock()\n\n\ti, ok := r.ipamDrivers[name]\n\tif !ok {\n\t\treturn \"\", \"\", fmt.Errorf(\"ipam %s not found\", name)\n\t}\n\n\treturn i.defaultLocalAddressSpace, i.defaultGlobalAddressSpace, nil\n}", "label": 5}
{"code": "def get_urls(self):\n        \"\"\"\n        Get urls method.\n\n        Returns:\n            list: the list of url objects.\n        \"\"\"\n        urls = super(DashboardSite, self).get_urls()\n        custom_urls = [\n            url(r'^$',\n                self.admin_view(HomeView.as_view()),\n                name='index'),\n            url(r'^logs/', include(logs_urlpatterns(self.admin_view))),\n        ]\n\n        custom_urls += get_realtime_urls(self.admin_view)\n\n        del urls[0]\n        return custom_urls + urls", "label": 1}
{"code": "function Persistable (key, value) {\n        const __self = this;\n        __self.key = key;\n\n        // Set value and type of object.\n        if (value === undefined || value === null) {\n            __self.value = undefined;\n            __self.type = typeof undefined;\n        } else if (value instanceof Array) {\n            __self.value = [];\n            value.forEach(function (e, i) {\n                __self.value.push(new Persistable(key + '[' + i + ']', e));\n            });\n            __self.type = Type.ARRAY;\n        } else {\n            switch (typeof value) {\n                case Type.STRING:\n                case Type.NUMBER:\n                case Type.BOOLEAN:\n                    __self.value = value;\n                    __self.type = typeof value;\n                    break;\n                case Type.OBJECT:\n                    __self.value = [];\n                    Object.keys(value).forEach(function (e) {\n                        __self.value.push(new Persistable(key + '[' + e + ']', value[e]));\n                    });\n                    __self.type = typeof value;\n                    break;\n                default:\n                    _logUnknownType(typeof value);\n            }\n        }\n\n        __self.timestamp = Date.now();\n\n        __self.toOriginal = function () {\n            return _fromPersistable(__self);\n        };\n    }", "label": 3}
{"code": "function (number, halfSteps) {\n  var diatonicHalfSteps = getDiatonicHalfSteps(number);\n  var halfStepOffset = halfSteps - diatonicHalfSteps;\n\n  // Handle various abnormalities\n  if (halfStepOffset === 11) halfStepOffset = -1;\n  if (halfStepOffset === -11) halfStepOffset = 1;\n\n  return halfStepOffset;\n}", "label": 3}
{"code": "def is_sequence(value):\n    \"\"\"Determine if a value is a sequence type.\n\n    Returns:\n      ``True`` if `value` is a sequence type (e.g., ``list``, or ``tuple``).\n      String types will return ``False``.\n\n    NOTE: On Python 3, strings have the __iter__ defined, so a simple hasattr\n    check is insufficient.\n    \"\"\"\n    return (hasattr(value, \"__iter__\") and not\n            isinstance(value, (six.string_types, six.binary_type)))", "label": 1}
{"code": "public boolean removeReader(Object key, Object resourceId)\r\n    {\r\n        boolean result = false;\r\n        ObjectLocks objectLocks = null;\r\n        synchronized(locktable)\r\n        {\r\n            objectLocks = (ObjectLocks) locktable.get(resourceId);\r\n            if(objectLocks != null)\r\n            {\r\n                /**\r\n                 * MBAIRD, last one out, close the door and turn off the lights.\r\n                 * if no locks (readers or writers) exist for this object, let's remove\r\n                 * it from the locktable.\r\n                 */\r\n                Map readers = objectLocks.getReaders();\r\n                result = readers.remove(key) != null;\r\n                if((objectLocks.getWriter() == null) && (readers.size() == 0))\r\n                {\r\n                    locktable.remove(resourceId);\r\n                }\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "public static base_response clear(nitro_service client, bridgetable resource) throws Exception {\n\t\tbridgetable clearresource = new bridgetable();\n\t\tclearresource.vlan = resource.vlan;\n\t\tclearresource.ifnum = resource.ifnum;\n\t\treturn clearresource.perform_operation(client,\"clear\");\n\t}", "label": 0}
{"code": "public function show_synopsis_if_composite_command() {\n\t\t$r = $this->find_command_to_run( $this->arguments );\n\t\tif ( is_array( $r ) ) {\n\t\t\tlist( $command ) = $r;\n\n\t\t\tif ( $command->can_have_subcommands() ) {\n\t\t\t\t$command->show_usage();\n\t\t\t\texit;\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "def set_country(request):\n    \"\"\"\n    Sets the chosen country in the session or cookie.\n\n    If `next' query param is present, it redirects to a given url.\n    \"\"\"\n    if request.method == 'POST':\n        next = request.POST.get('next', request.GET.get('next'))\n        if is_safe_url(url=next, host=request.get_host()):\n            response = http.HttpResponseRedirect(next)\n        else:\n            response = http.HttpResponse()\n\n        country_code = request.POST.get('country', '').upper()\n        if country_code != geo.get_supported_country(country_code):\n            return http.HttpResponseBadRequest()\n\n        if hasattr(request, 'session'):\n            request.session[geo.COUNTRY_SESSION_KEY] = country_code\n        else:\n            response.set_cookie(geo.COUNTRY_COOKIE_NAME,\n                               country_code,\n                               max_age=geo.COUNTRY_COOKIE_AGE,\n                               path=geo.COUNTRY_COOKIE_PATH)\n        return response\n    else:\n        return http.HttpResponseNotAllowed(['POST'])", "label": 1}
{"code": "public static Long getAsLong(Object value) {\n\t\tLong result = null;\n\n\t\ttry {\n\t\t\tif (value instanceof String) {\n\t\t\t\tresult = Long.valueOf((String) value);\n\t\t\t} else if (value instanceof Number) {\n\t\t\t\tresult = ((Number) value).longValue();\n\t\t\t} else {\n\t\t\t\tresult = null;\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tresult = null;\n\t\t}\n\n\t\treturn result == null ? 0 : result;\n\t}", "label": 0}
{"code": "function () {\n      var self = this;\n      var startWidth = this.scoreboardWidth + this.trajectories[0].length;\n      var color = '\\u001b[' + startWidth + 'C';\n      var padding = '';\n\n      write(color);\n      write('_,------,');\n      write('\\n');\n\n      write(color);\n      padding = self.tick ? '  ' : '   ';\n      write('_|' + padding + '/\\\\_/\\\\ ');\n      write('\\n');\n\n      write(color);\n      padding = self.tick ? '_' : '__';\n      var tail = self.tick ? '~' : '^';\n      var face;\n      write(tail + '|' + padding + this.drawFace() + ' ');\n      write('\\n');\n\n      write(color);\n      padding = self.tick ? ' ' : '  ';\n      write(padding + '\"\"  \"\" ');\n      write('\\n');\n\n      cursor.up(this.numberOfLines);\n    }", "label": 3}
{"code": "function reply(id, args) {\n  var msg = new Array(2 + args.length);\n\n  msg[0] = '_reply_';\n  msg[1] = id;\n\n  for (var i = 0; i < args.length; i++) {\n    msg[i + 2] = args[i];\n  }\n\n  return msg;\n}", "label": 3}
{"code": "def parts\n      parts = [\n       {:entry => RELS_PN, :doc => relationships, :schema => RELS_XSD},\n       {:entry => \"xl/#{STYLES_PN}\", :doc => workbook.styles, :schema => SML_XSD},\n       {:entry => CORE_PN, :doc => @core, :schema => CORE_XSD},\n       {:entry => APP_PN, :doc => @app, :schema => APP_XSD},\n       {:entry => WORKBOOK_RELS_PN, :doc => workbook.relationships, :schema => RELS_XSD},\n       {:entry => CONTENT_TYPES_PN, :doc => content_types, :schema => CONTENT_TYPES_XSD},\n       {:entry => WORKBOOK_PN, :doc => workbook, :schema => SML_XSD}\n      ]\n\n      workbook.drawings.each do |drawing|\n        parts << {:entry => \"xl/#{drawing.rels_pn}\", :doc => drawing.relationships, :schema => RELS_XSD}\n        parts << {:entry => \"xl/#{drawing.pn}\", :doc => drawing, :schema => DRAWING_XSD}\n      end\n\n\n      workbook.tables.each do |table|\n        parts << {:entry => \"xl/#{table.pn}\", :doc => table, :schema => SML_XSD}\n      end\n      workbook.pivot_tables.each do |pivot_table|\n        cache_definition = pivot_table.cache_definition\n        parts << {:entry => \"xl/#{pivot_table.rels_pn}\", :doc => pivot_table.relationships, :schema => RELS_XSD}\n        parts << {:entry => \"xl/#{pivot_table.pn}\", :doc => pivot_table} #, :schema => SML_XSD}\n        parts << {:entry => \"xl/#{cache_definition.pn}\", :doc => cache_definition} #, :schema => SML_XSD}\n      end\n\n      workbook.comments.each do|comment|\n        if comment.size > 0\n          parts << { :entry => \"xl/#{comment.pn}\", :doc => comment, :schema => SML_XSD }\n          parts << { :entry => \"xl/#{comment.vml_drawing.pn}\", :doc => comment.vml_drawing, :schema => nil }\n        end\n      end\n\n      workbook.charts.each do |chart|\n        parts << {:entry => \"xl/#{chart.pn}\", :doc => chart, :schema => DRAWING_XSD}\n      end\n\n      workbook.images.each do |image|\n        parts << {:entry => \"xl/#{image.pn}\", :path => image.image_src}\n      end\n\n      if use_shared_strings\n        parts << {:entry => \"xl/#{SHARED_STRINGS_PN}\", :doc => workbook.shared_strings, :schema => SML_XSD}\n      end\n\n      workbook.worksheets.each do |sheet|\n        parts << {:entry => \"xl/#{sheet.rels_pn}\", :doc => sheet.relationships, :schema => RELS_XSD}\n        parts << {:entry => \"xl/#{sheet.pn}\", :doc => sheet, :schema => SML_XSD}\n      end\n\n      # Sort parts for correct MIME detection\n      parts.sort_by { |part| part[:entry] }\n    end", "label": 4}
{"code": "func isISBN10(fl FieldLevel) bool {\n\n\ts := strings.Replace(strings.Replace(fl.Field().String(), \"-\", \"\", 3), \" \", \"\", 3)\n\n\tif !iSBN10Regex.MatchString(s) {\n\t\treturn false\n\t}\n\n\tvar checksum int32\n\tvar i int32\n\n\tfor i = 0; i < 9; i++ {\n\t\tchecksum += (i + 1) * int32(s[i]-'0')\n\t}\n\n\tif s[9] == 'X' {\n\t\tchecksum += 10 * 10\n\t} else {\n\t\tchecksum += 10 * int32(s[9]-'0')\n\t}\n\n\treturn checksum%11 == 0\n}", "label": 5}
{"code": "def fetch_and_filter_tags\n      since_tag\n      due_tag\n\n      all_tags = @fetcher.get_all_tags\n      fetch_tags_dates(all_tags) # Creates a Hash @tag_times_hash\n      all_sorted_tags = sort_tags_by_date(all_tags)\n\n      @sorted_tags   = filter_excluded_tags(all_sorted_tags)\n      @filtered_tags = get_filtered_tags(@sorted_tags)\n\n      # Because we need to properly create compare links, we need a sorted list\n      # of all filtered tags (including the excluded ones). We'll exclude those\n      # tags from section headers inside the mapping function.\n      section_tags = get_filtered_tags(all_sorted_tags)\n\n      @tag_section_mapping = build_tag_section_mapping(section_tags, @filtered_tags)\n\n      @filtered_tags\n    end", "label": 4}
{"code": "def get_list_of_applications():\n    \"\"\"\n    Get list of applications\n    \"\"\"\n    apps = mod_prg.Programs('Applications', 'C:\\\\apps')\n    fl = mod_fl.FileList(['C:\\\\apps'], ['*.exe'], [\"\\\\bk\\\\\"])\n    for f in fl.get_list():\n        apps.add(f, 'autogenerated list')\n    apps.list()\n    apps.save()", "label": 1}
{"code": "func (r *Registry) UserDirectory() *UserDirectory {\n\treturn r.Get(r.content().UserDirectory.Reference()).(*UserDirectory)\n}", "label": 5}
{"code": "func (tl TypeLoader) NthParam(i int) string {\n\tif tl.ParamN != nil {\n\t\treturn tl.ParamN(i)\n\t}\n\n\treturn fmt.Sprintf(\"$%d\", i+1)\n}", "label": 5}
{"code": "function insertInto(annotations, index, text, afterExisting) {\n  for (let i = 0; i < annotations.length; ++i) {\n    if (annotations[i].index >= index) {\n      if (afterExisting) {\n        while (i < annotations.length && annotations[i].index === index) {\n          ++i;\n        }\n      }\n\n      annotations.splice(i, 0, { index, text });\n      return;\n    }\n  }\n  annotations.push({ index, text });\n}", "label": 3}
{"code": "public function lookupBatch(array $keys, array $options = [])\n    {\n        return $this->operation->lookup($keys, $options + [\n            'transaction' => $this->transactionId\n        ]);\n    }", "label": 2}
{"code": "public static base_response unset(nitro_service client, sslparameter resource, String[] args) throws Exception{\n\t\tsslparameter unsetresource = new sslparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "private function getSaveAsParameter()\n    {\n        return static function (callable $handler) {\n            return function (Command $command, $request = null) use ($handler) {\n                if ($command->getName() === 'GetObject' && isset($command['SaveAs'])) {\n                    $command['@http']['sink'] = $command['SaveAs'];\n                    unset($command['SaveAs']);\n                }\n\n                return $handler($command, $request);\n            };\n        };\n    }", "label": 2}
{"code": "func (ts *Store) Size(id string) (int64, error) {\n\tsz, err := fileutil.DirSize(ts.GetPath(id))\n\tif err != nil {\n\t\treturn -1, errwrap.Wrap(errors.New(\"error calculating size\"), err)\n\t}\n\treturn sz, nil\n}", "label": 5}
{"code": "def bolt_command_on(host, command, flags = {}, opts = {})\n      bolt_command = command.dup\n      flags.each { |k, v| bolt_command << \" #{k} #{v}\" }\n\n      case host['platform']\n      when /windows/\n        execute_powershell_script_on(host, bolt_command, opts)\n      when /osx/\n        # Ensure Bolt runs with UTF-8 under macOS. Otherwise we get issues with\n        # UTF-8 content in task results.\n        env = 'source /etc/profile  ~/.bash_profile ~/.bash_login ~/.profile && env LANG=en_US.UTF-8'\n        on(host, env + ' ' + bolt_command)\n      else\n        on(host, bolt_command, opts)\n      end\n    end", "label": 4}
{"code": "public static Long getSize(final File file){\n        if ( file!=null && file.exists() ){\n            return file.length();\n        }\n        return null;\n    }", "label": 0}
{"code": "func PgQueryColumns(args *internal.ArgType, inspect []string) ([]*models.Column, error) {\n\tvar err error\n\n\t// create temporary view xoid\n\txoid := \"_xo_\" + internal.GenRandomID()\n\tviewq := `CREATE TEMPORARY VIEW ` + xoid + ` AS (` + strings.Join(inspect, \"\\n\") + `)`\n\tmodels.XOLog(viewq)\n\t_, err = args.DB.Exec(viewq)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// query to determine schema name where temporary view was created\n\tvar nspq = `SELECT n.nspname ` +\n\t\t`FROM pg_class c ` +\n\t\t`JOIN pg_namespace n ON n.oid = c.relnamespace ` +\n\t\t`WHERE n.nspname LIKE 'pg_temp%' AND c.relname = $1`\n\n\t// run query\n\tvar schema string\n\tmodels.XOLog(nspq, xoid)\n\terr = args.DB.QueryRow(nspq, xoid).Scan(&schema)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// load column information\n\treturn models.PgTableColumns(args.DB, schema, xoid, false)\n}", "label": 5}
{"code": "def print_clusters(fastas, info, ANI):\n    \"\"\"\n    choose represenative genome and\n    print cluster information\n\n    *if ggKbase table is provided, use SCG info to choose best genome\n    \"\"\"\n    header = ['#cluster', 'num. genomes', 'rep.', 'genome', '#SCGs', '#SCG duplicates', \\\n            'genome size (bp)', 'fragments', 'list']\n    yield header\n    in_cluster = []\n    for cluster_num, cluster in enumerate(connected_components(ANI)):\n        cluster = sorted([genome_info(genome, info[genome]) \\\n                            for genome in cluster], \\\n                            key = lambda x: x[0:], reverse = True)\n        rep = cluster[0][-1]\n        cluster = [i[-1] for i in cluster]\n        size = len(cluster)\n        for genome in cluster:\n            in_cluster.append(genome)\n            try:\n                stats = [size, rep, genome, \\\n                            info[genome]['#SCGs'], info[genome]['#SCG duplicates'], \\\n                            info[genome]['genome size (bp)'], info[genome]['# contigs'], cluster]\n            except:\n                stats = [size, rep, genome, \\\n                            'n/a', 'n/a', \\\n                            info[genome]['genome size (bp)'], info[genome]['# contigs'], cluster]\n            if rep == genome:\n                stats = ['*%s' % (cluster_num)] + stats\n            else:\n                stats = [cluster_num] + stats\n            yield stats\n    # print singletons\n    try:\n        start = cluster_num + 1\n    except:\n        start = 0\n    fastas = set([i.rsplit('.', 1)[0].rsplit('/', 1)[-1].rsplit('.contigs')[0] for i in fastas])\n    for cluster_num, genome in \\\n            enumerate(fastas.difference(set(in_cluster)), start):\n        try:\n            stats = ['*%s' % (cluster_num), 1, genome, genome, \\\n                        info[genome]['#SCGs'], info[genome]['#SCG duplicates'], \\\n                        info[genome]['genome size (bp)'], info[genome]['# contigs'], [genome]]\n        except:\n            stats = ['*%s' % (cluster_num), 1, genome, genome, \\\n                        'n/a', 'n/a', \\\n                        info[genome]['genome size (bp)'], info[genome]['# contigs'], [genome]]\n        yield stats", "label": 1}
{"code": "public function datasets(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $dataset) {\n                    return new Dataset(\n                        $this->connection,\n                        $dataset['datasetReference']['datasetId'],\n                        $this->projectId,\n                        $this->mapper,\n                        $dataset\n                    );\n                },\n                [$this->connection, 'listDatasets'],\n                $options + ['projectId' => $this->projectId],\n                [\n                    'itemsKey' => 'datasets',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "public function sendNextMessage()\n    {\n        if (count($this->outQueue) > 0) {\n            $msgnode = array_shift($this->outQueue);\n            $msgnode->refreshTimes();\n            $this->lastId = $msgnode->getAttribute('id');\n            $this->sendNode($msgnode);\n        } else {\n            $this->lastId = false;\n        }\n    }", "label": 2}
{"code": "function validateForm(form, cb) {\n\n  async.series([function(callback) {\n    fs.exists(form, function(exists) {\n      if (exists) {\n        callback(null);\n      } else {\n        callback('File ' + path.basename(form) + ' referenced by metadata.json does not exists');\n      }\n    });\n  },\n    function(callback) {\n      validateJSonStructure(form, callback);\n    }\n  ], function(err, data) {\n    cb(err, data);\n  });\n}", "label": 3}
{"code": "public static String getModuleName(final String moduleId) {\n        final int splitter = moduleId.indexOf(':');\n        if(splitter == -1){\n            return moduleId;\n        }\n        return moduleId.substring(0, splitter);\n    }", "label": 0}
{"code": "def assert_npfloatarray(obj, varname, desc, exc, tc, errsrc):\n    \"\"\" Assert a value is an |nparray| of NumPy floats.\n\n    Pass |None| to `varname` if `obj` itself is to be checked.\n    Otherwise, `varname` is the string name of the attribute of `obj` to\n    check.  In either case, `desc` is a string description of the\n    object to be checked, for use in raising of exceptions.\n\n    Raises the exception `exc` with typecode `tc` if the indicated\n    object is determined not to be an |nparray|, with a NumPy float dtype.\n\n    Intended primarily to serve as an early check for\n    proper implementation of subclasses of\n    :class:`~opan.grad.SuperOpanGrad` and\n    :class:`~opan.hess.SuperOpanHess`. Early type-checking of key\n    attributes will hopefully avoid confusing bugs downstream.\n\n    Parameters\n    ----------\n    obj\n        (arbitrary) --\n        Object to be checked, or object with attribute to be checked.\n\n    varname\n        |str| or |None| --\n        Name of the attribute of `obj` to be type-checked. |None|\n        indicates to check `obj` itself.\n\n    desc\n        |str| --\n        Description of the object being checked to be used in any\n        raised exceptions.\n\n    exc\n        Subclass of :class:`~opan.error.OpanError` to be raised on\n        a failed typecheck.\n\n    tc\n        Typecode of `exc` to be raised on a failed typecheck.\n\n    errsrc\n        |str| --\n        String description of the source of the data leading to a\n        failed typecheck.\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Check for whether member or object is to be checked\n    if varname is None:\n        var = obj\n    else:\n        # Try to get the variable to be typechecked\n        try:\n            var = getattr(obj, varname)\n        except AttributeError:\n            raise exc(tc, \"Attribute '{0}' not defined in '{1}'\"\n                    .format(varname, obj), errsrc)\n        ## end try\n    ## end if\n\n    # Try to pull the np dtype off of it\n    try:\n        dt = var.dtype\n    except AttributeError:\n        raise exc(tc, \"'{0}' is not an np.array (lacks a 'dtype' member)\"\n                    .format(desc), errsrc)\n    else:\n        if not var.shape:\n            raise exc(tc, \"'{0}' is not an np.array ('len(shape)' < 1)\"\n                    .format(desc), errsrc)\n    ## end try\n\n    # Confirm dtype inherits from np.float\n    if not np.issubdtype(dt, np.float):\n        raise exc(tc, \"'{0}' is not an np.array of np.float\".format(desc),\n                errsrc)", "label": 1}
{"code": "public void updateLockingValues(Object obj) throws PersistenceBrokerException\r\n    {\r\n        FieldDescriptor[] fields = getLockingFields();\r\n        for (int i = 0; i < fields.length; i++)\r\n        {\r\n            FieldDescriptor fmd = fields[i];\r\n            if (fmd.isUpdateLock())\r\n            {\r\n                PersistentField f = fmd.getPersistentField();\r\n                Object cv = f.get(obj);\r\n                // int\r\n                if ((f.getType() == int.class) || (f.getType() == Integer.class))\r\n                {\r\n                    int newCv = 0;\r\n                    if (cv != null)\r\n                    {\r\n                        newCv = ((Number) cv).intValue();\r\n                    }\r\n                    newCv++;\r\n                    f.set(obj, new Integer(newCv));\r\n                }\r\n                // long\r\n                else if ((f.getType() == long.class) || (f.getType() == Long.class))\r\n                {\r\n                    long newCv = 0;\r\n                    if (cv != null)\r\n                    {\r\n                        newCv = ((Number) cv).longValue();\r\n                    }\r\n                    newCv++;\r\n                    f.set(obj, new Long(newCv));\r\n                }\r\n                // Timestamp\r\n                else if (f.getType() == Timestamp.class)\r\n                {\r\n                    long newCv = System.currentTimeMillis();\r\n                    f.set(obj, new Timestamp(newCv));\r\n                }\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def log_runtime_environment(extra_info=nil)\n    runtime_info = {\n      'puppet_version' => Puppet.version,\n      'ruby_version'   => RUBY_VERSION,\n      'run_mode'       => self.class.run_mode.name,\n    }\n    runtime_info['default_encoding'] = Encoding.default_external\n    runtime_info.merge!(extra_info) unless extra_info.nil?\n\n    Puppet.debug 'Runtime environment: ' + runtime_info.map{|k,v| k + '=' + v.to_s}.join(', ')\n  end", "label": 4}
{"code": "def dependency(lib = nil)\n      lib ? require(lib) : yield\n    rescue LoadError, NameError => e\n      self.load_error = e\n    end", "label": 4}
{"code": "func setAggregationValueIfPresent(aggName core.AggregationType, rawVal []interface{}, aggregations *core.AggregationValue, indexLookup map[core.AggregationType]int, wasInt map[string]bool) error {\n\tif fieldIndex, ok := indexLookup[aggName]; ok {\n\t\ttargetValue := &core.MetricValue{}\n\t\tif err := tryParseMetricValue(string(aggName), rawVal, targetValue, fieldIndex, wasInt); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\taggregations.Aggregations[aggName] = *targetValue\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func (r *Registry) Any(kind string) mo.Entity {\n\tr.m.Lock()\n\tdefer r.m.Unlock()\n\n\tfor ref, val := range r.objects {\n\t\tif ref.Type == kind {\n\t\t\treturn val.(mo.Entity)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static base_response unset(nitro_service client, lbparameter resource, String[] args) throws Exception{\n\t\tlbparameter unsetresource = new lbparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function(token){\n            return {\n                users: require('./runners/users')(token),\n                tokens: require('./runners/tokens')(token),\n                content: require('./runners/content')(token),\n                contentTypes: require('./runners/contentTypes')(token),\n                nodes: require('./runners/nodes')(token),\n                assets: require('./runners/assets')(token),\n                system: require('./runners/system')(token)\n            };\n        }", "label": 3}
{"code": "public function setCommandReadOnly($commandID, $readonly = true)\n    {\n        $commandID = strtoupper($commandID);\n\n        if ($readonly) {\n            $this->readonly[$commandID] = $readonly;\n        } else {\n            unset($this->readonly[$commandID]);\n        }\n    }", "label": 2}
{"code": "public static void main(String[] args) {\r\n    Treebank treebank = new DiskTreebank();\r\n    treebank.loadPath(args[0]);\r\n    WordStemmer ls = new WordStemmer();\r\n    for (Tree tree : treebank) {\r\n      ls.visitTree(tree);\r\n      System.out.println(tree);\r\n    }\r\n  }", "label": 0}
{"code": "function(errors) {\n\t\t\t//!steal-remove-start\n\t\t\tif (process.env.NODE_ENV !== 'production') {\n\t\t\t\tclearTimeout(asyncTimer);\n\t\t\t}\n\t\t\t//!steal-remove-end\n\n\t\t\tvar stub = error && error.call(self, errors);\n\t\t\t// if 'validations' is on the page it will trigger\n\t\t\t// the error itself and we dont want to trigger\n\t\t\t// the event twice. :)\n\t\t\tif (stub !== false) {\n\t\t\t\tmapEventsMixin.dispatch.call(self, 'error', [ prop, errors ], true);\n\t\t\t}\n\t\t\treturn false;\n\t\t}", "label": 3}
{"code": "def source_extraction(in1, tolerance, mode=\"cpu\", store_on_gpu=False,\n                      neg_comp=False):\n    \"\"\"\n    Convenience function for allocating work to cpu or gpu, depending on the selected mode.\n\n    INPUTS:\n    in1         (no default):   Array containing the wavelet decomposition.\n    tolerance   (no default):   Percentage of maximum coefficient at which objects are deemed significant.\n    mode        (default=\"cpu\"):Mode of operation - either \"gpu\" or \"cpu\".\n\n    OUTPUTS:\n    Array containing the significant wavelet coefficients of extracted sources.\n    \"\"\"\n\n    if mode==\"cpu\":\n        return cpu_source_extraction(in1, tolerance, neg_comp)\n    elif mode==\"gpu\":\n        return gpu_source_extraction(in1, tolerance, store_on_gpu, neg_comp)", "label": 1}
{"code": "public function updateCluster($projectId, $region, $clusterName, $cluster, $updateMask, array $optionalArgs = [])\n    {\n        $request = new UpdateClusterRequest();\n        $request->setProjectId($projectId);\n        $request->setRegion($region);\n        $request->setClusterName($clusterName);\n        $request->setCluster($cluster);\n        $request->setUpdateMask($updateMask);\n        if (isset($optionalArgs['gracefulDecommissionTimeout'])) {\n            $request->setGracefulDecommissionTimeout($optionalArgs['gracefulDecommissionTimeout']);\n        }\n        if (isset($optionalArgs['requestId'])) {\n            $request->setRequestId($optionalArgs['requestId']);\n        }\n\n        return $this->startOperationsCall(\n            'UpdateCluster',\n            $optionalArgs,\n            $request,\n            $this->getOperationsClient()\n        )->wait();\n    }", "label": 2}
{"code": "public static function productName($project, $location, $product)\n    {\n        return self::getProductNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'product' => $product,\n        ]);\n    }", "label": 2}
{"code": "func (a *Allocator) DumpDatabase() string {\n\ta.Lock()\n\taspaces := make(map[string]*addrSpace, len(a.addrSpaces))\n\torderedAS := make([]string, 0, len(a.addrSpaces))\n\tfor as, aSpace := range a.addrSpaces {\n\t\torderedAS = append(orderedAS, as)\n\t\taspaces[as] = aSpace\n\t}\n\ta.Unlock()\n\n\tsort.Strings(orderedAS)\n\n\tvar s string\n\tfor _, as := range orderedAS {\n\t\taSpace := aspaces[as]\n\t\ts = fmt.Sprintf(\"\\n\\n%s Config\", as)\n\t\taSpace.Lock()\n\t\tfor k, config := range aSpace.subnets {\n\t\t\ts += fmt.Sprintf(\"\\n%v: %v\", k, config)\n\t\t\tif config.Range == nil {\n\t\t\t\ta.retrieveBitmask(k, config.Pool)\n\t\t\t}\n\t\t}\n\t\taSpace.Unlock()\n\t}\n\n\ts = fmt.Sprintf(\"%s\\n\\nBitmasks\", s)\n\tfor k, bm := range a.addresses {\n\t\ts += fmt.Sprintf(\"\\n%s: %s\", k, bm)\n\t}\n\n\treturn s\n}", "label": 5}
{"code": "private synchronized static Cluster getCluster(URI baseUrl, String[] personalities) throws IOException\n    {\n        final Entry<URI, Set<String>> key = Maps.immutableEntry(baseUrl, (Set<String>)ImmutableSet.copyOf(personalities));\n\n        Cluster result = CLUSTERS.get(key);\n        if (result != null) {\n            return result;\n        }\n\n        result = new Cluster(EmbeddedPostgreSQL.start());\n\n        final DBI dbi = new DBI(result.getPg().getTemplateDatabase());\n        final Migratory migratory = new Migratory(new MigratoryConfig() {}, dbi, dbi);\n        migratory.addLocator(new DatabasePreparerLocator(migratory, baseUrl));\n\n        final MigrationPlan plan = new MigrationPlan();\n        int priority = 100;\n\n        for (final String personality : personalities) {\n            plan.addMigration(personality, Integer.MAX_VALUE, priority--);\n        }\n\n        migratory.dbMigrate(plan);\n\n        result.start();\n\n        CLUSTERS.put(key, result);\n        return result;\n    }", "label": 0}
{"code": "function stringifyString( v , runtime , isTemplateSentence ) {\n\tvar maybeDollar = '' ;\n\n\tif ( isTemplateSentence ) {\n\t\tif ( v.key ) {\n\t\t\tv = v.key ;\n\t\t\tmaybeDollar = '$' ;\n\t\t}\n\t\telse {\n\t\t\truntime.str += runtime.depth ? ' <Sentence>' : '<Sentence>' ;\n\t\t\treturn ;\n\t\t}\n\t}\n\n\tif ( runtime.preferQuotes ) {\n\t\treturn stringifyStringMaybeQuotes( v , runtime , maybeDollar ) ;\n\t}\n\n\treturn stringifyStringMaybeStringLine( v , runtime , maybeDollar ) ;\n\n}", "label": 3}
{"code": "function jsnox(React) {\n    var client = function jsnoxClient(componentType, props, children) {\n        // Special $renderIf prop allows you to conditionally render an element:\n        //if (props && typeof props.$renderIf !== 'undefined') {\n        if (props && typeof props === 'object' && props.hasOwnProperty('$renderIf')) {\n            if (props.$renderIf) delete props.$renderIf     // Don't pass down to components\n            else return null\n        }\n\n        // Handle case where an array of children is given as the second argument:\n        if (Array.isArray(props) || typeof props !== 'object') {\n            children = props\n            props = null\n        }\n\n        // Handle case where props object (second arg) is omitted\n        var arg2IsReactElement = props && React.isValidElement(props)\n\n        var finalProps = props\n        if (typeof componentType === 'string' || !componentType) {\n            // Parse the provided string into a hash of props\n            // If componentType is invalid (undefined, empty string, etc),\n            // parseTagSpec should throw.\n            var spec = parseTagSpec(componentType)\n            componentType = spec.tagName\n            finalProps = arg2IsReactElement ? spec.props : extend(spec.props, props)\n        }\n\n        // If more than three args are given, assume args 3..n are ReactElement\n        // children. You can also pass an array of children as the 3rd argument,\n        // but in that case each child should have a unique key to avoid warnings.\n        var args = protoSlice.call(arguments)\n        if (args.length > 3 || arg2IsReactElement) {\n            args[0] = componentType\n            if (arg2IsReactElement) {\n                args.splice(1, 0, finalProps || null)\n            } else {\n                args[1] = finalProps\n            }\n            return React.createElement.apply(React, args)\n        } else {\n            return React.createElement(componentType, finalProps, children)\n        }\n    }\n    client.ParseError = ParseError\n    return client\n}", "label": 3}
{"code": "func (au *AuthUser) Delete(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !au._exists {\n\t\treturn nil\n\t}\n\n\t// if deleted, bail\n\tif au._deleted {\n\t\treturn nil\n\t}\n\n\t// sql query\n\tconst sqlstr = `DELETE FROM django.auth_user WHERE id = :1`\n\n\t// run query\n\tXOLog(sqlstr, au.ID)\n\t_, err = db.Exec(sqlstr, au.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// set deleted\n\tau._deleted = true\n\n\treturn nil\n}", "label": 5}
{"code": "func readAddrType(conn net.Conn) (int, error) {\n\t// Read in the type of the remote host.\n\taddrType, err := readByte(conn)\n\tif err != nil {\n\t\treturn 0, trace.Wrap(err)\n\t}\n\n\t// Based off the type, determine how many more bytes to read in for the\n\t// remote address. For IPv4 it's 4 bytes, for IPv6 it's 16, and for domain\n\t// names read in another byte to determine the length of the field.\n\tswitch addrType {\n\tcase socks5AddressTypeIPv4:\n\t\treturn net.IPv4len, nil\n\tcase socks5AddressTypeIPv6:\n\t\treturn net.IPv6len, nil\n\tcase socks5AddressTypeDomainName:\n\t\tlen, err := readByte(conn)\n\t\tif err != nil {\n\t\t\treturn 0, trace.Wrap(err)\n\t\t}\n\t\treturn int(len), nil\n\tdefault:\n\t\treturn 0, trace.BadParameter(\"unsupported address type: %v\", addrType)\n\t}\n}", "label": 5}
{"code": "def delete_own_reaction(reaction)\n      reaction = reaction.to_reaction if reaction.respond_to?(:to_reaction)\n      API::Channel.delete_own_reaction(@bot.token, @channel.id, @id, reaction)\n    end", "label": 4}
{"code": "protected function fireDriverEvents()\n    {\n        $driverEvent = $this->getDriver()->hasMatchingEvent();\n        if ($driverEvent instanceof DriverEventInterface) {\n            $this->firedDriverEvents = true;\n\n            Collection::make($this->events)->filter(function ($event) use ($driverEvent) {\n                return $driverEvent->getName() === $event['name'];\n            })->each(function ($event) use ($driverEvent) {\n                /**\n                 * Load the message, so driver events can reply.\n                 */\n                $messages = $this->getDriver()->getMessages();\n                if (isset($messages[0])) {\n                    $this->message = $messages[0];\n                }\n\n                \\call_user_func_array($event['callback'], [$driverEvent->getPayload(), $this]);\n            });\n        }\n    }", "label": 2}
{"code": "public static double Y(int n, double x) {\r\n        double by, bym, byp, tox;\r\n\r\n        if (n == 0) return Y0(x);\r\n        if (n == 1) return Y(x);\r\n\r\n        tox = 2.0 / x;\r\n        by = Y(x);\r\n        bym = Y0(x);\r\n        for (int j = 1; j < n; j++) {\r\n            byp = j * tox * by - bym;\r\n            bym = by;\r\n            by = byp;\r\n        }\r\n        return by;\r\n    }", "label": 0}
{"code": "def hour_of_day(*hours)\n      hours.flatten.each do |hour|\n        unless hour.is_a?(Integer)\n          raise ArgumentError, \"expecting Integer value for hour, got #{hour.inspect}\"\n        end\n\n        verify_alignment(hour, :hour, :hour_of_day) { |error| raise error }\n\n        validations_for(:hour_of_day) << Validation.new(hour)\n      end\n      clobber_base_validations(:hour)\n      self\n    end", "label": 4}
{"code": "public static base_responses add(nitro_service client, sslaction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslaction addresources[] = new sslaction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new sslaction();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].clientauth = resources[i].clientauth;\n\t\t\t\taddresources[i].clientcert = resources[i].clientcert;\n\t\t\t\taddresources[i].certheader = resources[i].certheader;\n\t\t\t\taddresources[i].clientcertserialnumber = resources[i].clientcertserialnumber;\n\t\t\t\taddresources[i].certserialheader = resources[i].certserialheader;\n\t\t\t\taddresources[i].clientcertsubject = resources[i].clientcertsubject;\n\t\t\t\taddresources[i].certsubjectheader = resources[i].certsubjectheader;\n\t\t\t\taddresources[i].clientcerthash = resources[i].clientcerthash;\n\t\t\t\taddresources[i].certhashheader = resources[i].certhashheader;\n\t\t\t\taddresources[i].clientcertissuer = resources[i].clientcertissuer;\n\t\t\t\taddresources[i].certissuerheader = resources[i].certissuerheader;\n\t\t\t\taddresources[i].sessionid = resources[i].sessionid;\n\t\t\t\taddresources[i].sessionidheader = resources[i].sessionidheader;\n\t\t\t\taddresources[i].cipher = resources[i].cipher;\n\t\t\t\taddresources[i].cipherheader = resources[i].cipherheader;\n\t\t\t\taddresources[i].clientcertnotbefore = resources[i].clientcertnotbefore;\n\t\t\t\taddresources[i].certnotbeforeheader = resources[i].certnotbeforeheader;\n\t\t\t\taddresources[i].clientcertnotafter = resources[i].clientcertnotafter;\n\t\t\t\taddresources[i].certnotafterheader = resources[i].certnotafterheader;\n\t\t\t\taddresources[i].owasupport = resources[i].owasupport;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (a *ArgType) NewTemplateFuncs() template.FuncMap {\n\treturn template.FuncMap{\n\t\t\"colcount\":           a.colcount,\n\t\t\"colnames\":           a.colnames,\n\t\t\"colnamesmulti\":      a.colnamesmulti,\n\t\t\"colnamesquery\":      a.colnamesquery,\n\t\t\"colnamesquerymulti\": a.colnamesquerymulti,\n\t\t\"colprefixnames\":     a.colprefixnames,\n\t\t\"colvals\":            a.colvals,\n\t\t\"colvalsmulti\":       a.colvalsmulti,\n\t\t\"fieldnames\":         a.fieldnames,\n\t\t\"fieldnamesmulti\":    a.fieldnamesmulti,\n\t\t\"goparamlist\":        a.goparamlist,\n\t\t\"reniltype\":          a.reniltype,\n\t\t\"retype\":             a.retype,\n\t\t\"shortname\":          a.shortname,\n\t\t\"convext\":            a.convext,\n\t\t\"schema\":             a.schemafn,\n\t\t\"colname\":            a.colname,\n\t\t\"hascolumn\":          a.hascolumn,\n\t\t\"hasfield\":           a.hasfield,\n\t\t\"getstartcount\":      a.getstartcount,\n\t}\n}", "label": 5}
{"code": "public function findElement(WebDriverBy $by)\n    {\n        $params = ['using' => $by->getMechanism(), 'value' => $by->getValue()];\n        $raw_element = $this->execute(\n            DriverCommand::FIND_ELEMENT,\n            $params\n        );\n\n        return $this->newElement($raw_element['ELEMENT']);\n    }", "label": 2}
{"code": "public String getDependencyJsonModel() throws IOException {\n        final Artifact artifact = DataModelFactory.createArtifact(\"\",\"\",\"\",\"\",\"\",\"\",\"\");\n        return JsonUtils.serialize(DataModelFactory.createDependency(artifact, Scope.COMPILE));\n    }", "label": 0}
{"code": "def sam2fastq(sam, singles = False, force = False):\n    \"\"\"\n    convert sam to fastq\n    \"\"\"\n    L, R = None, None\n    for line in sam:\n        if line.startswith('@') is True:\n            continue\n        line = line.strip().split()\n        bit = [True if i == '1' else False \\\n                for i in bin(int(line[1])).split('b')[1][::-1]]\n        while len(bit) < 8:\n            bit.append(False)\n        pair, proper, na, nap, rev, mrev, left, right = bit\n        # make sure read is paired\n        if pair is False:\n            if singles is True:\n                print_single(line, rev)\n            continue\n        # check if sequence is reverse-complemented\n        if rev is True:\n            seq = rc(['', line[9]])[1]\n            qual = line[10][::-1]\n        else:\n            seq = line[9]\n            qual = line[10]\n        # check if read is forward or reverse, return when both have been found\n        if left is True:\n            if L is not None and force is False:\n                print('sam file is not sorted', file = sys.stderr)\n                print('\\te.g.: %s' % (line[0]), file = sys.stderr)\n                exit()\n            if L is not None:\n                L = None\n                continue\n            L = ['@%s' % line[0], seq, '+%s' % line[0], qual]\n            if R is not None:\n                yield L\n                yield R\n                L, R = None, None\n        if right is True:\n            if R is not None and force is False:\n                print('sam file is not sorted', file = sys.stderr)\n                print('\\te.g.: %s' % (line[0]), file = sys.stderr)\n                exit()\n            if R is not None:\n                R = None\n                continue\n            R = ['@%s' % line[0], seq, '+%s' % line[0], qual]\n            if L is not None:\n                yield L\n                yield R\n                L, R = None, None", "label": 1}
{"code": "function _getSibling(target, dir, filter, options) {\n    let match;\n\n    $each(target, (el) => {\n        const index = $index(el) + dir;\n\n        $children($parent(el)).forEach((el, i) => {\n            if (i === index &&\n                (! filter || filter && $is(el, filter, options))) {\n                match = el;\n            }\n        });\n    });\n\n    return match;\n}", "label": 3}
{"code": "func initExternalLog(auditConfig services.AuditConfig) (events.IAuditLog, error) {\n\tif auditConfig.AuditTableName != \"\" {\n\t\tlog.Warningf(\"Please note that 'audit_table_name' is deprecated and will be removed in several releases. Use audit_events_uri: '%v://%v' instead.\", dynamo.GetName(), auditConfig.AuditTableName)\n\t\tif len(auditConfig.AuditEventsURI) != 0 {\n\t\t\treturn nil, trace.BadParameter(\"Detected configuration specifying 'audit_table_name' and 'audit_events_uri' at the same time. Please migrate your config to use 'audit_events_uri' only.\")\n\t\t}\n\t\tauditConfig.AuditEventsURI = []string{fmt.Sprintf(\"%v://%v\", dynamo.GetName(), auditConfig.AuditTableName)}\n\t}\n\tif len(auditConfig.AuditEventsURI) > 0 && !auditConfig.ShouldUploadSessions() {\n\t\treturn nil, trace.BadParameter(\"please specify audit_sessions_uri when using external audit backends\")\n\t}\n\tvar hasNonFileLog bool\n\tvar loggers []events.IAuditLog\n\tfor _, eventsURI := range auditConfig.AuditEventsURI {\n\t\turi, err := utils.ParseSessionsURI(eventsURI)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tswitch uri.Scheme {\n\t\tcase dynamo.GetName():\n\t\t\thasNonFileLog = true\n\t\t\tlogger, err := dynamoevents.New(dynamoevents.Config{\n\t\t\t\tTablename: uri.Host,\n\t\t\t\tRegion:    auditConfig.Region,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\tloggers = append(loggers, logger)\n\t\tcase teleport.SchemeFile:\n\t\t\tif err := os.MkdirAll(uri.Path, teleport.SharedDirMode); err != nil {\n\t\t\t\treturn nil, trace.ConvertSystemError(err)\n\t\t\t}\n\t\t\tlogger, err := events.NewFileLog(events.FileLogConfig{\n\t\t\t\tDir: uri.Path,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\tloggers = append(loggers, logger)\n\t\tdefault:\n\t\t\treturn nil, trace.BadParameter(\n\t\t\t\t\"unsupported scheme for audit_events_uri: %q, currently supported schemes are %q and %q\",\n\t\t\t\turi.Scheme, dynamo.GetName(), teleport.SchemeFile)\n\t\t}\n\t}\n\t// only file external loggers are prohibited (they are not supposed\n\t// to be used on their own, only in combo with external loggers)\n\t// they also don't implement certain features, so they are going\n\t// to be inefficient\n\tswitch len(loggers) {\n\tcase 0:\n\t\treturn nil, trace.NotFound(\"no external log is defined\")\n\tcase 1:\n\t\tif !hasNonFileLog {\n\t\t\treturn nil, trace.BadParameter(\"file:// log can not be used on it's own, can be only used in combination with external session logs, e.g. dynamodb://\")\n\t\t}\n\t\treturn loggers[0], nil\n\tdefault:\n\t\tif !hasNonFileLog {\n\t\t\treturn nil, trace.BadParameter(\"file:// log can not be used on it's own, can be only used in combination with external session logs, e.g. dynamodb://\")\n\t\t}\n\t\treturn events.NewMultiLog(loggers...), nil\n\t}\n}", "label": 5}
{"code": "def getdirs(self, section, option, raw=False, vars=None, fallback=[]):\n        \"\"\"\n        A convenience method which coerces the option in the specified section to a list of directories.\n        \"\"\"\n        globs = self.getlist(section, option, fallback=[])\n        return [f for g in globs for f in glob.glob(g) if os.path.isdir(f)]", "label": 1}
{"code": "func OptionLocalKVProviderConfig(config *store.Config) Option {\n\treturn func(c *Config) {\n\t\tlogrus.Debugf(\"Option OptionLocalKVProviderConfig: %v\", config)\n\t\tif _, ok := c.Scopes[datastore.LocalScope]; !ok {\n\t\t\tc.Scopes[datastore.LocalScope] = &datastore.ScopeCfg{}\n\t\t}\n\t\tc.Scopes[datastore.LocalScope].Client.Config = config\n\t}\n}", "label": 5}
{"code": "public function setProjection($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Datastore\\V1\\Projection::class);\n        $this->projection = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (cl *Client) publicAddr(peer net.IP) IpPort {\n\treturn IpPort{cl.publicIp(peer), uint16(cl.incomingPeerPort())}\n}", "label": 5}
{"code": "public Object toInternal(Attribute<?> attribute) throws GeomajasException {\n\t\tif (attribute instanceof PrimitiveAttribute<?>) {\n\t\t\treturn toPrimitiveObject((PrimitiveAttribute<?>) attribute);\n\t\t} else if (attribute instanceof AssociationAttribute<?>) {\n\t\t\treturn toAssociationObject((AssociationAttribute<?>) attribute);\n\t\t} else {\n\t\t\tthrow new GeomajasException(ExceptionCode.CONVERSION_PROBLEM, attribute);\n\t\t}\n\t}", "label": 0}
{"code": "def createArchiveExample(fileName):\n    \"\"\" Creates Combine Archive containing the given file.\n\n    :param fileName: file to include in the archive\n    :return: None\n    \"\"\"\n    print('*' * 80)\n    print('Create archive')\n    print('*' * 80)\n\n    archive = CombineArchive()\n    archive.addFile(\n        fileName,  # filename\n        \"./models/model.xml\",  # target file name\n        KnownFormats.lookupFormat(\"sbml\"),  # look up identifier for SBML models\n        True  # mark file as master\n    )\n\n    # add metadata to the archive itself\n    description = OmexDescription()\n    description.setAbout(\".\")\n    description.setDescription(\"Simple test archive including one SBML model\")\n    description.setCreated(OmexDescription.getCurrentDateAndTime())\n\n    creator = VCard()\n    creator.setFamilyName(\"Bergmann\")\n    creator.setGivenName(\"Frank\")\n    creator.setEmail(\"fbergman@caltech.edu\")\n    creator.setOrganization(\"Caltech\")\n\n    description.addCreator(creator)\n\n    archive.addMetadata(\".\", description)\n\n    # add metadata to the added file\n    location = \"./models/model.xml\"\n    description = OmexDescription()\n    description.setAbout(location)\n    description.setDescription(\"SBML model\")\n    description.setCreated(OmexDescription.getCurrentDateAndTime())\n    archive.addMetadata(location, description)\n\n    # write the archive\n    out_file = \"out.omex\"\n    archive.writeToFile(out_file)\n\n    print('Archive created:', out_file)", "label": 1}
{"code": "protected function executeBatched(GraphQLRequest $request): array\n    {\n        $results = [];\n        do {\n            $results[] = $this->graphQL->executeRequest($request);\n        } while ($request->advanceBatchIndex());\n\n        return $results;\n    }", "label": 2}
{"code": "func (t *Torrent) consumeDhtAnnouncePeers(pvs <-chan dht.PeersValues) {\n\tcl := t.cl\n\tfor v := range pvs {\n\t\tcl.lock()\n\t\tfor _, cp := range v.Peers {\n\t\t\tif cp.Port == 0 {\n\t\t\t\t// Can't do anything with this.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tt.addPeer(Peer{\n\t\t\t\tIP:     cp.IP[:],\n\t\t\t\tPort:   cp.Port,\n\t\t\t\tSource: peerSourceDHTGetPeers,\n\t\t\t})\n\t\t}\n\t\tcl.unlock()\n\t}\n}", "label": 5}
{"code": "def get_ssm_parameter(parameter_name):\n    '''\n    Get the decrypted value of an SSM parameter\n\n    Args:\n        parameter_name - the name of the stored parameter of interest\n\n    Return:\n        Value if allowed and present else None\n    '''\n    try:\n        response = boto3.client('ssm').get_parameters(\n            Names=[parameter_name],\n            WithDecryption=True\n        )\n\n        return response.get('Parameters', None)[0].get('Value', '')\n    except Exception:\n        pass\n\n    return ''", "label": 1}
{"code": "private function handleSentinelErrorResponse(NodeConnectionInterface $sentinel, ErrorResponseInterface $error)\n    {\n        if ($error->getErrorType() === 'IDONTKNOW') {\n            throw new ConnectionException($sentinel, $error->getMessage());\n        } else {\n            throw new ServerException($error->getMessage());\n        }\n    }", "label": 2}
{"code": "public static boolean containsOnlyNotNull(Object... values){\t\n\t\tfor(Object o : values){\n\t\t\tif(o== null){\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "label": 0}
{"code": "function objectSchema(obj) {\n  const props = Object.entries(obj).reduce(\n    (reduced, [key, val]) => Object.assign(reduced, { [key]: typeof val }),\n    {}\n  );\n  return props;\n}", "label": 3}
{"code": "def percentile(self, lst_data, percent , key=lambda x:x):\n        \"\"\" calculates the 'num' percentile of the items in the list \"\"\"\n        new_list = sorted(lst_data)\n        #print('new list = ' , new_list)\n        #n = float(len(lst_data))\n        k = (len(new_list)-1) * percent\n        f = math.floor(k)\n        c = math.ceil(k)\n        if f == c:\n            #print(key(new_list[int(k)]))\n            return key(new_list[int(k)])\n        d0 = float(key(new_list[int(f)])) * (c-k)\n        d1 = float(key(new_list[int(c)])) * (k-f)\n        return d0+d1", "label": 1}
{"code": "func (s *APIServer) getReverseTunnels(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\treverseTunnels, err := auth.GetReverseTunnels()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\titems := make([]json.RawMessage, len(reverseTunnels))\n\tfor i, tunnel := range reverseTunnels {\n\t\tdata, err := services.GetReverseTunnelMarshaler().MarshalReverseTunnel(tunnel, services.WithVersion(version), services.PreserveResourceID())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\titems[i] = data\n\t}\n\treturn items, nil\n}", "label": 5}
{"code": "public void bind(T service, Map<String, Object> props) {\n    synchronized (serviceMap) {\n      serviceMap.put(ServiceUtil.getComparableForServiceRanking(props), service);\n      updateSortedServices();\n    }\n  }", "label": 0}
{"code": "func (s *PresenceService) DeleteTunnelConnections(clusterName string) error {\n\tif clusterName == \"\" {\n\t\treturn trace.BadParameter(\"missing cluster name\")\n\t}\n\tstartKey := backend.Key(tunnelConnectionsPrefix, clusterName)\n\terr := s.DeleteRange(context.TODO(), startKey, backend.RangeEnd(startKey))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def creator(_, config):\n        \"\"\"Creator function for creating an instance of a Packer image script.\"\"\"\n        packer_script = render(config.script, model=config.model, env=config.env,\n                               variables=config.variables, item=config.item)\n        filename = \"packer.dry.run.see.comment\"\n\n        if not config.dry_run:\n            # writing Packer file (JSON)\n            filename = write_temporary_file(packer_script, 'packer-', '.json')\n            packer_script = ''\n\n        # rendering the Bash script for generating the Packer image\n        template_file = os.path.join(os.path.dirname(__file__), 'templates/packer-image.sh.j2')\n\n        with open(template_file) as handle:\n            template = handle.read()\n            config.script = render(template, debug=config.debug,\n                                   packer_content=packer_script,\n                                   packer_filename=filename)\n\n        return Packer(config)", "label": 1}
{"code": "public function state(User $user = null)\n    {\n        $user = $user ?: static::$stateUser;\n\n        return $this->hasOne(UserState::class)->where('user_id', $user ? $user->id : null);\n    }", "label": 2}
{"code": "public void build(Point3d[] points, int nump) throws IllegalArgumentException {\n        if (nump < 4) {\n            throw new IllegalArgumentException(\"Less than four input points specified\");\n        }\n        if (points.length < nump) {\n            throw new IllegalArgumentException(\"Point array too small for specified number of points\");\n        }\n        initBuffers(nump);\n        setPoints(points, nump);\n        buildHull();\n    }", "label": 0}
{"code": "def colorize(printable, color, style='normal', autoreset=True):\n    \"\"\"Colorize some message with ANSI colors specification\n\n    :param printable: interface whose has __str__ or __repr__ method\n    :param color: the colors defined in COLOR_MAP to colorize the text\n    :style: can be 'normal', 'bold' or 'underline'\n\n    :returns: the 'printable' colorized with style\n    \"\"\"\n    if not COLORED:  # disable color\n        return printable\n    if color not in COLOR_MAP:\n        raise RuntimeError('invalid color set, no {}'.format(color))\n\n    return '{color}{printable}{reset}'.format(\n        printable=printable,\n        color=COLOR_MAP[color].format(style=STYLE_MAP[style]),\n        reset=COLOR_MAP['reset'] if autoreset else ''\n    )", "label": 1}
{"code": "func (e Env) MarshalManual() string {\n\tvar buffer bytes.Buffer\n\n\tbuffer.WriteString(xml.Header)\n\tbuffer.WriteString(fmt.Sprintf(ovfEnvHeader, e.EsxID))\n\tbuffer.WriteString(fmt.Sprintf(ovfEnvPlatformSection, e.Platform.Kind, e.Platform.Version, e.Platform.Vendor, e.Platform.Locale))\n\n\tbuffer.WriteString(fmt.Sprint(ovfEnvPropertyHeader))\n\tfor _, p := range e.Property.Properties {\n\t\tbuffer.WriteString(fmt.Sprintf(ovfEnvPropertyEntry, p.Key, p.Value))\n\t}\n\tbuffer.WriteString(fmt.Sprint(ovfEnvPropertyFooter))\n\n\tbuffer.WriteString(fmt.Sprint(ovfEnvFooter))\n\n\treturn buffer.String()\n}", "label": 5}
{"code": "public static function getSizeFromName($name)\n\t{\n\t\t$format = strtoupper($name);\n\t\t$formats = [\n\t\t\t'4A0' => [4767.87, 6740.79],\n\t\t\t'2A0' => [3370.39, 4767.87],\n\t\t\t'A0' => [2383.94, 3370.39],\n\t\t\t'A1' => [1683.78, 2383.94],\n\t\t\t'A2' => [1190.55, 1683.78],\n\t\t\t'A3' => [841.89, 1190.55],\n\t\t\t'A4' => [595.28, 841.89],\n\t\t\t'A5' => [419.53, 595.28],\n\t\t\t'A6' => [297.64, 419.53],\n\t\t\t'A7' => [209.76, 297.64],\n\t\t\t'A8' => [147.40, 209.76],\n\t\t\t'A9' => [104.88, 147.40],\n\t\t\t'A10' => [73.70, 104.88],\n\t\t\t'B0' => [2834.65, 4008.19],\n\t\t\t'B1' => [2004.09, 2834.65],\n\t\t\t'B2' => [1417.32, 2004.09],\n\t\t\t'B3' => [1000.63, 1417.32],\n\t\t\t'B4' => [708.66, 1000.63],\n\t\t\t'B5' => [498.90, 708.66],\n\t\t\t'B6' => [354.33, 498.90],\n\t\t\t'B7' => [249.45, 354.33],\n\t\t\t'B8' => [175.75, 249.45],\n\t\t\t'B9' => [124.72, 175.75],\n\t\t\t'B10' => [87.87, 124.72],\n\t\t\t'C0' => [2599.37, 3676.54],\n\t\t\t'C1' => [1836.85, 2599.37],\n\t\t\t'C2' => [1298.27, 1836.85],\n\t\t\t'C3' => [918.43, 1298.27],\n\t\t\t'C4' => [649.13, 918.43],\n\t\t\t'C5' => [459.21, 649.13],\n\t\t\t'C6' => [323.15, 459.21],\n\t\t\t'C7' => [229.61, 323.15],\n\t\t\t'C8' => [161.57, 229.61],\n\t\t\t'C9' => [113.39, 161.57],\n\t\t\t'C10' => [79.37, 113.39],\n\t\t\t'RA0' => [2437.80, 3458.27],\n\t\t\t'RA1' => [1729.13, 2437.80],\n\t\t\t'RA2' => [1218.90, 1729.13],\n\t\t\t'RA3' => [864.57, 1218.90],\n\t\t\t'RA4' => [609.45, 864.57],\n\t\t\t'SRA0' => [2551.18, 3628.35],\n\t\t\t'SRA1' => [1814.17, 2551.18],\n\t\t\t'SRA2' => [1275.59, 1814.17],\n\t\t\t'SRA3' => [907.09, 1275.59],\n\t\t\t'SRA4' => [637.80, 907.09],\n\t\t\t'LETTER' => [612.00, 792.00],\n\t\t\t'LEGAL' => [612.00, 1008.00],\n\t\t\t'LEDGER' => [1224.00, 792.00],\n\t\t\t'TABLOID' => [792.00, 1224.00],\n\t\t\t'EXECUTIVE' => [521.86, 756.00],\n\t\t\t'FOLIO' => [612.00, 936.00],\n\t\t\t'B' => [362.83, 561.26], // 'B' format paperback size 128x198mm\n\t\t\t'A' => [314.65, 504.57], // 'A' format paperback size 111x178mm\n\t\t\t'DEMY' => [382.68, 612.28], // 'Demy' format paperback size 135x216mm\n\t\t\t'ROYAL' => [433.70, 663.30], // 'Royal' format paperback size 153x234mm\n\t\t];\n\n\t\tif (!isset($formats[$format])) {\n\t\t\tthrow new \\Mpdf\\MpdfException(sprintf('Unknown page format %s', $format));\n\t\t}\n\n\t\treturn $formats[$format];\n\t}", "label": 2}
{"code": "func (*TeleportGithubConnectorMarshaler) Marshal(c GithubConnector, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch resource := c.(type) {\n\tcase *GithubConnectorV3:\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *resource\n\t\t\tcopy.SetResourceID(0)\n\t\t\tresource = &copy\n\t\t}\n\t\treturn utils.FastMarshal(resource)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"unrecognized resource version %T\", c)\n\t}\n}", "label": 5}
{"code": "public BeanDefinitionInfo toDto(BeanDefinition beanDefinition) {\n\t\tif (beanDefinition instanceof GenericBeanDefinition) {\n\t\t\tGenericBeanDefinitionInfo info = new GenericBeanDefinitionInfo();\n\t\t\tinfo.setClassName(beanDefinition.getBeanClassName());\n\n\t\t\tif (beanDefinition.getPropertyValues() != null) {\n\t\t\t\tMap<String, BeanMetadataElementInfo> propertyValues = new HashMap<String, BeanMetadataElementInfo>();\n\t\t\t\tfor (PropertyValue value : beanDefinition.getPropertyValues().getPropertyValueList()) {\n\t\t\t\t\tObject obj = value.getValue();\n\t\t\t\t\tif (obj instanceof BeanMetadataElement) {\n\t\t\t\t\t\tpropertyValues.put(value.getName(), toDto((BeanMetadataElement) obj));\n\t\t\t\t\t} else {\n\t\t\t\t\t\tthrow new IllegalArgumentException(\"Type \" + obj.getClass().getName()\n\t\t\t\t\t\t\t\t+ \" is not a BeanMetadataElement for property: \" + value.getName());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tinfo.setPropertyValues(propertyValues);\n\t\t\t}\n\t\t\treturn info;\n\t\t} else {\n\t\t\tthrow new IllegalArgumentException(\"Conversion to DTO of \" + beanDefinition.getClass().getName()\n\t\t\t\t\t+ \" not implemented\");\n\t\t}\n\t}", "label": 0}
{"code": "def to_xml_string(str = '')\n      str << '<colorScale>'\n      value_objects.to_xml_string(str)\n      colors.each { |color| color.to_xml_string(str) }\n      str << '</colorScale>'\n    end", "label": 4}
{"code": "function processImpedanceData (o) {\n  const byteId = parseInt(o.rawDataPacket[0]);\n  let channelNumber;\n  switch (byteId) {\n    case k.OBCIGanglionByteIdImpedanceChannel1:\n      channelNumber = 1;\n      break;\n    case k.OBCIGanglionByteIdImpedanceChannel2:\n      channelNumber = 2;\n      break;\n    case k.OBCIGanglionByteIdImpedanceChannel3:\n      channelNumber = 3;\n      break;\n    case k.OBCIGanglionByteIdImpedanceChannel4:\n      channelNumber = 4;\n      break;\n    case k.OBCIGanglionByteIdImpedanceChannelReference:\n      channelNumber = 0;\n      break;\n  }\n\n  let output = {\n    channelNumber: channelNumber,\n    impedanceValue: 0\n  };\n\n  let end = o.rawDataPacket.length;\n\n  while (Number.isNaN(Number(o.rawDataPacket.slice(1, end))) && end !== 0) {\n    end--;\n  }\n\n  if (end !== 0) {\n    output.impedanceValue = Number(o.rawDataPacket.slice(1, end));\n  }\n\n  return output;\n}", "label": 3}
{"code": "public function setBigQueryField($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\BigQueryField::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static systemuser_systemcmdpolicy_binding[] get(nitro_service service, String username) throws Exception{\n\t\tsystemuser_systemcmdpolicy_binding obj = new systemuser_systemcmdpolicy_binding();\n\t\tobj.set_username(username);\n\t\tsystemuser_systemcmdpolicy_binding response[] = (systemuser_systemcmdpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static void main(String[] args) throws Exception {\r\n    StringUtils.printErrInvocationString(\"CMMClassifier\", args);\r\n\r\n    Properties props = StringUtils.argsToProperties(args);\r\n    CMMClassifier cmm = new CMMClassifier<CoreLabel>(props);\r\n    String testFile = cmm.flags.testFile;\r\n    String textFile = cmm.flags.textFile;\r\n    String loadPath = cmm.flags.loadClassifier;\r\n    String serializeTo = cmm.flags.serializeTo;\r\n\r\n    // cmm.crossValidateTrainAndTest(trainFile);\r\n    if (loadPath != null) {\r\n      cmm.loadClassifierNoExceptions(loadPath, props);\r\n    } else if (cmm.flags.loadJarClassifier != null) {\r\n      cmm.loadJarClassifier(cmm.flags.loadJarClassifier, props);\r\n    } else if (cmm.flags.trainFile != null) {\r\n      if (cmm.flags.biasedTrainFile != null) {\r\n        cmm.trainSemiSup();\r\n      } else {\r\n        cmm.train();\r\n      }\r\n    } else {\r\n      cmm.loadDefaultClassifier();\r\n    }\r\n\r\n    if (serializeTo != null) {\r\n      cmm.serializeClassifier(serializeTo);\r\n    }\r\n\r\n    if (testFile != null) {\r\n      cmm.classifyAndWriteAnswers(testFile, cmm.makeReaderAndWriter());\r\n    } else if (cmm.flags.testFiles != null) {\r\n      cmm.classifyAndWriteAnswers(cmm.flags.baseTestDir, cmm.flags.testFiles,\r\n                                  cmm.makeReaderAndWriter());\r\n    }\r\n\r\n    if (textFile != null) {\r\n      DocumentReaderAndWriter readerAndWriter =\r\n        new PlainTextDocumentReaderAndWriter();\r\n      cmm.classifyAndWriteAnswers(textFile, readerAndWriter);\r\n    }\r\n  }", "label": 0}
{"code": "def start_daemon():\n        \"\"\"\n        Start a thread to continuously read log files and append lines in DB.\n\n        Work in progress. Currently the thread doesn't append anything,\n        it only print the information parsed from each line read.\n\n        Returns:\n            thread: the started thread.\n        \"\"\"\n        if RequestLog.daemon is None:\n            parser = get_nginx_parser()\n            RequestLog.daemon = RequestLog.ParseToDBThread(parser, daemon=True)\n        RequestLog.daemon.start()\n        return RequestLog.daemon", "label": 1}
{"code": "def getjp2image(date,\n                sourceId=None,\n                observatory=None,\n                instrument=None,\n                detector=None,\n                measurement=None):\n    '''\n    Helioviewer.org and JHelioviewer operate off of JPEG2000 formatted image data generated from science-quality FITS files. Use the APIs below to interact directly with these intermediary JPEG2000 files.\n    \n    Download a JP2 image for the specified datasource that is the closest match in time to the `date` requested.\n\n    Either `sourceId` must be specified, or the combination of `observatory`, `instrument`, `detector`, and `measurement`.\n\n    Request Parameters:\n\n    Parameter\tRequired\tType\tExample\tDescription\n    date\tRequired\tstring\t2014-01-01T23:59:59Z\tDesired date/time of the JP2 image. ISO 8601 combined UTC date and time UTC format.\n    sourceId\tOptional\tnumber\t14\tUnique image datasource identifier.\n    observatory\tOptional\tstring\tSDO\tObservatory name.\n    instrument\tOptional\tstring\tAIA\tInstrument name.\n    detector\tOptional\tstring\tAIA\tDetector name.\n    measurement\tOptional\tstring\t335\tMeasurement name.\n    jpip\tOptional\tboolean\tfalse\tOptionally return a JPIP URI instead of the binary data of the image itself.\n    json\tOptional\tboolean\tfalse\tOptionally return a JSON object.\n\n\n    EXAMPLE: http://helioviewer.org/api/v1/getJP2Image/?date=2014-01-01T23:59:59Z&sourceId=14&jpip=true\n    '''\n\n    base_url = 'http://helioviewer.org/api/v1/getJP2Image/?'\n    req_url = ''\n\n    try:\n        validate_iso8601(date)\n        if not date[-1:] == 'Z':\n            date += 'Z'\n        base_url += 'date=' + date\n    except:\n        raise ValueError(\n            \"Your date input is not in iso8601 format. ex: 2014-01-01T23:59:59\")\n\n    if sourceId:\n        if not isinstance(sourceId, int):\n            logger.error(\"The sourceId argument should be an int, ignoring it\")\n        else:\n            base_url += \"sourceId=\" + str(sourceId) + \"&\"\n\n    if observatory:\n        if not isinstance(observatory, str):\n            logger.error(\n                \"The observatory argument should be a str, ignoring it\")\n        else:\n            base_url += \"observatory=\" + observatory + \"&\"\n\n    if instrument:\n        if not isinstance(instrument, str):\n            logger.error(\n                \"The instrument argument should be a str, ignoring it\")\n        else:\n            base_url += \"instrument=\" + instrument + \"&\"\n    if detector:\n        if not isinstance(detector, str):\n            logger.error(\"The detector argument should be a str, ignoring it\")\n        else:\n            base_url += \"detector=\" + detector + \"&\"\n\n    if measurement:\n        if not isinstance(measurement, str):\n            logger.error(\n                \"The measurement argument should be a str, ignoring it\")\n        else:\n            base_url += \"measurement=\" + detector + \"&\"\n\n    req_url += base_url + \"jpip=true\"\n\n    return dispatch_http_get(req_url)", "label": 1}
{"code": "def get_audio_metadata_old(fname):\n    \"\"\" retrieve the metadata from an MP3 file \"\"\"\n    audio_dict = {}\n    print(\"IDv2 tag info for %s:\" % fname)\n    try:\n        audio = mutagenx.id3.ID3(fname, translate=False)\n    except StandardError as err:\n        print(\"ERROR = \" + str(err))\n    #else:\n        #print(audio.pprint().encode(\"utf-8\", \"replace\"))\n        #for frame in audio.values():\n        #    print(repr(frame))\n    \n    try:\n        audio_dict[\"title\"] = audio[\"title\"]\n    except KeyError:\n        print(\"No title\")\n        \n    try:\n        audio_dict[\"artist\"] = audio[\"artist\"] # tags['TPE1'] \n    except KeyError:\n        print(\"No artist\")\n        \n    try:\n        audio_dict[\"album\"] = audio[\"album\"]\n    except KeyError:\n        print(\"No album\")\n        \n    try:\n        audio_dict[\"length\"] = audio[\"length\"]\n    except KeyError:\n        print(\"No length\")\n        \n    #pprint.pprint(audio.tags)\n        \n    return audio_dict", "label": 1}
{"code": "function _gpfFsExploreEnumerator(iFileStorage, listOfPaths) {\n        var pos = GPF_FS_EXPLORE_BEFORE_START, info;\n        return {\n            reset: function () {\n                pos = GPF_FS_EXPLORE_BEFORE_START;\n                return Promise.resolve();\n            },\n            moveNext: function () {\n                ++pos;\n                info = undefined;\n                if (pos < listOfPaths.length) {\n                    return iFileStorage.getInfo(listOfPaths[pos]).then(function (fsInfo) {\n                        info = fsInfo;\n                        return info;\n                    });\n                }\n                return Promise.resolve();\n            },\n            getCurrent: function () {\n                return info;\n            }\n        };\n    }", "label": 3}
{"code": "public function resumeOperation($operationName, array $info = [])\n    {\n        return new LongRunningOperation(\n            $this->lroConnection,\n            $operationName,\n            $this->lroCallables,\n            $info\n        );\n    }", "label": 2}
{"code": "def process_delivery(message, notification):\n    \"\"\"Function to process a delivery notification\"\"\"\n    mail = message['mail']\n    delivery = message['delivery']\n\n    if 'timestamp' in delivery:\n        delivered_datetime = clean_time(delivery['timestamp'])\n    else:\n        delivered_datetime = None\n\n    deliveries = []\n    for eachrecipient in delivery['recipients']:\n        # Create each delivery \n        deliveries += [Delivery.objects.create(\n            sns_topic=notification['TopicArn'],\n            sns_messageid=notification['MessageId'],\n            mail_timestamp=clean_time(mail['timestamp']),\n            mail_id=mail['messageId'],\n            mail_from=mail['source'],\n            address=eachrecipient,\n            # delivery\n            delivered_time=delivered_datetime,\n            processing_time=int(delivery['processingTimeMillis']),\n            smtp_response=delivery['smtpResponse']\n        )]\n\n    # Send signals for each delivery.\n    for eachdelivery in deliveries:\n        signals.feedback.send(\n            sender=Delivery,\n            instance=eachdelivery,\n            message=message,\n            notification=notification\n        )\n\n    logger.info('Logged %s Deliveries(s)', str(len(deliveries)))\n\n    return HttpResponse('Delivery Processed')", "label": 1}
{"code": "function exportProjects(req, res, next) {\n  var options = req.connectionOptions;\n\n  forms.exportAppForms(options, formsResultHandlers(constants.resultTypes.formProjects, req, next));\n}", "label": 3}
{"code": "public void forAllExtents(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (Iterator it = _curClassDef.getExtentClasses(); it.hasNext(); )\r\n        {\r\n            _curExtent = (ClassDescriptorDef)it.next();\r\n            generate(template);\r\n        }\r\n        _curExtent = null;\r\n    }", "label": 0}
{"code": "@Modified(id = \"exporterServices\")\n    void modifiedExporterService(ServiceReference<ExporterService> serviceReference) {\n        try {\n            exportersManager.modified(serviceReference);\n        } catch (InvalidFilterException invalidFilterException) {\n            LOG.error(\"The ServiceProperty \\\"\" + TARGET_FILTER_PROPERTY + \"\\\" of the ExporterService \"\n                            + bundleContext.getService(serviceReference) + \" doesn't provides a valid Filter.\"\n                            + \" To be used, it must provides a correct \\\"\" + TARGET_FILTER_PROPERTY + \"\\\" ServiceProperty.\",\n                    invalidFilterException\n            );\n            exportersManager.removeLinks(serviceReference);\n            return;\n        }\n        if (exportersManager.matched(serviceReference)) {\n            exportersManager.updateLinks(serviceReference);\n        } else {\n            exportersManager.removeLinks(serviceReference);\n        }\n    }", "label": 0}
{"code": "private function decodeValue($value, array $type)\n    {\n        if ($value === null || $value === '') {\n            return $value;\n        }\n\n        switch ($type['code']) {\n            case self::TYPE_INT64:\n                $value = $this->returnInt64AsObject\n                    ? new Int64($value)\n                    : (int) $value;\n                break;\n\n            case self::TYPE_TIMESTAMP:\n                $value = $this->parseTimeString($value);\n                $value = new Timestamp($value[0], $value[1]);\n                break;\n\n            case self::TYPE_DATE:\n                $value = new Date(new \\DateTimeImmutable($value));\n                break;\n\n            case self::TYPE_BYTES:\n                $value = new Bytes(base64_decode($value));\n                break;\n\n            case self::TYPE_ARRAY:\n                $res = [];\n                foreach ($value as $item) {\n                    $res[] = $this->decodeValue($item, $type['arrayElementType']);\n                }\n\n                $value = $res;\n                break;\n\n            case self::TYPE_STRUCT:\n                $fields = isset($type['structType']['fields'])\n                    ? $type['structType']['fields']\n                    : [];\n\n                $value = $this->decodeValues($fields, $value, Result::RETURN_ASSOCIATIVE);\n                break;\n\n            case self::TYPE_FLOAT64:\n                // NaN, Infinite and -Infinite are possible FLOAT64 values,\n                // but when the gRPC response is decoded, they are represented\n                // as strings. This conditional checks for a string, converts to\n                // an equivalent double value, or dies if something really weird\n                // happens.\n                if (is_string($value)) {\n                    switch ($value) {\n                        case 'NaN':\n                            $value = NAN;\n                            break;\n\n                        case 'Infinity':\n                            $value = INF;\n                            break;\n\n                        case '-Infinity':\n                            $value = -INF;\n                            break;\n\n                        default:\n                            throw new \\RuntimeException(sprintf(\n                                'Unexpected string value %s encountered in FLOAT64 field.',\n                                $value\n                            ));\n                    }\n                }\n\n                break;\n        }\n\n        return $value;\n    }", "label": 2}
{"code": "def _read_bias_rating(self, short_filename):\n        \"\"\"\n        read the bias file based on the short_filename\n        and return as a dictionary\n        \"\"\"\n        res = {}\n        full_name = os.path.join(root_fldr, 'aikif', 'data', 'ref', short_filename)\n        lg.record_process('bias.py','reading ' + full_name)\n         \n        with open(full_name, 'r') as f:\n            for line in f:\n                if line.strip('') == '':\n                    break\n                bias_line = []\n                cols = line.split(',')\n                bias_line.extend([short_filename])\n                for col in cols:\n                    bias_line.extend([col.strip('\"').strip('\\n')])\n                self.bias_details.append(bias_line)", "label": 1}
{"code": "public function setValidImageTypes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->valid_image_types = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public void setJdbcLevel(String jdbcLevel)\r\n    {\r\n        if (jdbcLevel != null)\r\n        {\r\n            try\r\n            {\r\n                double intLevel = Double.parseDouble(jdbcLevel);\r\n                setJdbcLevel(intLevel);\r\n            }\r\n            catch(NumberFormatException nfe)\r\n            {\r\n                setJdbcLevel(2.0);\r\n                logger.info(\"Specified JDBC level was not numeric (Value=\" + jdbcLevel + \"), used default jdbc level of 2.0 \");\r\n            }\r\n        }\r\n        else\r\n        {\r\n            setJdbcLevel(2.0);\r\n            logger.info(\"Specified JDBC level was null, used default jdbc level of 2.0 \");\r\n        }\r\n    }", "label": 0}
{"code": "public static base_response add(nitro_service client, sslcipher resource) throws Exception {\n\t\tsslcipher addresource = new sslcipher();\n\t\taddresource.ciphergroupname = resource.ciphergroupname;\n\t\taddresource.ciphgrpalias = resource.ciphgrpalias;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def filter_somaticsniper(job, tumor_bam, somaticsniper_output, tumor_pileup, univ_options,\n                         somaticsniper_options):\n    \"\"\"\n    Filter SomaticSniper calls.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param toil.fileStore.FileID somaticsniper_output: SomaticSniper output vcf\n    :param toil.fileStore.FileID tumor_pileup: Pileup generated for the tumor bam\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict somaticsniper_options: Options specific to SomaticSniper\n    :returns: fsID for the filtered genome-level vcf\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'tumor.bam': tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n        'tumor.bam.bai': tumor_bam['tumor_dna_fix_pg_sorted.bam.bai'],\n        'input.vcf': somaticsniper_output,\n        'pileup.txt': tumor_pileup,\n        'genome.fa.tar.gz': somaticsniper_options['genome_fasta'],\n        'genome.fa.fai.tar.gz': somaticsniper_options['genome_fai']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n\n    for key in ('genome.fa', 'genome.fa.fai'):\n        input_files[key] = untargz(input_files[key + '.tar.gz'], work_dir)\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    # Run snpfilter.pl\n    parameters = ['snpfilter.pl',\n                  '--snp-file', input_files['input.vcf'],\n                  '--indel-file', input_files['pileup.txt']]\n    # Creates /data/input.vcf.SNPfilter\n    docker_call(tool='somaticsniper-addons', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=somaticsniper_options['version'])\n\n    # Run prepare_for_readcount.pl\n    parameters = ['prepare_for_readcount.pl',\n                  '--snp-file', input_files['input.vcf'] + '.SNPfilter']\n    # Creates /data/input.vcf.SNPfilter.pos\n    docker_call(tool='somaticsniper-addons', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=somaticsniper_options['version'])\n\n    # Run  bam-readcount\n    parameters = ['-b', '15',\n                  '-f', input_files['genome.fa'],\n                  '-l', input_files['input.vcf'] + '.SNPfilter.pos',\n                  '-w', '1',\n                  input_files['tumor.bam']]\n    # Creates the read counts file\n    with open(os.path.join(work_dir, 'readcounts.txt'), 'w') as readcounts_file:\n        docker_call(tool='bam-readcount', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=readcounts_file,\n                    tool_version=somaticsniper_options['bam_readcount']['version'])\n\n    # Run fpfilter.pl\n    parameters = ['fpfilter.pl',\n                  '--snp-file', input_files['input.vcf'] + '.SNPfilter',\n                  '--readcount-file', docker_path(readcounts_file.name)]\n\n    # Creates input.vcf.SNPfilter.fp_pass and input.vcf.SNPfilter.fp_fail\n    docker_call(tool='somaticsniper-addons', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=somaticsniper_options['version'])\n\n    # Run highconfidence.pl\n    parameters = ['highconfidence.pl',\n                  '--snp-file', input_files['input.vcf'] + '.SNPfilter.fp_pass']\n\n    # Creates input.vcf.SNPfilter.fp_pass.hc\n    docker_call(tool='somaticsniper-addons', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=somaticsniper_options['version'])\n\n    outfile = job.fileStore.writeGlobalFile(os.path.join(os.getcwd(),\n                                                         'input.vcf.SNPfilter.fp_pass.hc'))\n    job.fileStore.logToMaster('Filtered SomaticSniper for %s successfully' %\n                              univ_options['patient'])\n    return outfile", "label": 1}
{"code": "public String getStatement()\r\n    {\r\n        if(sql == null)\r\n        {\r\n            StringBuffer stmt = new StringBuffer(128);\r\n            ClassDescriptor cld = getClassDescriptor();\r\n\r\n            FieldDescriptor[] fieldDescriptors = cld.getPkFields();\r\n            if(fieldDescriptors == null || fieldDescriptors.length == 0)\r\n            {\r\n                throw new OJBRuntimeException(\"No PK fields defined in metadata for \" + cld.getClassNameOfObject());\r\n            }\r\n            FieldDescriptor field = fieldDescriptors[0];\r\n\r\n            stmt.append(SELECT);\r\n            stmt.append(field.getColumnName());\r\n            stmt.append(FROM);\r\n            stmt.append(cld.getFullTableName());\r\n            appendWhereClause(cld, false, stmt);\r\n\r\n            sql = stmt.toString();\r\n        }\r\n        return sql;\r\n    }", "label": 0}
{"code": "public static function generate(string $provider, string $identifier, array $attributes, array $payload)\n    {\n        $token = new static;\n\n        $token->token = str_random(40);\n        $token->provider = $provider;\n        $token->identifier = $identifier;\n        $token->user_attributes = $attributes;\n        $token->payload = $payload;\n        $token->created_at = Carbon::now();\n\n        return $token;\n    }", "label": 2}
{"code": "public function setOutputConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Asset\\V1beta1\\OutputConfig::class);\n        $this->output_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (proxy *ProxyClient) ConnectToCurrentCluster(ctx context.Context, quiet bool) (auth.ClientI, error) {\n\tcluster, err := proxy.currentCluster()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn proxy.ConnectToCluster(ctx, cluster.Name, quiet)\n}", "label": 5}
{"code": "func (l VirtualDeviceList) CreateCdrom(c *types.VirtualIDEController) (*types.VirtualCdrom, error) {\n\tdevice := &types.VirtualCdrom{}\n\n\tl.AssignController(device, c)\n\n\tl.setDefaultCdromBacking(device)\n\n\tdevice.Connectable = &types.VirtualDeviceConnectInfo{\n\t\tAllowGuestControl: true,\n\t\tConnected:         true,\n\t\tStartConnected:    true,\n\t}\n\n\treturn device, nil\n}", "label": 5}
{"code": "def modified_files\n      staged = squash?\n      refs = 'HEAD^ HEAD' if merge_commit?\n      @modified_files ||= Overcommit::GitRepo.modified_files(staged: staged, refs: refs)\n    end", "label": 4}
{"code": "def default_message_notifications=(notification_level)\n      notification_level = NOTIFICATION_LEVELS[notification_level] if notification_level.is_a?(Symbol)\n\n      update_server_data(default_message_notifications: notification_level)\n    end", "label": 4}
{"code": "public function loadRelationsForPage(int $perPage, int $page = 1): self\n    {\n        foreach ($this->relations as $name => $constraints) {\n            $this->loadRelationForPage($perPage, $page, $name, $constraints);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "func (t *TransportPort) Equal(o *TransportPort) bool {\n\tif t == o {\n\t\treturn true\n\t}\n\n\tif o == nil {\n\t\treturn false\n\t}\n\n\tif t.Proto != o.Proto || t.Port != o.Port {\n\t\treturn false\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "public static base_response release(nitro_service client) throws Exception {\n\t\tnsdhcpip releaseresource = new nsdhcpip();\n\t\treturn releaseresource.perform_operation(client,\"release\");\n\t}", "label": 0}
{"code": "function backup(source, options) {\n  options = _.sanitize(options, {destination: null});\n  let dest = options.destination;\n  if (dest === null) {\n    dest = `${source.replace(/\\/*$/, '')}_${Date.now()}`;\n  }\n  copy(source, dest);\n  return dest;\n}", "label": 3}
{"code": "def delete_files_in_folder(fldr):\n\t\"\"\"\n\tdelete all files in folder 'fldr'\n\t\"\"\"\n\tfl = glob.glob(fldr + os.sep + '*.*')\n\tfor f in fl:\n\t\tdelete_file(f, True)", "label": 1}
{"code": "function create_require (env) {\n  function require (id) {\n    // `require('a@0.0.0')` is prohibited.\n    prohibit_require_id_with_version(id);\n\n    // When `require()` another module inside the factory,\n    // the module of depdendencies must already been created\n    var module = get_module(id, env, true);\n    return get_exports(module);\n  }\n\n  // @param {string} id Module identifier.\n  // Since 4.2.0, we only allow to asynchronously load a single module\n  require.async = function(id, callback) {\n    if (callback) {\n      // `require.async('a@0.0.0')` is prohibited\n      prohibit_require_id_with_version(id);\n      var module = get_module(id, env);\n\n      // If `require.async` a foreign module, it must be a main entry\n      if (!module.main) {\n\n        // Or it should be a module inside the current package\n        if (module.n !== env.n) {\n          // Otherwise, we will stop that.\n          return;\n        }\n        module.a = true;\n      }\n\n      use_module(module, callback);\n    }\n  };\n\n  // @param {string} path\n  require.resolve = function (path) {\n    return NEURON_CONF.resolve(parse_id(path, env).id);\n  };\n\n  return require;\n}", "label": 3}
{"code": "function Identifier(type, value) {\n  var isValue = (value != null);\n\n  // Constructor for EUI-64\n  if((type == TYPE_EUI64) && isValue) {\n    this.type = TYPE_EUI64;\n    this.value = value;\n  }\n\n  // Constructor for RA-28\n  else if((type == TYPE_RA28) && isValue) {\n    this.type = TYPE_RA28;\n    this.value = value.substr(value.length - 7, 7);\n  }\n\n  // Constructor for ADVA-48\n  else if((type == TYPE_ADVA48) && isValue) {\n    this.type = TYPE_ADVA48;\n    this.value = value;\n  }\n\n  // Constructor for RadioPayload\n  else if((type = TYPE_RADIO_PAYLOAD) && isValue) {\n    this.type = TYPE_RADIO_PAYLOAD;\n    this.value = value.payload;\n    this.lengthBytes = value.payloadLengthBytes;\n  }\n\n  // Constructor for Undefined\n  else {\n    this.type = TYPE_UNDEFINED;\n    this.value = null;\n  }\n}", "label": 3}
{"code": "public String getSearchJsonModel() throws IOException {\n        DbSearch search = new DbSearch();\n        search.setArtifacts(new ArrayList<>());\n        search.setModules(new ArrayList<>());\n        return JsonUtils.serialize(search);\n    }", "label": 0}
{"code": "def cell(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'cell_for', &block)\n      define_method(\"#{name}\") do\n        return platform.cell_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "function EntityNotFoundError(entity, innerError) {\n  /**\n   * The name of the entity that was not found.\n   * @type {?string}\n   */\n  this.entity = entity;\n  /**\n   * The inner error that generated the current error.\n   * @type {?Error}\n   */\n  this.innerError = innerError;\n\n  expect(arguments).to.have.length.below(\n    3,\n    'Invalid arguments length when creating a new EntityNotFoundError (it ' +\n    'has to be passed less than 3 arguments)'\n  );\n\n  this.name = 'EntityNotFoundError';\n\n  this.message = 'Cannot find Entity';\n  if (entity) {\n    expect(entity).to.be.a(\n      'string',\n      'Invalid argument \"entity\" when creating a new EntityNotFoundError ' +\n      '(it has to be a string)'\n    );\n    this.message += ' \"' + entity + '\"';\n  }\n\n  this.stack = (new Error(this.message)).stack;\n  if (innerError) {\n    expect(innerError).to.be.an.instanceof(\n      Error,\n      'Invalid argument \"innerError\" when creating a new EntityNotFoundError ' +\n      '(it has to be an Error)'\n    );\n    this.stack += '\\n\\n' + innerError.stack;\n  }\n}", "label": 3}
{"code": "def process_response(self, request, response):\n        \"\"\"\n        Send broken link emails for relevant 404 NOT FOUND responses.\n        \"\"\"\n        if response.status_code == 404 and not settings.DEBUG:\n            domain = request.get_host()\n            path = request.get_full_path()\n            referer = force_text(\n                request.META.get('HTTP_REFERER', ''), errors='replace')\n\n            if not self.is_ignorable_request(request, path, domain, referer):\n                ua = request.META.get('HTTP_USER_AGENT', '<none>')\n                ip = request.META.get('REMOTE_ADDR', '<none>')\n\n                user = None\n                if request.user and hasattr(request.user, 'email'):\n                    user = request.user.email\n                content = (\n                    \"Referrer: %s\\n\"\n                    \"Requested URL: %s\\n\"\n                    \"User agent: %s\\n\"\n                    \"IP address: %s\\n\"\n                    \"User: %s\\n\"\n                ) % (referer, path, ua, ip, user)\n                if self.is_internal_request(domain, referer):\n                    internal = 'INTERNAL '\n                else:\n                    internal = ''\n                mail_managers(\n                    \"Broken %slink on %s\" % (\n                        internal,\n                        domain\n                    ),\n                    content,\n                    fail_silently=True)\n        return response", "label": 1}
{"code": "func (v VirtualMachine) CreateSnapshot(ctx context.Context, name string, description string, memory bool, quiesce bool) (*Task, error) {\n\treq := types.CreateSnapshot_Task{\n\t\tThis:        v.Reference(),\n\t\tName:        name,\n\t\tDescription: description,\n\t\tMemory:      memory,\n\t\tQuiesce:     quiesce,\n\t}\n\n\tres, err := methods.CreateSnapshot_Task(ctx, v.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewTask(v.c, res.Returnval), nil\n}", "label": 5}
{"code": "public function drop($disconnect = false)\n    {\n        if ($disconnect) {\n            if ($this->valid()) {\n                $this->position = $this->size;\n                $this->connection->disconnect();\n            }\n        } else {\n            while ($this->valid()) {\n                $this->next();\n            }\n        }\n    }", "label": 2}
{"code": "function areSameModule(a, b) {\n                    if (a.body.kind !== b.body.kind) {\n                        return false;\n                    }\n                    if (a.body.kind !== 225 /* ModuleDeclaration */) {\n                        return true;\n                    }\n                    return areSameModule(a.body, b.body);\n                }", "label": 3}
{"code": "def run_server_bidi(mth, interception_ctx)\n      view = multi_req_view\n      bidi_call = BidiCall.new(\n        @call,\n        @marshal,\n        @unmarshal,\n        metadata_received: @metadata_received,\n        req_view: view\n      )\n      requests = bidi_call.read_next_loop(proc { set_input_stream_done }, false)\n      interception_ctx.intercept!(\n        :bidi_streamer,\n        call: view,\n        method: mth,\n        requests: requests\n      ) do\n        bidi_call.run_on_server(mth, requests)\n      end\n    end", "label": 4}
{"code": "def remove_global():\n    \"\"\"Remove global action rule.\"\"\"\n    def processor(action, argument):\n        ActionUsers.query_by_action(action, argument=argument).filter(\n            ActionUsers.user_id.is_(None)\n        ).delete(synchronize_session=False)\n    return processor", "label": 1}
{"code": "def si_format(value, precision=1, format_str=u'{value} {prefix}',\n              exp_format_str=u'{value}e{expof10}'):\n    '''\n    Format value to string with SI prefix, using the specified precision.\n\n    Parameters\n    ----------\n    value : int, float\n        Input value.\n    precision : int\n        Number of digits after decimal place to include.\n    format_str : str or unicode\n        Format string where ``{prefix}`` and ``{value}`` represent the SI\n        prefix and the value (scaled according to the prefix), respectively.\n        The default format matches the `SI prefix style`_ format.\n    exp_str : str or unicode\n        Format string where ``{expof10}`` and ``{value}`` represent the\n        exponent of 10 and the value (scaled according to the exponent of 10),\n        respectively.  This format is used if the absolute exponent of 10 value\n        is greater than 24.\n\n    Returns\n    -------\n    unicode\n        :data:`value` formatted according to the `SI prefix style`_.\n\n    Examples\n    --------\n\n    For example, with `precision=2`:\n\n    .. code-block:: python\n\n        1e-27 --> 1.00e-27\n        1.764e-24 --> 1.76 y\n        7.4088e-23 --> 74.09 y\n        3.1117e-21 --> 3.11 z\n        1.30691e-19 --> 130.69 z\n        5.48903e-18 --> 5.49 a\n        2.30539e-16 --> 230.54 a\n        9.68265e-15 --> 9.68 f\n        4.06671e-13 --> 406.67 f\n        1.70802e-11 --> 17.08 p\n        7.17368e-10 --> 717.37 p\n        3.01295e-08 --> 30.13 n\n        1.26544e-06 --> 1.27 u\n        5.31484e-05 --> 53.15 u\n        0.00223223 --> 2.23 m\n        0.0937537 --> 93.75 m\n        3.93766 --> 3.94\n        165.382 --> 165.38\n        6946.03 --> 6.95 k\n        291733 --> 291.73 k\n        1.22528e+07 --> 12.25 M\n        5.14617e+08 --> 514.62 M\n        2.16139e+10 --> 21.61 G\n        9.07785e+11 --> 907.78 G\n        3.8127e+13 --> 38.13 T\n        1.60133e+15 --> 1.60 P\n        6.7256e+16 --> 67.26 P\n        2.82475e+18 --> 2.82 E\n        1.1864e+20 --> 118.64 E\n        4.98286e+21 --> 4.98 Z\n        2.0928e+23 --> 209.28 Z\n        8.78977e+24 --> 8.79 Y\n        3.6917e+26 --> 369.17 Y\n        1.55051e+28 --> 15.51e+27\n        6.51216e+29 --> 651.22e+27\n\n    .. versionchanged:: 1.0\n        Use unicode string for :data:`format_str` and SI value format string to\n        support micro (i.e., \u00b5) characte, and change return type to unicode\n        string.\n\n        .. seealso::\n\n            `Issue #4`_.\n\n    .. _`Issue #4`: https://github.com/cfobel/si-prefix/issues/4\n    .. _SI prefix style:\n        http://physics.nist.gov/cuu/Units/checklist.html\n    '''\n    svalue, expof10 = split(value, precision)\n    value_format = u'%%.%df' % precision\n    value_str = value_format % svalue\n    try:\n        return format_str.format(value=value_str,\n                                 prefix=prefix(expof10).strip())\n    except ValueError:\n        sign = ''\n        if expof10 > 0:\n            sign = \"+\"\n        return exp_format_str.format(value=value_str,\n                                     expof10=''.join([sign, str(expof10)]))", "label": 1}
{"code": "def handleNotification(self, req):\n        \"\"\"handles a notification request by calling the appropriete method the service exposes\"\"\"\n        name = req[\"method\"]\n        params = req[\"params\"]\n        try: #to get a callable obj \n            obj = getMethodByName(self.service, name)\n            rslt = obj(*params)\n        except:\n            pass", "label": 1}
{"code": "def remove_bad(string):\n    \"\"\"\n    remove problem characters from string\n    \"\"\"\n    remove = [':', ',', '(', ')', ' ', '|', ';', '\\'']\n    for c in remove:\n        string = string.replace(c, '_')\n    return string", "label": 1}
{"code": "def add_recipient(recipient)\n      raise 'Tried to add recipient to a non-group channel' unless group?\n      raise ArgumentError, 'Tried to add a non-recipient to a group' unless recipient.is_a?(Recipient)\n\n      @recipients << recipient\n    end", "label": 4}
{"code": "function() {\n      if (!_.isUndefined(this.ids.property)) {\n        this.stopListeningToIdsPropertyChangeEvent();\n        var idsPropertyNameAndContext = this.__parseIdsPropertyNameAndIdContainer();\n        var idContainer = idsPropertyNameAndContext.idContainer;\n        var canListenToEvents = idContainer && _.isFunction(idContainer.on);\n        if (canListenToEvents) {\n          this.__currentContextWithListener = idContainer;\n          this.__currentContextEventName = 'change:' + idsPropertyNameAndContext.idsPropertyName;\n          this.listenTo(this.__currentContextWithListener, this.__currentContextEventName, this.retrieve);\n          this.listenTo(this.__currentContextWithListener, 'fetched:ids', this.retrieve);\n        }\n      }\n    }", "label": 3}
{"code": "function(modelAlias, fields) {\n      var model = this.getTrackedModel(modelAlias);\n      if (model) {\n        return {\n          fields: fields,\n          model: model\n        };\n      }\n    }", "label": 3}
{"code": "public static protocoludp_stats get(nitro_service service) throws Exception{\n\t\tprotocoludp_stats obj = new protocoludp_stats();\n\t\tprotocoludp_stats[] response = (protocoludp_stats[])obj.stat_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public function ancestor($kind, $identifier, array $options = [])\n    {\n        $options += [\n            'identifierType' => null\n        ];\n\n        $pathElement = $this->normalizeElement($kind, $identifier, $options['identifierType']);\n\n        array_unshift($this->path, $pathElement);\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *PresenceService) DeleteNode(namespace string, name string) error {\n\tkey := backend.Key(nodesPrefix, namespace, name)\n\treturn s.Delete(context.TODO(), key)\n}", "label": 5}
{"code": "function addVectorAttribute(gl, program, location, dimension, obj, name, doLink) {\n  var constFuncArgs = [ 'gl', 'v' ]\n  var varNames = []\n  for(var i=0; i<dimension; ++i) {\n    constFuncArgs.push('x'+i)\n    varNames.push('x'+i)\n  }\n  constFuncArgs.push([\n    'if(x0.length===void 0){return gl.vertexAttrib', dimension, 'f(v,', varNames.join(), ')}else{return gl.vertexAttrib', dimension, 'fv(v,x0)}'\n  ].join(''))\n  var constFunc = Function.apply(undefined, constFuncArgs)\n  var attr = new ShaderAttribute(gl, program, location, dimension, name, constFunc, doLink)\n  Object.defineProperty(obj, name, {\n    set: function(x) {\n      gl.disableVertexAttribArray(attr._location)\n      constFunc(gl, attr._location, x)\n      return x\n    }\n    , get: function() {\n      return attr\n    }\n    , enumerable: true\n  })\n}", "label": 3}
{"code": "public static authenticationldappolicy_vpnglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationldappolicy_vpnglobal_binding obj = new authenticationldappolicy_vpnglobal_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationldappolicy_vpnglobal_binding response[] = (authenticationldappolicy_vpnglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def TEST():\n    \"\"\" tests for this module \"\"\"\n    grd = Grid(4,4, [2,4])\n    grd.new_tile()\n    grd.new_tile()\n    print(grd)\n    print(\"There are \", grd.count_blank_positions(), \" blanks in grid 1\\n\")\n\n    grd2 = Grid(5,5, ['A','B'])\n    grd2.new_tile(26)\n    print(grd2)\n    build_board_checkers()\n\n    print(\"There are \", grd2.count_blank_positions(), \" blanks in grid 2\")", "label": 1}
{"code": "def execute\n      subcmd_name = @match[1]\n      return puts(help) unless subcmd_name\n\n      subcmd = subcommand_list.match(subcmd_name)\n      raise CommandNotFound.new(subcmd_name, self.class) unless subcmd\n\n      subcmd.new(processor, arguments).execute\n    end", "label": 4}
{"code": "func ReverseIP(IP string) string {\n\tvar reverseIP []string\n\n\tif net.ParseIP(IP).To4() != nil {\n\t\treverseIP = strings.Split(IP, \".\")\n\t\tl := len(reverseIP)\n\t\tfor i, j := 0, l-1; i < l/2; i, j = i+1, j-1 {\n\t\t\treverseIP[i], reverseIP[j] = reverseIP[j], reverseIP[i]\n\t\t}\n\t} else {\n\t\treverseIP = strings.Split(IP, \":\")\n\n\t\t// Reversed IPv6 is represented in dotted decimal instead of the typical\n\t\t// colon hex notation\n\t\tfor key := range reverseIP {\n\t\t\tif len(reverseIP[key]) == 0 { // expand the compressed 0s\n\t\t\t\treverseIP[key] = strings.Repeat(\"0000\", 8-strings.Count(IP, \":\"))\n\t\t\t} else if len(reverseIP[key]) < 4 { // 0-padding needed\n\t\t\t\treverseIP[key] = strings.Repeat(\"0\", 4-len(reverseIP[key])) + reverseIP[key]\n\t\t\t}\n\t\t}\n\n\t\treverseIP = strings.Split(strings.Join(reverseIP, \"\"), \"\")\n\n\t\tl := len(reverseIP)\n\t\tfor i, j := 0, l-1; i < l/2; i, j = i+1, j-1 {\n\t\t\treverseIP[i], reverseIP[j] = reverseIP[j], reverseIP[i]\n\t\t}\n\t}\n\n\treturn strings.Join(reverseIP, \".\")\n}", "label": 5}
{"code": "async def load_cache(self, archive: bool = False) -> int:\n        \"\"\"\n        Load caches and archive enough to go offline and be able to generate proof\n        on all credentials in wallet.\n\n        Return timestamp (epoch seconds) of cache load event, also used as subdirectory\n        for cache archives.\n\n        :return: cache load event timestamp (epoch seconds)\n        \"\"\"\n\n        LOGGER.debug('HolderProver.load_cache >>> archive: %s', archive)\n\n        rv = int(time())\n        box_ids = json.loads(await self.get_box_ids_json())\n        for s_id in box_ids['schema_id']:\n            with SCHEMA_CACHE.lock:\n                await self.get_schema(s_id)\n        for cd_id in box_ids['cred_def_id']:\n            with CRED_DEF_CACHE.lock:\n                await self.get_cred_def(cd_id)\n        for rr_id in box_ids['rev_reg_id']:\n            await self._get_rev_reg_def(rr_id)\n            with REVO_CACHE.lock:\n                revo_cache_entry = REVO_CACHE.get(rr_id, None)\n                if revo_cache_entry:\n                    try:\n                        await revo_cache_entry.get_delta_json(self._build_rr_delta_json, rv, rv)\n                    except ClosedPool:\n                        LOGGER.warning(\n                            'Holder-Prover %s is offline from pool %s, cannot update revo cache reg delta for %s to %s',\n                            self.wallet.name,\n                            self.pool.name,\n                            rr_id,\n                            rv)\n\n        if archive:\n            Caches.archive(self.dir_cache)\n        LOGGER.debug('HolderProver.load_cache <<< %s', rv)\n        return rv", "label": 1}
{"code": "def count(stat, count, opts=EMPTY_OPTIONS)\n      opts = {:sample_rate => opts} if opts.is_a? Numeric\n      send_stats stat, count, COUNTER_TYPE, opts\n    end", "label": 4}
{"code": "def insert_many(documents, options = {})\n      inserts = documents.map{ |doc| { :insert_one => doc }}\n      bulk_write(inserts, options)\n    end", "label": 4}
{"code": "func PgTsTemplateByOid(db XODB, oid pgtypes.Oid) (*PgTsTemplate, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, tmplname, tmplnamespace, tmplinit, tmpllexize ` +\n\t\t`FROM pg_catalog.pg_ts_template ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tptt := PgTsTemplate{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&ptt.Tableoid, &ptt.Cmax, &ptt.Xmax, &ptt.Cmin, &ptt.Xmin, &ptt.Oid, &ptt.Ctid, &ptt.Tmplname, &ptt.Tmplnamespace, &ptt.Tmplinit, &ptt.Tmpllexize)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ptt, nil\n}", "label": 5}
{"code": "func (ts *TemplateSet) Execute(w io.Writer, name string, obj interface{}) error {\n\ttpl, ok := ts.tpls[name]\n\tif !ok {\n\t\t// attempt to load and parse the template\n\t\tbuf, err := ts.l(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// parse template\n\t\ttpl, err = template.New(name).Funcs(ts.funcs).Parse(string(buf))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn tpl.Execute(w, obj)\n}", "label": 5}
{"code": "function (schema) {\n\n    var extendList = find(schema, 'extend');\n    for (var extendElem in extendList) {\n        if (extendList[extendElem] && extendList[extendElem].extend && _.isFunction(extendList[extendElem].extend)) {\n            schema[extendElem] = extendList[extendElem].extend();\n        }\n    }\n    return schema;\n}", "label": 3}
{"code": "public function setGcsSource($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\ImportProductSetsGcsSource::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function deleteBatch(array $keys, array $options = [])\n    {\n        $options += [\n            'baseVersion' => null\n        ];\n\n        $mutations = [];\n        foreach ($keys as $key) {\n            $mutations[] = $this->operation->mutation('delete', $key, Key::class, $options['baseVersion']);\n        }\n\n        return $this->operation->commit($mutations, $options);\n    }", "label": 2}
{"code": "public void set(int index, double element) {\r\n\t// overridden for performance only.\r\n\tif (index >= size || index < 0)\r\n\t\tthrow new IndexOutOfBoundsException(\"Index: \"+index+\", Size: \"+size);\r\n\telements[index] = element;\r\n}", "label": 0}
{"code": "def predict_mhci_binding(job, peptfile, allele, peplen, univ_options, mhci_options):\n    \"\"\"\n    Predict binding for each peptide in `peptfile` to `allele` using the IEDB mhci binding\n    prediction tool.\n\n    :param toil.fileStore.FileID peptfile: The input peptide fasta\n    :param str allele: Allele to predict binding against\n    :param str peplen: Length of peptides to process\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict mhci_options: Options specific to mhci binding prediction\n    :return: fsID for file containing the predictions\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'peptfile.faa': peptfile}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    peptides = read_peptide_file(os.path.join(os.getcwd(), 'peptfile.faa'))\n    if not peptides:\n        return job.fileStore.writeGlobalFile(job.fileStore.getLocalTempFile())\n    parameters = [mhci_options['pred'],\n                  allele,\n                  peplen,\n                  input_files['peptfile.faa']]\n    with open('/'.join([work_dir, 'predictions.tsv']), 'w') as predfile:\n        docker_call(tool='mhci', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=predfile, interactive=True,\n                    tool_version=mhci_options['version'])\n    output_file = job.fileStore.writeGlobalFile(predfile.name)\n    job.fileStore.logToMaster('Ran mhci on %s:%s:%s successfully'\n                              % (univ_options['patient'], allele, peplen))\n    return output_file", "label": 1}
{"code": "function parseTemplates(options) {\n  return readFileTree(options.src.templates, options.keys.templates, options);\n}", "label": 3}
{"code": "public function deleteJob($name, array $optionalArgs = [])\n    {\n        $request = new DeleteJobRequest();\n        $request->setName($name);\n\n        $requestParams = new RequestParamsHeaderDescriptor([\n          'name' => $request->getName(),\n        ]);\n        $optionalArgs['headers'] = isset($optionalArgs['headers'])\n            ? array_merge($requestParams->getHeader(), $optionalArgs['headers'])\n            : $requestParams->getHeader();\n\n        return $this->startCall(\n            'DeleteJob',\n            GPBEmpty::class,\n            $optionalArgs,\n            $request\n        )->wait();\n    }", "label": 2}
{"code": "function uniqueArray(arr) {\n  var result = [];\n\n  for (var i = 0; i < arr.length; i++) {\n    if (result.indexOf(arr[i]) === -1) {\n      result.push(arr[i]);\n    }\n  }\n\n  return result;\n}", "label": 3}
{"code": "def post_ext_init(state):\n    \"\"\"Setup blueprint.\"\"\"\n    app = state.app\n\n    app.config.setdefault(\n        'OAUTHCLIENT_SITENAME',\n        app.config.get('THEME_SITENAME', 'Invenio'))\n    app.config.setdefault(\n        'OAUTHCLIENT_BASE_TEMPLATE',\n        app.config.get('BASE_TEMPLATE',\n                       'invenio_oauthclient/base.html'))\n    app.config.setdefault(\n        'OAUTHCLIENT_COVER_TEMPLATE',\n        app.config.get('COVER_TEMPLATE',\n                       'invenio_oauthclient/base_cover.html'))\n    app.config.setdefault(\n        'OAUTHCLIENT_SETTINGS_TEMPLATE',\n        app.config.get('SETTINGS_TEMPLATE',\n                       'invenio_oauthclient/settings/base.html'))", "label": 1}
{"code": "function blur(progress) {\n  var to = (this.options.to !== undefined) ? this.options.to : 0;\n  var from = (this.options.from !== undefined) ? this.options.from : 0;\n  var amount = (to - from) * progress + from;\n\n  this.element.style.filter = 'blur(' + amount + 'px)';\n}", "label": 3}
{"code": "function processLogs() {\n  var calcs = 0;\n  for (var i in stats) {\n    stats[i].average = stats[i].totalTime / stats[i].count;\n    calcs += stats[i].calcs;\n  }\n  var time1 = meaningfulTime();\n  var time2 = meaningfulTime();\n  console.error(\"TRACER TOTAL OVERHEAD\", (calcs*timeDiff(time2, time1)).toFixed(2)+'ms');\n\n  while (Object.keys(stats).length > 0) {\n    var biggest = 0;\n    var biggestPath = Object.keys(stats)[0];\n    for (var path in stats) {\n      if (stats[path].average >= biggest) {\n        biggestPath = path;\n        biggest = stats[path].average;\n      }\n    }\n    console.error(\"TRACER TOTAL\",\n                  stats[biggestPath].min.toFixed(2)+'ms',\n                  stats[biggestPath].average.toFixed(2)+'ms',\n                  stats[biggestPath].max.toFixed(2)+'ms',\n                  stats[biggestPath].count,\n                  biggestPath);\n    delete stats[biggestPath];\n  }\n}", "label": 3}
{"code": "public static function createForSocket(\n        array $config,\n        LoopInterface $loop,\n        CacheInterface $cache = null,\n        StorageInterface $storageDriver = null\n    ) {\n        $port = isset($config['port']) ? $config['port'] : 8080;\n\n        $socket = new Server($loop);\n\n        if (empty($cache)) {\n            $cache = new ArrayCache();\n        }\n\n        if (empty($storageDriver)) {\n            $storageDriver = new FileStorage(__DIR__);\n        }\n\n        $driverManager = new DriverManager($config, new Curl());\n\n        $botman = new BotMan($cache, DriverManager::loadFromName('Null', $config), $config, $storageDriver);\n        $botman->runsOnSocket(true);\n\n        $socket->on('connection', function ($conn) use ($botman, $driverManager) {\n            $conn->on('data', function ($data) use ($botman, $driverManager) {\n                $requestData = json_decode($data, true);\n                $request = new Request($requestData['query'], $requestData['request'], $requestData['attributes'], [], [], [], $requestData['content']);\n                $driver = $driverManager->getMatchingDriver($request);\n                $botman->setDriver($driver);\n                $botman->listen();\n            });\n        });\n        $socket->listen($port);\n\n        return $botman;\n    }", "label": 2}
{"code": "def inh(table):\n    \"\"\"\n    inverse hyperbolic sine transformation\n    \"\"\"\n    t = []\n    for i in table:\n        t.append(np.ndarray.tolist(np.arcsinh(i)))\n    return t", "label": 1}
{"code": "function iPadTouchStart(event) {\r\n\tvar touches = event.changedTouches,\r\n\t\tfirst = touches[0],\r\n\t\ttype = \"mouseover\",\r\n\t\tsimulatedEvent = document.createEvent(\"MouseEvent\");\r\n\t//\r\n\t// Mouse over first - I have live events attached on mouse over\r\n\t//\r\n\tsimulatedEvent.initMouseEvent(type, true, true, window, 1, first.screenX, first.screenY, first.clientX, first.clientY,\r\n                            false, false, false, false, 0, null);\r\n\tfirst.target.dispatchEvent(simulatedEvent);\r\n\r\n\ttype = \"mousedown\";\r\n\tsimulatedEvent = document.createEvent(\"MouseEvent\");\r\n\r\n\tsimulatedEvent.initMouseEvent(type, true, true, window, 1, first.screenX, first.screenY, first.clientX, first.clientY,\r\n                            false, false, false, false, 0, null);\r\n\tfirst.target.dispatchEvent(simulatedEvent);\r\n\r\n\r\n\tif (!tapValid) {\r\n\t\tlastTap = first.target;\r\n\t\ttapValid = true;\r\n\t\ttapTimeout = window.setTimeout(\"cancelTap();\", 600);\r\n\t\tstartHold(event);\r\n\t}\r\n\telse {\r\n\t\twindow.clearTimeout(tapTimeout);\r\n\r\n\t\t//\r\n\t\t// If a double tap is still a possibility and the elements are the same\r\n\t\t//\tThen perform a double click\r\n\t\t//\r\n\t\tif (first.target == lastTap) {\r\n\t\t\tlastTap = null;\r\n\t\t\ttapValid = false;\r\n\r\n\t\t\ttype = \"click\";\r\n\t\t\tsimulatedEvent = document.createEvent(\"MouseEvent\");\r\n\r\n\t\t\tsimulatedEvent.initMouseEvent(type, true, true, window, 1, first.screenX, first.screenY, first.clientX, first.clientY,\r\n                         \tfalse, false, false, false, 0/*left*/, null);\r\n\t\t\tfirst.target.dispatchEvent(simulatedEvent);\r\n\r\n\t\t\ttype = \"dblclick\";\r\n\t\t\tsimulatedEvent = document.createEvent(\"MouseEvent\");\r\n\r\n\t\t\tsimulatedEvent.initMouseEvent(type, true, true, window, 1, first.screenX, first.screenY, first.clientX, first.clientY,\r\n                         \tfalse, false, false, false, 0/*left*/, null);\r\n\t\t\tfirst.target.dispatchEvent(simulatedEvent);\r\n\t\t}\r\n\t\telse {\r\n\t\t\tlastTap = first.target;\r\n\t\t\ttapValid = true;\r\n\t\t\ttapTimeout = window.setTimeout(\"cancelTap();\", 600);\r\n\t\t\tstartHold(event);\r\n\t\t}\r\n\t}\r\n}", "label": 3}
{"code": "function consumeBody(body) {\n  if (this[DISTURBED]) {\n    return Body.Promise.reject(new Error(`body used already for: ${this.url}`));\n  }\n\n  this[DISTURBED] = true;\n\n  // body is null\n  if (this.body === null) {\n    return Body.Promise.resolve(Buffer.alloc(0));\n  }\n\n  // body is string\n  if (typeof this.body === 'string') {\n    return Body.Promise.resolve(Buffer.from(this.body));\n  }\n\n  // body is blob\n  if (this.body instanceof Blob) {\n    return Body.Promise.resolve(this.body.buffer);\n  }\n\n  // body is buffer\n  if (Buffer.isBuffer(this.body)) {\n    return Body.Promise.resolve(this.body);\n  }\n\n  // istanbul ignore if: should never happen\n  if (!(this.body instanceof Stream)) {\n    return Body.Promise.resolve(Buffer.alloc(0));\n  }\n\n  // body is stream\n  // get ready to actually consume the body\n  let accum = [];\n  let accumBytes = 0;\n  let abort = false;\n\n  return new Body.Promise((resolve, reject) => {\n    let resTimeout;\n\n    // allow timeout on slow response body\n    if (this.timeout) {\n      resTimeout = setTimeout(() => {\n        abort = true;\n        reject(new FetchError(`Response timeout while trying to fetch ${this.url} (over ${this.timeout}ms)`, 'body-timeout'));\n      }, this.timeout);\n    }\n\n    // handle stream error, such as incorrect content-encoding\n    this.body.on('error', err => {\n      reject(new FetchError(`Invalid response body while trying to fetch ${this.url}: ${err.message}`, 'system', err));\n    });\n\n    this.body.on('data', chunk => {\n      if (abort || chunk === null) {\n        return;\n      }\n\n      if (this.size && accumBytes + chunk.length > this.size) {\n        abort = true;\n        reject(new FetchError(`content size at ${this.url} over limit: ${this.size}`, 'max-size'));\n        return;\n      }\n\n      accumBytes += chunk.length;\n      accum.push(chunk);\n    });\n\n    this.body.on('end', () => {\n      if (abort) {\n        return;\n      }\n\n      clearTimeout(resTimeout);\n      resolve(Buffer.concat(accum));\n    });\n  });\n}", "label": 3}
{"code": "private void harvestReturnValues(\r\n        ProcedureDescriptor proc,\r\n        Object obj,\r\n        PreparedStatement stmt)\r\n        throws PersistenceBrokerSQLException\r\n    {\r\n        // If the procedure descriptor is null or has no return values or\r\n        // if the statement is not a callable statment, then we're done.\r\n        if ((proc == null) || (!proc.hasReturnValues()))\r\n        {\r\n            return;\r\n        }\r\n\r\n        // Set up the callable statement\r\n        CallableStatement callable = (CallableStatement) stmt;\r\n\r\n        // This is the index that we'll use to harvest the return value(s).\r\n        int index = 0;\r\n\r\n        // If the proc has a return value, then try to harvest it.\r\n        if (proc.hasReturnValue())\r\n        {\r\n\r\n            // Increment the index\r\n            index++;\r\n\r\n            // Harvest the value.\r\n            this.harvestReturnValue(obj, callable, proc.getReturnValueFieldRef(), index);\r\n        }\r\n\r\n        // Check each argument.  If it's returned by the procedure,\r\n        // then harvest the value.\r\n        Iterator iter = proc.getArguments().iterator();\r\n        while (iter.hasNext())\r\n        {\r\n            index++;\r\n            ArgumentDescriptor arg = (ArgumentDescriptor) iter.next();\r\n            if (arg.getIsReturnedByProcedure())\r\n            {\r\n                this.harvestReturnValue(obj, callable, arg.getFieldRef(), index);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "function(el) {\n      var newDOM = document.createElement(el.tagName);\n      _.each(el.attributes, function(attrib) {\n        newDOM.setAttribute(attrib.name, attrib.value);\n      });\n      return newDOM;\n    }", "label": 3}
{"code": "public function setLocation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Location::class);\n        $this->location = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func getAggregations(request *restful.Request) ([]core.AggregationType, error) {\n\taggregationsRaw := strings.Split(request.PathParameter(\"aggregations\"), \",\")\n\tif len(aggregationsRaw) == 0 {\n\t\treturn nil, fmt.Errorf(\"No aggregations specified\")\n\t}\n\n\taggregations := make([]core.AggregationType, len(aggregationsRaw))\n\n\tfor ind, aggNameRaw := range aggregationsRaw {\n\t\taggName := core.AggregationType(aggNameRaw)\n\t\tif _, ok := core.AllAggregations[aggName]; !ok {\n\t\t\treturn nil, fmt.Errorf(\"Unknown aggregation %q\", aggName)\n\t\t}\n\t\taggregations[ind] = aggName\n\t}\n\n\treturn aggregations, nil\n}", "label": 5}
{"code": "def payment_init(self, wallet):\n        \"\"\"\n        Marks all accounts in wallet as available for being used as a payment\n        session.\n\n        :param wallet: Wallet to init payment in\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.payment_init(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        True\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('payment_init', payload)\n\n        return resp['status'] == 'Ready'", "label": 1}
{"code": "public function generateForm(): string\n    {\n        foreach ($this->fields as $field) {\n            if (is_array($field)) {\n                $this->renderGroup($field);\n                continue;\n            }\n\n            $this->form .= $this->render($field);\n        }\n\n        return $this->form;\n    }", "label": 2}
{"code": "public static base_responses unset(nitro_service client, onlinkipv6prefix resources[],  String[] args) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tonlinkipv6prefix unsetresources[] = new onlinkipv6prefix[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tunsetresources[i] = new onlinkipv6prefix();\n\t\t\t\tunsetresources[i].ipv6prefix = resources[i].ipv6prefix;\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (v *validate) GetStructFieldOK() (reflect.Value, reflect.Kind, bool) {\n\treturn v.getStructFieldOKInternal(v.slflParent, v.ct.param)\n}", "label": 5}
{"code": "def run(self):\n        \"\"\"Reads data from disk and generates CSV files.\"\"\"\n        # Try to create the directory\n        if not os.path.exists(self.output):\n            try:\n                os.mkdir(self.output)\n            except:\n                print 'failed to create output directory %s' % self.output\n\n        # Be sure it is a directory\n        if not os.path.isdir(self.output):\n            print 'invalid output directory %s' % self.output\n            sys.exit(1)\n\n        # Create the CSV handlers\n        visitors = [\n            _CompaniesCSV(self.output),\n            _ActivitiesCSV(self.output),\n            _ActivitiesSeenCSV(self.output),\n            _QSACSV(self.output),\n        ]\n\n        # Run by each company populating the CSV files\n        for path in glob.glob(os.path.join(self.input, '*.json')):\n            with open(path, 'r') as f:\n                try:\n                    data = json.load(f, encoding='utf-8')\n                except ValueError:\n                    continue\n\n                for visitor in visitors:\n                    visitor.visit(data)", "label": 1}
{"code": "def add_exposed_to_context(context)\n      (self.class.exposed_to_template || {}).each do |k, v|\n        context.define_singleton_method(k, &method(v))\n      end\n    end", "label": 4}
{"code": "public static function createMidnightDate($year = null, $month = null, $day = null, $tz = null)\n    {\n        return static::create($year, $month, $day, 0, 0, 0, $tz);\n    }", "label": 2}
{"code": "def render_erb\n      renderer = ERB.new(template_content, nil, '-')\n      renderer.filename = @template_file\n      renderer.result(binding)\n    end", "label": 4}
{"code": "def prune_count(days)\n      raise ArgumentError, 'Days must be between 1 and 30' unless days.between?(1, 30)\n\n      response = JSON.parse API::Server.prune_count(@bot.token, @id, days)\n      response['pruned']\n    end", "label": 4}
{"code": "function(options) {\n      var trackedViewsHash = this.getTrackedViews(options);\n      _.each(trackedViewsHash, function(view) {\n        this.unregisterTrackedView(view, options);\n      }, this);\n    }", "label": 3}
{"code": "public function setProper($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1beta2\\PartOfSpeech_Proper::class);\n        $this->proper = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def update_attributes(values, opts = {}, dirty: true)\n      values.each do |k, v|\n        add_accessors([k], values) unless metaclass.method_defined?(k.to_sym)\n        @values[k] = Util.convert_to_stripe_object(v, opts)\n        dirty_value!(@values[k]) if dirty\n        @unsaved_values.add(k)\n      end\n    end", "label": 4}
{"code": "func parseInt(bytes []byte) (v int64, ok bool, overflow bool) {\n\tif len(bytes) == 0 {\n\t\treturn 0, false, false\n\t}\n\n\tvar neg bool = false\n\tif bytes[0] == '-' {\n\t\tneg = true\n\t\tbytes = bytes[1:]\n\t}\n\n\tvar b int64 = 0\n\tfor _, c := range bytes {\n\t\tif c >= '0' && c <= '9' {\n\t\t\tb = (10 * v) + int64(c-'0')\n\t\t} else {\n\t\t\treturn 0, false, false\n\t\t}\n\t\tif overflow = (b < v); overflow {\n\t\t\tbreak\n\t\t}\n\t\tv = b\n\t}\n\n\tif overflow {\n\t\tif neg && bio.Equal(bytes, []byte(minInt64)) {\n\t\t\treturn b, true, false\n\t\t}\n\t\treturn 0, false, true\n\t}\n\n\tif neg {\n\t\treturn -v, true, false\n\t} else {\n\t\treturn v, true, false\n\t}\n}", "label": 5}
{"code": "def hsv_to_rgb(self,HSV):\n        \"hsv to linear rgb\"\n        gammaRGB = self._ABC_to_DEF_by_fn(HSV,hsv_to_rgb)\n        return self._ungamma_rgb(gammaRGB)", "label": 1}
{"code": "public function setLabels($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Api\\LabelDescriptor::class);\n        $this->labels = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def document path\n      rake_yard(store)\n      docs = []\n      docs.push code_object_at(path) unless code_object_at(path).nil?\n      docs\n    end", "label": 4}
{"code": "public void addAll(Vertex vtx) {\n        if (head == null) {\n            head = vtx;\n        } else {\n            tail.next = vtx;\n        }\n        vtx.prev = tail;\n        while (vtx.next != null) {\n            vtx = vtx.next;\n        }\n        tail = vtx;\n    }", "label": 0}
{"code": "function getApparentType(type) {\n            if (type.flags & 16384 /* TypeParameter */) {\n                type = getApparentTypeOfTypeParameter(type);\n            }\n            if (type.flags & 34 /* StringLike */) {\n                type = globalStringType;\n            }\n            else if (type.flags & 340 /* NumberLike */) {\n                type = globalNumberType;\n            }\n            else if (type.flags & 136 /* BooleanLike */) {\n                type = globalBooleanType;\n            }\n            else if (type.flags & 512 /* ESSymbol */) {\n                type = getGlobalESSymbolType();\n            }\n            return type;\n        }", "label": 3}
{"code": "func didPanic(f PanicTestFunc) (bool, interface{}) {\n\n\tdidPanic := false\n\tvar message interface{}\n\tfunc() {\n\n\t\tdefer func() {\n\t\t\tif message = recover(); message != nil {\n\t\t\t\tdidPanic = true\n\t\t\t}\n\t\t}()\n\n\t\t// call the target function\n\t\tf()\n\n\t}()\n\n\treturn didPanic, message\n\n}", "label": 5}
{"code": "public Collection<SerialMessage> initialize() {\r\n\t\tArrayList<SerialMessage> result = new ArrayList<SerialMessage>();\r\n\t\t\r\n\t\tif (this.getNode().getManufacturer() == 0x010F && this.getNode().getDeviceType() == 0x0501) {\r\n\t\t\t\tlogger.warn(\"Detected Fibaro FGBS001 Universal Sensor - this device fails to respond to SENSOR_ALARM_GET and SENSOR_ALARM_SUPPORTED_GET.\");\r\n\t\t\t\treturn result;\r\n\t\t}\r\n\t\t\r\n\t\tresult.add(this.getSupportedMessage());\r\n\t\treturn result;\r\n\t}", "label": 0}
{"code": "public function setText($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->text = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def send_range_for_local_file\n        _, range = request.headers['Range'].split('bytes=')\n        from, to = range.split('-').map(&:to_i)\n        to = local_file_size - 1 unless to\n        length = to - from + 1\n        response.headers['Content-Range'] = \"bytes #{from}-#{to}/#{local_file_size}\"\n        response.headers['Content-Length'] = length.to_s\n        self.status = 206\n        prepare_local_file_headers\n        # For derivatives stored on the local file system\n        send_data IO.binread(file, length, from), local_derivative_download_options.merge(status: status)\n      end", "label": 4}
{"code": "public void delete(Vertex vtx1, Vertex vtx2) {\n        if (vtx1.prev == null) {\n            head = vtx2.next;\n        } else {\n            vtx1.prev.next = vtx2.next;\n        }\n        if (vtx2.next == null) {\n            tail = vtx1.prev;\n        } else {\n            vtx2.next.prev = vtx1.prev;\n        }\n    }", "label": 0}
{"code": "def role(name)\n      json = client.get(\"/v1/auth/approle/role/#{encode_path(name)}\")\n      return Secret.decode(json)\n    rescue HTTPError => e\n      return nil if e.code == 404\n      raise\n    end", "label": 4}
{"code": "protected function shouldBypassCache($token, $secret)\n    {\n        $newHash = sha1($token.'_'.$secret);\n\n        if (! empty($this->userHash) && $newHash !== $this->userHash) {\n            $this->userHash = $newHash;\n\n            return true;\n        }\n\n        $this->userHash = $this->userHash ?: $newHash;\n\n        return false;\n    }", "label": 2}
{"code": "def gather_categories(imap, header, categories=None):\n    \"\"\"\n    Find the user specified categories in the map and create a dictionary to contain the\n    relevant data for each type within the categories. Multiple categories will have their\n    types combined such that each possible combination will have its own entry in the\n    dictionary.\n\n    :type imap: dict\n    :param imap: The input mapping file data keyed by SampleID\n    :type header: list\n    :param header: The header line from the input mapping file. This will be searched for\n                   the user-specified categories\n    :type categories: list\n    :param categories: The list of user-specified category column name from mapping file\n    :rtype: dict\n    :return: A sorted dictionary keyed on the combinations of all the types found within\n             the user-specified categories. Each entry will contain an empty DataCategory\n             namedtuple. If no categories are specified, a single entry with the key\n             'default' will be returned\n    \"\"\"\n    # If no categories provided, return all SampleIDs\n    if categories is None:\n        return {\"default\": DataCategory(set(imap.keys()), {})}\n\n    cat_ids = [header.index(cat)\n               for cat in categories if cat in header and \"=\" not in cat]\n\n    table = OrderedDict()\n    conditions = defaultdict(set)\n    for i, cat in enumerate(categories):\n        if \"=\" in cat and cat.split(\"=\")[0] in header:\n            cat_name = header[header.index(cat.split(\"=\")[0])]\n            conditions[cat_name].add(cat.split(\"=\")[1])\n\n    # If invalid categories or conditions identified, return all SampleIDs\n    if not cat_ids and not conditions:\n        return {\"default\": DataCategory(set(imap.keys()), {})}\n\n    #If only category column given, return column-wise SampleIDs\n    if cat_ids and not conditions:\n        for sid, row in imap.items():\n            cat_name = \"_\".join([row[cid] for cid in cat_ids])\n            if cat_name not in table:\n                table[cat_name] = DataCategory(set(), {})\n            table[cat_name].sids.add(sid)\n        return table\n\n    # Collect all condition names\n    cond_ids = set()\n    for k in conditions:\n        try:\n            cond_ids.add(header.index(k))\n        except ValueError:\n            continue\n    idx_to_test = set(cat_ids).union(cond_ids)\n\n    # If column name and condition given, return overlapping SampleIDs of column and\n    # condition combinations\n    for sid, row in imap.items():\n        if all([row[header.index(c)] in conditions[c] for c in conditions]):\n            key = \"_\".join([row[idx] for idx in idx_to_test])\n            try:\n                assert key in table.keys()\n            except AssertionError:\n                table[key] = DataCategory(set(), {})\n            table[key].sids.add(sid)\n    try:\n        assert len(table) > 0\n    except AssertionError:\n        return {\"default\": DataCategory(set(imap.keys()), {})}\n    else:\n        return table", "label": 1}
{"code": "function getFunctionFromDefaultAndShaderValue(sceneDrawGroup, ccssProperty, defaultValue, shaderValue) {\n    if (referenceCSS[ccssProperty].type === 'color') {\n        defaultValue = `'${color.normalize(defaultValue, tangramReference)}'`;\n    }\n    var fn = `var _value=${defaultValue};`;\n    shaderValue.js.forEach(function (code) {\n        if (code.search(/data\\['mapnik::\\S+'\\]/) >= 0) {\n            throw new Error('mapnik selector present in the CartoCSS');\n        }\n        fn += code;\n    });\n    if (referenceCSS[ccssProperty].type === 'color') {\n        fn += getColorOverrideCode(sceneDrawGroup, ccssProperty.indexOf('fill') >= 0);\n    }\n    if (ccssProperty === 'line-width') {\n        fn += '_value=_value*$meters_per_pixel;';\n    }\n    fn += 'return _value;';\n    return wrapFn(fn);\n}", "label": 3}
{"code": "func (a *CellView) Resize() {\n\t// We might want to reflow text\n\twidth, height := a.view.Size()\n\ta.port.Resize(0, 0, width, height)\n\ta.port.ValidateView()\n\ta.MakeCursorVisible()\n}", "label": 5}
{"code": "public function setTrainingPhrases($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dialogflow\\V2\\Intent\\TrainingPhrase::class);\n        $this->training_phrases = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *APIServer) upsertAuthServer(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\treturn s.upsertServer(auth, teleport.RoleAuth, w, r, p, version)\n}", "label": 5}
{"code": "function getMethodHtml(method) {\n    var params = method.getParams();\n\n    return [\n        '<h3>', method.getName(), '</h3>',\n        method.getOption('executeOnServerOnly') &&\n            '<span class=\"label label-primary\" style=\"font-size:0.5em;vertical-align:middle\">server only</span>',\n        '<p>', method.getDescription(), '</p>',\n         Object.keys(params).length &&\n            [\n                '<table class=\"table table-bordered table-condensed\">',\n                    '<thead>',\n                        '<tr>',\n                            '<th class=\"col-md-2\">Name</th>',\n                            '<th class=\"col-md-2\">Type</th>',\n                            '<th>Description</th>',\n                        '</tr>',\n                    '</thead>',\n                    '<tbody>',\n                        Object.keys(params).map(function (key) {\n                            return getMethodParamHtml(key, params[key]);\n                        }).join(''),\n                    '</tbody>',\n                '</table>'\n            ].join('')\n    ].filter(Boolean).join('');\n}", "label": 3}
{"code": "function renderPDF(params, cb) {\n  var template = params.template;\n  var session = params.session;\n  var form = params.form;\n  var submission = params.submission;\n  submission.formName = form.name;\n  var studioLocation = params.location;\n  var generationTimestamp = params.generationTimestamp || Date.now();\n\n  var page;\n\n  session.createPage()\n    .then(function(_page) {\n      logger.debug('page created');\n      page = _page;\n      // A4 aspect ratio\n      page.property('paperSize', {format: 'A4'})\n        .then(function() {\n          logger.debug('page aspect ratio set');\n\n          //Can't load css files over https. Needs to be http.\n          if (typeof(studioLocation) === \"string\") {\n            studioLocation = studioLocation.replace(\"https://\", \"http://\");\n          }\n          form = processForm(form, submission);\n          var html = template({\n            form: form.form,\n            location: studioLocation,\n            subexport: form.sub,\n            js: params.js,\n            css: params.css\n          });\n\n          // inject html as we don't have a server to serve html to phantom\n          page.setContent(html, null)\n            .then(function(status) {\n              logger.debug('content set. status', status);\n\n              var file = path.join(params.pdfExportDir, form.sub.formSubmittedAgainst._id + '_' + form.sub._id + '_' + generationTimestamp + '.pdf');\n              page.render(file)\n                .then(function() {\n                  logger.info('Rendered pdf:', {file: file});\n                  page.close();\n                  page = null;\n\n                  destroyPhantomSession(session, function() {\n                    return cb(null, file);\n                  });\n                });\n            });\n        });\n    })\n    .catch(function(e1) {\n      logger.error('Exception rendering pdf', {exception: e1});\n      try {\n        if (page) {\n          page.close();\n        }\n      } catch (e2) {\n        // silent\n        logger.warn('Error closing page after phantom exception', {exception: e2});\n      }\n      return cb('Exception rendering pdf:' + e1.toString());\n    });\n}", "label": 3}
{"code": "def each\n      return to_enum(__callee__) unless block_given?\n\n      node = self\n      loop do\n        yield node\n        break unless (node = node.next_node)\n      end\n    end", "label": 4}
{"code": "func FirewalldInit() error {\n\tvar err error\n\n\tif connection, err = newConnection(); err != nil {\n\t\treturn fmt.Errorf(\"Failed to connect to D-Bus system bus: %v\", err)\n\t}\n\tfirewalldRunning = checkRunning()\n\tif !firewalldRunning {\n\t\tconnection.sysconn.Close()\n\t\tconnection = nil\n\t}\n\tif connection != nil {\n\t\tgo signalHandler()\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def _log(self, fname, txt, prg=''):\n        \"\"\"\n        logs an entry to fname along with standard date and user details\n        \"\"\"\n        if os.sep not in fname:\n            fname = self.log_folder + os.sep + fname\n        delim = ','\n        q = '\"'\n        dte = TodayAsString()\n        usr = GetUserName()\n        hst = GetHostName()\n        i = self.session_id\n \n        if prg == '':\n            prg = 'cls_log.log' \n        logEntry = q + dte + q + delim + q + i + q + delim + q + usr + q + delim + q + hst + q + delim + q + prg + q + delim + q + txt + q + delim + '\\n'\n        with open(fname, \"a\", encoding='utf-8', errors='replace') as myfile:\n            myfile.write(logEntry)", "label": 1}
{"code": "func (h *Handle) validateOrdinal(ordinal uint64) error {\n\th.Lock()\n\tdefer h.Unlock()\n\tif ordinal >= h.bits {\n\t\treturn errors.New(\"bit does not belong to the sequence\")\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def write(self, file_or_filename, prog=None, format='xdot'):\n        \"\"\" Writes the case data in Graphviz DOT language.\n\n        The format 'raw' is used to dump the Dot representation of the Case\n        object, without further processing. The output can be processed by any\n        of graphviz tools, defined in 'prog'.\n        \"\"\"\n        if prog is None:\n            file = super(DotWriter, self).write(file_or_filename)\n        else:\n            buf = StringIO.StringIO()\n            super(DotWriter, self).write(buf)\n            buf.seek(0)\n            data = self.create(buf.getvalue(), prog, format)\n\n            if isinstance(file_or_filename, basestring):\n                file = None\n                try:\n                    file = open(file_or_filename, \"wb\")\n                except:\n                    logger.error(\"Error opening %s.\" % file_or_filename)\n                finally:\n                    if file is not None:\n                        file.write(data)\n                        file.close()\n            else:\n                file = file_or_filename\n                file.write(data)\n\n        return file", "label": 1}
{"code": "def d2Ibr_dV2(Ybr, V, lam):\n    \"\"\" Computes 2nd derivatives of complex branch current w.r.t. voltage.\n    \"\"\"\n    nb = len(V)\n    diaginvVm = spdiag(div(matrix(1.0, (nb, 1)), abs(V)))\n\n    Haa = spdiag(mul(-(Ybr.T * lam), V))\n    Hva = -1j * Haa * diaginvVm\n    Hav = Hva\n    Hvv = spmatrix([], [], [], (nb, nb))\n\n    return Haa, Hav, Hva, Hvv", "label": 1}
{"code": "public static base_response update(nitro_service client, nd6ravariables resource) throws Exception {\n\t\tnd6ravariables updateresource = new nd6ravariables();\n\t\tupdateresource.vlan = resource.vlan;\n\t\tupdateresource.ceaserouteradv = resource.ceaserouteradv;\n\t\tupdateresource.sendrouteradv = resource.sendrouteradv;\n\t\tupdateresource.srclinklayeraddroption = resource.srclinklayeraddroption;\n\t\tupdateresource.onlyunicastrtadvresponse = resource.onlyunicastrtadvresponse;\n\t\tupdateresource.managedaddrconfig = resource.managedaddrconfig;\n\t\tupdateresource.otheraddrconfig = resource.otheraddrconfig;\n\t\tupdateresource.currhoplimit = resource.currhoplimit;\n\t\tupdateresource.maxrtadvinterval = resource.maxrtadvinterval;\n\t\tupdateresource.minrtadvinterval = resource.minrtadvinterval;\n\t\tupdateresource.linkmtu = resource.linkmtu;\n\t\tupdateresource.reachabletime = resource.reachabletime;\n\t\tupdateresource.retranstime = resource.retranstime;\n\t\tupdateresource.defaultlifetime = resource.defaultlifetime;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function extend(Container $app)\n    {\n        foreach ($this->getEnabledExtensions() as $extension) {\n            $extension->extend($app);\n        }\n    }", "label": 2}
{"code": "func (c *Client) GetDomainName() (string, error) {\n\tout, err := c.Get(c.Endpoint(\"domain\"), url.Values{})\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\tvar domain string\n\tif err := json.Unmarshal(out.Bytes(), &domain); err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\treturn domain, nil\n}", "label": 5}
{"code": "def _text_to_graphiz(self, text):\n        \"\"\"create a graphviz graph from text\"\"\"\n        dot = Source(text, format='svg')\n        return dot.pipe().decode('utf-8')", "label": 1}
{"code": "def updates(self, id, update_id=None): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get updates of a running result via long-polling.  If no updates are available, CDRouter waits up to 10 seconds before sending an empty response.\n\n        :param id: Result ID as an int.\n        :param update_id: (optional) Update ID as an int.\n        :return: :class:`results.Update <results.Update>` object\n        :rtype: results.Update\n\n        \"\"\"\n        if update_id is None:\n            update_id = -1\n        schema = UpdateSchema()\n        resp = self.service.get_id(self.base, id, params={'updates': update_id})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public static function fieldName($project, $database, $collectionId, $fieldId)\n    {\n        return self::getFieldNameTemplate()->render([\n            'project' => $project,\n            'database' => $database,\n            'collection_id' => $collectionId,\n            'field_id' => $fieldId,\n        ]);\n    }", "label": 2}
{"code": "public static function tar_error_msg( $process_run ) {\n\t\t$stderr = trim( $process_run->stderr );\n\t\t$nl_pos = strpos( $stderr, \"\\n\" );\n\t\tif ( false !== $nl_pos ) {\n\t\t\t$stderr = trim( substr( $stderr, 0, $nl_pos ) );\n\t\t}\n\t\tif ( $stderr ) {\n\t\t\treturn sprintf( '%s (%d)', $stderr, $process_run->return_code );\n\t\t}\n\t\treturn $process_run->return_code;\n\t}", "label": 2}
{"code": "func (m *MockEmbed) RegularMethod() {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"RegularMethod\")\n}", "label": 5}
{"code": "@Deprecated\n\t@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n\tpublic void setAttributes(Map<String, PrimitiveAttribute<?>> attributes) {\n\t\tif (!isPrimitiveOnly()) {\n\t\t\tthrow new UnsupportedOperationException(\"Primitive API not supported for nested association values\");\n\t\t}\n\t\tthis.attributes = (Map) attributes;\n\t}", "label": 0}
{"code": "func (c *Client) PutJSON(\n\tendpoint string, val interface{}) (*roundtrip.Response, error) {\n\treturn httplib.ConvertResponse(c.Client.PutJSON(context.TODO(), endpoint, val))\n}", "label": 5}
{"code": "func NewUnstartedServer(handler http.Handler, serve string) *Server {\n\treturn &Server{\n\t\tListener: newLocalListener(serve),\n\t\tConfig:   &http.Server{Handler: handler},\n\t}\n}", "label": 5}
{"code": "def strip_masked(fasta, min_len, print_masked):\n    \"\"\"\n    remove masked regions from fasta file as long as\n    they are longer than min_len\n    \"\"\"\n    for seq in parse_fasta(fasta):\n        nm, masked = parse_masked(seq, min_len)\n        nm = ['%s removed_masked >=%s' % (seq[0], min_len), ''.join(nm)]\n        yield [0, nm]\n        if print_masked is True:\n            for i, m in enumerate([i for i in masked if i != []], 1):\n                m = ['%s insertion:%s' % (seq[0], i), ''.join(m)]\n                yield [1, m]", "label": 1}
{"code": "func NewSCTPProxy(frontendAddr, backendAddr *sctp.SCTPAddr) (*SCTPProxy, error) {\n\tlistener, err := sctp.ListenSCTP(\"sctp\", frontendAddr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// If the port in frontendAddr was 0 then ListenSCTP will have a picked\n\t// a port to listen on, hence the call to Addr to get that actual port:\n\treturn &SCTPProxy{\n\t\tlistener:     listener,\n\t\tfrontendAddr: listener.Addr().(*sctp.SCTPAddr),\n\t\tbackendAddr:  backendAddr,\n\t}, nil\n}", "label": 5}
{"code": "def register(resource_class, options = {}, &block)\n      config = find_or_build_resource(resource_class, options)\n\n      # Register the resource\n      register_resource_controller(config)\n      parse_registration_block(config, &block) if block_given?\n      reset_menu!\n\n      # Dispatch a registration event\n      ActiveSupport::Notifications.publish ActiveAdmin::Resource::RegisterEvent, config\n\n      # Return the config\n      config\n    end", "label": 4}
{"code": "function(props) {\n      if (typeof props !== 'object') {\n        throw new Error('_configureItems called with invalid props');\n      }\n      // not initialized yet\n      if (!this._items) {\n        return;\n      }\n      this._items.configure({\n        where: bindIfFn(props.where, this),\n        filter: bindIfFn(props.filter, this),\n        limit: bindIfFn(props.limit, this),\n        offset: bindIfFn(props.offset, this),\n        comparator: bindIfFn(props.sort, this)\n      }, true);\n    }", "label": 3}
{"code": "public static function getClient($protocol = null)\n    {\n        $protocol = $protocol ?: self::DEFAULT_PROTOCOL;\n        return self::$clients[$protocol];\n    }", "label": 2}
{"code": "func (ap *AuthPermission) Save(db XODB) error {\n\tif ap.Exists() {\n\t\treturn ap.Update(db)\n\t}\n\n\treturn ap.Insert(db)\n}", "label": 5}
{"code": "public function setQuickReplies($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_QuickReplies::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function excludeFilesFrom($excludeFilesAndDirectories): self\n    {\n        $this->excludeFilesAndDirectories = $this->excludeFilesAndDirectories->merge($this->sanitize($excludeFilesAndDirectories));\n\n        return $this;\n    }", "label": 2}
{"code": "def ucharenc(a, i, u)\n    if u <= Uchar1max\n      a[i] = (u & 0xff).chr\n      1\n    elsif u <= Uchar2max\n      a[i+0] = (Utag2 | ((u>>6)&0xff)).chr\n      a[i+1] = (Utagx | (u&Umaskx)).chr\n      2\n    elsif u <= Uchar3max\n      a[i+0] = (Utag3 | ((u>>12)&0xff)).chr\n      a[i+1] = (Utagx | ((u>>6)&Umaskx)).chr\n      a[i+2] = (Utagx | (u&Umaskx)).chr\n      3\n    else\n      a[i+0] = (Utag4 | ((u>>18)&0xff)).chr\n      a[i+1] = (Utagx | ((u>>12)&Umaskx)).chr\n      a[i+2] = (Utagx | ((u>>6)&Umaskx)).chr\n      a[i+3] = (Utagx | (u&Umaskx)).chr\n      4\n    end\n  end", "label": 4}
{"code": "function expandKeys(object) {\n  var hasFlattenedKeys = _.some(object, function(val, key) {\n    return key.split('.').length > 1;\n  });\n  if (!hasFlattenedKeys) return object;\n\n  return _.reduce(object, function(payload, value, key) {\n    var path = key.split('.');\n    if (path.length === 1) {\n      var obj = {};\n      obj[key] = value;\n      payload = deepExtend(payload, obj);\n      return payload;\n    }\n    var subKey = path.pop();\n    var localObj = payload;\n    while (path.length) {\n      var subPath = path.shift();\n      localObj = localObj[subPath] = localObj[subPath] || {};\n    }\n    localObj[subKey] = object[key];\n    return payload;\n  }, {});\n}", "label": 3}
{"code": "def run(addr, *commands, **kwargs):\n    \"\"\"\n    Non-threaded batch command runner returning output results\n    \"\"\"\n    results = []\n    handler = VarnishHandler(addr, **kwargs)\n    for cmd in commands:\n        if isinstance(cmd, tuple) and len(cmd)>1:\n            results.extend([getattr(handler, c[0].replace('.','_'))(*c[1:]) for c in cmd])\n        else:\n            results.append(getattr(handler, cmd.replace('.','_'))(*commands[1:]))\n            break\n    handler.close()\n    return results", "label": 1}
{"code": "public function serialize()\n    {\n        $vars = get_object_vars($this);\n        $vars['keySet'] = $vars['keySet']->keySetObject();\n\n        return base64_encode(json_encode($vars + [\n            BatchClient::PARTITION_TYPE_KEY => static::class\n        ]));\n    }", "label": 2}
{"code": "def process_file_metrics(context, file_processors):\n    \"\"\"Main routine for metrics.\"\"\"\n    file_metrics = OrderedDict()\n\n    # TODO make available the includes and excludes feature\n    gitignore = []\n    if os.path.isfile('.gitignore'):\n        with open('.gitignore', 'r') as ifile:\n            gitignore = ifile.read().splitlines()\n\n    in_files = glob_files(context['root_dir'], context['in_file_names'], gitignore=gitignore)\n    # main loop\n    for in_file, key in in_files:\n        # print 'file %i: %s' % (i, in_file)\n        try:\n            with open(in_file, 'rb') as ifile:\n                code = ifile.read()\n            # lookup lexicographical scanner to use for this run\n            try:\n                lex = guess_lexer_for_filename(in_file, code, encoding='guess')\n                # encoding is 'guess', chardet', 'utf-8'\n            except:\n                pass\n            else:\n                token_list = lex.get_tokens(code)  # parse code\n\n                file_metrics[key] = OrderedDict()\n                file_metrics[key].update(compute_file_metrics(file_processors, lex.name, key, token_list))\n                file_metrics[key]['language'] = lex.name\n\n        except IOError as e:\n            sys.stderr.writelines(str(e) + \" -- Skipping input file.\\n\\n\")\n\n    return file_metrics", "label": 1}
{"code": "function validate(node, context) {\n  if (!node) {\n    return;\n  }\n\n  if (node.type === 'TaggedTemplateExpression' && node.tag.name !== 'sql') {\n    node = node.quasi;\n  }\n\n  if (node.type === 'TemplateLiteral' && node.expressions.length) {\n    const literal = node.quasis.map(quasi => quasi.value.raw).join('x');\n\n    if (isSqlQuery(literal)) {\n      context.report(node, 'Use the `sql` tagged template literal for raw queries');\n    }\n  }\n}", "label": 3}
{"code": "def get(filename, ignore_fields=None):\n    \"\"\"\n    Get all entries from a BibTeX file.\n\n    :param filename: The name of the BibTeX file.\n    :param ignore_fields: An optional list of fields to strip from the BibTeX \\\n            file.\n\n    :returns: A ``bibtexparser.BibDatabase`` object representing the fetched \\\n            entries.\n    \"\"\"\n    # Handle default argument\n    if ignore_fields is None:\n        ignore_fields = []\n\n    # Open bibtex file\n    with open(filename, 'r') as fh:\n        bibtex = bibtexparser.load(fh)\n\n    # Clean the entries if necessary\n    bibtex.entries = [{k: entry[k]\n                       for k in entry if k not in ignore_fields}\n                      for entry in bibtex.entries]\n\n    return bibtex", "label": 1}
{"code": "def produce(value, topic:, **options)\n      ensure_threads_running!\n\n      if @queue.size >= @max_queue_size\n        buffer_overflow topic,\n          \"Cannot produce to #{topic}, max queue size (#{@max_queue_size} messages) reached\"\n      end\n\n      args = [value, **options.merge(topic: topic)]\n      @queue << [:produce, args]\n\n      @instrumenter.instrument(\"enqueue_message.async_producer\", {\n        topic: topic,\n        queue_size: @queue.size,\n        max_queue_size: @max_queue_size,\n      })\n\n      nil\n    end", "label": 4}
{"code": "public void removeLinks(ServiceReference<D> declarationSRef) {\n        D declaration = getDeclaration(declarationSRef);\n        for (ServiceReference serviceReference : declaration.getStatus().getServiceReferencesBounded()) {\n            // FIXME : In case of multiples Linker, we will remove the link of all the ServiceReference\n            // FIXME : event the ones which dun know nothing about\n            linkerManagement.unlink(declaration, serviceReference);\n        }\n    }", "label": 0}
{"code": "public function setGcsDestination($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Asset\\V1\\GcsDestination::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (r *TunnelConnectionV2) String() string {\n\treturn fmt.Sprintf(\"TunnelConnection(name=%v, type=%v, cluster=%v, proxy=%v)\",\n\t\tr.Metadata.Name, r.Spec.Type, r.Spec.ClusterName, r.Spec.ProxyName)\n}", "label": 5}
{"code": "func (v VirtualMachine) Device(ctx context.Context) (VirtualDeviceList, error) {\n\tvar o mo.VirtualMachine\n\n\terr := v.Properties(ctx, v.Reference(), []string{\"config.hardware.device\", \"summary.runtime.connectionState\"}, &o)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Quoting the SDK doc:\n\t//   The virtual machine configuration is not guaranteed to be available.\n\t//   For example, the configuration information would be unavailable if the server\n\t//   is unable to access the virtual machine files on disk, and is often also unavailable\n\t//   during the initial phases of virtual machine creation.\n\tif o.Config == nil {\n\t\treturn nil, fmt.Errorf(\"%s Config is not available, connectionState=%s\",\n\t\t\tv.Reference(), o.Summary.Runtime.ConnectionState)\n\t}\n\n\treturn VirtualDeviceList(o.Config.Hardware.Device), nil\n}", "label": 5}
{"code": "public static base_responses unset(nitro_service client, String username[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (username != null && username.length > 0) {\n\t\t\tsystemuser unsetresources[] = new systemuser[username.length];\n\t\t\tfor (int i=0;i<username.length;i++){\n\t\t\t\tunsetresources[i] = new systemuser();\n\t\t\t\tunsetresources[i].username = username[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static sslcipher[] get(nitro_service service) throws Exception{\n\t\tsslcipher obj = new sslcipher();\n\t\tsslcipher[] response = (sslcipher[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function formatNotifiable($notifiable)\n    {\n        if ($notifiable instanceof Model) {\n            return FormatModel::given($notifiable);\n        } elseif ($notifiable instanceof AnonymousNotifiable) {\n            return 'Anonymous:'.implode(',', $notifiable->routes);\n        }\n\n        return get_class($notifiable);\n    }", "label": 2}
{"code": "def run_tsne(self, X=None, metric='correlation', **kwargs):\n        \"\"\"Wrapper for sklearn's t-SNE implementation.\n\n        See sklearn for the t-SNE documentation. All arguments are the same\n        with the exception that 'metric' is set to 'precomputed' by default,\n        implying that this function expects a distance matrix by default.\n        \"\"\"\n        if(X is not None):\n            dt = man.TSNE(metric=metric, **kwargs).fit_transform(X)\n            return dt\n\n        else:\n            dt = man.TSNE(metric=self.distance,\n                          **kwargs).fit_transform(self.adata.obsm['X_pca'])\n            tsne2d = dt\n            self.adata.obsm['X_tsne'] = tsne2d", "label": 1}
{"code": "func (f *Fpdf) textstring(s string) string {\n\tif f.protect.encrypted {\n\t\tb := []byte(s)\n\t\tf.protect.rc4(uint32(f.n), &b)\n\t\ts = string(b)\n\t}\n\treturn \"(\" + f.escape(s) + \")\"\n}", "label": 5}
{"code": "public function render()\n    {\n        $results = '';\n        foreach ($this->toArray() as $column => $attributes) {\n            $results .= $this->createField($column, $attributes);\n        }\n\n        return $results;\n    }", "label": 2}
{"code": "func isIP6AddrResolvable(fl FieldLevel) bool {\n\n\tif !isIPv6(fl) {\n\t\treturn false\n\t}\n\n\t_, err := net.ResolveIPAddr(\"ip6\", fl.Field().String())\n\n\treturn err == nil\n}", "label": 5}
{"code": "def consume!(token)\n      return self if @error\n\n      action = @state.action[token] || @state.defact\n      case action\n      when Shift\n        @sstack.push(@state)\n        @state = action.goto_state\n        shifted(token)\n      when Reduce\n        reduce_by!(action.rule)\n        consume!(token)\n      when Accept\n        done\n      when Error\n        @error = true\n        error\n      else\n        raise \"Illegal action type: #{action.class}\"\n      end\n\n      self\n    end", "label": 4}
{"code": "public static void finishThread(){\r\n    //--Create Task\r\n    final long threadId = Thread.currentThread().getId();\r\n    Runnable finish = new Runnable(){\r\n      public void run(){\r\n        releaseThreadControl(threadId);\r\n      }\r\n    };\r\n    //--Run Task\r\n    if(isThreaded){\r\n      //(case: multithreaded)\r\n      attemptThreadControl( threadId, finish );\r\n    } else {\r\n      //(case: no threading)\r\n      throw new IllegalStateException(\"finishThreads() called outside of threaded environment\");\r\n    }\r\n  }", "label": 0}
{"code": "def touch(name = nil)\n      now = DateTime.now\n      self.updated_at = now\n      attributes[name] = now if name\n      save\n    end", "label": 4}
{"code": "func ioctlAddToBridge(iface, master *net.Interface) error {\n\treturn ifIoctBridge(iface, master, ioctlBrAddIf)\n}", "label": 5}
{"code": "public function setLastElementIdentifier($value, $type = Key::TYPE_ID)\n    {\n        $end = $this->pathEnd();\n        $end[$type] = (string) $value;\n\n        $elements = array_keys($this->path);\n        $lastElement = end($elements);\n\n        $this->path[$lastElement] = $end;\n    }", "label": 2}
{"code": "func ArrayEach(data []byte, cb func(value []byte, dataType ValueType, offset int, err error), keys ...string) (offset int, err error) {\n\tif len(data) == 0 {\n\t\treturn -1, MalformedObjectError\n\t}\n\n\toffset = 1\n\n\tif len(keys) > 0 {\n\t\tif offset = searchKeys(data, keys...); offset == -1 {\n\t\t\treturn offset, KeyPathNotFoundError\n\t\t}\n\n\t\t// Go to closest value\n\t\tnO := nextToken(data[offset:])\n\t\tif nO == -1 {\n\t\t\treturn offset, MalformedJsonError\n\t\t}\n\n\t\toffset += nO\n\n\t\tif data[offset] != '[' {\n\t\t\treturn offset, MalformedArrayError\n\t\t}\n\n\t\toffset++\n\t}\n\n\tnO := nextToken(data[offset:])\n\tif nO == -1 {\n\t\treturn offset, MalformedJsonError\n\t}\n\n\toffset += nO\n\n\tif data[offset] == ']' {\n\t\treturn offset, nil\n\t}\n\n\tfor true {\n\t\tv, t, o, e := Get(data[offset:])\n\n\t\tif e != nil {\n\t\t\treturn offset, e\n\t\t}\n\n\t\tif o == 0 {\n\t\t\tbreak\n\t\t}\n\n\t\tif t != NotExist {\n\t\t\tcb(v, t, offset+o-len(v), e)\n\t\t}\n\n\t\tif e != nil {\n\t\t\tbreak\n\t\t}\n\n\t\toffset += o\n\n\t\tskipToToken := nextToken(data[offset:])\n\t\tif skipToToken == -1 {\n\t\t\treturn offset, MalformedArrayError\n\t\t}\n\t\toffset += skipToToken\n\n\t\tif data[offset] == ']' {\n\t\t\tbreak\n\t\t}\n\n\t\tif data[offset] != ',' {\n\t\t\treturn offset, MalformedArrayError\n\t\t}\n\n\t\toffset++\n\t}\n\n\treturn offset, nil\n}", "label": 5}
{"code": "public function setAutoExpansionMode($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\EntityType_AutoExpansionMode::class);\n        $this->auto_expansion_mode = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "async function renderCatalog (opts = {}) {\n  if (!opts.fontName) throw new ReferenceError('fontName is undefined');\n  if (!opts.className) throw new ReferenceError('className is undefined');\n  if (!opts.icons || !opts.icons.length) throw new ReferenceError('icons is undefined or empty');\n\n  const fonts = opts.fonts\n    ? Object.keys(opts.fonts).reduce((acc, name) => {\n      return {\n        ...acc,\n        [name]: opts.fonts[name].contents.toString('base64')\n      };\n    }, {})\n    : undefined;\n\n  return JSON.stringify({\n    name: opts.fontName,\n    className: opts.className,\n    fonts,\n    icons: opts.icons.map(i => ({\n      icon: `${opts.className}-${i.name}`,\n      charCode: `${i.codepoint.toString(16).toUpperCase()}`\n    }))\n  });\n}", "label": 3}
{"code": "function some(iterable, n) {\n\n  if (n <= 0) return true;\n\n  for (let item of iterable) {\n\n    if (item && --n === 0) return true;\n  }\n\n  return false;\n}", "label": 3}
{"code": "def update_presence(data)\n      @status = data['status'].to_sym\n\n      if data['game']\n        game = data['game']\n\n        @game = game['name']\n        @stream_url = game['url']\n        @stream_type = game['type']\n      else\n        @game = @stream_url = @stream_type = nil\n      end\n    end", "label": 4}
{"code": "public static function createFromLocaleIsoFormat($format, $locale, $time, $tz = null)\n    {\n        $time = static::translateTimeString($time, $locale, 'en', CarbonInterface::TRANSLATE_MONTHS | CarbonInterface::TRANSLATE_DAYS | CarbonInterface::TRANSLATE_MERIDIEM);\n\n        return static::createFromIsoFormat($format, $time, $tz, $locale);\n    }", "label": 2}
{"code": "public function setTimeEvents($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Trace\\V2\\Span_TimeEvents::class);\n        $this->time_events = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function setValueDisplay() {\n      var selectedIndex = self.$manipulatorTarget.get('selectedIndex');\n      var $options = self.$manipulatorTarget.select('option');\n      var value = $options[selectedIndex] && $options[selectedIndex].innerHTML;\n      $value.set('innerHTML', value);\n    }", "label": 3}
{"code": "func (s *PresenceService) GetNodes(namespace string, opts ...services.MarshalOption) ([]services.Server, error) {\n\tif namespace == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing namespace value\")\n\t}\n\n\t// Get all items in the bucket.\n\tstartKey := backend.Key(nodesPrefix, namespace)\n\tresult, err := s.GetRange(context.TODO(), startKey, backend.RangeEnd(startKey), backend.NoLimit)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\t// Marshal values into a []services.Server slice.\n\tservers := make([]services.Server, len(result.Items))\n\tfor i, item := range result.Items {\n\t\tserver, err := services.GetServerMarshaler().UnmarshalServer(\n\t\t\titem.Value,\n\t\t\tservices.KindNode,\n\t\t\tservices.AddOptions(opts,\n\t\t\t\tservices.WithResourceID(item.ID),\n\t\t\t\tservices.WithExpires(item.Expires))...)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tservers[i] = server\n\t}\n\n\treturn servers, nil\n}", "label": 5}
{"code": "def external_icon(path, options = {})\n      classes = _icon_classes(options) + [\"external-icon\"]\n\n      if path.split(\".\").last == \"svg\"\n        asset = Rails.application.assets_manifest.find_sources(path).first\n        asset.gsub(\"<svg \", \"<svg class=\\\"#{classes.join(\" \")}\\\" \").html_safe\n      else\n        image_tag(path, class: classes.join(\" \"), style: \"display: none\")\n      end\n    end", "label": 4}
{"code": "def gpu_iuwt_recomposition(in1, scale_adjust, store_on_gpu, smoothed_array):\n    \"\"\"\n    This function calls the a trous algorithm code to recompose the input into a single array. This is the\n    implementation of the isotropic undecimated wavelet transform recomposition for a GPU.\n\n    INPUTS:\n    in1             (no default):   Array containing wavelet coefficients.\n    scale_adjust    (no default):   Indicates the number of omitted array pages.\n    store_on_gpu    (no default):   Boolean specifier for whether the decomposition is stored on the gpu or not.\n\n    OUTPUTS:\n    recomposiiton                   Array containing the reconstructed array.\n    \"\"\"\n\n    wavelet_filter = (1./16)*np.array([1,4,6,4,1], dtype=np.float32)    # Filter-bank for use in the a trous algorithm.\n    wavelet_filter = gpuarray.to_gpu_async(wavelet_filter)\n\n    # Determines scale with adjustment and creates a zero array on the GPU to store the output,unless smoothed_array\n    # is given.\n\n    max_scale = in1.shape[0] + scale_adjust\n\n    if smoothed_array is None:\n        recomposition = gpuarray.zeros([in1.shape[1], in1.shape[2]], np.float32)\n    else:\n        recomposition = gpuarray.to_gpu(smoothed_array.astype(np.float32))\n\n    # Determines whether the array is already on the GPU or not. If not, moves it to the GPU.\n\n    try:\n        gpu_in1 = gpuarray.to_gpu_async(in1.astype(np.float32))\n    except:\n        gpu_in1 = in1\n\n    # Creates a working array on the GPU.\n\n    gpu_tmp = gpuarray.empty_like(recomposition)\n\n    # Creates and fills an array with the appropriate scale value.\n\n    gpu_scale = gpuarray.zeros([1], np.int32)\n    gpu_scale += max_scale-1\n\n     # Fetches the a trous kernels.\n\n    gpu_a_trous_row_kernel, gpu_a_trous_col_kernel = gpu_a_trous()\n\n    grid_rows = int(in1.shape[1]//32)\n    grid_cols = int(in1.shape[2]//32)\n\n    # The following loops call the a trous algorithm code to recompose the input. The first loop assumes that there are\n    # non-zero wavelet coefficients at scales above scale_adjust, while the second loop completes the recomposition\n    # on the scales less than scale_adjust.\n\n    for i in range(max_scale-1, scale_adjust-1, -1):\n        gpu_a_trous_row_kernel(recomposition, gpu_tmp, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n        gpu_a_trous_col_kernel(gpu_tmp, recomposition, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n        recomposition = recomposition[:,:] + gpu_in1[i-scale_adjust,:,:]\n\n        gpu_scale -= 1\n\n    if scale_adjust>0:\n        for i in range(scale_adjust-1, -1, -1):\n            gpu_a_trous_row_kernel(recomposition, gpu_tmp, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n            gpu_a_trous_col_kernel(gpu_tmp, recomposition, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n            gpu_scale -= 1\n\n    # Return values depend on mode.\n\n    if store_on_gpu:\n        return recomposition\n    else:\n        return recomposition.get()", "label": 1}
{"code": "func SetSessionStreamPollPeriod(period time.Duration) HandlerOption {\n\treturn func(h *Handler) error {\n\t\tif period < 0 {\n\t\t\treturn trace.BadParameter(\"period should be non zero\")\n\t\t}\n\t\th.sessionStreamPollPeriod = period\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public function setContentMatchers($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Monitoring\\V3\\UptimeCheckConfig\\ContentMatcher::class);\n        $this->content_matchers = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static function elementValueContains(WebDriverBy $by, $text)\n    {\n        return new static(\n            function (WebDriver $driver) use ($by, $text) {\n                try {\n                    $element_text = $driver->findElement($by)->getAttribute('value');\n\n                    return mb_strpos($element_text, $text) !== false;\n                } catch (StaleElementReferenceException $e) {\n                    return null;\n                }\n            }\n        );\n    }", "label": 2}
{"code": "protected static <E extends LogRecordHandler> boolean removeHandler(Class<E> toRemove) {\r\n    boolean rtn = false;\r\n    Iterator<LogRecordHandler> iter = handlers.iterator();\r\n    while(iter.hasNext()){\r\n      if(iter.next().getClass().equals(toRemove)){\r\n        rtn = true;\r\n        iter.remove();\r\n      }\r\n    }\r\n    return rtn;\r\n  }", "label": 0}
{"code": "protected boolean check(String value, String regex) {\n\t\tPattern pattern = Pattern.compile(regex);\n\t\treturn pattern.matcher(value).matches();\n\t}", "label": 0}
{"code": "public function getTaxTotal(): int\n    {\n        $taxTotal = 0;\n\n        foreach ($this->getAdjustments(AdjustmentInterface::TAX_ADJUSTMENT) as $taxAdjustment) {\n            $taxTotal += $taxAdjustment->getAmount();\n        }\n        foreach ($this->items as $item) {\n            $taxTotal += $item->getTaxTotal();\n        }\n\n        return $taxTotal;\n    }", "label": 2}
{"code": "def _get_pq_array_construct(self):\n        \"\"\" Returns a construct for an array of PQ load data.\n        \"\"\"\n        bus_no = integer.setResultsName(\"bus_no\")\n        s_rating = real.setResultsName(\"s_rating\") # MVA\n        v_rating = real.setResultsName(\"v_rating\") # kV\n        p = real.setResultsName(\"p\") # p.u.\n        q = real.setResultsName(\"q\") # p.u.\n        v_max = Optional(real).setResultsName(\"v_max\") # p.u.\n        v_min = Optional(real).setResultsName(\"v_min\") # p.u.\n        # Allow conversion to impedance\n        z_conv = Optional(boolean).setResultsName(\"z_conv\")\n        status = Optional(boolean).setResultsName(\"status\")\n\n        pq_data = bus_no + s_rating + v_rating + p + q + v_max + \\\n            v_min + z_conv + status + scolon\n\n        pq_data.setParseAction(self.push_pq)\n\n        pq_array = Literal(\"PQ.con\") + \"=\" + \"[\" + \"...\" + \\\n            ZeroOrMore(pq_data + Optional(\"]\" + scolon))\n\n        return pq_array", "label": 1}
{"code": "public function wait(): array\n    {\n        // Read all the streams from child processes into an array.\n        $content = $this->readResultsFromChildren();\n\n        // Wait for all children to return\n        foreach ($this->child_pid_list as $child_pid) {\n            $process_lookup = posix_kill($child_pid, 0);\n\n            $status = 0;\n\n            if ($process_lookup) {\n                /**\n                 * @psalm-suppress UndefinedConstant - does not exist on windows\n                 * @psalm-suppress MixedArgument\n                 */\n                posix_kill($child_pid, SIGALRM);\n\n                if (pcntl_waitpid($child_pid, $status) < 0) {\n                    error_log(posix_strerror(posix_get_last_error()));\n                }\n            }\n\n            // Check to see if the child died a graceful death\n            if (pcntl_wifsignaled($status)) {\n                $return_code = pcntl_wexitstatus($status);\n                $term_sig = pcntl_wtermsig($status);\n\n                /**\n                 * @psalm-suppress UndefinedConstant - does not exist on windows\n                 */\n                if ($term_sig !== SIGALRM) {\n                    $this->did_have_error = true;\n                    error_log(\"Child terminated with return code $return_code and signal $term_sig\");\n                }\n            }\n        }\n\n        return $content;\n    }", "label": 2}
{"code": "def build(self, recipe, plugin=None):\n        \"\"\"\n        Execute a recipe and creates new folder and files.\n\n        :param recipe: Name of the recipe\n        :param plugin: Name of the plugin, to which the recipe must belong.\n        \"\"\"\n        if recipe not in self.recipes.keys():\n            raise RecipeMissingException(\"Recipe %s unknown.\" % recipe)\n\n        recipe_obj = self.recipes[recipe]\n\n        if plugin is not None:\n            if recipe_obj.plugin != plugin:\n                raise RecipeWrongPluginException(\"The requested recipe does not belong to the given plugin. Use\"\n                                                 \"the app object, to retrieve the requested recipe: \"\n                                                 \"my_app.recipes.get(%s)\" % recipe)\n\n        recipe_obj.build()", "label": 1}
{"code": "func prepareApp(p *stage1commontypes.Pod, ra *schema.RuntimeApp) (*preparedApp, error) {\n\tpa := preparedApp{\n\t\tapp:             ra,\n\t\tenv:             ra.App.Environment,\n\t\tnoNewPrivileges: getAppNoNewPrivileges(ra.App.Isolators),\n\t}\n\tvar err error\n\n\t// Determine numeric uid and gid\n\tu, g, err := ParseUserGroup(p, ra)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"unable to determine app's uid and gid\"), err)\n\t}\n\tif u < 0 || g < 0 {\n\t\treturn nil, errors.New(\"Invalid uid or gid\")\n\t}\n\tpa.uid = uint32(u)\n\tpa.gid = uint32(g)\n\n\t// Set some rkt-provided environment variables\n\tpa.env.Set(\"AC_APP_NAME\", ra.Name.String())\n\tif p.MetadataServiceURL != \"\" {\n\t\tpa.env.Set(\"AC_METADATA_URL\", p.MetadataServiceURL)\n\t}\n\n\t// Determine capability set\n\tpa.capabilities, err = getAppCapabilities(ra.App.Isolators)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"unable to construct capabilities\"), err)\n\t}\n\n\t// Determine mounts\n\tcfd := ConvertedFromDocker(p.Images[ra.Name.String()])\n\tpa.mounts, err = GenerateMounts(ra, p.Manifest.Volumes, cfd)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"unable to compute mounts\"), err)\n\t}\n\n\t// Compute resources\n\tpa.resources, err = computeAppResources(ra.App.Isolators)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"unable to compute resources\"), err)\n\t}\n\n\t// Protect kernel tunables by default\n\tif !p.InsecureOptions.DisablePaths {\n\t\tpa.roPaths = append(pa.roPaths, protectKernelROPaths...)\n\t\tpa.hiddenPaths = append(pa.hiddenDirs, protectKernelHiddenPaths...)\n\t\tpa.hiddenDirs = append(pa.hiddenDirs, protectKernelHiddenDirs...)\n\t}\n\n\t// Seccomp\n\tif !p.InsecureOptions.DisableSeccomp {\n\t\tpa.seccomp, err = generateSeccompFilter(p, &pa)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif pa.seccomp != nil && pa.seccomp.forceNoNewPrivileges {\n\t\t\tpa.noNewPrivileges = true\n\t\t}\n\t}\n\n\t// Write the systemd-sysusers config file\n\tif err := generateSysusers(p, pa.app, int(pa.uid), int(pa.gid), &p.UidRange); err != nil {\n\t\treturn nil, errwrap.Wrapf(\"unable to generate sysusers file\", err)\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "public function setCluster($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\Admin\\V2\\Cluster::class);\n        $this->cluster = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private MetadataManager initOJB()\r\n    {\r\n        try\r\n        {\r\n            if (_ojbPropertiesFile == null)\r\n            {\r\n                _ojbPropertiesFile = new File(\"OJB.properties\");\r\n                if (!_ojbPropertiesFile.exists())\r\n                {\r\n                    throw new BuildException(\"Could not find OJB.properties, please specify it via the ojbpropertiesfile attribute\");\r\n                }\r\n            }\r\n            else\r\n            {\r\n                if (!_ojbPropertiesFile.exists())\r\n                {\r\n                    throw new BuildException(\"Could not load the specified OJB properties file \"+_ojbPropertiesFile);\r\n                }\r\n                log(\"Using properties file \"+_ojbPropertiesFile.getAbsolutePath(), Project.MSG_INFO);\r\n                System.setProperty(\"OJB.properties\", _ojbPropertiesFile.getAbsolutePath());\r\n            }\r\n\r\n            MetadataManager     metadataManager = MetadataManager.getInstance();\r\n            RepositoryPersistor persistor       = new RepositoryPersistor();\r\n\r\n            if (_repositoryFile != null)\r\n            {\r\n                if (!_repositoryFile.exists())\r\n                {\r\n                    throw new BuildException(\"Could not load the specified repository file \"+_repositoryFile);\r\n                }\r\n                log(\"Loading repository file \"+_repositoryFile.getAbsolutePath(), Project.MSG_INFO);\r\n\r\n                // this will load the info from the specified repository file\r\n                // and merge it with the existing info (if it has been loaded)\r\n                metadataManager.mergeConnectionRepository(persistor.readConnectionRepository(_repositoryFile.getAbsolutePath()));\r\n                metadataManager.mergeDescriptorRepository(persistor.readDescriptorRepository(_repositoryFile.getAbsolutePath()));\r\n            }\r\n            else if (metadataManager.connectionRepository().getAllDescriptor().isEmpty() &&\r\n                     metadataManager.getGlobalRepository().getDescriptorTable().isEmpty())\r\n            {\r\n                // Seems nothing was loaded, probably because we're not starting in the directory\r\n                // that the properties file is in, and the repository file path is relative\r\n                // So lets try to resolve this path and load the repository info manually\r\n                Properties props = new Properties();\r\n\r\n                props.load(new FileInputStream(_ojbPropertiesFile));\r\n    \r\n                String repositoryPath = props.getProperty(\"repositoryFile\", \"repository.xml\");\r\n                File   repositoryFile = new File(repositoryPath);\r\n    \r\n                if (!repositoryFile.exists())\r\n                {\r\n                    repositoryFile = new File(_ojbPropertiesFile.getParentFile(), repositoryPath);\r\n                }\r\n                metadataManager.mergeConnectionRepository(persistor.readConnectionRepository(repositoryFile.getAbsolutePath()));\r\n                metadataManager.mergeDescriptorRepository(persistor.readDescriptorRepository(repositoryFile.getAbsolutePath()));\r\n            }\r\n            // we might have to determine the default pb key ourselves\r\n            if (metadataManager.getDefaultPBKey() == null)\r\n            {\r\n                for (Iterator it = metadataManager.connectionRepository().getAllDescriptor().iterator(); it.hasNext();)\r\n                {\r\n                    JdbcConnectionDescriptor descriptor = (JdbcConnectionDescriptor)it.next();\r\n\r\n                    if (descriptor.isDefaultConnection())\r\n                    {\r\n                        metadataManager.setDefaultPBKey(new PBKey(descriptor.getJcdAlias(), descriptor.getUserName(), descriptor.getPassWord()));\r\n                        break;\r\n                    }\r\n                }\r\n            }\r\n            return metadataManager;\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            if (ex instanceof BuildException)\r\n            {\r\n                throw (BuildException)ex;\r\n            }\r\n            else\r\n            {\r\n                throw new BuildException(ex);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def move(user, channel)\n      API::Server.update_member(@bot.token, @id, user.resolve_id, channel_id: channel.resolve_id)\n    end", "label": 4}
{"code": "protected function mailNotifications(MailableInterface $blueprint, array $recipients)\n    {\n        foreach ($recipients as $user) {\n            if ($user->shouldEmail($blueprint::getType())) {\n                $this->mailer->send($blueprint, $user);\n            }\n        }\n    }", "label": 2}
{"code": "function doRequest (options, items) {\n  const uid = options.uid || uuid.v4()\n  const date = options.currentDate || new Date()\n  const soapOptions = {}\n  if (options.playground) {\n    soapOptions.endpoint = PG_WSDL_URL\n  }\n  if (options.httpClient) {\n    soapOptions.httpClient = options.httpClient\n  }\n  const timeout = options.timeout || 2000\n  const offline = options.offline || false\n\n  return new Promise((resolve, reject) => {\n    const body = getBodyItems(options.privateKey, date, uid, items)\n    soap.createClient(WSDL, soapOptions, (err, client) => {\n      if (err) return reject(err)\n      client.setSecurity(new WSSecurity(options.privateKey, options.certificate, uid))\n      client.OdeslaniTrzby(body, (err, response) => {\n        if (err) return reject(err)\n        try {\n          validate.httpResponse(response)\n          resolve(getResponseItems(response))\n        } catch (e) {\n          reject(e)\n        }\n      }, {timeout: timeout})\n    })\n  }).catch(err => {\n    if (!offline) return Promise.reject(err)\n    let code = getFooterItems(options.privateKey, items)\n    let bkp = code.bkp\n    let pkp = code.pkp\n    return Promise.resolve({pkp: pkp.$value, bkp: bkp.$value, err})\n  })\n}", "label": 3}
{"code": "def set(stat, value, opts=EMPTY_OPTIONS)\n      opts = {:sample_rate => opts} if opts.is_a? Numeric\n      send_stats stat, value, SET_TYPE, opts\n    end", "label": 4}
{"code": "def friendly_id(base = nil, options = {}, &block)\n      yield friendly_id_config if block_given?\n      friendly_id_config.dependent = options.delete :dependent\n      friendly_id_config.use options.delete :use\n      friendly_id_config.send :set, base ? options.merge(:base => base) : options\n      include Model\n    end", "label": 4}
{"code": "public function setNormalizedBoundingBox($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\VideoIntelligence\\V1\\NormalizedBoundingBox::class);\n        $this->normalized_bounding_box = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func connectToSSHAgent() agent.Agent {\n\tsocketPath := os.Getenv(teleport.SSHAuthSock)\n\tconn, err := agentconn.Dial(socketPath)\n\tif err != nil {\n\t\tlog.Errorf(\"[KEY AGENT] Unable to connect to SSH agent on socket: %q.\", socketPath)\n\t\treturn nil\n\t}\n\n\tlog.Infof(\"[KEY AGENT] Connected to the system agent: %q\", socketPath)\n\treturn agent.NewClient(conn)\n}", "label": 5}
{"code": "private function executeExtraUpdates()\n    {\n        foreach ($this->extraUpdates as $oid => $update) {\n            [$entity, $changeset] = $update;\n\n            $this->entityChangeSets[$oid] = $changeset;\n\n            $this->getEntityPersister(get_class($entity))->update($entity);\n        }\n\n        $this->extraUpdates = [];\n    }", "label": 2}
{"code": "def _ref_check(self, case):\n        \"\"\" Checks that there is only one reference bus.\n        \"\"\"\n        refs = [bus._i for bus in case.buses if bus.type == REFERENCE]\n\n        if len(refs) == 1:\n            return True, refs\n        else:\n            logger.error(\"OPF requires a single reference bus.\")\n            return False, refs", "label": 1}
{"code": "private void setMaxMin(IntervalRBTreeNode<T> n) {\n    n.min = n.left;\n    n.max = n.right;\n    if (n.leftChild != null) {\n      n.min = Math.min(n.min, n.leftChild.min);\n      n.max = Math.max(n.max, n.leftChild.max);\n    }\n    if (n.rightChild != null) {\n      n.min = Math.min(n.min, n.rightChild.min);\n      n.max = Math.max(n.max, n.rightChild.max);\n    }\n  }", "label": 0}
{"code": "def render_bad_parameters(*args)\n      default_message = if request.xhr?\n                          _('Invalid parameters sent in the request for this operation. Please contact a system administrator.')\n                        else\n                          _('Invalid parameters sent. You may have mistyped the address. If you continue having trouble with this, please contact an Administrator.')\n                        end\n\n      exception = args.find { |o| o.is_a? Exception }\n      message   = args.find { |o| o.is_a? String } || exception.try(:message) || default_message\n\n      status = if exception && exception.respond_to?(:status_code)\n                 exception.status_code\n               else\n                 400\n               end\n\n      if exception\n        log_exception exception\n      else\n        Rails.logger.warn message\n      end\n\n      respond_to do |format|\n        format.html do\n          render :template => 'common/400', :layout => !request.xhr?, :status => status,\n                 :locals   => {:message => message}\n        end\n        format.atom { head exception.status_code }\n        format.xml  { head exception.status_code }\n        format.json { head exception.status_code }\n      end\n      User.current = nil\n    end", "label": 4}
{"code": "function generateCSVSingleValue(field, val, downloadUrl, submissionId) {\n  var line = '';\n  var fieldValue = val;\n  if (!(typeof (fieldValue) === 'undefined' || fieldValue === null)) {\n    //Value is something, add the value\n    if (field.type === 'checkboxes') {\n      fieldValue = val.selections;\n    } else if (fieldTypeUtils.isFileType(field.type)) {\n      //File types have two fields, a name and url to be added\n      if (val.fileName) {\n        fieldValue = val.fileName;\n      } else {\n        fieldValue = '<not uploaded>';\n      }\n    } else if (fieldTypeUtils.isBarcodeType(field.type)) {\n      if (val.format) {\n        fieldValue = val.format;\n      } else {\n        fieldValue = \"<not set>\";\n      }\n    }\n    line += csvStr(fieldValue);\n    line += ',';\n\n    //If it is a file type, then the url should also be added\n    if (fieldTypeUtils.isFileType(field.type)) {\n      if (val.groupId) {\n        fieldValue = downloadUrl.replace(\":id\", submissionId).replace(\":fileId\", val\n          .groupId);\n      } else {\n        fieldValue = '<not uploaded>';\n      }\n\n      line += csvStr(fieldValue);\n      line += ',';\n    } else if (fieldTypeUtils.isBarcodeType(field.type)) {\n      if (val.text) {\n        fieldValue = val.text;\n      } else {\n        fieldValue = \"<not set>\";\n      }\n      line += csvStr(fieldValue);\n      line += ',';\n    }\n\n  } else {\n    //No value, spacers have to be added.\n\n    //For file type, the file name and url are included. Therefore blank values have to be spaced twice.\n    if (fieldTypeUtils.isFileType(field.type) || fieldTypeUtils.isBarcodeType(\n        field.type)) {\n      line += ',,';\n    } else {\n      line += ',';\n    }\n  }\n\n  return line;\n}", "label": 3}
{"code": "func (p *DatastorePath) String() string {\n\ts := fmt.Sprintf(\"[%s]\", p.Datastore)\n\n\tif p.Path == \"\" {\n\t\treturn s\n\t}\n\n\treturn strings.Join([]string{s, p.Path}, \" \")\n}", "label": 5}
{"code": "public function getOrderPromotionTotal(): int\n    {\n        $orderPromotionTotal = 0;\n\n        foreach ($this->items as $item) {\n            $orderPromotionTotal += $item->getAdjustmentsTotalRecursively(AdjustmentInterface::ORDER_PROMOTION_ADJUSTMENT);\n        }\n\n        return $orderPromotionTotal;\n    }", "label": 2}
{"code": "func (t *Torrent) byteRegionPieces(off, size int64) (begin, end pieceIndex) {\n\tif off >= *t.length {\n\t\treturn\n\t}\n\tif off < 0 {\n\t\tsize += off\n\t\toff = 0\n\t}\n\tif size <= 0 {\n\t\treturn\n\t}\n\tbegin = pieceIndex(off / t.info.PieceLength)\n\tend = pieceIndex((off + size + t.info.PieceLength - 1) / t.info.PieceLength)\n\tif end > pieceIndex(t.info.NumPieces()) {\n\t\tend = pieceIndex(t.info.NumPieces())\n\t}\n\treturn\n}", "label": 5}
{"code": "public static base_response export(nitro_service client, sslfipskey resource) throws Exception {\n\t\tsslfipskey exportresource = new sslfipskey();\n\t\texportresource.fipskeyname = resource.fipskeyname;\n\t\texportresource.key = resource.key;\n\t\treturn exportresource.perform_operation(client,\"export\");\n\t}", "label": 0}
{"code": "func (tc *TeleportClient) directLogin(ctx context.Context, secondFactorType string, pub []byte) (*auth.SSHLoginResponse, error) {\n\tvar err error\n\n\tvar password string\n\tvar otpToken string\n\n\tpassword, err = tc.AskPassword()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// only ask for a second factor if it's enabled\n\tif secondFactorType != teleport.OFF {\n\t\totpToken, err = tc.AskOTP()\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\n\t// ask the CA (via proxy) to sign our public key:\n\tresponse, err := tc.credClient.SSHAgentLogin(\n\t\tctx,\n\t\ttc.Config.Username,\n\t\tpassword,\n\t\totpToken,\n\t\tpub,\n\t\ttc.KeyTTL,\n\t\ttc.CertificateFormat)\n\n\treturn response, trace.Wrap(err)\n}", "label": 5}
{"code": "def image(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'image_for', &block)\n      define_method(\"#{name}_loaded?\") do\n        return platform.image_loaded_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").loaded?\n      end\n    end", "label": 4}
{"code": "public function topic()\n    {\n        if ($this->info['topic']) {\n            return new Topic(\n                $this->connection,\n                $this->projectId,\n                $this->info['topic'],\n                $this->encode,\n                [],\n                $this->clientConfig\n            );\n        }\n\n        return null;\n    }", "label": 2}
{"code": "private static void handleSignals() {\n        if (DaemonStarter.isRunMode()) {\n            try {\n                // handle SIGHUP to prevent process to get killed when exiting the tty\n                Signal.handle(new Signal(\"HUP\"), arg0 -> {\n                    // Nothing to do here\n                    System.out.println(\"SIG INT\");\n                });\n            } catch (IllegalArgumentException e) {\n                System.err.println(\"Signal HUP not supported\");\n            }\n\n            try {\n                // handle SIGTERM to notify the program to stop\n                Signal.handle(new Signal(\"TERM\"), arg0 -> {\n                    System.out.println(\"SIG TERM\");\n                    DaemonStarter.stopService();\n                });\n            } catch (IllegalArgumentException e) {\n                System.err.println(\"Signal TERM not supported\");\n            }\n\n            try {\n                // handle SIGINT to notify the program to stop\n                Signal.handle(new Signal(\"INT\"), arg0 -> {\n                    System.out.println(\"SIG INT\");\n                    DaemonStarter.stopService();\n                });\n            } catch (IllegalArgumentException e) {\n                System.err.println(\"Signal INT not supported\");\n            }\n\n            try {\n                // handle SIGUSR2 to notify the life-cycle listener\n                Signal.handle(new Signal(\"USR2\"), arg0 -> {\n                    System.out.println(\"SIG USR2\");\n                    DaemonStarter.getLifecycleListener().signalUSR2();\n                });\n            } catch (IllegalArgumentException e) {\n                System.err.println(\"Signal USR2 not supported\");\n            }\n        }\n    }", "label": 0}
{"code": "def validate_configured_sources!\n      Gem.sources.each_source do |src|\n        begin\n          src.load_specs(:released)\n        rescue Gem::Exception => source_error\n          if ENV[\"VAGRANT_ALLOW_PLUGIN_SOURCE_ERRORS\"]\n            @logger.warn(\"Failed to load configured plugin source: #{src}!\")\n            @logger.warn(\"Error received attempting to load source (#{src}): #{source_error}\")\n            @logger.warn(\"Ignoring plugin source load failure due user request via env variable\")\n          else\n            @logger.error(\"Failed to load configured plugin source `#{src}`: #{source_error}\")\n            raise Vagrant::Errors::PluginSourceError,\n              source: src.uri.to_s,\n              error_msg: source_error.message\n          end\n        end\n      end\n    end", "label": 4}
{"code": "public function setAudioConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\InputAudioConfig::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func ensureSuperuser(cf func(cmd *cobra.Command, args []string)) func(cmd *cobra.Command, args []string) {\n\treturn func(cmd *cobra.Command, args []string) {\n\t\tif os.Geteuid() != 0 {\n\t\t\tstderr.Print(\"cannot run as unprivileged user\")\n\t\t\tcmdExitCode = 254\n\t\t\treturn\n\t\t}\n\n\t\tcf(cmd, args)\n\t}\n}", "label": 5}
{"code": "public static sslcertkey get(nitro_service service, String certkey) throws Exception{\n\t\tsslcertkey obj = new sslcertkey();\n\t\tobj.set_certkey(certkey);\n\t\tsslcertkey response = (sslcertkey) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function matches(node, selector) {\n  var parent, matches, i;\n\n  if (node.matches) {\n    return node.matches(selector);\n  } else {\n    parent = node.parentElement;\n    matches = parent ? parent.querySelectorAll(selector) : [];\n    i = 0;\n    while (matches[i] && matches[i] !== node) {\n      i++;\n    }\n    return !!matches[i];\n  }\n}", "label": 3}
{"code": "func (c *Client) DeleteWebSession(user string, sid string) error {\n\t_, err := c.Delete(c.Endpoint(\"users\", user, \"web\", \"sessions\", sid))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def compare_config(self, commands=\"\", req_format=\"text\"):\n        \"\"\" Execute a 'show | compare' against the specified commands.\n\n        Purpose: This method will take in string of multiple commands,\n               | and perform and 'show | compare' on the device to show the\n               | differences between the active running configuration and\n               | the changes proposed by the passed commands parameter.\n\n        @param commands: A string, filepath, or list of multiple commands\n                       | that the device will compare with.\n        @type commands: str or list\n        @param req_format: The desired format of the response, defaults to\n                         | 'text', but also accepts 'xml'\n        @type req_format: str\n\n        @returns: The reply from the device.\n        @rtype: str\n        \"\"\"\n        if not commands:\n            raise InvalidCommandError('No commands specified')\n        clean_cmds = [cmd for cmd in clean_lines(commands)]\n        self.lock()\n        self._session.load_configuration(action='set', config=clean_cmds)\n        out = self._session.compare_configuration()\n        self.unlock()\n        if req_format.lower() == \"xml\":\n            return out\n        return out.xpath(\n            'configuration-information/configuration-output')[0].text", "label": 1}
{"code": "def token(new_token)\n      old_token    = client.token\n      client.token = new_token\n      json = client.get(\"/v1/auth/token/lookup-self\")\n      secret = Secret.decode(json)\n      return secret\n    rescue\n      client.token = old_token\n      raise\n    end", "label": 4}
{"code": "def offers_to_pwl(self, offers):\n        \"\"\" Updates the piece-wise linear total cost function using the given\n        offer blocks.\n\n        Based on off2case.m from MATPOWER by Ray Zimmerman, developed at PSERC\n        Cornell. See U{http://www.pserc.cornell.edu/matpower/} for more info.\n        \"\"\"\n        assert not self.is_load\n        # Only apply offers associated with this generator.\n        g_offers = [offer for offer in offers if offer.generator == self]\n        # Fliter out zero quantity offers.\n        gt_zero = [offr for offr in g_offers if round(offr.quantity, 4) > 0.0]\n        # Ignore withheld offers.\n        valid = [offer for offer in gt_zero if not offer.withheld]\n\n        p_offers = [v for v in valid if not v.reactive]\n        q_offers = [v for v in valid if v.reactive]\n\n        if p_offers:\n            self.p_cost = self._offbids_to_points(p_offers)\n            self.pcost_model = PW_LINEAR\n            self.online = True\n        else:\n            self.p_cost = [(0.0, 0.0), (self.p_max, 0.0)]\n            self.pcost_model = PW_LINEAR\n            if q_offers:\n                # Dispatch at zero real power without shutting down\n                # if capacity offered for reactive power.\n                self.p_min = 0.0\n                self.p_max = 0.0\n                self.online = True\n            else:\n                self.online = False\n\n        if q_offers:\n            self.q_cost = self._offbids_to_points(q_offers)\n            self.qcost_model = PW_LINEAR\n        else:\n            self.q_cost = None#[(0.0, 0.0), (self.q_max, 0.0)]\n            self.qcost_model = PW_LINEAR\n\n        if not len(p_offers) and not len(q_offers):\n            logger.info(\"No valid offers for generator [%s], shutting down.\" %\n                        self.name)\n            self.online = False\n\n        self._adjust_limits()", "label": 1}
{"code": "public static base_response update(nitro_service client, nsacl6 resource) throws Exception {\n\t\tnsacl6 updateresource = new nsacl6();\n\t\tupdateresource.acl6name = resource.acl6name;\n\t\tupdateresource.aclaction = resource.aclaction;\n\t\tupdateresource.srcipv6 = resource.srcipv6;\n\t\tupdateresource.srcipop = resource.srcipop;\n\t\tupdateresource.srcipv6val = resource.srcipv6val;\n\t\tupdateresource.srcport = resource.srcport;\n\t\tupdateresource.srcportop = resource.srcportop;\n\t\tupdateresource.srcportval = resource.srcportval;\n\t\tupdateresource.destipv6 = resource.destipv6;\n\t\tupdateresource.destipop = resource.destipop;\n\t\tupdateresource.destipv6val = resource.destipv6val;\n\t\tupdateresource.destport = resource.destport;\n\t\tupdateresource.destportop = resource.destportop;\n\t\tupdateresource.destportval = resource.destportval;\n\t\tupdateresource.srcmac = resource.srcmac;\n\t\tupdateresource.protocol = resource.protocol;\n\t\tupdateresource.protocolnumber = resource.protocolnumber;\n\t\tupdateresource.icmptype = resource.icmptype;\n\t\tupdateresource.icmpcode = resource.icmpcode;\n\t\tupdateresource.vlan = resource.vlan;\n\t\tupdateresource.Interface = resource.Interface;\n\t\tupdateresource.priority = resource.priority;\n\t\tupdateresource.established = resource.established;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public static Object buildNewObjectInstance(ClassDescriptor cld)\r\n    {\r\n        Object result = null;\r\n\r\n        // If either the factory class and/or factory method is null,\r\n        // just follow the normal code path and create via constructor\r\n        if ((cld.getFactoryClass() == null) || (cld.getFactoryMethod() == null))\r\n        {\r\n            try\r\n            {\r\n                // 1. create an empty Object (persistent classes need a public default constructor)\r\n                Constructor con = cld.getZeroArgumentConstructor();\r\n                if(con == null)\r\n                {\r\n                    throw new ClassNotPersistenceCapableException(\r\n                    \"A zero argument constructor was not provided! Class was '\" + cld.getClassNameOfObject() + \"'\");\r\n                }\r\n                result = ConstructorHelper.instantiate(con);\r\n            }\r\n            catch (InstantiationException e)\r\n            {\r\n                throw new ClassNotPersistenceCapableException(\r\n                        \"Can't instantiate class '\" + cld.getClassNameOfObject()+\"'\");\r\n            }\r\n        }\r\n        else\r\n        {\r\n            try\r\n            {\r\n                // 1. create an empty Object by calling the no-parms factory method\r\n                Method method = cld.getFactoryMethod();\r\n\r\n                if (Modifier.isStatic(method.getModifiers()))\r\n                {\r\n                    // method is static so call it directly\r\n                    result = method.invoke(null, null);\r\n                }\r\n                else\r\n                {\r\n                    // method is not static, so create an object of the factory first\r\n                    // note that this requires a public no-parameter (default) constructor\r\n                    Object factoryInstance = cld.getFactoryClass().newInstance();\r\n\r\n                    result = method.invoke(factoryInstance, null);\r\n                }\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                throw new PersistenceBrokerException(\"Unable to build object instance of class '\"\r\n                        + cld.getClassNameOfObject() + \"' from factory:\" + cld.getFactoryClass()\r\n                        + \".\" + cld.getFactoryMethod(), ex);\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def save_local\n      ensure_read_only!\n      self.path ||= Doggy.object_root.join(\"#{prefix}-#{id}.json\")\n      File.open(@path, 'w') { |f| f.write(JSON.pretty_generate(to_h)) }\n    end", "label": 4}
{"code": "func OptionDataDir(dataDir string) Option {\n\treturn func(c *Config) {\n\t\tc.Daemon.DataDir = dataDir\n\t}\n}", "label": 5}
{"code": "func (f *Fpdf) putTemplates() {\n\tfilter := \"\"\n\tif f.compress {\n\t\tfilter = \"/Filter /FlateDecode \"\n\t}\n\n\ttemplates := sortTemplates(f.templates, f.catalogSort)\n\tvar t Template\n\tfor _, t = range templates {\n\t\tcorner, size := t.Size()\n\n\t\tf.newobj()\n\t\tf.templateObjects[t.ID()] = f.n\n\t\tf.outf(\"<<%s/Type /XObject\", filter)\n\t\tf.out(\"/Subtype /Form\")\n\t\tf.out(\"/Formtype 1\")\n\t\tf.outf(\"/BBox [%.2f %.2f %.2f %.2f]\", corner.X*f.k, corner.Y*f.k, (corner.X+size.Wd)*f.k, (corner.Y+size.Ht)*f.k)\n\t\tif corner.X != 0 || corner.Y != 0 {\n\t\t\tf.outf(\"/Matrix [1 0 0 1 %.5f %.5f]\", -corner.X*f.k*2, corner.Y*f.k*2)\n\t\t}\n\n\t\t// Template's resource dictionary\n\t\tf.out(\"/Resources \")\n\t\tf.out(\"<</ProcSet [/PDF /Text /ImageB /ImageC /ImageI]\")\n\n\t\tf.templateFontCatalog()\n\n\t\ttImages := t.Images()\n\t\ttTemplates := t.Templates()\n\t\tif len(tImages) > 0 || len(tTemplates) > 0 {\n\t\t\tf.out(\"/XObject <<\")\n\t\t\t{\n\t\t\t\tvar key string\n\t\t\t\tvar keyList []string\n\t\t\t\tvar ti *ImageInfoType\n\t\t\t\tfor key = range tImages {\n\t\t\t\t\tkeyList = append(keyList, key)\n\t\t\t\t}\n\t\t\t\tif gl.catalogSort {\n\t\t\t\t\tsort.Strings(keyList)\n\t\t\t\t}\n\t\t\t\tfor _, key = range keyList {\n\t\t\t\t\t// for _, ti := range tImages {\n\t\t\t\t\tti = tImages[key]\n\t\t\t\t\tf.outf(\"/I%s %d 0 R\", ti.i, ti.n)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, tt := range tTemplates {\n\t\t\t\tid := tt.ID()\n\t\t\t\tif objID, ok := f.templateObjects[id]; ok {\n\t\t\t\t\tf.outf(\"/TPL%s %d 0 R\", id, objID)\n\t\t\t\t}\n\t\t\t}\n\t\t\tf.out(\">>\")\n\t\t}\n\n\t\tf.out(\">>\")\n\n\t\t//  Write the template's byte stream\n\t\tbuffer := t.Bytes()\n\t\t// fmt.Println(\"Put template bytes\", string(buffer[:]))\n\t\tif f.compress {\n\t\t\tbuffer = sliceCompress(buffer)\n\t\t}\n\t\tf.outf(\"/Length %d >>\", len(buffer))\n\t\tf.putstream(buffer)\n\t\tf.out(\"endobj\")\n\t}\n}", "label": 5}
{"code": "func (v VirtualMachine) IsToolsRunning(ctx context.Context) (bool, error) {\n\tvar o mo.VirtualMachine\n\n\terr := v.Properties(ctx, v.Reference(), []string{\"guest.toolsRunningStatus\"}, &o)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn o.Guest.ToolsRunningStatus == string(types.VirtualMachineToolsRunningStatusGuestToolsRunning), nil\n}", "label": 5}
{"code": "func GetBee(identifier string) *BeeInterface {\n\tbee, ok := bees[identifier]\n\tif ok {\n\t\treturn bee\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def call\n      return broadcast(:invalid) unless @form.valid?\n\n      Decidim::User.transaction do\n        destroy_user_account!\n        destroy_user_identities\n        destroy_user_group_memberships\n        destroy_follows\n      end\n\n      broadcast(:ok)\n    end", "label": 4}
{"code": "func GetInit(networkType string) func(dc driverapi.DriverCallback, config map[string]interface{}) error {\n\treturn func(dc driverapi.DriverCallback, config map[string]interface{}) error {\n\t\tif !IsBuiltinLocalDriver(networkType) {\n\t\t\treturn types.BadRequestErrorf(\"Network type not supported: %s\", networkType)\n\t\t}\n\n\t\td := newDriver(networkType)\n\n\t\terr := d.initStore(config)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn dc.RegisterDriver(networkType, d, driverapi.Capability{\n\t\t\tDataScope:         datastore.LocalScope,\n\t\t\tConnectivityScope: datastore.LocalScope,\n\t\t})\n\t}\n}", "label": 5}
{"code": "def render_diff_value(value, type, action, options = {})\n      return \"\".html_safe if value.blank?\n\n      value_to_render = case type\n                        when :date\n                          l value, format: :long\n                        when :percentage\n                          number_to_percentage value, precision: 2\n                        else\n                          value\n                        end\n\n      content_tag(:div, class: \"card--list__item #{action}\") do\n        content_tag(:div, class: \"card--list__text\") do\n          content_tag(:div, { class: \"diff__value\" }.merge(options)) do\n            value_to_render\n          end\n        end\n      end\n    end", "label": 4}
{"code": "public static base_response unset(nitro_service client, sslcertkey resource, String[] args) throws Exception{\n\t\tsslcertkey unsetresource = new sslcertkey();\n\t\tunsetresource.certkey = resource.certkey;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public function setIntentBatchInline($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\IntentBatch::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def predicted_effects_for_variant(\n        variant,\n        transcript_id_whitelist=None,\n        only_coding_changes=True):\n    \"\"\"\n    For a given variant, return its set of predicted effects. Optionally\n    filter to transcripts where this variant results in a non-synonymous\n    change to the protein sequence.\n\n    Parameters\n    ----------\n    variant : varcode.Variant\n\n    transcript_id_whitelist : set\n        Filter effect predictions to only include these transcripts\n\n    Returns a varcode.EffectCollection object\n    \"\"\"\n\n    effects = []\n    for transcript in variant.transcripts:\n        if only_coding_changes and not transcript.complete:\n            logger.info(\n                \"Skipping transcript %s for variant %s because it's incomplete\",\n                transcript.name,\n                variant)\n            continue\n\n        if transcript_id_whitelist and transcript.id not in transcript_id_whitelist:\n            logger.info(\n                \"Skipping transcript %s for variant %s because it's not one of %d allowed\",\n                transcript.name,\n                variant,\n                len(transcript_id_whitelist))\n            continue\n        effects.append(variant.effect_on_transcript(transcript))\n\n    effects = EffectCollection(effects)\n\n    n_total_effects = len(effects)\n    logger.info(\"Predicted total %d effects for variant %s\" % (\n        n_total_effects,\n        variant))\n    if not only_coding_changes:\n        return effects\n    else:\n        nonsynonymous_coding_effects = effects.drop_silent_and_noncoding()\n        logger.info(\n            \"Keeping %d/%d effects which affect protein coding sequence for %s: %s\",\n            len(nonsynonymous_coding_effects),\n            n_total_effects,\n            variant,\n            nonsynonymous_coding_effects)\n\n        usable_effects = [\n            effect\n            for effect in nonsynonymous_coding_effects\n            if effect.mutant_protein_sequence is not None\n        ]\n        logger.info(\n            \"Keeping %d effects with predictable AA sequences for %s: %s\",\n            len(usable_effects),\n            variant,\n            usable_effects)\n        return usable_effects", "label": 1}
{"code": "def drop(self, fname):\n        \"\"\" \n        drop the table, view or delete the file\n        \"\"\"\n        if self.dataset_type == 'file':\n            import os\n            try:\n                os.remove(fname)\n            except Exception as ex:\n                print('cant drop file \"' + fname + '\" : ' + str(ex))", "label": 1}
{"code": "def grant_symlink_privilege(who, machine=''):\n\t\"\"\"\n\tGrant the 'create symlink' privilege to who.\n\n\tBased on http://support.microsoft.com/kb/132958\n\t\"\"\"\n\tflags = security.POLICY_CREATE_ACCOUNT | security.POLICY_LOOKUP_NAMES\n\tpolicy = OpenPolicy(machine, flags)\n\treturn policy", "label": 1}
{"code": "def data(self):\n        \"\"\"Form data.\"\"\"\n        d = super(CommunityForm, self).data\n        d.pop('csrf_token', None)\n        return d", "label": 1}
{"code": "function injectRegistry(entry) {\n  const extraFiles = [registryFile, actBuildInfoFile, actMetaData];\n  // build also the registry\n  if (typeof entry === 'string') {\n    return extraFiles.concat(entry);\n  }\n  const transformed = {};\n  Object.keys(entry).forEach((eentry) => {\n    transformed[eentry] = extraFiles.concat(entry[eentry]);\n  });\n  return transformed;\n}", "label": 3}
{"code": "public function getCacheRepository()\n    {\n        if (is_null($this->cacheRepository)) {\n            $this->cacheRepository = app(config('repository.cache.repository', 'cache'));\n        }\n\n        return $this->cacheRepository;\n    }", "label": 2}
{"code": "private function executeQuery(QueryPartition $partition)\n    {\n        return $this->execute($partition->sql(), [\n            'partitionToken' => $partition->token()\n        ] + $partition->options());\n    }", "label": 2}
{"code": "func (m *DatastoreFileManager) DeleteVirtualDisk(ctx context.Context, name string) error {\n\tp := m.Path(name)\n\n\tvar merr error\n\n\tif m.Force {\n\t\tmerr = m.markDiskAsDeletable(ctx, p)\n\t}\n\n\ttask, err := m.VirtualDiskManager.DeleteVirtualDisk(ctx, p.String(), m.Datacenter)\n\tif err != nil {\n\t\tlog.Printf(\"markDiskAsDeletable(%s): %s\", p, merr)\n\t\treturn err\n\t}\n\n\treturn m.wait(ctx, task)\n}", "label": 5}
{"code": "def codon2aa(codon, trans_table):\n    \"\"\"\n    convert codon to amino acid\n    \"\"\"\n    return Seq(''.join(codon), IUPAC.ambiguous_dna).translate(table = trans_table)[0]", "label": 1}
{"code": "function _wrapQueryInterface (orgQueryInterface) {\n    return function (interfaceDefinition) {\n        /*eslint-disable no-invalid-this*/\n        _gpfIgnore(interfaceDefinition);\n        var result = _queryInterface.apply(this, arguments);\n        if (null === result) {\n            result = orgQueryInterface.apply(this, arguments);\n        }\n        return result;\n        /*eslint-enable no-invalid-this*/\n    };\n}", "label": 3}
{"code": "public function exchange_bind(\n        $destination,\n        $source,\n        $routing_key = '',\n        $nowait = false,\n        $arguments = array(),\n        $ticket = null\n    ) {\n        $ticket = $this->getTicket($ticket);\n\n        list($class_id, $method_id, $args) = $this->protocolWriter->exchangeBind(\n            $ticket,\n            $destination,\n            $source,\n            $routing_key,\n            $nowait,\n            $arguments\n        );\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        if ($nowait) {\n            return null;\n        }\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('exchange.bind_ok')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "function _addMethod(methodDictionary, func, name) {\n  expect(func).to.be.a(\n    'function',\n    'Invalid argument \"func\" when adding a method called \"' + name + '\" in a ' +\n    'MethodDictionary (it has to be a function)'\n  );\n\n  Object.defineProperty(methodDictionary, name, {\n    value: func,\n    enumerable: true,\n    writable: false,\n    configurable: false\n  });\n}", "label": 3}
{"code": "public static appfwsignatures get(nitro_service service, String name) throws Exception{\n\t\tappfwsignatures obj = new appfwsignatures();\n\t\tobj.set_name(name);\n\t\tappfwsignatures response = (appfwsignatures) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _build_circle(self):\n        \"\"\"\n            Creates hash ring.\n        \"\"\"\n        total_weight = 0\n        for node in self._nodes:\n            total_weight += self._weights.get(node, 1)\n\n        for node in self._nodes:\n            weight = self._weights.get(node, 1)\n\n            ks = math.floor((40 * len(self._nodes) * weight) / total_weight)\n\n            for i in xrange(0, int(ks)):\n                b_key = self._md5_digest('%s-%s-salt' % (node, i))\n\n                for l in xrange(0, 4):\n                    key = ((b_key[3 + l * 4] << 24)\n                           | (b_key[2 + l * 4] << 16)\n                           | (b_key[1 + l * 4] << 8)\n                           | b_key[l * 4])\n\n                    self._hashring[key] = node\n                    self._sorted_keys.append(key)\n\n        self._sorted_keys.sort()", "label": 1}
{"code": "public function toIso8601String()\n    {\n        $parts = [];\n\n        if ($this->recurrences !== null) {\n            $parts[] = 'R'.$this->recurrences;\n        }\n\n        $parts[] = $this->startDate->toIso8601String();\n\n        $parts[] = $this->dateInterval->spec();\n\n        if ($this->endDate !== null) {\n            $parts[] = $this->endDate->toIso8601String();\n        }\n\n        return implode('/', $parts);\n    }", "label": 2}
{"code": "public String getUrl(){\n\t\tfinal StringBuilder sb = new StringBuilder();\n\t\tsb.append(\"http://\");\n\t\tsb.append(getHttpConfiguration().getBindHost().get());\n\t\tsb.append(\":\");\n\t\tsb.append(getHttpConfiguration().getPort());\n\t\t\n\t\treturn sb.toString();\n\t}", "label": 0}
{"code": "def each_run(file)\n      if file\n        file = File.new(file)\n        matrix = YAML.load(ERB.new(file.read).result)\n        file.close\n\n        matrix.each_with_index do |run, i|\n          DEFAULT_RUN.merge(run)\n          yield(run, i)\n        end\n      else\n        yield(DEFAULT_RUN)\n      end\n    end", "label": 4}
{"code": "func archiveWrite(u *url.URL, tw *tar.Writer) error {\n\tinfo, err := os.Stat(u.Path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Note that the VMX will trim any trailing slash.  For example:\n\t// \"/foo/bar/?prefix=bar/\" will end up here as \"/foo/bar/?prefix=bar\"\n\t// Escape to avoid this: \"/for/bar/?prefix=bar%2F\"\n\tprefix := u.Query().Get(\"prefix\")\n\n\tdir := u.Path\n\n\tf := func(file string, fi os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn filepath.SkipDir\n\t\t}\n\n\t\tname := strings.TrimPrefix(file, dir)\n\t\tname = strings.TrimPrefix(name, \"/\")\n\n\t\tif name == \"\" {\n\t\t\treturn nil // this is u.Path itself (which may or may not have a trailing \"/\")\n\t\t}\n\n\t\tif prefix != \"\" {\n\t\t\tname = prefix + name\n\t\t}\n\n\t\theader, _ := tar.FileInfoHeader(fi, name)\n\n\t\theader.Name = name\n\n\t\tif header.Typeflag == tar.TypeDir {\n\t\t\theader.Name += \"/\"\n\t\t}\n\n\t\tvar f *os.File\n\n\t\tif header.Typeflag == tar.TypeReg && fi.Size() != 0 {\n\t\t\tf, err = os.Open(filepath.Clean(file))\n\t\t\tif err != nil {\n\t\t\t\tif os.IsPermission(err) {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t_ = tw.WriteHeader(header)\n\n\t\tif f != nil {\n\t\t\t_, err = io.Copy(tw, f)\n\t\t\t_ = f.Close()\n\t\t}\n\n\t\treturn err\n\t}\n\n\tif info.IsDir() {\n\t\treturn filepath.Walk(u.Path, f)\n\t}\n\n\tdir = filepath.Dir(dir)\n\n\treturn f(u.Path, info, nil)\n}", "label": 5}
{"code": "def extract_macaroons(headers_or_request):\n    ''' Returns an array of any macaroons found in the given slice of cookies.\n    If the argument implements a get_header method, that will be used\n    instead of the get method to retrieve headers.\n    @param headers_or_request: dict of headers or a\n    urllib.request.Request-like object.\n    @return: A list of list of mpy macaroons\n    '''\n    def get_header(key, default=None):\n        try:\n            return headers_or_request.get_header(key, default)\n        except AttributeError:\n            return headers_or_request.get(key, default)\n\n    mss = []\n\n    def add_macaroon(data):\n        try:\n            data = utils.b64decode(data)\n            data_as_objs = json.loads(data.decode('utf-8'))\n        except ValueError:\n            return\n        ms = [utils.macaroon_from_dict(x) for x in data_as_objs]\n        mss.append(ms)\n\n    cookie_header = get_header('Cookie')\n    if cookie_header is not None:\n        cs = SimpleCookie()\n        # The cookie might be a unicode object, so convert it\n        # to ASCII. This may cause an exception under Python 2.\n        # TODO is that a problem?\n        cs.load(str(cookie_header))\n        for c in cs:\n            if c.startswith('macaroon-'):\n                add_macaroon(cs[c].value)\n    # Python doesn't make it easy to have multiple values for a\n    # key, so split the header instead, which is necessary\n    # for HTTP1.1 compatibility anyway (see RFC 7230, section 3.2.2)\n    macaroon_header = get_header('Macaroons')\n    if macaroon_header is not None:\n        for h in macaroon_header.split(','):\n            add_macaroon(h)\n    return mss", "label": 1}
{"code": "def center\n      point = location\n      dimensions = size\n      Selenium::WebDriver::Point.new(point.x + (dimensions['width'] / 2),\n                                     point.y + (dimensions['height'] / 2))\n    end", "label": 4}
{"code": "def mobile_prefix(leading_zero = true)\n      mobile_prefix = '1' + rand(5..7).to_s + rand(0..9).to_s\n      mobile_prefix = '0' + mobile_prefix if leading_zero\n      mobile_prefix\n    end", "label": 4}
{"code": "def secret_id(role_name, secret_id)\n      opts = { secret_id: secret_id }\n      json = client.post(\"/v1/auth/approle/role/#{encode_path(role_name)}/secret-id/lookup\", JSON.fast_generate(opts), {})\n      return nil unless json\n      return Secret.decode(json)\n    rescue HTTPError => e\n      if e.code == 404 || e.code == 405\n        begin\n          json = client.get(\"/v1/auth/approle/role/#{encode_path(role_name)}/secret-id/#{encode_path(secret_id)}\")\n          return Secret.decode(json)\n        rescue HTTPError => e\n          return nil if e.code == 404\n          raise e\n        end\n      end\n\n      raise\n    end", "label": 4}
{"code": "def release_date\n      # If no release delays allowed, return today's date as release date\n      return Time.zone.today if release_no_delay?\n\n      # If this isn't an embargo, just return release_date from database\n      return self[:release_date] unless release_max_embargo?\n\n      # Otherwise (if an embargo), return latest embargo date by adding specified months to today's date\n      Time.zone.today + RELEASE_EMBARGO_PERIODS.fetch(release_period).months\n    end", "label": 4}
{"code": "def area_code\n      return nil unless area_code_possible?\n\n      format_match, _format_string = formatting_data\n      take_group = 1\n      if type == Core::MOBILE && Core::AREA_CODE_MOBILE_TOKENS[country] && \\\n         format_match[1] == Core::AREA_CODE_MOBILE_TOKENS[country]\n        take_group = 2\n      end\n      format_match[take_group]\n    end", "label": 4}
{"code": "public static void writeStringToFileNoExceptions(String contents, String path, String encoding) {\r\n\t\tOutputStream writer = null;\r\n\t\ttry{\r\n\t\t\tif (path.endsWith(\".gz\")) {\r\n\t\t\t\twriter = new GZIPOutputStream(new FileOutputStream(path));\r\n\t\t\t} else {\r\n\t\t\t\twriter = new BufferedOutputStream(new FileOutputStream(path));\r\n\t\t\t}\r\n\t\t\twriter.write(contents.getBytes(encoding));\r\n\t\t} catch (Exception e) {\r\n\t\t\te.printStackTrace();\r\n\t\t} finally {\r\n\t\t\tif(writer != null){ closeIgnoringExceptions(writer); }\r\n\t\t}\r\n\t}", "label": 0}
{"code": "func (r *remoteExec) Wait() (*ExecResult, error) {\n\t// block until the command is finished and then figure out if the command\n\t// successfully exited or if it exited in failure\n\texecResult, err := r.collectRemoteStatus(r.session.Wait())\n\n\t// emit the result of execution to the audit log\n\temitExecAuditEvent(r.ctx, r.command, execResult, err)\n\n\treturn execResult, trace.Wrap(err)\n}", "label": 5}
{"code": "func (o HostNetworkSystem) UpdateConsoleIpRouteConfig(ctx context.Context, config types.BaseHostIpRouteConfig) error {\n\treq := types.UpdateConsoleIpRouteConfig{\n\t\tThis:   o.Reference(),\n\t\tConfig: config,\n\t}\n\n\t_, err := methods.UpdateConsoleIpRouteConfig(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def record_command(self, cmd, prg=''):\n        \"\"\"\n        record the command passed - this is usually the name of the program\n        being run or task being run\n        \"\"\"\n        self._log(self.logFileCommand , force_to_string(cmd), prg)", "label": 1}
{"code": "public function setGcsSource($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Redis\\V1\\GcsSource::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "protected void computeVariablesFromObject(MtasParserObject object,\n      Map<String, List<MtasParserObject>> currentList,\n      Map<String, Map<String, String>> variables) {\n    MtasParserType<MtasParserVariable> parserType = object.getType();\n    String id = object.getId();\n    if (id != null) {\n      for (MtasParserVariable variable : parserType.getItems()) {\n        if (!variables.containsKey(variable.variable)) {\n          variables.put(variable.variable, new HashMap<String, String>());\n        }\n        StringBuilder builder = new StringBuilder();\n        for (MtasParserVariableValue variableValue : variable.values) {\n          if (variableValue.type.equals(\"attribute\")) {\n            String subValue = object.getAttribute(variableValue.name);\n            if (subValue != null) {\n              builder.append(subValue);\n            }\n          }\n        }\n        variables.get(variable.variable).put(id, builder.toString());\n      }\n    }\n  }", "label": 0}
{"code": "function (el, cls) {\n        cls = getString(cls);\n        if (!cls) return;\n        if (Array.isArray(cls)) {\n            cls.forEach(function(c) {\n                dom.addClass(el, c);\n            });\n        } else if (el.classList) {\n            el.classList.add(cls);\n        } else {\n            if (!hasClass(el, cls)) {\n                if (el.classList) {\n                    el.classList.add(cls);\n                } else {\n                    el.className += ' ' + cls;\n                }\n            }\n        }\n    }", "label": 3}
{"code": "function _gpfDefineBuildTypedEntity (definition) {\n    var EntityBuilder = _gpfDefineRead$TypedProperties(definition),\n        entityDefinition;\n    if (!EntityBuilder) {\n        EntityBuilder = _gpfDefineCheck$TypeProperty(definition);\n    }\n    entityDefinition = new EntityBuilder(definition);\n    entityDefinition.check();\n    return entityDefinition;\n}", "label": 3}
{"code": "def is_valid(obj: JSGValidateable, log: Optional[Union[TextIO, Logger]] = None) -> bool:\n    \"\"\" Determine whether obj is valid\n\n    :param obj: Object to validate\n    :param log: Logger to record validation failures.  If absent, no information is recorded\n    \"\"\"\n    return obj._is_valid(log)", "label": 1}
{"code": "func (s *sequence) equal(o *sequence) bool {\n\tthis := s\n\tother := o\n\tfor this != nil {\n\t\tif other == nil {\n\t\t\treturn false\n\t\t}\n\t\tif this.block != other.block || this.count != other.count {\n\t\t\treturn false\n\t\t}\n\t\tthis = this.next\n\t\tother = other.next\n\t}\n\t// Check if other is longer than this\n\tif other != nil {\n\t\treturn false\n\t}\n\treturn true\n}", "label": 5}
{"code": "public static base_response rename(nitro_service client, gslbservice resource, String new_servicename) throws Exception {\n\t\tgslbservice renameresource = new gslbservice();\n\t\trenameresource.servicename = resource.servicename;\n\t\treturn renameresource.rename_resource(client,new_servicename);\n\t}", "label": 0}
{"code": "func (s *Service) Reset([]byte) ([]byte, error) {\n\ts.SendGuestInfo() // Send the IP info ASAP\n\n\treturn []byte(\"ATR \" + s.name), nil\n}", "label": 5}
{"code": "function (interval) {\n  var quality;\n  var number;\n\n  if (interval instanceof Interval) return interval;\n\n  quality = interval.replace(/\\d/g, ''); // Remove digits\n  number = parseInt(interval.replace(/\\D/g, ''), 10); // Remove non-digits\n\n  if (!quality) { // No quality given, assume major or perfect\n    quality = isPerfect(number) ? 'P' : 'M';\n  }\n\n  return new Interval(number, quality);\n}", "label": 3}
{"code": "def call(test_framework)\n      begin\n        initializers.find { |i| i.match? test_framework }.start [], {}\n      rescue ArgumentError => e\n        $stderr.puts e.message\n        exit 0\n      end\n\n      Initializers::CommonInitializer.start [], {}\n    end", "label": 4}
{"code": "func (c *Client) GetReverseTunnels(opts ...services.MarshalOption) ([]services.ReverseTunnel, error) {\n\tout, err := c.Get(c.Endpoint(\"reversetunnels\"), url.Values{})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar items []json.RawMessage\n\tif err := json.Unmarshal(out.Bytes(), &items); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttunnels := make([]services.ReverseTunnel, len(items))\n\tfor i, raw := range items {\n\t\ttunnel, err := services.GetReverseTunnelMarshaler().UnmarshalReverseTunnel(raw, services.SkipValidation())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\ttunnels[i] = tunnel\n\t}\n\treturn tunnels, nil\n}", "label": 5}
{"code": "public static dospolicy get(nitro_service service, String name) throws Exception{\n\t\tdospolicy obj = new dospolicy();\n\t\tobj.set_name(name);\n\t\tdospolicy response = (dospolicy) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (c *Client) UpsertUser(user services.User) error {\n\tdata, err := services.GetUserMarshaler().MarshalUser(user)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"users\"), &upsertUserRawReq{User: data})\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "protected PreparedStatement prepareStatement(Connection con,\r\n                                                 String sql,\r\n                                                 boolean scrollable,\r\n                                                 boolean createPreparedStatement,\r\n                                                 int explicitFetchSizeHint)\r\n        throws SQLException\r\n    {\r\n        PreparedStatement result;\r\n\r\n        // if a JDBC1.0 driver is used the signature\r\n        // prepareStatement(String, int, int) is  not defined.\r\n        // we then call the JDBC1.0 variant prepareStatement(String)\r\n        try\r\n        {\r\n            // if necessary use JDB1.0 methods\r\n            if (!FORCEJDBC1_0)\r\n            {\r\n                if (createPreparedStatement)\r\n                {\r\n                    result =\r\n                        con.prepareStatement(\r\n                            sql,\r\n                            scrollable\r\n                                ? ResultSet.TYPE_SCROLL_INSENSITIVE\r\n                                : ResultSet.TYPE_FORWARD_ONLY,\r\n                            ResultSet.CONCUR_READ_ONLY);\r\n                    afterJdbc2CapableStatementCreate(result, explicitFetchSizeHint);\r\n                }\r\n                else\r\n                {\r\n                    result =\r\n                        con.prepareCall(\r\n                            sql,\r\n                            scrollable\r\n                                ? ResultSet.TYPE_SCROLL_INSENSITIVE\r\n                                : ResultSet.TYPE_FORWARD_ONLY,\r\n                            ResultSet.CONCUR_READ_ONLY);\r\n                }\r\n            }\r\n            else\r\n            {\r\n                if (createPreparedStatement)\r\n                {\r\n                    result = con.prepareStatement(sql);\r\n                }\r\n                else\r\n                {\r\n                    result = con.prepareCall(sql);\r\n                }\r\n            }\r\n        }\r\n        catch (AbstractMethodError err)\r\n        {\r\n            // this exception is raised if Driver is not JDBC 2.0 compliant\r\n            log.warn(\"Used driver seems not JDBC 2.0 compatible, use the JDBC 1.0 mode\", err);\r\n            if (createPreparedStatement)\r\n            {\r\n                result = con.prepareStatement(sql);\r\n            }\r\n            else\r\n            {\r\n                result = con.prepareCall(sql);\r\n            }\r\n            FORCEJDBC1_0 = true;\r\n        }\r\n        catch (SQLException eSql)\r\n        {\r\n            // there are JDBC Driver that nominally implement JDBC 2.0, but\r\n            // throw DriverNotCapableExceptions. If we catch one of these\r\n            // we force usage of JDBC 1.0\r\n            if (eSql\r\n                .getClass()\r\n                .getName()\r\n                .equals(\"interbase.interclient.DriverNotCapableException\"))\r\n            {\r\n                log.warn(\"JDBC 2.0 problems with this interbase driver, we use the JDBC 1.0 mode\");\r\n                if (createPreparedStatement)\r\n                {\r\n                    result = con.prepareStatement(sql);\r\n                }\r\n                else\r\n                {\r\n                    result = con.prepareCall(sql);\r\n                }\r\n                FORCEJDBC1_0 = true;\r\n            }\r\n            else\r\n            {\r\n                throw eSql;\r\n            }\r\n        }\r\n        try\r\n        {\r\n            if (!ProxyHelper.isNormalOjbProxy(result))  // tomdz: What about VirtualProxy\r\n            {\r\n                platform.afterStatementCreate(result);\r\n            }\r\n        }\r\n        catch (PlatformException e)\r\n        {\r\n            log.error(\"Platform dependend failure\", e);\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def _makna(self):\n        \"\"\"Mengembalikan representasi string untuk semua makna entri ini.\n\n        :returns: String representasi makna-makna\n        :rtype: str\n        \"\"\"\n\n        if len(self.makna) > 1:\n            return '\\n'.join(\n                str(i) + \". \" + str(makna)\n                for i, makna in enumerate(self.makna, 1)\n            )\n        return str(self.makna[0])", "label": 1}
{"code": "def reject(&block)\n      current = get_current\n      ilist = self.class.new\n      a = @images.reject(&block)\n      a.each { |image| ilist << image }\n      ilist.set_current current\n      ilist\n    end", "label": 4}
{"code": "def download_remote_file(resource, remote_file, local_file, num_redirects = 0)\n      @logger.info(\"Downloading remote #{resource} from #{remote_file}\") if @logger\n      uri = URI.parse(remote_file)\n      req = Net::HTTP::Get.new(uri)\n\n      if uri.user && uri.password\n        req.basic_auth uri.user, uri.password\n      end\n\n      Net::HTTP.start(uri.host, uri.port, :ENV,\n                      :use_ssl => uri.scheme == 'https') do |http|\n        http.request req do |response|\n          case response\n            when Net::HTTPSuccess\n              File.open(local_file, 'wb') do |file|\n                response.read_body do |chunk|\n                  file.write(chunk)\n                end\n              end\n\n            when Net::HTTPFound, Net::HTTPMovedPermanently\n              raise ResourceError, \"Too many redirects at '#{remote_file}'.\" if num_redirects >= 9\n              location = response.header['location']\n              raise ResourceError, \"No location header for redirect found at '#{remote_file}'.\" if location.nil?\n\n              location = URI.join(uri, location).to_s\n              download_remote_file(resource, location, local_file, num_redirects + 1)\n\n            when Net::HTTPNotFound\n              @logger.error(\"Downloading remote #{resource} from #{remote_file} failed: #{response.message}\") if @logger\n              raise ResourceNotFound, \"No #{resource} found at '#{remote_file}'.\"\n\n            else\n              @logger.error(\"Downloading remote #{resource} from #{remote_file} failed: #{response.message}\") if @logger\n              raise ResourceError, \"Downloading remote #{resource} failed. Check task debug log for details.\"\n          end\n        end\n      end\n    rescue URI::Error, SocketError, ::Timeout::Error, Errno::EINVAL, Errno::ECONNRESET, Errno::ECONNREFUSED, EOFError,\n           Net::HTTPBadResponse, Net::HTTPHeaderSyntaxError, Net::ProtocolError => e\n      @logger.error(\"Downloading remote #{resource} from #{remote_file} failed: #{e.inspect}\") if @logger\n      raise ResourceError, \"Downloading remote #{resource} failed. Check task debug log for details.\"\n    end", "label": 4}
{"code": "async def dump_message_field(obj, msg, field, field_archiver=None):\n    \"\"\"\n    Dumps a message field to the object. Field is defined by the message field specification.\n\n    :param obj:\n    :param msg:\n    :param field:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    fname, ftype, params = field[0], field[1], field[2:]\n    fvalue = getattr(msg, fname, None)\n    field_archiver = field_archiver if field_archiver else dump_field\n    return await field_archiver(eref(obj, fname, True), fvalue, ftype, params)", "label": 1}
{"code": "def get_file_size(self, fid):\n        \"\"\"\n        Gets size of uploaded file\n        Or None if file doesn't exist.\n\n        Args:\n            **fid**: File identifier <volume_id>,<file_name_hash>\n\n        Returns:\n            Int or None\n        \"\"\"\n        url = self.get_file_url(fid)\n        res = self.conn.head(url)\n        if res is not None:\n            size = res.headers.get(\"content-length\", None)\n            if size is not None:\n                return int(size)\n        return None", "label": 1}
{"code": "def on_load(name, options = {}, &block)\n      @loaded[name].each do |base|\n        execute_hook(name, base, options, block)\n      end\n\n      @load_hooks[name] << [block, options]\n    end", "label": 4}
{"code": "func (r *Resource) WithID(id string) *Resource {\n\tr.u.Path += \"/id:\" + id\n\treturn r\n}", "label": 5}
{"code": "public static function projectRunName($project, $transferConfig, $run)\n    {\n        return self::getProjectRunNameTemplate()->render([\n            'project' => $project,\n            'transfer_config' => $transferConfig,\n            'run' => $run,\n        ]);\n    }", "label": 2}
{"code": "public function setInstance($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\Admin\\V2\\Instance::class);\n        $this->instance = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def fetch_deposits_since(self, since: int) -> List[Deposit]:\n        \"\"\"Fetch all deposits since the given timestamp.\"\"\"\n        return self._transactions_since(self._deposits_since, 'deposits', since)", "label": 1}
{"code": "function( el, e ) {\r\n      var ajaxOptions = {},\r\n        data = {},\r\n        fieldName = el.name || el.id;\r\n\r\n      if ( typeof this.remoteCache === 'undefined' ) this.remoteCache = {};\r\n\r\n      data[ fieldName ] = this.tmp.val; // Set data\r\n      // exends ajax options\r\n      ajaxOptions = $.extend( true, {}, {\r\n        data: data\r\n      }, this.options.validators.remote[ this.tmp.remote ] || {} );\r\n\r\n      // use $.param() function for generate specific cache key\r\n      var cacheKey = $.param( ajaxOptions );\r\n\r\n      // Check cache\r\n      var cache = this.remoteCache[ cacheKey ];\r\n\r\n      if ( typeof cache !== 'undefined' ) {\r\n        switch( cache.state ) {\r\n          case 'pending' : // pending means remote request not finished yet\r\n            this.handler = 'pending'; // update handler and cache event type\r\n            cache.event = e.type;\r\n            break;\r\n          case 'rejected' : // rejected means remote request could not be performed\r\n            e.preventDefault(); // we have to break submit because of throw error\r\n            throw new Error( cache.result.message );\r\n          case 'resolved' : // resolved means remote request has done\r\n            // Check to cache, if result is invalid, open an error window\r\n            if ( cache.result.valid === false ) {\r\n              this.addErrorClass( this.tmp.parent );\r\n              this.window.open.call( this, el, cache.result.message );\r\n            } else {\r\n              this.addValidClass( this.tmp.parent );\r\n            }\r\n        }\r\n      } else {\r\n        // Abort if previous ajax request still running\r\n        var _xhr = this.xhr[ fieldName ];\r\n        if ( typeof _xhr !== 'undefined' && _xhr.state() === 'pending' ) _xhr.abort();\r\n        // Start caching\r\n        cache = this.remoteCache[ cacheKey ] = { state : 'pending', event : e.type };\r\n        // make a remote request\r\n        this.remoteRequest( ajaxOptions, cache, el, fieldName );\r\n      }\r\n    }", "label": 3}
{"code": "def client\n      @client ||= (client = Clients.with_name(client_name)\n                    client = client.use(database_name) if database_name_option\n                    client.with(client_options))\n    end", "label": 4}
{"code": "def connected(self):\n        \"\"\"\n        If connected to server.\n        \"\"\"\n        return self.websocket is not None and \\\n               self.websocket.sock is not None and \\\n               self.websocket.sock.connected", "label": 1}
{"code": "function (node) {\n        var element = this._createElement(node);\n        this._setAttributesTo(element);\n        this._appendChildrenTo(element);\n        return node.appendChild(element);\n    }", "label": 3}
{"code": "private boolean exceedsScreenDimensions(InternalFeature f, double scale) {\n\t\tEnvelope env = f.getBounds();\n\t\treturn (env.getWidth() * scale > MAXIMUM_TILE_COORDINATE) ||\n\t\t\t\t(env.getHeight() * scale > MAXIMUM_TILE_COORDINATE);\n\t}", "label": 0}
{"code": "def increment_api_version_string(api_version_string: nil, increment_by: :patch)\n      versions = api_version_string.split(\".\")\n      major = versions[0].to_i\n      minor = versions[1].to_i\n      patch = versions[2].to_i\n\n      case increment_by\n      when :patch\n        patch += 1\n      when :minor\n        minor += 1\n        patch = 0\n      when :major\n        major += 1\n        minor = 0\n        patch = 0\n      end\n\n      new_version_string = [major, minor, patch].join(\".\")\n      return new_version_string\n    end", "label": 4}
{"code": "func (a *AuthCommand) GenerateAndSignKeys(clusterApi auth.ClientI) error {\n\tswitch {\n\tcase a.genUser != \"\" && a.genHost == \"\":\n\t\treturn a.generateUserKeys(clusterApi)\n\tcase a.genUser == \"\" && a.genHost != \"\":\n\t\treturn a.generateHostKeys(clusterApi)\n\tdefault:\n\t\treturn trace.BadParameter(\"--user or --host must be specified\")\n\t}\n}", "label": 5}
{"code": "function (root, bass, intervals) {\n  var chord = _.chain(intervals)\n    .map(function (quality, number) {\n      var int;\n      if (quality) {\n        // #9 is stored as b10, so special case this\n        if (number === 10 && quality === 'm') {\n          int = interval.create(9, 'aug');\n        }\n        else {\n          int = interval.create(number, quality);\n        }\n        return root.transpose(int);\n      }\n    })\n    .compact()\n    .value();\n\n  var bassIndex;\n\n  // Handle slash chords\n  if (bass && !root.enharmonic(bass)) {\n    bassIndex = _.findIndex(chord, bass.enharmonic.bind(bass));\n\n    if (bassIndex > -1) { // Rotate chord so bass is first\n      chord = rotateArr(chord, bassIndex);\n    }\n    else { // Otherwise, add bass to beginning\n      chord.unshift(bass);\n    }\n  }\n\n  return chord;\n}", "label": 3}
{"code": "def _create_update_tracking_related_event(instance):\n    \"\"\"\n    Create a TrackingEvent and TrackedFieldModification for an UPDATE event\n    for each related model.\n    \"\"\"\n    events = {}\n    # Create a dict mapping related model field to modified fields\n    for field, related_fields in instance._tracked_related_fields.items():\n        if not isinstance(instance._meta.get_field(field), ManyToManyField):\n            if isinstance(instance._meta.get_field(field), ForeignKey):\n                # Compare pk\n                value = getattr(instance, '{0}_id'.format(field))\n            else:\n                value = getattr(instance, field)\n            if instance._original_fields[field] != value:\n                for related_field in related_fields:\n                    events.setdefault(related_field, []).append(field)\n\n    # Create the events from the events dict\n    for related_field, fields in events.items():\n        try:\n            related_instances = getattr(instance, related_field[1])\n        except ObjectDoesNotExist:\n            continue\n\n        # FIXME: isinstance(related_instances, RelatedManager ?)\n        if hasattr(related_instances, 'all'):\n            related_instances = related_instances.all()\n        else:\n            related_instances = [related_instances]\n        for related_instance in related_instances:\n            event = _create_event(related_instance, UPDATE)\n            for field in fields:\n                fieldname = '{0}__{1}'.format(related_field[0], field)\n                _create_tracked_field(\n                    event, instance, field, fieldname=fieldname\n                )", "label": 1}
{"code": "public function moveBy($x_offset, $y_offset)\n    {\n        $this->x += $x_offset;\n        $this->y += $y_offset;\n\n        return $this;\n    }", "label": 2}
{"code": "func NewAuthWithRoles(authServer *AuthServer,\n\tchecker services.AccessChecker,\n\tuser services.User,\n\tsessions session.Service,\n\talog events.IAuditLog) *AuthWithRoles {\n\treturn &AuthWithRoles{\n\t\tauthServer: authServer,\n\t\tchecker:    checker,\n\t\tsessions:   sessions,\n\t\tuser:       user,\n\t\talog:       alog,\n\t}\n}", "label": 5}
{"code": "func (info *HostCertificateInfo) IssuerName() *pkix.Name {\n\tif info.issuerName != nil {\n\t\treturn info.issuerName\n\t}\n\n\treturn info.toName(info.Issuer)\n}", "label": 5}
{"code": "function rerouteLinks (html) {\n  return html.replace(/href=\"(\\.\\/[a-z0-9\\-]+\\.md)\"/g, (all, key) => {\n    const found = documentationPages.filter((page) => page.key === key)[0]\n    if (!found) return all\n    /* global __legendary_pancake_base_pathname__ */\n    const base = __legendary_pancake_base_pathname__ // eslint-disable-line camelcase\n    const pathname = found.pathname\n    return `href=\"${base}${pathname}\" data-to=\"${pathname}\"`\n  })\n}", "label": 3}
{"code": "public static long getMaxId(PersistenceBroker brokerForClass, Class topLevel, FieldDescriptor original) throws PersistenceBrokerException\r\n    {\r\n        long max = 0;\r\n        long tmp;\r\n        ClassDescriptor cld = brokerForClass.getClassDescriptor(topLevel);\r\n\r\n        // if class is not an interface / not abstract we have to search its directly mapped table\r\n        if (!cld.isInterface() && !cld.isAbstract())\r\n        {\r\n            tmp = getMaxIdForClass(brokerForClass, cld, original);\r\n            if (tmp > max)\r\n            {\r\n                max = tmp;\r\n            }\r\n        }\r\n        // if class is an extent we have to search through its subclasses\r\n        if (cld.isExtent())\r\n        {\r\n            Vector extentClasses = cld.getExtentClasses();\r\n            for (int i = 0; i < extentClasses.size(); i++)\r\n            {\r\n                Class extentClass = (Class) extentClasses.get(i);\r\n                if (cld.getClassOfObject().equals(extentClass))\r\n                {\r\n                    throw new PersistenceBrokerException(\"Circular extent in \" + extentClass +\r\n                            \", please check the repository\");\r\n                }\r\n                else\r\n                {\r\n                    // fix by Mark Rowell\r\n                    // Call recursive\r\n                    tmp = getMaxId(brokerForClass, extentClass, original);\r\n                }\r\n                if (tmp > max)\r\n                {\r\n                    max = tmp;\r\n                }\r\n            }\r\n        }\r\n        return max;\r\n    }", "label": 0}
{"code": "public function setCarouselSelect($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_CarouselSelect::class);\n        $this->writeOneof(12, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "private function resolveTypeDefinition($type, $key = null)\n    {\n        $definition = null;\n        if (is_array($type)) {\n            $type += [\n                1 => null,\n                2 => null\n            ];\n\n            $definition = new ArrayType($type[1], $type[2]);\n            $type = Database::TYPE_ARRAY;\n        } elseif ($type instanceof ArrayType) {\n            $definition = $type;\n            $type = Database::TYPE_ARRAY;\n        } elseif ($type instanceof StructType) {\n            $definition = $type;\n            $type = Database::TYPE_STRUCT;\n        }\n\n        return [$type, $definition];\n    }", "label": 2}
{"code": "def last_textfield\n      result = eles_by_json(_textfield_visible).last\n      raise _no_such_element if result.nil?\n\n      result\n    end", "label": 4}
{"code": "func (s *sequence) getCopy() *sequence {\n\tn := &sequence{block: s.block, count: s.count}\n\tpn := n\n\tps := s.next\n\tfor ps != nil {\n\t\tpn.next = &sequence{block: ps.block, count: ps.count}\n\t\tpn = pn.next\n\t\tps = ps.next\n\t}\n\treturn n\n}", "label": 5}
{"code": "protected boolean determineFeatureState(final ITemplateContext context, final IProcessableElementTag tag, final AttributeName attributeName, final String attributeValue, boolean defaultState) {\n        final IStandardExpressionParser expressionParser = StandardExpressions.getExpressionParser(context.getConfiguration());\n        final IStandardExpression expression = expressionParser.parseExpression(context, attributeValue);\n        final Object value = expression.execute(context);\n        if (value != null) {\n            return isFeatureActive(value.toString());\n        }\n        else {\n            return defaultState;\n        }\n    }", "label": 0}
{"code": "def response(request)\n      response = responses.fetch(@response_counter, responses.last)\n      if response.respond_to?(:call)\n        response = response.call(request)\n      end\n      @response_counter += 1\n      response.mock = @from || true\n      response\n    end", "label": 4}
{"code": "def apply_fee(location_id, item_id, fee_id, opts = {})\n      data, _status_code, _headers = apply_fee_with_http_info(location_id, item_id, fee_id, opts)\n      return data\n    end", "label": 4}
{"code": "func OnReloaded(callback func()) {\n\tfor _, pf := range onReloaded {\n\t\tif pf == &callback {\n\t\t\treturn\n\t\t}\n\t}\n\tonReloaded = append(onReloaded, &callback)\n}", "label": 5}
{"code": "private GregorianCalendar getLastReleventDate(GregorianCalendar currentDate) {\n\t\tint age=this.getProperties().getMaxFileAge();\n\t\tGregorianCalendar result=new GregorianCalendar(currentDate.get(Calendar.YEAR),currentDate.get(Calendar.MONTH),currentDate.get(Calendar.DAY_OF_MONTH));\n\t\tresult.add(Calendar.DAY_OF_MONTH, -age);\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (info *ImageInfoType) Height() float64 {\n\treturn info.h / (info.scale * info.dpi / 72)\n}", "label": 5}
{"code": "private void enforceSrid(Object feature) throws LayerException {\n\t\tGeometry geom = getFeatureModel().getGeometry(feature);\n\t\tif (null != geom) {\n\t\t\tgeom.setSRID(srid);\n\t\t\tgetFeatureModel().setGeometry(feature, geom);\n\t\t}\n\t}", "label": 0}
{"code": "function (int) {\n  var map = interval.isPerfect(int.number) ? perfectOffsets : majorOffsets;\n  var key = _.invert(map)[int.quality];\n\n  return parseInt(key, 10);\n}", "label": 3}
{"code": "func (g GridType) XRange() (min, max float64) {\n\tmin = g.xTicks[0]\n\tmax = g.xTicks[len(g.xTicks)-1]\n\treturn\n}", "label": 5}
{"code": "public function disconnect()\n     {\n         if (is_resource($this->socket)) {\n             @socket_shutdown($this->socket, 2);\n             @socket_close($this->socket);\n         }\n         $this->socket = null;\n         $this->loginStatus = Constants::DISCONNECTED_STATUS;\n         $this->logFile('info', 'Disconnected from WA server');\n         $this->eventManager()->fire('onDisconnect',\n             [\n                 $this->phoneNumber,\n                 $this->socket,\n             ]\n         );\n     }", "label": 2}
{"code": "function _requireFile(requirable, directory) {\n    var required;\n    try{\n      var res = resolve.sync(requirable, { basedir: directory});\n      required = require(res);\n    }\n    catch(err) {\n      required = (void 0);\n    }\n    return required;\n  }", "label": 3}
{"code": "function( tmp ) {\r\n      if ( tmp.val === '' ) return true; // allow empty because empty check does by required metheod\r\n      var reg, cardNumber, pos, digit, i, sub_total, sum = 0, strlen;\r\n      reg = new RegExp( /[^0-9]+/g );\r\n      cardNumber = tmp.val.replace( reg, '' );\r\n      strlen = cardNumber.length;\r\n      if( strlen < 13 ) return messages.creditCard;\r\n      for( i=0 ; i < strlen ; i++ ) {\r\n        pos = strlen - i;\r\n        digit = parseInt( cardNumber.substring( pos - 1, pos ), 10 );\r\n        if( i % 2 === 1 ) {\r\n          sub_total = digit * 2 ;\r\n          if( sub_total > 9 ) {\r\n            sub_total = 1 + ( sub_total - 10 );\r\n          }\r\n        } else {\r\n          sub_total = digit ;\r\n        }\r\n        sum += sub_total ;\r\n      }\r\n      if( sum > 0 && sum % 10 === 0 ) return true;\r\n      return messages.creditCard;\r\n    }", "label": 3}
{"code": "public void loadProfile(Object key)\r\n    {\r\n        if (!isEnablePerThreadChanges())\r\n        {\r\n            throw new MetadataException(\"Can not load profile with disabled per thread mode\");\r\n        }\r\n        DescriptorRepository rep = (DescriptorRepository) metadataProfiles.get(key);\r\n        if (rep == null)\r\n        {\r\n            throw new MetadataException(\"Can not find profile for key '\" + key + \"'\");\r\n        }\r\n        currentProfileKey.set(key);\r\n        setDescriptor(rep);\r\n    }", "label": 0}
{"code": "def generate_numeric_range(items, lower_bound, upper_bound):\n    \"\"\"Generate postgresql numeric range and label for insertion.\n\n    Parameters\n    ----------\n    items: iterable labels for ranges.\n    lower_bound: numeric lower bound\n    upper_bound: numeric upper bound\n    \"\"\"\n\n    quantile_grid = create_quantiles(items, lower_bound, upper_bound)\n    labels, bounds = (zip(*quantile_grid))\n    ranges = ((label, NumericRange(*bound))\n              for label, bound in zip(labels, bounds))\n    return ranges", "label": 1}
{"code": "public function setBoundingBoxes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\BoundingBox::class);\n        $this->bounding_boxes = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private ArrayList handleDependentReferences(Identity oid, Object userObject,\r\n            Object[] origFields, Object[] newFields, Object[] newRefs)\r\n            throws LockingException\r\n    {\r\n        ClassDescriptor mif = _pb.getClassDescriptor(userObject.getClass());\r\n        FieldDescriptor[] fieldDescs = mif.getFieldDescriptions();\r\n        Collection refDescs = mif.getObjectReferenceDescriptors();\r\n        int count = 1 + fieldDescs.length;\r\n        ArrayList newObjects = new ArrayList();\r\n        int countRefs = 0;\r\n\r\n        for (Iterator it = refDescs.iterator(); it.hasNext(); count++, countRefs++)\r\n        {\r\n            ObjectReferenceDescriptor rds = (ObjectReferenceDescriptor) it.next();\r\n            Identity origOid = (origFields == null ? null : (Identity) origFields[count]);\r\n            Identity newOid = (Identity) newFields[count];\r\n\r\n            if (rds.getOtmDependent())\r\n            {\r\n                if ((origOid == null) && (newOid != null))\r\n                {\r\n                    ContextEntry entry = (ContextEntry) _objects.get(newOid);\r\n\r\n                    if (entry == null)\r\n                    {\r\n                        Object relObj = newRefs[countRefs];\r\n                        insertInternal(newOid, relObj, LockType.WRITE_LOCK,\r\n                                       true, oid, new Stack());\r\n                        newObjects.add(newOid);\r\n                    }\r\n                }\r\n                else if ((origOid != null) &&\r\n                         ((newOid == null) || !newOid.equals(origOid)))\r\n                {\r\n                    markDelete(origOid, oid, false);\r\n                }\r\n            }\r\n        }\r\n\r\n        return newObjects;\r\n    }", "label": 0}
{"code": "public function set($key, $value)\n    {\n        // Check if the specified property is defined.\n        if (property_exists($this, $key) && $key != 'data') {\n            $this->{$key} = trim($value);\n\n            return $this;\n        } elseif (property_exists($this, $key) && $key == 'data') {\n            foreach ($value as $v_key => $v_value) {\n                $this->{$key}[$v_key] = trim($v_value);\n            }\n\n            return $this;\n        } else {\n            return false;\n        }\n    }", "label": 2}
{"code": "def analyze(phone, passed_country)\n      country = country_or_default_country passed_country\n\n      result = parse_country(phone, country)\n      d_result = case\n                 when result && result.values.find { |e| e[:valid].any? }\n                   # all is good, return result\n                 when passed_country.nil?\n                   # trying for all countries if no country was passed\n                   detect_and_parse(phone, country)\n                 when country_can_dp?(country)\n                   # if country allows double prefix trying modified phone\n                   parse_country(changed_dp_phone(country, phone), country)\n                 end\n      better_result(result, d_result)\n    end", "label": 4}
{"code": "func pruneOldBackups(dir string, limit int) error {\n\tif list, err := ioutil.ReadDir(dir); err != nil {\n\t\treturn err\n\t} else {\n\t\tfor _, fi := range list {\n\t\t\tif num, err := strconv.Atoi(fi.Name()); err != nil {\n\t\t\t\t// directory name is not a number,\n\t\t\t\t// leave it alone\n\t\t\t\tcontinue\n\t\t\t} else if num < limit {\n\t\t\t\t// directory name is a number lower\n\t\t\t\t// than a limit, leave it alone\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tpath := filepath.Join(dir, fi.Name())\n\t\t\tif err := os.RemoveAll(path); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "async def load_container(obj, container_type, params=None, container=None, field_archiver=None):\n    \"\"\"\n    Loads container of elements from the object representation. Supports the container ref.\n    Returns loaded container.\n\n    :param reader:\n    :param container_type:\n    :param params:\n    :param container:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    field_archiver = field_archiver if field_archiver else load_field\n    if obj is None:\n        return None\n\n    c_len = len(obj)\n    elem_type = params[0] if params else None\n    if elem_type is None:\n        elem_type = container_type.ELEM_TYPE\n\n    res = container if container else []\n    for i in range(c_len):\n        fvalue = await field_archiver(obj[i], elem_type,\n                                      params[1:] if params else None,\n                                      eref(res, i) if container else None)\n        if not container:\n            res.append(fvalue)\n    return res", "label": 1}
{"code": "public function tel($name, $value = null, $options = [])\n    {\n        return $this->input('tel', $name, $value, $options);\n    }", "label": 2}
{"code": "def diff_list(self, list1, list2):\n        \"\"\"Extracts differences between lists. For debug purposes\"\"\"\n        for key in list1:\n            if key in list2 and list2[key] != list1[key]:\n                print key\n            elif key not in list2:\n                print key", "label": 1}
{"code": "function(config){\n            config.bindingName = config.bindingName || 'widget';\n\n            if(config.kinds){\n                var toRegister = config.kinds;\n\n                for(var i = 0; i < toRegister.length; i++){\n                    widget.registerKind(toRegister[i]);\n                }\n            }\n\n            ko.bindingHandlers[config.bindingName] = {\n                init: function() {\n                    return { controlsDescendantBindings: true };\n                },\n                update: function(element, valueAccessor, allBindingsAccessor, viewModel, bindingContext) {\n                    var settings = widget.getSettings(valueAccessor);\n                    extractParts(element, settings);\n                    widget.create(element, settings, bindingContext, true);\n                }\n            };\n\n            composition.composeBindings.push(config.bindingName + ':');\n            ko.virtualElements.allowedBindings[config.bindingName] = true;\n        }", "label": 3}
{"code": "func ValidateValuer(field reflect.Value) interface{} {\n\n\tif valuer, ok := field.Interface().(driver.Valuer); ok {\n\n\t\tval, err := valuer.Value()\n\t\tif err == nil {\n\t\t\treturn val\n\t\t}\n\t\t// handle the error how you want\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function time (name) {\n  const t = timers[name];\n  if (t) {\n    let elapsed = Date.now() - t;\n    if (elapsed < 1000) return `${elapsed}ms`;\n    if (elapsed < 60 * 1000) return `${elapsed / 1000}s`;\n\n    elapsed /= 1000;\n    const h = Math.floor(elapsed / 3600);\n    const m = Math.floor((elapsed % 3600) / 60);\n    const s = Math.floor((elapsed % 3600) % 60);\n\n    delete timers[name];\n\n    return `${h}h ${m}m ${s}s`;\n  } else {\n    timers[name] = Date.now();\n  }\n}", "label": 3}
{"code": "func (p *PortAllocator) RequestPort(ip net.IP, proto string, port int) (int, error) {\n\treturn p.RequestPortInRange(ip, proto, port, port)\n}", "label": 5}
{"code": "public static vpnsessionpolicy_aaauser_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnsessionpolicy_aaauser_binding obj = new vpnsessionpolicy_aaauser_binding();\n\t\tobj.set_name(name);\n\t\tvpnsessionpolicy_aaauser_binding response[] = (vpnsessionpolicy_aaauser_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def serialize_attribute(attrs, name, names, options)\n      if relations.key?(name)\n        value = send(name)\n        attrs[name] = value ? value.serializable_hash(options) : nil\n      elsif names.include?(name) && !fields.key?(name)\n        attrs[name] = read_raw_attribute(name)\n      elsif !attribute_missing?(name)\n        attrs[name] = send(name)\n      end\n    end", "label": 4}
{"code": "func CreateDownloadCommand(cfg Config) (Command, error) {\n\tcfg.Flags.Sink = true\n\tcfg.Flags.Source = false\n\tcmd, err := CreateCommand(cfg)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn cmd, nil\n}", "label": 5}
{"code": "def invoke(*args)\n      task_args = TaskArguments.new(arg_names, args)\n      invoke_with_call_chain(task_args, InvocationChain::EMPTY)\n    end", "label": 4}
{"code": "def queue_execute(targets)\n      targets.group_by(&:transport).flat_map do |protocol, protocol_targets|\n        transport = transport(protocol)\n        report_transport(transport, protocol_targets.count)\n        transport.batches(protocol_targets).flat_map do |batch|\n          batch_promises = Array(batch).each_with_object({}) do |target, h|\n            h[target] = Concurrent::Promise.new(executor: :immediate)\n          end\n          # Pass this argument through to avoid retaining a reference to a\n          # local variable that will change on the next iteration of the loop.\n          @pool.post(batch_promises) do |result_promises|\n            begin\n              results = yield transport, batch\n              Array(results).each do |result|\n                result_promises[result.target].set(result)\n              end\n            # NotImplementedError can be thrown if the transport is not implemented improperly\n            rescue StandardError, NotImplementedError => e\n              result_promises.each do |target, promise|\n                # If an exception happens while running, the result won't be logged\n                # by the CLI. Log a warning, as this is probably a problem with the transport.\n                # If batch_* commands are used from the Base transport, then exceptions\n                # normally shouldn't reach here.\n                @logger.warn(e)\n                promise.set(Bolt::Result.from_exception(target, e))\n              end\n            ensure\n              # Make absolutely sure every promise gets a result to avoid a\n              # deadlock. Use whatever exception is causing this block to\n              # execute, or generate one if we somehow got here without an\n              # exception and some promise is still missing a result.\n              result_promises.each do |target, promise|\n                next if promise.fulfilled?\n                error = $ERROR_INFO || Bolt::Error.new(\"No result was returned for #{target.uri}\",\n                                                       \"puppetlabs.bolt/missing-result-error\")\n                promise.set(Bolt::Result.from_exception(target, error))\n              end\n            end\n          end\n          batch_promises.values\n        end\n      end\n    end", "label": 4}
{"code": "public function findByAlias($alias)\n    {\n        foreach ($this->all() as $module) {\n            if ($module->getAlias() === $alias) {\n                return $module;\n            }\n        }\n\n        return;\n    }", "label": 2}
{"code": "public void setInitialSequence(int[] sequence) {\r\n    if(models != null){\r\n      for(int i = 0; i < models.length; i++)\r\n        models[i].setInitialSequence(sequence);\r\n      return;\r\n    }\r\n    model1.setInitialSequence(sequence);\r\n    model2.setInitialSequence(sequence);\r\n  }", "label": 0}
{"code": "def sort_protein_sequences(protein_sequences):\n    \"\"\"\n    Sort protein sequences in decreasing order of priority\n    \"\"\"\n    return list(\n        sorted(\n            protein_sequences,\n            key=ProteinSequence.ascending_sort_key,\n            reverse=True))", "label": 1}
{"code": "func NewProcessFunc(run func(ctx context.Context, args string) error) *Process {\n\tf := &processFunc{run: run}\n\n\treturn &Process{\n\t\tStart: f.start,\n\t\tWait:  f.wait,\n\t}\n}", "label": 5}
{"code": "function Tokenizer(str) {\n  this._str = str;\n  this._pos = 0;\n  this._queue = new BoundedQueue(3); // Bounded queue of last emitted tokens.\n  this._token = undefined; // Current token.\n  this._doc = undefined; // Javadoc.\n}", "label": 3}
{"code": "protected void restoreAutoCommitState()\r\n    {\r\n        try\r\n        {\r\n            if(!broker.isManaged())\r\n            {\r\n                if (jcd.getUseAutoCommit() == JdbcConnectionDescriptor.AUTO_COMMIT_SET_TRUE_AND_TEMPORARY_FALSE\r\n                        && originalAutoCommitState == true && con != null && !con.isClosed())\r\n                {\r\n                    platform.changeAutoCommitState(jcd, con, true);\r\n                }\r\n            }\r\n            else\r\n            {\r\n                if(log.isDebugEnabled()) log.debug(\r\n                        \"Found managed environment setting in PB, will skip Platform.changeAutoCommitState(...) call\");\r\n            }\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            // should never be reached\r\n            throw new OJBRuntimeException(\"Restore of connection autocommit state failed\", e);\r\n        }\r\n    }", "label": 0}
{"code": "function tell(name, taskInfo) {\n  if (swig.tasks[name]) {\n    console.log(`Task '${name}' has been overridden by a local installation`.yellow);\n  }\n\n  swig.tasks[name] = _.extend({\n    description: '<unknown>',\n    flags: {},\n  }, taskInfo);\n}", "label": 3}
{"code": "function off (state, eventName, handler) {\n  if (arguments.length === 2) {\n    state.emitter.removeAllListeners(eventName)\n  } else {\n    state.emitter.removeListener(eventName, handler)\n  }\n\n  return state.api\n}", "label": 3}
{"code": "function validateCurlyPair(openingCurly, closingCurly) {\n         const tokenBeforeOpeningCurly = sourceCode.getTokenBefore(openingCurly),\n               tokenAfterOpeningCurly = sourceCode.getTokenAfter(openingCurly),\n               tokenBeforeClosingCurly = sourceCode.getTokenBefore(closingCurly),\n               singleLineException = params.allowSingleLine && astUtils.isTokenOnSameLine(openingCurly, closingCurly),\n               isOpeningCurlyOnSameLine = astUtils.isTokenOnSameLine(openingCurly, tokenAfterOpeningCurly),\n               isClosingCurlyOnSameLine = astUtils.isTokenOnSameLine(tokenBeforeClosingCurly, closingCurly);\n\n         if (style !== 'allman' && !astUtils.isTokenOnSameLine(tokenBeforeOpeningCurly, openingCurly)) {\n            context.report({\n               node: openingCurly,\n               messageId: 'nextLineOpen',\n               fix: removeNewlineBetween(tokenBeforeOpeningCurly, openingCurly),\n            });\n         }\n\n         if (style === 'allman' && astUtils.isTokenOnSameLine(tokenBeforeOpeningCurly, openingCurly) && !singleLineException) {\n            context.report({\n               node: openingCurly,\n               messageId: 'sameLineOpen',\n               fix: (fixer) => fixer.insertTextBefore(openingCurly, '\\n'),\n            });\n         }\n\n\n         if (isOpeningCurlyOnSameLine && tokenAfterOpeningCurly !== closingCurly && !singleLineException) {\n            context.report({\n               node: openingCurly,\n               messageId: 'blockSameLine',\n               fix: (fixer) => fixer.insertTextAfter(openingCurly, '\\n'),\n            });\n         }\n\n         if (tokenBeforeClosingCurly !== openingCurly && !singleLineException && isClosingCurlyOnSameLine) {\n            context.report({\n               node: closingCurly,\n               messageId: 'singleLineClose',\n               fix: (fixer) => fixer.insertTextBefore(closingCurly, '\\n'),\n            });\n         }\n      }", "label": 3}
{"code": "public function findElements(WebDriverBy $by)\n    {\n        $params = ['using' => $by->getMechanism(), 'value' => $by->getValue()];\n        $raw_elements = $this->execute(\n            DriverCommand::FIND_ELEMENTS,\n            $params\n        );\n\n        $elements = [];\n        foreach ($raw_elements as $raw_element) {\n            $elements[] = $this->newElement($raw_element['ELEMENT']);\n        }\n\n        return $elements;\n    }", "label": 2}
{"code": "def evaluate_default_value(val)\n      if val.respond_to?(:call)\n        val.call\n      elsif val.duplicable?\n        val.dup\n      else\n        val\n      end\n    end", "label": 4}
{"code": "def urbext(self, year):\n        \"\"\"\n        Estimate the `urbext2000` parameter for a given year assuming a nation-wide urbanisation curve.\n\n        Methodology source: eqn 5.5, report FD1919/TR\n\n        :param year: Year to provide estimate for\n        :type year: float\n        :return: Urban extent parameter\n        :rtype: float\n        \"\"\"\n\n        # Decimal places increased to ensure year 2000 corresponds with 1\n        urban_expansion = 0.7851 + 0.2124 * atan((year - 1967.5) / 20.331792998)\n        try:\n            return self.catchment.descriptors.urbext2000 * urban_expansion\n        except TypeError:\n            # Sometimes urbext2000 is not set, assume zero\n            return 0", "label": 1}
{"code": "def services\n      services = {}\n      open_scm(SC_MANAGER_ENUMERATE_SERVICE) do |scm|\n        size_required = 0\n        services_returned = 0\n        FFI::MemoryPointer.new(:dword) do |bytes_pointer|\n          FFI::MemoryPointer.new(:dword) do |svcs_ret_ptr|\n            FFI::MemoryPointer.new(:dword) do |resume_ptr|\n              resume_ptr.write_dword(0)\n              # Fetch the bytes of memory required to be allocated\n              # for QueryServiceConfigW to return succesfully. This\n              # is done by sending NULL and 0 for the pointer and size\n              # respectively, letting the command fail, then reading the\n              # value of pcbBytesNeeded\n              #\n              # return value will be false from this call, since it's designed\n              # to fail. Just ignore it\n              EnumServicesStatusExW(\n                scm,\n                :SC_ENUM_PROCESS_INFO,\n                ALL_SERVICE_TYPES,\n                SERVICE_STATE_ALL,\n                FFI::Pointer::NULL,\n                0,\n                bytes_pointer,\n                svcs_ret_ptr,\n                resume_ptr,\n                FFI::Pointer::NULL\n              )\n              size_required = bytes_pointer.read_dword\n              FFI::MemoryPointer.new(size_required) do |buffer_ptr|\n                resume_ptr.write_dword(0)\n                svcs_ret_ptr.write_dword(0)\n                success = EnumServicesStatusExW(\n                  scm,\n                  :SC_ENUM_PROCESS_INFO,\n                  ALL_SERVICE_TYPES,\n                  SERVICE_STATE_ALL,\n                  buffer_ptr,\n                  buffer_ptr.size,\n                  bytes_pointer,\n                  svcs_ret_ptr,\n                  resume_ptr,\n                  FFI::Pointer::NULL\n                )\n                if success == FFI::WIN32_FALSE\n                  raise Puppet::Util::Windows::Error.new(_(\"Failed to fetch services\"))\n                end\n                # Now that the buffer is populated with services\n                # we pull the data from memory using pointer arithmetic:\n                # the number of services returned by the function is\n                # available to be read from svcs_ret_ptr, and we iterate\n                # that many times moving the cursor pointer the length of\n                # ENUM_SERVICE_STATUS_PROCESSW.size. This should iterate\n                # over the buffer and extract each struct.\n                services_returned = svcs_ret_ptr.read_dword\n                cursor_ptr = FFI::Pointer.new(ENUM_SERVICE_STATUS_PROCESSW, buffer_ptr)\n                0.upto(services_returned - 1) do |index|\n                  service = ENUM_SERVICE_STATUS_PROCESSW.new(cursor_ptr[index])\n                  services[service[:lpServiceName].read_arbitrary_wide_string_up_to(SERVICENAME_MAX)] = {\n                    :display_name => service[:lpDisplayName].read_arbitrary_wide_string_up_to(SERVICENAME_MAX),\n                    :service_status_process => service[:ServiceStatusProcess]\n                  }\n                end\n              end # buffer_ptr\n            end # resume_ptr\n          end # scvs_ret_ptr\n        end # bytes_ptr\n      end # open_scm\n      services\n    end", "label": 4}
{"code": "protected function executeTransactionBlock($callable)\n    {\n        $exception = null;\n        $this->state->flag(MultiExecState::INSIDEBLOCK);\n\n        try {\n            call_user_func($callable, $this);\n        } catch (CommunicationException $exception) {\n            // NOOP\n        } catch (ServerException $exception) {\n            // NOOP\n        } catch (\\Exception $exception) {\n            $this->discard();\n        }\n\n        $this->state->unflag(MultiExecState::INSIDEBLOCK);\n\n        if ($exception) {\n            throw $exception;\n        }\n    }", "label": 2}
{"code": "function(user_id, profile, options) {\n          options = opts(this, options);\n          return new APICall({\n              action: 'account/' + user_id,\n              type: 'POST',\n              options: options,\n              query: server_params(options),\n              data: JSON.stringify(profile)\n          });\n      }", "label": 3}
{"code": "private function getCascade(string $className, string $fieldName, array $originalCascades)\n    {\n        $cascadeTypes = ['remove', 'persist', 'refresh'];\n        $cascades     = array_map('strtolower', $originalCascades);\n\n        if (in_array('all', $cascades, true)) {\n            $cascades = $cascadeTypes;\n        }\n\n        if (count($cascades) !== count(array_intersect($cascades, $cascadeTypes))) {\n            $diffCascades = array_diff($cascades, array_intersect($cascades, $cascadeTypes));\n\n            throw Mapping\\MappingException::invalidCascadeOption($diffCascades, $className, $fieldName);\n        }\n\n        return $cascades;\n    }", "label": 2}
{"code": "public function getSeederName($name)\n    {\n        $name = Str::studly($name);\n\n        $namespace = $this->laravel['modules']->config('namespace');\n        $seederPath = GenerateConfigReader::read('seeder');\n        $seederPath = str_replace('/', '\\\\', $seederPath->getPath());\n\n        return $namespace . '\\\\' . $name . '\\\\' . $seederPath . '\\\\' . $name . 'DatabaseSeeder';\n    }", "label": 2}
{"code": "function handleAttributeContext(attrNode, context) {\n    if (!attrNode.type && attrNode.inherit !== 'inherit') attrNode.type = 'string';\n\n    if (attrNode.map) {\n        Object.keys(attrNode.map).forEach(mappingName => {\n            const mapping = attrNode.map[mappingName];\n\n            Object.keys(mapping).forEach(dataSourceName => {\n                if (!context.dataSourceAttributes[dataSourceName]) {\n                    throw new ImplementationError(\n                        `Unknown DataSource \"${dataSourceName}\" in map${context.errorContext}`\n                    );\n                }\n\n                context.dataSourceAttributes[dataSourceName].push(mapping[dataSourceName]);\n            });\n        });\n\n        if ('value' in attrNode) {\n            throw new ImplementationError(\n                'Static \"value\" in combination with \"map\" makes no sense' + context.errorContext\n            );\n        }\n    }\n}", "label": 3}
{"code": "def parse_orf(insertion, gff):\n    \"\"\"\n    parse ORF to gff format\n    \"\"\"\n    offset = insertion['offset']\n    if type(insertion['orf']) is not str:\n        return gff\n    for orf in parse_fasta(insertion['orf'].split('|')):\n        ID = orf[0].split('>')[1].split()[0]\n        Start, End, strand = [int(i) for i in orf[0].split(' # ')[1:4]]\n        if strand == 1:\n            strand = '+'\n        else:\n            strand = '-'\n        GeneStrand = insertion['strand']\n        if strand != GeneStrand:\n            if strand == '+':\n                strand = '-'\n            else:\n                strand = '+'\n            Start, End = End - 2, Start - 2\n        Start, End = abs(Start + offset) - 1, abs(End + offset) - 1\n        annot = orf[0].split()[1]\n        if annot == 'n/a':\n            annot = 'unknown'\n        gff['#seqname'].append(insertion['ID'])\n        gff['source'].append('Prodigal and Pfam')\n        gff['feature'].append('CDS')\n        gff['start'].append(Start)\n        gff['end'].append(End)\n        gff['score'].append('.')\n        gff['strand'].append(strand)\n        gff['frame'].append('.')\n        gff['attribute'].append('ID=%s; Name=%s' % (ID, annot))\n    return gff", "label": 1}
{"code": "public function boot()\n    {\n        $engines = config('datatables.engines');\n        foreach ($engines as $engine => $class) {\n            $engine = camel_case($engine);\n\n            if (! method_exists(DataTables::class, $engine) && ! DataTables::hasMacro($engine)) {\n                DataTables::macro($engine, function () use ($class) {\n                    if (! call_user_func_array([$class, 'canCreate'], func_get_args())) {\n                        throw new \\InvalidArgumentException();\n                    }\n\n                    return call_user_func_array([$class, 'create'], func_get_args());\n                });\n            }\n        }\n    }", "label": 2}
{"code": "public function register(array $options = [])\n    {\n        $resp = $this->connection->registerDebuggee(['debuggee' => $this->info()] + $options);\n        if (array_key_exists('debuggee', $resp)) {\n            $this->id = $resp['debuggee']['id'];\n            return true;\n        }\n        return false;\n    }", "label": 2}
{"code": "def get_custom_image(user_context, app_id):\n  \"\"\"Returns the custom image associated with a given app. If there are\n  multiple candidate images on disk, one is chosen arbitrarily.\"\"\"\n  possible_paths = _valid_custom_image_paths(user_context, app_id)\n  existing_images = filter(os.path.exists, possible_paths)\n  if len(existing_images) > 0:\n    return existing_images[0]", "label": 1}
{"code": "def suggest(message, possibilities, options = {})\n      suggestion = Suggestion.new(options)\n      say(suggestion.suggest(message, possibilities))\n    end", "label": 4}
{"code": "protected function registerTelescopeServiceProvider()\n    {\n        $namespace = str_replace_last('\\\\', '', $this->getAppNamespace());\n\n        $appConfig = file_get_contents(config_path('app.php'));\n\n        if (Str::contains($appConfig, $namespace.'\\\\Providers\\\\TelescopeServiceProvider::class')) {\n            return;\n        }\n\n        $lineEndingCount = [\n            \"\\r\\n\" => substr_count($appConfig, \"\\r\\n\"),\n            \"\\r\" => substr_count($appConfig, \"\\r\"),\n            \"\\n\" => substr_count($appConfig, \"\\n\"),\n        ];\n\n        $eol = array_keys($lineEndingCount, max($lineEndingCount))[0];\n\n        file_put_contents(config_path('app.php'), str_replace(\n            \"{$namespace}\\\\Providers\\EventServiceProvider::class,\".$eol,\n            \"{$namespace}\\\\Providers\\EventServiceProvider::class,\".$eol.\"        {$namespace}\\Providers\\TelescopeServiceProvider::class,\".$eol,\n            $appConfig\n        ));\n\n        file_put_contents(app_path('Providers/TelescopeServiceProvider.php'), str_replace(\n            \"namespace App\\Providers;\",\n            \"namespace {$namespace}\\Providers;\",\n            file_get_contents(app_path('Providers/TelescopeServiceProvider.php'))\n        ));\n    }", "label": 2}
{"code": "public static vpnvserver_authenticationsamlpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_authenticationsamlpolicy_binding obj = new vpnvserver_authenticationsamlpolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_authenticationsamlpolicy_binding response[] = (vpnvserver_authenticationsamlpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def resolve(self, value=None):\n        \"\"\" Resolve the current expression against the supplied value \"\"\"\n\n        # If we still have an uninitialized matcher init it now\n        if self.matcher:\n            self._init_matcher()\n\n        # Evaluate the current set of matchers forming the expression\n        matcher = self.evaluate()\n\n        try:\n            value = self._transform(value)\n            self._assertion(matcher, value)\n        except AssertionError as ex:\n            # By re-raising here the exception we reset the traceback\n            raise ex\n        finally:\n            # Reset the state of the object so we can use it again\n            if self.deferred:\n                self.reset()", "label": 1}
{"code": "public function setDeploymentState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\AutoMl\\V1beta1\\Model_DeploymentState::class);\n        $this->deployment_state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def page_section(name, section_class, identifier)\n      define_method(name) do\n        platform.page_for(identifier, section_class)\n      end\n    end", "label": 4}
{"code": "func (mr *MockEmbedMockRecorder) ForeignEmbeddedMethod() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ForeignEmbeddedMethod\", reflect.TypeOf((*MockEmbed)(nil).ForeignEmbeddedMethod))\n}", "label": 5}
{"code": "public static cmppolicy_stats get(nitro_service service, String name) throws Exception{\n\t\tcmppolicy_stats obj = new cmppolicy_stats();\n\t\tobj.set_name(name);\n\t\tcmppolicy_stats response = (cmppolicy_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def read_hash\n      buffer = new_buffer\n      if !@io.read(HEADER_SIZE, buffer)\n        return nil\n      end\n      while buffer.size < HEADER_SIZE\n        tmp = @io.read(HEADER_SIZE - buffer.size)\n        if tmp.empty?\n          return nil\n        else\n          buffer << tmp\n        end\n      end\n\n      chunk_size = buffer.unpack(UINT16_PACK_FORMAT)[0]\n      if !@io.read(chunk_size, buffer)\n        return nil\n      end\n      while buffer.size < chunk_size\n        tmp = @io.read(chunk_size - buffer.size)\n        if tmp.empty?\n          return nil\n        else\n          buffer << tmp\n        end\n      end\n\n      result = {}\n      offset = 0\n      delimiter_pos = buffer.index(DELIMITER, offset)\n      while !delimiter_pos.nil?\n        if delimiter_pos == 0\n          name = \"\"\n        else\n          name = buffer[offset .. delimiter_pos - 1]\n        end\n\n        offset = delimiter_pos + 1\n        delimiter_pos = buffer.index(DELIMITER, offset)\n        if delimiter_pos.nil?\n          raise InvalidHashError\n        elsif delimiter_pos == 0\n          value = \"\"\n        else\n          value = buffer[offset .. delimiter_pos - 1]\n        end\n\n        result[name] = value\n        offset = delimiter_pos + 1\n        delimiter_pos = buffer.index(DELIMITER, offset)\n      end\n      return result\n    rescue Errno::ECONNRESET\n      return nil\n    end", "label": 4}
{"code": "public static nd6ravariables[] get(nitro_service service, options option) throws Exception{\n\t\tnd6ravariables obj = new nd6ravariables();\n\t\tnd6ravariables[] response = (nd6ravariables[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def format_app_info(info)\n      str = info[:name]\n      str = \"#{str}/#{info[:version]}\" unless info[:version].nil?\n      str = \"#{str} (#{info[:url]})\" unless info[:url].nil?\n      str\n    end", "label": 4}
{"code": "public function get_project_config_path() {\n\t\t$config_files = array(\n\t\t\t'wp-cli.local.yml',\n\t\t\t'wp-cli.yml',\n\t\t);\n\n\t\t// Stop looking upward when we find we have emerged from a subdirectory\n\t\t// installation into a parent installation\n\t\t$project_config_path = Utils\\find_file_upward(\n\t\t\t$config_files,\n\t\t\tgetcwd(),\n\t\t\tfunction ( $dir ) {\n\t\t\t\tstatic $wp_load_count = 0;\n\t\t\t\t$wp_load_path         = $dir . DIRECTORY_SEPARATOR . 'wp-load.php';\n\t\t\t\tif ( file_exists( $wp_load_path ) ) {\n\t\t\t\t\t++ $wp_load_count;\n\t\t\t\t}\n\t\t\t\treturn $wp_load_count > 1;\n\t\t\t}\n\t\t);\n\n\t\t$this->project_config_path_debug = 'No project config found';\n\n\t\tif ( ! empty( $project_config_path ) ) {\n\t\t\t$this->project_config_path_debug = 'Using project config: ' . $project_config_path;\n\t\t}\n\n\t\treturn $project_config_path;\n\t}", "label": 2}
{"code": "func (c *controller) agentOperationStart() {\n\tc.Lock()\n\tif c.agentInitDone == nil {\n\t\tc.agentInitDone = make(chan struct{})\n\t}\n\tif c.agentStopDone == nil {\n\t\tc.agentStopDone = make(chan struct{})\n\t}\n\tc.Unlock()\n}", "label": 5}
{"code": "func NewDiskSessionLogger(cfg DiskSessionLoggerConfig) (*DiskSessionLogger, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar err error\n\n\tsessionDir := filepath.Join(cfg.DataDir, cfg.ServerID, SessionLogsDir, cfg.Namespace)\n\tindexFile, err := os.OpenFile(\n\t\tfilepath.Join(sessionDir, fmt.Sprintf(\"%v.index\", cfg.SessionID.String())), os.O_WRONLY|os.O_CREATE|os.O_APPEND, 0640)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tsessionLogger := &DiskSessionLogger{\n\t\tDiskSessionLoggerConfig: cfg,\n\t\tEntry: log.WithFields(log.Fields{\n\t\t\ttrace.Component: teleport.ComponentAuditLog,\n\t\t\ttrace.ComponentFields: log.Fields{\n\t\t\t\t\"sid\": cfg.SessionID,\n\t\t\t},\n\t\t}),\n\t\tsessionDir:     sessionDir,\n\t\tindexFile:      indexFile,\n\t\tlastEventIndex: -1,\n\t\tlastChunkIndex: -1,\n\t}\n\treturn sessionLogger, nil\n}", "label": 5}
{"code": "function loadDefault() {\n  return {\n    port: 8000,\n    host: '127.0.0.1',\n    root: './',\n    logFormat: 'combined',\n    middlewares: [\n      {\n        name: 'cors',\n        cfg: {\n          origin: true\n        }\n      },\n      {\n        name: 'morgan',\n        cfg: {}\n      },\n      {\n        name: 'serveStatic',\n        cfg: {}\n      },\n      {\n        name: 'serveIndex',\n        cfg: {\n          icons: true\n        }\n      }\n    ]\n  }\n}", "label": 3}
{"code": "public static dnsnsecrec[] get(nitro_service service) throws Exception{\n\t\tdnsnsecrec obj = new dnsnsecrec();\n\t\tdnsnsecrec[] response = (dnsnsecrec[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "protected function optionsApplyToControllerMethod(array $options)\n    {\n        if (empty($options)) {\n            return true;\n        } elseif (isset($options['only']) && in_array($this->controllerMethod,\n                $this->explodeOnPipes($options['only']))) {\n            return true;\n        } elseif (isset($options['except'])) {\n            return ! in_array($this->controllerMethod, $this->explodeOnPipes($options['except']));\n        } elseif (in_array($this->controllerMethod, $this->explodeOnPipes($options))) {\n            return true;\n        }\n\n        return false;\n    }", "label": 2}
{"code": "function chainPromises(calls, val) {\n    if (!calls || !calls.length) { return Q.when(val); }\n    return calls.reduce(Q.when, Q.when(val));\n}", "label": 3}
{"code": "def play(opts = {}, &done_proc)\n\n      animation = opts[:animation]\n      loop = opts[:loop]\n      flip = opts[:flip]\n\n      if !@playing || (animation != @playing_animation && animation != nil) || flip != @flip\n\n        @playing = true\n        @playing_animation = animation || :default\n        frames = @animations[@playing_animation]\n        flip_sprite(flip)\n        @done_proc = done_proc\n\n        case frames\n        # When animation is a range, play through frames horizontally\n        when Range\n          @first_frame   = frames.first || @defaults[:frame]\n          @current_frame = frames.first || @defaults[:frame]\n          @last_frame    = frames.last\n        # When array...\n        when Array\n          @first_frame   = 0\n          @current_frame = 0\n          @last_frame    = frames.length - 1\n        end\n\n        # Set looping\n        @loop = loop == true || @defaults[:loop] ? true : false\n\n        set_frame\n        restart_time\n      end\n    end", "label": 4}
{"code": "def redact(datum)\n      datum = datum.dup\n      if datum.has_key?(:headers) && datum[:headers].has_key?('Authorization')\n        datum[:headers] = datum[:headers].dup\n        datum[:headers]['Authorization'] = REDACTED\n      end\n      if datum.has_key?(:password)\n        datum[:password] = REDACTED\n      end\n      datum\n    end", "label": 4}
{"code": "def _filtered_walk(path, file_filter):\n\t\t\"\"\"\n\t\tstatic method that calls os.walk, but filters out\n\t\tanything that doesn't match the filter\n\t\t\"\"\"\n\t\tfor root, dirs, files in os.walk(path):\n\t\t\tlog.debug('looking in %s', root)\n\t\t\tlog.debug('files is %s', files)\n\t\t\tfile_filter.set_root(root)\n\t\t\tfiles = filter(file_filter, files)\n\t\t\tlog.debug('filtered files is %s', files)\n\t\t\tyield (root, dirs, files)", "label": 1}
{"code": "func (c *Call) MinTimes(n int) *Call {\n\tc.minCalls = n\n\tif c.maxCalls == 1 {\n\t\tc.maxCalls = 1e8\n\t}\n\treturn c\n}", "label": 5}
{"code": "def check_yard_coverage(stat_lines)\n      if config['min_coverage_percentage']\n        match = stat_lines.last.match(/^\\s*([\\d.]+)%\\s+documented\\s*$/)\n        unless match\n          return :warn\n        end\n\n        yard_coverage = match.captures[0].to_f\n        if yard_coverage >= config['min_coverage_percentage'].to_f\n          return :pass\n        end\n\n        yard_coverage\n      end\n    end", "label": 4}
{"code": "function getConfig(config) {\n    // Read a RESTBase configuration from a (optional) path argument, an (optional) CONFIG\n    // env var, or from /etc/restbase/config.yaml\n    var conf;\n\n    if (config) {\n        conf = config;\n    } else if (process.env.CONFIG) {\n        conf = process.env.CONFIG;\n    } else {\n        conf = '/etc/restbase/config.yaml';\n    }\n\n    var confObj = yaml.safeLoad(fs.readFileSync(conf));\n    return confObj.default_project['x-modules'][0].options.table;\n}", "label": 3}
{"code": "def create_id(self, prefix=\"guid\"):\n        \"\"\"Create an ID.\n\n        Note that if `prefix` is not provided, it will be `guid`, even if the\n        `method` is `METHOD_INT`.\n        \"\"\"\n        if self.method == IDGenerator.METHOD_UUID:\n            id_ = str(uuid.uuid4())\n        elif self.method == IDGenerator.METHOD_INT:\n            id_ = self.next_int\n            self.next_int += 1\n        else:\n            raise InvalidMethodError(self.method)\n\n        return \"%s:%s-%s\" % (self.namespace.prefix, prefix, id_)", "label": 1}
{"code": "function createClient(conf, options) {\n  conf.default_redirection_url = conf.default_redirection_url || '/';\n  options = options || {};\n  return new OAuth2Client(conf, options);\n}", "label": 3}
{"code": "def line(y, thickness, gaussian_width):\n    \"\"\"\n    Infinite-length line with a solid central region, then Gaussian fall-off at the edges.\n    \"\"\"\n    distance_from_line = abs(y)\n    gaussian_y_coord = distance_from_line - thickness/2.0\n    sigmasq = gaussian_width*gaussian_width\n\n    if sigmasq==0.0:\n        falloff = y*0.0\n    else:\n        with float_error_ignore():\n            falloff = np.exp(np.divide(-gaussian_y_coord*gaussian_y_coord,2*sigmasq))\n\n    return np.where(gaussian_y_coord<=0, 1.0, falloff)", "label": 1}
{"code": "public function copy($destination, array $options = [])\n    {\n        $key = isset($options['encryptionKey']) ? $options['encryptionKey'] : null;\n        $keySHA256 = isset($options['encryptionKeySHA256']) ? $options['encryptionKeySHA256'] : null;\n\n        $response = $this->connection->copyObject(\n            $this->formatDestinationRequest($destination, $options)\n        );\n\n        return new StorageObject(\n            $this->connection,\n            $response['name'],\n            $response['bucket'],\n            $response['generation'],\n            $response + ['requesterProjectId' => $this->identity['userProject']],\n            $key,\n            $keySHA256\n        );\n    }", "label": 2}
{"code": "function(injectionSiteName, previousView, newView, options) {\n      var newInjectionSite, currentPromise,\n        previousDeferred = $.Deferred();\n      this.attachView(injectionSiteName, previousView, options);\n      options.cachedInjectionSite = previousView.injectionSite;\n      newInjectionSite = options.newInjectionSite = $('<span inject=\"' + injectionSiteName + '\">');\n      if (options.addBefore) {\n        previousView.$el.before(newInjectionSite);\n      } else {\n        previousView.$el.after(newInjectionSite);\n      }\n\n      // clear the injections site so it isn't replaced back into the dom.\n      previousView.injectionSite = undefined;\n\n      // transition previous view out\n      previousView.transitionOut(previousDeferred.resolve, options);\n      // transition new current view in\n      currentPromise = this.__transitionInView(newInjectionSite, newView, options);\n\n      // return a combined promise\n      return $.when(previousDeferred.promise(), currentPromise);\n    }", "label": 3}
{"code": "def remove(o)\n      if o == nil\n        raise Error, \"Cannot remove '#{o.class}' from window!\"\n      end\n\n      if i = @objects.index(o)\n        @objects.delete_at(i)\n        true\n      else\n        false\n      end\n    end", "label": 4}
{"code": "def read filename\n      return @current if @current && @current.filename == filename\n      raise FileNotFoundError, \"File not found: #{filename}\" unless workspace.has_file?(filename)\n      workspace.source(filename)\n    end", "label": 4}
{"code": "func (r *reader) read() error {\n\tn, err := r.r.Read(r.b)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif n < 1 {\n\t\treturn trace.Errorf(\"unexpected error, read 0 bytes\")\n\t}\n\n\tswitch r.b[0] {\n\tcase OKByte:\n\t\treturn nil\n\tcase WarnByte, ErrByte:\n\t\tr.s.Scan()\n\t\tif err := r.s.Err(); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\treturn trace.Errorf(r.s.Text())\n\t}\n\treturn trace.Errorf(\"unrecognized command: %#v\", r.b)\n}", "label": 5}
{"code": "def levenshtein_distance(str_a, str_b):\n    \"\"\"Calculate the Levenshtein distance between string a and b.\n\n    :param str_a: String - input string a\n    :param str_b: String - input string b\n    :return: Number - Levenshtein Distance between string a and b\n    \"\"\"\n    len_a, len_b = len(str_a), len(str_b)\n    if len_a > len_b:\n        str_a, str_b = str_b, str_a\n        len_a, len_b = len_b, len_a\n    current = range(len_a + 1)\n    for i in range(1, len_b + 1):\n        previous, current = current, [i] + [0] * len_a\n        for j in range(1, len_a + 1):\n            add, delete = previous[j] + 1, current[j - 1] + 1\n            change = previous[j - 1]\n            if str_a[j - 1] != str_b[i - 1]:\n                change += + 1\n            current[j] = min(add, delete, change)\n    return current[len_a]", "label": 1}
{"code": "def pause(self, id, when=None): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Pause a running result.\n\n        :param id: Result ID as an int.\n        :param when: Must be string `end-of-test` or `end-of-loop`.\n        \"\"\"\n        return self.service.post(self.base+str(id)+'/pause/', params={'when': when})", "label": 1}
{"code": "def logger(options)\n      if options[:level]\n        options[:level] = options[:level].to_sym\n\n        unless [:debug, :info, :warn, :error].include? options[:level]\n          UI.warning(format(WARN_INVALID_LOG_LEVEL, options[:level]))\n          options.delete :level\n        end\n      end\n\n      if options[:only] && options[:except]\n        UI.warning WARN_INVALID_LOG_OPTIONS\n\n        options.delete :only\n        options.delete :except\n      end\n\n      # Convert the :only and :except options to a regular expression\n      [:only, :except].each do |name|\n        next unless options[name]\n\n        list = [].push(options[name]).flatten.map do |plugin|\n          Regexp.escape(plugin.to_s)\n        end\n\n        options[name] = Regexp.new(list.join(\"|\"), Regexp::IGNORECASE)\n      end\n\n      UI.options = UI.options.merge(options)\n    end", "label": 4}
{"code": "def parallel_map(func, iterable, args=None, kwargs=None, workers=None):\n    \"\"\"Map func on a list using gevent greenlets.\n\n    :param func: function applied on iterable elements\n    :type func: function\n    :param iterable: elements to map the function over\n    :type iterable: iterable\n    :param args: arguments of func\n    :type args: tuple\n    :param kwargs: keyword arguments of func\n    :type kwargs: dict\n    :param workers: limit the number of greenlets\n                    running in parrallel\n    :type workers: int\n    \"\"\"\n    if args is None:\n        args = ()\n    if kwargs is None:\n        kwargs = {}\n    if workers is not None:\n        pool = Pool(workers)\n    else:\n        pool = Group()\n    iterable = [pool.spawn(func, i, *args, **kwargs) for i in iterable]\n    pool.join(raise_error=True)\n    for idx, i in enumerate(iterable):\n        i_type = type(i.get())\n        i_value = i.get()\n        if issubclass(i_type, BaseException):\n            raise i_value\n        iterable[idx] = i_value\n    return iterable", "label": 1}
{"code": "def indifferent_hash\n      Hash.new {|hash,key| hash[key.to_s] if Symbol === key }\n    end", "label": 4}
{"code": "public function translateBatch(array $strings, array $options = [])\n    {\n        $options += [\n            'model' => null,\n        ];\n\n        $options = array_filter($options + [\n            'q' => $strings,\n            'key' => $this->key,\n            'target' => $this->targetLanguage,\n            'model' => $options['model']\n        ], function ($opt) {\n            return !is_null($opt);\n        });\n\n        $response = $this->connection->listTranslations($options);\n\n        $translations = [];\n        $strings = array_values($strings);\n\n        if (isset($response['data']['translations'])) {\n            foreach ($response['data']['translations'] as $key => $translation) {\n                $source = isset($translation['detectedSourceLanguage'])\n                    ? $translation['detectedSourceLanguage']\n                    : $options['source'];\n\n                $model = (isset($translation['model']))\n                    ? $translation['model']\n                    : null;\n\n                $translations[] = [\n                    'source' => $source,\n                    'input' => $strings[$key],\n                    'text' => $translation['translatedText'],\n                    'model' => $model\n                ];\n            }\n        }\n\n        return $translations;\n    }", "label": 2}
{"code": "func NewClusterName(spec ClusterNameSpecV2) (ClusterName, error) {\n\tcn := ClusterNameV2{\n\t\tKind:    KindClusterName,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName:      MetaNameClusterName,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: spec,\n\t}\n\tif err := cn.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &cn, nil\n}", "label": 5}
{"code": "function detect_method_or_property(cls, key, value, pair) {\n  if (isFn(value)) {\n    var m = make_method(key, value);\n    if (apply_autodetected(m, pair))\n      return cls[\"members\"].push(m); \n  }\n  else {\n    var p = make_property(key, value);\n    if (apply_autodetected(p, pair))\n      return cls[\"members\"].push(p);\n  }\n}", "label": 3}
{"code": "public boolean hasMoreElements()\r\n    {\r\n        try\r\n        {\r\n            if (!hasCalledCheck)\r\n            {\r\n                hasCalledCheck = true;\r\n                hasNext = resultSetAndStatment.m_rs.next();\r\n            }\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            LoggerFactory.getDefaultLogger().error(e);\r\n            //releaseDbResources();\r\n            hasNext = false;\r\n        }\r\n        finally\r\n        {\r\n            if(!hasNext)\r\n            {\r\n                releaseDbResources();\r\n            }\r\n        }\r\n        return hasNext;\r\n    }", "label": 0}
{"code": "public void setRowReader(String newReaderClassName)\r\n    {\r\n        try\r\n        {\r\n            m_rowReader =\r\n                (RowReader) ClassHelper.newInstance(\r\n                    newReaderClassName,\r\n                    ClassDescriptor.class,\r\n                    this);\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            throw new MetadataException(\"Instantiating of current set RowReader failed\", e);\r\n        }\r\n    }", "label": 0}
{"code": "public function add(array $fields = [], array $options = [])\n    {\n        $name = $this->randomName($this->name);\n\n        $document = $this->documentFactory($name);\n        $result = $document->create($fields, $options);\n\n        return $document;\n    }", "label": 2}
{"code": "function _gpfWebGetNamespace (prefix) {\n    var namespace = _gpfWebNamespacePrefix[prefix];\n    if (undefined === namespace) {\n        gpf.Error.unknownNamespacePrefix();\n    }\n    return namespace;\n}", "label": 3}
{"code": "private function doDeserializeProperty(Annotations\\AbstractAnnotation $annotation, $property, $value)\n    {\n        // property is primitive type\n        if (array_key_exists($property, $annotation::$_types)) {\n            return $this->doDeserializeBaseProperty($annotation::$_types[$property], $value);\n        }\n        // property is embedded annotation\n        foreach ($annotation::$_nested as $class => $declaration) {\n            // property is an annotation\n            if (is_string($declaration) && $declaration === $property) {\n                return $this->doDeserialize($value, $class);\n            }\n\n            // property is an annotation array\n            if (is_array($declaration) && count($declaration) === 1 && $declaration[0] === $property) {\n                $annotationArr = [];\n                foreach ($value as $v) {\n                    $annotationArr[] = $this->doDeserialize($v, $class);\n                }\n                return $annotationArr;\n            }\n\n            // property is an annotation hash map\n            if (is_array($declaration) && count($declaration) === 2 && $declaration[0] === $property) {\n                $key = $declaration[1];\n                $annotationHash = [];\n                foreach ($value as $k => $v) {\n                    $annotation = $this->doDeserialize($v, $class);\n                    $annotation->$key = $k;\n                    $annotationHash[$k] = $annotation;\n                }\n                return $annotationHash;\n            }\n        }\n\n        return $value;\n    }", "label": 2}
{"code": "func NewUploader(cfg UploaderConfig) (*Uploader, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tctx, cancel := context.WithCancel(cfg.Context)\n\tuploader := &Uploader{\n\t\tUploaderConfig: cfg,\n\t\tEntry: log.WithFields(log.Fields{\n\t\t\ttrace.Component: teleport.ComponentAuditLog,\n\t\t}),\n\t\tcancel:    cancel,\n\t\tctx:       ctx,\n\t\tsemaphore: make(chan struct{}, cfg.ConcurrentUploads),\n\t\tscanDir:   filepath.Join(cfg.DataDir, cfg.ServerID, SessionLogsDir, cfg.Namespace),\n\t}\n\treturn uploader, nil\n}", "label": 5}
{"code": "def with_base_url(dns_resolver)\n      if @server && @port\n        # First try connecting to the previously selected server and port.\n        begin\n          return yield(base_url)\n        rescue SystemCallError => e\n          if Puppet[:use_srv_records]\n            Puppet.debug \"Connection to cached server and port #{@server}:#{@port} failed, reselecting.\"\n          else\n            raise Puppet::Error, _(\"Connection to cached server and port %{server}:%{port} failed: %{message}\") %\n              { server: @server, port: @port, message: e.message }\n          end\n        end\n      end\n\n      if Puppet[:use_srv_records]\n        dns_resolver.each_srv_record(Puppet[:srv_domain], @srv_service) do |srv_server, srv_port|\n          # Try each of the servers for this service in weighted order\n          # until a working one is found.\n          begin\n            @server = srv_server\n            @port = srv_port\n            return yield(base_url)\n          rescue SystemCallError\n            Puppet.debug \"Connection to selected server and port #{@server}:#{@port} failed. Trying next cached SRV record.\"\n            @server = nil\n            @port = nil\n          end\n        end\n      end\n\n      # If not using SRV records, fall back to the defaults calculated above\n      @server = @default_server\n      @port = @default_port\n\n      Puppet.debug \"No more servers in SRV record, falling back to #{@server}:#{@port}\" if Puppet[:use_srv_records]\n      return yield(base_url)\n    end", "label": 4}
{"code": "def read(self, file_or_filename):\n        \"\"\" Parses a PSAT data file and returns a case object\n\n            file_or_filename: File object or path to PSAT data file\n            return: Case object\n        \"\"\"\n        self.file_or_filename = file_or_filename\n\n        logger.info(\"Parsing PSAT case file [%s].\" % file_or_filename)\n\n        t0 = time.time()\n\n        self.case = Case()\n\n        # Name the case\n        if isinstance(file_or_filename, basestring):\n            name, _ = splitext(basename(file_or_filename))\n        else:\n            name, _ = splitext(file_or_filename.name)\n\n        self.case.name = name\n\n        bus_array = self._get_bus_array_construct()\n        line_array = self._get_line_array_construct()\n        # TODO: Lines.con - Alternative line data format\n        slack_array = self._get_slack_array_construct()\n        pv_array = self._get_pv_array_construct()\n        pq_array = self._get_pq_array_construct()\n        demand_array = self._get_demand_array_construct()\n        supply_array = self._get_supply_array_construct()\n        # TODO: Varname.bus (Bus names)\n\n        # Pyparsing case:\n        case = \\\n            ZeroOrMore(matlab_comment) + bus_array + \\\n            ZeroOrMore(matlab_comment) + line_array + \\\n            ZeroOrMore(matlab_comment) + slack_array + \\\n            ZeroOrMore(matlab_comment) + pv_array + \\\n            ZeroOrMore(matlab_comment) + pq_array + \\\n            ZeroOrMore(matlab_comment) + demand_array + \\\n            ZeroOrMore(matlab_comment) + supply_array\n\n        case.parseFile(file_or_filename)\n\n        elapsed = time.time() - t0\n        logger.info(\"PSAT case file parsed in %.3fs.\" % elapsed)\n\n        return self.case", "label": 1}
{"code": "def run_mutect(job, tumor_bam, normal_bam, univ_options, mutect_options):\n    \"\"\"\n    Spawn a MuTect job for each chromosome on the DNA bams.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict mutect_options: Options specific to MuTect\n    :return: Dict of results from running MuTect on every chromosome\n             perchrom_mutect:\n                 |- 'chr1': fsID\n                 |- 'chr2' fsID\n                 |\n                 |-...\n                 |\n                 +- 'chrM': fsID\n    :rtype: dict\n    \"\"\"\n    # Get a list of chromosomes to handle\n    if mutect_options['chromosomes']:\n        chromosomes = mutect_options['chromosomes']\n    else:\n        chromosomes = sample_chromosomes(job, mutect_options['genome_fai'])\n    perchrom_mutect = defaultdict()\n    for chrom in chromosomes:\n        perchrom_mutect[chrom] = job.addChildJobFn(\n            run_mutect_perchrom, tumor_bam, normal_bam, univ_options, mutect_options, chrom,\n            memory='6G', disk=PromisedRequirement(mutect_disk,\n                                                  tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n                                                  normal_bam['normal_dna_fix_pg_sorted.bam'],\n                                                  mutect_options['genome_fasta'],\n                                                  mutect_options['dbsnp_vcf'],\n                                                  mutect_options['cosmic_vcf'])).rv()\n    return perchrom_mutect", "label": 1}
{"code": "func (cli *NetworkCli) CmdNetworkCreate(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"create\", \"NETWORK-NAME\", \"Creates a new network with a name specified by the user\", false)\n\tflDriver := cmd.String([]string{\"d\", \"-driver\"}, \"\", \"Driver to manage the Network\")\n\tflID := cmd.String([]string{\"-id\"}, \"\", \"Network ID string\")\n\tflOpts := cmd.String([]string{\"o\", \"-opt\"}, \"\", \"Network options\")\n\tflInternal := cmd.Bool([]string{\"-internal\"}, false, \"Config the network to be internal\")\n\tflIPv6 := cmd.Bool([]string{\"-ipv6\"}, false, \"Enable IPv6 on the network\")\n\tflSubnet := cmd.String([]string{\"-subnet\"}, \"\", \"Subnet option\")\n\tflRange := cmd.String([]string{\"-ip-range\"}, \"\", \"Range option\")\n\n\tcmd.Require(flag.Exact, 1)\n\terr := cmd.ParseFlags(args, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\tnetworkOpts := make(map[string]string)\n\tif *flInternal {\n\t\tnetworkOpts[netlabel.Internal] = \"true\"\n\t}\n\tif *flIPv6 {\n\t\tnetworkOpts[netlabel.EnableIPv6] = \"true\"\n\t}\n\n\tdriverOpts := make(map[string]string)\n\tif *flOpts != \"\" {\n\t\topts := strings.Split(*flOpts, \",\")\n\t\tfor _, opt := range opts {\n\t\t\tdriverOpts[netlabel.Key(opt)] = netlabel.Value(opt)\n\t\t}\n\t}\n\n\tvar icList []ipamConf\n\tif *flSubnet != \"\" {\n\t\tic := ipamConf{\n\t\t\tPreferredPool: *flSubnet,\n\t\t}\n\n\t\tif *flRange != \"\" {\n\t\t\tic.SubPool = *flRange\n\t\t}\n\n\t\ticList = append(icList, ic)\n\t}\n\n\t// Construct network create request body\n\tnc := networkCreate{Name: cmd.Arg(0), NetworkType: *flDriver, ID: *flID, IPv4Conf: icList, DriverOpts: driverOpts, NetworkOpts: networkOpts}\n\tobj, _, err := readBody(cli.call(\"POST\", \"/networks\", nc, nil))\n\tif err != nil {\n\t\treturn err\n\t}\n\tvar replyID string\n\terr = json.Unmarshal(obj, &replyID)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfmt.Fprintf(cli.out, \"%s\\n\", replyID)\n\treturn nil\n}", "label": 5}
{"code": "def save\n      n_cmds = Setting[:histsize] > size ? size : Setting[:histsize]\n\n      File.open(Setting[:histfile], \"w\") do |file|\n        n_cmds.times { file.puts(pop) }\n      end\n\n      clear\n    end", "label": 4}
{"code": "public function connect($instance, $name, array $options = [])\n    {\n        if (is_string($instance)) {\n            $instance = $this->instance($instance);\n        }\n\n        $database = $instance->database($name, $options);\n\n        return $database;\n    }", "label": 2}
{"code": "public static vpath get(nitro_service service, String name) throws Exception{\n\t\tvpath obj = new vpath();\n\t\tobj.set_name(name);\n\t\tvpath response = (vpath) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (s *MockStore) Exists(key string) (bool, error) {\n\t_, ok := s.db[key]\n\treturn ok, nil\n}", "label": 5}
{"code": "public static <E> Set<E> retainAbove(Counter<E> counter, double countThreshold) {\r\n    Set<E> removed = new HashSet<E>();\r\n    for (E key : counter.keySet()) {\r\n      if (counter.getCount(key) < countThreshold) {\r\n        removed.add(key);\r\n      }\r\n    }\r\n    for (E key : removed) {\r\n      counter.remove(key);\r\n    }\r\n    return removed;\r\n  }", "label": 0}
{"code": "public function write_bits($bits)\n    {\n        $value = 0;\n\n        foreach ($bits as $n => $bit) {\n            $bit = $bit ? 1 : 0;\n            $value |= ($bit << $n);\n        }\n\n        $this->out .= chr($value);\n\n        return $this;\n    }", "label": 2}
{"code": "def inside_new_context(klass, *args)\n      new_context = append_new_context(klass, *args)\n\n      orig, self.current_context = current_context, new_context\n      yield\n      self.current_context = orig\n    end", "label": 4}
{"code": "public static dnspolicylabel get(nitro_service service, String labelname) throws Exception{\n\t\tdnspolicylabel obj = new dnspolicylabel();\n\t\tobj.set_labelname(labelname);\n\t\tdnspolicylabel response = (dnspolicylabel) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def truncate!\n      Clients.default.database.collections.each do |collection|\n        collection.find.delete_many\n      end and true\n    end", "label": 4}
{"code": "function(key, value)\n  {\n    if ( key in this.indices )\n    {\n      this.values[ this.indices[ key ] ] = value;\n    }\n    else\n    {\n      this.indices[ key ] = this.values.length;\n      AP.push.call( this.values, value );\n      AP.push.call( this.keys, key );\n    }\n\n    return this;\n  }", "label": 3}
{"code": "function stringify(start, end) {\n  var values = []\n  var positions = []\n  var offsets = []\n\n  add(start)\n  add(end)\n\n  if (positions.length !== 0) {\n    values.push(positions.join('-'))\n  }\n\n  if (offsets.length !== 0) {\n    values.push(offsets.join('-'))\n  }\n\n  return values.join(', ')\n\n  // Add a position.\n  function add(position) {\n    var tuple = compile(position)\n\n    if (tuple) {\n      positions.push(tuple[0])\n\n      if (tuple[1]) {\n        offsets.push(tuple[1])\n      }\n    }\n  }\n}", "label": 3}
{"code": "func (s *SizeType) ScaleToWidth(width float64) SizeType {\n\theight := s.Ht * width / s.Wd\n\treturn SizeType{width, height}\n}", "label": 5}
{"code": "def update(data)\n      # Only pass a value for avatar if the key is defined as sending nil will delete the\n      data[:avatar] = avatarise(data[:avatar]) if data.key?(:avatar)\n      data[:channel_id] = data[:channel].resolve_id\n      data.delete(:channel)\n      update_webhook(data)\n    end", "label": 4}
{"code": "def validate_name(name)\n      return if name =~ /\\A[a-z0-9]+[-\\/][a-z][a-z0-9_]*\\Z/i\n\n      namespace, modname = name.split(/[-\\/]/, 2)\n      modname = :namespace_missing if namespace == ''\n\n      err = case modname\n      when nil, '', :namespace_missing\n        _(\"the field must be a namespaced module name\")\n      when /[^a-z0-9_]/i\n        _(\"the module name contains non-alphanumeric (or underscore) characters\")\n      when /^[^a-z]/i\n        _(\"the module name must begin with a letter\")\n      else\n        _(\"the namespace contains non-alphanumeric characters\")\n      end\n\n      raise ArgumentError, _(\"Invalid 'name' field in metadata.json: %{err}\") % { err: err }\n    end", "label": 4}
{"code": "def mouse_callback(type, button, direction, x, y, delta_x, delta_y)\n      # All mouse events\n      @events[:mouse].each do |id, e|\n        e.call(MouseEvent.new(type, button, direction, x, y, delta_x, delta_y))\n      end\n\n      case type\n      # When mouse button pressed\n      when :down\n        @events[:mouse_down].each do |id, e|\n          e.call(MouseEvent.new(type, button, nil, x, y, nil, nil))\n        end\n      # When mouse button released\n      when :up\n        @events[:mouse_up].each do |id, e|\n          e.call(MouseEvent.new(type, button, nil, x, y, nil, nil))\n        end\n      # When mouse motion / movement\n      when :scroll\n        @events[:mouse_scroll].each do |id, e|\n          e.call(MouseEvent.new(type, nil, direction, nil, nil, delta_x, delta_y))\n        end\n      # When mouse scrolling, wheel or trackpad\n      when :move\n        @events[:mouse_move].each do |id, e|\n          e.call(MouseEvent.new(type, nil, nil, x, y, delta_x, delta_y))\n        end\n      end\n    end", "label": 4}
{"code": "public function setDelete($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\V1\\Mutation_Delete::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function read(fp, opts) {\n  if (opts && opts.read) {\n    return opts.read(fp, opts);\n  }\n  return readData.call(this, fp, opts);\n}", "label": 3}
{"code": "def at_exit(&block)\n      return proc {} unless running || block_given?\n      @at_exit = block if block_given?\n      @at_exit ||= proc { SimpleCov.result.format! }\n    end", "label": 4}
{"code": "public function appendInit(callable $middleware, $name = null)\n    {\n        $this->add(self::INIT, $name, $middleware);\n    }", "label": 2}
{"code": "def save_fits(self, data, name):\n        \"\"\"\n        This method simply saves the model components and the residual.\n\n        INPUTS:\n        data    (no default)    Data which is to be saved.\n        name    (no default)    File name for new .fits file. Will overwrite.\n        \"\"\"\n        data = data.reshape(1, 1, data.shape[0], data.shape[0])\n        new_file = pyfits.PrimaryHDU(data,self.img_hdu_list[0].header)\n        new_file.writeto(\"{}\".format(name), overwrite=True)", "label": 1}
{"code": "protected function ensure_dir_exists( $dir ) {\n\t\tif ( ! is_dir( $dir ) ) {\n\t\t\t// Disable the cache if a null device like /dev/null is being used.\n\t\t\tif ( preg_match( '{(^|[\\\\\\\\/])(\\$null|nul|NUL|/dev/null)([\\\\\\\\/]|$)}', $dir ) ) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tif ( ! @mkdir( $dir, 0777, true ) ) {\n\t\t\t\t$error = error_get_last();\n\t\t\t\t\\WP_CLI::warning( sprintf( \"Failed to create directory '%s': %s.\", $dir, $error['message'] ) );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\treturn true;\n\t}", "label": 2}
{"code": "func (s *Server) serveAgent(ctx *srv.ServerContext) error {\n\t// gather information about user and process. this will be used to set the\n\t// socket path and permissions\n\tsystemUser, err := user.Lookup(ctx.Identity.Login)\n\tif err != nil {\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\tuid, err := strconv.Atoi(systemUser.Uid)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tgid, err := strconv.Atoi(systemUser.Gid)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tpid := os.Getpid()\n\n\t// build the socket path and set permissions\n\tsocketDir, err := ioutil.TempDir(os.TempDir(), \"teleport-\")\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdirCloser := &utils.RemoveDirCloser{Path: socketDir}\n\tsocketPath := filepath.Join(socketDir, fmt.Sprintf(\"teleport-%v.socket\", pid))\n\tif err := os.Chown(socketDir, uid, gid); err != nil {\n\t\tif err := dirCloser.Close(); err != nil {\n\t\t\tlog.Warnf(\"failed to remove directory: %v\", err)\n\t\t}\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\n\t// start an agent on a unix socket\n\tagentServer := &teleagent.AgentServer{Agent: ctx.GetAgent()}\n\terr = agentServer.ListenUnixSocket(socketPath, uid, gid, 0600)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tctx.SetEnv(teleport.SSHAuthSock, socketPath)\n\tctx.SetEnv(teleport.SSHAgentPID, fmt.Sprintf(\"%v\", pid))\n\tctx.AddCloser(agentServer)\n\tctx.AddCloser(dirCloser)\n\tctx.Debugf(\"Opened agent channel for Teleport user %v and socket %v.\", ctx.Identity.TeleportUser, socketPath)\n\tgo agentServer.Serve()\n\n\treturn nil\n}", "label": 5}
{"code": "public void forAllReferenceDefinitions(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (Iterator it = _curClassDef.getReferences(); it.hasNext(); )\r\n        {\r\n            _curReferenceDef = (ReferenceDescriptorDef)it.next();\r\n            // first we check whether it is an inherited anonymous reference\r\n            if (_curReferenceDef.isAnonymous() && (_curReferenceDef.getOwner() != _curClassDef))\r\n            {\r\n                continue;\r\n            }\r\n            if (!isFeatureIgnored(LEVEL_REFERENCE) &&\r\n                !_curReferenceDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_IGNORE, false))\r\n            {\r\n                generate(template);\r\n            }\r\n        }\r\n        _curReferenceDef = null;\r\n    }", "label": 0}
{"code": "def write(self, file_or_filename):\n        \"\"\" Writes case data as CSV.\n        \"\"\"\n        if isinstance(file_or_filename, basestring):\n            file = open(file_or_filename, \"wb\")\n        else:\n            file = file_or_filename\n\n        self.writer = csv.writer(file)\n\n        super(CSVWriter, self).write(file)", "label": 1}
{"code": "def dump(cfg, f):\n    '''Serialize ``cfg`` as a libconfig-formatted stream into ``f``\n\n    ``cfg`` must be a ``dict`` with ``str`` keys and libconf-supported values\n    (numbers, strings, booleans, possibly nested dicts, lists, and tuples).\n\n    ``f`` must be a ``file``-like object with a ``write()`` method.\n    '''\n\n    if not isinstance(cfg, dict):\n        raise ConfigSerializeError(\n                'dump() requires a dict as input, not %r of type %r' %\n                (cfg, type(cfg)))\n\n    dump_dict(cfg, f, 0)", "label": 1}
{"code": "func oidcConfigsEqual(a, b oidc.ClientConfig) bool {\n\tif a.RedirectURL != b.RedirectURL {\n\t\treturn false\n\t}\n\tif a.Credentials.ID != b.Credentials.ID {\n\t\treturn false\n\t}\n\tif a.Credentials.Secret != b.Credentials.Secret {\n\t\treturn false\n\t}\n\tif len(a.Scope) != len(b.Scope) {\n\t\treturn false\n\t}\n\tfor i := range a.Scope {\n\t\tif a.Scope[i] != b.Scope[i] {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "label": 5}
{"code": "public static appflowpolicylabel_binding get(nitro_service service, String labelname) throws Exception{\n\t\tappflowpolicylabel_binding obj = new appflowpolicylabel_binding();\n\t\tobj.set_labelname(labelname);\n\t\tappflowpolicylabel_binding response = (appflowpolicylabel_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function declare_loggers() {\n\t\t$logger_dir = WP_CLI_ROOT . '/php/WP_CLI/Loggers';\n\t\t$iterator   = new \\DirectoryIterator( $logger_dir );\n\n\t\t// Make sure the base class is declared first.\n\t\tinclude_once \"$logger_dir/Base.php\";\n\n\t\tforeach ( $iterator as $filename ) {\n\t\t\tif ( '.php' !== substr( $filename, - 4 ) ) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tinclude_once \"$logger_dir/$filename\";\n\t\t}\n\t}", "label": 2}
{"code": "def _preprocess(inp):\n        \"\"\"Revise wording to match canonical and expected forms.\"\"\"\n        inp = re.sub(r'(\\b)a(\\b)', r'\\g<1>one\\g<2>', inp)\n        inp = re.sub(r'to the (.*) power', r'to \\g<1>', inp)\n        inp = re.sub(r'to the (.*?)(\\b)', r'to \\g<1>\\g<2>', inp)\n        inp = re.sub(r'log of', r'log', inp)\n        inp = re.sub(r'(square )?root( of)?', r'sqrt', inp)\n        inp = re.sub(r'squared', r'to two', inp)\n        inp = re.sub(r'cubed', r'to three', inp)\n        inp = re.sub(r'divided?( by)?', r'divide', inp)\n        inp = re.sub(r'(\\b)over(\\b)', r'\\g<1>divide\\g<2>', inp)\n        inp = re.sub(r'(\\b)EE(\\b)', r'\\g<1>e\\g<2>', inp)\n        inp = re.sub(r'(\\b)E(\\b)', r'\\g<1>e\\g<2>', inp)\n        inp = re.sub(r'(\\b)pie(\\b)', r'\\g<1>pi\\g<2>', inp)\n        inp = re.sub(r'(\\b)PI(\\b)', r'\\g<1>pi\\g<2>', inp)\n\n        def findImplicitMultiplications(inp):\n            \"\"\"Replace omitted 'times' references.\"\"\"\n\n            def findConstantMultiplications(inp):\n                split = inp.split(' ')\n                revision = \"\"\n\n                converter = NumberService()\n                for i, w in enumerate(split):\n                    if i > 0 and w in MathService.__constants__:\n                        if converter.isValid(split[i - 1]):\n                            revision += \" times\"\n                    if not revision:\n                        revision = w\n                    else:\n                        revision += \" \" + w\n\n                return revision\n\n            def findUnaryMultiplications(inp):\n                split = inp.split(' ')\n                revision = \"\"\n\n                for i, w in enumerate(split):\n                    if i > 0 and w in MathService.__unaryOperators__:\n                        last_op = split[i - 1]\n\n                        binary = last_op in MathService.__binaryOperators__\n                        unary = last_op in MathService.__unaryOperators__\n\n                        if last_op and not (binary or unary):\n                            revision += \" times\"\n                    if not revision:\n                        revision = w\n                    else:\n                        revision += \" \" + w\n\n                return revision\n\n            return findUnaryMultiplications(findConstantMultiplications(inp))\n\n        return findImplicitMultiplications(inp)", "label": 1}
{"code": "function compile() {\n    swig.log.info('', 'Compiling module list...');\n\n    const modulesPath = path.join(swig.temp, '/**/node_modules/@gilt-tech');\n    const modPaths = glob.sync(modulesPath);\n    let dirs;\n\n    swig.log.verbose(`[compile] searching: ${modulesPath}`);\n    swig.log.verbose(`[compile] found module directories: ${modPaths.length}`);\n\n    modPaths.forEach((modPath) => {\n      swig.log.verbose(`[compile] compiling: ${modPath}`);\n\n      dirs = fs.readdirSync(modPath);\n\n      _.each(dirs, (dir) => {\n        const dirPath = path.join(modPath, dir);\n        if (fs.existsSync(dirPath) && fs.lstatSync(dirPath).isDirectory()) {\n          azModules.push({ name: dir, path: dirPath });\n        }\n      });\n    });\n\n    // group by basename, and take the 'topmost' module in the hierarchy\n    azModules = _.groupBy(azModules, module => path.basename(module.path));\n\n    // pull out the 'winning' module path, for each module\n    azModules = _.map(azModules, (modulesList) => {\n      // the modules arg will be [{ name:, path: }, ...]\n\n      if (modulesList.length === 1) {\n        return modulesList[0];\n      }\n\n      // glob will almost always return the right order,\n      // but let's assert this to be safe. we can spare the cycles.\n      return _.sortBy(modulesList, module => module.path.length)[0];\n    });\n\n    // and now we pretty sort a-z for various output\n    // we dont reset azModules to the sorted array because we need it dirty for deps.less\n    _.sortBy(azModules, mod => mod.name).forEach((mod) => {\n      modules[mod.name] = mod.path;\n    });\n\n    swig.log.verbose('[compile] sorted modules: ');\n    swig.log.verbose(modules);\n  }", "label": 3}
{"code": "func (c *ChannelOut) Request(request []byte) ([]byte, error) {\n\tif err := c.Send(request); err != nil {\n\t\treturn nil, err\n\t}\n\n\treply, err := c.Receive()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif bytes.HasPrefix(reply, rpciOK) {\n\t\treturn reply[2:], nil\n\t}\n\n\treturn nil, fmt.Errorf(\"request %q: %q\", request, reply)\n}", "label": 5}
{"code": "def get_form_prefix(self, step=None, form=None):\n        \"\"\"\n        Returns the prefix which will be used when calling the actual form for\n        the given step. `step` contains the step-name, `form` the form which\n        will be called with the returned prefix.\n\n        If no step is given, the form_prefix will determine the current step\n        automatically.\n        \"\"\"\n        if step is None:\n            step = self.steps.current\n        return str(step)", "label": 1}
{"code": "public static base_responses add(nitro_service client, appfwconfidfield resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwconfidfield addresources[] = new appfwconfidfield[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new appfwconfidfield();\n\t\t\t\taddresources[i].fieldname = resources[i].fieldname;\n\t\t\t\taddresources[i].url = resources[i].url;\n\t\t\t\taddresources[i].isregex = resources[i].isregex;\n\t\t\t\taddresources[i].comment = resources[i].comment;\n\t\t\t\taddresources[i].state = resources[i].state;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def _q_iteration(self, Q, Bpp_solver, Vm, Va, pq):\n        \"\"\" Performs a Q iteration, updates Vm.\n        \"\"\"\n        dVm = -Bpp_solver.solve(Q)\n\n        # Update voltage.\n        Vm[pq] = Vm[pq] + dVm\n        V = Vm * exp(1j * Va)\n\n        return V, Vm, Va", "label": 1}
{"code": "private void readTextsCompressed(File dir, HashMap results) throws IOException\r\n    {\r\n        if (dir.exists() && dir.isDirectory())\r\n        {\r\n            File[] files = dir.listFiles();\r\n\r\n            for (int idx = 0; idx < files.length; idx++)\r\n            {\r\n                if (files[idx].isDirectory())\r\n                {\r\n                    continue;\r\n                }\r\n                results.put(files[idx].getName(), readTextCompressed(files[idx]));\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "func (f *Fpdf) SetMargins(left, top, right float64) {\n\tf.lMargin = left\n\tf.tMargin = top\n\tif right < 0 {\n\t\tright = left\n\t}\n\tf.rMargin = right\n}", "label": 5}
{"code": "func (l *Logger) PanicE(msg string, e error) {\n\tl.Panic(l.formatErr(e, msg))\n}", "label": 5}
{"code": "public FullTypeSignature getTypeErasureSignature() {\r\n\t\tif (typeErasureSignature == null) {\r\n\t\t\ttypeErasureSignature = new ClassTypeSignature(binaryName,\r\n\t\t\t\t\tnew TypeArgSignature[0], ownerTypeSignature == null ? null\r\n\t\t\t\t\t\t\t: (ClassTypeSignature) ownerTypeSignature\r\n\t\t\t\t\t\t\t\t\t.getTypeErasureSignature());\r\n\t\t}\r\n\t\treturn typeErasureSignature;\r\n\t}", "label": 0}
{"code": "protected function configureServer(array $ctx): array\n    {\n        $server = $this->originalServer;\n        $server['REQUEST_TIME'] = time();\n        $server['REQUEST_TIME_FLOAT'] = microtime(true);\n        $server['REMOTE_ADDR'] = $ctx['attributes']['ipAddress'] ?? $ctx['remoteAddr'] ?? '127.0.0.1';\n\n        $server['HTTP_USER_AGENT'] = '';\n        foreach ($ctx['headers'] as $key => $value) {\n            $key = strtoupper(str_replace('-', '_', $key));\n            if (\\in_array($key, ['CONTENT_TYPE', 'CONTENT_LENGTH'])) {\n                $server[$key] = implode(', ', $value);\n            } else {\n                $server['HTTP_' . $key] = implode(', ', $value);\n            }\n        }\n\n        return $server;\n    }", "label": 2}
{"code": "def start(self):\n        \"\"\" Monitor the bus for events and handle them \"\"\"\n        print(\"Entering monitoring mode, press CTRL-C to quit\")\n        serial = self._connection.serial\n\n        while True:\n            serial.write(b\"@R\")\n            length = int(serial.read(), 16)\n            data = serial.read(length * 2)\n            message = messages.parse(data)\n            if not (self._options.filter and\n                    message.entity and\n                    message.entity in self._devices):\n                logging.debug(\" \".join(message.bytes))\n            if not self._options.config or \\\n               message.entity is None or \\\n               message.entity in self._devices:\n                continue\n\n            print(\"New device found\")\n            ha_id = input(\"Enter home assistant unique ID: \")\n            name = input(\"Enter name: \")\n            self._add_device(scs_id=message.entity, ha_id=ha_id, name=name)", "label": 1}
{"code": "def bam2fastq(bamfile, univ_options, picard_options):\n    \"\"\"\n    Split an input bam to paired fastqs.\n\n    :param str bamfile: Path to a bam file\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict picard_options: Dict of options specific to Picard\n    :return: Path to the _1.fastq file\n    :rtype: str\n    \"\"\"\n    work_dir = os.path.split(bamfile)[0]\n    base_name = os.path.split(os.path.splitext(bamfile)[0])[1]\n    parameters = ['SamToFastq',\n                  ''.join(['I=', docker_path(bamfile)]),\n                  ''.join(['F=/data/', base_name, '_1.fastq']),\n                  ''.join(['F2=/data/', base_name, '_2.fastq']),\n                  ''.join(['FU=/data/', base_name, '_UP.fastq'])]\n    docker_call(tool='picard', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], java_xmx=univ_options['java_Xmx'],\n                tool_version=picard_options['version'])\n    first_fastq = ''.join([work_dir, '/', base_name, '_1.fastq'])\n    assert os.path.exists(first_fastq)\n    return first_fastq", "label": 1}
{"code": "function (criteria) {\n            var self = this;\n\n            return this.needOne(criteria).then(function (target) {\n                return self.destroy(target.id).then(function (documents) {\n                    return documents[0];\n                });\n            });\n        }", "label": 3}
{"code": "function addToArray(ast, varName, identifierName) {\n  let changes = [];\n  traverse(ast, {\n    VariableDeclarator(path) {\n      const node = path.node;\n      if (_.get(node, 'id.name') !== varName || _.get(node, 'init.type') !== 'ArrayExpression')\n        return;\n      node.init._filePath = ast._filePath;\n      changes = addToArrayByNode(node.init, identifierName);\n      path.stop();\n    },\n  });\n  return changes;\n}", "label": 3}
{"code": "function(set, clause, result, useSet) {\n\t\tif(result && typeof result === \"object\" && useSet !== false) {\n\t\t\tif( this.translators[clause] ) {\n\t\t\t\tset = this.translators.where.toSet(set, result);\n\t\t\t} else {\n\t\t\t\tset = assign(set, result);\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\telse if(result) {\n\t\t\treturn useSet === undefined ? undefined : false;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}", "label": 3}
{"code": "def trac():\n    '''Set up or update a trac project.\n\n    This trac installation uses python2, git, sqlite (trac-default), gunicorn,\n    and nginx.\n\n    The connection is https-only and secured by a letsencrypt certificate.  This\n    certificate must be created separately with task setup.server_letsencrypt.\n\n    This task installes or updates to the latest trac version hosted at\n    https://pypi.python.org/pypi/Trac\n\n    Created and modified files and dirs of this task:\n\n        ```\n        ~/sites/<sitename>      <--- example: sitename = trac.example.com\n        \u2502\n        \u251c\u2500\u2500 backup.sh           <--- create a local backup (deletes dir backup/\n        \u251c\u2500\u2500 backup                                     |    before it creates\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 <sitename>_tracenv_hotcopy.tar.gz  <--\u00b4     the tarball)\n        \u251c\u2500\u2500 run\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 trac.sock       <--- file-socket for binding to nginx\n        \u251c\u2500\u2500 scripts\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 tracwsgi.py\n        \u251c\u2500\u2500 tracenv\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 conf\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 trac.htpasswd   <--- trac user password hashes\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 trac.ini        <--- trac config file\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 db\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 trac.db         <--- sqlite database\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 git\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 htdocs\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 log\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 plugins\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 README\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 VERSION\n        \u2514\u2500\u2500 virtualenv\n            \u251c\u2500\u2500 bin\n            \u251c\u2500\u2500 include\n            \u251c\u2500\u2500 lib\n            \u251c\u2500\u2500 local\n            \u2514\u2500\u2500 pip-selfcheck.json\n        ```\n\n    How to create a backup tarball \"manually\":\n    `~/sites/<sitename>/backup/tracenv_hotcopy_<yyyy-mm-dd>.tar.gz`:\n\n        ```\n        cd ~/sites/<sitename>  &&  rm -rf ./backup\n        ./virtualenv/bin/trac-admin ./tracenv  hotcopy ./backup/tracenv_hotcopy\n        mkdir -p ./backup  &&  cd ./backup\n        tar czf <sitename>_tracenv_hotcopy_$(date +%F).tar.gz  tracenv_hotcopy/\n        rm -rf tracenv_hotcopy; ls -hl\n        ```\n\n    More infos:\n      https://trac.edgewall.org/wiki/TracInstall\n      https://trac.edgewall.org/wiki/TracFastCgi#NginxConfiguration\n      https://trac.edgewall.org/wiki/TracNginxRecipe\n      https://trac.edgewall.org/wiki/Gunicorn\n      http://www.obeythetestinggoat.com/book/chapter_08.html#_getting_to_a_production_ready_deployment\n      Setting REMOTE_USER for Trac in Gunicorn behind Nginx:\n        http://serverfault.com/a/392096\n      https://trac.edgewall.org/wiki/TracBackup\n    '''\n    hostname = re.sub(r'^[^@]+@', '', env.host)  # without username if any\n    sitename = query_input(\n                   question='\\nEnter site-name of Your trac web service',\n                   default=flo('trac.{hostname}'))\n    username = env.user\n\n    site_dir = flo('/home/{username}/sites/{sitename}')\n    bin_dir = flo('{site_dir}/virtualenv/bin')\n\n    # provisioning steps\n    install_or_upgrade_virtualenv_pip_package()\n    create_directory_structure(site_dir)\n    update_virtualenv(site_dir, sitename)\n    set_up_trac_plugins(sitename, site_dir, bin_dir)\n    set_up_gunicorn(site_dir, sitename)\n    configure_nginx(username, sitename, hostname)\n\n    if query_yes_no('\\nRestore trac environment from backup tarball?',\n                    default='no'):\n        restore_tracenv_from_backup_tarball(site_dir, bin_dir)\n    elif not tracenv_exists(site_dir):\n        init_tracenv(site_dir, bin_dir, username)\n\n    upgrade_tracenv(site_dir, bin_dir)\n\n    set_up_upstart_for_gunicorn(sitename, username, site_dir)", "label": 1}
{"code": "def plot_correlated_groups(self, group=None, n_genes=5, **kwargs):\n        \"\"\"Plots orthogonal expression patterns.\n\n        In the default mode, plots orthogonal gene expression patterns. A\n        specific correlated group of genes can be specified to plot gene\n        expression patterns within that group.\n\n        Parameters\n        ----------\n        group - int, optional, default None\n            If specified, display the genes within the desired correlated\n            group. Otherwise, display the top ranked gene within each distinct\n            correlated group.\n\n        n_genes - int, optional, default 5\n            The number of top ranked genes to display within a correlated\n            group if 'group' is specified.\n\n        **kwargs -\n            All keyword arguments in 'show_gene_expression' and 'scatter'\n            are eligible.\n        \"\"\"\n        geneID_groups = self.adata.uns['gene_groups']\n        if(group is None):\n            for i in range(len(geneID_groups)):\n                self.show_gene_expression(geneID_groups[i][0], **kwargs)\n        else:\n            for i in range(n_genes):\n                self.show_gene_expression(geneID_groups[group][i], **kwargs)", "label": 1}
{"code": "private DefBase getDefForLevel(String level)\r\n    {\r\n        if (LEVEL_CLASS.equals(level))\r\n        {\r\n            return _curClassDef;\r\n        }\r\n        else if (LEVEL_FIELD.equals(level))\r\n        {\r\n            return _curFieldDef;\r\n        }\r\n        else if (LEVEL_REFERENCE.equals(level))\r\n        {\r\n            return _curReferenceDef;\r\n        }\r\n        else if (LEVEL_COLLECTION.equals(level))\r\n        {\r\n            return _curCollectionDef;\r\n        }\r\n        else if (LEVEL_OBJECT_CACHE.equals(level))\r\n        {\r\n            return _curObjectCacheDef;\r\n        }\r\n        else if (LEVEL_INDEX_DESC.equals(level))\r\n        {\r\n            return _curIndexDescriptorDef;\r\n        }\r\n        else if (LEVEL_TABLE.equals(level))\r\n        {\r\n            return _curTableDef;\r\n        }\r\n        else if (LEVEL_COLUMN.equals(level))\r\n        {\r\n            return _curColumnDef;\r\n        }\r\n        else if (LEVEL_FOREIGNKEY.equals(level))\r\n        {\r\n            return _curForeignkeyDef;\r\n        }\r\n        else if (LEVEL_INDEX.equals(level))\r\n        {\r\n            return _curIndexDef;\r\n        }\r\n        else if (LEVEL_PROCEDURE.equals(level))\r\n        {\r\n            return _curProcedureDef;\r\n        }\r\n        else if (LEVEL_PROCEDURE_ARGUMENT.equals(level))\r\n        {\r\n            return _curProcedureArgumentDef;\r\n        }\r\n        else\r\n        {\r\n            return null;\r\n        }\r\n    }", "label": 0}
{"code": "public static base_response delete(nitro_service client, appfwconfidfield resource) throws Exception {\n\t\tappfwconfidfield deleteresource = new appfwconfidfield();\n\t\tdeleteresource.fieldname = resource.fieldname;\n\t\tdeleteresource.url = resource.url;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "func defaultFormatter(val float64, precision int) string {\n\treturn strconv.FormatFloat(val, 'f', precision, 64)\n}", "label": 5}
{"code": "def atomic_unsets\n      unsets = []\n      delayed_atomic_unsets.each_pair do |name, docs|\n        path = nil\n        docs.each do |doc|\n          path ||= doc.flag_as_destroyed\n        end\n        unsets.push(path || name)\n      end\n      unsets\n    end", "label": 4}
{"code": "def copy_insecure_private_key\n      if !@default_private_key_path.exist?\n        @logger.info(\"Copying private key to home directory\")\n\n        source      = File.expand_path(\"keys/vagrant\", Vagrant.source_root)\n        destination = @default_private_key_path\n\n        begin\n          FileUtils.cp(source, destination)\n        rescue Errno::EACCES\n          raise Errors::CopyPrivateKeyFailed,\n            source: source,\n            destination: destination\n        end\n      end\n\n      if !Util::Platform.windows?\n        # On Windows, permissions don't matter as much, so don't worry\n        # about doing chmod.\n        if Util::FileMode.from_octal(@default_private_key_path.stat.mode) != \"600\"\n          @logger.info(\"Changing permissions on private key to 0600\")\n          @default_private_key_path.chmod(0600)\n        end\n      end\n    end", "label": 4}
{"code": "function createDefaultLogger(options) {\n\tconst ConsoleLogger = require('./console'),\n\t\tconsoleLogger = new ConsoleLogger(options),\n\t\tconfig = _.mergeWith({\n\t\t\tname: 'logger',\n\t\t\tstreams: [\n\t\t\t\t{\n\t\t\t\t\tlevel: options && options.level || 'trace',\n\t\t\t\t\ttype: 'raw',\n\t\t\t\t\tstream: consoleLogger\n\t\t\t\t}\n\t\t\t]\n\t\t}, options, function (a, b) {\n\t\t\treturn _.isArray(a) ? a.concat(b) : undefined;\n\t\t});\n\n\tconsoleLogger.level = bunyan.resolveLevel(options && options.level || 'trace');\n\n\t// default is to add the problem logger\n\tif (!options || options.problemLogger || options.problemLogger === undefined) {\n\t\tconst ProblemLogger = require('./problem');\n\t\tconfig.streams.push({\n\t\t\tlevel: 'trace',\n\t\t\ttype: 'raw',\n\t\t\tstream: new ProblemLogger(options)\n\t\t});\n\t}\n\n\tconst defaultLogger = bunyan.createLogger(config);\n\t/**\n\t * Set log level\n\t * Backward compatible with Arrow Cloud MVC framework\n\t * @param {Object} nameOrNum log level in string or number\n\t * @return {String}\n\t */\n\tdefaultLogger.setLevel = function (nameOrNum) {\n\t\tvar level = 'trace';\n\t\ttry {\n\t\t\tlevel = bunyan.resolveLevel(nameOrNum);\n\t\t} catch (e) {} // eslint-disable-line no-empty\n\t\tconsoleLogger.level = level;\n\t\treturn this.level(level);\n\t};\n\treturn defaultLogger;\n}", "label": 3}
{"code": "def activate_program(self, program):\n        \"\"\"\n            Called by program which desires to manipulate this actuator, when it is activated.\n        \"\"\"\n        self.logger.debug(\"activate_program %s\", program)\n        if program in self.program_stack:\n            return\n\n        with self._program_lock:\n            self.logger.debug(\"activate_program got through %s\", program)\n            self.program_stack.append(program)\n            self._update_program_stack()", "label": 1}
{"code": "public static String getOjbClassName(ResultSet rs)\r\n    {\r\n        try\r\n        {\r\n            return rs.getString(OJB_CLASS_COLUMN);\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            return null;\r\n        }\r\n    }", "label": 0}
{"code": "def write_case_data(self, file):\r\n        \"\"\" Writes case data to file.\r\n        \"\"\"\r\n        change_code = 0\r\n        s_base = self.case.base_mva\r\n        timestr = time.strftime(\"%Y%m%d%H%M\", time.gmtime())\r\n        file.write(\"%d, %8.2f, 30 / PSS(tm)E-30 RAW created by Pylon (%s).\\n\" %\r\n                   (change_code, s_base, timestr))\r\n        file.write(\"Modified by Hantao Cui, CURENT, UTK\\n \")\r\n        file.write(\"%s, %d BUSES, %d BRANCHES\\n\" %\r\n                   (self.case.name, len(self.case.buses), len(self.case.branches)))", "label": 1}
{"code": "def replace(X, old, new, strict=True, cols=None, rows=None):\n    \"\"\"\n    Replace value `old` with `new` everywhere it appears in-place.\n\n    Implemented by the tabarray method \n    :func:`tabular.tab.tabarray.replace`.\n\n    **Parameters**\n\n            **X** :  numpy ndarray with structured dtype\n\n                    Numpy array for which in-place replacement of `old` with \n                    `new` is to be done.\n\n            **old** : string\n\n            **new** : string\n\n            **strict** :  boolean, optional\n\n            *   If `strict` = `True`, replace only exact occurences of `old`.\n\n            *   If `strict` = `False`, assume `old` and `new` are strings and   \n                replace all occurences of substrings (e.g. like \n                :func:`str.replace`)\n\n            **cols** :  list of strings, optional\n\n                    Names of columns to make replacements in; if `None`, make \n                    replacements everywhere.\n\n            **rows** : list of booleans or integers, optional\n\n                    Rows to make replacements in; if `None`, make replacements \n                    everywhere.\n\n    Note:  This function does in-place replacements.  Thus there are issues \n    handling data types here when replacement dtype is larger than original \n    dtype.  This can be resolved later by making a new array when necessary ...\n\n    \"\"\"\n\n    if cols == None:\n        cols = X.dtype.names\n    elif isinstance(cols, str):\n        cols = cols.split(',')\n\n    if rows == None:\n        rows = np.ones((len(X),), bool)\n\n    if strict:\n        new = np.array(new)\n        for a in cols:\n            if X.dtype[a] < new.dtype:\n                print('WARNING: dtype of column', a, \n                      'is inferior to dtype of ', new, \n                      'which may cause problems.')\n            try:\n                X[a][(X[a] == old)[rows]] = new\n            except:\n                print('Replacement not made on column', a, '.')\n    else:\n        for a in cols:\n            QuickRep = True\n            try:\n                colstr = ''.join(X[a][rows])\n            except TypeError:\n                print('Not replacing in column', a, 'due to type mismatch.')\n            else:\n                avoid = [ord(o) for o in utils.uniqify(old + new + colstr)]\n                ok = set(range(256)).difference(avoid)\n                if len(ok) > 0:\n                    sep = chr(list(ok)[0])\n                else:\n                    ok = set(range(65536)).difference(avoid)\n                    if len(ok) > 0:\n                        sep = unichr(list(ok)[0])\n                    else:\n                        print('All unicode characters represented in column', \n                              a, ', can\\t replace quickly.')\n                        QuickRep = False\n\n                if QuickRep:\n                    newrows = np.array(sep.join(X[a][rows])\n                                       .replace(old, new).split(sep))\n                else:\n                    newrows = np.array([aa.replace(old,new) for aa in \n                                        X[a][rows]])\n                X[a][rows] = np.cast[X.dtype[a]](newrows)\n\n                if newrows.dtype > X.dtype[a]:\n                    print('WARNING: dtype of column', a, 'is inferior to the ' \n                          'dtype of its replacement which may cause problems '\n                          '(ends of strings might get chopped off).')", "label": 1}
{"code": "func MyTables(db models.XODB, schema string, relkind string) ([]*models.Table, error) {\n\tvar err error\n\n\t// get the tables\n\trows, err := models.MyTables(db, schema, relkind)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// get the tables that have Autoincrementing included\n\tautoIncrements, err := models.MyAutoIncrements(db, schema)\n\tif err != nil {\n\t\t// Set it to an empty set on error.\n\t\tautoIncrements = []*models.MyAutoIncrement{}\n\t}\n\n\t// Add information about manual FK.\n\tvar tables []*models.Table\n\tfor _, row := range rows {\n\t\tmanualPk := true\n\t\t// Look for a match in the table name where it contains the autoincrement\n\t\tfor _, autoInc := range autoIncrements {\n\t\t\tif autoInc.TableName == row.TableName {\n\t\t\t\tmanualPk = false\n\t\t\t}\n\t\t}\n\t\ttables = append(tables, &models.Table{\n\t\t\tTableName: row.TableName,\n\t\t\tType:      row.Type,\n\t\t\tManualPk:  manualPk,\n\t\t})\n\t}\n\n\treturn tables, nil\n}", "label": 5}
{"code": "func (f *File) State() (ret []FilePieceState) {\n\tf.t.cl.rLock()\n\tdefer f.t.cl.rUnlock()\n\tpieceSize := int64(f.t.usualPieceSize())\n\toff := f.offset % pieceSize\n\tremaining := f.length\n\tfor i := pieceIndex(f.offset / pieceSize); ; i++ {\n\t\tif remaining == 0 {\n\t\t\tbreak\n\t\t}\n\t\tlen1 := pieceSize - off\n\t\tif len1 > remaining {\n\t\t\tlen1 = remaining\n\t\t}\n\t\tps := f.t.pieceState(i)\n\t\tret = append(ret, FilePieceState{len1, ps})\n\t\toff = 0\n\t\tremaining -= len1\n\t}\n\treturn\n}", "label": 5}
{"code": "public static base_responses update(nitro_service client, nsacl6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnsacl6 updateresources[] = new nsacl6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new nsacl6();\n\t\t\t\tupdateresources[i].acl6name = resources[i].acl6name;\n\t\t\t\tupdateresources[i].aclaction = resources[i].aclaction;\n\t\t\t\tupdateresources[i].srcipv6 = resources[i].srcipv6;\n\t\t\t\tupdateresources[i].srcipop = resources[i].srcipop;\n\t\t\t\tupdateresources[i].srcipv6val = resources[i].srcipv6val;\n\t\t\t\tupdateresources[i].srcport = resources[i].srcport;\n\t\t\t\tupdateresources[i].srcportop = resources[i].srcportop;\n\t\t\t\tupdateresources[i].srcportval = resources[i].srcportval;\n\t\t\t\tupdateresources[i].destipv6 = resources[i].destipv6;\n\t\t\t\tupdateresources[i].destipop = resources[i].destipop;\n\t\t\t\tupdateresources[i].destipv6val = resources[i].destipv6val;\n\t\t\t\tupdateresources[i].destport = resources[i].destport;\n\t\t\t\tupdateresources[i].destportop = resources[i].destportop;\n\t\t\t\tupdateresources[i].destportval = resources[i].destportval;\n\t\t\t\tupdateresources[i].srcmac = resources[i].srcmac;\n\t\t\t\tupdateresources[i].protocol = resources[i].protocol;\n\t\t\t\tupdateresources[i].protocolnumber = resources[i].protocolnumber;\n\t\t\t\tupdateresources[i].icmptype = resources[i].icmptype;\n\t\t\t\tupdateresources[i].icmpcode = resources[i].icmpcode;\n\t\t\t\tupdateresources[i].vlan = resources[i].vlan;\n\t\t\t\tupdateresources[i].Interface = resources[i].Interface;\n\t\t\t\tupdateresources[i].priority = resources[i].priority;\n\t\t\t\tupdateresources[i].established = resources[i].established;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def dict():\n    \"\"\"\n    Compatibility with NLTK.\n    Returns the cmudict lexicon as a dictionary, whose keys are\n    lowercase words and whose values are lists of pronunciations.\n    \"\"\"\n    default = defaultdict(list)\n    for key, value in entries():\n        default[key].append(value)\n    return default", "label": 1}
{"code": "func FMeasure(text string, body interface{}, samples int) bool {\n\tglobalSuite.PushMeasureNode(text, body, types.FlagTypeFocused, codelocation.New(1), samples)\n\treturn true\n}", "label": 5}
{"code": "def lookup(lookup_variants, lookup_invocation)\n      case lookup_variants.size\n      when 0\n        throw :no_such_key\n      when 1\n        merge_single(yield(lookup_variants[0]))\n      else\n        lookup_invocation.with(:merge, self) do\n          result = lookup_variants.reduce(NOT_FOUND) do |memo, lookup_variant|\n            not_found = true\n            value = catch(:no_such_key) do\n              v = yield(lookup_variant)\n              not_found = false\n              v\n            end\n            if not_found\n              memo\n            else\n              memo.equal?(NOT_FOUND) ? convert_value(value) : merge(memo, value)\n            end\n          end\n          throw :no_such_key if result == NOT_FOUND\n          lookup_invocation.report_result(result)\n        end\n      end\n    end", "label": 4}
{"code": "function() {\n      var resultDeferred = $.Deferred();\n      if (this.isDisposed()) {\n        var rejectArguments = Array.prototype.slice.call(arguments);\n        rejectArguments.push('Data Behavior disposed, aborting.');\n        resultDeferred.reject.apply(resultDeferred, rejectArguments);\n      } else {\n        resultDeferred.resolve.apply(resultDeferred, arguments);\n      }\n      return resultDeferred.promise();\n    }", "label": 3}
{"code": "private function readOptions(array $readOptions)\n    {\n        if (isset($readOptions['readConsistency'])) {\n            switch ($readOptions['readConsistency']) {\n                case 'STRONG':\n                    $readOptions['readConsistency'] = ReadConsistency::STRONG;\n                    break;\n\n                case 'EVENTUAL':\n                    $readOptions['readConsistency'] = ReadConsistency::EVENTUAL;\n                    break;\n\n                default:\n                    //@codeCoverageIgnoreStart\n                    throw new \\InvalidArgumentException('Invalid value for Read Consistency.');\n                    break;\n                    //@codeCoverageIgnoreEnd\n            }\n        }\n\n        return $this->serializer->decodeMessage(\n            new ReadOptions,\n            $readOptions\n        );\n    }", "label": 2}
{"code": "public static Context getContext()\r\n    {\r\n        if (ctx == null)\r\n        {\r\n            try\r\n            {\r\n                setContext(null);\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                log.error(\"Cannot instantiate the InitialContext\", e);\r\n                throw new OJBRuntimeException(e);\r\n            }\r\n        }\r\n        return ctx;\r\n    }", "label": 0}
{"code": "public static netbridge_binding get(nitro_service service, String name) throws Exception{\n\t\tnetbridge_binding obj = new netbridge_binding();\n\t\tobj.set_name(name);\n\t\tnetbridge_binding response = (netbridge_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function invalidType($name, $provided)\n    {\n        $expected = implode('|', $this->argDefinitions[$name]['valid']);\n        $msg = \"Invalid configuration value \"\n            . \"provided for \\\"{$name}\\\". Expected {$expected}, but got \"\n            . describe_type($provided) . \"\\n\\n\"\n            . $this->getArgMessage($name);\n        throw new IAE($msg);\n    }", "label": 2}
{"code": "protected function getBaseQueryBuilder($instance = null)\n    {\n        if (! $instance) {\n            $instance = $this->query;\n        }\n\n        if ($instance instanceof EloquentBuilder) {\n            return $instance->getQuery();\n        }\n\n        return $instance;\n    }", "label": 2}
{"code": "def repl\n      until @proceed\n        cmd = interface.read_command(prompt)\n        return if cmd.nil?\n\n        next if cmd == \"\"\n\n        run_cmd(cmd)\n      end\n    end", "label": 4}
{"code": "public function setThreatTypes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::ENUM, \\Google\\Cloud\\WebRisk\\V1beta1\\ThreatType::class);\n        $this->threat_types = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public Set<String> rangeByRankReverse(final long start, final long end) {\n        return doWithJedis(new JedisCallable<Set<String>>() {\n            @Override\n            public Set<String> call(Jedis jedis) {\n                return jedis.zrevrange(getKey(), start, end);\n            }\n        });\n    }", "label": 0}
{"code": "public static base_responses delete(nitro_service client, ntpserver resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tntpserver deleteresources[] = new ntpserver[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tdeleteresources[i] = new ntpserver();\n\t\t\t\tdeleteresources[i].serverip = resources[i].serverip;\n\t\t\t\tdeleteresources[i].servername = resources[i].servername;\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def failed(topic, event)\n      subscribers_for(topic).each{ |subscriber| subscriber.failed(event) }\n    end", "label": 4}
{"code": "public static int Mod(int x, int m) {\r\n        if (m < 0) m = -m;\r\n        int r = x % m;\r\n        return r < 0 ? r + m : r;\r\n    }", "label": 0}
{"code": "def authorize(self, ctx, identity, ops):\n        '''Implements Authorizer.authorize by calling f with the given identity\n        for each operation.\n        '''\n        allowed = []\n        caveats = []\n        for op in ops:\n            ok, fcaveats = self._f(ctx, identity, op)\n            allowed.append(ok)\n            if fcaveats is not None:\n                caveats.extend(fcaveats)\n        return allowed, caveats", "label": 1}
{"code": "public function isReportableException()\n    {\n        $handler = app(ExceptionHandler::class);\n\n        return method_exists($handler, 'shouldReport')\n                ? $handler->shouldReport($this->exception) : true;\n    }", "label": 2}
{"code": "def validate_reuse_access_token_value\n      strategy = token_secret_strategy\n      return if !reuse_access_token || strategy.allows_restoring_secrets?\n\n      ::Rails.logger.warn(\n        \"You have configured both reuse_access_token \" \\\n        \"AND strategy strategy '#{strategy}' that cannot restore tokens. \" \\\n        \"This combination is unsupported. reuse_access_token will be disabled\"\n      )\n      @reuse_access_token = false\n    end", "label": 4}
{"code": "public static <T> List<T> flatten(Collection<List<T>> nestedList) {\r\n    List<T> result = new ArrayList<T>();\r\n    for (List<T> list : nestedList) {\r\n      result.addAll(list);\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "public static OptionalString ofNullable(ResourceKey key, String value) {\n        return new GenericOptionalString(RUNTIME_SOURCE, key, value);\n    }", "label": 0}
{"code": "function getContextualTypeForInitializerExpression(node) {\n            var declaration = node.parent;\n            if (node === declaration.initializer) {\n                if (declaration.type) {\n                    return getTypeFromTypeNode(declaration.type);\n                }\n                if (declaration.kind === 142 /* Parameter */) {\n                    var type = getContextuallyTypedParameterType(declaration);\n                    if (type) {\n                        return type;\n                    }\n                }\n                if (ts.isBindingPattern(declaration.name)) {\n                    return getTypeFromBindingPattern(declaration.name, /*includePatternInType*/ true, /*reportErrors*/ false);\n                }\n                if (ts.isBindingPattern(declaration.parent)) {\n                    var parentDeclaration = declaration.parent.parent;\n                    var name_12 = declaration.propertyName || declaration.name;\n                    if (ts.isVariableLike(parentDeclaration) &&\n                        parentDeclaration.type &&\n                        !ts.isBindingPattern(name_12)) {\n                        var text = getTextOfPropertyName(name_12);\n                        if (text) {\n                            return getTypeOfPropertyOfType(getTypeFromTypeNode(parentDeclaration.type), text);\n                        }\n                    }\n                }\n            }\n            return undefined;\n        }", "label": 3}
{"code": "func (l VirtualDeviceList) ConfigSpec(op types.VirtualDeviceConfigSpecOperation) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tvar fop types.VirtualDeviceConfigSpecFileOperation\n\tswitch op {\n\tcase types.VirtualDeviceConfigSpecOperationAdd:\n\t\tfop = types.VirtualDeviceConfigSpecFileOperationCreate\n\tcase types.VirtualDeviceConfigSpecOperationEdit:\n\t\tfop = types.VirtualDeviceConfigSpecFileOperationReplace\n\tcase types.VirtualDeviceConfigSpecOperationRemove:\n\t\tfop = types.VirtualDeviceConfigSpecFileOperationDestroy\n\tdefault:\n\t\tpanic(\"unknown op\")\n\t}\n\n\tvar res []types.BaseVirtualDeviceConfigSpec\n\tfor _, device := range l {\n\t\tconfig := &types.VirtualDeviceConfigSpec{\n\t\t\tDevice:    device,\n\t\t\tOperation: op,\n\t\t}\n\n\t\tif disk, ok := device.(*types.VirtualDisk); ok {\n\t\t\tconfig.FileOperation = fop\n\n\t\t\t// Special case to attach an existing disk\n\t\t\tif op == types.VirtualDeviceConfigSpecOperationAdd && disk.CapacityInKB == 0 {\n\t\t\t\tchildDisk := false\n\t\t\t\tif b, ok := disk.Backing.(*types.VirtualDiskFlatVer2BackingInfo); ok {\n\t\t\t\t\tchildDisk = b.Parent != nil\n\t\t\t\t}\n\n\t\t\t\tif !childDisk {\n\t\t\t\t\t// Existing disk, clear file operation\n\t\t\t\t\tconfig.FileOperation = \"\"\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tres = append(res, config)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "private function formatDate($when = null)\n    {\n        if (is_string($when)) {\n            return $when;\n        } elseif (!$when) {\n            list($usec, $sec) = explode(' ', microtime());\n            $micro = sprintf(\"%06d\", $usec * 1000000);\n            $when = new \\DateTime(date('Y-m-d H:i:s.' . $micro));\n        } elseif (is_numeric($when)) {\n            // Expect that this is a timestamp\n            $micro = sprintf(\"%06d\", ($when - floor($when)) * 1000000);\n            $when = new \\DateTime(date('Y-m-d H:i:s.'. $micro, (int) $when));\n        }\n        $when->setTimezone(new \\DateTimeZone('UTC'));\n        return $when->format('Y-m-d\\TH:i:s.u000\\Z');\n    }", "label": 2}
{"code": "def parse(source)\n      buffer = ::Parser::Source::Buffer.new('(string)')\n      buffer.source = source\n\n      @parser.reset\n      @parser.parse(buffer)\n    end", "label": 4}
{"code": "public static function get($payload)\n    {\n        switch ($payload) {\n            case 'OK':\n            case 'QUEUED':\n                if (isset(self::$$payload)) {\n                    return self::$$payload;\n                }\n\n                return self::$$payload = new self($payload);\n\n            default:\n                return new self($payload);\n        }\n    }", "label": 2}
{"code": "func GetMinimalIPNet(nw *net.IPNet) *net.IPNet {\n\tif nw == nil {\n\t\treturn nil\n\t}\n\tif len(nw.IP) == 16 && nw.IP.To4() != nil {\n\t\tm := nw.Mask\n\t\tif len(m) == 16 {\n\t\t\tm = m[12:16]\n\t\t}\n\t\treturn &net.IPNet{IP: nw.IP.To4(), Mask: m}\n\t}\n\treturn nw\n}", "label": 5}
{"code": "public Collection getReaders(Object obj)\r\n    {\r\n    \tcheckTimedOutLocks();\r\n        Identity oid = new Identity(obj,getBroker());\r\n        return getReaders(oid);\r\n    }", "label": 0}
{"code": "func (dct *DjangoContentType) Update(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !dct._exists {\n\t\treturn errors.New(\"update failed: does not exist\")\n\t}\n\n\t// if deleted, bail\n\tif dct._deleted {\n\t\treturn errors.New(\"update failed: marked for deletion\")\n\t}\n\n\t// sql query\n\tconst sqlstr = `UPDATE public.django_content_type SET (` +\n\t\t`app_label, model` +\n\t\t`) = ( ` +\n\t\t`$1, $2` +\n\t\t`) WHERE id = $3`\n\n\t// run query\n\tXOLog(sqlstr, dct.AppLabel, dct.Model, dct.ID)\n\t_, err = db.Exec(sqlstr, dct.AppLabel, dct.Model, dct.ID)\n\treturn err\n}", "label": 5}
{"code": "private function operationToArray($operation, $serializer, array $lroMappers)\n    {\n        $response = $operation->getLastProtoResponse();\n        if (is_null($response)) {\n            return null;\n        }\n\n        $response = $serializer->encodeMessage($response);\n\n        $result = null;\n        if ($operation->isDone()) {\n            $type = $response['metadata']['typeUrl'];\n            $result = $this->deserializeResult($operation, $type, $serializer, $lroMappers);\n        }\n\n        $error = $operation->getError();\n        if (!is_null($error)) {\n            $error = $serializer->encodeMessage($error);\n        }\n\n        $response['response'] = $result;\n        $response['error'] = $error;\n\n        return $response;\n    }", "label": 2}
{"code": "protected static function runningApprovedArtisanCommand($app)\n    {\n        return $app->runningInConsole() && ! in_array(\n            $_SERVER['argv'][1] ?? null,\n            array_merge([\n                // 'migrate',\n                'migrate:rollback',\n                'migrate:fresh',\n                // 'migrate:refresh',\n                'migrate:reset',\n                'migrate:install',\n                'package:discover',\n                'queue:listen',\n                'queue:work',\n                'horizon',\n                'horizon:work',\n                'horizon:supervisor',\n            ], config('telescope.ignoreCommands', []), config('telescope.ignore_commands', []))\n        );\n    }", "label": 2}
{"code": "func FSWriteLock(f *os.File) error {\n\tif err := syscall.Flock(int(f.Fd()), syscall.LOCK_EX); err != nil {\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static systemglobal_authenticationradiuspolicy_binding[] get(nitro_service service) throws Exception{\n\t\tsystemglobal_authenticationradiuspolicy_binding obj = new systemglobal_authenticationradiuspolicy_binding();\n\t\tsystemglobal_authenticationradiuspolicy_binding response[] = (systemglobal_authenticationradiuspolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public Response updateTemplate(String id, Map<String, Object> options)\n            throws RequestException, LocalOperationException {\n        Request request = new Request(this);\n        return new Response(request.put(\"/templates/\" + id, options));\n    }", "label": 0}
{"code": "private static function load_yml( $yml_file ) {\n\t\tif ( ! $yml_file ) {\n\t\t\treturn array();\n\t\t}\n\n\t\t$config = Spyc::YAMLLoad( $yml_file );\n\n\t\t// Make sure config-file-relative paths are made absolute.\n\t\t$yml_file_dir = dirname( $yml_file );\n\n\t\tif ( isset( $config['path'] ) ) {\n\t\t\tself::absolutize( $config['path'], $yml_file_dir );\n\t\t}\n\n\t\tif ( isset( $config['require'] ) ) {\n\t\t\tself::arrayify( $config['require'] );\n\t\t\t$config['require'] = \\WP_CLI\\Utils\\expand_globs( $config['require'] );\n\t\t\tforeach ( $config['require'] as &$path ) {\n\t\t\t\tself::absolutize( $path, $yml_file_dir );\n\t\t\t}\n\t\t}\n\n\t\t// Backwards compat\n\t\t// Command 'core config' was moved to 'config create'.\n\t\tif ( isset( $config['core config'] ) ) {\n\t\t\t$config['config create'] = $config['core config'];\n\t\t\tunset( $config['core config'] );\n\t\t}\n\t\t// Command 'checksum core' was moved to 'core verify-checksums'.\n\t\tif ( isset( $config['checksum core'] ) ) {\n\t\t\t$config['core verify-checksums'] = $config['checksum core'];\n\t\t\tunset( $config['checksum core'] );\n\t\t}\n\t\t// Command 'checksum plugin' was moved to 'plugin verify-checksums'.\n\t\tif ( isset( $config['checksum plugin'] ) ) {\n\t\t\t$config['plugin verify-checksums'] = $config['checksum plugin'];\n\t\t\tunset( $config['checksum plugin'] );\n\t\t}\n\n\t\treturn $config;\n\t}", "label": 2}
{"code": "func NewTracer(description string) *Tracer {\n\treturn &Tracer{Started: time.Now().UTC(), Description: description}\n}", "label": 5}
{"code": "public static responderpolicylabel_responderpolicy_binding[] get(nitro_service service, String labelname) throws Exception{\n\t\tresponderpolicylabel_responderpolicy_binding obj = new responderpolicylabel_responderpolicy_binding();\n\t\tobj.set_labelname(labelname);\n\t\tresponderpolicylabel_responderpolicy_binding response[] = (responderpolicylabel_responderpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function prepareElementHidden() {\n\n        var name\n\n        if ( SETTINGS.hiddenName === true ) {\n            name = ELEMENT.name\n            ELEMENT.name = ''\n        }\n        else {\n            name = [\n                typeof SETTINGS.hiddenPrefix == 'string' ? SETTINGS.hiddenPrefix : '',\n                typeof SETTINGS.hiddenSuffix == 'string' ? SETTINGS.hiddenSuffix : '_submit'\n            ]\n            name = name[0] + ELEMENT.name + name[1]\n        }\n\n        P._hidden = $(\n            '<input ' +\n            'type=hidden ' +\n\n            // Create the name using the original input\u2019s with a prefix and suffix.\n            'name=\"' + name + '\"' +\n\n            // If the element has a value, set the hidden value as well.\n            (\n                $ELEMENT.data('value') || ELEMENT.value ?\n                    ' value=\"' + P.get('select', SETTINGS.formatSubmit) + '\"' :\n                    ''\n            ) +\n            '>'\n        )[0]\n\n        $ELEMENT.\n\n            // If the value changes, update the hidden input with the correct format.\n            on('change.' + STATE.id, function() {\n                P._hidden.value = ELEMENT.value ?\n                    P.get('select', SETTINGS.formatSubmit) :\n                    ''\n            })\n\n\n        // Insert the hidden input as specified in the settings.\n        if ( SETTINGS.container ) $( SETTINGS.container ).append( P._hidden )\n        else $ELEMENT.after( P._hidden )\n    }", "label": 3}
{"code": "def undefined_entries(self) -> Set[str]:\n        \"\"\" Return the set of tokens that are referenced but not defined. \"\"\"\n        return as_set([[d for d in self.dependencies(k) if d not in self.grammarelts]\n                       for k in self.grammarelts.keys()])", "label": 1}
{"code": "public PreparedStatement getPreparedStatement(ClassDescriptor cds, String sql,\r\n                                                  boolean scrollable, int explicitFetchSizeHint, boolean callableStmt)\r\n            throws PersistenceBrokerException\r\n    {\r\n        try\r\n        {\r\n            return cds.getStatementsForClass(m_conMan).getPreparedStmt(m_conMan.getConnection(), sql, scrollable, explicitFetchSizeHint, callableStmt);\r\n        }\r\n        catch (LookupException e)\r\n        {\r\n            throw new PersistenceBrokerException(\"Used ConnectionManager instance could not obtain a connection\", e);\r\n        }\r\n    }", "label": 0}
{"code": "def icon(name, options = {})\n      html_properties = {}\n\n      html_properties[\"width\"] = options[:width]\n      html_properties[\"height\"] = options[:height]\n      html_properties[\"aria-label\"] = options[:aria_label]\n      html_properties[\"role\"] = options[:role]\n      html_properties[\"aria-hidden\"] = options[:aria_hidden]\n\n      html_properties[\"class\"] = ([\"icon--#{name}\"] + _icon_classes(options)).join(\" \")\n\n      content_tag :svg, html_properties do\n        content_tag :use, nil, \"xlink:href\" => \"#{asset_path(\"decidim/icons.svg\")}#icon-#{name}\"\n      end\n    end", "label": 4}
{"code": "def run\n      log = @generator.compound_changelog\n\n      if @options.write_to_file?\n        output_filename = @options[:output].to_s\n        File.open(output_filename, \"wb\") { |file| file.write(log) }\n        puts \"Done!\"\n        puts \"Generated log placed in #{Dir.pwd}/#{output_filename}\"\n      else\n        puts log\n      end\n    end", "label": 4}
{"code": "function addSpecFiles() {\n        const specFiles = {};\n        for (const spec in filters.specs) {\n            specFiles[parseResults.specs.specTable[spec].specFile] = true;\n        }\n        filters.specFiles = specFiles;\n    }", "label": 3}
{"code": "def adjust_security_groups(options)\n      return options unless options[:network_configuration] &&\n                     options[:network_configuration][:awsvpc_configuration]\n\n      awsvpc_conf = options[:network_configuration][:awsvpc_configuration]\n\n      security_groups = awsvpc_conf[:security_groups]\n      if [nil, '', 'nil'].include?(security_groups)\n        security_groups = []\n      end\n      if security_groups.empty?\n        fetch = Network::Fetch.new(network[:vpc])\n        sg = fetch.security_group_id\n        security_groups << sg\n        security_groups.uniq!\n      end\n\n      # override security groups\n      options[:network_configuration][:awsvpc_configuration][:security_groups] = security_groups\n      options\n    end", "label": 4}
{"code": "func (h *Handle) Unset(ordinal uint64) error {\n\tif err := h.validateOrdinal(ordinal); err != nil {\n\t\treturn err\n\t}\n\t_, err := h.set(ordinal, 0, 0, false, true, false)\n\treturn err\n}", "label": 5}
{"code": "func writeReply(conn net.Conn) error {\n\t// Write success reply, similar to OpenSSH only success is written.\n\t// https://github.com/openssh/openssh-portable/blob/5d14019/channels.c#L1442-L1452\n\tmessage := []byte{\n\t\tsocks5Version,\n\t\tsocks5Succeeded,\n\t\tsocks5Reserved,\n\t\tsocks5AddressTypeIPv4,\n\t}\n\tn, err := conn.Write(message)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif n != len(message) {\n\t\treturn trace.BadParameter(\"wrote: %v wanted to write: %v\", n, len(message))\n\t}\n\n\t// Reply also requires BND.ADDR and BDN.PORT even though they are ignored\n\t// because Teleport only supports CONNECT.\n\tmessage = []byte{0, 0, 0, 0, 0, 0}\n\tn, err = conn.Write(message)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif n != len(message) {\n\t\treturn trace.BadParameter(\"wrote: %v wanted to write: %v\", n, len(message))\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def to_era(format = \"%o%E.%m.%d\", era_names: ERA_NAME_DEFAULTS)\n      raise EraJa::DateOutOfRangeError unless era_convertible?\n\n      @era_format = format.gsub(/%J/, \"%J%\")\n      str_time = strftime(@era_format)\n      if @era_format =~ /%([EOo]|1O)/\n        case\n        when self.to_time < ::Time.mktime(1912,7,30)\n          str_time = era_year(year - 1867, :meiji, era_names)\n        when self.to_time < ::Time.mktime(1926,12,25)\n          str_time = era_year(year - 1911, :taisho, era_names)\n        when self.to_time < ::Time.mktime(1989,1,8)\n          str_time = era_year(year - 1925, :showa, era_names)\n        when self.to_time < ::Time.mktime(2019, 5, 1)\n          str_time = era_year(year - 1988, :heisei, era_names)\n        else\n          str_time = era_year(year - 2018, :reiwa, era_names)\n        end\n      end\n      str_time.gsub(/%J(\\d+)/) { to_kanzi($1) }\n    end", "label": 4}
{"code": "public void deleteModule(final String name, final String version, final String user, final String password) throws GrapesCommunicationException, AuthenticationException{\n        final Client client = getClient(user, password);\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.getModulePath(name, version));\n        final ClientResponse response = resource.delete(ClientResponse.class);\n\n        client.destroy();\n        if(ClientResponse.Status.OK.getStatusCode() != response.getStatus()){\n            final String message = String.format(FAILED_TO_GET_MODULE, \"to delete module\", name, version);\n\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n    }", "label": 0}
{"code": "protected function encode($content)\n    {\n        $jsonEncodeOptions = [];\n\n        // Here is a place, where any available JSON encoding options, that\n        // deal with users' requirements to JSON response formatting and\n        // structure, can be conveniently applied to tweak the output.\n\n        if ($this->isJsonPrettyPrintEnabled()) {\n            $jsonEncodeOptions[] = JSON_PRETTY_PRINT;\n        }\n\n        $encodedString = $this->performJsonEncoding($content, $jsonEncodeOptions);\n\n        if ($this->isCustomIndentStyleRequired()) {\n            $encodedString = $this->indentPrettyPrintedJson(\n                $encodedString,\n                $this->options['indent_style']\n            );\n        }\n\n        return $encodedString;\n    }", "label": 2}
{"code": "def as_fixture(self, name=None):\n        \"\"\"\n        A decorator to inject this container into a function as a test fixture.\n        \"\"\"\n        if name is None:\n            name = self.name\n\n        def deco(f):\n            @functools.wraps(f)\n            def wrapper(*args, **kw):\n                with self:\n                    kw[name] = self\n                    return f(*args, **kw)\n            return wrapper\n        return deco", "label": 1}
{"code": "public function hasPermission($permission)\n    {\n        if ($this->isAdmin()) {\n            return true;\n        }\n\n        if (is_null($this->permissions)) {\n            $this->permissions = $this->getPermissions();\n        }\n\n        return in_array($permission, $this->permissions);\n    }", "label": 2}
{"code": "def build_text_images(max_width, max_height, stack_title)\n      words = [:keyword, :title].keep_if { |a| fetch_text(a) } # optional keyword/title\n      results = {}\n      trim_boxes = {}\n      top_vertical_trim_offset = Float::INFINITY # Init at a large value, as the code will search for a minimal value.\n      bottom_vertical_trim_offset = 0\n      words.each do |key|\n        # Create empty background\n        empty_path = File.join(Frameit::ROOT, \"lib/assets/empty.png\")\n        text_image = MiniMagick::Image.open(empty_path)\n        image_height = max_height # gets trimmed afterwards anyway, and on the iPad the `y` would get cut\n        text_image.combine_options do |i|\n          # Oversize as the text might be larger than the actual image. We're trimming afterwards anyway\n          i.resize(\"#{max_width * 5.0}x#{image_height}!\") # `!` says it should ignore the ratio\n        end\n\n        current_font = font(key)\n        text = fetch_text(key)\n        UI.verbose(\"Using #{current_font} as font the #{key} of #{screenshot.path}\") if current_font\n        UI.verbose(\"Adding text '#{text}'\")\n\n        text.gsub!('\\n', \"\\n\")\n        text.gsub!(/(?<!\\\\)(')/) { |s| \"\\\\#{s}\" } # escape unescaped apostrophes with a backslash\n\n        interline_spacing = fetch_config['interline_spacing']\n\n        # Add the actual title\n        text_image.combine_options do |i|\n          i.font(current_font) if current_font\n          i.gravity(\"Center\")\n          i.pointsize(actual_font_size)\n          i.draw(\"text 0,0 '#{text}'\")\n          i.interline_spacing(interline_spacing) if interline_spacing\n          i.fill(fetch_config[key.to_s]['color'])\n        end\n\n        results[key] = text_image\n\n        # Natively trimming the image with .trim will result in the loss of the common baseline between the text in all images when side-by-side (e.g. stack_title is false).\n        # Hence retrieve the calculated trim bounding box without actually trimming:\n        calculated_trim_box = text_image.identify do |b|\n          b.format(\"%@\") # CALCULATED: trim bounding box (without actually trimming), see: http://www.imagemagick.org/script/escape.php\n        end\n\n        # Create a Trimbox object from the MiniMagick .identify string with syntax \"<width>x<height>+<offset_x>+<offset_y>\":\n        trim_box = Frameit::Trimbox.new(calculated_trim_box)\n\n        # Get the minimum top offset of the trim box:\n        if trim_box.offset_y < top_vertical_trim_offset\n          top_vertical_trim_offset = trim_box.offset_y\n        end\n\n        # Get the maximum bottom offset of the trim box, this is the top offset + height:\n        if (trim_box.offset_y + trim_box.height) > bottom_vertical_trim_offset\n          bottom_vertical_trim_offset = trim_box.offset_y + trim_box.height\n        end\n\n        # Store for the crop action:\n        trim_boxes[key] = trim_box\n      end\n\n      # Crop text images:\n      words.each do |key|\n        # Get matching trim box:\n        trim_box = trim_boxes[key]\n\n        # For side-by-side text images (e.g. stack_title is false) adjust the trim box based on top_vertical_trim_offset and bottom_vertical_trim_offset to maintain the text baseline:\n        unless stack_title\n          # Determine the trim area by maintaining the same vertical top offset based on the smallest value from all trim boxes (top_vertical_trim_offset).\n          # When the vertical top offset is larger than the smallest vertical top offset, the trim box needs to be adjusted:\n          if trim_box.offset_y > top_vertical_trim_offset\n            # Increase the height of the trim box with the difference in vertical top offset:\n            trim_box.height += trim_box.offset_y - top_vertical_trim_offset\n            # Change the vertical top offset to match that of the others:\n            trim_box.offset_y = top_vertical_trim_offset\n\n            UI.verbose(\"Trim box for key \\\"#{key}\\\" is adjusted to align top: #{trim_box}\\n\")\n          end\n\n          # Check if the height needs to be adjusted to reach the bottom offset:\n          if (trim_box.offset_y + trim_box.height) < bottom_vertical_trim_offset\n            # Set the height of the trim box to the difference between vertical bottom and top offset:\n            trim_box.height = bottom_vertical_trim_offset - trim_box.offset_y\n\n            UI.verbose(\"Trim box for key \\\"#{key}\\\" is adjusted to align bottom: #{trim_box}\\n\")\n          end\n        end\n\n        # Crop image with (adjusted) trim box parameters in MiniMagick string format:\n        results[key].crop(trim_box.string_format)\n      end\n\n      results\n    end", "label": 4}
{"code": "def machine(name, provider, refresh=false)\n      @logger.info(\"Getting machine: #{name} (#{provider})\")\n\n      # Compose the cache key of the name and provider, and return from\n      # the cache if we have that.\n      cache_key = [name, provider]\n      @machines ||= {}\n      if refresh\n        @logger.info(\"Refreshing machine (busting cache): #{name} (#{provider})\")\n        @machines.delete(cache_key)\n      end\n\n      if @machines.key?(cache_key)\n        @logger.info(\"Returning cached machine: #{name} (#{provider})\")\n        return @machines[cache_key]\n      end\n\n      @logger.info(\"Uncached load of machine.\")\n\n      # Determine the machine data directory and pass it to the machine.\n      machine_data_path = @local_data_path.join(\n        \"machines/#{name}/#{provider}\")\n\n      # Create the machine and cache it for future calls. This will also\n      # return the machine from this method.\n      @machines[cache_key] = vagrantfile.machine(\n        name, provider, boxes, machine_data_path, self)\n    end", "label": 4}
{"code": "@Override\n    public ImageSource apply(ImageSource input) {\n        int w = input.getWidth();\n        int h = input.getHeight();\n\n        MatrixSource output = new MatrixSource(input);\n\n        Vector3 n = new Vector3(0, 0, 1);\n\n        for (int y = 0; y < h; y++) {\n            for (int x = 0; x < w; x++) {\n\n                if (x < border || x == w - border || y < border || y == h - border) {\n                    output.setRGB(x, y, VectorHelper.Z_NORMAL);\n                    continue;\n                }\n\n                float s0 = input.getR(x - 1, y + 1);\n                float s1 = input.getR(x, y + 1);\n                float s2 = input.getR(x + 1, y + 1);\n                float s3 = input.getR(x - 1, y);\n                float s5 = input.getR(x + 1, y);\n                float s6 = input.getR(x - 1, y - 1);\n                float s7 = input.getR(x, y - 1);\n                float s8 = input.getR(x + 1, y - 1);\n\n                float nx = -(s2 - s0 + 2 * (s5 - s3) + s8 - s6);\n                float ny = -(s6 - s0 + 2 * (s7 - s1) + s8 - s2);\n\n                n.set(nx, ny, scale);\n                n.nor();\n\n                int rgb = VectorHelper.vectorToColor(n);\n                output.setRGB(x, y, rgb);\n            }\n        }\n\n        return new MatrixSource(output);\n    }", "label": 0}
{"code": "public void addAll(List<TaggedWord> taggedWords, double weight) {\r\n    List<IntTaggedWord> tagWords = listToEvents(taggedWords);\r\n  }", "label": 0}
{"code": "def get_nearest(self, lat, lng, skip_cache=False): \n        \"\"\"\n        Calls `postcodes.get_nearest` but checks correctness of `lat` \n        and `long`, and by default utilises a local cache.\n\n        :param skip_cache: optional argument specifying whether to skip \n                           the cache and make an explicit request.\n\n        :raises IllegalPointException: if the latitude or longitude \n                                       are out of bounds.\n\n        :returns: a dict of the nearest postcode's data.\n        \"\"\"\n        lat, lng = float(lat), float(lng)\n        self._check_point(lat, lng)\n        return self._lookup(skip_cache, get_nearest, lat, lng)", "label": 1}
{"code": "function (req, controller) {\n        var parameters = [];\n        if (controller.conditions && controller.conditions.parameters && controller.conditions.parameters.header) {\n            parameters.push(_checkValues(req.headers, controller.conditions.parameters.header, \"header\"))\n        }\n\n        if (controller.conditions && controller.conditions.parameters && controller.conditions.parameters.query) {\n            parameters.push(_checkValues(req.query, controller.conditions.parameters.query, \"query\"))\n        }\n\n        if (controller.conditions && controller.conditions.parameters && controller.conditions.parameters.body) {\n            parameters.push(_checkValues(req.body, controller.conditions.parameters.body, \"body\"))\n        }\n\n        if (controller.conditions && controller.conditions.parameters && controller.conditions.parameters.path) {\n            parameters.push(_checkValues(req.params, controller.conditions.parameters.path, \"path\"))\n        }\n\n        return Q.all(parameters).then(function (results) {\n            var validatedData = [];\n            var errors = [];\n            results.forEach(function (result) {\n                if (result.data) {\n                    if (!validatedData[result.type]) {\n                        validatedData[result.type] = {};\n                    }\n                    validatedData[result.type] = result.data;\n                }\n\n                // Collect validation errors\n                if (result.err && result.err.err && result.err.name == \"ValidationError\") {\n                    var resultErrors = result.err.err;\n                    resultErrors.forEach(function (error) {\n                        error.in = result.type;\n                        errors.push(error);\n                    });\n                }\n            });\n\n            return Q({\n                validatedData: {\n                    name: controller.name,\n                    version: controller.version,\n                    method: controller.method,\n                    function: controller.function,\n                    data: validatedData\n                },\n                errors: errors\n            });\n        });\n    }", "label": 3}
{"code": "function(a, b){\n\t\t\treturn (a._x < b._x + b._w && a._y < b._y + b._h \n\t\t\t\t\t&& a._x + a._w > b._x && a._y + a._h > b._y)\n\t\t}", "label": 3}
{"code": "public static aaaglobal_binding get(nitro_service service) throws Exception{\n\t\taaaglobal_binding obj = new aaaglobal_binding();\n\t\taaaglobal_binding response = (aaaglobal_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private double getConstraint(double x1, double x2)\n   {\n      double c1,c2,h;\n      c1 = -x1*x1-x2*x2+1+0.1*Math.cos(16*Math.atan(x1/x2));\n      c2 = (x1-0.5)*(x1-0.5)+(x2-0.5)*(x2-0.5)-0.5;\n      if(c1>c2)\n         h = (c1>0)?c1:0;\n      else\n         h = (c2>0)?c2:0;\n      return h;\n   }", "label": 0}
{"code": "function create(req, res, next) {\n  var options = req.connectionOptions;\n  req.user = req.user || {};\n  var params = {\n    userEmail: req.user.email || req.body.updatedBy\n  };\n\n  options = _.extend(options, params);\n\n  logger.debug(\"Middleware: create form: \", {options: options});\n\n  forms.updateForm(options, req.body, formsResultHandlers(constants.resultTypes.forms, req, next));\n}", "label": 3}
{"code": "protected function prepare_method_frame($method_sig, $args = '', $pkt = null)\n    {\n        return $this->connection->prepare_channel_method_frame($this->channel_id, $method_sig, $args, $pkt);\n    }", "label": 2}
{"code": "def expKEGG(organism,names_KEGGids):\n    \"\"\"\n    Gets all KEGG pathways for an organism\n\n    :param organism: an organism as listed in organismsKEGG()\n    :param names_KEGGids: a Pandas dataframe with the columns 'gene_name': and  'KEGGid' as reported from idsKEGG(organism) (or a subset of it).\n\n    :returns df: a Pandas dataframe with 'KEGGid','pathID(1):pathNAME(1)', 'pathID(n):pathNAME(n)'\n    :returns paths: a list of retrieved KEGG pathways\n    \"\"\"\n    #print \"KEGG API: http://rest.kegg.jp/list/pathway/\"+organism\n    #sys.stdout.flush()\n    kegg_paths=urlopen(\"http://rest.kegg.jp/list/pathway/\"+organism).read()\n    kegg_paths=kegg_paths.split(\"\\n\")\n    final=[]\n    for k in kegg_paths:\n        final.append(k.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n\n    df.columns=['pathID','pathName']\n    print(\"Collecting genes for pathways\")\n    sys.stdout.flush()\n    df_pg=pd.DataFrame()\n    for i in df['pathID'].tolist():\n        print(i)\n        sys.stdout.flush()\n        path_genes=urlopen(\"http://rest.kegg.jp/link/genes/\"+i).read()\n        path_genes=path_genes.split(\"\\n\")\n        final=[]\n        for k in path_genes:\n            final.append(k.split(\"\\t\"))\n        if len(final[0]) > 1:\n            df_tmp=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n            df_tmp.columns=['pathID','KEGGid']\n            df_pg=pd.concat([df_pg,df_tmp])\n    df=pd.merge(df,df_pg,on=[\"pathID\"], how=\"outer\")\n    df=df[df['KEGGid'].isin(names_KEGGids['KEGGid'].tolist())]\n    df=pd.merge(df,names_KEGGids,how='left',on=['KEGGid'])\n    df_fA=pd.DataFrame(columns=['KEGGid'])\n    paths=[]\n    for k in df[['pathID']].drop_duplicates()['pathID'].tolist():\n        df_tmp=df[df['pathID']==k]\n        pathName=df_tmp['pathName'].tolist()[0]\n        pathName=\" : \".join([k,pathName])\n        keggIDs_in_path=df_tmp[['KEGGid']].drop_duplicates()['KEGGid'].tolist()\n        a={pathName:keggIDs_in_path}\n        a=pd.DataFrame(a,index=range(len(keggIDs_in_path)))\n        a['KEGGid']=a[pathName].copy()\n        df_fA=pd.merge(df_fA,a,how='outer',on=['KEGGid'])\n        paths.append(pathName)\n\n    return df_fA, paths", "label": 1}
{"code": "function OnlineCheckout(body) {\n  if (!body) throw new Error('No data provided')\n  const config = this.config\n  const hubtelurl =\n    'https://api.hubtel.com/v1/merchantaccount/onlinecheckout/invoice/create'\n\n  const auth =\n    'Basic ' +\n     Buffer.from(config.clientid + ':' + config.secretid).toString('base64')\n\n  return request.post(hubtelurl, {\n    body: body,\n    headers: {\n      Authorization: auth,\n      'content-type': 'application/json',\n    },\n    json: true,\n  })\n}", "label": 3}
{"code": "public function setContext($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Context::class);\n        $this->context = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def _get_crl_url(self, distribution_points):\n        \"\"\"\n        Grabs the first URL out of a asn1crypto.x509.CRLDistributionPoints\n        object\n\n        :param distribution_points:\n            The x509.CRLDistributionPoints object to pull the URL out of\n\n        :return:\n            A unicode string or None\n        \"\"\"\n\n        if distribution_points is None:\n            return None\n\n        for distribution_point in distribution_points:\n            name = distribution_point['distribution_point']\n            if name.name == 'full_name' and name.chosen[0].name == 'uniform_resource_identifier':\n                return name.chosen[0].chosen.native\n\n        return None", "label": 1}
{"code": "public function xcontent(TextDocumentIdentifier $textDocument): Promise\n    {\n        return call(\n            /**\n             * @return \\Generator<int, mixed, mixed, TextDocumentItem>\n             */\n            function () use ($textDocument) {\n                $result = yield $this->handler->request(\n                    'textDocument/xcontent',\n                    ['textDocument' => $textDocument]\n                );\n\n                /** @var TextDocumentItem */\n                return $this->mapper->map($result, new TextDocumentItem);\n            }\n        );\n    }", "label": 2}
{"code": "def get(self, document=None, plugin=None):\n        \"\"\"\n        Get one or more documents.\n\n        :param document: Name of the document\n        :type document: str\n        :param plugin: Plugin object, under which the document was registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if plugin is not None:\n            if document is None:\n                documents_list = {}\n                for key in self.documents.keys():\n                    if self.documents[key].plugin == plugin:\n                        documents_list[key] = self.documents[key]\n                return documents_list\n            else:\n                if document in self.documents.keys():\n                    if self.documents[document].plugin == plugin:\n                        return self.documents[document]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if document is None:\n                return self.documents\n            else:\n                if document in self.documents.keys():\n                    return self.documents[document]\n                else:\n                    return None", "label": 1}
{"code": "def help\n      # We use the optionparser for this. Its just easier. We don't use\n      # an optionparser above because I don't think the performance hits\n      # of creating a whole object are worth checking only a couple flags.\n      opts = OptionParser.new do |o|\n        o.banner = \"Usage: vagrant [options] <command> [<args>]\"\n        o.separator \"\"\n        o.on(\"-v\", \"--version\", \"Print the version and exit.\")\n        o.on(\"-h\", \"--help\", \"Print this help.\")\n        o.separator \"\"\n        o.separator \"Common commands:\"\n\n        # Add the available subcommands as separators in order to print them\n        # out as well.\n        commands = {}\n        longest = 0\n        Vagrant.plugin(\"2\").manager.commands.each do |key, data|\n          # Skip non-primary commands. These only show up in extended\n          # help output.\n          next if !data[1][:primary]\n\n          key           = key.to_s\n          klass         = data[0].call\n          commands[key] = klass.synopsis\n          longest       = key.length if key.length > longest\n        end\n\n        commands.keys.sort.each do |key|\n          o.separator \"     #{key.ljust(longest+2)} #{commands[key]}\"\n          @env.ui.machine(\"cli-command\", key.dup)\n        end\n\n        o.separator \"\"\n        o.separator \"For help on any individual command run `vagrant COMMAND -h`\"\n        o.separator \"\"\n        o.separator \"Additional subcommands are available, but are either more advanced\"\n        o.separator \"or not commonly used. To see all subcommands, run the command\"\n        o.separator \"`vagrant list-commands`.\"\n      end\n\n      @env.ui.info(opts.help, prefix: false)\n    end", "label": 4}
{"code": "public function setExplicitContentDetectionConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\VideoIntelligence\\V1\\ExplicitContentDetectionConfig::class);\n        $this->explicit_content_detection_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def define_resources_routes\n      resources = namespaces.flat_map { |n| n.resources.values }\n      resources.each do |config|\n        define_resource_routes(config)\n      end\n    end", "label": 4}
{"code": "def write(self, message, flush=True):\n        if isinstance(message, bytes):  # pragma: no cover\n            message = message.decode('utf-8')\n\n        \"\"\"A Writting like write method, delayed at each char\"\"\"\n        for char in message:\n            time.sleep(self.delay * (4 if char == '\\n' else 1))\n            super(Writting, self).write(char, flush)", "label": 1}
{"code": "def new():\n    \"\"\"Create a new community.\"\"\"\n    form = CommunityForm(formdata=request.values)\n\n    ctx = mycommunities_ctx()\n    ctx.update({\n        'form': form,\n        'is_new': True,\n        'community': None,\n    })\n\n    if form.validate_on_submit():\n        data = copy.deepcopy(form.data)\n\n        community_id = data.pop('identifier')\n        del data['logo']\n\n        community = Community.create(\n            community_id, current_user.get_id(), **data)\n\n        file = request.files.get('logo', None)\n        if file:\n            if not community.save_logo(file.stream, file.filename):\n                form.logo.errors.append(_(\n                    'Cannot add this file as a logo. Supported formats: '\n                    'PNG, JPG and SVG. Max file size: 1.5 MB.'))\n                db.session.rollback()\n                community = None\n\n        if community:\n            db.session.commit()\n            flash(\"Community was successfully created.\", category='success')\n            return redirect(url_for('.edit', community_id=community.id))\n\n    return render_template(\n        current_app.config['COMMUNITIES_NEW_TEMPLATE'],\n        community_form=form,\n        **ctx\n    )", "label": 1}
{"code": "public function toString()\n    {\n        $translator = call_user_func([$this->dateClass, 'getTranslator']);\n\n        $parts = [];\n\n        $format = !$this->startDate->isStartOfDay() || $this->endDate && !$this->endDate->isStartOfDay()\n            ? 'Y-m-d H:i:s'\n            : 'Y-m-d';\n\n        if ($this->recurrences !== null) {\n            $parts[] = $this->translate('period_recurrences', [], $this->recurrences, $translator);\n        }\n\n        $parts[] = $this->translate('period_interval', [':interval' => $this->dateInterval->forHumans([\n            'join' => true,\n        ])], null, $translator);\n\n        $parts[] = $this->translate('period_start_date', [':date' => $this->startDate->rawFormat($format)], null, $translator);\n\n        if ($this->endDate !== null) {\n            $parts[] = $this->translate('period_end_date', [':date' => $this->endDate->rawFormat($format)], null, $translator);\n        }\n\n        $result = implode(' ', $parts);\n\n        return mb_strtoupper(mb_substr($result, 0, 1)).mb_substr($result, 1);\n    }", "label": 2}
{"code": "function writePages(drizzleData) {\n  return Promise.all(walkPages(drizzleData.pages, drizzleData)).then(\n    () => drizzleData,\n    error => DrizzleError.error(error, drizzleData.options.debug)\n  );\n}", "label": 3}
{"code": "function ContentAuth (pubkey, sig, blockhashbuf, blockheightnum, parenthashbuf, date, address, contentbuf) {\n  if (!(this instanceof ContentAuth)) {\n    return new ContentAuth(pubkey, sig, blockhashbuf, blockheightnum, parenthashbuf, date, address, contentbuf)\n  }\n  this.initialize()\n  this.fromObject({pubkey, sig, blockhashbuf, blockheightnum, parenthashbuf, date, address, contentbuf})\n}", "label": 3}
{"code": "func (a *HistoricalApi) podListAggregations(request *restful.Request, response *restful.Response) {\n\tstart, end, err := getStartEndTimeHistorical(request)\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\tbucketSize, err := getBucketSize(request)\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\taggregations, err := getAggregations(request)\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\tlabels, err := getLabels(request)\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\tkeys := []core.HistoricalKey{}\n\tif request.PathParameter(\"pod-id-list\") != \"\" {\n\t\tfor _, podId := range strings.Split(request.PathParameter(\"pod-id-list\"), \",\") {\n\t\t\tkey := core.HistoricalKey{\n\t\t\t\tObjectType: core.MetricSetTypePod,\n\t\t\t\tPodId:      podId,\n\t\t\t}\n\t\t\tkeys = append(keys, key)\n\t\t}\n\t} else {\n\t\tfor _, podName := range strings.Split(request.PathParameter(\"pod-list\"), \",\") {\n\t\t\tkey := core.HistoricalKey{\n\t\t\t\tObjectType:    core.MetricSetTypePod,\n\t\t\t\tNamespaceName: request.PathParameter(\"namespace-name\"),\n\t\t\t\tPodName:       podName,\n\t\t\t}\n\t\t\tkeys = append(keys, key)\n\t\t}\n\t}\n\tmetricName := request.PathParameter(\"metric-name\")\n\tconvertedMetricName := convertMetricName(metricName)\n\tvar metrics map[core.HistoricalKey][]core.TimestampedAggregationValue\n\tif labels != nil {\n\t\tmetrics, err = a.historicalSource.GetLabeledAggregation(convertedMetricName, labels, aggregations, keys, start, end, bucketSize)\n\t} else {\n\t\tmetrics, err = a.historicalSource.GetAggregation(convertedMetricName, aggregations, keys, start, end, bucketSize)\n\t}\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusInternalServerError, err)\n\t\treturn\n\t}\n\n\tresult := types.MetricAggregationResultList{\n\t\tItems: make([]types.MetricAggregationResult, 0, len(keys)),\n\t}\n\tfor _, key := range keys {\n\t\tresult.Items = append(result.Items, exportTimestampedAggregationValue(metrics[key]))\n\t}\n\tresponse.PrettyPrint(false)\n\tresponse.WriteEntity(result)\n}", "label": 5}
{"code": "def generate_config_for_linter(linter, files)\n      [].tap do |output|\n        output << \"  # Offense count: #{linters_lint_count[linter]}\"\n        output << \"  #{linter}:\"\n        # disable the linter when there are many files with offenses.\n        # exclude the affected files otherwise.\n        if files.count > exclude_limit\n          output << '    enabled: false'\n        else\n          output << '    exclude:'\n          files.each do |filename|\n            output << %{      - \"#{filename}\"}\n          end\n        end\n      end.join(\"\\n\")\n    end", "label": 4}
{"code": "public static final boolean isInside(int x, int y, Rect box) {\n        return (box.x < x && x < box.x + box.w && box.y < y && y < box.y + box.h);\n    }", "label": 0}
{"code": "function Parser(str, opts) {\n  this._oneWayVoid = !!(opts && opts.oneWayVoid);\n  this._reassignJavadoc = !!(opts && opts.reassignJavadoc);\n  this._imports = [];\n  this._tk = new Tokenizer(str);\n  this._tk.next(); // Prime tokenizer.\n}", "label": 3}
{"code": "def each(&block)\n      return enum_for(:each_page) unless block_given?\n      response = self\n      yield(response)\n      until response.last_page?\n        response = response.next_page\n        yield(response)\n      end\n    end", "label": 4}
{"code": "private OJBIterator getRsIteratorFromQuery(Query query, ClassDescriptor cld, RsIteratorFactory factory)\n        throws PersistenceBrokerException\n    {\n        query.setFetchSize(1);\n        if (query instanceof QueryBySQL)\n        {\n            if(logger.isDebugEnabled()) logger.debug(\"Creating SQL-RsIterator for class [\"+cld.getClassNameOfObject()+\"]\");\n            return factory.createRsIterator((QueryBySQL) query, cld, this);\n        }\n\n        if (!cld.isExtent() || !query.getWithExtents())\n        {\n            // no extents just use the plain vanilla RsIterator\n            if(logger.isDebugEnabled()) logger.debug(\"Creating RsIterator for class [\"+cld.getClassNameOfObject()+\"]\");\n\n            return factory.createRsIterator(query, cld, this);\n        }\n\n        if(logger.isDebugEnabled()) logger.debug(\"Creating ChainingIterator for class [\"+cld.getClassNameOfObject()+\"]\");\n\n        ChainingIterator chainingIter = new ChainingIterator();\n\n        // BRJ: add base class iterator\n        if (!cld.isInterface())\n        {\n            if(logger.isDebugEnabled()) logger.debug(\"Adding RsIterator for class [\"+cld.getClassNameOfObject()+\"] to ChainingIterator\");\n\n            chainingIter.addIterator(factory.createRsIterator(query, cld, this));\n        }\n\n        Iterator extents = getDescriptorRepository().getAllConcreteSubclassDescriptors(cld).iterator();\n        while (extents.hasNext())\n        {\n            ClassDescriptor extCld = (ClassDescriptor) extents.next();\n\n            // read same table only once\n            if (chainingIter.containsIteratorForTable(extCld.getFullTableName()))\n            {\n                if(logger.isDebugEnabled()) logger.debug(\"Skipping class [\"+extCld.getClassNameOfObject()+\"]\");\n            }\n            else\n            {\n                if(logger.isDebugEnabled()) logger.debug(\"Adding RsIterator of class [\"+extCld.getClassNameOfObject()+\"] to ChainingIterator\");\n\n                // add the iterator to the chaining iterator.\n                chainingIter.addIterator(factory.createRsIterator(query, extCld, this));\n            }\n        }\n\n        return chainingIter;\n    }", "label": 0}
{"code": "public function getSize()\n    {\n        $size = $this->executor->execute(\n            DriverCommand::GET_ELEMENT_SIZE,\n            [':id' => $this->id]\n        );\n\n        return new WebDriverDimension($size['width'], $size['height']);\n    }", "label": 2}
{"code": "public static gslbrunningconfig get(nitro_service service) throws Exception{\n\t\tgslbrunningconfig obj = new gslbrunningconfig();\n\t\tgslbrunningconfig[] response = (gslbrunningconfig[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "function () {\n        var pending = this._pending,\n            done = this._done,\n            a,\n            b;\n        while (0 !== pending.length) {\n            b = pending.pop();\n            a = pending.pop();\n            done.push(a, b);\n            if (this._areDifferent(a, b)) {\n                return false;\n            }\n        }\n        return true;\n    }", "label": 3}
{"code": "def subscribe(self, field_names):\n        \"\"\"\n        Subscribe to given fields.\n\n        Special fields cannot be subscribed to and will be checked on every iteration. These include:\n\n        * loco name\n        * coordinates\n        * fuel level\n        * gradient\n        * current heading\n        * is in tunnel\n        * time\n\n        You can of course still receive notifications when those change.\n\n        It is important to understand that when the loco changes the set of possible controllers will likely change\n        too. Any missing field changes will stop triggering notifications.\n\n        :param field_names: list\n        :raises ValueError if field is not present on current loco\n        \"\"\"\n        available_controls = dict(self.raildriver.get_controller_list()).values()\n        for field in field_names:\n            if field not in available_controls:\n                raise ValueError('Cannot subscribe to a missing controller {}'.format(field))\n        self.subscribed_fields = field_names", "label": 1}
{"code": "func PgTsDictByDictnameDictnamespace(db XODB, dictname pgtypes.Name, dictnamespace pgtypes.Oid) (*PgTsDict, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, dictname, dictnamespace, dictowner, dicttemplate, dictinitoption ` +\n\t\t`FROM pg_catalog.pg_ts_dict ` +\n\t\t`WHERE dictname = $1 AND dictnamespace = $2`\n\n\t// run query\n\tXOLog(sqlstr, dictname, dictnamespace)\n\tptd := PgTsDict{}\n\n\terr = db.QueryRow(sqlstr, dictname, dictnamespace).Scan(&ptd.Tableoid, &ptd.Cmax, &ptd.Xmax, &ptd.Cmin, &ptd.Xmin, &ptd.Oid, &ptd.Ctid, &ptd.Dictname, &ptd.Dictnamespace, &ptd.Dictowner, &ptd.Dicttemplate, &ptd.Dictinitoption)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ptd, nil\n}", "label": 5}
{"code": "def check(*args)\n      raise_authentication_error unless authenticated?\n      params = arguments(args, required: [:client_id, :access_token]).params\n\n      if arguments.client_id\n        begin\n          get_request(\"/applications/#{arguments.client_id}/tokens/#{arguments.access_token}\", params)\n        rescue Github::Error::NotFound\n          nil\n        end\n      else\n        raise raise_app_authentication_error\n      end\n    end", "label": 4}
{"code": "def loadSV(fname, shape=None, titles=None, aligned=False, byteorder=None,  \n           renamer=None, **kwargs):\n    \"\"\"\n    Load a delimited text file to a numpy record array.\n\n    Basically, this function calls loadSVcols and combines columns returned by \n    that function into a numpy ndarray with stuctured dtype.  Also uses and \n    returns metadata including column names, formats, coloring, &c. if these \n    items are determined during the loading process.\n\n    **Parameters**\n\n        **fname** :  string or file object\n\n            Path (or file object) corresponding to a separated variable\n            (CSV) text file.\n\n         **names** : list of strings\n                \n            Sets the names of the columns of the resulting tabarray.   If \n            not specified, `names` value is determined first by looking for \n            metadata in the header of the file, and if that is not found, \n            are assigned by NumPy's `f0, f1, ... fn` convention.  See \n            **namesinheader** parameter below.\n                \n        **formats** :  string or list of strings\n            \n            Sets the datatypes of the columns.  The value of `formats` can \n            be a list or comma-delimited string of values describing values \n            for each column (e.g. \"str,str,int,float\" or \n            [\"str\", \"str\", \"int\", \"float\"]), a single value to apply to all \n            columns, or anything that can be used in numpy.rec.array \n            constructor.   \n                \n            If the **formats** (or **dtype**) parameter are not  specified, \n            typing is done by inference.  See **typer** parameter below.  \n                                    \n        **dtype** : numpy dtype object\n             \n            Sets the numpy dtype of the resulting tabarray, combining column \n            format and column name information.  If dtype is set, any \n            **names** and **formats** specifications will be overriden.  If \n            the **dtype** (or **formats**) parameter are not  specified, \n            typing is done by inference.  See **typer** parameter below.   \n\n        The **names**, **formats** and **dtype** parameters duplicate \n        parameters of the NumPy record array creation inferface.  Additional \n        paramters of the NumPy inferface that are passed through are \n        **shape**, **titles**, **byteorder** and **aligned** (see NumPy \n        documentation for more information.)\n\n    **kwargs**: keyword argument dictionary of variable length\n\n        Contains various parameters to be passed down to loadSVcols.  These may \n        include  **skiprows**, **comments**, **delimiter**, **lineterminator**, \n        **uselines**, **usecols**, **excludecols**, **metametadata**, \n        **namesinheader**,**headerlines**, **valuefixer**, **linefixer**, \n        **colfixer**, **delimiter_regex**, **inflines**, **typer**, \n        **missingvalues**, **fillingvalues**, **verbosity**, and various CSV \n        module parameters like **escapechar**, **quoting**, **quotechar**, \n        **doublequote**, **skipinitialspace**.              \n\n    **Returns**\n\n        **R** :  numpy record array\n\n            Record array constructed from data in the SV file\n\n        **metadata** :  dictionary\n\n            Metadata read and constructed during process of reading file.\n\n    **See Also:**\n\n            :func:`tabular.io.loadSVcols`, :func:`tabular.io.saveSV`, \n            :func:`tabular.io.DEFAULT_TYPEINFERER`\n\n    \"\"\"    \n    [columns, metadata] = loadSVcols(fname, **kwargs)\n    \n    if 'names' in metadata.keys():\n        names = metadata['names']\n    else:\n        names = None\n \n    if 'formats' in metadata.keys():\n        formats = metadata['formats']\n    else:\n        formats = None\n    \n    if 'dtype' in metadata.keys():\n        dtype = metadata['dtype']\n    else:\n        dtype = None\n \n    if renamer is not None:\n        print 'Trying user-given renamer ...'\n        renamed = renamer(names)\n        if len(renamed) == len(uniqify(renamed)):\n            names = renamed\n            print '''... using renamed names (original names will be in return \n                     metadata)'''\n        else:\n            print '... renamer failed to produce unique names, not using.'\n            \n    if names and len(names) != len(uniqify(names)):\n        print 'Names are not unique, reverting to default naming scheme.'\n        names = None\n\n\n    return [utils.fromarrays(columns, type=np.ndarray, dtype=dtype, \n                             shape=shape, formats=formats, names=names, \n                             titles=titles, aligned=aligned, \n                             byteorder=byteorder), metadata]", "label": 1}
{"code": "public static long count(nitro_service service, Long id) throws Exception{\n\t\tbridgegroup_vlan_binding obj = new bridgegroup_vlan_binding();\n\t\tobj.set_id(id);\n\t\toptions option = new options();\n\t\toption.set_count(true);\n\t\tbridgegroup_vlan_binding response[] = (bridgegroup_vlan_binding[]) obj.get_resources(service,option);\n\t\tif (response != null) {\n\t\t\treturn response[0].__count;\n\t\t}\n\t\treturn 0;\n\t}", "label": 0}
{"code": "public function setApplication($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\Application::class);\n        $this->application = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def mygenerator(n=5, n_edges=5):\n    '''\n    Just a simple generator that creates a network with n nodes and\n    n_edges edges. Edges are assigned randomly, only avoiding self loops.\n    '''\n    G = nx.Graph()\n\n    for i in range(n):\n        G.add_node(i)\n    \n    for i in range(n_edges):\n        nodes = list(G.nodes)\n        n_in = choice(nodes)\n        nodes.remove(n_in)  # Avoid loops\n        n_out = choice(nodes)\n        G.add_edge(n_in, n_out)\n    return G", "label": 1}
{"code": "public String processProcedure(Properties attributes) throws XDocletException\r\n    {\r\n        String       type    = attributes.getProperty(ATTRIBUTE_TYPE);\r\n        ProcedureDef procDef = _curClassDef.getProcedure(type);\r\n        String       attrName;\r\n\r\n        if (procDef == null)\r\n        {    \r\n            procDef = new ProcedureDef(type);\r\n            _curClassDef.addProcedure(procDef);\r\n        }\r\n\r\n        for (Enumeration attrNames = attributes.propertyNames(); attrNames.hasMoreElements(); )\r\n        {\r\n            attrName = (String)attrNames.nextElement();\r\n            procDef.setProperty(attrName, attributes.getProperty(attrName));\r\n        }\r\n        return \"\";\r\n    }", "label": 0}
{"code": "private function render(Field $field)\n    {\n        $field->set('lang', $this->language);\n        $field->set('prefix', $this->buildPrefix($field));\n\n        foreach ($this->fill($field->getAttributes()) as $key => $value) {\n            $field->set($key, $value);\n        }\n\n        return $field->render();\n    }", "label": 2}
{"code": "def _signal_handler(self, signum, frame):\n        \"\"\" Method called when handling signals \"\"\"\n        if self._options.config:\n            with open(self._options.config, \"w\") as cfg:\n                yaml.dump(self._home_assistant_config(), cfg)\n                print(\n                    \"Dumped home assistant configuration at\",\n                    self._options.config)\n        self._connection.close()\n        sys.exit(0)", "label": 1}
{"code": "func (ca *CertAuthorityV2) AddRole(name string) {\n\tfor _, r := range ca.Spec.Roles {\n\t\tif r == name {\n\t\t\treturn\n\t\t}\n\t}\n\tca.Spec.Roles = append(ca.Spec.Roles, name)\n}", "label": 5}
{"code": "public static sslpolicylabel[] get(nitro_service service) throws Exception{\n\t\tsslpolicylabel obj = new sslpolicylabel();\n\t\tsslpolicylabel[] response = (sslpolicylabel[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (f EventFields) GetString(key string) string {\n\tval, found := f[key]\n\tif !found {\n\t\treturn \"\"\n\t}\n\tv, _ := val.(string)\n\treturn v\n}", "label": 5}
{"code": "def list(*args)\n      arguments(args, required: [:column_id])\n      params = arguments.params\n\n      params[\"accept\"] ||= ::Github::Client::Projects::PREVIEW_MEDIA\n\n      response = get_request(\"/projects/columns/#{arguments.column_id}/cards\", params)\n\n      return response unless block_given?\n      response.each { |el| yield el }\n    end", "label": 4}
{"code": "def validate_file_contains_plugin!(file)\n      plugin_count_was = Danger::Plugin.all_plugins.length\n      yield\n\n      if Danger::Plugin.all_plugins.length == plugin_count_was\n        raise(\"#{file} doesn't contain any valid danger plugins.\")\n      end\n    end", "label": 4}
{"code": "def check_config(self, contents):\n        \"\"\"Process config contents with cdrouter-cli -check-config.\n\n        :param contents: Config contents as string.\n        :return: :class:`configs.CheckConfig <configs.CheckConfig>` object\n        :rtype: configs.CheckConfig\n        \"\"\"\n        schema = CheckConfigSchema()\n        resp = self.service.post(self.base,\n                                 params={'process': 'check'}, json={'contents': contents})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "func (c *Client) DeleteNode(namespace string, name string) error {\n\tif namespace == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter namespace\")\n\t}\n\tif name == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter name\")\n\t}\n\t_, err := c.Delete(c.Endpoint(\"namespaces\", namespace, \"nodes\", name))\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def read_object\n      klass_name = read(cache: false)\n      klass = safe_const_get(klass_name)\n\n      object = klass.allocate\n      @object_cache << object\n\n      ivars = read_hash(cache: false)\n      ivars.each do |name, value|\n        if name[0] == '@'\n          object.instance_variable_set(name, value)\n        else\n          # MRI allows an object to have ivars that do not start from '@'\n          # https://github.com/ruby/ruby/blob/ab3a40c1031ff3a0535f6bcf26de40de37dbb1db/range.c#L1225\n          `object[name] = value`\n        end\n      end\n\n      object\n    end", "label": 4}
{"code": "def loop(self):\n        \"\"\"Main loop daemon.\"\"\"\n        while True:\n            sleep(1)\n            new_file_list = self.walk(self.file_path, {})\n            if new_file_list != self.file_list:\n                if self.debug:\n                    self.diff_list(new_file_list, self.file_list)\n                self.run_tests()\n                self.file_list = new_file_list", "label": 1}
{"code": "def edit(self, resource):\n        \"\"\"Edit a device.\n\n        :param resource: :class:`devices.Device <devices.Device>` object\n        :return: :class:`devices.Device <devices.Device>` object\n        :rtype: devices.Device\n        \"\"\"\n        schema = DeviceSchema(exclude=('id', 'created', 'updated', 'result_id', 'attachments_dir'))\n        json = self.service.encode(schema, resource)\n\n        schema = DeviceSchema()\n        resp = self.service.edit(self.base, resource.id, json)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public function addProperty(Property $property)\n    {\n        $fieldName = $property->getName();\n\n        // Check for empty field name\n        if (empty($fieldName)) {\n            throw MappingException::missingFieldName($this->className);\n        }\n\n        $property->setDeclaringClass($this);\n\n        switch (true) {\n            case $property instanceof VersionFieldMetadata:\n                $this->validateAndCompleteFieldMapping($property);\n                $this->validateAndCompleteVersionFieldMapping($property);\n                break;\n\n            case $property instanceof FieldMetadata:\n                $this->validateAndCompleteFieldMapping($property);\n                break;\n\n            case $property instanceof OneToOneAssociationMetadata:\n                $this->validateAndCompleteAssociationMapping($property);\n                $this->validateAndCompleteToOneAssociationMetadata($property);\n                $this->validateAndCompleteOneToOneMapping($property);\n                break;\n\n            case $property instanceof OneToManyAssociationMetadata:\n                $this->validateAndCompleteAssociationMapping($property);\n                $this->validateAndCompleteToManyAssociationMetadata($property);\n                $this->validateAndCompleteOneToManyMapping($property);\n                break;\n\n            case $property instanceof ManyToOneAssociationMetadata:\n                $this->validateAndCompleteAssociationMapping($property);\n                $this->validateAndCompleteToOneAssociationMetadata($property);\n                $this->validateAndCompleteManyToOneMapping($property);\n                break;\n\n            case $property instanceof ManyToManyAssociationMetadata:\n                $this->validateAndCompleteAssociationMapping($property);\n                $this->validateAndCompleteToManyAssociationMetadata($property);\n                $this->validateAndCompleteManyToManyMapping($property);\n                break;\n\n            default:\n                // Transient properties are ignored on purpose here! =)\n                break;\n        }\n\n        $this->addDeclaredProperty($property);\n    }", "label": 2}
{"code": "def permission_required(action):\n    \"\"\"Decorator to require permission.\"\"\"\n    def decorator(f):\n        @wraps(f)\n        def inner(community, *args, **kwargs):\n            permission = current_permission_factory(community, action=action)\n            if not permission.can():\n                abort(403)\n            return f(community, *args, **kwargs)\n        return inner\n    return decorator", "label": 1}
{"code": "def get_raw_default_config_and_read_file_list():\n    \"\"\"Returns a ConfigParser object and a list of filenames that were parsed to initialize it\"\"\"\n    global _CONFIG, _READ_DEFAULT_FILES\n    if _CONFIG is not None:\n        return _CONFIG, _READ_DEFAULT_FILES\n    with _CONFIG_LOCK:\n        if _CONFIG is not None:\n            return _CONFIG, _READ_DEFAULT_FILES\n        try:\n            # noinspection PyCompatibility\n            from ConfigParser import SafeConfigParser\n        except ImportError:\n            # noinspection PyCompatibility,PyUnresolvedReferences\n            from configparser import ConfigParser as SafeConfigParser  # pylint: disable=F0401\n        cfg = SafeConfigParser()\n        read_files = cfg.read(get_default_config_filename())\n        _CONFIG, _READ_DEFAULT_FILES = cfg, read_files\n        return _CONFIG, _READ_DEFAULT_FILES", "label": 1}
{"code": "public static base_response unset(nitro_service client, ntpserver resource, String[] args) throws Exception{\n\t\tntpserver unsetresource = new ntpserver();\n\t\tunsetresource.serverip = resource.serverip;\n\t\tunsetresource.servername = resource.servername;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function _linkIdentity() {\n    var identityOptions = {\n            id: this.socialUserInfo.id,\n            accessToken: this.params.access_token,\n            screen_name: this.socialUserInfo.username\n        };\n\n    return BB.resolve(grasshopper.request(this.token).users.linkIdentity(this.user._id.toString(), 'pinterest', identityOptions));\n}", "label": 3}
{"code": "private function formatValue($value)\n    {\n        if ($value === '') {\n            return '';\n        }\n\n        if ($value === null) {\n            return '<comment>Null</comment>';\n        }\n\n        if (is_bool($value)) {\n            return '<comment>' . ($value ? 'True' : 'False') . '</comment>';\n        }\n\n        if (empty($value)) {\n            return '<comment>Empty</comment>';\n        }\n\n        if (is_array($value)) {\n            return json_encode($value, JSON_UNESCAPED_UNICODE | JSON_UNESCAPED_SLASHES);\n        }\n\n        if (is_object($value)) {\n            return sprintf('<%s>', get_class($value));\n        }\n\n        if (is_scalar($value)) {\n            return $value;\n        }\n\n        throw new InvalidArgumentException(sprintf('Do not know how to format value \"%s\"', print_r($value, true)));\n    }", "label": 2}
{"code": "public SelectStatement getPreparedSelectStatement(Query query, ClassDescriptor cld)\r\n    {\r\n        SelectStatement sql = new SqlSelectStatement(m_platform, cld, query, logger);\r\n        if (logger.isDebugEnabled())\r\n        {\r\n            logger.debug(\"SQL:\" + sql.getStatement());\r\n        }\r\n        return sql;\r\n    }", "label": 0}
{"code": "func (h *ArchiveHandler) Open(u *url.URL, mode int32) (File, error) {\n\tswitch mode {\n\tcase OpenModeReadOnly:\n\t\treturn h.newArchiveFromGuest(u)\n\tcase OpenModeWriteOnly:\n\t\treturn h.newArchiveToGuest(u)\n\tdefault:\n\t\treturn nil, os.ErrNotExist\n\t}\n}", "label": 5}
{"code": "func (b *BoxLayout) SetStyle(style tcell.Style) {\n\tb.style = style\n\tb.PostEventWidgetContent(b)\n}", "label": 5}
{"code": "public static void main(String[] args) throws IOException, ClassNotFoundException {\r\n    CoNLLDocumentReaderAndWriter f = new CoNLLDocumentReaderAndWriter();\r\n    f.init(new SeqClassifierFlags());\r\n    int numDocs = 0;\r\n    int numTokens = 0;\r\n    int numEntities = 0;\r\n    String lastAnsBase = \"\";\r\n    for (Iterator<List<CoreLabel>> it = f.getIterator(new FileReader(args[0])); it.hasNext(); ) {\r\n      List<CoreLabel> doc = it.next();\r\n      numDocs++;\r\n      for (CoreLabel fl : doc) {\r\n        // System.out.println(\"FL \" + (++i) + \" was \" + fl);\r\n        if (fl.word().equals(BOUNDARY)) {\r\n          continue;\r\n        }\r\n        String ans = fl.get(AnswerAnnotation.class);\r\n        String ansBase;\r\n        String ansPrefix;\r\n        String[] bits = ans.split(\"-\");\r\n        if (bits.length == 1) {\r\n          ansBase = bits[0];\r\n          ansPrefix = \"\";\r\n        } else {\r\n          ansBase = bits[1];\r\n          ansPrefix = bits[0];\r\n        }\r\n        numTokens++;\r\n        if (ansBase.equals(\"O\")) {\r\n        } else if (ansBase.equals(lastAnsBase)) {\r\n          if (ansPrefix.equals(\"B\")) {\r\n            numEntities++;\r\n          }\r\n        } else {\r\n          numEntities++;\r\n        }\r\n      }\r\n    }\r\n    System.out.println(\"File \" + args[0] + \" has \" + numDocs + \" documents, \" +\r\n            numTokens + \" (non-blank line) tokens and \" +\r\n            numEntities + \" entities.\");\r\n  }", "label": 0}
{"code": "def get_logdir_file(self, id, filename): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Download a logdir file.\n\n        :param id: Result ID as an int.\n        :param filename: Logdir filename as string.\n        :rtype: tuple `(io.BytesIO, 'filename')`\n        \"\"\"\n        resp = self.service.get(self.base+str(id)+'/logdir/'+filename+'/', stream=True)\n        b = io.BytesIO()\n        stream.stream_response_to_file(resp, path=b)\n        resp.close()\n        b.seek(0)\n        return (b, self.service.filename(resp))", "label": 1}
{"code": "def show\n      Cli::Environments::EvaluateOnly.new(options).evaluate\n      DslDescriber.new.show\n    end", "label": 4}
{"code": "def _get_supply_array_construct(self):\n        \"\"\" Returns a construct for an array of power supply data.\n        \"\"\"\n        bus_no = integer.setResultsName(\"bus_no\")\n        s_rating = real.setResultsName(\"s_rating\") # MVA\n        p_direction = real.setResultsName(\"p_direction\") # CPF\n        p_bid_max = real.setResultsName(\"p_bid_max\") # p.u.\n        p_bid_min = real.setResultsName(\"p_bid_min\") # p.u.\n        p_bid_actual = real.setResultsName(\"p_bid_actual\") # p.u.\n        p_fixed = real.setResultsName(\"p_fixed\") # $/hr\n        p_proportional = real.setResultsName(\"p_proportional\") # $/MWh\n        p_quadratic = real.setResultsName(\"p_quadratic\") # $/MW^2h\n        q_fixed = real.setResultsName(\"q_fixed\") # $/hr\n        q_proportional = real.setResultsName(\"q_proportional\") # $/MVArh\n        q_quadratic = real.setResultsName(\"q_quadratic\") # $/MVAr^2h\n        commitment = boolean.setResultsName(\"commitment\")\n        cost_tie_break = real.setResultsName(\"cost_tie_break\") # $/MWh\n        lp_factor = real.setResultsName(\"lp_factor\")# Loss participation factor\n        q_max = real.setResultsName(\"q_max\") # p.u.\n        q_min = real.setResultsName(\"q_min\") # p.u.\n        cost_cong_up = real.setResultsName(\"cost_cong_up\") # $/h\n        cost_cong_down = real.setResultsName(\"cost_cong_down\") # $/h\n        status = Optional(boolean).setResultsName(\"status\")\n\n        supply_data = bus_no + s_rating + p_direction + p_bid_max + \\\n            p_bid_min + p_bid_actual + p_fixed + p_proportional + \\\n            p_quadratic + q_fixed + q_proportional + q_quadratic + \\\n            commitment + cost_tie_break + lp_factor + q_max + q_min + \\\n            cost_cong_up + cost_cong_down + status + scolon\n\n        supply_data.setParseAction(self.push_supply)\n\n        supply_array = Literal(\"Supply.con\") + \"=\" + \"[\" + \"...\" + \\\n            ZeroOrMore(supply_data + Optional(\"]\" + scolon))\n\n        return supply_array", "label": 1}
{"code": "public static base_responses update(nitro_service client, nslimitselector resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnslimitselector updateresources[] = new nslimitselector[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new nslimitselector();\n\t\t\t\tupdateresources[i].selectorname = resources[i].selectorname;\n\t\t\t\tupdateresources[i].rule = resources[i].rule;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func AppsForPod(uuid, dataDir string, appName string) ([]*v1.App, error) {\n\tp, err := pkgPod.PodFromUUIDString(dataDir, uuid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer p.Close()\n\n\treturn appsForPod(p, appName, appStateInMutablePod)\n}", "label": 5}
{"code": "public DbOrganization getOrganization(final String organizationId) {\n        final DbOrganization dbOrganization = repositoryHandler.getOrganization(organizationId);\n\n        if(dbOrganization == null){\n            throw new WebApplicationException(Response.status(Response.Status.NOT_FOUND)\n                    .entity(\"Organization \" + organizationId + \" does not exist.\").build());\n        }\n\n        return dbOrganization;\n    }", "label": 0}
{"code": "public function setRegex($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CustomInfoType_Regex::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function setPatents($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\Patent::class);\n        $this->patents = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function listDebuggees(array $args = [])\n    {\n        return $this->send([$this->debuggerClient, 'listDebuggees'], [\n            $this->pluck('project', $args),\n            DebuggerClient::getDefaultAgentVersion(),\n            $args\n        ]);\n    }", "label": 2}
{"code": "public static base_response unset(nitro_service client, snmpoption resource, String[] args) throws Exception{\n\t\tsnmpoption unsetresource = new snmpoption();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public long addAll(final Map<String, Double> scoredMember) {\n        return doWithJedis(new JedisCallable<Long>() {\n            @Override\n            public Long call(Jedis jedis) {\n                return jedis.zadd(getKey(), scoredMember);\n            }\n        });\n    }", "label": 0}
{"code": "func GetFloat(data []byte, keys ...string) (val float64, err error) {\n\tv, t, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn 0, e\n\t}\n\n\tif t != Number {\n\t\treturn 0, fmt.Errorf(\"Value is not a number: %s\", string(v))\n\t}\n\n\treturn ParseFloat(v)\n}", "label": 5}
{"code": "public static base_responses export(nitro_service client, appfwlearningdata resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwlearningdata exportresources[] = new appfwlearningdata[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\texportresources[i] = new appfwlearningdata();\n\t\t\t\texportresources[i].profilename = resources[i].profilename;\n\t\t\t\texportresources[i].securitycheck = resources[i].securitycheck;\n\t\t\t\texportresources[i].target = resources[i].target;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, exportresources,\"export\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected function prepare_write( $key ) {\n\t\tif ( ! $this->enabled ) {\n\t\t\treturn false;\n\t\t}\n\n\t\t$filename = $this->filename( $key );\n\n\t\tif ( ! $this->ensure_dir_exists( dirname( $filename ) ) ) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn $filename;\n\t}", "label": 2}
{"code": "public static function fromListObjects(\n        AwsClientInterface $client,\n        array $listObjectsParams,\n        array $options = []\n    ) {\n        $iter = $client->getPaginator('ListObjects', $listObjectsParams);\n        $bucket = $listObjectsParams['Bucket'];\n        $fn = function (BatchDelete $that) use ($iter) {\n            return $iter->each(function ($result) use ($that) {\n                $promises = [];\n                if (is_array($result['Contents'])) {\n                    foreach ($result['Contents'] as $object) {\n                        if ($promise = $that->enqueue($object)) {\n                            $promises[] = $promise;\n                        }\n                    }\n                }\n                return $promises ? Promise\\all($promises) : null;\n            });\n        };\n\n        return new self($client, $bucket, $fn, $options);\n    }", "label": 2}
{"code": "def haml_internal_concat(text = \"\", newline = true, indent = true)\n      if haml_buffer.tabulation == 0\n        haml_buffer.buffer << \"#{text}#{\"\\n\" if newline}\"\n      else\n        haml_buffer.buffer << %[#{haml_indent if indent}#{text.to_s.gsub(\"\\n\", \"\\n#{haml_indent}\")}#{\"\\n\" if newline}]\n      end\n    end", "label": 4}
{"code": "def stop(wait = 5)\n      if @running\n        @server.shutdown if @server\n        @thread.join(wait) if @thread\n      end\n    rescue Timeout::Error\n      if @thread\n        ChefZero::Log.error(\"Chef Zero did not stop within #{wait} seconds! Killing...\")\n        @thread.kill\n        SocketlessServerMap.deregister(port)\n      end\n    ensure\n      @server = nil\n      @thread = nil\n    end", "label": 4}
{"code": "def aikif_web_menu(cur=''):\n    \"\"\" returns the web page header containing standard AIKIF top level web menu \"\"\"\n    pgeHdg = ''\n    pgeBlurb = ''\n    if cur == '': \n        cur = 'Home'\n    txt = get_header(cur) #\"<div id=top_menu>\"\n    txt += '<div id = \"container\">\\n'\n    txt += '   <div id = \"header\">\\n'\n    txt += '   <!-- Banner -->\\n'\n    txt += '   <img src = \"' + os.path.join('/static','aikif_banner.jpg') + '\" alt=\"AIKIF Banner\"/>\\n'\n    txt += '   <ul id = \"menu_list\">\\n'\n    for m in menu:\n        if m[1] == cur:\n            txt += '      <LI id=\"top_menu_selected\"><a href=' + m[0] + '>' + m[1] + '</a></li>\\n'\n            pgeHdg = m[1]\n            try:\n                pgeBlurb = m[2]\n            except Exception:\n                pass\n        else:\n            txt += '      <LI id=\"top_menu\"><a href=' + m[0] + '>' + m[1] + '</a></li>\\n'\n    txt += \"    </ul>\\n    </div>\\n\\n\"\n    txt += '<H1>AIKIF ' + pgeHdg + '</H1>\\n'\n    txt += '<H4>' + pgeBlurb + '</H4>\\n'\n    return txt", "label": 1}
{"code": "def body(self, frame):\n        \"\"\" Creates the dialog body. Returns the widget that should have\n            initial focus.\n        \"\"\"\n        master = Frame(self)\n        master.pack(padx=5, pady=0, expand=1, fill=BOTH)\n\n        title = Label(master, text=\"Buses\")\n        title.pack(side=TOP)\n\n        bus_lb = self.bus_lb = Listbox(master, selectmode=SINGLE, width=10)\n        bus_lb.pack(side=LEFT)\n\n        for bus in self.case.buses:\n            bus_lb.insert(END, bus.name)\n\n        bus_lb.bind(\"<<ListboxSelect>>\", self.on_bus)\n\n        self.bus_params = BusProperties(master)\n\n        return bus_lb", "label": 1}
{"code": "func (fp DynamicForwardedPorts) String() (retval []string) {\n\tfor _, p := range fp {\n\t\tretval = append(retval, p.ToString())\n\t}\n\treturn retval\n}", "label": 5}
{"code": "def variablename(var):\n    \"\"\"\n    Returns the string of a variable name.\n    \"\"\"\n    s=[tpl[0] for tpl in itertools.ifilter(lambda x: var is x[1], globals().items())]\n    s=s[0].upper()\n    return s", "label": 1}
{"code": "function concat(attributeDictionary, attribute) {\n  expect(arguments).to.have.length(\n    2,\n    'Invalid arguments length when concatenating an AttributeDictionary (it ' +\n    'has to be passed 2 arguments)'\n  );\n\n  expect(attributeDictionary).to.be.instanceof(\n    AttributeDictionary,\n    'Invalid argument \"attributeDictionary\" when concatenating an ' +\n    'AttributeDictionary (it has to be an AttributeDictionary)'\n  );\n\n  expect(attribute).to.be.instanceof(\n    Attribute,\n    'Invalid argument \"attribute\" when concatenating an AttributeDictionary ' +\n    '(it has to be an Attribute)'\n  );\n\n  var currentAttributes = [];\n\n  for (var currentAttribute in attributeDictionary) {\n    currentAttributes.push(attributeDictionary[currentAttribute]);\n  }\n\n  currentAttributes.push(attribute);\n\n  return new AttributeDictionary(currentAttributes);\n}", "label": 3}
{"code": "def proxy_connect_headers\n      connect_headers = HTTP::Headers.coerce(\n        Headers::HOST        => headers[Headers::HOST],\n        Headers::USER_AGENT  => headers[Headers::USER_AGENT]\n      )\n\n      connect_headers[Headers::PROXY_AUTHORIZATION] = proxy_authorization_header if using_authenticated_proxy?\n      connect_headers.merge!(proxy[:proxy_headers]) if proxy.key?(:proxy_headers)\n      connect_headers\n    end", "label": 4}
{"code": "function getObject(EntityClass, query) {\n  expect(arguments).to.have.length(\n    2,\n    'Invalid arguments length when inserting an object in a MongoAdapter ' +\n    '(it has to be passed 2 arguments)'\n  );\n\n  var cursor;\n  var document;\n\n  function findDocument(db) {\n    cursor = _buildCursor(db, EntityClass, query);\n    return cursor.next();\n  }\n\n  function checkNotEmpty(doc) {\n    // save document\n    document = doc;\n\n    // check for no result\n    if (doc === null) {\n      throw new QueryError('Object does not exist');\n    }\n  }\n\n  function checkNotMultiple() {\n    // check for multiple results\n    return cursor.hasNext()\n      .then(function (hasNext) {\n        if (hasNext) {\n          throw new QueryError('Query matches multiple objects');\n        }\n      });\n  }\n\n  function populateEntity() {\n    // return populated entity\n    return documentToObject(document, EntityClass.adapterName);\n  }\n\n  return this.getDatabase()\n    .then(findDocument)\n    .then(checkNotEmpty)\n    .then(checkNotMultiple)\n    .then(populateEntity);\n}", "label": 3}
{"code": "func TtfParse(fileStr string) (TtfRec TtfType, err error) {\n\tvar t ttfParser\n\tt.f, err = os.Open(fileStr)\n\tif err != nil {\n\t\treturn\n\t}\n\tversion, err := t.ReadStr(4)\n\tif err != nil {\n\t\treturn\n\t}\n\tif version == \"OTTO\" {\n\t\terr = fmt.Errorf(\"fonts based on PostScript outlines are not supported\")\n\t\treturn\n\t}\n\tif version != \"\\x00\\x01\\x00\\x00\" {\n\t\terr = fmt.Errorf(\"unrecognized file format\")\n\t\treturn\n\t}\n\tnumTables := int(t.ReadUShort())\n\tt.Skip(3 * 2) // searchRange, entrySelector, rangeShift\n\tt.tables = make(map[string]uint32)\n\tvar tag string\n\tfor j := 0; j < numTables; j++ {\n\t\ttag, err = t.ReadStr(4)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tt.Skip(4) // checkSum\n\t\toffset := t.ReadULong()\n\t\tt.Skip(4) // length\n\t\tt.tables[tag] = offset\n\t}\n\terr = t.ParseComponents()\n\tif err != nil {\n\t\treturn\n\t}\n\tt.f.Close()\n\tTtfRec = t.rec\n\treturn\n}", "label": 5}
{"code": "def map_or_apply(function, param):\n    \"\"\"\n    Map the function on ``param``, or apply it, depending whether ``param`` \\\n            is a list or an item.\n\n    :param function: The function to apply.\n    :param param: The parameter to feed the function with (list or item).\n    :returns: The computed value or ``None``.\n    \"\"\"\n    try:\n        if isinstance(param, list):\n            return [next(iter(function(i))) for i in param]\n        else:\n            return next(iter(function(param)))\n    except StopIteration:\n        return None", "label": 1}
{"code": "def add_caveats(self, cavs, key, loc):\n        '''Add an array of caveats to the macaroon.\n\n        This method does not mutate the current object.\n        @param cavs arrary of caveats.\n        @param key the PublicKey to encrypt third party caveat.\n        @param loc locator to find the location object that has a method\n        third_party_info.\n        '''\n        if cavs is None:\n            return\n        for cav in cavs:\n            self.add_caveat(cav, key, loc)", "label": 1}
{"code": "func (r *Registry) Update(obj mo.Reference, changes []types.PropertyChange) {\n\tfor i := range changes {\n\t\tif changes[i].Op == \"\" {\n\t\t\tchanges[i].Op = types.PropertyChangeOpAssign\n\t\t}\n\t\tif changes[i].Val != nil {\n\t\t\trval := reflect.ValueOf(changes[i].Val)\n\t\t\tchanges[i].Val = wrapValue(rval, rval.Type())\n\t\t}\n\t}\n\n\tval := getManagedObject(obj).Addr().Interface().(mo.Reference)\n\n\tmo.ApplyPropertyChange(val, changes)\n\n\tr.applyHandlers(func(o RegisterObject) {\n\t\to.UpdateObject(val, changes)\n\t})\n}", "label": 5}
{"code": "def inclusive_length_of_stay?\n      # lengthOfStay - EH111, EH108\n      less_than_equal_los = attr_val('../cda:low/@nullFlavor') == 'NINF' &&\n                            attr_val('../@highClosed') != 'false'\n\n      greater_than_equal_los = attr_val('../cda:high/@nullFlavor') == 'PINF' &&\n                               attr_val('../@lowClosed') != 'false'\n      # Both less and greater require that the type is PQ\n      (less_than_equal_los || greater_than_equal_los) && attr_val('@xsi:type') == 'PQ'\n    end", "label": 4}
{"code": "func (p *Panel) SetTitle(w Widget) {\n\tif p.title != nil {\n\t\tp.RemoveWidget(p.title)\n\t}\n\tp.InsertWidget(0, w, 0.0)\n\tp.title = w\n}", "label": 5}
{"code": "def self_signed(self, value):\n        \"\"\"\n        A bool - if the certificate should be self-signed.\n        \"\"\"\n\n        self._self_signed = bool(value)\n\n        if self._self_signed:\n            self._issuer = None", "label": 1}
{"code": "public Conditionals addIfMatch(Tag tag) {\n        Preconditions.checkArgument(!modifiedSince.isPresent(), String.format(ERROR_MESSAGE, HeaderConstants.IF_MATCH, HeaderConstants.IF_MODIFIED_SINCE));\n        Preconditions.checkArgument(noneMatch.isEmpty(), String.format(ERROR_MESSAGE, HeaderConstants.IF_MATCH, HeaderConstants.IF_NONE_MATCH));\n        List<Tag> match = new ArrayList<>(this.match);\n\n        if (tag == null) {\n            tag = Tag.ALL;\n        }\n        if (Tag.ALL.equals(tag)) {\n            match.clear();\n        }\n        if (!match.contains(Tag.ALL)) {\n            if (!match.contains(tag)) {\n                match.add(tag);\n            }\n        }\n        else {\n            throw new IllegalArgumentException(\"Tag ALL already in the list\");\n        }\n        return new Conditionals(Collections.unmodifiableList(match), empty(), Optional.empty(), unModifiedSince);\n    }", "label": 0}
{"code": "def activate_scene(self, scene_uuid, duration=1.0):\n        \"\"\"Activate a scene.\n\n        See http://api.developer.lifx.com/docs/activate-scene\n\n        scene_uuid: required String\n            The UUID for the scene you wish to activate\n\n        duration: Double\n            The time in seconds to spend performing the scene transition.\n            default: 1.0\n        \"\"\"\n\n        argument_tuples = [\n            (\"duration\", duration),\n        ]\n\n        return self.client.perform_request(\n            method='put', endpoint='scenes/scene_id:{}/activate',\n            endpoint_args=[scene_uuid], argument_tuples=argument_tuples)", "label": 1}
{"code": "function _gpfHttpSetRequestImplIf (host, httpRequestImpl) {\n    var result = _gpfHttpRequestImpl;\n    if (host === _gpfHost) {\n        _gpfHttpRequestImpl = httpRequestImpl;\n    }\n    return result;\n}", "label": 3}
{"code": "func (l VirtualDeviceList) CreateNVMEController() (types.BaseVirtualDevice, error) {\n\tnvme := &types.VirtualNVMEController{}\n\tnvme.BusNumber = l.newNVMEBusNumber()\n\tnvme.Key = l.NewKey()\n\n\treturn nvme, nil\n}", "label": 5}
{"code": "public function setChildLinks($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Spanner\\V1\\PlanNode\\ChildLink::class);\n        $this->child_links = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def colorize(params)\n      return self if self.class.disable_colorization\n      require_windows_libs\n      scan_for_colors.inject(self.class.new) do |str, match|\n        colors_from_params(match, params)\n        defaults_colors(match)\n        str << \"\\033[#{match[0]};#{match[1]};#{match[2]}m#{match[3]}\\033[0m\"\n      end\n    end", "label": 4}
{"code": "def add(options={})\n      value_objects << Cfvo.new(:type => options[:type] || :min, :val => options[:val] || 0)\n      colors << Color.new(:rgb => options[:color] || \"FF000000\")\n      {:cfvo => value_objects.last, :color => colors.last}\n    end", "label": 4}
{"code": "func isIP4AddrResolvable(fl FieldLevel) bool {\n\n\tif !isIPv4(fl) {\n\t\treturn false\n\t}\n\n\t_, err := net.ResolveIPAddr(\"ip4\", fl.Field().String())\n\n\treturn err == nil\n}", "label": 5}
{"code": "def add_environment(env, version)\n      if self.content_view_environments.where(:environment_id => env.id).empty?\n        label = generate_cp_environment_label(env)\n        ContentViewEnvironment.create!(:name => label,\n                                       :label => label,\n                                       :cp_id => generate_cp_environment_id(env),\n                                       :environment_id => env.id,\n                                       :content_view => self,\n                                       :content_view_version => version\n                                      )\n      end\n    end", "label": 4}
{"code": "func invokeFWMarker(path string, vip net.IP, fwMark uint32, ingressPorts []*PortConfig, eIP *net.IPNet, isDelete bool, lbMode string) error {\n\tvar ingressPortsFile string\n\n\tif len(ingressPorts) != 0 {\n\t\tvar err error\n\t\tingressPortsFile, err = writePortsToFile(ingressPorts)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdefer os.Remove(ingressPortsFile)\n\t}\n\n\taddDelOpt := \"-A\"\n\tif isDelete {\n\t\taddDelOpt = \"-D\"\n\t}\n\n\tcmd := &exec.Cmd{\n\t\tPath:   reexec.Self(),\n\t\tArgs:   append([]string{\"fwmarker\"}, path, vip.String(), fmt.Sprintf(\"%d\", fwMark), addDelOpt, ingressPortsFile, eIP.String(), lbMode),\n\t\tStdout: os.Stdout,\n\t\tStderr: os.Stderr,\n\t}\n\n\tif err := cmd.Run(); err != nil {\n\t\treturn fmt.Errorf(\"reexec failed: %v\", err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function removeKeybindings (bindings, method) {\n  if (!bindings) return;\n  if (typeof bindings === 'string' && !method) console.warn('removeKeybindings requries method as second arg');\n  if (typeof bindings === 'string') return removeMethod(bindings, method);\n  Object.keys(bindings).forEach((key) => removeMethod(key, bindings[key]));\n}", "label": 3}
{"code": "def normalized_password\n      return nil unless self.password\n      return @normalized_password if defined?(@normalized_password)\n      @normalized_password ||= begin\n        if self.normalized_scheme =~ /https?/ && self.password.strip.empty? &&\n            (!self.user || self.user.strip.empty?)\n          nil\n        else\n          Addressable::URI.normalize_component(\n            self.password.strip,\n            Addressable::URI::CharacterClasses::UNRESERVED\n          )\n        end\n      end\n      # All normalized values should be UTF-8\n      if @normalized_password\n        @normalized_password.force_encoding(Encoding::UTF_8)\n      end\n      @normalized_password\n    end", "label": 4}
{"code": "public static snmpalarm[] get(nitro_service service, String trapname[]) throws Exception{\n\t\tif (trapname !=null && trapname.length>0) {\n\t\t\tsnmpalarm response[] = new snmpalarm[trapname.length];\n\t\t\tsnmpalarm obj[] = new snmpalarm[trapname.length];\n\t\t\tfor (int i=0;i<trapname.length;i++) {\n\t\t\t\tobj[i] = new snmpalarm();\n\t\t\t\tobj[i].set_trapname(trapname[i]);\n\t\t\t\tresponse[i] = (snmpalarm) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def handle_orr(tokens, outer_span, options)\n      repeater = tokens[1].get_tag(Repeater)\n      repeater.start = outer_span.begin - 1\n      ordinal = tokens[0].get_tag(Ordinal).type\n      span = nil\n\n      ordinal.times do\n        span = repeater.next(:future)\n\n        if span.begin >= outer_span.end\n          span = nil\n          break\n        end\n      end\n\n      span\n    end", "label": 4}
{"code": "function commitAllChanges(msg) {\n    return vowExec(util.format('git commit -a -m \"%s\" -n', msg))\n        .fail(function (res) {\n            return vow.reject('Commit failed:\\n' + res.stderr);\n        });\n}", "label": 3}
{"code": "def set_value(self, model, value):\n        \"\"\"Set field's value.\n\n        :param DomainModel model:\n        :param object value:\n        \"\"\"\n        if value is None and self.required:\n            raise AttributeError(\"This field is required.\")\n\n        if value is not None:\n            value = self._converter(value)\n\n        setattr(model, self.storage_name, value)", "label": 1}
{"code": "function declarationImpliesInitialisation(variable, scope) {\n  return variable.name === \"arguments\" && scope.type === ScopeType.FUNCTION ||\n    variable.declarations.some(decl =>\n      decl.type === DeclarationType.PARAMETER ||\n      decl.type === DeclarationType.FUNCTION_NAME ||\n      decl.type === DeclarationType.CATCH\n    );\n}", "label": 3}
{"code": "public List<String> getArtifactVersions(final String gavc) throws GrapesCommunicationException {\n        final Client client = getClient();\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.getArtifactVersions(gavc));\n        final ClientResponse response = resource\n                .accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);\n\n        client.destroy();\n        if(ClientResponse.Status.OK.getStatusCode() != response.getStatus()){\n            final String message = FAILED_TO_GET_CORPORATE_FILTERS;\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n\n        return response.getEntity(new GenericType<List<String>>(){});\n\n    }", "label": 0}
{"code": "protected static function extractEvent($job)\n    {\n        return isset($job->data[0]) && is_object($job->data[0])\n                        ? $job->data[0]\n                        : new stdClass;\n    }", "label": 2}
{"code": "public function addFieldResult($alias, $columnName, $fieldName, $declaringClass = null)\n    {\n        // column name (in result set) => field name\n        $this->fieldMappings[$columnName] = $fieldName;\n        // column name => alias of owner\n        $this->columnOwnerMap[$columnName] = $alias;\n        // field name => class name of declaring class\n        $this->declaringClasses[$columnName] = $declaringClass ?: $this->aliasMap[$alias];\n\n        if (! $this->isMixed && $this->scalarMappings) {\n            $this->isMixed = true;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def create_group(user_ids)\n      raise 'Attempted to create group channel on a non-pm channel!' unless pm?\n\n      response = API::Channel.create_group(@bot.token, @id, user_ids.shift)\n      channel = Channel.new(JSON.parse(response), @bot)\n      channel.add_group_users(user_ids)\n    end", "label": 4}
{"code": "def draw_plot(self):\n        \"\"\" Initialises plots of the environment.\n        \"\"\"\n        pylab.ion()\n        fig = pylab.figure(1)\n\n        # State plot.\n#        state_axis = fig.add_subplot(3, 1, 1) # numrows, numcols, fignum\n#        state_axis.title = 'State'\n#        state_axis.xlabel = 'Time (hours)'\n#        state_axis.grid = True\n#        for i in range(self.state_data.shape[0]):\n#            lines = state_axis.plot(self.state_data[i, 0], \"g+-\")\n#            self.state_lines.append(lines[0])\n\n        # Action plot.\n#        action_axis = fig.add_subplot(3, 1, 2)\n#        action_axis.title = 'Action'\n#        action_axis.xlabel = 'Time (hours)'\n#        action_axis.ylabel = 'Price ($/MWh)'\n#        action_axis.grid = True\n#        for i in range(self.action_data.shape[0]):\n#            lines = action_axis.plot(self.action_data[i, 0], \"ro-\")\n#            self.action_lines.append(lines[0])\n\n        # Reward plot.\n        reward_axis = fig.add_subplot(3, 1, 3)\n#        reward_axis.title = 'Reward'\n#        reward_axis.xlabel = 'Time (hours)'\n#        reward_axis.ylabel = 'Earnings ($)'\n#        reward_axis.grid(True)\n        reward_lines = reward_axis.plot(self.reward_data[0, 0], [0], \"mx-\")\n        self.reward_line = reward_lines[0]\n\n        pylab.draw()", "label": 1}
{"code": "func (l *Logger) Error(e error) {\n\tl.Print(l.formatErr(e, \"\"))\n}", "label": 5}
{"code": "function timeAndLog(text) {\n  if (active) {\n    var spaces = space.substring(0, currentIndentation);\n    console.error('TRACER TXT', meaningfulTime(), spaces, text);\n  }\n}", "label": 3}
{"code": "func (s *ClusterConfigurationService) SetAuthPreference(preferences services.AuthPreference) error {\n\tvalue, err := services.GetAuthPreferenceMarshaler().Marshal(preferences)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\titem := backend.Item{\n\t\tKey:   backend.Key(authPrefix, preferencePrefix, generalPrefix),\n\t\tValue: value,\n\t\tID:    preferences.GetResourceID(),\n\t}\n\n\t_, err = s.Put(context.TODO(), item)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def ws_disconnect(message):\n    \"\"\"\n    Channels connection close.\n    Deregister the client\n    \"\"\"\n    language = message.channel_session['knocker']\n    gr = Group('knocker-{0}'.format(language))\n    gr.discard(message.reply_channel)", "label": 1}
{"code": "def extract_from_text(text):\n    \"\"\"\n    Extract ISBNs from a text.\n\n    :param text: Some text.\n    :returns: A list of canonical ISBNs found in the text.\n\n    >>> extract_from_text(\"978-3-16-148410-0 9783161484100 9783161484100aa abcd 0136091814 0136091812 9780136091817 123456789X\")\n    ['9783161484100', '9783161484100', '9783161484100', '0136091814', '123456789X']\n    \"\"\"\n    isbns = [isbnlib.get_canonical_isbn(isbn)\n             for isbn in isbnlib.get_isbnlike(text)]\n    return [i for i in isbns if i is not None]", "label": 1}
{"code": "function getLinked(elem, attr) {\n\t\tvar str = elem.getAttribute(attr);\n\t\tif(!str) {return null;}\n\t\tvar m = str.match(/\\(\\#(.*)\\)/);\n\t\tif(!m || m.length !== 2) {\n\t\t\treturn null;\n\t\t}\n\t\treturn S.getElem(m[1]);\n\t}", "label": 3}
{"code": "def creator(entry, config):\n        \"\"\"Creator function for creating an instance of an Ansible script.\"\"\"\n        ansible_playbook = \"ansible.playbook.dry.run.see.comment\"\n        ansible_inventory = \"ansible.inventory.dry.run.see.comment\"\n\n        ansible_playbook_content = render(config.script, model=config.model, env=config.env,\n                                          variables=config.variables, item=config.item)\n        ansible_inventory_content = render(entry['inventory'], model=config.model, env=config.env,\n                                           variables=config.variables, item=config.item)\n\n        if not config.dry_run:\n            ansible_playbook = write_temporary_file(ansible_playbook_content, 'ansible-play-', '.yaml')\n            ansible_playbook_content = ''\n            ansible_inventory = write_temporary_file(ansible_inventory_content, prefix='ansible-inventory-')\n            ansible_inventory_content = ''\n\n        # rendering the Bash script for running the Ansible playbook\n        template_file = os.path.join(os.path.dirname(__file__), 'templates/ansible.sh.j2')\n        with open(template_file) as handle:\n            template = handle.read()\n            config.script = render(template, debug=config.debug,\n                                   ansible_playbook_content=ansible_playbook_content,\n                                   ansible_playbook=ansible_playbook,\n                                   ansible_inventory_content=ansible_inventory_content,\n                                   ansible_inventory=ansible_inventory,\n                                   limit=entry['limit'])\n\n        return Ansible(config)", "label": 1}
{"code": "def parseGTF(inGTF):\n    \"\"\"\n    Reads an extracts all attributes in the attributes section of a GTF and constructs a new dataframe wiht one collumn per attribute instead of the attributes column\n\n    :param inGTF: GTF dataframe to be parsed\n    :returns: a dataframe of the orignal input GTF with attributes parsed.\n\n    \"\"\"\n\n    desc=attributesGTF(inGTF)\n    ref=inGTF.copy()\n    ref.reset_index(inplace=True, drop=True)\n    df=ref.drop(['attribute'],axis=1).copy()\n    for d in desc:\n        field=retrieve_GTF_field(d,ref)\n        df=pd.concat([df,field],axis=1)\n    return df", "label": 1}
{"code": "func (e ErrPortAlreadyAllocated) Error() string {\n\treturn fmt.Sprintf(\"Bind for %s:%d failed: port is already allocated\", e.ip, e.port)\n}", "label": 5}
{"code": "function(alias) {\n      var config = this.getMapping(alias);\n      if (config.computed && config.mapping.pull) {\n        this.__invokeComputedPull.call({formModel: this, alias: alias});\n      } else if (config.computed) {\n        var modelAliases = this.__getModelAliases(alias);\n        _.each(modelAliases, function(modelAlias) {\n          var model = this.getTrackedModel(modelAlias);\n          if (model) {\n            this.__copyFields(config.mapping[modelAlias], this, model);\n          }\n        }, this);\n      } else {\n        var model = this.getTrackedModel(alias);\n        if (model) {\n          this.__copyFields(config.mapping, this, model);\n        }\n      }\n    }", "label": 3}
{"code": "def visit_root(node)\n      @enabled = matcher.match(File.basename(node.file)) ? true : false\n    end", "label": 4}
{"code": "func (h *Heartbeat) fetchAndAnnounce() error {\n\tif err := h.fetch(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := h.announce(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static base_responses add(nitro_service client, dnssuffix resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdnssuffix addresources[] = new dnssuffix[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new dnssuffix();\n\t\t\t\taddresources[i].Dnssuffix = resources[i].Dnssuffix;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def pipeline(steps, initial=None):\n    \"\"\"\n    Chain results from a list of functions. Inverted reduce.\n\n    :param (function) steps: List of function callbacks\n    :param initial: Starting value for pipeline.\n    \"\"\"\n\n    def apply(result, step):\n        return step(result)\n\n    return reduce(apply, steps, initial)", "label": 1}
{"code": "def reads_generator_to_protein_sequences_generator(\n        variant_and_overlapping_reads_generator,\n        transcript_id_whitelist=None,\n        protein_sequence_length=PROTEIN_SEQUENCE_LENGTH,\n        min_alt_rna_reads=MIN_ALT_RNA_READS,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,\n        min_transcript_prefix_length=MIN_TRANSCRIPT_PREFIX_LENGTH,\n        max_transcript_mismatches=MAX_REFERENCE_TRANSCRIPT_MISMATCHES,\n        include_mismatches_after_variant=INCLUDE_MISMATCHES_AFTER_VARIANT,\n        max_protein_sequences_per_variant=MAX_PROTEIN_SEQUENCES_PER_VARIANT,\n        variant_sequence_assembly=VARIANT_SEQUENCE_ASSEMBLY):\n    \"\"\"\"\n    Translates each coding variant in a collection to one or more\n    Translation objects, which are then aggregated into equivalent\n    ProteinSequence objects.\n\n    Parameters\n    ----------\n    variant_and_overlapping_reads_generator : generator\n        Yields sequence of varcode.Variant objects paired with sequences\n        of AlleleRead objects that support that variant.\n\n    transcript_id_whitelist : set, optional\n        If given, expected to be a set of transcript IDs which we should use\n        for determining the reading frame around a variant. If omitted, then\n        try to use all overlapping reference transcripts.\n\n    protein_sequence_length : int\n        Try to translate protein sequences of this length, though sometimes\n        we'll have to return something shorter (depending on the RNAseq data,\n        and presence of stop codons).\n\n    min_alt_rna_reads : int\n        Drop variant sequences at loci with fewer than this number of reads\n        supporting the alt allele.\n\n    min_variant_sequence_coverage : int\n        Trim variant sequences to positions supported by at least this number\n        of RNA reads.\n\n    min_transcript_prefix_length : int\n        Minimum number of bases we need to try matching between the reference\n        context and variant sequence.\n\n    max_transcript_mismatches : int\n        Don't try to determine the reading frame for a transcript if more\n        than this number of bases differ.\n\n    include_mismatches_after_variant : bool\n        Include mismatches after the variant locus in the count compared\n        against max_transcript_mismatches.\n\n    max_protein_sequences_per_variant : int\n        Number of protein sequences to return for each ProteinSequence\n\n    variant_cdna_sequence_assembly : bool\n        If True, then assemble variant cDNA sequences based on overlap of\n        RNA reads. If False, then variant cDNA sequences must be fully spanned\n        and contained within RNA reads.\n\n    Yields pairs of a Variant and a list of ProteinSequence objects\n    \"\"\"\n\n    for (variant, overlapping_reads) in variant_and_overlapping_reads_generator:\n        overlapping_transcript_ids = [\n            t.id\n            for t in variant.transcripts\n            if t.is_protein_coding\n        ]\n        _, ref, alt = trim_variant(variant)\n        overlapping_reads = list(overlapping_reads)\n        reads_grouped_by_allele = group_reads_by_allele(overlapping_reads)\n\n        ref_reads = reads_grouped_by_allele.get(ref, [])\n        alt_reads = reads_grouped_by_allele.get(alt, [])\n\n        translations = translate_variant_reads(\n            variant=variant,\n            variant_reads=alt_reads,\n            transcript_id_whitelist=transcript_id_whitelist,\n            protein_sequence_length=protein_sequence_length,\n            min_alt_rna_reads=min_alt_rna_reads,\n            min_variant_sequence_coverage=min_variant_sequence_coverage,\n            min_transcript_prefix_length=min_transcript_prefix_length,\n            max_transcript_mismatches=max_transcript_mismatches,\n            include_mismatches_after_variant=include_mismatches_after_variant,\n            variant_sequence_assembly=variant_sequence_assembly)\n\n        protein_sequences = []\n        for (key, equivalent_translations) in groupby(\n                translations, key_fn=Translation.as_translation_key).items():\n\n            # get the variant read names, transcript IDs and gene names for\n            # protein sequence we're about to construct\n            alt_reads_supporting_protein_sequence, group_transcript_ids, group_gene_names = \\\n                ProteinSequence._summarize_translations(equivalent_translations)\n\n            logger.info(\n                \"%s: %s alt reads supporting protein sequence (gene names = %s)\",\n                key,\n                len(alt_reads_supporting_protein_sequence),\n                group_gene_names)\n\n            protein_sequence = ProteinSequence.from_translation_key(\n                translation_key=key,\n                translations=equivalent_translations,\n                overlapping_reads=overlapping_reads,\n                alt_reads=alt_reads,\n                ref_reads=ref_reads,\n                alt_reads_supporting_protein_sequence=alt_reads_supporting_protein_sequence,\n                transcripts_supporting_protein_sequence=group_transcript_ids,\n                transcripts_overlapping_variant=overlapping_transcript_ids,\n                gene=list(group_gene_names))\n            logger.info(\"%s: protein sequence = %s\" % (key, protein_sequence.amino_acids))\n            protein_sequences.append(protein_sequence)\n\n        # sort protein sequences before returning the top results\n        protein_sequences = sort_protein_sequences(protein_sequences)\n\n        yield variant, protein_sequences[:max_protein_sequences_per_variant]", "label": 1}
{"code": "def updatePools(self,\n                    pool1,\n                    username1,\n                    password1,\n                    pool2=None,\n                    username2=None,\n                    password2=None,\n                    pool3=None,\n                    username3=None,\n                    password3=None):\n        \"\"\"Change the pools of the miner. This call will restart cgminer.\"\"\"\n        return self.__post('/api/updatePools',\n                           data={\n                               'Pool1': pool1,\n                               'UserName1': username1,\n                               'Password1': password1,\n                               'Pool2': pool2,\n                               'UserName2': username2,\n                               'Password2': password2,\n                               'Pool3': pool3,\n                               'UserName3': username3,\n                               'Password3': password3,\n                           })", "label": 1}
{"code": "function(model, stopListening) {\n      if (this.model && stopListening) {\n        this.stopListening(this.model);\n      }\n      this.model = model;\n      this.listenTo(this.model, 'validated:valid', this.valid);\n      this.listenTo(this.model, 'validated:invalid', this.invalid);\n    }", "label": 3}
{"code": "def wait_for_start(self):\n        \"\"\"\n        Wait for the RabbitMQ process to be come up.\n        \"\"\"\n        er = self.exec_rabbitmqctl(\n            'wait', ['--pid', '1', '--timeout', str(int(self.wait_timeout))])\n        output_lines(er, error_exc=TimeoutError)", "label": 1}
{"code": "public static base_response update(nitro_service client, rsskeytype resource) throws Exception {\n\t\trsskeytype updateresource = new rsskeytype();\n\t\tupdateresource.rsstype = resource.rsstype;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def start_tls(req, options)\n      return unless req.uri.https? && !failed_proxy_connect?\n\n      ssl_context = options.ssl_context\n\n      unless ssl_context\n        ssl_context = OpenSSL::SSL::SSLContext.new\n        ssl_context.set_params(options.ssl || {})\n      end\n\n      @socket.start_tls(req.uri.host, options.ssl_socket_class, ssl_context)\n    end", "label": 4}
{"code": "function useVpcNetwork(mCb) {\n\t\t\t//assign network name to deployment entry\n\t\t\toneDeployment.options.network = name;\n\t\t\t\n\t\t\tfunction patchFirewall() {\n\t\t\t\tlet firewallRules = getFirewallRules(oneDeployment.options.network);\n\t\t\t\t\n\t\t\t\tlet request = getConnector(options.infra.api);\n\t\t\t\trequest.filter = `network eq .*${oneDeployment.options.network}`;\n\t\t\t\trequest.project = options.infra.api.project;\n\t\t\t\t\n\t\t\t\t//list firewalls\n\t\t\t\t//Ref: https://cloud.google.com/compute/docs/reference/rest/v1/firewalls/list\n\t\t\t\tv1Compute().firewalls.list(request, function (error, firewalls) {\n\t\t\t\t\tif (error) return mCb(error);\n\t\t\t\t\t\n\t\t\t\t\tif (!firewalls.items) firewalls.items = [];\n\t\t\t\t\t\n\t\t\t\t\tasync.eachSeries(firewallRules, (oneRule, vCb) => {\n\t\t\t\t\t\tlet foundFirewall = firewalls.items.find((oneEntry) => {\n\t\t\t\t\t\t\treturn oneEntry.name === oneRule.name\n\t\t\t\t\t\t});\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (foundFirewall) {\n\t\t\t\t\t\t\toptions.soajs.log.debug(\"Firewall rule:\", oneRule.name, \"already exists, skipping\");\n\t\t\t\t\t\t\treturn vCb();\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\toptions.soajs.log.debug(\"Creating firewall rule:\", oneRule.name);\n\t\t\t\t\t\t\trequest.resource = oneRule;\n\t\t\t\t\t\t\treturn v1Compute().firewalls.insert(request, vCb);\n\t\t\t\t\t\t}\n\t\t\t\t\t}, mCb);\n\t\t\t\t});\n\t\t\t}\n\t\t\t\n\t\t\tpatchFirewall();\n\t\t}", "label": 3}
{"code": "def accept_record(self, record):\n        \"\"\"Accept a record for inclusion in the community.\n\n        :param record: Record object.\n        \"\"\"\n        with db.session.begin_nested():\n            req = InclusionRequest.get(self.id, record.id)\n            if req is None:\n                raise InclusionRequestMissingError(community=self,\n                                                   record=record)\n            req.delete()\n            self.add_record(record)\n            self.last_record_accepted = datetime.utcnow()", "label": 1}
{"code": "public String putDocument(Document document) {\n\t\tString key = UUID.randomUUID().toString();\n\t\tdocumentMap.put(key, document);\n\t\treturn key;\n\t}", "label": 0}
{"code": "public String createTorqueSchema(Properties attributes) throws XDocletException\r\n    {\r\n        String dbName = (String)getDocletContext().getConfigParam(CONFIG_PARAM_DATABASENAME);\r\n\r\n        _torqueModel = new TorqueModelDef(dbName, _model);\r\n        return \"\";\r\n    }", "label": 0}
{"code": "public static server_service_binding[] get(nitro_service service, String name) throws Exception{\n\t\tserver_service_binding obj = new server_service_binding();\n\t\tobj.set_name(name);\n\t\tserver_service_binding response[] = (server_service_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function check_update( $_, $assoc_args ) {\n\t\t$updates = $this->get_updates( $assoc_args );\n\n\t\tif ( $updates ) {\n\t\t\t$formatter = new \\WP_CLI\\Formatter(\n\t\t\t\t$assoc_args,\n\t\t\t\tarray( 'version', 'update_type', 'package_url' )\n\t\t\t);\n\t\t\t$formatter->display_items( $updates );\n\t\t} elseif ( empty( $assoc_args['format'] ) || 'table' === $assoc_args['format'] ) {\n\t\t\t$update_type = $this->get_update_type_str( $assoc_args );\n\t\t\tWP_CLI::success( \"WP-CLI is at the latest{$update_type}version.\" );\n\t\t}\n\t}", "label": 2}
{"code": "def handle_error(ex, file_name)\n      if ex.message == \"NOSCRIPT No matching script. Please use EVAL.\"\n        SCRIPT_SHAS.delete(file_name)\n        return yield if block_given?\n      end\n\n      raise ScriptError, file_name: file_name, source_exception: ex\n    end", "label": 4}
{"code": "public Set<String> getTags() {\r\n    Set<String> tags = new HashSet<String>(classIndex.objectsList());\r\n    tags.remove(flags.backgroundSymbol);\r\n    return tags;\r\n  }", "label": 0}
{"code": "function (destCtx, debug) {\n                if (!this.visible) {\n                    return;\n                }\n\n                // auto goto next frame\n                if (this.currentAnimName.length) {\n                    this.advanceFrame(this.currentAnimName);\n                }\n\n                var w = this.getCurrentWidth(),\n                    scaledW = w * this.scale,\n                    h = this.getCurrentHeight(),\n                    scaledH = h * this.scale,\n                    subScaledW = (scaledW / 2) | 0,\n                    subScaledH = (scaledH / 2) | 0,\n                    x = this.getCurrentOffsetX(),\n                    y = this.getCurrentOffsetY(),\n                    drawX = this.x + this.getCurrentShiftX(),\n                    drawY = this.y + this.getCurrentShiftY(),\n                    mapOffsetX = this.currentMap && this.currentMap.viewportX || 0,\n\n                    mapOffsetY = this.currentMap && this.currentMap.viewportY || 0;\n\n                // TODO: fix map position when rotate is used\n                if ($.isEmptyObject(this.fxQueue)) {\n                    if (this.type === 'enemy1' && window.todo)\n                        var date = new Date().getTime();\n                    destCtx.drawImage(this.image, x, y, w, h, drawX + mapOffsetX, drawY + mapOffsetY, scaledW, scaledH);\n                    if (this.type === 'enemy1' && window.todo) {\n                        var date2 = new Date().getTime();\n                        console.log('drawSprite call duration:', date2 - date);\n                    }\n                    if (this.isDebug === true || debug === true) {\n                        this.showHitBox(destCtx);\n                    }\n                } else {\n                    this.executeFx(destCtx);\n                    // translate to keep the object as its position\n                    destCtx.save();\n                    destCtx.translate(drawX + mapOffsetX + subScaledW, drawY + mapOffsetY + subScaledH);\n                    destCtx.rotate(this.angle);\n                    destCtx.drawImage(this.image, x, y, w, h, -subScaledW, -subScaledH, scaledW, scaledH);\n                    if (this.isDebug === true || debug === true) {\n                        this.showHitBox(destCtx);\n                    }\n                    destCtx.restore();\n                }\n            }", "label": 3}
{"code": "def set_role(name, options = {})\n      headers = extract_headers!(options)\n      client.post(\"/v1/auth/approle/role/#{encode_path(name)}\", JSON.fast_generate(options), headers)\n      return true\n    end", "label": 4}
{"code": "def update_target(target)\n      data = @groups.data_for(target.name)\n      data ||= {}\n\n      unless data['config']\n        @logger.debug(\"Did not find config for #{target.name} in inventory\")\n        data['config'] = {}\n      end\n\n      data = self.class.localhost_defaults(data) if target.name == 'localhost'\n      # These should only get set from the inventory if they have not yet\n      # been instantiated\n      set_vars_from_hash(target.name, data['vars']) unless @target_vars[target.name]\n      set_facts(target.name, data['facts']) unless @target_facts[target.name]\n      data['features']&.each { |feature| set_feature(target, feature) } unless @target_features[target.name]\n\n      # Use Config object to ensure config section is treated consistently with config file\n      conf = @config.deep_clone\n      conf.update_from_inventory(data['config'])\n      conf.validate\n\n      target.update_conf(conf.transport_conf)\n\n      unless target.transport.nil? || Bolt::TRANSPORTS.include?(target.transport.to_sym)\n        raise Bolt::UnknownTransportError.new(target.transport, target.uri)\n      end\n\n      target\n    end", "label": 4}
{"code": "def getResourceFileList(self, pid):\n        \"\"\" Get a listing of files within a resource.\n\n        :param pid: The HydroShare ID of the resource whose resource files are to be listed.\n\n        :raises: HydroShareArgumentException if any parameters are invalid.\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n\n        :return: A generator that can be used to fetch dict objects, each dict representing\n            the JSON object representation of the resource returned by the REST end point.  For example:\n\n        {\n            \"count\": 95,\n            \"next\": \"https://www.hydroshare.org/hsapi/resource/32a08bc23a86e471282a832143491b49/file_list/?page=2\",\n            \"previous\": null,\n            \"results\": [\n                {\n                    \"url\": \"http://www.hydroshare.org/django_irods/download/32a08bc23a86e471282a832143491b49/data/contents/foo/bar.txt\",\n                    \"size\": 23550,\n                    \"content_type\": \"text/plain\"\n                },\n                {\n                    \"url\": \"http://www.hydroshare.org/django_irods/download/32a08bc23a86e471282a832143491b49/data/contents/dem.tif\",\n                    \"size\": 107545,\n                    \"content_type\": \"image/tiff\"\n                },\n                {\n                    \"url\": \"http://www.hydroshare.org/django_irods/download/32a08bc23a86e471282a832143491b49/data/contents/data.csv\",\n                    \"size\": 148,\n                    \"content_type\": \"text/csv\"\n                },\n                {\n                    \"url\": \"http://www.hydroshare.org/django_irods/download/32a08bc23a86e471282a832143491b49/data/contents/data.sqlite\",\n                    \"size\": 267118,\n                    \"content_type\": \"application/x-sqlite3\"\n                },\n                {\n                    \"url\": \"http://www.hydroshare.org/django_irods/download/32a08bc23a86e471282a832143491b49/data/contents/viz.png\",\n                    \"size\": 128,\n                    \"content_type\": \"image/png\"\n                }\n            ]\n        }\n        \"\"\"\n        url = \"{url_base}/resource/{pid}/files/\".format(url_base=self.url_base,\n                                                            pid=pid)\n        return resultsListGenerator(self, url)", "label": 1}
{"code": "public static wisite_binding get(nitro_service service, String sitepath) throws Exception{\n\t\twisite_binding obj = new wisite_binding();\n\t\tobj.set_sitepath(sitepath);\n\t\twisite_binding response = (wisite_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function read(Session $session, $table, KeySet $keySet, array $columns, array $options = [])\n    {\n        $options += [\n            'index' => null,\n            'limit' => null,\n            'offset' => null,\n            'transactionContext' => null\n        ];\n\n        $context = $this->pluck('transactionContext', $options);\n\n        $call = function ($resumeToken = null) use ($table, $session, $columns, $keySet, $options) {\n            if ($resumeToken) {\n                $options['resumeToken'] = $resumeToken;\n            }\n\n            return $this->connection->streamingRead([\n                'table' => $table,\n                'session' => $session->name(),\n                'columns' => $columns,\n                'keySet' => $this->flattenKeySet($keySet),\n                'database' => $session->info()['database']\n            ] + $options);\n        };\n\n        return new Result($this, $session, $call, $context, $this->mapper);\n    }", "label": 2}
{"code": "public function getEloquentRepository()\n    {\n        $repositoryGenerator = new RepositoryEloquentGenerator([\n            'name' => $this->name,\n        ]);\n\n        $repository = $repositoryGenerator->getRootNamespace() . '\\\\' . $repositoryGenerator->getName();\n\n        return str_replace([\n            \"\\\\\",\n            '/'\n        ], '\\\\', $repository) . 'RepositoryEloquent';\n    }", "label": 2}
{"code": "private function determineBindingType(array $options)\n    {\n        if (isset($options['bindings']) && !$this->isAssoc($options['bindings'])) {\n            return self::BINDING_POSITIONAL;\n        }\n\n        return self::BINDING_NAMED;\n    }", "label": 2}
{"code": "def log_common_options(opts)\n      arr_opts = []\n\n      arr_opts << \"-#{opts[:count]}\" if opts[:count]\n      arr_opts << \"--no-color\"\n      arr_opts << \"--since=#{opts[:since]}\" if opts[:since].is_a? String\n      arr_opts << \"--until=#{opts[:until]}\" if opts[:until].is_a? String\n      arr_opts << \"--grep=#{opts[:grep]}\" if opts[:grep].is_a? String\n      arr_opts << \"--author=#{opts[:author]}\" if opts[:author].is_a? String\n      arr_opts << \"#{opts[:between][0].to_s}..#{opts[:between][1].to_s}\" if (opts[:between] && opts[:between].size == 2)\n\n      arr_opts\n    end", "label": 4}
{"code": "function getConfig(fpath, defaults) {\n  var path = require('path');\n  var dpath = path.dirname(path.resolve(fpath));\n\n  function parentpath(fromdir, pattern) {\n    var pp = require('parentpath'),\n        cwd = process.cwd();\n    try {\n      process.chdir(fromdir);\n      return pp.sync(pattern);\n    } catch (e) {\n      return null;\n    } finally {\n      process.chdir(cwd);\n    }\n  }\n\n  function fromNpm() {\n    var config;\n    var dir = parentpath(dpath, 'package.json');\n    if (dir) {\n      try {\n        config = require(dir + '/package.json')[MJS_NPM];\n        config.__origin__ = dir + '/package.json';\n      } catch (e) {\n      }\n    }\n    return config;\n  }\n\n  function fromResourceFile() {\n    var candidates = [\n      parentpath(path, MJS_RC),\n      process.env.HOME, process.env.USERPROFILE, process.env.HOMEPATH, process.env.HOMEDRIVE + process.env.HOMEPATH\n    ];\n\n    var config;\n    for (var i = 0; i < candidates.length; i++) {\n      var candidate = candidates[i] + '/' + MJS_RC;\n      if (fs.existsSync(candidate)) {\n        try {\n          config = JSON.parse(fs.readFileSync(candidate));\n          config.__origin__ = candidate;\n          break;\n        } catch (e) {\n          showHelpAndExit('Unable to read config from \"' + candidate + '\": ' + e.message, 1);\n        }\n      }\n    }\n    return config;\n  }\n\n  var config = fromNpm() || fromResourceFile() || {};\n  // Make sure we apply defaults to missing values\n  Object.keys(defaults).filter(function (k) {\n    return config[k] == null\n  }).forEach(function (k) {\n    config[k] = defaults[k];\n  });\n  return config;\n}", "label": 3}
{"code": "public function requestObject($encode = true)\n    {\n        return array_filter([\n            'image' => $this->imageObject($encode),\n            'features' => $this->features,\n            'imageContext' => $this->options['imageContext']\n        ]);\n    }", "label": 2}
{"code": "public function setMetricDescriptors($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Api\\MetricDescriptor::class);\n        $this->metric_descriptors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *AuthServer) AuthenticateWebUser(req AuthenticateUserRequest) (services.WebSession, error) {\n\tif req.Session != nil {\n\t\tsession, err := s.GetWebSession(req.Username, req.Session.ID)\n\t\tif err != nil {\n\t\t\treturn nil, trace.AccessDenied(\"session is invalid or has expired\")\n\t\t}\n\t\treturn session, nil\n\t}\n\tif err := s.AuthenticateUser(req); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tsess, err := s.NewWebSession(req.Username)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif err := s.UpsertWebSession(req.Username, sess); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tsess, err = services.GetWebSessionMarshaler().GenerateWebSession(sess)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn sess, nil\n}", "label": 5}
{"code": "def delete(self, id, seq, line): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Delete a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param line: Line number in TestResult's logfile as an int.\n        \"\"\"\n        return self.service.delete_id(self._base(id, seq), line)", "label": 1}
{"code": "def driver_attributes\n      # rubocop:disable Layout/AlignHash\n      {\n        caps:                @core.caps,\n        automation_name:     @core.automation_name,\n        custom_url:          @core.custom_url,\n        export_session:      @core.export_session,\n        export_session_path: @core.export_session_path,\n        default_wait:        @core.default_wait,\n        sauce_username:      @sauce.username,\n        sauce_access_key:    @sauce.access_key,\n        sauce_endpoint:      @sauce.endpoint,\n        port:                @core.port,\n        device:              @core.device,\n        debug:               @appium_debug,\n        listener:            @listener,\n        wait_timeout:        @core.wait_timeout,\n        wait_interval:       @core.wait_interval\n      }\n      # rubocop:enable Layout/AlignHash\n    end", "label": 4}
{"code": "def _set_original_fields(instance):\n    \"\"\"\n    Save fields value, only for non-m2m fields.\n    \"\"\"\n    original_fields = {}\n\n    def _set_original_field(instance, field):\n        if instance.pk is None:\n            original_fields[field] = None\n        else:\n            if isinstance(instance._meta.get_field(field), ForeignKey):\n                # Only get the PK, we don't want to get the object\n                # (which would make an additional request)\n                original_fields[field] = getattr(instance,\n                                                 '{0}_id'.format(field))\n            else:\n                original_fields[field] = getattr(instance, field)\n\n    for field in getattr(instance, '_tracked_fields', []):\n        _set_original_field(instance, field)\n    for field in getattr(instance, '_tracked_related_fields', {}).keys():\n        _set_original_field(instance, field)\n\n    instance._original_fields = original_fields\n    # Include pk to detect the creation of an object\n    instance._original_fields['pk'] = instance.pk", "label": 1}
{"code": "def get_dict_from_response(response):\n    \"\"\"Check for errors in the response and return the resulting JSON.\"\"\"\n    if getattr(response, '_resp') and response._resp.code > 400:\n        raise OAuthResponseError(\n                'Application mis-configuration in Globus', None, response\n            )\n\n    return response.data", "label": 1}
{"code": "protected function wait_frame($timeout = 0)\n    {\n        if (is_null($this->input))\n        {\n            $this->setIsConnected(false);\n            throw new AMQPConnectionClosedException('Broken pipe or closed connection');\n        }\n\n        $currentTimeout = $this->input->getTimeout();\n        $this->input->setTimeout($timeout);\n\n        try {\n            // frame_type + channel_id + size\n            $this->wait_frame_reader->reuse(\n                $this->input->read(AMQPReader::OCTET + AMQPReader::SHORT + AMQPReader::LONG)\n            );\n\n            $frame_type = $this->wait_frame_reader->read_octet();\n            $class = self::$PROTOCOL_CONSTANTS_CLASS;\n            if (!array_key_exists($frame_type, $class::$FRAME_TYPES)) {\n                throw new AMQPInvalidFrameException('Invalid frame type ' . $frame_type);\n            }\n            $channel = $this->wait_frame_reader->read_short();\n            $size = $this->wait_frame_reader->read_long();\n\n            // payload + ch\n            $this->wait_frame_reader->reuse($this->input->read(AMQPReader::OCTET + (int) $size));\n\n            $payload = $this->wait_frame_reader->read($size);\n            $ch = $this->wait_frame_reader->read_octet();\n\n        } catch (AMQPTimeoutException $e) {\n            $this->input->setTimeout($currentTimeout);\n            throw $e;\n        } catch (AMQPNoDataException $e) {\n            if ($this->input) {\n                $this->input->setTimeout($currentTimeout);\n            }\n            throw $e;\n        } catch (AMQPConnectionClosedException $exception) {\n            $this->do_close();\n            throw $exception;\n        }\n\n        $this->input->setTimeout($currentTimeout);\n\n        if ($ch != 0xCE) {\n            throw new AMQPInvalidFrameException(sprintf(\n                'Framing error, unexpected byte: %x',\n                $ch\n            ));\n        }\n\n        return array($frame_type, $channel, $payload);\n    }", "label": 2}
{"code": "def parse_country(phone, country)\n      data = Phonelib.phone_data[country]\n      return nil unless data\n\n      # if country was provided and it's a valid country, trying to\n      # create e164 representation of phone number,\n      # kind of normalization for parsing\n      e164 = convert_to_e164 with_replaced_national_prefix(phone, data), data\n      # if phone starts with international prefix of provided\n      # country try to reanalyze without international prefix for\n      # all countries\n      return analyze(e164[1..-1], nil) if Core::PLUS_SIGN == e164[0]\n      # trying to parse number for provided country\n      parse_single_country e164, data\n    end", "label": 4}
{"code": "def genargs() -> ArgumentParser:\n    \"\"\"\n    Create a command line parser\n\n    :return: parser\n    \"\"\"\n    parser = ArgumentParser()\n    parser.add_argument(\"spec\", help=\"JSG specification - can be file name, URI or string\")\n    parser.add_argument(\"-o\", \"--outfile\", help=\"Output python file - if omitted, python is not saved\")\n    parser.add_argument(\"-p\", \"--print\", help=\"Print python file to stdout\")\n    parser.add_argument(\"-id\", \"--inputdir\", help=\"Input directory with JSON files\")\n    parser.add_argument(\"-i\", \"--json\", help=\"URL, file name or json text\", nargs='*')\n    return parser", "label": 1}
{"code": "func (c *SessionContext) GetAgent() (agent.Agent, *ssh.Certificate, error) {\n\tpub, _, _, _, err := ssh.ParseAuthorizedKey(c.sess.GetPub())\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\tcert, ok := pub.(*ssh.Certificate)\n\tif !ok {\n\t\treturn nil, nil, trace.BadParameter(\"expected certificate, got %T\", pub)\n\t}\n\tif len(cert.ValidPrincipals) == 0 {\n\t\treturn nil, nil, trace.BadParameter(\"expected at least valid principal in certificate\")\n\t}\n\tprivateKey, err := ssh.ParseRawPrivateKey(c.sess.GetPriv())\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err, \"failed to parse SSH private key\")\n\t}\n\n\tkeyring := agent.NewKeyring()\n\terr = keyring.Add(agent.AddedKey{\n\t\tPrivateKey:  privateKey,\n\t\tCertificate: cert,\n\t})\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\treturn keyring, cert, nil\n}", "label": 5}
{"code": "public function sendBroadcastVideo($targets, $path, $storeURLmedia = false, $fsize = 0, $fhash = '', $caption = '')\n    {\n        if (!is_array($targets)) {\n            $targets = [$targets];\n        }\n        // Return message ID. Make pull request for this.\n        return $this->sendMessageVideo($targets, $path, $storeURLmedia, $fsize, $fhash, $caption);\n    }", "label": 2}
{"code": "function Demux(refs, limit) {\n\n  if (!(this instanceof Fireproof.Demux)) {\n    return new Fireproof.Demux(refs);\n  } else if (arguments.length > 1 && !Array.isArray(refs)) {\n    refs = Array.prototype.slice.call(arguments, 0);\n  }\n\n  this._limit = (limit !== undefined ? limit : true);\n  this._refs = refs;\n  this._positions = refs.reduce(function(positions, ref) {\n\n    positions[ref.ref().toString()] = {\n      name: undefined,\n      priority: undefined\n    };\n\n    return positions;\n\n  }, {});\n\n  // we always want there to be a \"previous\" promise to hang operations from\n  this._previousPromise = Fireproof.Promise.resolve([]);\n\n  this._buffer = [];\n\n}", "label": 3}
{"code": "def starring?(*args)\n      arguments(args, required: [:user, :repo])\n\n      get_request(\"/user/starred/#{arguments.user}/#{arguments.repo}\", arguments.params)\n      true\n    rescue Github::Error::NotFound\n      false\n    end", "label": 4}
{"code": "public function mkdir($path, $mode, $options)\n    {\n        $path = $this->makeDirectory($path);\n        $client = $this->openPath($path);\n        $predefinedAcl = $this->determineAclFromMode($mode);\n\n        try {\n            if ($options & STREAM_MKDIR_RECURSIVE || $this->file == '') {\n                if (!$this->bucket->exists()) {\n                    $client->createBucket($this->bucket->name(), [\n                        'predefinedAcl' => $predefinedAcl,\n                        'predefinedDefaultObjectAcl' => $predefinedAcl\n                    ]);\n                }\n            }\n\n            // If the file name is empty, we were trying to create a bucket. In this case,\n            // don't create the placeholder file.\n            if ($this->file != '') {\n                // Fake a directory by creating an empty placeholder file whose name ends in '/'\n                $this->bucket->upload('', [\n                    'name' => $this->file,\n                    'predefinedAcl' => $predefinedAcl\n                ]);\n            }\n        } catch (ServiceException $e) {\n            return false;\n        }\n        return true;\n    }", "label": 2}
{"code": "func PgInheritByInhrelidInhseqno(db XODB, inhrelid pgtypes.Oid, inhseqno int) (*PgInherit, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, inhrelid, inhparent, inhseqno ` +\n\t\t`FROM pg_catalog.pg_inherits ` +\n\t\t`WHERE inhrelid = $1 AND inhseqno = $2`\n\n\t// run query\n\tXOLog(sqlstr, inhrelid, inhseqno)\n\tpi := PgInherit{}\n\n\terr = db.QueryRow(sqlstr, inhrelid, inhseqno).Scan(&pi.Tableoid, &pi.Cmax, &pi.Xmax, &pi.Cmin, &pi.Xmin, &pi.Ctid, &pi.Inhrelid, &pi.Inhparent, &pi.Inhseqno)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pi, nil\n}", "label": 5}
{"code": "public function sendExtendAccount()\n    {\n        $msgId = $this->createIqId();\n        $extendingNode = new ProtocolNode('extend', null, null, null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'urn:xmpp:whatsapp:account',\n                'type'  => 'set',\n                'to'    => Constants::WHATSAPP_SERVER,\n            ], [$extendingNode], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "public function prependValidate(callable $middleware, $name = null)\n    {\n        $this->add(self::VALIDATE, $name, $middleware, true);\n    }", "label": 2}
{"code": "def remove(*args)\n      arguments(args, required: [:user, :repo, :number])\n      params = arguments.params\n      user   = arguments.user\n      repo   = arguments.repo\n      number = arguments.number\n\n      if (label_name = params.delete('label_name'))\n        delete_request(\"/repos/#{user}/#{repo}/issues/#{number}/labels/#{label_name}\", params)\n      else\n        delete_request(\"/repos/#{user}/#{repo}/issues/#{number}/labels\", params)\n      end\n    end", "label": 4}
{"code": "public base_response enable_modes(String[] modes) throws Exception\n\t{\n\t\tbase_response result = null;\n\t\tnsmode resource = new nsmode();\n\t\tresource.set_mode(modes);\n\t\toptions option = new options();\n\t\toption.set_action(\"enable\");\n\t\tresult = resource.perform_operation(this, option);\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static nsacl6[] get(nitro_service service, String acl6name[]) throws Exception{\n\t\tif (acl6name !=null && acl6name.length>0) {\n\t\t\tnsacl6 response[] = new nsacl6[acl6name.length];\n\t\t\tnsacl6 obj[] = new nsacl6[acl6name.length];\n\t\t\tfor (int i=0;i<acl6name.length;i++) {\n\t\t\t\tobj[i] = new nsacl6();\n\t\t\t\tobj[i].set_acl6name(acl6name[i]);\n\t\t\t\tresponse[i] = (nsacl6) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "private void addObjectReferenceEdges(Vertex vertex, ObjectReferenceDescriptor rds)\r\n    {\r\n        Object refObject = rds.getPersistentField().get(vertex.getEnvelope().getRealObject());\r\n        Class refClass = rds.getItemClass();\r\n        for (int i = 0; i < vertices.length; i++)\r\n        {\r\n            Edge edge = null;\r\n            // ObjectEnvelope envelope = vertex.getEnvelope();\r\n            Vertex refVertex = vertices[i];\r\n            ObjectEnvelope refEnvelope = refVertex.getEnvelope();\r\n            if (refObject == refEnvelope.getRealObject())\r\n            {\r\n                edge = buildConcrete11Edge(vertex, refVertex, rds.hasConstraint());\r\n            }\r\n            else if (refClass.isInstance(refVertex.getEnvelope().getRealObject()))\r\n            {\r\n                edge = buildPotential11Edge(vertex, refVertex, rds.hasConstraint());\r\n            }\r\n            if (edge != null)\r\n            {\r\n                if (!edgeList.contains(edge))\r\n                {\r\n                    edgeList.add(edge);\r\n                }\r\n                else\r\n                {\r\n                    edge.increaseWeightTo(edge.getWeight());\r\n                }\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "function computeLcsMatrix(xs, ys) {\n  var n = xs.size||0;\n  var m = ys.size||0;\n  var a = makeMatrix(n + 1, m + 1, 0);\n\n  for (var i = 0; i < n; i++) {\n    for (var j = 0; j < m; j++) {\n      if (Immutable.is(xs.get(i), ys.get(j))) {\n        a[i + 1][j + 1] = a[i][j] + 1;\n      }\n      else {\n        a[i + 1][j + 1] = Math.max(a[i + 1][j], a[i][j + 1]);\n      }\n    }\n  }\n\n  return a;\n}", "label": 3}
{"code": "function (driver, response, remote, options, deferred) {\n      return driver[(response.statusCode === 500 ? '_onError' : '_onSuccess')].bind(this)(driver, response, remote, options, deferred);\n    }", "label": 3}
{"code": "function flatten (expression) {\n  const expanded = Array.from(expandInner(expression))\n  const flattened = expanded.reduce(function (result, clause) {\n    return Object.assign(result, clause)\n  }, {})\n  return sort([flattened])[0]\n}", "label": 3}
{"code": "public function setSshPublicKeys($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\OsLogin\\Common\\SshPublicKey::class);\n        $this->ssh_public_keys = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response unset(nitro_service client, lbsipparameters resource, String[] args) throws Exception{\n\t\tlbsipparameters unsetresource = new lbsipparameters();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def account_groups_and_extra_data(account, resource,\n                                  refresh_timedelta=None):\n    \"\"\"Fetch account groups and extra data from resource if necessary.\"\"\"\n    updated = datetime.utcnow()\n    modified_since = updated\n    if refresh_timedelta is not None:\n        modified_since += refresh_timedelta\n    modified_since = modified_since.isoformat()\n    last_update = account.extra_data.get('updated', modified_since)\n\n    if last_update > modified_since:\n        return account.extra_data.get('groups', [])\n\n    groups = fetch_groups(resource['Group'])\n    extra_data = current_app.config.get(\n        'OAUTHCLIENT_CERN_EXTRA_DATA_SERIALIZER',\n        fetch_extra_data\n    )(resource)\n\n    account.extra_data.update(\n        groups=groups,\n        updated=updated.isoformat(),\n        **extra_data\n    )\n    return groups", "label": 1}
{"code": "public static base_responses clear(nitro_service client, rnat resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\trnat clearresources[] = new rnat[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tclearresources[i] = new rnat();\n\t\t\t\tclearresources[i].network = resources[i].network;\n\t\t\t\tclearresources[i].netmask = resources[i].netmask;\n\t\t\t\tclearresources[i].aclname = resources[i].aclname;\n\t\t\t\tclearresources[i].redirectport = resources[i].redirectport;\n\t\t\t\tclearresources[i].natip = resources[i].natip;\n\t\t\t\tclearresources[i].td = resources[i].td;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, clearresources,\"clear\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def _convert_hbf_meta_val_for_xml(key, val):\n    \"\"\"Convert to a BadgerFish-style dict for addition to a dict suitable for\n    addition to XML tree or for v1.0 to v0.0 conversion.\"\"\"\n    if isinstance(val, list):\n        return [_convert_hbf_meta_val_for_xml(key, i) for i in val]\n    is_literal = True\n    content = None\n    if isinstance(val, dict):\n        ret = val\n        if '@href' in val:\n            is_literal = False\n        else:\n            content = val.get('$')\n            if isinstance(content, dict) and _contains_hbf_meta_keys(val):\n                is_literal = False\n    else:\n        ret = {}\n        content = val\n    if is_literal:\n        ret.setdefault('@xsi:type', 'nex:LiteralMeta')\n        ret.setdefault('@property', key)\n        if content is not None:\n            ret.setdefault('@datatype', _python_instance_to_nexml_meta_datatype(content))\n        if ret is not val:\n            ret['$'] = content\n    else:\n        ret.setdefault('@xsi:type', 'nex:ResourceMeta')\n        ret.setdefault('@rel', key)\n    return ret", "label": 1}
{"code": "func (c *remoteConn) findDisconnectedProxies() ([]services.Server, error) {\n\t// Find all proxies that have connection from the remote domain.\n\tconns, err := c.accessPoint.GetTunnelConnections(c.clusterName, services.SkipValidation())\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tconnected := make(map[string]bool)\n\tfor _, conn := range conns {\n\t\tif c.isOnline(conn) {\n\t\t\tconnected[conn.GetProxyName()] = true\n\t\t}\n\t}\n\n\t// Build a list of local proxies that do not have a remote connection to them.\n\tvar missing []services.Server\n\tproxies, err := c.accessPoint.GetProxies()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tfor i := range proxies {\n\t\tproxy := proxies[i]\n\n\t\t// A proxy should never add itself to the list of missing proxies.\n\t\tif proxy.GetName() == c.proxyName {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !connected[proxy.GetName()] {\n\t\t\tmissing = append(missing, proxy)\n\t\t}\n\t}\n\n\treturn missing, nil\n}", "label": 5}
{"code": "public function setContexts($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dialogflow\\V2\\Context::class);\n        $this->contexts = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function format_parsed (parsed) {\n  var pkg = (parsed.s && '@' + parsed.s + '/')\n    + parsed.n + '@' + parsed.v;\n\n  parsed.id = pkg + parsed.p;\n  parsed.k = pkg;\n  return parsed;\n}", "label": 3}
{"code": "def format_request_email_templ(increq, template, **ctx):\n    \"\"\"Format the email message element for inclusion request notification.\n\n    Formats the message according to the provided template file, using\n    some default fields from 'increq' object as default context.\n    Arbitrary context can be provided as keywords ('ctx'), and those will\n    not be overwritten by the fields from 'increq' object.\n\n    :param increq: Inclusion request object for which the request is made.\n    :type increq: `invenio_communities.models.InclusionRequest`\n    :param template: relative path to jinja template.\n    :type template: str\n    :param ctx: Optional extra context parameters passed to formatter.\n    :type ctx: dict.\n    :returns: Formatted message.\n    :rtype: str\n    \"\"\"\n    # Add minimal information to the contex (without overwriting).\n    curate_link = '{site_url}/communities/{id}/curate/'.format(\n        site_url=current_app.config['THEME_SITEURL'],\n        id=increq.community.id)\n\n    min_ctx = dict(\n        record=Record.get_record(increq.record.id),\n        requester=increq.user,\n        community=increq.community,\n        curate_link=curate_link,\n    )\n    for k, v in min_ctx.items():\n        if k not in ctx:\n            ctx[k] = v\n\n    msg_element = render_template_to_string(template, **ctx)\n    return msg_element", "label": 1}
{"code": "public int[] otherOccurrences(Entity entity){\r\n    List<Integer> other = new ArrayList<Integer>();\r\n    for (int i = 0; i < doc.size(); i++) {\r\n      if (i == entity.startPosition) { continue; }\r\n      if (matches(entity, i)) {\r\n        other.add(Integer.valueOf(i));\r\n      }\r\n    }\r\n    return toArray(other);\r\n  }", "label": 0}
{"code": "def call(args = [])\n      object, meth = @when_called[0, 2]\n      meth ||= :call\n      options = proxy_option_struct\n\n      case object\n      when Proc then object.call(args, options)\n      when Class then meth != :call ? object.new.send(meth, args, options) : object.new(args, options)\n      else object.send(meth, args, options) if object\n      end\n    end", "label": 4}
{"code": "public static function snapshotName($project, $instance, $cluster, $snapshot)\n    {\n        return self::getSnapshotNameTemplate()->render([\n            'project' => $project,\n            'instance' => $instance,\n            'cluster' => $cluster,\n            'snapshot' => $snapshot,\n        ]);\n    }", "label": 2}
{"code": "def check_type_declaration(parameter_names, parameter_types):\n    \"\"\"Checks that exactly the given parameter names have declared types.\n\n    :param parameter_names: The names of the parameters in the method declaration\n    :type parameter_names: list[str]\n    :param parameter_types: Parameter type by name\n    :type parameter_types: dict[str, type]\n    \"\"\"\n    if len(parameter_names) != len(parameter_types):\n        raise Exception(\"Number of method parameters ({}) does not match number of \"\n                        \"declared types ({})\"\n                        .format(len(parameter_names), len(parameter_types)))\n    for parameter_name in parameter_names:\n        if parameter_name not in parameter_types:\n            raise Exception(\"Parameter '{}' does not have a declared type\".format(parameter_name))", "label": 1}
{"code": "public function injectEntityManager(EntityManagerInterface $entityManager, ClassMetadata $classMetadata) : void\n    {\n        if ($entityManager !== self::$entityManager) {\n            throw new RuntimeException(\n                'Trying to use PersistentObject with different EntityManager instances. ' .\n                'Was PersistentObject::setEntityManager() called?'\n            );\n        }\n\n        $this->cm = $classMetadata;\n    }", "label": 2}
{"code": "func (s *MockStore) Watch(key string, stopCh <-chan struct{}) (<-chan *store.KVPair, error) {\n\treturn nil, ErrNotImplemented\n}", "label": 5}
{"code": "def end_session\n      if !ended? && @client\n        if within_states?(TRANSACTION_IN_PROGRESS_STATE)\n          begin\n            abort_transaction\n          rescue Mongo::Error\n          end\n        end\n        @client.cluster.session_pool.checkin(@server_session)\n      end\n    ensure\n      @server_session = nil\n    end", "label": 4}
{"code": "def bind_fields_to_model_cls(cls, model_fields):\n        \"\"\"Bind fields to model class.\"\"\"\n        return dict(\n            (field.name, field.bind_model_cls(cls)) for field in model_fields)", "label": 1}
{"code": "def architecture(file)\n      return :invalid unless File.exist?(file)\n\n      f = File.open(file)\n      str = ELFTools::ELFFile.new(f).machine\n      {\n        'Advanced Micro Devices X86-64' => :amd64,\n        'Intel 80386' => :i386,\n        'ARM' => :arm,\n        'AArch64' => :aarch64,\n        'MIPS R3000' => :mips\n      }[str] || :unknown\n    rescue ELFTools::ELFError # not a valid ELF\n      :invalid\n    ensure\n      f&.close\n    end", "label": 4}
{"code": "func nodeName(node string) string {\n\tn, _, err := net.SplitHostPort(node)\n\tif err != nil {\n\t\treturn node\n\t}\n\treturn n\n}", "label": 5}
{"code": "function (notes, settings) {\n  var noteEvents = makeNoteEvents(notes, settings);\n  var setPatch = makePatchEvent(0, settings.melodyPatch);\n  var length = setPatch.length + noteEvents.length + trackFooter.length;\n\n  return Buffer.concat([trackHeader, padNumber(length, 4), setPatch, noteEvents, trackFooter]);\n}", "label": 3}
{"code": "function () {\n        var _this = this;\n\n        console.info('INFO: creating tunnel to %s', this.proxyHost);\n\n        this._tunnel = childProcess.spawn('ssh', this._buildSSHArgs());\n\n        var cleanup = function () {\n            _this._tunnel.stderr.removeAllListeners('data');\n        };\n\n        this._tunnel.stderr.on('data', function (data) {\n            if (/success/.test(data)) {\n                cleanup();\n                return _this._resolveTunnel();\n            }\n\n            if (/failed/.test(data)) {\n                cleanup();\n                return _this._rejectTunnel();\n            }\n        });\n\n        this._tunnel.on('exit', function (code, signal) {\n            _this.emit('exit', code, signal);\n        });\n\n        this._tunnel.on('close', function (code, signal) {\n            _this.emit('close', code, signal);\n            return _this._closeTunnel(code);\n        });\n\n        this._tunnel.on('error', function () {\n            return _this._rejectTunnel();\n        });\n\n        return _this._tunnelDeferred.promise.timeout(this._connectTimeout);\n    }", "label": 3}
{"code": "func (s *MetricSeries) ValueCSV() string {\n\tvals := make([]string, len(s.Value))\n\n\tfor i := range s.Value {\n\t\tvals[i] = s.Format(s.Value[i])\n\t}\n\n\treturn strings.Join(vals, \",\")\n}", "label": 5}
{"code": "def slice!(*keys)\n      deprecation_removal_warning(:slice!)\n\n      keys = keys.map(&:to_sym)\n\n      results = messages.dup.slice!(*keys)\n\n      @errors.keep_if do |error|\n        keys.include?(error.attribute)\n      end\n\n      results\n    end", "label": 4}
{"code": "def insert_default_acl\n      self.class.default_acl.each do |acl|\n        unless rights[acl[:acl]]\n          Puppet.info _(\"Inserting default '%{acl}' (auth %{auth}) ACL\") % { acl: acl[:acl], auth: acl[:authenticated] }\n          mk_acl(acl)\n        end\n      end\n      # queue an empty (ie deny all) right for every other path\n      # actually this is not strictly necessary as the rights system\n      # denies not explicitly allowed paths\n      unless rights[\"/\"]\n        rights.newright(\"/\").restrict_authenticated(:any)\n      end\n    end", "label": 4}
{"code": "public static function sessionEntityTypeName($project, $session, $entityType)\n    {\n        return self::getSessionEntityTypeNameTemplate()->render([\n            'project' => $project,\n            'session' => $session,\n            'entity_type' => $entityType,\n        ]);\n    }", "label": 2}
{"code": "func (w *Wrapper) UpsertNode(s services.Server) (*services.KeepAlive, error) {\n\treturn w.Write.UpsertNode(s)\n}", "label": 5}
{"code": "def relation_reflect(relation)\n      relation = relation.is_a?(Enumerable) ? relation.dup : [relation]\n\n      # go from one relation to the next until we hit the last reflect object\n      klass = model\n      while relation.size > 0\n        cur_relation = relation.shift\n        reflect = klass.reflect_on_association(cur_relation)\n        raise \"No relation #{cur_relation} on #{klass.name}\" if reflect.nil?\n\n        if relation.size > 0\n          # not necessary to do this at the last link because we won't use\n          # klass again. not calling this avoids the following causing an\n          # exception in the now-supported one-level polymorphic counter cache\n          klass = reflect.klass\n        end\n      end\n\n      return reflect\n    end", "label": 4}
{"code": "public function setAggregation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\Aggregation::class);\n        $this->aggregation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def actions(options = {})\n      actions = Action.from_response client.get(\"#{request_prefix}/actions\", { filter: :all }.merge(options))\n      MultiAssociation.new(self, actions).proxy\n    end", "label": 4}
{"code": "func (m *Manager) AvailableMetric(ctx context.Context, entity types.ManagedObjectReference, interval int32) (MetricList, error) {\n\treq := types.QueryAvailablePerfMetric{\n\t\tThis:       m.Reference(),\n\t\tEntity:     entity.Reference(),\n\t\tIntervalId: interval,\n\t}\n\n\tres, err := methods.QueryAvailablePerfMetric(ctx, m.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif m.Sort {\n\t\tinfo, err := m.CounterInfoByKey(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tsort.Sort(groupPerfCounterInfo{info, res.Returnval})\n\t}\n\n\treturn MetricList(res.Returnval), nil\n}", "label": 5}
{"code": "function process(advertiserData) {\n  var data = advertiserData.manufacturerSpecificData.data;\n  var packetType = data.substr(0,2);\n\n  switch(packetType) {\n    case '01':\n      snfsingle.process(advertiserData);\n      break;\n    case '42':\n      snsmotion.process(advertiserData);\n      break;\n    default:\n  }\n}", "label": 3}
{"code": "public static CRFClassifier getClassifier(InputStream in) throws IOException, ClassCastException,\r\n      ClassNotFoundException {\r\n    CRFClassifier crf = new CRFClassifier();\r\n    crf.loadClassifier(in);\r\n    return crf;\r\n  }", "label": 0}
{"code": "public static tmtrafficpolicy_lbvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\ttmtrafficpolicy_lbvserver_binding obj = new tmtrafficpolicy_lbvserver_binding();\n\t\tobj.set_name(name);\n\t\ttmtrafficpolicy_lbvserver_binding response[] = (tmtrafficpolicy_lbvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setFilters(array $filters)\n    {\n        $this->filters = $filters;\n\n        $this->updateInternalState();\n\n        $this->handleChangedParameters();\n\n        return $this;\n    }", "label": 2}
{"code": "def transform_partial_capture(mapping, capture, processor = nil,\n                                  normalize_values = true)\n      _, operator, varlist = *capture.match(EXPRESSION)\n\n      vars = varlist.split(\",\")\n\n      if operator == \"?\"\n        # partial expansion of form style query variables sometimes requires a\n        # slight reordering of the variables to produce a valid url.\n        first_to_expand = vars.find { |varspec|\n          _, name, _ =  *varspec.match(VARSPEC)\n          mapping.key?(name) && !mapping[name].nil?\n        }\n\n        vars = [first_to_expand] + vars.reject {|varspec| varspec == first_to_expand}  if first_to_expand\n      end\n\n      vars.\n        inject(\"\".dup) do |acc, varspec|\n          _, name, _ =  *varspec.match(VARSPEC)\n          next_val = if mapping.key? name\n                       transform_capture(mapping, \"{#{operator}#{varspec}}\",\n                                         processor, normalize_values)\n                     else\n                       \"{#{operator}#{varspec}}\"\n                     end\n          # If we've already expanded at least one '?' operator with non-empty\n          # value, change to '&'\n          operator = \"&\" if (operator == \"?\") && (next_val != \"\")\n          acc << next_val\n      end\n    end", "label": 4}
{"code": "def _track_class_field(cls, field):\n    \"\"\" Track a field on the current model \"\"\"\n    if '__' in field:\n        _track_class_related_field(cls, field)\n        return\n    # Will raise FieldDoesNotExist if there is an error\n    cls._meta.get_field(field)\n    # Detect m2m fields changes\n    if isinstance(cls._meta.get_field(field), ManyToManyField):\n        m2m_changed.connect(\n            tracking_m2m,\n            sender=getattr(cls, field).through,\n            dispatch_uid=repr(cls),\n        )", "label": 1}
{"code": "def encoded\n      ready_to_send!\n      buffer = header.encoded\n      buffer << \"\\r\\n\"\n      buffer << body.encoded(content_transfer_encoding)\n      buffer\n    end", "label": 4}
{"code": "function rename(source, destination) {\n  const parent = path.dirname(destination);\n  if (exists(destination)) {\n    if (isDirectory(destination)) {\n      destination = path.join(destination, path.basename(source));\n    } else {\n      if (isDirectory(source)) {\n        throw new Error(`Cannot rename directory ${source} into existing file ${destination}`);\n      }\n    }\n  } else if (!exists(parent)) {\n    mkdir(parent);\n  }\n  try {\n    fs.renameSync(source, destination);\n  } catch (e) {\n    if (e.code !== 'EXDEV') throw e;\n    // Fallback for moving across devices\n    copy(source, destination);\n    fileDelete(source);\n  }\n}", "label": 3}
{"code": "def lookup(alias):\n    \"\"\" Tries to find a matcher callable associated to the given alias. If\n        an exact match does not exists it will try normalizing it and even\n        removing underscores to find one.\n    \"\"\"\n\n    if alias in matchers:\n        return matchers[alias]\n    else:\n        norm = normalize(alias)\n        if norm in normalized:\n            alias = normalized[norm]\n            return matchers[alias]\n\n    # Check without snake case\n    if -1 != alias.find('_'):\n        norm = normalize(alias).replace('_', '')\n        return lookup(norm)\n\n    return None", "label": 1}
{"code": "function indexReducers() {\n  const { reducers = {} } = getComponentsSettings();\n\n  return index({\n    file: 'reducers.js',\n    config: {\n      type: TYPE_REDUCERS,\n      config: reducers,\n    },\n    defaultContent: 'export default null;\\n',\n    ...getIndexLogTranslations(TYPE_REDUCERS),\n  });\n}", "label": 3}
{"code": "func GetIfaceAddr(name string) (net.Addr, []net.Addr, error) {\n\tiface, err := net.InterfaceByName(name)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\taddrs, err := iface.Addrs()\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tvar addrs4 []net.Addr\n\tvar addrs6 []net.Addr\n\tfor _, addr := range addrs {\n\t\tip := (addr.(*net.IPNet)).IP\n\t\tif ip4 := ip.To4(); ip4 != nil {\n\t\t\taddrs4 = append(addrs4, addr)\n\t\t} else if ip6 := ip.To16(); len(ip6) == net.IPv6len {\n\t\t\taddrs6 = append(addrs6, addr)\n\t\t}\n\t}\n\tswitch {\n\tcase len(addrs4) == 0:\n\t\treturn nil, nil, fmt.Errorf(\"Interface %v has no IPv4 addresses\", name)\n\tcase len(addrs4) > 1:\n\t\tfmt.Printf(\"Interface %v has more than 1 IPv4 address. Defaulting to using %v\\n\",\n\t\t\tname, (addrs4[0].(*net.IPNet)).IP)\n\t}\n\treturn addrs4[0], addrs6, nil\n}", "label": 5}
{"code": "func generateSeccompFilter(p *stage1commontypes.Pod, pa *preparedApp) (*seccompFilter, error) {\n\tsf := seccompFilter{}\n\tseenIsolators := 0\n\tfor _, i := range pa.app.App.Isolators {\n\t\tvar flag string\n\t\tvar err error\n\t\tif seccomp, ok := i.Value().(types.LinuxSeccompSet); ok {\n\t\t\tseenIsolators++\n\t\t\t// By appc spec, only one seccomp isolator per app is allowed\n\t\t\tif seenIsolators > 1 {\n\t\t\t\treturn nil, ErrTooManySeccompIsolators\n\t\t\t}\n\t\t\tswitch i.Name {\n\t\t\tcase types.LinuxSeccompRemoveSetName:\n\t\t\t\tsf.mode = ModeBlacklist\n\t\t\t\tsf.syscalls, flag, err = parseLinuxSeccompSet(p, seccomp)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tif flag == \"empty\" {\n\t\t\t\t\t// we interpret \"remove @empty\" to mean \"default whitelist\"\n\t\t\t\t\tsf.mode = ModeWhitelist\n\t\t\t\t\tsf.syscalls = RktDefaultSeccompWhitelist\n\t\t\t\t}\n\t\t\tcase types.LinuxSeccompRetainSetName:\n\t\t\t\tsf.mode = ModeWhitelist\n\t\t\t\tsf.syscalls, flag, err = parseLinuxSeccompSet(p, seccomp)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tif flag == \"all\" {\n\t\t\t\t\t// Opt-out seccomp filtering\n\t\t\t\t\treturn nil, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\tsf.errno = string(seccomp.Errno())\n\t\t}\n\t}\n\n\t// If unset, use rkt default whitelist\n\tif seenIsolators == 0 {\n\t\tsf.mode = ModeWhitelist\n\t\tsf.syscalls = RktDefaultSeccompWhitelist\n\t}\n\n\t// Non-priv apps *must* have NoNewPrivileges set if they have seccomp\n\tsf.forceNoNewPrivileges = (pa.uid != 0)\n\n\treturn &sf, nil\n}", "label": 5}
{"code": "def set_stats(self, ids):\n        \"\"\"Compute stats for a set of results.\n\n        :param id: Result IDs as int list.\n        :return: :class:`results.SetStats <results.SetStats>` object\n        :rtype: results.SetStats\n        \"\"\"\n        schema = SetStatsSchema()\n        resp = self.service.post(self.base, params={'stats': 'set'}, json=[{'id': str(x)} for x in ids])\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "def _get_related_fields(self, model):\n        \"Returns the names of all related fields for model class.\"\n        reverse_fk = self._get_all_related_objects(model)\n        reverse_m2m = self._get_all_related_many_to_many_objects(model)\n\n        fields = tuple(reverse_fk + reverse_m2m)\n        names = tuple([x.get_accessor_name() for x in fields])\n\n        return {\n            ':related': dict(list(zip(names, fields))),\n        }", "label": 1}
{"code": "def initialize_from_file\n      pbxproj_path = path + 'project.pbxproj'\n      plist = Plist.read_from_path(pbxproj_path.to_s)\n      root_object.remove_referrer(self) if root_object\n      @root_object     = new_from_plist(plist['rootObject'], plist['objects'], self)\n      @archive_version = plist['archiveVersion']\n      @object_version  = plist['objectVersion']\n      @classes         = plist['classes'] || {}\n      @dirty           = false\n\n      unless root_object\n        raise \"[Xcodeproj] Unable to find a root object in #{pbxproj_path}.\"\n      end\n\n      if archive_version.to_i > Constants::LAST_KNOWN_ARCHIVE_VERSION\n        raise '[Xcodeproj] Unknown archive version.'\n      end\n\n      if object_version.to_i > Constants::LAST_KNOWN_OBJECT_VERSION\n        raise '[Xcodeproj] Unknown object version.'\n      end\n\n      # Projects can have product_ref_groups that are not listed in the main_groups[\"Products\"]\n      root_object.product_ref_group ||= root_object.main_group['Products'] || root_object.main_group.new_group('Products')\n    end", "label": 4}
{"code": "func (c *Manager) GetCategories(ctx context.Context) ([]Category, error) {\n\tids, err := c.ListCategories(ctx)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"list categories: %s\", err)\n\t}\n\n\tvar categories []Category\n\tfor _, id := range ids {\n\t\tcategory, err := c.GetCategory(ctx, id)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"get category %s: %s\", id, err)\n\t\t}\n\n\t\tcategories = append(categories, *category)\n\n\t}\n\treturn categories, nil\n}", "label": 5}
{"code": "public function setStatusHistory($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dataproc\\V1beta2\\JobStatus::class);\n        $this->status_history = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def filter_issues_for_tags(newer_tag, older_tag)\n      filtered_pull_requests = filter_by_tag(@pull_requests, newer_tag)\n      filtered_issues        = delete_by_time(@issues, \"actual_date\", older_tag, newer_tag)\n\n      newer_tag_name = newer_tag.nil? ? nil : newer_tag[\"name\"]\n\n      if options[:filter_issues_by_milestone]\n        # delete excess irrelevant issues (according milestones). Issue #22.\n        filtered_issues = filter_by_milestone(filtered_issues, newer_tag_name, @issues)\n        filtered_pull_requests = filter_by_milestone(filtered_pull_requests, newer_tag_name, @pull_requests)\n      end\n      [filtered_issues, filtered_pull_requests]\n    end", "label": 4}
{"code": "func (c *Client) Renew(ctx context.Context, req TokenRequest) (*Signer, error) {\n\ts := &Signer{\n\t\tCertificate: req.Certificate,\n\t}\n\n\trst, err := c.newRequest(req, \"Renew\", s)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif req.Token == \"\" {\n\t\treturn nil, errors.New(\"TokenRequest Token is required\")\n\t}\n\n\trst.RenewTarget = &internal.Target{Token: req.Token}\n\n\theader := soap.Header{\n\t\tSecurity: s,\n\t\tAction:   rst.Action(),\n\t}\n\n\tres, err := internal.Renew(c.WithHeader(ctx, header), c, &rst)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ts.Token = res.RequestedSecurityToken.Assertion\n\n\treturn s, s.setLifetime(res.Lifetime)\n}", "label": 5}
{"code": "function hasCallback (callbackContext = null) {\n        if (!this.state[ACTION]\n            || callbackContext === this.state[CONTEXT]\n            || !this.isText()) {\n\n            return false;\n        }\n        return true;\n    }", "label": 3}
{"code": "def addresses\n      list = element.addresses.map { |a| a.address }\n      Mail::AddressContainer.new(self, list)\n    end", "label": 4}
{"code": "public function setAngerLikelihood($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Vision\\V1\\Likelihood::class);\n        $this->anger_likelihood = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def load_item(inbox, type=\"string\", remove=True, buffer=None):\n    \"\"\"\n    Loads data from a file. Determines the file type automatically ``\"file\"``,\n    ``\"fifo\"``, ``\"socket\"``, but allows to specify the representation type \n    ``\"string\"`` or ``\"mmap\"`` for memory mapped access to the file. Returns \n    the  loaded item as a ``str`` or ``mmap`` object. Internally creates an item\n    from a ``file``.\n\n    Arguments:\n\n      - type(``\"string\"`` or ``\"mmap\"``) [default: ``\"string\"``] Determines the\n        type of ``object`` the worker returns i.e. the ``file`` is read as a \n        string or a memmory map. FIFOs cannot be memory mapped. \n      - remove(``bool``) [default: ``True``] Should the file be removed from the\n        filesystem? This is mandatory for FIFOs and sockets. Only Files can be \n        used to store data persistantly.\n    \n    \"\"\"\n    is_file, is_fifo, is_socket = False, False, False\n\n    file = inbox[0]\n    try:\n        file_type = file[0]\n    except:\n        raise ValueError(\"invalid inbox item\")\n    if file_type == \"file\":\n        is_file = os.path.exists(file[1])\n    elif file_type == \"fifo\":\n        is_fifo = stat.S_ISFIFO(os.stat(file[1]).st_mode)\n    elif file_type == \"socket\":\n        # how to test is valid socket?\n        is_socket = True\n    else:\n        raise ValueError(\"type: %s not undertood\" % file_type)\n\n\n    if (is_fifo or is_socket) and (type == 'mmap'):\n        raise ValueError(\"mmap is not supported for FIFOs and sockets\")\n    if (is_fifo or is_socket) and not remove:\n        raise ValueError(\"FIFOs and sockets have to be removed\")\n\n    # get a fd and start/stop\n    start = 0\n    if is_fifo or is_file:\n        stop = os.stat(file[1]).st_size - 1\n        fd = os.open(file[1], os.O_RDONLY)\n        BUFFER = (buffer or PAPY_DEFAULTS['PIPE_BUF'])\n    elif is_socket:\n        host, port = socket.gethostbyname(file[1]), file[2]\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.connect((host, port))\n        stop = -1\n        fd = sock.fileno()\n        BUFFER = (buffer or PAPY_DEFAULTS['TCP_RCVBUF'])\n    else:\n        raise ValueError(\"got unknown inbox: %s\" % (repr(inbox)))\n\n    # get the data\n    if type == 'mmap':\n        offset = start - (start % (getattr(mmap, 'ALLOCATIONGRANULARITY', None)\\\n                                   or getattr(mmap, 'PAGESIZE')))\n        start = start - offset\n        stop = stop - offset + 1\n        try:\n            data = mmap.mmap(fd, stop, access=mmap.ACCESS_READ, offset=offset)\n        except TypeError:\n            # we're on Python 2.5\n            data = mmap.mmap(fd, stop, access=mmap.ACCESS_READ)\n        data.seek(start)\n\n    elif type == 'string':\n        data = []\n        if stop == -1:\n            while True:\n                buffer_ = os.read(fd, BUFFER)\n                if not buffer_:\n                    break\n                data.append(buffer_)\n            data = \"\".join(data)\n            # data = sock.recv(socket.MSG_WAITALL) \n            # this would read all the data from a socket\n        else:\n            os.lseek(fd, start, 0)\n            data = os.read(fd, stop - start + 1)\n    else:\n        raise ValueError('type: %s not understood.' % type)\n\n    # remove the file or close the socket\n    if remove:\n        if is_socket:\n            # closes client socket\n            sock.close()\n        else:\n            # pipes and files are just removed\n            os.close(fd)\n            os.unlink(file[1])\n    else:\n        os.close(fd)\n    # returns a string or mmap\n    return data", "label": 1}
{"code": "def as_resultset(targets)\n      result_array = begin\n                       yield\n                     rescue StandardError => e\n                       @logger.warn(e)\n                       # CODEREVIEW how should we fail if there's an error?\n                       Array(Bolt::Result.from_exception(targets[0], e))\n                     end\n      Bolt::ResultSet.new(result_array)\n    end", "label": 4}
{"code": "public function getNativeName(): string\n    {\n        $name = $this->getFullNativeName();\n\n        return trim(strstr($name, ',', true) ?: $name);\n    }", "label": 2}
{"code": "func New(c ServerConfig) (*Server, error) {\n\t// Check and make sure we everything we need to build a forwarding node.\n\terr := c.CheckDefaults()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Build a pipe connection to hook up the client and the server. we save both\n\t// here and will pass them along to the context when we create it so they\n\t// can be closed by the context.\n\tserverConn, clientConn := utils.DualPipeNetConn(c.SrcAddr, c.DstAddr)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\ts := &Server{\n\t\tlog: logrus.WithFields(logrus.Fields{\n\t\t\ttrace.Component: teleport.ComponentForwardingNode,\n\t\t\ttrace.ComponentFields: map[string]string{\n\t\t\t\t\"src-addr\": c.SrcAddr.String(),\n\t\t\t\t\"dst-addr\": c.DstAddr.String(),\n\t\t\t},\n\t\t}),\n\t\tid:              uuid.New(),\n\t\ttargetConn:      c.TargetConn,\n\t\tserverConn:      utils.NewTrackingConn(serverConn),\n\t\tclientConn:      clientConn,\n\t\tuserAgent:       c.UserAgent,\n\t\thostCertificate: c.HostCertificate,\n\t\tauthClient:      c.AuthClient,\n\t\tauditLog:        c.AuthClient,\n\t\tauthService:     c.AuthClient,\n\t\tsessionServer:   c.AuthClient,\n\t\tdataDir:         c.DataDir,\n\t\tclock:           c.Clock,\n\t}\n\n\t// Set the ciphers, KEX, and MACs that the in-memory server will send to the\n\t// client in its SSH_MSG_KEXINIT.\n\ts.ciphers = c.Ciphers\n\ts.kexAlgorithms = c.KEXAlgorithms\n\ts.macAlgorithms = c.MACAlgorithms\n\n\ts.sessionRegistry, err = srv.NewSessionRegistry(s)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Common auth handlers.\n\ts.authHandlers = &srv.AuthHandlers{\n\t\tEntry: logrus.WithFields(logrus.Fields{\n\t\t\ttrace.Component:       teleport.ComponentForwardingNode,\n\t\t\ttrace.ComponentFields: logrus.Fields{},\n\t\t}),\n\t\tServer:      s,\n\t\tComponent:   teleport.ComponentForwardingNode,\n\t\tAuditLog:    c.AuthClient,\n\t\tAccessPoint: c.AuthClient,\n\t}\n\n\t// Common term handlers.\n\ts.termHandlers = &srv.TermHandlers{\n\t\tSessionRegistry: s.sessionRegistry,\n\t}\n\n\t// Create a close context that is used internally to signal when the server\n\t// is closing and for any blocking goroutines to unblock.\n\ts.closeContext, s.closeCancel = context.WithCancel(context.Background())\n\n\treturn s, nil\n}", "label": 5}
{"code": "public static function pathToUri(string $filepath): string\n    {\n        $filepath = trim(str_replace('\\\\', '/', $filepath), '/');\n        $parts = explode('/', $filepath);\n        // Don't %-encode the colon after a Windows drive letter\n        $first = array_shift($parts);\n        if (substr($first, -1) !== ':') {\n            $first = rawurlencode($first);\n        }\n        $parts = array_map('rawurlencode', $parts);\n        array_unshift($parts, $first);\n        $filepath = implode('/', $parts);\n        return 'file:///' . $filepath;\n    }", "label": 2}
{"code": "def ReSpecTh_to_ChemKED(filename_xml, file_author='', file_author_orcid='', *, validate=False):\n    \"\"\"Convert ReSpecTh XML file to ChemKED-compliant dictionary.\n\n    Args:\n        filename_xml (`str`): Name of ReSpecTh XML file to be converted.\n        file_author (`str`, optional): Name to override original file author\n        file_author_orcid (`str`, optional): ORCID of file author\n        validate (`bool`, optional, keyword-only): Set to `True` to validate the resulting\n            property dictionary with `ChemKED`. Set to `False` if the file is being loaded and will\n            be validated at some other point before use.\n    \"\"\"\n    # get all information from XML file\n    tree = etree.parse(filename_xml)\n    root = tree.getroot()\n\n    # get file metadata\n    properties = get_file_metadata(root)\n\n    # get reference info\n    properties['reference'] = get_reference(root)\n    # Save name of original data filename\n    properties['reference']['detail'] = (properties['reference'].get('detail', '') +\n                                         'Converted from ReSpecTh XML file ' +\n                                         os.path.basename(filename_xml)\n                                         )\n\n    # Ensure ignition delay, and get which kind of experiment\n    properties.update(get_experiment_kind(root))\n\n    # Get properties shared across the file\n    properties['common-properties'] = get_common_properties(root)\n\n    # Determine definition of ignition delay\n    properties['common-properties']['ignition-type'] = get_ignition_type(root)\n\n    # Now parse ignition delay datapoints\n    properties['datapoints'] = get_datapoints(root)\n\n    # Ensure inclusion of pressure rise or volume history matches apparatus.\n    has_pres_rise = ('pressure-rise' in properties['common-properties'] or\n                     any([True for dp in properties['datapoints'] if 'pressure-rise' in dp])\n                     )\n    if has_pres_rise and properties['apparatus']['kind'] == 'rapid compression machine':\n        raise KeywordError('Pressure rise cannot be defined for RCM.')\n\n    has_vol_hist = any(\n        [t.get('type') == 'volume' for dp in properties['datapoints']\n         for t in dp.get('time-histories', [{}])]\n    )\n    if has_vol_hist and properties['apparatus']['kind'] == 'shock tube':\n        raise KeywordError('Volume history cannot be defined for shock tube.')\n\n    # add any additional file authors\n    if file_author_orcid and not file_author:\n        raise KeywordError('If file_author_orcid is specified, file_author must be as well')\n\n    if file_author:\n        temp_author = {'name': file_author}\n        if file_author_orcid:\n            temp_author['ORCID'] = file_author_orcid\n        properties['file-authors'].append(temp_author)\n\n    # Now go through datapoints and apply common properties\n    for idx in range(len(properties['datapoints'])):\n        for prop in properties['common-properties']:\n            properties['datapoints'][idx][prop] = properties['common-properties'][prop]\n\n    if validate:\n        chemked.ChemKED(dict_input=properties)\n\n    return properties", "label": 1}
{"code": "public static <E> Set<E> intersection(Set<E> s1, Set<E> s2) {\r\n    Set<E> s = new HashSet<E>();\r\n    s.addAll(s1);\r\n    s.retainAll(s2);\r\n    return s;\r\n  }", "label": 0}
{"code": "def create(attributes = nil, &block)\n      if attributes.is_a?(Array)\n        attributes.collect { |attr| create(attr, &block) }\n      else\n        block = _deprecated_scope_block(\"create\", &block)\n        scoping { klass.create(attributes, &block) }\n      end\n    end", "label": 4}
{"code": "public static function getDateIntervalSpec(DateInterval $interval)\n    {\n        $date = array_filter([\n            static::PERIOD_YEARS => abs($interval->y),\n            static::PERIOD_MONTHS => abs($interval->m),\n            static::PERIOD_DAYS => abs($interval->d),\n        ]);\n\n        $time = array_filter([\n            static::PERIOD_HOURS => abs($interval->h),\n            static::PERIOD_MINUTES => abs($interval->i),\n            static::PERIOD_SECONDS => abs($interval->s),\n        ]);\n\n        $specString = static::PERIOD_PREFIX;\n\n        foreach ($date as $key => $value) {\n            $specString .= $value.$key;\n        }\n\n        if (count($time) > 0) {\n            $specString .= static::PERIOD_TIME_PREFIX;\n            foreach ($time as $key => $value) {\n                $specString .= $value.$key;\n            }\n        }\n\n        return $specString === static::PERIOD_PREFIX ? 'PT0S' : $specString;\n    }", "label": 2}
{"code": "public function setDebuggees($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Debugger\\V2\\Debuggee::class);\n        $this->debuggees = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function(params) {\n    const order = this;\n\n    if (!params) {\n        params = {};\n    }\n\n    // the standards attributes\n    this.id = params.id;\n    this.dateCreated = params.dateCreated;\n    this.lastUpdated = params.lastUpdated;\n    this.version = params.version;\n\n    this.customer = params.customer;\n    this.orderDate = params.orderDate;\n    this.total = params.total;\n\n    this.items = params.items;\n\n    this.calcTotal = function() {\n        order.total = 0;\n\n        order.items.forEach(function(item) {\n            order.total += item.price;\n        });\n\n        return order.total;\n    };\n}", "label": 3}
{"code": "public function toArray()\n    {\n        $state = [\n            $this->key,\n            $this->current ? $this->current->copy() : null,\n            $this->validationResult,\n        ];\n\n        $result = iterator_to_array($this);\n\n        [\n            $this->key,\n            $this->current,\n            $this->validationResult\n        ] = $state;\n\n        return $result;\n    }", "label": 2}
{"code": "func MsTables(db models.XODB, schema string, relkind string) ([]*models.Table, error) {\n\tvar err error\n\n\t// get the tables\n\trows, err := models.MsTables(db, schema, relkind)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// get the tables that have Identity included\n\tidentities, err := models.MsIdentities(db, schema)\n\tif err != nil {\n\t\t// Set it to an empty set on error.\n\t\tidentities = []*models.MsIdentity{}\n\t}\n\n\t// Add information about manual FK.\n\tvar tables []*models.Table\n\tfor _, row := range rows {\n\t\tmanualPk := true\n\t\t// Look for a match in the table name where it contains the identity\n\t\tfor _, identity := range identities {\n\t\t\tif identity.TableName == row.TableName {\n\t\t\t\tmanualPk = false\n\t\t\t}\n\t\t}\n\t\ttables = append(tables, &models.Table{\n\t\t\tTableName: row.TableName,\n\t\t\tType:      row.Type,\n\t\t\tManualPk:  manualPk,\n\t\t})\n\t}\n\n\treturn tables, nil\n}", "label": 5}
{"code": "func (a *CellView) SetCursorX(x int) {\n\ta.SetCursor(x, a.cursorY)\n}", "label": 5}
{"code": "def upload_watch_icon(app_version, upload_image)\n      raise \"app_version is required\" unless app_version\n      raise \"upload_image is required\" unless upload_image\n\n      du_client.upload_watch_icon(app_version, upload_image, content_provider_id, sso_token_for_image)\n    end", "label": 4}
{"code": "function relative(a, b, stat) {\n  if (typeof a !== 'string') {\n    throw new TypeError('relative expects a string.');\n  }\n\n  if (a == '' && !b) return a;\n\n  var len = arguments.length;\n  if (len === 1) {\n    b = a; a = process.cwd(); stat = null;\n  }\n\n  if (len === 2 && typeof b === 'boolean') {\n    b = a; a = process.cwd(); stat = true;\n  }\n\n  if (len === 2 && typeof b === 'object') {\n    stat = b; b = a; a = process.cwd();\n  }\n\n  var origB = b;\n\n  // see if a slash exists before normalizing\n  var slashA = endsWith(a, '/');\n  var slashB = endsWith(b, '/');\n\n  a = unixify(a);\n  b = unixify(b);\n\n  // if `a` had a slash, add it back\n  if (slashA) { a = a + '/'; }\n\n  if (isFile(a, stat)) {\n    a = path.dirname(a);\n  }\n\n  var res = path.relative(a, b);\n  if (res === '') {\n    return '.';\n  }\n\n  // if `b` originally had a slash, and the path ends\n  // with `b` missing a slash, then re-add the slash.\n  var noslash = trimEnd(origB, '/');\n  if (slashB && (res === noslash || endsWith(res, noslash))) {\n    res = res + '/';\n  }\n  return res;\n}", "label": 3}
{"code": "func (n *network) initSubnetSandbox(s *subnet, restore bool) error {\n\tbrName := n.generateBridgeName(s)\n\tvxlanName := n.generateVxlanName(s)\n\n\tif restore {\n\t\tif err := n.restoreSubnetSandbox(s, brName, vxlanName); err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\tif err := n.setupSubnetSandbox(s, brName, vxlanName); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\ts.vxlanName = vxlanName\n\ts.brName = brName\n\n\treturn nil\n}", "label": 5}
{"code": "function(viewId) {\n            var that = this;\n            var requirePath = this.convertViewIdToRequirePath(viewId);\n\n            return system.defer(function(dfd) {\n                system.acquire(requirePath).then(function(markup) {\n                    var element = that.processMarkup(markup);\n                    element.setAttribute('data-view', viewId);\n                    dfd.resolve(element);\n                }).fail(function(err){\n                        that.createFallbackView(viewId, requirePath, err).then(function(element){\n                            element.setAttribute('data-view', viewId);\n                            dfd.resolve(element);\n                        });\n                    });\n            }).promise();\n        }", "label": 3}
{"code": "def displ_iter(self, g_nums, ats_1, ats_2, invalid_error=False):\n        \"\"\" Iterator over indicated displacement vectors.\n\n        Displacements are in Bohrs as with :meth:`displ_single`.\n\n        See `above <toc-generators_>`_ for more information on\n        calling options.\n\n        Parameters\n        ----------\n        g_nums\n            |int| or length-R iterable |int| or |None| --\n            Index/indices of the desired geometry/geometries\n\n        ats_1\n            |int| or length-R iterable |int| or |None| --\n            Index/indices of the first atom(s)\n\n        ats_2\n            |int| or length-R iterable |int| or |None| --\n            Index/indices of the second atom(s)\n\n        invalid_error\n            |bool|, optional --\n            If |False| (the default), |None| values are returned for\n            results corresponding to invalid indices. If |True|,\n            exceptions are raised per normal.\n\n        Yields\n        ------\n        displ\n            |npfloat_| --\n            Displacement vector in Bohrs between each atom pair of |br|\n            `ats_1` :math:`\\\\rightarrow` `ats_2` from the corresponding\n            geometries of `g_nums`.\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an invalid (out-of-range) `g_num` or `at_#` is provided.\n\n        ~exceptions.ValueError\n            If all iterable objects are not the same length.\n\n        \"\"\"\n\n        # Import the tuple-generating function\n        from .utils import pack_tups\n\n        # Print the function inputs if debug mode is on\n        if _DEBUG:  # pragma: no cover\n            print(\"g_nums = {0}\".format(g_nums))\n            print(\"ats_1 = {0}\".format(ats_1))\n            print(\"ats_2 = {0}\".format(ats_2))\n        ## end if\n\n        # Perform the None substitution\n        arglist = self._none_subst(g_nums, ats_1, ats_2)\n\n        # Expand/pack the tuples from the inputs\n        tups = pack_tups(*arglist)\n\n        # Dump the results if debug mode is on\n        if _DEBUG:  # pragma: no cover\n            print(tups)\n        ## end if\n\n        # Construct the generator using the packed tuples.\n        for tup in tups:\n            yield self._iter_return(tup, self.displ_single, invalid_error)", "label": 1}
{"code": "def list(region, profile):\n    \"\"\"\n    List all the CloudFormation stacks in the given region.\n    \"\"\"\n    ini_data = {}\n    environment = {}\n\n    if region:\n        environment['region'] = region\n    else:\n        environment['region'] = find_myself()\n\n    if profile:\n        environment['profile'] = profile\n\n    ini_data['environment'] = environment\n    if start_list(ini_data):\n        sys.exit(0)\n    else:\n        sys.exit(1)", "label": 1}
{"code": "function (parametersList, parameters, section) {\n            if (parameters[section]) {\n                for (var name in parameters[section]) {\n                    var addCondition = parameters[section][name];\n                    if (parametersList[section] && parametersList[section][name]) {\n\n                        // Merge parameters attributes\n                        for (var attr in addCondition) {\n                            if (_.has(parametersList, [section, name, attr]) === false) {\n                                // Attribute does not exists -> add to list\n                                parametersList[section][name][attr] = addCondition[attr];\n                            } else {\n                                // Attribute already exists compare values\n                                if (_.isFunction(addCondition[attr])) {\n                                    addCondition[attr] = _functionName(addCondition[attr]);\n                                }\n\n                                if (JSON.stringify(parametersList[section][name][attr]) != JSON.stringify(addCondition[attr])) {\n                                    throw new Error(\"Precondition conflict: \" + preconditions[index].name + ' -> ' + preconditions[index].version + ' -> ' + preconditions[index].method + ' -> ' + attr + ':' + addCondition[attr] + ' ->  already defined in previous controller and value is mismatching');\n                                }\n                                else {\n                                    parametersList[section][name][attr] = addCondition[attr];\n                                }\n                            }\n                        }\n                    } else {\n                        parametersList[section] = parametersList[section] ? parametersList[section] : {};\n                        parametersList[section][name] = addCondition;\n                    }\n\n                    // Filter parameter attributes by allowedAttributes\n                    var validatedParameterAttributes = {};\n                    if (_.has(parametersList, [section, name])) {\n                        for (var attr in parametersList[section][name]) {\n                            validatedParameterAttributes[attr] = _removeAttributes(parametersList[section][name][attr], attr);\n                        }\n                    }\n\n                    if (!_.isEmpty(validatedParameterAttributes)) {\n                        parametersList[section][name] = validatedParameterAttributes;\n                    }\n                }\n            }\n            return parametersList;\n        }", "label": 3}
{"code": "public ResultSetAndStatement executeSQL(\r\n        final String sql,\r\n        ClassDescriptor cld,\r\n        ValueContainer[] values,\r\n        boolean scrollable)\r\n        throws PersistenceBrokerException\r\n    {\r\n        if (logger.isDebugEnabled()) logger.debug(\"executeSQL: \" + sql);\r\n        final boolean isStoredprocedure = isStoredProcedure(sql);\r\n        final StatementManagerIF sm = broker.serviceStatementManager();\r\n        PreparedStatement stmt = null;\r\n        ResultSet rs = null;\r\n        try\r\n        {\r\n            stmt = sm.getPreparedStatement(cld, sql,\r\n                    scrollable, StatementManagerIF.FETCH_SIZE_NOT_EXPLICITLY_SET, isStoredprocedure);\r\n            if (isStoredprocedure)\r\n            {\r\n                // Query implemented as a stored procedure, which must return a result set.\r\n                // Query sytax is: { ?= call PROCEDURE_NAME(?,...,?)}\r\n                getPlatform().registerOutResultSet((CallableStatement) stmt, 1);\r\n                sm.bindValues(stmt, values, 2);\r\n                stmt.execute();\r\n                rs = (ResultSet) ((CallableStatement) stmt).getObject(1);\r\n            }\r\n            else\r\n            {\r\n                sm.bindValues(stmt, values, 1);\r\n                rs = stmt.executeQuery();\r\n            }\r\n\r\n            // as we return the resultset for further operations, we cannot release the statement yet.\r\n            // that has to be done by the JdbcAccess-clients (i.e. RsIterator, ProxyRsIterator and PkEnumeration.)\r\n            return new ResultSetAndStatement(sm, stmt, rs, new SelectStatement()\r\n            {\r\n                public Query getQueryInstance()\r\n                {\r\n                    return null;\r\n                }\r\n\r\n                public int getColumnIndex(FieldDescriptor fld)\r\n                {\r\n                    return JdbcType.MIN_INT;\r\n                }\r\n\r\n                public String getStatement()\r\n                {\r\n                    return sql;\r\n                }\r\n            });\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            // release resources on exception\r\n            sm.closeResources(stmt, rs);\r\n            logger.error(\"PersistenceBrokerException during the execution of the SQL query: \" + e.getMessage(), e);\r\n            throw e;\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            // release resources on exception\r\n            sm.closeResources(stmt, rs);\r\n            throw ExceptionHelper.generateException(e, sql, cld, values, logger, null);\r\n        }\r\n    }", "label": 0}
{"code": "public static base_response update(nitro_service client, dbdbprofile resource) throws Exception {\n\t\tdbdbprofile updateresource = new dbdbprofile();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.interpretquery = resource.interpretquery;\n\t\tupdateresource.stickiness = resource.stickiness;\n\t\tupdateresource.kcdaccount = resource.kcdaccount;\n\t\tupdateresource.conmultiplex = resource.conmultiplex;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function callError($id, $errorUri, $desc = '', $details = null) {\n        if ($errorUri instanceof Topic) {\n            $errorUri = (string)$errorUri;\n        }\n\n        $data = array(WAMP::MSG_CALL_ERROR, $id, $errorUri, $desc);\n\n        if (null !== $details) {\n            $data[] = $details;\n        }\n\n        return $this->send(json_encode($data));\n    }", "label": 2}
{"code": "func (f *file) isUntypedConst(expr ast.Expr) (defType string, ok bool) {\n\t// Re-evaluate expr outside of its context to see if it's untyped.\n\t// (An expr evaluated within, for example, an assignment context will get the type of the LHS.)\n\texprStr := f.render(expr)\n\ttv, err := types.Eval(f.fset, f.pkg.typesPkg, expr.Pos(), exprStr)\n\tif err != nil {\n\t\treturn \"\", false\n\t}\n\tif b, ok := tv.Type.(*types.Basic); ok {\n\t\tif dt, ok := basicTypeKinds[b.Kind()]; ok {\n\t\t\treturn dt, true\n\t\t}\n\t}\n\n\treturn \"\", false\n}", "label": 5}
{"code": "public static policyexpression get(nitro_service service, String name) throws Exception{\n\t\tpolicyexpression obj = new policyexpression();\n\t\tobj.set_name(name);\n\t\tpolicyexpression response = (policyexpression) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (file, unused, cb) {\n    if (file.isNull()) {\n      // nothing to do\n      return cb(null, file)\n    } else if (file.isStream()) {\n      // file.contents is a Stream.  We don't support streams\n      this.emit('error', new PluginError(PLUGIN_NAME, 'Streams not supported!'))\n    } else if (file.isBuffer()) {\n      // lazy init the acss class\n      if (!acss) {\n        acss = new Atomizer()\n\n        if (addRules) {\n          acss.addRules(addRules)\n        }\n      }\n\n      // generate the class names and push them into the global collector array\n      var html = String(file.contents)\n      var classes = acss.findClassNames(html)\n      foundClasses = Array.prototype.concat(foundClasses, classes)\n\n      // make a note of this file if it's the newer than we've seen before\n      if (!latestMod || file.stat && file.stat.mtime > latestMod) {\n        latestFile = file\n        latestMod = file.stat && file.stat.mtime\n      }\n\n      // tell the engine we're done\n      cb()\n    }\n  }", "label": 3}
{"code": "public SqlStatement getPreparedDeleteStatement(Query query, ClassDescriptor cld)\r\n    {\r\n        return new SqlDeleteByQuery(m_platform, cld, query, logger);\r\n    }", "label": 0}
{"code": "public function start(): void\n    {\n        // In case Lambda stopped our process (e.g. because of a timeout) we need to make sure PHP-FPM has stopped\n        // as well and restart it\n        if ($this->isReady()) {\n            $this->killExistingFpm();\n        }\n\n        if (! is_dir(dirname(self::SOCKET))) {\n            mkdir(dirname(self::SOCKET));\n        }\n\n        /**\n         * --nodaemonize: we want to keep control of the process\n         * --force-stderr: force logs to be sent to stderr, which will allow us to send them to CloudWatch\n         */\n        $this->fpm = new Process(['php-fpm', '--nodaemonize', '--force-stderr', '--fpm-config', $this->configFile]);\n        $this->fpm->setTimeout(null);\n        $this->fpm->start(function ($type, $output): void {\n            // Send any PHP-FPM log to CloudWatch\n            echo $output;\n        });\n\n        $connection = new UnixDomainSocket(self::SOCKET, 1000, 30000);\n        $this->client = new Client($connection);\n\n        $this->waitUntilReady();\n    }", "label": 2}
{"code": "def coord(col, row=0)\n      coordinates = parse_coord_args(col, row)\n      self.col = coordinates[0]\n      self.row = coordinates[1]\n    end", "label": 4}
{"code": "public function setCropHintsAnnotation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\CropHintsAnnotation::class);\n        $this->crop_hints_annotation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def build_board_2048():\n    \"\"\" builds a 2048 starting board \n    Printing Grid\n     0     0     0     2\n     0     0     4     0\n     0     0     0     0\n     0     0     0     0\n\n    \"\"\"\n    grd = Grid(4,4, [2,4])\n    grd.new_tile()\n    grd.new_tile()\n    print(grd)\n    return grd", "label": 1}
{"code": "public function put(array $item, $table = null)\n    {\n        $this->queue[] = [\n            'table' => $this->determineTable($table),\n            'data'  => ['PutRequest' => ['Item' => $item]],\n        ];\n\n        $this->autoFlush();\n\n        return $this;\n    }", "label": 2}
{"code": "def etag_matches?(list, new_resource = request.post?)\n      return !new_resource if list == '*'\n      list.to_s.split(/\\s*,\\s*/).include? response['ETag']\n    end", "label": 4}
{"code": "function wrap(fn, before, after, advisor) {\n    var ignoredKeys = { prototype: 1 };\n\n    function wrapper() {\n      var _before = wrapper[BEFORE],\n          bLen    = _before.length,\n          _after  = wrapper[AFTER],\n          aLen    = _after.length,\n          _fn     = wrapper[ORIGIN],\n          ret, r;\n\n      // Invoke before, if it returns { $skip: true } then skip fn() and after() and returns $data\n      while (bLen--) {\n        r = _before[bLen].apply(this, arguments);\n        if (mapOrNil(r) && r.$skip === true) {\n          return r.$data;\n        }\n      }\n\n      // Invoke fn, save return value\n      ret = _fn.apply(this, arguments);\n\n      while (aLen--) {\n        r = _after[aLen].apply(this, arguments);\n        if (mapOrNil(r) && r.$skip === true) {\n          return ret;\n        }\n      }\n      return ret;\n    }\n\n    // wrapper exists? reuse it\n    if (fn[WRAPPER] === fn) {\n      fn[BEFORE].push(before);\n      fn[AFTER].push(after);\n      fn[ADVISOR].push(advisor);\n      return fn;\n    }\n\n    // create a reusable wrapper structure\n    extend(wrapper, fn, 0, true);\n    if (classOrNil(fn)) {\n      wrapper.prototype = fn.prototype;\n\n      // this destroys the origin of wrapper[ORIGIN], in theory, prototype.constructor should point\n      // to the class constructor itself, but it's no harm to not let that happen\n      // wrapper.prototype.constructor = wrapper;\n    }\n\n    wrapper[BEFORE]  = [ before ];\n    wrapper[AFTER]   = [ after ];\n    wrapper[ORIGIN]  = fn;\n    wrapper[ADVISOR] = [ advisor ];\n    wrapper[WRAPPER] = wrapper;\n    wrapper.$super   = fn.$super;\n    wrapper.$superp  = fn.$superp;\n    return wrapper;\n  }", "label": 3}
{"code": "def _process_options(options)\n        status, content_type, location = options.values_at(:status, :content_type, :location)\n\n        self.status = status if status\n        self.content_type = content_type if content_type\n        headers[\"Location\"] = url_for(location) if location\n\n        super\n      end", "label": 4}
{"code": "public static boolean containsOnlyNull(Object... values){\t\n\t\tfor(Object o : values){\n\t\t\tif(o!= null){\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "label": 0}
{"code": "public function updateBreakpointBatch(array $breakpoints, array $options = [])\n    {\n        foreach ($breakpoints as $breakpoint) {\n            $this->updateBreakpoint($breakpoint, $options);\n        }\n    }", "label": 2}
{"code": "func PgIndexColumns(db XODB, schema string, index string) ([]*IndexColumn, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`(row_number() over()), ` + // ::integer AS seq_no\n\t\t`a.attnum, ` + // ::integer AS cid\n\t\t`a.attname ` + // ::varchar AS column_name\n\t\t`FROM pg_index i ` +\n\t\t`JOIN ONLY pg_class c ON c.oid = i.indrelid ` +\n\t\t`JOIN ONLY pg_namespace n ON n.oid = c.relnamespace ` +\n\t\t`JOIN ONLY pg_class ic ON ic.oid = i.indexrelid ` +\n\t\t`LEFT JOIN pg_attribute a ON i.indrelid = a.attrelid AND a.attnum = ANY(i.indkey) AND a.attisdropped = false ` +\n\t\t`WHERE i.indkey <> '0' AND n.nspname = $1 AND ic.relname = $2`\n\n\t// run query\n\tXOLog(sqlstr, schema, index)\n\tq, err := db.Query(sqlstr, schema, index)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*IndexColumn{}\n\tfor q.Next() {\n\t\tic := IndexColumn{}\n\n\t\t// scan\n\t\terr = q.Scan(&ic.SeqNo, &ic.Cid, &ic.ColumnName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ic)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "function addToChai(names, fn){\n\tfor(const name of names)\n\t\tChai.Assertion.addMethod(name, fn);\n}", "label": 3}
{"code": "def unmapped(sam, mates):\n    \"\"\"\n    get unmapped reads\n    \"\"\"\n    for read in sam:\n        if read.startswith('@') is True:\n            continue\n        read = read.strip().split()\n        if read[2] == '*' and read[6] == '*':\n                yield read\n        elif mates is True:\n            if read[2] == '*' or read[6] == '*':\n                yield read\n            for i in read:\n                if i == 'YT:Z:UP':\n                    yield read", "label": 1}
{"code": "public static void registerAgent(Agent agent, String serviceName, String serviceType) throws FIPAException{\n        DFAgentDescription dfd = new DFAgentDescription();\n        ServiceDescription sd = new ServiceDescription();\n        \n        sd.setType(serviceType);\n        sd.setName(serviceName);\n        \n        //NOTE El serviceType es un string que define el tipo de servicio publicado en el DF por el Agente X. \n        //     He escogido crear nombres en clave en jade.common.Definitions para este campo. \n        //NOTE El serviceName es el nombre efectivo del servicio. \n        //     Esto es lo que el usuario va a definir en MockConfiguration.DFNameService y no el tipo como estaba puesto. \n        //        sd.setType(agentType);\n        //        sd.setName(agent.getLocalName());\n        \n        //Add services??\n        \n        // Sets the agent description\n        dfd.setName(agent.getAID());\n        dfd.addServices(sd);\n        \n        // Register the agent\n        DFService.register(agent, dfd);\n    }", "label": 0}
{"code": "def max_staleness(value)\n      if /\\A\\d+\\z/ =~ value\n        int = value.to_i\n\n        if int >= 0 && int < 90\n          log_warn(\"max staleness must be either 0 or greater than 90: #{value}\")\n        end\n\n        return int\n      end\n\n      log_warn(\"Invalid max staleness value: #{value}\")\n      nil\n    end", "label": 4}
{"code": "public static base_responses add(nitro_service client, cmppolicylabel resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcmppolicylabel addresources[] = new cmppolicylabel[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new cmppolicylabel();\n\t\t\t\taddresources[i].labelname = resources[i].labelname;\n\t\t\t\taddresources[i].type = resources[i].type;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func NewRegistry() *Registry {\n\tr := &Registry{\n\t\tobjects:  make(map[types.ManagedObjectReference]mo.Reference),\n\t\thandlers: make(map[types.ManagedObjectReference]RegisterObject),\n\t\tlocks:    make(map[types.ManagedObjectReference]sync.Locker),\n\n\t\tNamespace: vim25.Namespace,\n\t\tPath:      vim25.Path,\n\t}\n\n\treturn r\n}", "label": 5}
{"code": "public function setRemovedTargetIds($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::INT32);\n        $this->removed_target_ids = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private void srand(int ijkl) {\n        u = new double[97];\n\n        int ij = ijkl / 30082;\n        int kl = ijkl % 30082;\n\n        // Handle the seed range errors\n        // First random number seed must be between 0 and 31328\n        // Second seed must have a value between 0 and 30081\n        if (ij < 0 || ij > 31328 || kl < 0 || kl > 30081) {\n            ij = ij % 31329;\n            kl = kl % 30082;\n        }\n\n        int i = ((ij / 177) % 177) + 2;\n        int j = (ij % 177) + 2;\n        int k = ((kl / 169) % 178) + 1;\n        int l = kl % 169;\n\n        int m;\n        double s, t;\n        for (int ii = 0; ii < 97; ii++) {\n            s = 0.0;\n            t = 0.5;\n            for (int jj = 0; jj < 24; jj++) {\n                m = (((i * j) % 179) * k) % 179;\n                i = j;\n                j = k;\n                k = m;\n                l = (53 * l + 1) % 169;\n                if (((l * m) % 64) >= 32) {\n                    s += t;\n                }\n                t *= 0.5;\n            }\n            u[ii] = s;\n        }\n\n        c = 362436.0 / 16777216.0;\n        cd = 7654321.0 / 16777216.0;\n        cm = 16777213.0 / 16777216.0;\n        i97 = 96;\n        j97 = 32;\n    }", "label": 0}
{"code": "def create(*args)\n      raise_authentication_error unless authenticated?\n      arguments(args, required: [:client_id])\n\n      if arguments.client_id\n        put_request(\"/authorizations/clients/#{arguments.client_id}\", arguments.params)\n      else\n        raise raise_app_authentication_error\n      end\n    end", "label": 4}
{"code": "def types_for_check(data)\n      exclude_list = PhoneAnalyzer::NOT_FOR_CHECK\n      exclude_list += Phonelib::Core::SHORT_CODES unless Phonelib.parse_special\n      Core::TYPES_DESC.keys - exclude_list + fixed_and_mobile_keys(data)\n    end", "label": 4}
{"code": "def main_loop\n      debug(\"Entering request handler main loop\")\n      reset_signal_handlers\n      begin\n        @graceful_termination_pipe = IO.pipe\n        @graceful_termination_pipe[0].close_on_exec!\n        @graceful_termination_pipe[1].close_on_exec!\n\n        @main_loop_thread_lock.synchronize do\n          @main_loop_generation += 1\n          @main_loop_running = true\n          @main_loop_thread_cond.broadcast\n\n          @select_timeout = nil\n\n          @selectable_sockets = []\n          @server_sockets.each_value do |value|\n            socket = value[2]\n            @selectable_sockets << socket if socket\n          end\n          @selectable_sockets << @owner_pipe\n          @selectable_sockets << @graceful_termination_pipe[0]\n        end\n\n        install_useful_signal_handlers\n        start_threads\n        wait_until_termination_requested\n        wait_until_all_threads_are_idle\n        terminate_threads\n        debug(\"Request handler main loop exited normally\")\n\n      rescue EOFError\n        # Exit main loop.\n        trace(2, \"Request handler main loop interrupted by EOFError exception\")\n      rescue Interrupt\n        # Exit main loop.\n        trace(2, \"Request handler main loop interrupted by Interrupt exception\")\n      rescue SignalException => signal\n        trace(2, \"Request handler main loop interrupted by SignalException\")\n        if signal.message != HARD_TERMINATION_SIGNAL\n          raise\n        end\n      rescue Exception => e\n        trace(2, \"Request handler main loop interrupted by #{e.class} exception\")\n        raise\n      ensure\n        debug(\"Exiting request handler main loop\")\n        revert_signal_handlers\n        @main_loop_thread_lock.synchronize do\n          @graceful_termination_pipe[1].close rescue nil\n          @graceful_termination_pipe[0].close rescue nil\n          @selectable_sockets = []\n          @main_loop_generation += 1\n          @main_loop_running = false\n          @main_loop_thread_cond.broadcast\n        end\n      end\n    end", "label": 4}
{"code": "def template_body\n      custom_template = \"#{Ufo.root}/.ufo/settings/cfn/stack.yml\"\n      path = if File.exist?(custom_template)\n               custom_template\n             else\n               # built-in default\n               File.expand_path(\"../cfn/stack.yml\", File.dirname(__FILE__))\n             end\n      RenderMePretty.result(path, context: context.scope)\n    end", "label": 4}
{"code": "def init(app_name=\"rake\", argv = ARGV)\n      standard_exception_handling do\n        @name = app_name\n        begin\n          args = handle_options argv\n        rescue ArgumentError\n          # Backward compatibility for capistrano\n          args = handle_options\n        end\n        collect_command_line_tasks(args)\n      end\n    end", "label": 4}
{"code": "func (c Common) Name() string {\n\tif c.InventoryPath == \"\" {\n\t\treturn \"\"\n\t}\n\treturn path.Base(c.InventoryPath)\n}", "label": 5}
{"code": "def get_xml_stats(fname):\n    \"\"\"\n    return a dictionary of statistics about an \n    XML file including size in bytes, num lines,\n    number of elements, count by elements\n    \"\"\"\n    f = mod_file.TextFile(fname)\n    res = {}\n    res['shortname'] = f.name\n    res['folder'] = f.path\n    res['filesize'] = str(f.size) + ' bytes'\n    res['num_lines'] = str(f.lines) + ' lines'\n    res['date_modified'] = f.GetDateAsString(f.date_modified)\n    \n    return res", "label": 1}
{"code": "public function analyzeSyntax($content, array $options = [])\n    {\n        $syntaxResponse = $this->connection->analyzeSyntax(\n            $this->formatRequest($content, $options)\n        );\n\n        return new Annotation($syntaxResponse + ['entities' => []]);\n    }", "label": 2}
{"code": "protected static final String formatUsingFormat(Long value, DateTimeFormat fmt) {\n        if (value == null) {\n            return \"\";\n        }\n        else {\n            // midnight GMT\n            Date date = new Date(0);\n            // offset by timezone and value\n            date.setTime(UTCDateBox.timezoneOffsetMillis(date) + value.longValue());\n            // format it\n            return fmt.format(date);\n        }\n    }", "label": 0}
{"code": "def save_filelist(self, opFile, opFormat, delim=',', qu='\"'):\r\n        \"\"\"\r\n        uses a List of files and collects meta data on them and saves\r\n        to an text file as a list or with metadata depending on opFormat.\r\n        \"\"\"\r\n\r\n        op_folder = os.path.dirname(opFile)\r\n        if op_folder is not None:   # short filename passed\r\n            if not os.path.exists(op_folder):\r\n                os.makedirs(op_folder)\r\n\r\n\r\n        with open(opFile,'w') as fout:\r\n            fout.write(\"fullFilename\" + delim)\r\n            for colHeading in opFormat:\r\n                fout.write(colHeading + delim)\r\n            fout.write('\\n')\r\n            for f in self.filelist:\r\n                line = qu + f + qu + delim\r\n                try:\r\n                    for fld in opFormat:\r\n                        if fld == \"name\":\r\n                            line = line + qu + os.path.basename(f) + qu + delim\r\n                        if fld == \"date\":\r\n                            line = line + qu + self.GetDateAsString(f) + qu + delim\r\n                        if fld == \"size\":\r\n                            line = line + qu + str(os.path.getsize(f)) + qu + delim\r\n                        if fld == \"path\":\r\n                            line = line + qu + os.path.dirname(f) + qu + delim\r\n                except IOError:\r\n                    line += '\\n'   # no metadata\r\n                try:\r\n                    fout.write (str(line.encode('ascii', 'ignore').decode('utf-8')))\r\n                    fout.write ('\\n')\r\n                except IOError:\r\n                    #print(\"Cant print line - cls_filelist line 304\")\r\n                    pass", "label": 1}
{"code": "public static appfwconfidfield[] get(nitro_service service) throws Exception{\n\t\tappfwconfidfield obj = new appfwconfidfield();\n\t\tappfwconfidfield[] response = (appfwconfidfield[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private static String makeAsciiTableCell(Object obj, int padLeft, int padRight, boolean tsv) {\r\n    String result = obj.toString();\r\n    if (padLeft > 0) {\r\n      result = padLeft(result, padLeft);\r\n    }\r\n    if (padRight > 0) {\r\n      result = pad(result, padRight);\r\n    }\r\n    if (tsv) {\r\n      result = result + '\\t';\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "public static lbroute[] get(nitro_service service) throws Exception{\n\t\tlbroute obj = new lbroute();\n\t\tlbroute[] response = (lbroute[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static function slug($str)\n    {\n        $str = strtolower($str);\n        $str = preg_replace('/[^a-z0-9]/i', '-', $str);\n        $str = preg_replace('/-+/', '-', $str);\n        $str = preg_replace('/-$|^-/', '', $str);\n\n        return $str;\n    }", "label": 2}
{"code": "public function setDesiredNodePoolAutoscaling($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\NodePoolAutoscaling::class);\n        $this->desired_node_pool_autoscaling = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function matchObj(obj, line) {\n        for (const p in obj) if (obj[p] && obj[p].test(line)) return p;\n        return \"\";\n    }", "label": 3}
{"code": "public function setTier($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Redis\\V1beta1\\Instance_Tier::class);\n        $this->tier = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setTranslation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\TranslationAnnotation::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def _login(self):\n        \"\"\"\n        LOGIN CAN ONLY BE DONE BY POSTING TO A HTTP FORM.\n        A COOKIE IS THEN USED FOR INTERACTING WITH THE API\n        \"\"\"\n        self.logger.debug(\"Logging into \" + \"{}/{}\".format(self._im_api_url, \"j_spring_security_check\"))\n        self._im_session.headers.update({'Content-Type':'application/x-www-form-urlencoded', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.99 Safari/537.36'})\n        #self._im_session.mount('https://', TLS1Adapter())\n        #self._im_verify_ssl = False\n        self.j_username = self._username\n        self.j_password = self._password\n        requests.packages.urllib3.disable_warnings() # Disable unverified connection warning.\n        payload = {'j_username': self.j_username, 'j_password': self.j_password, 'submit':'Login'}\n        \n        # login to ScaleIO IM\n        r = self._im_session.post(\n            \"{}/{}\".format(self._im_api_url,\"j_spring_security_check\"),\n            verify=self._im_verify_ssl,\n            #headers = {'Content-Type':'application/x-www-form-urlencoded', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.99 Safari/537.36'},\n            data=payload)\n        self.logger.debug(\"Login POST response: \" + \"{}\".format(r.text))\n\n        self._im_logged_in = True\n        \n        \"\"\"\n        ADD CODE:\n        Check if this is IM have existing configuration. If so populate ScaleIO_configurtion_object\n        \"\"\"", "label": 1}
{"code": "def extension\n      copy_file 'extension/gitignore', File.join(name, '.gitignore') unless options[:'skip-git']\n      template 'extension/Rakefile', File.join(name, 'Rakefile')\n      template 'extension/gemspec', File.join(name, \"#{name}.gemspec\")\n      template 'extension/Gemfile', File.join(name, 'Gemfile')\n      template 'extension/lib/lib.rb', File.join(name, 'lib', \"#{name}.rb\")\n      template 'extension/lib/lib/extension.rb', File.join(name, 'lib', name, 'extension.rb')\n      template 'extension/features/support/env.rb', File.join(name, 'features', 'support', 'env.rb')\n      empty_directory File.join(name, 'fixtures')\n    end", "label": 4}
{"code": "def _iop(self, operation, other, *allowed):\n\t\t\"\"\"An iterative operation operating on multiple values.\n\t\t\n\t\tConsumes iterators to construct a concrete list at time of execution.\n\t\t\"\"\"\n\t\t\n\t\tf = self._field\n\t\t\n\t\tif self._combining:  # We are a field-compound query fragment, e.g. (Foo.bar & Foo.baz).\n\t\t\treturn reduce(self._combining,\n\t\t\t\t\t(q._iop(operation, other, *allowed) for q in f))  # pylint:disable=protected-access\n\t\t\n\t\t# Optimize this away in production; diagnosic aide.\n\t\tif __debug__ and _complex_safety_check(f, {operation} | set(allowed)):  # pragma: no cover\n\t\t\traise NotImplementedError(\"{self!r} does not allow {op} comparison.\".format(\n\t\t\t\t\tself=self, op=operation))\n\t\t\n\t\tdef _t(o):\n\t\t\tfor value in o:\n\t\t\t\tyield None if value is None else f.transformer.foreign(value, (f, self._document))\n\t\t\n\t\tother = other if len(other) > 1 else other[0]\n\t\tvalues = list(_t(other))\n\t\t\n\t\treturn Filter({self._name: {operation: values}})", "label": 1}
{"code": "func (s *parentStack) trim(parents []string) error {\n\tsplit := 0\n\tfor ; split < len(parents) && split < len(s.stack); split++ {\n\t\tif parents[split] != s.stack[split] {\n\t\t\tbreak\n\t\t}\n\t}\n\tfor i := len(s.stack) - 1; i >= split; i-- {\n\t\tif err := s.p.writeEnd(Name{Local: s.stack[i]}); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\ts.stack = parents[:split]\n\treturn nil\n}", "label": 5}
{"code": "def assign(list)\n      unless list.is_a?(TopicPartitionList)\n        raise TypeError.new(\"list has to be a TopicPartitionList\")\n      end\n      tpl = list.to_native_tpl\n      response = Rdkafka::Bindings.rd_kafka_assign(@native_kafka, tpl)\n      if response != 0\n        raise Rdkafka::RdkafkaError.new(response, \"Error assigning '#{list.to_h}'\")\n      end\n    end", "label": 4}
{"code": "public function setResource($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Asset\\V1beta1\\Resource::class);\n        $this->resource = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func printIdentities(entity *openpgp.Entity) {\n\tlines := []string{\"signature verified:\"}\n\tfor _, v := range entity.Identities {\n\t\tlines = append(lines, fmt.Sprintf(\"  %s\", v.Name))\n\t}\n\tlog.Print(strings.Join(lines, \"\\n\"))\n}", "label": 5}
{"code": "private function formatName($type, $name, $projectId = null)\n    {\n        if (!isset($this->templates[$type])) {\n            throw new InvalidArgumentException(sprintf(\n                'Template `%s` is not defined',\n                $type\n            ));\n        }\n\n        return vsprintf($this->templates[$type], [$name, $projectId]);\n    }", "label": 2}
{"code": "def ocsp_no_check(self, value):\n        \"\"\"\n        A bool - if the certificate should have the OCSP no check extension.\n        Only applicable to certificates created for signing OCSP responses.\n        Such certificates should normally be issued for a very short period of\n        time since they are effectively whitelisted by clients.\n        \"\"\"\n\n        if value is None:\n            self._ocsp_no_check = None\n        else:\n            self._ocsp_no_check = bool(value)", "label": 1}
{"code": "async function connectUser(form) {\n  if (!form.login.value || !form.password.value) {\n    document.getElementById('login-errors').innerHTML += `<p>Login and password are required</p>`;\n    return;\n  }\n\n  await client.setCredentials({ login: form.login.value, password: form.password.value });\n  client\n    .connect()\n    .then(() => {\n      displayMessage('Login success', 'Welcome to wonderful service', 'is-success');\n      goTo('home');\n    })\n    .catch((e) => {\n      displayMessage(\n        'Login failed',\n        'Your account is not validated, have you clicked on the link in the email ?',\n        'is-warning'\n      );\n    });\n}", "label": 3}
{"code": "def set_role_id(name, role_id)\n      options = { role_id: role_id }\n      client.post(\"/v1/auth/approle/role/#{encode_path(name)}/role-id\", JSON.fast_generate(options))\n      return true\n    end", "label": 4}
{"code": "def resume(topic, partition)\n      pause_for(topic, partition).resume!\n\n      # During re-balancing we might have lost the paused partition. Check if partition is still in group before seek.\n      seek_to_next(topic, partition) if @group.assigned_to?(topic, partition)\n    end", "label": 4}
{"code": "public static appfwprofile_safeobject_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappfwprofile_safeobject_binding obj = new appfwprofile_safeobject_binding();\n\t\tobj.set_name(name);\n\t\tappfwprofile_safeobject_binding response[] = (appfwprofile_safeobject_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void addColumnPair(String localColumn, String remoteColumn)\r\n    {\r\n        if (!_localColumns.contains(localColumn))\r\n        {    \r\n            _localColumns.add(localColumn);\r\n        }\r\n        if (!_remoteColumns.contains(remoteColumn))\r\n        {    \r\n            _remoteColumns.add(remoteColumn);\r\n        }\r\n    }", "label": 0}
{"code": "def colorize(str, sev: :normal_s)\n      return str unless color_enabled?\n\n      cc = COLOR_CODE\n      color = cc.key?(sev) ? cc[sev] : ''\n      \"#{color}#{str.sub(cc[:esc_m], color)}#{cc[:esc_m]}\"\n    end", "label": 4}
{"code": "function removeTrailingLinebreaks(text) {\n    let linebreak = determineLinebreaks(text);\n    if (linebreak === \"\") return text;\n\n    while (text.endsWith(linebreak)) {\n        text = text.slice(0, 0 - linebreak.length);\n    }\n\n    return text;\n}", "label": 3}
{"code": "def solve(self, max_worlds=10000, silent=False):\n        \"\"\"\n        find the best world to make people happy\n        \"\"\"\n        self.num_worlds = 0\n        num_unhappy = 0\n        for tax_rate in range(self.tax_range[0],self.tax_range[1]):\n            for equity in range(self.equity_range[0],self.equity_range[1]):\n                for tradition in range(self.tradition_range[0],self.tradition_range[1]):\n                    self.num_worlds += 1\n                    if self.num_worlds > max_worlds:\n                        break\n                    w = World(str(self.num_worlds).zfill(6), [5000, tax_rate/10, tradition/10, equity/10])\n                    world_happiness = 0\n                    num_unhappy = 0\n                    for person in self.all_people:\n                        wh = Happiness(person, w)\n                        world_happiness += wh.rating\n                        if wh.rating < 0:\n                            num_unhappy += 1\n                    if world_happiness > self.net_happiness:\n                        self.net_happiness = world_happiness\n                        self.unhappy_people = num_unhappy\n                        if not silent:\n                            print('found better world - ' + w.nme + ' = ' + str(world_happiness) + ' - total unhappy_people = ' + str(self.unhappy_people))", "label": 1}
{"code": "function appendModelPath (modelPath, id, internal) {\n  const addedModelPath = getModelPath(id)\n  if (internal) {\n    if (modelPath === '') {\n      return `properties._internal.${addedModelPath}`\n    }\n    return `${modelPath}.properties._internal.${addedModelPath}`\n  }\n  if (modelPath === '') {\n    return addedModelPath\n  }\n  return `${modelPath}.${addedModelPath}`\n}", "label": 3}
{"code": "def preserve(input = nil, &block)\n      return preserve(capture_haml(&block)) if block\n      s = input.to_s.chomp(\"\\n\")\n      s.gsub!(/\\n/, '&#x000A;')\n      s.delete!(\"\\r\")\n      s\n    end", "label": 4}
{"code": "def sum(context, key, value, multiplier=1):\n    \"\"\"\n    Adds the given value to the total value currently held in ``key``.\n\n    Use the multiplier if you want to turn a positive value into a negative\n    and actually substract from the current total sum.\n\n    Usage::\n\n        {% sum \"MY_TOTAL\" 42 -1 %}\n        {{ MY_TOTAL }}\n\n    \"\"\"\n    if key not in context.dicts[0]:\n        context.dicts[0][key] = 0\n    context.dicts[0][key] += value * multiplier\n    return ''", "label": 1}
{"code": "function(loader, packageJSON, isRoot){\n\t\tvar deps = crawl.getDependencyMap(loader, packageJSON, isRoot);\n\n\t\tvar dependencies = [];\n\t\tfor(var name in deps) {\n\t\t\tdependencies.push(deps[name]);\n\t\t}\n\n\t\treturn dependencies;\n\t}", "label": 3}
{"code": "public void scale(double v){\n\t\tfor(int i = 0; i < this.size(); i++){\n\t\t\tthis.get(i).scale(v);;\n\t\t}\n\t}", "label": 0}
{"code": "def __end_of_list(self, ast_token):\n        \"\"\"Handle end of a list.\"\"\"\n        self.list_level -= 1\n        if self.list_level == 0:\n            if self.list_entry is not None:\n                self.final_ast_tokens.append(self.list_entry)\n                self.list_entry = None\n            self.final_ast_tokens.append(ast_token)", "label": 1}
{"code": "func (h *Handler) ensureBucket() error {\n\t_, err := h.client.HeadBucket(&s3.HeadBucketInput{\n\t\tBucket: aws.String(h.Bucket),\n\t})\n\terr = ConvertS3Error(err)\n\t// assumes that bucket is administered by other entity\n\tif err == nil {\n\t\treturn nil\n\t}\n\tif !trace.IsNotFound(err) {\n\t\treturn trace.Wrap(err)\n\t}\n\tinput := &s3.CreateBucketInput{\n\t\tBucket: aws.String(h.Bucket),\n\t\tACL:    aws.String(\"private\"),\n\t}\n\t_, err = h.client.CreateBucket(input)\n\terr = ConvertS3Error(err, \"bucket %v already exists\", aws.String(h.Bucket))\n\tif err != nil {\n\t\tif !trace.IsAlreadyExists(err) {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\t// if this client has not created the bucket, don't reconfigure it\n\t\treturn nil\n\t}\n\t// turn on versioning\n\tver := &s3.PutBucketVersioningInput{\n\t\tBucket: aws.String(h.Bucket),\n\t\tVersioningConfiguration: &s3.VersioningConfiguration{\n\t\t\tStatus: aws.String(\"Enabled\"),\n\t\t},\n\t}\n\t_, err = h.client.PutBucketVersioning(ver)\n\terr = ConvertS3Error(err, \"failed to set versioning state for bucket %q\", h.Bucket)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t_, err = h.client.PutBucketEncryption(&s3.PutBucketEncryptionInput{\n\t\tBucket: aws.String(h.Bucket),\n\t\tServerSideEncryptionConfiguration: &s3.ServerSideEncryptionConfiguration{\n\t\t\tRules: []*s3.ServerSideEncryptionRule{&s3.ServerSideEncryptionRule{\n\t\t\t\tApplyServerSideEncryptionByDefault: &s3.ServerSideEncryptionByDefault{\n\t\t\t\t\tSSEAlgorithm: aws.String(s3.ServerSideEncryptionAwsKms),\n\t\t\t\t},\n\t\t\t}},\n\t\t},\n\t})\n\terr = ConvertS3Error(err, \"failed to set versioning state for bucket %q\", h.Bucket)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func (r *RemoveDirCloser) Close() error {\n\treturn trace.ConvertSystemError(os.RemoveAll(r.Path))\n}", "label": 5}
{"code": "def check_arguments(cls, passed):\n        \"\"\"Put warnings of arguments whose can't be handle by the class\"\"\"\n        defaults = list(cls.default_arguments().keys())\n        template = (\"Pass arg {argument:!r} in {cname:!r}, can be a typo? \"\n                    \"Supported key arguments: {defaults}\")\n        fails = []\n        for arg in passed:\n            if arg not in defaults:\n                warn(template.format(argument=arg,\n                                     cname=cls.__name__,\n                                     defaults=defaults))\n                fails.append(arg)\n\n        return any(fails)", "label": 1}
{"code": "def setup_queues\n      logger.info 'setting up queues'\n      vetted = @consumers.reject { |c| group_configured? && group_restricted?(c) }\n      vetted.each do |c|\n        setup_queue(c)\n      end\n    end", "label": 4}
{"code": "func (l VirtualDeviceList) FindDiskController(name string) (types.BaseVirtualController, error) {\n\tswitch {\n\tcase name == \"ide\":\n\t\treturn l.FindIDEController(\"\")\n\tcase name == \"scsi\" || name == \"\":\n\t\treturn l.FindSCSIController(\"\")\n\tcase name == \"nvme\":\n\t\treturn l.FindNVMEController(\"\")\n\tdefault:\n\t\tif c, ok := l.Find(name).(types.BaseVirtualController); ok {\n\t\t\treturn c, nil\n\t\t}\n\t\treturn nil, fmt.Errorf(\"%s is not a valid controller\", name)\n\t}\n}", "label": 5}
{"code": "func readAuthenticationMethod(conn net.Conn) ([]byte, error) {\n\t// Read in the number of authentication methods supported.\n\tnmethods, err := readByte(conn)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Read nmethods number of bytes from the connection return the list of\n\t// supported authentication methods to the caller.\n\tauthMethods := make([]byte, nmethods)\n\tfor i := byte(0); i < nmethods; i++ {\n\t\tmethod, err := readByte(conn)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\n\t\tauthMethods = append(authMethods, method)\n\t}\n\n\treturn authMethods, nil\n}", "label": 5}
{"code": "function patch(node, p5, parentSchema) {\n  var schema = parentSchema\n  var position = node.position\n  var children = node.children\n  var childNodes = []\n  var length = children ? children.length : 0\n  var index = -1\n  var child\n\n  if (node.type === 'element') {\n    if (schema.space === 'html' && node.tagName === 'svg') {\n      schema = svg\n    }\n\n    p5.namespaceURI = ns[schema.space]\n  }\n\n  while (++index < length) {\n    child = one(children[index], schema)\n    child.parentNode = p5\n    childNodes[index] = child\n  }\n\n  if (node.type === 'element' || node.type === 'root') {\n    p5.childNodes = childNodes\n  }\n\n  if (position && position.start && position.end) {\n    p5.sourceCodeLocation = {\n      startLine: position.start.line,\n      startCol: position.start.column,\n      startOffset: position.start.offset,\n      endLine: position.end.line,\n      endCol: position.end.column,\n      endOffset: position.end.offset\n    }\n  }\n\n  return p5\n}", "label": 3}
{"code": "public function createSnapshot(Session $session, array $res = [], $className = Snapshot::class)\n    {\n        $res += [\n            'id' => null,\n            'readTimestamp' => null\n        ];\n\n        if ($res['readTimestamp']) {\n            if (!($res['readTimestamp'] instanceof Timestamp)) {\n                $time = $this->parseTimeString($res['readTimestamp']);\n                $res['readTimestamp'] = new Timestamp($time[0], $time[1]);\n            }\n        }\n\n        return new $className($this, $session, $res);\n    }", "label": 2}
{"code": "public function extend($key, $provider)\n    {\n        if (is_callable($provider)) {\n            $provider = call_user_func($provider, $this->container);\n        }\n\n        $this->providers[$key] = $provider;\n    }", "label": 2}
{"code": "def get_table(self):\n\t\t\"\"\"\n\t\tGet the table\n\t\t\"\"\"\n\t\tbuffer_length = self.__get_table_size()\n\t\treturned_buffer_length = ctypes.wintypes.DWORD(buffer_length)\n\t\tbuffer = ctypes.create_string_buffer(buffer_length)\n\t\tpointer_type = ctypes.POINTER(self.structure)\n\t\ttable_p = ctypes.cast(buffer, pointer_type)\n\t\tres = self.method(table_p, returned_buffer_length, False)\n\t\tif res != errors.NO_ERROR:\n\t\t\traise RuntimeError(\"Error retrieving table (%d)\" % res)\n\t\treturn table_p.contents", "label": 1}
{"code": "public function discard()\n    {\n        if ($this->state->isInitialized()) {\n            $this->call($this->state->isCAS() ? 'UNWATCH' : 'DISCARD');\n\n            $this->reset();\n            $this->state->flag(MultiExecState::DISCARDED);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def _get_ending(self, lookup_url):\n        \"\"\"\n        Returns the short url ending from a short url or an short url ending.\n\n        Example:\n         - Given `<your Polr server>/5N3f8`, return `5N3f8`.\n         - Given `5N3f8`, return `5N3f8`.\n\n        :param lookup_url: A short url or short url ending\n        :type lookup_url: str\n        :return: The url ending\n        :rtype: str\n        \"\"\"\n        if lookup_url.startswith(self.api_server):\n            return lookup_url[len(self.api_server) + 1:]\n        return lookup_url", "label": 1}
{"code": "func (f *gzipReader) Close() error {\n\tvar errors []error\n\tif f.ReadCloser != nil {\n\t\terrors = append(errors, f.ReadCloser.Close())\n\t\tf.ReadCloser = nil\n\t}\n\tif f.file != nil {\n\t\terrors = append(errors, f.file.Close())\n\t\tf.file = nil\n\t}\n\treturn trace.NewAggregate(errors...)\n}", "label": 5}
{"code": "func NewProcessStorage(ctx context.Context, path string) (*ProcessStorage, error) {\n\tif path == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing parameter path\")\n\t}\n\tlitebk, err := lite.NewWithConfig(ctx, lite.Config{Path: path, EventsOff: true})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\t// Import storage data\n\terr = legacy.Import(ctx, litebk, func() (legacy.Exporter, error) {\n\t\treturn dir.New(legacy.Params{\"path\": path})\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &ProcessStorage{Backend: litebk}, nil\n}", "label": 5}
{"code": "public static autoscaleaction get(nitro_service service, String name) throws Exception{\n\t\tautoscaleaction obj = new autoscaleaction();\n\t\tobj.set_name(name);\n\t\tautoscaleaction response = (autoscaleaction) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func configDefaultNetworks(defaultAddressPool []*NetworkToSplit, result *[]*net.IPNet) error {\n\tmutex.Lock()\n\tdefer mutex.Unlock()\n\tdefaultNetworks, err := splitNetworks(defaultAddressPool)\n\tif err != nil {\n\t\treturn err\n\t}\n\t*result = defaultNetworks\n\treturn nil\n}", "label": 5}
{"code": "def get_args(self):\n        \"\"\"\n        Use this context manager to add arguments to an argparse object with the add_argument\n        method. Arguments must be defined before the command is defined. Note that\n        no-clean and resume are added upon exit and should not be added in the context manager. For\n        more info about these default arguments see below.\n        \"\"\"\n        parser = argparse.ArgumentParser(description=self._desc,\n                                         formatter_class=MyUniversalHelpFormatter)\n        # default args\n        if  self._no_clean:\n            parser.add_argument('--no-clean', action='store_true',\n                                help='If this flag is used, temporary work directory is not '\n                                     'cleaned.')\n        if self._resume:\n            parser.add_argument('--resume', action='store_true',\n                                help='If this flag is used, a previously uncleaned workflow in the'\n                                     ' same directory will be resumed')\n        return parser", "label": 1}
{"code": "public function setSpellCorrection($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\SpellingCorrection::class);\n        $this->spell_correction = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function getEntityNameForExtendingInterface(node) {\n            switch (node.kind) {\n                case 69 /* Identifier */:\n                case 172 /* PropertyAccessExpression */:\n                    return node.parent ? getEntityNameForExtendingInterface(node.parent) : undefined;\n                case 194 /* ExpressionWithTypeArguments */:\n                    ts.Debug.assert(ts.isEntityNameExpression(node.expression));\n                    return node.expression;\n                default:\n                    return undefined;\n            }\n        }", "label": 3}
{"code": "func (c *controller) SetKeys(keys []*types.EncryptionKey) error {\n\tsubsysKeys := make(map[string]int)\n\tfor _, key := range keys {\n\t\tif key.Subsystem != subsysGossip &&\n\t\t\tkey.Subsystem != subsysIPSec {\n\t\t\treturn fmt.Errorf(\"key received for unrecognized subsystem\")\n\t\t}\n\t\tsubsysKeys[key.Subsystem]++\n\t}\n\tfor s, count := range subsysKeys {\n\t\tif count != keyringSize {\n\t\t\treturn fmt.Errorf(\"incorrect number of keys for subsystem %v\", s)\n\t\t}\n\t}\n\n\tagent := c.getAgent()\n\n\tif agent == nil {\n\t\tc.Lock()\n\t\tc.keys = keys\n\t\tc.Unlock()\n\t\treturn nil\n\t}\n\treturn c.handleKeyChange(keys)\n}", "label": 5}
{"code": "func satisfiesAnyPodFilters(pod *v1alpha.Pod, filters []*v1alpha.PodFilter) bool {\n\t// No filters, return true directly.\n\tif len(filters) == 0 {\n\t\treturn true\n\t}\n\n\tfor _, filter := range filters {\n\t\tif satisfiesPodFilter(*pod, *filter) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "def count_peaks(ts):\n    \"\"\"\n    Toggle counter for gas boilers\n\n    Counts the number of times the gas consumption increases with more than 3kW\n\n    Parameters\n    ----------\n    ts: Pandas Series\n        Gas consumption in minute resolution\n\n    Returns\n    -------\n    int\n    \"\"\"\n\n    on_toggles = ts.diff() > 3000\n    shifted = np.logical_not(on_toggles.shift(1))\n    result = on_toggles & shifted\n    count = result.sum()\n    return count", "label": 1}
{"code": "public function setHdfsMetrics($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::INT64);\n        $this->hdfs_metrics = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static function process($profile = null, $filename = null)\n    {\n        $filename = $filename ?: (self::getHomeDir() . '/.aws/credentials');\n        $profile = $profile ?: (getenv(self::ENV_PROFILE) ?: 'default');\n\n        return function () use ($profile, $filename) {\n            if (!is_readable($filename)) {\n                return self::reject(\"Cannot read process credentials from $filename\");\n            }\n            $data = \\Aws\\parse_ini_file($filename, true, INI_SCANNER_RAW);\n            if ($data === false) {\n                return self::reject(\"Invalid credentials file: $filename\");\n            }\n            if (!isset($data[$profile])) {\n                return self::reject(\"'$profile' not found in credentials file\");\n            }\n            if (!isset($data[$profile]['credential_process'])\n            ) {\n                return self::reject(\"No credential_process present in INI profile \"\n                    . \"'$profile' ($filename)\");\n            }\n\n            $credentialProcess = $data[$profile]['credential_process'];\n            $json = shell_exec($credentialProcess);\n\n            $processData = json_decode($json, true);\n\n            // Only support version 1\n            if (isset($processData['Version'])) {\n                if ($processData['Version'] !== 1) {\n                    return self::reject(\"credential_process does not return Version == 1\");\n                }\n            }\n\n            if (!isset($processData['AccessKeyId']) || !isset($processData['SecretAccessKey'])) {\n                return self::reject(\"credential_process does not return valid credentials\");\n            }\n\n            if (isset($processData['Expiration'])) {\n                try {\n                    $expiration = new DateTimeResult($processData['Expiration']);\n                } catch (\\Exception $e) {\n                    return self::reject(\"credential_process returned invalid expiration\");\n                }\n                $now = new DateTimeResult();\n                if ($expiration < $now) {\n                    return self::reject(\"credential_process returned expired credentials\");\n                }\n            } else {\n                $processData['Expiration'] = null;\n            }\n\n            if (empty($processData['SessionToken'])) {\n                $processData['SessionToken'] = null;\n            }\n\n            return Promise\\promise_for(\n                new Credentials(\n                    $processData['AccessKeyId'],\n                    $processData['SecretAccessKey'],\n                    $processData['SessionToken'],\n                    $processData['Expiration']\n                )\n            );\n        };\n    }", "label": 2}
{"code": "public static void abortSystem(final Throwable error) {\n        DaemonStarter.currentPhase.set(LifecyclePhase.ABORTING);\n        try {\n            DaemonStarter.getLifecycleListener().aborting();\n        } catch (Exception e) {\n            DaemonStarter.rlog.error(\"Custom abort failed\", e);\n        }\n        if (error != null) {\n            DaemonStarter.rlog.error(\"Unrecoverable error encountered  --> Exiting : {}\", error.getMessage());\n            DaemonStarter.getLifecycleListener().exception(LifecyclePhase.ABORTING, error);\n        } else {\n            DaemonStarter.rlog.error(\"Unrecoverable error encountered --> Exiting\");\n        }\n        // Exit system with failure return code\n        System.exit(1);\n    }", "label": 0}
{"code": "function fetchFilePathsByType(distFiles, basePath, type) {\n  return distFiles\n    .filter(function(filePath) {\n      return new RegExp('assets/.*\\\\.' + type + '$').test(filePath);\n    })\n    .map(function(filePath) {\n      return path.join(basePath, filePath);\n    });\n}", "label": 3}
{"code": "function matches(file, patternList, excludePatterList, options) {\n  options = _.sanitize(options, {minimatch: false});\n  let shouldInclude = false;\n  let shouldExclude = false;\n  const matcher = options.minimatch ? (f, pattern) => minimatch(f, pattern, {dot: true, matchBase: true}) : globMatch;\n\n  if (!_.isEmpty(patternList)) {\n    shouldInclude = _.some(_ensureArray(patternList), pattern => matcher(file, pattern));\n  }\n  if (!_.isEmpty(excludePatterList)) {\n    shouldExclude = _.some(_ensureArray(excludePatterList), pattern => matcher(file, pattern));\n  }\n  return shouldInclude && !shouldExclude;\n}", "label": 3}
{"code": "def render_title(tags)\n      normalized_meta_tags[:title] = meta_tags.page_title\n      normalized_meta_tags[:site] = meta_tags[:site]\n      title = meta_tags.extract_full_title\n      normalized_meta_tags[:full_title] = title\n      tags << ContentTag.new(:title, content: title) if title.present?\n    end", "label": 4}
{"code": "def global_backtrace_report\n      if Kernel.respond_to?(:caller_for_all_threads)\n        all_thread_stacks = caller_for_all_threads\n      elsif Thread.respond_to?(:list) && Thread.public_method_defined?(:backtrace)\n        all_thread_stacks = {}\n        Thread.list.each do |thread|\n          all_thread_stacks[thread] = thread.backtrace\n        end\n      end\n\n      output = \"========== Process #{Process.pid}: backtrace dump ==========\\n\"\n      if all_thread_stacks\n        all_thread_stacks.each_pair do |thread, stack|\n          if thread_name = thread[:name]\n            thread_name = \"(#{thread_name})\"\n          end\n          stack ||= [\"(empty)\"]\n          output << (\"-\" * 60) << \"\\n\"\n          output << \"# Thread: #{thread.inspect}#{thread_name}, \"\n          if thread == Thread.main\n            output << \"[main thread], \"\n          end\n          if thread == Thread.current\n            output << \"[current thread], \"\n          end\n          output << \"alive = #{thread.alive?}\\n\"\n          output << (\"-\" * 60) << \"\\n\"\n          output << \"    \" << stack.join(\"\\n    \")\n          output << \"\\n\\n\"\n        end\n      else\n        output << (\"-\" * 60) << \"\\n\"\n        output << \"# Current thread: #{Thread.current.inspect}\\n\"\n        output << (\"-\" * 60) << \"\\n\"\n        output << \"    \" << caller.join(\"\\n    \")\n      end\n      return output\n    end", "label": 4}
{"code": "def get_tokens(condition):\n        \"\"\"\n        Get AST tokens for Python condition.\n\n        Returns:\n            list: list of AST tokens\n        \"\"\"\n        try:\n            ast_tokens = list(ast.walk(ast.parse(condition.strip())))\n        except SyntaxError as exception:\n            Logger.get_logger(__name__).error(\"Syntax error: %s\", exception)\n            ast_tokens = []\n        return ast_tokens", "label": 1}
{"code": "private function isMathOperator($token)\n    {\n        return in_array($token['type'], [Lexer::T_PLUS, Lexer::T_MINUS, Lexer::T_DIVIDE, Lexer::T_MULTIPLY], true);\n    }", "label": 2}
{"code": "private function getRetryFunction($shouldRetryMessages = true)\n    {\n        $httpRetryCodes = $this->httpRetryCodes;\n        $httpRetryMessages = $this->httpRetryMessages;\n\n        return function (\\Exception $ex) use ($httpRetryCodes, $httpRetryMessages, $shouldRetryMessages) {\n            $statusCode = $ex->getCode();\n\n            if (in_array($statusCode, $httpRetryCodes)) {\n                return true;\n            }\n\n            if (!$shouldRetryMessages) {\n                return false;\n            }\n\n            $message = ($ex instanceof RequestException && $ex->hasResponse())\n                ? (string) $ex->getResponse()->getBody()\n                : $ex->getMessage();\n\n            try {\n                $message = $this->jsonDecode(\n                    $message,\n                    true\n                );\n            } catch (\\InvalidArgumentException $ex) {\n                return false;\n            }\n\n            if (!isset($message['error']['errors'])) {\n                return false;\n            }\n\n            foreach ($message['error']['errors'] as $error) {\n                if (in_array($error['reason'], $httpRetryMessages)) {\n                    return true;\n                }\n            }\n\n            return false;\n        };\n    }", "label": 2}
{"code": "public static function extract( $tarball_or_zip, $dest ) {\n\t\tif ( preg_match( '/\\.zip$/', $tarball_or_zip ) ) {\n\t\t\treturn self::extract_zip( $tarball_or_zip, $dest );\n\t\t}\n\n\t\tif ( preg_match( '/\\.tar\\.gz$/', $tarball_or_zip ) ) {\n\t\t\treturn self::extract_tarball( $tarball_or_zip, $dest );\n\t\t}\n\t\tthrow new \\Exception( \"Extraction only supported for '.zip' and '.tar.gz' file types.\" );\n\t}", "label": 2}
{"code": "func (r *Registry) FindByName(name string, refs []types.ManagedObjectReference) mo.Entity {\n\tfor _, ref := range refs {\n\t\tif e, ok := r.Get(ref).(mo.Entity); ok {\n\t\t\tif name == e.Entity().Name {\n\t\t\t\treturn e\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function emitDetachedComments(text, lineMap, writer, writeComment, node, newLine, removeComments) {\n        var leadingComments;\n        var currentDetachedCommentInfo;\n        if (removeComments) {\n            // removeComments is true, only reserve pinned comment at the top of file\n            // For example:\n            //      /*! Pinned Comment */\n            //\n            //      var x = 10;\n            if (node.pos === 0) {\n                leadingComments = ts.filter(ts.getLeadingCommentRanges(text, node.pos), isPinnedComment);\n            }\n        }\n        else {\n            // removeComments is false, just get detached as normal and bypass the process to filter comment\n            leadingComments = ts.getLeadingCommentRanges(text, node.pos);\n        }\n        if (leadingComments) {\n            var detachedComments = [];\n            var lastComment = void 0;\n            for (var _i = 0, leadingComments_1 = leadingComments; _i < leadingComments_1.length; _i++) {\n                var comment = leadingComments_1[_i];\n                if (lastComment) {\n                    var lastCommentLine = getLineOfLocalPositionFromLineMap(lineMap, lastComment.end);\n                    var commentLine = getLineOfLocalPositionFromLineMap(lineMap, comment.pos);\n                    if (commentLine >= lastCommentLine + 2) {\n                        // There was a blank line between the last comment and this comment.  This\n                        // comment is not part of the copyright comments.  Return what we have so\n                        // far.\n                        break;\n                    }\n                }\n                detachedComments.push(comment);\n                lastComment = comment;\n            }\n            if (detachedComments.length) {\n                // All comments look like they could have been part of the copyright header.  Make\n                // sure there is at least one blank line between it and the node.  If not, it's not\n                // a copyright header.\n                var lastCommentLine = getLineOfLocalPositionFromLineMap(lineMap, ts.lastOrUndefined(detachedComments).end);\n                var nodeLine = getLineOfLocalPositionFromLineMap(lineMap, ts.skipTrivia(text, node.pos));\n                if (nodeLine >= lastCommentLine + 2) {\n                    // Valid detachedComments\n                    emitNewLineBeforeLeadingComments(lineMap, writer, node, leadingComments);\n                    emitComments(text, lineMap, writer, detachedComments, /*trailingSeparator*/ true, newLine, writeComment);\n                    currentDetachedCommentInfo = { nodePos: node.pos, detachedCommentEndPos: ts.lastOrUndefined(detachedComments).end };\n                }\n            }\n        }\n        return currentDetachedCommentInfo;\n        function isPinnedComment(comment) {\n            return text.charCodeAt(comment.pos + 1) === 42 /* asterisk */ &&\n                text.charCodeAt(comment.pos + 2) === 33 /* exclamation */;\n        }\n    }", "label": 3}
{"code": "function(context, pkg, isRoot, deps){\n\t\tvar stealPkg = utils.filter(deps, function(dep){\n\t\t\treturn dep && dep.name === \"steal\";\n\t\t})[0];\n\n\t\tif(stealPkg) {\n\t\t\treturn crawl.fetchDep(context, pkg, stealPkg, isRoot)\n\t\t\t\t.then(function(childPkg){\n\t\t\t\t\tif(childPkg) {\n\t\t\t\t\t\treturn crawl.deps(context, childPkg);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t} else {\n\t\t\treturn Promise.resolve();\n\t\t}\n\t}", "label": 3}
{"code": "public static List<Artifact> getAllArtifacts(final Module module){\n        final List<Artifact> artifacts = new ArrayList<Artifact>();\n\n        for(final Module subModule: module.getSubmodules()){\n            artifacts.addAll(getAllArtifacts(subModule));\n        }\n\n        artifacts.addAll(module.getArtifacts());\n\n        return artifacts;\n    }", "label": 0}
{"code": "public static function sessionName($project, $instance, $database, $session)\n    {\n        return self::getSessionNameTemplate()->render([\n            'project' => $project,\n            'instance' => $instance,\n            'database' => $database,\n            'session' => $session,\n        ]);\n    }", "label": 2}
{"code": "public static base_responses update(nitro_service client, dospolicy resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdospolicy updateresources[] = new dospolicy[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new dospolicy();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].qdepth = resources[i].qdepth;\n\t\t\t\tupdateresources[i].cltdetectrate = resources[i].cltdetectrate;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setSshPublicKey($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\OsLogin\\Common\\SshPublicKey::class);\n        $this->ssh_public_key = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def deserialize(type_, value=None, **kwargs):\n    '''Get an object from a text representation'''\n    if not isinstance(type_, str):\n        return type_\n    des = deserializer(type_, **kwargs)\n    if value is None:\n        return des\n    return des(value)", "label": 1}
{"code": "public Object get(IConverter converter, Object sourceObject,\n\t\t\tTypeReference<?> destinationType) {\n\t\treturn convertedObjects.get(new ConvertedObjectsKey(converter,\n\t\t\t\tsourceObject, destinationType));\n\t}", "label": 0}
{"code": "def generate_entry_for_tag(pull_requests, issues, newer_tag_name, newer_tag_link, newer_tag_time, older_tag_name) # rubocop:disable Metrics/ParameterLists\n      github_site = @options[:github_site] || \"https://github.com\"\n      project_url = \"#{github_site}/#{@options[:user]}/#{@options[:project]}\"\n\n      create_sections\n\n      @content = generate_header(newer_tag_name, newer_tag_link, newer_tag_time, older_tag_name, project_url)\n      @content += generate_body(pull_requests, issues)\n      @content\n    end", "label": 4}
{"code": "function(properties, value, equals, out)\n  {\n    var where = createWhere( properties, value, equals );\n    var changes = out && out instanceof ModelCollection ? out : this.cloneEmpty();\n\n    this.each(function(model)\n    {\n      if ( where( model ) && model.$hasChanges() )\n      {\n        changes.put( model.$key(), model.$getChanges() );\n      }\n    });\n\n    return changes;\n  }", "label": 3}
{"code": "def base_content_types\n      c_types = ContentType.new()\n      c_types << Default.new(:ContentType => RELS_CT, :Extension => RELS_EX)\n      c_types << Default.new(:Extension => XML_EX, :ContentType => XML_CT)\n      c_types << Override.new(:PartName => \"/#{APP_PN}\", :ContentType => APP_CT)\n      c_types << Override.new(:PartName => \"/#{CORE_PN}\", :ContentType => CORE_CT)\n      c_types << Override.new(:PartName => \"/xl/#{STYLES_PN}\", :ContentType => STYLES_CT)\n      c_types << Axlsx::Override.new(:PartName => \"/#{WORKBOOK_PN}\", :ContentType => WORKBOOK_CT)\n      c_types.lock\n      c_types\n    end", "label": 4}
{"code": "func (s *GRPCServer) Config() string {\n\t// Create a buffer that will contain our final contents\n\tvar buf bytes.Buffer\n\n\t// Wrap the base64 encoding with JSON encoding.\n\tif err := json.NewEncoder(&buf).Encode(s.config); err != nil {\n\t\t// We panic since ths shouldn't happen under any scenario. We\n\t\t// carefully control the structure being encoded here and it should\n\t\t// always be successful.\n\t\tpanic(err)\n\t}\n\n\treturn buf.String()\n}", "label": 5}
{"code": "public function validate(Request $request)\n    {\n        try {\n            $this->accept->parse($request, $this->strict);\n        } catch (BadRequestHttpException $exception) {\n            if ($request->getMethod() === 'OPTIONS') {\n                return true;\n            }\n\n            throw $exception;\n        }\n    }", "label": 2}
{"code": "func isUnixAddrResolvable(fl FieldLevel) bool {\n\n\t_, err := net.ResolveUnixAddr(\"unix\", fl.Field().String())\n\n\treturn err == nil\n}", "label": 5}
{"code": "func EventFromChunk(sessionID string, chunk *SessionChunk) (EventFields, error) {\n\tvar fields EventFields\n\teventStart := time.Unix(0, chunk.Time).In(time.UTC).Round(time.Millisecond)\n\terr := json.Unmarshal(chunk.Data, &fields)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tfields[SessionEventID] = sessionID\n\tfields[EventIndex] = chunk.EventIndex\n\tfields[EventTime] = eventStart\n\tfields[EventType] = chunk.EventType\n\tif fields[EventID] == \"\" {\n\t\tfields[EventID] = uuid.New()\n\t}\n\treturn fields, nil\n}", "label": 5}
{"code": "func (aSpace *addrSpace) UnmarshalJSON(data []byte) error {\n\taSpace.Lock()\n\tdefer aSpace.Unlock()\n\n\tm := map[string]interface{}{}\n\terr := json.Unmarshal(data, &m)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\taSpace.scope = datastore.LocalScope\n\ts := m[\"Scope\"].(string)\n\tif s == string(datastore.GlobalScope) {\n\t\taSpace.scope = datastore.GlobalScope\n\t}\n\n\tif v, ok := m[\"Subnets\"]; ok {\n\t\tsb, _ := json.Marshal(v)\n\t\tvar s map[string]*PoolData\n\t\terr := json.Unmarshal(sb, &s)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor ks, v := range s {\n\t\t\tk := SubnetKey{}\n\t\t\tk.FromString(ks)\n\t\t\taSpace.subnets[k] = v\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function getTypingNamesFromSourceFileNames(fileNames) {\n                var jsFileNames = ts.filter(fileNames, ts.hasJavaScriptFileExtension);\n                var inferredTypingNames = ts.map(jsFileNames, function (f) { return ts.removeFileExtension(ts.getBaseFileName(f.toLowerCase())); });\n                var cleanedTypingNames = ts.map(inferredTypingNames, function (f) { return f.replace(/((?:\\.|-)min(?=\\.|$))|((?:-|\\.)\\d+)/g, \"\"); });\n                if (safeList !== EmptySafeList) {\n                    mergeTypings(ts.filter(cleanedTypingNames, function (f) { return f in safeList; }));\n                }\n                var hasJsxFile = ts.forEach(fileNames, function (f) { return ts.ensureScriptKind(f, ts.getScriptKindFromFileName(f)) === 2 /* JSX */; });\n                if (hasJsxFile) {\n                    mergeTypings([\"react\"]);\n                }\n            }", "label": 3}
{"code": "func (process *TeleportProcess) setupCachePolicy(in cache.SetupConfigFn) cache.SetupConfigFn {\n\treturn func(c cache.Config) cache.Config {\n\t\tconfig := in(c)\n\t\tconfig.PreferRecent = cache.PreferRecent{\n\t\t\tEnabled:      process.Config.CachePolicy.Enabled,\n\t\t\tNeverExpires: process.Config.CachePolicy.NeverExpires,\n\t\t\tMaxTTL:       process.Config.CachePolicy.TTL,\n\t\t}\n\t\treturn config\n\t}\n}", "label": 5}
{"code": "def clean_directories!\n      all_build_files = File.join(@app.config[:build_dir], '**', '*')\n\n      empty_directories = Dir[all_build_files].select do |d|\n        File.directory?(d)\n      end\n\n      empty_directories.each do |d|\n        remove_file d, force: true if Pathname(d).children.empty?\n      end\n    end", "label": 4}
{"code": "def build(exp, parent_exp = nil)\n      context_processor = \"process_#{exp.type}\"\n      if context_processor_exists?(context_processor)\n        send(context_processor, exp, parent_exp)\n      else\n        process exp\n      end\n      current_context\n    end", "label": 4}
{"code": "func (a *Agent) connectedTo(proxy services.Server) bool {\n\tprincipals := a.getPrincipals()\n\tproxyID := fmt.Sprintf(\"%v.%v\", proxy.GetName(), a.ClusterName)\n\tif _, ok := principals[proxyID]; ok {\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "func NewHawkularSink(u *url.URL) (core.DataSink, error) {\n\tsink := &hawkularSink{\n\t\turi:       u,\n\t\tbatchSize: 1000,\n\t}\n\tif err := sink.init(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tmetrics := make([]core.MetricDescriptor, 0, len(core.AllMetrics))\n\tfor _, metric := range core.AllMetrics {\n\t\tmetrics = append(metrics, metric.MetricDescriptor)\n\t}\n\tsink.Register(metrics)\n\treturn sink, nil\n}", "label": 5}
{"code": "func SCSIControllerTypes() VirtualDeviceList {\n\t// Return a mutable list of SCSI controller types, initialized with defaults.\n\treturn VirtualDeviceList([]types.BaseVirtualDevice{\n\t\t&types.VirtualLsiLogicController{},\n\t\t&types.VirtualBusLogicController{},\n\t\t&types.ParaVirtualSCSIController{},\n\t\t&types.VirtualLsiLogicSASController{},\n\t}).Select(func(device types.BaseVirtualDevice) bool {\n\t\tc := device.(types.BaseVirtualSCSIController).GetVirtualSCSIController()\n\t\tc.SharedBus = types.VirtualSCSISharingNoSharing\n\t\tc.BusNumber = -1\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "func (s Style) Underline(on bool) Style {\n\treturn s.setAttrs(Style(AttrUnderline), on)\n}", "label": 5}
{"code": "function writeSpecFile(grunt, options, filesToPack) {\n\treturn function(callback) {\n\t\ttry {\n\t\t\tvar specPath = path.join(options.destination, specFolder);\n\t\t\toptions.files = filesToPack;\n\t\t\tvar pkg = grunt.file.readJSON('package.json');\n\t\t\tgrunt.util._.defaults(options, pkg);\n\t\t\t\n\t\t\toptions.specFilepath = path.join(specPath, options.name + '.spec');\n\t\t\tspec(options, callback);\n\t\t} catch(e) {\n\t\t\tcallback(e);\n\t\t}\n\t};\n}", "label": 3}
{"code": "public void scaleWeights(double scale) {\r\n    for (int i = 0; i < weights.length; i++) {\r\n      for (int j = 0; j < weights[i].length; j++) {\r\n        weights[i][j] *= scale;\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "function Subscription () {\n  this._id = null\n\n  this._storeRelations = null\n  this._memberRelations = null\n  this._dependencyRelations = null\n\n  this._events = {\n    'beforePublish': [],\n    'afterPublish': []\n  }\n\n  this._subscriptionStream = null\n  this._stream = null\n  this._lastData = null\n\n  this._muted = false\n\n  storeRelation.constructParent(this)\n  memberRelation.constructParent(this)\n  dependencyRelation.constructParent(this)\n\n  subscription.apply(this, arguments)\n}", "label": 3}
{"code": "public int getJdbcType(String ojbType) throws SQLException\r\n    {\r\n        int result;\r\n        if(ojbType == null) ojbType = \"\";\r\n\t\tojbType = ojbType.toLowerCase();\r\n        if (ojbType.equals(\"bit\"))\r\n            result = Types.BIT;\r\n        else if (ojbType.equals(\"tinyint\"))\r\n            result = Types.TINYINT;\r\n        else if (ojbType.equals(\"smallint\"))\r\n            result = Types.SMALLINT;\r\n        else if (ojbType.equals(\"integer\"))\r\n            result = Types.INTEGER;\r\n        else if (ojbType.equals(\"bigint\"))\r\n            result = Types.BIGINT;\r\n\r\n        else if (ojbType.equals(\"float\"))\r\n            result = Types.FLOAT;\r\n        else if (ojbType.equals(\"real\"))\r\n            result = Types.REAL;\r\n        else if (ojbType.equals(\"double\"))\r\n            result = Types.DOUBLE;\r\n\r\n        else if (ojbType.equals(\"numeric\"))\r\n            result = Types.NUMERIC;\r\n        else if (ojbType.equals(\"decimal\"))\r\n            result = Types.DECIMAL;\r\n\r\n        else if (ojbType.equals(\"char\"))\r\n            result = Types.CHAR;\r\n        else if (ojbType.equals(\"varchar\"))\r\n            result = Types.VARCHAR;\r\n        else if (ojbType.equals(\"longvarchar\"))\r\n            result = Types.LONGVARCHAR;\r\n\r\n        else if (ojbType.equals(\"date\"))\r\n            result = Types.DATE;\r\n        else if (ojbType.equals(\"time\"))\r\n            result = Types.TIME;\r\n        else if (ojbType.equals(\"timestamp\"))\r\n            result = Types.TIMESTAMP;\r\n\r\n        else if (ojbType.equals(\"binary\"))\r\n            result = Types.BINARY;\r\n        else if (ojbType.equals(\"varbinary\"))\r\n            result = Types.VARBINARY;\r\n        else if (ojbType.equals(\"longvarbinary\"))\r\n            result = Types.LONGVARBINARY;\r\n\r\n\t\telse if (ojbType.equals(\"clob\"))\r\n     \t\tresult = Types.CLOB;\r\n\t\telse if (ojbType.equals(\"blob\"))\r\n\t\t\tresult = Types.BLOB;\r\n        else\r\n            throw new SQLException(\r\n                \"The type '\"+ ojbType + \"' is not a valid jdbc type.\");\r\n        return result;\r\n    }", "label": 0}
{"code": "public function performConversions(ConversionCollection $conversions, Media $media, $onlyIfMissing = false)\n    {\n        if ($conversions->isEmpty()) {\n            return;\n        }\n\n        $imageGenerator = $this->determineImageGenerator($media);\n\n        if (! $imageGenerator) {\n            return;\n        }\n\n        $temporaryDirectory = TemporaryDirectory::create();\n\n        $copiedOriginalFile = app(Filesystem::class)->copyFromMediaLibrary(\n            $media,\n            $temporaryDirectory->path(str_random(16).'.'.$media->extension)\n        );\n\n        $conversions\n            ->reject(function (Conversion $conversion) use ($onlyIfMissing, $media) {\n                $relativePath = $media->getPath($conversion->getName());\n\n                $rootPath = config('filesystems.disks.'.$media->disk.'.root');\n\n                if ($rootPath) {\n                    $relativePath = str_replace($rootPath, '', $relativePath);\n                }\n\n                return $onlyIfMissing && Storage::disk($media->disk)->exists($relativePath);\n            })\n            ->each(function (Conversion $conversion) use ($media, $imageGenerator, $copiedOriginalFile) {\n                event(new ConversionWillStart($media, $conversion, $copiedOriginalFile));\n\n                $copiedOriginalFile = $imageGenerator->convert($copiedOriginalFile, $conversion);\n\n                $manipulationResult = $this->performManipulations($media, $conversion, $copiedOriginalFile);\n\n                $newFileName = pathinfo($media->file_name, PATHINFO_FILENAME).\n                    '-'.$conversion->getName().\n                    '.'.$conversion->getResultExtension(pathinfo($copiedOriginalFile, PATHINFO_EXTENSION));\n\n                $renamedFile = MediaLibraryFileHelper::renameInDirectory($manipulationResult, $newFileName);\n\n                if ($conversion->shouldGenerateResponsiveImages()) {\n                    app(ResponsiveImageGenerator::class)->generateResponsiveImagesForConversion(\n                        $media,\n                        $conversion,\n                        $renamedFile\n                    );\n                }\n\n                app(Filesystem::class)->copyToMediaLibrary($renamedFile, $media, 'conversions');\n\n                $media->markAsConversionGenerated($conversion->getName(), true);\n\n                event(new ConversionHasBeenCompleted($media, $conversion));\n            });\n\n        $temporaryDirectory->delete();\n    }", "label": 2}
{"code": "private PBKey buildDefaultKey()\r\n    {\r\n        List descriptors = connectionRepository().getAllDescriptor();\r\n        JdbcConnectionDescriptor descriptor;\r\n        PBKey result = null;\r\n        for (Iterator iterator = descriptors.iterator(); iterator.hasNext();)\r\n        {\r\n            descriptor = (JdbcConnectionDescriptor) iterator.next();\r\n            if (descriptor.isDefaultConnection())\r\n            {\r\n                if(result != null)\r\n                {\r\n                    log.error(\"Found additional connection descriptor with enabled 'default-connection' \"\r\n                            + descriptor.getPBKey() + \". This is NOT allowed. Will use the first found descriptor \" + result\r\n                            + \" as default connection\");\r\n                }\r\n                else\r\n                {\r\n                    result = descriptor.getPBKey();\r\n                }\r\n            }\r\n        }\r\n\r\n        if(result == null)\r\n        {\r\n            log.info(\"No 'default-connection' attribute set in jdbc-connection-descriptors,\" +\r\n                    \" thus it's currently not possible to use 'defaultPersistenceBroker()' \" +\r\n                    \" convenience method to lookup PersistenceBroker instances. But it's possible\"+\r\n                    \" to enable this at runtime using 'setDefaultKey' method.\");\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "private function purgeOrphanedInUseSessions(array &$data)\n    {\n        foreach ($data['inUse'] as $key => $session) {\n            if ($session['lastActive'] + SessionPoolInterface::SESSION_EXPIRATION_SECONDS < $this->time()) {\n                unset($data['inUse'][$key]);\n            } elseif ($session['lastActive'] + self::DURATION_TWENTY_MINUTES < $this->time()) {\n                unset($session['lastActive']);\n                array_push($data['queue'], $session);\n                unset($data['inUse'][$key]);\n            }\n        }\n    }", "label": 2}
{"code": "public function filter_pre_http_request( $response, $args, $url ) {\n\t\t// check if whitelisted\n\t\tif ( ! isset( $this->whitelist[ $url ] ) ) {\n\t\t\treturn $response;\n\t\t}\n\t\t// check if downloading\n\t\tif ( 'GET' !== $args['method'] || empty( $args['filename'] ) ) {\n\t\t\treturn $response;\n\t\t}\n\t\t// check cache and export to designated location\n\t\t$filename = $this->cache->has( $this->whitelist[ $url ]['key'], $this->whitelist[ $url ]['ttl'] );\n\t\tif ( $filename ) {\n\t\t\tWP_CLI::log( sprintf( 'Using cached file \\'%s\\'...', $filename ) );\n\t\t\tif ( copy( $filename, $args['filename'] ) ) {\n\t\t\t\t// simulate successful download response\n\t\t\t\treturn array(\n\t\t\t\t\t'response' => array(\n\t\t\t\t\t\t'code'    => 200,\n\t\t\t\t\t\t'message' => 'OK',\n\t\t\t\t\t),\n\t\t\t\t\t'filename' => $args['filename'],\n\t\t\t\t);\n\t\t\t}\n\n\t\t\tWP_CLI::error( sprintf( 'Error copying cached file %s to %s', $filename, $url ) );\n\t\t}\n\t\treturn $response;\n\t}", "label": 2}
{"code": "function (initFunction) {\n        if (_.isFunction(initFunction)) {\n            Logger.info(\"Run init function\");\n            _customInitFuncton = initFunction;\n            return initFunction(appHttp)\n                .then(function () {\n                    return initFunction(appHttps);\n                });\n        }\n        return Q();\n    }", "label": 3}
{"code": "public String getPromotionDetailsJsonModel() throws IOException {\n        final PromotionEvaluationReport sampleReport = new PromotionEvaluationReport();\n        sampleReport.addMessage(String.format(TWO_PLACES, PromotionReportTranslator.UNPROMOTED_MSG, \"com.acme.secure-smh:core-relay:1.2.0\"), MAJOR);\n        sampleReport.addMessage(String.format(TWO_PLACES, PromotionReportTranslator.DO_NOT_USE_MSG, \"com.google.guava:guava:20.0\"), MAJOR);\n        sampleReport.addMessage(String.format(TWO_PLACES, PromotionReportTranslator.MISSING_LICENSE_MSG, \"org.apache.maven.wagon:wagon-webdav-jackrabbit:2.12\"), MINOR);\n        sampleReport.addMessage(String.format(TWO_PLACES, PromotionReportTranslator.UNACCEPTABLE_LICENSE_MSG,\n                \"aopaliance:aopaliance:1.0 licensed as Attribution-ShareAlike 2.5 Generic, \" +\n                \"org.polyjdbc:polyjdbc0.7.1 licensed as Creative Commons Attribution-ShareAlike 3.0 Unported License\"),\n                MINOR);\n\n        sampleReport.addMessage(PromotionReportTranslator.SNAPSHOT_VERSION_MSG, Tag.CRITICAL);\n        return JsonUtils.serialize(sampleReport);\n    }", "label": 0}
{"code": "function warnOnce(message) {\n  if (!(previousWarnOnceMessages.indexOf(message) !== -1)) {\n    previousWarnOnceMessages.push(message);\n    warn(message);\n  }\n}", "label": 3}
{"code": "func (m *MockIndex) ForeignThree(arg0 imp3.Imp3) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"ForeignThree\", arg0)\n}", "label": 5}
{"code": "protected function argKeys(): Collection\n    {\n        $args = $this->args;\n\n        ksort($args);\n\n        return (new Collection($args))->map(function ($value, $key) {\n            $keyValue = is_array($value)\n                ? json_encode($value, true)\n                : $value;\n\n            return \"{$key}:{$keyValue}\";\n        });\n    }", "label": 2}
{"code": "func (m *MockIndex) EllipOnly(arg0 ...string) {\n\tm.ctrl.T.Helper()\n\tvarargs := []interface{}{}\n\tfor _, a := range arg0 {\n\t\tvarargs = append(varargs, a)\n\t}\n\tm.ctrl.Call(m, \"EllipOnly\", varargs...)\n}", "label": 5}
{"code": "def update\n      filter_docs_with_edit_access!\n      copy_visibility = params[:embargoes].values.map { |h| h[:copy_visibility] }\n      ActiveFedora::Base.find(batch).each do |curation_concern|\n        Hyrax::Actors::EmbargoActor.new(curation_concern).destroy\n        # if the concern is a FileSet, set its visibility and skip the copy_visibility_to_files, which is built for Works\n        if curation_concern.file_set?\n          curation_concern.visibility = curation_concern.to_solr[\"visibility_after_embargo_ssim\"]\n          curation_concern.save!\n        elsif copy_visibility.include?(curation_concern.id)\n          curation_concern.copy_visibility_to_files\n        end\n      end\n      redirect_to embargoes_path, notice: t('.embargo_deactivated')\n    end", "label": 4}
{"code": "protected function sendCheckAndSendMedia($filepath, $maxSize, $to, $type, $allowedExtensions, $storeURLmedia, $caption = '')\n    {\n        if ($this->getMediaFile($filepath, $maxSize) == true) {\n            if (in_array(strtolower($this->mediaFileInfo['fileextension']), $allowedExtensions)) {\n                $b64hash = base64_encode(hash_file('sha256', $this->mediaFileInfo['filepath'], true));\n                //request upload and get Message ID\n                $id = $this->sendRequestFileUpload($b64hash, $type, $this->mediaFileInfo['filesize'], $this->mediaFileInfo['filepath'], $to, $caption);\n                $this->processTempMediaFile($storeURLmedia);\n                // Return message ID. Make pull request for this.\n                return $id;\n            } else {\n                //Not allowed file type.\n                $this->processTempMediaFile($storeURLmedia);\n\n                return;\n            }\n        } else {\n            //Didn't get media file details.\n            return;\n        }\n    }", "label": 2}
{"code": "def list(*args)\n      arguments(args)\n      params = arguments.params\n\n      response = if ( (user_name = params.delete('user')) &&\n                      (repo_name = params.delete('repo')) )\n        get_request(\"/repos/#{user_name}/#{repo_name}/notifications\", params)\n      else\n        get_request('/notifications', params)\n      end\n      return response unless block_given?\n      response.each { |el| yield el }\n    end", "label": 4}
{"code": "function merge(docset, customTags) {\n  doc_ast.linenr = docset[\"linenr\"];\n\n  // useful for applying global NS items to the proper NS\n  docset[\"original_name\"] = docset[\"code\"].name;\n  docset[\"comment\"] = doc_ast.detect(docset[\"tagname\"], docset[\"comment\"], customTags);\n  \n  return Merger.merge(docset);\n}", "label": 3}
{"code": "public static int[] toInt(double[] array) {\n        int[] n = new int[array.length];\n        for (int i = 0; i < array.length; i++) {\n            n[i] = (int) array[i];\n        }\n        return n;\n    }", "label": 0}
{"code": "public int[] indices(Collection<E> elems) {\r\n    int[] indices = new int[elems.size()];\r\n    int i = 0;\r\n    for (E elem : elems) {\r\n      indices[i++] = indexOf(elem);\r\n    }\r\n    return indices;\r\n  }", "label": 0}
{"code": "def write(self, file_or_filename):\n        \"\"\" Writes case data to file in MATPOWER format.\n        \"\"\"\n        if isinstance(file_or_filename, basestring):\n            self._fcn_name, _ = splitext(basename(file_or_filename))\n        else:\n            self._fcn_name = self.case.name\n\n        self._fcn_name = self._fcn_name.replace(\",\", \"\").replace(\" \", \"_\")\n\n        super(MATPOWERWriter, self).write(file_or_filename)", "label": 1}
{"code": "def get_commit_request(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a commit request for a staged import.\n\n        :param id: Staged import ID as an int.\n        :return: :class:`imports.Request <imports.Request>` object\n        :rtype: imports.Request\n        \"\"\"\n        schema = RequestSchema()\n        resp = self.service.get(self.base+str(id)+'/request/')\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "func (d *Decoder) autoClose(t Token) (Token, bool) {\n\tif d.stk == nil || d.stk.kind != stkStart {\n\t\treturn nil, false\n\t}\n\tname := strings.ToLower(d.stk.name.Local)\n\tfor _, s := range d.AutoClose {\n\t\tif strings.ToLower(s) == name {\n\t\t\t// This one should be auto closed if t doesn't close it.\n\t\t\tet, ok := t.(EndElement)\n\t\t\tif !ok || et.Name.Local != name {\n\t\t\t\treturn EndElement{d.stk.name}, true\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\treturn nil, false\n}", "label": 5}
{"code": "public static responderglobal_responderpolicy_binding[] get(nitro_service service) throws Exception{\n\t\tresponderglobal_responderpolicy_binding obj = new responderglobal_responderpolicy_binding();\n\t\tresponderglobal_responderpolicy_binding response[] = (responderglobal_responderpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _do_change_status(self, status, force=False):\n        \"\"\"\n        This function is called by\n           - set_status\n           - _update_program_stack if active program is being changed\n             - thia may be launched by sensor status change.\n             status lock is necessary because these happen from different\n             threads.\n\n        This does not directly change status, but adds change request\n        to queue.\n        \"\"\"\n        self.system.worker_thread.put(DummyStatusWorkerTask(self._request_status_change_in_queue, status, force=force))", "label": 1}
{"code": "protected AssemblyResponse watchStatus() throws LocalOperationException, RequestException {\n        AssemblyResponse response;\n        do {\n            response = getClient().getAssemblyByUrl(url);\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                throw new LocalOperationException(e);\n            }\n        } while (!response.isFinished());\n\n        setState(State.FINISHED);\n        return response;\n    }", "label": 0}
{"code": "function getUiPart(modulePath, options) {\n        var rootDir = this.injector.rootDir;\n        var tplDir = (options && options.tplDir) || 'dist' + delim + 'tpls';\n        var pathParts = modulePath.split(delim);\n        var appName = pathParts[1];\n        var len = modulePath.length;\n        var filePath, fullModulePath, uipart, viewObj;\n\n        // filePath has .js, modulePath does not\n        if (modulePath.substring(len - 3) === '.js') {\n            filePath = rootDir + delim + modulePath;\n            fullModulePath = rootDir + delim + modulePath.substring(0, len - 3);\n        }\n        else {\n            filePath = rootDir + delim + modulePath + '.js';\n            fullModulePath = rootDir + delim + modulePath;\n        }\n\n        // if exists, get it\n        if (fs.existsSync(filePath)) {\n            uipart = this.injector.require(fullModulePath);\n        }\n        // else if in an app folder, try the common folder\n        else if (appName !== 'common') {\n            fullModulePath = fullModulePath.replace(delim + appName + delim, delim + 'common' + delim);\n            uipart = this.injector.require(fullModulePath);\n            appName = 'common';\n        }\n\n        // if no view, check to see if precompiled in tpl dir\n        var viewFile = fullModulePath.replace(\n            delim + 'app' + delim + appName + delim,\n            delim + tplDir + delim + appName + delim\n        );\n        if (!uipart.view && fs.existsSync(viewFile + '.js')) {\n            viewObj = this.injector.require(viewFile);\n            uipart.view = function () {\n                return viewObj;\n            };\n        }\n\n        return uipart;\n    }", "label": 3}
{"code": "function checkForDisallowedESSymbolOperand(operator) {\n                var offendingSymbolOperand = maybeTypeOfKind(leftType, 512 /* ESSymbol */) ? left :\n                    maybeTypeOfKind(rightType, 512 /* ESSymbol */) ? right :\n                        undefined;\n                if (offendingSymbolOperand) {\n                    error(offendingSymbolOperand, ts.Diagnostics.The_0_operator_cannot_be_applied_to_type_symbol, ts.tokenToString(operator));\n                    return false;\n                }\n                return true;\n            }", "label": 3}
{"code": "func (a *AuthServer) GetClusterName(opts ...services.MarshalOption) (services.ClusterName, error) {\n\treturn a.GetCache().GetClusterName(opts...)\n}", "label": 5}
{"code": "public void sendValue(int nodeId, int endpoint, int value) {\n\t\tZWaveNode node = this.getNode(nodeId);\n\t\tZWaveSetCommands zwaveCommandClass = null;\n\t\tSerialMessage serialMessage = null;\n\t\t\n\t\tfor (ZWaveCommandClass.CommandClass commandClass : new ZWaveCommandClass.CommandClass[] { ZWaveCommandClass.CommandClass.SWITCH_MULTILEVEL, ZWaveCommandClass.CommandClass.SWITCH_BINARY, ZWaveCommandClass.CommandClass.BASIC }) {\n\t\t\tzwaveCommandClass = (ZWaveSetCommands)node.resolveCommandClass(commandClass, endpoint);\n\t\t\tif (zwaveCommandClass != null)\n\t\t\t\tbreak;\n\t\t}\n\t\t\n\t\tif (zwaveCommandClass == null) {\n\t\t\tlogger.error(\"No Command Class found on node {}, instance/endpoint {} to request level.\", nodeId, endpoint);\n\t\t\treturn;\n\t\t}\n\t\t\t \n\t\tserialMessage = node.encapsulate(zwaveCommandClass.setValueMessage(value), (ZWaveCommandClass)zwaveCommandClass, endpoint);\n\t\t\n\t\tif (serialMessage != null)\n\t\t\tthis.sendData(serialMessage);\n\t\t\n\t\t// read back level on \"ON\" command\n\t\tif (((ZWaveCommandClass)zwaveCommandClass).getCommandClass() == ZWaveCommandClass.CommandClass.SWITCH_MULTILEVEL && value == 255)\n\t\t\tthis.requestValue(nodeId, endpoint);\n\t}", "label": 0}
{"code": "public function reconnect()\n    {\n        // Try to close the AMQP connection\n        $this->safeClose();\n        // Reconnect the socket/stream then AMQP\n        $this->io->close();\n        $this->setIsConnected(false); // getIO can initiate the connection setting via LazyConnection, set it here to be sure\n        $this->connect();\n    }", "label": 2}
{"code": "public static lbvserver_cachepolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_cachepolicy_binding obj = new lbvserver_cachepolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_cachepolicy_binding response[] = (lbvserver_cachepolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def parseMagnitude(m):\n        \"\"\"Parses a number m into a human-ready string representation.\n        For example, crops off floats if they're too accurate.\n\n        Arguments:\n            m (float): Floating-point number to be cleaned.\n\n        Returns:\n            Human-ready string description of the number.\n        \"\"\"\n        m = NumberService().parse(m)\n\n        def toDecimalPrecision(n, k):\n            return float(\"%.*f\" % (k, round(n, k)))\n\n        # Cast to two digits of precision\n        digits = 2\n        magnitude = toDecimalPrecision(m, digits)\n\n        # If value is really small, keep going\n        while not magnitude:\n            digits += 1\n            magnitude = toDecimalPrecision(m, digits)\n\n        # If item is less than one, go one beyond 'necessary' number of digits\n        if m < 1.0:\n            magnitude = toDecimalPrecision(m, digits + 1)\n\n        # Ignore decimal accuracy if irrelevant\n        if int(magnitude) == magnitude:\n            magnitude = int(magnitude)\n\n        # Adjust for scientific notation\n        magString = str(magnitude)\n        magString = re.sub(r'(\\d)e-(\\d+)',\n                           '\\g<1> times ten to the negative \\g<2>', magString)\n        magString = re.sub(r'(\\d)e\\+(\\d+)',\n                           '\\g<1> times ten to the \\g<2>', magString)\n        magString = re.sub(r'-(\\d+)', 'negative \\g<1>', magString)\n        magString = re.sub(r'\\b0(\\d+)', '\\g<1>', magString)\n        return magString", "label": 1}
{"code": "def add_attribute(name, &block)\n      declaration = Declaration::Dynamic.new(name, @ignore, block)\n      @definition.declare_attribute(declaration)\n    end", "label": 4}
{"code": "def find_default_key(key_names)\n      key_names.each do |filename|\n        path = Pathname.new(filename)\n        # If we have a config location (like ./.chef/), look there first.\n        if config_location\n          local_path = path.expand_path(File.dirname(config_location))\n          return local_path.to_s if local_path.exist?\n        end\n        # Then check ~/.chef.\n        home_path = path.expand_path(home_chef_dir)\n        return home_path.to_s if home_path.exist?\n      end\n      nil\n    end", "label": 4}
{"code": "def insertions_from_masked(seq):\n    \"\"\"\n    get coordinates of insertions from insertion-masked sequence\n    \"\"\"\n    insertions = []\n    prev = True\n    for i, base in enumerate(seq):\n        if base.isupper() and prev is True:\n            insertions.append([])\n            prev = False\n        elif base.islower():\n            insertions[-1].append(i)\n            prev = True\n    return [[min(i), max(i)] for i in insertions if i != []]", "label": 1}
{"code": "func PgLargeobjectMetadatumByOid(db XODB, oid pgtypes.Oid) (*PgLargeobjectMetadatum, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, lomowner, lomacl ` +\n\t\t`FROM pg_catalog.pg_largeobject_metadata ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tplm := PgLargeobjectMetadatum{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&plm.Tableoid, &plm.Cmax, &plm.Xmax, &plm.Cmin, &plm.Xmin, &plm.Oid, &plm.Ctid, &plm.Lomowner, &plm.Lomacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &plm, nil\n}", "label": 5}
{"code": "function indexOfNode (host, node) {\n  const chs = host.childNodes;\n  const chsLen = chs.length;\n  for (let a = 0; a < chsLen; a++) {\n    if (chs[a] === node) {\n      return a;\n    }\n  }\n  return -1;\n}", "label": 3}
{"code": "func PgTransformByOid(db XODB, oid pgtypes.Oid) (*PgTransform, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, trftype, trflang, trffromsql, trftosql ` +\n\t\t`FROM pg_catalog.pg_transform ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpt := PgTransform{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pt.Tableoid, &pt.Cmax, &pt.Xmax, &pt.Cmin, &pt.Xmin, &pt.Oid, &pt.Ctid, &pt.Trftype, &pt.Trflang, &pt.Trffromsql, &pt.Trftosql)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pt, nil\n}", "label": 5}
{"code": "public function setValue($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\TypedValue::class);\n        $this->value = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function snapshot(array $options = [])\n    {\n        return $this->createSnapshot($this->connection, $this->valueMapper, $this, $options);\n    }", "label": 2}
{"code": "def in_same_dir(as_file, target_file):\n    \"\"\"Return an absolute path to a target file that is located in the same directory as as_file\n\n    Args:\n        as_file: File name (including __file__)\n            Use the directory path of this file\n        target_file: Name of the target file\n    \"\"\"\n    return os.path.abspath(os.path.join(os.path.dirname(as_file), target_file))", "label": 1}
{"code": "func (c *Client) killed() bool {\n\tc.l.Lock()\n\tdefer c.l.Unlock()\n\treturn c.processKilled\n}", "label": 5}
{"code": "def render_document\n      info = {\n        :registers        => { :site => site, :page => payload[\"page\"] },\n        :strict_filters   => liquid_options[\"strict_filters\"],\n        :strict_variables => liquid_options[\"strict_variables\"],\n      }\n\n      output = document.content\n      if document.render_with_liquid?\n        Jekyll.logger.debug \"Rendering Liquid:\", document.relative_path\n        output = render_liquid(output, payload, info, document.path)\n      end\n\n      Jekyll.logger.debug \"Rendering Markup:\", document.relative_path\n      output = convert(output.to_s)\n      document.content = output\n\n      if document.place_in_layout?\n        Jekyll.logger.debug \"Rendering Layout:\", document.relative_path\n        output = place_in_layouts(output, payload, info)\n      end\n\n      output\n    end", "label": 4}
{"code": "func PgClassByOid(db XODB, oid pgtypes.Oid) (*PgClass, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, relname, relnamespace, reltype, reloftype, relowner, relam, relfilenode, reltablespace, relpages, reltuples, relallvisible, reltoastrelid, relhasindex, relisshared, relpersistence, relkind, relnatts, relchecks, relhasoids, relhaspkey, relhasrules, relhastriggers, relhassubclass, relrowsecurity, relforcerowsecurity, relispopulated, relreplident, relfrozenxid, relminmxid, relacl, reloptions ` +\n\t\t`FROM pg_catalog.pg_class ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpc := PgClass{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pc.Tableoid, &pc.Cmax, &pc.Xmax, &pc.Cmin, &pc.Xmin, &pc.Oid, &pc.Ctid, &pc.Relname, &pc.Relnamespace, &pc.Reltype, &pc.Reloftype, &pc.Relowner, &pc.Relam, &pc.Relfilenode, &pc.Reltablespace, &pc.Relpages, &pc.Reltuples, &pc.Relallvisible, &pc.Reltoastrelid, &pc.Relhasindex, &pc.Relisshared, &pc.Relpersistence, &pc.Relkind, &pc.Relnatts, &pc.Relchecks, &pc.Relhasoids, &pc.Relhaspkey, &pc.Relhasrules, &pc.Relhastriggers, &pc.Relhassubclass, &pc.Relrowsecurity, &pc.Relforcerowsecurity, &pc.Relispopulated, &pc.Relreplident, &pc.Relfrozenxid, &pc.Relminmxid, &pc.Relacl, &pc.Reloptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pc, nil\n}", "label": 5}
{"code": "func (a *LocalKeyAgent) UnloadKeys() error {\n\tagents := []agent.Agent{a.Agent}\n\tif a.sshAgent != nil {\n\t\tagents = append(agents, a.sshAgent)\n\t}\n\n\t// iterate over all agents we have\n\tfor i, _ := range agents {\n\t\t// get a list of all keys in the agent\n\t\tkeyList, err := agents[i].List()\n\t\tif err != nil {\n\t\t\ta.log.Warnf(\"Unable to communicate with agent and list keys: %v\", err)\n\t\t}\n\n\t\t// remove any teleport keys we currently have loaded in the agent\n\t\tfor _, key := range keyList {\n\t\t\tif strings.HasPrefix(key.Comment, \"teleport:\") {\n\t\t\t\terr = agents[i].Remove(key)\n\t\t\t\tif err != nil {\n\t\t\t\t\ta.log.Warnf(\"Unable to communicate with agent and remove key: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static String padLeft(String str, int totalChars, char ch) {\r\n    if (str == null) {\r\n      str = \"null\";\r\n    }\r\n    StringBuilder sb = new StringBuilder();\r\n    for (int i = 0, num = totalChars - str.length(); i < num; i++) {\r\n      sb.append(ch);\r\n    }\r\n    sb.append(str);\r\n    return sb.toString();\r\n  }", "label": 0}
{"code": "private function messageFactory(array $message, ConnectionInterface $connection, $projectId, $encode)\n    {\n        if (!isset($message['message'])) {\n            throw new GoogleException('Invalid message data.');\n        }\n\n        if (isset($message['message']['data']) && $encode) {\n            $message['message']['data'] = base64_decode($message['message']['data']);\n        }\n\n        $subscription = null;\n        if (isset($message['subscription'])) {\n            $subscription = new Subscription(\n                $connection,\n                $projectId,\n                $message['subscription'],\n                null,\n                $encode\n            );\n        }\n\n        return new Message($message['message'], [\n            'ackId' => (isset($message['ackId'])) ? $message['ackId'] : null,\n            'subscription' => $subscription\n        ]);\n    }", "label": 2}
{"code": "def _rename(self):\n        \"\"\"\n        Called during a PUT request where the action specifies\n        a rename operation. Returns resource URI of the renamed file.\n        \"\"\"\n        newname = self.action['newname']\n        try:\n            newpath = self.fs.rename(self.fp,newname)\n        except OSError:\n            raise tornado.web.HTTPError(400)\n        return newpath", "label": 1}
{"code": "public static base_response change(nitro_service client, sslfips resource) throws Exception {\n\t\tsslfips updateresource = new sslfips();\n\t\tupdateresource.fipsfw = resource.fipsfw;\n\t\treturn updateresource.perform_operation(client,\"update\");\n\t}", "label": 0}
{"code": "protected function processTempMediaFile($storeURLmedia)\n    {\n        if (!isset($this->mediaFileInfo['url'])) {\n            return false;\n        }\n\n        if ($storeURLmedia && is_file($this->mediaFileInfo['filepath'])) {\n            rename($this->mediaFileInfo['filepath'], $this->mediaFileInfo['filepath'].'.'.$this->mediaFileInfo['fileextension']);\n        } elseif (is_file($this->mediaFileInfo['filepath'])) {\n            unlink($this->mediaFileInfo['filepath']);\n        }\n    }", "label": 2}
{"code": "def has_custom_image(user_context, app_id):\n  \"\"\"Returns True if there exists a custom image for app_id.\"\"\"\n  possible_paths = _valid_custom_image_paths(user_context, app_id)\n  return any(map(os.path.exists, possible_paths))", "label": 1}
{"code": "protected boolean checkExcludePackages(String classPackageName) {\n\t\tif (excludePackages != null && excludePackages.length > 0) {\n\t\t\tWildcardHelper wildcardHelper = new WildcardHelper();\n\n\t\t\t// we really don't care about the results, just the boolean\n\t\t\tMap<String, String> matchMap = new HashMap<String, String>();\n\n\t\t\tfor (String packageExclude : excludePackages) {\n\t\t\t\tint[] packagePattern = wildcardHelper.compilePattern(packageExclude);\n\t\t\t\tif (wildcardHelper.match(matchMap, classPackageName, packagePattern)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "label": 0}
{"code": "public function setMaxValue($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Value::class);\n        $this->max_value = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func InstrumentRouteFunc(handlerName string, routeFunc restful.RouteFunction) restful.RouteFunction {\n\topts := prometheus.SummaryOpts{\n\t\tSubsystem:   \"http\",\n\t\tConstLabels: prometheus.Labels{\"handler\": handlerName},\n\t}\n\n\treqCnt := prometheus.NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tSubsystem:   opts.Subsystem,\n\t\t\tName:        \"requests_total\",\n\t\t\tHelp:        \"Total number of HTTP requests made.\",\n\t\t\tConstLabels: opts.ConstLabels,\n\t\t},\n\t\tinstLabels,\n\t)\n\n\topts.Name = \"request_duration_microseconds\"\n\topts.Help = \"The HTTP request latencies in microseconds.\"\n\treqDur := prometheus.NewSummary(opts)\n\n\topts.Name = \"request_size_bytes\"\n\topts.Help = \"The HTTP request sizes in bytes.\"\n\treqSz := prometheus.NewSummary(opts)\n\n\topts.Name = \"response_size_bytes\"\n\topts.Help = \"The HTTP response sizes in bytes.\"\n\tresSz := prometheus.NewSummary(opts)\n\n\tregReqCnt := prometheus.MustRegisterOrGet(reqCnt).(*prometheus.CounterVec)\n\tregReqDur := prometheus.MustRegisterOrGet(reqDur).(prometheus.Summary)\n\tregReqSz := prometheus.MustRegisterOrGet(reqSz).(prometheus.Summary)\n\tregResSz := prometheus.MustRegisterOrGet(resSz).(prometheus.Summary)\n\n\treturn restful.RouteFunction(func(request *restful.Request, response *restful.Response) {\n\t\tnow := time.Now()\n\n\t\tdelegate := &responseWriterDelegator{ResponseWriter: response.ResponseWriter}\n\t\tout := make(chan int)\n\t\turlLen := 0\n\t\tif request.Request.URL != nil {\n\t\t\turlLen = len(request.Request.URL.String())\n\t\t}\n\t\tgo computeApproximateRequestSize(request.Request, out, urlLen)\n\n\t\t_, cn := response.ResponseWriter.(http.CloseNotifier)\n\t\t_, fl := response.ResponseWriter.(http.Flusher)\n\t\t_, hj := response.ResponseWriter.(http.Hijacker)\n\t\t_, rf := response.ResponseWriter.(io.ReaderFrom)\n\t\tvar rw http.ResponseWriter\n\t\tif cn && fl && hj && rf {\n\t\t\trw = &fancyResponseWriterDelegator{delegate}\n\t\t} else {\n\t\t\trw = delegate\n\t\t}\n\t\tresponse.ResponseWriter = rw\n\n\t\trouteFunc(request, response)\n\n\t\telapsed := float64(time.Since(now)) / float64(time.Microsecond)\n\n\t\tmethod := strings.ToLower(request.Request.Method)\n\t\tcode := strconv.Itoa(delegate.status)\n\t\tregReqCnt.WithLabelValues(method, code).Inc()\n\t\tregReqDur.Observe(elapsed)\n\t\tregResSz.Observe(float64(delegate.written))\n\t\tregReqSz.Observe(float64(<-out))\n\t})\n}", "label": 5}
{"code": "function sanitizeSpontaneousAreas(req, data, page, callback) {\n    var toSanitize = [];\n    _.each(data, function(val, key) {\n      if (typeof(val) === 'object') {\n        if (val.type === 'area') {\n          if (_.has(page, key) && ((typeof(page[key]) !== 'object') || (page[key].type !== 'area'))) {\n            // Spontaneous areas may not replace properties that are not areas\n            return;\n          }\n          toSanitize.push({ key: key, items: val.items });\n        }\n      }\n    });\n    return async.eachSeries(toSanitize, function(entry, callback) {\n      return apos.sanitizeItems(req, entry.items || [], function(err, _items) {\n        if (err) {\n          return callback(err);\n        }\n        entry.items = _items;\n        return callback(null);\n      });\n    }, function(err) {\n      if (err) {\n        return callback(err);\n      }\n      _.each(toSanitize, function(entry) {\n        page[entry.key] = { type: 'area', items: entry.items };\n      });\n      return callback(null);\n    });\n  }", "label": 3}
{"code": "public static function fromClient(DynamoDbClient $client, array $config = [])\n    {\n        $config += ['locking' => false];\n        if ($config['locking']) {\n            $connection = new LockingSessionConnection($client, $config);\n        } else {\n            $connection = new StandardSessionConnection($client, $config);\n        }\n\n        return new static($connection);\n    }", "label": 2}
{"code": "private function encodeObjectValue($value)\n    {\n        if ($value instanceof \\stdClass) {\n            return $this->encodeAssociativeArrayValue((array) $value);\n        }\n\n        if ($value instanceof Blob) {\n            return ['bytesValue' => (string) $value];\n        }\n\n        if ($value instanceof \\DateTimeInterface) {\n            return [\n                'timestampValue' => [\n                    'seconds' => $value->format('U'),\n                    'nanos' => (int)($value->format('u') * 1000)\n                ]\n            ];\n        }\n\n        if ($value instanceof Timestamp) {\n            return [\n                'timestampValue' => [\n                    'seconds' => $value->get()->format('U'),\n                    'nanos' => $value->nanoSeconds()\n                ]\n            ];\n        }\n\n        if ($value instanceof GeoPoint) {\n            return ['geoPointValue' => $value->point()];\n        }\n\n        if ($value instanceof DocumentReference || $value instanceof DocumentSnapshot) {\n            return ['referenceValue' => $value->name()];\n        }\n\n        throw new \\RuntimeException(sprintf(\n            'Object of type %s cannot be encoded to a Firestore value type.',\n            get_class($value)\n        ));\n    }", "label": 2}
{"code": "function(args) {\n        var result = [], callback;\n        var rules = build_rules(this.filters, this._rules);\n        var tokens = args.concat([]);\n        var token;\n        while(this._halt == false && (token = tokens.shift())) {\n            if(LONG_SWITCH_RE.test(token) || SHORT_SWITCH_RE.test(token)) {\n                var arg = undefined;\n                // The token is a long or a short switch. Get the corresponding\n                // rule, filter and handle it. Pass the switch to the default\n                // handler if no rule matched.\n                for(var i = 0; i < rules.length; i++) {\n                    var rule = rules[i];\n                    if(rule.long == token || rule.short == token) {\n                        if(rule.filter !== undefined) {\n                            arg = tokens.shift();\n                            if(!LONG_SWITCH_RE.test(arg) && !SHORT_SWITCH_RE.test(arg)) {\n                                try {\n                                    arg = rule.filter(arg);\n                                } catch(e) {\n                                    throw OptError(token + ': ' + e.toString());\n                                }\n                            } else if(rule.optional_arg) {\n                                tokens.unshift(arg);\n                            } else {\n                                throw OptError('Expected switch argument.');\n                            }\n                        }\n                        callback = this.on_switches[rule.name];\n                        if (!callback) callback = this.on_switches['*'];\n                        if(callback) callback.apply(this, [rule.name, arg]);\n                        break;\n                    }\n                }\n                if(i == rules.length) this.default_handler.apply(this, [token]);\n            } else {\n                // Did not match long or short switch. Parse the token as a\n                // normal argument.\n                callback = this.on_args[result.length];\n                result.push(token);\n                if(callback) callback.apply(this, [token]);\n            }\n        }\n        return this._halt ? this.on_halt.apply(this, [tokens]) : result;\n    }", "label": 3}
{"code": "public static nsappflowcollector get(nitro_service service, String name) throws Exception{\n\t\tnsappflowcollector obj = new nsappflowcollector();\n\t\tobj.set_name(name);\n\t\tnsappflowcollector response = (nsappflowcollector) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setDeviceType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\DeviceInfo_DeviceType::class);\n        $this->device_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function componentUpdated(el, _ref2) {\n      var modifiers = _ref2.modifiers;\n\n      var target;\n      target = modifiers.children ? Array.from(el.children) : el;\n      return balanceText(target);\n    }", "label": 3}
{"code": "function(alias) {\n      var config = this.getMapping(alias);\n      if (config.computed && config.mapping.push) {\n        var models = this.__getComputedModels(alias);\n        if (models) {\n          config.mapping.push.call(this, models);\n        }\n      } else if (config.computed) {\n        var modelAliases = this.__getModelAliases(alias);\n        _.each(modelAliases, function(modelAlias) {\n          var model = this.getTrackedModel(modelAlias);\n          if (model) {\n            this.__copyFields(config.mapping[modelAlias], model, this);\n          }\n        }, this);\n      } else {\n        var model = this.getTrackedModel(alias);\n        if (model) {\n          this.__copyFields(config.mapping, model, this);\n        }\n      }\n    }", "label": 3}
{"code": "public DbArtifact getArtifact(final String gavc) {\n        final DbArtifact artifact = repositoryHandler.getArtifact(gavc);\n\n        if(artifact == null){\n            throw new WebApplicationException(Response.status(Response.Status.NOT_FOUND)\n                    .entity(\"Artifact \" + gavc + \" does not exist.\").build());\n        }\n\n        return artifact;\n    }", "label": 0}
{"code": "public function setKind($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\EntityType_Kind::class);\n        $this->kind = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def point_reflect(pt, nv):\n    \"\"\" Reflect a 3-D point through a plane intersecting the origin.\n\n    nv defines the normal vector to the plane (needs not be normalized)\n\n    .. todo:: Complete point_reflect docstring\n\n    Raises\n    ------\n    ValueError : If pt or nv are not reducible to 3-D vectors\n    ValueError : If norm of nv is too small\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n\n    # Ensure pt is reducible to 3-D vector\n    pt = make_nd_vec(pt, nd=3, t=np.float64, norm=False)\n\n    # Transform the point and return\n    refl_pt = np.dot(mtx_refl(nv, reps=1), pt)\n    return refl_pt", "label": 1}
{"code": "public function setSize($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\CompanySize::class);\n        $this->size = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function Request(opts, callback) {\n    this.opts = opts;\n    this.callback = callback;\n\n    Object.defineProperty(this, 'method', {\n        get: function() {\n            return opts.method;\n        },\n    });\n\n    Object.defineProperty(this, 'path', {\n        get: function() {\n            return opts.uri;\n        },\n    });\n\n    /**\n     * Parse the body of the request as a JSON object and return it.\n     */\n    Object.defineProperty(this, 'data', {\n        get: function() {\n            return opts.body ? JSON.parse(opts.body) : opts.body;\n        },\n    });\n\n    /**\n     * Return the raw body passed to request\n     */\n    Object.defineProperty(this, 'rawData', {\n        get: function() {\n            return opts.body;\n        },\n    });\n\n    Object.defineProperty(this, 'queryParams', {\n        get: function() {\n            return opts.qs;\n        },\n    });\n\n    Object.defineProperty(this, 'headers', {\n        get: function() {\n            return opts.headers || {};\n        },\n    });\n}", "label": 3}
{"code": "private void ensureConversion(FieldDescriptorDef fieldDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        // we issue a warning if we encounter a field with a java.util.Date java type without a conversion\r\n        if (\"java.util.Date\".equals(fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_JAVA_TYPE)) &&\r\n            !fieldDef.hasProperty(PropertyHelper.OJB_PROPERTY_CONVERSION))\r\n        {\r\n            LogHelper.warn(true,\r\n                           FieldDescriptorConstraints.class,\r\n                           \"ensureConversion\",\r\n                           \"The field \"+fieldDef.getName()+\" in class \"+fieldDef.getOwner().getName()+\r\n                               \" of type java.util.Date is directly mapped to jdbc-type \"+\r\n                               fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_JDBC_TYPE)+\r\n                               \". However, most JDBC drivers can't handle java.util.Date directly so you might want to \"+\r\n                               \" use a conversion for converting it to a JDBC datatype like TIMESTAMP.\");\r\n        }\r\n\r\n        String conversionClass = fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_CONVERSION);\r\n\r\n        if (((conversionClass == null) || (conversionClass.length() == 0)) &&\r\n            fieldDef.hasProperty(PropertyHelper.OJB_PROPERTY_DEFAULT_CONVERSION) &&\r\n            fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_DEFAULT_JDBC_TYPE).equals(fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_JDBC_TYPE)))\r\n        {\r\n            conversionClass = fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_DEFAULT_CONVERSION);\r\n            fieldDef.setProperty(PropertyHelper.OJB_PROPERTY_CONVERSION, conversionClass);\r\n        }\r\n        // now checking\r\n        if (CHECKLEVEL_STRICT.equals(checkLevel) && (conversionClass != null) && (conversionClass.length() > 0))\r\n        {\r\n            InheritanceHelper helper = new InheritanceHelper();\r\n\r\n            try\r\n            {\r\n                if (!helper.isSameOrSubTypeOf(conversionClass, CONVERSION_INTERFACE))\r\n                {\r\n                    throw new ConstraintException(\"The conversion class specified for field \"+fieldDef.getName()+\" in class \"+fieldDef.getOwner().getName()+\" does not implement the necessary interface \"+CONVERSION_INTERFACE);\r\n                }\r\n            }\r\n            catch (ClassNotFoundException ex)\r\n            {\r\n                throw new ConstraintException(\"The class \"+ex.getMessage()+\" hasn't been found on the classpath while checking the conversion class specified for field \"+fieldDef.getName()+\" in class \"+fieldDef.getOwner().getName());\r\n            }\r\n        }\r\n}", "label": 0}
{"code": "function loader(source) {\n\n  // dust files don't have side effects, so loader results are cacheable\n  if (this.cacheable) this.cacheable();\n\n  // Set up default options & override them with other options\n  const default_options = {\n    root: '',\n    dustAlias: 'dustjs-linkedin',\n    namingFn: defaultNamingFunction,\n    preserveWhitespace: false,\n    wrapOutput: false,\n    verbose: false,\n    ignoreImages: false,\n    excludeImageRegex: undefined\n  };\n\n  // webpack 4 'this.options' was deprecated in webpack 3 and removed in webpack 4\n  // if you want to use global loader options, use dust-loader-complete < v4.0.0\n  // var query = this.options || this.query || {};\n  // var global_options = query['dust-loader-complete'] || {};\n\n  // get user supplied loader options from `this.query`\n  const loader_options = getOptions(this) || {};\n\n  // merge user options with default options\n  const options = Object.assign({}, default_options, loader_options);\n\n  // Fix slashes & resolve root\n  options.root = path.resolve(options.root.replace('/', path.sep));\n\n  // Get the path\n  const template_path = path.relative(options.root, this.resourcePath);\n\n  // Create the template name\n  const name = options.namingFn(template_path, options);\n\n  // Log\n  log(options, 'Loading DustJS module from \"' + template_path + '\": naming template \"' + name + '\"');\n\n  // Find different styles of dependencies\n  const deps = [];\n\n  // Find regular dust partials, updating the source as needed for relatively-pathed partials\n  source = findPartials(source, template_path + '/../', options, deps);\n\n  // Find image dependencies\n  if (!options.ignoreImages) {\n    source = findImages(name, source, deps, options);\n  }\n\n  // Find require comments\n  findRequireComments(source, template_path + '/../', options, deps);\n\n  // Do not trim whitespace in case preserveWhitespace option is enabled\n  dust.config.whitespace = options.preserveWhitespace;\n\n  // Compile the template\n  const template = dust.compile(source, name);\n\n  // Build the returned string\n  let returnedString;\n  if (options.wrapOutput) {\n    returnedString = \"var dust = require('\" + options.dustAlias + \"/lib/dust'); \"\n      + deps.join(' ') + template\n      + \"var fn = \" + defaultWrapperGenerator(name)\n      + '; fn.templateName = \"' + name + '\"; '\n      + \"module.exports = fn;\";\n  } else {\n    returnedString = \"var dust = require('\" + options.dustAlias + \"'); \"\n      + deps.join(' ')\n      + 'var template = ' + template + ';'\n      + 'template.templateName = \"' + name + '\";'\n      + \"module.exports = template;\";\n  }\n\n  // Return the string to be used\n  return returnedString\n}", "label": 3}
{"code": "protected function evictCollectionCache(PersistentCollection $collection)\n    {\n        $key = new CollectionCacheKey(\n            $this->sourceEntity->getRootClassName(),\n            $this->association->getName(),\n            $this->uow->getEntityIdentifier($collection->getOwner())\n        );\n\n        $this->region->evict($key);\n\n        if ($this->cacheLogger) {\n            $this->cacheLogger->collectionCachePut($this->regionName, $key);\n        }\n    }", "label": 2}
{"code": "public static base_response change(nitro_service client, appfwsignatures resource) throws Exception {\n\t\tappfwsignatures updateresource = new appfwsignatures();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.mergedefault = resource.mergedefault;\n\t\treturn updateresource.perform_operation(client,\"update\");\n\t}", "label": 0}
{"code": "func setupDeviceUp(config *networkConfiguration, i *bridgeInterface) error {\n\terr := i.nlh.LinkSetUp(i.Link)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed to set link up for %s: %v\", config.BridgeName, err)\n\t}\n\n\t// Attempt to update the bridge interface to refresh the flags status,\n\t// ignoring any failure to do so.\n\tif lnk, err := i.nlh.LinkByName(config.BridgeName); err == nil {\n\t\ti.Link = lnk\n\t} else {\n\t\tlogrus.Warnf(\"Failed to retrieve link for interface (%s): %v\", config.BridgeName, err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static base_response enable(nitro_service client, nspbr resource) throws Exception {\n\t\tnspbr enableresource = new nspbr();\n\t\tenableresource.name = resource.name;\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "function(next) {\n            var files = [];\n            if (core.appPackage && core.packages[core.appPackage]) files.push(core.packages[core.appPackage].path);\n            files.push(core.home, core.path.etc + \"/..\", __dirname + \"/..\");\n            for (var i in files) {\n                var pkg = lib.readFileSync(files[i] + \"/package.json\", { json: 1, logger: \"error\", missingok: 1 });\n                logger.debug(\"init:\", files[i] + \"/package.json\", pkg.name, pkg.version);\n                if (!core.appName && pkg.name) core.appName = pkg.name;\n                if (!core.appVersion && pkg.version) core.appVersion = pkg.version;\n                if (!core.appDescr && pkg.description) core.appDescr = pkg.description;\n                if (!core.version && pkg.name == \"backendjs\") core.version = pkg.version;\n            }\n            if (!core.appName) core.appName = core.name;\n            if (!core.appVersion) core.appVersion = core.version;\n            // Use the app name as salt for consistentcy\n            if (!core.salt) core.salt = lib.salt = core.appName;\n            next();\n        }", "label": 3}
{"code": "def require_theme_deps\n      return false unless site.theme.runtime_dependencies\n\n      site.theme.runtime_dependencies.each do |dep|\n        next if dep.name == \"jekyll\"\n\n        External.require_with_graceful_fail(dep.name) if plugin_allowed?(dep.name)\n      end\n    end", "label": 4}
{"code": "func (nDB *NetworkDB) findNode(nodeName string) (*node, nodeState, map[string]*node) {\n\tfor i, nodes := range []map[string]*node{\n\t\tnDB.nodes,\n\t\tnDB.leftNodes,\n\t\tnDB.failedNodes,\n\t} {\n\t\tif n, ok := nodes[nodeName]; ok {\n\t\t\treturn n, nodeState(i), nodes\n\t\t}\n\t}\n\treturn nil, nodeNotFound, nil\n}", "label": 5}
{"code": "protected function filterByVersions(array $route)\n    {\n        foreach ($this->option('versions') as $version) {\n            if (Str::contains($route['versions'], $version)) {\n                return true;\n            }\n        }\n\n        return false;\n    }", "label": 2}
{"code": "def batch(iterable, size):\n    \"\"\"\n    Get items from a sequence a batch at a time.\n\n    .. note:\n\n        Adapted from\n        https://code.activestate.com/recipes/303279-getting-items-in-batches/.\n\n\n    .. note:\n\n        All batches must be exhausted immediately.\n\n    :params iterable: An iterable to get batches from.\n    :params size: Size of the batches.\n    :returns: A new batch of the given size at each time.\n\n    >>> [list(i) for i in batch([1, 2, 3, 4, 5], 2)]\n    [[1, 2], [3, 4], [5]]\n    \"\"\"\n    item = iter(iterable)\n    while True:\n        batch_iterator = islice(item, size)\n        try:\n            yield chain([next(batch_iterator)], batch_iterator)\n        except StopIteration:\n            return", "label": 1}
{"code": "def save(filename)\n      data_to_save = @metadata.merge({\n        \"licenses\" => licenses,\n        \"notices\" => notices\n      })\n\n      FileUtils.mkdir_p(File.dirname(filename))\n      File.write(filename, data_to_save.to_yaml)\n    end", "label": 4}
{"code": "def info(package, long_description, classifiers, license):\n    \"\"\"Get info about a package or packages.\n    \"\"\"\n    client = requests.Session()\n    for name_or_url in package:\n        package = get_package(name_or_url, client)\n        if not package:\n            secho(u'Invalid name or URL: \"{name}\"'.format(name=name_or_url),\n                  fg='red', file=sys.stderr)\n            continue\n\n        # Name and summary\n        try:\n            info = package.data['info']\n        except NotFoundError:\n            secho(u'No versions found for \"{0}\". '\n                  u'Skipping. . .'.format(package.name),\n                  fg='red', file=sys.stderr)\n            continue\n        echo_header(name_or_url)\n        if package.summary:\n            echo(package.summary)\n\n        # Version info\n        echo()\n        echo('Latest release:   {version:12}'.format(version=info['version']))\n\n        # Long description\n        if long_description:\n            echo()\n            echo(package.description)\n\n        # Download info\n        echo()\n        echo_download_summary(package)\n\n        # Author info\n        echo()\n        author, author_email = package.author, package.author_email\n        if author:\n            echo(u'Author:   {author:12}'.format(**locals()))\n        if author_email:\n            echo(u'Author email: {author_email:12}'.format(**locals()))\n\n        # Maintainer info\n        maintainer, maintainer_email = (package.maintainer,\n                                        package.maintainer_email)\n        if maintainer or maintainer_email:\n            echo()\n        if maintainer:\n            echo(u'Maintainer:   {maintainer:12}'.format(**locals()))\n        if maintainer_email:\n            echo(u'Maintainer email: {maintainer_email:12}'.format(**locals()))\n\n        # URLS\n        echo()\n        echo(u'PyPI URL:  {pypi_url:12}'.format(pypi_url=package.package_url))\n        if package.home_page:\n            echo(u'Home Page: {home_page:12}'.format(\n                home_page=package.home_page))\n        if package.docs_url:\n            echo(u'Documentation: {docs_url:12}'.format(\n                docs_url=package.docs_url))\n\n        # Classifiers\n        if classifiers:\n            echo()\n            echo(u'Classifiers: ')\n            for each in info.get('classifiers', []):\n                echo('\\t' + each)\n\n        if license and package.license:\n            echo()\n            echo(u'License: ', nl=False)\n            # license may be just a name, e.g. 'BSD' or the full license text\n            # If a new line is found in the text, print a new line\n            if package.license.find('\\n') >= 0 or len(package.license) > 80:\n                echo()\n            echo(package.license)\n        echo()", "label": 1}
{"code": "function listBuilder(list, bufb, codec, width) {\n  if (!Array.isArray(list)) {\n    throw new errors.EncodingError(list, 'Unsure how to encode non-array as list');\n  }\n\n  if (!width && list.length === 0) {\n    bufb.appendUInt8(0x45);\n    return;\n  }\n\n  // Encode all elements into a temp buffer to allow us to front-load appropriate size and count.\n  var tempBuilder = new Builder();\n  var _len = list.length;\n  for (var _i = 0; _i < _len; ++_i) codec.encode(list[_i], tempBuilder);\n  var tempBuffer = tempBuilder.get();\n\n  // Code, size, length, data\n  if (width === 1 || (tempBuffer.length < 0xFF && list.length < 0xFF && width !== 4)) {\n    // list8\n    if (!width) bufb.appendUInt8(0xC0);\n    bufb.appendUInt8(tempBuffer.length + 1);\n    bufb.appendUInt8(list.length);\n  } else {\n    // list32\n    if (!width) bufb.appendUInt8(0xD0);\n    bufb.appendUInt32BE(tempBuffer.length + 4);\n    bufb.appendUInt32BE(list.length);\n  }\n\n  bufb.appendBuffer(tempBuffer);\n}", "label": 3}
{"code": "func (m *ProcessManager) Kill(pid int64) bool {\n\tm.mu.Lock()\n\tentry, ok := m.entries[pid]\n\tm.mu.Unlock()\n\n\tif ok {\n\t\tentry.Kill()\n\t\treturn true\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "func DefaultIP() string {\n\taddrs, err := netInterfaceAddrs()\n\tif err == nil {\n\t\tfor _, addr := range addrs {\n\t\t\tif ip, ok := addr.(*net.IPNet); ok && !ip.IP.IsLoopback() {\n\t\t\t\tif ip.IP.To4() != nil {\n\t\t\t\t\treturn ip.IP.String()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn \"\"\n}", "label": 5}
{"code": "def create(self, id, seq, resource): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Create a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param resource: :class:`highlights.Highlight <highlights.Highlight>` object\n        :return: :class:`highlights.Highlight <highlights.Highlight>` object\n        :rtype: highlights.Highlight\n        \"\"\"\n        return self.create_or_edit(id, seq, resource)", "label": 1}
{"code": "public function setLinks($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Trace\\V2\\Span_Links::class);\n        $this->links = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function customStrategyInPlace(projectDir, builder, cb)\n{\n  const installerDir = path.resolve(projectDir, \"node_modules\", \"@deskpro\", INSTALLER_PACKAGE_NAME);\n  const customInstallerTarget = path.resolve(installerDir, \"src\", \"settings\");\n  shelljs.rm('-rf', customInstallerTarget);\n\n  const copyOptions = { overwrite: true, expand: true, dot: true };\n\n  function onCustomInstallerFilesReady (err) {\n    builder.buildFromSource(installerDir, projectDir);\n    cb();\n  }\n\n  let customInstallerSrc = path.resolve(projectDir, \"src\", \"installer\");\n  customInstallerSrc = fs.realpathSync(customInstallerSrc);\n\n  copy(customInstallerSrc, customInstallerTarget, copyOptions, onCustomInstallerFilesReady);\n}", "label": 3}
{"code": "def clean(self):\n        \"\"\"\n        Make sure there is at least a translation has been filled in. If a\n        default language has been specified, make sure that it exists amongst\n        translations.\n        \"\"\"\n\n        # First make sure the super's clean method is called upon.\n        super(TranslationFormSet, self).clean()\n\n        if settings.HIDE_LANGUAGE:\n            return\n\n        if len(self.forms) > 0:\n            # If a default language has been provided, make sure a translation\n            # is available\n\n            if settings.DEFAULT_LANGUAGE and not any(self.errors):\n                # Don't bother validating the formset unless each form is\n                # valid on its own. Reference:\n                # http://docs.djangoproject.com/en/dev/topics/forms/formsets/#custom-formset-validation\n\n                for form in self.forms:\n                    language_code = form.cleaned_data.get(\n                        'language_code', None\n                    )\n\n                    if language_code == settings.DEFAULT_LANGUAGE:\n\n                        # All is good, don't bother checking any further\n                        return\n\n                raise forms.ValidationError(_(\n                    'No translation provided for default language \\'%s\\'.'\n                ) % settings.DEFAULT_LANGUAGE)\n\n        else:\n            raise forms.ValidationError(\n                _('At least one translation should be provided.')\n            )", "label": 1}
{"code": "private Client getClient(){\n        final ClientConfig cfg = new DefaultClientConfig();\n        cfg.getClasses().add(com.fasterxml.jackson.jaxrs.json.JacksonJsonProvider.class);\n        cfg.getProperties().put(ClientConfig.PROPERTY_CONNECT_TIMEOUT, timeout);\n\n        return Client.create(cfg);\n    }", "label": 0}
{"code": "public function setTenant($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\Tenant::class);\n        $this->tenant = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, filterpolicy resource) throws Exception {\n\t\tfilterpolicy updateresource = new filterpolicy();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.rule = resource.rule;\n\t\tupdateresource.reqaction = resource.reqaction;\n\t\tupdateresource.resaction = resource.resaction;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function collections(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n        return new ItemIterator(\n            new PageIterator(\n                function ($collectionId) {\n                    return $this->collection($collectionId);\n                },\n                [$this->connection, 'listCollectionIds'],\n                [\n                    'parent' => $this->fullName($this->projectId, $this->database),\n                ] + $options,\n                [\n                    'itemsKey' => 'collectionIds',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "func (c *Client) WithHeader(ctx context.Context, header Header) context.Context {\n\treturn context.WithValue(ctx, headerContext{}, header)\n}", "label": 5}
{"code": "def implements(interfaces, inherit: false)\n      if !interfaces.is_a?(Array)\n        raise ArgumentError, \"`implements(interfaces)` must be an array, not #{interfaces.class} (#{interfaces})\"\n      end\n\n      @clean_interfaces = nil\n      @clean_inherited_fields = nil\n      dirty_ifaces = inherit ? @dirty_inherited_interfaces : @dirty_interfaces\n      dirty_ifaces.concat(interfaces)\n    end", "label": 4}
{"code": "def process_atomic_operations(operations)\n      operations.each do |field, value|\n        access = database_field_name(field)\n        yield(access, value)\n        remove_change(access) unless executing_atomically?\n      end\n    end", "label": 4}
{"code": "def print_new(ctx, name, migration_type):\n    \"\"\"Prints filename of a new migration\"\"\"\n    click.echo(ctx.obj.repository.generate_migration_name(name, migration_type))", "label": 1}
{"code": "func (a *Allocator) RequestPool(addressSpace, pool, subPool string, options map[string]string, v6 bool) (string, *net.IPNet, map[string]string, error) {\n\tlogrus.Debugf(\"RequestPool(%s, %s, %s, %v, %t)\", addressSpace, pool, subPool, options, v6)\n\n\tk, nw, ipr, err := a.parsePoolRequest(addressSpace, pool, subPool, v6)\n\tif err != nil {\n\t\treturn \"\", nil, nil, types.InternalErrorf(\"failed to parse pool request for address space %q pool %q subpool %q: %v\", addressSpace, pool, subPool, err)\n\t}\n\n\tpdf := k == nil\n\nretry:\n\tif pdf {\n\t\tif nw, err = a.getPredefinedPool(addressSpace, v6); err != nil {\n\t\t\treturn \"\", nil, nil, err\n\t\t}\n\t\tk = &SubnetKey{AddressSpace: addressSpace, Subnet: nw.String()}\n\t}\n\n\tif err := a.refresh(addressSpace); err != nil {\n\t\treturn \"\", nil, nil, err\n\t}\n\n\taSpace, err := a.getAddrSpace(addressSpace)\n\tif err != nil {\n\t\treturn \"\", nil, nil, err\n\t}\n\n\tinsert, err := aSpace.updatePoolDBOnAdd(*k, nw, ipr, pdf)\n\tif err != nil {\n\t\tif _, ok := err.(types.MaskableError); ok {\n\t\t\tlogrus.Debugf(\"Retrying predefined pool search: %v\", err)\n\t\t\tgoto retry\n\t\t}\n\t\treturn \"\", nil, nil, err\n\t}\n\n\tif err := a.writeToStore(aSpace); err != nil {\n\t\tif _, ok := err.(types.RetryError); !ok {\n\t\t\treturn \"\", nil, nil, types.InternalErrorf(\"pool configuration failed because of %s\", err.Error())\n\t\t}\n\n\t\tgoto retry\n\t}\n\n\treturn k.String(), nw, nil, insert()\n}", "label": 5}
{"code": "function _gpfSkipPad (text, pad) {\n    var idx = 0;\n    while (idx < text.length && -1 !== pad.indexOf(text.charAt(idx))) {\n        ++idx;\n    }\n    return idx;\n}", "label": 3}
{"code": "public function setPersonNames($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\PersonName::class);\n        $this->person_names = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (aSpace *addrSpace) SetValue(value []byte) error {\n\trc := &addrSpace{subnets: make(map[SubnetKey]*PoolData)}\n\tif err := json.Unmarshal(value, rc); err != nil {\n\t\treturn err\n\t}\n\taSpace.subnets = rc.subnets\n\treturn nil\n}", "label": 5}
{"code": "function register(gesture) {\n    // add an enable gesture options if there is no given\n    var options = gesture.defaults || {};\n    if(options[gesture.name] === undefined) {\n      options[gesture.name] = true;\n    }\n\n    // extend Hammer default options with the Hammer.gesture options\n    Hammer.utils.extend(Hammer.defaults, options, true);\n\n    // set its index\n    gesture.index = gesture.index || 1000;\n\n    // add Hammer.gesture to the list\n    this.gestures.push(gesture);\n\n    // sort the list by index\n    this.gestures.sort(function(a, b) {\n      if(a.index < b.index) { return -1; }\n      if(a.index > b.index) { return 1; }\n      return 0;\n    });\n\n    return this.gestures;\n  }", "label": 3}
{"code": "def default_parallel_manager\n      @default_parallel_manager ||= begin\n        adapter = @builder.adapter.klass if @builder.adapter\n\n        if support_parallel?(adapter)\n          adapter.setup_parallel_manager\n        elsif block_given?\n          yield\n        end\n      end\n    end", "label": 4}
{"code": "def fields=(fields)\n      @fields = fields.collect do |field|\n        r = field.intern\n        raise ArgumentError.new(_(\"Cannot have fields named %{name}\") % { name: r }) if INVALID_FIELDS.include?(r)\n        r\n      end\n    end", "label": 4}
{"code": "func GetIPNetCanonical(nw *net.IPNet) *net.IPNet {\n\tif nw == nil {\n\t\treturn nil\n\t}\n\tc := GetIPNetCopy(nw)\n\tc.IP = c.IP.Mask(nw.Mask)\n\treturn c\n}", "label": 5}
{"code": "def json_loads(inbox):\n    \"\"\"\n    Deserializes the first element of the input using the JSON protocol as \n    implemented by the ``json`` Python 2.6 library.\n    \n    \"\"\"\n    gc.disable()\n    obj = json.loads(inbox[0])\n    gc.enable()\n    return obj", "label": 1}
{"code": "private function buildListObjectsIterator(array $options)\n    {\n        // Extract and normalize the date values from the options\n        $startDate = isset($options[self::START_DATE])\n            ? $this->normalizeDateValue($options[self::START_DATE])\n            : null;\n        $endDate = isset($options[self::END_DATE])\n            ? $this->normalizeDateValue($options[self::END_DATE])\n            : null;\n\n        // Determine the parts of the key prefix of the log files being read\n        $parts = [\n            'prefix' => isset($options[self::KEY_PREFIX])\n                    ? $options[self::KEY_PREFIX]\n                    : null,\n            'account' => isset($options[self::ACCOUNT_ID])\n                    ? $options[self::ACCOUNT_ID]\n                    : self::PREFIX_WILDCARD,\n            'region' => isset($options[self::LOG_REGION])\n                    ? $options[self::LOG_REGION]\n                    : self::PREFIX_WILDCARD,\n            'date' => $this->determineDateForPrefix($startDate, $endDate),\n        ];\n\n        // Determine the longest key prefix that can be used to retrieve all\n        // of the relevant log files.\n        $candidatePrefix = ltrim(strtr(self::PREFIX_TEMPLATE, $parts), '/');\n        $logKeyPrefix = $candidatePrefix;\n        $index = strpos($candidatePrefix, self::PREFIX_WILDCARD);\n\n        if ($index !== false) {\n            $logKeyPrefix = substr($candidatePrefix, 0, $index);\n        }\n\n        // Create an iterator that will emit all of the objects matching the\n        // key prefix.\n        $objectsIterator = $this->s3Client->getIterator('ListObjects', [\n            'Bucket' => $this->s3BucketName,\n            'Prefix' => $logKeyPrefix,\n        ]);\n\n        // Apply regex and/or date filters to the objects iterator to emit only\n        // log files matching the options.\n        $objectsIterator = $this->applyRegexFilter(\n            $objectsIterator,\n            $logKeyPrefix,\n            $candidatePrefix\n        );\n\n        $objectsIterator = $this->applyDateFilter(\n            $objectsIterator,\n            $startDate,\n            $endDate\n        );\n\n        return $objectsIterator;\n    }", "label": 2}
{"code": "def webhooks\n      raise 'Tried to request webhooks from a non-server channel' unless server\n\n      webhooks = JSON.parse(API::Channel.webhooks(@bot.token, @id))\n      webhooks.map { |webhook_data| Webhook.new(webhook_data, @bot) }\n    end", "label": 4}
{"code": "function (width, height, animation) {\n            var chart = this,\n              chartWidth,\n              chartHeight,\n              fireEndResize;\n\n            // Handle the isResizing counter\n            chart.isResizing += 1;\n            fireEndResize = function () {\n                if (chart) {\n                    fireEvent(chart, 'endResize', null, function () {\n                        chart.isResizing -= 1;\n                    });\n                }\n            };\n\n            // set the animation for the current process\n            setAnimation(animation, chart);\n\n            chart.oldChartHeight = chart.chartHeight;\n            chart.oldChartWidth = chart.chartWidth;\n            if (defined(width)) {\n                chart.chartWidth = chartWidth = mathMax(0, mathRound(width));\n                chart.hasUserSize = !!chartWidth;\n            }\n            if (defined(height)) {\n                chart.chartHeight = chartHeight = mathMax(0, mathRound(height));\n            }\n\n            // Resize the container with the global animation applied if enabled (#2503)\n            (globalAnimation ? animate : css)(chart.container, {\n                width: chartWidth + PX,\n                height: chartHeight + PX\n            }, globalAnimation);\n\n            chart.setChartSize(true);\n            chart.renderer.setSize(chartWidth, chartHeight, animation);\n\n            // handle axes\n            chart.maxTicks = null;\n            each(chart.axes, function (axis) {\n                axis.isDirty = true;\n                axis.setScale();\n            });\n\n            // make sure non-cartesian series are also handled\n            each(chart.series, function (serie) {\n                serie.isDirty = true;\n            });\n\n            chart.isDirtyLegend = true; // force legend redraw\n            chart.isDirtyBox = true; // force redraw of plot and chart border\n\n            chart.layOutTitles(); // #2857\n            chart.getMargins();\n\n            chart.redraw(animation);\n\n\n            chart.oldChartHeight = null;\n            fireEvent(chart, 'resize');\n\n            // fire endResize and set isResizing back\n            // If animation is disabled, fire without delay\n            if (globalAnimation === false) {\n                fireEndResize();\n            } else { // else set a timeout with the animation duration\n                setTimeout(fireEndResize, (globalAnimation && globalAnimation.duration) || 500);\n            }\n        }", "label": 3}
{"code": "def _init_boto3_clients(self):\n        \"\"\"\n        The utililty requires boto3 clients to Cloud Formation and S3. Here is\n        where we make them.\n\n        Args:\n            None\n\n        Returns:\n            Good or Bad; True or False\n        \"\"\"\n        try:\n            profile = self._config.get('environment', {}).get('profile')\n            region = self._config.get('environment', {}).get('region')\n            if profile:\n                self._b3Sess = boto3.session.Session(profile_name=profile)\n            else:\n                self._b3Sess = boto3.session.Session()\n\n            self._s3 = self._b3Sess.client('s3')\n            self._cloudFormation = self._b3Sess.client('cloudformation', region_name=region)\n            self._ssm = self._b3Sess.client('ssm', region_name=region)\n\n            return True\n        except Exception as wtf:\n            logging.error('Exception caught in intialize_session(): {}'.format(wtf))\n            traceback.print_exc(file=sys.stdout)\n            return False", "label": 1}
{"code": "function loadFileAsString(path, replaceWhiteSpaces){\r\n\r\n\tvar file = new java.io.File(path);\r\n\tvar fr = new java.io.FileReader(file);\r\n\tvar br = new java.io.BufferedReader(fr);\r\n\r\n\tvar line;\r\n\tvar lines = \"\";\r\n\r\n\twhile((line = br.readLine()) != null){\r\n\r\n\t\tif(replaceWhiteSpaces){\r\n\r\n\t\t\tlines = lines + line.replace(\" \", \"\");\r\n\r\n\t\t}else{\r\n\r\n\t\t\tlines = lines + line;\r\n\t\t}\r\n\t}\r\n\r\n\treturn lines;\r\n}", "label": 3}
{"code": "def boost_ranks(job, isoform_expression, merged_mhc_calls, transgene_out, univ_options,\n                rank_boost_options):\n    \"\"\"\n    This is the final module in the pipeline.  It will call the rank boosting R\n    script.\n\n    This module corresponds to node 21 in the tree\n    \"\"\"\n    job.fileStore.logToMaster('Running boost_ranks on %s' % univ_options['patient'])\n    work_dir = os.path.join(job.fileStore.getLocalTempDir(), univ_options['patient'])\n    os.mkdir(work_dir)\n    input_files = {\n        'rsem_quant.tsv': isoform_expression,\n        'mhci_merged_files.tsv': merged_mhc_calls['mhci_merged_files.list'],\n        'mhcii_merged_files.tsv': merged_mhc_calls['mhcii_merged_files.list'],\n        'mhci_peptides.faa': transgene_out['transgened_tumor_10_mer_snpeffed.faa'],\n        'mhcii_peptides.faa': transgene_out['transgened_tumor_15_mer_snpeffed.faa']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    output_files = {}\n    for mhc in ('mhci', 'mhcii'):\n        parameters = [mhc,\n                      input_files[''.join([mhc, '_merged_files.tsv'])],\n                      input_files['rsem_quant.tsv'],\n                      input_files[''.join([mhc, '_peptides.faa'])],\n                      rank_boost_options[''.join([mhc, '_combo'])]\n                      ]\n        docker_call(tool='rankboost', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'])\n        output_files[mhc] = {\n            ''.join([mhc, '_concise_results.tsv']):\n                job.fileStore.writeGlobalFile(''.join([work_dir, '/', mhc,\n                                                       '_merged_files_concise_results.tsv'])),\n            ''.join([mhc, '_detailed_results.tsv']):\n                job.fileStore.writeGlobalFile(''.join([work_dir, '/', mhc,\n                                                       '_merged_files_detailed_results.tsv']))}\n    export_results(work_dir, univ_options)\n    return output_files", "label": 1}
{"code": "def carpet(timeseries, **kwargs):\n    \"\"\"\n    Draw a carpet plot of a pandas timeseries.\n\n    The carpet plot reads like a letter. Every day one line is added to the\n    bottom of the figure, minute for minute moving from left (morning) to right\n    (evening).\n    The color denotes the level of consumption and is scaled logarithmically.\n    If vmin and vmax are not provided as inputs, the minimum and maximum of the\n    colorbar represent the minimum and maximum of the (resampled) timeseries.\n\n    Parameters\n    ----------\n    timeseries : pandas.Series\n    vmin, vmax : If not None, either or both of these values determine the range\n    of the z axis. If None, the range is given by the minimum and/or maximum\n    of the (resampled) timeseries.\n    zlabel, title : If not None, these determine the labels of z axis and/or\n    title. If None, the name of the timeseries is used if defined.\n    cmap : matplotlib.cm instance, default coolwarm\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import pandas as pd\n    >>> from opengrid.library import plotting\n    >>> plt = plotting.plot_style()\n    >>> index = pd.date_range('2015-1-1','2015-12-31',freq='h')\n    >>> ser = pd.Series(np.random.normal(size=len(index)), index=index, name='abc')\n    >>> im = plotting.carpet(ser)\n    \"\"\"\n\n    # define optional input parameters\n    cmap = kwargs.pop('cmap', cm.coolwarm)\n    norm = kwargs.pop('norm', LogNorm())\n    interpolation = kwargs.pop('interpolation', 'nearest')\n    cblabel = kwargs.pop('zlabel', timeseries.name if timeseries.name else '')\n    title = kwargs.pop('title', 'carpet plot: ' + timeseries.name if timeseries.name else '')\n\n    # data preparation\n    if timeseries.dropna().empty:\n        print('skipped {} - no data'.format(title))\n        return\n    ts = timeseries.resample('15min').interpolate()\n    vmin = max(0.1, kwargs.pop('vmin', ts[ts > 0].min()))\n    vmax = max(vmin, kwargs.pop('vmax', ts.quantile(.999)))\n\n    # convert to dataframe with date as index and time as columns by\n    # first replacing the index by a MultiIndex\n    mpldatetimes = date2num(ts.index.to_pydatetime())\n    ts.index = pd.MultiIndex.from_arrays(\n        [np.floor(mpldatetimes), 2 + mpldatetimes % 1])  # '2 +': matplotlib bug workaround.\n    # and then unstacking the second index level to columns\n    df = ts.unstack()\n\n    # data plotting\n\n    fig, ax = plt.subplots()\n    # define the extent of the axes (remark the +- 0.5  for the y axis in order to obtain aligned date ticks)\n    extent = [df.columns[0], df.columns[-1], df.index[-1] + 0.5, df.index[0] - 0.5]\n    im = plt.imshow(df, vmin=vmin, vmax=vmax, extent=extent, cmap=cmap, aspect='auto', norm=norm,\n                    interpolation=interpolation, **kwargs)\n\n    # figure formatting\n\n    # x axis\n    ax.xaxis_date()\n    ax.xaxis.set_major_locator(HourLocator(interval=2))\n    ax.xaxis.set_major_formatter(DateFormatter('%H:%M'))\n    ax.xaxis.grid(True)\n    plt.xlabel('UTC Time')\n\n    # y axis\n    ax.yaxis_date()\n    dmin, dmax = ax.yaxis.get_data_interval()\n    number_of_days = (num2date(dmax) - num2date(dmin)).days\n    # AutoDateLocator is not suited in case few data is available\n    if abs(number_of_days) <= 35:\n        ax.yaxis.set_major_locator(DayLocator())\n    else:\n        ax.yaxis.set_major_locator(AutoDateLocator())\n    ax.yaxis.set_major_formatter(DateFormatter(\"%a, %d %b %Y\"))\n\n    # plot colorbar\n    cbticks = np.logspace(np.log10(vmin), np.log10(vmax), 11, endpoint=True)\n    cb = plt.colorbar(format='%.0f', ticks=cbticks)\n    cb.set_label(cblabel)\n\n    # plot title\n    plt.title(title)\n\n    return im", "label": 1}
{"code": "func (f *Fpdf) parsepng(r io.Reader, readdpi bool) (info *ImageInfoType) {\n\tbuf, err := bufferFromReader(r)\n\tif err != nil {\n\t\tf.err = err\n\t\treturn\n\t}\n\treturn f.parsepngstream(buf, readdpi)\n}", "label": 5}
{"code": "function configure(config) {\n    var key,\n        layout = null,\n        fields = {},\n        options = {\n            port: (typeof config.port === \"number\") ? config.port : 5959,\n            host: (typeof config.host === \"string\") ? config.host : 'localhost',\n            debug: config.debug || false\n        };\n\n    if (config.batch) {\n        options.batch = true;\n        options.batchSize = config.batch.size;\n        options.batchTimeout = config.batch.timeout;\n    }\n\n    if (config.fields && typeof config.fields === 'object') {\n        for (key in config.fields) {\n            if (typeof config.fields[key] !== 'function') {\n                fields[key] = config.fields[key];\n            }\n        }\n    }\n    return logStashAppender(options, fields, layout);\n}", "label": 3}
{"code": "public byte[] serialize() throws PersistenceBrokerException\r\n    {\r\n        // Identity is serialized and written to an ObjectOutputStream\r\n        // This ObjectOutputstream is compressed by a GZIPOutputStream\r\n        // and finally written to a ByteArrayOutputStream.\r\n        // the resulting byte[] is returned\r\n        try\r\n        {\r\n            final ByteArrayOutputStream bao = new ByteArrayOutputStream();\r\n            final GZIPOutputStream gos = new GZIPOutputStream(bao);\r\n            final ObjectOutputStream oos = new ObjectOutputStream(gos);\r\n            oos.writeObject(this);\r\n            oos.close();\r\n            gos.close();\r\n            bao.close();\r\n            return bao.toByteArray();\r\n        }\r\n        catch (Exception ignored)\r\n        {\r\n            throw new PersistenceBrokerException(ignored);\r\n        }\r\n    }", "label": 0}
{"code": "public static function store(EntriesRepository $storage)\n    {\n        if (empty(static::$entriesQueue) && empty(static::$updatesQueue)) {\n            return;\n        }\n\n        if (! collect(static::$filterBatchUsing)->every->__invoke(collect(static::$entriesQueue))) {\n            static::flushEntries();\n        }\n\n        try {\n            $batchId = Str::orderedUuid()->toString();\n\n            $storage->store(static::collectEntries($batchId));\n            $storage->update(static::collectUpdates($batchId));\n\n            if ($storage instanceof TerminableRepository) {\n                $storage->terminate();\n            }\n        } catch (Exception $e) {\n            app(ExceptionHandler::class)->report($e);\n        }\n\n        static::$entriesQueue = [];\n        static::$updatesQueue = [];\n    }", "label": 2}
{"code": "public function setValidMasterVersions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->valid_master_versions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setAdapterRoutes(array $routes)\n    {\n        $this->adapter->setRoutes($routes);\n\n        $this->container->instance('api.routes', $this->getRoutes());\n    }", "label": 2}
{"code": "public function setStartAt($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1\\Cursor::class);\n        $this->start_at = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setSpeechTranscriptions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\SpeechTranscription::class);\n        $this->speech_transcriptions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo, :sha]) do\n        assert_required REQUIRED_COMMENT_OPTIONS\n      end\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/commits/#{arguments.sha}/comments\", arguments.params)\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, responderparam resource) throws Exception {\n\t\tresponderparam updateresource = new responderparam();\n\t\tupdateresource.undefaction = resource.undefaction;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def block_param(*type_and_name)\n      case type_and_name.size\n      when 0\n        type = @all_callables\n        name = :block\n      when 1\n        type = @all_callables\n        name = type_and_name[0]\n      when 2\n        type, name = type_and_name\n        type = Puppet::Pops::Types::TypeParser.singleton.parse(type, loader) unless type.is_a?(Puppet::Pops::Types::PAnyType)\n      else\n        raise ArgumentError, _(\"block_param accepts max 2 arguments (type, name), got %{size}.\") % { size: type_and_name.size }\n      end\n\n      unless Puppet::Pops::Types::TypeCalculator.is_kind_of_callable?(type, false)\n        raise ArgumentError, _(\"Expected PCallableType or PVariantType thereof, got %{type_class}\") % { type_class: type.class }\n      end\n\n      unless name.is_a?(Symbol)\n        raise ArgumentError, _(\"Expected block_param name to be a Symbol, got %{name_class}\") % { name_class: name.class }\n      end\n\n      if @block_type.nil?\n        @block_type = type\n        @block_name = name\n      else\n        raise ArgumentError, _('Attempt to redefine block')\n      end\n    end", "label": 4}
{"code": "def setHandler(self,handler,cbfn):\n\t\t'''\n\t\tRegister a handler for a particular notification type.\n\t\tThese are the types of notifications that are acceptable. \n\t\t\n\t\t| 'async-responses'\n\t\t| 'registrations-expired'\n\t\t| 'de-registrations'\n\t\t| 'reg-updates'\n\t\t| 'registrations'\n\t\t| 'notifications'\n\n\t\t:param str handler: name of the notification type\n\t\t:param fnptr cbfn: function to pass the notification channel messages to.\n\t\t:return: Nothing.\n\t\t'''\n\t\tif handler == \"async-responses\":\n\t\t\tself.async_responses_callback = cbfn\n\t\telif handler == \"registrations-expired\":\n\t\t\tself.registrations_expired_callback = cbfn\n\t\telif handler == \"de-registrations\":\n\t\t\tself.de_registrations_callback = cbfn\n\t\telif handler == \"reg-updates\":\n\t\t\tself.reg_updates_callback = cbfn\n\t\telif handler == \"registrations\":\n\t\t\tself.registrations_callback = cbfn\n\t\telif handler == \"notifications\":\n\t\t\tself.notifications_callback = cbfn\n\t\telse:\n\t\t\tself.log.warn(\"'%s' is not a legitimate notification channel option. Please check your spelling.\",handler)", "label": 1}
{"code": "public static function applicationName($project, $tenant, $profile, $application)\n    {\n        return self::getApplicationNameTemplate()->render([\n            'project' => $project,\n            'tenant' => $tenant,\n            'profile' => $profile,\n            'application' => $application,\n        ]);\n    }", "label": 2}
{"code": "public static base_response unset(nitro_service client, clusterinstance resource, String[] args) throws Exception{\n\t\tclusterinstance unsetresource = new clusterinstance();\n\t\tunsetresource.clid = resource.clid;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def store_offset(message)\n      # rd_kafka_offset_store is one of the few calls that does not support\n      # a string as the topic, so create a native topic for it.\n      native_topic = Rdkafka::Bindings.rd_kafka_topic_new(\n        @native_kafka,\n        message.topic,\n        nil\n      )\n      response = Rdkafka::Bindings.rd_kafka_offset_store(\n        native_topic,\n        message.partition,\n        message.offset\n      )\n      if response != 0\n        raise Rdkafka::RdkafkaError.new(response)\n      end\n    ensure\n      if native_topic && !native_topic.null?\n        Rdkafka::Bindings.rd_kafka_topic_destroy(native_topic)\n      end\n    end", "label": 4}
{"code": "function (values) {\n            var record = {};\n            _gpfArrayForEach(this._columns, function (name, idx) {\n                var value = values[idx];\n                if (value !== undefined) {\n                    record[name] = values[idx];\n                }\n            });\n            return record;\n        }", "label": 3}
{"code": "function (path) {\n        var name = _gpfPathName(path),\n            pos = name.lastIndexOf(\".\");\n        if (pos === _GPF_NOT_FOUND) {\n            return name;\n        }\n        return name.substring(_GPF_START, pos);\n    }", "label": 3}
{"code": "function removeFromArrayByNode(node, eleNode) {\n  const elements = node.elements;\n\n  if (!elements.includes(eleNode)) {\n    logger.warn('Failed to find element when trying to remove element from array.');\n    return [];\n  }\n\n  if (!node._filePath) {\n    throw new Error('No _filePath property found on node when removing element from array');\n  }\n\n  const content = vio.getContent(node._filePath);\n\n  let startPos = nearestCharBefore(',', content, eleNode.start);\n  let isFirstElement = false;\n  if (startPos < 0) {\n    // it's the first element\n    isFirstElement = true;\n    startPos = node.start + 1; // start from the char just after the '['\n  }\n\n  let endPos = eleNode.end;\n\n  if (elements.length === 1 || isFirstElement) {\n    // if the element is the only element, try to remove the trailing comma if exists\n    const nextComma = nearestCharAfter(',', content, endPos - 1);\n    if (nextComma >= 0) endPos = nextComma + 1;\n  }\n\n  return [\n    {\n      start: startPos,\n      end: endPos,\n      replacement: '',\n    },\n  ];\n}", "label": 3}
{"code": "func (r *Registry) getEntityComputeResource(item mo.Entity) mo.Entity {\n\tfor {\n\t\tparent := item.Entity().Parent\n\n\t\titem = r.Get(*parent).(mo.Entity)\n\n\t\tswitch item.Reference().Type {\n\t\tcase \"ComputeResource\":\n\t\t\treturn item\n\t\tcase \"ClusterComputeResource\":\n\t\t\treturn item\n\t\t}\n\t}\n}", "label": 5}
{"code": "function matchFileNames(fileNames, include, exclude, basePath, options, host, errors) {\n        basePath = ts.normalizePath(basePath);\n        // The exclude spec list is converted into a regular expression, which allows us to quickly\n        // test whether a file or directory should be excluded before recursively traversing the\n        // file system.\n        var keyMapper = host.useCaseSensitiveFileNames ? caseSensitiveKeyMapper : caseInsensitiveKeyMapper;\n        // Literal file names (provided via the \"files\" array in tsconfig.json) are stored in a\n        // file map with a possibly case insensitive key. We use this map later when when including\n        // wildcard paths.\n        var literalFileMap = ts.createMap();\n        // Wildcard paths (provided via the \"includes\" array in tsconfig.json) are stored in a\n        // file map with a possibly case insensitive key. We use this map to store paths matched\n        // via wildcard, and to handle extension priority.\n        var wildcardFileMap = ts.createMap();\n        if (include) {\n            include = validateSpecs(include, errors, /*allowTrailingRecursion*/ false);\n        }\n        if (exclude) {\n            exclude = validateSpecs(exclude, errors, /*allowTrailingRecursion*/ true);\n        }\n        // Wildcard directories (provided as part of a wildcard path) are stored in a\n        // file map that marks whether it was a regular wildcard match (with a `*` or `?` token),\n        // or a recursive directory. This information is used by filesystem watchers to monitor for\n        // new entries in these paths.\n        var wildcardDirectories = getWildcardDirectories(include, exclude, basePath, host.useCaseSensitiveFileNames);\n        // Rather than requery this for each file and filespec, we query the supported extensions\n        // once and store it on the expansion context.\n        var supportedExtensions = ts.getSupportedExtensions(options);\n        // Literal files are always included verbatim. An \"include\" or \"exclude\" specification cannot\n        // remove a literal file.\n        if (fileNames) {\n            for (var _i = 0, fileNames_1 = fileNames; _i < fileNames_1.length; _i++) {\n                var fileName = fileNames_1[_i];\n                var file = ts.combinePaths(basePath, fileName);\n                literalFileMap[keyMapper(file)] = file;\n            }\n        }\n        if (include && include.length > 0) {\n            for (var _a = 0, _b = host.readDirectory(basePath, supportedExtensions, exclude, include); _a < _b.length; _a++) {\n                var file = _b[_a];\n                // If we have already included a literal or wildcard path with a\n                // higher priority extension, we should skip this file.\n                //\n                // This handles cases where we may encounter both <file>.ts and\n                // <file>.d.ts (or <file>.js if \"allowJs\" is enabled) in the same\n                // directory when they are compilation outputs.\n                if (hasFileWithHigherPriorityExtension(file, literalFileMap, wildcardFileMap, supportedExtensions, keyMapper)) {\n                    continue;\n                }\n                // We may have included a wildcard path with a lower priority\n                // extension due to the user-defined order of entries in the\n                // \"include\" array. If there is a lower priority extension in the\n                // same directory, we should remove it.\n                removeWildcardFilesWithLowerPriorityExtension(file, wildcardFileMap, supportedExtensions, keyMapper);\n                var key = keyMapper(file);\n                if (!(key in literalFileMap) && !(key in wildcardFileMap)) {\n                    wildcardFileMap[key] = file;\n                }\n            }\n        }\n        var literalFiles = ts.reduceProperties(literalFileMap, addFileToOutput, []);\n        var wildcardFiles = ts.reduceProperties(wildcardFileMap, addFileToOutput, []);\n        wildcardFiles.sort(host.useCaseSensitiveFileNames ? ts.compareStrings : ts.compareStringsCaseInsensitive);\n        return {\n            fileNames: literalFiles.concat(wildcardFiles),\n            wildcardDirectories: wildcardDirectories\n        };\n    }", "label": 3}
{"code": "def _remove_document(self, gh_user, doc_id, parent_sha, author, commit_msg=None):\n        \"\"\"Remove a document\n        Remove a document on the given branch and attribute the commit to author.\n        Returns the SHA of the commit on branch.\n        \"\"\"\n        # _LOG.debug(\"@@@@@@@@ GitActionBase._remove_document, doc_id={}\".format(doc_id))\n        doc_filepath = self.path_for_doc(doc_id)\n        # _LOG.debug(\"@@@@@@@@ GitActionBase._remove_document, doc_filepath={}\".format(doc_filepath))\n\n        branch = self.create_or_checkout_branch(gh_user, doc_id, parent_sha)\n        prev_file_sha = None\n        if commit_msg is None:\n            msg = \"Delete document '%s' via OpenTree API\" % doc_id\n        else:\n            msg = commit_msg\n        if os.path.exists(doc_filepath):\n            prev_file_sha = self.get_blob_sha_for_file(doc_filepath)\n            if self.doc_type == 'nexson':\n                # delete the parent directory entirely\n                doc_dir = os.path.split(doc_filepath)[0]\n                # _LOG.debug(\"@@@@@@@@ GitActionBase._remove_document, doc_dir={}\".format(doc_dir))\n                git(self.gitdir, self.gitwd, \"rm\", \"-rf\", doc_dir)\n            elif self.doc_type in ('collection', 'favorites', 'amendment'):\n                # delete just the target file\n                git(self.gitdir, self.gitwd, \"rm\", doc_filepath)\n            else:\n                raise NotImplementedError(\"No deletion rules for doc_type '{}'\".format(self.doc_type))\n            git(self.gitdir,\n                self.gitwd,\n                \"commit\",\n                author=author,\n                message=msg)\n        new_sha = git(self.gitdir, self.gitwd, \"rev-parse\", \"HEAD\").strip()\n        return {'commit_sha': new_sha,\n                'branch': branch,\n                'prev_file_sha': prev_file_sha,\n                }", "label": 1}
{"code": "def all_builtin_hook_configs\n      hook_configs = {}\n\n      Overcommit::Utils.supported_hook_type_classes.each do |hook_type|\n        hook_names = @hash[hook_type].keys.reject { |name| name == 'ALL' }\n\n        hook_configs[hook_type] = Hash[\n          hook_names.map do |hook_name|\n            [hook_name, for_hook(hook_name, hook_type)]\n          end\n        ]\n      end\n\n      hook_configs\n    end", "label": 4}
{"code": "function(text) {\n        var openItalic = false,\n            cText = [],\n            italicStart = new RegExp(/\\{italic\\}/),\n            commandBreak = new RegExp(/\\{break\\}/),\n            italicEnd = new RegExp(/\\{end-italic\\}/),\n            finalText = \"\",\n            textArray = text.split(''),\n            idx = 0;\n\n        for (idx = 0; idx <= textArray.length; idx++) {\n            cText.push(textArray[idx]);\n            if (italicStart.test(cText.join('')) && openItalic === false) {\n                // found an italic start, push to array, reset.\n                finalText += cText.join('');\n                cText = [];\n                openItalic = true;\n            } else if (commandBreak.test(cText.join('')) && openItalic === false) {\n                finalText += cText.join('');\n                cText = [];\n                openItalic = false;\n            } else if (commandBreak.test(cText.join('')) && openItalic === true) {\n                finalText += cText.join('').replace(commandBreak, '{end-italic}{break}');\n                cText = [];\n                openItalic = false;\n            } else if (italicStart.test(cText.join('')) && openItalic === true) {\n                // found an italic start within another italic...prepend an end\n                finalText += cText.join('').replace(italicStart, '');\n                cText = [];\n                openItalic = true;\n            } else if (italicEnd.test(cText.join('')) && openItalic === true) {\n                finalText += cText.join('');\n                cText = [];\n                openItalic = false;\n            } else if (italicEnd.test(cText.join('')) && openItalic === false) {\n                //drop useless end italics that are out of place.\n                finalText += cText.join('').replace(italicEnd, '');\n                cText = [];\n                openItalic = false;\n            }\n            if (idx === text.length) {\n                if (openItalic) {\n                    finalText += cText.join('') + '{end-italic}';\n                } else {\n                    finalText += cText.join('');\n                }\n\n                cText = [];\n            }\n        }\n\n        return finalText;\n\n    }", "label": 3}
{"code": "protected function cleanValueFrom($name, $value, array &$values = [])\n    {\n        if (str_contains($name, '[')) {\n            $name = str_replace(['][', '[', ']', '..'], ['.', '.', '', '.*.'], $name);\n        }\n        array_set($values, str_replace('.*', '.0', $name), $value);\n    }", "label": 2}
{"code": "function parse(primus, raw, res) {\n  var called = 0\n    , data\n    , err;\n\n  try {\n    data = JSON.parse(raw);\n  } catch (e) {\n    err = e;\n  }\n\n  if (\n       err                              // No error..\n    || 'object' !== typeof data         // Should be an object.\n    || Array.isArray(data)              // A real object, not array.\n    || !data.msg                        // The data we send should be defined.\n  ) {\n    res.statusCode = 500;\n    res.setHeader('Content-Type', 'application/json');\n    return res.end('{ \"ok\": false, \"reason\": \"invalid data structure\" }');\n  }\n\n  //\n  // Process the incoming messages in three different modes:\n  //\n  // Sparks: The data.sparks is an array with spark id's which we should write\n  //         the data to.\n  // Spark:  The data.sparks is the id of one single individual spark which\n  //         should receive the data.\n  // All:    Broadcast the message to every single connected spark if no\n  //         `data.sparks` has been provided.\n  //\n  if (Array.isArray(data.sparks)) {\n    data.sparks.forEach(function each(id) {\n      var spark = primus.spark(id);\n\n      if (spark) {\n        spark.write(data.msg);\n        called++;\n      }\n    });\n  } else if ('string' === typeof data.sparks && data.sparks) {\n    var spark = primus.spark(data.sparks);\n\n    if (spark) {\n      spark.write(data.msg);\n      called++;\n    }\n  } else {\n    primus.forEach(function each(spark) {\n      spark.write(data.msg);\n      called++;\n    });\n  }\n\n  res.statusCode = 200;\n  res.setHeader('Content-Type', 'application/json');\n  res.end('{ \"ok\": true, \"send\":'+ called +' }');\n}", "label": 3}
{"code": "def end_document implicit_end = !streaming?\n      @last.implicit_end = implicit_end\n      n = pop\n      set_end_location(n)\n      n\n    end", "label": 4}
{"code": "def connects_to(database: {})\n      connections = []\n\n      database.each do |role, database_key|\n        config_hash = resolve_config_for_connection(database_key)\n        handler = lookup_connection_handler(role.to_sym)\n\n        connections << handler.establish_connection(config_hash)\n      end\n\n      connections\n    end", "label": 4}
{"code": "function(callback, properties, values, equals)\n  {\n    var where = createWhere( properties, values, equals );\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var item = this[ i ];\n\n      if ( where( item ) )\n      {\n        callback.call( this, item, i );\n\n        if ( this[ i ] !== item )\n        {\n          i--;\n        }\n      }\n    }\n\n    return this;\n  }", "label": 3}
{"code": "public static lbvserver_appflowpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_appflowpolicy_binding obj = new lbvserver_appflowpolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_appflowpolicy_binding response[] = (lbvserver_appflowpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func Logger() Handler {\n\treturn func(res http.ResponseWriter, req *http.Request, c Context, log *log.Logger) {\n\t\tstart := time.Now()\n\n\t\taddr := req.Header.Get(\"X-Real-IP\")\n\t\tif addr == \"\" {\n\t\t\taddr = req.Header.Get(\"X-Forwarded-For\")\n\t\t\tif addr == \"\" {\n\t\t\t\taddr = req.RemoteAddr\n\t\t\t}\n\t\t}\n\n\t\tlog.Printf(\"Started %s %s for %s\", req.Method, req.URL.Path, addr)\n\n\t\trw := res.(ResponseWriter)\n\t\tc.Next()\n\n\t\tlog.Printf(\"Completed %v %s in %v\\n\", rw.Status(), http.StatusText(rw.Status()), time.Since(start))\n\t}\n}", "label": 5}
{"code": "public function table($instanceId, $tableId, array $options = [])\n    {\n        return new Table(\n            $this->gapicClient,\n            GapicClient::tableName($this->projectId, $instanceId, $tableId),\n            $options\n        );\n    }", "label": 2}
{"code": "def start_document version, tag_directives, implicit\n      n = Nodes::Document.new version, tag_directives, implicit\n      set_start_location(n)\n      @last.children << n\n      push n\n    end", "label": 4}
{"code": "def setup_callables(self):\n        \"\"\"\n            Setup Callable attributes that belong to this object.\n        \"\"\"\n        defaults = self.get_default_callables()\n        for key, value in list(defaults.items()):\n            self._postponed_callables.setdefault(key, value)\n        for key in self.callables:\n            value = self._postponed_callables.pop(key)\n            value.setup_callable_system(self.system, init=True)\n            setattr(self, key, value)", "label": 1}
{"code": "func CreateCommand(cfg Config) (Command, error) {\n\terr := cfg.CheckAndSetDefaults()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tcmd := command{\n\t\tConfig: cfg,\n\t}\n\n\tcmd.log = log.WithFields(log.Fields{\n\t\ttrace.Component: \"SCP\",\n\t\ttrace.ComponentFields: log.Fields{\n\t\t\t\"LocalAddr\":      cfg.Flags.LocalAddr,\n\t\t\t\"RemoteAddr\":     cfg.Flags.RemoteAddr,\n\t\t\t\"Target\":         cfg.Flags.Target,\n\t\t\t\"User\":           cfg.User,\n\t\t\t\"RunOnServer\":    cfg.RunOnServer,\n\t\t\t\"RemoteLocation\": cfg.RemoteLocation,\n\t\t},\n\t})\n\n\treturn &cmd, nil\n}", "label": 5}
{"code": "function applyTags(Class, addTags, fieldName, descriptor) {\n  var tags = (Array.isArray(addTags) && addTags || []).map(function (tag) {\n    return typeof tag === 'string' && Symbol.for(tag) || tag;\n  }).filter(function (tag) {\n    return (0, _typeof2.default)(tag) === 'symbol';\n  });\n  tags.forEach(function (tag) {\n    Class[_GQLBase.META_KEY][tag] = Class[_GQLBase.META_KEY][tag] || {};\n    Class[_GQLBase.META_KEY][tag][fieldName] = descriptor;\n  });\n}", "label": 3}
{"code": "function captionTransition(caption, duration) {\n          if (caption.hasClass(\"center-align\")) {\n            caption.velocity({opacity: 0, translateY: -100}, {duration: duration, queue: false});\n          }\n          else if (caption.hasClass(\"right-align\")) {\n            caption.velocity({opacity: 0, translateX: 100}, {duration: duration, queue: false});\n          }\n          else if (caption.hasClass(\"left-align\")) {\n            caption.velocity({opacity: 0, translateX: -100}, {duration: duration, queue: false});\n          }\n        }", "label": 3}
{"code": "function (req, res) {\n        const spaceName = req.params.name;\n        const geometry = _getSpaceGeometries()[spaceName];\n        if (Utils.isNullOrEmpty(geometry)) {\n            log.error('Invalid Space', 'name:', spaceName);\n            Utils.sendMessage(res, HttpStatus.BAD_REQUEST, JSON.stringify({ error: 'invalid space' }));\n        } else {\n            log.debug('Returning geometry for space:', spaceName);\n            Utils.sendMessage(res, HttpStatus.OK, JSON.stringify(geometry));\n        }\n    }", "label": 3}
{"code": "def replace(*args)\n      arguments(args, required: [:user, :repo, :number])\n      params = arguments.params\n      params['data'] = arguments.remaining unless arguments.remaining.empty?\n\n      put_request(\"/repos/#{arguments.user}/#{arguments.repo}/issues/#{arguments.number}/labels\", params)\n    end", "label": 4}
{"code": "func (c *NodeCommand) Initialize(app *kingpin.Application, config *service.Config) {\n\tc.config = config\n\n\t// add node command\n\tnodes := app.Command(\"nodes\", \"Issue invites for other nodes to join the cluster\")\n\tc.nodeAdd = nodes.Command(\"add\", \"Generate a node invitation token\")\n\tc.nodeAdd.Flag(\"roles\", \"Comma-separated list of roles for the new node to assume [node]\").Default(\"node\").StringVar(&c.roles)\n\tc.nodeAdd.Flag(\"ttl\", \"Time to live for a generated token\").Default(defaults.ProvisioningTokenTTL.String()).DurationVar(&c.ttl)\n\tc.nodeAdd.Flag(\"token\", \"Custom token to use, autogenerated if not provided\").StringVar(&c.token)\n\tc.nodeAdd.Flag(\"format\", \"Output format, 'text' or 'json'\").Hidden().Default(\"text\").StringVar(&c.format)\n\tc.nodeAdd.Alias(AddNodeHelp)\n\n\tc.nodeList = nodes.Command(\"ls\", \"List all active SSH nodes within the cluster\")\n\tc.nodeList.Flag(\"namespace\", \"Namespace of the nodes\").Default(defaults.Namespace).StringVar(&c.namespace)\n\tc.nodeList.Alias(ListNodesHelp)\n}", "label": 5}
{"code": "def translate key = nil, scope: nil, retries: nil, timeout: nil\n      Google::Cloud.translate key, project_id: @project, credentials: @keyfile,\n                                   scope: scope,\n                                   retries: (retries || @retries),\n                                   timeout: (timeout || @timeout)\n    end", "label": 4}
{"code": "def conjunction_code\n      case @type\n      when HQMF::PopulationCriteria::IPP, HQMF::PopulationCriteria::DENOM, HQMF::PopulationCriteria::NUMER,\n           HQMF::PopulationCriteria::MSRPOPL, HQMF::PopulationCriteria::STRAT\n        HQMF::Precondition::ALL_TRUE\n      when HQMF::PopulationCriteria::DENEXCEP, HQMF::PopulationCriteria::DENEX, HQMF::PopulationCriteria::MSRPOPLEX,\n           HQMF::PopulationCriteria::NUMEX\n        HQMF::Precondition::AT_LEAST_ONE_TRUE\n      else\n        fail \"Unknown population type [#{@type}]\"\n      end\n    end", "label": 4}
{"code": "function initClient() {\n\tgapi.client.init({\n\t\tapiKey: config.api.google.web.key,\n\t\tclientId: config.api.google.web.client_id,\n\t\tdiscoveryDocs: DISCOVERY_DOCS,\n\t\tscope: SCOPES\n\t}).then(function () {\n\t\t// Listen for sign-in state changes.\n\t\tgapi.auth2.getAuthInstance().isSignedIn.listen(updateSigninStatus);\n\n\t\t// Handle the initial sign-in state.\n\t\tupdateSigninStatus(gapi.auth2.getAuthInstance().isSignedIn.get());\n\t\tauthorizeButton.onclick = handleAuthClick;\n\t\tsignoutButton.onclick = handleSignoutClick;\n\t}, function(error) {\n\t\tappendPre(JSON.stringify(error, null, 2));\n\t});\n}", "label": 3}
{"code": "def addrecords(X, new):\n    \"\"\"\n    Append one or more records to the end of a numpy recarray or ndarray .\n\n    Can take a single record, void or tuple, or a list of records, voids or \n    tuples.\n\n    Implemented by the tabarray method \n    :func:`tabular.tab.tabarray.addrecords`.\n\n    **Parameters**\n\n            **X** :  numpy ndarray with structured dtype or recarray\n\n                    The array to add records to.\n\n            **new** :  record, void or tuple, or list of them\n\n                    Record(s) to add to `X`.\n\n    **Returns**\n\n            **out** :  numpy ndarray with structured dtype\n\n                    New numpy array made up of `X` plus the new records.\n\n    **See also:**  :func:`tabular.spreadsheet.rowstack`\n\n    \"\"\"\n    if isinstance(new, np.record) or isinstance(new, np.void) or \\\n                                                        isinstance(new, tuple):\n        new = [new]\n    return np.append(X, utils.fromrecords(new, type=np.ndarray,\n                                              dtype=X.dtype), axis=0)", "label": 1}
{"code": "function (config, mockSrc, defaultScenario, filenames,\n      scenarioName) {\n    // read mock data files for this scenario\n    var scenario = filenames.map(function (filename) {\n      var filepath = fs.realpathSync(path.join(mockSrc, filename));\n\n      return {\n        scenarioName: scenarioName,\n        filename: filename,\n        scenario: require(filepath)\n      };\n    });\n\n    return scenario;\n  }", "label": 3}
{"code": "def boards\n      boards = Board.from_response client.get(\"/organizations/#{id}/boards/all\")\n      MultiAssociation.new(self, boards).proxy\n    end", "label": 4}
{"code": "public static nsacl_stats[] get(nitro_service service) throws Exception{\n\t\tnsacl_stats obj = new nsacl_stats();\n\t\tnsacl_stats[] response = (nsacl_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func PgDefaultACLByDefaclroleDefaclnamespaceDefaclobjtype(db XODB, defaclrole pgtypes.Oid, defaclnamespace pgtypes.Oid, defaclobjtype uint8) (*PgDefaultACL, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, defaclrole, defaclnamespace, defaclobjtype, defaclacl ` +\n\t\t`FROM pg_catalog.pg_default_acl ` +\n\t\t`WHERE defaclrole = $1 AND defaclnamespace = $2 AND defaclobjtype = $3`\n\n\t// run query\n\tXOLog(sqlstr, defaclrole, defaclnamespace, defaclobjtype)\n\tpda := PgDefaultACL{}\n\n\terr = db.QueryRow(sqlstr, defaclrole, defaclnamespace, defaclobjtype).Scan(&pda.Tableoid, &pda.Cmax, &pda.Xmax, &pda.Cmin, &pda.Xmin, &pda.Oid, &pda.Ctid, &pda.Defaclrole, &pda.Defaclnamespace, &pda.Defaclobjtype, &pda.Defaclacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pda, nil\n}", "label": 5}
{"code": "public function findByName($name, User $actor = null)\n    {\n        $query = Group::where('name_singular', $name)->orWhere('name_plural', $name);\n\n        return $this->scopeVisibleTo($query, $actor)->first();\n    }", "label": 2}
{"code": "def button(value)\n      # Don't use ele_index because that only works on one element type.\n      # Android needs to combine button and image button to match iOS.\n      if value.is_a? Numeric\n        index = value\n        raise \"#{index} is not a valid index. Must be >= 1\" if index <= 0\n\n        # 1 indexed\n        return find_element :uiautomator, _button_visible_selectors(index: index)\n      end\n\n      find_element :uiautomator, _button_contains_string(value)\n    end", "label": 4}
{"code": "func isBitcoinBech32Address(fl FieldLevel) bool {\n\taddress := fl.Field().String()\n\n\tif !btcLowerAddressRegexBech32.MatchString(address) && !btcUpperAddressRegexBech32.MatchString(address) {\n\t\treturn false\n\t}\n\n\tam := len(address) % 8\n\n\tif am == 0 || am == 3 || am == 5 {\n\t\treturn false\n\t}\n\n\taddress = strings.ToLower(address)\n\n\talphabet := \"qpzry9x8gf2tvdw0s3jn54khce6mua7l\"\n\n\thr := []int{3, 3, 0, 2, 3} // the human readable part will always be bc\n\taddr := address[3:]\n\tdp := make([]int, 0, len(addr))\n\n\tfor _, c := range addr {\n\t\tdp = append(dp, strings.IndexRune(alphabet, c))\n\t}\n\n\tver := dp[0]\n\n\tif ver < 0 || ver > 16 {\n\t\treturn false\n\t}\n\n\tif ver == 0 {\n\t\tif len(address) != 42 && len(address) != 62 {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tvalues := append(hr, dp...)\n\n\tGEN := []int{0x3b6a57b2, 0x26508e6d, 0x1ea119fa, 0x3d4233dd, 0x2a1462b3}\n\n\tp := 1\n\n\tfor _, v := range values {\n\t\tb := p >> 25\n\t\tp = (p&0x1ffffff)<<5 ^ v\n\n\t\tfor i := 0; i < 5; i++ {\n\t\t\tif (b>>uint(i))&1 == 1 {\n\t\t\t\tp ^= GEN[i]\n\t\t\t}\n\t\t}\n\t}\n\n\tif p != 1 {\n\t\treturn false\n\t}\n\n\tb := uint(0)\n\tacc := 0\n\tmv := (1 << 5) - 1\n\tvar sw []int\n\n\tfor _, v := range dp[1 : len(dp)-6] {\n\t\tacc = (acc << 5) | v\n\t\tb += 5\n\t\tfor b >= 8 {\n\t\t\tb -= 8\n\t\t\tsw = append(sw, (acc>>b)&mv)\n\t\t}\n\t}\n\n\tif len(sw) < 2 || len(sw) > 40 {\n\t\treturn false\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "function (items) {\n                var\n                    idx;\n                idx = items.length;\n                while (idx--) {\n                    if (0 !== items[idx].min()) {\n                        ++idx;\n                        break;\n                    }\n                }\n                return idx;\n            }", "label": 3}
{"code": "async def _load_message_field(self, reader, msg, field):\n        \"\"\"\n        Loads message field from the reader. Field is defined by the message field specification.\n        Returns loaded value, supports field reference.\n\n        :param reader:\n        :param msg:\n        :param field:\n        :return:\n        \"\"\"\n        fname, ftype, params = field[0], field[1], field[2:]\n        await self.load_field(reader, ftype, params, eref(msg, fname))", "label": 1}
{"code": "function( tmp ) {\r\n      var _length = tmp.val.length;\r\n      return _length === 0 || _length >= tmp.arg || messages.minLength.replace( '{count}', tmp.arg );\r\n    }", "label": 3}
{"code": "function importProjectConfig(req, res, next) {\n  var options = req.connectionOptions;\n\n  var projectConfigToImport = req.body || [];\n\n  if (!_.isArray(projectConfigToImport)) {\n    return next(\"Expected An Array Of Project Config Values\");\n  }\n\n  forms.importAppConfig(options, projectConfigToImport, formsResultHandlers(constants.resultTypes.formProjects, req, next));\n}", "label": 3}
{"code": "def set!(*args)\n      msg = '#set! does not support special keys, use #set instead'\n      raise ArgumentError, msg if args.any? { |v| v.is_a?(::Symbol) }\n\n      input_value = args.join\n      set input_value[0]\n      return content_editable_set!(*args) if @content_editable\n\n      element_call { execute_js(:setValue, @element, input_value[0..-2]) }\n      append(input_value[-1])\n      return if value == input_value\n\n      raise Exception::Error, \"#set! value: '#{value}' does not match expected input: '#{input_value}'\"\n    end", "label": 4}
{"code": "function (arguments) {\n                var argData = ArgumentHelpers.prepareCallback(arguments);\n                var callback = argData.callback;\n                var args = argData.arguments;\n                if (callback) {\n                    args.pop();\n                }\n                return args;\n            }", "label": 3}
{"code": "public String toRomanNumeral() {\n\t\tif (this.romanString == null) {\n\t\t\tthis.romanString = \"\";\n\t\t\tint remainder = this.value;\n\t\t\tfor (int i = 0; i < BASIC_VALUES.length; i++) {\n\t\t\t\twhile (remainder >= BASIC_VALUES[i]) {\n\t\t\t\t\tthis.romanString += BASIC_ROMAN_NUMERALS[i];\n\t\t\t\t\tremainder -= BASIC_VALUES[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this.romanString;\n\t}", "label": 0}
{"code": "function deepCollection(collectionId, obj) {\n  const pathBits = idKeys(collectionId);\n  pathBits.pop();\n  pathBits.push('collection');\n  pathBits.shift();\n  return deepObj(pathBits, obj, false);\n}", "label": 3}
{"code": "private function show_multiple_fields( $data, $format, $ascii_pre_colorized = false ) {\n\n\t\t$true_fields = array();\n\t\tforeach ( $this->args['fields'] as $field ) {\n\t\t\t$true_fields[] = $this->find_item_key( $data, $field );\n\t\t}\n\n\t\tforeach ( $data as $key => $value ) {\n\t\t\tif ( ! in_array( $key, $true_fields, true ) ) {\n\t\t\t\tif ( is_array( $data ) ) {\n\t\t\t\t\tunset( $data[ $key ] );\n\t\t\t\t} elseif ( is_object( $data ) ) {\n\t\t\t\t\tunset( $data->$key );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tswitch ( $format ) {\n\n\t\t\tcase 'table':\n\t\t\tcase 'csv':\n\t\t\t\t$rows   = $this->assoc_array_to_rows( $data );\n\t\t\t\t$fields = array( 'Field', 'Value' );\n\t\t\t\tif ( 'table' === $format ) {\n\t\t\t\t\tself::show_table( $rows, $fields, $ascii_pre_colorized );\n\t\t\t\t} elseif ( 'csv' === $format ) {\n\t\t\t\t\t\\WP_CLI\\Utils\\write_csv( STDOUT, $rows, $fields );\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase 'yaml':\n\t\t\tcase 'json':\n\t\t\t\t\\WP_CLI::print_value(\n\t\t\t\t\t$data,\n\t\t\t\t\tarray(\n\t\t\t\t\t\t'format' => $format,\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\t\\WP_CLI::error( 'Invalid format: ' . $format );\n\t\t\t\tbreak;\n\n\t\t}\n\n\t}", "label": 2}
{"code": "func (m HostCertificateManager) InstallServerCertificate(ctx context.Context, cert string) error {\n\treq := types.InstallServerCertificate{\n\t\tThis: m.Reference(),\n\t\tCert: cert,\n\t}\n\n\t_, err := methods.InstallServerCertificate(ctx, m.Client(), &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// NotifyAffectedService is internal, not exposing as we don't have a use case other than with InstallServerCertificate\n\t// Without this call, hostd needs to be restarted to use the updated certificate\n\t// Note: using Refresh as it has the same struct/signature, we just need to use different xml name tags\n\tbody := struct {\n\t\tReq *types.Refresh         `xml:\"urn:vim25 NotifyAffectedServices,omitempty\"`\n\t\tRes *types.RefreshResponse `xml:\"urn:vim25 NotifyAffectedServicesResponse,omitempty\"`\n\t\tmethods.RefreshBody\n\t}{\n\t\tReq: &types.Refresh{This: m.Reference()},\n\t}\n\n\treturn m.Client().RoundTrip(ctx, &body, &body)\n}", "label": 5}
{"code": "final void end() {\n    final Thread thread = this.threadRef;\n    this.keepRunning.set(false);\n    if (thread != null) {\n     // thread.interrupt();\n      try {\n        thread.join();\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n      }\n    }\n    this.threadRef = null;\n  }", "label": 0}
{"code": "protected function selectOnlyNeededColumns(array $data)\n    {\n        if (is_null($this->onlyColumns)) {\n            return $data;\n        } else {\n            return array_intersect_key($data, array_flip(array_merge($this->onlyColumns, $this->exceptions)));\n        }\n    }", "label": 2}
{"code": "public void setBean(String name, Object object) {\n\t\tBean bean = beans.get(name);\n\t\tif (null == bean) {\n\t\t\tbean = new Bean();\n\t\t\tbeans.put(name, bean);\n\t\t}\n\t\tbean.object = object;\n\t}", "label": 0}
{"code": "def range(input)\n      return auto_range(@match[1] || \"+\") unless input\n\n      b, e = parse_range(input)\n      raise(\"Invalid line range\") unless valid_range?(b, e)\n\n      [b, e]\n    end", "label": 4}
{"code": "function confChanged(current, proposed) {\n    if (stringify(current.conf) !== stringify(proposed.conf)) {\n        if (current.version >= proposed.version) {\n            const e = new Error('Schema change, but no version increment.');\n            e.current = current;\n            e.proposed = proposed;\n            throw e;\n        }\n        return true;\n    } else {\n        return false;\n    }\n}", "label": 3}
{"code": "function() {\n      if (this.__attachedCallbackInvoked) {\n        this.trigger('before-detached-callback');\n        this._detached();\n        this.__attachedCallbackInvoked = false;\n      }\n      _.each(this.getTrackedViews(), function(view) {\n        // If the tracked view is currently attached to the parent, then invoke detatched on it.\n        if (view.isAttachedToParent()) {\n          view.__invokeDetached();\n        }\n      });\n    }", "label": 3}
{"code": "def count_num_trees(nexson, nexson_version=None):\n    \"\"\"Returns the number of trees summed across all tree\n    groups.\n    \"\"\"\n    if nexson_version is None:\n        nexson_version = detect_nexson_version(nexson)\n    nex = get_nexml_el(nexson)\n    num_trees_by_group = []\n    if _is_by_id_hbf(nexson_version):\n        for tree_group in nex.get('treesById', {}).values():\n            nt = len(tree_group.get('treeById', {}))\n            num_trees_by_group.append(nt)\n    else:\n        trees_group = nex.get('trees', [])\n        if isinstance(trees_group, dict):\n            trees_group = [trees_group]\n        for tree_group in trees_group:\n            t = tree_group.get('tree')\n            if isinstance(t, list):\n                nt = len(t)\n            else:\n                nt = 1\n            num_trees_by_group.append(nt)\n    return sum(num_trees_by_group)", "label": 1}
{"code": "def match(self, item):\n        \"\"\"\n        Return ``True`` if the expected matchers are matched in the expected\n        order, otherwise ``False``.\n        \"\"\"\n        if self._position == len(self._matchers):\n            raise RuntimeError('Matcher exhausted, no more matchers to use')\n\n        matcher = self._matchers[self._position]\n        if matcher(item):\n            self._position += 1\n\n        if self._position == len(self._matchers):\n            # All patterns have been matched\n            return True\n\n        return False", "label": 1}
{"code": "public function ancestorKey(Key $key)\n    {\n        if ($key->state() !== self::STATE_NAMED) {\n            throw new InvalidArgumentException('Cannot use an incomplete key as an ancestor');\n        }\n\n        $path = $key->path();\n\n        $this->path = array_merge($path, $this->path);\n\n        return $this;\n    }", "label": 2}
{"code": "public function setAuthors($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->authors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private function determineDateForPrefix($startDate, $endDate)\n    {\n        // The default date value should look like \"*/*/*\" after joining\n        $dateParts = array_fill_keys(['Y', 'm', 'd'], self::PREFIX_WILDCARD);\n\n        // Narrow down the date by replacing the WILDCARDs with values if they\n        // are the same for the start and end date.\n        if ($startDate && $endDate) {\n            foreach ($dateParts as $key => &$value) {\n                $candidateValue = date($key, $startDate);\n                if ($candidateValue === date($key, $endDate)) {\n                    $value = $candidateValue;\n                } else {\n                    break;\n                }\n            }\n        }\n\n        return join('/', $dateParts);\n    }", "label": 2}
{"code": "def partial_expand(mapping, processor=nil, normalize_values=true)\n      result = self.pattern.dup\n      mapping = normalize_keys(mapping)\n      result.gsub!( EXPRESSION ) do |capture|\n        transform_partial_capture(mapping, capture, processor, normalize_values)\n      end\n      return Addressable::Template.new(result)\n    end", "label": 4}
{"code": "func New(out io.Writer, prefix string, debug bool) *Logger {\n\tl := &Logger{\n\t\tdebug:  debug,\n\t\tLogger: log.New(out, prefix, 0),\n\t}\n\tl.SetFlags(0)\n\treturn l\n}", "label": 5}
{"code": "def add_label(label)\n      unless label.valid?\n        errors.add(:label, \"is not valid.\")\n        return Trello.logger.warn \"Label is not valid.\" unless label.valid?\n      end\n      client.post(\"/cards/#{id}/idLabels\", {value: label.id})\n    end", "label": 4}
{"code": "func (rd *Redirector) wrapCallback(fn func(http.ResponseWriter, *http.Request) (*auth.SSHLoginResponse, error)) http.Handler {\n\tclone := *rd.proxyURL\n\tclone.Path = \"/web/msg/error/login_failed\"\n\terrorURL := clone.String()\n\tclone.Path = \"/web/msg/info/login_success\"\n\tsuccessURL := clone.String()\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tresponse, err := fn(w, r)\n\t\tif err != nil {\n\t\t\tif trace.IsNotFound(err) {\n\t\t\t\thttp.NotFound(w, r)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase rd.errorC <- err:\n\t\t\tcase <-rd.context.Done():\n\t\t\t\thttp.Redirect(w, r, errorURL, http.StatusFound)\n\t\t\t\treturn\n\t\t\t}\n\t\t\thttp.Redirect(w, r, errorURL, http.StatusFound)\n\t\t\treturn\n\t\t}\n\t\tselect {\n\t\tcase rd.responseC <- response:\n\t\tcase <-rd.context.Done():\n\t\t\thttp.Redirect(w, r, errorURL, http.StatusFound)\n\t\t\treturn\n\t\t}\n\t\thttp.Redirect(w, r, successURL, http.StatusFound)\n\t})\n}", "label": 5}
{"code": "def attributes_source\n      @attributes_source ||=\n        begin\n          _explicit_tag, static_attrs, rest =\n            source_code.scan(/\\A\\s*(%[-:\\w]+)?([-:\\w\\.\\#]*)(.*)/m)[0]\n\n          attr_types = {\n            '{' => [:hash, %w[{ }]],\n            '(' => [:html, %w[( )]],\n            '[' => [:object_ref, %w[[ ]]],\n          }\n\n          attr_source = { static: static_attrs }\n          while rest\n            type, chars = attr_types[rest[0]]\n            break unless type # Not an attribute opening character, so we're done\n\n            # Can't define multiple of the same attribute type (e.g. two {...})\n            break if attr_source[type]\n\n            attr_source[type], rest = Haml::Util.balance(rest, *chars)\n          end\n\n          attr_source\n        end\n    end", "label": 4}
{"code": "public function setSubscription($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\PubSub\\V1\\Subscription::class);\n        $this->subscription = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def allow(cls, action, **kwargs):\n        \"\"\"Allow the given action need.\n\n        :param action: The action to allow.\n        :returns: A :class:`invenio_access.models.ActionNeedMixin` instance.\n        \"\"\"\n        return cls.create(action, exclude=False, **kwargs)", "label": 1}
{"code": "def launch(self, port=None):\n        \"\"\" Run the app. \"\"\"\n        \n        if port is not None:\n            self.port = port\n        url = 'http://127.0.0.1:{PORT}'.format(PORT=self.port)\n        print('Interface starting at {url}'.format(url=url))\n        self.listen(self.port)\n        # webbrowser.open(url)\n        tornado.ioloop.IOLoop.instance().start()", "label": 1}
{"code": "private function parseTimeString($timestamp)\n    {\n        $nanoRegex = '/\\d{4}-\\d{1,2}-\\d{1,2}T\\d{1,2}\\:\\d{1,2}\\:\\d{1,2}(?:\\.(\\d{1,}))?/';\n\n        preg_match($nanoRegex, $timestamp, $matches);\n        $subSeconds = isset($matches[1])\n            ? $matches[1]\n            : '0';\n\n        if (strlen($subSeconds) > 6) {\n            $timestamp = str_replace('.'. $subSeconds, '.' . substr($subSeconds, 0, 6), $timestamp);\n        }\n\n        $dt = new \\DateTimeImmutable($timestamp);\n        if (!$dt) {\n            throw new \\InvalidArgumentException(sprintf(\n                'Could not create a DateTime instance from given timestamp %s.',\n                $timestamp\n            ));\n        }\n\n        $nanos = (int) str_pad($subSeconds, 9, '0', STR_PAD_RIGHT);\n\n        return [$dt, $nanos];\n    }", "label": 2}
{"code": "public void addIn(Object attribute, Query subQuery)\r\n    {\r\n        // PAW\r\n\t\t// addSelectionCriteria(ValueCriteria.buildInCriteria(attribute, subQuery, getAlias()));\r\n\t\taddSelectionCriteria(ValueCriteria.buildInCriteria(attribute, subQuery, getUserAlias(attribute)));\r\n    }", "label": 0}
{"code": "def build_data_list(lst):\n    \"\"\" \n    returns the html with supplied list as a HTML listbox \n    \"\"\"\n    txt = '<H3>' + List + '<H3><UL>'\n    for i in lst:\n        txt += '<LI>' + i + '</LI>'\n        \n    txt += '<UL>'\n    return txt", "label": 1}
{"code": "def _peek_buffer(self, i=0):\n        \"\"\"Get the next line without consuming it.\"\"\"\n        while len(self._buffer) <= i:\n            self._buffer.append(next(self._source))\n        return self._buffer[i]", "label": 1}
{"code": "public static void hideOnlyChannels(Object... channels){\r\n    for(LogRecordHandler handler : handlers){\r\n      if(handler instanceof VisibilityHandler){\r\n        VisibilityHandler visHandler = (VisibilityHandler) handler;\r\n        visHandler.showAll();\r\n        for (Object channel : channels) {\r\n          visHandler.alsoHide(channel);\r\n        }\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "public function equals(self $dimension)\n    {\n        return $this->height === $dimension->getHeight() && $this->width === $dimension->getWidth();\n    }", "label": 2}
{"code": "def validate_layout(layout)\n      if invalid_layout?(layout)\n        Jekyll.logger.warn(\n          \"Build Warning:\",\n          \"Layout '#{document.data[\"layout\"]}' requested \"\\\n          \"in #{document.relative_path} does not exist.\"\n        )\n      elsif !layout.nil?\n        layout_source = layout.path.start_with?(site.source) ? :site : :theme\n        Jekyll.logger.debug \"Layout source:\", layout_source\n      end\n    end", "label": 4}
{"code": "public function filter(callable $callback, $globalSearch = false)\n    {\n        $this->autoFilter      = $globalSearch;\n        $this->isFilterApplied = true;\n        $this->filterCallback  = $callback;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setDateInterval($interval)\n    {\n        if (!$interval = CarbonInterval::make($interval)) {\n            throw new InvalidArgumentException('Invalid interval.');\n        }\n\n        if ($interval->spec() === 'PT0S') {\n            throw new InvalidArgumentException('Empty interval is not accepted.');\n        }\n\n        $this->dateInterval = $interval;\n\n        $this->isDefaultInterval = false;\n\n        $this->handleChangedParameters();\n\n        return $this;\n    }", "label": 2}
{"code": "private static Collection<String> addOtherClasses(Collection<String> feats, List<? extends CoreLabel> info,\r\n                                     int loc, Clique c) {\r\n    String addend = null;\r\n    String pAnswer = info.get(loc - 1).get(AnswerAnnotation.class);\r\n    String p2Answer = info.get(loc - 2).get(AnswerAnnotation.class);\r\n    String p3Answer = info.get(loc - 3).get(AnswerAnnotation.class);\r\n    String p4Answer = info.get(loc - 4).get(AnswerAnnotation.class);\r\n    String p5Answer = info.get(loc - 5).get(AnswerAnnotation.class);\r\n    String nAnswer = info.get(loc + 1).get(AnswerAnnotation.class);\r\n    // cdm 2009: Is this really right? Do we not need to differentiate names that would collide???\r\n    if (c == FeatureFactory.cliqueCpC) {\r\n      addend = '|' + pAnswer;\r\n    } else if (c == FeatureFactory.cliqueCp2C) {\r\n      addend = '|' + p2Answer;\r\n    } else if (c == FeatureFactory.cliqueCp3C) {\r\n      addend = '|' + p3Answer;\r\n    } else if (c == FeatureFactory.cliqueCp4C) {\r\n      addend = '|' + p4Answer;\r\n    } else if (c == FeatureFactory.cliqueCp5C) {\r\n      addend = '|' + p5Answer;\r\n    } else if (c == FeatureFactory.cliqueCpCp2C) {\r\n      addend = '|' + pAnswer + '-' + p2Answer;\r\n    } else if (c == FeatureFactory.cliqueCpCp2Cp3C) {\r\n      addend = '|' + pAnswer + '-' + p2Answer + '-' + p3Answer;\r\n    } else if (c == FeatureFactory.cliqueCpCp2Cp3Cp4C) {\r\n      addend = '|' + pAnswer + '-' + p2Answer + '-' + p3Answer + '-' + p4Answer;\r\n    } else if (c == FeatureFactory.cliqueCpCp2Cp3Cp4Cp5C) {\r\n      addend = '|' + pAnswer + '-' + p2Answer + '-' + p3Answer + '-' + p4Answer + '-' + p5Answer;\r\n    } else if (c == FeatureFactory.cliqueCnC) {\r\n      addend = '|' + nAnswer;\r\n    } else if (c == FeatureFactory.cliqueCpCnC) {\r\n      addend = '|' + pAnswer + '-' + nAnswer;\r\n    }\r\n    if (addend == null) {\r\n      return feats;\r\n    }\r\n    Collection<String> newFeats = new HashSet<String>();\r\n    for (String feat : feats) {\r\n      String newFeat = feat + addend;\r\n      newFeats.add(newFeat);\r\n    }\r\n    return newFeats;\r\n  }", "label": 0}
{"code": "public static int cudnnOpTensor(\n        cudnnHandle handle, \n        cudnnOpTensorDescriptor opTensorDesc, \n        Pointer alpha1, \n        cudnnTensorDescriptor aDesc, \n        Pointer A, \n        Pointer alpha2, \n        cudnnTensorDescriptor bDesc, \n        Pointer B, \n        Pointer beta, \n        cudnnTensorDescriptor cDesc, \n        Pointer C)\n    {\n        return checkResult(cudnnOpTensorNative(handle, opTensorDesc, alpha1, aDesc, A, alpha2, bDesc, B, beta, cDesc, C));\n    }", "label": 0}
{"code": "function (value, lineWidth, old, force, translatedValue) {\n            var axis = this,\n              chart = axis.chart,\n              axisLeft = axis.left,\n              axisTop = axis.top,\n              x1,\n              y1,\n              x2,\n              y2,\n              cHeight = (old && chart.oldChartHeight) || chart.chartHeight,\n              cWidth = (old && chart.oldChartWidth) || chart.chartWidth,\n              skip,\n              transB = axis.transB;\n\n            translatedValue = pick(translatedValue, axis.translate(value, null, null, old));\n            x1 = x2 = mathRound(translatedValue + transB);\n            y1 = y2 = mathRound(cHeight - translatedValue - transB);\n\n            if (isNaN(translatedValue)) { // no min or max\n                skip = true;\n\n            } else if (axis.horiz) {\n                y1 = axisTop;\n                y2 = cHeight - axis.bottom;\n                if (x1 < axisLeft || x1 > axisLeft + axis.width) {\n                    skip = true;\n                }\n            } else {\n                x1 = axisLeft;\n                x2 = cWidth - axis.right;\n\n                if (y1 < axisTop || y1 > axisTop + axis.height) {\n                    skip = true;\n                }\n            }\n            return skip && !force ?\n              null :\n              chart.renderer.crispLine([M, x1, y1, L, x2, y2], lineWidth || 1);\n        }", "label": 3}
{"code": "function () {\n        //set logger\n        if (!module.parent) {\n            appHttp.use(morgan({format: 'dev'}));\n            appHttps.use(morgan({format: 'dev'}));\n        }\n        return Q();\n    }", "label": 3}
{"code": "func WriteACIInfo(tx *sql.Tx, aciinfo *ACIInfo) error {\n\t// ql doesn't have an INSERT OR UPDATE function so\n\t// it's faster to remove and reinsert the row\n\t_, err := tx.Exec(\"DELETE from aciinfo where blobkey == $1\", aciinfo.BlobKey)\n\tif err != nil {\n\t\treturn err\n\t}\n\t_, err = tx.Exec(\"INSERT into aciinfo (blobkey, name, importtime, lastused, latest, size, treestoresize) VALUES ($1, $2, $3, $4, $5, $6, $7)\", aciinfo.BlobKey, aciinfo.Name, aciinfo.ImportTime, aciinfo.LastUsed, aciinfo.Latest, aciinfo.Size, aciinfo.TreeStoreSize)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def get_conn(self, *args, **kwargs):\n        \"\"\"\n        Returns a connection object from the router given ``args``.\n\n        Useful in cases where a connection cannot be automatically determined\n        during all steps of the process. An example of this would be\n        Redis pipelines.\n        \"\"\"\n        connections = self.__connections_for('get_conn', args=args, kwargs=kwargs)\n\n        if len(connections) is 1:\n            return connections[0]\n        else:\n            return connections", "label": 1}
{"code": "function setDefaultUser (kontx, next) {\n        var a = _.clone(kontx.args);\n\n        if (a.length === 0) { //No args are sent in, set first to be user id\n            a[0] = kontx.user._id;\n        }\n        else if (_.has(a[0], 'include') || _.has(a[0], 'exclude')) { // If first arg is options then reassign\n            a[0] = kontx.user._id;\n            a[1] = kontx.args[0];\n        }\n\n        kontx.args = a;\n        next();\n    }", "label": 3}
{"code": "func (cn *connection) setNumPieces(num pieceIndex) error {\n\tcn.peerPieces.RemoveRange(bitmap.BitIndex(num), bitmap.ToEnd)\n\tcn.peerPiecesChanged()\n\treturn nil\n}", "label": 5}
{"code": "function removeFromArray(ast, varName, identifierName) {\n  let changes = [];\n  traverse(ast, {\n    VariableDeclarator(path) {\n      const node = path.node;\n      if (_.get(node, 'id.name') !== varName || _.get(node, 'init.type') !== 'ArrayExpression')\n        return;\n      node.init._filePath = ast._filePath;\n      const toRemove = _.find(node.init.elements, ele => ele.name === identifierName);\n      changes = removeFromArrayByNode(node.init, toRemove);\n      path.stop();\n    },\n  });\n  return changes;\n}", "label": 3}
{"code": "def permission?(user, level, server)\n      determined_level = if user.webhook? || server.nil?\n                           0\n                         else\n                           user.roles.reduce(0) do |memo, role|\n                             [@permissions[:roles][role.id] || 0, memo].max\n                           end\n                         end\n\n      [@permissions[:users][user.id] || 0, determined_level].max >= level\n    end", "label": 4}
{"code": "private void doFileRoll(final File from, final File to) {\n    final FileHelper fileHelper = FileHelper.getInstance();\n    if (!fileHelper.deleteExisting(to)) {\n      this.getAppender().getErrorHandler()\n          .error(\"Unable to delete existing \" + to + \" for rename\");\n    }\n    final String original = from.toString();\n    if (fileHelper.rename(from, to)) {\n      LogLog.debug(\"Renamed \" + original + \" to \" + to);\n    } else {\n      this.getAppender().getErrorHandler()\n          .error(\"Unable to rename \" + original + \" to \" + to);\n    }\n  }", "label": 0}
{"code": "def bulk_export(self, ids, exclude_captures=False):\n        \"\"\"Bulk export a set of results.\n\n        :param ids: Int list of result IDs.\n        :rtype: tuple `(io.BytesIO, 'filename')`\n        \"\"\"\n        return self.service.bulk_export(self.base, ids, params={'exclude_captures': exclude_captures})", "label": 1}
{"code": "function (cfg, state, n) {\n        cfg.args = cfg.args || {};\n        var phantomPath = cfg.phantomPath;\n        var controlScript = pathUtil.join(__dirname, '../browsers/phantomjs-control-script.js');\n\n        var args = [];\n        args.push(controlScript);\n        args.push(\"--auto-exit\");\n        if (cfg.args.autoExitPolling) {\n            args.push(\"--auto-exit-polling=\" + cfg.args.autoExitPolling);\n        }\n        if (typeof n == \"undefined\") {\n            n = Math.round(Math.random() * 1000) % 1000;\n        }\n        args.push(\"--instance-id=\" + n);\n        args.push(cfg.slaveURL);\n\n        var phantomProcess = spawn(phantomPath, args, {\n            stdio: \"pipe\"\n        });\n        if (cfg.pipeStdOut) {\n            phantomProcess.stdout.pipe(process.stdout);\n            phantomProcess.stderr.pipe(process.stderr);\n        }\n        if (cfg.onData) {\n            phantomProcess.stdout.on(\"data\", cfg.onData);\n        }\n        phantomProcess.on(\"exit\", cfg.onExit || this.createPhantomExitCb(cfg, state, n).bind(this));\n        phantomProcess.on(\"error\", cfg.onError || this.createPhantomErrorCb(cfg, state, n).bind(this));\n        return phantomProcess;\n    }", "label": 3}
{"code": "def _new_caveat_id(self, base):\n        '''Return a third party caveat id\n\n        This does not duplicate any third party caveat ids already inside\n        macaroon. If base is non-empty, it is used as the id prefix.\n\n        @param base bytes\n        @return bytes\n        '''\n        id = bytearray()\n        if len(base) > 0:\n            id.extend(base)\n        else:\n            # Add a version byte to the caveat id. Technically\n            # this is unnecessary as the caveat-decoding logic\n            # that looks at versions should never see this id,\n            # but if the caveat payload isn't provided with the\n            # payload, having this version gives a strong indication\n            # that the payload has been omitted so we can produce\n            # a better error for the user.\n            id.append(VERSION_3)\n\n        # Iterate through integers looking for one that isn't already used,\n        # starting from n so that if everyone is using this same algorithm,\n        # we'll only perform one iteration.\n        i = len(self._caveat_data)\n        caveats = self._macaroon.caveats\n        while True:\n            # We append a varint to the end of the id and assume that\n            # any client that's created the id that we're using as a base\n            # is using similar conventions - in the worst case they might\n            # end up with a duplicate third party caveat id and thus create\n            # a macaroon that cannot be discharged.\n            temp = id[:]\n            encode_uvarint(i, temp)\n            found = False\n            for cav in caveats:\n                if (cav.verification_key_id is not None\n                        and cav.caveat_id == temp):\n                    found = True\n                    break\n            if not found:\n                return bytes(temp)\n            i += 1", "label": 1}
{"code": "function _checkResult(type, err, obj, options)\n{\n    if (options) {\n        if (options.logger) logger.logger(options.logger, 'parse:', type, options, lib.traceError(err), obj);\n        if (options.datatype == \"object\" || options.datatype == \"obj\") return {};\n        if (options.datatype == \"list\") return [];\n        if (options.datatype == \"str\") return \"\";\n    }\n    return null;\n}", "label": 3}
{"code": "function extractIso8601TimePieces(value) {\n    var timePieces = /^(\\d{2}):(\\d{2})(?:\\:(\\d{2}))?(?:\\.(\\d{1,3}))?$/.exec(value);\n    if (timePieces === null) {\n      return null;\n    }\n\n    var hour = timePieces[1] ? parseInt(timePieces[1], 10) : 0;\n    var minute = timePieces[2] ? parseInt(timePieces[2], 10) : 0;\n    var second = timePieces[3] ? parseInt(timePieces[3], 10) : 0;\n\n    // The millisecond component has a variable length; normalize the length by padding it with zeros\n    var millisecond = timePieces[4] ? parseInt(utils.padRight(timePieces[4], 3, '0'), 10) : 0;\n\n    return [ hour, minute, second, millisecond ];\n  }", "label": 3}
{"code": "def sam_list(sam):\n\t\"\"\"\n\tget a list of mapped reads\n\t\"\"\"\n\tlist = []\n\tfor file in sam:\n\t\tfor line in file:\n\t\t\tif line.startswith('@') is False:\n\t\t\t\tline = line.strip().split()\n\t\t\t\tid, map = line[0], int(line[1])\n\t\t\t\tif map != 4 and map != 8:\n\t\t\t\t\tlist.append(id)\n\treturn set(list)", "label": 1}
{"code": "func (f *gzipWriter) Close() error {\n\tvar errors []error\n\tif f.Writer != nil {\n\t\terrors = append(errors, f.Writer.Close())\n\t\tf.Writer.Reset(ioutil.Discard)\n\t\twriterPool.Put(f.Writer)\n\t\tf.Writer = nil\n\t}\n\tif f.file != nil {\n\t\terrors = append(errors, f.file.Close())\n\t\tf.file = nil\n\t}\n\treturn trace.NewAggregate(errors...)\n}", "label": 5}
{"code": "func (a *HistoricalApi) processMetricRequest(key core.HistoricalKey, request *restful.Request, response *restful.Response) {\n\tstart, end, err := getStartEndTimeHistorical(request)\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\tlabels, err := getLabels(request)\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\tmetricName := request.PathParameter(\"metric-name\")\n\tconvertedMetricName := convertMetricName(metricName)\n\n\tvar metrics map[core.HistoricalKey][]core.TimestampedMetricValue\n\tif labels != nil {\n\t\tmetrics, err = a.historicalSource.GetLabeledMetric(convertedMetricName, labels, []core.HistoricalKey{key}, start, end)\n\t} else {\n\t\tmetrics, err = a.historicalSource.GetMetric(convertedMetricName, []core.HistoricalKey{key}, start, end)\n\t}\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusInternalServerError, err)\n\t\treturn\n\t}\n\n\tconverted := exportTimestampedMetricValue(metrics[key])\n\tresponse.WriteEntity(converted)\n}", "label": 5}
{"code": "public function setEmailAddresses($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\Email::class);\n        $this->email_addresses = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public AbstractGraph getModuleGraph(final String moduleId) {\n        final ModuleHandler moduleHandler = new ModuleHandler(repoHandler);\n        final DbModule module = moduleHandler.getModule(moduleId);\n        final DbOrganization organization = moduleHandler.getOrganization(module);\n\n        filters.setCorporateFilter(new CorporateFilter(organization));\n\n        final AbstractGraph graph = new ModuleGraph();\n        addModuleToGraph(module, graph, 0);\n\n        return graph;\n    }", "label": 0}
{"code": "func (h *hawkularSink) recent(live *metrics.MetricDefinition, model *metrics.MetricDefinition) bool {\n\trecent := true\n\tfor k := range model.Tags {\n\t\tif v, found := live.Tags[k]; !found {\n\t\t\t// There's a label that wasn't in our stored definition\n\t\t\tlive.Tags[k] = v\n\t\t\trecent = false\n\t\t}\n\t}\n\n\treturn recent\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, clusterinstance resource) throws Exception {\n\t\tclusterinstance addresource = new clusterinstance();\n\t\taddresource.clid = resource.clid;\n\t\taddresource.deadinterval = resource.deadinterval;\n\t\taddresource.hellointerval = resource.hellointerval;\n\t\taddresource.preemption = resource.preemption;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "private static boolean typeEquals(ParameterizedType from,\n\t\t\tParameterizedType to, Map<String, Type> typeVarMap) {\n\t\tif (from.getRawType().equals(to.getRawType())) {\n\t\t\tType[] fromArgs = from.getActualTypeArguments();\n\t\t\tType[] toArgs = to.getActualTypeArguments();\n\t\t\tfor (int i = 0; i < fromArgs.length; i++) {\n\t\t\t\tif (!matches(fromArgs[i], toArgs[i], typeVarMap)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}", "label": 0}
{"code": "func MsParseType(args *internal.ArgType, dt string, nullable bool) (int, string, string) {\n\tprecision := 0\n\tnilVal := \"nil\"\n\n\t// extract precision\n\tdt, precision, _ = args.ParsePrecision(dt)\n\n\tvar typ string\n\tswitch dt {\n\tcase \"tinyint\", \"bit\":\n\t\tnilVal = \"false\"\n\t\ttyp = \"bool\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullBool{}\"\n\t\t\ttyp = \"sql.NullBool\"\n\t\t}\n\n\tcase \"char\", \"varchar\", \"text\", \"nchar\", \"nvarchar\", \"ntext\", \"smallmoney\", \"money\":\n\t\tnilVal = `\"\"`\n\t\ttyp = \"string\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullString{}\"\n\t\t\ttyp = \"sql.NullString\"\n\t\t}\n\n\tcase \"smallint\":\n\t\tnilVal = \"0\"\n\t\ttyp = \"int16\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\tcase \"int\":\n\t\tnilVal = \"0\"\n\t\ttyp = args.Int32Type\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\tcase \"bigint\":\n\t\tnilVal = \"0\"\n\t\ttyp = \"int64\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\n\tcase \"smallserial\":\n\t\tnilVal = \"0\"\n\t\ttyp = \"uint16\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\tcase \"serial\":\n\t\tnilVal = \"0\"\n\t\ttyp = args.Uint32Type\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\tcase \"bigserial\":\n\t\tnilVal = \"0\"\n\t\ttyp = \"uint64\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\n\tcase \"real\":\n\t\tnilVal = \"0.0\"\n\t\ttyp = \"float32\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullFloat64{}\"\n\t\t\ttyp = \"sql.NullFloat64\"\n\t\t}\n\tcase \"numeric\", \"decimal\":\n\t\tnilVal = \"0.0\"\n\t\ttyp = \"float64\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullFloat64{}\"\n\t\t\ttyp = \"sql.NullFloat64\"\n\t\t}\n\n\tcase \"binary\", \"varbinary\":\n\t\ttyp = \"[]byte\"\n\n\tcase \"datetime\", \"datetime2\", \"timestamp\":\n\t\tnilVal = \"time.Time{}\"\n\t\ttyp = \"time.Time\"\n\n\tcase \"time with time zone\", \"time without time zone\", \"timestamp without time zone\":\n\t\tnilVal = \"0\"\n\t\ttyp = \"int64\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\n\tcase \"interval\":\n\t\ttyp = \"*time.Duration\"\n\n\tdefault:\n\t\tif strings.HasPrefix(dt, args.Schema+\".\") {\n\t\t\t// in the same schema, so chop off\n\t\t\ttyp = snaker.SnakeToCamelIdentifier(dt[len(args.Schema)+1:])\n\t\t\tnilVal = typ + \"(0)\"\n\t\t} else {\n\t\t\ttyp = snaker.SnakeToCamelIdentifier(dt)\n\t\t\tnilVal = typ + \"{}\"\n\t\t}\n\t}\n\n\treturn precision, nilVal, typ\n}", "label": 5}
{"code": "func (p *Pod) SaveRuntime() error {\n\tpath := filepath.Join(p.Root, RuntimeConfigPath)\n\tbuf, err := json.Marshal(p.RuntimePod)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn ioutil.WriteFile(path, buf, 0644)\n}", "label": 5}
{"code": "public function addIndexBy($alias, $fieldName)\n    {\n        $found = false;\n\n        foreach (array_merge($this->metaMappings, $this->fieldMappings) as $columnName => $columnFieldName) {\n            if (! ($columnFieldName === $fieldName && $this->columnOwnerMap[$columnName] === $alias)) {\n                continue;\n            }\n\n            $this->addIndexByColumn($alias, $columnName);\n            $found = true;\n\n            break;\n        }\n\n        /* TODO: check if this exception can be put back, for now it's gone because of assumptions made by some ORM internals\n        if ( ! $found) {\n            $message = sprintf(\n                'Cannot add index by for DQL alias %s and field %s without calling addFieldResult() for them before.',\n                $alias,\n                $fieldName\n            );\n\n            throw new \\LogicException($message);\n        }\n        */\n\n        return $this;\n    }", "label": 2}
{"code": "def verify(self, tool):\n        \"\"\"\n        check that the tool exists\n        \"\"\"\n        if os.path.isfile(tool['file']):\n            print('Toolbox: program exists = TOK  :: ' + tool['file'])\n            return True\n        else:\n            print('Toolbox: program exists = FAIL :: ' + tool['file'])\n            return False", "label": 1}
{"code": "public static function getSignContent(array $data, $verify = false): string\n    {\n        $data = self::encoding($data, $data['charset'] ?? 'gb2312', 'utf-8');\n\n        ksort($data);\n\n        $stringToBeSigned = '';\n        foreach ($data as $k => $v) {\n            if ($verify && $k != 'sign' && $k != 'sign_type') {\n                $stringToBeSigned .= $k.'='.$v.'&';\n            }\n            if (!$verify && $v !== '' && !is_null($v) && $k != 'sign' && '@' != substr($v, 0, 1)) {\n                $stringToBeSigned .= $k.'='.$v.'&';\n            }\n        }\n\n        Log::debug('Alipay Generate Sign Content Before Trim', [$data, $stringToBeSigned]);\n\n        return trim($stringToBeSigned, '&');\n    }", "label": 2}
{"code": "func (self *KubeletClient) GetAllRawContainers(host Host, start, end time.Time) ([]cadvisor.ContainerInfo, error) {\n\turl := self.getUrl(host, \"/stats/container/\")\n\n\treturn self.getAllContainers(url, start, end)\n}", "label": 5}
{"code": "public static double Function1D(double x, double mean, double amplitude, double position, double width, double phase, double frequency) {\n        double envelope = mean + amplitude * Math.exp(-Math.pow((x - position), 2) / Math.pow((2 * width), 2));\n        double carry = Math.cos(2 * Math.PI * frequency * (x - position) + phase);\n        return envelope * carry;\n    }", "label": 0}
{"code": "def button(value)\n      # return button at index.\n      return ele_index button_class, value if value.is_a? Numeric\n\n      ele_by_json_visible_contains button_class, value\n    end", "label": 4}
{"code": "def ensure_app_exists!\n      return if Spaceship::App.find(Sigh.config[:app_identifier], mac: Sigh.config[:platform].to_s == 'macos')\n      print_produce_command(Sigh.config)\n      UI.user_error!(\"Could not find App with App Identifier '#{Sigh.config[:app_identifier]}'\")\n    end", "label": 4}
{"code": "func PgSequences(db XODB, schema string) ([]*Sequence, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`t.relname ` + // ::varchar AS table_name\n\t\t`FROM pg_class s ` +\n\t\t`JOIN pg_depend d ON d.objid = s.oid ` +\n\t\t`JOIN pg_class t ON d.objid = s.oid AND d.refobjid = t.oid ` +\n\t\t`JOIN pg_namespace n ON n.oid = s.relnamespace ` +\n\t\t`WHERE n.nspname = $1 AND s.relkind = 'S'`\n\n\t// run query\n\tXOLog(sqlstr, schema)\n\tq, err := db.Query(sqlstr, schema)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*Sequence{}\n\tfor q.Next() {\n\t\ts := Sequence{}\n\n\t\t// scan\n\t\terr = q.Scan(&s.TableName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &s)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public static systementitydata[] get(nitro_service service, systementitydata_args args) throws Exception{\n\t\tsystementitydata obj = new systementitydata();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tsystementitydata[] response = (systementitydata[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "protected function filterEndDate($current)\n    {\n        if (!$this->isEndExcluded() && $current == $this->endDate) {\n            return true;\n        }\n\n        if ($this->dateInterval->invert ? $current > $this->endDate : $current < $this->endDate) {\n            return true;\n        }\n\n        return static::END_ITERATION;\n    }", "label": 2}
{"code": "def load_data(fname):\n    \"\"\" loads previously exported CSV file to redis database \"\"\"\n    print('Loading ' + fname + ' to redis')\n    r = redis.StrictRedis(host = '127.0.0.1', port = 6379, db = 0);\n    with open(fname, 'r') as f:\n        for line_num, row in enumerate(f): \n            if row.strip('') != '':\n                if line_num < 100000000:\n                    l_key, l_val = parse_n3(row, 'csv')\n                    if line_num % 1000 == 0: \n                        print('loading line #', line_num, 'key=', l_key, ' = ', l_val)\n                    if l_key != '':\n                        r.set(l_key, l_val)", "label": 1}
{"code": "def setoption(parser, metadata=None):\n    \"\"\"Set argument parser option.\"\"\"\n    parser.add_argument('-v', action='version',\n                        version=__version__)\n    subparsers = parser.add_subparsers(help='sub commands help')\n    create_cmd = subparsers.add_parser('create')\n    create_cmd.add_argument('name',\n                            help='Specify Python package name.')\n    create_cmd.add_argument('-d', dest='description', action='store',\n                            help='Short description about your package.')\n    create_cmd.add_argument('-a', dest='author', action='store',\n                            required=True,\n                            help='Python package author name.')\n    create_cmd.add_argument('-e', dest='email', action='store',\n                            required=True,\n                            help='Python package author email address.')\n    create_cmd.add_argument('-l', dest='license',\n                            choices=metadata.licenses().keys(),\n                            default='GPLv3+',\n                            help='Specify license. (default: %(default)s)')\n    create_cmd.add_argument('-s', dest='status',\n                            choices=metadata.status().keys(),\n                            default='Alpha',\n                            help=('Specify development status. '\n                                  '(default: %(default)s)'))\n    create_cmd.add_argument('--no-check', action='store_true',\n                            help='No checking package name in PyPI.')\n    create_cmd.add_argument('--with-samples', action='store_true',\n                            help='Generate package with sample code.')\n    group = create_cmd.add_mutually_exclusive_group(required=True)\n    group.add_argument('-U', dest='username', action='store',\n                       help='Specify GitHub username.')\n    group.add_argument('-u', dest='url', action='store', type=valid_url,\n                       help='Python package homepage url.')\n    create_cmd.add_argument('-o', dest='outdir', action='store',\n                            default=os.path.abspath(os.path.curdir),\n                            help='Specify output directory. (default: $PWD)')\n    list_cmd = subparsers.add_parser('list')\n    list_cmd.add_argument('-l', dest='licenses', action='store_true',\n                          help='show license choices.')", "label": 1}
{"code": "def node_ancestor(node, levels)\n      while levels > 0\n        node = node.node_parent\n        return unless node\n        levels -= 1\n      end\n\n      node\n    end", "label": 4}
{"code": "public static sslcipher[] get(nitro_service service, String ciphergroupname[]) throws Exception{\n\t\tif (ciphergroupname !=null && ciphergroupname.length>0) {\n\t\t\tsslcipher response[] = new sslcipher[ciphergroupname.length];\n\t\t\tsslcipher obj[] = new sslcipher[ciphergroupname.length];\n\t\t\tfor (int i=0;i<ciphergroupname.length;i++) {\n\t\t\t\tobj[i] = new sslcipher();\n\t\t\t\tobj[i].set_ciphergroupname(ciphergroupname[i]);\n\t\t\t\tresponse[i] = (sslcipher) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public static function resolve(callable $provider, array $args = [])\n    {\n        $result = $provider($args);\n        if (is_array($result)) {\n            return $result;\n        }\n\n        throw new UnresolvedEndpointException(\n            'Unable to resolve an endpoint using the provider arguments: '\n            . json_encode($args) . '. Note: you can provide an \"endpoint\" '\n            . 'option to a client constructor to bypass invoking an endpoint '\n            . 'provider.');\n    }", "label": 2}
{"code": "func (r *RotateRequest) Types() []services.CertAuthType {\n\tswitch r.Type {\n\tcase \"\":\n\t\treturn []services.CertAuthType{services.HostCA, services.UserCA}\n\tcase services.HostCA:\n\t\treturn []services.CertAuthType{services.HostCA}\n\tcase services.UserCA:\n\t\treturn []services.CertAuthType{services.UserCA}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def class_rules\n      [\n        Rule.new(:error, 4..6, \"Description Markdown\", \"Above your class you need documentation that covers the scope, and the usage of your plugin.\", proc do |json|\n          json[:body_md] && json[:body_md].empty?\n        end),\n        Rule.new(:warning, 30, \"Tags\", \"This plugin does not include `@tags tag1, tag2` and thus will be harder to find in search.\", proc do |json|\n          json[:tags] && json[:tags].empty?\n        end),\n        Rule.new(:warning, 29, \"References\", \"Ideally, you have a reference implementation of your plugin that you can show to people, add `@see org/repo` to have the site auto link it.\", proc do |json|\n          json[:see] && json[:see].empty?\n        end),\n        Rule.new(:error, 8..27, \"Examples\", \"You should include some examples of common use-cases for your plugin.\", proc do |json|\n          json[:example_code] && json[:example_code].empty?\n        end)\n      ]\n    end", "label": 4}
{"code": "def fetch_external\n        object.controlled_properties.each do |property|\n          object[property].each do |value|\n            resource = value.respond_to?(:resource) ? value.resource : value\n            next unless resource.is_a?(ActiveTriples::Resource)\n            next if value.is_a?(ActiveFedora::Base)\n            fetch_with_persistence(resource)\n          end\n        end\n      end", "label": 4}
{"code": "public static base_responses restore(nitro_service client, appfwprofile resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwprofile restoreresources[] = new appfwprofile[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\trestoreresources[i] = new appfwprofile();\n\t\t\t\trestoreresources[i].archivename = resources[i].archivename;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, restoreresources,\"restore\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (c *Client) CreateOIDCAuthRequest(req services.OIDCAuthRequest) (*services.OIDCAuthRequest, error) {\n\tout, err := c.PostJSON(c.Endpoint(\"oidc\", \"requests\", \"create\"), createOIDCAuthRequestReq{\n\t\tReq: req,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar response *services.OIDCAuthRequest\n\tif err := json.Unmarshal(out.Bytes(), &response); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn response, nil\n}", "label": 5}
{"code": "function extendedCallback(res) {\n        timeline.mark(`end:${id}`);\n        // add full response data\n        moduleData[id].response = getResDataObject(res);\n        // flatten object for easy transformation/filtering later\n        moduleData[id] = flatten(moduleData[id], { maxDepth: 5 });\n        moduleData[id] = filterData(config, moduleData[id]);\n\n        // if filter function returns falsey value, drop all data completely\n        if (typeof moduleData[id] !== 'object') {\n          timeline.data = timeline.data.filter(\n            d => !new RegExp(id).test(d.name)\n          );\n          delete moduleData[id];\n        }\n\n        if (typeof originalCallback === 'function') {\n          return originalCallback.apply(this, [res]);\n        }\n        return true;\n      }", "label": 3}
{"code": "private static function remove_decorations( $comment ) {\n\t\t$comment = preg_replace( '|^/\\*\\*[\\r\\n]+|', '', $comment );\n\t\t$comment = preg_replace( '|\\n[\\t ]*\\*/$|', '', $comment );\n\t\t$comment = preg_replace( '|^[\\t ]*\\* ?|m', '', $comment );\n\n\t\treturn $comment;\n\t}", "label": 2}
{"code": "def address_checksum(address):\n    \"\"\"\n    Returns the checksum in bytes for an address in bytes\n    \"\"\"\n    address_bytes = address\n    h = blake2b(digest_size=5)\n    h.update(address_bytes)\n    checksum = bytearray(h.digest())\n    checksum.reverse()\n    return checksum", "label": 1}
{"code": "def set(option, value=(not_set=true), ignore_setter=false, &block)\n      raise ArgumentError, 'value not set' if block and !not_set\n      return self if !not_set and value.nil?\n\n      if not_set\n        set_options option\n        return self\n      end\n\n      if respond_to?(\"#{option}=\") and not ignore_setter\n        return __send__(\"#{option}=\", value)\n      end\n\n      define_accessors option, value\n      self\n    end", "label": 4}
{"code": "def _helper_for_model(self, model_type):\n        \"\"\"\n        Get the helper for a given type of Docker model. For use by resource\n        definitions.\n        \"\"\"\n        if model_type is models.containers.Container:\n            return self.containers\n        if model_type is models.images.Image:\n            return self.images\n        if model_type is models.networks.Network:\n            return self.networks\n        if model_type is models.volumes.Volume:\n            return self.volumes\n\n        raise ValueError('Unknown model type {}'.format(model_type))", "label": 1}
{"code": "protected function getTransformerResponse(array $tags)\n    {\n        try {\n            if (empty($transformerTag = $this->getTransformerTag($tags))) {\n                return;\n            }\n\n            $transformer = $this->getTransformerClass($transformerTag);\n            $model = $this->getClassToBeTransformed($tags, (new ReflectionClass($transformer))->getMethod('transform'));\n            $modelInstance = $this->instantiateTransformerModel($model);\n\n            $fractal = new Manager();\n\n            if (! is_null(config('apidoc.fractal.serializer'))) {\n                $fractal->setSerializer(app(config('apidoc.fractal.serializer')));\n            }\n\n            $resource = (strtolower($transformerTag->getName()) == 'transformercollection')\n                ? new Collection([$modelInstance, $modelInstance], new $transformer)\n                : new Item($modelInstance, new $transformer);\n\n            return [response($fractal->createData($resource)->toJson())];\n        } catch (\\Exception $e) {\n            return;\n        }\n    }", "label": 2}
{"code": "def d2Sbus_dV2(Ybus, V, lam):\n    \"\"\" Computes 2nd derivatives of power injection w.r.t. voltage.\n    \"\"\"\n    n = len(V)\n    Ibus = Ybus * V\n    diaglam = spdiag(lam)\n    diagV = spdiag(V)\n\n    A = spmatrix(mul(lam, V), range(n), range(n))\n    B = Ybus * diagV\n    C = A * conj(B)\n    D = Ybus.H * diagV\n    E = conj(diagV) * (D * diaglam - spmatrix(D*lam, range(n), range(n)))\n    F = C - A * spmatrix(conj(Ibus), range(n), range(n))\n    G = spmatrix(div(matrix(1.0, (n, 1)), abs(V)), range(n), range(n))\n\n    Gaa = E + F\n    Gva = 1j * G * (E - F)\n    Gav = Gva.T\n    Gvv = G * (C + C.T) * G\n\n    return Gaa, Gav, Gva, Gvv", "label": 1}
{"code": "function stuff_after(comment, ast) { \n  var code = code_after(comment[\"range\"], ast);\n\n  if (code && comment[\"next\"])\n    return code[\"range\"][0] < comment[\"next\"][\"range\"][0] ? code : \"\";\n  else\n    return code;\n}", "label": 3}
{"code": "def is_internal_request(self, domain, referer):\n        \"\"\"\n        Returns True if referring URL is the same domain as current request.\n\n        \"\"\"\n        # Different subdomains are treated as different domains.\n        return bool(re.match(\"^https?://%s/\" % re.escape(domain), referer))", "label": 1}
{"code": "func (c *RPCClient) SyncStreams(stdout io.Writer, stderr io.Writer) error {\n\tgo copyStream(\"stdout\", stdout, c.stdout)\n\tgo copyStream(\"stderr\", stderr, c.stderr)\n\treturn nil\n}", "label": 5}
{"code": "public void abort()\r\n    {\r\n        /*\r\n        do nothing if already rolledback\r\n        */\r\n        if (txStatus == Status.STATUS_NO_TRANSACTION\r\n                || txStatus == Status.STATUS_UNKNOWN\r\n                || txStatus == Status.STATUS_ROLLEDBACK)\r\n        {\r\n            log.info(\"Nothing to abort, tx is not active - status is \" + TxUtil.getStatusString(txStatus));\r\n            return;\r\n        }\r\n        // check status of tx\r\n        if (txStatus != Status.STATUS_ACTIVE && txStatus != Status.STATUS_PREPARED &&\r\n                txStatus != Status.STATUS_MARKED_ROLLBACK)\r\n        {\r\n            throw new IllegalStateException(\"Illegal state for abort call, state was '\" + TxUtil.getStatusString(txStatus) + \"'\");\r\n        }\r\n        if(log.isEnabledFor(Logger.INFO))\r\n        {\r\n            log.info(\"Abort transaction was called on tx \" + this);\r\n        }\r\n        try\r\n        {\r\n            try\r\n            {\r\n                doAbort();\r\n            }\r\n            catch(Exception e)\r\n            {\r\n                log.error(\"Error while abort transaction, will be skipped\", e);\r\n            }\r\n\r\n            // used in managed environments, ignored in non-managed\r\n            this.implementation.getTxManager().abortExternalTx(this);\r\n\r\n            try\r\n            {\r\n                if(hasBroker() && getBroker().isInTransaction())\r\n                {\r\n                    getBroker().abortTransaction();\r\n                }\r\n            }\r\n            catch(Exception e)\r\n            {\r\n                log.error(\"Error while do abort used broker instance, will be skipped\", e);\r\n            }\r\n        }\r\n        finally\r\n        {\r\n            txStatus = Status.STATUS_ROLLEDBACK;\r\n            // cleanup things, e.g. release all locks\r\n            doClose();\r\n        }\r\n    }", "label": 0}
{"code": "function scrapImage(window){\n   var $ = window.$;\n   var url = window.url;\n\n   var thumbs = [];\n   var thumbsRejected = [];\n   var title = scrapTitle(window);\n   var addToThumbs = function(image,beginning){\n      var src = $(image).attr('src');\n      if(src && isValidExtension(src) ){\n         src = utils.toURL(src,url);\n         if(beginning){\n            thumbs.unshift(src);\n         }else{\n            thumbs.push(src);\n         }\n      }else if(src){\n         thumbsRejected.push(src);\n      }\n   };\n   // Open Graph protocol by Facebook: <meta property=\"og:image\" content=\"(*)\"/>\n   $('meta[property=\"og:image\"]').each(function(){\n      var content = $(this).attr('content');\n      if(content) thumbs.push(utils.toURL(content));\n   });\n\n   // Schema.org: <img itemprop=\"image\" src=\"(*)\"/>\n   $('img[itemprop=\"image\"]').each(function(){\n      addToThumbs(this);\n   });\n\n   // Oriented product informations\n   if(thumbs.length < 1){\n      $('img[id*=\"product\"]').each(function(){\n          addToThumbs(this);\n      });\n\n      $('img[class*=\"product\"]').each(function(){\n          addToThumbs(this);\n      });\n   }\n\n   // Grab all images\n   if(thumbs.length < 10){\n      $('img').each(function(){\n         if($(this).attr('itemprop') === 'image') return;\n         var alt = $(this).attr('alt');\n         // Leave this test alone\n         // the selector 'img[alt=\"title\"]' will not work if the title is like LG 42PT35342\" PLASMA TV. Escaping issues.\n         // Image where the title of the page is equal to the content of the alt attribute of the image tag.\n         if(alt === title){\n            addToThumbs(this,true);\n         }else{\n            addToThumbs(this);\n         }\n      });\n   }\n\n   if(thumbs.length === 0){\n      thumbs = thumbsRejected;\n   }\n\n   return thumbs;\n}", "label": 3}
{"code": "function addMissingChirality(molecule, esrType = Molecule.cESRTypeAnd) {\n  for (let iAtom = 0; iAtom < molecule.getAllAtoms(); iAtom++) {\n    let tempMolecule = molecule.getCompactCopy();\n    changeAtomForStereo(tempMolecule, iAtom);\n    // After copy, helpers must be recalculated\n    tempMolecule.ensureHelperArrays(Molecule.cHelperParities);\n    // We need to have >0 and not >1 because there could be unspecified chirality in racemate\n    for (let i = 0; i < tempMolecule.getAtoms(); i++) {\n      // changed from from handling below; TLS 9.Nov.2015\n      if (\n        tempMolecule.isAtomStereoCenter(i) &&\n        tempMolecule.getStereoBond(i) === -1\n      ) {\n        let stereoBond = tempMolecule.getAtomPreferredStereoBond(i);\n        if (stereoBond !== -1) {\n          molecule.setBondType(stereoBond, Molecule.cBondTypeUp);\n          if (molecule.getBondAtom(1, stereoBond) === i) {\n            let connAtom = molecule.getBondAtom(0, stereoBond);\n            molecule.setBondAtom(0, stereoBond, i);\n            molecule.setBondAtom(1, stereoBond, connAtom);\n          }\n          // To me it seems that we have to add all stereo centers into AND group 0. TLS 9.Nov.2015\n          molecule.setAtomESR(i, esrType, 0);\n        }\n      }\n    }\n  }\n}", "label": 3}
{"code": "def write_case_data(self, file):\n        \"\"\" Writes the case data in MATPOWER format.\n        \"\"\"\n        file.write(\"function mpc = %s\\n\" % self._fcn_name)\n        file.write('\\n%%%% MATPOWER Case Format : Version %d\\n' % 2)\n        file.write(\"mpc.version = '%d';\\n\" % 2)\n\n        file.write(\"\\n%%%%-----  Power Flow Data  -----%%%%\\n\")\n        file.write(\"%%%% system MVA base\\n\")\n        file.write(\"%sbaseMVA = %g;\\n\" % (self._prefix, self.case.base_mva))", "label": 1}
{"code": "def check_github_response\n      Retriable.retriable(retry_options) do\n        yield\n      end\n    rescue MovedPermanentlyError => e\n      fail_with_message(e, \"The repository has moved, update your configuration\")\n    rescue Octokit::Forbidden => e\n      fail_with_message(e, \"Exceeded retry limit\")\n    rescue Octokit::Unauthorized => e\n      fail_with_message(e, \"Error: wrong GitHub token\")\n    end", "label": 4}
{"code": "protected function write($buffer)\n    {\n        $socket = $this->getResource();\n\n        while (($length = strlen($buffer)) > 0) {\n            $written = @fwrite($socket, $buffer);\n\n            if ($length === $written) {\n                return;\n            }\n\n            if ($written === false || $written === 0) {\n                $this->onConnectionError('Error while writing bytes to the server.');\n            }\n\n            $buffer = substr($buffer, $written);\n        }\n    }", "label": 2}
{"code": "def remove_recurrence_time(time)\n      found = false\n      @all_recurrence_rules.delete_if do |rule|\n        found = true if rule.is_a?(SingleOccurrenceRule) && rule.time == time\n      end\n      time if found\n    end", "label": 4}
{"code": "public void writeObject(Object o, GraphicsDocument document, boolean asChild) throws RenderException {\n\t\tdocument.writeElement(\"vml:shape\", asChild);\n\t\tPoint p = (Point) o;\n\t\tString adj = document.getFormatter().format(p.getX()) + \",\"\n\t\t\t\t+ document.getFormatter().format(p.getY());\n\t\tdocument.writeAttribute(\"adj\", adj);\n\t}", "label": 0}
{"code": "func ObjectsAreEqualValues(expected, actual interface{}) bool {\n\tif ObjectsAreEqual(expected, actual) {\n\t\treturn true\n\t}\n\n\tactualType := reflect.TypeOf(actual)\n\tif actualType == nil {\n\t\treturn false\n\t}\n\texpectedValue := reflect.ValueOf(expected)\n\tif expectedValue.IsValid() && expectedValue.Type().ConvertibleTo(actualType) {\n\t\t// Attempt comparison after type conversion\n\t\treturn reflect.DeepEqual(expectedValue.Convert(actualType).Interface(), actual)\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "function (member, memberValue, visibility) {\n        var newType = typeof memberValue,\n            baseMemberValue,\n            baseType,\n            prototype = this._Constructor.prototype;\n        _gpfAssert(!prototype.hasOwnProperty(member), \"Existing own member can't be overridden\");\n        baseMemberValue = this._Super.prototype[member];\n        baseType = typeof baseMemberValue;\n        if (\"undefined\" !== baseType) {\n            if (null !== baseMemberValue && newType !== baseType) {\n                gpf.Error.classMemberOverloadWithTypeChange();\n            }\n            if (\"function\" === newType && _gpfUsesSuper(memberValue)) {\n                memberValue = _gpfGenSuperMember(baseMemberValue, memberValue);\n            }\n        }\n        _gpfIgnore(visibility); // TODO Handle constructor visibility\n        prototype[member] = memberValue;\n    }", "label": 3}
{"code": "public function setRefersTo($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Debugger\\V2\\StatusMessage_Reference::class);\n        $this->refers_to = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private function predictEndpoint()\n    {\n        return static function (callable $handler) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler) {\n                if ($command->getName() === 'Predict') {\n                    $request = $request->withUri(new Uri($command['PredictEndpoint']));\n                }\n                return $handler($command, $request);\n            };\n        };\n    }", "label": 2}
{"code": "public static <E> Filter<E> switchedFilter(Filter<E> filter, boolean negated) {\r\n    return (new NegatedFilter<E>(filter, negated));\r\n  }", "label": 0}
{"code": "function emptySources(map) {\n  return !map.sources ||\n    !map.sources.length ||\n    !map.sourcesContent ||\n    !map.sourcesContent.length ||\n    map.sources.length != map.sourcesContent.length;\n}", "label": 3}
{"code": "func (ds *datastore) GetObject(key string, o KVObject) error {\n\tif ds.sequential {\n\t\tds.Lock()\n\t\tdefer ds.Unlock()\n\t}\n\n\tif ds.cache != nil {\n\t\treturn ds.cache.get(key, o)\n\t}\n\n\tkvPair, err := ds.store.Get(key)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := o.SetValue(kvPair.Value); err != nil {\n\t\treturn err\n\t}\n\n\t// Make sure the object has a correct view of the DB index in\n\t// case we need to modify it and update the DB.\n\to.SetIndex(kvPair.LastIndex)\n\treturn nil\n}", "label": 5}
{"code": "def get_files_from_filestore(job, files, work_dir, docker=False):\n    \"\"\"\n    Download a dict of files to the given directory and modify the path to a docker-friendly one if\n    requested.\n\n    :param dict files: A dictionary of filenames: fsIDs\n    :param str work_dir: The destination directory\n    :param bool docker: Should the file path be converted to our standard docker '/data/filename'?\n    :return: Dict of files: (optionallly docker-friendly) fileepaths\n    :rtype: dict\n    \"\"\"\n    for name in files.keys():\n        outfile = job.fileStore.readGlobalFile(files[name], '/'.join([work_dir, name]))\n        # If the files will be sent to docker, we will mount work_dir to the container as /data and\n        # we want the /data prefixed path to the file\n        if docker:\n            files[name] = docker_path(outfile)\n        else:\n            files[name] = outfile\n    return files", "label": 1}
{"code": "public function queue_delete($queue = '', $if_unused = false, $if_empty = false, $nowait = false, $ticket = null)\n    {\n        $ticket = $this->getTicket($ticket);\n\n        list($class_id, $method_id, $args) = $this->protocolWriter->queueDelete(\n            $ticket,\n            $queue,\n            $if_unused,\n            $if_empty,\n            $nowait\n        );\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        if ($nowait) {\n            return null;\n        }\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('queue.delete_ok')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "function scrapDescription(window){\n   var $ = window.$;\n   var descriptions = [];\n\n   // Open Graph protocol by Facebook <meta property=\"og:description\" content=\"(*)\"/>\n   $('meta[property=\"og:description\"]').each(function(){\n      var content = $(this).attr('content');\n      if(content) descriptions.push(content);\n   });\n\n   // Schema.org : <* itemprop=\"description\">(*)</*>\n   $('[itemprop=\"description\"]').each(function(){\n      var text = $(this).text();\n      if(text) descriptions.push(text);\n   });\n\n   // Meta tag description: <meta property=\"description\" content=\"(*)\" />\n   $('meta[name=\"description\"]').each(function(){\n      var description = utils.inline($(this).attr('content')).trim();\n      if(description) descriptions.push(description);\n   });\n\n   // Random text in div and p tags. Oriented product informations\n   if(descriptions.length === 0){\n      $('div,p').each(function(){\n         if( ($(this).attr('class') && $(this).attr('class').toLowerCase() === 'productdesc') || ($(this).attr('id') && $(this).attr('id').toLowerCase() === 'productdesc')){\n            var description = utils.inline($(this).text()).trim();\n            if(description) descriptions.push(description);\n         }\n      });\n   }\n   return descriptions;\n}", "label": 3}
{"code": "def start(self, datas):\n        \"\"\"\n        Starts the pipeline by connecting the input ``Pipers`` of the pipeline \n        to the input data, connecting the pipeline and starting the ``NuMap``\n        instances.\n        \n        The order of items in the \"datas\" argument sequence should correspond \n        to the order of the input ``Pipers`` defined by ``Dagger._cmp`` and \n        ``Piper.ornament``.\n\n        Arguments:\n        \n          - datas(sequence) A sequence of external input data in the form of \n            sequences or iterators.\n\n        \"\"\"\n        if not self._started.isSet() and \\\n           not self._running.isSet() and \\\n           not self._pausing.isSet():\n            # Plumber statistics\n            self.stats = {}\n            self.stats['start_time'] = None\n            self.stats['run_time'] = None\n            # connects input pipers to external data\n            self.connect_inputs(datas)\n            # connects pipers within the pipeline\n            self.connect()\n            # make pointers to results collected for pipers by imaps\n            self.stats['pipers_tracked'] = {}\n            for piper in self.postorder():\n                if hasattr(piper.imap, '_tasks_tracked') and piper.track:\n                    self.stats['pipers_tracked'][piper] = \\\n                    [piper.imap._tasks_tracked[t.task] for t in piper.imap_tasks]\n\n            self.stats['start_time'] = time()\n            # starts the Dagger\n            # this starts Pipers and NuMaps\n            super(Plumber, self).start()\n            # transitioning to started state\n            self._started.set()\n            self._finished.clear()\n        else:\n            raise PlumberError", "label": 1}
{"code": "func (fs *FlagSet) Set(name, value string) error {\n\tflag, ok := fs.formal[name]\n\tif !ok {\n\t\treturn fmt.Errorf(\"no such flag -%v\", name)\n\t}\n\tif err := flag.Value.Set(value); err != nil {\n\t\treturn err\n\t}\n\tif fs.actual == nil {\n\t\tfs.actual = make(map[string]*Flag)\n\t}\n\tfs.actual[name] = flag\n\treturn nil\n}", "label": 5}
{"code": "def clean\n      return unless text\n      remove_all_newlines\n      replace_double_newlines\n      replace_newlines\n      replace_escaped_newlines\n\n      @text.apply(HTML::All)\n\n      replace_punctuation_in_brackets\n      @text.apply(InlineFormattingRule)\n      clean_quotations\n      clean_table_of_contents\n      check_for_no_space_in_between_sentences\n      clean_consecutive_characters\n    end", "label": 4}
{"code": "def find_all(name, prefix = nil, partial = false, details = {}, key = nil, locals = [])\n      locals = locals.map(&:to_s).sort!.freeze\n\n      cached(key, [name, prefix, partial], details, locals) do\n        _find_all(name, prefix, partial, details, key, locals)\n      end\n    end", "label": 4}
{"code": "func (s *sequence) toString() string {\n\tvar nextBlock string\n\tif s.next == nil {\n\t\tnextBlock = \"end\"\n\t} else {\n\t\tnextBlock = s.next.toString()\n\t}\n\treturn fmt.Sprintf(\"(0x%x, %d)->%s\", s.block, s.count, nextBlock)\n}", "label": 5}
{"code": "function getCamelCase(filePath) {\n    if (!filePath) {\n        return '';\n    }\n\n    // clip off everything by after the last slash and the .js\n    filePath = filePath.substring(filePath.lastIndexOf(delim) + 1);\n\n    if (filePath.substring(filePath.length - 3) === '.js') {\n        filePath = filePath.substring(0, filePath.length - 3);\n    }\n\n    // replace dots with caps\n    var parts = filePath.split('.');\n    var i;\n    for (i = 1; i < parts.length; i++) {\n        parts[i] = parts[i].substring(0, 1).toUpperCase() +\n            parts[i].substring(1);\n    }\n\n    // replace dashs with caps\n    filePath = parts.join('');\n    parts = filePath.split('-');\n    for (i = 1; i < parts.length; i++) {\n        parts[i] = parts[i].substring(0, 1).toUpperCase() + parts[i].substring(1);\n    }\n\n    return parts.join('');\n}", "label": 3}
{"code": "def _construct_opf_model(self, case):\n        \"\"\" Returns an OPF model.\n        \"\"\"\n        # Zero the case result attributes.\n        self.case.reset()\n\n        base_mva = case.base_mva\n\n        # Check for one reference bus.\n        oneref, refs = self._ref_check(case)\n        if not oneref: #return {\"status\": \"error\"}\n            None\n\n        # Remove isolated components.\n        bs, ln, gn = self._remove_isolated(case)\n\n        # Update bus indexes.\n        self.case.index_buses(bs)\n\n        # Convert single-block piecewise-linear costs into linear polynomial.\n        gn = self._pwl1_to_poly(gn)\n\n        # Set-up initial problem variables.\n        Va = self._get_voltage_angle_var(refs, bs)\n        Pg = self._get_pgen_var(gn, base_mva)\n\n        if self.dc: # DC model.\n            # Get the susceptance matrices and phase shift injection vectors.\n            B, Bf, Pbusinj, Pfinj = self.case.makeBdc(bs, ln)\n\n            # Power mismatch constraints (B*Va + Pg = Pd).\n            Pmis = self._power_mismatch_dc(bs, gn, B, Pbusinj, base_mva)\n\n            # Branch flow limit constraints.\n            Pf, Pt = self._branch_flow_dc(ln, Bf, Pfinj, base_mva)\n        else:\n            # Set-up additional AC-OPF problem variables.\n            Vm = self._get_voltage_magnitude_var(bs, gn)\n            Qg = self._get_qgen_var(gn, base_mva)\n\n            Pmis, Qmis, Sf, St = self._nln_constraints(len(bs), len(ln))\n\n            vl = self._const_pf_constraints(gn, base_mva)\n\n            # TODO: Generator PQ capability curve constraints.\n#            PQh, PQl = self._pq_capability_curve_constraints(gn)\n\n        # Branch voltage angle difference limits.\n        ang = self._voltage_angle_diff_limit(bs, ln)\n\n        if self.dc:\n            vars = [Va, Pg]\n            constraints = [Pmis, Pf, Pt, ang]\n        else:\n            vars = [Va, Vm, Pg, Qg]\n            constraints = [Pmis, Qmis, Sf, St, #PQh, PQL,\n                           vl, ang]\n\n        # Piece-wise linear generator cost constraints.\n        y, ycon = self._pwl_gen_costs(gn, base_mva)\n\n        if ycon is not None:\n            vars.append(y)\n            constraints.append(ycon)\n\n        # Add variables and constraints to the OPF model object.\n        opf = OPFModel(case)\n        opf.add_vars(vars)\n        opf.add_constraints(constraints)\n\n        if self.dc: # user data\n            opf._Bf = Bf\n            opf._Pfinj = Pfinj\n\n        return opf", "label": 1}
{"code": "public static Trajectory concactTrajectorie(Trajectory a, Trajectory b){\n\t\tif(a.getDimension()!=b.getDimension()){\n\t\t\tthrow new IllegalArgumentException(\"Combination not possible: The trajectorys does not have the same dimension\");\n\t\t}\n\t\tTrajectory c = new Trajectory(a.getDimension());\n\t\t\n\t\tfor(int i = 0 ; i < a.size(); i++){\n\t\t\tPoint3d pos = new Point3d(a.get(i).x, \n\t\t\t\t\ta.get(i).y, \n\t\t\t\t\ta.get(i).z);\n\t\t\tc.add(pos);\n\t\t}\n\t\t\n\t\tdouble dx = a.get(a.size()-1).x - b.get(0).x;\n\t\tdouble dy = a.get(a.size()-1).y - b.get(0).y;\n\t\tdouble dz = a.get(a.size()-1).z - b.get(0).z;\n\t\t\n\t\tfor(int i = 1 ; i < b.size(); i++){\n\t\t\tPoint3d pos = new Point3d(b.get(i).x+dx, \n\t\t\t\t\tb.get(i).y+dy, \n\t\t\t\t\tb.get(i).z+dz);\n\t\t\tc.add(pos);\n\t\t}\n\t\t\n\t\treturn c;\n\t\t\n\t}", "label": 0}
{"code": "function getFileFactoryOptions(build, parent, version, options, fileFactoryOptions) {\n  const { fileFactory, runtimeOptions } = fileFactoryOptions;\n  const hasPlugins = parent ? !!(options || version) : true;\n  const needsPlugins = 'input' in build && build.input != null && !build.watchOnly;\n\n  fileFactoryOptions.browser = build.browser;\n  fileFactoryOptions.buildFactory = getBuildFactory(build);\n  fileFactoryOptions.bundle = build.bundle;\n  fileFactoryOptions.fileCache = build.fileCache;\n  fileFactoryOptions.level = build.level + 2;\n  fileFactoryOptions.pluginOptions = {};\n  fileFactoryOptions.resolverCache = build.resolverCache;\n\n  // Only load plugins for active output builds\n  if (needsPlugins) {\n    // Use parent's if none defined\n    fileFactoryOptions.pluginOptions = hasPlugins\n      ? buildPlugins.load(build.type, options, version, runtimeOptions.compress)\n      : parent.fileFactoryOptions.pluginOptions;\n  }\n\n  // Overwrite fileFactory function with memoized options\n  fileFactoryOptions.fileFactory = function createFile(filepath) {\n    return fileFactory(filepath, fileFactoryOptions);\n  };\n\n  return fileFactoryOptions;\n}", "label": 3}
{"code": "function padcomments(str, num) {\n    var nl = _str.repeat('\\n', (num || 1));\n    return str.replace(/(\\s*)(<!--.+)\\s*(===.+)?/g, nl + '$1$2$1$3');\n  }", "label": 3}
{"code": "protected function extractPayload($eventName, $payload)\n    {\n        if (class_exists($eventName) && isset($payload[0]) && is_object($payload[0])) {\n            return ExtractProperties::from($payload[0]);\n        }\n\n        return collect($payload)->map(function ($value) {\n            return is_object($value) ? [\n                'class' => get_class($value),\n                'properties' => json_decode(json_encode($value), true),\n            ] : $value;\n        })->toArray();\n    }", "label": 2}
{"code": "public function setFamilies($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Bigtable\\V2\\Family::class);\n        $this->families = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func NewSessionArchive(dataDir, serverID, namespace string, sessionID session.ID) (io.ReadCloser, error) {\n\tindex, err := readSessionIndex(\n\t\tdataDir, []string{serverID}, namespace, sessionID)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// io.Pipe allows to generate the archive part by part\n\t// without writing to disk or generating it in memory\n\t// at the pace which reader is ready to consume it\n\treader, writer := io.Pipe()\n\ttarball := tar.NewWriter(writer)\n\tgo func() {\n\t\tif err := writeSessionArchive(index, tarball, writer); err != nil {\n\t\t\tlog.Warningf(\"Failed to write archive: %v.\", trace.DebugReport(err))\n\t\t}\n\t}()\n\n\treturn reader, nil\n}", "label": 5}
{"code": "func (m *Model) Count() Model {\n\tcount := Model{}\n\n\tfor ref, obj := range Map.objects {\n\t\tif _, ok := obj.(mo.Entity); !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tcount.total++\n\n\t\tswitch ref.Type {\n\t\tcase \"Datacenter\":\n\t\t\tcount.Datacenter++\n\t\tcase \"DistributedVirtualPortgroup\":\n\t\t\tcount.Portgroup++\n\t\tcase \"ClusterComputeResource\":\n\t\t\tcount.Cluster++\n\t\tcase \"Datastore\":\n\t\t\tcount.Datastore++\n\t\tcase \"HostSystem\":\n\t\t\tcount.Host++\n\t\tcase \"VirtualMachine\":\n\t\t\tcount.Machine++\n\t\tcase \"ResourcePool\":\n\t\t\tcount.Pool++\n\t\tcase \"VirtualApp\":\n\t\t\tcount.App++\n\t\tcase \"Folder\":\n\t\t\tcount.Folder++\n\t\tcase \"StoragePod\":\n\t\t\tcount.Pod++\n\t\t}\n\t}\n\n\treturn count\n}", "label": 5}
{"code": "public function setPolicy($policy, array $options = [])\n    {\n        if ($policy instanceof PolicyBuilder) {\n            $policy = $policy->result();\n        }\n\n        if (!is_array($policy)) {\n            throw new \\InvalidArgumentException('Given policy data must be an array or an instance of PolicyBuilder.');\n        }\n\n        $request = [];\n        if ($this->options['parent']) {\n            $parent = $this->options['parent'];\n            $request[$parent] = $policy;\n        } else {\n            $request = $policy;\n        }\n\n        return $this->policy = $this->connection->setPolicy([\n            'resource' => $this->resource\n        ] + $request + $options + $this->options['args']);\n    }", "label": 2}
{"code": "def _validate_isvalid_uncertainty(self, isvalid_uncertainty, field, value):\n        \"\"\"Checks for valid given value and appropriate units with uncertainty.\n\n        Args:\n            isvalid_uncertainty (`bool`): flag from schema indicating uncertainty to be checked\n            field (`str`): property associated with the quantity in question.\n            value (`list`): list with the string of the value of the quantity and a dictionary of\n                the uncertainty\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_uncertainty': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'list'}}\n        \"\"\"\n        self._validate_isvalid_quantity(True, field, value)\n\n        # This len check is necessary for reasons that aren't quite clear to me\n        # Cerberus calls this validation method even when lists have only one element\n        # and should therefore be validated only by isvalid_quantity\n        if len(value) > 1 and value[1]['uncertainty-type'] != 'relative':\n            if value[1].get('uncertainty') is not None:\n                self._validate_isvalid_quantity(True, field, [value[1]['uncertainty']])\n\n            if value[1].get('upper-uncertainty') is not None:\n                self._validate_isvalid_quantity(True, field, [value[1]['upper-uncertainty']])\n\n            if value[1].get('lower-uncertainty') is not None:\n                self._validate_isvalid_quantity(True, field, [value[1]['lower-uncertainty']])", "label": 1}
{"code": "function(tox, opts) {\n  if(!opts) opts = {};\n  var libpath = opts['path'];\n\n  this._tox = tox;\n  this._toxav = this.createLibrary(libpath);\n}", "label": 3}
{"code": "function walk(configDirectory, resourceName, resources) {\n    resourceName = resourceName || '';\n    resources = resources || {};\n\n    fs.readdirSync(path.join(configDirectory, resourceName)).forEach(fileName => {\n        const subResourceName = (resourceName !== '' ? resourceName + '/' : '') + fileName;\n        const absoluteFilePath = path.join(configDirectory, subResourceName);\n        const stat = fs.statSync(absoluteFilePath);\n        if (stat && stat.isDirectory()) {\n            walk(configDirectory, subResourceName, resources);\n        } else if (resourceName !== '') {\n            if (fileName.startsWith('config.')) {\n                if (!resources[resourceName]) resources[resourceName] = {};\n                resources[resourceName].configFile = absoluteFilePath;\n            }\n            if (fileName === 'index.js') {\n                if (!resources[resourceName]) resources[resourceName] = {};\n                resources[resourceName].instanceFile = absoluteFilePath;\n            }\n        }\n    });\n\n    return resources;\n}", "label": 3}
{"code": "def team_id=(team_id)\n      # First, we verify the team actually exists, because otherwise iTC would return the\n      # following confusing error message\n      #\n      #     invalid content provider id\n      #\n      available_teams = teams.collect do |team|\n        {\n          team_id: (team[\"contentProvider\"] || {})[\"contentProviderId\"],\n          team_name: (team[\"contentProvider\"] || {})[\"name\"]\n        }\n      end\n\n      result = available_teams.find do |available_team|\n        team_id.to_s == available_team[:team_id].to_s\n      end\n\n      unless result\n        error_string = \"Could not set team ID to '#{team_id}', only found the following available teams:\\n\\n#{available_teams.map { |team| \"- #{team[:team_id]} (#{team[:team_name]})\" }.join(\"\\n\")}\\n\"\n        raise Tunes::Error.new, error_string\n      end\n\n      response = request(:post) do |req|\n        req.url(\"ra/v1/session/webSession\")\n        req.body = {\n          contentProviderId: team_id,\n          dsId: user_detail_data.ds_id # https://github.com/fastlane/fastlane/issues/6711\n        }.to_json\n        req.headers['Content-Type'] = 'application/json'\n      end\n\n      handle_itc_response(response.body)\n\n      @current_team_id = team_id\n    end", "label": 4}
{"code": "@PostConstruct\n\tprotected void postConstruct() throws GeomajasException {\n\t\tif (null != crsDefinitions) {\n\t\t\tfor (CrsInfo crsInfo : crsDefinitions.values()) {\n\t\t\t\ttry {\n\t\t\t\t\tCoordinateReferenceSystem crs = CRS.parseWKT(crsInfo.getCrsWkt());\n\t\t\t\t\tString code = crsInfo.getKey();\n\t\t\t\t\tcrsCache.put(code, CrsFactory.getCrs(code, crs));\n\t\t\t\t} catch (FactoryException e) {\n\t\t\t\t\tthrow new GeomajasException(e, ExceptionCode.CRS_DECODE_FAILURE_FOR_MAP, crsInfo.getKey());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (null != crsTransformDefinitions) {\n\t\t\tfor (CrsTransformInfo crsTransformInfo : crsTransformDefinitions.values()) {\n\t\t\t\tString key = getTransformKey(crsTransformInfo);\n\t\t\t\ttransformCache.put(key, getCrsTransform(key, crsTransformInfo));\n\t\t\t}\n\t\t}\n\t\tGeometryFactory factory = new GeometryFactory();\n\t\tEMPTY_GEOMETRIES.put(Point.class, factory.createPoint((Coordinate) null));\n\t\tEMPTY_GEOMETRIES.put(LineString.class, factory.createLineString((Coordinate[]) null));\n\t\tEMPTY_GEOMETRIES.put(Polygon.class, factory.createPolygon(null, null));\n\t\tEMPTY_GEOMETRIES.put(MultiPoint.class, factory.createMultiPoint((Coordinate[]) null));\n\t\tEMPTY_GEOMETRIES.put(MultiLineString.class, factory.createMultiLineString((LineString[]) null)); // cast needed!\n\t\tEMPTY_GEOMETRIES.put(MultiPolygon.class, factory.createMultiPolygon((Polygon[]) null)); // cast needed!\n\t\tEMPTY_GEOMETRIES.put(Geometry.class, factory.createGeometryCollection(null));\n\t}", "label": 0}
{"code": "def check_ontology(fname):    \n    \"\"\"\n    reads the ontology yaml file and does basic verifcation\n    \"\"\"\n    with open(fname, 'r') as stream:\n        y = yaml.safe_load(stream)\n    import pprint\n    pprint.pprint(y)", "label": 1}
{"code": "public static double HighAccuracyComplemented(double x) {\n        double[] R =\n                {\n                        1.25331413731550025, 0.421369229288054473, 0.236652382913560671,\n                        0.162377660896867462, 0.123131963257932296, 0.0990285964717319214,\n                        0.0827662865013691773, 0.0710695805388521071, 0.0622586659950261958\n                };\n\n        int j = (int) (0.5 * (Math.abs(x) + 1));\n\n        double a = R[j];\n        double z = 2 * j;\n        double b = a * z - 1;\n\n        double h = Math.abs(x) - z;\n        double q = h * h;\n        double pwr = 1;\n\n        double sum = a + h * b;\n        double term = a;\n\n\n        for (int i = 2; sum != term; i += 2) {\n            term = sum;\n\n            a = (a + z * b) / (i);\n            b = (b + z * a) / (i + 1);\n            pwr *= q;\n\n            sum = term + pwr * (a + h * b);\n        }\n\n        sum *= Math.exp(-0.5 * (x * x) - 0.5 * Constants.Log2PI);\n\n        return (x >= 0) ? sum : (1.0 - sum);\n    }", "label": 0}
{"code": "func (c *controller) AgentInitWait() {\n\tc.Lock()\n\tagentInitDone := c.agentInitDone\n\tc.Unlock()\n\n\tif agentInitDone != nil {\n\t\t<-agentInitDone\n\t}\n}", "label": 5}
{"code": "public DbOrganization getOrganization(final DbArtifact dbArtifact) {\n        final DbModule module = getModule(dbArtifact);\n\n        if(module == null || module.getOrganization() == null){\n            return null;\n        }\n\n        return repositoryHandler.getOrganization(module.getOrganization());\n    }", "label": 0}
{"code": "public function make($name, $value = null, $maxAge = null)\n    {\n        $cookie = SetCookie::create($this->getName($name), $value);\n\n        // Make sure we send both the MaxAge and Expires parameters (the former\n        // is not supported by all browser versions)\n        if ($maxAge) {\n            $cookie = $cookie\n                ->withMaxAge($maxAge)\n                ->withExpires(time() + $maxAge);\n        }\n\n        if ($this->domain != null) {\n            $cookie = $cookie->withDomain($this->domain);\n        }\n\n        return $cookie\n            ->withPath($this->path)\n            ->withSecure($this->secure)\n            ->withHttpOnly(true);\n    }", "label": 2}
{"code": "function processThunkArgs( args ) {\n    let length = args.length | 0;\n\n    if( length >= 3 ) {\n        let res = new Array( --length );\n\n        for( let i = 0; i < length; ) {\n            res[i] = args[++i]; //It's a good thing this isn't undefined behavior in JavaScript\n        }\n\n        return res;\n    }\n\n    return args[1];\n}", "label": 3}
{"code": "def register_signals(self, app):\n        \"\"\"Register the signals.\"\"\"\n        before_record_index.connect(inject_provisional_community)\n        if app.config['COMMUNITIES_OAI_ENABLED']:\n            listen(Community, 'after_insert', create_oaipmh_set)\n            listen(Community, 'after_delete', destroy_oaipmh_set)\n        inclusion_request_created.connect(new_request)", "label": 1}
{"code": "public static nspbr6[] get(nitro_service service) throws Exception{\n\t\tnspbr6 obj = new nspbr6();\n\t\tnspbr6[] response = (nspbr6[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def extract_interpolated_values(text) # rubocop:disable Metrics/AbcSize\n      dumped_text = text.dump\n      newline_positions = extract_substring_positions(dumped_text, '\\\\\\n')\n\n      Haml::Util.handle_interpolation(dumped_text) do |scan|\n        line = (newline_positions.find_index { |marker| scan.pos <= marker } ||\n                newline_positions.size) + 1\n\n        escape_count = (scan[2].size - 1) / 2\n        break unless escape_count.even?\n\n        dumped_interpolated_str = Haml::Util.balance(scan, '{', '}', 1)[0][0...-1]\n\n        # Hacky way to turn a dumped string back into a regular string\n        yield [eval('\"' + dumped_interpolated_str + '\"'), line] # rubocop:disable Eval\n      end\n    end", "label": 4}
{"code": "def device_info(self):\n        \"\"\" Pull basic device information.\n\n        Purpose: This function grabs the hostname, model, running version, and\n               | serial number of the device.\n\n        @returns: The output that should be shown to the user.\n        @rtype: str\n        \"\"\"\n        # get hostname, model, and version from 'show version'\n        resp = self._session.get_software_information(format='xml')\n\n        hostname = resp.xpath('//software-information/host-name')[0].text\n        model = resp.xpath('//software-information/product-model')[0].text\n\n        version = 'Unknown'\n        if resp.xpath('//junos-version'):\n            \"\"\" case:\n                <junos-version>15.1</junos-version>\n            \"\"\"\n            try:\n                version = resp.xpath('//junos-version')[0].text\n            except IndexError:\n                pass\n        elif resp.xpath(\"//package-information[name = 'junos-version']\"):\n            \"\"\" case:\n                <package-information>\n                    <name>junos-version</name>\n                    <comment>Junos: 14.2R4</comment>\n                </package-information>\n           \"\"\"\n            try:\n                version = (resp.xpath(\n                    \"//package-information[name = 'junos-version']/comment\"\n                    )[0].text).split()[1]\n            except IndexError:\n                pass\n        else:\n            \"\"\" case:\n                <package-information>\n                    <name>junos</name>\n                    <comment>JUNOS Base OS boot [12.3R5]</comment>\n                </package-information>\n            \"\"\"\n            try:\n                version = ((resp.xpath(\n                    '//software-information/package-information/comment'\n                    )[0].text.split('[')[1].split(']')[0]))\n            except IndexError:\n                pass\n\n        # try looking for 'junos-version' for >= 14.2\n#        for element in resp.xpath('//software-information'):\n#            version = element.findtext('junos-version')\n\n#        if not version:\n#            try:\n#                version = ((resp.xpath(\n#                    '//software-information/package-information/comment')\n#                    [0].text.split('[')[1].split(']')[0]))\n#            except IndexError:\n#                version = 'Unknown'\n\n        # get uptime from 'show system uptime'\n        resp = self._session.get_system_uptime_information(format='xml')\n        try:\n            current_time = resp.xpath('//current-time/date-time')[0].text\n        except IndexError:\n            current_time = 'Unknown'\n        try:\n            uptime = resp.xpath('//uptime-information/up-time')[0].text\n        except IndexError:\n            uptime = 'Unknown'\n        # get serial number from 'show chassis hardware'\n        show_hardware = self._session.get_chassis_inventory(format='xml')\n        # If we're hitting an EX, grab each Routing Engine Serial number\n        # to get all RE SNs in a VC\n        try:\n            chassis_module = show_hardware.xpath(\n                '//chassis-inventory/chassis/chassis-module/description'\n                )[0].text\n        except IndexError:\n            chassis_module = 'Unknown'\n\n        if ('EX' or 'ex' or 'Ex') in chassis_module:\n            serial_num = ''\n            for eng in show_hardware.xpath(\n                    '//chassis-inventory/chassis/chassis-module'):\n                if 'Routing Engine' in eng.xpath('name')[0].text:\n                    serial_num += (eng.xpath('name')[0].text + ' Serial #: ' +\n                                   eng.xpath('serial-number')[0].text)\n        else:  # Any other device type, just grab chassis SN\n            try:\n                serial_num = ('Chassis Serial Number: ' + show_hardware.xpath(\n                    '//chassis-inventory/chassis/serial-number')[0].text)\n            except IndexError:\n                serial_num = 'Chassis Serial Number: ' \\\n                    + 'Unknown (virtual machine?)'\n        return ('Hostname: %s\\nModel: %s\\nJunos Version: %s\\n%s\\nCurrent Time:'\n                ' %s\\nUptime: %s\\n' %\n                (hostname, model, version, serial_num, current_time, uptime))", "label": 1}
{"code": "function (definition, visibility) {\n        var isWScript = _GPF_HOST.WSCRIPT === _gpfHost;\n        this._defaultVisibility = visibility;\n        _gpfObjectForEach(definition, this._processDefinitionMember, this);\n        if (isWScript && definition.hasOwnProperty(\"toString\")) {\n            this._processDefinitionMember(definition.toString, \"toString\");\n        }\n        this._defaultVisibility = _GPF_VISIBILITY_UNKNOWN;\n        if (isWScript && definition.hasOwnProperty(\"constructor\")) {\n            this._addConstructor(definition.constructor, this._defaultVisibility);\n        }\n    }", "label": 3}
{"code": "public String haikunate() {\n        if (tokenHex) {\n            tokenChars = \"0123456789abcdef\";\n        }\n\n        String adjective = randomString(adjectives);\n        String noun = randomString(nouns);\n\n        StringBuilder token = new StringBuilder();\n        if (tokenChars != null && tokenChars.length() > 0) {\n            for (int i = 0; i < tokenLength; i++) {\n                token.append(tokenChars.charAt(random.nextInt(tokenChars.length())));\n            }\n        }\n\n        return Stream.of(adjective, noun, token.toString())\n                .filter(s -> s != null && !s.isEmpty())\n                .collect(joining(delimiter));\n    }", "label": 0}
{"code": "def get_filename(self, year):\n        \"\"\"\n        returns the filename\n        \"\"\"\n        res = self.fldr + os.sep + self.type + year + '.' + self.user \n        return res", "label": 1}
{"code": "private function executeRead(ReadPartition $partition)\n    {\n        return $this->read($partition->table(), $partition->keySet(), $partition->columns(), [\n            'partitionToken' => $partition->token()\n        ] + $partition->options());\n    }", "label": 2}
{"code": "def extractDates(self, inp):\n        \"\"\"Extract semantic date information from an input string.\n        In effect, runs both parseDay and parseTime on the input\n        string and merges the results to produce a comprehensive\n        datetime object.\n\n        Args:\n            inp (str): Input string to be parsed.\n\n        Returns:\n            A list of datetime objects containing the extracted dates from the\n            input snippet, or an empty list if not found.\n        \"\"\"\n        def merge(param):\n            day, time = param\n            if not (day or time):\n                return None\n\n            if not day:\n                return time\n            if not time:\n                return day\n\n            return datetime.datetime(\n                day.year, day.month, day.day, time.hour, time.minute\n            )\n\n        days = self.extractDays(inp)\n        times = self.extractTimes(inp)\n        return map(merge, zip_longest(days, times, fillvalue=None))", "label": 1}
{"code": "public function searchableColumnIndex()\n    {\n        $searchable = [];\n        for ($i = 0, $c = count($this->request->input('columns')); $i < $c; $i++) {\n            if ($this->isColumnSearchable($i, false)) {\n                $searchable[] = $i;\n            }\n        }\n\n        return $searchable;\n    }", "label": 2}
{"code": "public static base_responses enable(nitro_service client, String acl6name[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (acl6name != null && acl6name.length > 0) {\n\t\t\tnsacl6 enableresources[] = new nsacl6[acl6name.length];\n\t\t\tfor (int i=0;i<acl6name.length;i++){\n\t\t\t\tenableresources[i] = new nsacl6();\n\t\t\t\tenableresources[i].acl6name = acl6name[i];\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, enableresources,\"enable\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected function initialize()\n    {\n        $this->classCache = [];\n        if ($this->globalBasename !== null) {\n            foreach ($this->locator->getPaths() as $path) {\n                $file = $path . '/' . $this->globalBasename . $this->locator->getFileExtension();\n                if (is_file($file)) {\n                    $this->classCache = array_merge(\n                        $this->classCache,\n                        $this->loadMappingFile($file)\n                    );\n                }\n            }\n        }\n    }", "label": 2}
{"code": "function mixin(mixinParams) {\n  return withNoNewKeyword(\n  /*#__PURE__*/\n  function (_this) {\n    _inherits(MixinSwal, _this);\n\n    function MixinSwal() {\n      _classCallCheck(this, MixinSwal);\n\n      return _possibleConstructorReturn(this, _getPrototypeOf(MixinSwal).apply(this, arguments));\n    }\n\n    _createClass(MixinSwal, [{\n      key: \"_main\",\n      value: function _main(params) {\n        return _get(_getPrototypeOf(MixinSwal.prototype), \"_main\", this).call(this, _extends({}, mixinParams, params));\n      }\n    }]);\n\n    return MixinSwal;\n  }(this));\n}", "label": 3}
{"code": "function precedence(ast) {\n  var p = PRECEDENCE[ast[\"type\"]];\n  if ( _.isNumber(p) ) // represents Fixnum? I'm so sorry.\n    return p;\n  else if ( p && p.constructor === Object ) // p is a {} object\n    return p[ast[\"operator\"]];\n  else\n    return 0;\n}", "label": 3}
{"code": "function(object, otherterms) {\n    var filenames = this._index.filenames;\n    var docnames = this._index.docnames;\n    var objects = this._index.objects;\n    var objnames = this._index.objnames;\n    var titles = this._index.titles;\n\n    var i;\n    var results = [];\n\n    for (var prefix in objects) {\n      for (var name in objects[prefix]) {\n        var fullname = (prefix ? prefix + '.' : '') + name;\n        if (fullname.toLowerCase().indexOf(object) > -1) {\n          var score = 0;\n          var parts = fullname.split('.');\n          // check for different match types: exact matches of full name or\n          // \"last name\" (i.e. last dotted part)\n          if (fullname == object || parts[parts.length - 1] == object) {\n            score += Scorer.objNameMatch;\n          // matches in last name\n          } else if (parts[parts.length - 1].indexOf(object) > -1) {\n            score += Scorer.objPartialMatch;\n          }\n          var match = objects[prefix][name];\n          var objname = objnames[match[1]][2];\n          var title = titles[match[0]];\n          // If more than one term searched for, we require other words to be\n          // found in the name/title/description\n          if (otherterms.length > 0) {\n            var haystack = (prefix + ' ' + name + ' ' +\n                            objname + ' ' + title).toLowerCase();\n            var allfound = true;\n            for (i = 0; i < otherterms.length; i++) {\n              if (haystack.indexOf(otherterms[i]) == -1) {\n                allfound = false;\n                break;\n              }\n            }\n            if (!allfound) {\n              continue;\n            }\n          }\n          var descr = objname + _(', in ') + title;\n\n          var anchor = match[3];\n          if (anchor === '')\n            anchor = fullname;\n          else if (anchor == '-')\n            anchor = objnames[match[1]][1] + '-' + fullname;\n          // add custom score for some objects according to scorer\n          if (Scorer.objPrio.hasOwnProperty(match[2])) {\n            score += Scorer.objPrio[match[2]];\n          } else {\n            score += Scorer.objPrioDefault;\n          }\n          results.push([docnames[match[0]], fullname, '#'+anchor, descr, score, filenames[match[0]]]);\n        }\n      }\n    }\n\n    return results;\n  }", "label": 3}
{"code": "private static StackTraceElement getStackTrace() {\r\n    StackTraceElement[] stack = Thread.currentThread().getStackTrace();\r\n\r\n    int i = 2; // we can skip the first two (first is getStackTrace(), second is this method)\r\n    while (i < stack.length) {\r\n      boolean isLoggingClass = false;\r\n      for (String loggingClass : loggingClasses) {\r\n        String className = stack[i].getClassName();\r\n        if (className.startsWith(loggingClass)) {\r\n          isLoggingClass = true;\r\n          break;\r\n        }\r\n      }\r\n      if (!isLoggingClass) {\r\n        break;\r\n      }\r\n\r\n      i += 1;\r\n    }\r\n\r\n    // if we didn't find anything, keep last element (probably shouldn't happen, but could if people add too many logging classes)\r\n    if (i >= stack.length) {\r\n      i = stack.length - 1;\r\n    }\r\n    return stack[i];\r\n  }", "label": 0}
{"code": "public function setMqttConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Iot\\V1\\MqttConfig::class);\n        $this->mqtt_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public void schedule(BackoffTask task, long initialDelay, long fixedDelay) {\n    \tsynchronized (queue) {\n\t    \tstart();\n\t        queue.put(new DelayedTimerTask(task, initialDelay, fixedDelay));\n    \t}\n    }", "label": 0}
{"code": "def option_value\n      if option_id\n        option_endpoint = \"/customFields/#{custom_field_id}/options/#{option_id}\"\n        option = CustomFieldOption.from_response client.get(option_endpoint)\n        option.value\n      end\n    end", "label": 4}
{"code": "func OptionHostsPath(path string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.hostsPath = path\n\t}\n}", "label": 5}
{"code": "def _get_m2m_field(model, sender):\n    \"\"\"\n    Get the field name from a model and a sender from m2m_changed signal.\n    \"\"\"\n    for field in getattr(model, '_tracked_fields', []):\n        if isinstance(model._meta.get_field(field), ManyToManyField):\n            if getattr(model, field).through == sender:\n                return field\n    for field in getattr(model, '_tracked_related_fields', {}).keys():\n        if isinstance(model._meta.get_field(field), ManyToManyField):\n            if getattr(model, field).through == sender:\n                return field", "label": 1}
{"code": "func PgNamespaceByNspname(db XODB, nspname pgtypes.Name) (*PgNamespace, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, nspname, nspowner, nspacl ` +\n\t\t`FROM pg_catalog.pg_namespace ` +\n\t\t`WHERE nspname = $1`\n\n\t// run query\n\tXOLog(sqlstr, nspname)\n\tpn := PgNamespace{}\n\n\terr = db.QueryRow(sqlstr, nspname).Scan(&pn.Tableoid, &pn.Cmax, &pn.Xmax, &pn.Cmin, &pn.Xmin, &pn.Oid, &pn.Ctid, &pn.Nspname, &pn.Nspowner, &pn.Nspacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pn, nil\n}", "label": 5}
{"code": "public static base_response delete(nitro_service client, String id) throws Exception {\n\t\tlinkset deleteresource = new linkset();\n\t\tdeleteresource.id = id;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "public function setFound($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Datastore\\V1\\EntityResult::class);\n        $this->found = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function isLoadNeeded(newProps, oldProps) {\n        return !_.isEqual(newProps.formDesign, oldProps.formDesign) || !_.isEqual(newProps.data, oldProps.data);\n      }", "label": 3}
{"code": "public function setDiscriminatorColumn($alias, $discrColumn)\n    {\n        $this->discriminatorColumns[$alias] = $discrColumn;\n        $this->columnOwnerMap[$discrColumn] = $alias;\n\n        return $this;\n    }", "label": 2}
{"code": "protected function getNullsLastSql($column, $direction)\n    {\n        $sql = $this->config->get('datatables.nulls_last_sql', '%s %s NULLS LAST');\n\n        return sprintf($sql, $column, $direction);\n    }", "label": 2}
{"code": "func (h *AuthHandlers) authorityForCert(caType services.CertAuthType, key ssh.PublicKey) (services.CertAuthority, error) {\n\t// get all certificate authorities for given type\n\tcas, err := h.AccessPoint.GetCertAuthorities(caType, false)\n\tif err != nil {\n\t\th.Warnf(\"%v\", trace.DebugReport(err))\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// find the one that signed our certificate\n\tvar ca services.CertAuthority\n\tfor i := range cas {\n\t\tcheckers, err := cas[i].Checkers()\n\t\tif err != nil {\n\t\t\th.Warnf(\"%v\", err)\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tfor _, checker := range checkers {\n\t\t\t// if we have a certificate, compare the certificate signing key against\n\t\t\t// the ca key. otherwise check the public key that was passed in. this is\n\t\t\t// due to the differences in how this function is called by the user and\n\t\t\t// host checkers.\n\t\t\tswitch v := key.(type) {\n\t\t\tcase *ssh.Certificate:\n\t\t\t\tif sshutils.KeysEqual(v.SignatureKey, checker) {\n\t\t\t\t\tca = cas[i]\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tif sshutils.KeysEqual(key, checker) {\n\t\t\t\t\tca = cas[i]\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// the certificate was signed by unknown authority\n\tif ca == nil {\n\t\treturn nil, trace.AccessDenied(\"the certificate signed by untrusted CA\")\n\t}\n\n\treturn ca, nil\n}", "label": 5}
{"code": "def moresane_by_scale(self, start_scale=1, stop_scale=20, subregion=None, sigma_level=4, loop_gain=0.1,\n                          tolerance=0.75, accuracy=1e-6, major_loop_miter=100, minor_loop_miter=30, all_on_gpu=False,\n                          decom_mode=\"ser\", core_count=1, conv_device='cpu', conv_mode='linear', extraction_mode='cpu',\n                          enforce_positivity=False, edge_suppression=False,\n                          edge_offset=0, flux_threshold=0, neg_comp=False, edge_excl=0, int_excl=0):\n        \"\"\"\n        Extension of the MORESANE algorithm. This takes a scale-by-scale approach, attempting to remove all sources\n        at the lower scales before moving onto the higher ones. At each step the algorithm may return to previous\n        scales to remove the sources uncovered by the deconvolution.\n\n        INPUTS:\n        start_scale         (default=1)         The first scale which is to be considered.\n        stop_scale          (default=20)        The maximum scale which is to be considered. Optional.\n        subregion           (default=None):     Size, in pixels, of the central region to be analyzed and deconvolved.\n        sigma_level         (default=4)         Number of sigma at which thresholding is to be performed.\n        loop_gain           (default=0.1):      Loop gain for the deconvolution.\n        tolerance           (default=0.75):     Tolerance level for object extraction. Significant objects contain\n                                                wavelet coefficients greater than the tolerance multiplied by the\n                                                maximum wavelet coefficient in the scale under consideration.\n        accuracy            (default=1e-6):     Threshold on the standard deviation of the residual noise. Exit main\n                                                loop when this threshold is reached.\n        major_loop_miter    (default=100):      Maximum number of iterations allowed in the major loop. Exit\n                                                condition.\n        minor_loop_miter    (default=30):       Maximum number of iterations allowed in the minor loop. Serves as an\n                                                exit condition when the SNR does not reach a maximum.\n        all_on_gpu          (default=False):    Boolean specifier to toggle all gpu modes on.\n        decom_mode          (default='ser'):    Specifier for decomposition mode - serial, multiprocessing, or gpu.\n        core_count          (default=1):        In the event that multiprocessing, specifies the number of cores.\n        conv_device         (default='cpu'):    Specifier for device to be used - cpu or gpu.\n        conv_mode           (default='linear'): Specifier for convolution mode - linear or circular.\n        extraction_mode     (default='cpu'):    Specifier for mode to be used - cpu or gpu.\n        enforce_positivity  (default=False):    Boolean specifier for whether or not a model must be strictly positive.\n        edge_suppression    (default=False):    Boolean specifier for whether or not the edges are to be suprressed.\n        edge_offset         (default=0):        Numeric value for an additional user-specified number of edge pixels\n                                                to be ignored. This is added to the minimum suppression.\n\n        OUTPUTS:\n        self.model          (no default):       Model extracted by the algorithm.\n        self.residual       (no default):       Residual signal after deconvolution.\n        \"\"\"\n\n        # The following preserves the dirty image as it will be changed on every iteration.\n\n        dirty_data = self.dirty_data\n\n        scale_count = start_scale\n\n\n        while not (self.complete):\n\n            logger.info(\"MORESANE at scale {}\".format(scale_count))\n\n            self.moresane(subregion=subregion, scale_count=scale_count, sigma_level=sigma_level, loop_gain=loop_gain,\n                          tolerance=tolerance, accuracy=accuracy, major_loop_miter=major_loop_miter,\n                          minor_loop_miter=minor_loop_miter, all_on_gpu=all_on_gpu, decom_mode=decom_mode,\n                          core_count=core_count, conv_device=conv_device, conv_mode=conv_mode,\n                          extraction_mode=extraction_mode, enforce_positivity=enforce_positivity,\n                          edge_suppression=edge_suppression, edge_offset=edge_offset,\n                          flux_threshold=flux_threshold, neg_comp=neg_comp,\n                          edge_excl=edge_excl, int_excl=int_excl)\n\n            self.dirty_data = self.residual\n\n            scale_count += 1\n\n            if (scale_count>(np.log2(self.dirty_data.shape[0]))-1):\n                logger.info(\"Maximum scale reached - finished.\")\n                break\n\n            if (scale_count>stop_scale):\n                logger.info(\"Maximum scale reached - finished.\")\n                break\n\n        # Restores the original dirty image.\n\n        self.dirty_data = dirty_data\n        self.complete = False", "label": 1}
{"code": "public static base_responses save(nitro_service client, cacheobject resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcacheobject saveresources[] = new cacheobject[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tsaveresources[i] = new cacheobject();\n\t\t\t\tsaveresources[i].locator = resources[i].locator;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, saveresources,\"save\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def find_ribosomal(rps, scaffolds, s2rp, min_hits, max_hits_rp, max_errors):\n    \"\"\"\n    determine which hits represent real ribosomal proteins, identify each in syntenic block\n    max_hits_rp = maximum number of hits to consider per ribosomal protein per scaffold\n    \"\"\"\n    for scaffold, proteins in list(s2rp.items()):\n        # for each scaffold, get best hits for each rp\n        hits = {p: [i for i in sorted(hits, key = itemgetter(10))][0:max_hits_rp]\n            for p, hits in list(proteins.items()) if len(hits) > 0}\n        # skip if fewer than min_hits RPs are identified\n        if len(hits) < min_hits:\n            continue\n        best = sorted([hit[0] + [p]\n            for p, hit in list(hits.items())], key = itemgetter(10))[0]\n        block = find_block(rps, scaffolds[scaffold], hits, best, max_errors)\n        if (len(block) - 1) >= min_hits:\n            yield scaffold, block", "label": 1}
{"code": "def verify_available_languages!(options)\n      return if options[:skip_metadata]\n\n      # Collect all languages we need\n      # We only care about languages from user provided values\n      # as the other languages are on iTC already anyway\n      v = options[:app].edit_version(platform: options[:platform])\n      UI.user_error!(\"Could not find a version to edit for app '#{options[:app].name}', the app metadata is read-only currently\") unless v\n\n      enabled_languages = options[:languages] || []\n      LOCALISED_VERSION_VALUES.each do |key|\n        current = options[key]\n        next unless current && current.kind_of?(Hash)\n        current.each do |language, value|\n          language = language.to_s\n          enabled_languages << language unless enabled_languages.include?(language)\n        end\n      end\n\n      # Reject \"default\" language from getting enabled\n      # because \"default\" is not an iTC language\n      enabled_languages = enabled_languages.reject do |lang|\n        lang == \"default\"\n      end.uniq\n\n      if enabled_languages.count > 0\n        v.create_languages(enabled_languages)\n        lng_text = \"language\"\n        lng_text += \"s\" if enabled_languages.count != 1\n        Helper.show_loading_indicator(\"Activating #{lng_text} #{enabled_languages.join(', ')}...\")\n        v.save!\n        Helper.hide_loading_indicator\n      end\n      true\n    end", "label": 4}
{"code": "private void handleIncomingMessage(SerialMessage incomingMessage) {\n\t\t\n\t\tlogger.debug(\"Incoming message to process\");\n\t\tlogger.debug(incomingMessage.toString());\n\t\t\n\t\tswitch (incomingMessage.getMessageType()) {\n\t\t\tcase Request:\n\t\t\t\thandleIncomingRequestMessage(incomingMessage);\n\t\t\t\tbreak;\n\t\t\tcase Response:\n\t\t\t\thandleIncomingResponseMessage(incomingMessage);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tlogger.warn(\"Unsupported incomingMessageType: 0x%02X\", incomingMessage.getMessageType());\n\t\t}\n\t}", "label": 0}
{"code": "protected void checkForPrimaryKeys(final Object realObject) throws ClassNotPersistenceCapableException\r\n    {\r\n        // if no PKs are specified OJB can't handle this class !\r\n        if (m_pkValues == null || m_pkValues.length == 0)\r\n        {\r\n            throw createException(\"OJB needs at least one primary key attribute for class: \", realObject, null);\r\n        }\r\n// arminw: should never happen\r\n//        if(m_pkValues[0] instanceof ValueContainer)\r\n//            throw new OJBRuntimeException(\"Can't handle pk values of type \"+ValueContainer.class.getName());\r\n    }", "label": 0}
{"code": "function useAccessAuth() {\n  return new Promise((resolve, reject) => {\n    if (!defaults.accessToken) {\n      reject(__generateFakeResponse__(0, '', {}, 'accessToken is missing for Access authentication'))\n    }\n    else {\n      let details = {\n        \"token_type\": \"\",\n        \"expires_in\": 0,\n        \"appName\": defaults.appName,\n        \"username\": \"\",\n        \"role\": \"\",\n        \"firstName\": \"\",\n        \"lastName\": \"\",\n        \"fullName\": \"\",\n        \"regId\": 0,\n        \"userId\": null\n      };\n      var aToken = defaults.accessToken.toLowerCase().startsWith('bearer') ? defaults.accessToken : 'Bearer ' + defaults.accessToken;\n      utils.storage.set('user', {\n        token: {\n          Authorization:  aToken,\n          appName: defaults.appName\n        },\n        details: details\n      });\n      resolve(__generateFakeResponse__(200, 'OK', {}, details, {}));\n    }\n  });\n\n}", "label": 3}
{"code": "protected boolean check(String id, List<String> includes, List<String> excludes) {\n\t\treturn check(id, includes) && !check(id, excludes);\n\t}", "label": 0}
{"code": "func NewLicense(name string, spec LicenseSpecV3) (License, error) {\n\treturn &LicenseV3{\n\t\tKind:    KindLicense,\n\t\tVersion: V3,\n\t\tMetadata: Metadata{\n\t\t\tName:      name,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: spec,\n\t}, nil\n}", "label": 5}
{"code": "private function findPackageVersion($path, $fallback = null)\n    {\n        if (file_exists(\"$path/.git\")) {\n            $cwd = getcwd();\n            chdir($path);\n\n            $output = [];\n            $status = null;\n            exec('git rev-parse HEAD 2>&1', $output, $status);\n\n            chdir($cwd);\n\n            if ($status == 0) {\n                return isset($fallback) ? \"$fallback ($output[0])\" : $output[0];\n            }\n        }\n\n        return $fallback;\n    }", "label": 2}
{"code": "func ListenTLS(address string, certFile, keyFile string, cipherSuites []uint16) (net.Listener, error) {\n\ttlsConfig, err := CreateTLSConfiguration(certFile, keyFile, cipherSuites)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn tls.Listen(\"tcp\", address, tlsConfig)\n}", "label": 5}
{"code": "func (r *Linear) String() string {\n\treturn fmt.Sprintf(\"Linear(attempt=%v, duration=%v)\", r.attempt, r.Duration())\n}", "label": 5}
{"code": "public static base_response update(nitro_service client, policyexpression resource) throws Exception {\n\t\tpolicyexpression updateresource = new policyexpression();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.value = resource.value;\n\t\tupdateresource.description = resource.description;\n\t\tupdateresource.comment = resource.comment;\n\t\tupdateresource.clientsecuritymessage = resource.clientsecuritymessage;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function getRegionName(): ?string\n    {\n        return $this->region ? (static::regions()[$this->region] ?? $this->region) : null;\n    }", "label": 2}
{"code": "public function getName()\n    {\n        $name = $this->name;\n        if (str_contains($this->name, '\\\\')) {\n            $name = str_replace('\\\\', '/', $this->name);\n        }\n        if (str_contains($this->name, '/')) {\n            $name = str_replace('/', '/', $this->name);\n        }\n\n        return Str::studly(str_replace(' ', '/', ucwords(str_replace('/', ' ', $name))));\n    }", "label": 2}
{"code": "public function setTextSnippet($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\TextSnippet::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def run_radia_with_merge(job, rna_bam, tumor_bam, normal_bam, univ_options, radia_options):\n    \"\"\"\n    A wrapper for the the entire RADIA sub-graph.\n\n    :param dict rna_bam: Dict dicts of bam and bai for tumor RNA-Seq obtained by running STAR within\n           ProTECT.\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict radia_options: Options specific to RADIA\n    :return: fsID to the merged RADIA calls\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    spawn = job.wrapJobFn(run_radia, rna_bam['rna_genome'], tumor_bam,\n                          normal_bam, univ_options, radia_options, disk='100M',\n                          memory='100M').encapsulate()\n    merge = job.wrapJobFn(merge_perchrom_vcfs, spawn.rv(), univ_options, disk='100M', memory='100M')\n    job.addChild(spawn)\n    spawn.addChild(merge)\n    return merge.rv()", "label": 1}
{"code": "def process_rule(self, m, dct, tpe):\n        \"\"\" \n        uses the MapRule 'm' to run through the 'dict'\n        and extract data based on the rule\n        \"\"\"\n        print('TODO - ' + tpe + ' + applying rule ' + str(m).replace('\\n', '') )", "label": 1}
{"code": "def update!\n      client.put(\"/webhooks/#{id}\", {\n        description: description,\n        idModel: id_model,\n        callbackURL: callback_url,\n        active: active\n      })\n    end", "label": 4}
{"code": "public static function createFromDate($year = null, $month = null, $day = null, $tz = null)\n    {\n        return static::create($year, $month, $day, null, null, null, $tz);\n    }", "label": 2}
{"code": "protected function byIndex($index, $select = true)\n    {\n        $elements = $this->getRelatedElements();\n        if (!isset($elements[$index])) {\n            throw new NoSuchElementException(sprintf('Cannot locate %s with index: %d', $this->type, $index));\n        }\n\n        $select ? $this->selectOption($elements[$index]) : $this->deselectOption($elements[$index]);\n    }", "label": 2}
{"code": "public Dataset<String, String> getDataset(Dataset<String, String> oldData, Index<String> goodFeatures) {\r\n    //public Dataset getDataset(List data, Collection goodFeatures) {\r\n    //makeAnswerArraysAndTagIndex(data);\r\n\r\n    int[][] oldDataArray = oldData.getDataArray();\r\n    int[] oldLabelArray = oldData.getLabelsArray();\r\n    Index<String> oldFeatureIndex = oldData.featureIndex;\r\n\r\n    int[] oldToNewFeatureMap = new int[oldFeatureIndex.size()];\r\n\r\n    int[][] newDataArray = new int[oldDataArray.length][];\r\n\r\n    System.err.print(\"Building reduced dataset...\");\r\n\r\n    int size = oldFeatureIndex.size();\r\n    int max = 0;\r\n    for (int i = 0; i < size; i++) {\r\n      oldToNewFeatureMap[i] = goodFeatures.indexOf(oldFeatureIndex.get(i));\r\n      if (oldToNewFeatureMap[i] > max) {\r\n        max = oldToNewFeatureMap[i];\r\n      }\r\n    }\r\n\r\n    for (int i = 0; i < oldDataArray.length; i++) {\r\n      int[] data = oldDataArray[i];\r\n      size = 0;\r\n      for (int j = 0; j < data.length; j++) {\r\n        if (oldToNewFeatureMap[data[j]] > 0) {\r\n          size++;\r\n        }\r\n      }\r\n      int[] newData = new int[size];\r\n      int index = 0;\r\n      for (int j = 0; j < data.length; j++) {\r\n        int f = oldToNewFeatureMap[data[j]];\r\n        if (f > 0) {\r\n          newData[index++] = f;\r\n        }\r\n      }\r\n      newDataArray[i] = newData;\r\n    }\r\n\r\n    Dataset<String, String> train = new Dataset<String, String>(oldData.labelIndex, oldLabelArray, goodFeatures, newDataArray, newDataArray.length);\r\n\r\n    System.err.println(\"done.\");\r\n    if (flags.featThreshFile != null) {\r\n      System.err.println(\"applying thresholds...\");\r\n      List<Pair<Pattern,Integer>> thresh = getThresholds(flags.featThreshFile);\r\n      train.applyFeatureCountThreshold(thresh);\r\n    } else if (flags.featureThreshold > 1) {\r\n      System.err.println(\"Removing Features with counts < \" + flags.featureThreshold);\r\n      train.applyFeatureCountThreshold(flags.featureThreshold);\r\n    }\r\n    train.summaryStatistics();\r\n    return train;\r\n  }", "label": 0}
{"code": "def evaluate(condition):\n        \"\"\"\n        Evaluate simple condition.\n\n        >>> Condition.evaluate('  2  ==  2  ')\n        True\n        >>> Condition.evaluate('  not  2  ==  2  ')\n        False\n        >>> Condition.evaluate('  not  \"abc\"  ==  \"xyz\"  ')\n        True\n        >>> Condition.evaluate('2 in [2, 4, 6, 8, 10]')\n        True\n        >>> Condition.evaluate('5 in [2, 4, 6, 8, 10]')\n        False\n        >>> Condition.evaluate('\"apple\" in [\"apple\", \"kiwi\", \"orange\"]')\n        True\n        >>> Condition.evaluate('5 not in [2, 4, 6, 8, 10]')\n        True\n        >>> Condition.evaluate('\"apple\" not in [\"kiwi\", \"orange\"]')\n        True\n\n        Args:\n            condition (str): Python condition as string.\n\n        Returns:\n            bool: True when condition evaluates to True.\n        \"\"\"\n        success = False\n        if len(condition) > 0:\n            try:\n                rule_name, ast_tokens, evaluate_function = Condition.find_rule(condition)\n                if not rule_name == 'undefined':\n                    success = evaluate_function(ast_tokens)\n            except AttributeError as exception:\n                Logger.get_logger(__name__).error(\"Attribute error: %s\", exception)\n        else:\n            success = True\n        return success", "label": 1}
{"code": "private function sendMessage()\n    {\n        if (is_array($this->inputs['to'])) {\n            $this->connectToWhatsApp();\n            foreach ($this->inputs['to'] as $to) {\n                if (trim($to) !== '') {\n                    if (isset($this->inputs['message']) && trim($this->inputs['message'] !== '')) {\n                        $this->wa->sendMessageComposing($to);\n                        $this->wa->sendMessage($to, $this->inputs['message']);\n                    }\n                    if (isset($this->inputs['image']) && $this->inputs['image'] !== false) {\n                        $this->wa->sendMessageImage($to, $this->inputs['image']);\n                    }\n                    if (isset($this->inputs['audio']) && $this->inputs['audio'] !== false) {\n                        $this->wa->sendMessageAudio($to, $this->inputs['audio']);\n                    }\n                    if (isset($this->inputs['video']) && $this->inputs['video'] !== false) {\n                        $this->wa->sendMessageVideo($to, $this->inputs['video']);\n                    }\n                    if (isset($this->inputs['locationname']) && trim($this->inputs['locationname'] !== '')) {\n                        $this->wa->sendMessageLocation($to, $this->inputs['userlong'], $this->inputs['userlat'], $this->inputs['locationname'], null);\n                    }\n                } else {\n                    exit(json_encode([\n                        'success'  => false,\n                        'errormsg' => 'A blank number was provided!',\n                        'messages' => $this->messages,\n                    ]));\n                }\n            }\n\n            exit(json_encode([\n                'success'  => true,\n                'data'     => 'Message Sent!',\n                'messages' => $this->messages,\n            ]));\n        }\n        exit(json_encode([\n            'success'  => false,\n            'errormsg' => 'Provided numbers to send message to were not in valid format.',\n        ]));\n    }", "label": 2}
{"code": "function create(objectName) {\n\n        // for resources we need to load them the first time they are referenced\n        if (objectName === 'resources' && this.internalObjects[objectName] === true) {\n            this.internalObjects[objectName] = this.loadResources();\n        }\n\n        // for reactors we need to load them the first time they are referenced\n        else if (objectName === 'reactors' && this.internalObjects[objectName] === true) {\n            this.internalObjects[objectName] = this.loadReactors();\n        }\n\n        // for reactors we need to load them the first time they are referenced\n        else if (objectName === 'appConfigs' && this.internalObjects[objectName] === true) {\n            this.internalObjects[objectName] = this.loadAppConfigs();\n        }\n\n        // for adapters we need to load them the first time they are referenced\n        else if (objectName === 'adapters' && this.internalObjects[objectName] === true) {\n            this.internalObjects[objectName] = this.loadAdapters();\n        }\n\n        return this.internalObjects[objectName];\n    }", "label": 3}
{"code": "public function setProducts($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\Product::class);\n        $this->products = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response delete(nitro_service client, dnsnsrec resource) throws Exception {\n\t\tdnsnsrec deleteresource = new dnsnsrec();\n\t\tdeleteresource.domain = resource.domain;\n\t\tdeleteresource.nameserver = resource.nameserver;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def ask_update(msg: '')\n      name = 'one_gadget'\n      cmd = OneGadget::Helper.colorize(\"gem update #{name} && gem cleanup #{name}\")\n      OneGadget::Logger.info(msg + \"\\n\" + \"Update with: $ #{cmd}\" + \"\\n\")\n    end", "label": 4}
{"code": "def parse_connect_attrs(conn_attrs)\n      return {} if Mysql2::Client::CONNECT_ATTRS.zero?\n      conn_attrs ||= {}\n      conn_attrs[:program_name] ||= $PROGRAM_NAME\n      conn_attrs.each_with_object({}) do |(key, value), hash|\n        hash[key.to_s] = value.to_s\n      end\n    end", "label": 4}
{"code": "func (o HostNetworkSystem) UpdatePortGroup(ctx context.Context, pgName string, portgrp types.HostPortGroupSpec) error {\n\treq := types.UpdatePortGroup{\n\t\tThis:    o.Reference(),\n\t\tPgName:  pgName,\n\t\tPortgrp: portgrp,\n\t}\n\n\t_, err := methods.UpdatePortGroup(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function parser (inputs, output, plugins, cb) {\n  var data = {\n    charset: 'UTF-8',\n    headers: DEFAULT_HEADERS,\n    translations: {\n      context: {}\n    }\n  }\n\n  var defaultContext = data.translations.context\n\n  var headers = data.headers\n  headers['plural-forms'] = headers['plural-forms'] || DEFAULT_HEADERS['plural-forms']\n  headers['content-type'] = headers['content-type'] || DEFAULT_HEADERS['content-type']\n\n  var nplurals = /nplurals ?= ?(\\d)/.exec(headers['plural-forms'])[1]\n\n  inputs\n    .forEach(function (file) {\n      var resolvedFilePath = path.join(process.cwd(), file)\n      var src = fs.readFileSync(resolvedFilePath, 'utf8')\n\n      try {\n        var ast = babelParser.parse(src, {\n          sourceType: 'module',\n          plugins: ['jsx'].concat(plugins)\n        })\n      } catch (e) {\n        console.error(`SyntaxError in ${file} (line: ${e.loc.line}, column: ${e.loc.column})`)\n        process.exit(1)\n      }\n\n      walk.simple(ast.program, {\n        CallExpression: function (node) {\n          if (functionNames.hasOwnProperty(node.callee.name) ||\n            node.callee.property && functionNames.hasOwnProperty(node.callee.property.name)) {\n            var functionName = functionNames[node.callee.name] || functionNames[node.callee.property.name]\n            var translate = {}\n\n            var args = node.arguments\n            for (var i = 0, l = args.length; i < l; i++) {\n              var name = functionName[i]\n\n              if (name && name !== 'count' && name !== 'domain') {\n                var arg = args[i]\n                var value = arg.value\n\n                if (value) {\n                  var line = node.loc.start.line\n                  translate[name] = value\n                  translate['comments'] = {\n                    reference: file + ':' + line\n                  }\n                }\n\n                if (name === 'msgid_plural') {\n                  translate.msgstr = []\n                  for (var p = 0; p < nplurals; p++) {\n                    translate.msgstr[p] = ''\n                  }\n                }\n              }\n            }\n\n            var context = defaultContext\n            var msgctxt = translate.msgctxt\n\n            if (msgctxt) {\n              data.translations[msgctxt] = data.translations[msgctxt] || {}\n              context = data.translations[msgctxt]\n            }\n\n            context[translate.msgid] = translate\n          }\n        }\n      })\n    })\n\n  fs.writeFile(output, gettextParser.po.compile(data), function (err) {\n    if (err) {\n      cb(err)\n    }\n    cb(null)\n  })\n}", "label": 3}
{"code": "func isIPAddrResolvable(fl FieldLevel) bool {\n\n\tif !isIP(fl) {\n\t\treturn false\n\t}\n\n\t_, err := net.ResolveIPAddr(\"ip\", fl.Field().String())\n\n\treturn err == nil\n}", "label": 5}
{"code": "def std(self, bessel_correction=True):\n        \"\"\"Estimates std of underlying data, assuming each datapoint was exactly in the center of its bin.\"\"\"\n        if bessel_correction:\n            n = self.n\n            bc = n / (n - 1)\n        else:\n            bc = 1\n        return np.sqrt(np.average((self.bin_centers - self.mean) ** 2, weights=self.histogram)) * bc", "label": 1}
{"code": "def deep_dup(obj)\n      if obj.class == Hash\n        new_obj = obj.dup\n        new_obj.each do |key, value|\n          new_obj[deep_dup(key)] = deep_dup(value)\n        end\n        new_obj\n      elsif obj.class == Array\n        arr = []\n        obj.each do |item|\n          arr << deep_dup(item)\n        end\n        arr\n      elsif obj.class == String\n        obj.dup\n      else\n        obj\n      end\n    end", "label": 4}
{"code": "func (process *TeleportProcess) ExportFileDescriptors() ([]FileDescriptor, error) {\n\tvar out []FileDescriptor\n\tprocess.Lock()\n\tdefer process.Unlock()\n\tfor _, r := range process.registeredListeners {\n\t\tfile, err := utils.GetListenerFile(r.Listener)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tout = append(out, FileDescriptor{File: file, Type: r.Type, Address: r.Address})\n\t}\n\treturn out, nil\n}", "label": 5}
{"code": "public function setReadOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Datastore\\V1\\ReadOptions::class);\n        $this->read_options = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def collapse_substrings(variant_sequences):\n    \"\"\"\n    Combine shorter sequences which are fully contained in longer sequences.\n\n    Parameters\n    ----------\n    variant_sequences : list\n       List of VariantSequence objects\n\n    Returns a (potentially shorter) list without any contained subsequences.\n    \"\"\"\n    if len(variant_sequences) <= 1:\n        # if we don't have at least two VariantSequences then just\n        # return your input\n        return variant_sequences\n\n    # dictionary mapping VariantSequence objects to lists of reads\n    # they absorb from substring VariantSequences\n    extra_reads_from_substrings = defaultdict(set)\n    result_list = []\n    # sort by longest to shortest total length\n    for short_variant_sequence in sorted(\n            variant_sequences,\n            key=lambda seq: -len(seq)):\n        found_superstring = False\n        for long_variant_sequence in result_list:\n            found_superstring = long_variant_sequence.contains(short_variant_sequence)\n            if found_superstring:\n                extra_reads_from_substrings[long_variant_sequence].update(\n                    short_variant_sequence.reads)\n        if not found_superstring:\n            result_list.append(short_variant_sequence)\n    # add to each VariantSequence the reads it absorbed from dropped substrings\n    # and then return\n    return [\n        variant_sequence.add_reads(\n            extra_reads_from_substrings[variant_sequence])\n        for variant_sequence in result_list\n    ]", "label": 1}
{"code": "public static <T> List<T> toList(Iterable<T> items) {\r\n    List<T> list = new ArrayList<T>();\r\n    addAll(list, items);\r\n    return list;\r\n  }", "label": 0}
{"code": "def images\n      images = @anchors.select { |a| a.object.is_a?(Pic) }\n      images.map { |a| a.object }\n    end", "label": 4}
{"code": "public final void error(Object pObject)\r\n\t{\r\n\t\tgetLogger().log(FQCN, Level.ERROR, pObject, null);\r\n\t}", "label": 0}
{"code": "public static appfwlearningsettings get(nitro_service service, String profilename) throws Exception{\n\t\tappfwlearningsettings obj = new appfwlearningsettings();\n\t\tobj.set_profilename(profilename);\n\t\tappfwlearningsettings response = (appfwlearningsettings) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static appflowpolicy_appflowglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappflowpolicy_appflowglobal_binding obj = new appflowpolicy_appflowglobal_binding();\n\t\tobj.set_name(name);\n\t\tappflowpolicy_appflowglobal_binding response[] = (appflowpolicy_appflowglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def generate_random_id(method)\n      data = File.open(\"/dev/urandom\", \"rb\") do |f|\n        f.read(64)\n      end\n      case method\n      when :base64\n        data = base64(data)\n        data.gsub!(\"+\", '')\n        data.gsub!(\"/\", '')\n        data.gsub!(/==$/, '')\n        return data\n      when :hex\n        return data.unpack('H*')[0]\n      else\n        raise ArgumentError, \"Invalid method #{method.inspect}\"\n      end\n    end", "label": 4}
{"code": "def show\n      user = ::User.from_url_component(params[:id])\n      return redirect_to root_path, alert: \"User '#{params[:id]}' does not exist\" if user.nil?\n      @presenter = Hyrax::UserProfilePresenter.new(user, current_ability)\n    end", "label": 4}
{"code": "def hyperlink=(v, options={})\n      options[:href] = v\n      if hyperlink.is_a?(Hyperlink)\n        options.each do |o|\n          hyperlink.send(\"#{o[0]}=\", o[1]) if hyperlink.respond_to? \"#{o[0]}=\"\n        end\n      else\n        @hyperlink = Hyperlink.new(self, options)\n      end\n      hyperlink\n    end", "label": 4}
{"code": "func (t *TextBar) Resize() {\n\tt.initialize()\n\tt.layout()\n\n\tt.left.Resize()\n\tt.center.Resize()\n\tt.right.Resize()\n\n\tt.PostEventWidgetResize(t)\n}", "label": 5}
{"code": "def get_schemaloc_string(self, ns_uris=None, sort=False, delim=\"\\n\"):\n        \"\"\"Constructs and returns a schemalocation attribute.  If no\n        namespaces in this set have any schema locations defined, returns\n        an empty string.\n\n        Args:\n            ns_uris (iterable): The namespaces to include in the constructed\n                attribute value.  If None, all are included.\n            sort (bool): Whether the sort the namespace URIs.\n            delim (str): The delimiter to use between namespace/schemaloc\n                *pairs*.\n\n        Returns:\n            str: A schemalocation attribute in the format:\n                ``xsi:schemaLocation=\"nsuri schemaloc<delim>nsuri2 schemaloc2<delim>...\"``\n\n        \"\"\"\n        if not ns_uris:\n            ns_uris = six.iterkeys(self.__ns_uri_map)\n\n        if sort:\n            ns_uris = sorted(ns_uris)\n\n        schemalocs = []\n\n        for ns_uri in ns_uris:\n            ni = self.__lookup_uri(ns_uri)\n\n            if ni.schema_location:\n                schemalocs.append(\"{0.uri} {0.schema_location}\".format(ni))\n\n        if not schemalocs:\n            return \"\"\n\n        return 'xsi:schemaLocation=\"{0}\"'.format(delim.join(schemalocs))", "label": 1}
{"code": "public function prependSign(callable $middleware, $name = null)\n    {\n        $this->add(self::SIGN, $name, $middleware, true);\n    }", "label": 2}
{"code": "function startAppServer(fn) {\n  if (!checkingAppServerPort) {\n    server = fork(appServer.file, [], appServer.options);\n    server.on('exit', code => {\n      checkingAppServerPort = false;\n      server.removeAllListeners();\n      server = null;\n      fn(Error('failed to start server'));\n    });\n\n    checkingAppServerPort = true;\n    waitForPortOpen(appServer.port, fn);\n  }\n}", "label": 3}
{"code": "func (v VirtualMachine) WaitForPowerState(ctx context.Context, state types.VirtualMachinePowerState) error {\n\tp := property.DefaultCollector(v.c)\n\terr := property.Wait(ctx, p, v.Reference(), []string{PropRuntimePowerState}, func(pc []types.PropertyChange) bool {\n\t\tfor _, c := range pc {\n\t\t\tif c.Name != PropRuntimePowerState {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif c.Val == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tps := c.Val.(types.VirtualMachinePowerState)\n\t\t\tif ps == state {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\n\treturn err\n}", "label": 5}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getTopic($options + [\n            'topic' => $this->name\n        ]);\n    }", "label": 2}
{"code": "public function setParameters($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->parameters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (a *LocalKeyAgent) DeleteKeys() error {\n\t// Remove keys from the filesystem.\n\terr := a.keyStore.DeleteKeys()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// Remove all keys from the Teleport and system agents.\n\terr = a.UnloadKeys()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function checkPageViewsCriteria() {\n\n    // don't bother if another box is currently open\n    if( isAnyBoxVisible() ) {\n        return;\n    }\n\n    boxes.forEach(function(box) {\n        if( ! box.mayAutoShow() ) {\n            return;\n        }\n\n        if( box.config.trigger.method === 'pageviews' && pageViews >= box.config.trigger.value ) {\n            box.trigger();\n        }\n    });\n}", "label": 3}
{"code": "public function hasPermissionLike($match)\n    {\n        if ($this->isAdmin()) {\n            return true;\n        }\n\n        if (is_null($this->permissions)) {\n            $this->permissions = $this->getPermissions();\n        }\n\n        foreach ($this->permissions as $permission) {\n            if (substr($permission, -strlen($match)) === $match) {\n                return true;\n            }\n        }\n\n        return false;\n    }", "label": 2}
{"code": "def json_response(response_code, data, options = {})\n      options = { pretty: true }.merge(options)\n      do_pretty_json = !!options.delete(:pretty) # make sure we have a proper Boolean.\n      json = FFI_Yajl::Encoder.encode(data, pretty: do_pretty_json)\n      already_json_response(response_code, json, options)\n    end", "label": 4}
{"code": "func (i *Handle) parseDestination(msg []byte) (*Destination, error) {\n\tvar dst *Destination\n\n\t//Remove General header for this message\n\thdr := deserializeGenlMsg(msg)\n\tNetLinkAttrs, err := nl.ParseRouteAttr(msg[hdr.Len():])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(NetLinkAttrs) == 0 {\n\t\treturn nil, fmt.Errorf(\"error no valid netlink message found while parsing destination record\")\n\t}\n\n\t//Now Parse and get IPVS related attributes messages packed in this message.\n\tipvsAttrs, err := nl.ParseRouteAttr(NetLinkAttrs[0].Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//Assemble netlink attributes and create a Destination record\n\tdst, err = assembleDestination(ipvsAttrs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn dst, nil\n}", "label": 5}
{"code": "func (f *Fpdf) GetTextSpotColor() (name string, c, m, y, k byte) {\n\treturn f.returnSpotColor(f.color.text)\n}", "label": 5}
{"code": "func PgAmprocByAmprocfamilyAmproclefttypeAmprocrighttypeAmprocnum(db XODB, amprocfamily pgtypes.Oid, amproclefttype pgtypes.Oid, amprocrighttype pgtypes.Oid, amprocnum int16) (*PgAmproc, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, amprocfamily, amproclefttype, amprocrighttype, amprocnum, amproc ` +\n\t\t`FROM pg_catalog.pg_amproc ` +\n\t\t`WHERE amprocfamily = $1 AND amproclefttype = $2 AND amprocrighttype = $3 AND amprocnum = $4`\n\n\t// run query\n\tXOLog(sqlstr, amprocfamily, amproclefttype, amprocrighttype, amprocnum)\n\tpa := PgAmproc{}\n\n\terr = db.QueryRow(sqlstr, amprocfamily, amproclefttype, amprocrighttype, amprocnum).Scan(&pa.Tableoid, &pa.Cmax, &pa.Xmax, &pa.Cmin, &pa.Xmin, &pa.Oid, &pa.Ctid, &pa.Amprocfamily, &pa.Amproclefttype, &pa.Amprocrighttype, &pa.Amprocnum, &pa.Amproc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "public function setValueRangeFilter($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\ValueRange::class);\n        $this->writeOneof(15, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function() {\n\t\t\tcanReflect.onValue( observation, updater,\"notify\");\n\t\t\tif (observation.hasOwnProperty(\"_value\")) {// can-observation 4.1+\n\t\t\t\tcompute.value = observation._value;\n\t\t\t} else {// can-observation < 4.1\n\t\t\t\tcompute.value = observation.value;\n\t\t\t}\n\t\t}", "label": 3}
{"code": "func gcTreeStore(ts *treestore.Store) error {\n\t// Take an exclusive lock to block other pods being created.\n\t// This is needed to avoid races between the below steps (getting the\n\t// list of referenced treeStoreIDs, getting the list of treeStoreIDs\n\t// from the store, removal of unreferenced treeStoreIDs) and new\n\t// pods/treeStores being created/referenced\n\tkeyLock, err := lock.ExclusiveKeyLock(lockDir(), common.PrepareLock)\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"cannot get exclusive prepare lock\"), err)\n\t}\n\tdefer keyLock.Close()\n\treferencedTreeStoreIDs, err := getReferencedTreeStoreIDs()\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"cannot get referenced treestoreIDs\"), err)\n\t}\n\ttreeStoreIDs, err := ts.GetIDs()\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"cannot get treestoreIDs from the store\"), err)\n\t}\n\tfor _, treeStoreID := range treeStoreIDs {\n\t\tif _, ok := referencedTreeStoreIDs[treeStoreID]; !ok {\n\t\t\tif err := ts.Remove(treeStoreID); err != nil {\n\t\t\t\tstderr.PrintE(fmt.Sprintf(\"error removing treestore %q\", treeStoreID), err)\n\t\t\t} else {\n\t\t\t\tstderr.Printf(\"removed treestore %q\", treeStoreID)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function openConnection() {\n    expect(arguments).to.have.length(\n      0,\n      'Invalid arguments length when opening a connection in a MongoAdapter ' +\n      '(it has to be passed no arguments)'\n    );\n\n    return new Promise(function (resolve, reject) {\n      if (_databaseIsLocked) {\n        _databaseRequestQueue.push(function () {\n          openConnection().then(resolve).catch(reject);\n        });\n      } else if (_database) {\n        resolve();\n      } else {\n        _databaseIsLocked = true;\n\n        MongoClient\n          .connect(connectionUrl, connectionOptions)\n          .then(function (database) {\n            _database = database;\n            _databaseIsLocked = false;\n            resolve();\n            _processDatabaseRequestQueue();\n          })\n          .catch(function (error) {\n            _databaseIsLocked = false;\n            reject(error);\n            _processDatabaseRequestQueue();\n          });\n      }\n    });\n  }", "label": 3}
{"code": "func NewLinear(cfg LinearConfig) (*Linear, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tclosedChan := make(chan time.Time)\n\tclose(closedChan)\n\treturn &Linear{LinearConfig: cfg, closedChan: closedChan}, nil\n}", "label": 5}
{"code": "def read_class\n      klass_name = read_string(cache: false)\n      result = safe_const_get(klass_name)\n      unless result.class == Class\n        raise ArgumentError, \"#{klass_name} does not refer to a Class\"\n      end\n      @object_cache << result\n      result\n    end", "label": 4}
{"code": "def new_search(*types, &block)\n      types.flatten!\n      search = Search::StandardSearch.new(\n        connection,\n        setup_for_types(types),\n        Query::StandardQuery.new(types),\n        @config\n      )\n      search.build(&block) if block\n      search\n    end", "label": 4}
{"code": "def current_page\n      offset_without_padding = offset_value\n      offset_without_padding -= @_padding if defined?(@_padding) && @_padding\n      offset_without_padding = 0 if offset_without_padding < 0\n\n      (offset_without_padding / limit_value) + 1\n    rescue ZeroDivisionError\n      raise ZeroPerPageOperation, \"Current page was incalculable. Perhaps you called .per(0)?\"\n    end", "label": 4}
{"code": "def try_friends(self, others):\n        ''' Look for random agents around me and try to befriend them'''\n        befriended = False\n        k = int(10*self['openness'])\n        shuffle(others)\n        for friend in islice(others, k):  # random.choice >= 3.7\n            if friend == self:\n                continue\n            if friend.befriend(self):\n                self.befriend(friend, force=True)\n                self.debug('Hooray! new friend: {}'.format(friend.id))\n                befriended = True\n            else:\n                self.debug('{} does not want to be friends'.format(friend.id))\n        return befriended", "label": 1}
{"code": "public static nsconfig get(nitro_service service) throws Exception{\n\t\tnsconfig obj = new nsconfig();\n\t\tnsconfig[] response = (nsconfig[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def allele_counts_dataframe(variant_and_allele_reads_generator):\n    \"\"\"\n    Creates a DataFrame containing number of reads supporting the\n    ref vs. alt alleles for each variant.\n    \"\"\"\n    df_builder = DataFrameBuilder(\n        AlleleCount,\n        extra_column_fns={\n            \"gene\": lambda variant, _: \";\".join(variant.gene_names),\n        })\n    for variant, allele_reads in variant_and_allele_reads_generator:\n        counts = count_alleles_at_variant_locus(variant, allele_reads)\n        df_builder.add(variant, counts)\n    return df_builder.to_dataframe()", "label": 1}
{"code": "def get_plaintext(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a config as plaintext.\n\n        :param id: Config ID as an int.\n        :rtype: string\n        \"\"\"\n        return self.service.get_id(self.base, id, params={'format': 'text'}).text", "label": 1}
{"code": "function(obj, activationData, context) {\n            var that = this;\n            var dialogContext = contexts[context || 'default'];\n\n            return system.defer(function(dfd) {\n                ensureDialogInstance(obj).then(function(instance) {\n                    var dialogActivator = activator.create();\n\n                    dialogActivator.activateItem(instance, activationData).then(function (success) {\n                        if (success) {\n                            var theDialog = instance.__dialog__ = {\n                                owner: instance,\n                                context: dialogContext,\n                                activator: dialogActivator,\n                                close: function () {\n                                    var args = arguments;\n                                    dialogActivator.deactivateItem(instance, true).then(function (closeSuccess) {\n                                        if (closeSuccess) {\n                                            dialogCount--;\n                                            dialogContext.removeHost(theDialog);\n                                            delete instance.__dialog__;\n\n                                            if (args.length === 0) {\n                                                dfd.resolve();\n                                            } else if (args.length === 1) {\n                                                dfd.resolve(args[0]);\n                                            } else {\n                                                dfd.resolve.apply(dfd, args);\n                                            }\n                                        }\n                                    });\n                                }\n                            };\n\n                            theDialog.settings = that.createCompositionSettings(instance, dialogContext);\n                            dialogContext.addHost(theDialog);\n\n                            dialogCount++;\n                            composition.compose(theDialog.host, theDialog.settings);\n                        } else {\n                            dfd.resolve(false);\n                        }\n                    });\n                });\n            }).promise();\n        }", "label": 3}
{"code": "def signatures_at filename, line, column\n      position = Position.new(line, column)\n      cursor = Source::Cursor.new(checkout(filename), position)\n      api_map.clip(cursor).signify\n    end", "label": 4}
{"code": "function(callback, context)\n  {\n    var callbackContext = context || this;\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var item = this[ i ];\n\n      callback.call( callbackContext, item, i );\n\n      if ( this[ i ] !== item )\n      {\n        i--;\n      }\n    }\n\n    return this;\n  }", "label": 3}
{"code": "def page_request(path, params={})\n      if params[PARAM_PER_PAGE] == NOT_FOUND\n        params[PARAM_PER_PAGE] = default_page_size\n      end\n      if params[PARAM_PAGE] && params[PARAM_PAGE] == NOT_FOUND\n        params[PARAM_PAGE] = default_page\n      end\n\n      current_api.get_request(path, ParamsHash.new(params))\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, lbsipparameters resource) throws Exception {\n\t\tlbsipparameters updateresource = new lbsipparameters();\n\t\tupdateresource.rnatsrcport = resource.rnatsrcport;\n\t\tupdateresource.rnatdstport = resource.rnatdstport;\n\t\tupdateresource.retrydur = resource.retrydur;\n\t\tupdateresource.addrportvip = resource.addrportvip;\n\t\tupdateresource.sip503ratethreshold = resource.sip503ratethreshold;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def register(self, name, path, description, final_words=None):\n        \"\"\"\n        Registers a new recipe in the context of the current plugin.\n\n        :param name: Name of the recipe\n        :param path: Absolute path of the recipe folder\n        :param description: A meaningful description of the recipe\n        :param final_words: A string, which gets printed after the recipe was build.\n        \"\"\"\n        return self.__app.recipes.register(name, path, self._plugin, description, final_words)", "label": 1}
{"code": "function isWritable(dir) {\n\tdebug('checking if ' + dir + ' is writable');\n\ttry {\n\t\tif (!fs.existsSync(dir)) {\n\t\t\tdebug(' - it does not exist yet, attempting to create it');\n\t\t\tfs.mkdirSync(dir);\n\t\t}\n\t\tif (fs.accessSync) {\n\t\t\tfs.accessSync(dir, fs.W_OK);\n\t\t} else {\n\t\t\tdebug(' - fs.accessSync is not available, falling back to manual write detection');\n\t\t\tfs.writeFileSync(path.join(dir, '.foo'), 'foo');\n\t\t\tassert.equal(fs.readFileSync(path.join(dir, '.foo'), 'UTF-8'), 'foo');\n\t\t\tfs.unlinkSync(path.join(dir, '.foo'));\n\t\t}\n\t\tdebug(' - yes, it is writable');\n\t\treturn true;\n\t} catch (exc) {\n\t\tdebug(' - no, it is not writable: ', exc);\n\t\treturn false;\n\t}\n}", "label": 3}
{"code": "def _unpack_case(self, case):\n        \"\"\" Returns the contents of the case to be used in the OPF.\n        \"\"\"\n        base_mva = case.base_mva\n        b = case.connected_buses\n        l = case.online_branches\n        g = case.online_generators\n        nb = len(b)\n        nl = len(l)\n        ng = len(g)\n\n        return b, l, g, nb, nl, ng, base_mva", "label": 1}
{"code": "public static base_response update(nitro_service client, snmpgroup resource) throws Exception {\n\t\tsnmpgroup updateresource = new snmpgroup();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.securitylevel = resource.securitylevel;\n\t\tupdateresource.readviewname = resource.readviewname;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public static csvserver_rewritepolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tcsvserver_rewritepolicy_binding obj = new csvserver_rewritepolicy_binding();\n\t\tobj.set_name(name);\n\t\tcsvserver_rewritepolicy_binding response[] = (csvserver_rewritepolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def join(*paths):\n\tr\"\"\"\n\tWrapper around os.path.join that works with Windows drive letters.\n\n\t>>> join('d:\\\\foo', '\\\\bar')\n\t'd:\\\\bar'\n\t\"\"\"\n\tpaths_with_drives = map(os.path.splitdrive, paths)\n\tdrives, paths = zip(*paths_with_drives)\n\t# the drive we care about is the last one in the list\n\tdrive = next(filter(None, reversed(drives)), '')\n\treturn os.path.join(drive, os.path.join(*paths))", "label": 1}
{"code": "public ValueContainer[] getKeyValues(ClassDescriptor cld, Object objectOrProxy, boolean convertToSql) throws PersistenceBrokerException\r\n    {\r\n        IndirectionHandler handler = ProxyHelper.getIndirectionHandler(objectOrProxy);\r\n\r\n        if(handler != null)\r\n        {\r\n            return getKeyValues(cld, handler.getIdentity(), convertToSql);  //BRJ: convert Identity\r\n        }\r\n        else\r\n        {\r\n            ClassDescriptor realCld = getRealClassDescriptor(cld, objectOrProxy);\r\n            return getValuesForObject(realCld.getPkFields(), objectOrProxy, convertToSql);\r\n        }\r\n    }", "label": 0}
{"code": "public static dnsnsrec[] get(nitro_service service, dnsnsrec_args args) throws Exception{\n\t\tdnsnsrec obj = new dnsnsrec();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tdnsnsrec[] response = (dnsnsrec[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private Filter getFilter(String layerFilter, String[] featureIds) throws GeomajasException {\n\t\tFilter filter = null;\n\t\tif (null != layerFilter) {\n\t\t\tfilter = filterService.parseFilter(layerFilter);\n\t\t}\n\t\tif (null != featureIds) {\n\t\t\tFilter fidFilter = filterService.createFidFilter(featureIds);\n\t\t\tif (null == filter) {\n\t\t\t\tfilter = fidFilter;\n\t\t\t} else {\n\t\t\t\tfilter = filterService.createAndFilter(filter, fidFilter);\n\t\t\t}\n\t\t}\n\t\treturn filter;\n\t}", "label": 0}
{"code": "private function pluckArray(array $keys, &$arr)\n    {\n        $values = [];\n\n        foreach ($keys as $key) {\n            if (array_key_exists($key, $arr)) {\n                $values[$key] = $this->pluck($key, $arr, false);\n            }\n        }\n\n        return $values;\n    }", "label": 2}
{"code": "function find(kernelName) {\n  return jp.dataDirs({ withSysPrefix: true }).then(dirs => {\n\n    const kernelInfos = dirs.map(dir => ({\n      name: kernelName,\n      resourceDir: path.join(dir, 'kernels', kernelName),\n    }))\n\n    return extractKernelResources(kernelInfos);\n  }).then(kernelResource => kernelResource[kernelName])\n}", "label": 3}
{"code": "public synchronized Object next() throws NoSuchElementException\r\n    {\r\n        try\r\n        {\r\n            if (!isHasCalledCheck())\r\n            {\r\n                hasNext();\r\n            }\r\n            setHasCalledCheck(false);\r\n            if (getHasNext())\r\n            {\r\n                Object obj = getObjectFromResultSet();\r\n                m_current_row++;\r\n\r\n                // Invoke events on PersistenceBrokerAware instances and listeners\r\n                // set target object\r\n                if (!disableLifeCycleEvents)\r\n                {\r\n                    getAfterLookupEvent().setTarget(obj);\r\n                    getBroker().fireBrokerEvent(getAfterLookupEvent());\r\n                    getAfterLookupEvent().setTarget(null);\r\n                }    \r\n                return obj;\r\n            }\r\n            else\r\n            {\r\n                throw new NoSuchElementException(\"inner hasNext was false\");\r\n            }\r\n        }\r\n        catch (ResourceClosedException ex)\r\n        {\r\n            autoReleaseDbResources();\r\n            throw ex;\r\n        }\r\n        catch (NoSuchElementException ex)\r\n        {\r\n            autoReleaseDbResources();\r\n            logger.error(\"Error while iterate ResultSet for query \" + m_queryObject, ex);\r\n            throw new NoSuchElementException(\"Could not obtain next object: \" + ex.getMessage());\r\n        }\r\n    }", "label": 0}
{"code": "def all_subset_operators\n      @entry.xpath('./*/cda:excerpt', HQMF2::Document::NAMESPACES).collect do |subset_operator|\n        SubsetOperator.new(subset_operator)\n      end\n    end", "label": 4}
{"code": "public function add($node, $weight = null)\n    {\n        // In case of collisions in the hashes of the nodes, the node added\n        // last wins, thus the order in which nodes are added is significant.\n        $this->nodes[] = array(\n            'object' => $node,\n            'weight' => (int) $weight ?: $this::DEFAULT_WEIGHT,\n        );\n\n        $this->reset();\n    }", "label": 2}
{"code": "function(el, properties) {\n    var duration = 0;\n\n    for (var i = 0; i < properties.length; i++) {\n      // Get raw CSS value\n      var value = el.css(properties[i]);\n      if (!value) continue;\n\n      // Multiple transitions--pick the longest\n      if (value.indexOf(\",\") !== -1) {\n        var values = value.split(\",\");\n        var durations = (function(){\n          var results = [];\n          for (var i = 0; i < values.length; i++) {\n            var duration = parseTime(values[i]);\n            results.push(duration);\n          }\n          return results;\n        })();\n\n        duration = Math.max.apply(Math, durations);\n      }\n\n      // Single transition\n      else {\n        duration = parseTime(value);\n      }\n\n      // Accept first vaue\n      break;\n    }\n\n    return duration;\n  }", "label": 3}
{"code": "def _load_pil_image(self, filename):\n        \"\"\"\n        Load image using PIL.\n        \"\"\"\n        self._channel_data = []\n        self._original_channel_data = []\n\n        im = Image.open(filename)\n        self._image = ImageOps.grayscale(im)\n        im.load()\n\n        file_data = np.asarray(im, float)\n        file_data = file_data / file_data.max()\n\n        # if the image has more than one channel, load them\n        if( len(file_data.shape) == 3 ):\n            num_channels = file_data.shape[2]\n            for i in range(num_channels):\n                self._channel_data.append( file_data[:, :, i])\n                self._original_channel_data.append( file_data[:, :, i] )", "label": 1}
{"code": "public static double TruncatedPower(double value, double degree) {\r\n        double x = Math.pow(value, degree);\r\n        return (x > 0) ? x : 0.0;\r\n    }", "label": 0}
{"code": "function readFiles(\n  glob,\n  { parsers = {}, encoding = 'utf-8', globOpts = {} } = {}\n) {\n  return getFiles(glob, globOpts).then(paths => {\n    return Promise.all(\n      paths.map(filepath => {\n        return readFile(filepath, encoding).then(fileData => {\n          const parser = matchParser(filepath, parsers);\n          fileData = parser(fileData, filepath);\n          if (typeof fileData === 'string') {\n            fileData = { contents: fileData };\n          }\n          return Object.assign(fileData, { path: filepath });\n        });\n      })\n    );\n  });\n}", "label": 3}
{"code": "public static base_response add(nitro_service client, vpnurl resource) throws Exception {\n\t\tvpnurl addresource = new vpnurl();\n\t\taddresource.urlname = resource.urlname;\n\t\taddresource.linkname = resource.linkname;\n\t\taddresource.actualurl = resource.actualurl;\n\t\taddresource.clientlessaccess = resource.clientlessaccess;\n\t\taddresource.comment = resource.comment;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public function breakpointsWithWaitToken(array $options = [])\n    {\n        $ret = $this->connection->listBreakpoints(['debuggeeId' => $this->id] + $options);\n\n        if (array_key_exists('breakpoints', $ret)) {\n            $ret['breakpoints'] = array_map(function ($breakpointData) {\n                return new Breakpoint($breakpointData);\n            }, $ret['breakpoints']);\n        } else {\n            $ret['breakpoints'] = [];\n        }\n        return $ret;\n    }", "label": 2}
{"code": "function (numeral, quality) {\n  // Roman numeral representing chord\n  this.numeral = numeral;\n\n  // Chord quality: M, m, x, o, \u00f8, s\n  this.quality = quality;\n  if (!_.contains(['M', 'm', 'x', 'o', '\u00f8', 's'], quality)) {\n    throw new Error('Invalid chord quality');\n  }\n\n  // The number of half-steps between the key and the chord\n  // e.g. I => 0, bIV => 6\n  this.interval = getHalfSteps(numeral);\n\n  this.toString = function () {\n    return this.numeral + this.quality;\n  };\n}", "label": 3}
{"code": "func (m *MockIndex) Anon(arg0 string) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"Anon\", arg0)\n}", "label": 5}
{"code": "public static function convertPostToGet(RequestInterface $request)\n    {\n        if ($request->getMethod() !== 'POST') {\n            throw new \\InvalidArgumentException('Expected a POST request but '\n                . 'received a ' . $request->getMethod() . ' request.');\n        }\n\n        $sr = $request->withMethod('GET')\n            ->withBody(Psr7\\stream_for(''))\n            ->withoutHeader('Content-Type')\n            ->withoutHeader('Content-Length');\n\n        // Move POST fields to the query if they are present\n        if ($request->getHeaderLine('Content-Type') === 'application/x-www-form-urlencoded') {\n            $body = (string) $request->getBody();\n            $sr = $sr->withUri($sr->getUri()->withQuery($body));\n        }\n\n        return $sr;\n    }", "label": 2}
{"code": "function brush() {\n      var actives = dimensions.filter(function(p) { return !y[p].brush.empty(); }),\n          extents = actives.map(function(p) { return y[p].brush.extent(); }),\n          selectedPaths = foregroundPaths.filter(function(d) {\n            return actives.every(function(p, i) {\n              return extents[i][0] <= d[p] && d[p] <= extents[i][1];\n            });\n          });\n      foregroundPaths.style('display', 'none');\n      selectedPaths.style('display', null);\n      model.selectedData = selectedPaths.data();\n    }", "label": 3}
{"code": "public function setDomain($domain)\n    {\n        if (mb_strpos($domain, ':') !== false) {\n            throw new InvalidArgumentException(sprintf('Cookie domain \"%s\" should not contain a port', $domain));\n        }\n\n        $this->cookie['domain'] = $domain;\n    }", "label": 2}
{"code": "def write_json_string(str)\n      @context.write(trans)\n      trans.write(@@kJSONStringDelimiter)\n      str.split('').each do |ch|\n        write_json_char(ch)\n      end\n      trans.write(@@kJSONStringDelimiter)\n    end", "label": 4}
{"code": "def init_model(self, model, value):\n        \"\"\"Init model with field.\n\n        :param DomainModel model:\n        :param object value:\n        \"\"\"\n        if value is None and self.default is not None:\n            value = self.default() if callable(self.default) else self.default\n\n        self.set_value(model, value)", "label": 1}
{"code": "def _update_report_item(self, **update_props):\n        \"\"\" Update the text for each element at the configured path if attribute matches \"\"\"\n\n        tree_to_update = update_props['tree_to_update']\n        prop = update_props['prop']\n        values = wrap_value(update_props['values'])\n        xroot = self._get_xroot_for(prop)\n\n        attr_key = 'type'\n        attr_val = u''\n\n        if prop == 'attribute_accuracy':\n            attr_val = 'DQQuanAttAcc'\n        elif prop == 'dataset_completeness':\n            attr_val = 'DQCompOm'\n\n        # Clear (make empty) all elements of the appropriate type\n        for elem in get_elements(tree_to_update, xroot):\n            if get_element_attributes(elem).get(attr_key) == attr_val:\n                clear_element(elem)\n\n        # Remove all empty elements, including those previously cleared\n        remove_empty_element(tree_to_update, xroot)\n\n        # Insert elements with correct attributes for each new value\n\n        attrs = {attr_key: attr_val}\n        updated = []\n\n        for idx, value in enumerate(values):\n            elem = insert_element(tree_to_update, idx, xroot, **attrs)\n            updated.append(insert_element(elem, idx, 'measDesc', value))\n\n        return updated", "label": 1}
{"code": "public function setPerson($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1\\PartOfSpeech_Person::class);\n        $this->person = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *Store) backupDB() error {\n\tif os.Geteuid() != 0 {\n\t\treturn ErrDBUpdateNeedsRoot\n\t}\n\tbackupsDir := filepath.Join(s.dir, \"db-backups\")\n\treturn backup.CreateBackup(s.dbDir(), backupsDir, backupsNumber)\n}", "label": 5}
{"code": "def prepare_key(action, options = {})\n      (\n        options[:key] ||\n        self.activity_key ||\n        ((self.class.name.underscore.gsub('/', '_') + \".\" + action.to_s) if action)\n      ).try(:to_s)\n    end", "label": 4}
{"code": "func (c *Client) RegisterNewAuthServer(token string) error {\n\t_, err := c.PostJSON(c.Endpoint(\"tokens\", \"register\", \"auth\"), registerNewAuthServerReq{\n\t\tToken: token,\n\t})\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def visit_or_create(started_at: nil)\n      ahoy.track_visit(started_at: started_at) if !visit && Ahoy.server_side_visits\n      visit\n    end", "label": 4}
{"code": "func (t *terminal) SetWinSize(params rsession.TerminalParams) error {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif t.pty == nil {\n\t\treturn trace.NotFound(\"no pty\")\n\t}\n\tif err := term.SetWinsize(t.pty.Fd(), params.Winsize()); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tt.params = params\n\treturn nil\n}", "label": 5}
{"code": "public void check(CollectionDescriptorDef collDef, String checkLevel) throws ConstraintException\r\n    {\r\n        ensureElementClassRef(collDef, checkLevel);\r\n        checkInheritedForeignkey(collDef, checkLevel);\r\n        ensureCollectionClass(collDef, checkLevel);\r\n        checkProxyPrefetchingLimit(collDef, checkLevel);\r\n        checkOrderby(collDef, checkLevel);\r\n        checkQueryCustomizer(collDef, checkLevel);\r\n    }", "label": 0}
{"code": "private void ensureElementClassRef(CollectionDescriptorDef collDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        String arrayElementClassName = collDef.getProperty(PropertyHelper.OJB_PROPERTY_ARRAY_ELEMENT_CLASS_REF);\r\n\r\n        if (!collDef.hasProperty(PropertyHelper.OJB_PROPERTY_ELEMENT_CLASS_REF))\r\n        {\r\n            if (arrayElementClassName != null)\r\n            {\r\n                // we use the array element type\r\n                collDef.setProperty(PropertyHelper.OJB_PROPERTY_ELEMENT_CLASS_REF, arrayElementClassName);\r\n            }\r\n            else\r\n            {\r\n                throw new ConstraintException(\"Collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" does not specify its element class\");\r\n            }\r\n        }\r\n\r\n        // now checking the element type\r\n        ModelDef           model            = (ModelDef)collDef.getOwner().getOwner();\r\n        String             elementClassName = collDef.getProperty(PropertyHelper.OJB_PROPERTY_ELEMENT_CLASS_REF);\r\n        ClassDescriptorDef elementClassDef  = model.getClass(elementClassName);\r\n\r\n        if (elementClassDef == null)\r\n        {\r\n            throw new ConstraintException(\"Collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" references an unknown class \"+elementClassName);\r\n        }\r\n        if (!elementClassDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_OJB_PERSISTENT, false))\r\n        {\r\n            throw new ConstraintException(\"The element class \"+elementClassName+\" of the collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" is not persistent\");\r\n        }\r\n        if (CHECKLEVEL_STRICT.equals(checkLevel) && (arrayElementClassName != null))\r\n        {\r\n            // specified element class must be a subtype of the element type\r\n            try\r\n            {\r\n                InheritanceHelper helper = new InheritanceHelper();\r\n\r\n                if (!helper.isSameOrSubTypeOf(elementClassDef, arrayElementClassName, true))\r\n                {\r\n                    throw new ConstraintException(\"The element class \"+elementClassName+\" of the collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" is not the same or a subtype of the array base type \"+arrayElementClassName);\r\n                }\r\n            }\r\n            catch (ClassNotFoundException ex)\r\n            {\r\n                throw new ConstraintException(\"Could not find the class \"+ex.getMessage()+\" on the classpath while checking the collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName());\r\n            }\r\n        }\r\n        // we're adjusting the property to use the classloader-compatible form\r\n        collDef.setProperty(PropertyHelper.OJB_PROPERTY_ELEMENT_CLASS_REF, elementClassDef.getName());\r\n    }", "label": 0}
{"code": "public List<String> deviceTypes() {\n        Integer count = json().size(DEVICE_FAMILIES);\n        List<String> deviceTypes = new ArrayList<String>(count);\n        for(int i = 0 ; i < count ; i++) {\n            String familyNumber = json().stringValue(DEVICE_FAMILIES, i);\n            if(familyNumber.equals(\"1\")) deviceTypes.add(\"iPhone\");\n            if(familyNumber.equals(\"2\")) deviceTypes.add(\"iPad\");\n        }\n        return deviceTypes;\n    }", "label": 0}
{"code": "public static function cryptoKeyName($project, $location, $keyRing, $cryptoKey)\n    {\n        return self::getCryptoKeyNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'key_ring' => $keyRing,\n            'crypto_key' => $cryptoKey,\n        ]);\n    }", "label": 2}
{"code": "func hasValue(fl FieldLevel) bool {\n\n\tfield := fl.Field()\n\n\tswitch field.Kind() {\n\tcase reflect.Slice, reflect.Map, reflect.Ptr, reflect.Interface, reflect.Chan, reflect.Func:\n\t\treturn !field.IsNil()\n\tdefault:\n\n\t\tif fl.(*validate).fldIsPointer && field.Interface() != nil {\n\t\t\treturn true\n\t\t}\n\n\t\treturn field.IsValid() && field.Interface() != reflect.Zero(field.Type()).Interface()\n\t}\n}", "label": 5}
{"code": "def noise_uniform(self, lower_bound, upper_bound):\n        \"\"\"Create a uniform noise variable\"\"\"\n        assert upper_bound > lower_bound\n        nu = self.sym.sym('nu_{:d}'.format(len(self.scope['nu'])))\n        self.scope['nu'].append(nu)\n        return lower_bound + nu*(upper_bound - lower_bound)", "label": 1}
{"code": "protected function addNodeSupport(DocumentAST $document): DocumentAST\n    {\n        $hasTypeImplementingNode = $document\n            ->objectTypeDefinitions()\n            ->contains(function (ObjectTypeDefinitionNode $objectType): bool {\n                return (new Collection($objectType->interfaces))\n                    ->contains(function (NamedTypeNode $interface): bool {\n                        return $interface->name->value === 'Node';\n                    });\n            });\n\n        // Only add the node type and node field if a type actually implements them\n        // Otherwise, a validation error is thrown\n        if (! $hasTypeImplementingNode) {\n            return $document;\n        }\n\n        $globalId = config('lighthouse.global_id_field');\n        // Double slashes to escape the slashes in the namespace.\n        return $document\n            ->setDefinition(\n                PartialParser::interfaceTypeDefinition(<<<GRAPHQL\n\"Node global interface\"\t\ninterface Node @interface(resolveType: \"Nuwave\\\\\\Lighthouse\\\\\\Schema\\\\\\NodeRegistry@resolveType\") {\t\n  \"Global identifier that can be used to resolve any Node implementation.\"\n  $globalId: ID!\t\n}\t\nGRAPHQL\n                )\n            )\n            ->addFieldToQueryType(\n                PartialParser::fieldDefinition(\n                    'node(id: ID! @globalId): Node @field(resolver: \"Nuwave\\\\\\Lighthouse\\\\\\Schema\\\\\\NodeRegistry@resolve\")'\n                )\n            );\n    }", "label": 2}
{"code": "public static MtasSpanQuery constructQuery(String queryValue,\n      String queryType, String queryPrefix,\n      HashMap<String, String[]> queryVariables, String field,\n      String queryIgnore, Integer maximumIgnoreLength) throws IOException {\n    if (queryType == null || queryType.isEmpty()) {\n      throw new IOException(\"no (valid) type for query \" + queryValue);\n    } else if (queryValue == null || queryValue.isEmpty()) {\n      throw new IOException(\"no (valid) value for \" + queryType + \" query\");\n    }\n    MtasSpanQuery ignore = null;\n    if (queryIgnore != null) {\n      Reader queryIgnoreReader = new BufferedReader(\n          new StringReader(queryIgnore));\n      if (queryType.equals(QUERY_TYPE_CQL)) {\n        MtasCQLParser ip = new MtasCQLParser(queryIgnoreReader);\n        try {\n          ignore = ip.parse(field, null, null, null, null);\n        } catch (mtas.parser.cql.ParseException e) {\n          throw new IOException(\"couldn't parse \" + queryType + \" query \"\n              + queryIgnore + \" (\" + e.getMessage() + \")\", e);\n        } catch (TokenMgrError e) {\n          throw new IOException(\"couldn't parse \" + queryType + \" query \"\n              + queryIgnore + \" (\" + e.getMessage() + \")\", e);\n        }\n      } else {\n        throw new IOException(\n            \"unknown queryType \" + queryType + \" for query \" + queryValue);\n      }\n    }\n    Reader queryValueReader = new BufferedReader(new StringReader(queryValue));\n    if (queryType.equals(QUERY_TYPE_CQL)) {\n      MtasCQLParser qp = new MtasCQLParser(queryValueReader);\n      try {\n        return qp.parse(field, queryPrefix, queryVariables, ignore,\n            maximumIgnoreLength);\n      } catch (mtas.parser.cql.ParseException e) {\n        throw new IOException(\"couldn't parse \" + queryType + \" query \"\n            + queryValue + \" (\" + e.getMessage() + \")\", e);\n      } catch (TokenMgrError e) {\n        throw new IOException(\"couldn't parse \" + queryType + \" query \"\n            + queryValue + \" (\" + e.getMessage() + \")\", e);\n      }\n    } else {\n      throw new IOException(\n          \"unknown queryType \" + queryType + \" for query \" + queryValue);\n    }\n  }", "label": 0}
{"code": "public static sslvserver_sslcertkey_binding[] get(nitro_service service, String vservername) throws Exception{\n\t\tsslvserver_sslcertkey_binding obj = new sslvserver_sslcertkey_binding();\n\t\tobj.set_vservername(vservername);\n\t\tsslvserver_sslcertkey_binding response[] = (sslvserver_sslcertkey_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def create_roadmap_doc(dat, opFile):\n    \"\"\"\n    takes a dictionary read from a yaml file and converts\n    it to the roadmap documentation\n    \"\"\"\n    op = format_title('Roadmap for AIKIF')\n    for h1 in dat['projects']:\n        op += format_h1(h1)\n        if dat[h1] is None:\n            op += '(No details)\\n'\n        else:\n            for h2 in dat[h1]:\n                op += '\\n' + format_h2(h2)\n                if dat[h1][h2] is None:\n                    op += '(blank text)\\n'\n                else:\n                    for txt in dat[h1][h2]:\n                        op += '  - ' + txt + '\\n'\n        op += '\\n'\n\n    with open(opFile, 'w') as f:\n        f.write(op)", "label": 1}
{"code": "function (a, b) {\n        if (a === b) {\n            return true;\n        }\n        if (typeof a !== typeof b) {\n            return this._alike(a, b);\n        }\n        return this._objectLike(a, b);\n    }", "label": 3}
{"code": "def track(*fields):\n    \"\"\"\n       Decorator used to track changes on Model's fields.\n\n       :Example:\n       >>> @track('name')\n       ... class Human(models.Model):\n       ...     name = models.CharField(max_length=30)\n    \"\"\"\n    def inner(cls):\n        _track_class(cls, fields)\n        _add_get_tracking_url(cls)\n        return cls\n    return inner", "label": 1}
{"code": "def would_merge? filename\n      return true if directory == '*' || source_hash.include?(filename)\n      @config = Solargraph::Workspace::Config.new(directory)\n      config.calculated.include?(filename)\n    end", "label": 4}
{"code": "function () {\n\n                    // Added by button implementation\n                    removeEvent(wrapper.element, 'mouseenter');\n                    removeEvent(wrapper.element, 'mouseleave');\n\n                    if (text) {\n                        text = text.destroy();\n                    }\n                    if (box) {\n                        box = box.destroy();\n                    }\n                    // Call base implementation to destroy the rest\n                    SVGElement.prototype.destroy.call(wrapper);\n\n                    // Release local pointers (#1298)\n                    wrapper = renderer = updateBoxSize = updateTextPadding = boxAttr = null;\n                }", "label": 3}
{"code": "func (h *hawkularSink) descriptorToDefinition(md *core.MetricDescriptor) metrics.MetricDefinition {\n\ttags := make(map[string]string)\n\t// Postfix description tags with _description\n\tfor _, l := range md.Labels {\n\t\tif len(l.Description) > 0 {\n\t\t\ttags[l.Key+descriptionTag] = l.Description\n\t\t}\n\t}\n\n\tif len(md.Units.String()) > 0 {\n\t\ttags[unitsTag] = md.Units.String()\n\t}\n\n\ttags[descriptorTag] = md.Name\n\n\thmd := metrics.MetricDefinition{\n\t\tID:   md.Name,\n\t\tTags: tags,\n\t\tType: heapsterTypeToHawkularType(md.Type),\n\t}\n\n\treturn hmd\n}", "label": 5}
{"code": "public function setRequestedOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\InspectDataSourceDetails_RequestedOptions::class);\n        $this->requested_options = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def oauth1_token_setter(remote, resp, token_type='', extra_data=None):\n    \"\"\"Set an OAuth1 token.\n\n    :param remote: The remote application.\n    :param resp: The response.\n    :param token_type: The token type. (Default: ``''``)\n    :param extra_data: Extra information. (Default: ``None``)\n    :returns: A :class:`invenio_oauthclient.models.RemoteToken` instance.\n    \"\"\"\n    return token_setter(\n        remote,\n        resp['oauth_token'],\n        secret=resp['oauth_token_secret'],\n        extra_data=extra_data,\n        token_type=token_type,\n    )", "label": 1}
{"code": "function reformatFormIdAndName(submission) {\n  var formName = \"Unknown\";\n  if (submission && submission.formId && submission.formId.name) {\n    formName = submission.formId.name;\n  }\n\n  if (submission && submission.formSubmittedAgainst) {\n    formName = submission.formSubmittedAgainst.name;\n  }\n\n  submission.formName = formName;\n  submission.formId = submission.formId.toString();\n  return submission;\n}", "label": 3}
{"code": "public boolean assertValidPkForDelete(ClassDescriptor cld, Object obj)\r\n    {\r\n        if(!ProxyHelper.isProxy(obj))\r\n        {\r\n            FieldDescriptor fieldDescriptors[] = cld.getPkFields();\r\n            int fieldDescriptorSize = fieldDescriptors.length;\r\n            for(int i = 0; i < fieldDescriptorSize; i++)\r\n            {\r\n                FieldDescriptor fd = fieldDescriptors[i];\r\n                Object pkValue = fd.getPersistentField().get(obj);\r\n                if (representsNull(fd, pkValue))\r\n                {\r\n                    return false;\r\n                }\r\n            }\r\n        }\r\n        return true;\r\n    }", "label": 0}
{"code": "func (cmd *command) sendError(ch io.ReadWriter, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\tcmd.log.Error(err)\n\tmessage := err.Error()\n\tbytes := make([]byte, 0, len(message)+2)\n\tbytes = append(bytes, ErrByte)\n\tbytes = append(bytes, message...)\n\tbytes = append(bytes, []byte{'\\n'}...)\n\t_, writeErr := ch.Write(bytes)\n\tif writeErr != nil {\n\t\tcmd.log.Error(writeErr)\n\t}\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "function (options, limiter) {\n  EventEmitter.call(this);\n\n  this.limiter = limiter;\n\n  this.active = false;\n\n  this.options = _.extend({\n    user: '',\n    password: '',\n    url: '',\n    query: ''\n  }, options || {});\n}", "label": 3}
{"code": "def get_full_year():\n    \"\"\" Returns percentages of peak load for all hours of the year.\n\n    @return:\n        Numpy array of doubles with length 8736.\n    \"\"\"\n    weekly = get_weekly()\n    daily = get_daily()\n    hourly_winter_wkdy, hourly_winter_wknd = get_winter_hourly()\n    hourly_summer_wkdy, hourly_summer_wknd = get_summer_hourly()\n    hourly_spring_autumn_wkdy, hourly_spring_autumn_wknd = \\\n        get_spring_autumn_hourly()\n\n    fullyear = zeros(364 * 24)\n    c = 0\n    l = [(0, 7, hourly_winter_wkdy, hourly_winter_wknd),\n         (8, 16, hourly_spring_autumn_wkdy, hourly_spring_autumn_wknd),\n         (17, 29, hourly_summer_wkdy, hourly_summer_wknd),\n         (30, 42, hourly_spring_autumn_wkdy, hourly_spring_autumn_wknd),\n         (43, 51, hourly_winter_wkdy, hourly_winter_wknd)]\n\n    for start, end, wkdy, wknd in l:\n        for w in weekly[start:end + 1]:\n            for d in daily[:5]:\n                for h in wkdy:\n                    fullyear[c] = w * (d / 100.0) * (h / 100.0)\n                    c += 1\n            for d in daily[5:]:\n                for h in wknd:\n                    fullyear[c] = w * (d / 100.0) * (h / 100.0)\n                    c += 1\n    return fullyear", "label": 1}
{"code": "protected function _line( $message, $label, $color, $handle = STDOUT ) { // phpcs:ignore PSR2.Methods.MethodDeclaration.Underscore -- Used in third party extensions.\n\t\tif ( class_exists( 'cli\\Colors' ) ) {\n\t\t\t$label = \\cli\\Colors::colorize( \"$color$label:%n\", $this->in_color );\n\t\t} else {\n\t\t\t$label = \"$label:\";\n\t\t}\n\t\t$this->write( $handle, \"$label $message\\n\" );\n\t}", "label": 2}
{"code": "private static function create_namespace( $parent, $name, $callable ) {\n\t\t$reflection  = new ReflectionClass( $callable );\n\t\t$doc_comment = self::get_doc_comment( $reflection );\n\t\tif ( ! $doc_comment ) {\n\t\t\t\\WP_CLI::debug( null === $doc_comment ? \"Failed to get doc comment for {$name}.\" : \"No doc comment for {$name}.\", 'commandfactory' );\n\t\t}\n\t\t$docparser = new \\WP_CLI\\DocParser( $doc_comment );\n\n\t\treturn new CommandNamespace( $parent, $name, $docparser );\n\t}", "label": 2}
{"code": "public function setSegments($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1beta2\\VideoSegment::class);\n        $this->segments = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private function determineSource($source)\n    {\n        // Use the contents of a file as the data source.\n        if (is_string($source)) {\n            $source = Psr7\\try_fopen($source, 'r');\n        }\n\n        // Create a source stream.\n        $stream = Psr7\\stream_for($source);\n        if (!$stream->isReadable()) {\n            throw new IAE('Source stream must be readable.');\n        }\n\n        return $stream;\n    }", "label": 2}
{"code": "protected function createSettingsFile($format, $options)\n    {\n        $SettingsClass = ($format === 'json') ? JsonSettings::class : YamlSettings::class;\n\n        $filename = $this->exampleSettingsExists($format) ?\n            \"{$this->basePath}/Homestead.{$format}.example\" :\n            __DIR__.\"/../resources/Homestead.{$format}\";\n\n        $settings = $SettingsClass::fromFile($filename);\n\n        if (! $this->exampleSettingsExists($format)) {\n            $settings->updateName($options['name'])\n                ->updateHostname($options['hostname']);\n        }\n\n        $settings->updateIpAddress($options['ip'])\n            ->configureSites($this->projectName, $this->defaultProjectName)\n            ->configureSharedFolders($this->basePath, $this->defaultProjectName)\n            ->save(\"{$this->basePath}/Homestead.{$format}\");\n    }", "label": 2}
{"code": "public function setWarnings($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->warnings = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function read(myLocale) {\n    locales[myLocale] = {};\n    try {\n        locales[myLocale] = JSON.parse(fs.readFileSync(locate(myLocale)));\n    } catch(e) {\n        console.log('initializing ' + locate(myLocale));\n        write(myLocale);\n    }\n}", "label": 3}
{"code": "func (pm *PortMapper) DeleteForwardingTableEntry(proto string, sourceIP net.IP, sourcePort int, containerIP string, containerPort int) error {\n\treturn pm.forward(iptables.Delete, proto, sourceIP, sourcePort, containerIP, containerPort)\n}", "label": 5}
{"code": "func GetLoginShell(username string) (string, error) {\n\tvar err error\n\tvar shellcmd string\n\n\tshellcmd, err = getLoginShell(username)\n\tif err != nil {\n\t\tif !trace.IsNotFound(err) {\n\t\t\tlogrus.Warnf(\"No shell specified for %v, using default %v.\", username, DefaultShell)\n\t\t\treturn DefaultShell, nil\n\t\t}\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\n\treturn shellcmd, nil\n}", "label": 5}
{"code": "public static int NextPowerOf2(int x) {\r\n        --x;\r\n        x |= x >> 1;\r\n        x |= x >> 2;\r\n        x |= x >> 4;\r\n        x |= x >> 8;\r\n        x |= x >> 16;\r\n        return ++x;\r\n    }", "label": 0}
{"code": "public function deferPostLoadInvoking(ClassMetadata $class, $entity)\n    {\n        $invoke = $this->listenersInvoker->getSubscribedSystems($class, Events::postLoad);\n\n        if ($invoke === ListenersInvoker::INVOKE_NONE) {\n            return;\n        }\n\n        $this->deferredPostLoadInvocations[] = [$class, $invoke, $entity];\n    }", "label": 2}
{"code": "function updateIntoDB() {\n                    //Yaaay, alle Tests bestanden gogo, insert!\n                    lastQry = connection.query('UPDATE ?? SET ? WHERE ?? = ?', [req.params.table , updateJson, updateSelector.field, updateSelector.value] , function (err) {\n                        if (err) return sendError(res,err.code);\n                        sendSuccessAnswer(req.params.table , res, req.params.id, updateSelector.field);\n\n                    });\n                }", "label": 3}
{"code": "def fetch_groups(groups):\n    \"\"\"Prepare list of allowed group names.\n\n    :param groups: The complete list of groups.\n    :returns: A filtered list of groups.\n    \"\"\"\n    hidden_groups = current_app.config.get(\n        'OAUTHCLIENT_CERN_HIDDEN_GROUPS', OAUTHCLIENT_CERN_HIDDEN_GROUPS)\n    hidden_groups_re = current_app.config.get(\n        'OAUTHCLIENT_CERN_HIDDEN_GROUPS_RE',\n        OAUTHCLIENT_CERN_HIDDEN_GROUPS_RE)\n    groups = [group for group in groups if group not in hidden_groups]\n    filter_groups = []\n    for regexp in hidden_groups_re:\n        for group in groups:\n            if regexp.match(group):\n                filter_groups.append(group)\n    groups = [group for group in groups if group not in filter_groups]\n\n    return groups", "label": 1}
{"code": "def filter!(keys, params, options={:recursive => true})  # :nodoc:\n      case params\n      when Hash, ParamsHash\n        params.keys.each do |k, v|\n          unless (keys.include?(k) or Github::Validations::VALID_API_KEYS.include?(k))\n            params.delete(k)\n          else\n            filter!(keys, params[k]) if options[:recursive]\n          end\n        end\n      when Array\n        params.map! do |el|\n          filter!(keys, el) if options[:recursive]\n        end\n      else\n        params\n      end\n      return params\n    end", "label": 4}
{"code": "async function setMcpSettings(accessToken, settings) {\n    return await mcpCustomizr.putSettings(accessToken, {\n        language: settings.language,\n        regionalSettings: settings.regionalSettings,\n        timezone: settings.timezone,\n    });\n}", "label": 3}
{"code": "def add_strategy(name, klass)\n      raise ArgumentError, \"strategy #{name} already defined, please use another name\" if strategies.key?(name.to_sym)\n\n      new_strategies = strategies.dup.merge(name.to_sym => klass).freeze\n      self.strategies = new_strategies\n    end", "label": 4}
{"code": "def voice_regions\n      return @voice_regions unless @voice_regions.empty?\n\n      regions = JSON.parse API.voice_regions(token)\n      regions.each do |data|\n        @voice_regions[data['id']] = VoiceRegion.new(data)\n      end\n\n      @voice_regions\n    end", "label": 4}
{"code": "function (note, number) {\n  var letter = note.letter;\n  var index = scale.indexOf(note.letter);\n  var newIndex = mod(index + number - 1, scale.length);\n\n  assert(index > -1);\n  assert(newIndex > -1 && newIndex < scale.length);\n\n  return scale[newIndex];\n}", "label": 3}
{"code": "func (a *ArgType) ExecuteTemplate(tt TemplateType, name string, sub string, obj interface{}) error {\n\tvar err error\n\n\t// setup generated\n\tif a.Generated == nil {\n\t\ta.Generated = []TBuf{}\n\t}\n\n\t// create store\n\tv := TBuf{\n\t\tTemplateType: tt,\n\t\tName:         name,\n\t\tSubname:      sub,\n\t\tBuf:          new(bytes.Buffer),\n\t}\n\n\t// build template name\n\tloaderType := \"\"\n\tif tt != XOTemplate {\n\t\tif a.LoaderType == \"oci8\" || a.LoaderType == \"ora\" {\n\t\t\t// force oracle for oci8 since the oracle driver doesn't recognize\n\t\t\t// 'oracle' as valid protocol\n\t\t\tloaderType = \"oracle.\"\n\t\t} else {\n\t\t\tloaderType = a.LoaderType + \".\"\n\t\t}\n\t}\n\ttemplateName := fmt.Sprintf(\"%s%s.go.tpl\", loaderType, tt)\n\n\t// execute template\n\terr = a.TemplateSet().Execute(v.Buf, templateName, obj)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ta.Generated = append(a.Generated, v)\n\treturn nil\n}", "label": 5}
{"code": "func (pc *PropertyCollector) WaitForUpdates(ctx *Context, r *types.WaitForUpdates) soap.HasFault {\n\tbody := &methods.WaitForUpdatesBody{}\n\n\tres := pc.WaitForUpdatesEx(ctx, &types.WaitForUpdatesEx{\n\t\tThis:    r.This,\n\t\tVersion: r.Version,\n\t})\n\n\tif res.Fault() != nil {\n\t\tbody.Fault_ = res.Fault()\n\t} else {\n\t\tbody.Res = &types.WaitForUpdatesResponse{\n\t\t\tReturnval: *res.(*methods.WaitForUpdatesExBody).Res.Returnval,\n\t\t}\n\t}\n\n\treturn body\n}", "label": 5}
{"code": "func (sb *sandbox) getGatewayEndpoint() *endpoint {\n\tfor _, ep := range sb.getConnectedEndpoints() {\n\t\tif ep.getNetwork().Type() == \"null\" || ep.getNetwork().Type() == \"host\" {\n\t\t\tcontinue\n\t\t}\n\t\tif len(ep.Gateway()) != 0 {\n\t\t\treturn ep\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def parseFloat(self, words):\n        \"\"\"Convert a floating-point number described in words to a double.\n\n        Supports two kinds of descriptions: those with a 'point' (e.g.,\n        \"one point two five\") and those with a fraction (e.g., \"one and\n        a quarter\").\n\n        Args:\n            words (str): Description of the floating-point number.\n\n        Returns:\n            A double representation of the words.\n        \"\"\"\n        def pointFloat(words):\n            m = re.search(r'(.*) point (.*)', words)\n            if m:\n                whole = m.group(1)\n                frac = m.group(2)\n                total = 0.0\n                coeff = 0.10\n                for digit in frac.split(' '):\n                    total += coeff * self.parse(digit)\n                    coeff /= 10.0\n\n                return self.parseInt(whole) + total\n            return None\n\n        def fractionFloat(words):\n            m = re.search(r'(.*) and (.*)', words)\n            if m:\n                whole = self.parseInt(m.group(1))\n                frac = m.group(2)\n\n                # Replace plurals\n                frac = re.sub(r'(\\w+)s(\\b)', '\\g<1>\\g<2>', frac)\n\n                # Convert 'a' to 'one' (e.g., 'a third' to 'one third')\n                frac = re.sub(r'(\\b)a(\\b)', '\\g<1>one\\g<2>', frac)\n\n                split = frac.split(' ')\n\n                # Split fraction into num (regular integer), denom (ordinal)\n                num = split[:1]\n                denom = split[1:]\n\n                while denom:\n                    try:\n                        # Test for valid num, denom\n                        num_value = self.parse(' '.join(num))\n                        denom_value = self.parse(' '.join(denom))\n                        return whole + float(num_value) / denom_value\n                    except:\n                        # Add another word to num\n                        num += denom[:1]\n                        denom = denom[1:]\n            return None\n\n        # Extract \"one point two five\"-type float\n        result = pointFloat(words)\n        if result:\n            return result\n\n        # Extract \"one and a quarter\"-type float\n        result = fractionFloat(words)\n        if result:\n            return result\n\n        # Parse as integer\n        return self.parseInt(words)", "label": 1}
{"code": "func containsKind(kinds []reflect.Kind, kind reflect.Kind) bool {\n\tfor i := 0; i < len(kinds); i++ {\n\t\tif kind == kinds[i] {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "func (a *CellView) SetModel(model CellModel) {\n\tw, h := model.GetBounds()\n\tmodel.SetCursor(0, 0)\n\ta.model = model\n\ta.port.SetContentSize(w, h, true)\n\ta.port.ValidateView()\n\ta.PostEventWidgetContent(a)\n}", "label": 5}
{"code": "def find_db_config(env)\n      configurations.find do |db_config|\n        db_config.env_name == env.to_s ||\n          (db_config.for_current_env? && db_config.spec_name == env.to_s)\n      end\n    end", "label": 4}
{"code": "function setTemplate(transformDir, templateName, clientType) {\n    clientType = clientType ? (clientType + '.') : '';\n\n    if (templateCache[templateName]) {\n        this.template = templateCache[templateName];\n    }\n    else {\n        var fileName = transformDir + '/' + clientType + templateName + '.template';\n\n        if (fs.existsSync(path.normalize(fileName))) {\n            var file = fs.readFileSync(path.normalize(fileName));\n            this.template = templateCache[templateName] = dot.template(file);\n        }\n        else {\n            throw new Error('No template at ' + fileName);\n        }\n    }\n}", "label": 3}
{"code": "func (c *controller) AgentStopWait() {\n\tc.Lock()\n\tagentStopDone := c.agentStopDone\n\tc.Unlock()\n\tif agentStopDone != nil {\n\t\t<-agentStopDone\n\t}\n}", "label": 5}
{"code": "def process_shells(self, shells):\n        \"\"\"Processing a list of shells.\"\"\"\n        result = {'success': True, 'output': []}\n        if self.parallel and len(shells) > 1:\n            result = self.process_shells_parallel(shells)\n        elif len(shells) > 0:\n            result = self.process_shells_ordered(shells)\n        return result", "label": 1}
{"code": "func NewHandler(cfg Config) (*Handler, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\th := &Handler{\n\t\tEntry: log.WithFields(log.Fields{\n\t\t\ttrace.Component: teleport.Component(teleport.SchemeS3),\n\t\t}),\n\t\tConfig:     cfg,\n\t\tuploader:   s3manager.NewUploader(cfg.Session),\n\t\tdownloader: s3manager.NewDownloader(cfg.Session),\n\t\tclient:     s3.New(cfg.Session),\n\t}\n\tstart := time.Now()\n\th.Infof(\"Setting up bucket %q, sessions path %q in region %q.\", h.Bucket, h.Path, h.Region)\n\tif err := h.ensureBucket(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\th.WithFields(log.Fields{\"duration\": time.Now().Sub(start)}).Infof(\"Setup bucket %q completed.\", h.Bucket)\n\treturn h, nil\n}", "label": 5}
{"code": "def create(self, resource):\n        \"\"\"Create a new package.\n\n        :param resource: :class:`packages.Package <packages.Package>` object\n        :return: :class:`packages.Package <packages.Package>` object\n        :rtype: packages.Package\n        \"\"\"\n        schema = PackageSchema(exclude=('id', 'created', 'updated', 'test_count', 'agent_id', 'result_id'))\n        json = self.service.encode(schema, resource)\n\n        schema = PackageSchema()\n        resp = self.service.create(self.base, json)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "def list_objects\n      objects = @model_class.method(:list).arity == 0 ? @model_class.list : @model_class.list(true)\n      objects.map { |obj| Array(obj).find { |o| o.kind_of?(@model_class) } }\n    end", "label": 4}
{"code": "public function setTranslationDatasetMetadata($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\TranslationDatasetMetadata::class);\n        $this->writeOneof(23, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def decrypt(str)\n      decoded = decode(str)\n      return unless decoded\n\n      return decoded if decoded.empty?\n\n      decrypted = binary_decrypt(decoded)\n\n      # Try to force result to UTF-8 encoding, but if it is not valid, force it back to Binary\n      decrypted.force_encoding(SymmetricEncryption::BINARY_ENCODING) unless decrypted.force_encoding(SymmetricEncryption::UTF8_ENCODING).valid_encoding?\n\n      decrypted\n    end", "label": 4}
{"code": "func waitStreamReply(ctx context.Context, replySent <-chan struct{}, notify chan<- struct{}) {\n\tselect {\n\tcase <-replySent:\n\t\tnotify <- struct{}{}\n\tcase <-ctx.Done():\n\t}\n}", "label": 5}
{"code": "def get_format_modules(lang=None, reverse=False):\n    \"\"\"\n    Returns a list of the format modules found\n\n    \"\"\"\n    if lang is None:\n        lang = get_language()\n    modules = _format_modules_cache.setdefault(lang, list(\n        iter_format_modules(lang)))\n    if reverse:\n        return list(reversed(modules))\n    return modules", "label": 1}
{"code": "func (process *TeleportProcess) newAccessCache(cfg accessCacheConfig) (*cache.Cache, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar cacheBackend backend.Backend\n\tif cfg.inMemory {\n\t\tmem, err := memory.New(memory.Config{\n\t\t\tContext:   process.ExitContext(),\n\t\t\tEventsOff: !cfg.events,\n\t\t\tMirror:    true,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tcacheBackend = mem\n\t} else {\n\t\tpath := filepath.Join(append([]string{process.Config.DataDir, \"cache\"}, cfg.cacheName...)...)\n\t\tif err := os.MkdirAll(path, teleport.SharedDirMode); err != nil {\n\t\t\treturn nil, trace.ConvertSystemError(err)\n\t\t}\n\t\tliteBackend, err := lite.NewWithConfig(process.ExitContext(),\n\t\t\tlite.Config{\n\t\t\t\tPath:             path,\n\t\t\t\tEventsOff:        !cfg.events,\n\t\t\t\tMemory:           false,\n\t\t\t\tMirror:           true,\n\t\t\t\tPollStreamPeriod: 100 * time.Millisecond,\n\t\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tcacheBackend = liteBackend\n\t}\n\treporter, err := backend.NewReporter(backend.ReporterConfig{\n\t\tComponent:        teleport.ComponentCache,\n\t\tBackend:          cacheBackend,\n\t\tTrackTopRequests: process.Config.Debug,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn cache.New(cfg.setup(cache.Config{\n\t\tContext:         process.ExitContext(),\n\t\tBackend:         reporter,\n\t\tEvents:          cfg.services,\n\t\tClusterConfig:   cfg.services,\n\t\tProvisioner:     cfg.services,\n\t\tTrust:           cfg.services,\n\t\tUsers:           cfg.services,\n\t\tAccess:          cfg.services,\n\t\tPresence:        cfg.services,\n\t\tComponent:       teleport.Component(append(cfg.cacheName, process.id, teleport.ComponentCache)...),\n\t\tMetricComponent: teleport.Component(append(cfg.cacheName, teleport.ComponentCache)...),\n\t}))\n}", "label": 5}
{"code": "def entrez(db, acc):\n    \"\"\"\n    search entrez using specified database\n    and accession\n    \"\"\"\n    c1 = ['esearch', '-db', db, '-query', acc]\n    c2 = ['efetch', '-db', 'BioSample', '-format', 'docsum']\n    p1 = Popen(c1, stdout = PIPE, stderr = PIPE)\n    p2 = Popen(c2, stdin = p1.stdout, stdout = PIPE, stderr = PIPE)\n    return p2.communicate()", "label": 1}
{"code": "public static base_responses unset(nitro_service client, snmptrap resources[],  String[] args) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmptrap unsetresources[] = new snmptrap[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tunsetresources[i] = new snmptrap();\n\t\t\t\tunsetresources[i].trapclass = resources[i].trapclass;\n\t\t\t\tunsetresources[i].trapdestination = resources[i].trapdestination;\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func isKeySafe(s []byte) bool {\n\treturn whitelistPattern.Match(s) && !blacklistPattern.Match(s)\n}", "label": 5}
{"code": "function(name) {\n            var l = _dependsInjected[name];\n            if (!l) {\n                l = _dependsInjected[name] = [];\n            }\n            l.push(Array.prototype.slice.call(arguments, 1));\n        }", "label": 3}
{"code": "def read_tree(treeish, opts = {})\n      arr_opts = []\n      arr_opts << \"--prefix=#{opts[:prefix]}\" if opts[:prefix]\n      arr_opts += [treeish]\n      command('read-tree', arr_opts)\n    end", "label": 4}
{"code": "func NewService(rpcIn Channel, rpcOut Channel) *Service {\n\ts := &Service{\n\t\tname:     \"toolbox\", // Same name used by vmtoolsd\n\t\tin:       NewTraceChannel(rpcIn),\n\t\tout:      &ChannelOut{NewTraceChannel(rpcOut)},\n\t\thandlers: make(map[string]Handler),\n\t\twg:       new(sync.WaitGroup),\n\t\tstop:     make(chan struct{}),\n\n\t\tPrimaryIP: DefaultIP,\n\t}\n\n\ts.RegisterHandler(\"reset\", s.Reset)\n\ts.RegisterHandler(\"ping\", s.Ping)\n\ts.RegisterHandler(\"Set_Option\", s.SetOption)\n\ts.RegisterHandler(\"Capabilities_Register\", s.CapabilitiesRegister)\n\n\ts.Command = registerCommandServer(s)\n\ts.Command.FileServer = hgfs.NewServer()\n\ts.Command.FileServer.RegisterFileHandler(\"proc\", s.Command.ProcessManager)\n\ts.Command.FileServer.RegisterFileHandler(hgfs.ArchiveScheme, hgfs.NewArchiveHandler())\n\n\ts.Power = registerPowerCommandHandler(s)\n\n\treturn s\n}", "label": 5}
{"code": "func (cn *connection) shouldRequestWithoutBias() bool {\n\tif cn.t.requestStrategy != 2 {\n\t\treturn false\n\t}\n\tif len(cn.t.readers) == 0 {\n\t\treturn false\n\t}\n\tif len(cn.t.conns) == 1 {\n\t\treturn true\n\t}\n\tif cn == cn.t.fastestConn {\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "func containsRune(fl FieldLevel) bool {\n\n\tr, _ := utf8.DecodeRuneInString(fl.Param())\n\n\treturn strings.ContainsRune(fl.Field().String(), r)\n}", "label": 5}
{"code": "def start():\r\n    \"\"\"Starts the web server.\"\"\"\r\n    global app\r\n    bottle.run(app, host=conf.WebHost, port=conf.WebPort,\r\n               debug=conf.WebAutoReload, reloader=conf.WebAutoReload,\r\n               quiet=conf.WebQuiet)", "label": 1}
{"code": "def handle_mapping_template(mapping)\n      if mapping\n        if mapping[:valueset_path] && @entry.at_xpath(mapping[:valueset_path])\n          @code_list_xpath = mapping[:valueset_path]\n        end\n        @value = DataCriteriaMethods.parse_value(@entry, mapping[:result_path]) if mapping[:result_path]\n      end\n    end", "label": 4}
{"code": "void markReferenceElements(PersistenceBroker broker)\r\n    {\r\n        // these cases will be handled by ObjectEnvelopeTable#cascadingDependents()\r\n        // if(getModificationState().needsInsert() || getModificationState().needsDelete()) return;\r\n\r\n        Map oldImage = getBeforeImage();\r\n        Map newImage = getCurrentImage();\r\n\r\n        Iterator iter = newImage.entrySet().iterator();\r\n        while (iter.hasNext())\r\n        {\r\n            Map.Entry entry = (Map.Entry) iter.next();\r\n            Object key = entry.getKey();\r\n            // we only interested in references\r\n            if(key instanceof ObjectReferenceDescriptor)\r\n            {\r\n                Image oldRefImage = (Image) oldImage.get(key);\r\n                Image newRefImage = (Image) entry.getValue();\r\n                newRefImage.performReferenceDetection(oldRefImage);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "static Relation getRelation(String s, String arg,\r\n                              Function<String,String> basicCatFunction,\r\n                              HeadFinder headFinder)\r\n    throws ParseException\r\n  {\r\n    if (arg == null) {\r\n      return getRelation(s, basicCatFunction, headFinder);\r\n    }\r\n    Relation r;\r\n    if (s.equals(\"<\")) {\r\n      r = new HasIthChild(Integer.parseInt(arg));\r\n    } else if (s.equals(\">\")) {\r\n      r = new IthChildOf(Integer.parseInt(arg));\r\n    } else if (s.equals(\"<+\")) {\r\n      r = new UnbrokenCategoryDominates(arg, basicCatFunction);\r\n    } else if (s.equals(\">+\")) {\r\n      r = new UnbrokenCategoryIsDominatedBy(arg, basicCatFunction);\r\n    } else if (s.equals(\".+\")) {\r\n      r = new UnbrokenCategoryPrecedes(arg, basicCatFunction);\r\n    } else if (s.equals(\",+\")) {\r\n      r = new UnbrokenCategoryFollows(arg, basicCatFunction);\r\n    } else {\r\n      throw new ParseException(\"Unrecognized compound relation \" + s + ' '\r\n          + arg);\r\n    }\r\n    return Interner.globalIntern(r);\r\n  }", "label": 0}
{"code": "def create_application!(name: nil, primary_language: nil, version: nil, sku: nil, bundle_id: nil, bundle_id_suffix: nil, company_name: nil, platform: nil, itunes_connect_users: nil)\n      puts(\"The `version` parameter is deprecated. Use `Spaceship::Tunes::Application.ensure_version!` method instead\") if version\n\n      # First, we need to fetch the data from Apple, which we then modify with the user's values\n      primary_language ||= \"English\"\n      platform ||= \"ios\"\n      r = request(:get, \"ra/apps/create/v2/?platformString=#{platform}\")\n      data = parse_response(r, 'data')\n\n      # Now fill in the values we have\n      # some values are nil, that's why there is a hash\n      data['name'] = { value: name }\n      data['bundleId'] = { value: bundle_id }\n      data['primaryLanguage'] = { value: primary_language }\n      data['primaryLocaleCode'] = { value: primary_language.to_itc_locale }\n      data['vendorId'] = { value: sku }\n      data['bundleIdSuffix'] = { value: bundle_id_suffix }\n      data['companyName'] = { value: company_name } if company_name\n      data['enabledPlatformsForCreation'] = { value: [platform] }\n\n      data['initialPlatform'] = platform\n      data['enabledPlatformsForCreation'] = { value: [platform] }\n\n      unless itunes_connect_users.nil?\n        data['iTunesConnectUsers']['grantedAllUsers'] = false\n        data['iTunesConnectUsers']['grantedUsers'] = data['iTunesConnectUsers']['availableUsers'].select { |user| itunes_connect_users.include?(user['username']) }\n      end\n\n      # Now send back the modified hash\n      r = request(:post) do |req|\n        req.url('ra/apps/create/v2')\n        req.body = data.to_json\n        req.headers['Content-Type'] = 'application/json'\n      end\n\n      data = parse_response(r, 'data')\n      handle_itc_response(data)\n    end", "label": 4}
{"code": "public function setHttpCheck($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\UptimeCheckConfig_HttpCheck::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func ParseProtocol(s string) Protocol {\n\tswitch strings.ToLower(s) {\n\tcase \"icmp\":\n\t\treturn ICMP\n\tcase \"udp\":\n\t\treturn UDP\n\tcase \"tcp\":\n\t\treturn TCP\n\tcase \"sctp\":\n\t\treturn SCTP\n\tdefault:\n\t\treturn 0\n\t}\n}", "label": 5}
{"code": "def rna_bases(rna_cov, scaffold, bases, line):\n    \"\"\"\n    determine if read overlaps with rna, if so count bases\n    \"\"\"\n    start = int(line[3])\n    stop = start + bases - 1\n    if scaffold not in rna_cov:\n        return rna_cov\n    for pos in rna_cov[scaffold][2]:\n        ol = get_overlap([start, stop], pos)\n        rna_cov[scaffold][0] += ol\n    return rna_cov", "label": 1}
{"code": "func GenerateCertificate(authServer *AuthServer, identity TestIdentity) ([]byte, []byte, error) {\n\tswitch id := identity.I.(type) {\n\tcase LocalUser:\n\t\tuser, err := authServer.GetUser(id.Username)\n\t\tif err != nil {\n\t\t\treturn nil, nil, trace.Wrap(err)\n\t\t}\n\t\troles, err := services.FetchRoles(user.GetRoles(), authServer, user.GetTraits())\n\t\tif err != nil {\n\t\t\treturn nil, nil, trace.Wrap(err)\n\t\t}\n\t\tif identity.TTL == 0 {\n\t\t\tidentity.TTL = time.Hour\n\t\t}\n\t\tpriv, pub, err := authServer.GenerateKeyPair(\"\")\n\t\tif err != nil {\n\t\t\treturn nil, nil, trace.Wrap(err)\n\t\t}\n\t\tcerts, err := authServer.generateUserCert(certRequest{\n\t\t\tpublicKey: pub,\n\t\t\tuser:      user,\n\t\t\troles:     roles,\n\t\t\tttl:       identity.TTL,\n\t\t\tusage:     identity.AcceptedUsage,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, nil, trace.Wrap(err)\n\t\t}\n\t\treturn certs.tls, priv, nil\n\tcase BuiltinRole:\n\t\tkeys, err := authServer.GenerateServerKeys(GenerateServerKeysRequest{\n\t\t\tHostID:   id.Username,\n\t\t\tNodeName: id.Username,\n\t\t\tRoles:    teleport.Roles{id.Role},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, nil, trace.Wrap(err)\n\t\t}\n\t\treturn keys.TLSCert, keys.Key, nil\n\tdefault:\n\t\treturn nil, nil, trace.BadParameter(\"identity of unknown type %T is unsupported\", identity)\n\t}\n}", "label": 5}
{"code": "private TypeArgSignature getTypeArgSignature(Type type) {\r\n\t\tif (type instanceof WildcardType) {\r\n\t\t\tWildcardType wildcardType = (WildcardType) type;\r\n\t\t\tType lowerBound = wildcardType.getLowerBounds().length == 0 ? null\r\n\t\t\t\t\t: wildcardType.getLowerBounds()[0];\r\n\t\t\tType upperBound = wildcardType.getUpperBounds().length == 0 ? null\r\n\t\t\t\t\t: wildcardType.getUpperBounds()[0];\r\n\r\n\t\t\tif (lowerBound == null && Object.class.equals(upperBound)) {\r\n\t\t\t\treturn new TypeArgSignature(\r\n\t\t\t\t\t\tTypeArgSignature.UNBOUNDED_WILDCARD,\r\n\t\t\t\t\t\t(FieldTypeSignature) getFullTypeSignature(upperBound));\r\n\t\t\t} else if (lowerBound == null && upperBound != null) {\r\n\t\t\t\treturn new TypeArgSignature(\r\n\t\t\t\t\t\tTypeArgSignature.UPPERBOUND_WILDCARD,\r\n\t\t\t\t\t\t(FieldTypeSignature) getFullTypeSignature(upperBound));\r\n\t\t\t} else if (lowerBound != null) {\r\n\t\t\t\treturn new TypeArgSignature(\r\n\t\t\t\t\t\tTypeArgSignature.LOWERBOUND_WILDCARD,\r\n\t\t\t\t\t\t(FieldTypeSignature) getFullTypeSignature(lowerBound));\r\n\t\t\t} else {\r\n\t\t\t\tthrow new RuntimeException(\"Invalid type\");\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\treturn new TypeArgSignature(TypeArgSignature.NO_WILDCARD,\r\n\t\t\t\t\t(FieldTypeSignature) getFullTypeSignature(type));\r\n\t\t}\r\n\t}", "label": 0}
{"code": "func (s *CA) DeactivateCertAuthority(id services.CertAuthID) error {\n\tcertAuthority, err := s.GetCertAuthority(id, true)\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn trace.NotFound(\"can not deactivate cert authority %q which does not exist\", id.DomainName)\n\t\t}\n\t\treturn trace.Wrap(err)\n\t}\n\n\terr = s.DeleteCertAuthority(id)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tvalue, err := services.GetCertAuthorityMarshaler().MarshalCertAuthority(certAuthority)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\titem := backend.Item{\n\t\tKey:     backend.Key(authoritiesPrefix, deactivatedPrefix, string(id.Type), id.DomainName),\n\t\tValue:   value,\n\t\tExpires: certAuthority.Expiry(),\n\t\tID:      certAuthority.GetResourceID(),\n\t}\n\n\t_, err = s.Put(context.TODO(), item)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def fixed_length_secure_compare(a, b)\n      raise ArgumentError, \"string length mismatch.\" unless a.bytesize == b.bytesize\n\n      l = a.unpack \"C#{a.bytesize}\"\n\n      res = 0\n      b.each_byte { |byte| res |= byte ^ l.shift }\n      res == 0\n    end", "label": 4}
{"code": "public function setNodePools($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Container\\V1\\NodePool::class);\n        $this->node_pools = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def build_edit_form(title, id, cols, return_page):\n    \"\"\" \n    returns the html for a simple edit form \n    \"\"\"\n    txt = '<H3>' + title + '<H3>'\n    txt += '<form action=\"' + return_page + '\" method=\"POST\">\\n' # return_page = /agents\n    txt += '  updating id:' + str(id) + '\\n<BR>'\n    txt += '  <input type=\"hidden\" name=\"rec_id\" readonly value=\"' + str(id) + '\"> '\n    txt += '  <TABLE width=80% valign=top border=1>'\n    \n    for col_num, col in enumerate(cols):\n        txt += '  <TR>\\n'\n        txt += '    <TD><div id=\"form_label\">' + col + '</div></TD>\\n'\n        txt += '    <TD><div id=\"form_input\"><input type=\"text\" name=\"col_' + str(col_num) + '\"></div></TD>\\n'\n        txt += '  </TR>\\n'\n    txt += '  <TR><TD></TD>\\n'\n    txt += '  <TD>\\n'\n    txt += '    <input type=\"submit\" name=\"update-form\" value=\"Save Changes\">\\n'\n    txt += '    <input type=\"submit\" name=\"delete-form\" value=\"Delete\">\\n'\n    txt += '    <input type=\"submit\" name=\"add-form\" value=\"Add\">\\n'\n    txt += '  </TD></TR></TABLE>'\n    txt += '</form>\\n'\n    return txt", "label": 1}
{"code": "public static base_response update(nitro_service client, policystringmap resource) throws Exception {\n\t\tpolicystringmap updateresource = new policystringmap();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.comment = resource.comment;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def get_bibtex(arxiv_id):\n    \"\"\"\n    Get a BibTeX entry for a given arXiv ID.\n\n    .. note::\n\n        Using awesome https://pypi.python.org/pypi/arxiv2bib/ module.\n\n    :param arxiv_id: The canonical arXiv id to get BibTeX from.\n    :returns: A BibTeX string or ``None``.\n\n    >>> get_bibtex('1506.06690')\n    \"@article{1506.06690v2,\\\\nAuthor        = {Lucas Verney and Lev Pitaevskii and Sandro Stringari},\\\\nTitle         = {Hybridization of first and second sound in a weakly-interacting Bose gas},\\\\nEprint        = {1506.06690v2},\\\\nDOI           = {10.1209/0295-5075/111/40005},\\\\nArchivePrefix = {arXiv},\\\\nPrimaryClass  = {cond-mat.quant-gas},\\\\nAbstract      = {Using Landau's theory of two-fluid hydrodynamics we investigate the sound\\\\nmodes propagating in a uniform weakly-interacting superfluid Bose gas for\\\\nvalues of temperature, up to the critical point. In order to evaluate the\\\\nrelevant thermodynamic functions needed to solve the hydrodynamic equations,\\\\nincluding the temperature dependence of the superfluid density, we use\\\\nBogoliubov theory at low temperatures and the results of a perturbative\\\\napproach based on Beliaev diagrammatic technique at higher temperatures.\\\\nSpecial focus is given on the hybridization phenomenon between first and second\\\\nsound which occurs at low temperatures of the order of the interaction energy\\\\nand we discuss explicitly the behavior of the two sound velocities near the\\\\nhybridization point.},\\\\nYear          = {2015},\\\\nMonth         = {Jun},\\\\nUrl           = {http://arxiv.org/abs/1506.06690v2},\\\\nFile          = {1506.06690v2.pdf}\\\\n}\"\n\n    >>> get_bibtex('1506.06690v1')\n    \"@article{1506.06690v1,\\\\nAuthor        = {Lucas Verney and Lev Pitaevskii and Sandro Stringari},\\\\nTitle         = {Hybridization of first and second sound in a weakly-interacting Bose gas},\\\\nEprint        = {1506.06690v1},\\\\nDOI           = {10.1209/0295-5075/111/40005},\\\\nArchivePrefix = {arXiv},\\\\nPrimaryClass  = {cond-mat.quant-gas},\\\\nAbstract      = {Using Landau's theory of two-fluid hydrodynamics we investigate the sound\\\\nmodes propagating in a uniform weakly-interacting superfluid Bose gas for\\\\nvalues of temperature, up to the critical point. In order to evaluate the\\\\nrelevant thermodynamic functions needed to solve the hydrodynamic equations,\\\\nincluding the temperature dependence of the superfluid density, we use\\\\nBogoliubov theory at low temperatures and the results of a perturbative\\\\napproach based on Beliaev diagrammatic technique at higher temperatures.\\\\nSpecial focus is given on the hybridization phenomenon between first and second\\\\nsound which occurs at low temperatures of the order of the interaction energy\\\\nand we discuss explicitly the behavior of the two sound velocities near the\\\\nhybridization point.},\\\\nYear          = {2015},\\\\nMonth         = {Jun},\\\\nUrl           = {http://arxiv.org/abs/1506.06690v1},\\\\nFile          = {1506.06690v1.pdf}\\\\n}\"\n    \"\"\"\n    # Fetch bibtex using arxiv2bib module\n    try:\n        bibtex = arxiv2bib.arxiv2bib([arxiv_id])\n    except HTTPError:\n        bibtex = []\n\n    for bib in bibtex:\n        if isinstance(bib, arxiv2bib.ReferenceErrorInfo):\n            continue\n        else:\n            # Return fetched bibtex\n            return bib.bibtex()\n    # An error occurred, return None\n    return None", "label": 1}
{"code": "def stats(self):\n        \"\"\"Basic group statistics.\n\n        Returned dict has the following keys:\n\n            'online' - users online count\n            'ingame' - users currently in game count\n            'chatting' - users chatting count\n\n        :return: dict\n        \"\"\"\n        stats_online = CRef.cint()\n        stats_ingame = CRef.cint()\n        stats_chatting = CRef.cint()\n\n        self._iface.get_clan_stats(\n            self.group_id,\n            stats_online,\n            stats_ingame,\n            stats_chatting,\n        )\n\n        return {\n            'online': int(stats_online),\n            'ingame': int(stats_ingame),\n            'chatting': int(stats_chatting),\n        }", "label": 1}
{"code": "public function detectLanguageBatch(array $strings, array $options = [])\n    {\n        $response =  $this->connection->listDetections($options + [\n            'q' => $strings,\n            'key' => $this->key\n        ]);\n\n        $detections = [];\n\n        foreach ($response['data']['detections'] as $key => $detection) {\n            $detection = $detection[0];\n\n            $detections[] = array_filter([\n                'languageCode' => $detection['language'],\n                'input' => $strings[$key],\n                'confidence' => isset($detection['confidence']) ? $detection['confidence'] : null\n            ]);\n        }\n\n        return $detections;\n    }", "label": 2}
{"code": "function chown(file, uid, gid, options) {\n  if (!isPlatform('unix')) return;\n\n  if (_.isObject(uid)) {\n    options = gid;\n    const ownerInfo = uid;\n    uid = (ownerInfo.uid || ownerInfo.owner || ownerInfo.user || ownerInfo.username);\n    gid = (ownerInfo.gid || ownerInfo.group);\n  }\n  options = _.sanitize(options, {abortOnError: true, recursive: false});\n  let recurse = false;\n  try {\n    if (uid) uid = getUid(uid, {refresh: false});\n    if (gid) gid = getGid(gid, {refresh: false});\n    if (!exists(file)) throw new Error(`Path '${file}' does not exists`);\n    recurse = options.recursive && isDirectory(file);\n  } catch (e) {\n    if (options.abortOnError) {\n      throw e;\n    } else {\n      return;\n    }\n  }\n  if (recurse) {\n    _.each(listDirContents(file, {includeTopDir: true}), function(f) {\n      _chown(f, uid, gid, options);\n    });\n  } else {\n    _chown(file, uid, gid, options);\n  }\n}", "label": 3}
{"code": "function one (state, eventName, handler) {\n  state.emitter.once(eventName, handler)\n\n  return state.api\n}", "label": 3}
{"code": "public FieldDescriptor getAutoIncrementField()\r\n    {\r\n        if (m_autoIncrementField == null)\r\n        {\r\n            FieldDescriptor[] fds = getPkFields();\r\n\r\n            for (int i = 0; i < fds.length; i++)\r\n            {\r\n                FieldDescriptor fd = fds[i];\r\n                if (fd.isAutoIncrement())\r\n                {\r\n                    m_autoIncrementField = fd;\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n        if (m_autoIncrementField == null)\r\n        {\r\n            LoggerFactory.getDefaultLogger().warn(\r\n                this.getClass().getName()\r\n                    + \": \"\r\n                    + \"Could not find autoincrement attribute for class: \"\r\n                    + this.getClassNameOfObject());\r\n        }\r\n        return m_autoIncrementField;\r\n    }", "label": 0}
{"code": "def get_var(self, name):\n        \"\"\" Returns the variable set with the given name.\n        \"\"\"\n        for var in self.vars:\n            if var.name == name:\n                return var\n        else:\n            raise ValueError", "label": 1}
{"code": "func (c *Client) DeleteUser(user string) error {\n\t_, err := c.Delete(c.Endpoint(\"users\", user))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def fetch_tags_dates(tags)\n      print \"Fetching tag dates...\\r\" if options[:verbose]\n      i = 0\n      tags.each do |tag|\n        get_time_of_tag(tag)\n        i += 1\n      end\n      puts \"Fetching tags dates: #{i}/#{tags.count}\" if options[:verbose]\n    end", "label": 4}
{"code": "public function getIdsForUsername($string, User $actor = null)\n    {\n        $string = $this->escapeLikeString($string);\n\n        $query = User::where('username', 'like', '%'.$string.'%')\n            ->orderByRaw('username = ? desc', [$string])\n            ->orderByRaw('username like ? desc', [$string.'%']);\n\n        return $this->scopeVisibleTo($query, $actor)->pluck('id')->all();\n    }", "label": 2}
{"code": "func (a *Api) availableClusterMetrics(request *restful.Request, response *restful.Response) {\n\ta.processMetricNamesRequest(core.ClusterKey(), response)\n}", "label": 5}
{"code": "def _get_version(self, root):\n        \"\"\"Return the version of the root element passed in.\n\n        Args:\n            root (etree.Element)\n\n        Returns:\n            distutils.StrictVersion\n\n        Raises:\n            UnknownVersionError\n        \"\"\"\n        # Note: STIX and MAEC use a \"version\" attribute. To support CybOX, a\n        # subclass will need to combine \"cybox_major_version\",\n        # \"cybox_minor_version\", and \"cybox_update_version\".\n        version = self.get_version(root)\n        if version:\n            return StrictVersion(version)\n\n        raise UnknownVersionError(\n            \"Unable to determine the version of the input document. No \"\n            \"version information found on the root element.\"\n        )", "label": 1}
{"code": "public function setDataset($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\Dataset::class);\n        $this->dataset = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def render_noindex(tags)\n      meta_tags.extract_noindex.each do |name, content|\n        tags << Tag.new(:meta, name: name, content: content) if content.present?\n      end\n    end", "label": 4}
{"code": "def BLASTresults(rid, format_type=\"Tabular\", \\\n                 hitlist_size= None, alignments=None, \\\n                 ncbi_gi = None, format_object=None,\\\n                 baseURL=\"http://blast.ncbi.nlm.nih.gov\"):\n    \"\"\"\n    Retrieves results for an RID.\n\n    :param rid: BLAST search request identifier. Allowed values: The Request ID (RID) returned when the search was submitted\n    :param format_type: Report type. Allowed values: HTML, Text, XML, XML2, JSON2, or Tabular. Tabular is the default.\n    :param hitlist_size: Number of databases sequences to keep. Allowed values: Integer greater than zero.\n    :param alignments: Number of alignments to print (applies to HTML and Text). Allowed values: Integer greater than zero.\n    :param ncbi_gi: Show NCBI GIs in report. Allowed values: T or F.\n    :param format_object: Object type. Allowed values: SearchInfo (status check) or Alignment (report formatting).\n    :param baseURL: server url. Default=http://blast.ncbi.nlm.nih.gov\n\n    :returns: the result of a BLAST query. If format_type=\"Tabular\" it will parse the content into a Pandas dataframe.\n    \"\"\"\n\n    URL=baseURL+\"/Blast.cgi?\"\n    URL=URL+\"RID=\"+str(rid)+\"&FORMAT_TYPE=\"+str(format_type)\n    for o in [ hitlist_size, alignments,\\\n              ncbi_gi, format_object]:\n        if o:\n            URL=URL+\"&\"+ variablename(var) +\"=\"+str(o)\n    URL=URL+\"&CMD=Get\"\n    response=requests.get(url = URL)\n    response=response.content\n\n    if format_type==\"Tabular\":\n        result=response.split(\"\\n\")\n        result=[ s.split(\"\\t\") for s in result][6:]\n        header=result[:7]\n        content=result[7:]\n        fields=header[5][0].strip(\"# Fields: \").split(\", \")\n        result=pd.DataFrame(content,columns=fields)\n        response=result[:int(header[-1][0].split(\" \")[1])]\n\n    return response", "label": 1}
{"code": "def _index_buses(self, buses):\n        \"\"\" Set up indexing for updating v.\n        \"\"\"\n        refs = [bus._i for bus in buses if bus.type == REFERENCE]\n#        if len(refs) != 1:\n#            raise SlackBusError\n        pv = [bus._i for bus in buses if bus.type == PV]\n        pq = [bus._i for bus in buses if bus.type == PQ]\n        pvpq = pv + pq\n\n        return refs, pq, pv, pvpq", "label": 1}
{"code": "public Object copy(Object obj, PersistenceBroker broker)\r\n\t\t\tthrows ObjectCopyException\r\n\t{\r\n\t\tif (obj instanceof OjbCloneable)\r\n\t\t{\r\n\t\t\ttry\r\n\t\t\t{\r\n\t\t\t\treturn ((OjbCloneable) obj).ojbClone();\r\n\t\t\t}\r\n\t\t\tcatch (Exception e)\r\n\t\t\t{\r\n\t\t\t\tthrow new ObjectCopyException(e);\r\n\t\t\t}\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\tthrow new ObjectCopyException(\"Object must implement OjbCloneable in order to use the\"\r\n\t\t\t\t\t\t\t\t\t\t  + \" CloneableObjectCopyStrategy\");\r\n\t\t}\r\n\t}", "label": 0}
{"code": "func PgTsConfigMapByMapcfgMaptokentypeMapseqno(db XODB, mapcfg pgtypes.Oid, maptokentype int, mapseqno int) (*PgTsConfigMap, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, mapcfg, maptokentype, mapseqno, mapdict ` +\n\t\t`FROM pg_catalog.pg_ts_config_map ` +\n\t\t`WHERE mapcfg = $1 AND maptokentype = $2 AND mapseqno = $3`\n\n\t// run query\n\tXOLog(sqlstr, mapcfg, maptokentype, mapseqno)\n\tptcm := PgTsConfigMap{}\n\n\terr = db.QueryRow(sqlstr, mapcfg, maptokentype, mapseqno).Scan(&ptcm.Tableoid, &ptcm.Cmax, &ptcm.Xmax, &ptcm.Cmin, &ptcm.Xmin, &ptcm.Ctid, &ptcm.Mapcfg, &ptcm.Maptokentype, &ptcm.Mapseqno, &ptcm.Mapdict)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ptcm, nil\n}", "label": 5}
{"code": "def get_reference(root):\n    \"\"\"Read reference info from root of ReSpecTh XML file.\n\n    Args:\n        root (`~xml.etree.ElementTree.Element`): Root of ReSpecTh XML file\n\n    Returns:\n        properties (`dict`): Dictionary with reference information\n    \"\"\"\n    reference = {}\n    elem = root.find('bibliographyLink')\n    if elem is None:\n        raise MissingElementError('bibliographyLink')\n\n    # Try to get reference info via DOI, fall back on preferredKey if necessary.\n    ref_doi = elem.get('doi', None)\n    ref_key = elem.get('preferredKey', None)\n\n    if ref_doi is not None:\n        try:\n            ref = crossref_api.works(ids=ref_doi)['message']\n        except (HTTPError, habanero.RequestError, ConnectionError):\n            if ref_key is None:\n                raise KeywordError('DOI not found and preferredKey attribute not set')\n            else:\n                warn('Missing doi attribute in bibliographyLink or lookup failed. '\n                     'Setting \"detail\" key as a fallback; please update to the appropriate fields.'\n                     )\n                reference['detail'] = ref_key\n                if reference['detail'][-1] != '.':\n                    reference['detail'] += '.'\n        else:\n            if ref_key is not None:\n                warn('Using DOI to obtain reference information, rather than preferredKey.')\n            reference['doi'] = elem.attrib['doi']\n            # Now get elements of the reference data\n            # Assume that the reference returned by the DOI lookup always has a container-title\n            reference['journal'] = ref.get('container-title')[0]\n            ref_year = ref.get('published-print') or ref.get('published-online')\n            reference['year'] = int(ref_year['date-parts'][0][0])\n            reference['volume'] = int(ref.get('volume'))\n            reference['pages'] = ref.get('page')\n            reference['authors'] = []\n            for author in ref['author']:\n                auth = {}\n                auth['name'] = ' '.join([author['given'], author['family']])\n                # Add ORCID if available\n                orcid = author.get('ORCID')\n                if orcid:\n                    auth['ORCID'] = orcid.lstrip('http://orcid.org/')\n                reference['authors'].append(auth)\n\n    elif ref_key is not None:\n        warn('Missing doi attribute in bibliographyLink. '\n             'Setting \"detail\" key as a fallback; please update to the appropriate fields.'\n             )\n        reference['detail'] = ref_key\n        if reference['detail'][-1] != '.':\n            reference['detail'] += '.'\n    else:\n        # Need one of DOI or preferredKey\n        raise MissingAttributeError('preferredKey', 'bibliographyLink')\n\n    return reference", "label": 1}
{"code": "func Extend(description string) error {\n\tconnection := tpmclient.New(\"localhost:12041\", timeout)\n\terr := connection.Extend(15, 0x1000, nil, description)\n\treturn err\n}", "label": 5}
{"code": "public static double StdDev( int[] values, double mean ){\n        double  stddev = 0;\n        double  diff;\n        int     hits;\n        int     total = 0;\n\n        // for all values\n        for ( int i = 0, n = values.length; i < n; i++ )\n        {\n            hits = values[i];\n            diff = (double) i - mean;\n            // accumulate std.dev.\n            stddev += diff * diff * hits;\n            // accumalate total\n            total += hits;\n        }\n\n        return ( total == 0 ) ? 0 : Math.sqrt( stddev / (total - 1) );\n    }", "label": 0}
{"code": "function createCompositeKeyString(rec) {\n    const cKey = createCompositeKey(rec);\n    return rec.hasDynamicPath\n        ? cKey.id +\n            Object.keys(cKey)\n                .filter(k => k !== \"id\")\n                .map(k => `::${k}:${cKey[k]}`)\n        : rec.id;\n}", "label": 3}
{"code": "def push_slack(self, tokens):\n        \"\"\" Finds the slack bus, adds a Generator with the appropriate data\n        and sets the bus type to slack.\n        \"\"\"\n        logger.debug(\"Pushing slack data: %s\" % tokens)\n\n        bus = self.case.buses[tokens[\"bus_no\"] - 1]\n\n        g = Generator(bus)\n        g.q_max = tokens[\"q_max\"]\n        g.q_min = tokens[\"q_min\"]\n        # Optional parameter\n#        if tokens.has_key(\"status\"):\n#        g.online = tokens[\"status\"]\n\n        self.case.generators.append(g)\n\n        bus.type = \"ref\"", "label": 1}
{"code": "public function insert(EntityInterface $entity, array $options = [])\n    {\n        $res = $this->insertBatch([$entity], $options);\n        return $this->parseSingleMutationResult($res);\n    }", "label": 2}
{"code": "function (options, iterationInfo, modules) {\n\n        // Ignore explicitly excluded directories\n        if (options.excludeDirs) {\n            var match = iterationInfo.fileName.match(options.excludeDirs);\n            if (match)\n                return;\n        }\n\n        // Recursively call requireAll on each child directory\n        var subIterationInfo = _.clone(iterationInfo);\n        ++subIterationInfo.depth;\n        subIterationInfo.dirName = iterationInfo.absoluteFullPath;\n\n        //process subtree recursively\n        var subTreeResult = doInterations(options, subIterationInfo);\n\n        //omit empty dirs\n        if (_.isEmpty(subTreeResult))\n            return;\n\n        //add to the list or to the subtree\n        if (options.mode === 'list') {\n            //check uniqueness\n            _.forEach(subTreeResult, function (value, index) {\n                if (options.useVersions === true) {\n                    modules[index] = modules[index] || {};\n                    _.forEach(value, function (versionValue, versionIndex) {\n                        if (modules[index][versionIndex])\n                            throw new Error(\"Identity '\" + index + \"' with version '\" + versionIndex + \"' is already registered by module at '\" + modules[index][versionIndex].absoluteFullPath + \"'\");\n                        modules[index][versionIndex] = versionValue;\n                    });\n                }\n                else {\n                    if (modules[index])\n                        throw new Error(\"Identity '\" + index + \"' is already registered by module at '\" + modules[index].absoluteFullPath + \"'\");\n                    modules[index] = value;\n                }\n            })\n        }\n        else if (options.mode === 'tree') {\n            if (options.markDirectories !== false) {\n                subTreeResult.isDirectory = true;\n            }\n\n            var identity = generateIdentity(options, iterationInfo);\n            modules[identity] = subTreeResult;\n        }\n        else\n            throw new Error('Unknown mode');\n    }", "label": 3}
{"code": "function (index, silent) {\n\t\tvar info = this._ordered_values[index];\n\t\t_destroy_info(this._ordered_values.splice(index, 1), silent);\n\t\tif(silent !== true) {\n\t\t\tthis.$size.invalidate();\n\t\t}\n\t}", "label": 3}
{"code": "public void retrieveProxyCollections(Object newObj, ClassDescriptor cld, boolean forced) throws PersistenceBrokerException\r\n    {\r\n        doRetrieveCollections(newObj, cld, forced, true);\r\n    }", "label": 0}
{"code": "function chainStepsNoError() {\n\tvar steps = slice.call(arguments).map(function(step) {\n\t\treturn notHandlingError(step);\n\t});\n\treturn chainSteps.apply(null, steps);\n}", "label": 3}
{"code": "def delete(name)\n      name = normalize_header name.to_s\n      @pile.delete_if { |k, _| k == name }\n    end", "label": 4}
{"code": "def install_dir(self):\n        \"\"\"Returns application installation path.\n\n        .. note::\n\n            If fails this falls back to a restricted interface, which can only be used by approved apps.\n\n        :rtype: str\n        \"\"\"\n        max_len = 500\n\n        directory = self._get_str(self._iface.get_install_dir, [self.app_id], max_len=max_len)\n\n        if not directory:\n            # Fallback to restricted interface (can only be used by approved apps).\n            directory = self._get_str(self._iface_list.get_install_dir, [self.app_id], max_len=max_len)\n\n        return directory", "label": 1}
{"code": "func (proxy *TCPProxy) Run() {\n\tquit := make(chan bool)\n\tdefer close(quit)\n\tfor {\n\t\tclient, err := proxy.listener.Accept()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Stopping proxy on tcp/%v for tcp/%v (%s)\", proxy.frontendAddr, proxy.backendAddr, err)\n\t\t\treturn\n\t\t}\n\t\tgo proxy.clientLoop(client.(*net.TCPConn), quit)\n\t}\n}", "label": 5}
{"code": "def automatic_update_check_allowed?\n      check_path = directory.join(\"box_update_check\")\n      if check_path.exist?\n        last_check_span = Time.now.to_i - check_path.mtime.to_i\n        if last_check_span < BOX_UPDATE_CHECK_INTERVAL\n          @logger.info(\"box update check is under the interval threshold\")\n          return false\n        end\n      end\n      FileUtils.touch(check_path)\n      true\n    end", "label": 4}
{"code": "func (s *Server) StartTLS() {\n\tif s.URL != \"\" {\n\t\tpanic(\"Server already started\")\n\t}\n\tif s.client == nil {\n\t\ts.client = &http.Client{Transport: &http.Transport{}}\n\t}\n\tcert, err := tls.X509KeyPair(LocalhostCert, LocalhostKey)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"httptest: NewTLSServer: %v\", err))\n\t}\n\n\texistingConfig := s.TLS\n\tif existingConfig != nil {\n\t\ts.TLS = existingConfig.Clone()\n\t} else {\n\t\ts.TLS = new(tls.Config)\n\t}\n\tif s.TLS.NextProtos == nil {\n\t\ts.TLS.NextProtos = []string{\"http/1.1\"}\n\t}\n\tif len(s.TLS.Certificates) == 0 {\n\t\ts.TLS.Certificates = []tls.Certificate{cert}\n\t}\n\ts.certificate, err = x509.ParseCertificate(s.TLS.Certificates[0].Certificate[0])\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"httptest: NewTLSServer: %v\", err))\n\t}\n\tcertpool := x509.NewCertPool()\n\tcertpool.AddCert(s.certificate)\n\ts.client.Transport = &http.Transport{\n\t\tTLSClientConfig: &tls.Config{\n\t\t\tRootCAs: certpool,\n\t\t},\n\t}\n\ts.Listener = tls.NewListener(s.Listener, s.TLS)\n\ts.URL = \"https://\" + s.Listener.Addr().String()\n\ts.wrap()\n\ts.goServe()\n}", "label": 5}
{"code": "function ExpectedRequest(method, path, data) {\n    this.method = method;\n    this.path = path;\n    this.data = data;\n    this.response = null;\n    this.checks = [];\n}", "label": 3}
{"code": "public function hydrationComplete()\n    {\n        $toInvoke                          = $this->deferredPostLoadInvocations;\n        $this->deferredPostLoadInvocations = [];\n\n        foreach ($toInvoke as $classAndEntity) {\n            [$class, $invoke, $entity] = $classAndEntity;\n\n            $this->listenersInvoker->invoke(\n                $class,\n                Events::postLoad,\n                $entity,\n                new LifecycleEventArgs($entity, $this->em),\n                $invoke\n            );\n        }\n    }", "label": 2}
{"code": "function createClient (ravelInstance, restrict = true) {\n  const localRedis = ravelInstance.get('redis port') === undefined || ravelInstance.get('redis host') === undefined;\n  ravelInstance.on('post init', () => {\n    ravelInstance.$log.info(localRedis\n      ? 'Using in-memory key-value store. Please do not scale this app horizontally.'\n      : `Using redis at ${ravelInstance.get('redis host')}:${ravelInstance.get('redis port')}`);\n  });\n  let client;\n  if (localRedis) {\n    const mock = require('redis-mock');\n    mock.removeAllListeners(); // redis-mock doesn't clean up after itself very well.\n    client = mock.createClient();\n    client.flushall(); // in case this has been required before\n  } else {\n    client = redis.createClient(\n      ravelInstance.get('redis port'),\n      ravelInstance.get('redis host'),\n      {\n        'no_ready_check': true,\n        'retry_strategy': retryStrategy(ravelInstance)\n      });\n  }\n  if (ravelInstance.get('redis password')) {\n    client.auth(ravelInstance.get('redis password'));\n  }\n  // log errors\n  client.on('error', ravelInstance.$log.error);\n\n  // keepalive when not testing\n  const redisKeepaliveInterval = setInterval(() => {\n    client && client.ping && client.ping();\n  }, ravelInstance.get('redis keepalive interval'));\n  ravelInstance.once('end', () => {\n    clearInterval(redisKeepaliveInterval);\n  });\n\n  if (restrict) {\n    disable(client, 'quit');\n    disable(client, 'subscribe');\n    disable(client, 'psubscribe');\n    disable(client, 'unsubscribe');\n    disable(client, 'punsubscribe');\n  } else {\n    const origQuit = client.quit;\n    client.quit = function (...args) {\n      clearInterval(redisKeepaliveInterval);\n      return origQuit.apply(client, args);\n    };\n  }\n\n  client.clone = function () {\n    return createClient(ravelInstance, false);\n  };\n\n  return client;\n}", "label": 3}
{"code": "def _make_readline_peeker(self):\n        \"\"\"Make a readline-like function which peeks into the source.\"\"\"\n        counter = itertools.count(0)\n        def readline():\n            try:\n                return self._peek_buffer(next(counter))\n            except StopIteration:\n                return ''\n        return readline", "label": 1}
{"code": "func getFile(args *internal.ArgType, t *internal.TBuf) (*os.File, error) {\n\tvar f *os.File\n\tvar err error\n\n\t// determine filename\n\tvar filename = strings.ToLower(t.Name) + args.Suffix\n\tif args.SingleFile {\n\t\tfilename = args.Filename\n\t}\n\tfilename = path.Join(args.Path, filename)\n\n\t// lookup file\n\tf, ok := files[filename]\n\tif ok {\n\t\treturn f, nil\n\t}\n\n\t// default open mode\n\tmode := os.O_RDWR | os.O_CREATE | os.O_TRUNC\n\n\t// stat file to determine if file already exists\n\tfi, err := os.Stat(filename)\n\tif err == nil && fi.IsDir() {\n\t\treturn nil, errors.New(\"filename cannot be directory\")\n\t} else if _, ok = err.(*os.PathError); !ok && args.Append && t.TemplateType != internal.XOTemplate {\n\t\t// file exists so append if append is set and not XO type\n\t\tmode = os.O_APPEND | os.O_WRONLY\n\t}\n\n\t// skip\n\tif t.TemplateType == internal.XOTemplate && fi != nil {\n\t\treturn nil, nil\n\t}\n\n\t// open file\n\tf, err = os.OpenFile(filename, mode, 0666)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// file didn't originally exist, so add package header\n\tif fi == nil || !args.Append {\n\t\t// add build tags\n\t\tif args.Tags != \"\" {\n\t\t\tf.WriteString(`// +build ` + args.Tags + \"\\n\\n\")\n\t\t}\n\n\t\t// execute\n\t\terr = args.TemplateSet().Execute(f, \"xo_package.go.tpl\", args)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// store file\n\tfiles[filename] = f\n\n\treturn f, nil\n}", "label": 5}
{"code": "public IExternalAccess getAgentsExternalAccess(String agent_name) {\n\n        return cmsService.getExternalAccess(getAgentID(agent_name)).get(\n                new ThreadSuspendable());\n    }", "label": 0}
{"code": "function(options) {\n\tthis.options = options;\n\tthis.targets = options.targets; // the DOM nodes\n\tvar setter = options.setter, // a function that sets the attribute value\n\t\tgetter = options.getter, // a function that gets the attribute value\n\t\tinit_val = options.init_val, // the value of the attribute before the binding was set\n\t\tcurr_value, // used in live fn\n\t\tlast_value, // used in live fn\n\t\told_targets = [], // used in live fn\n\t\tdo_update = function() {\n\t\t\tthis._timeout_id = false; // Make it clear that I don't have a timeout set\n\t\t\tvar new_targets = filter(get_dom_array(this.targets), isAnyElement); // update the list of targets\n\n\t\t\tif(has(options, \"onChange\")) {\n\t\t\t\toptions.onChange.call(this, curr_value, last_value);\n\t\t\t}\n\n\t\t\t// For every target, update the attribute\n\t\t\teach(new_targets, function(target) {\n\t\t\t\tsetter.call(this, target, curr_value, last_value);\n\t\t\t}, this);\n\n\t\t\t// track the last value so that next time we call diff\n\t\t\tlast_value = curr_value;\n\t\t};\n\tthis._throttle_delay = false; // Optional throttling to improve performance\n\tthis._timeout_id = false; // tracks the timeout that helps throttle\n\n\tif(isFunction(init_val)) { // If init_val is a getter, call it on the first element\n\t\tlast_value = init_val(get_dom_array(this.targets[0]));\n\t} else { // Otherwise, just take it as is\n\t\tlast_value = init_val;\n\t}\n\n\tthis.$live_fn = cjs.liven(function() {\n\t\tcurr_value = getter(); // get the value once and inside of live fn to make sure a dependency is added\n\n\t\tif(this._throttle_delay) { // We shouldn't update values right away\n\t\t\tif(!this._timeout_id) { // If there isn't any timeout set yet, then set a timeout to delay the call to do update\n\t\t\t\tthis._timeout_id = sTO(bind(do_update, this), this._throttle_delay);\n\t\t\t}\n\t\t} else { // we can update the value right away if no throttle delay is set\n\t\t\tdo_update.call(this);\n\t\t}\n\t}, {\n\t\tcontext: this\n\t});\n}", "label": 3}
{"code": "public function rateLimitRequest(Request $request, $limit = 0, $expires = 0)\n    {\n        $this->request = $request;\n\n        // If the throttle instance is already set then we'll just carry on as\n        // per usual.\n        if ($this->throttle instanceof Throttle) {\n\n            // If the developer specified a certain amount of requests or expiration\n        // time on a specific route then we'll always use the route specific\n        // throttle with the given values.\n        } elseif ($limit > 0 || $expires > 0) {\n            $this->throttle = new Route(['limit' => $limit, 'expires' => $expires]);\n            $this->keyPrefix = sha1($request->path());\n\n        // Otherwise we'll use the throttle that gives the consumer the largest\n        // amount of requests. If no matching throttle is found then rate\n        // limiting will not be imposed for the request.\n        } else {\n            $this->throttle = $this->getMatchingThrottles()->sort(function ($a, $b) {\n                return $a->getLimit() < $b->getLimit();\n            })->first();\n        }\n\n        if (is_null($this->throttle)) {\n            return;\n        }\n\n        if ($this->throttle instanceof HasRateLimiter) {\n            $this->setRateLimiter([$this->throttle, 'getRateLimiter']);\n        }\n\n        $this->prepareCacheStore();\n\n        $this->cache('requests', 0, $this->throttle->getExpires());\n        $this->cache('expires', $this->throttle->getExpires(), $this->throttle->getExpires());\n        $this->cache('reset', time() + ($this->throttle->getExpires() * 60), $this->throttle->getExpires());\n        $this->increment('requests');\n    }", "label": 2}
{"code": "public static gslbservice_stats[] get(nitro_service service) throws Exception{\n\t\tgslbservice_stats obj = new gslbservice_stats();\n\t\tgslbservice_stats[] response = (gslbservice_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function createRoute($route)\n    {\n        return new Route($this->adapter, $this->container, $this->container['request'], $route);\n    }", "label": 2}
{"code": "func (a *Allocator) parsePoolRequest(addressSpace, pool, subPool string, v6 bool) (*SubnetKey, *net.IPNet, *AddressRange, error) {\n\tvar (\n\t\tnw  *net.IPNet\n\t\tipr *AddressRange\n\t\terr error\n\t)\n\n\tif addressSpace == \"\" {\n\t\treturn nil, nil, nil, ipamapi.ErrInvalidAddressSpace\n\t}\n\n\tif pool == \"\" && subPool != \"\" {\n\t\treturn nil, nil, nil, ipamapi.ErrInvalidSubPool\n\t}\n\n\tif pool == \"\" {\n\t\treturn nil, nil, nil, nil\n\t}\n\n\tif _, nw, err = net.ParseCIDR(pool); err != nil {\n\t\treturn nil, nil, nil, ipamapi.ErrInvalidPool\n\t}\n\n\tif subPool != \"\" {\n\t\tif ipr, err = getAddressRange(subPool, nw); err != nil {\n\t\t\treturn nil, nil, nil, err\n\t\t}\n\t}\n\n\treturn &SubnetKey{AddressSpace: addressSpace, Subnet: nw.String(), ChildSubnet: subPool}, nw, ipr, nil\n}", "label": 5}
{"code": "private static String firstFoundTableName(PersistenceBroker brokerForClass, ClassDescriptor cld)\r\n    {\r\n        String name = null;\r\n        if (!cld.isInterface() && cld.getFullTableName() != null)\r\n        {\r\n            return cld.getFullTableName();\r\n        }\r\n        if (cld.isExtent())\r\n        {\r\n            Collection extentClasses = cld.getExtentClasses();\r\n            for (Iterator iterator = extentClasses.iterator(); iterator.hasNext();)\r\n            {\r\n                name = firstFoundTableName(brokerForClass, brokerForClass.getClassDescriptor((Class) iterator.next()));\r\n                // System.out.println(\"## \" + cld.getClassNameOfObject()+\" - name: \"+name);\r\n                if (name != null) break;\r\n            }\r\n        }\r\n        return name;\r\n    }", "label": 0}
{"code": "private FieldConversion[] getPkFieldConversion(ClassDescriptor cld)\r\n    {\r\n        FieldDescriptor[] pks = cld.getPkFields();\r\n        FieldConversion[] fc = new FieldConversion[pks.length]; \r\n        \r\n        for (int i= 0; i < pks.length; i++)\r\n        {\r\n            fc[i] = pks[i].getFieldConversion();\r\n        }\r\n        \r\n        return fc;\r\n    }", "label": 0}
{"code": "private static function get_project_milestones( $project, $args = array() ) {\n\t\t$request_url            = sprintf( 'https://api.github.com/repos/%s/milestones', $project );\n\t\tlist( $body, $headers ) = self::make_github_api_request( $request_url, $args );\n\t\treturn $body;\n\t}", "label": 2}
{"code": "protected function breakUriSegments($uri)\n    {\n        if (! Str::contains($uri, '?}')) {\n            return (array) $uri;\n        }\n\n        $segments = preg_split(\n            '/\\/(\\{.*?\\})/',\n            preg_replace('/\\{(.*?)\\?\\}/', '{$1}', $uri),\n            -1,\n            PREG_SPLIT_DELIM_CAPTURE | PREG_SPLIT_NO_EMPTY\n        );\n\n        $uris = [];\n\n        while ($segments) {\n            $uris[] = implode('/', $segments);\n\n            array_pop($segments);\n        }\n\n        return $uris;\n    }", "label": 2}
{"code": "public function flush()\n    {\n        $id = $this->batchRunner\n            ->getJobFromId($this->identifier)\n            ->id();\n\n        return $this->batchRunner\n            ->getProcessor()\n            ->flush($id);\n    }", "label": 2}
{"code": "def count_statements(ast)\n      case ast\n      when Puppet::Pops::Model::Program\n        count_statements(ast.body)\n      when Puppet::Pops::Model::BlockExpression\n        ast.statements.count\n      else\n        1\n      end\n    end", "label": 4}
{"code": "function get(connections, params, cb) {\n  //validateParams\n  //LookUpDataSource\n  //CheckFormsThatAre Using The Data Source\n  //Return Result.\n\n  async.waterfall([\n    function validateParams(cb) {\n      validate(params).has(CONSTANTS.DATA_SOURCE_ID, function(err) {\n        if (err) {\n          return cb(buildErrorResponse({error: new Error(\"An ID Parameter Is Required To Get A Data Source\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n        }\n\n        return cb(undefined, params[CONSTANTS.DATA_SOURCE_ID]);\n      });\n    },\n    function findDataSources(id, cb) {\n      var query = {\n\n      };\n\n      //Searching By ID.\n      query[CONSTANTS.DATA_SOURCE_ID] = id;\n\n      lookUpDataSources(connections, {\n        query: query,\n        lean: true,\n        includeAuditLog: params.includeAuditLog,\n        includeAuditLogData: params.includeAuditLogData\n      }, function(err, dataSources) {\n        if (err) {\n          return cb(buildErrorResponse({\n            error: err,\n            userDetail: \"Unexpected Error When Searching For A Data Source\",\n            code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n          }));\n        }\n\n        //Checking if the data source exists. Should be only one\n        if (dataSources.length !== 1) {\n          return cb(buildErrorResponse({\n            error: new Error(\"Data Source Not Found\"),\n            systemDetail: \"Requested ID: \"  + params[CONSTANTS.DATA_SOURCE_ID],\n            code: ERROR_CODES.FH_FORMS_NOT_FOUND\n          }));\n        }\n\n        var dataSourceJSON = dataSources[0];\n        dataSourceJSON = processDataSourceResponse(dataSourceJSON, {\n          includeAuditLog: params.includeAuditLog\n        });\n\n        return cb(undefined, dataSourceJSON);\n      });\n    },\n    function checkForms(dataSourceJSON, cb) {\n      //Checking For Any Forms Associated With The Data Source\n      checkFormsUsingDataSource(connections, dataSourceJSON, cb);\n    }\n  ], cb);\n}", "label": 3}
{"code": "def add_settings(mod, allow_extras=True, settings=django_settings):\n    \"\"\"\n    Adds all settings that are part of ``mod`` to the global settings object.\n\n    Special cases ``EXTRA_APPS`` to append the specified applications to the\n    list of ``INSTALLED_APPS``.\n    \"\"\"\n    extras = {}\n\n    for setting in dir(mod):\n        if setting == setting.upper():\n            setting_value = getattr(mod, setting)\n            if setting in TUPLE_SETTINGS and type(setting_value) == str:\n                setting_value = (setting_value,)  # In case the user forgot the comma.\n\n            # Any setting that starts with EXTRA_ and matches a setting that is a list or tuple\n            # will automatically append the values to the current setting.\n            # It might make sense to make this less magical\n            if setting.startswith('EXTRA_'):\n                base_setting = setting.split('EXTRA_', 1)[-1]\n                if isinstance(getattr(settings, base_setting), (list, tuple)):\n                    extras[base_setting] = setting_value\n                    continue\n\n            setattr(settings, setting, setting_value)\n\n    for key, value in extras.items():\n        curval = getattr(settings, key)\n        setattr(settings, key, curval + type(curval)(value))", "label": 1}
{"code": "def auth_tune(path)\n      json = client.get(\"/v1/sys/auth/#{encode_path(path)}/tune\")\n      return AuthConfig.decode(json)\n    rescue HTTPError => e\n      return nil if e.code == 404\n      raise\n    end", "label": 4}
{"code": "def _initializer_for(self, raw_name: str, cooked_name: str, prefix: Optional[str]) -> List[str]:\n        \"\"\"Create an initializer entry for the entry\n\n        :param raw_name: name unadjusted for python compatibility.\n        :param cooked_name: name that may or may not be python compatible\n\n        :param prefix: owner of the element - used when objects passed as arguments\n\n        :return: Initialization statements\n        \"\"\"\n        mt_val = self._ebnf.mt_value(self._typ)\n        rval = []\n\n        if is_valid_python(raw_name):\n            if prefix:\n                # If a prefix exists, the input has already been processed - no if clause is necessary\n                rval.append(f\"self.{raw_name} = {prefix}.{raw_name}\")\n            else:\n                cons = raw_name\n                rval.append(f\"self.{raw_name} = {cons}\")\n        elif is_valid_python(cooked_name):\n            if prefix:\n                rval.append(f\"setattr(self, '{raw_name}', getattr({prefix}, '{raw_name}')\")\n            else:\n                cons = f\"{cooked_name} if {cooked_name} is not {mt_val} else _kwargs.get('{raw_name}', {mt_val})\"\n                rval.append(f\"setattr(self, '{raw_name}', {cons})\")\n        else:\n            getter = f\"_kwargs.get('{raw_name}', {mt_val})\"\n            if prefix:\n                rval.append(f\"setattr(self, '{raw_name}', getattr({prefix}, '{getter}')\")\n            else:\n                rval.append(f\"setattr(self, '{raw_name}', {getter})\")\n\n        return rval", "label": 1}
{"code": "function mockProperties(db, config = { relationshipBehavior: \"ignore\" }, exceptions) {\n    return async (record) => {\n        const meta = ModelMeta_1.getModelMeta(record);\n        const props = meta.properties;\n        const recProps = {};\n        // below is needed to import faker library\n        props.map(prop => {\n            const p = prop.property;\n            recProps[p] = mockValue_1.default(db, prop);\n        });\n        const finalized = Object.assign({}, recProps, exceptions);\n        // write to mock db and retain a reference to same model\n        record = await __1.Record.add(record.modelConstructor, finalized, {\n            silent: true\n        });\n        return record;\n    };\n}", "label": 3}
{"code": "def validate_complex(prop, value, xpath_map=None):\n    \"\"\" Default validation for single complex data structure \"\"\"\n\n    if value is not None:\n        validate_type(prop, value, dict)\n\n        if prop in _complex_definitions:\n            complex_keys = _complex_definitions[prop]\n        else:\n            complex_keys = {} if xpath_map is None else xpath_map\n\n        for complex_prop, complex_val in iteritems(value):\n            complex_key = '.'.join((prop, complex_prop))\n\n            if complex_prop not in complex_keys:\n                _validation_error(prop, None, value, ('keys: {0}'.format(','.join(complex_keys))))\n\n            validate_type(complex_key, complex_val, (string_types, list))", "label": 1}
{"code": "def work(argv)\n      @options = DEFAULT_OPTIONS.dup\n      parser.parse!(argv)\n      return show(\"OneGadget Version #{OneGadget::VERSION}\") if @options[:version]\n      return info_build_id(@options[:info]) if @options[:info]\n\n      libc_file = argv.pop\n      build_id = @options[:build_id]\n      level = @options[:level]\n      return error('Either FILE or BuildID can be passed') if libc_file && @options[:build_id]\n      return show(parser.help) && false unless build_id || libc_file\n\n      gadgets = if build_id\n                  OneGadget.gadgets(build_id: build_id, details: true, level: level)\n                else # libc_file\n                  OneGadget.gadgets(file: libc_file, details: true, force_file: @options[:force_file], level: level)\n                end\n      handle_gadgets(gadgets, libc_file)\n    end", "label": 4}
{"code": "def managed_process(process):\n    \"\"\"Wrapper for subprocess.Popen to work across various Python versions, when using the with syntax.\"\"\"\n    try:\n        yield process\n    finally:\n        for stream in [process.stdout, process.stdin, process.stderr]:\n            if stream:\n                stream.close()\n        process.wait()", "label": 1}
{"code": "def socket(socket_timeout, ssl_options = {}, options = {})\n      create_resolver(ssl_options).socket(socket_timeout, ssl_options, options)\n    end", "label": 4}
{"code": "def _has_changed(instance):\n    \"\"\"\n    Check if some tracked fields have changed\n    \"\"\"\n    for field, value in instance._original_fields.items():\n        if field != 'pk' and \\\n           not isinstance(instance._meta.get_field(field), ManyToManyField):\n            try:\n                if field in getattr(instance, '_tracked_fields', []):\n                    if isinstance(instance._meta.get_field(field), ForeignKey):\n                        if getattr(instance, '{0}_id'.format(field)) != value:\n                            return True\n                    else:\n                        if getattr(instance, field) != value:\n                            return True\n            except TypeError:\n                # Can't compare old and new value, should be different.\n                return True\n    return False", "label": 1}
{"code": "private String randomString(String[] s) {\n        if (s == null || s.length <= 0) return \"\";\n        return s[this.random.nextInt(s.length)];\n    }", "label": 0}
{"code": "public function setOperationState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Firestore\\Admin\\V1\\OperationState::class);\n        $this->operation_state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def __get_url(url):\n    \"\"\"Load json data from url and return result.\"\"\"\n    log.info(\"Retrieving  weather data (%s)...\", url)\n    result = {SUCCESS: False, MESSAGE: None}\n    try:\n        r = requests.get(url)\n        result[STATUS_CODE] = r.status_code\n        result[HEADERS] = r.headers\n        result[CONTENT] = r.text\n        if (200 == r.status_code):\n            result[SUCCESS] = True\n        else:\n            result[MESSAGE] = \"Got http statuscode: %d.\" % (r.status_code)\n        return result\n    except requests.RequestException as ose:\n        result[MESSAGE] = 'Error getting url data. %s' % ose\n        log.error(result[MESSAGE])\n\n    return result", "label": 1}
{"code": "func Retry(roundTripper soap.RoundTripper, fn RetryFunc) soap.RoundTripper {\n\tr := &retry{\n\t\troundTripper: roundTripper,\n\t\tfn:           fn,\n\t}\n\n\treturn r\n}", "label": 5}
{"code": "func (v *ViewPort) ScrollRight(cols int) {\n\tv.viewx += cols\n\tv.ValidateViewX()\n}", "label": 5}
{"code": "func CreateTpl(corner PointType, size SizeType, orientationStr, unitStr, fontDirStr string, fn func(*Tpl)) Template {\n\treturn newTpl(corner, size, orientationStr, unitStr, fontDirStr, fn, nil)\n}", "label": 5}
{"code": "public function setTransferMessages($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferMessage::class);\n        $this->transfer_messages = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private static int getTrimmedXStart(BufferedImage img) {\n    int height = img.getHeight();\n    int width = img.getWidth();\n    int xStart = width;\n\n    for (int i = 0; i < height; i++) {\n      for (int j = 0; j < width; j++) {\n        if (img.getRGB(j, i) != Color.WHITE.getRGB() && j < xStart) {\n          xStart = j;\n          break;\n        }\n      }\n    }\n\n    return xStart;\n  }", "label": 0}
{"code": "public function getAltNumber(string $key): string\n    {\n        $number = strlen($key) > 1 ? $this->$key : $this->rawFormat('h');\n        $translateKey = \"alt_numbers.$number\";\n        $symbol = $this->translate($translateKey);\n\n        if ($symbol !== $translateKey) {\n            return $symbol;\n        }\n\n        if ($number > 99 && $this->translate('alt_numbers.99') !== 'alt_numbers.99') {\n            $start = '';\n            foreach ([10000, 1000, 100] as $exp) {\n                $key = \"alt_numbers_pow.$exp\";\n                if ($number >= $exp && $number < $exp * 10 && ($pow = $this->translate($key)) !== $key) {\n                    $unit = floor($number / $exp);\n                    $number -= $unit * $exp;\n                    $start .= ($unit > 1 ? $this->translate(\"alt_numbers.$unit\") : '').$pow;\n                }\n            }\n            $result = '';\n            while ($number) {\n                $chunk = $number % 100;\n                $result = $this->translate(\"alt_numbers.$chunk\").$result;\n                $number = floor($number / 100);\n            }\n\n            return \"$start$result\";\n        }\n\n        if ($number > 9 && $this->translate('alt_numbers.9') !== 'alt_numbers.9') {\n            $result = '';\n            while ($number) {\n                $chunk = $number % 10;\n                $result = $this->translate(\"alt_numbers.$chunk\").$result;\n                $number = floor($number / 10);\n            }\n\n            return $result;\n        }\n\n        return $number;\n    }", "label": 2}
{"code": "function phase (phase_date) {\n  if (!phase_date) {\n    phase_date = new Date()\n  }\n  phase_date = julian.fromDate(phase_date)\n\n  const day = phase_date - EPOCH\n\n  // calculate sun position\n  const sun_mean_anomaly =\n    (360.0 / 365.2422) * day +\n    (ECLIPTIC_LONGITUDE_EPOCH - ECLIPTIC_LONGITUDE_PERIGEE)\n  const sun_true_anomaly =\n    2 * todeg(Math.atan(\n      Math.sqrt((1.0 + ECCENTRICITY) / (1.0 - ECCENTRICITY)) *\n      Math.tan(0.5 * kepler(sun_mean_anomaly, ECCENTRICITY))\n    ))\n  const sun_ecliptic_longitude =\n    ECLIPTIC_LONGITUDE_PERIGEE + sun_true_anomaly\n  const sun_orbital_distance_factor =\n    (1 + ECCENTRICITY * dcos(sun_true_anomaly)) /\n    (1 - ECCENTRICITY * ECCENTRICITY)\n\n  // calculate moon position\n  const moon_mean_longitude =\n    MOON_MEAN_LONGITUDE_EPOCH + 13.1763966 * day\n  const moon_mean_anomaly =\n    moon_mean_longitude - 0.1114041 * day - MOON_MEAN_PERIGEE_EPOCH\n  const moon_evection =\n    1.2739 * dsin(\n      2 * (moon_mean_longitude - sun_ecliptic_longitude) - moon_mean_anomaly\n    )\n  const moon_annual_equation =\n    0.1858 * dsin(sun_mean_anomaly)\n  // XXX: what is the proper name for this value?\n  const moon_mp =\n    moon_mean_anomaly +\n    moon_evection -\n    moon_annual_equation -\n    0.37 * dsin(sun_mean_anomaly)\n  const moon_equation_center_correction =\n    6.2886 * dsin(moon_mp)\n  const moon_corrected_longitude =\n    moon_mean_longitude +\n    moon_evection +\n    moon_equation_center_correction -\n    moon_annual_equation +\n    0.214 * dsin(2.0 * moon_mp)\n  const moon_age =\n    fixangle(\n      moon_corrected_longitude -\n      sun_ecliptic_longitude +\n      0.6583 * dsin(\n        2 * (moon_corrected_longitude - sun_ecliptic_longitude)\n      )\n    )\n  const moon_distance =\n    (MOON_SMAXIS * (1.0 - MOON_ECCENTRICITY * MOON_ECCENTRICITY)) /\n    (1.0 + MOON_ECCENTRICITY * dcos(moon_mp + moon_equation_center_correction))\n\n  return {\n    phase: (1.0 / 360.0) * moon_age,\n    illuminated: 0.5 * (1.0 - dcos(moon_age)),\n    age: (SYNODIC_MONTH / 360.0) * moon_age,\n    distance: moon_distance,\n    angular_diameter: MOON_ANGULAR_SIZE_SMAXIS / moon_distance,\n    sun_distance: SUN_SMAXIS / sun_orbital_distance_factor,\n    sun_angular_diameter: SUN_ANGULAR_SIZE_SMAXIS * sun_orbital_distance_factor\n  }\n}", "label": 3}
{"code": "protected function getCookieParameter($parameter, ServerRequestInterface $request, $default = null)\n    {\n        return isset($request->getCookieParams()[$parameter]) ? $request->getCookieParams()[$parameter] : $default;\n    }", "label": 2}
{"code": "def set_elem(elem_ref, elem):\n    \"\"\"\n    Sets element referenced by the elem_ref. Returns the elem.\n\n    :param elem_ref:\n    :param elem:\n    :return:\n    \"\"\"\n    if elem_ref is None or elem_ref == elem or not is_elem_ref(elem_ref):\n        return elem\n\n    elif elem_ref[0] == ElemRefObj:\n        setattr(elem_ref[1], elem_ref[2], elem)\n        return elem\n\n    elif elem_ref[0] == ElemRefArr:\n        elem_ref[1][elem_ref[2]] = elem\n        return elem", "label": 1}
{"code": "func (r *Registry) AddReference(obj mo.Reference, field *[]types.ManagedObjectReference, ref types.ManagedObjectReference) {\n\tr.WithLock(obj, func() {\n\t\tif FindReference(*field, ref) == nil {\n\t\t\t*field = append(*field, ref)\n\t\t}\n\t})\n}", "label": 5}
{"code": "public static sslcertkey[] get(nitro_service service) throws Exception{\n\t\tsslcertkey obj = new sslcertkey();\n\t\tsslcertkey[] response = (sslcertkey[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setImageClassificationModelMetadata($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\ImageClassificationModelMetadata::class);\n        $this->writeOneof(13, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func OptionDiscoveryAddress(address string) Option {\n\treturn func(c *Config) {\n\t\tc.Cluster.Address = address\n\t}\n}", "label": 5}
{"code": "def signup(remote_app):\n    \"\"\"Extra signup step.\"\"\"\n    if remote_app not in current_oauthclient.signup_handlers:\n        return abort(404)\n    res = current_oauthclient.signup_handlers[remote_app]['view']()\n    return abort(404) if res is None else res", "label": 1}
{"code": "def gpu_iuwt_decomposition(in1, scale_count, scale_adjust, store_smoothed, store_on_gpu):\n    \"\"\"\n    This function calls the a trous algorithm code to decompose the input into its wavelet coefficients. This is\n    the isotropic undecimated wavelet transform implemented for a GPU.\n\n    INPUTS:\n    in1                 (no default):   Array on which the decomposition is to be performed.\n    scale_count         (no default):   Maximum scale to be considered.\n    scale_adjust        (no default):   Adjustment to scale value if first scales are of no interest.\n    store_smoothed      (no default):   Boolean specifier for whether the smoothed image is stored or not.\n    store_on_gpu        (no default):   Boolean specifier for whether the decomposition is stored on the gpu or not.\n\n    OUTPUTS:\n    detail_coeffs                       Array containing the detail coefficients.\n    C0                  (optional):     Array containing the smoothest version of the input.\n    \"\"\"\n\n    # The following simple kernel just allows for the construction of a 3D decomposition on the GPU.\n\n    ker = SourceModule(\"\"\"\n                        __global__ void gpu_store_detail_coeffs(float *in1, float *in2, float* out1, int *scale, int *adjust)\n                        {\n                            const int len = gridDim.x*blockDim.x;\n                            const int i = (blockDim.x * blockIdx.x + threadIdx.x);\n                            const int j = (blockDim.y * blockIdx.y + threadIdx.y)*len;\n                            const int k = (blockDim.z * blockIdx.z + threadIdx.z)*(len*len);\n                            const int tid2 = i + j;\n                            const int tid3 = i + j + k;\n\n                            if ((blockIdx.z + adjust[0])==scale[0])\n                                { out1[tid3] = in1[tid2] - in2[tid2]; }\n\n                        }\n                       \"\"\")\n\n    wavelet_filter = (1./16)*np.array([1,4,6,4,1], dtype=np.float32)    # Filter-bank for use in the a trous algorithm.\n    wavelet_filter = gpuarray.to_gpu_async(wavelet_filter)\n\n    # Initialises an empty array to store the detail coefficients.\n\n    detail_coeffs = gpuarray.empty([scale_count-scale_adjust, in1.shape[0], in1.shape[1]], np.float32)\n\n    # Determines whether the array is already on the GPU or not. If not, moves it to the GPU.\n\n    try:\n        gpu_in1 = gpuarray.to_gpu_async(in1.astype(np.float32))\n    except:\n        gpu_in1 = in1\n\n    # Sets up some working arrays on the GPU to prevent memory transfers.\n\n    gpu_tmp = gpuarray.empty_like(gpu_in1)\n    gpu_out1 = gpuarray.empty_like(gpu_in1)\n    gpu_out2 = gpuarray.empty_like(gpu_in1)\n\n    # Sets up some parameters required by the algorithm on the GPU.\n\n    gpu_scale = gpuarray.zeros([1], np.int32)\n    gpu_adjust = gpuarray.zeros([1], np.int32)\n    gpu_adjust += scale_adjust\n\n    # Fetches the a trous kernels and sets up the unique storing kernel.\n\n    gpu_a_trous_row_kernel, gpu_a_trous_col_kernel = gpu_a_trous()\n    gpu_store_detail_coeffs = ker.get_function(\"gpu_store_detail_coeffs\")\n\n    grid_rows = int(in1.shape[0]//32)\n    grid_cols = int(in1.shape[1]//32)\n\n    # The following loop, which iterates up to scale_adjust, applies the a trous algorithm to the scales which are\n    # considered insignificant. This is important as each set of wavelet coefficients depends on the last smoothed\n    # version of the input.\n\n    if scale_adjust>0:\n        for i in range(0, scale_adjust):\n            gpu_a_trous_row_kernel(gpu_in1, gpu_tmp, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n            gpu_a_trous_col_kernel(gpu_tmp, gpu_out1, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n            gpu_in1, gpu_out1 = gpu_out1, gpu_in1\n            gpu_scale += 1\n\n    # The meat of the algorithm - two sequential applications fo the a trous followed by determination and storing of\n    # the detail coefficients. C0 is reassigned the value of C on each loop - C0 is always the smoothest version of the\n    # input image.\n\n    for i in range(scale_adjust, scale_count):\n\n        gpu_a_trous_row_kernel(gpu_in1, gpu_tmp, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n        gpu_a_trous_col_kernel(gpu_tmp, gpu_out1, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))           # Approximation coefficients.\n\n        gpu_a_trous_row_kernel(gpu_out1, gpu_tmp, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))\n\n        gpu_a_trous_col_kernel(gpu_tmp, gpu_out2, wavelet_filter, gpu_scale,\n                                block=(32,32,1), grid=(grid_cols, grid_rows))           # Approximation coefficients.\n\n        gpu_store_detail_coeffs(gpu_in1, gpu_out2, detail_coeffs, gpu_scale, gpu_adjust,\n                                block=(32,32,1), grid=(grid_cols, grid_rows, int(scale_count))) # Detail coefficients.\n\n        gpu_in1, gpu_out1 = gpu_out1, gpu_in1\n        gpu_scale += 1\n\n    # Return values depend on mode. NOTE: store_smoothed does not work if the result stays on the gpu.\n\n    if store_on_gpu:\n        return detail_coeffs\n    elif store_smoothed:\n        return detail_coeffs.get(), gpu_in1.get()\n    else:\n        return detail_coeffs.get()", "label": 1}
{"code": "def update_all_catalogs_and_return_filepaths\n      does_rambafile_exist = Dir[RAMBAFILE_NAME].count > 0\n\n      if does_rambafile_exist\n        rambafile = YAML.load_file(RAMBAFILE_NAME)\n        catalogs = rambafile[CATALOGS_KEY]\n      end\n\n      terminator = CatalogTerminator.new\n      terminator.remove_all_catalogs\n\n      catalog_paths = [download_catalog(GENERAMBA_CATALOG_NAME, RAMBLER_CATALOG_REPO)]\n\n      if catalogs != nil && catalogs.count > 0\n        catalogs.each do |catalog_url|\n          catalog_name = catalog_url.split('://').last\n          catalog_name = catalog_name.gsub('/', '-');\n          catalog_paths.push(download_catalog(catalog_name, catalog_url))\n        end\n      end\n      return catalog_paths\n    end", "label": 4}
{"code": "def reload(self, *fields, **kw):\n\t\t\"\"\"Reload the entire document from the database, or refresh specific named top-level fields.\"\"\"\n\t\t\n\t\tDoc, collection, query, options = self._prepare_find(id=self.id, projection=fields, **kw)\n\t\tresult = collection.find_one(query, **options)\n\t\t\n\t\tif fields:  # Refresh only the requested data.\n\t\t\tfor k in result:  # TODO: Better merge algorithm.\n\t\t\t\tif k == ~Doc.id: continue\n\t\t\t\tself.__data__[k] = result[k]\n\t\telse:\n\t\t\tself.__data__ = result\n\t\t\n\t\treturn self", "label": 1}
{"code": "function(model, attr) {\n      var attrValidationSet = model.validation ? _.result(model, 'validation')[attr] || {} : {};\n\n      // If the validator is a function or a string, wrap it in a function validator\n      if (_.isFunction(attrValidationSet) || _.isString(attrValidationSet)) {\n        attrValidationSet = {\n          fn: attrValidationSet\n        };\n      }\n\n      // Stick the validator object into an array\n      if(!_.isArray(attrValidationSet)) {\n        attrValidationSet = [attrValidationSet];\n      }\n\n      // Reduces the array of validators into a new array with objects\n      // with a validation method to call, the value to validate against\n      // and the specified error message, if any\n      return _.reduce(attrValidationSet, function(memo, attrValidation) {\n        _.each(_.without(_.keys(attrValidation), 'msg', 'msgKey'), function(validator) {\n          memo.push({\n            fn: defaultValidators[validator],\n            val: attrValidation[validator],\n            msg: attrValidation.msg,\n            msgKey: attrValidation.msgKey\n          });\n        });\n        return memo;\n      }, []);\n    }", "label": 3}
{"code": "function (char) {\n                var\n                    parsedItem = this._parsedItem,\n                    result;\n                if (parsedItem) {\n                    result = parsedItem.parse(char);\n                    if (bitTest(result, PatternItem.PARSE_END_OF_PATTERN)) {\n                        parsedItem.finalize();\n                        this._parsedItem = null;\n                        // Remove the flag\n                        result = bitClear(result,\n                            PatternItem.PARSE_END_OF_PATTERN);\n                    }\n                } else {\n                    result = 0;\n                }\n                return result;\n            }", "label": 3}
{"code": "function (src) {\n        // https://github.com/Constellation/escodegen/issues/85\n        let ast = esprima.parse(src, {\n            range: true,\n            tokens: true,\n            comment: true\n        });\n        ast = escodegen.attachComments(ast, ast.comments, ast.tokens);\n        delete ast.tokens;\n        delete ast.comments;\n        return ast;\n    }", "label": 3}
{"code": "function AdapterFactory(injector) {\n    if (!injector.adapters) { return; }\n    var me = this;\n\n    this.adapterMap = {};\n    _.each(injector.adapterMap, function (adapterName, adapterType) {\n        var adapter = injector.adapters[adapterName];\n        if (adapter) {\n            me.adapterMap[adapterType + 'adapter'] = adapter;\n        }\n    });\n}", "label": 3}
{"code": "def get_logs(self, stdout=True, stderr=True, timestamps=False, tail='all',\n                 since=None):\n        \"\"\"\n        Get container logs.\n\n        This method does not support streaming, use :meth:`stream_logs` for\n        that.\n        \"\"\"\n        return self.inner().logs(\n            stdout=stdout, stderr=stderr, timestamps=timestamps, tail=tail,\n            since=since)", "label": 1}
{"code": "function convertGanglionArrayToBuffer (arr, data) {\n  for (let i = 0; i < k.OBCINumberOfChannelsGanglion; i++) {\n    data.writeInt16BE(arr[i] >> 8, (i * 3));\n    data.writeInt8(arr[i] & 255, (i * 3) + 2);\n  }\n}", "label": 3}
{"code": "public function setDevice($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Iot\\V1\\Device::class);\n        $this->device = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *Service) NewServer() *Server {\n\ts.RegisterSDK(Map)\n\n\tmux := s.ServeMux\n\tvim := Map.Path + \"/vimService\"\n\ts.sdk[vim] = s.sdk[vim25.Path]\n\tmux.HandleFunc(vim, s.ServeSDK)\n\tmux.HandleFunc(Map.Path+\"/vimServiceVersions.xml\", s.ServiceVersions)\n\tmux.HandleFunc(folderPrefix, s.ServeDatastore)\n\tmux.HandleFunc(nfcPrefix, ServeNFC)\n\tmux.HandleFunc(\"/about\", s.About)\n\n\tts := internal.NewUnstartedServer(mux, s.Listen)\n\taddr := ts.Listener.Addr().(*net.TCPAddr)\n\tport := strconv.Itoa(addr.Port)\n\tu := &url.URL{\n\t\tScheme: \"http\",\n\t\tHost:   net.JoinHostPort(defaultIP(addr), port),\n\t\tPath:   Map.Path,\n\t}\n\tif s.TLS != nil {\n\t\tu.Scheme += \"s\"\n\t}\n\n\t// Redirect clients to this http server, rather than HostSystem.Name\n\tMap.SessionManager().ServiceHostName = u.Host\n\n\t// Add vcsim config to OptionManager for use by SDK handlers (see lookup/simulator for example)\n\tm := Map.OptionManager()\n\tm.Setting = append(m.Setting,\n\t\t&types.OptionValue{\n\t\t\tKey:   \"vcsim.server.url\",\n\t\t\tValue: u.String(),\n\t\t},\n\t)\n\n\tu.User = url.UserPassword(\"user\", \"pass\")\n\n\tif s.TLS != nil {\n\t\tts.TLS = s.TLS\n\t\tts.TLS.ClientAuth = tls.RequestClientCert // Used by SessionManager.LoginExtensionByCertificate\n\t\tMap.SessionManager().TLSCert = func() string {\n\t\t\treturn base64.StdEncoding.EncodeToString(ts.TLS.Certificates[0].Certificate[0])\n\t\t}\n\t\tts.StartTLS()\n\t} else {\n\t\tts.Start()\n\t}\n\n\treturn &Server{\n\t\tServer: ts,\n\t\tURL:    u,\n\t}\n}", "label": 5}
{"code": "def creator(entry, config):\n        \"\"\"Preparing and creating script.\"\"\"\n        script = render(config.script, model=config.model, env=config.env, item=config.item)\n\n        temp = tempfile.NamedTemporaryFile(prefix=\"script-\", suffix=\".py\", mode='w+t', delete=False)\n        temp.writelines(script)\n        temp.close()\n\n        language = 'python' if 'type' not in entry else entry['type']\n        template_file = os.path.join(os.path.dirname(__file__), 'templates/%s-script.sh.j2' % language)\n\n        with open(template_file) as handle:\n            template = handle.read()\n            config.script = render(template, script=temp.name)\n\n        return Script(config)", "label": 1}
{"code": "public function setFollowupIntentInfo($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dialogflow\\V2\\Intent\\FollowupIntentInfo::class);\n        $this->followup_intent_info = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function prepareMeasureForLine(cm, line) {\n    var lineN = lineNo(line);\n    var view = findViewForLine(cm, lineN);\n    if (view && !view.text)\n      view = null;\n    else if (view && view.changes)\n      updateLineForChanges(cm, view, lineN, getDimensions(cm));\n    if (!view)\n      view = updateExternalMeasurement(cm, line);\n\n    var info = mapFromLineView(view, line, lineN);\n    return {\n      line: line, view: view, rect: null,\n      map: info.map, cache: info.cache, before: info.before,\n      hasHeights: false\n    };\n  }", "label": 3}
{"code": "def paging\n      page = 0\n      results = []\n      loop do\n        page += 1\n        current = yield(page)\n\n        results += current\n\n        break if (current || []).count < page_size # no more results\n      end\n\n      return results\n    end", "label": 4}
{"code": "def normalize_path(url)\n      url = URI(url)\n      (url.path.start_with?('/') ? url.path : '/' + url.path) +\n        (url.query ? \"?#{sort_query_params(url.query)}\" : '')\n    end", "label": 4}
{"code": "function _gpfAttributesCheckAppliedOnBaseClass (classDefinition, ExpectedBaseClass) {\n    var Extend = classDefinition._extend;\n    if (Extend !== ExpectedBaseClass) {\n        _gpfAttributesCheckAppliedOnBaseClassIsInstanceOf(Extend.prototype, ExpectedBaseClass);\n    }\n}", "label": 3}
{"code": "public function setCommonDefaults(array $config)\n    {\n        $config += [\n            'authCache' => new MemoryCacheItemPool(),\n            'authCacheOptions' => [],\n            'credentialsFetcher' => null,\n            'keyFile' => null,\n            'requestTimeout' => null,\n            'retries' => 3,\n            'scopes' => null\n        ];\n\n        if ($config['credentialsFetcher'] && !$config['credentialsFetcher'] instanceof FetchAuthTokenInterface) {\n            throw new \\InvalidArgumentException('credentialsFetcher must implement FetchAuthTokenInterface.');\n        }\n\n        if (!$config['authCache'] instanceof CacheItemPoolInterface) {\n            throw new \\InvalidArgumentException('authCache must implement CacheItemPoolInterface.');\n        }\n\n        $this->authCache = $config['authCache'];\n        $this->authCacheOptions = $config['authCacheOptions'];\n        $this->credentialsFetcher = $config['credentialsFetcher'];\n        $this->retries = $config['retries'];\n        $this->scopes = $config['scopes'];\n        $this->keyFile = $config['keyFile'];\n        $this->requestTimeout = $config['requestTimeout'];\n    }", "label": 2}
{"code": "func EthernetCardTypes() VirtualDeviceList {\n\treturn VirtualDeviceList([]types.BaseVirtualDevice{\n\t\t&types.VirtualE1000{},\n\t\t&types.VirtualE1000e{},\n\t\t&types.VirtualVmxnet2{},\n\t\t&types.VirtualVmxnet3{},\n\t\t&types.VirtualPCNet32{},\n\t\t&types.VirtualSriovEthernetCard{},\n\t}).Select(func(device types.BaseVirtualDevice) bool {\n\t\tc := device.(types.BaseVirtualEthernetCard).GetVirtualEthernetCard()\n\t\tc.GetVirtualDevice().Key = -1\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "function uploadToSentry(projectSlug, orgSlug, releaseVersion, assets) {\n  var releaseEndpoint = makeUrl(projectSlug, orgSlug);\n  var uploadEndpoint = releaseEndpoint + releaseVersion + '/files/';\n\n  createRelease(releaseEndpoint, releaseVersion)\n    .then(function() {\n      return Promise.all(assets.map(uploadFile.bind(null,\n                                                    uploadEndpoint,\n                                                    releaseVersion\n                                                    )));\n    })\n    .catch(function(e) {\n      console.log('Release failed with error: ', e);\n    });\n}", "label": 3}
{"code": "func (f *Fpdf) parsejpg(r io.Reader) (info *ImageInfoType) {\n\tinfo = f.newImageInfo()\n\tvar (\n\t\tdata bytes.Buffer\n\t\terr  error\n\t)\n\t_, err = data.ReadFrom(r)\n\tif err != nil {\n\t\tf.err = err\n\t\treturn\n\t}\n\tinfo.data = data.Bytes()\n\n\tconfig, err := jpeg.DecodeConfig(bytes.NewReader(info.data))\n\tif err != nil {\n\t\tf.err = err\n\t\treturn\n\t}\n\tinfo.w = float64(config.Width)\n\tinfo.h = float64(config.Height)\n\tinfo.f = \"DCTDecode\"\n\tinfo.bpc = 8\n\tswitch config.ColorModel {\n\tcase color.GrayModel:\n\t\tinfo.cs = \"DeviceGray\"\n\tcase color.YCbCrModel:\n\t\tinfo.cs = \"DeviceRGB\"\n\tcase color.CMYKModel:\n\t\tinfo.cs = \"DeviceCMYK\"\n\tdefault:\n\t\tf.err = fmt.Errorf(\"image JPEG buffer has unsupported color space (%v)\", config.ColorModel)\n\t\treturn\n\t}\n\treturn\n}", "label": 5}
{"code": "public function setOriginalRequest($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\Admin\\V2\\CreateTableFromSnapshotRequest::class);\n        $this->original_request = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function createIqId()\n    {\n      $iqId = $this->iqCounter;\n      $this->iqCounter++;\n      $id = dechex($iqId);\n\n      return $id;\n    }", "label": 2}
{"code": "public T next() {\r\n    if (nextToken == null) {\r\n      nextToken = getNext();\r\n    }\r\n    T result = nextToken;\r\n    nextToken = null;\r\n    if (result == null) {\r\n      throw new NoSuchElementException();\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "def initialize_communities_bucket():\n    \"\"\"Initialize the communities file bucket.\n\n    :raises: `invenio_files_rest.errors.FilesException`\n    \"\"\"\n    bucket_id = UUID(current_app.config['COMMUNITIES_BUCKET_UUID'])\n\n    if Bucket.query.get(bucket_id):\n        raise FilesException(\"Bucket with UUID {} already exists.\".format(\n            bucket_id))\n    else:\n        storage_class = current_app.config['FILES_REST_DEFAULT_STORAGE_CLASS']\n        location = Location.get_default()\n        bucket = Bucket(id=bucket_id,\n                        location=location,\n                        default_storage_class=storage_class)\n        db.session.add(bucket)\n        db.session.commit()", "label": 1}
{"code": "public function enough_positionals( $args ) {\n\t\t$positional = $this->query_spec(\n\t\t\tarray(\n\t\t\t\t'type'     => 'positional',\n\t\t\t\t'optional' => false,\n\t\t\t)\n\t\t);\n\n\t\treturn count( $args ) >= count( $positional );\n\t}", "label": 2}
{"code": "def nrfa_metadata():\n    \"\"\"\n    Return metadata on the NRFA data.\n\n    Returned metadata is a dict with the following elements:\n\n    - `url`: string with NRFA data download URL\n    - `version`: string with NRFA version number, e.g. '3.3.4'\n    - `published_on`: datetime of data release/publication (only month and year are accurate, rest should be ignored)\n    - `downloaded_on`: datetime of last download\n\n    :return: metadata\n    :rtype: dict\n    \"\"\"\n    result = {\n        'url': config.get('nrfa', 'url', fallback=None) or None,  # Empty strings '' become None\n        'version': config.get('nrfa', 'version', fallback=None) or None,\n        'published_on': config.get_datetime('nrfa', 'published_on', fallback=None) or None,\n        'downloaded_on': config.get_datetime('nrfa', 'downloaded_on', fallback=None) or None\n    }\n    return result", "label": 1}
{"code": "def convert_ligatures(text_string):\n    '''\n    Coverts Latin character references within text_string to their corresponding unicode characters\n    and returns converted string as type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a string or NoneType not be passed as an argument\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        for i in range(0, len(LIGATURES)):\n            text_string = text_string.replace(LIGATURES[str(i)][\"ligature\"], LIGATURES[str(i)][\"term\"])\n        return text_string\n    else:\n        raise InputError(\"none type or string not passed as an argument\")", "label": 1}
{"code": "def inertia_tensor(geom, masses):\n    \"\"\"Generate the 3x3 moment-of-inertia tensor.\n\n    Compute the 3x3 moment-of-inertia tensor for the\n    provided geometry and atomic masses.  Always recenters the\n    geometry to the center of mass as the first step.\n\n    Reference for inertia tensor: [Kro92]_, Eq. (2.26)\n\n    .. todo:: Replace cite eventually with link to exposition in user guide.\n\n    Parameters\n    ----------\n    geom\n        length-3N |npfloat_| --\n        Coordinates of the atoms\n\n    masses\n        length-N OR length-3N |npfloat_| --\n        Atomic masses of the atoms. Length-3N option is to allow calculation of\n        a per-coordinate perturbed value.\n\n    Returns\n    -------\n    tensor\n        3 x 3 |npfloat_| --\n        Moment of inertia tensor for the system\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If shapes of `geom` & `masses` are inconsistent\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Center the geometry. Takes care of any improper shapes of geom or\n    #  masses via the internal call to 'ctr_mass' within the call to 'ctr_geom'\n    geom = ctr_geom(geom, masses)\n\n    # Expand the masses if required. Shape should only ever be (N,) or (3N,),\n    #  else would raise an exception within the above 'ctr_geom' call\n    if geom.shape[0] == 3*masses.shape[0]:\n        masses = masses.repeat(3)\n    ## end if\n\n    # Initialize the tensor matrix\n    tensor = np.zeros((3,3))\n\n    # Fill the matrix\n    for i in range(3):\n        for j in range(i,3):\n            if i == j:\n                # On-diagonal element; calculate indices to include\n                ind = np.concatenate([np.array(list(map(lambda v: v % 3,\n                                        range(i+1, i+3)))) + o for o in\n                                        range(0,geom.shape[0],3)])\n\n                # Calculate the tensor element\n                tensor[i,i] = np.multiply(np.square(geom[ind]),\n                                                        masses[ind]).sum()\n            else:\n                # Off-diagonal element; calculate the indices\n                ind_i = np.array(range(i,geom.shape[0]+i,3))\n                ind_j = np.array(range(j,geom.shape[0]+j,3))\n\n                # Calculate the tensor element and its symmetric partner\n                tensor[i,j] = np.multiply(\n                        np.sqrt(np.multiply(masses[ind_i], masses[ind_j])) ,\n                        np.multiply(geom[ind_i], geom[ind_j]) ).sum() * -1\n                tensor[j,i] = tensor[i,j]\n            ## end if\n        ## next j\n    ## next i\n\n    # Return the tensor\n    return tensor", "label": 1}
{"code": "function(message, title, options){\n            if(system.isString(this.MessageBox)){\n                return dialog.show(this.MessageBox, [\n                    message,\n                    title || MessageBox.defaultTitle,\n                    options || MessageBox.defaultOptions\n                ]);\n            }\n\n            return dialog.show(new this.MessageBox(message, title, options));\n        }", "label": 3}
{"code": "public NestedDef getNested(String name)\r\n    {\r\n        NestedDef nestedDef = null;\r\n\r\n        for (Iterator it = _nested.iterator(); it.hasNext(); )\r\n        {\r\n            nestedDef = (NestedDef)it.next();\r\n            if (nestedDef.getName().equals(name))\r\n            {\r\n                return nestedDef;\r\n            }\r\n        }\r\n        return null;\r\n    }", "label": 0}
{"code": "def persist_atomic_operations(operations)\n      if persisted? && operations && !operations.empty?\n        selector = atomic_selector\n        _root.collection.find(selector).update_one(positionally(selector, operations), session: _session)\n      end\n    end", "label": 4}
{"code": "func PgUserMappingByOid(db XODB, oid pgtypes.Oid) (*PgUserMapping, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, umuser, umserver, umoptions ` +\n\t\t`FROM pg_catalog.pg_user_mapping ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpum := PgUserMapping{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pum.Tableoid, &pum.Cmax, &pum.Xmax, &pum.Cmin, &pum.Xmin, &pum.Oid, &pum.Ctid, &pum.Umuser, &pum.Umserver, &pum.Umoptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pum, nil\n}", "label": 5}
{"code": "function() {\n  if (! (this instanceof Chain)) {\n    return new Chain();\n  }\n\n  this.validators = [];\n  this.target = null;\n  this.isOptional = false;\n  this.isImmutable = false;\n  this.isUpdateRequired = false;\n  this._validatorCount = 0;\n  this._numItemsValidator = null;\n}", "label": 3}
{"code": "public function removeDirectory(string $directory)\n    {\n        $search = rtrim(strtr($directory, '\\\\', '/'), '/');\n\n        return $this->setDirectories(array_filter($this->getDirectories(), function ($item) use ($search) {\n            return rtrim(strtr($item, '\\\\', '/'), '/') !== $search;\n        }));\n    }", "label": 2}
{"code": "def render_bash_options(self):\n        \"\"\"Rendering Bash options.\"\"\"\n        options = ''\n        if self.config.debug:\n            options += \"set -x\\n\"\n        if self.config.strict:\n            options += \"set -euo pipefail\\n\"\n        return options", "label": 1}
{"code": "def visible?\n      msg = '#visible? behavior will be changing slightly, consider switching to #present? ' \\\n            '(more details: http://watir.com/element-existentialism/)'\n      Watir.logger.warn msg, ids: [:visible_element]\n      displayed = display_check\n      if displayed.nil? && display_check\n        Watir.logger.deprecate 'Checking `#visible? == false` to determine a stale element',\n                               '`#stale? == true`',\n                               reference: 'http://watir.com/staleness-changes',\n                               ids: [:stale_visible]\n      end\n      raise unknown_exception if displayed.nil?\n\n      displayed\n    end", "label": 4}
{"code": "func NotZerof(t TestingT, i interface{}, msg string, args ...interface{}) bool {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn NotZero(t, i, append([]interface{}{msg}, args...)...)\n}", "label": 5}
{"code": "public void sendMessageToAgents(String[] agent_name, String msgtype,\n            Object message_content, Connector connector) {\n        HashMap<String, Object> hm = new HashMap<String, Object>();\n        hm.put(\"performative\", msgtype);\n        hm.put(SFipa.CONTENT, message_content);\n        IComponentIdentifier[] ici = new IComponentIdentifier[agent_name.length];\n        for (int i = 0; i < agent_name.length; i++) {\n            ici[i] = (IComponentIdentifier) connector.getAgentID(agent_name[i]);\n        }\n        ((IMessageService) connector.getMessageService()).deliverMessage(hm,\n                \"fipa\", ici);\n    }", "label": 0}
{"code": "def call(member, ctx)\n      (@only ? @only.call(member, ctx) : true) &&\n      (@except ? !@except.call(member, ctx) : true)\n    end", "label": 4}
{"code": "public static configstatus[] get(nitro_service service) throws Exception{\n\t\tconfigstatus obj = new configstatus();\n\t\tconfigstatus[] response = (configstatus[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function _gpfIsImplementedBy (inspectedObject, interfaceDefinition) {\n    var member,\n        memberReference,\n        memberValue,\n        memberType;\n    /*\n     * IMPORTANT note: we test the object itself (i.e. own members and the prototype).\n     * That's why the hasOwnProperty is skipped\n     */\n    /*jslint forin:true*/\n    for (member in interfaceDefinition.prototype) {\n        if (\"constructor\" === member) { // Object\n            continue;\n        }\n        memberReference = interfaceDefinition.prototype[member];\n        memberValue = inspectedObject[member];\n        memberType = typeof memberValue;\n        if (typeof memberReference !== memberType) {\n            return false;\n        }\n        if (\"function\" === memberType && memberReference.length !== memberValue.length) {\n            return false;\n        }\n    }\n    return true;\n}", "label": 3}
{"code": "func (t *Text) Size() (int, int) {\n\tif len(t.text) != 0 {\n\t\treturn t.width, t.height\n\t}\n\treturn 0, 0\n}", "label": 5}
{"code": "public static void validateZip(File file) throws IOException {\n    ZipInputStream zipInput = new ZipInputStream(new FileInputStream(file));\n    ZipEntry zipEntry = zipInput.getNextEntry();\n\n    while (zipEntry != null) {\n      zipEntry = zipInput.getNextEntry();\n    }\n\n    try {\n      if (zipInput != null) {\n        zipInput.close();\n      }\n    } catch (IOException e) {\n    }\n  }", "label": 0}
{"code": "func (ca *CertAuthorityV2) Signers() ([]ssh.Signer, error) {\n\tout := make([]ssh.Signer, 0, len(ca.Spec.SigningKeys))\n\tfor _, keyBytes := range ca.Spec.SigningKeys {\n\t\tsigner, err := ssh.ParsePrivateKey(keyBytes)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tout = append(out, signer)\n\t}\n\treturn out, nil\n}", "label": 5}
{"code": "function getOptionsObject () {\n    if (parts.length > 1) {\n      // Options should be appended to the last hosts querystring\n      return qs.parse(url.parse(parts[parts.length - 1]).query);\n    }\n\n    return {};\n  }", "label": 3}
{"code": "def fetch_tag_shas_async(tags)\n      i = 0\n      threads = []\n      print_in_same_line(\"Fetching SHAs for tags: #{i}/#{tags.count}\\r\") if @options[:verbose]\n\n      tags.each_slice(MAX_THREAD_NUMBER) do |tags_slice|\n        tags_slice.each do |tag|\n          threads << Thread.new do\n            # Use oldest commit because comparing two arbitrary tags may be diverged\n            commits_in_tag = fetch_compare(oldest_commit[\"sha\"], tag[\"name\"])\n            tag[\"shas_in_tag\"] = commits_in_tag[\"commits\"].collect { |commit| commit[\"sha\"] }\n            print_in_same_line(\"Fetching SHAs for tags: #{i + 1}/#{tags.count}\") if @options[:verbose]\n            i += 1\n          end\n        end\n        threads.each(&:join)\n        threads = []\n      end\n\n      # to clear line from prev print\n      print_empty_line\n\n      Helper.log.info \"Fetching SHAs for tags: #{i}\"\n      nil\n    end", "label": 4}
{"code": "function processUncompressedData (o) {\n  // Resets the packet counter back to zero\n  o.lastSampleNumber = k.OBCIGanglionByteIdUncompressed;  // used to find dropped packets\n\n  for (let i = 0; i < 4; i++) {\n    o.decompressedSamples[0][i] = utilitiesModule.interpret24bitAsInt32(o.rawDataPacket.slice(1 + (i * 3), 1 + (i * 3) + 3));  // seed the decompressor\n  }\n\n  return [buildSample(0, o.decompressedSamples[0], o.sendCounts)];\n}", "label": 3}
{"code": "def add_access_control_attributes(af_object)\n        af_object.visibility = attributes[:visibility] unless attributes[:visibility].blank?\n        af_object.read_users = attributes[:read_users] unless attributes[:read_users].blank?\n        af_object.edit_users = attributes[:edit_users] unless attributes[:edit_users].blank?\n        af_object.read_groups = attributes[:read_groups] unless attributes[:read_groups].blank?\n        af_object.edit_groups = attributes[:edit_groups] unless attributes[:edit_groups].blank?\n      end", "label": 4}
{"code": "def en_last(self):\n        \"\"\" Report the energies from the last SCF present in the output.\n\n        Returns a |dict| providing the various energy values from the\n        last SCF cycle performed in the output. Keys are those of\n        :attr:`~opan.output.OrcaOutput.p_en`.\n        Any energy value not relevant to the parsed\n        output is assigned as |None|.\n\n        Returns\n        -------\n        last_ens\n            |dict| of |npfloat_|--\n            Energies from the last SCF present in the output.\n\n        \"\"\"\n\n        # Initialize the return dict\n        last_ens = dict()\n\n        # Iterate and store\n        for (k,l) in self.en.items():\n            last_ens.update({ k : l[-1] if l != [] else None })\n        ##next (k,l)\n\n        # Should be ready to return?\n        return last_ens", "label": 1}
{"code": "private function validateLogLevel($level)\n    {\n        $map = Logger::getLogLevelMap();\n        $level = (string) $level;\n\n        if (isset($map[$level]) || isset(array_flip($map)[strtoupper($level)])) {\n            return true;\n        }\n\n        throw new InvalidArgumentException(\"Severity level '$level' is not defined.\");\n    }", "label": 2}
{"code": "def EXTRA_LOGGING(self):\n        \"\"\"\n        lista modulos con los distintos niveles a logear y su\n        nivel de debug\n\n        Por ejemplo:\n\n            [Logs]\n            EXTRA_LOGGING = oscar.paypal:DEBUG, django.db:INFO\n\n        \"\"\"\n\n        input_text = get('EXTRA_LOGGING', '')\n        modules = input_text.split(',')\n        if input_text:\n            modules = input_text.split(',')\n            modules = [x.split(':') for x in modules]\n        else:\n            modules = []\n        return modules", "label": 1}
{"code": "public void setTileUrls(List<String> tileUrls) {\n\t\tthis.tileUrls = tileUrls;\n\t\tif (null != urlStrategy) {\n\t\t\turlStrategy.setUrls(tileUrls);\n\t\t}\n\t}", "label": 0}
{"code": "func NewServerIdentity(clt *AuthServer, hostID string, role teleport.Role) (*Identity, error) {\n\tkeys, err := clt.GenerateServerKeys(GenerateServerKeysRequest{\n\t\tHostID:   hostID,\n\t\tNodeName: hostID,\n\t\tRoles:    teleport.Roles{teleport.RoleAuth},\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn ReadIdentityFromKeyPair(keys)\n}", "label": 5}
{"code": "def canonical_ops(ops):\n    ''' Returns the given operations array sorted with duplicates removed.\n\n    @param ops checker.Ops\n    @return: checker.Ops\n    '''\n    new_ops = sorted(set(ops), key=lambda x: (x.entity, x.action))\n    return new_ops", "label": 1}
{"code": "def rot_consts(geom, masses, units=_EURC.INV_INERTIA, on_tol=_DEF.ORTHONORM_TOL):\n    \"\"\"Rotational constants for a given molecular system.\n\n    Calculates the rotational constants for the provided system with numerical\n    value given in the units provided in `units`.  The orthnormality tolerance\n    `on_tol` is required in order to be passed through to the\n    :func:`principals` function.\n\n    If the system is linear or a single atom, the effectively-zero principal\n    moments of inertia will be assigned values of\n    :data:`opan.const.PRM.ZERO_MOMENT_TOL`\n    before transformation into the appropriate rotational constant units.\n\n    The moments of inertia are always sorted in increasing order as\n    :math:`0 \\\\leq I_A \\\\leq I_B \\\\leq I_C`; the rotational constants\n    calculated from these will thus always be in **decreasing** order\n    as :math:`B_A \\\\geq B_B \\\\geq B_C`, retaining the\n    ordering and association with the three principal ``axes[:,i]`` generated\n    by :func:`principals`.\n\n    Parameters\n    ----------\n    geom\n        length-3N |npfloat_| --\n        Coordinates of the atoms\n\n    masses\n        length-N OR length-3N |npfloat_| --\n        Atomic masses of the atoms. Length-3N option is to allow calculation of\n        a per-coordinate perturbed value.\n\n    units\n        :class:`~opan.const.EnumUnitsRotConst`, optional --\n        Enum value indicating the desired units of the output rotational\n        constants. Default is :data:`~opan.const.EnumUnitsRotConst.INV_INERTIA`\n        :math:`\\\\left(1\\\\over \\\\mathrm{uB^2}\\\\right)`\n\n    on_tol\n        |npfloat_|,  optional --\n        Tolerance for deviation from unity/zero for principal axis dot\n        products, within which axes are considered orthonormal. Default is\n        :data:`opan.const.DEF.ORTHONORM_TOL`\n\n    Returns\n    -------\n    rc\n        length-3 |npfloat_| --\n        Vector of rotational constants in the indicated units\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from ..const import EnumTopType as ETT, EnumUnitsRotConst as EURC, PRM, PHYS\n\n    # Ensure units are valid\n    if not units in EURC:\n        raise ValueError(\"'{0}' is not a valid units value\".format(units))\n    ## end if\n\n    # Retrieve the moments, axes and top type. Geom and masses are proofed\n    #  internally in this call.\n    mom, ax, top = principals(geom, masses, on_tol)\n\n    # Check for special cases\n    if top == ETT.ATOM:\n        # All moments are zero; set to zero-moment threshold\n        mom = np.repeat(PRM.ZERO_MOMENT_TOL, 3)\n    elif top == ETT.LINEAR:\n        # First moment is zero; set to zero-moment threshold\n        mom[0] = PRM.ZERO_MOMENT_TOL\n    ## end if\n\n    # Calculate the values in the indicated units\n    if units == EURC.INV_INERTIA:            # 1/(amu*B^2)\n        rc = 1.0 / (2.0 * mom)\n    elif units == EURC.ANGFREQ_ATOMIC:       # 1/Ta\n        rc = PHYS.PLANCK_BAR / (2.0 * mom * PHYS.ME_PER_AMU)\n    elif units == EURC.ANGFREQ_SECS:      # 1/s\n        rc = PHYS.PLANCK_BAR / (2.0 * mom * PHYS.ME_PER_AMU) / PHYS.SEC_PER_TA\n    elif units == EURC.CYCFREQ_ATOMIC:    # cyc/Ta\n        rc = PHYS.PLANCK_BAR / (4.0 * np.pi * mom * PHYS.ME_PER_AMU)\n    elif units == EURC.CYCFREQ_HZ:        # cyc/s\n        rc = PHYS.PLANCK_BAR / (4.0 * np.pi * mom * PHYS.ME_PER_AMU) / \\\n                                                            PHYS.SEC_PER_TA\n    elif units == EURC.CYCFREQ_MHZ:       # Mcyc/s\n        rc = PHYS.PLANCK_BAR / (4.0 * np.pi * mom * PHYS.ME_PER_AMU) / \\\n                                                    PHYS.SEC_PER_TA / 1.0e6\n    elif units == EURC.WAVENUM_ATOMIC:       # cyc/B\n        rc = PHYS.PLANCK / (mom * PHYS.ME_PER_AMU) / \\\n            (8.0 * np.pi**2.0 * PHYS.LIGHT_SPEED)\n    elif units == EURC.WAVENUM_CM:           # cyc/cm\n        rc = PHYS.PLANCK / (mom * PHYS.ME_PER_AMU) / \\\n            (8.0 * np.pi**2.0 * PHYS.LIGHT_SPEED * PHYS.ANG_PER_BOHR) * 1.0e8\n    else:               # pragma: no cover -- Valid units; not implemented\n        raise NotImplementedError(\"Units conversion not yet implemented.\")\n    ## end if\n\n    # Return the result\n    return rc", "label": 1}
{"code": "protected function checkSameSlotForKeys(array $keys)\n    {\n        if (!$count = count($keys)) {\n            return false;\n        }\n\n        $currentSlot = $this->getSlotByKey($keys[0]);\n\n        for ($i = 1; $i < $count; ++$i) {\n            $nextSlot = $this->getSlotByKey($keys[$i]);\n\n            if ($currentSlot !== $nextSlot) {\n                return false;\n            }\n\n            $currentSlot = $nextSlot;\n        }\n\n        return true;\n    }", "label": 2}
{"code": "function (ports) {\n\t\n\tvar port = ports[0];\n\n\tvar list = '';\n\tfor (var i=0; i < ports.length; i++) {\n\t\tlist += (ports[i] + ', ');\n\t\tdelete l_ports[ports[i]];\n\t}\n\n\tLOG.warn('release ports: ' + list, 'SR.Monitor');\n\t\n\t// remove all other ports associated with this port\n\tfor (var i in l_ports) {\n\t\tif (l_ports[i] === port) {\n\t\t\tLOG.warn('release port: ' + i, 'SR.Monitor');\n\t\t\tdelete l_ports[i];\n\t\t}\n\t}\n}", "label": 3}
{"code": "function(kind) {\n            ko.bindingHandlers[kind] = {\n                init: function() {\n                    return { controlsDescendantBindings: true };\n                },\n                update: function(element, valueAccessor, allBindingsAccessor, viewModel, bindingContext) {\n                    var settings = widget.getSettings(valueAccessor);\n                    settings.kind = kind;\n                    extractParts(element, settings);\n                    widget.create(element, settings, bindingContext, true);\n                }\n            };\n\n            ko.virtualElements.allowedBindings[kind] = true;\n            composition.composeBindings.push(kind + ':');\n        }", "label": 3}
{"code": "func OptionKVOpts(opts map[string]string) Option {\n\treturn func(c *Config) {\n\t\tif opts[\"kv.cacertfile\"] != \"\" && opts[\"kv.certfile\"] != \"\" && opts[\"kv.keyfile\"] != \"\" {\n\t\t\tlogrus.Info(\"Option Initializing KV with TLS\")\n\t\t\ttlsConfig, err := tlsconfig.Client(tlsconfig.Options{\n\t\t\t\tCAFile:   opts[\"kv.cacertfile\"],\n\t\t\t\tCertFile: opts[\"kv.certfile\"],\n\t\t\t\tKeyFile:  opts[\"kv.keyfile\"],\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"Unable to set up TLS: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif _, ok := c.Scopes[datastore.GlobalScope]; !ok {\n\t\t\t\tc.Scopes[datastore.GlobalScope] = &datastore.ScopeCfg{}\n\t\t\t}\n\t\t\tif c.Scopes[datastore.GlobalScope].Client.Config == nil {\n\t\t\t\tc.Scopes[datastore.GlobalScope].Client.Config = &store.Config{TLS: tlsConfig}\n\t\t\t} else {\n\t\t\t\tc.Scopes[datastore.GlobalScope].Client.Config.TLS = tlsConfig\n\t\t\t}\n\t\t\t// Workaround libkv/etcd bug for https\n\t\t\tc.Scopes[datastore.GlobalScope].Client.Config.ClientTLS = &store.ClientTLSConfig{\n\t\t\t\tCACertFile: opts[\"kv.cacertfile\"],\n\t\t\t\tCertFile:   opts[\"kv.certfile\"],\n\t\t\t\tKeyFile:    opts[\"kv.keyfile\"],\n\t\t\t}\n\t\t} else {\n\t\t\tlogrus.Info(\"Option Initializing KV without TLS\")\n\t\t}\n\t}\n}", "label": 5}
{"code": "def insert_worksheet(index=0, options={})\n      worksheet = Worksheet.new(self, options)\n      @worksheets.delete_at(@worksheets.size - 1)\n      @worksheets.insert(index, worksheet)\n      yield worksheet if block_given?\n      worksheet\n    end", "label": 4}
{"code": "public function attach(array $files)\n    {\n        foreach ($files as $key => $file) {\n            if (is_array($file)) {\n                $file = new UploadedFile($file['path'], basename($file['path']), $file['mime'], $file['size']);\n            } elseif (is_string($file)) {\n                $finfo = finfo_open(FILEINFO_MIME_TYPE);\n\n                $file = new UploadedFile($file, basename($file), finfo_file($finfo, $file), $this->files->size($file));\n            } elseif (! $file instanceof UploadedFile) {\n                continue;\n            }\n\n            $this->uploads[$key] = $file;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function(config, baseUrl){\n            var pluginIds = system.keys(config);\n            baseUrl = baseUrl || 'plugins/';\n\n            if(baseUrl.indexOf('/', baseUrl.length - 1) === -1){\n                baseUrl += '/';\n            }\n\n            for(var i = 0; i < pluginIds.length; i++){\n                var key = pluginIds[i];\n                allPluginIds.push(baseUrl + key);\n                allPluginConfigs.push(config[key]);\n            }\n        }", "label": 3}
{"code": "function contains(dirs, p) {\n    if (!Array.isArray(dirs)) dirs = [dirs];\n    return dirs.some(dir => {\n      return indir(dir, p);\n    });\n  }", "label": 3}
{"code": "public function runQuery(JobConfigurationInterface $query, array $options = [])\n    {\n        $queryResultsOptions = $this->pluckArray([\n            'maxResults',\n            'startIndex',\n            'timeoutMs',\n            'maxRetries'\n        ], $options);\n        $queryResultsOptions['initialTimeoutMs'] = 10000;\n\n        $queryResults = $this->startQuery(\n            $query,\n            $options\n        )->queryResults($queryResultsOptions + $options);\n        $queryResults->waitUntilComplete();\n        return $queryResults;\n    }", "label": 2}
{"code": "public function logger($name, array $options = [])\n    {\n        return new Logger(\n            $this->connection,\n            $name,\n            $this->projectId,\n            isset($options['resource']) ? $options['resource'] : null,\n            isset($options['labels']) ? $options['labels'] : null\n        );\n    }", "label": 2}
{"code": "func applyString(src string, target *string) bool {\n\tif src != \"\" {\n\t\t*target = src\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "function deploy(contract, callback, contractMap) {\n  // Reuse existing contract address\n  if (config.deployedContracts.hasOwnProperty(contract.name)) {\n    contract.address = config.deployedContracts[contract.name];\n    return callback(null, contract);\n  }\n\n  linkBytecode(contract, contractMap);\n\n  // Deploy a new one\n  var params = resolveConstructorParams(contract, contractMap);\n  logDebug('Constructor params ' + contract.name + ':', params);\n  if(contract.bytecode && !contract.bytecode.startsWith('0x')) {\n    contract.bytecode = '0x' + contract.bytecode;\n  }\n  params.push({\n    from: config.from,\n    data: contract.bytecode,\n    gas: config.gasLimit,\n  });\n  params.push(function (err, deployed) {\n    if (err) {\n      return callback(err);\n    }\n    if (typeof deployed.address !== 'undefined') {\n      contract.address = deployed.address;\n      return callback(null, contract);\n    }\n  });\n\n  var web3Contract = web3.eth.contract(contract.abi);\n  web3Contract.new.apply(web3Contract, params);\n}", "label": 3}
{"code": "public function buildSlotsMap()\n    {\n        $this->slotsMap = array();\n\n        foreach ($this->pool as $connectionID => $connection) {\n            $parameters = $connection->getParameters();\n\n            if (!isset($parameters->slots)) {\n                continue;\n            }\n\n            foreach (explode(',', $parameters->slots) as $slotRange) {\n                $slots = explode('-', $slotRange, 2);\n\n                if (!isset($slots[1])) {\n                    $slots[1] = $slots[0];\n                }\n\n                $this->setSlots($slots[0], $slots[1], $connectionID);\n            }\n        }\n\n        return $this->slotsMap;\n    }", "label": 2}
{"code": "def get(self, name=None):\n        \"\"\"\n        Returns the plugin class object with the given name.\n        Or if a name is not given, the complete plugin dictionary is returned.\n\n        :param name: Name of a plugin\n        :return: None, single plugin or dictionary of plugins\n        \"\"\"\n        if name is None:\n            return self._classes\n        else:\n            if name not in self._classes.keys():\n                return None\n            else:\n                return self._classes[name]", "label": 1}
{"code": "def exists?(service_name)\n      open_service(service_name, SC_MANAGER_CONNECT, SERVICE_QUERY_STATUS) do |_|\n        true\n      end\n    rescue Puppet::Util::Windows::Error => e\n      return false if e.code == ERROR_SERVICE_DOES_NOT_EXIST\n      raise e\n    end", "label": 4}
{"code": "okhttp3.Response delete(String url, Map<String, Object> params)\n            throws RequestException, LocalOperationException {\n        okhttp3.Request request = new okhttp3.Request.Builder()\n                .url(getFullUrl(url))\n                .delete(getBody(toPayload(params), null))\n                .addHeader(\"Transloadit-Client\", version)\n                .build();\n\n        try {\n            return httpClient.newCall(request).execute();\n        } catch (IOException e) {\n            throw new RequestException(e);\n        }\n    }", "label": 0}
{"code": "public Object copy(final Object obj, PersistenceBroker broker)\r\n\t\t\tthrows ObjectCopyException\r\n\t{\r\n\t\tObjectOutputStream oos = null;\r\n\t\tObjectInputStream ois = null;\r\n\t\ttry\r\n\t\t{\r\n\t\t\tfinal ByteArrayOutputStream bos = new ByteArrayOutputStream();\r\n\t\t\toos = new ObjectOutputStream(bos);\r\n\t\t\t// serialize and pass the object\r\n\t\t\toos.writeObject(obj);\r\n\t\t\toos.flush();\r\n\t\t\tfinal ByteArrayInputStream bin =\r\n\t\t\t\t\tnew ByteArrayInputStream(bos.toByteArray());\r\n\t\t\tois = new ObjectInputStream(bin);\r\n\t\t\t// return the new object\r\n\t\t\treturn ois.readObject();\r\n\t\t}\r\n\t\tcatch (Exception e)\r\n\t\t{\r\n\t\t\tthrow new ObjectCopyException(e);\r\n\t\t}\r\n\t\tfinally\r\n\t\t{\r\n\t\t\ttry\r\n\t\t\t{\r\n\t\t\t\tif (oos != null)\r\n\t\t\t\t{\r\n\t\t\t\t\toos.close();\r\n\t\t\t\t}\r\n\t\t\t\tif (ois != null)\r\n\t\t\t\t{\r\n\t\t\t\t\tois.close();\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcatch (IOException ioe)\r\n\t\t\t{\r\n\t\t\t\t// ignore\r\n\t\t\t}\r\n\t\t}\r\n\t}", "label": 0}
{"code": "public function setNewValue($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Value::class);\n        $this->new_value = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(token, this_, args, scope){\n        //fconsole.log('extend', arguments);\n        if (this.file.jsScope == basisScope)\n        {\n          var arg0 = token.arguments[0];\n\n          if (arg0 && arg0.type == 'Identifier' && arg0.name == 'Object')\n            flow.exit('Too old basis.js (prior 1.0) detected! Current tools doesn\\'t support it. Use basisjs-tools 1.3 or lower.');\n        }\n\n        astExtend(scope, args[0], args[1]);\n        token.obj = args[0];\n      }", "label": 3}
{"code": "public function setIntersection($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\Admin\\V2\\GcRule_Intersection::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def fetch_date_of_tag(tag)\n      commit_data = fetch_commit(tag[\"commit\"][\"sha\"])\n      commit_data = stringify_keys_deep(commit_data.to_hash)\n\n      commit_data[\"commit\"][\"committer\"][\"date\"]\n    end", "label": 4}
{"code": "function keysInObject(obj, keys) {\n  for (var i in keys) {\n    if (keys[i] in obj) return true;\n  }\n  return false;\n}", "label": 3}
{"code": "def drift(stack, region, profile):\n    \"\"\"\n    Produce a CloudFormation drift report for the given stack.\n    \"\"\"\n    logging.debug('finding drift - stack: {}'.format(stack))\n    logging.debug('region: {}'.format(region))\n    logging.debug('profile: {}'.format(profile))\n    tool = DriftTool(\n        Stack=stack,\n        Region=region,\n        Profile=profile,\n        Verbose=True\n    )\n\n    if tool.determine_drift():\n        sys.exit(0)\n    else:\n        sys.exit(1)", "label": 1}
{"code": "def multi_split(txt, delims):\n    \"\"\" \n    split by multiple delimiters \n    \"\"\"\n    res = [txt]\n    for delimChar in delims:\n        txt, res = res, []\n        for word in txt:\n            if len(word) > 1:\n                res += word.split(delimChar)\n    return res", "label": 1}
{"code": "def write(bytes)\n      loop do\n        written = 0\n        begin\n          # unlike plain tcp sockets, ssl sockets don't support IO.select\n          # properly.\n          # Instead, timeouts happen on a per write basis, and we have to\n          # catch exceptions from write_nonblock, and gradually build up\n          # our write buffer.\n          written += @ssl_socket.write_nonblock(bytes)\n        rescue Errno::EFAULT => error\n          raise error\n        rescue OpenSSL::SSL::SSLError, Errno::EAGAIN, Errno::EWOULDBLOCK, IO::WaitWritable => error\n          if error.is_a?(OpenSSL::SSL::SSLError) && error.message == 'write would block'\n            if select_with_timeout(@ssl_socket, :write)\n              retry\n            else\n              raise Errno::ETIMEDOUT\n            end\n          else\n            raise error\n          end\n        end\n\n        # Fast, common case.\n        break if written == bytes.size\n\n        # This takes advantage of the fact that most ruby implementations\n        # have Copy-On-Write strings. Thusly why requesting a subrange\n        # of data, we actually don't copy data because the new string\n        # simply references a subrange of the original.\n        bytes = bytes[written, bytes.size]\n      end\n    end", "label": 4}
{"code": "public static void addStory(File caseManager, String storyName,\n            String testPath, String user, String feature, String benefit) throws BeastException {\n        FileWriter caseManagerWriter;\n\n        String storyClass = SystemReader.createClassName(storyName);\n        try {\n            BufferedReader reader = new BufferedReader(new FileReader(\n                    caseManager));\n            String targetLine1 = \"  public void \"\n                    + MASReader.createFirstLowCaseName(storyName) + \"() {\";\n            String targetLine2 = \"      Result result = JUnitCore.runClasses(\" + testPath + \".\"\n                    + storyClass + \".class);\";\n            String in;\n            while ((in = reader.readLine()) != null) {\n                if (in.equals(targetLine1)) {\n                    while ((in = reader.readLine()) != null) {\n                        if (in.equals(targetLine2)) {\n                            reader.close();\n                            // This test is already written in the case manager.\n                            return;\n                        }\n                    }\n                    reader.close();\n                    throw new BeastException(\"Two different stories with the same name (same method name) are being created in the same CaseManager file. That is not possible. Please, change the name of the story: \" + testPath + \".\"\n                            + storyClass + \".java\");\n                }\n            }\n            reader.close();\n            caseManagerWriter = new FileWriter(caseManager, true);\n            caseManagerWriter.write(\"  /**\\n\");\n            caseManagerWriter.write(\"   * This is the story: \" + storyName\n                    + \"\\n\");\n            caseManagerWriter.write(\"   * requested by: \" + user + \"\\n\");\n            caseManagerWriter.write(\"   * providing the feature: \" + feature\n                    + \"\\n\");\n            caseManagerWriter.write(\"   * so the user gets the benefit: \"\n                    + benefit + \"\\n\");\n            caseManagerWriter.write(\"   */\\n\");\n            caseManagerWriter.write(\"  @Test\\n\");\n            caseManagerWriter.write(\"  public void \"\n                    + MASReader.createFirstLowCaseName(storyName) + \"() {\\n\");\n            caseManagerWriter.write(\"      Result result = JUnitCore.runClasses(\" + testPath\n                    + \".\" + storyClass + \".class);\\n\");\n            caseManagerWriter.write(\"      Assert.assertTrue(result.wasSuccessful());\\n\");\n            caseManagerWriter.write(\"  }\\n\");\n            caseManagerWriter.write(\"\\n\");\n            caseManagerWriter.flush();\n            caseManagerWriter.close();\n        } catch (IOException e) {\n            Logger logger = Logger.getLogger(\"CreateMASCaseManager.createTest\");\n            logger.info(\"ERROR writing the file\");\n        }\n\n    }", "label": 0}
{"code": "protected function getEventOutput(Event $event)\n    {\n        if (! $event->output ||\n            $event->output === $event->getDefaultOutput() ||\n            $event->shouldAppendOutput ||\n            ! file_exists($event->output)) {\n            return '';\n        }\n\n        return trim(file_get_contents($event->output));\n    }", "label": 2}
{"code": "def _consfcn(self, x):\n        \"\"\" Evaluates nonlinear constraints and their Jacobian for OPF.\n        \"\"\"\n        h, g = self._gh(x)\n        dh, dg = self._dgh(x)\n\n        return h, g, dh, dg", "label": 1}
{"code": "public function setSQLTableAlias($tableName, $alias, $dqlAlias = '')\n    {\n        $tableName .= $dqlAlias ? '@[' . $dqlAlias . ']' : '';\n\n        $this->tableAliasMap[$tableName] = $alias;\n\n        return $alias;\n    }", "label": 2}
{"code": "function arrayify(urls) {\n  var tmp = Array.isArray(urls) ? urls : [urls];\n  return tmp.filter(Boolean);\n}", "label": 3}
{"code": "private function initializeDoctrine()\n    {\n        if ($this->cm !== null) {\n            return;\n        }\n\n        if (! self::$entityManager) {\n            throw new RuntimeException('No runtime entity manager set. Call PersistentObject#setEntityManager().');\n        }\n\n        $this->cm = self::$entityManager->getClassMetadata(static::class);\n    }", "label": 2}
{"code": "def getV0(self, v_mag_guess, buses, generators, type=CASE_GUESS):\n        \"\"\" Returns the initial voltage profile.\n        \"\"\"\n        if type == CASE_GUESS:\n            Va = array([b.v_angle * (pi / 180.0) for b in buses])\n            Vm = array([b.v_magnitude for b in buses])\n            V0 = Vm * exp(1j * Va)\n        elif type == FLAT_START:\n            V0 = ones(len(buses))\n        elif type == FROM_INPUT:\n            V0 = v_mag_guess\n        else:\n            raise ValueError\n\n        # Set the voltages of PV buses and the reference bus in the guess.\n#        online = [g for g in self.case.generators if g.online]\n        gbus = [g.bus._i for g in generators]\n        Vg = array([g.v_magnitude for g in generators])\n\n        V0[gbus] = Vg * abs(V0[gbus]) / V0[gbus]\n\n        return V0", "label": 1}
{"code": "def update_roles(role_ids)\n      @roles = []\n      role_ids.each do |id|\n        # It is posible for members to have roles that do not exist\n        # on the server any longer. See https://github.com/meew0/discordrb/issues/371\n        role = @server.role(id)\n        @roles << role if role\n      end\n    end", "label": 4}
{"code": "function abort(state)\n{\n  Object.keys(state.jobs).forEach(clean.bind(state));\n\n  // reset leftover jobs\n  state.jobs = {};\n}", "label": 3}
{"code": "def run_mutect(job, tumor_bam, normal_bam, univ_options, mutect_options, chrom):\n    \"\"\"\n    This module will run mutect on the DNA bams\n\n    ARGUMENTS\n    1. tumor_bam: REFER ARGUMENTS of spawn_mutect()\n    2. normal_bam: REFER ARGUMENTS of spawn_mutect()\n    3. univ_options: REFER ARGUMENTS of spawn_mutect()\n    4. mutect_options: REFER ARGUMENTS of spawn_mutect()\n    5. chrom: String containing chromosome name with chr appended\n\n    RETURN VALUES\n    1. output_files: Dict of results of mutect for chromosome\n            output_files\n              |- 'mutect_CHROM.vcf': <JSid>\n              +- 'mutect_CHROM.out': <JSid>\n\n    This module corresponds to node 12 on the tree\n    \"\"\"\n    job.fileStore.logToMaster('Running mutect on %s:%s' % (univ_options['patient'], chrom))\n    work_dir = job.fileStore.getLocalTempDir()\n    input_files = {\n        'tumor.bam': tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n        'tumor.bam.bai': tumor_bam['tumor_dna_fix_pg_sorted.bam.bai'],\n        'normal.bam': normal_bam['normal_dna_fix_pg_sorted.bam'],\n        'normal.bam.bai': normal_bam['normal_dna_fix_pg_sorted.bam.bai'],\n        'genome.fa': mutect_options['genome_fasta'],\n        'genome.fa.fai': mutect_options['genome_fai'],\n        'genome.dict': mutect_options['genome_dict'],\n        'cosmic.vcf': mutect_options['cosmic_vcf'],\n        'cosmic.vcf.idx': mutect_options['cosmic_idx'],\n        'dbsnp.vcf': mutect_options['dbsnp_vcf'],\n        'dbsnp.vcf.idx': mutect_options['dbsnp_idx']}\n    input_files = get_files_from_filestore(job, input_files, work_dir,\n                                           docker=True)\n    mutout = ''.join([work_dir, '/mutect_', chrom, '.out'])\n    mutvcf = ''.join([work_dir, '/mutect_', chrom, '.vcf'])\n    parameters = ['-R', input_files['genome.fa'],\n                  '--cosmic', input_files['cosmic.vcf'],\n                  '--dbsnp', input_files['dbsnp.vcf'],\n                  '--input_file:normal', input_files['normal.bam'],\n                  '--input_file:tumor', input_files['tumor.bam'],\n                  #'--tumor_lod', str(10),\n                  #'--initial_tumor_lod', str(4.0),\n                  '-L', chrom,\n                  '--out', docker_path(mutout),\n                  '--vcf', docker_path(mutvcf)\n                 ]\n    Xmx = mutect_options['java_Xmx'] if mutect_options['java_Xmx'] else univ_options['java_Xmx']\n    docker_call(tool='mutect:1.1.7', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], java_opts=Xmx)\n    output_files = defaultdict()\n    for mutect_file in [mutout, mutvcf]:\n        output_files[os.path.basename(mutect_file)] = job.fileStore.writeGlobalFile(mutect_file)\n    return output_files", "label": 1}
{"code": "func (nDB *NetworkDB) findCommonNetworks(nodeName string) []string {\n\tnDB.RLock()\n\tdefer nDB.RUnlock()\n\n\tvar networks []string\n\tfor nid := range nDB.networks[nDB.config.NodeID] {\n\t\tif n, ok := nDB.networks[nodeName][nid]; ok {\n\t\t\tif !n.leaving {\n\t\t\t\tnetworks = append(networks, nid)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn networks\n}", "label": 5}
{"code": "public function setPlacement($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1\\JobPlacement::class);\n        $this->placement = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def manage_component_path(component)\n      current_params = try(:params) || {}\n      EngineRouter.admin_proxy(component).root_path(locale: current_params[:locale])\n    end", "label": 4}
{"code": "function defaultRenderer(template, data) {\n    return template.replace(/%\\w+/g, function (match) {\n        return data[match.slice(1)];\n    });\n}", "label": 3}
{"code": "def checksum_bytes(data):\n    \"\"\" Returns a XOR of all the bytes specified inside of the given list \"\"\"\n\n    int_values = [int(x, 16) for x in data]\n    int_xor = reduce(lambda x, y: x ^ y, int_values)\n    hex_xor = \"{:X}\".format(int_xor)\n    if len(hex_xor) % 2 != 0:\n        hex_xor = \"0\" + hex_xor\n\n    return str.encode(hex_xor)", "label": 1}
{"code": "function (type, para) {\n\n\t\t// avoid flooding if SR_PUBLISH is sending streaming data\n\t\tSR.Log('[' + type + '] received');\n\t\tswitch (type) {\n\t\t\t//\n\t\t\t// pubsub related\n\t\t\t//\n\t\t\t// when a new published message arrives \n\t\t\tcase 'SR_MSG':\n\t\t\t// handle server-published messages\n\t\t\tcase 'SR_PUBLISH':\n\t\t\t\tif (onChannelMessages.hasOwnProperty(para.channel)) {\n\t\t\t\t\tif (typeof onChannelMessages[para.channel] !== 'function')\n\t\t\t\t\t\tSR.Error('channel [' + para.channel + '] handler is not a function');\n\t\t\t\t\telse\n\t\t\t\t\t\tonChannelMessages[para.channel](para.msg, para.channel);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\tSR.Error('cannot find channel [' + para.channel + '] to publish'); \n\t\t\t\treturn true;\n\t\t\t\t\n\t\t\t// when a list of messages arrive (in array)\n\t\t\tcase 'SR_MSGLIST':\t\n\t\t\t\tvar msg_list = para.msgs;\t\t\t\n\t\t\t\tif (msg_list && msg_list.length > 0 && onChannelMessages.hasOwnProperty(para.channel)) {\n\t\t\t\t\t\n\t\t\t\t\tfor (var i=0; i < msg_list.length; i++)\n\t\t\t\t\t\tonChannelMessages[para.channel](msg_list[i], para.channel);\n\t\t\t\t}\t\t\t\t\n\t\t\t\treturn true;\n\t\t\t\t\n\t\t\t// redirect to another webpage\n\t\t\tcase 'SR_REDIRECT':\n\t\t\t\twindow.location.href = para.url;\n\t\t\t\treturn true;\n\t\t\tcase \"SR_NOTIFY\" :\n\t\t\t\tSR.Warn('SR_NOTIFY para: ');\n\t\t\t\tSR.Warn(para);\n\t\t\t\tconsole.log(onChannelMessages);\n\t\t\t\tif (onChannelMessages.hasOwnProperty('notify'))\n\t\t\t\t\tonChannelMessages['notify'](para, 'notify');\n\t\t\t\treturn true;\n\t\t\t//\n\t\t\t// login related\n\t\t\t//\n\t\t\tcase \"SR_LOGIN_RESPONSE\":\n\t\t\tcase \"SR_LOGOUT_RESPONSE\":\n\t\t\t\treplyLogin(para);\n\t\t\t\treturn true;\n\t\t\tcase \"SR_MESSAGE\":\n\t\t\t\talert('SR_MESSAGE: ' + para.msg);\n\t\t\t\treturn true;\n\t\t\tcase \"SR_WARNING\":\n\t\t\t\talert('SR_WARNING: ' + para.msg);\n\t\t\t\treturn true;\n\t\t\tcase \"SR_ERROR\":\n\t\t\t\talert('SR_ERROR: ' + para.msg);\n                return true;\n\t\t\t\t\n\t\t\tdefault:\n\t\t\t\t// check if custom handlers exist and can handle it\n\t\t\t\tif (responseHandlers.hasOwnProperty(type)) {\n\t\t\t\t\t\n\t\t\t\t\tvar callbacks = responseHandlers[type];\n\t\t\t\t\t\n\t\t\t\t\t// extract rid if available \n\t\t\t\t\tvar rid = undefined;\t\t\t\t\t\n\t\t\t\t\tif (para.hasOwnProperty('_rid') === true) {\t\t\t\t\n\t\t\t\t\t\trid = para['_rid'];\n\t\t\t\t\t\tdelete para['_rid'];\n\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\tif (rid) {\n\t\t\t\t\t\tcallbacks[rid](para, type);\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t// remove callback once done\n\t\t\t\t\t\tif (rid !== 'keep') {\n\t\t\t\t\t\t\tdelete callbacks[rid];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// otherwise ALL registered callbacks will be called\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (Object.keys(callbacks).length > 1)\n\t\t\t\t\t\t\tSR.Warn('[' + type + '] no rid in update, dispatching to first of ' +  Object.keys(callbacks).length + ' callbacks');\n\t\t\t\t\t\t\n\t\t\t\t\t\t// call the first in callbacks then remove it\n\t\t\t\t\t\t// so only one callback is called unless it's registered via the 'keep_callback' flag\n\t\t\t\t\t\tfor (var key in callbacks) {\n\t\t\t\t\t\t\tcallbacks[key](para, type);\n\t\t\t\t\t\t\tif (key !== 'keep') {\n\t\t\t\t\t\t\t\tdelete callbacks[key];\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\n\t\t\t\t// still un-handled\n\t\t\t\tconsole.error('onResponse: unrecongized type: ' + type);\n\t\t\t\treturn false;\n\t\t}\n\t}", "label": 3}
{"code": "def get(host=\"localhost\", port=3551, timeout=30):\n    \"\"\"\n    Connect to the APCUPSd NIS and request its status.\n    \"\"\"\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.settimeout(timeout)\n    sock.connect((host, port))\n    sock.send(CMD_STATUS)\n    buffr = \"\"\n    while not buffr.endswith(EOF):\n        buffr += sock.recv(BUFFER_SIZE).decode()\n    sock.close()\n    return buffr", "label": 1}
{"code": "def yes?(message, *args, &block)\n      defaults = { default: true }\n      options  = Utils.extract_options!(args)\n      options.merge!(defaults.reject { |k, _| options.key?(k) })\n\n      question = ConfirmQuestion.new(self, options)\n      question.call(message, &block)\n    end", "label": 4}
{"code": "public static appfwprofile_xmlxss_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappfwprofile_xmlxss_binding obj = new appfwprofile_xmlxss_binding();\n\t\tobj.set_name(name);\n\t\tappfwprofile_xmlxss_binding response[] = (appfwprofile_xmlxss_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (i *IpamInfo) UnmarshalJSON(data []byte) error {\n\tvar (\n\t\tm   map[string]interface{}\n\t\terr error\n\t)\n\tif err = json.Unmarshal(data, &m); err != nil {\n\t\treturn err\n\t}\n\ti.PoolID = m[\"PoolID\"].(string)\n\tif v, ok := m[\"Meta\"]; ok {\n\t\tb, _ := json.Marshal(v)\n\t\tif err = json.Unmarshal(b, &i.Meta); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif v, ok := m[\"IPAMData\"]; ok {\n\t\tif err = json.Unmarshal([]byte(v.(string)), &i.IPAMData); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "private function prepareQueryBinding(array $binding)\n    {\n        $value = $binding['value'];\n\n        list ($type, $val) = $this->toGrpcValue($value);\n\n        $binding['value'][$type] = $val;\n\n        return $binding;\n    }", "label": 2}
{"code": "public void processAnonymousField(Properties attributes) throws XDocletException\r\n    {\r\n        if (!attributes.containsKey(ATTRIBUTE_NAME))\r\n        {\r\n            throw new XDocletException(Translator.getString(XDocletModulesOjbMessages.class,\r\n                                       XDocletModulesOjbMessages.PARAMETER_IS_REQUIRED,\r\n                                       new String[]{ATTRIBUTE_NAME}));\r\n        }\r\n\r\n        String             name     = attributes.getProperty(ATTRIBUTE_NAME);\r\n        FieldDescriptorDef fieldDef = _curClassDef.getField(name);\r\n        String             attrName;\r\n\r\n        if (fieldDef == null)\r\n        {\r\n            fieldDef = new FieldDescriptorDef(name);\r\n            _curClassDef.addField(fieldDef);\r\n        }\r\n        fieldDef.setAnonymous();\r\n        LogHelper.debug(false, OjbTagsHandler.class, \"processAnonymousField\", \"  Processing anonymous field \"+fieldDef.getName());\r\n\r\n        attributes.remove(ATTRIBUTE_NAME);\r\n        for (Enumeration attrNames = attributes.propertyNames(); attrNames.hasMoreElements(); )\r\n        {\r\n            attrName = (String)attrNames.nextElement();\r\n            fieldDef.setProperty(attrName, attributes.getProperty(attrName));\r\n        }\r\n        fieldDef.setProperty(PropertyHelper.OJB_PROPERTY_ACCESS, \"anonymous\");\r\n    }", "label": 0}
{"code": "def genome_lengths(fastas, info):\n    \"\"\"\n    get genome lengths\n    \"\"\"\n    if info is False:\n        info = {}\n    for genome in fastas:\n        name = genome.rsplit('.', 1)[0].rsplit('/', 1)[-1].rsplit('.contigs')[0]\n        if name in info:\n            continue\n        length = 0\n        fragments = 0\n        for seq in parse_fasta(genome):\n            length += len(seq[1])\n            fragments += 1\n        info[name] = {'genome size (bp)':length, '# contigs':fragments}\n    return info", "label": 1}
{"code": "function (partStatistics) {\n        this.count += partStatistics.count;\n        this.tested += partStatistics.tested;\n        this.ignored += partStatistics.ignored;\n    }", "label": 3}
{"code": "def delete(table, ids, options = {})\n      range_key = options[:range_key] # array of range keys that matches the ids passed in\n      if ids.respond_to?(:each)\n        ids = if range_key.respond_to?(:each)\n                # turn ids into array of arrays each element being hash_key, range_key\n                ids.each_with_index.map { |id, i| [id, range_key[i]] }\n              else\n                range_key ? ids.map { |id| [id, range_key] } : ids\n              end\n\n        batch_delete_item(table => ids)\n      else\n        delete_item(table, ids, options)\n      end\n    end", "label": 4}
{"code": "function (login_id, session, data) {\n\n\t// acknowledge as 'logined'\t\n\tl_loginID[login_id] = data.account;\n\t\n\t// init session\n\tsession['_account'] = data.account;\n\t\n\t// TODO: needs to fix this, should read \"groups\" from DB\n\tsession['_groups'] = data.groups;\n\tsession['_permissions'] = data.permissions;\n\tsession['lastStatus'] = data.lastStatus;\n\t\n\t// TODO: centralize handling of logined users?\n\t//SR.User.addGroup(user_data.account, ['user', 'admin']);\n}", "label": 3}
{"code": "function(model, noUpdateToIdList) {\n      var itemView,\n        ItemViewClass = this.itemView;\n      if (!_.isFunction(this.itemView.extend)) {\n        ItemViewClass = this.itemView(model);\n      }\n      itemView = new ItemViewClass(this.__generateItemViewArgs(model));\n      this.registerTrackedView(itemView, { shared: false });\n      this.__modelToViewMap[model[this.__modelId]] = itemView.cid;\n      if (!noUpdateToIdList) {\n        this.__updateOrderedModelIdList();\n      }\n      this.trigger('child-view-added', {model: model, view: itemView});\n      this.trigger('item-view-added', {model: model, view: itemView});\n      return itemView;\n    }", "label": 3}
{"code": "public Pair<int[][][][], int[][]> documentsToDataAndLabels(Collection<List<IN>> documents) {\r\n\r\n    // first index is the number of the document\r\n    // second index is position in the document also the index of the\r\n    // clique/factor table\r\n    // third index is the number of elements in the clique/window these features\r\n    // are for (starting with last element)\r\n    // fourth index is position of the feature in the array that holds them\r\n    // element in data[i][j][k][m] is the index of the mth feature occurring in\r\n    // position k of the jth clique of the ith document\r\n    // int[][][][] data = new int[documentsSize][][][];\r\n    List<int[][][]> data = new ArrayList<int[][][]>();\r\n\r\n    // first index is the number of the document\r\n    // second index is the position in the document\r\n    // element in labels[i][j] is the index of the correct label (if it exists)\r\n    // at position j in document i\r\n    // int[][] labels = new int[documentsSize][];\r\n    List<int[]> labels = new ArrayList<int[]>();\r\n\r\n    int numDatums = 0;\r\n\r\n    for (List<IN> doc : documents) {\r\n      Pair<int[][][], int[]> docPair = documentToDataAndLabels(doc);\r\n      data.add(docPair.first());\r\n      labels.add(docPair.second());\r\n      numDatums += doc.size();\r\n    }\r\n\r\n    System.err.println(\"numClasses: \" + classIndex.size() + ' ' + classIndex);\r\n    System.err.println(\"numDocuments: \" + data.size());\r\n    System.err.println(\"numDatums: \" + numDatums);\r\n    System.err.println(\"numFeatures: \" + featureIndex.size());\r\n    printFeatures();\r\n\r\n    int[][][][] dataA = new int[0][][][];\r\n    int[][] labelsA = new int[0][];\r\n\r\n    return new Pair<int[][][][], int[][]>(data.toArray(dataA), labels.toArray(labelsA));\r\n  }", "label": 0}
{"code": "def _get_size_recursive(self, dat):\n        \"\"\"\n        recursively walk through a data set or json file \n        to get the total number of nodes\n        \"\"\"\n        self.total_records += 1\n        #self.total_nodes += 1\n        for rec in dat:\n            if hasattr(rec, '__iter__') and type(rec) is not str:\n                self._get_size_recursive(rec)\n            else:\n                self.total_nodes += 1\n                self.total_length += len(str(rec))", "label": 1}
{"code": "protected static void captureSystemStreams(boolean captureOut, boolean captureErr){\r\n    if(captureOut){\r\n      System.setOut(new RedwoodPrintStream(STDOUT, realSysOut));\r\n    }\r\n    if(captureErr){\r\n      System.setErr(new RedwoodPrintStream(STDERR, realSysErr));\r\n    }\r\n  }", "label": 0}
{"code": "def alias_action(self, *args, **kwargs):\n        \"\"\"\n        Alias one or more actions into another one.\n\n        self.alias_action('create', 'read', 'update', 'delete', to='crud')\n\n        \"\"\"\n        to = kwargs.pop('to', None)\n        if not to:\n            return\n        error_message = (\"You can't specify target ({}) as alias \"\n                         \"because it is real action name\".format(to)\n                         )\n        if to in list(itertools.chain(*self.aliased_actions.values())):\n            raise Exception(error_message)\n\n        self.aliased_actions.setdefault(to, []).extend(args)", "label": 1}
{"code": "func PgCastByOid(db XODB, oid pgtypes.Oid) (*PgCast, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, castsource, casttarget, castfunc, castcontext, castmethod ` +\n\t\t`FROM pg_catalog.pg_cast ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpc := PgCast{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pc.Tableoid, &pc.Cmax, &pc.Xmax, &pc.Cmin, &pc.Xmin, &pc.Oid, &pc.Ctid, &pc.Castsource, &pc.Casttarget, &pc.Castfunc, &pc.Castcontext, &pc.Castmethod)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pc, nil\n}", "label": 5}
{"code": "function create(connections, dataSource, callback) {\n  async.waterfall([\n    function validateParams(cb) {\n\n      //If it is a deploy, the JSON can contain an _id param\n      if (connections.deploy) {\n        return cb(undefined, dataSource);\n      }\n\n      //Otherwise, check that it is not there.\n      validate(dataSource).hasno(CONSTANTS.DATA_SOURCE_ID, function(err) {\n        if (err) {\n          return cb(buildErrorResponse({error: new Error(\"Data Source ID Should Not Be Included When Creating A Data Source\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n        }\n\n        cb(undefined, dataSource);\n      });\n    },\n    function validateNameNotUsed(dataSource, cb) {\n      //Duplicate Names Are Not Allowed.\n      var DataSource = models.get(connections.mongooseConnection, models.MODELNAMES.DATA_SOURCE);\n\n      DataSource.count({name: dataSource.name}, function(err, numDuplicateDSs) {\n        if (numDuplicateDSs && numDuplicateDSs > 0) {\n          return cb({\n            userDetail: \"Invalid Data To Create A Data Source\" ,\n            systemDetail: \"A Data Source With The Name \" + dataSource.name + \" Already Exists\",\n            code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS\n          });\n        } else {\n          return cb(err, dataSource);\n        }\n      });\n    },\n    function createDataSource(dataSourceJSON, cb) {\n      dataSourceJSON = misc.sanitiseJSON(dataSourceJSON);\n\n      var DataSource = models.get(connections.mongooseConnection, models.MODELNAMES.DATA_SOURCE);\n      var newDataSource = new DataSource(dataSourceJSON);\n\n      newDataSource.save(function(err) {\n        if (err) {\n          return cb(buildErrorResponse({\n            error: err,\n            userDetail: \"Invalid Data Source Creation Data.\",\n            systemDetail: err.errors,\n            code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS\n          }));\n        }\n\n        newDataSource = processDataSourceResponse(newDataSource.toJSON());\n\n        return cb(undefined, newDataSource);\n      });\n\n    }\n  ], callback);\n}", "label": 3}
{"code": "public static base_response update(nitro_service client, scpolicy resource) throws Exception {\n\t\tscpolicy updateresource = new scpolicy();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.url = resource.url;\n\t\tupdateresource.rule = resource.rule;\n\t\tupdateresource.delay = resource.delay;\n\t\tupdateresource.maxconn = resource.maxconn;\n\t\tupdateresource.action = resource.action;\n\t\tupdateresource.altcontentsvcname = resource.altcontentsvcname;\n\t\tupdateresource.altcontentpath = resource.altcontentpath;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (a *AuthWithRoles) GetClusterConfig(opts ...services.MarshalOption) (services.ClusterConfig, error) {\n\tif err := a.action(defaults.Namespace, services.KindClusterConfig, services.VerbRead); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn a.authServer.GetClusterConfig(opts...)\n}", "label": 5}
{"code": "func isSSN(fl FieldLevel) bool {\n\n\tfield := fl.Field()\n\n\tif field.Len() != 11 {\n\t\treturn false\n\t}\n\n\treturn sSNRegex.MatchString(field.String())\n}", "label": 5}
{"code": "def mail(headers = {}, &block)\n      return message if @_mail_was_called && headers.blank? && !block\n\n      # At the beginning, do not consider class default for content_type\n      content_type = headers[:content_type]\n\n      headers = apply_defaults(headers)\n\n      # Apply charset at the beginning so all fields are properly quoted\n      message.charset = charset = headers[:charset]\n\n      # Set configure delivery behavior\n      wrap_delivery_behavior!(headers[:delivery_method], headers[:delivery_method_options])\n\n      assign_headers_to_message(message, headers)\n\n      # Render the templates and blocks\n      responses = collect_responses(headers, &block)\n      @_mail_was_called = true\n\n      create_parts_from_responses(message, responses)\n\n      # Setup content type, reapply charset and handle parts order\n      message.content_type = set_content_type(message, content_type, headers[:content_type])\n      message.charset      = charset\n\n      if message.multipart?\n        message.body.set_sort_order(headers[:parts_order])\n        message.body.sort_parts!\n      end\n\n      message\n    end", "label": 4}
{"code": "func (*TeleportCertAuthorityMarshaler) MarshalCertAuthority(ca CertAuthority, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttype cav1 interface {\n\t\tV1() *CertAuthorityV1\n\t}\n\n\ttype cav2 interface {\n\t\tV2() *CertAuthorityV2\n\t}\n\tversion := cfg.GetVersion()\n\tswitch version {\n\tcase V1:\n\t\tv, ok := ca.(cav1)\n\t\tif !ok {\n\t\t\treturn nil, trace.BadParameter(\"don't know how to marshal %v\", V1)\n\t\t}\n\t\treturn utils.FastMarshal(v.V1())\n\tcase V2:\n\t\tv, ok := ca.(cav2)\n\t\tif !ok {\n\t\t\treturn nil, trace.BadParameter(\"don't know how to marshal %v\", V2)\n\t\t}\n\t\tv2 := v.V2()\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *v2\n\t\t\tcopy.SetResourceID(0)\n\t\t\tv2 = &copy\n\t\t}\n\t\treturn utils.FastMarshal(v2)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"version %v is not supported\", version)\n\t}\n}", "label": 5}
{"code": "public static gslbldnsentries[] get(nitro_service service) throws Exception{\n\t\tgslbldnsentries obj = new gslbldnsentries();\n\t\tgslbldnsentries[] response = (gslbldnsentries[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function getOptions($removeContextData = false)\n    {\n        // Context is not set when doing things like stat\n        if ($this->context === null) {\n            $options = [];\n        } else {\n            $options = stream_context_get_options($this->context);\n            $options = isset($options[$this->protocol])\n                ? $options[$this->protocol]\n                : [];\n        }\n\n        $default = stream_context_get_options(stream_context_get_default());\n        $default = isset($default[$this->protocol])\n            ? $default[$this->protocol]\n            : [];\n        $result = $this->params + $options + $default;\n\n        if ($removeContextData) {\n            unset($result['client'], $result['seekable'], $result['cache']);\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "def destroy\n      self.last_result_set = self.class.requestor.destroy(self)\n      if last_result_set.has_errors?\n        fill_errors\n        false\n      else\n        mark_as_destroyed!\n        self.relationships.last_result_set = nil\n        _clear_cached_relationships\n        _clear_belongs_to_params\n        true\n      end\n    end", "label": 4}
{"code": "public void setAlias(String alias)\r\n\t{\r\n\t\tif (alias == null || alias.trim().equals(\"\"))\r\n\t\t{\r\n\t\t\tm_alias = null;\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\tm_alias = alias;\r\n\t\t}\r\n\r\n\t\t// propagate to SelectionCriteria,not to Criteria\r\n\t\tfor (int i = 0; i < m_criteria.size(); i++)\r\n\t\t{\r\n\t\t\tif (!(m_criteria.elementAt(i) instanceof Criteria))\r\n\t\t\t{\r\n\t\t\t\t((SelectionCriteria) m_criteria.elementAt(i)).setAlias(m_alias);\r\n\t\t\t}\r\n\t\t}\r\n\t}", "label": 0}
{"code": "def save(self, fname):\n        \"\"\" saves a grid to file as ASCII text \"\"\"\n        try:\n            with open(fname, \"w\") as f:\n                f.write(str(self))\n        except Exception as ex:\n            print('ERROR = cant save grid results to ' + fname + str(ex))", "label": 1}
{"code": "func (s *Server) OpenV3(p *Packet) (interface{}, error) {\n\treq := new(RequestOpenV3)\n\terr := UnmarshalBinary(p.Payload, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsession, err := s.getSession(p)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tname := req.FileName.Path()\n\n\tif req.DesiredLock != LockNone {\n\t\treturn nil, &Status{\n\t\t\tErr:  fmt.Errorf(\"open lock type=%d not supported for file %q\", req.DesiredLock, name),\n\t\t\tCode: StatusOperationNotSupported,\n\t\t}\n\t}\n\n\tfile, err := s.OpenFile(name, req.OpenMode)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres := &ReplyOpenV3{\n\t\tHandle: s.newHandle(),\n\t}\n\n\tsession.mu.Lock()\n\tsession.files[res.Handle] = file\n\tsession.mu.Unlock()\n\n\treturn res, nil\n}", "label": 5}
{"code": "public function multi()\n    {\n        if ($this->state->check(MultiExecState::INITIALIZED | MultiExecState::CAS)) {\n            $this->state->unflag(MultiExecState::CAS);\n            $this->call('MULTI');\n        } else {\n            $this->initialize();\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def status(self):\n        \"\"\"The status of the connection to perforce\"\"\"\n        try:\n            # -- Check client\n            res = self.run(['info'])\n            if res[0]['clientName'] == '*unknown*':\n                return ConnectionStatus.INVALID_CLIENT\n            # -- Trigger an auth error if not logged in\n            self.run(['user', '-o'])\n        except errors.CommandError as err:\n            if 'password (P4PASSWD) invalid or unset' in str(err.args[0]):\n                return ConnectionStatus.NO_AUTH\n            if 'Connect to server failed' in str(err.args[0]):\n                return ConnectionStatus.OFFLINE\n\n        return ConnectionStatus.OK", "label": 1}
{"code": "public <T> T convert(Object source, TypeReference<T> typeReference)\r\n\t\t\tthrows ConverterException {\r\n\t\treturn (T) convert(new ConversionContext(), source, typeReference);\r\n\t}", "label": 0}
{"code": "private function validateType($type, $value): bool\n    {\n        if (substr($type, 0, 1) === '[' && substr($type, -1) === ']') { // Array of a specified type?\n            if ($this->validateType('array', $value) === false) {\n                return false;\n            }\n            $itemType = substr($type, 1, -1);\n            foreach ($value as $i => $item) {\n                if ($this->validateType($itemType, $item) === false) {\n                    return false;\n                }\n            }\n            return true;\n        }\n\n        if (is_subclass_of($type, AbstractAnnotation::class)) {\n            $type = 'object';\n        }\n\n        return $this->validateDefaultTypes($type, $value);\n    }", "label": 2}
{"code": "def __get_nondirect_init(self, init):\n        \"\"\"\n        return the non-direct init if the direct algorithm has been selected.\n        \"\"\"\n        crc = init\n        for i in range(self.Width):\n            bit = crc & 0x01\n            if bit:\n                crc^= self.Poly\n            crc >>= 1\n            if bit:\n                crc |= self.MSB_Mask\n        return crc & self.Mask", "label": 1}
{"code": "function PostgreStore(conString, options) {\n    if(!conString){\n        throw new Error('Connection String is missing.');\n    }\n\n    this._options = options || {};\n    this._options.pgstore = this._options.pgstore || {};\n    this._difficulty = this._options.pgstore.difficulty || 10;\n\tthis._table = this._options.pgstore.table || 'passwordless';\n\n    this._client = new pg.Pool({\n        connectionString: conString,\n        max: this._options.pgstore.pgPoolSize || 10\n    });\n\n    if(!isNumber(this._difficulty) || this._cost < 1) {\n        throw new Error('bcrypt difficulty must be an integer >= 1');\n    }\n\n    delete this._options.pgstore;\n\n    var self = this;\n    this._client.connect(function(err, client) {\n        if(err) {\n            throw new Error('Could not connect to Postgres database, with error : ' + err);\n        }\n    });\n}", "label": 3}
{"code": "function(loader, name){\n\t\tvar pkg = utils.pkg.findByName(loader, name.split(\"/\")[0]);\n\t\tif(pkg) {\n\t\t\tvar parsed = utils.moduleName.parse(name, pkg.name);\n\t\t\tparsed.version = pkg.version;\n\t\t\tif(!parsed.modulePath) {\n\t\t\t\tparsed.modulePath = utils.pkg.main(pkg);\n\t\t\t}\n\t\t\treturn utils.moduleName.create(parsed);\n\t\t}\n\t\treturn name;\n\t}", "label": 3}
{"code": "def add_text_to_image(fname, txt, opFilename):\n    \"\"\" convert an image by adding text \"\"\"\n    ft = ImageFont.load(\"T://user//dev//src//python//_AS_LIB//timR24.pil\")\n    #wh = ft.getsize(txt)\n    print(\"Adding text \", txt, \" to \", fname, \" pixels wide to file \" , opFilename)\n    im = Image.open(fname)\n    draw = ImageDraw.Draw(im)\n    draw.text((0, 0), txt, fill=(0, 0, 0), font=ft)\n    del draw  \n    im.save(opFilename)", "label": 1}
{"code": "public function bufferReadAsync(int $length): \\Generator\n    {\n        if ($this->read_check_after && $length + $this->read_check_pos >= $this->read_check_after) {\n            if ($length + $this->read_check_pos > $this->read_check_after) {\n                throw new \\danog\\MadelineProto\\Exception('Tried to read too much out of frame data');\n            }\n            $data = yield $this->read_buffer->bufferRead($length);\n            hash_update($this->read_hash, $data);\n            $hash = $this->getReadHash();\n            if ($hash !== yield $this->read_buffer->bufferRead(strlen($hash))) {\n                throw new \\danog\\MadelineProto\\Exception('Hash mismatch');\n            }\n\n            return $data;\n        }\n        $data = yield $this->read_buffer->bufferRead($length);\n        hash_update($this->read_hash, $data);\n        if ($this->read_check_after) {\n            $this->read_check_pos += $length;\n        }\n\n        return $data;\n    }", "label": 2}
{"code": "func (c *Call) Times(n int) *Call {\n\tc.minCalls, c.maxCalls = n, n\n\treturn c\n}", "label": 5}
{"code": "func (s Strings) MarshalJSON() ([]byte, error) {\n\tif len(s) == 1 {\n\t\treturn json.Marshal(s[0])\n\t}\n\treturn json.Marshal([]string(s))\n}", "label": 5}
{"code": "protected String getUniqueString(FieldDescriptor field) throws SequenceManagerException\r\n    {\r\n        ResultSetAndStatement rsStmt = null;\r\n        String returnValue = null;\r\n        try\r\n        {\r\n            rsStmt = getBrokerForClass().serviceJdbcAccess().executeSQL(\r\n                    \"select newid()\", field.getClassDescriptor(), Query.NOT_SCROLLABLE);\r\n            if (rsStmt.m_rs.next())\r\n            {\r\n                returnValue = rsStmt.m_rs.getString(1);\r\n            }\r\n            else\r\n            {\r\n                LoggerFactory.getDefaultLogger().error(this.getClass()\r\n                        + \": Can't lookup new oid for field \" + field);\r\n            }\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            throw new SequenceManagerException(e);\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            throw new SequenceManagerException(e);\r\n        }\r\n\r\n        finally\r\n        {\r\n            // close the used resources\r\n            if (rsStmt != null) rsStmt.close();\r\n        }\r\n        return returnValue;\r\n    }", "label": 0}
{"code": "func (r *DrvRegistry) RegisterIpamDriverWithCapabilities(name string, driver ipamapi.Ipam, caps *ipamapi.Capability) error {\n\treturn r.registerIpamDriver(name, driver, caps)\n}", "label": 5}
{"code": "def all_plugin_hook_configs\n      hook_configs = {}\n\n      Overcommit::Utils.supported_hook_types.each do |hook_type|\n        hook_type_class_name = Overcommit::Utils.camel_case(hook_type)\n\n        directory = File.join(plugin_directory, hook_type.tr('-', '_'))\n        plugin_paths = Dir[File.join(directory, '*.rb')].sort\n\n        hook_names = plugin_paths.map do |path|\n          Overcommit::Utils.camel_case(File.basename(path, '.rb'))\n        end\n\n        hook_configs[hook_type_class_name] = Hash[\n          hook_names.map do |hook_name|\n            [hook_name, for_hook(hook_name, Overcommit::Utils.camel_case(hook_type))]\n          end\n        ]\n      end\n\n      hook_configs\n    end", "label": 4}
{"code": "def available?(an_rpc)\n      return an_rpc if @pool.ready_for_work?\n      GRPC.logger.warn('no free worker threads currently')\n      noop = proc { |x| x }\n\n      # Create a new active call that knows that metadata hasn't been\n      # sent yet\n      c = ActiveCall.new(an_rpc.call, noop, noop, an_rpc.deadline,\n                         metadata_received: true, started: false)\n      c.send_status(GRPC::Core::StatusCodes::RESOURCE_EXHAUSTED,\n                    'No free threads in thread pool')\n      nil\n    end", "label": 4}
{"code": "function getParseType (file) {\n  let ext = path.extname(file)\n\n  for (let type in FILE_TYPE_MAP) {\n    let exts = FILE_TYPE_MAP[type]\n\n    if (exts.indexOf(ext) >= 0) {\n      return type\n    }\n  }\n}", "label": 3}
{"code": "def headers(row = nil)\n      row ||= rows.first\n      header_type = row.th.exist? ? 'th' : 'td'\n      row.send(\"#{header_type}s\")\n    end", "label": 4}
{"code": "@Api\n\tpublic void restoreSecurityContext(SavedAuthorization savedAuthorization) {\n\t\tList<Authentication> auths = new ArrayList<Authentication>();\n\t\tif (null != savedAuthorization) {\n\t\t\tfor (SavedAuthentication sa : savedAuthorization.getAuthentications()) {\n\t\t\t\tAuthentication auth = new Authentication();\n\t\t\t\tauth.setSecurityServiceId(sa.getSecurityServiceId());\n\t\t\t\tauth.setAuthorizations(sa.getAuthorizations());\n\t\t\t\tauths.add(auth);\n\t\t\t}\n\t\t}\n\t\tsetAuthentications(null, auths);\n\t\tuserInfoInit();\n\t}", "label": 0}
{"code": "func (s *APIServer) upsertTunnelConnection(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tvar req upsertTunnelConnectionRawReq\n\tif err := httplib.ReadJSON(r, &req); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tconn, err := services.UnmarshalTunnelConnection(req.TunnelConnection)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif err := auth.UpsertTunnelConnection(conn); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn message(\"ok\"), nil\n}", "label": 5}
{"code": "def table_rows\n      # allow a standard key to be used for doing defaults in YAML\n      fixtures.delete(\"DEFAULTS\")\n\n      TableRows.new(\n        table_name,\n        model_class: model_class,\n        fixtures: fixtures,\n        config: config,\n      ).to_hash\n    end", "label": 4}
{"code": "func InternalMaskableErrorf(format string, params ...interface{}) error {\n\treturn maskInternal(fmt.Sprintf(format, params...))\n}", "label": 5}
{"code": "public function setLifecycleConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\LifecycleConfig::class);\n        $this->lifecycle_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def clone(self):\n        \"\"\" Clone this expression \"\"\"\n        from copy import copy\n        clone = copy(self)\n        clone.expr = copy(self.expr)\n        clone.factory = False\n        return clone", "label": 1}
{"code": "public function setAudioConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\TextToSpeech\\V1\\AudioConfig::class);\n        $this->audio_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public RasterLayerInfo asLayerInfo(TileMap tileMap) {\n\t\tRasterLayerInfo layerInfo = new RasterLayerInfo();\n\n\t\tlayerInfo.setCrs(tileMap.getSrs());\n\t\tlayerInfo.setDataSourceName(tileMap.getTitle());\n\t\tlayerInfo.setLayerType(LayerType.RASTER);\n\t\tlayerInfo.setMaxExtent(asBbox(tileMap.getBoundingBox()));\n\t\tlayerInfo.setTileHeight(tileMap.getTileFormat().getHeight());\n\t\tlayerInfo.setTileWidth(tileMap.getTileFormat().getWidth());\n\n\t\tList<ScaleInfo> zoomLevels = new ArrayList<ScaleInfo>(tileMap.getTileSets().getTileSets().size());\n\t\tfor (TileSet tileSet : tileMap.getTileSets().getTileSets()) {\n\t\t\tzoomLevels.add(asScaleInfo(tileSet));\n\t\t}\n\t\tlayerInfo.setZoomLevels(zoomLevels);\n\n\t\treturn layerInfo;\n\t}", "label": 0}
{"code": "function (bodySchemaModels, defName) {\n        for (var i in bodySchemaModels) {\n            if (bodySchemaModels[i][\"name\"] == defName) {\n                return bodySchemaModels[i];\n            }\n        }\n        return null;\n    }", "label": 3}
{"code": "func (c *Client) DownloadRequest(ctx context.Context, u *url.URL, param *Download) (*http.Response, error) {\n\treq, err := http.NewRequest(param.Method, u.String(), nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq = req.WithContext(ctx)\n\n\tfor k, v := range param.Headers {\n\t\treq.Header.Add(k, v)\n\t}\n\n\tif param.Ticket != nil {\n\t\treq.AddCookie(param.Ticket)\n\t}\n\n\treturn c.Client.Do(req)\n}", "label": 5}
{"code": "public function setDateTime($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\DateTime::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "private function checksum($code)\n\t{\n\t\t$len = strlen($code);\n\t\t$sum = 0;\n\t\tfor ($i = 0; $i < $len; $i += 2) {\n\t\t\t$sum += $code[$i];\n\t\t}\n\t\t$sum *= 3;\n\t\tfor ($i = 1; $i < $len; $i += 2) {\n\t\t\t$sum += ($code[$i]);\n\t\t}\n\t\t$r = $sum % 10;\n\t\tif ($r > 0) {\n\t\t\t$r = (10 - $r);\n\t\t}\n\t\treturn $r;\n\t}", "label": 2}
{"code": "func (v VirtualMachine) RemoveAllSnapshot(ctx context.Context, consolidate *bool) (*Task, error) {\n\treq := types.RemoveAllSnapshots_Task{\n\t\tThis:        v.Reference(),\n\t\tConsolidate: consolidate,\n\t}\n\n\tres, err := methods.RemoveAllSnapshots_Task(ctx, v.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewTask(v.c, res.Returnval), nil\n}", "label": 5}
{"code": "func (ts *Store) IsRendered(id string) (bool, error) {\n\t// if the \"rendered\" flag file exists, assume that the store is already\n\t// fully rendered.\n\ttreepath := ts.GetPath(id)\n\t_, err := os.Stat(filepath.Join(treepath, renderedfilename))\n\tif os.IsNotExist(err) {\n\t\treturn false, nil\n\t}\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn true, nil\n}", "label": 5}
{"code": "public function addColumns(array $names, $order = false)\n    {\n        foreach ($names as $name => $attribute) {\n            if (is_int($name)) {\n                $name = $attribute;\n            }\n\n            $this->addColumn($name, function ($model) use ($attribute) {\n                return $model->getAttribute($attribute);\n            }, is_int($order) ? $order++ : $order);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "public function unserialize($data)\n    {\n        list(\n            $this->messageKey,\n            $this->batchEnabled,\n            $this->metadataProvider,\n            $this->debugOutput,\n            $this->clientConfig,\n            $this->batchMethod,\n            $this->logName,\n            $debugOutputResource\n        ) = unserialize($data);\n\n        if (is_array($debugOutputResource)) {\n            $this->debugOutputResource = fopen(\n                $debugOutputResource['uri'],\n                $debugOutputResource['mode']\n            );\n        }\n    }", "label": 2}
{"code": "def wrap_fusion(job,\n                fastqs,\n                star_output,\n                univ_options,\n                star_fusion_options,\n                fusion_inspector_options):\n    \"\"\"\n    A wrapper for run_fusion using the results from cutadapt and star as input.\n\n    :param tuple fastqs: RNA-Seq FASTQ Filestore IDs\n    :param dict star_output: Dictionary containing STAR output files\n    :param dict univ_options: universal arguments used by almost all tools\n    :param dict star_fusion_options: STAR-Fusion specific parameters\n    :param dict fusion_inspector_options: FusionInspector specific parameters\n    :return: Transgene BEDPE file\n    :rtype: toil.fileStore.FileID\n\n    \"\"\"\n    # Give user option to skip fusion calling\n    if not star_fusion_options['run']:\n        job.fileStore.logToMaster('Skipping STAR-Fusion on %s' % univ_options['patient'])\n        return\n\n    fusion = job.wrapJobFn(run_fusion, fastqs, star_output['rnaChimeric.out.junction'],\n                               univ_options, star_fusion_options, fusion_inspector_options,\n                               cores=star_fusion_options['n'],\n                               memory=PromisedRequirement(lambda x: int(1.85 * x.size),\n                                                          star_fusion_options['index']),\n                               disk=PromisedRequirement(fusion_disk,\n                                                        fastqs,\n                                                        star_fusion_options['index'])).encapsulate()\n    job.addChild(fusion)\n    return fusion.rv()", "label": 1}
{"code": "def create_page(location_id, body, opts = {})\n      data, _status_code, _headers = create_page_with_http_info(location_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "func getTypeInfo(typ reflect.Type) (*typeInfo, error) {\n\ttinfoLock.RLock()\n\ttinfo, ok := tinfoMap[typ]\n\ttinfoLock.RUnlock()\n\tif ok {\n\t\treturn tinfo, nil\n\t}\n\ttinfo = &typeInfo{}\n\tif typ.Kind() == reflect.Struct && typ != nameType {\n\t\tn := typ.NumField()\n\t\tfor i := 0; i < n; i++ {\n\t\t\tf := typ.Field(i)\n\t\t\tif f.PkgPath != \"\" || f.Tag.Get(\"xml\") == \"-\" {\n\t\t\t\tcontinue // Private field\n\t\t\t}\n\n\t\t\t// For embedded structs, embed its fields.\n\t\t\tif f.Anonymous {\n\t\t\t\tt := f.Type\n\t\t\t\tif t.Kind() == reflect.Ptr {\n\t\t\t\t\tt = t.Elem()\n\t\t\t\t}\n\t\t\t\tif t.Kind() == reflect.Struct {\n\t\t\t\t\tinner, err := getTypeInfo(t)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tif tinfo.xmlname == nil {\n\t\t\t\t\t\ttinfo.xmlname = inner.xmlname\n\t\t\t\t\t}\n\t\t\t\t\tfor _, finfo := range inner.fields {\n\t\t\t\t\t\tfinfo.idx = append([]int{i}, finfo.idx...)\n\t\t\t\t\t\tif err := addFieldInfo(typ, tinfo, &finfo); err != nil {\n\t\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfinfo, err := structFieldInfo(typ, &f)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tif f.Name == \"XMLName\" {\n\t\t\t\ttinfo.xmlname = finfo\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Add the field if it doesn't conflict with other fields.\n\t\t\tif err := addFieldInfo(typ, tinfo, finfo); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\ttinfoLock.Lock()\n\ttinfoMap[typ] = tinfo\n\ttinfoLock.Unlock()\n\treturn tinfo, nil\n}", "label": 5}
{"code": "public void unbind(String name) throws ObjectNameNotFoundException\r\n    {\r\n        /**\r\n         * Is DB open? ODMG 3.0 says it has to be to call unbind.\r\n         */\r\n        if (!this.isOpen())\r\n        {\r\n            throw new DatabaseClosedException(\"Database is not open. Must have an open DB to call unbind\");\r\n        }\r\n        TransactionImpl tx = getTransaction();\r\n        if (tx == null || !tx.isOpen())\r\n        {\r\n            throw new TransactionNotInProgressException(\"Tx is not open. Must have an open TX to call lookup.\");\r\n        }\r\n\r\n        tx.getNamedRootsMap().unbind(name);\r\n    }", "label": 0}
{"code": "public function setGceClusterConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1\\GceClusterConfig::class);\n        $this->gce_cluster_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "protected function transform($results, $processed)\n    {\n        if (isset($this->transformer) && class_exists('Yajra\\\\DataTables\\\\Transformers\\\\FractalTransformer')) {\n            return app('datatables.transformer')->transform(\n                $results,\n                $this->transformer,\n                $this->serializer ?? null\n            );\n        }\n\n        return Helper::transform($processed);\n    }", "label": 2}
{"code": "public static java.sql.Timestamp toTimestamp(Object value) throws ParseException {\n        if (value == null) {\n            return null;\n        }\n        if (value instanceof java.sql.Timestamp) {\n            return (java.sql.Timestamp) value;\n        }\n        if (value instanceof String) {\n\n            if (\"\".equals((String) value)) {\n                return null;\n            }\n            return new java.sql.Timestamp(IN_TIMESTAMP_FORMAT.parse((String) value).getTime());\n        }\n\n        return new java.sql.Timestamp(IN_TIMESTAMP_FORMAT.parse(value.toString()).getTime());\n    }", "label": 0}
{"code": "def pins\n      msgs = API::Channel.pinned_messages(@bot.token, @id)\n      JSON.parse(msgs).map { |msg| Message.new(msg, @bot) }\n    end", "label": 4}
{"code": "public function setAudioEncoding($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\TextToSpeech\\V1\\AudioEncoding::class);\n        $this->audio_encoding = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setPrerequisiteStepIds($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->prerequisite_step_ids = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "protected void addImage(PdfContext context, ImageResult imageResult) throws BadElementException, IOException {\n\t\tBbox imageBounds = imageResult.getRasterImage().getBounds();\n\t\tfloat scaleFactor = (float) (72 / getMap().getRasterResolution());\n\t\tfloat width = (float) imageBounds.getWidth() * scaleFactor;\n\t\tfloat height = (float) imageBounds.getHeight() * scaleFactor;\n\t\t// subtract screen position of lower-left corner\n\t\tfloat x = (float) (imageBounds.getX() - rasterScale * bbox.getMinX()) * scaleFactor;\n\t\t// shift y to lowerleft corner, flip y to user space and subtract\n\t\t// screen position of lower-left\n\t\t// corner\n\t\tfloat y = (float) (-imageBounds.getY() - imageBounds.getHeight() - rasterScale * bbox.getMinY()) * scaleFactor;\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"adding image, width=\" + width + \",height=\" + height + \",x=\" + x + \",y=\" + y);\n\t\t}\n\t\t// opacity\n\t\tlog.debug(\"before drawImage\");\n\t\tcontext.drawImage(Image.getInstance(imageResult.getImage()), new Rectangle(x, y, x + width, y + height),\n\t\t\t\tgetSize(), getOpacity());\n\t\tlog.debug(\"after drawImage\");\n\t}", "label": 0}
{"code": "public function sendMessageRead($to, $id)\n    {\n        $listNode = null;\n        $idNode = $id;\n        if (is_array($id) && count($id > 1)) {\n            $idNode = array_shift($id);\n            foreach ($id as $itemId) {\n                $items[] = new ProtocolNode('item',\n                [\n                  'id' => $itemId,\n                ], null, null);\n            }\n            $listNode = new ProtocolNode('list', null, $items, null);\n        }\n\n        $messageNode = new ProtocolNode('receipt',\n        [\n          'type' => 'read',\n          't'    => time(),\n          'to'   => $this->getJID($to),\n          'id'   => $idNode,\n        ], [$listNode], null);\n\n        $this->sendNode($messageNode);\n    }", "label": 2}
{"code": "public static function getAllSessions($selenium_server_url = 'http://localhost:4444/wd/hub', $timeout_in_ms = 30000)\n    {\n        $executor = new HttpCommandExecutor($selenium_server_url);\n        $executor->setConnectionTimeout($timeout_in_ms);\n\n        $command = new WebDriverCommand(\n            null,\n            DriverCommand::GET_ALL_SESSIONS,\n            []\n        );\n\n        return $executor->execute($command)->getValue();\n    }", "label": 2}
{"code": "def _copy_status(self, filename, size, sent):\n        \"\"\" Echo status of an SCP operation.\n\n        Purpose: Callback function for an SCP operation. Used to show\n               | the progress of an actively running copy. This directly\n               | prints to stdout, one line for each file as it's copied.\n               | The parameters received by this function are those received\n               | from the scp.put or scp.get function, as explained in the\n               | python scp module docs.\n\n        @param filename: The filename of file being copied.\n        @type filename: str\n        @param size: The total size of the current file being copied.\n        @type size: str or float\n        @param sent: The amount of data sent for the current file being copied.\n        @type sent: str or float\n\n        @returns: None\n        \"\"\"\n        output = \"Transferred %.0f%% of the file %s\" % (\n            (float(sent) / float(size) * 100), path.normpath(filename))\n        output += (' ' * (120 - len(output)))\n        if filename != self._filename:\n            if self._filename is not None:\n                print('')\n            self._filename = filename\n        print(output, end='\\r')", "label": 1}
{"code": "def remove_workflow_responsibilities(role, allowed_agents)\n        wf_role = Sipity::WorkflowRole.find_by(workflow: self, role_id: role)\n        wf_role.workflow_responsibilities.where.not(agent: allowed_agents).destroy_all\n      end", "label": 4}
{"code": "def blank?(value)\n      if value.kind_of?(NilClass)\n        true\n      elsif value.kind_of?(String)\n        value !~ /\\S/\n      else\n        value.respond_to?(:empty?) ? value.empty? : !value\n      end\n    end", "label": 4}
{"code": "public void storeIfNew(final DbArtifact fromClient) {\n        final DbArtifact existing = repositoryHandler.getArtifact(fromClient.getGavc());\n\n        if(existing != null){\n            existing.setLicenses(fromClient.getLicenses());\n            store(existing);\n        }\n\n        if(existing == null){\n\t        store(fromClient);\n        }\n    }", "label": 0}
{"code": "function getDbName(uri) {\n  var parsedMongooseUri = mongoUriParser.parse(uri);\n  var dbName = parsedMongooseUri.database;\n  return dbName;\n}", "label": 3}
{"code": "protected function assertConnectionRole(NodeConnectionInterface $connection, $role)\n    {\n        $role = strtolower($role);\n        $actualRole = $connection->executeCommand(RawCommand::create('ROLE'));\n\n        if ($role !== $actualRole[0]) {\n            throw new RoleException($connection, \"Expected $role but got $actualRole[0] [$connection]\");\n        }\n    }", "label": 2}
{"code": "public static <T1, T2> Counter<T2> transform(Counter<T1> c, Function<T1, T2> f) {\r\n    Counter<T2> c2 = new ClassicCounter<T2>();\r\n    for (T1 key : c.keySet()) {\r\n      c2.setCount(f.apply(key), c.getCount(key));\r\n    }\r\n    return c2;\r\n  }", "label": 0}
{"code": "def import_class(classpath):\n    \"\"\"Import the class referred to by the fully qualified class path.\n\n    Args:\n        classpath: A full \"foo.bar.MyClass\" path to a class definition.\n\n    Returns:\n        The class referred to by the classpath.\n\n    Raises:\n        ImportError: If an error occurs while importing the module.\n        AttributeError: IF the class does not exist in the imported module.\n    \"\"\"\n    modname, classname = classpath.rsplit(\".\", 1)\n    module = importlib.import_module(modname)\n    klass  = getattr(module, classname)\n    return klass", "label": 1}
{"code": "public static String resolveProxyUrl(String relativeUrl, TileMap tileMap, String baseTmsUrl) {\n\t\tTileCode tc = parseTileCode(relativeUrl);\n\t\treturn buildUrl(tc, tileMap, baseTmsUrl);\n\t}", "label": 0}
{"code": "public function next()\n    {\n        $this->position++;\n        $this->page = $this->nextResultToken()\n            ? $this->executeCall()\n            : null;\n    }", "label": 2}
{"code": "func (pkg *Package) Imports() map[string]bool {\n\tim := make(map[string]bool)\n\tfor _, intf := range pkg.Interfaces {\n\t\tintf.addImports(im)\n\t}\n\treturn im\n}", "label": 5}
{"code": "function Route(path) {\n  this.path = path;\n  this.stack = [];\n  this.handle = compose(this.stack);\n\n  debug('new %s', path);\n\n  // route handlers for various http methods\n  this.methods = {};\n}", "label": 3}
{"code": "public function objectKey($n)\n\t{\n\t\tif ($this->useRC128Encryption) {\n\t\t\t$len = 16;\n\t\t} else {\n\t\t\t$len = 10;\n\t\t}\n\n\t\treturn substr($this->md5toBinary($this->encryptionKey . pack('VXxx', $n)), 0, $len);\n\t}", "label": 2}
{"code": "func (m *Manager) AddKeys(pkls []string, prefix string, accept AcceptOption) error {\n\tensureLogger(m.Debug)\n\tif m.Ks == nil {\n\t\treturn fmt.Errorf(\"no keystore available to add keys to\")\n\t}\n\n\tfor _, pkl := range pkls {\n\t\tu, err := url.Parse(pkl)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tpk, err := m.getPubKey(u)\n\t\tif err != nil {\n\t\t\treturn errwrap.Wrap(fmt.Errorf(\"error accessing the key %s\", pkl), err)\n\t\t}\n\t\tdefer pk.Close()\n\n\t\terr = displayKey(prefix, pkl, pk)\n\t\tif err != nil {\n\t\t\treturn errwrap.Wrap(fmt.Errorf(\"error displaying the key %s\", pkl), err)\n\t\t}\n\n\t\tif m.TrustKeysFromHTTPS && u.Scheme == \"https\" {\n\t\t\taccept = AcceptForce\n\t\t}\n\n\t\tif accept == AcceptAsk {\n\t\t\tif !terminal.IsTerminal(int(os.Stdin.Fd())) || !terminal.IsTerminal(int(os.Stderr.Fd())) {\n\t\t\t\tlog.Printf(\"To trust the key for %q, do one of the following:\", prefix)\n\t\t\t\tlog.Printf(\" - call rkt with --trust-keys-from-https\")\n\t\t\t\tlog.Printf(\" - run: rkt trust --prefix %q\", prefix)\n\t\t\t\treturn fmt.Errorf(\"error reviewing key: unable to ask user to review fingerprint due to lack of tty\")\n\t\t\t}\n\t\t\taccepted, err := reviewKey()\n\t\t\tif err != nil {\n\t\t\t\treturn errwrap.Wrap(errors.New(\"error reviewing key\"), err)\n\t\t\t}\n\t\t\tif !accepted {\n\t\t\t\tlog.Printf(\"not trusting %q\", pkl)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif accept == AcceptForce {\n\t\t\tstdout.Printf(\"Trusting %q for prefix %q without fingerprint review.\", pkl, prefix)\n\t\t} else {\n\t\t\tstdout.Printf(\"Trusting %q for prefix %q after fingerprint review.\", pkl, prefix)\n\t\t}\n\n\t\tif prefix == \"\" {\n\t\t\tpath, err := m.Ks.StoreTrustedKeyRoot(pk)\n\t\t\tif err != nil {\n\t\t\t\treturn errwrap.Wrap(errors.New(\"error adding root key\"), err)\n\t\t\t}\n\t\t\tstdout.Printf(\"Added root key at %q\", path)\n\t\t} else {\n\t\t\tpath, err := m.Ks.StoreTrustedKeyPrefix(prefix, pk)\n\t\t\tif err != nil {\n\t\t\t\treturn errwrap.Wrap(fmt.Errorf(\"error adding key for prefix %q\", prefix), err)\n\t\t\t}\n\t\t\tstdout.Printf(\"Added key for prefix %q at %q\", prefix, path)\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static authenticationlocalpolicy_binding get(nitro_service service, String name) throws Exception{\n\t\tauthenticationlocalpolicy_binding obj = new authenticationlocalpolicy_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationlocalpolicy_binding response = (authenticationlocalpolicy_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function(object, settings) {\n            settings = (settings === undefined) ? {} : settings;\n\n            if(system.isString(settings) || system.isNumber(settings)) {\n                settings = { space: settings };\n            }\n\n            return JSON.stringify(object, settings.replacer || this.replacer, settings.space || this.space);\n        }", "label": 3}
{"code": "def path(path_separator: ' - ', ancestors_first: true)\n      return title if root?\n\n      chain = ancestors_first ? self_and_ancestors : self_and_ancestors.reverse\n      chain.map(&:title).join(path_separator)\n    end", "label": 4}
{"code": "def respond_to?(name, include_private = false)\n      super || klass.respond_to?(name) || CHECK.respond_to?(name, include_private)\n    end", "label": 4}
{"code": "def commit_current_edit!\n      ensure_active_edit!\n\n      call_google_api { client.commit_edit(current_package_name, current_edit.id) }\n\n      self.current_edit = nil\n      self.current_package_name = nil\n    end", "label": 4}
{"code": "def get_plaintext_citations(arxiv_id):\n    \"\"\"\n    Get the citations of a given preprint, in plain text.\n\n    .. note::\n\n        Bulk download of sources from arXiv is not permitted by their API. \\\n                You should have a look at http://arxiv.org/help/bulk_data_s3.\n\n    :param arxiv_id: The arXiv id (e.g. ``1401.2910`` or ``1401.2910v1``) in \\\n            a canonical form.\n    :returns:  A list of cleaned plaintext citations.\n    \"\"\"\n    plaintext_citations = []\n    # Get the list of bbl files for this preprint\n    bbl_files = arxiv.get_bbl(arxiv_id)\n    for bbl_file in bbl_files:\n        # Fetch the cited DOIs for each of the bbl files\n        plaintext_citations.extend(bbl.get_plaintext_citations(bbl_file))\n    return plaintext_citations", "label": 1}
{"code": "def make_invite(max_age = 0, max_uses = 0, temporary = false, unique = false, reason = nil)\n      response = API::Channel.create_invite(@bot.token, @id, max_age, max_uses, temporary, unique, reason)\n      Invite.new(JSON.parse(response), @bot)\n    end", "label": 4}
{"code": "function value(utils) {\n  const target = this._obj,\n        value = target.value || null;\n  isValidation(target);\n  this.assert(null !== value,\n      '#{this} should have value',\n      '#{this} should not have value'\n  );\n  utils.flag(this, 'object', value);\n}", "label": 3}
{"code": "function resolve(value, conf, ring = []) {\n\tvalue.match(CONFIG_VAR_REGEX).forEach((variable) => {\n\t\tconst key = variable.substring(variable.lastIndexOf('${') + 2, variable.lastIndexOf('}'));\n\n\t\tif (ring.includes(key)) {\n\t\t\tthrow `Circular dependency error: cannot resolve variable(s) ${ring}.`;\n\t\t}\n\t\tring.push(key);\n\n\t\tlet resolved = conf[key];\n\t\tif (!resolved) {\n\t\t\tthrow `Could not resolve ${key} - make sure this key is defined in _config.yml.`;\n\t\t}\n\t\tif (CONFIG_VAR_REGEX.test(resolved)) {\n\t\t\tresolved = resolve(resolved, conf, ring);\n\t\t}\n\t\tvalue = value.replace(variable, resolved);\n\t\tring.pop();\n\t});\n\treturn value;\n}", "label": 3}
{"code": "func (pm *PortMapper) ReMapAll() {\n\tpm.lock.Lock()\n\tdefer pm.lock.Unlock()\n\tlogrus.Debugln(\"Re-applying all port mappings.\")\n\tfor _, data := range pm.currentMappings {\n\t\tcontainerIP, containerPort := getIPAndPort(data.container)\n\t\thostIP, hostPort := getIPAndPort(data.host)\n\t\tif err := pm.AppendForwardingTableEntry(data.proto, hostIP, hostPort, containerIP.String(), containerPort); err != nil {\n\t\t\tlogrus.Errorf(\"Error on iptables add: %s\", err)\n\t\t}\n\t}\n}", "label": 5}
{"code": "def build_packages(ctx, hide=False):\n    \"\"\"Build packages for this release.\"\"\"\n    print(\"build_packages:\")\n    ctx.run(\"python setup.py sdist bdist_wheel\", echo=True, hide=hide)", "label": 1}
{"code": "final public Boolean checkPositionType(String type) {\n    if (tokenPosition == null) {\n      return false;\n    } else {\n      return tokenPosition.checkType(type);\n    }\n  }", "label": 0}
{"code": "def build(self):\n        \"\"\"Do the query.\"\"\"\n        result = []\n        for entry in self.sequence:\n            ignore = False\n            for filter_function in self.filter_functions:\n                if not filter_function(entry):\n                    ignore = True\n                    break\n            if not ignore:\n                value = entry\n                for transform_function in self.transform_functions:\n                    value = transform_function(value)\n                result.append(value)\n        return result", "label": 1}
{"code": "function presentRendering(selector, classNames, speed) {\n    const text = document.getElementById(selector).childNodes[0];\n    const thisLength = text.length;\n\n    const render = (autoMarkText, cp, length) => {\n      let c = cp;\n      const r = new Rendering(document, {\n        className: classNames\n      });\n      const range = document.createRange();\n      range.setStart(autoMarkText, 0);\n      range.setEnd(autoMarkText, 1);\n      r.renderWithRange(range);\n      if (autoMarkText.parentNode.nextSibling) {\n        const nextText = autoMarkText.parentNode.nextSibling.childNodes[0];\n        setTimeout(() => {\n          render(nextText, ++c, length);\n        }, speed);\n      }\n    };\n\n    return render(text, 0, thisLength);\n  }", "label": 3}
{"code": "public SerialMessage getMessage(AlarmType alarmType) {\r\n\t\tlogger.debug(\"Creating new message for application command SENSOR_ALARM_GET for node {}\", this.getNode().getNodeId());\r\n\t\tSerialMessage result = new SerialMessage(this.getNode().getNodeId(), SerialMessage.SerialMessageClass.SendData, SerialMessage.SerialMessageType.Request, SerialMessage.SerialMessageClass.ApplicationCommandHandler, SerialMessage.SerialMessagePriority.Get);\r\n    \tbyte[] newPayload = { \t(byte) this.getNode().getNodeId(), \r\n    \t\t\t\t\t\t\t3, \r\n\t\t\t\t\t\t\t\t(byte) getCommandClass().getKey(), \r\n\t\t\t\t\t\t\t\t(byte) SENSOR_ALARM_GET,\r\n\t\t\t\t\t\t\t\t(byte) alarmType.getKey() };\r\n    \tresult.setMessagePayload(newPayload);\r\n    \treturn result;\t\t\r\n\t}", "label": 0}
{"code": "def get_imports(fname):\n    \"\"\" get a list of imports from a Python program \"\"\"\n    txt = ''\n    with open(fname, 'r') as f:\n        for line in f:\n            if line[0:6] == 'import':\n                txt += '<PRE>' + strip_text_after_string(line[7:], ' as ') + '</PRE>\\n'\n    return txt + '<BR>'", "label": 1}
{"code": "function unifiedDiff (err) {\n  let indent = '      '\n  function cleanUp (line) {\n    if (line[0] === '+') {\n      return indent + format.colorLines('green', line)\n    }\n    if (line[0] === '-') {\n      return indent + format.colorLines('red', line)\n    }\n    if (line.match(/@@/)) {\n      return null\n    }\n    if (line.match(/\\\\ No newline/)) {\n      return null\n    }\n    if (line.trim().length) {\n      line = format.colorLines('white', line)\n    }\n    return indent + line\n  }\n  function notBlank (line) {\n    return typeof line !== 'undefined' && line !== null\n  }\n  let msg = diff.createPatch('string', err.actual, err.expected)\n  let lines = msg.split('\\n').splice(4)\n  let diffResult = lines.map(cleanUp).filter(notBlank).join('\\n')\n  if (!diffResult.trim().length) {\n    msg = diff.createPatch(\n      'string',\n      stringify(Object.keys(err._actual || err.actual).sort()),\n      stringify(Object.keys(err._expected || err.expected).sort())\n    )\n    lines = msg.split('\\n').splice(4)\n    diffResult = format.red('       object keys not match: \\n') + lines.map(cleanUp).filter(notBlank).join('\\n')\n  }\n  return '\\n      ' +\n    format.colorLines('green', '+ expected') + ' ' +\n    format.colorLines('red', '- actual') +\n    '\\n\\n' +\n    diffResult\n}", "label": 3}
{"code": "func ExclusiveKeyLock(lockDir string, key string) (*KeyLock, error) {\n\treturn createAndLock(lockDir, key, keyLockExclusive)\n}", "label": 5}
{"code": "function _checkGSUBignore($flag, $glyph, $MarkFilteringSet)\n\t{\n\t\t$ignore = false;\n\t\t// Flag & 0x0008 = Ignore Marks\n\t\tif ((($flag & 0x0008) == 0x0008) && strpos($this->GlyphClassMarks, $glyph)) {\n\t\t\t$ignore = true;\n\t\t}\n\t\tif ((($flag & 0x0004) == 0x0004) && strpos($this->GlyphClassLigatures, $glyph)) {\n\t\t\t$ignore = true;\n\t\t}\n\t\tif ((($flag & 0x0002) == 0x0002) && strpos($this->GlyphClassBases, $glyph)) {\n\t\t\t$ignore = true;\n\t\t}\n\t\t// Flag & 0xFF?? = MarkAttachmentType\n\t\tif (($flag & 0xFF00) && strpos($this->MarkAttachmentType[($flag >> 8)], $glyph)) {\n\t\t\t$ignore = true;\n\t\t}\n\t\t// Flag & 0x0010 = UseMarkFilteringSet\n\t\tif (($flag & 0x0010) && strpos($this->MarkGlyphSets[$MarkFilteringSet], $glyph)) {\n\t\t\t$ignore = true;\n\t\t}\n\n\t\treturn $ignore;\n\t}", "label": 2}
{"code": "function _gpfDefAttr (name, base, definition) {\n    var\n        isAlias = name.charAt(0) === \"$\",\n        fullName,\n        result;\n    if (isAlias) {\n        name = name.substr(1);\n        fullName = name + \"Attribute\";\n    } else {\n        fullName = name;\n    }\n    result = _gpfDefAttrBase(fullName, base, definition);\n    if (isAlias) {\n        _gpfAlias(result, name);\n    }\n    return result;\n}", "label": 3}
{"code": "func (uw *UnitWriter) writeShutdownService(exec string, opts ...*unit.UnitOption) {\n\tif uw.err != nil {\n\t\treturn\n\t}\n\n\tflavor, systemdVersion, err := GetFlavor(uw.p)\n\tif err != nil {\n\t\tuw.err = errwrap.Wrap(errors.New(\"failed to create shutdown service\"), err)\n\t\treturn\n\t}\n\n\topts = append(opts, []*unit.UnitOption{\n\t\t// The default stdout is /dev/console (the tty created by nspawn).\n\t\t// But the tty might be destroyed if rkt is executed via ssh and\n\t\t// the user terminates the ssh session. We still want\n\t\t// shutdown.service to succeed in that case, so don't use\n\t\t// /dev/console.\n\t\tunit.NewUnitOption(\"Service\", \"StandardInput\", \"null\"),\n\t\tunit.NewUnitOption(\"Service\", \"StandardOutput\", \"null\"),\n\t\tunit.NewUnitOption(\"Service\", \"StandardError\", \"null\"),\n\t}...)\n\n\tshutdownVerb := \"exit\"\n\t// systemd <v227 doesn't allow the \"exit\" verb when running as PID 1, so\n\t// use \"halt\".\n\t// If systemdVersion is 0 it means it couldn't be guessed, assume it's new\n\t// enough for \"systemctl exit\".\n\t// This can happen, for example, when building rkt with:\n\t//\n\t// ./configure --with-stage1-flavors=src --with-stage1-systemd-version=master\n\t//\n\t// The patches for the \"exit\" verb are backported to the \"coreos\" flavor, so\n\t// don't rely on the systemd version on the \"coreos\" flavor.\n\tif flavor != \"coreos\" && systemdVersion != 0 && systemdVersion < 227 {\n\t\tshutdownVerb = \"halt\"\n\t}\n\n\topts = append(\n\t\topts,\n\t\tunit.NewUnitOption(\"Service\", exec, fmt.Sprintf(\"/usr/bin/systemctl --force %s\", shutdownVerb)),\n\t)\n\n\tuw.WriteUnit(\n\t\tServiceUnitPath(uw.p.Root, \"shutdown\"),\n\t\t\"failed to create shutdown service\",\n\t\topts...,\n\t)\n}", "label": 5}
{"code": "func NewAppcFromApp(app *discovery.App) Distribution {\n\trawuri := NewCIMDString(TypeAppc, distAppcVersion, url.QueryEscape(app.Name.String()))\n\n\tvar version string\n\tlabels := types.Labels{}\n\tfor n, v := range app.Labels {\n\t\tif n == \"version\" {\n\t\t\tversion = v\n\t\t}\n\n\t\tlabels = append(labels, types.Label{Name: n, Value: v})\n\t}\n\n\tif len(labels) > 0 {\n\t\tqueries := make([]string, len(labels))\n\t\trawuri += \"?\"\n\t\tfor i, l := range labels {\n\t\t\tqueries[i] = fmt.Sprintf(\"%s=%s\", l.Name, url.QueryEscape(l.Value))\n\t\t}\n\t\trawuri += strings.Join(queries, \"&\")\n\t}\n\n\tu, err := url.Parse(rawuri)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"cannot parse URI %q: %v\", rawuri, err))\n\t}\n\n\t// save the URI as sorted to make it ready for comparison\n\tpurell.NormalizeURL(u, purell.FlagSortQuery)\n\n\tstr := app.Name.String()\n\tif version != \"\" {\n\t\tstr += fmt.Sprintf(\":%s\", version)\n\t}\n\n\tlabelsort.By(labelsort.RankedName).Sort(labels)\n\tfor _, l := range labels {\n\t\tif l.Name != \"version\" {\n\t\t\tstr += fmt.Sprintf(\",%s=%s\", l.Name, l.Value)\n\t\t}\n\t}\n\n\treturn &Appc{\n\t\tcimd: u,\n\t\tapp:  app.Copy(),\n\t\tstr:  str,\n\t}\n}", "label": 5}
{"code": "function(e, win) {\n      var event = $.event.get(e, win);\n      var wheel = $.event.getWheel(event);\n      that.handleEvent('MouseWheel', e, win, wheel);\n    }", "label": 3}
{"code": "public function getPosition()\n    {\n        $position = $this->executor->execute(\n            DriverCommand::GET_WINDOW_POSITION,\n            [':windowHandle' => 'current']\n        );\n\n        return new WebDriverPoint(\n            $position['x'],\n            $position['y']\n        );\n    }", "label": 2}
{"code": "public function setType($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\V1\\Type::class);\n        $this->type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def outputDeflections(self):\n    \"\"\"\n    Outputs a grid of deflections if an output directory is defined in the \n    configuration file\n    \n    If the filename given in the configuration file ends in \".npy\", then a binary \n    numpy grid will be exported.\n    \n    Otherwise, an ASCII grid will be exported.\n    \"\"\"\n    try:\n      # If wOutFile exists, has already been set by a setter\n      self.wOutFile\n      if self.Verbose:\n        print(\"Output filename provided.\")\n    # Otherwise, it needs to be set by an configuration file\n    except:\n      try:\n        self.wOutFile = self.configGet(\"string\", \"output\", \"DeflectionOut\", optional=True)\n      except:\n        # if there is no parsable output string, do not generate output;\n        # this allows the user to leave the line blank and produce no output\n        if self.Debug:\n          print(\"No output filename provided:\")\n          print(\"  not writing any deflection output to file\")\n    if self.wOutFile:\n        if self.wOutFile[-4:] == '.npy':\n          from numpy import save\n          save(self.wOutFile,self.w)\n        else:\n          from numpy import savetxt\n          # Shouldn't need more than mm precision, at very most\n          savetxt(self.wOutFile,self.w,fmt='%.3f')\n          if self.Verbose:\n            print(\"Saving deflections --> \" + self.wOutFile)", "label": 1}
{"code": "func (mr *MockIndexMockRecorder) Anon(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Anon\", reflect.TypeOf((*MockIndex)(nil).Anon), arg0)\n}", "label": 5}
{"code": "def dumps(cfg):\n    '''Serialize ``cfg`` into a libconfig-formatted ``str``\n\n    ``cfg`` must be a ``dict`` with ``str`` keys and libconf-supported values\n    (numbers, strings, booleans, possibly nested dicts, lists, and tuples).\n\n    Returns the formatted string.\n    '''\n\n    str_file = io.StringIO()\n    dump(cfg, str_file)\n    return str_file.getvalue()", "label": 1}
{"code": "private void registerPrefix(String field, String prefix,\n      IndexOutput outPrefix) throws IOException {\n    if (!prefixReferenceIndex.containsKey(field)) {\n      prefixReferenceIndex.put(field, new HashMap<String, Long>());\n      prefixIdIndex.put(field, new HashMap<String, Integer>());\n    }\n    if (!prefixReferenceIndex.get(field).containsKey(prefix)) {\n      int id = 1 + prefixReferenceIndex.get(field).size();\n      prefixReferenceIndex.get(field).put(prefix, outPrefix.getFilePointer());\n      prefixIdIndex.get(field).put(prefix, id);\n      outPrefix.writeString(prefix);\n    }\n  }", "label": 0}
{"code": "def get_user_id(remote, email):\n    \"\"\"Get the Globus identity for a users given email.\n\n    A Globus ID is a UUID that can uniquely identify a Globus user. See the\n    docs here for v2/api/identities\n    https://docs.globus.org/api/auth/reference/\n    \"\"\"\n    try:\n        url = '{}?usernames={}'.format(GLOBUS_USER_ID_URL, email)\n        user_id = get_dict_from_response(remote.get(url))\n        return user_id['identities'][0]['id']\n    except KeyError:\n        # If we got here the response was successful but the data was invalid.\n        # It's likely the URL is wrong but possible the API has changed.\n        raise OAuthResponseError('Failed to fetch user id, likely server '\n                                 'mis-configuration', None, remote)", "label": 1}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo]) do\n        permit VALID_DEPLOYMENTS_OPTIONS\n        assert_required %w[ ref ]\n      end\n      params = arguments.params\n      params['accept'] ||= PREVIEW_MEDIA\n\n      post_request(\"repos/#{arguments.user}/#{arguments.repo}/deployments\", arguments.params)\n    end", "label": 4}
{"code": "def autoload_module!(into, const_name, qualified_name, path_suffix)\n      return nil unless base_path = autoloadable_module?(path_suffix)\n      mod = Module.new\n      into.const_set const_name, mod\n      log(\"constant #{qualified_name} autoloaded (module autovivified from #{File.join(base_path, path_suffix)})\")\n      autoloaded_constants << qualified_name unless autoload_once_paths.include?(base_path)\n      autoloaded_constants.uniq!\n      mod\n    end", "label": 4}
{"code": "public void linkOneToOne(Object obj, ClassDescriptor cld, ObjectReferenceDescriptor rds, boolean insert)\n    {\n        storeAndLinkOneToOne(true, obj, cld, rds, true);\n    }", "label": 0}
{"code": "def to_h\n      {\n          event_id:   event_id,\n          metadata:   metadata.to_h,\n          data:       data,\n          type:       type,\n      }\n    end", "label": 4}
{"code": "public static function elementSelectionStateToBe($element_or_by, $selected)\n    {\n        if ($element_or_by instanceof WebDriverElement) {\n            return new static(\n                function () use ($element_or_by, $selected) {\n                    return $element_or_by->isSelected() === $selected;\n                }\n            );\n        } else {\n            if ($element_or_by instanceof WebDriverBy) {\n                return new static(\n                    function (WebDriver $driver) use ($element_or_by, $selected) {\n                        try {\n                            $element = $driver->findElement($element_or_by);\n\n                            return $element->isSelected() === $selected;\n                        } catch (StaleElementReferenceException $e) {\n                            return null;\n                        }\n                    }\n                );\n            }\n        }\n    }", "label": 2}
{"code": "function updateSigninStatus(isSignedIn) {\n\tif (isSignedIn) {\n\t\tauthorizeButton.style.display = 'none';\n\t\tsignoutButton.style.display = 'block';\n\t\tlistFiles();\n\t} else {\n\t\tauthorizeButton.style.display = 'block';\n\t\tsignoutButton.style.display = 'none';\n\t}\n}", "label": 3}
{"code": "def deny_user(user):\n    \"\"\"Deny a user identified by an email address.\"\"\"\n    def processor(action, argument):\n        db.session.add(\n            ActionUsers.deny(action, argument=argument, user_id=user.id)\n        )\n    return processor", "label": 1}
{"code": "public static function missingRequiredOption($field, $expectedOption, $hint = '')\n    {\n        $message = sprintf(\"The mapping of field '%s' is invalid: The option '%s' is required.\", $field, $expectedOption);\n\n        if (! empty($hint)) {\n            $message .= ' (Hint: ' . $hint . ')';\n        }\n\n        return new self($message);\n    }", "label": 2}
{"code": "func (s *AuthServer) CheckPasswordWOToken(user string, password []byte) error {\n\tconst errMsg = \"invalid username or password\"\n\n\terr := services.VerifyPassword(password)\n\tif err != nil {\n\t\treturn trace.BadParameter(errMsg)\n\t}\n\n\thash, err := s.GetPasswordHash(user)\n\tif err != nil && !trace.IsNotFound(err) {\n\t\treturn trace.Wrap(err)\n\t}\n\tif trace.IsNotFound(err) {\n\t\tlog.Debugf(\"Username %q not found, using fake hash to mitigate timing attacks.\", user)\n\t\thash = fakePasswordHash\n\t}\n\n\tif err = bcrypt.CompareHashAndPassword(hash, password); err != nil {\n\t\tlog.Debugf(\"Password for %q does not match\", user)\n\t\treturn trace.BadParameter(errMsg)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func FromStringOrNil(input string) UUID {\n\tuuid, err := FromString(input)\n\tif err != nil {\n\t\treturn Nil\n\t}\n\treturn uuid\n}", "label": 5}
{"code": "public void updateDownLoadUrl(final String gavc, final String downLoadUrl) {\n        final DbArtifact artifact = getArtifact(gavc);\n        repositoryHandler.updateDownloadUrl(artifact, downLoadUrl);\n    }", "label": 0}
{"code": "function serviceCall(req, res, next) {\n        Q(pushService.registerPushDevice(req.body)).then(res.json.bind(res), next).done();\n    }", "label": 3}
{"code": "def valid_request_origin? # :doc:\n        if forgery_protection_origin_check\n          # We accept blank origin headers because some user agents don't send it.\n          raise InvalidAuthenticityToken, NULL_ORIGIN_MESSAGE if request.origin == \"null\"\n          request.origin.nil? || request.origin == request.base_url\n        else\n          true\n        end\n      end", "label": 4}
{"code": "private function determineState($result)\n    {\n        foreach ($this->config['acceptors'] as $acceptor) {\n            $matcher = 'matches' . ucfirst($acceptor['matcher']);\n            if ($this->{$matcher}($result, $acceptor)) {\n                return $acceptor['state'];\n            }\n        }\n\n        return $result instanceof \\Exception ? 'failed' : 'retry';\n    }", "label": 2}
{"code": "func CreateTLSConfiguration(certFile, keyFile string, cipherSuites []uint16) (*tls.Config, error) {\n\tconfig := TLSConfig(cipherSuites)\n\n\tif _, err := os.Stat(certFile); err != nil {\n\t\treturn nil, trace.BadParameter(\"certificate is not accessible by '%v'\", certFile)\n\t}\n\tif _, err := os.Stat(keyFile); err != nil {\n\t\treturn nil, trace.BadParameter(\"certificate is not accessible by '%v'\", certFile)\n\t}\n\n\tcert, err := tls.LoadX509KeyPair(certFile, keyFile)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tconfig.Certificates = []tls.Certificate{cert}\n\n\treturn config, nil\n}", "label": 5}
{"code": "def method_missing(method_sym, *arguments, &_block)\n      # We have to go inside the fastlane directory\n      # since in the fastlane runner.rb we do the following\n      #   custom_dir = \"..\"\n      #   Dir.chdir(custom_dir) do\n      # this goes one folder up, since we're inside the \"fastlane\"\n      # folder at that point\n      # Since we call an action from an action we need to go inside\n      # the fastlane folder too\n\n      self.runner.trigger_action_by_name(method_sym,\n                                         FastlaneCore::FastlaneFolder.path,\n                                         true,\n                                         *arguments)\n    end", "label": 4}
{"code": "protected void beforeMaterialization()\r\n\t{\r\n\t\tif (_listeners != null)\r\n\t\t{\r\n\t\t\tMaterializationListener listener;\r\n\r\n\t\t\tfor (int idx = _listeners.size() - 1; idx >= 0; idx--)\r\n\t\t\t{\r\n\t\t\t\tlistener = (MaterializationListener) _listeners.get(idx);\r\n\t\t\t\tlistener.beforeMaterialization(this, _id);\r\n\t\t\t}\r\n\t\t}\r\n\t}", "label": 0}
{"code": "func (e *podEnv) netPluginAdd(n *activeNet, netns string) error {\n\toutput, err := e.execNetPlugin(\"ADD\", n, netns)\n\tif err != nil {\n\t\treturn pluginErr(err, output)\n\t}\n\n\tpr := cnitypes.Result{}\n\tif err = json.Unmarshal(output, &pr); err != nil {\n\t\terr = errwrap.Wrap(fmt.Errorf(\"parsing %q\", string(output)), err)\n\t\treturn errwrap.Wrap(fmt.Errorf(\"error parsing %q result\", n.conf.Name), err)\n\t}\n\n\tif pr.IP4 == nil {\n\t\treturn nil // TODO(casey) should this be an error?\n\t}\n\n\t// All is well - mutate the runtime\n\tn.runtime.MergeCNIResult(pr)\n\treturn nil\n}", "label": 5}
{"code": "def sign_in(authenticatable)\n      key = cookie_name(authenticatable.class)\n      cookies.encrypted.permanent[key] = {value: authenticatable.id}\n      authenticatable\n    end", "label": 4}
{"code": "func AddFlags(flags []CliFlag) {\n\tfor _, flag := range flags {\n\t\tappflags = append(appflags, flag)\n\t}\n}", "label": 5}
{"code": "public function setContext($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\ErrorReporting\\V1beta1\\ErrorContext::class);\n        $this->context = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func reverseIndexRune(s string, r rune) int {\n\tif s == \"\" {\n\t\treturn -1\n\t}\n\n\trs := []rune(s)\n\tfor i := len(rs) - 1; i >= 0; i-- {\n\t\tif rs[i] == r {\n\t\t\treturn i\n\t\t}\n\t}\n\n\treturn -1\n}", "label": 5}
{"code": "function(\n    /*number*/ combinedWidth,\n    /*number*/ leftOffset,\n    /*number*/ cellWidth,\n    /*?number*/ cellMinWidth,\n    /*?number*/ cellMaxWidth,\n    /*number|string*/ columnKey,\n    /*object*/ event) {\n    if (Locale.isRTL()) {\n      leftOffset = -leftOffset;\n    }\n    this.setState({\n      isColumnResizing: true,\n      columnResizingData: {\n        left: leftOffset + combinedWidth - cellWidth,\n        width: cellWidth,\n        minWidth: cellMinWidth,\n        maxWidth: cellMaxWidth,\n        initialEvent: {\n          clientX: event.clientX,\n          clientY: event.clientY,\n          preventDefault: emptyFunction\n        },\n        key: columnKey\n      }\n    });\n  }", "label": 3}
{"code": "protected function call($commandID, array $arguments = array())\n    {\n        $response = $this->client->executeCommand(\n            $this->client->createCommand($commandID, $arguments)\n        );\n\n        if ($response instanceof ErrorResponseInterface) {\n            throw new ServerException($response->getMessage());\n        }\n\n        return $response;\n    }", "label": 2}
{"code": "def reload_root_document\n      {}.merge(collection.find({ _id: _id }, session: _session).read(mode: :primary).first || {})\n    end", "label": 4}
{"code": "def getResource(self, pid, destination=None, unzip=False, wait_for_bag_creation=True):\n        \"\"\" Get a resource in BagIt format\n\n        :param pid: The HydroShare ID of the resource\n        :param destination: String representing the directory to save bag to. Bag will be saved to file named\n            $(PID).zip in destination; existing file of the same name will be overwritten. If None, a stream to the\n            zipped bag will be returned instead.\n        :param unzip: True if the bag should be unzipped when saved to destination. Bag contents to be saved to\n            directory named $(PID) residing in destination. Only applies when destination is not None.\n\n        :param wait_for_bag_creation: True if to wait to download the bag in case the bag is not ready\n            (bag needs to be recreated before it can be downloaded).\n        :raises: HydroShareArgumentException if any arguments are invalid.\n        :raises: HydroShareNotAuthorized if the user is not authorized to access the\n            resource.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException to signal an HTTP error\n        :raise: HydroShareBagNotReady if the bag is not ready to be downloaded and wait_for_bag_creation is False\n\n        :return: None if the bag was saved directly to disk.  Or a generator representing a buffered stream of the\n            bytes comprising the bag returned by the REST end point.\n        \"\"\"\n        stream = self._getBagStream(pid, wait_for_bag_creation)\n        if destination:\n            self._storeBagOnFilesystem(stream, pid, destination, unzip)\n            return None\n        else:\n            return stream", "label": 1}
{"code": "public static final String getSelectedText(ListBox list) {\n\tint index = list.getSelectedIndex();\n\treturn (index >= 0) ? list.getItemText(index) : null;\n    }", "label": 0}
{"code": "protected function connection_redirect($args)\n    {\n        $host = $args->read_shortstr();\n        $this->known_hosts = $args->read_shortstr();\n        $this->debug->debug_msg(sprintf(\n                'Redirected to [%s], known_hosts [%s]',\n                $host,\n                $this->known_hosts\n            ));\n\n        return $host;\n    }", "label": 2}
{"code": "public static function anyPathName($project, $database, $document, $anyPath)\n    {\n        return self::getAnyPathNameTemplate()->render([\n            'project' => $project,\n            'database' => $database,\n            'document' => $document,\n            'any_path' => $anyPath,\n        ]);\n    }", "label": 2}
{"code": "def resolve_class(classref):\n    \"\"\"Attempt to return a Python class for the input class reference.\n\n    If `classref` is a class or None, return it. If `classref` is a\n    python classpath (e.g., \"foo.bar.MyClass\") import the class and return\n    it.\n\n    Args:\n        classref: A fully-qualified Python path to class, or a Python class.\n\n    Returns:\n        A class.\n    \"\"\"\n    if classref is None:\n        return None\n    elif isinstance(classref, six.class_types):\n        return classref\n    elif isinstance(classref, six.string_types):\n        return import_class(classref)\n    else:\n        raise ValueError(\"Unable to resolve class for '%s'\" % classref)", "label": 1}
{"code": "func (c *Client) PostForm(\n\tendpoint string,\n\tvals url.Values,\n\tfiles ...roundtrip.File) (*roundtrip.Response, error) {\n\treturn httplib.ConvertResponse(c.Client.PostForm(context.TODO(), endpoint, vals, files...))\n}", "label": 5}
{"code": "function getGid(groupname, options) {\n  const gid = _.tryOnce(findGroup(groupname, options), 'id');\n  return _.isUndefined(gid) ? null : gid;\n}", "label": 3}
{"code": "func (cmd *find) rootMatch(ctx context.Context, root object.Reference, client *vim25.Client, filter property.Filter) bool {\n\tref := root.Reference()\n\n\tif !cmd.kind.wanted(ref.Type) {\n\t\treturn false\n\t}\n\n\tif len(filter) == 1 && filter[\"name\"] == \"*\" {\n\t\treturn true\n\t}\n\n\tvar content []types.ObjectContent\n\n\tpc := property.DefaultCollector(client)\n\t_ = pc.RetrieveWithFilter(ctx, []types.ManagedObjectReference{ref}, filter.Keys(), &content, filter)\n\n\treturn content != nil\n}", "label": 5}
{"code": "def conflicts_with?(other_schedule, closing_time = nil)\n      closing_time = TimeUtil.ensure_time(closing_time)\n      unless terminating? || other_schedule.terminating? || closing_time\n        raise ArgumentError, \"One or both schedules must be terminating to use #conflicts_with?\"\n      end\n      # Pick the terminating schedule, and other schedule\n      # No need to reverse if terminating? or there is a closing time\n      terminating_schedule = self\n      unless terminating? || closing_time\n        terminating_schedule, other_schedule = other_schedule, terminating_schedule\n      end\n      # Go through each occurrence of the terminating schedule and determine\n      # if the other occurs at that time\n      #\n      last_time = nil\n      terminating_schedule.each_occurrence do |time|\n        if closing_time && time > closing_time\n          last_time = closing_time\n          break\n        end\n        last_time = time\n        return true if other_schedule.occurring_at?(time)\n      end\n      # Due to durations, we need to walk up to the end time, and verify in the\n      # other direction\n      if last_time\n        last_time += terminating_schedule.duration\n        other_schedule.each_occurrence do |time|\n          break if time > last_time\n          return true if terminating_schedule.occurring_at?(time)\n        end\n      end\n      # No conflict, return false\n      false\n    end", "label": 4}
{"code": "def delete_role(role_id)\n      @roles.reject! { |r| r.id == role_id }\n      @members.each do |_, member|\n        new_roles = member.roles.reject { |r| r.id == role_id }\n        member.update_roles(new_roles)\n      end\n      @channels.each do |channel|\n        overwrites = channel.permission_overwrites.reject { |id, _| id == role_id }\n        channel.update_overwrites(overwrites)\n      end\n    end", "label": 4}
{"code": "public function scopeWhereSubjectVisibleTo(Builder $query, User $actor)\n    {\n        $query->where(function ($query) use ($actor) {\n            $classes = [];\n\n            foreach (static::$subjectModels as $type => $class) {\n                $classes[$class][] = $type;\n            }\n\n            foreach ($classes as $class => $types) {\n                $query->orWhere(function ($query) use ($types, $class, $actor) {\n                    $query->whereIn('type', $types)\n                        ->whereExists(function ($query) use ($class, $actor) {\n                            $query->selectRaw(1)\n                                ->from((new $class)->getTable())\n                                ->whereColumn('id', 'subject_id');\n\n                            static::$dispatcher->dispatch(\n                                new ScopeModelVisibility($class::query()->setQuery($query), $actor, 'view')\n                            );\n                        });\n                });\n            }\n        });\n    }", "label": 2}
{"code": "def check_for_missing_enabled_option(hash)\n      return unless @log\n\n      any_warnings = false\n\n      Overcommit::Utils.supported_hook_type_classes.each do |hook_type|\n        hash.fetch(hook_type) { {} }.each do |hook_name, hook_config|\n          next if hook_name == 'ALL'\n\n          if hook_config['enabled'].nil?\n            @log.warning \"#{hook_type}::#{hook_name} hook does not explicitly \" \\\n                         'set `enabled` option in .overcommit.yml'\n            any_warnings = true\n          end\n        end\n      end\n\n      @log.newline if any_warnings\n    end", "label": 4}
{"code": "def args_without_command_name\n      removed = []\n      parts = command_name_from_args.split rescue []\n      @args.dup.delete_if do |arg|\n        removed << arg if parts.include?(arg) && !removed.include?(arg)\n      end\n    end", "label": 4}
{"code": "def unlock!(token = nil)\n      token ||= jid\n\n      Scripts.call(\n        :unlock,\n        redis_pool,\n        keys: [exists_key, grabbed_key, available_key, version_key, UNIQUE_SET, unique_digest],\n        argv: [token, ttl, lock_type],\n      )\n    end", "label": 4}
{"code": "public static function render( &$synopsis ) {\n\t\tif ( ! is_array( $synopsis ) ) {\n\t\t\treturn '';\n\t\t}\n\t\t$bits               = [\n\t\t\t'positional' => '',\n\t\t\t'assoc'      => '',\n\t\t\t'generic'    => '',\n\t\t\t'flag'       => '',\n\t\t];\n\t\t$reordered_synopsis = [\n\t\t\t'positional' => [],\n\t\t\t'assoc'      => [],\n\t\t\t'generic'    => [],\n\t\t\t'flag'       => [],\n\t\t];\n\t\tforeach ( $bits as $key => &$value ) {\n\t\t\tforeach ( $synopsis as $arg ) {\n\t\t\t\tif ( empty( $arg['type'] )\n\t\t\t\t\t|| $key !== $arg['type'] ) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif ( empty( $arg['name'] ) && 'generic' !== $arg['type'] ) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif ( 'positional' === $key ) {\n\t\t\t\t\t$rendered_arg = \"<{$arg['name']}>\";\n\n\t\t\t\t\t$reordered_synopsis['positional'] [] = $arg;\n\t\t\t\t} elseif ( 'assoc' === $key ) {\n\t\t\t\t\t$arg_value    = isset( $arg['value']['name'] ) ? $arg['value']['name'] : $arg['name'];\n\t\t\t\t\t$rendered_arg = \"--{$arg['name']}=<{$arg_value}>\";\n\n\t\t\t\t\t$reordered_synopsis['assoc'] [] = $arg;\n\t\t\t\t} elseif ( 'generic' === $key ) {\n\t\t\t\t\t$rendered_arg = '--<field>=<value>';\n\n\t\t\t\t\t$reordered_synopsis['generic'] [] = $arg;\n\t\t\t\t} elseif ( 'flag' === $key ) {\n\t\t\t\t\t$rendered_arg = \"--{$arg['name']}\";\n\n\t\t\t\t\t$reordered_synopsis['flag'] [] = $arg;\n\t\t\t\t}\n\t\t\t\tif ( ! empty( $arg['repeating'] ) ) {\n\t\t\t\t\t$rendered_arg = \"{$rendered_arg}...\";\n\t\t\t\t}\n\t\t\t\tif ( ! empty( $arg['optional'] ) ) {\n\t\t\t\t\t$rendered_arg = \"[{$rendered_arg}]\";\n\t\t\t\t}\n\t\t\t\t$value .= \"{$rendered_arg} \";\n\t\t\t}\n\t\t}\n\t\t$rendered = '';\n\t\tforeach ( $bits as $v ) {\n\t\t\tif ( ! empty( $v ) ) {\n\t\t\t\t$rendered .= $v;\n\t\t\t}\n\t\t}\n\n\t\t$synopsis = array_merge(\n\t\t\t$reordered_synopsis['positional'],\n\t\t\t$reordered_synopsis['assoc'],\n\t\t\t$reordered_synopsis['generic'],\n\t\t\t$reordered_synopsis['flag']\n\t\t);\n\n\t\treturn rtrim( $rendered, ' ' );\n\t}", "label": 2}
{"code": "def POST\n      fetch_header(\"action_dispatch.request.request_parameters\") do\n        pr = parse_formatted_parameters(params_parsers) do |params|\n          super || {}\n        end\n        self.request_parameters = Request::Utils.normalize_encode_params(pr)\n      end\n    rescue Rack::Utils::ParameterTypeError, Rack::Utils::InvalidParameterError => e\n      raise ActionController::BadRequest.new(\"Invalid request parameters: #{e.message}\")\n    end", "label": 4}
{"code": "def add_business_days(date, delta)\n      date = roll_forward(date)\n      delta.times do\n        begin\n          date += day_interval_for(date)\n        end until business_day?(date)\n      end\n      date\n    end", "label": 4}
{"code": "def _varian(self, varian):\n        \"\"\"Mengembalikan representasi string untuk varian entri ini.\n        Dapat digunakan untuk \"Varian\" maupun \"Bentuk tidak baku\".\n\n        :param varian: List bentuk tidak baku atau varian\n        :type varian: list\n        :returns: String representasi varian atau bentuk tidak baku\n        :rtype: str\n        \"\"\"\n\n        if varian == self.bentuk_tidak_baku:\n            nama = \"Bentuk tidak baku\"\n        elif varian == self.varian:\n            nama = \"Varian\"\n        else:\n            return ''\n        return nama + ': ' + ', '.join(varian)", "label": 1}
{"code": "public function removeTags(array $tags)\n    {\n        $this->tagsChanges['removed'] = array_unique(\n            array_merge($this->tagsChanges['removed'], $tags)\n        );\n\n        return $this;\n    }", "label": 2}
{"code": "def full_path\n      p = self\n      until p.prior.nil? || p.prior.library\n        p = p.prior\n      end\n      p.prior.nil? ? p.path : [p.prior] + p.path\n    end", "label": 4}
{"code": "function () {\n    config.multipleFiles = config.multipleFiles || false;\n\n    var defaultTemplate = singleFileDefaultTemplate;\n    if (config.multipleFiles) {\n      defaultTemplate = multipleFilesDefaultTemplate;\n    }\n    config.template = config.template || defaultTemplate;\n\n    var mockSrc = _.isArray(config.src) ? _.first(config.src) : config.src;\n    logger('mock source', mockSrc);\n    logger('dest', config.dest);\n    logger('template', config.template);\n    logger('multipleFiles', config.multipleFiles);\n    logger('plugins', config.plugins);\n\n    // read all scenario data from manifest/JSON files\n    var scenarioData = readScenarioData(config, mockSrc);\n\n    logger('scenarioData', scenarioData);\n\n    var scenarioModuleFilename = config.dest,\n      scenarioString;\n\n    if (!config.multipleFiles) {\n      // stringify all scenario files into a single Angular module\n      scenarioString = JSON.stringify(scenarioData);\n      writeScenarioModule(config.template, scenarioModuleFilename,\n        scenarioString);\n    } else {\n      fs.mkdirSync(config.dest);\n\n      // stringify each scenario file into it's own Angular module\n      for (var scenarioName in scenarioData) {\n        if (scenarioData.hasOwnProperty(scenarioName)) {\n          scenarioModuleFilename = config.dest + '/' + scenarioName +\n            '.js';\n\n          scenarioString = JSON.stringify(scenarioData[scenarioName]);\n          writeScenarioModule(config.template, scenarioModuleFilename,\n            scenarioString, scenarioName);\n        }\n      }\n    }\n  }", "label": 3}
{"code": "public function createRelease($target, $tagName, $display, $notes)\n    {\n        $requestBody = [\n            'tag_name' => $tagName,\n            'name' => $display,\n            'body' => $notes\n        ];\n\n        $res = $this->client->post(sprintf(\n            self::GITHUB_RELEASE_CREATE_ENDPOINT,\n            $this->cleanTarget($target)\n        ), [\n            'http_errors' => false,\n            'json' => $requestBody,\n            'auth' => [null, $this->token]\n        ]);\n\n        return $this->doesTagExist($target, $tagName);\n    }", "label": 2}
{"code": "public static iptunnel[] get(nitro_service service) throws Exception{\n\t\tiptunnel obj = new iptunnel();\n\t\tiptunnel[] response = (iptunnel[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def read_csv_to_html_table(csvFile, hasHeader='N'):\n    \"\"\"\n    reads a CSV file and converts it to HTML\n    \"\"\"\n    txt = '<table class=\"as-table as-table-zebra as-table-horizontal\">'\n    with open(csvFile, \"r\") as f:  # \n        numRows = 1\n        for row in f:\n            if hasHeader == 'Y':\n                if numRows == 1:\n                    td_begin = '<TH>'\n                    td_end = '</TH>'\n                else:\n                    td_begin = '<TD>'\n                    td_end = '</TD>'\n            else:\n                td_begin = '<TD>'\n                td_end = '</TD>'\n            cols = row.split(',')\n            numRows += 1\n\n            txt += \"<TR>\"\n            for col in cols:\n                txt += td_begin\n                try:\n                    colString = col\n                except Exception:\n                    colString = '<font color=red>Error decoding column data</font>'\n                txt += colString.strip('\"')\t\n                txt += td_end\n            txt += \"</TR>\\n\"\n        txt += \"</TABLE>\\n\\n\"\n    return txt", "label": 1}
{"code": "function warn(msg) {\n    console.log(TAG + ' ' + colors.bold.black.bgYellow('WARNING') + ' ' + msg);\n}", "label": 3}
{"code": "public void rollback()\r\n    {\r\n        try\r\n        {\r\n            Iterator iter = mvOrderOfIds.iterator();\r\n            while(iter.hasNext())\r\n            {\r\n                ObjectEnvelope mod = (ObjectEnvelope) mhtObjectEnvelopes.get(iter.next());\r\n                if(log.isDebugEnabled())\r\n                    log.debug(\"rollback: \" + mod);\r\n                // if the Object has been modified by transaction, mark object as dirty\r\n                if(mod.hasChanged(transaction.getBroker()))\r\n                {\r\n                    mod.setModificationState(mod.getModificationState().markDirty());\r\n                }\r\n                mod.getModificationState().rollback(mod);\r\n            }\r\n        }\r\n        finally\r\n        {\r\n            needsCommit = false;\r\n        }\r\n        afterWriteCleanup();\r\n    }", "label": 0}
{"code": "function AttributeTypeNotFoundError(type, innerError) {\n  /**\n   * The attribute type that was not found.\n   * @type {?string}\n   */\n  this.type = type;\n  /**\n   * The inner error that generated the current error.\n   * @type {?Error}\n   */\n  this.innerError = innerError;\n\n  expect(arguments).to.have.length.below(\n    3,\n    'Invalid arguments length when creating a new ' +\n    'AttributeTypeNotFoundError (it has to be passed less than 3 arguments)'\n  );\n\n  this.name = 'AttributeTypeNotFoundError';\n\n  this.message = 'Cannot find Attribute type';\n  if (type) {\n    expect(type).to.be.a(\n      'string',\n      'Invalid argument \"type\" when creating a new ' +\n      'AttributeTypeNotFoundError (it has to be a string)'\n    );\n    this.message += ' \"' + type + '\"';\n  }\n\n  this.stack = (new Error(this.message)).stack;\n  if (innerError) {\n    expect(innerError).to.be.an.instanceof(\n      Error,\n      'Invalid argument \"innerError\" when creating a new ' +\n      'AttributeTypeNotFoundError (it has to be an Error)'\n    );\n    this.stack += '\\n\\n' + innerError.stack;\n  }\n}", "label": 3}
{"code": "def _pwl_costs(self, ny, nxyz, ipwl):\n        \"\"\" Returns the piece-wise linear components of the objective function.\n        \"\"\"\n        any_pwl = int(ny > 0)\n        if any_pwl:\n            y = self.om.get_var(\"y\")\n            # Sum of y vars.\n            Npwl = csr_matrix((ones(ny), (zeros(ny), array(ipwl) + y.i1)))\n            Hpwl = csr_matrix((1, 1))\n            Cpwl = array([1])\n            fparm_pwl = array([[1., 0., 0., 1.]])\n        else:\n            Npwl = None#zeros((0, nxyz))\n            Hpwl = None#array([])\n            Cpwl = array([])\n            fparm_pwl = zeros((0, 4))\n\n        return Npwl, Hpwl, Cpwl, fparm_pwl, any_pwl", "label": 1}
{"code": "public static authenticationradiusaction[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tauthenticationradiusaction obj = new authenticationradiusaction();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tauthenticationradiusaction[] response = (authenticationradiusaction[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setSynthesizeSpeechConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\SynthesizeSpeechConfig::class);\n        $this->synthesize_speech_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static function register(\n        string $metadataDir,\n        string $metadataNamespace,\n        ?callable $notFoundCallback = null\n    ) : Closure {\n        $metadataNamespace = ltrim($metadataNamespace, '\\\\');\n\n        if (! ($notFoundCallback === null || is_callable($notFoundCallback))) {\n            $type = is_object($notFoundCallback) ? get_class($notFoundCallback) : gettype($notFoundCallback);\n\n            throw new InvalidArgumentException(\n                sprintf('Invalid \\$notFoundCallback given: must be a callable, \"%s\" given', $type)\n            );\n        }\n\n        $autoloader = static function ($className) use ($metadataDir, $metadataNamespace, $notFoundCallback) {\n            if (strpos($className, $metadataNamespace) === 0) {\n                $file = Autoloader::resolveFile($metadataDir, $metadataNamespace, $className);\n\n                if ($notFoundCallback && ! file_exists($file)) {\n                    call_user_func($notFoundCallback, $metadataDir, $metadataNamespace, $className);\n                }\n\n                require $file;\n            }\n        };\n\n        spl_autoload_register($autoloader);\n\n        return $autoloader;\n    }", "label": 2}
{"code": "function process(payload) {\n  var addressType = parseInt(payload.substr(0,1),16);\n  var typeCode = payload.substr(1,1);\n  var length = parseInt(payload.substr(2,2),16) % 64;\n  var rxAdd = \"public\";\n  var txAdd = \"public\";\n  if(addressType & 0x8) {\n    rxAdd = \"random\";\n  }\n  if(addressType & 0x4) {\n    txAdd = \"random\";\n  }   \n  var type;\n  switch(typeCode) {\n    case(\"0\"):\n      type = TYPE0_NAME;\n      break;\n    case(\"1\"):\n      type = TYPE1_NAME;\n      break;\n    case(\"2\"):\n      type = TYPE2_NAME;\n      break;\n    case(\"3\"):\n      type = TYPE3_NAME;\n      break;\n    case(\"4\"):\n      type = TYPE4_NAME;\n      break;\n    case(\"5\"):\n      type = TYPE5_NAME;\n      break;\n    case(\"6\"):\n      type = TYPE6_NAME;\n      break;\n    default: \n      type = TYPE_UNDEFINED_NAME;\n  }\n  return { type: type,\n           length: length,\n           txAdd: txAdd,\n           rxAdd: rxAdd\n  };\n}", "label": 3}
{"code": "def get_data(self, url, *args, **kwargs):\n        \"\"\"Gets data from url as text\n\n        Returns content under the provided url as text\n\n        Args:\n            **url**: address of the wanted data\n\n            .. versionadded:: 0.3.2\n                **additional_headers**: (optional) Additional headers\n                to be used with request\n\n        Returns:\n            string\n\n        \"\"\"\n        res = self._conn.get(url, headers=self._prepare_headers(**kwargs))\n        if res.status_code == 200:\n            return res.text\n        else:\n            return None", "label": 1}
{"code": "def flatten(l: Iterable) -> List:\n    \"\"\"Return a list of all non-list items in l\n\n    :param l: list to be flattened\n    :return:\n    \"\"\"\n    rval = []\n    for e in l:\n        if not isinstance(e, str) and isinstance(e, Iterable):\n            if len(list(e)):\n                rval += flatten(e)\n        else:\n            rval.append(e)\n    return rval", "label": 1}
{"code": "public function setDocumentation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\AlertPolicy_Documentation::class);\n        $this->documentation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func PgOpclassByOpcmethodOpcnameOpcnamespace(db XODB, opcmethod pgtypes.Oid, opcname pgtypes.Name, opcnamespace pgtypes.Oid) (*PgOpclass, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, opcmethod, opcname, opcnamespace, opcowner, opcfamily, opcintype, opcdefault, opckeytype ` +\n\t\t`FROM pg_catalog.pg_opclass ` +\n\t\t`WHERE opcmethod = $1 AND opcname = $2 AND opcnamespace = $3`\n\n\t// run query\n\tXOLog(sqlstr, opcmethod, opcname, opcnamespace)\n\tpo := PgOpclass{}\n\n\terr = db.QueryRow(sqlstr, opcmethod, opcname, opcnamespace).Scan(&po.Tableoid, &po.Cmax, &po.Xmax, &po.Cmin, &po.Xmin, &po.Oid, &po.Ctid, &po.Opcmethod, &po.Opcname, &po.Opcnamespace, &po.Opcowner, &po.Opcfamily, &po.Opcintype, &po.Opcdefault, &po.Opckeytype)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &po, nil\n}", "label": 5}
{"code": "public void deleteProduct(final String name) {\n        final DbProduct dbProduct = getProduct(name);\n        repositoryHandler.deleteProduct(dbProduct.getName());\n    }", "label": 0}
{"code": "function (uuid, action, params, interval) {\n        var actions = null;\n\n        if (typeof uuid !== 'string' ||\n            typeof action !== 'function') {\n            return false;\n        }\n\n        if (interval === undefined) {\n            if (typeof params === 'number') {\n                interval = params;\n                params = null;\n            } else {\n                interval = 100;\n            }\n        }\n\n        if (uuidMap[uuid]) {\n            return false;\n        }\n\n        if (!intervalsMap[interval]) {\n            actions = [];\n            intervalsMap[interval] = {\n                id: setInterval(getIntervalRunner(this.context, actions), interval),\n                interval: interval,\n                actions: actions\n            };\n        }\n\n        intervalsMap[interval].actions.push({\n            uuid: uuid,\n            action: action,\n            params: params\n        });\n        uuidMap[uuid] = intervalsMap[interval];\n\n        if (!this._periodicActionUUIDs) {\n            this._periodicActionUUIDs = [];\n        }\n\n        this._periodicActionUUIDs.push(uuid);\n        return true;\n    }", "label": 3}
{"code": "public static Collection<Component> getComponentsList() {\n    TransactionLogger instance = getInstance();\n    if (instance == null) {\n      return null;\n    }\n\n    return instance.components.values();\n  }", "label": 0}
{"code": "private J2EETransactionImpl newInternTransaction()\r\n    {\r\n        if (log.isDebugEnabled()) log.debug(\"obtain new intern odmg-transaction\");\r\n        J2EETransactionImpl tx = new J2EETransactionImpl(this);\r\n        try\r\n        {\r\n            getConfigurator().configure(tx);\r\n        }\r\n        catch (ConfigurationException e)\r\n        {\r\n            throw new OJBRuntimeException(\"Cannot create new intern odmg transaction\", e);\r\n        }\r\n        return tx;\r\n    }", "label": 0}
{"code": "def define_task\n      namespace(@namespace) do\n        namespace(\"schema\") do\n          desc(\"Dump the schema to IDL in #{idl_path}\")\n          task :idl => @dependencies do\n            write_outfile(:to_definition, idl_path)\n            puts \"Schema IDL dumped into #{idl_path}\"\n          end\n\n          desc(\"Dump the schema to JSON in #{json_path}\")\n          task :json => @dependencies do\n            write_outfile(:to_json, json_path)\n            puts \"Schema JSON dumped into #{json_path}\"\n          end\n\n          desc(\"Dump the schema to JSON and IDL\")\n          task :dump => [:idl, :json]\n        end\n      end\n    end", "label": 4}
{"code": "@Override\n    public Optional<String> hash(final Optional<URL> url) throws IOException {\n        if (!url.isPresent()) {\n            return Optional.absent();\n        }\n        logger.debug(\"Calculating md5 hash, url:{}\", url);\n        if (isHotReloadModeOff()) {\n            final String md5 = cache.getIfPresent(url.get());\n\n            logger.debug(\"md5 hash:{}\", md5);\n\n            if (md5 != null) {\n                return Optional.of(md5);\n            }\n        }\n\n        final InputStream is = url.get().openStream();\n        final String md5 = getMD5Checksum(is);\n\n        if (isHotReloadModeOff()) {\n            logger.debug(\"caching url:{} with hash:{}\", url, md5);\n\n            cache.put(url.get(), md5);\n        }\n\n        return Optional.fromNullable(md5);\n    }", "label": 0}
{"code": "protected function loadDefaultWith(EloquentCollection $collection): self\n    {\n        if ($collection->isEmpty()) {\n            return $this;\n        }\n\n        $model = $collection->first();\n        $reflection = new ReflectionClass($model);\n        $withProperty = $reflection->getProperty('with');\n        $withProperty->setAccessible(true);\n\n        $with = array_filter((array) $withProperty->getValue($model), function ($relation) use ($model) {\n            return ! $model->relationLoaded($relation);\n        });\n\n        if (! empty($with)) {\n            $collection->load($with);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response add(nitro_service client, filterpolicy resource) throws Exception {\n\t\tfilterpolicy addresource = new filterpolicy();\n\t\taddresource.name = resource.name;\n\t\taddresource.rule = resource.rule;\n\t\taddresource.reqaction = resource.reqaction;\n\t\taddresource.resaction = resource.resaction;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function endsWith(string, suffix) {\n  return string.indexOf(suffix, string.length - suffix.length) !== -1;\n}", "label": 3}
{"code": "public function setLandmarkAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\EntityAnnotation::class);\n        $this->landmark_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function joinCurrentModelActivity(method, stateName, modelOrCollection, context, force) {\n        var xhrActivity = modelOrCollection[xhrModelLoadingAttribute];\n        if (xhrActivity) {\n            _.each(xhrActivity, function(xhrEvent) {\n                if (!method || method === ALL_XHR_ACTIVITY || xhrEvent.method === method) {\n                    // this is one that is applicable\n                    pushLoadingState(xhrEvent, stateName, modelOrCollection, context, force);\n                }\n            });\n        }\n    }", "label": 3}
{"code": "function(obj, cache) {\n      cache[obj.cid] = obj;\n      this.listenToOnce(obj, 'before-dispose', function() {\n        delete cache[obj.cid];\n      });\n    }", "label": 3}
{"code": "def get_discrete_task_agent(generators, market, nStates, nOffer, markups,\n        withholds, maxSteps, learner, Pd0=None, Pd_min=0.0):\n    \"\"\" Returns a tuple of task and agent for the given learner.\n    \"\"\"\n    env = pyreto.discrete.MarketEnvironment(generators, market,\n                                            numStates=nStates,\n                                            numOffbids=nOffer,\n                                            markups=markups,\n                                            withholds=withholds,\n                                            Pd0=Pd0,\n                                            Pd_min=Pd_min)\n    task = pyreto.discrete.ProfitTask(env, maxSteps=maxSteps)\n\n    nActions = len(env._allActions)\n    module = ActionValueTable(numStates=nStates, numActions=nActions)\n\n    agent = LearningAgent(module, learner)\n\n    return task, agent", "label": 1}
{"code": "function( tmp, self ) {\r\n      var _arg = self.options.validators.regExp[ tmp.arg ],\r\n        _reg = new RegExp( _arg.pattern );\r\n      return _reg.test( tmp.val ) || _arg.errorMessage;\r\n    }", "label": 3}
{"code": "public function scheduleForUpdate($entity) : void\n    {\n        $oid = spl_object_id($entity);\n\n        if (! isset($this->entityIdentifiers[$oid])) {\n            throw ORMInvalidArgumentException::entityHasNoIdentity($entity, 'scheduling for update');\n        }\n\n        if (isset($this->entityDeletions[$oid])) {\n            throw ORMInvalidArgumentException::entityIsRemoved($entity, 'schedule for update');\n        }\n\n        if (! isset($this->entityUpdates[$oid]) && ! isset($this->entityInsertions[$oid])) {\n            $this->entityUpdates[$oid] = $entity;\n        }\n    }", "label": 2}
{"code": "def call(env)\n      req = ActionDispatch::Request.new env\n      req.remote_ip = GetIp.new(req, check_ip, proxies)\n      @app.call(req.env)\n    end", "label": 4}
{"code": "protected void createSequence(PersistenceBroker broker, FieldDescriptor field,\r\n                                  String sequenceName, long maxKey) throws Exception\r\n    {\r\n        Statement stmt = null;\r\n        try\r\n        {\r\n            stmt = broker.serviceStatementManager().getGenericStatement(field.getClassDescriptor(), Query.NOT_SCROLLABLE);\r\n            stmt.execute(sp_createSequenceQuery(sequenceName, maxKey));\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            log.error(e);\r\n            throw new SequenceManagerException(\"Could not create new row in \"+SEQ_TABLE_NAME+\" table - TABLENAME=\" +\r\n                    sequenceName + \" field=\" + field.getColumnName(), e);\r\n        }\r\n        finally\r\n        {\r\n            try\r\n            {\r\n                if (stmt != null) stmt.close();\r\n            }\r\n            catch (SQLException sqle)\r\n            {\r\n                if(log.isDebugEnabled())\r\n                    log.debug(\"Threw SQLException while in createSequence and closing stmt\", sqle);\r\n                // ignore it\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def _dist_corr(dist, phi1, phi2, phi3):\n        \"\"\"\n        Generic distance-decaying correlation function\n\n        :param dist: Distance between catchment centrolds in km\n        :type dist: float\n        :param phi1: Decay function parameters 1\n        :type phi1: float\n        :param phi2: Decay function parameters 2\n        :type phi2: float\n        :param phi3: Decay function parameters 3\n        :type phi3: float\n        :return: Correlation coefficient, r\n        :rtype: float\n        \"\"\"\n        return phi1 * exp(-phi2 * dist) + (1 - phi1) * exp(-phi3 * dist)", "label": 1}
{"code": "def replace(input, string, replacement = ''.freeze)\n      input.to_s.gsub(string.to_s, replacement.to_s)\n    end", "label": 4}
{"code": "def edit(*args)\n      arguments(args, required: [:id])\n      params = arguments.params\n\n      params[\"accept\"] ||= PREVIEW_MEDIA\n\n      patch_request(\"/projects/#{arguments.id}\", params)\n    end", "label": 4}
{"code": "func (a *ArgType) schemafn(s string, names ...string) string {\n\t// escape table names\n\tif a.EscapeTableNames {\n\t\tfor i, t := range names {\n\t\t\tnames[i] = a.Loader.Escape(TableEsc, t)\n\t\t}\n\t}\n\n\tn := strings.Join(names, \".\")\n\n\tif s == \"\" && n == \"\" {\n\t\treturn \"\"\n\t}\n\n\tif s != \"\" && n != \"\" {\n\t\tif a.EscapeSchemaName {\n\t\t\ts = a.Loader.Escape(SchemaEsc, s)\n\t\t}\n\t\ts = s + \".\"\n\t}\n\n\treturn s + n\n}", "label": 5}
{"code": "function forEachColumn(children, callback) {\n  React.Children.forEach(children, function(child)  {\n    if (child.type === FixedDataTableColumnGroup.type) {\n      forEachColumn(child.props.children, callback);\n    } else if (child.type === FixedDataTableColumn.type) {\n      callback(child);\n    }\n  });\n}", "label": 3}
{"code": "public static function confirm( $question, $assoc_args = array() ) {\n\t\tif ( ! \\WP_CLI\\Utils\\get_flag_value( $assoc_args, 'yes' ) ) {\n\t\t\tfwrite( STDOUT, $question . ' [y/n] ' );\n\n\t\t\t$answer = strtolower( trim( fgets( STDIN ) ) );\n\n\t\t\tif ( 'y' !== $answer ) {\n\t\t\t\texit;\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "def acquire_writer(self):\n        \"\"\"\n        Acquire a write lock, only one thread can hold this lock\n        and only when no read locks are also held.\n        \"\"\"\n        with self.mutex:\n            while self.rwlock != 0:\n                self._writer_wait()\n            self.rwlock = -1", "label": 1}
{"code": "def scopes_picker_field_tag(name, value, id: nil)\n      picker_options = {\n        id: id || sanitize_to_id(name),\n        class: \"picker-single\",\n        name: name\n      }\n\n      prompt_params = yield(nil)\n      selected_scopes = value ? Decidim::Scope.where(id: value) : []\n      scopes = selected_scopes.map { |scope| [scope, yield(scope)] }\n\n      template = \"\"\n      template += render(\"decidim/scopes/scopes_picker_input\",\n                         picker_options: picker_options,\n                         prompt_params: prompt_params,\n                         scopes: scopes,\n                         checkboxes_on_top: true)\n      template.html_safe\n    end", "label": 4}
{"code": "public static auditnslogpolicy_vpnvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauditnslogpolicy_vpnvserver_binding obj = new auditnslogpolicy_vpnvserver_binding();\n\t\tobj.set_name(name);\n\t\tauditnslogpolicy_vpnvserver_binding response[] = (auditnslogpolicy_vpnvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def get_v1_batch_token_from_headers(headers)\n      if headers.is_a?(Hash) && headers.has_key?('Link')\n        match = /^<([^>]+)>;rel='next'$/.match(headers['Link'])\n        if match\n          uri = URI.parse(match[1])\n          params = CGI.parse(uri.query)\n          return params['batch_token'][0]\n        end\n      end\n    end", "label": 4}
{"code": "function (req, res, next) {\n            if (!req.miajs.controllerDebugInfo) {\n                req.miajs.controllerDebugInfo = {};\n            }\n            if (controller.name && controller.version) {\n                req.miajs.controllerDebugInfo[controller.name + '_' + controller.version] = {'runtime': Date.now() - req.miajs.controllerStart};\n            }\n            next();\n        }", "label": 3}
{"code": "function readableBy(file, user) {\n  if (!exists(file)) {\n    return readableBy(path.dirname(file), user);\n  }\n  const userData = findUser(user);\n  if (userData.id === 0) {\n    return true;\n  } else if (userData.id === process.getuid()) {\n    return readable(file);\n  } else {\n    return _accesibleByUser(userData, file, fs.R_OK);\n  }\n}", "label": 3}
{"code": "function resolveDependencyPaths(options) {\n  function init(items) {\n    // Invalid if not Array\n    if (Array.isArray(items)) {\n      items.forEach((item, idx, items) => {\n        const isArray = Array.isArray(item);\n        const id = isArray ? item[0] : item;\n\n        // Ignore already resolved\n        if ('string' == typeof id) {\n          const filepath = dependencies.find(id);\n\n          if (!filepath) return warn(`unable to load plugin ${strong(id)}`, 1);\n\n          if (isArray) {\n            item[0] = require(filepath);\n          } else {\n            items[idx] = require(filepath);\n          }\n        }\n      });\n    }\n  }\n\n  if (options.plugins) init(options.plugins);\n  if (options.presets) init(options.presets);\n}", "label": 3}
{"code": "public function getStoredConversation($message = null)\n    {\n        if (is_null($message)) {\n            $message = $this->getMessage();\n        }\n\n        $conversation = $this->cache->get($message->getConversationIdentifier());\n        if (is_null($conversation)) {\n            $conversation = $this->cache->get($message->getOriginatedConversationIdentifier());\n        }\n\n        return $conversation;\n    }", "label": 2}
{"code": "private Collection getOwnerObjects()\r\n    {\r\n        Collection owners = new Vector();\r\n        while (hasNext())\r\n        {\r\n            owners.add(next());\r\n        }\r\n        return owners;\r\n    }", "label": 0}
{"code": "public function setReadOnly($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\TransactionOptions_ReadOnly::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "private function urlStatFile()\n    {\n        try {\n            $this->object = $this->bucket->object($this->file);\n            $info = $this->object->info();\n        } catch (ServiceException $e) {\n            // couldn't stat file\n            return false;\n        }\n\n        // equivalent to 100666 and 100444 in octal\n        $stats = array(\n            'mode' => $this->bucket->isWritable()\n                ? self::FILE_WRITABLE_MODE\n                : self::FILE_READABLE_MODE\n        );\n        $this->statsFromFileInfo($info, $stats);\n        return $this->makeStatArray($stats);\n    }", "label": 2}
{"code": "function getStateValues (size, self) {\n  var width = $(self.getDOMNode()).width();\n  return {\n    profile: width > size ? 'large' : 'small'\n  };\n}", "label": 3}
{"code": "private String fixSpecials(final String inString) {\n\t\tStringBuilder tmp = new StringBuilder();\n\n\t\tfor (int i = 0; i < inString.length(); i++) {\n\t\t\tchar chr = inString.charAt(i);\n\n\t\t\tif (isSpecial(chr)) {\n\t\t\t\ttmp.append(this.escape);\n\t\t\t\ttmp.append(chr);\n\t\t\t} else {\n\t\t\t\ttmp.append(chr);\n\t\t\t}\n\t\t}\n\n\t\treturn tmp.toString();\n\t}", "label": 0}
{"code": "function fileChanged(status, filepath) {\n\t\t\t// If file was deleted and then re-added, consider it changed.\n\t\t\tif (changedFiles[filepath] === 'deleted' && status === 'added') {\n\t\t\t\tstatus = 'changed';\n\t\t\t}\n\t\t\t// Keep track of changed status for later.\n\t\t\tchangedFiles[filepath] = status;\n\t\t\t// Emit watch events if anyone is listening\n\t\t\tif (grunt.event.listeners('watch').length > 0) {\n\t\t\t\tvar matchingTargets = [];\n\t\t\t\ttargets.forEach(function(target) {\n\t\t\t\t\tif (grunt.file.match(target.files, filepath).length > 0) {\n\t\t\t\t\t\tmatchingTargets.push(target.name);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tmatchingTargets.forEach(function(matchingTarget) {\n\t\t\t\t\tgrunt.event.emit('watch', status, filepath, matchingTarget);\n\t\t\t\t});\n\t\t\t}\n\t\t\t// Keep track of changed status for later.\n\t\t\tchangedFiles[filepath] = status;\n\t\t\t// Execute debounced done function.\n\t\t\tdone();\n\t\t}", "label": 3}
{"code": "public function endOfSecond()\n    {\n        return $this->setTime($this->hour, $this->minute, $this->second, static::MICROSECONDS_PER_SECOND - 1);\n    }", "label": 2}
{"code": "public function setMembers($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Api\\MonitoredResource::class);\n        $this->members = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function filterConditionalStatements(rule) {\n      return _.filter(rule.ruleConditionalStatements, function(ruleCondStatement) {\n        var sourceField = ruleCondStatement.sourceField.toString();\n\n        if (invalidFields[sourceField]) {\n          /**\n           * If the user flagged the field in this rule for deletion, flag the rule for deletion.\n           */\n          if (ruleDeletionFlags[sourceField]) {\n            rulesFlaggedForDeletion[rule._id.toString()] = true;\n          }\n          return false;\n        } else {\n          return true;\n        }\n      });\n    }", "label": 3}
{"code": "func useProxy(addr string) bool {\n\tif len(addr) == 0 {\n\t\treturn true\n\t}\n\tvar noProxy string\n\tfor _, env := range []string{teleport.NoProxy, strings.ToLower(teleport.NoProxy)} {\n\t\tnoProxy = os.Getenv(env)\n\t\tif noProxy != \"\" {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif noProxy == \"\" {\n\t\treturn true\n\t}\n\tif noProxy == \"*\" {\n\t\treturn false\n\t}\n\n\taddr = strings.ToLower(strings.TrimSpace(addr))\n\tif hasPort(addr) {\n\t\taddr = addr[:strings.LastIndex(addr, \":\")]\n\t}\n\tfor _, p := range strings.Split(noProxy, \",\") {\n\t\tp = strings.ToLower(strings.TrimSpace(p))\n\t\tif len(p) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tif hasPort(p) {\n\t\t\tp = p[:strings.LastIndex(p, \":\")]\n\t\t}\n\t\tif addr == p {\n\t\t\treturn false\n\t\t}\n\t\tif len(p) == 0 {\n\t\t\t// There is no host part, likely the entry is malformed; ignore.\n\t\t\tcontinue\n\t\t}\n\t\tif p[0] == '.' && (strings.HasSuffix(addr, p) || addr == p[1:]) {\n\t\t\t// no_proxy \".foo.com\" matches \"bar.foo.com\" or \"foo.com\"\n\t\t\treturn false\n\t\t}\n\t\tif p[0] != '.' && strings.HasSuffix(addr, p) && addr[len(addr)-len(p)-1] == '.' {\n\t\t\t// no_proxy \"foo.com\" matches \"bar.foo.com\"\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "label": 5}
{"code": "def tls(pem = nil, path = 'cert')\n      new_client = client.dup\n      new_client.ssl_pem_contents = pem if !pem.nil?\n\n      json = new_client.post(\"/v1/auth/#{CGI.escape(path)}/login\")\n      secret = Secret.decode(json)\n      client.token = secret.auth.client_token\n      return secret\n    end", "label": 4}
{"code": "private String safeToString(Object obj)\r\n\t{\r\n\t\tString toString = null;\r\n\t\tif (obj != null)\r\n\t\t{\r\n\t\t    try\r\n\t\t    {\r\n\t\t        toString = obj.toString();\r\n\t\t    }\r\n\t\t    catch (Throwable ex)\r\n\t\t    {\r\n\t\t        toString = \"BAD toString() impl for \" + obj.getClass().getName();\r\n\t\t    }\r\n\t\t}\r\n\t\treturn toString;\r\n\t}", "label": 0}
{"code": "public function getEntityObject($slug = null)\n    {\n        if (! is_null($this->entity)) {\n            return $this->entity;\n        }\n\n        return $this->getEntity($slug ?? $this->getAttribute('type'))->entity;\n    }", "label": 2}
{"code": "func (v *validate) extractTypeInternal(current reflect.Value, nullable bool) (reflect.Value, reflect.Kind, bool) {\n\nBEGIN:\n\tswitch current.Kind() {\n\tcase reflect.Ptr:\n\n\t\tnullable = true\n\n\t\tif current.IsNil() {\n\t\t\treturn current, reflect.Ptr, nullable\n\t\t}\n\n\t\tcurrent = current.Elem()\n\t\tgoto BEGIN\n\n\tcase reflect.Interface:\n\n\t\tnullable = true\n\n\t\tif current.IsNil() {\n\t\t\treturn current, reflect.Interface, nullable\n\t\t}\n\n\t\tcurrent = current.Elem()\n\t\tgoto BEGIN\n\n\tcase reflect.Invalid:\n\t\treturn current, reflect.Invalid, nullable\n\n\tdefault:\n\n\t\tif v.v.hasCustomFuncs {\n\n\t\t\tif fn, ok := v.v.customFuncs[current.Type()]; ok {\n\t\t\t\tcurrent = reflect.ValueOf(fn(current))\n\t\t\t\tgoto BEGIN\n\t\t\t}\n\t\t}\n\n\t\treturn current, current.Kind(), nullable\n\t}\n}", "label": 5}
{"code": "func (info *Info) UpvertedFiles() []FileInfo {\n\tif len(info.Files) == 0 {\n\t\treturn []FileInfo{{\n\t\t\tLength: info.Length,\n\t\t\t// Callers should determine that Info.Name is the basename, and\n\t\t\t// thus a regular file.\n\t\t\tPath: nil,\n\t\t}}\n\t}\n\treturn info.Files\n}", "label": 5}
{"code": "public static String marshal(Object object) {\n        if (object == null) {\n            return null;\n        }\n\n        try {\n            JAXBContext jaxbCtx = JAXBContext.newInstance(object.getClass());\n\n            Marshaller marshaller = jaxbCtx.createMarshaller();\n            marshaller.setProperty(Marshaller.JAXB_FRAGMENT, Boolean.TRUE);\n\n            StringWriter sw = new StringWriter();\n            marshaller.marshal(object, sw);\n\n            return sw.toString();\n        } catch (Exception e) {\n        }\n\n        return null;\n    }", "label": 0}
{"code": "def gsub!(pat, rep)\n      each_with_index { |fn, i| self[i] = fn.gsub(pat, rep) }\n      self\n    end", "label": 4}
{"code": "func (o FileItem) File() types.OvfFile {\n\treturn types.OvfFile{\n\t\tDeviceId: o.DeviceId,\n\t\tPath:     o.Path,\n\t\tSize:     o.Size,\n\t}\n}", "label": 5}
{"code": "def extract_title\n      title = extract(:title).presence\n      return unless title\n\n      title = Array(title)\n      return title.map(&:downcase) if extract(:lowercase) == true\n\n      title\n    end", "label": 4}
{"code": "function (error) {\n\t\tif (error) {\n\t\t\tvar err = new Error(error.toString());\n\t\t\terr.name = \"l_createToken Error\";\n\t\t\tUTIL.safeCall(onDone, err);\n\t\t}\n\t\telse {\n\t\t\tLOG.warn('pass_token [' + token + '] stored');\n\t\t\tUTIL.safeCall(onDone, null, token);\t\t\t\n\t\t}\n\t}", "label": 3}
{"code": "public function subscribe($channel /*, ... */)\n    {\n        $this->writeRequest(self::SUBSCRIBE, func_get_args());\n        $this->statusFlags |= self::STATUS_SUBSCRIBED;\n    }", "label": 2}
{"code": "public function addUnitNoOverflow($valueUnit, $value, $overflowUnit)\n    {\n        return $this->setUnitNoOverflow($valueUnit, $this->$valueUnit + $value, $overflowUnit);\n    }", "label": 2}
{"code": "private String computeFilteredPrefixedValue(String type, String value,\n      String filter, String prefix) throws MtasConfigException {\n    String localValue = value;\n    // do magic with filter\n    if (filter != null) {\n      String[] filters = filter.split(\",\");\n      for (String item : filters) {\n        if (item.trim().equals(MAPPING_FILTER_UPPERCASE)) {\n          localValue = localValue == null ? null : localValue.toUpperCase();\n        } else if (item.trim().equals(MAPPING_FILTER_LOWERCASE)) {\n          localValue = localValue == null ? null : localValue.toLowerCase();\n        } else if (item.trim().equals(MAPPING_FILTER_ASCII)) {\n          if (localValue != null) {\n            char[] old = localValue.toCharArray();\n            char[] ascii = new char[4 * old.length];\n            ASCIIFoldingFilter.foldToASCII(old, 0, ascii, 0,\n                localValue.length());\n            localValue = new String(ascii);\n          }\n        } else if (item.trim()\n            .matches(Pattern.quote(MAPPING_FILTER_SPLIT) + \"\\\\([0-9\\\\-]+\\\\)\")) {\n          if (!type.equals(MtasParserMapping.PARSER_TYPE_TEXT_SPLIT)) {\n            throw new MtasConfigException(\n                \"split filter not allowed for \" + type);\n          }\n        } else {\n          throw new MtasConfigException(\n              \"unknown filter \" + item + \" for value \" + localValue);\n        }\n      }\n    }\n    if (localValue != null && prefix != null) {\n      localValue = prefix + localValue;\n    }\n    return localValue;\n  }", "label": 0}
{"code": "def execute\n      operation_id = Monitoring.next_operation_id\n      result_combiner = ResultCombiner.new\n      operations = op_combiner.combine\n\n      client.send(:with_session, @options) do |session|\n        operations.each do |operation|\n          if single_statement?(operation)\n            write_with_retry(session, write_concern) do |server, txn_num|\n              execute_operation(\n                  operation.keys.first,\n                  operation.values.flatten,\n                  server,\n                  operation_id,\n                  result_combiner,\n                  session,\n                  txn_num)\n            end\n          else\n            legacy_write_with_retry do |server|\n              execute_operation(\n                  operation.keys.first,\n                  operation.values.flatten,\n                  server,\n                  operation_id,\n                  result_combiner,\n                  session)\n            end\n          end\n        end\n      end\n      result_combiner.result\n    end", "label": 4}
{"code": "func valuePrefix(typeName string) string {\n\tif v, ok := refValueMap[typeName]; ok {\n\t\treturn v\n\t}\n\n\treturn strings.ToLower(typeName)\n}", "label": 5}
{"code": "def run\n\n    # I don't really like the names of these lifecycle phases.  It would be nice to change them to some more meaningful\n    # names, and make deprecated aliases.  --cprice 2012-03-16\n\n    exit_on_fail(_(\"Could not get application-specific default settings\")) do\n      initialize_app_defaults\n    end\n\n    Puppet::ApplicationSupport.push_application_context(self.class.run_mode, self.class.get_environment_mode)\n\n    exit_on_fail(_(\"Could not initialize\"))                { preinit }\n    exit_on_fail(_(\"Could not parse application options\")) { parse_options }\n    exit_on_fail(_(\"Could not prepare for execution\"))     { setup }\n\n    if deprecated?\n      Puppet.deprecation_warning(_(\"`puppet %{name}` is deprecated and will be removed in a future release.\") % { name: name })\n    end\n\n    exit_on_fail(_(\"Could not configure routes from %{route_file}\") % { route_file: Puppet[:route_file] }) { configure_indirector_routes }\n    exit_on_fail(_(\"Could not log runtime debug info\"))                       { log_runtime_environment }\n    exit_on_fail(_(\"Could not run\"))                                          { run_command }\n  end", "label": 4}
{"code": "def handle_error(error)\n      return unless que_target\n\n      max = resolve_que_setting(:maximum_retry_count)\n\n      if max && error_count > max\n        expire\n      else\n        retry_in_default_interval\n      end\n    end", "label": 4}
{"code": "func (c *Client) CreateRemoteCluster(rc services.RemoteCluster) error {\n\tdata, err := services.MarshalRemoteCluster(rc)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\targs := &createRemoteClusterRawReq{\n\t\tRemoteCluster: data,\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"remoteclusters\"), args)\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "private static function getUuidV4($bytes)\n    {\n        // set version to 0100\n        $bytes[6] = chr(ord($bytes[6]) & 0x0f | 0x40);\n        // set bits 6-7 to 10\n        $bytes[8] = chr(ord($bytes[8]) & 0x3f | 0x80);\n        return vsprintf('%s%s-%s-%s-%s-%s%s%s', str_split(bin2hex($bytes), 4));\n    }", "label": 2}
{"code": "public function setClassificationEvaluationMetrics($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\ClassificationEvaluationMetrics::class);\n        $this->writeOneof(8, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def last_button\n      # uiautomator index doesn't support last\n      # and it's 0 indexed\n      button_index = tags(BUTTON).length\n      button_index -= 1 if button_index > 0\n      image_button_index = tags(IMAGE_BUTTON).length\n      image_button_index -= 1 if image_button_index > 0\n\n      find_element :uiautomator,\n                   _button_visible_selectors(button_index: button_index,\n                                             image_button_index: image_button_index)\n    end", "label": 4}
{"code": "public static lbvserver_filterpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_filterpolicy_binding obj = new lbvserver_filterpolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_filterpolicy_binding response[] = (lbvserver_filterpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function parse(schema, opts) {\n  var attrs = files.load(schema);\n  return attrs.protocol ?\n    protocols.createProtocol(attrs, opts) :\n    types.createType(attrs, opts);\n}", "label": 3}
{"code": "public static dnsnsecrec[] get(nitro_service service, dnsnsecrec_args args) throws Exception{\n\t\tdnsnsecrec obj = new dnsnsecrec();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tdnsnsecrec[] response = (dnsnsecrec[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def read_input(prompt, save_hist = true)\n      line = prepare_input(prompt)\n      return unless line\n\n      history.push(line) if save_hist\n\n      command_queue.concat(split_commands(line))\n      command_queue.shift\n    end", "label": 4}
{"code": "public String getModuleJenkinsJobInfo(final DbArtifact dbArtifact) {\n\t\tfinal DbModule module = getModule(dbArtifact);\n\t\tif(module == null){\n\t\t\treturn \"\";\n\t\t}\n\t\t\n\t\tfinal String jenkinsJobUrl = module.getBuildInfo().get(\"jenkins-job-url\");\n\t\t\n\t\tif(jenkinsJobUrl == null){\n\t\t\treturn \"\";\t\t\t\n\t\t}\n\n\t\treturn jenkinsJobUrl;\n\t}", "label": 0}
{"code": "function updateTheme(req, res, next) {\n\n  //No theme sent, no need update the project theme\n  if (!req.body.theme) {\n    return next();\n  }\n\n  var params = {\n    appId: req.params.id || req.body._id,\n    theme: req.body.theme\n  };\n  forms.setAppTheme(_.extend(req.connectionOptions, params), formsResultHandlers(constants.resultTypes.formProjects, req, next));\n}", "label": 3}
{"code": "function emit (str) {\n    const nwState = emit._events[emit._state][str]\n    if (!reach(emit._state, nwState, emit._graph)) {\n      const err = 'invalid transition: ' + emit._state + ' -> ' + str\n      return emitter.emit('error', err)\n    }\n\n    const leaveEv = emit._state + ':leave'\n    const enterEv = nwState + ':enter'\n\n    if (!emit._state) return enter()\n    return leave()\n\n    function leave () {\n      if (!emitter._events[leaveEv]) enter()\n      else emitter.emit(leaveEv, enter)\n    }\n\n    function enter () {\n      if (!emitter._events[enterEv]) done()\n      else emitter.emit(enterEv, done)\n    }\n\n    function done () {\n      emit._state = nwState\n      emitter.emit(nwState)\n      emitter.emit('done')\n    }\n  }", "label": 3}
{"code": "public void writeTo(IIMWriter writer) throws IOException {\r\n\t\tfinal boolean doLog = log != null;\r\n\t\tfor (Iterator<DataSet> i = dataSets.iterator(); i.hasNext();) {\r\n\t\t\tDataSet ds = i.next();\r\n\t\t\twriter.write(ds);\r\n\t\t\tif (doLog) {\r\n\t\t\t\tlog.debug(\"Wrote data set \" + ds);\r\n\t\t\t}\r\n\t\t}\r\n\t}", "label": 0}
{"code": "func CheckCertificateFormatFlag(s string) (string, error) {\n\tswitch s {\n\tcase teleport.CertificateFormatStandard, teleport.CertificateFormatOldSSH, teleport.CertificateFormatUnspecified:\n\t\treturn s, nil\n\tdefault:\n\t\treturn \"\", trace.BadParameter(\"invalid certificate format parameter: %q\", s)\n\t}\n}", "label": 5}
{"code": "func (tl TypeLoader) LoadForeignKeys(args *ArgType, tableMap map[string]*Type) (map[string]*ForeignKey, error) {\n\tvar err error\n\n\tfkMap := map[string]*ForeignKey{}\n\tfor _, t := range tableMap {\n\t\t// load keys per table\n\t\terr = tl.LoadTableForeignKeys(args, tableMap, t, fkMap)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// determine foreign key names\n\tfor _, fk := range fkMap {\n\t\tfk.Name = args.ForeignKeyName(fkMap, fk)\n\t}\n\n\t// generate templates\n\tfor _, fk := range fkMap {\n\t\terr = args.ExecuteTemplate(ForeignKeyTemplate, fk.Type.Name, fk.ForeignKey.ForeignKeyName, fk)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn fkMap, nil\n}", "label": 5}
{"code": "func defaultStart(typ reflect.Type, finfo *fieldInfo, startTemplate *StartElement) StartElement {\n\tvar start StartElement\n\t// Precedence for the XML element name is as above,\n\t// except that we do not look inside structs for the first field.\n\tif startTemplate != nil {\n\t\tstart.Name = startTemplate.Name\n\t\tstart.Attr = append(start.Attr, startTemplate.Attr...)\n\t} else if finfo != nil && finfo.name != \"\" {\n\t\tstart.Name.Local = finfo.name\n\t\tstart.Name.Space = finfo.xmlns\n\t} else if typ.Name() != \"\" {\n\t\tstart.Name.Local = typ.Name()\n\t} else {\n\t\t// Must be a pointer to a named type,\n\t\t// since it has the Marshaler methods.\n\t\tstart.Name.Local = typ.Elem().Name()\n\t}\n\n\t// Add type attribute if necessary\n\tif finfo != nil && finfo.flags&fTypeAttr != 0 {\n\t\tstart.Attr = append(start.Attr, Attr{xmlSchemaInstance, typeToString(typ)})\n\t}\n\n\treturn start\n}", "label": 5}
{"code": "func base(key []byte, offset int) ([]byte, error) {\n\tparts := bytes.Split(key, []byte{backend.Separator})\n\tif len(parts) < offset+1 {\n\t\treturn nil, trace.NotFound(\"failed parsing %v\", string(key))\n\t}\n\treturn parts[len(parts)-offset-1], nil\n}", "label": 5}
{"code": "def _show_documentation(self):\n        \"\"\"\n        Shows all documents of the current groundwork app in the console.\n\n        Documents are sorted bei its names, except \"main\", which gets set to the beginning.\n        \"\"\"\n        documents = []\n        for key, document in self.app.documents.get().items():\n            if key != \"main\":\n                documents.append((key, document))\n        documents = sorted(documents, key=lambda x: x[0])\n        main = self.app.documents.get(\"main\")\n        if main is not None:\n            documents.insert(0, (main.name, main))\n\n        user_answer = \"\"\n        index = 0\n        while user_answer != \"X\":\n            if index < 0:\n                index = 0\n            if index > len(documents) - 1:\n                index = len(documents) - 1\n            document = documents[index][1]\n\n            os.system('cls' if os.name == 'nt' else 'clear')\n            echo(Environment().from_string(document.content).render(app=self.app, plugin=document.plugin))\n\n            source = \"This document is registered by '%s' under the name '%s'\" % (document.plugin.name, document.name)\n            echo(\"-\" * len(source))\n            echo(source)\n            echo(\"-\" * len(source))\n            commands = \"Actions: \"\n            if index < len(documents) - 1:\n                commands += \"[N]ext, \"\n            if index > 0:\n                commands += \"[P]revious, \"\n            commands += \"E[x]it\"\n            echo(commands)\n\n            if index < len(documents) - 1:\n                default = \"N\"\n            elif index > 0:\n                default = \"P\"\n            else:\n                default = \"X\"\n            user_answer = prompt(\"Select your action\", default=default).upper()\n\n            if user_answer == \"N\":\n                index += 1\n            elif user_answer == \"P\":\n                index -= 1", "label": 1}
{"code": "function (newPrototype) {\n        _gpfObjectForEach(this._initialDefinition, function (value, memberName) {\n            if (!memberName.startsWith(\"$\")) {\n                newPrototype[memberName] = value;\n            }\n        }, this);\n    }", "label": 3}
{"code": "func AppTreeStoreIDPath(root string, appName types.ACName) string {\n\treturn filepath.Join(AppInfoPath(root, appName), AppTreeStoreIDFilename)\n}", "label": 5}
{"code": "function classDeclarationExtendsNull(classDecl) {\n            var classSymbol = getSymbolOfNode(classDecl);\n            var classInstanceType = getDeclaredTypeOfSymbol(classSymbol);\n            var baseConstructorType = getBaseConstructorTypeOfClass(classInstanceType);\n            return baseConstructorType === nullWideningType;\n        }", "label": 3}
{"code": "def get_as_datadict(self):\n        \"\"\"\n            Get information about this object as a dictionary.  Used by WebSocket interface to pass some\n            relevant information to client applications.\n        \"\"\"\n        return dict(type=self.__class__.__name__, tags=list(self.tags))", "label": 1}
{"code": "func (f *file) errorf(n ast.Node, confidence float64, args ...interface{}) *Problem {\n\tpos := f.fset.Position(n.Pos())\n\tif pos.Filename == \"\" {\n\t\tpos.Filename = f.filename\n\t}\n\treturn f.pkg.errorfAt(pos, confidence, args...)\n}", "label": 5}
{"code": "private function getHeadObjectMiddleware()\n    {\n        return static function (callable $handler) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler) {\n                if ($command->getName() === 'HeadObject'\n                    && !isset($command['@http']['decode_content'])\n                ) {\n                    $command['@http']['decode_content'] = false;\n                }\n\n                return $handler($command, $request);\n            };\n        };\n    }", "label": 2}
{"code": "private function determineIdentifierType($identifier, $identifierType)\n    {\n        $allowedTypes = [self::TYPE_ID, self::TYPE_NAME];\n\n        if (!is_null($identifierType) && in_array($identifierType, $allowedTypes)) {\n            return $identifierType;\n        } elseif (!is_null($identifierType)) {\n            throw new InvalidArgumentException(sprintf(\n                'Invalid identifier type %s',\n                $identifierType\n            ));\n        }\n\n        if (is_numeric($identifier)) {\n            return self::TYPE_ID;\n        }\n\n        return self::TYPE_NAME;\n    }", "label": 2}
{"code": "def _getBusVoltageLambdaSensor(self):\n        \"\"\" Returns an array of length nb where each value is the sum of the\n        Lagrangian multipliers on the upper and the negative of the Lagrangian\n        multipliers on the lower voltage limits. \"\"\"\n        muVmin = array([b.mu_vmin for b in self.market.case.connected_buses])\n        muVmax = array([b.mu_vmax for b in self.market.case.connected_buses])\n        muVmin = -1.0 * muVmin\n        diff = muVmin + muVmax\n        return diff", "label": 1}
{"code": "public function getMetadata($key = null)\n    {\n        if (!$key) {\n            return $this['metadata'];\n        }\n\n        if (isset($this->definition['metadata'][$key])) {\n            return $this->definition['metadata'][$key];\n        }\n\n        return null;\n    }", "label": 2}
{"code": "def locals\n      return [] unless _binding\n\n      _binding.local_variables.each_with_object({}) do |e, a|\n        a[e] = _binding.local_variable_get(e)\n        a\n      end\n    end", "label": 4}
{"code": "def title=(v)\n      DataTypeValidator.validate \"#{self.class}.title\", [String, Cell], v\n      @title ||= Title.new\n      if v.is_a?(String)\n        @title.text = v\n      elsif v.is_a?(Cell)\n        @title.cell = v\n      end\n    end", "label": 4}
{"code": "function compareTimes(a, b) {\n    if (typeof a !== 'string' || typeof b !== 'string') {\n      return NaN;\n    }\n\n    var aTimePieces = extractIso8601TimePieces(a);\n    var bTimePieces = extractIso8601TimePieces(b);\n\n    if (aTimePieces === null || bTimePieces === null) {\n      return NaN;\n    }\n\n    for (var timePieceIndex = 0; timePieceIndex < aTimePieces.length; timePieceIndex++) {\n      if (aTimePieces[timePieceIndex] < bTimePieces[timePieceIndex]) {\n        return -1;\n      } else if (aTimePieces[timePieceIndex] > bTimePieces[timePieceIndex]) {\n        return 1;\n      }\n    }\n\n    // If we got here, the two parameters represent the same time of day\n    return 0;\n  }", "label": 3}
{"code": "function(viewOrUrlOrId, area, elementsToSearch) {\n            if (typeof viewOrUrlOrId === 'string') {\n                var viewId;\n\n                if (viewEngine.isViewUrl(viewOrUrlOrId)) {\n                    viewId = viewEngine.convertViewUrlToViewId(viewOrUrlOrId);\n                } else {\n                    viewId = viewOrUrlOrId;\n                }\n\n                if (area) {\n                    viewId = this.translateViewIdToArea(viewId, area);\n                }\n\n                if (elementsToSearch) {\n                    var existing = findInElements(elementsToSearch, viewId);\n                    if (existing) {\n                        return system.defer(function(dfd) {\n                            dfd.resolve(existing);\n                        }).promise();\n                    }\n                }\n\n                return viewEngine.createView(viewId);\n            }\n\n            return system.defer(function(dfd) {\n                dfd.resolve(viewOrUrlOrId);\n            }).promise();\n        }", "label": 3}
{"code": "public static bridgegroup_nsip_binding[] get(nitro_service service, Long id) throws Exception{\n\t\tbridgegroup_nsip_binding obj = new bridgegroup_nsip_binding();\n\t\tobj.set_id(id);\n\t\tbridgegroup_nsip_binding response[] = (bridgegroup_nsip_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function loadInlineCss(rootDir, apps) {\n    _.each(apps, function (app, appName) {\n        _.each(app.routes, function (route) {\n            var filePath = rootDir + '/app/' + appName + '/inline/' + route.name + '.css';\n            if (route.inline && fs.existsSync(filePath)) {\n                inlineCssCache[appName + '||' + route.name] = fs.readFileSync(filePath, { encoding: 'utf8' });\n            }\n        });\n    });\n}", "label": 3}
{"code": "function SegmentMeta(properties) {\n                this.evidences = [];\n                if (properties)\n                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n                        if (properties[keys[i]] != null)\n                            this[keys[i]] = properties[keys[i]];\n            }", "label": 3}
{"code": "public static base_response add(nitro_service client, vlan resource) throws Exception {\n\t\tvlan addresource = new vlan();\n\t\taddresource.id = resource.id;\n\t\taddresource.aliasname = resource.aliasname;\n\t\taddresource.ipv6dynamicrouting = resource.ipv6dynamicrouting;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public List<Artifact> getArtifacts(final Boolean hasLicense) throws GrapesCommunicationException {\n        final Client client = getClient();\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.getArtifactsPath());\n        final ClientResponse response = resource.queryParam(ServerAPI.HAS_LICENSE_PARAM, hasLicense.toString())\n                .accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);\n\n        client.destroy();\n        if(ClientResponse.Status.OK.getStatusCode() != response.getStatus()){\n            final String message = \"Failed to get artifacts\";\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n\n        return response.getEntity(ArtifactList.class);\n    }", "label": 0}
{"code": "function patch(ctx) {\n    const statusMethods = Object.assign({}, opts.statusMethods, statusCodeMap)\n    ctx.send = respond.bind(ctx, ctx)\n\n    // Bind status methods.\n    for (const method in statusMethods) {\n      const code = statusMethods[method]\n      ctx[method] = respond.bind(ctx, ctx, code)\n    }\n\n    // Bind other methods\n    const methods = Object.assign({}, opts.methods)\n    for (const method in methods) {\n      const fn = methods[method]\n      ctx[method] = fn.bind(ctx, ctx)\n    }\n\n    return ctx\n  }", "label": 3}
{"code": "func (esSvc *ElasticSearchService) SaveData(date time.Time, typeName string, sinkData []interface{}) error {\n\tif typeName == \"\" || len(sinkData) == 0 {\n\t\treturn nil\n\t}\n\n\tindexName := esSvc.Index(date)\n\n\t// Use the IndexExists service to check if a specified index exists.\n\texists, err := esSvc.EsClient.IndexExists(indexName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !exists {\n\t\t// Create a new index.\n\t\tcreateIndex, err := esSvc.EsClient.CreateIndex(indexName, mapping)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tack := false\n\t\tswitch i := createIndex.(type) {\n\t\tcase *elastic2.IndicesCreateResult:\n\t\t\tack = i.Acknowledged\n\t\tcase *elastic5.IndicesCreateResult:\n\t\t\tack = i.Acknowledged\n\t\t}\n\t\tif !ack {\n\t\t\treturn errors.New(\"Failed to acknoledge index creation\")\n\t\t}\n\t}\n\n\taliases, err := esSvc.EsClient.GetAliases(indexName)\n\tif err != nil {\n\t\treturn err\n\t}\n\taliasName := esSvc.IndexAlias(typeName)\n\n\thasAlias := false\n\tswitch a := aliases.(type) {\n\tcase *elastic2.AliasesResult:\n\t\thasAlias = a.Indices[indexName].HasAlias(aliasName)\n\tcase *elastic5.AliasesResult:\n\t\thasAlias = a.Indices[indexName].HasAlias(aliasName)\n\t}\n\tif !hasAlias {\n\t\tcreateAlias, err := esSvc.EsClient.AddAlias(indexName, esSvc.IndexAlias(typeName))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tack := false\n\t\tswitch i := createAlias.(type) {\n\t\tcase *elastic2.AliasResult:\n\t\t\tack = i.Acknowledged\n\t\tcase *elastic5.AliasResult:\n\t\t\tack = i.Acknowledged\n\t\t}\n\t\tif !ack {\n\t\t\treturn errors.New(\"Failed to acknoledge index alias creation\")\n\t\t}\n\t}\n\n\tfor _, data := range sinkData {\n\t\tesSvc.EsClient.AddBulkReq(indexName, typeName, data)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def load_schemes_from_project(project_full_path)\n      schemes = Xcodeproj::Project.schemes project_full_path\n      schemes.each do |scheme_name|\n        @schemes[scheme_name] = project_full_path\n      end\n    end", "label": 4}
{"code": "public function flush($untilEmpty = true)\n    {\n        // Send BatchWriteItem requests until the queue is empty\n        $keepFlushing = true;\n        while ($this->queue && $keepFlushing) {\n            $commands = $this->prepareCommands();\n            $pool = new CommandPool($this->client, $commands, [\n                'before' => $this->config['before'],\n                'concurrency' => $this->config['pool_size'],\n                'fulfilled'   => function (ResultInterface $result) {\n                    // Re-queue any unprocessed items\n                    if ($result->hasKey('UnprocessedItems')) {\n                        $this->retryUnprocessed($result['UnprocessedItems']);\n                    }\n                },\n                'rejected' => function ($reason) {\n                    if ($reason instanceof AwsException) {\n                        $code = $reason->getAwsErrorCode();\n                        if ($code === 'ProvisionedThroughputExceededException') {\n                            $this->retryUnprocessed($reason->getCommand()['RequestItems']);\n                        } elseif (is_callable($this->config['error'])) {\n                            $this->config['error']($reason);\n                        }\n                    }\n                }\n            ]);\n            $pool->promise()->wait();\n            $keepFlushing = (bool) $untilEmpty;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function processModules(item) {\n  if (item.exports && !item._traced) {\n    bootstrap(item, 'exports', item.filename);\n    item._traced = true;\n  }\n  if (item.children) {\n    item.children.map(processModules);\n  }\n}", "label": 3}
{"code": "public static void pauseTimer(final String type) {\n    TransactionLogger instance = getInstance();\n    if (instance == null) {\n      return;\n    }\n\n    instance.components.get(type).pauseTimer();\n  }", "label": 0}
{"code": "def outline_level_rows(start_index, end_index, level = 1, collapsed = true)\n      outline rows, (start_index..end_index), level, collapsed\n    end", "label": 4}
{"code": "function () {\n        var\n            attributes = this._definitionAttributes,\n            Constructor,\n            newPrototype;\n        if (attributes) {\n            _gpfAssert(\"function\" === typeof _gpfAttributesAdd, \"Attributes can't be defined before they exist\");\n            Constructor = this._Constructor;\n            newPrototype = Constructor.prototype;\n            _gpfObjectForEach(attributes, function (attributeList, attributeName) {\n                attributeName = _gpfDecodeAttributeMember(attributeName);\n                if (attributeName in newPrototype || attributeName === \"Class\") {\n                    _gpfAttributesAdd(Constructor, attributeName, attributeList);\n                } else {\n                    // 2013-12-15 ABZ Exceptional, trace it only\n                    console.error(\"gpf.define: Invalid attribute name '\" + attributeName + \"'\");\n                }\n            });\n        }\n    }", "label": 3}
{"code": "function firstPass (loadedComponents, messages) {\n  messages.heading('Reference resolution - first pass')\n\n  const components = loadedComponents.blueprintComponents\n  const tymlyRefs = loadedComponents.blueprintRefs\n\n  const resolutions = findFirstPassResolutions(tymlyRefs, components)\n\n  if (!resolutions) {\n    messages.subHeading('Nothing to resolve')\n    return\n  }\n\n  resolveResolutions(resolutions, components, messages)\n}", "label": 3}
{"code": "func (m *MultiLog) Close() error {\n\tvar errors []error\n\tfor _, log := range m.loggers {\n\t\terrors = append(errors, log.Close())\n\t}\n\treturn trace.NewAggregate(errors...)\n}", "label": 5}
{"code": "public void drawText(String text, Font font, Rectangle box, Color fontColor) {\n\t\ttemplate.saveState();\n\t\t// get the font\n\t\tDefaultFontMapper mapper = new DefaultFontMapper();\n\t\tBaseFont bf = mapper.awtToPdf(font);\n\t\ttemplate.setFontAndSize(bf, font.getSize());\n\n\t\t// calculate descent\n\t\tfloat descent = 0;\n\t\tif (text != null) {\n\t\t\tdescent = bf.getDescentPoint(text, font.getSize());\n\t\t}\n\n\t\t// calculate the fitting size\n\t\tRectangle fit = getTextSize(text, font);\n\n\t\t// draw text if necessary\n\t\ttemplate.setColorFill(fontColor);\n\t\ttemplate.beginText();\n\t\ttemplate.showTextAligned(PdfContentByte.ALIGN_LEFT, text, origX + box.getLeft() + 0.5f\n\t\t\t\t* (box.getWidth() - fit.getWidth()), origY + box.getBottom() + 0.5f\n\t\t\t\t* (box.getHeight() - fit.getHeight()) - descent, 0);\n\t\ttemplate.endText();\n\t\ttemplate.restoreState();\n\t}", "label": 0}
{"code": "function reverse (arr) {\n  const reversedArray = [];\n  for (let i = arr.length - 1; i >= 0; i--) {\n    reversedArray.push(arr[i]);\n  }\n  return reversedArray;\n}", "label": 3}
{"code": "public function collect() : GitInfo\n    {\n        $branch = $this->collectBranch();\n        $commit = $this->collectCommit();\n        $remotes = $this->collectRemotes();\n\n        return new GitInfo($branch, $commit, $remotes);\n    }", "label": 2}
{"code": "func (t *Torrent) allStats(f func(*ConnStats)) {\n\tf(&t.stats)\n\tf(&t.cl.stats)\n}", "label": 5}
{"code": "def _create_create_tracking_event(instance):\n    \"\"\"\n    Create a TrackingEvent and TrackedFieldModification for a CREATE event.\n    \"\"\"\n    event = _create_event(instance, CREATE)\n    for field in instance._tracked_fields:\n        if not isinstance(instance._meta.get_field(field), ManyToManyField):\n            _create_tracked_field(event, instance, field)", "label": 1}
{"code": "func MarshalBinary(fields ...interface{}) ([]byte, error) {\n\tbuf := new(bytes.Buffer)\n\n\tfor _, p := range fields {\n\t\tswitch m := p.(type) {\n\t\tcase encoding.BinaryMarshaler:\n\t\t\tdata, err := m.MarshalBinary()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, ProtocolError(err)\n\t\t\t}\n\n\t\t\t_, _ = buf.Write(data)\n\t\tcase []byte:\n\t\t\t_, _ = buf.Write(m)\n\t\tcase string:\n\t\t\t_, _ = buf.WriteString(m)\n\t\tdefault:\n\t\t\terr := binary.Write(buf, binary.LittleEndian, p)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, ProtocolError(err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn buf.Bytes(), nil\n}", "label": 5}
{"code": "public static function make($source)\n    {\n        $engines  = config('datatables.engines');\n        $builders = config('datatables.builders');\n\n        $args = func_get_args();\n        foreach ($builders as $class => $engine) {\n            if ($source instanceof $class) {\n                return call_user_func_array([$engines[$engine], 'create'], $args);\n            }\n        }\n\n        foreach ($engines as $engine => $class) {\n            if (call_user_func_array([$engines[$engine], 'canCreate'], $args)) {\n                return call_user_func_array([$engines[$engine], 'create'], $args);\n            }\n        }\n\n        throw new \\Exception('No available engine for ' . get_class($source));\n    }", "label": 2}
{"code": "function saveObjectToJSON(filePath, data) {\n    try {\n      data = JSON.stringify(data, null, 2);\n      writeFileSync(filePath, data, { encoding: 'utf8' });\n      return true;\n    } catch(ex) {\n      console.warn('Unable to save class JSON');\n      return false;\n    }\n\n    // NOTE: ASYNC REQUIRES PROMISIFYING ALL OPERATIONS\n    // fs.writeFile(filePath, data, err => {\n    //   if (err) { console.warn(`Unable to save ${filePath}`); }\n    // });\n  }", "label": 3}
{"code": "function _gpfAttributesDecorator() {\n        var attributes = _gpfArraySlice(arguments);\n        return function (ClassConstructor, member) {\n            if (!_gpfIsClass(ClassConstructor)) {\n                gpf.Error.es6classOnly();\n            }\n            _gpfAttributesDecoratorAddAttributes(_gpfDefineClassImport(ClassConstructor), member, attributes);\n        };\n    }", "label": 3}
{"code": "def interline_spacing(space)\n      begin\n        Float(space)\n      rescue ArgumentError\n        Kernel.raise ArgumentError, 'invalid value for interline_spacing'\n      rescue TypeError\n        Kernel.raise TypeError, \"can't convert #{space.class} into Float\"\n      end\n      primitive \"interline-spacing #{space}\"\n    end", "label": 4}
{"code": "function extend(a, b){\n\tvar p, type;\n\tfor(p in b) {\n\t\ttype = typeof b[p];\n\t\tif(type !== \"object\" && type !== \"function\") {\n\t\t\ta[p] = b[p];\n\t\t}\n\t}\n\treturn a;\n}", "label": 3}
{"code": "def parseEquation(self, inp):\n        \"\"\"Solves the equation specified by the input string.\n\n        Args:\n            inp (str): An equation, specified in words, containing some\n                combination of numbers, binary, and unary operations.\n\n        Returns:\n            The floating-point result of carrying out the computation.\n        \"\"\"\n        inp = MathService._preprocess(inp)\n        split = inp.split(' ')\n\n        # Recursive call on unary operators\n        for i, w in enumerate(split):\n            if w in self.__unaryOperators__:\n                op = self.__unaryOperators__[w]\n\n                # Split equation into halves\n                eq1 = ' '.join(split[:i])\n                eq2 = ' '.join(split[i + 1:])\n\n                # Calculate second half\n                result = MathService._applyUnary(self.parseEquation(eq2), op)\n\n                return self.parseEquation(eq1 + \" \" + str(result))\n\n        def extractNumbersAndSymbols(inp):\n            numbers = []\n            symbols = []\n\n            # Divide into values (numbers), operators (symbols)\n            next_number = \"\"\n            for w in inp.split(' '):\n                if w in self.__binaryOperators__:\n                    symbols.append(self.__binaryOperators__[w])\n\n                    if next_number:\n                        numbers.append(next_number)\n                        next_number = \"\"\n\n                else:\n                    if next_number:\n                        next_number += \" \"\n                    next_number += w\n\n            if next_number:\n                numbers.append(next_number)\n\n            # Cast numbers from words to integers\n            def convert(n):\n                if n in self.__constants__:\n                    return self.__constants__[n]\n\n                converter = NumberService()\n                return converter.parse(n)\n\n            numbers = [convert(n) for n in numbers]\n\n            return numbers, symbols\n\n        numbers, symbols = extractNumbersAndSymbols(inp)\n\n        return MathService._calculate(numbers, symbols)", "label": 1}
{"code": "function(msg) {\n      var gameOverElement = document.getElementById('gameOver'),\n          gameOverMsgElement = document.getElementById('gameOverMsg'),\n          waitingForPlayerElem = document.getElementById('waitingForPlayer');\n      if (msg === false)  {\n        gameOverElement.style.display = 'none';\n      }\n      else {\n        gameOverMsgElement.innerText = msg;\n        gameOverElement.style.display = 'block';\n        waitingForPlayerElem.style.display = 'none';\n      }\n    }", "label": 3}
{"code": "def to_definition(schema, printer: nil, **args)\n      printer ||= GraphQL::Schema::Printer.new(schema, **args)\n      printer.print_type(self)\n    end", "label": 4}
{"code": "async def set_version(self, tp, params, version=None, elem=None):\n        \"\"\"\n        Stores version to the stream if not stored yet\n\n        :param tp:\n        :param params:\n        :param version:\n        :param elem:\n        :return:\n        \"\"\"\n        self.registry.set_tr(None)\n        tw = TypeWrapper(tp, params)\n        if not tw.is_versioned():\n            return TypeWrapper.ELEMENTARY_RES\n\n        # If not in the DB, store to the archive at the current position\n        if not self.version_db.is_versioned(tw):\n            if version is None:\n                version = self._cur_version(tw, elem)\n\n            await dump_uvarint(self.iobj, 0)\n            await dump_uvarint(self.iobj, version)\n            self.version_db.set_version(tw, 0, version)\n\n        return self.version_db.get_version(tw)[1]", "label": 1}
{"code": "func (args Arguments) Error(index int) error {\n\tobj := args.Get(index)\n\tvar s error\n\tvar ok bool\n\tif obj == nil {\n\t\treturn nil\n\t}\n\tif s, ok = obj.(error); !ok {\n\t\tpanic(fmt.Sprintf(\"assert: arguments: Error(%d) failed because object wasn't correct type: %v\", index, args.Get(index)))\n\t}\n\treturn s\n}", "label": 5}
{"code": "public function diffInRealHours($date = null, $absolute = true)\n    {\n        return (int) ($this->diffInRealSeconds($date, $absolute) / static::SECONDS_PER_MINUTE / static::MINUTES_PER_HOUR);\n    }", "label": 2}
{"code": "function updateInfo(info, override, source, sourceId) {\n  if (source) {\n    if (source.minzoom !== undefined) {\n      // eslint-disable-next-line no-param-reassign\n      info.minzoom = source.minzoom;\n    }\n    if (source.maxzoom !== undefined) {\n      // eslint-disable-next-line no-param-reassign\n      info.maxzoom = source.maxzoom;\n    }\n  }\n  if (sourceId !== undefined) {\n    // eslint-disable-next-line no-param-reassign\n    info.name = sourceId;\n  }\n  if (override) {\n    _.each(override, (v, k) => {\n      if (v === null) {\n        // When override.key == null, delete that key\n        // eslint-disable-next-line no-param-reassign\n        delete info[k];\n      } else {\n        // override info of the parent\n        // eslint-disable-next-line no-param-reassign\n        info[k] = v;\n      }\n    });\n  }\n}", "label": 3}
{"code": "func (a *HistoricalApi) availableNamespaceMetrics(request *restful.Request, response *restful.Response) {\n\tkey := core.HistoricalKey{\n\t\tObjectType:    core.MetricSetTypeNamespace,\n\t\tNamespaceName: request.PathParameter(\"namespace-name\"),\n\t}\n\ta.processMetricNamesRequest(key, response)\n}", "label": 5}
{"code": "def apply_transform(key, value, type)\n      if type\n        if respond_to?(\"convert_#{type}\", true)\n          send(\"convert_#{type}\", key, value)\n        else\n          send(type, value)\n        end\n      else\n        value\n      end\n    end", "label": 4}
{"code": "def update_shift(id, body, opts = {})\n      data, _status_code, _headers = update_shift_with_http_info(id, body, opts)\n      return data\n    end", "label": 4}
{"code": "func NewMockEmbed(ctrl *gomock.Controller) *MockEmbed {\n\tmock := &MockEmbed{ctrl: ctrl}\n\tmock.recorder = &MockEmbedMockRecorder{mock}\n\treturn mock\n}", "label": 5}
{"code": "function (credits) {\n            if (credits.enabled && !this.credits) {\n                this.credits = this.renderer.text(\n                  credits.text,\n                  0,\n                  0\n                  )\n                  .on('click', function () {\n                      if (credits.href) {\n                          location.href = credits.href;\n                      }\n                  })\n                  .attr({\n                      align: credits.position.align,\n                      zIndex: 8\n                  })\n                  .css(credits.style)\n                  .add()\n                  .align(credits.position);\n            }\n        }", "label": 3}
{"code": "def split(value, precision=1):\n    '''\n    Split `value` into value and \"exponent-of-10\", where \"exponent-of-10\" is a\n    multiple of 3.  This corresponds to SI prefixes.\n\n    Returns tuple, where the second value is the \"exponent-of-10\" and the first\n    value is `value` divided by the \"exponent-of-10\".\n\n    Args\n    ----\n    value : int, float\n        Input value.\n    precision : int\n        Number of digits after decimal place to include.\n\n    Returns\n    -------\n    tuple\n        The second value is the \"exponent-of-10\" and the first value is `value`\n        divided by the \"exponent-of-10\".\n\n    Examples\n    --------\n\n    .. code-block:: python\n\n        si_prefix.split(0.04781)   ->  (47.8, -3)\n        si_prefix.split(4781.123)  ->  (4.8, 3)\n\n    See :func:`si_format` for more examples.\n    '''\n    negative = False\n    digits = precision + 1\n\n    if value < 0.:\n        value = -value\n        negative = True\n    elif value == 0.:\n        return 0., 0\n\n    expof10 = int(math.log10(value))\n    if expof10 > 0:\n        expof10 = (expof10 // 3) * 3\n    else:\n        expof10 = (-expof10 + 3) // 3 * (-3)\n\n    value *= 10 ** (-expof10)\n\n    if value >= 1000.:\n        value /= 1000.0\n        expof10 += 3\n    elif value >= 100.0:\n        digits -= 2\n    elif value >= 10.0:\n        digits -= 1\n\n    if negative:\n        value *= -1\n\n    return value, int(expof10)", "label": 1}
{"code": "public static base_response unset(nitro_service client, vpnurl resource, String[] args) throws Exception{\n\t\tvpnurl unsetresource = new vpnurl();\n\t\tunsetresource.urlname = resource.urlname;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "func PgAttrdefByAdrelidAdnum(db XODB, adrelid pgtypes.Oid, adnum int16) (*PgAttrdef, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, adrelid, adnum, adbin, adsrc ` +\n\t\t`FROM pg_catalog.pg_attrdef ` +\n\t\t`WHERE adrelid = $1 AND adnum = $2`\n\n\t// run query\n\tXOLog(sqlstr, adrelid, adnum)\n\tpa := PgAttrdef{}\n\n\terr = db.QueryRow(sqlstr, adrelid, adnum).Scan(&pa.Tableoid, &pa.Cmax, &pa.Xmax, &pa.Cmin, &pa.Xmin, &pa.Oid, &pa.Ctid, &pa.Adrelid, &pa.Adnum, &pa.Adbin, &pa.Adsrc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "def compile_column(name: str, data_type: str, nullable: bool) -> str:\n    \"\"\"Create column definition statement.\"\"\"\n\n    null_str = 'NULL' if nullable else 'NOT NULL'\n\n    return '{name} {data_type} {null},'.format(name=name,\n                                               data_type=data_type,\n                                               null=null_str)", "label": 1}
{"code": "func (c *Cache) NewWatcher(ctx context.Context, watch services.Watch) (services.Watcher, error) {\n\treturn c.eventsCache.NewWatcher(ctx, watch)\n}", "label": 5}
{"code": "func (t *TestTLSServer) Close() error {\n\terr := t.TLSServer.Close()\n\tif t.Listener != nil {\n\t\tt.Listener.Close()\n\t}\n\tif t.AuthServer.Backend != nil {\n\t\tt.AuthServer.Backend.Close()\n\t}\n\treturn err\n}", "label": 5}
{"code": "function Parser(options) {\n  options = options || {};\n\n  // env storage\n  this._env = Object.create(null);\n\n  // current env\n  this._currEnv = options.currEnv || process.env;\n\n  // enable/disable booleans\n  this._allowBool = has.call(options, 'booleans')\n    ? options.booleans\n    : false;\n\n  // enable/disable numbers\n  this._allowNum = has.call(options, 'numbers')\n    ? options.numbers\n    : false;\n}", "label": 3}
{"code": "def write_file(path, content)\n      Jekyll.logger.debug \"WRITING:\", path\n      path = sanitized_path(path)\n      FileUtils.mkdir_p File.dirname(path)\n      File.open(path, \"wb\") do |file|\n        file.write(content)\n      end\n      # we should fully process in dev mode for tests to pass\n      if ENV[\"RACK_ENV\"] == \"production\"\n        site.read\n      else\n        site.process\n      end\n    end", "label": 4}
{"code": "def create(self, dotdata, prog=\"dot\", format=\"xdot\"):\n        \"\"\" Creates and returns a representation of the graph using the\n        Graphviz layout program given by 'prog', according to the given format.\n\n        Writes the graph to a temporary dot file and processes it with the\n        program given by 'prog' (which defaults to 'dot'), reading the output\n        and returning it as a string if the operation is successful. On failure\n        None is returned.\n\n        Based on PyDot by Ero Carrera.\n        \"\"\"\n        import os, tempfile\n        from dot2tex.dotparsing import find_graphviz\n\n        # Map Graphviz executable names to their paths.\n        progs = find_graphviz()\n        if progs is None:\n            logger.warning(\"GraphViz executables not found.\")\n            return None\n        if not progs.has_key(prog):\n            logger.warning('Invalid program [%s]. Available programs are: %s' % \\\n                           (prog, progs.keys()))\n            return None\n\n        # Make a temporary file ...\n        tmp_fd, tmp_name = tempfile.mkstemp()\n        os.close(tmp_fd)\n        # ... and save the graph to it.\n        dot_fd = file(tmp_name, \"w+b\")\n        dot_fd.write(dotdata) # DOT language.\n        dot_fd.close()\n\n        # Get the temporary file directory name.\n        tmp_dir = os.path.dirname(tmp_name)\n\n        # Process the file using the layout program, specifying the format.\n        p = subprocess.Popen((progs[prog], '-T'+format, tmp_name),\n            cwd=tmp_dir, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\n        stderr = p.stderr\n        stdout = p.stdout\n\n        # Make sense of the standard output form the process.\n        stdout_output = list()\n        while True:\n            data = stdout.read()\n            if not data:\n                break\n            stdout_output.append(data)\n        stdout.close()\n\n        if stdout_output:\n            stdout_output = ''.join(stdout_output)\n\n        # Similarly so for any standard error.\n        if not stderr.closed:\n            stderr_output = list()\n            while True:\n                data = stderr.read()\n                if not data:\n                    break\n                stderr_output.append(data)\n            stderr.close()\n\n            if stderr_output:\n                stderr_output = ''.join(stderr_output)\n\n        status = p.wait()\n\n        if status != 0 :\n            logger.error(\"Program [%s] terminated with status: %d. stderr \" \\\n                \"follows: %s\" % ( prog, status, stderr_output ) )\n        elif stderr_output:\n            logger.error( \"%s\", stderr_output )\n\n        # Remove the temporary file.\n        os.unlink(tmp_name)\n\n        return stdout_output", "label": 1}
{"code": "private function webLogin()\n    {\n        if ($this->inputs['password'] == $this->config['webpassword']) {\n            $_SESSION['logged_in'] = true;\n            exit($this->showWebForm());\n        } else {\n            $error = 'Sorry your password was incorrect.';\n            exit($this->showWebLoginForm($error));\n        }\n    }", "label": 2}
{"code": "public static base_response delete(nitro_service client, String filename) throws Exception {\n\t\tsystembackup deleteresource = new systembackup();\n\t\tdeleteresource.filename = filename;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def _prepare_find(cls, *args, **kw):\n\t\t\"\"\"Execute a find and return the resulting queryset using combined plain and parametric query generation.\n\t\t\n\t\tAdditionally, performs argument case normalization, refer to the `_prepare_query` method's docstring.\n\t\t\"\"\"\n\t\t\n\t\tcls, collection, query, options = cls._prepare_query(\n\t\t\t\tcls.FIND_MAPPING,\n\t\t\t\tcls.FIND_OPTIONS,\n\t\t\t\t*args,\n\t\t\t\t**kw\n\t\t\t)\n\t\t\n\t\tif 'await' in options:\n\t\t\traise TypeError(\"Await is hard-deprecated as reserved keyword in Python 3.7, use wait instead.\")\n\t\t\n\t\tif 'cursor_type' in options and {'tail', 'wait'} & set(options):\n\t\t\traise TypeError(\"Can not combine cursor_type and tail/wait arguments.\")\n\t\t\n\t\telif options.pop('tail', False):\n\t\t\toptions['cursor_type'] = CursorType.TAILABLE_AWAIT if options.pop('wait', True) else CursorType.TAILABLE\n\t\t\n\t\telif 'wait' in options:\n\t\t\traise TypeError(\"Wait option only applies to tailing cursors.\")\n\t\t\n\t\tmodifiers = options.get('modifiers', dict())\n\t\t\n\t\tif 'max_time_ms' in options:\n\t\t\tmodifiers['$maxTimeMS'] = options.pop('max_time_ms')\n\t\t\n\t\tif modifiers:\n\t\t\toptions['modifiers'] = modifiers\n\t\t\n\t\treturn cls, collection, query, options", "label": 1}
{"code": "func (a *AuthWithRoles) SetClusterName(c services.ClusterName) error {\n\tif err := a.action(defaults.Namespace, services.KindClusterName, services.VerbCreate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := a.action(defaults.Namespace, services.KindClusterName, services.VerbUpdate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.SetClusterName(c)\n}", "label": 5}
{"code": "def parse(self, representation):\n        \"\"\"Parses a duration string representation\n\n\n        :param  representation: duration as a string, example: '1d' (day),\n                                '34minutes' (minutes), '485s' (seconds)...\n        :type   representation: string\n\n        :returns: the parsed duration representation\n        :rtype: DurationRepresentation\n        \"\"\"\n        elements = extract_tokens(representation)\n\n        try:\n            scales = [DurationRepresentation(float(p[0]), Scale(p[1])) for p in elements]\n        except ValueError:\n            raise ScaleFormatError(\"Malformed duration representation: {0}\".format(representation))\n\n        return scales", "label": 1}
{"code": "protected static Map<String, String> getHeadersAsMap(ResponseEntity response) {\n\n        Map<String, List<String>> headers = new HashMap<>(response.getHeaders());\n        Map<String, String> map = new HashMap<>();\n\n        for ( Map.Entry<String, List<String>> header :headers.entrySet() ) {\n            String headerValue = Joiner.on(\",\").join(header.getValue());\n            map.put(header.getKey(), headerValue);\n        }\n\n        return map;\n    }", "label": 0}
{"code": "def advance(self):\n        \"\"\"Advance the base iterator, publish to constituent iterators.\"\"\"\n        elem = next(self._iterable)\n        for deque in self._deques:\n            deque.append(elem)", "label": 1}
{"code": "def process(css, opts = {})\n      opts = convert_options(opts)\n\n      apply_wrapper =\n        \"(function(opts, pluginOpts) {\" \\\n        \"return eval(process.apply(this, opts, pluginOpts));\" \\\n        \"})\"\n\n      plugin_opts = params_with_browsers(opts[:from]).merge(opts)\n      process_opts = {\n        from: plugin_opts.delete(:from),\n        to: plugin_opts.delete(:to),\n        map: plugin_opts.delete(:map),\n      }\n\n      begin\n        result = runtime.call(apply_wrapper, [css, process_opts, plugin_opts])\n      rescue ExecJS::ProgramError => e\n        contry_error = \"BrowserslistError: \" \\\n          \"Country statistics is not supported \" \\\n          \"in client-side build of Browserslist\"\n        if e.message == contry_error\n          raise \"Country statistics is not supported in AutoprefixerRails. \" \\\n            \"Use Autoprefixer with webpack or other Node.js builder.\"\n        else\n          raise e\n        end\n      end\n\n      Result.new(result[\"css\"], result[\"map\"], result[\"warnings\"])\n    end", "label": 4}
{"code": "public function walkIdentificationVariableDeclaration($identificationVariableDecl)\n    {\n        $sql = $this->walkRangeVariableDeclaration($identificationVariableDecl->rangeVariableDeclaration);\n\n        if ($identificationVariableDecl->indexBy) {\n            $this->walkIndexBy($identificationVariableDecl->indexBy);\n        }\n\n        foreach ($identificationVariableDecl->joins as $join) {\n            $sql .= $this->walkJoin($join);\n        }\n\n        return $sql;\n    }", "label": 2}
{"code": "func (t *Text) StyleAt(pos int) tcell.Style {\n\tif pos < 0 || pos >= len(t.text) || t.widths[pos] < 1 {\n\t\treturn tcell.StyleDefault\n\t}\n\treturn t.styles[pos]\n}", "label": 5}
{"code": "function() {\n\t\t\t\t\t// don't create more object URLs than needed\n\t\t\t\t\tif (blob_changed || !object_url) {\n\t\t\t\t\t\tobject_url = get_URL().createObjectURL(blob);\n\t\t\t\t\t}\n\t\t\t\t\tif (target_view) {\n\t\t\t\t\t\ttarget_view.location.href = object_url;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tvar new_tab = view.open(object_url, \"_blank\");\n\t\t\t\t\t\tif (new_tab == undefined && typeof safari !== \"undefined\") {\n\t\t\t\t\t\t\t//Apple do not allow window.open, see http://bit.ly/1kZffRI\n\t\t\t\t\t\t\tview.location.href = object_url\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tfilesaver.readyState = filesaver.DONE;\n\t\t\t\t\tdispatch_all();\n\t\t\t\t\trevoke(object_url);\n\t\t\t\t}", "label": 3}
{"code": "func (t *TestTLSServer) ClientTLSConfig(identity TestIdentity) (*tls.Config, error) {\n\ttlsConfig, err := t.Identity.TLSConfig(t.AuthServer.CipherSuites)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif identity.I != nil {\n\t\tcert, err := t.AuthServer.NewCertificate(identity)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\ttlsConfig.Certificates = []tls.Certificate{*cert}\n\t} else {\n\t\t// this client is not authenticated, which means that auth\n\t\t// server should apply Nop builtin role\n\t\ttlsConfig.Certificates = nil\n\t}\n\treturn tlsConfig, nil\n}", "label": 5}
{"code": "def stop_playing(wait_for_confirmation = false)\n      @was_playing_before = @playing\n      @speaking = false\n      @playing = false\n      sleep IDEAL_LENGTH / 1000.0 if @was_playing_before\n\n      return unless wait_for_confirmation\n\n      @has_stopped_playing = false\n      sleep IDEAL_LENGTH / 1000.0 until @has_stopped_playing\n      @has_stopped_playing = false\n    end", "label": 4}
{"code": "function() {\n        var builder = [this.banner, '', this.options_title],\n            shorts = false, longest = 0, rule;\n        var rules = build_rules(this.filters, this._rules);\n        for(var i = 0; i < rules.length; i++) {\n            rule = rules[i];\n            // Quick-analyze the options.\n            if(rule.short) shorts = true;\n            if(rule.decl.length > longest) longest = rule.decl.length;\n        }\n        for(var i = 0; i < rules.length; i++) {\n            var text = spaces(6);\n            rule = rules[i];\n            if(shorts) {\n                if(rule.short) text = spaces(2) + rule.short + ', ';\n            }\n            text += spaces(rule.decl, longest) + spaces(3);\n            text += rule.desc;\n            builder.push(text);\n        }\n        return builder.join('\\n');\n    }", "label": 3}
{"code": "def check_alert(step, text):\n    \"\"\"\n    Check the alert text\n    \"\"\"\n\n    try:\n        alert = Alert(world.browser)\n        assert_equals(alert.text, text)\n    except WebDriverException:\n        # PhantomJS is kinda poor\n        pass", "label": 1}
{"code": "public function send(array $items)\n    {\n        $start = microtime(true);\n        try {\n            call_user_func_array($this->getCallback(), [$items]);\n        } catch (\\Exception $e) {\n            if ($this->debugOutput) {\n                fwrite(\n                    $this->debugOutputResource,\n                    $e->getMessage() . PHP_EOL . PHP_EOL\n                    . $e->getTraceAsString() . PHP_EOL\n                );\n            }\n\n            return false;\n        }\n        $end = microtime(true);\n        if ($this->debugOutput) {\n            fwrite(\n                $this->debugOutputResource,\n                sprintf(\n                    '%f seconds for %s: %d items' . PHP_EOL,\n                    $end - $start,\n                    $this->batchMethod,\n                    count($items)\n                )\n            );\n            fwrite(\n                $this->debugOutputResource,\n                sprintf(\n                    'memory used: %d' . PHP_EOL,\n                    memory_get_usage()\n                )\n            );\n        }\n\n        return true;\n    }", "label": 2}
{"code": "def decoded_group_addresses\n      groups.map { |k,v| v.map { |a| a.decoded } }.flatten\n    end", "label": 4}
{"code": "func HasPrefix(p string) FilterFunc {\n\treturn FilterFunc(func(m *Mount) bool {\n\t\treturn strings.HasPrefix(m.MountPoint, p)\n\t})\n}", "label": 5}
{"code": "def del(pattern = SCAN_PATTERN, count = 0)\n      raise ArgumentError, \"Please provide a number of keys to delete greater than zero\" if count.zero?\n\n      pattern = suffix(pattern)\n\n      log_debug { \"Deleting keys by: #{pattern}\" }\n      keys, time = timed { keys(pattern, count) }\n      key_size   = keys.size\n      log_debug { \"#{key_size} keys found in #{time} sec.\" }\n      _, time = timed { batch_delete(keys) }\n      log_debug { \"Deleted #{key_size} keys in #{time} sec.\" }\n\n      key_size\n    end", "label": 4}
{"code": "function mapProperties(obj, func) {\n    if (_.isArray(obj)) {\n        throw new Error(`Input must be an object: ${obj}`);\n    }\n    else {\n        const resultObj = Object.create(Object.prototype);\n        for (const key in obj) {\n            if (obj.hasOwnProperty(key)) {\n                resultObj[key] = func(obj[key], key);\n            }\n        }\n        return resultObj;\n    }\n}", "label": 3}
{"code": "public static base_response delete(nitro_service client, dnssrvrec resource) throws Exception {\n\t\tdnssrvrec deleteresource = new dnssrvrec();\n\t\tdeleteresource.domain = resource.domain;\n\t\tdeleteresource.target = resource.target;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def setup_queue(consumer)\n      logger.info \"setting up queue: #{consumer.get_queue_name}\"\n\n      queue = @broker.queue(consumer.get_queue_name, consumer.get_arguments)\n      @broker.bind_queue(queue, consumer.routing_keys)\n\n      queue.subscribe(consumer_tag: unique_consumer_tag, manual_ack: true) do |*args|\n        delivery_info, properties, payload = Hutch::Adapter.decode_message(*args)\n        handle_message(consumer, delivery_info, properties, payload)\n      end\n    end", "label": 4}
{"code": "def merge_perchrom_vcfs(job, perchrom_vcfs, tool_name, univ_options):\n    \"\"\"\n    Merge per-chromosome vcf files into a single genome level vcf.\n\n    :param dict perchrom_vcfs: Dictionary with chromosome name as key and fsID of the corresponding\n           vcf as value\n    :param str tool_name: Name of the tool that generated the vcfs\n    :returns: fsID for the merged vcf\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {''.join([chrom, '.vcf']): jsid for chrom, jsid in perchrom_vcfs.items()}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n    first = True\n    with open(''.join([work_dir, '/', 'all_merged.vcf']), 'w') as outvcf:\n        for chromvcfname in chrom_sorted([x.rstrip('.vcf') for x in input_files.keys()]):\n            with open(input_files[chromvcfname + '.vcf'], 'r') as infile:\n                for line in infile:\n                    line = line.strip()\n                    if line.startswith('#'):\n                        if first:\n                            print(line, file=outvcf)\n                        continue\n                    first = False\n                    print(line, file=outvcf)\n    output_file = job.fileStore.writeGlobalFile(outvcf.name)\n    export_results(job, output_file, outvcf.name, univ_options, subfolder='mutations/' + tool_name)\n    job.fileStore.logToMaster('Ran merge_perchrom_vcfs for %s successfully' % tool_name)\n    return output_file", "label": 1}
{"code": "def reset_attribute!(attr)\n      attr = database_field_name(attr)\n      attributes[attr] = changed_attributes.delete(attr) if attribute_changed?(attr)\n    end", "label": 4}
{"code": "function utf8Substr(str, startInBytes, lengthInBytes) {\n\tconst strBytes = stringToByteArray(str);\n\tconst subStrBytes = [];\n\tlet count = 0;\n\n\tfor (let i = startInBytes; count < lengthInBytes; i++) {\n\t\tsubStrBytes.push(strBytes[i]);\n\t\tcount++;\n\t}\n\n\treturn byteArrayToString(subStrBytes);\n\n\t// Converts the byte array to a UTF-8 string.\n\t// From http://stackoverflow.com/questions/1240408/reading-bytes-from-a-javascript-string?lq=1\n\tfunction byteArrayToString(byteArray) {\n\t\tlet str = '';\n\t\tfor (let i = 0; i < byteArray.length; i++) {\n\t\t\tstr += byteArray[i] <= 0x7F ? byteArray[i] === 0x25 ? '%25' : // %\n\t\t\t\tString.fromCharCode(byteArray[i]) : '%' + byteArray[i].toString(16).toUpperCase();\n\t\t}\n\n\t\treturn decodeURIComponent(str);\n\t}\n}", "label": 3}
{"code": "def _get_v_angle_guess(self, case):\n        \"\"\" Make the vector of voltage phase guesses.\n        \"\"\"\n        v_angle = array([bus.v_angle * (pi / 180.0)\n                         for bus in case.connected_buses])\n        return v_angle", "label": 1}
{"code": "def get_all_cleaned_data(self):\n        \"\"\"\n        Returns a merged dictionary of all step cleaned_data dictionaries.\n        If a step contains a `FormSet`, the key will be prefixed with formset\n        and contain a list of the formset' cleaned_data dictionaries.\n        \"\"\"\n        cleaned_data = {}\n        for form_key in self.get_form_list():\n            form_obj = self.get_form(\n                step=form_key,\n                data=self.storage.get_step_data(form_key),\n                files=self.storage.get_step_files(form_key)\n            )\n            if form_obj.is_valid():\n                if isinstance(form_obj.cleaned_data, (tuple, list)):\n                    cleaned_data.update({\n                        'formset-%s' % form_key: form_obj.cleaned_data\n                    })\n                else:\n                    cleaned_data.update(form_obj.cleaned_data)\n        return cleaned_data", "label": 1}
{"code": "protected function assignId()\n    {\n        list($vendor, $package) = explode('/', $this->name);\n        $package = str_replace(['flarum-ext-', 'flarum-'], '', $package);\n        $this->id = \"$vendor-$package\";\n    }", "label": 2}
{"code": "func OptionLoadBalancer(nid string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.loadBalancerNID = nid\n\t\tsb.oslTypes = append(sb.oslTypes, osl.SandboxTypeLoadBalancer)\n\t}\n}", "label": 5}
{"code": "protected void load()\r\n    {\r\n        properties = new Properties();\r\n\r\n        String filename = getFilename();\r\n        \r\n        try\r\n        {\r\n            URL url = ClassHelper.getResource(filename);\r\n\r\n            if (url == null)\r\n            {\r\n                url = (new File(filename)).toURL();\r\n            }\r\n\r\n            logger.info(\"Loading OJB's properties: \" + url);\r\n\r\n            URLConnection conn = url.openConnection();\r\n            conn.setUseCaches(false);\r\n            conn.connect();\r\n            InputStream strIn = conn.getInputStream();\r\n            properties.load(strIn);\r\n            strIn.close();\r\n        }\r\n        catch (FileNotFoundException ex)\r\n        {\r\n            // [tomdz] If the filename is explicitly reset (null or empty string) then we'll\r\n            //         output an info message because the user did this on purpose\r\n            //         Otherwise, we'll output a warning\r\n            if ((filename == null) || (filename.length() == 0))\r\n            {\r\n                logger.info(\"Starting OJB without a properties file. OJB is using default settings instead.\");\r\n            }\r\n            else\r\n            {\r\n                logger.warn(\"Could not load properties file '\"+filename+\"'. Using default settings!\", ex);\r\n            }\r\n            // [tomdz] There seems to be no use of this setting ?\r\n            //properties.put(\"valid\", \"false\");\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            throw new MetadataException(\"An error happend while loading the properties file '\"+filename+\"'\", ex);\r\n        }\r\n    }", "label": 0}
{"code": "def find_object\n      if params.key?(:product_id)\n        @obj = find_product\n      elsif params.key?(:repository_id)\n        @obj = find_repository\n      else\n        fail HttpErrors::NotFound, N_(\"Couldn't find subject of synchronization\") if @obj.nil?\n      end\n      @obj\n    end", "label": 4}
{"code": "func (i *Handle) doSetConfigCmd(c *Config) error {\n\treq := newIPVSRequest(ipvsCmdSetConfig)\n\treq.Seq = atomic.AddUint32(&i.seq, 1)\n\n\treq.AddData(nl.NewRtAttr(ipvsCmdAttrTimeoutTCP, nl.Uint32Attr(uint32(c.TimeoutTCP.Seconds()))))\n\treq.AddData(nl.NewRtAttr(ipvsCmdAttrTimeoutTCPFin, nl.Uint32Attr(uint32(c.TimeoutTCPFin.Seconds()))))\n\treq.AddData(nl.NewRtAttr(ipvsCmdAttrTimeoutUDP, nl.Uint32Attr(uint32(c.TimeoutUDP.Seconds()))))\n\n\t_, err := execute(i.sock, req, 0)\n\n\treturn err\n}", "label": 5}
{"code": "function _gpfProcessAlias (method, url, data) {\n    if (typeof url === \"string\") {\n        return _gpfHttpRequest({\n            method: method,\n            url: url,\n            data: data\n        });\n    }\n    return _gpfHttpRequest(Object.assign({\n        method: method\n    }, url));\n}", "label": 3}
{"code": "protected int countedSize() throws PersistenceBrokerException\r\n    {\r\n        Query countQuery = getBroker().serviceBrokerHelper().getCountQuery(getQueryObject().getQuery());\r\n        ResultSetAndStatement rsStmt;\r\n        ClassDescriptor cld = getQueryObject().getClassDescriptor();\r\n        int count = 0;\r\n\r\n        // BRJ: do not use broker.getCount() because it's extent-aware\r\n        // the count we need here must not include extents !\r\n        if (countQuery instanceof QueryBySQL)\r\n        {\r\n            String countSql = ((QueryBySQL) countQuery).getSql();\r\n            rsStmt = getBroker().serviceJdbcAccess().executeSQL(countSql, cld, Query.NOT_SCROLLABLE);\r\n        }\r\n        else\r\n        {\r\n            rsStmt = getBroker().serviceJdbcAccess().executeQuery(countQuery, cld);\r\n        }\r\n\r\n        try\r\n        {\r\n            if (rsStmt.m_rs.next())\r\n            {\r\n                count = rsStmt.m_rs.getInt(1);\r\n            }\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            throw new PersistenceBrokerException(e);\r\n        }\r\n        finally\r\n        {\r\n            rsStmt.close();\r\n        }\r\n\r\n        return count;\r\n    }", "label": 0}
{"code": "public static base_response unset(nitro_service client, locationparameter resource, String[] args) throws Exception{\n\t\tlocationparameter unsetresource = new locationparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "func newSession(client *NodeClient,\n\tjoinSession *session.Session,\n\tenv map[string]string,\n\tstdin io.Reader,\n\tstdout io.Writer,\n\tstderr io.Writer) (*NodeSession, error) {\n\n\tif stdin == nil {\n\t\tstdin = os.Stdin\n\t}\n\tif stdout == nil {\n\t\tstdout = os.Stdout\n\t}\n\tif stderr == nil {\n\t\tstderr = os.Stderr\n\t}\n\tif env == nil {\n\t\tenv = make(map[string]string)\n\t}\n\n\tvar err error\n\tns := &NodeSession{\n\t\tenv:        env,\n\t\tnodeClient: client,\n\t\tstdin:      stdin,\n\t\tstdout:     stdout,\n\t\tstderr:     stderr,\n\t\tnamespace:  client.Namespace,\n\t\tcloser:     utils.NewCloseBroadcaster(),\n\t}\n\t// if we're joining an existing session, we need to assume that session's\n\t// existing/current terminal size:\n\tif joinSession != nil {\n\t\tns.id = joinSession.ID\n\t\tns.namespace = joinSession.Namespace\n\t\ttsize := joinSession.TerminalParams.Winsize()\n\t\tif ns.isTerminalAttached() {\n\t\t\terr = term.SetWinsize(0, tsize)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(err)\n\t\t\t}\n\t\t\tos.Stdout.Write([]byte(fmt.Sprintf(\"\\x1b[8;%d;%dt\", tsize.Height, tsize.Width)))\n\t\t}\n\t\t// new session!\n\t} else {\n\t\tsid, ok := ns.env[sshutils.SessionEnvVar]\n\t\tif !ok {\n\t\t\tsid = string(session.NewID())\n\t\t}\n\t\tns.id = session.ID(sid)\n\t}\n\tns.env[sshutils.SessionEnvVar] = string(ns.id)\n\treturn ns, nil\n}", "label": 5}
{"code": "def fix_fasta(fasta):\n    \"\"\"\n    remove pesky characters from fasta file header\n    \"\"\"\n    for seq in parse_fasta(fasta):\n        seq[0] = remove_char(seq[0])\n        if len(seq[1]) > 0:\n            yield seq", "label": 1}
{"code": "public static base_response enable(nitro_service client, String trapname) throws Exception {\n\t\tsnmpalarm enableresource = new snmpalarm();\n\t\tenableresource.trapname = trapname;\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "def ensure_server(data)\n      if @servers.include?(data['id'].to_i)\n        @servers[data['id'].to_i]\n      else\n        @servers[data['id'].to_i] = Server.new(data, self)\n      end\n    end", "label": 4}
{"code": "def main_from_xml(file)\n      xml_data = File.read(file)\n      xml_data.force_encoding('utf-8')\n\n      doc = Nokogiri::XML(xml_data)\n      doc.elements.first.elements.first\n    end", "label": 4}
{"code": "function relativePathArray(filePath, fromPath) {\n  filePath = path.normalize(filePath);\n  fromPath = path.normalize(fromPath);\n  if (filePath.indexOf(fromPath) === -1 || filePath === fromPath) {\n    // TODO Error handling: this should cause a warn\n    return [];\n  }\n  const keys = path.relative(fromPath, path.dirname(filePath));\n  if (keys && keys.length !== 0) {\n    return keys.split(path.sep);\n  }\n  return [];\n}", "label": 3}
{"code": "def fail!(message = nil)\n      run_callbacks :failure do\n        update(status: FAILURE, message: message)\n        parent&.rollup_status\n      end\n    end", "label": 4}
{"code": "func Unmarshal(data []byte, v interface{}) (err error) {\n\tbuf := bytes.NewBuffer(data)\n\te := Decoder{r: buf}\n\terr = e.Decode(v)\n\tif err == nil && buf.Len() != 0 {\n\t\terr = ErrUnusedTrailingBytes{buf.Len()}\n\t}\n\treturn\n}", "label": 5}
{"code": "def select_member_of_collection(collection)\n      find('#s2id_member_of_collection_ids').click\n      find('.select2-input').set(collection.title.first)\n      # Crude way of waiting for the AJAX response\n      select2_results = []\n      time_elapsed = 0\n      while select2_results.empty? && time_elapsed < 30\n        begin_time = Time.now.to_f\n        doc = Nokogiri::XML.parse(page.body)\n        select2_results = doc.xpath('//html:li[contains(@class,\"select2-result\")]', html: 'http://www.w3.org/1999/xhtml')\n        end_time = Time.now.to_f\n        time_elapsed += end_time - begin_time\n      end\n      expect(page).to have_css('.select2-result')\n      within \".select2-result\" do\n        find(\"span\", text: collection.title.first).click\n      end\n    end", "label": 4}
{"code": "private function executeDoneCallback($type, $response)\n    {\n        if (is_null($response)) {\n            return null;\n        }\n\n        $callables = array_filter($this->callablesMap, function ($callable) use ($type) {\n            return $callable['typeUrl'] === $type;\n        });\n\n        if (count($callables) === 0) {\n            return $response;\n        }\n\n        $callable = current($callables);\n        $fn = $callable['callable'];\n\n        return call_user_func($fn, $response);\n    }", "label": 2}
{"code": "def write_with_retry(session, write_concern, ending_transaction = false, &block)\n      if ending_transaction && !session\n        raise ArgumentError, 'Cannot end a transaction without a session'\n      end\n\n      unless ending_transaction || retry_write_allowed?(session, write_concern)\n        return legacy_write_with_retry(nil, session, &block)\n      end\n\n      # If we are here, session is not nil. A session being nil would have\n      # failed retry_write_allowed? check.\n\n      server = cluster.next_primary\n\n      unless ending_transaction || server.retry_writes?\n        return legacy_write_with_retry(server, session, &block)\n      end\n\n      begin\n        txn_num = session.in_transaction? ? session.txn_num : session.next_txn_num\n        yield(server, txn_num, false)\n      rescue Error::SocketError, Error::SocketTimeoutError => e\n        if session.in_transaction? && !ending_transaction\n          raise\n        end\n        retry_write(e, txn_num, &block)\n      rescue Error::OperationFailure => e\n        if (session.in_transaction? && !ending_transaction) || !e.write_retryable?\n          raise\n        end\n        retry_write(e, txn_num, &block)\n      end\n    end", "label": 4}
{"code": "function (sectionId, state) {\n        if (!module.exports.operations.validateState || module.exports.operations.validateState(state)) {\n            appState.set('state[' + sectionId + ']', state);\n        } else {\n            log.error('Unable to update invalid state:', state, 'in section:', sectionId);\n        }\n    }", "label": 3}
{"code": "function isTripleSlashComment(comment) {\n                // Verify this is /// comment, but do the regexp match only when we first can find /// in the comment text\n                // so that we don't end up computing comment string and doing match for all // comments\n                if (currentText.charCodeAt(comment.pos + 1) === 47 /* slash */ &&\n                    comment.pos + 2 < comment.end &&\n                    currentText.charCodeAt(comment.pos + 2) === 47 /* slash */) {\n                    var textSubStr = currentText.substring(comment.pos, comment.end);\n                    return textSubStr.match(ts.fullTripleSlashReferencePathRegEx) ||\n                        textSubStr.match(ts.fullTripleSlashAMDReferencePathRegEx) ?\n                        true : false;\n                }\n                return false;\n            }", "label": 3}
{"code": "def invoke_question(object, message, *args, &block)\n      options = Utils.extract_options!(args)\n      options[:messages] = self.class.messages\n      question = object.new(self, options)\n      question.(message, &block)\n    end", "label": 4}
{"code": "public static base_response Force(nitro_service client, hafailover resource) throws Exception {\n\t\thafailover Forceresource = new hafailover();\n\t\tForceresource.force = resource.force;\n\t\treturn Forceresource.perform_operation(client,\"Force\");\n\t}", "label": 0}
{"code": "def _plugin_constant\n      @_plugin_constant ||= Guard.constants.detect do |c|\n        c.to_s.casecmp(_constant_name.downcase).zero?\n      end\n    end", "label": 4}
{"code": "def save_record(self, agent_id, t_step, key, value):\n        '''\n        Save a collection of records to the database.\n        Database writes are cached.\n        '''\n        value = self.convert(key, value)\n        self._tups.append(Record(agent_id=agent_id,\n                                 t_step=t_step,\n                                 key=key,\n                                 value=value))\n        if len(self._tups) > 100:\n            self.flush_cache()", "label": 1}
{"code": "func (l VirtualDeviceList) CreateSerialPort() (*types.VirtualSerialPort, error) {\n\tdevice := &types.VirtualSerialPort{\n\t\tYieldOnPoll: true,\n\t}\n\n\tc := l.PickController((*types.VirtualSIOController)(nil))\n\tif c == nil {\n\t\treturn nil, errors.New(\"no available SIO controller\")\n\t}\n\n\tl.AssignController(device, c)\n\n\tl.setDefaultSerialPortBacking(device)\n\n\treturn device, nil\n}", "label": 5}
{"code": "def sort_input(input, property, order)\n      input.map { |item| [item_property(item, property), item] }\n        .sort! do |a_info, b_info|\n          a_property = a_info.first\n          b_property = b_info.first\n\n          if !a_property.nil? && b_property.nil?\n            - order\n          elsif a_property.nil? && !b_property.nil?\n            + order\n          else\n            a_property <=> b_property || a_property.to_s <=> b_property.to_s\n          end\n        end\n        .map!(&:last)\n    end", "label": 4}
{"code": "public function setSourceLocation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Logging\\V2\\LogEntrySourceLocation::class);\n        $this->source_location = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def packed=(packed, update_perms = true)\n      update_role_data(permissions: packed)\n      @permissions.bits = packed if update_perms\n    end", "label": 4}
{"code": "func (g *GLogger) Warningln(args ...interface{}) {\n\tg.Entry.Warning(fmt.Sprintln(args...))\n}", "label": 5}
{"code": "func NewServer(parallelTotal int) (*Server, error) {\n\tlistener, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &Server{\n\t\tlistener:        listener,\n\t\tlock:            &sync.Mutex{},\n\t\talives:          make([]func() bool, parallelTotal),\n\t\tbeforeSuiteData: types.RemoteBeforeSuiteData{Data: nil, State: types.RemoteBeforeSuiteStatePending},\n\t\tparallelTotal:   parallelTotal,\n\t}, nil\n}", "label": 5}
{"code": "public boolean isLabelAnnotationIntroducingCharacter(char ch) {\r\n    char[] cutChars = labelAnnotationIntroducingCharacters();\r\n    for (char cutChar : cutChars) {\r\n      if (ch == cutChar) {\r\n        return true;\r\n      }\r\n    }\r\n    return false;\r\n  }", "label": 0}
{"code": "function statusLog(file, data, time) {\n  var msg = '';\n  var diff = (process.hrtime(time)[1] / 1000000000).toFixed(2);\n  var adapters = Object.keys(data._adapterData).join(', ');\n\n  msg += format('Supercollider: processed %s in %s', chalk.cyan(file), chalk.magenta(diff + ' s'));\n\n  if (adapters.length) {\n    msg += format(' with %s', chalk.yellow(adapters));\n  }\n\n  log(msg);\n}", "label": 3}
{"code": "def execute(*)\n      file, line, = caller.first.split(\":\")\n      colors = SSHKit::Color.new($stderr)\n      $stderr.puts colors.colorize(\"Warning: `execute' should be wrapped in an `on' scope in #{file}:#{line}.\", :red)\n      $stderr.puts\n      $stderr.puts \"  task :example do\"\n      $stderr.puts colors.colorize(\"    on roles(:app) do\", :yellow)\n      $stderr.puts \"      execute 'whoami'\"\n      $stderr.puts colors.colorize(\"    end\", :yellow)\n      $stderr.puts \"  end\"\n      $stderr.puts\n      raise NoMethodError, \"undefined method `execute' for main:Object\"\n    end", "label": 4}
{"code": "def each\n      body_parts = self.body.respond_to?(:each) ? self.body : [self.body]\n      return body_parts.to_enum unless block_given?\n      body_parts.each { |part| yield(part) }\n    end", "label": 4}
{"code": "def find_weighted_server(records)\n      return nil if records.nil? || records.empty?\n      return records.first if records.size == 1\n\n      # Calculate the sum of all weights in the list of resource records,\n      # This is used to then select hosts until the weight exceeds what\n      # random number we selected.  For example, if we have weights of 1 8 and 3:\n      #\n      # |-|--------|---|\n      #        ^\n      # We generate a random number 5, and iterate through the records, adding\n      # the current record's weight to the accumulator until the weight of the\n      # current record plus previous records is greater than the random number.\n      total_weight = records.inject(0) { |sum,record|\n        sum + weight(record)\n      }\n      current_weight = 0\n      chosen_weight  = 1 + Kernel.rand(total_weight)\n\n      records.each do |record|\n        current_weight += weight(record)\n        return record if current_weight >= chosen_weight\n      end\n    end", "label": 4}
{"code": "public function scanFiles(int $threads = 1)\n    {\n        $has_changes = $this->scanner->scanFiles($this->classlikes, $threads);\n\n        if ($has_changes) {\n            $this->populator->populateCodebase($this);\n        }\n    }", "label": 2}
{"code": "def run\n      Byebug.mode = :standalone\n\n      option_parser.order!($ARGV)\n      return if non_script_option? || error_in_script?\n\n      $PROGRAM_NAME = program\n\n      Byebug.run_init_script if init_script\n\n      loop do\n        debug_program\n\n        break if quit\n\n        ControlProcessor.new(nil, interface).process_commands\n      end\n    end", "label": 4}
{"code": "func DjangoSessionsBySessionKey(db XODB, sessionKey string) ([]*DjangoSession, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`session_key, session_data, expire_date ` +\n\t\t`FROM public.django_session ` +\n\t\t`WHERE session_key = $1`\n\n\t// run query\n\tXOLog(sqlstr, sessionKey)\n\tq, err := db.Query(sqlstr, sessionKey)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*DjangoSession{}\n\tfor q.Next() {\n\t\tds := DjangoSession{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&ds.SessionKey, &ds.SessionData, &ds.ExpireDate)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ds)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def draw(*argv) #:doc:\n        open_tempfile do |file|\n          instrument :preview, key: blob.key do\n            capture(*argv, to: file)\n          end\n\n          yield file\n        end\n      end", "label": 4}
{"code": "func (f *File) DisplayPath() string {\n\tfip := f.FileInfo().Path\n\tif len(fip) == 0 {\n\t\treturn f.t.info.Name\n\t}\n\treturn strings.Join(fip, \"/\")\n\n}", "label": 5}
{"code": "private void appendJoinSQL92NoParen(Join join, StringBuffer where, StringBuffer buf)\r\n    {\r\n        if (join.isOuter)\r\n        {\r\n            buf.append(\" LEFT OUTER JOIN \");\r\n        }\r\n        else\r\n        {\r\n            buf.append(\" INNER JOIN \");\r\n        }\r\n\r\n        buf.append(join.right.getTableAndAlias());\r\n        buf.append(\" ON \");\r\n        join.appendJoinEqualities(buf);\r\n\r\n        appendTableWithJoins(join.right, where, buf);\r\n    }", "label": 0}
{"code": "function (scales, chord) {\n  // Exclude scales with a particular interval\n  var exclude = function (int) {\n    scales = _.filter(scales, function (scale) {\n      return !scale.hasInterval(int);\n    });\n  };\n\n  // Add a scale at a particular index\n  var include = function (index, scaleId) {\n    scales.splice(index, 0, scale.create(chord.root, scaleId));\n  };\n\n  if (_.includes(['m', 'm6', 'm7', 'm9', 'm11', 'm13'], chord.formattedSymbol)) {\n    exclude('M3');\n  }\n  if (_.includes(['7', '9', '11', '13', 'm7', 'm9', 'm11', 'm13'], chord.formattedSymbol)) {\n    exclude('M7');\n  }\n  if (_.includes(['M7', 'M9', 'M11', 'M13'], chord.formattedSymbol)) {\n    exclude('m7');\n  }\n  if (chord.formattedSymbol[0] === '6' || chord.formattedSymbol.slice(0, 2) === 'M6') {\n    exclude('m7');\n  }\n\n  if (_.includes(['7', '7#9', '7+9', '7#11', '7+11'], chord.formattedSymbol)) {\n    include(2, 'blues');\n  }\n\n  return scales;\n}", "label": 3}
{"code": "public function setSorrowLikelihood($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Vision\\V1\\Likelihood::class);\n        $this->sorrow_likelihood = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_responses delete(nitro_service client, appfwconfidfield resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwconfidfield deleteresources[] = new appfwconfidfield[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tdeleteresources[i] = new appfwconfidfield();\n\t\t\t\tdeleteresources[i].fieldname = resources[i].fieldname;\n\t\t\t\tdeleteresources[i].url = resources[i].url;\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function (account) {\n\t// check if DB is initialized\n\tif (typeof l_accounts === 'undefined') {\n\t\tLOG.error('DB module is not loaded, please enable DB module', l_name);\n\t\treturn false;\n\t}\n\n\tif (l_accounts.hasOwnProperty(account) === false) {\n\t\tLOG.error('[' + account + '] not found', l_name);\n\t\treturn false;\n\t}\n\n\treturn true;\n}", "label": 3}
{"code": "func (tc *TeleportClient) ssoLogin(ctx context.Context, connectorID string, pub []byte, protocol string) (*auth.SSHLoginResponse, error) {\n\tlog.Debugf(\"samlLogin start\")\n\t// ask the CA (via proxy) to sign our public key:\n\tresponse, err := tc.credClient.SSHAgentSSOLogin(SSHLogin{\n\t\tContext:       ctx,\n\t\tConnectorID:   connectorID,\n\t\tPubKey:        pub,\n\t\tTTL:           tc.KeyTTL,\n\t\tProtocol:      protocol,\n\t\tCompatibility: tc.CertificateFormat,\n\t\tBindAddr:      tc.BindAddr,\n\t})\n\treturn response, trace.Wrap(err)\n}", "label": 5}
{"code": "function ReadableParallel(list, iterator, callback)\n{\n  if (!(this instanceof ReadableParallel))\n  {\n    return new ReadableParallel(list, iterator, callback);\n  }\n\n  // turn on object mode\n  ReadableParallel.super_.call(this, {objectMode: true});\n\n  this._start(parallel, list, iterator, callback);\n}", "label": 3}
{"code": "public function addStream(string $streamName, $extra = null): self\n    {\n        $this->nextStreams[] = [$streamName, $extra];\n        $this->key = count($this->nextStreams) - 1;\n\n        return $this;\n    }", "label": 2}
{"code": "func (t *terminal) Run() error {\n\tdefer t.closeTTY()\n\n\tcmd, err := prepareInteractiveCommand(t.ctx)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tt.cmd = cmd\n\n\tcmd.Stdout = t.tty\n\tcmd.Stdin = t.tty\n\tcmd.Stderr = t.tty\n\tcmd.SysProcAttr.Setctty = true\n\tcmd.SysProcAttr.Setsid = true\n\n\terr = cmd.Start()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public void removeFile(String name) {\n        if(files.containsKey(name)) {\n            files.remove(name);\n        }\n\n        if(fileStreams.containsKey(name)) {\n            fileStreams.remove(name);\n        }\n    }", "label": 0}
{"code": "function augmentMap(bemNode, map) {\n    const name = bemNode.block;\n\n    if (map[name]) {\n        assert(typeof map[name] === 'string', `options.map: new name of ${name} must be string`);\n        bemNode.block = map[name];\n    }\n\n    return bemNode;\n}", "label": 3}
{"code": "public static lbmonitor_metric_binding[] get(nitro_service service, String monitorname) throws Exception{\n\t\tlbmonitor_metric_binding obj = new lbmonitor_metric_binding();\n\t\tobj.set_monitorname(monitorname);\n\t\tlbmonitor_metric_binding response[] = (lbmonitor_metric_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func PgTsConfigByOid(db XODB, oid pgtypes.Oid) (*PgTsConfig, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, cfgname, cfgnamespace, cfgowner, cfgparser ` +\n\t\t`FROM pg_catalog.pg_ts_config ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tptc := PgTsConfig{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&ptc.Tableoid, &ptc.Cmax, &ptc.Xmax, &ptc.Cmin, &ptc.Xmin, &ptc.Oid, &ptc.Ctid, &ptc.Cfgname, &ptc.Cfgnamespace, &ptc.Cfgowner, &ptc.Cfgparser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ptc, nil\n}", "label": 5}
{"code": "func New(ctx context.Context, params backend.Params) (*LiteBackend, error) {\n\tvar cfg *Config\n\terr := utils.ObjectToStruct(params, &cfg)\n\tif err != nil {\n\t\treturn nil, trace.BadParameter(\"SQLite configuration is invalid: %v\", err)\n\t}\n\treturn NewWithConfig(ctx, *cfg)\n}", "label": 5}
{"code": "public function setGroup($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Monitoring\\V3\\Group::class);\n        $this->group = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public Headers getAllHeaders() {\n        Headers requestHeaders = getHeaders();\n        requestHeaders = hasPayload() ? requestHeaders.withContentType(getPayload().get().getMimeType()) : requestHeaders;\n        //We don't want to add headers more than once.\n        return requestHeaders;\n    }", "label": 0}
{"code": "def run_pileup(job, tumor_bam, univ_options, somaticsniper_options):\n    \"\"\"\n    Runs a samtools pileup on the tumor bam.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict somaticsniper_options: Options specific to SomaticSniper\n    :return: fsID for the pileup file\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'tumor.bam': tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n        'tumor.bam.bai': tumor_bam['tumor_dna_fix_pg_sorted.bam.bai'],\n        'genome.fa.tar.gz': somaticsniper_options['genome_fasta'],\n        'genome.fa.fai.tar.gz': somaticsniper_options['genome_fai']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n\n    for key in ('genome.fa', 'genome.fa.fai'):\n        input_files[key] = untargz(input_files[key + '.tar.gz'], work_dir)\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    parameters = ['pileup',\n                  '-cvi',\n                  '-f', docker_path(input_files['genome.fa']),\n                  docker_path(input_files['tumor.bam'])]\n\n    with open(os.path.join(work_dir, 'pileup.txt'), 'w') as pileup_file:\n        docker_call(tool='samtools', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=pileup_file,\n                    tool_version=somaticsniper_options['samtools']['version'])\n    outfile = job.fileStore.writeGlobalFile(pileup_file.name)\n    job.fileStore.logToMaster('Ran samtools pileup on %s successfully' % univ_options['patient'])\n    return outfile", "label": 1}
{"code": "def bindings\n      results = Hash.new { |hash, key| hash[key] = [] }\n      api_client.bindings.each do |binding|\n        next if binding['destination'] == binding['routing_key']\n        next unless binding['source'] == @config[:mq_exchange]\n        next unless binding['vhost'] == @config[:mq_vhost]\n        results[binding['destination']] << binding['routing_key']\n      end\n      results\n    end", "label": 4}
{"code": "def has_liquid_construct?(content)\n      return false if content.nil? || content.empty?\n\n      content.include?(\"{%\") || content.include?(\"{{\")\n    end", "label": 4}
{"code": "public static vpnvserver_responderpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_responderpolicy_binding obj = new vpnvserver_responderpolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_responderpolicy_binding response[] = (vpnvserver_responderpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function read($id)\n    {\n        $this->openSessionId = $id;\n        // PHP expects an empty string to be returned from this method if no\n        // data is retrieved\n        $this->dataRead = '';\n\n        // Get session data using the selected locking strategy\n        $item = $this->connection->read($this->formatId($id));\n\n        // Return the data if it is not expired. If it is expired, remove it\n        if (isset($item['expires']) && isset($item['data'])) {\n            $this->dataRead = $item['data'];\n            if ($item['expires'] <= time()) {\n                $this->dataRead = '';\n                $this->destroy($id);\n            }\n        }\n\n        return $this->dataRead;\n    }", "label": 2}
{"code": "def get_case6ww():\n    \"\"\" Returns the 6 bus case from Wood & Wollenberg PG&C.\n    \"\"\"\n    path = os.path.dirname(pylon.__file__)\n    path = os.path.join(path, \"test\", \"data\")\n    path = os.path.join(path, \"case6ww\", \"case6ww.pkl\")\n\n    case = pylon.Case.load(path)\n    case.generators[0].p_cost = (0.0, 4.0, 200.0)\n    case.generators[1].p_cost = (0.0, 3.0, 200.0)\n\n#    case.generators[0].p_cost = (0.0, 5.1, 200.0) # 10%\n#    case.generators[1].p_cost = (0.0, 4.5, 200.0) # 30%\n\n    case.generators[2].p_cost = (0.0, 6.0, 200.0) # passive\n\n#    case.generators[0].c_shutdown = 100.0\n#    case.generators[1].c_shutdown = 100.0\n#    case.generators[2].c_shutdown = 100.0\n\n    case.generators[0].p_min = 0.0 # TODO: Unit-decommitment.\n    case.generators[1].p_min = 0.0\n    case.generators[2].p_min = 0.0\n\n    case.generators[0].p_max = 110.0\n    case.generators[1].p_max = 110.0\n    case.generators[2].p_max = 220.0 # passive\n\n    # FIXME: Correct generator naming order.\n    for g in case.generators:\n        g.name\n\n    #pyreto.util.plotGenCost(case.generators)\n\n    return case", "label": 1}
{"code": "def expired? connection\n    return true  if     @max_requests && connection.requests >= @max_requests\n    return false unless @idle_timeout\n    return true  if     @idle_timeout.zero?\n\n    Time.now - connection.last_use > @idle_timeout\n  end", "label": 4}
{"code": "public static base_response unset(nitro_service client, onlinkipv6prefix resource, String[] args) throws Exception{\n\t\tonlinkipv6prefix unsetresource = new onlinkipv6prefix();\n\t\tunsetresource.ipv6prefix = resource.ipv6prefix;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def update_fields(fields)\n      attributes[:action_id]          = fields['id'] || attributes[:action_id]\n      attributes[:text]               = fields['data']['text'] || attributes[:text]\n      attributes[:date]               = Time.iso8601(fields['date']) if fields.has_key?('date')\n      attributes[:member_creator_id]  = fields['idMemberCreator'] || attributes[:member_creator_id]\n      self\n    end", "label": 4}
{"code": "def update_many(filter, update, options = {})\n      find(filter, options).update_many(update, options)\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, inatparam resource) throws Exception {\n\t\tinatparam updateresource = new inatparam();\n\t\tupdateresource.nat46v6prefix = resource.nat46v6prefix;\n\t\tupdateresource.nat46ignoretos = resource.nat46ignoretos;\n\t\tupdateresource.nat46zerochecksum = resource.nat46zerochecksum;\n\t\tupdateresource.nat46v6mtu = resource.nat46v6mtu;\n\t\tupdateresource.nat46fragheader = resource.nat46fragheader;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def gen_sub_directories\n        super\n        File.makedirs(MODULE_DIR)\n        File.makedirs(NODE_DIR)\n        File.makedirs(PLUGIN_DIR)\n    rescue\n        $stderr.puts $ERROR_INFO.message\n        exit 1\n    end", "label": 4}
{"code": "function updateRules(rulesToUpdate, cb) {\n    function updateRule(ruleDetails, cb1) {\n      var id = ruleDetails._id;\n\n      rulesModel.findOne({_id: id}, function(err, ruleToUpdate) {\n        if (err) {\n          return cb1(err);\n        }\n\n        if (ruleToUpdate === null && !options.createIfNotFound) {\n          return cb1(new Error(\"No \" + ruleType + \" rule matches id \" + id));\n        } else if (ruleToUpdate === null && options.createIfNotFound) {\n          ruleToUpdate = new rulesModel(ruleDetails);\n        }\n\n        for (var saveKey in ruleDetails) { // eslint-disable-line guard-for-in\n          ruleToUpdate[saveKey] = ruleDetails[saveKey];\n        }\n\n        ruleToUpdate.save(cb1);\n      });\n    }\n\n    async.map(rulesToUpdate, updateRule, cb);\n  }", "label": 3}
{"code": "func (t *Torrent) PieceStateRuns() []PieceStateRun {\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\treturn t.pieceStateRuns()\n}", "label": 5}
{"code": "private function getDefaultLock()\n    {\n        if ($this->isSysvIPCLoaded()) {\n            return new SemaphoreLock(\n                $this->getSysvKey(crc32($this->cacheKey))\n            );\n        }\n\n        return new FlockLock($this->cacheKey);\n    }", "label": 2}
{"code": "func ParseRoles(str string) (roles Roles, err error) {\n\tfor _, s := range strings.Split(str, \",\") {\n\t\tr := Role(strings.Title(strings.ToLower(strings.TrimSpace(s))))\n\t\tif err = r.Check(); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\troles = append(roles, r)\n\t}\n\treturn roles, nil\n}", "label": 5}
{"code": "public static RgbaColor fromHsl(float H, float S, float L) {\n\n        // convert to [0-1]\n        H /= 360f;\n        S /= 100f;\n        L /= 100f;\n\n        float R, G, B;\n\n        if (S == 0) {\n            // grey\n            R = G = B = L;\n        }\n        else {\n            float m2 = L <= 0.5 ? L * (S + 1f) : L + S - L * S;\n            float m1 = 2f * L - m2;\n            R = hue2rgb(m1, m2, H + 1 / 3f);\n            G = hue2rgb(m1, m2, H);\n            B = hue2rgb(m1, m2, H - 1 / 3f);\n        }\n\n        // convert [0-1] to [0-255]\n        int r = Math.round(R * 255f);\n        int g = Math.round(G * 255f);\n        int b = Math.round(B * 255f);\n\n        return new RgbaColor(r, g, b, 1);\n    }", "label": 0}
{"code": "public function setGatewayConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Iot\\V1\\GatewayConfig::class);\n        $this->gateway_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *Client) UpsertNode(s services.Server) (*services.KeepAlive, error) {\n\tif s.GetNamespace() == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing node namespace\")\n\t}\n\tprotoServer, ok := s.(*services.ServerV2)\n\tif !ok {\n\t\treturn nil, trace.BadParameter(\"unsupported client\")\n\t}\n\tclt, err := c.grpc()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tkeepAlive, err := clt.UpsertNode(context.TODO(), protoServer)\n\tif err != nil {\n\t\treturn nil, trail.FromGRPC(err)\n\t}\n\treturn keepAlive, nil\n}", "label": 5}
{"code": "def iter_doc_filepaths(self, **kwargs):\n        \"\"\"Generator that iterates over all detected documents.\n        and returns the filesystem path to each doc.\n        Order is by shard, but arbitrary within shards.\n        @TEMP not locked to prevent doc creation/deletion\n        \"\"\"\n        for shard in self._shards:\n            for doc_id, blob in shard.iter_doc_filepaths(**kwargs):\n                yield doc_id, blob", "label": 1}
{"code": "public function register_early_invoke( $when, $command ) {\n\t\t$this->early_invoke[ $when ][] = array_slice( Dispatcher\\get_path( $command ), 1 );\n\t}", "label": 2}
{"code": "function(cov){\n        cov = window._$blanket;\n\n        var sortedFileNames = [];\n\n        var totals =[];\n\n        for (var filename in cov) {\n            if (cov.hasOwnProperty(filename)) {\n                sortedFileNames.push(filename);\n            }\n        }\n\n        sortedFileNames.sort();\n\n        for (var i = 0; i < sortedFileNames.length; i++) {\n            var thisFile = sortedFileNames[i];\n            var data = cov[thisFile];\n            var thisTotal= reportFile( data );\n            sendMessage(\"blanket:fileDone\", thisTotal, thisFile);\n        }\n\n        sendMessage(\"blanket:done\");\n\n    }", "label": 3}
{"code": "public void afterCompletion(int status)\r\n    {\r\n        if(afterCompletionCall) return;\r\n\r\n        log.info(\"Method afterCompletion was called\");\r\n        try\r\n        {\r\n            switch(status)\r\n            {\r\n                case Status.STATUS_COMMITTED:\r\n                    if(log.isDebugEnabled())\r\n                    {\r\n                        log.debug(\"Method afterCompletion: Do commit internal odmg-tx, status of JTA-tx is \" + TxUtil.getStatusString(status));\r\n                    }\r\n                    commit();\r\n                    break;\r\n                default:\r\n                    log.error(\"Method afterCompletion: Do abort call on internal odmg-tx, status of JTA-tx is \" + TxUtil.getStatusString(status));\r\n                    abort();\r\n            }\r\n        }\r\n        finally\r\n        {\r\n            afterCompletionCall = true;\r\n            log.info(\"Method afterCompletion finished\");\r\n        }\r\n    }", "label": 0}
{"code": "func (ta *TextArea) Init() {\n\tta.once.Do(func() {\n\t\tlm := &linesModel{lines: []string{}, width: 0}\n\t\tta.model = lm\n\t\tta.CellView.Init()\n\t\tta.CellView.SetModel(lm)\n\t})\n}", "label": 5}
{"code": "func ParseKey(k []byte) (Key, error) {\n\tkey, err := hex.DecodeString(string(k))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn Key(key), nil\n}", "label": 5}
{"code": "function () {\n            var chart = this.series.chart,\n              hoverPoints = chart.hoverPoints;\n\n            this.firePointEvent('mouseOut');\n\n            if (!hoverPoints || inArray(this, hoverPoints) === -1) { // #887, #2240\n                this.setState();\n                chart.hoverPoint = null;\n            }\n        }", "label": 3}
{"code": "public function executeUpdate($sql, array $options = [])\n    {\n        $options['seqno'] = $this->seqno;\n        $this->seqno++;\n\n        return $this->operation\n            ->executeUpdate($this->session, $this, $sql, $options);\n    }", "label": 2}
{"code": "function accepts(func, validator, message) {\n\tmessage = messageBuilder(message || 'vet/utils/accepts error!');\n\n\treturn function wrapper(){\n\t\tvar args = arguments;\n\t\tif (validator.apply(this, args)) {\n\t\t\treturn func.apply(this, args);\n\t\t} else {\n\t\t\tthrow new Error(message.apply(this, args));\n\t\t}\n\t};\n}", "label": 3}
{"code": "func (d *Decoder) raiseUnknownValueType(b byte, offset int64) {\n\tpanic(&SyntaxError{\n\t\tOffset: offset,\n\t\tWhat:   fmt.Errorf(\"unknown value type %+q\", b),\n\t})\n}", "label": 5}
{"code": "function init() {\n    var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    dayStartsAt = options.dayStartsAt || DEFAULT_DAY_STARTS_AT;\n    nightStartsAt = options.nightStartsAt || DEFAULT_NIGHT_STARTS_AT;\n  }", "label": 3}
{"code": "def serialize_relations(attributes = {}, options = {})\n      inclusions = options[:include]\n      relation_names(inclusions).each do |name|\n        association = relations[name.to_s]\n        if association && relation = send(association.name)\n          attributes[association.name.to_s] =\n            relation.serializable_hash(relation_options(inclusions, options, name))\n        end\n      end\n    end", "label": 4}
{"code": "def extract_child_criteria\n      @entry.xpath(\"./*/cda:outboundRelationship[@typeCode='COMP']/cda:criteriaReference/cda:id\",\n                   HQMF2::Document::NAMESPACES).collect do |ref|\n        Reference.new(ref).id\n      end.compact\n    end", "label": 4}
{"code": "def set_frame\n      frames = @animations[@playing_animation]\n      case frames\n      when Range\n        reset_clipping_rect\n        @clip_x = @current_frame * @clip_width\n      when Array\n        f = frames[@current_frame]\n        @clip_x      = f[:x]      || @defaults[:clip_x]\n        @clip_y      = f[:y]      || @defaults[:clip_y]\n        @clip_width  = f[:width]  || @defaults[:clip_width]\n        @clip_height = f[:height] || @defaults[:clip_height]\n        @frame_time  = f[:time]   || @defaults[:frame_time]\n      end\n    end", "label": 4}
{"code": "function setFormatting(outNode, profile) {\n\tconst node = outNode.node;\n\n\tif (shouldFormatNode(node, profile)) {\n\t\toutNode.indent = profile.indent(getIndentLevel(node, profile));\n\t\toutNode.newline = '\\n';\n\t\tconst prefix = outNode.newline + outNode.indent;\n\n\t\t// do not format the very first node in output\n\t\tif (!isRoot(node.parent) || !isFirstChild(node)) {\n\t\t\toutNode.beforeOpen = prefix;\n\t\t\tif (node.isTextOnly) {\n\t\t\t\toutNode.beforeText = prefix;\n\t\t\t}\n\t\t}\n\n\t\tif (hasInnerFormatting(node, profile)) {\n\t\t\tif (!node.isTextOnly) {\n\t\t\t\toutNode.beforeText = prefix + profile.indent(1);\n\t\t\t}\n\t\t\toutNode.beforeClose = prefix;\n\t\t}\n\t}\n\n\treturn outNode;\n}", "label": 3}
{"code": "async function main() {\n  // Initialize the application.\n  process.title = 'Which.js';\n\n  // Parse the command line arguments.\n  program.name('which')\n    .description('Find the instances of an executable in the system path.')\n    .version(packageVersion, '-v, --version')\n    .option('-a, --all', 'list all instances of executables found (instead of just the first one)')\n    .option('-s, --silent', 'silence the output, just return the exit code (0 if any executable is found, otherwise 1)')\n    .arguments('<command>').action(command => program.executable = command)\n    .parse(process.argv);\n\n  if (!program.executable) {\n    program.outputHelp();\n    process.exitCode = 64;\n    return;\n  }\n\n  // Run the program.\n  let executables = await which(program.executable, {all: program.all});\n  if (!program.silent) {\n    if (!Array.isArray(executables)) executables = [executables];\n    for (const path of executables) console.log(path);\n  }\n}", "label": 3}
{"code": "def include_depositor_facet(solr_parameters)\n      solr_parameters[:\"facet.field\"].concat([DepositSearchBuilder.depositor_field])\n\n      # default facet limit is 10, which will only show the top 10 users.\n      # As we want to show all user deposits, so set the facet.limit to the\n      # the number of users in the database\n      solr_parameters[:\"facet.limit\"] = ::User.count\n\n      # we only want the facte counts not the actual data\n      solr_parameters[:rows] = 0\n    end", "label": 4}
{"code": "private void setObjectForStatement(PreparedStatement stmt, int index, Object value, int sqlType)\r\n            throws SQLException\r\n    {\r\n        if (value == null)\r\n        {\r\n            m_platform.setNullForStatement(stmt, index, sqlType);\r\n        }\r\n        else\r\n        {\r\n            m_platform.setObjectForStatement(stmt, index, value, sqlType);\r\n        }\r\n    }", "label": 0}
{"code": "func PgDefaultACLByOid(db XODB, oid pgtypes.Oid) (*PgDefaultACL, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, defaclrole, defaclnamespace, defaclobjtype, defaclacl ` +\n\t\t`FROM pg_catalog.pg_default_acl ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpda := PgDefaultACL{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pda.Tableoid, &pda.Cmax, &pda.Xmax, &pda.Cmin, &pda.Xmin, &pda.Oid, &pda.Ctid, &pda.Defaclrole, &pda.Defaclnamespace, &pda.Defaclobjtype, &pda.Defaclacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pda, nil\n}", "label": 5}
{"code": "public static ComplexNumber Multiply(ComplexNumber z1, ComplexNumber z2) {\r\n        double z1R = z1.real, z1I = z1.imaginary;\r\n        double z2R = z2.real, z2I = z2.imaginary;\r\n\r\n        return new ComplexNumber(z1R * z2R - z1I * z2I, z1R * z2I + z1I * z2R);\r\n    }", "label": 0}
{"code": "func (r RoleMap) String() string {\n\tvalues, err := r.parse()\n\tif err != nil {\n\t\treturn fmt.Sprintf(\"<failed to parse: %v\", err)\n\t}\n\tif len(values) != 0 {\n\t\treturn fmt.Sprintf(\"%v\", values)\n\t}\n\treturn \"<empty>\"\n}", "label": 5}
{"code": "function defaultStrategy(projectDir, builder, cb)\n{\n  const pkg = fs.realpathSync(INSTALLER_PACKAGE);\n  builder.buildFromPackage(pkg, projectDir, cb);\n}", "label": 3}
{"code": "protected ManageableCollection createCollection(CollectionDescriptor desc, Class collectionClass)\r\n    {\r\n        Class                fieldType = desc.getPersistentField().getType();\r\n        ManageableCollection col;\r\n\r\n        if (collectionClass == null)\r\n        {\r\n            if (ManageableCollection.class.isAssignableFrom(fieldType))\r\n            {\r\n                try\r\n                {\r\n                    col = (ManageableCollection)fieldType.newInstance();\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    throw new OJBRuntimeException(\"Cannot instantiate the default collection type \"+fieldType.getName()+\" of collection \"+desc.getAttributeName()+\" in type \"+desc.getClassDescriptor().getClassNameOfObject());\r\n                }\r\n            }\r\n            else if (fieldType.isAssignableFrom(RemovalAwareCollection.class))\r\n            {\r\n                col = new RemovalAwareCollection();\r\n            }\r\n            else if (fieldType.isAssignableFrom(RemovalAwareList.class))\r\n            {\r\n                col = new RemovalAwareList();\r\n            }\r\n            else if (fieldType.isAssignableFrom(RemovalAwareSet.class))\r\n            {\r\n                col = new RemovalAwareSet();\r\n            }\r\n            else\r\n            {\r\n                throw new MetadataException(\"Cannot determine a default collection type for collection \"+desc.getAttributeName()+\" in type \"+desc.getClassDescriptor().getClassNameOfObject());\r\n            }\r\n        }\r\n        else\r\n        {\r\n            try\r\n            {\r\n                col = (ManageableCollection)collectionClass.newInstance();\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                throw new OJBRuntimeException(\"Cannot instantiate the collection class \"+collectionClass.getName()+\" of collection \"+desc.getAttributeName()+\" in type \"+desc.getClassDescriptor().getClassNameOfObject());\r\n            }\r\n        }\r\n        return col;\r\n    }", "label": 0}
{"code": "def connect_cloudfront(self):\n        \"Connect to Cloud Front. This is done automatically for you when needed.\"\n        self.conn_cloudfront = connect_cloudfront(self.AWS_ACCESS_KEY_ID, self.AWS_SECRET_ACCESS_KEY, debug=self.S3UTILS_DEBUG_LEVEL)", "label": 1}
{"code": "function npmLoad(context, pkg){\n\tvar task = new FetchTask(context, pkg);\n\n\treturn task.load().then(function(){\n\t\tif(task.failed) {\n\t\t\t// Recurse. Calling task.next gives us a new pkg object\n\t\t\t// with the fileUrl being the parent node_modules folder.\n\t\t\treturn npmLoad(context, task.next());\n\t\t}\n\t\treturn task.getPackage();\n\t});\n}", "label": 3}
{"code": "public String getURN() throws InvalidRegistrationContentException {\n        if (parsedConfig==null || parsedConfig.urn==null || parsedConfig.urn.trim().isEmpty()) {\n            throw new InvalidRegistrationContentException(\"Invalid registration config - failed to read mediator URN\");\n        }\n        return parsedConfig.urn;\n    }", "label": 0}
{"code": "def list(*args)\n      arguments(args)\n\n      response = get_request(\"/gitignore/templates\", arguments.params)\n      return response unless block_given?\n      response.each { |el| yield el }\n    end", "label": 4}
{"code": "public function setReadConsistency($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Datastore\\V1\\ReadOptions_ReadConsistency::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static Map<String, List<String>> getResponseHeaders(String stringUrl) throws IOException {\n    return getResponseHeaders(stringUrl, true);\n  }", "label": 0}
{"code": "public static base_response unset(nitro_service client, aaapreauthenticationparameter resource, String[] args) throws Exception{\n\t\taaapreauthenticationparameter unsetresource = new aaapreauthenticationparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "func NewChain(name string, table Table, hairpinMode bool) (*ChainInfo, error) {\n\tc := &ChainInfo{\n\t\tName:        name,\n\t\tTable:       table,\n\t\tHairpinMode: hairpinMode,\n\t}\n\tif string(c.Table) == \"\" {\n\t\tc.Table = Filter\n\t}\n\n\t// Add chain if it doesn't exist\n\tif _, err := Raw(\"-t\", string(c.Table), \"-n\", \"-L\", c.Name); err != nil {\n\t\tif output, err := Raw(\"-t\", string(c.Table), \"-N\", c.Name); err != nil {\n\t\t\treturn nil, err\n\t\t} else if len(output) != 0 {\n\t\t\treturn nil, fmt.Errorf(\"Could not create %s/%s chain: %s\", c.Table, c.Name, output)\n\t\t}\n\t}\n\treturn c, nil\n}", "label": 5}
{"code": "def handle_retry_after(response)\n      retry_after = response['Retry-After']\n      return response if retry_after.nil?\n\n      retry_sleep = parse_retry_after_header(retry_after)\n      # Recover remote hostname if Net::HTTPResponse was generated by a\n      # method that fills in the uri attribute.\n      #\n      server_hostname = if response.uri.is_a?(URI)\n                          response.uri.host\n                        else\n                          # TRANSLATORS: Used in the phrase:\n                          # \"Received a response from the remote server.\"\n                          _('the remote server')\n                        end\n\n      if retry_sleep.nil?\n        Puppet.err(_('Received a %{status_code} response from %{server_hostname}, but the Retry-After header value of \"%{retry_after}\" could not be converted to an integer or RFC 2822 date.') %\n                   {status_code: response.code,\n                    server_hostname: server_hostname,\n                    retry_after: retry_after.inspect})\n\n        return response\n      end\n\n      # Cap maximum sleep at the run interval of the Puppet agent.\n      retry_sleep = [retry_sleep, Puppet[:runinterval]].min\n\n      Puppet.warning(_('Received a %{status_code} response from %{server_hostname}. Sleeping for %{retry_sleep} seconds before retrying the request.') %\n                     {status_code: response.code,\n                      server_hostname: server_hostname,\n                      retry_sleep: retry_sleep})\n\n      ::Kernel.sleep(retry_sleep)\n\n      return nil\n    end", "label": 4}
{"code": "function isSafeString(str) {\n      var escape = ['&amp;', '&lt;', '&gt;', '&quot;', '&#x27;', '&#96;'];\n      if (typeof str !== \"string\" || (escape.some(function(specialChar) {\n        return str.indexOf(specialChar) >= 0;\n      }))) {\n        return true;\n      }\n    }", "label": 3}
{"code": "private String generateAbbreviatedExceptionMessage(final Throwable throwable) {\n\n\t\tfinal StringBuilder builder = new StringBuilder();\n\t\tbuilder.append(\": \");\n\t\tbuilder.append(throwable.getClass().getCanonicalName());\n\t\tbuilder.append(\": \");\n\t\tbuilder.append(throwable.getMessage());\n\n\t\tThrowable cause = throwable.getCause();\n\t\twhile (cause != null) {\n\t\t\tbuilder.append('\\n');\n\t\t\tbuilder.append(\"Caused by: \");\n\t\t\tbuilder.append(cause.getClass().getCanonicalName());\n\t\t\tbuilder.append(\": \");\n\t\t\tbuilder.append(cause.getMessage());\n\t\t\t// make sure the exception cause is not itself to prevent infinite\n\t\t\t// looping\n\t\t\tassert (cause != cause.getCause());\n\t\t\tcause = (cause == cause.getCause() ? null : cause.getCause());\n\t\t}\n\t\treturn builder.toString();\n\t}", "label": 0}
{"code": "func (d Datastore) ServiceTicket(ctx context.Context, path string, method string) (*url.URL, *http.Cookie, error) {\n\tu := d.NewURL(path)\n\n\thost, ok := ctx.Value(datastoreServiceTicketHostKey{}).(*HostSystem)\n\n\tif !ok {\n\t\tif !d.useServiceTicket() {\n\t\t\treturn u, nil, nil\n\t\t}\n\n\t\thosts, err := d.AttachedHosts(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\n\t\tif len(hosts) == 0 {\n\t\t\t// Fallback to letting vCenter choose a host\n\t\t\treturn u, nil, nil\n\t\t}\n\n\t\t// Pick a random attached host\n\t\thost = hosts[rand.Intn(len(hosts))]\n\t}\n\n\tips, err := host.ManagementIPs(ctx)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tif len(ips) > 0 {\n\t\t// prefer a ManagementIP\n\t\tu.Host = ips[0].String()\n\t} else {\n\t\t// fallback to inventory name\n\t\tu.Host, err = host.ObjectName(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\n\t// VC datacenter path will not be valid against ESX\n\tq := u.Query()\n\tdelete(q, \"dcPath\")\n\tu.RawQuery = q.Encode()\n\n\tspec := types.SessionManagerHttpServiceRequestSpec{\n\t\tUrl: u.String(),\n\t\t// See SessionManagerHttpServiceRequestSpecMethod enum\n\t\tMethod: fmt.Sprintf(\"http%s%s\", method[0:1], strings.ToLower(method[1:])),\n\t}\n\n\tsm := session.NewManager(d.Client())\n\n\tticket, err := sm.AcquireGenericServiceTicket(ctx, &spec)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tcookie := &http.Cookie{\n\t\tName:  \"vmware_cgi_ticket\",\n\t\tValue: ticket.Id,\n\t}\n\n\tif d.useServiceTicketHostName(ticket.HostName) {\n\t\tu.Host = ticket.HostName\n\t}\n\n\td.Client().SetThumbprint(u.Host, ticket.SslThumbprint)\n\n\treturn u, cookie, nil\n}", "label": 5}
{"code": "function IntercomError(message, errors) {\n  AbstractError.apply(this, arguments);\n  this.name = 'IntercomError';\n  this.message = message;\n  this.errors = errors;\n}", "label": 3}
{"code": "def _update_raster_info(self, **update_props):\n        \"\"\" Derives multiple dimensions from a single raster_info complex struct \"\"\"\n\n        tree_to_update = update_props['tree_to_update']\n        prop = update_props['prop']\n        values = update_props.pop('values')\n\n        # Update number of dimensions at raster_info root (applies to all dimensions below)\n\n        xroot, xpath = None, self._data_map['_ri_num_dims']\n        raster_info = [update_property(tree_to_update, xroot, xpath, prop, values.get('dimensions', u''))]\n\n        # Derive vertical, longitude, and latitude dimensions from raster_info\n\n        xpath_root = self._get_xroot_for(prop)\n        xpath_map = self._data_structures[prop]\n\n        v_dimension = {}\n        if values.get('vertical_count'):\n            v_dimension = v_dimension.fromkeys(xpath_map, u'')\n            v_dimension['type'] = 'vertical'\n            v_dimension['size'] = values.get('vertical_count', u'')\n\n        x_dimension = {}\n        if values.get('column_count') or values.get('x_resolution'):\n            x_dimension = x_dimension.fromkeys(xpath_map, u'')\n            x_dimension['type'] = 'column'\n            x_dimension['size'] = values.get('column_count', u'')\n            x_dimension['value'] = values.get('x_resolution', u'')\n\n        y_dimension = {}\n        if values.get('row_count') or values.get('y_resolution'):\n            y_dimension = y_dimension.fromkeys(xpath_map, u'')\n            y_dimension['type'] = 'row'\n            y_dimension['size'] = values.get('row_count', u'')\n            y_dimension['value'] = values.get('y_resolution', u'')\n\n        # Update derived dimensions as complex list, and append affected elements for return\n\n        update_props['prop'] = RASTER_DIMS\n        update_props['values'] = [v_dimension, x_dimension, y_dimension]\n\n        raster_info += update_complex_list(xpath_root=xpath_root, xpath_map=xpath_map, **update_props)\n\n        return raster_info", "label": 1}
{"code": "public function add($name, $type)\n    {\n        $invalidIntTypes = [\n            Database::TYPE_STRUCT,\n            Database::TYPE_ARRAY\n        ];\n\n        if (is_int($type) && in_array($type, $invalidIntTypes)) {\n            throw new \\InvalidArgumentException(\n                '`Database::TYPE_ARRAY` and `Database::TYPE_STRUCT` are not valid as struct types. ' .\n                'Instead provide `Google\\Cloud\\Spanner\\ArrayType` or `Google\\Cloud\\Spanner\\StructType`.'\n            );\n        }\n\n        $child = null;\n        if ($type instanceof StructType) {\n            $child = $type;\n            $type = Database::TYPE_STRUCT;\n        } elseif ($type instanceof ArrayType) {\n            $child = $type;\n            $type = Database::TYPE_ARRAY;\n        }\n\n        if (!in_array($type, ValueMapper::$allowedTypes)) {\n            throw new \\InvalidArgumentException(sprintf(\n                'Field type `%s` is not valid.',\n                $type\n            ));\n        }\n\n        $this->fields[] = [\n            'name' => $name,\n            'type' => $type,\n            'child' => $child\n        ];\n\n        return $this;\n    }", "label": 2}
{"code": "public static function evalKeys(CommandInterface $command, $prefix)\n    {\n        if ($arguments = $command->getArguments()) {\n            for ($i = 2; $i < $arguments[1] + 2; ++$i) {\n                $arguments[$i] = \"$prefix{$arguments[$i]}\";\n            }\n\n            $command->setRawArguments($arguments);\n        }\n    }", "label": 2}
{"code": "public static function make($var)\n    {\n        if ($var instanceof DateTimeInterface) {\n            return static::instance($var);\n        }\n\n        $date = null;\n\n        if (is_string($var)) {\n            $var = trim($var);\n            $first = substr($var, 0, 1);\n\n            if (is_string($var) && $first !== 'P' && $first !== 'R' && preg_match('/[a-z0-9]/i', $var)) {\n                $date = static::parse($var);\n            }\n        }\n\n        return $date;\n    }", "label": 2}
{"code": "function add(position) {\n    var tuple = compile(position)\n\n    if (tuple) {\n      positions.push(tuple[0])\n\n      if (tuple[1]) {\n        offsets.push(tuple[1])\n      }\n    }\n  }", "label": 3}
{"code": "def subscribe(*topics)\n      # Create topic partition list with topics and no partition set\n      tpl = TopicPartitionList.new_native_tpl(topics.length)\n\n      topics.each do |topic|\n        Rdkafka::Bindings.rd_kafka_topic_partition_list_add(\n          tpl,\n          topic,\n          -1\n        )\n      end\n      # Subscribe to topic partition list and check this was successful\n      response = Rdkafka::Bindings.rd_kafka_subscribe(@native_kafka, tpl)\n      if response != 0\n        raise Rdkafka::RdkafkaError.new(response, \"Error subscribing to '#{topics.join(', ')}'\")\n      end\n    end", "label": 4}
{"code": "def _voltage_angle_diff_limit(self, buses, branches):\n        \"\"\" Returns the constraint on the branch voltage angle differences.\n        \"\"\"\n        nb = len(buses)\n\n        if not self.ignore_ang_lim:\n            iang = [i for i, b in enumerate(branches)\n                    if (b.ang_min and (b.ang_min > -360.0))\n                    or (b.ang_max and (b.ang_max < 360.0))]\n            iangl = array([i for i, b in enumerate(branches)\n                     if b.ang_min is not None])[iang]\n            iangh = array([i for i, b in enumerate(branches)\n                           if b.ang_max is not None])[iang]\n            nang = len(iang)\n\n            if nang > 0:\n                ii = range(nang) + range(nang)\n                jjf = array([b.from_bus._i for b in branches])[iang]\n                jjt = array([b.to_bus._i for b in branches])[iang]\n                jj = r_[jjf, jjt]\n                Aang = csr_matrix(r_[ones(nang), -ones(nang)], (ii, jj))\n                uang = Inf * ones(nang)\n                lang = -uang\n                lang[iangl] = array([b.ang_min * (pi / 180.0)\n                                    for b in branches])[iangl]\n                uang[iangh] = array([b.ang_max * (pi / 180.0)\n                                    for b in branches])[iangh]\n            else:\n#                Aang = csr_matrix((0, nb), dtype=float64)\n#                lang = array([], dtype=float64)\n#                uang = array([], dtype=float64)\n                Aang = zeros((0, nb))\n                lang = array([])\n                uang = array([])\n        else:\n#            Aang = csr_matrix((0, nb), dtype=float64)\n#            lang = array([], dtype=float64)\n#            uang = array([], dtype=float64)\n#            iang = array([], dtype=float64)\n            Aang = zeros((0, nb))\n            lang = array([])\n            uang = array([])\n\n        return LinearConstraint(\"ang\", Aang, lang, uang, [\"Va\"])", "label": 1}
{"code": "public function getUri($uri) {\n        $curieSeperator = ':';\n\n        if (preg_match('/http(s*)\\:\\/\\//', $uri) == false) {\n            if (strpos($uri, $curieSeperator) !== false) {\n                list($prefix, $action) = explode($curieSeperator, $uri);\n                \n                if(isset($this->WAMP->prefixes[$prefix]) === true){\n                  return $this->WAMP->prefixes[$prefix] . '#' . $action;\n                }\n            }\n        }\n\n        return $uri;\n    }", "label": 2}
{"code": "def spread_money(money: Money, spread_p: Decimal) -> Tuple[Money, Money]:\n    \"\"\"Returns a lower and upper money amount separated by a spread percentage\"\"\"\n    upper, lower = spread_value(money.amount, spread_p)\n    return Money(upper, money.currency), Money(lower, money.currency)", "label": 1}
{"code": "function generate(targetPath, args) {\n  if (\n    !args.template &&\n    (!args.templateFile || (args.templateFile && !vio.fileExists(args.templateFile)))\n  ) {\n    const err = new Error(`No template file found: ${args.templateFile}`);\n    err.code = 'TEMPLATE_FILE_NOT_FOUND';\n    throw err;\n  }\n  const tpl = args.template || vio.getContent(args.templateFile);\n  const compiled = _.template(tpl, args.templateOptions || {});\n  const result = compiled(args.context || {});\n\n  vio.save(targetPath, result);\n}", "label": 3}
{"code": "def double_prefix_allowed?(data, phone, parsed = {})\n      data[Core::DOUBLE_COUNTRY_PREFIX_FLAG] &&\n        phone =~ cr(\"^#{data[Core::COUNTRY_CODE]}\") &&\n        parsed && (parsed[:valid].nil? || parsed[:valid].empty?) &&\n        !original_starts_with_plus?\n    end", "label": 4}
{"code": "def generate_package(params):\n    \"\"\"Generate package repository.\n\n    :param argparse.Namespace params: parameters\n    \"\"\"\n    pkg_data = package.PackageData(params)\n    pkg_tree = package.PackageTree(pkg_data)\n    pkg_tree.generate()\n    pkg_tree.move()\n    VCS(os.path.join(pkg_tree.outdir, pkg_tree.name), pkg_tree.pkg_data)", "label": 1}
{"code": "public function commit($database, $writes, array $optionalArgs = [])\n    {\n        $request = new CommitRequest();\n        $request->setDatabase($database);\n        $request->setWrites($writes);\n        if (isset($optionalArgs['transaction'])) {\n            $request->setTransaction($optionalArgs['transaction']);\n        }\n\n        $requestParams = new RequestParamsHeaderDescriptor([\n          'database' => $request->getDatabase(),\n        ]);\n        $optionalArgs['headers'] = isset($optionalArgs['headers'])\n            ? array_merge($requestParams->getHeader(), $optionalArgs['headers'])\n            : $requestParams->getHeader();\n\n        return $this->startCall(\n            'Commit',\n            CommitResponse::class,\n            $optionalArgs,\n            $request\n        )->wait();\n    }", "label": 2}
{"code": "def send_shared_login_request(user, password)\n      # Check if we have a cached/valid session\n      #\n      # Background:\n      # December 4th 2017 Apple introduced a rate limit - which is of course fine by itself -\n      # but unfortunately also rate limits successful logins. If you call multiple tools in a\n      # lane (e.g. call match 5 times), this would lock you out of the account for a while.\n      # By loading existing sessions and checking if they're valid, we're sending less login requests.\n      # More context on why this change was necessary https://github.com/fastlane/fastlane/pull/11108\n      #\n      # If there was a successful manual login before, we have a session on disk\n      if load_session_from_file\n        # Check if the session is still valid here\n        begin\n          # We use the olympus session to determine if the old session is still valid\n          # As this will raise an exception if the old session has expired\n          # If the old session is still valid, we don't have to do anything else in this method\n          # that's why we return true\n          return true if fetch_olympus_session\n        rescue\n          # If the `fetch_olympus_session` method raises an exception\n          # we'll land here, and therefore continue doing a full login process\n          # This happens if the session we loaded from the cache isn't valid any more\n          # which is common, as the session automatically invalidates after x hours (we don't know x)\n          # In this case we don't actually care about the exact exception, and why it was failing\n          # because either way, we'll have to do a fresh login, where we do the actual error handling\n          puts(\"Available session is not valid any more. Continuing with normal login.\")\n        end\n      end\n      #\n      # The user can pass the session via environment variable (Mainly used in CI environments)\n      if load_session_from_env\n        # see above\n        begin\n          # see above\n          return true if fetch_olympus_session\n        rescue\n          puts(\"Session loaded from environment variable is not valid. Continuing with normal login.\")\n          # see above\n        end\n      end\n      #\n      # After this point, we sure have no valid session any more and have to create a new one\n      #\n\n      data = {\n        accountName: user,\n        password: password,\n        rememberMe: true\n      }\n\n      begin\n        # The below workaround is only needed for 2 step verified machines\n        # Due to escaping of cookie values we have a little workaround here\n        # By default the cookie jar would generate the following header\n        #   DES5c148...=HSARM.......xaA/O69Ws/CHfQ==SRVT\n        # However we need the following\n        #   DES5c148...=\"HSARM.......xaA/O69Ws/CHfQ==SRVT\"\n        # There is no way to get the cookie jar value with \" around the value\n        # so we manually modify the cookie (only this one) to be properly escaped\n        # Afterwards we pass this value manually as a header\n        # It's not enough to just modify @cookie, it needs to be done after self.cookie\n        # as a string operation\n        important_cookie = @cookie.store.entries.find { |a| a.name.include?(\"DES\") }\n        if important_cookie\n          modified_cookie = self.cookie # returns a string of all cookies\n          unescaped_important_cookie = \"#{important_cookie.name}=#{important_cookie.value}\"\n          escaped_important_cookie = \"#{important_cookie.name}=\\\"#{important_cookie.value}\\\"\"\n          modified_cookie.gsub!(unescaped_important_cookie, escaped_important_cookie)\n        end\n\n        response = request(:post) do |req|\n          req.url(\"https://idmsa.apple.com/appleauth/auth/signin\")\n          req.body = data.to_json\n          req.headers['Content-Type'] = 'application/json'\n          req.headers['X-Requested-With'] = 'XMLHttpRequest'\n          req.headers['X-Apple-Widget-Key'] = self.itc_service_key\n          req.headers['Accept'] = 'application/json, text/javascript'\n          req.headers[\"Cookie\"] = modified_cookie if modified_cookie\n        end\n      rescue UnauthorizedAccessError\n        raise InvalidUserCredentialsError.new, \"Invalid username and password combination. Used '#{user}' as the username.\"\n      end\n\n      # Now we know if the login is successful or if we need to do 2 factor\n\n      case response.status\n      when 403\n        raise InvalidUserCredentialsError.new, \"Invalid username and password combination. Used '#{user}' as the username.\"\n      when 200\n        fetch_olympus_session\n        return response\n      when 409\n        # 2 step/factor is enabled for this account, first handle that\n        handle_two_step_or_factor(response)\n        # and then get the olympus session\n        fetch_olympus_session\n        return true\n      else\n        if (response.body || \"\").include?('invalid=\"true\"')\n          # User Credentials are wrong\n          raise InvalidUserCredentialsError.new, \"Invalid username and password combination. Used '#{user}' as the username.\"\n        elsif response.status == 412 && AUTH_TYPES.include?(response.body[\"authType\"])\n          # Need to acknowledge Apple ID and Privacy statement - https://github.com/fastlane/fastlane/issues/12577\n          # Looking for status of 412 might be enough but might be safer to keep looking only at what is being reported\n          raise AppleIDAndPrivacyAcknowledgementNeeded.new, \"Need to acknowledge to Apple's Apple ID and Privacy statement. Please manually log into https://appleid.apple.com (or https://appstoreconnect.apple.com) to acknowledge the statement.\"\n        elsif (response['Set-Cookie'] || \"\").include?(\"itctx\")\n          raise \"Looks like your Apple ID is not enabled for App Store Connect, make sure to be able to login online\"\n        else\n          info = [response.body, response['Set-Cookie']]\n          raise Tunes::Error.new, info.join(\"\\n\")\n        end\n      end\n    end", "label": 4}
{"code": "function getName () {\n    const pathname = url.parse(parts[parts.length - 1]).pathname;\n\n    return pathname ? pathname.replace('/', '') : pathname;\n  }", "label": 3}
{"code": "function _loadEntityMethod(func, name) {\n    expect(_attributes).to.not.have.ownProperty(\n      name,\n      'failed to load entity method \"' + name + '\" because there is an ' +\n      'attribute with same name in the current Entity and it cannot be ' +\n      'overloaded'\n    );\n\n    if (_Entity.General) {\n      expect(_Entity.General.attributes).to.not.have.ownProperty(\n        name,\n        'failed to load entity method \"' + name + '\" because there is an ' +\n        'attribute with same name in a parent of current Entity and it ' +\n        'cannot be overriden'\n      );\n    }\n\n    var entitySpecializations = _Entity.specializations;\n    for (var specialization in entitySpecializations) {\n      expect(entitySpecializations[specialization].specification.attributes)\n        .to.not.have.ownProperty(\n        name,\n        'failed to load entity method \"' + name + '\" because there is an ' +\n        'attribute with same name in a child of current Entity'\n      );\n    }\n\n    _Entity.prototype[name] = func;\n  }", "label": 3}
{"code": "public function setPredicateFilter($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\RowFilter::class);\n        $this->predicate_filter = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static vpnglobal_authenticationsamlpolicy_binding[] get(nitro_service service) throws Exception{\n\t\tvpnglobal_authenticationsamlpolicy_binding obj = new vpnglobal_authenticationsamlpolicy_binding();\n\t\tvpnglobal_authenticationsamlpolicy_binding response[] = (vpnglobal_authenticationsamlpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getColor (i) {\n    i = parseInt(i);\n    if (i < 0 || i >= colors.length) {\n      // pick a color from the scale defined above\n      return scale(((i - colors.length) * (211 / 971)) % 1);\n    } else {\n      return chroma(colors[i]);\n    }\n  }", "label": 3}
{"code": "func (s *sequence) fromByteArray(data []byte) error {\n\tl := len(data)\n\tif l%12 != 0 {\n\t\treturn fmt.Errorf(\"cannot deserialize byte sequence of length %d (%v)\", l, data)\n\t}\n\n\tp := s\n\ti := 0\n\tfor {\n\t\tp.block = binary.BigEndian.Uint32(data[i : i+4])\n\t\tp.count = binary.BigEndian.Uint64(data[i+4 : i+12])\n\t\ti += 12\n\t\tif i == l {\n\t\t\tbreak\n\t\t}\n\t\tp.next = &sequence{}\n\t\tp = p.next\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def print_KruskalWallisH(div_calc):\n    \"\"\"\n    Compute the Kruskal-Wallis H-test for independent samples. A typical rule is that\n    each group must have at least 5 measurements.\n    \"\"\"\n    calc = defaultdict(list)\n    try:\n        for k1, v1 in div_calc.iteritems():\n            for k2, v2 in v1.iteritems():\n                calc[k1].append(v2)\n    except:\n        return \"Error setting up input arrays for Kruskal-Wallis H-Test. Skipping \"\\\n               \"significance testing.\"\n    h, p = stats.kruskal(*calc.values())\n    print \"\\nKruskal-Wallis H-test statistic for {} groups: {}\".format(str(len(div_calc)), h)\n    print \"p-value: {}\".format(p)", "label": 1}
{"code": "public static int[][] toInt(double[][] array) {\n        int[][] n = new int[array.length][array[0].length];\n        for (int i = 0; i < array.length; i++) {\n            for (int j = 0; j < array[0].length; j++) {\n                n[i][j] = (int) array[i][j];\n            }\n        }\n        return n;\n    }", "label": 0}
{"code": "def parse_checkM_tables(tables):\n    \"\"\"\n    convert checkM genome info tables to dictionary\n    \"\"\"\n    g2info = {}\n    for table in tables:\n        for line in open(table):\n            line = line.strip().split('\\t')\n            if line[0].startswith('Bin Id'):\n                header = line\n                header[8] = 'genome size (bp)'\n                header[5] = '#SCGs'\n                header[6] = '#SCG duplicates'\n                continue\n            ID, info = line[0], line\n            info = [to_int(i) for i in info]\n            ID = ID.replace(' ', '')\n            g2info[ID] = {item:stat for item, stat in zip(header, info)}\n            if g2info[ID]['genome size (bp)'] == '':\n                g2info[ID]['genome size (bp)'] = 0\n    return g2info", "label": 1}
{"code": "func (c *Manager) UpdateTag(ctx context.Context, tag *Tag) error {\n\tspec := struct {\n\t\tTag Tag `json:\"update_spec\"`\n\t}{\n\t\tTag: Tag{\n\t\t\tName:        tag.Name,\n\t\t\tDescription: tag.Description,\n\t\t},\n\t}\n\turl := internal.URL(c, internal.TagPath).WithID(tag.ID)\n\treturn c.Do(ctx, url.Request(http.MethodPatch, spec), nil)\n}", "label": 5}
{"code": "function (preconditions) {\n        var errorCodesList = {\n            \"500\": [\"InternalServerError\"],\n            \"400\": [\n                \"UnexpectedDefaultValue\",\n                \"UnexpectedType\",\n                \"MinLengthUnderachieved\",\n                \"MaxLengthExceeded\",\n                \"MinValueUnderachived\",\n                \"MaxValueExceeded\",\n                \"ValueNotAllowed\",\n                \"PatternMismatch\",\n                \"MissingRequiredParameter\"],\n            \"429\": [\"RateLimitExceeded\"],\n        };\n        for (var index in preconditions) {\n            if (preconditions[index].conditions && preconditions[index].conditions.responses) {\n                for (var code in preconditions[index].conditions.responses) {\n                    if (errorCodesList[code]) {\n                        if (_.isArray(preconditions[index].conditions.responses[code])) {\n                            for (var ecode in preconditions[index].conditions.responses[code]) {\n                                if (_.indexOf(errorCodesList[code], preconditions[index].conditions.responses[code][ecode]) == -1) {\n                                    errorCodesList[code].push(preconditions[index].conditions.responses[code][ecode]);\n                                }\n                            }\n                        }\n                        else {\n                            if (_.indexOf(errorCodesList[code], preconditions[index].conditions.responses[code]) == -1) {\n                                errorCodesList[code].push(preconditions[index].conditions.responses[code]);\n                            }\n                        }\n                    }\n                    else {\n                        if (_.isArray(preconditions[index].conditions.responses[code])) {\n                            errorCodesList[code] = _.clone(preconditions[index].conditions.responses[code]);\n                        }\n                        else {\n                            errorCodesList[code] = [_.clone(preconditions[index].conditions.responses[code])];\n                        }\n                    }\n                }\n            }\n        }\n        return errorCodesList;\n    }", "label": 3}
{"code": "func (ca *CertAuthorityV2) Check() error {\n\terr := ca.ID().Check()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = ca.Checkers()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = ca.Signers()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t// This is to force users to migrate\n\tif len(ca.Spec.Roles) != 0 && len(ca.Spec.RoleMap) != 0 {\n\t\treturn trace.BadParameter(\"should set either 'roles' or 'role_map', not both\")\n\t}\n\tif err := RoleMap(ca.Spec.RoleMap).Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function setTimestampRangeFilter($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\TimestampRange::class);\n        $this->writeOneof(8, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function languages(array $options = [])\n    {\n        $response = $this->localizedLanguages($options + ['target' => null]);\n\n        return array_map(function ($language) {\n            return $language['code'];\n        }, $response);\n    }", "label": 2}
{"code": "func makeFontEncoding(encList encListType, refEncFileStr string) (diffStr string, err error) {\n\tvar refList encListType\n\tif refList, err = loadMap(refEncFileStr); err != nil {\n\t\treturn\n\t}\n\tvar buf fmtBuffer\n\tlast := 0\n\tfor j := 32; j < 256; j++ {\n\t\tif encList[j].name != refList[j].name {\n\t\t\tif j != last+1 {\n\t\t\t\tbuf.printf(\"%d \", j)\n\t\t\t}\n\t\t\tlast = j\n\t\t\tbuf.printf(\"/%s \", encList[j].name)\n\t\t}\n\t}\n\tdiffStr = strings.TrimSpace(buf.String())\n\treturn\n}", "label": 5}
{"code": "function connectHandlers (decorator, event) {\n    const handlers = Metadata.getClassMeta(Object.getPrototypeOf(self), decorator, Object.create(null));\n    for (const f of Object.keys(handlers)) {\n      ravelInstance.once(event, (...args) => {\n        ravelInstance.$log.trace(`${name}: Invoking ${decorator} ${f}`);\n        handlers[f].apply(self, args);\n      });\n    }\n  }", "label": 3}
{"code": "def fetch_commit(commit_id)\n      found = commits.find do |commit|\n        commit[\"sha\"] == commit_id\n      end\n      if found\n        stringify_keys_deep(found.to_hash)\n      else\n        # cache miss; don't add to @commits because unsure of order.\n        check_github_response do\n          commit = @client.commit(user_project, commit_id)\n          commit = stringify_keys_deep(commit.to_hash)\n          commit\n        end\n      end\n    end", "label": 4}
{"code": "function(tokenService, domainPrefix) {\n  var tokenUrl = tokenService.replace(/\\{DOMAIN_PREFIX\\}/, domainPrefix);\n  log.debug('token Url: '+ tokenUrl);\n  return tokenUrl;\n}", "label": 3}
{"code": "func (l *Forwarder) Close() error {\n\tl.Lock()\n\tdefer l.Unlock()\n\tif l.isClosed {\n\t\treturn nil\n\t}\n\tl.isClosed = true\n\treturn l.sessionLogger.Finalize()\n}", "label": 5}
{"code": "public function show_usage() {\n\t\t$methods = $this->get_subcommands();\n\n\t\t$i = 0;\n\n\t\tforeach ( $methods as $name => $subcommand ) {\n\t\t\t$prefix = ( 0 === $i ) ? 'usage: ' : '   or: ';\n\t\t\t$i++;\n\n\t\t\tif ( \\WP_CLI::get_runner()->is_command_disabled( $subcommand ) ) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t\\WP_CLI::line( $subcommand->get_usage( $prefix ) );\n\t\t}\n\n\t\t$cmd_name = implode( ' ', array_slice( get_path( $this ), 1 ) );\n\n\t\t\\WP_CLI::line();\n\t\t\\WP_CLI::line( \"See 'wp help $cmd_name <command>' for more information on a specific command.\" );\n\t}", "label": 2}
{"code": "func (a *Api) Register(container *restful.Container) {\n\tws := new(restful.WebService)\n\tws.Path(\"/api/v1/metric-export\").\n\t\tDoc(\"Exports the latest point for all Heapster metrics\").\n\t\tProduces(restful.MIME_JSON)\n\tws.Route(ws.GET(\"\").\n\t\tTo(a.exportMetrics).\n\t\tDoc(\"export the latest data point for all metrics\").\n\t\tOperation(\"exportMetrics\").\n\t\tWrites([]*types.Timeseries{}))\n\tcontainer.Add(ws)\n\tws = new(restful.WebService)\n\tws.Path(\"/api/v1/metric-export-schema\").\n\t\tDoc(\"Schema for metrics exported by heapster\").\n\t\tProduces(restful.MIME_JSON)\n\tws.Route(ws.GET(\"\").\n\t\tTo(a.exportMetricsSchema).\n\t\tDoc(\"export the schema for all metrics\").\n\t\tOperation(\"exportmetricsSchema\").\n\t\tWrites(types.TimeseriesSchema{}))\n\tcontainer.Add(ws)\n\n\tif a.metricSink != nil {\n\t\ta.RegisterModel(container)\n\t}\n\n\tif a.historicalSource != nil {\n\t\ta.RegisterHistorical(container)\n\t}\n}", "label": 5}
{"code": "function toNLCST(tree, file, Parser, options) {\n  var settings = options || {}\n  var parser\n\n  // Warn for invalid parameters.\n  if (!tree || !tree.type) {\n    throw new Error('mdast-util-to-nlcst expected node')\n  }\n\n  if (!file || !file.messages) {\n    throw new Error('mdast-util-to-nlcst expected file')\n  }\n\n  // Construct parser.\n  if (!Parser) {\n    throw new Error('mdast-util-to-nlcst expected parser')\n  }\n\n  if (\n    !tree.position ||\n    !tree.position.start ||\n    !tree.position.start.column ||\n    !tree.position.start.line\n  ) {\n    throw new Error('mdast-util-to-nlcst expected position on nodes')\n  }\n\n  parser = 'parse' in Parser ? Parser : new Parser()\n\n  // Transform mdast into NLCST tokens, and pass these into `parser.parse` to\n  // insert sentences, paragraphs where needed.\n  return parser.parse(\n    one(\n      {\n        doc: String(file),\n        location: vfileLocation(file),\n        parser: parser,\n        ignore: ignore.concat(settings.ignore || []),\n        source: source.concat(settings.source || [])\n      },\n      tree\n    )\n  )\n}", "label": 3}
{"code": "public void addDependency(final Dependency dependency) {\n        if(dependency != null && !dependencies.contains(dependency)){\n            this.dependencies.add(dependency);\n        }\n    }", "label": 0}
{"code": "function FieldReference(typeFunction, fieldOptions = {}) {\n    return function (target, key) {\n        let fieldType = Reflect.getMetadata(\"design:type\", target, key);\n        let schema = MongoSchemaRegistry_1.MongoSchemaRegistry.getSchema(target.constructor.name);\n        if (!schema) {\n            schema = new MongoSchema_1.MongoSchema(target.constructor);\n            MongoSchemaRegistry_1.MongoSchemaRegistry.register(target.constructor.name, schema);\n        }\n        if (!typeFunction) {\n            typeFunction = type => {\n                return fieldOptions.type || Reflect.getMetadata(\"design:type\", target, key).name;\n            };\n        }\n        fieldOptions.foreignField = fieldOptions.foreignField || \"_id\";\n        if (!fieldType || fieldType.name != \"Array\") {\n            fieldOptions.relationType = MongoSchema_1.ERelationType.SingleObjectId;\n        }\n        if (fieldType && fieldType.name == \"Array\") {\n            fieldOptions.relationType = MongoSchema_1.ERelationType.ArrayObjectId;\n        }\n        schema.addField(key, typeFunction, fieldOptions);\n    };\n}", "label": 3}
{"code": "public function url($path = null)\n    {\n        $config = $this->make('flarum.config');\n        $url = array_get($config, 'url', array_get($_SERVER, 'REQUEST_URI'));\n\n        if (is_array($url)) {\n            if (isset($url[$path])) {\n                return $url[$path];\n            }\n\n            $url = $url['base'];\n        }\n\n        if ($path) {\n            $url .= '/'.array_get($config, \"paths.$path\", $path);\n        }\n\n        return $url;\n    }", "label": 2}
{"code": "def parse_text_to_dict(self, txt):\n        \"\"\" \n        takes a string and parses via NLP, ready for mapping\n        \"\"\"\n        op = {}\n        print('TODO - import NLP, split into verbs / nouns')\n        op['nouns'] = txt\n        op['verbs'] = txt\n        \n        return op", "label": 1}
{"code": "function (args, result, func, extra) {\n\t\treturn new SR.promise(function (resolve, reject) {\n\t\t\tUTIL.safeCall(func, args, result, function () {\n\t\t\t\tUTIL.safeCall(resolve);\n\t\t\t}, extra);\n\t\t});\n\t}", "label": 3}
{"code": "def method_missing(name, *args, &block)\n      #:nodoc:\n      # Only take the structured fields, as we could take _anything_ really\n      # as it could become an optional field... \"but therin lies the dark side\"\n      field_name = Utilities.underscoreize(name).chomp(\"=\")\n      if Mail::Field::KNOWN_FIELDS.include?(field_name)\n        if args.empty?\n          header[field_name]\n        else\n          header[field_name] = args.first\n        end\n      else\n        super # otherwise pass it on\n      end\n      #:startdoc:\n    end", "label": 4}
{"code": "def copy_from_csv_sql(qualified_name: str, delimiter=',', encoding='utf8',\n                      null_str='', header=True, escape_str='\\\\', quote_char='\"',\n                      force_not_null=None, force_null=None):\n    \"\"\"Generate copy from csv statement.\"\"\"\n\n    options = []\n    options.append(\"DELIMITER '%s'\" % delimiter)\n    options.append(\"NULL '%s'\" % null_str)\n\n    if header:\n        options.append('HEADER')\n\n    options.append(\"QUOTE '%s'\" % quote_char)\n    options.append(\"ESCAPE '%s'\" % escape_str)\n\n    if force_not_null:\n        options.append(_format_force_not_null(column_names=force_not_null))\n\n    if force_null:\n        options.append(_format_force_null(column_names=force_null))\n\n    postgres_encoding = get_postgres_encoding(encoding)\n    options.append(\"ENCODING '%s'\" % postgres_encoding)\n\n    copy_sql = _format_copy_csv_sql(qualified_name, copy_options=options)\n\n    return copy_sql", "label": 1}
{"code": "def patch(path, options = {}, &block)\n      perform_request Net::HTTP::Patch, path, options, &block\n    end", "label": 4}
{"code": "def run(self):\n        \"\"\" Starts the thread \"\"\"\n\n        task = None\n        monitor_task = MonitorTask(\n            notification_endpoint=self._handle_message)\n\n        while True:\n            if self._terminate:\n                self._logger.info(\"scsgate.Reactor exiting\")\n                self._connection.close()\n                break\n            try:\n                task = self._request_queue.get_nowait()\n                self._logger.debug(\"scsgate.Reactor: got task {}\".format(task))\n            except queue.Empty:\n                task = monitor_task\n\n            try:\n                task.execute(connection=self._connection)\n            except ExecutionError as err:\n                self._logger.error(err)", "label": 1}
{"code": "public void notifyEventListeners(ZWaveEvent event) {\n\t\tlogger.debug(\"Notifying event listeners\");\n\t\tfor (ZWaveEventListener listener : this.zwaveEventListeners) {\n\t\t\tlogger.trace(\"Notifying {}\", listener.toString());\n\t\t\tlistener.ZWaveIncomingEvent(event);\n\t\t}\n\t}", "label": 0}
{"code": "func (c *CertAuthorityV1) String() string {\n\treturn fmt.Sprintf(\"CA(name=%v, type=%v)\", c.DomainName, c.Type)\n}", "label": 5}
{"code": "func (sink *influxdbSink) GetSystemContainersFromNode(node string) ([]string, error) {\n\tif !nameAllowedChars.MatchString(node) {\n\t\treturn nil, fmt.Errorf(\"Invalid node name %q\", node)\n\t}\n\t// This is a bit difficult for the influx query language, so we cheat a bit here --\n\t// we just get all series for the uptime measurement for system containers on our node\n\t// (any measurement should work here, though)\n\tq := fmt.Sprintf(\"SHOW SERIES FROM %q WHERE %s = '%s' AND type = '%s'\", core.MetricUptime.MetricDescriptor.Name, core.LabelNodename.Key, node, core.MetricSetTypeSystemContainer)\n\treturn sink.stringListQueryCol(q, core.LabelContainerName.Key, fmt.Sprintf(\"Unable to list system containers on node %q\", node))\n}", "label": 5}
{"code": "public function pathEndIdentifier()\n    {\n        $end = $this->pathEnd();\n\n        if (isset($end['id'])) {\n            return $end['id'];\n        }\n\n        if (isset($end['name'])) {\n            return $end['name'];\n        }\n\n        return null;\n    }", "label": 2}
{"code": "func (r *RegisterUsingTokenRequest) CheckAndSetDefaults() error {\n\tif r.HostID == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter HostID\")\n\t}\n\tif r.Token == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter Token\")\n\t}\n\tif err := r.Role.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function() {\n    var data   = {};\n\n    if (this.data && !isObject(this.data)) {\n      return this.data;\n    }\n\n    // TODO - don't do this yet until virt properties are checked\n    // var keys   = Object.keys(this);\n    var keys = Object.keys(this.data ? this.data : this);\n\n    for (var i = 0, n = keys.length; i < n; i++) {\n      var key = keys[i];\n\n      if (key in this.constructor.prototype || key.charCodeAt(0) === 95) {\n        continue;\n      }\n\n      data[key] = this[key];\n    }\n\n    return data;\n  }", "label": 3}
{"code": "public function setFeatures($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Language\\V1\\AnnotateTextRequest_Features::class);\n        $this->features = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def cached(key, path_info, details, locals)\n      name, prefix, partial = path_info\n\n      if key\n        @cache.cache(key, name, prefix, partial, locals) do\n          yield\n        end\n      else\n        yield\n      end\n    end", "label": 4}
{"code": "def process(*) #:nodoc:\n      old_config, I18n.config = I18n.config, I18nProxy.new(I18n.config, lookup_context)\n      super\n    ensure\n      I18n.config = old_config\n    end", "label": 4}
{"code": "public static function convertToArray($row)\n    {\n        $data = $row instanceof Arrayable ? $row->toArray() : (array) $row;\n\n        foreach ($data as &$value) {\n            if (is_object($value) || is_array($value)) {\n                $value = self::convertToArray($value);\n            }\n\n            unset($value);\n        }\n\n        return $data;\n    }", "label": 2}
{"code": "def to_xpath(string)\n      subs = string.to_s.scan(/\\G(?:\\A\\z|[^\"]+|[^']+)/).map { |x|\n        case x\n        when /\"/\n          %Q{'#{x}'}\n        else\n          %Q{\"#{x}\"}\n        end\n      }\n      if subs.size == 1\n        subs.first\n      else\n        'concat(' << subs.join(', ') << ')'\n      end\n    end", "label": 4}
{"code": "def delete_file(self, fid):\n        \"\"\"\n        Delete file from WeedFS\n\n        :param string fid: File ID\n        \"\"\"\n        url = self.get_file_url(fid)\n        return self.conn.delete_data(url)", "label": 1}
{"code": "def install_packages(packages,\n                     what_for='for a complete setup to work properly'):\n    '''Try to install .deb packages given by list.\n\n    Return True, if packages could be installed or are installed already, or if\n    they cannot be installed but the user gives feedback to continue.\n\n    Else return False.\n    '''\n    res = True\n    non_installed_packages = _non_installed(packages)\n    packages_str = '  '.join(non_installed_packages)\n    if non_installed_packages:\n        with quiet():\n            dpkg = _has_dpkg()\n        hint = '  (You may have to install them manually)'\n        do_install = False\n        go_on = True\n        if dpkg:\n            if _is_sudoer('Want to install dpkg packages'):\n                do_install = True\n            else:\n                do_install is False  # cannot install anything\n                info = yellow(' '.join([\n                    'This deb packages are missing to be installed',\n                    flo(\"{what_for}: \"), ', '.join(non_installed_packages),\n                ]))\n                question = '  Continue anyway?'\n                go_on = query_yes_no(info + hint + question, default='no')\n        else:\n            # dpkg == False, unable to determine if packages are installed\n            do_install = False  # cannot install anything\n            info = yellow(' '.join([\n                flo('Required {what_for}: '),\n                ', '.join(non_installed_packages),\n            ]))\n            go_on = query_yes_no(info + hint + '  Continue?', default='yes')\n        if not go_on:\n            sys.exit('Abort')\n        if do_install:\n            command = flo('sudo  apt-get install {packages_str}')\n            res = run(command).return_code == 0\n    return res", "label": 1}
{"code": "function createLoggerStream(name, level, logglyConfig) {\n    const streams = [process.stdout];\n    if (logglyConfig.enabled) {\n        const logglyStream = new LogglyStream({\n            token: logglyConfig.token,\n            subdomain: logglyConfig.subdomain,\n            name,\n            environment: logglyConfig.environment,\n        });\n        streams.push(logglyStream);\n    }\n    return new UnionStream({ streams });\n}", "label": 3}
{"code": "function pidFind(pid) {\n  if (!_.isFinite(pid)) return false;\n  try {\n    if (runningAsRoot()) {\n      return process.kill(pid, 0);\n    } else {\n      return !!ps(pid);\n    }\n  } catch (e) {\n    return false;\n  }\n}", "label": 3}
{"code": "def render(layouts, site_payload)\n      site_payload[\"page\"] = to_liquid\n      site_payload[\"paginator\"] = pager.to_liquid\n\n      do_layout(site_payload, layouts)\n    end", "label": 4}
{"code": "public function removeFilter($filter)\n    {\n        $key = is_callable($filter) ? 0 : 1;\n\n        $this->filters = array_values(array_filter(\n            $this->filters,\n            function ($tuple) use ($key, $filter) {\n                return $tuple[$key] !== $filter;\n            }\n        ));\n\n        $this->updateInternalState();\n\n        $this->handleChangedParameters();\n\n        return $this;\n    }", "label": 2}
{"code": "def dump(obj, fp=None, indent=None, sort_keys=False, **kw):\n    \"\"\"\n    Dump object to a file like object or string.\n\n    :param obj:\n    :param fp: Open file like object\n    :param int indent: Indent size, default 2\n    :param bool sort_keys: Optionally sort dictionary keys.\n    :return: Yaml serialized data.\n    \"\"\"\n\n    if fp:\n        iterable = YAMLEncoder(indent=indent, sort_keys=sort_keys, **kw).iterencode(obj)\n        for chunk in iterable:\n            fp.write(chunk)\n    else:\n        return dumps(obj, indent=indent, sort_keys=sort_keys, **kw)", "label": 1}
{"code": "function (notes, settings) {\n  var restBuffer = 0;\n\n  var events = _.reduce(notes, function (arr, obj) {\n    var time = noteLength(obj.duration, settings);\n\n    if (obj.note) {\n      arr.push(makeNoteEvent(restBuffer, true, 0, noteValue(obj.note), settings.noteVelocity)); // On\n      arr.push(makeNoteEvent(time, false, 0, noteValue(obj.note), settings.noteVelocity)); // Off\n      restBuffer = 0;\n    }\n    else {\n      restBuffer += time;\n    }\n\n    return arr;\n  }, []);\n\n  return Buffer.concat(events);\n}", "label": 3}
{"code": "def create_script_fact(self):\n        \"\"\"\n        appends the CREATE TABLE, index etc to self.ddl_text\n        \"\"\"\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += '-- CREATE Fact Table - ' + self.fact_table + '\\n'\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += 'DROP TABLE ' + self.fact_table + ' CASCADE CONSTRAINTS;\\n'\n        self.ddl_text += 'CREATE TABLE ' + self.fact_table + ' (\\n'\n        self.ddl_text += ' '.join([col + ' VARCHAR2(200), \\n' for col in self.col_list])\n        self.ddl_text += ' ' + self.date_updated_col + ' DATE \\n' # + src_table + '; \\n'\n        self.ddl_text += ');\\n'", "label": 1}
{"code": "public ValueContainer[] getValuesForObject(FieldDescriptor[] fields, Object obj, boolean convertToSql, boolean assignAutoincrement) throws PersistenceBrokerException\r\n    {\r\n        ValueContainer[] result = new ValueContainer[fields.length];\r\n\r\n        for(int i = 0; i < fields.length; i++)\r\n        {\r\n            FieldDescriptor fd = fields[i];\r\n            Object cv = fd.getPersistentField().get(obj);\r\n\r\n            /*\r\n            handle autoincrement attributes if\r\n            - is a autoincrement field\r\n            - field represents a 'null' value, is nullified\r\n            and generate a new value\r\n            */\r\n            if(assignAutoincrement && fd.isAutoIncrement() && representsNull(fd, cv))\r\n            {\r\n                /*\r\n                setAutoIncrementValue returns a value that is\r\n                properly typed for the java-world.  This value\r\n                needs to be converted to it's corresponding\r\n                sql type so that the entire result array contains\r\n                objects that are properly typed for sql.\r\n                */\r\n                cv = setAutoIncrementValue(fd, obj);\r\n            }\r\n            if(convertToSql)\r\n            {\r\n                // apply type and value conversion\r\n                cv = fd.getFieldConversion().javaToSql(cv);\r\n            }\r\n            // create ValueContainer\r\n            result[i] = new ValueContainer(cv, fd.getJdbcType());\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def global_unlock_percent(self):\n        \"\"\"Global achievement unlock percent.\n\n        :rtype: float\n        \"\"\"\n        percent = CRef.cfloat()\n        result = self._iface.get_ach_progress(self.name, percent)\n\n        if not result:\n            return 0.0\n\n        return float(percent)", "label": 1}
{"code": "def national(formatted = true)\n      return @national_number unless valid?\n      format_match, format_string = formatting_data\n\n      if format_match\n        out = format_string.gsub(/\\$\\d/) { |el| format_match[el[1].to_i] }\n        formatted ? out : out.gsub(/[^0-9]/, '')\n      else\n        @national_number\n      end\n    end", "label": 4}
{"code": "def DoxyfileParse(file_contents):\n   \"\"\"\n   Parse a Doxygen source file and return a dictionary of all the values.\n   Values will be strings and lists of strings.\n   \"\"\"\n   data = {}\n\n   import shlex\n   lex = shlex.shlex(instream = file_contents, posix = True)\n   lex.wordchars += \"*+./-:\"\n   lex.whitespace = lex.whitespace.replace(\"\\n\", \"\")\n   lex.escape = \"\"\n\n   lineno = lex.lineno\n   token = lex.get_token()\n   key = token   # the first token should be a key\n   last_token = \"\"\n   key_token = False\n   next_key = False\n   new_data = True\n\n   def append_data(data, key, new_data, token):\n      if new_data or len(data[key]) == 0:\n         data[key].append(token)\n      else:\n         data[key][-1] += token\n\n   while token:\n      if token in ['\\n']:\n         if last_token not in ['\\\\']:\n            key_token = True\n      elif token in ['\\\\']:\n         pass\n      elif key_token:\n         key = token\n         key_token = False\n      else:\n         if token == \"+=\":\n            if not data.has_key(key):\n               data[key] = list()\n         elif token == \"=\":\n            if key == \"TAGFILES\" and data.has_key(key):\n               append_data( data, key, False, \"=\" )\n               new_data=False\n            else:\n               data[key] = list()\n         else:\n            append_data( data, key, new_data, token )\n            new_data = True\n\n      last_token = token\n      token = lex.get_token()\n\n      if last_token == '\\\\' and token != '\\n':\n         new_data = False\n         append_data( data, key, new_data, '\\\\' )\n\n   # compress lists of len 1 into single strings\n   for (k, v) in data.items():\n      if len(v) == 0:\n         data.pop(k)\n\n      # items in the following list will be kept as lists and not converted to strings\n      if k in [\"INPUT\", \"FILE_PATTERNS\", \"EXCLUDE_PATTERNS\", \"TAGFILES\"]:\n         continue\n\n      if len(v) == 1:\n         data[k] = v[0]\n\n   return data", "label": 1}
{"code": "function walkCollections(patterns, drizzleData, writePromises = []) {\n  if (hasCollection(patterns)) {\n    writePromises.push(\n      writePage(\n        patterns.collection.id,\n        patterns.collection,\n        drizzleData.options.dest.patterns,\n        drizzleData.options.keys.collections.plural\n      )\n    );\n  }\n  for (const patternKey in patterns) {\n    if (!isCollection(patterns[patternKey])) {\n      walkCollections(patterns[patternKey], drizzleData, writePromises);\n    }\n  }\n  return writePromises;\n}", "label": 3}
{"code": "function mapBuilder(map, bufb, codec, width) {\n  if (typeof map !== 'object') {\n    throw new errors.EncodingError(map, 'Unsure how to encode non-object as map');\n  }\n\n  if (Array.isArray(map)) {\n    throw new errors.EncodingError(map, 'Unsure how to encode array as map');\n  }\n\n  var keys = Object.keys(map);\n  if (!width && keys.length === 0) {\n    bufb.appendUInt8(0xC1);\n    bufb.appendUInt8(1);\n    bufb.appendUInt8(0);\n    return;\n  }\n\n  // Encode all elements into a temp buffer to allow us to front-load appropriate size and count.\n  var tempBuilder = new Builder();\n  var _len = keys.length;\n  for (var _i = 0; _i < _len; ++_i) {\n    codec.encode(keys[_i], tempBuilder);\n    codec.encode(map[keys[_i]], tempBuilder);\n  }\n  var tempBuffer = tempBuilder.get();\n\n  // Code, size, length, data\n  if (width === 1 || (width !== 4 && tempBuffer.length < 0xFF)) {\n    // map8\n    if (!width) bufb.appendUInt8(0xC1);\n    bufb.appendUInt8(tempBuffer.length + 1);\n    bufb.appendUInt8(keys.length * 2);\n  } else {\n    // map32\n    if (!width) bufb.appendUInt8(0xD1);\n    bufb.appendUInt32BE(tempBuffer.length + 4);\n    bufb.appendUInt32BE(keys.length * 2);\n  }\n\n  bufb.appendBuffer(tempBuffer);\n}", "label": 3}
{"code": "func isEthereumAddress(fl FieldLevel) bool {\n\taddress := fl.Field().String()\n\n\tif !ethAddressRegex.MatchString(address) {\n\t\treturn false\n\t}\n\n\tif ethaddressRegexUpper.MatchString(address) || ethAddressRegexLower.MatchString(address) {\n\t\treturn true\n\t}\n\n\t// checksum validation is blocked by https://github.com/golang/crypto/pull/28\n\n\treturn true\n}", "label": 5}
{"code": "public function getFirstAppearance($var_id)\n    {\n        return isset($this->all_vars[$var_id]) ? $this->all_vars[$var_id] : null;\n    }", "label": 2}
{"code": "def add_dependency(name, version_requirement=nil, repository=nil)\n      validate_name(name)\n      validate_version_range(version_requirement) if version_requirement\n\n      if dup = @data['dependencies'].find { |d| d.full_module_name == name && d.version_requirement != version_requirement }\n        raise ArgumentError, _(\"Dependency conflict for %{module_name}: Dependency %{name} was given conflicting version requirements %{version_requirement} and %{dup_version}. Verify that there are no duplicates in the metadata.json.\") % { module_name: full_module_name, name: name, version_requirement: version_requirement, dup_version: dup.version_requirement }\n      end\n\n      dep = Dependency.new(name, version_requirement, repository)\n      @data['dependencies'].add(dep)\n\n      dep\n    end", "label": 4}
{"code": "public function iam()\n    {\n        if (!$this->iam) {\n            $this->iam = new Iam(\n                new IamDatabase($this->connection),\n                $this->name\n            );\n        }\n\n        return $this->iam;\n    }", "label": 2}
{"code": "func (this *NamespaceBasedEnricher) addNamespaceInfo(metricSet *core.MetricSet) {\n\tmetricSetType, found := metricSet.Labels[core.LabelMetricSetType.Key]\n\tif !found {\n\t\treturn\n\t}\n\tif metricSetType != core.MetricSetTypePodContainer &&\n\t\tmetricSetType != core.MetricSetTypePod &&\n\t\tmetricSetType != core.MetricSetTypeNamespace {\n\t\treturn\n\t}\n\n\tnamespaceName, found := metricSet.Labels[core.LabelNamespaceName.Key]\n\tif !found {\n\t\treturn\n\t}\n\n\tnsObj, exists, err := this.store.GetByKey(namespaceName)\n\tif exists && err == nil {\n\t\tnamespace, ok := nsObj.(*kube_api.Namespace)\n\t\tif ok {\n\t\t\tmetricSet.Labels[core.LabelPodNamespaceUID.Key] = string(namespace.UID)\n\t\t} else {\n\t\t\tglog.Errorf(\"Wrong namespace store content\")\n\t\t}\n\t} else if err != nil {\n\t\tglog.Warningf(\"Failed to get namespace %s: %v\", namespaceName, err)\n\t} else if !exists {\n\t\tglog.Warningf(\"Namespace doesn't exist: %s\", namespaceName)\n\t}\n}", "label": 5}
{"code": "public Collection getReaders(Object obj)\r\n\t{\r\n\t\tCollection result = null;\r\n        try\r\n        {\r\n            Identity oid = new Identity(obj, getBroker());\r\n            byte selector = (byte) 'r';\r\n            byte[] requestBarr = buildRequestArray(oid, selector);\r\n            \r\n            HttpURLConnection conn = getHttpUrlConnection();\r\n            \r\n            //post request\r\n            BufferedOutputStream out = new BufferedOutputStream(conn.getOutputStream());\r\n            out.write(requestBarr,0,requestBarr.length);\r\n            out.flush();\t\t\r\n            \r\n            // read result from \r\n            InputStream in = conn.getInputStream();\r\n            ObjectInputStream ois = new ObjectInputStream(in);\r\n            result = (Collection) ois.readObject();\r\n            \r\n            // cleanup\r\n            ois.close();\r\n            out.close();\r\n            conn.disconnect();\t\t\r\n        }\r\n        catch (Throwable t)\r\n        {\r\n            throw new PersistenceBrokerException(t);\r\n        }\r\n        return result;\r\n\t}", "label": 0}
{"code": "def to_perseus(df, path_or_file, main_columns=None,\n        separator=separator,\n        convert_bool_to_category=True,\n        numerical_annotation_rows = set([])):\n    \"\"\"\n    Save pd.DataFrame to Perseus text format.\n\n    :param df: pd.DataFrame.\n    :param path_or_file: File name or file-like object.\n    :param main_columns: Main columns. Will be infered if set to None. All numeric columns up-until the first non-numeric column are considered main columns.\n    :param separator: For separating fields, default='\\t'.\n    :param covert_bool_to_category: Convert bool columns of True/False to category columns '+'/'', default=True.\n    :param numerical_annotation_rows: Set of column names to be interpreted as numerical annotation rows, default=set([]).\n    \"\"\"\n    _df = df.copy()\n    if not _df.columns.name:\n        _df.columns.name = 'Column Name'\n    column_names = _df.columns.get_level_values('Column Name')\n    annotations = {}\n    main_columns = _infer_main_columns(_df) if main_columns is None else main_columns\n    annotations['Type'] = ['E' if column_names[i] in main_columns else dtype_to_perseus(dtype)\n            for i, dtype in enumerate(_df.dtypes)]\n    # detect multi-numeric columns\n    for i, column in enumerate(_df.columns):\n        valid_values = [value for value in _df[column] if value is not None]\n        if len(valid_values) > 0 and all(type(value) is list for value in valid_values):\n            annotations['Type'][i] = 'M'\n            _df[column] = _df[column].apply(lambda xs: ';'.join(str(x) for x in xs))\n    if convert_bool_to_category:\n        for i, column in enumerate(_df.columns):\n            if _df.dtypes[i] is np.dtype('bool'):\n                values = _df[column].values\n                _df[column][values] = '+'\n                _df[column][~values] = ''\n    annotation_row_names = set(_df.columns.names) - {'Column Name'}\n    for name in annotation_row_names:\n        annotation_type = 'N' if name in numerical_annotation_rows else 'C'\n        annotations['{}:{}'.format(annotation_type, name)] = _df.columns.get_level_values(name)\n    with PathOrFile(path_or_file, 'w') as f:\n        f.write(separator.join(column_names) + '\\n')\n        for name, values in annotations.items():\n            f.write('#!{{{name}}}{values}\\n'.format(name=name, values=separator.join([str(x) for x in values])))\n        _df.to_csv(f, header=None, index=False, sep=separator)", "label": 1}
{"code": "def rewriteFasta(sequence, sequence_name, fasta_in, fasta_out):\n    \"\"\"\n    Rewrites a specific sequence in a multifasta file while keeping the sequence header.\n\n    :param sequence: a string with the sequence to be written\n    :param sequence_name: the name of the sequence to be retrieved eg. for '>2 dna:chromosome chromosome:GRCm38:2:1:182113224:1 REF' use: sequence_name=str(2)\n    :param fasta_in: /path/to/original.fa\n    :param fasta_out: /path/to/destination.fa\n\n    :returns: nothing\n    \"\"\"\n    f=open(fasta_in, 'r+')\n    f2=open(fasta_out,'w')\n    lines = f.readlines()\n    i=0\n    while i < len(lines):\n        line = lines[i]\n        if line[0] == \">\":\n            f2.write(line)\n            fChr=line.split(\" \")[0]\n            fChr=fChr[1:]\n            if fChr == sequence_name:\n                code=['N','A','C','T','G']\n                firstbase=lines[i+1][0]\n                while firstbase in code:\n                    i=i+1\n                    firstbase=lines[i][0]\n                s=0\n                while s <= len(sequence):\n                    f2.write(sequence[s:s+60]+\"\\n\")\n                    s=s+60\n            else:\n                i=i+1\n        else:\n            f2.write(line)\n            i=i+1\n\n    f2.close\n    f.close", "label": 1}
{"code": "func (o HostNetworkSystem) RemovePortGroup(ctx context.Context, pgName string) error {\n\treq := types.RemovePortGroup{\n\t\tThis:   o.Reference(),\n\t\tPgName: pgName,\n\t}\n\n\t_, err := methods.RemovePortGroup(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func (c *Manager) ListLibraries(ctx context.Context) ([]string, error) {\n\turl := internal.URL(c, internal.LibraryPath)\n\tvar res []string\n\treturn res, c.Do(ctx, url.Request(http.MethodGet), &res)\n}", "label": 5}
{"code": "def _text_file(self, url):\n        \"\"\"return the content of a file\"\"\"\n        try:\n            with open(url, 'r', encoding='utf-8') as file:\n                return file.read()\n        except FileNotFoundError:\n            print('File `{}` not found'.format(url))\n            sys.exit(0)", "label": 1}
{"code": "func (f *Fpdf) SetLineCapStyle(styleStr string) {\n\tvar capStyle int\n\tswitch styleStr {\n\tcase \"round\":\n\t\tcapStyle = 1\n\tcase \"square\":\n\t\tcapStyle = 2\n\tdefault:\n\t\tcapStyle = 0\n\t}\n\tf.capStyle = capStyle\n\tif f.page > 0 {\n\t\tf.outf(\"%d J\", f.capStyle)\n\t}\n}", "label": 5}
{"code": "function extendSelection(doc, head, other, options) {\n    setSelection(doc, new Selection([extendRange(doc, doc.sel.primary(), head, other)], 0), options);\n  }", "label": 3}
{"code": "func (ds *datastore) DeleteObject(kvObject KVObject) error {\n\tif ds.sequential {\n\t\tds.Lock()\n\t\tdefer ds.Unlock()\n\t}\n\n\t// cleanup the cache first\n\tif ds.cache != nil {\n\t\t// If persistent store is skipped, sequencing needs to\n\t\t// happen in cache.\n\t\tds.cache.del(kvObject, kvObject.Skip())\n\t}\n\n\tif kvObject.Skip() {\n\t\treturn nil\n\t}\n\n\treturn ds.store.Delete(Key(kvObject.Key()...))\n}", "label": 5}
{"code": "def search_local_galaxies(galaxy):\n    '''\n    It is also possible to query the local galaxies by label, here is an example of querying for the local galaxy labeled  IC 10\n\n    http://star-api.herokuapp.com/api/v1/local_groups/IC 10\n    '''\n\n    base_url = \"http://star-api.herokuapp.com/api/v1/local_groups/\"\n\n    if not isinstance(galaxy, str):\n        raise ValueError(\"The galaxy arg you provided is not the type of str\")\n    else:\n        base_url += galaxy\n\n    return dispatch_http_get(base_url)", "label": 1}
{"code": "function(opt_randFunc) {\n    var randFunc = opt_randFunc || randInt;\n    var strong = randFunc(3);\n    var colors = [];\n    for (var ii = 0; ii < 3; ++ii) {\n      colors.push(randFunc(128) + (ii === strong ? 128 : 64));\n    }\n    return \"rgb(\" + colors.join(\",\") + \")\";\n  }", "label": 3}
{"code": "def cleanup_payload(self, payload):\n        \"\"\"\n        Basically, turns payload that looks like '   \\\\n  ' to ''. In the \n        calling function, if this function returns '' no object is added \n        for that payload.\n        \"\"\"\n        p = payload.replace('\\n', '')\n        p = p.rstrip()\n        p = p.lstrip()\n        return p", "label": 1}
{"code": "public static base_response unset(nitro_service client, nsspparams resource, String[] args) throws Exception{\n\t\tnsspparams unsetresource = new nsspparams();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def loop_handle_server_calls\n      fail 'not started' if running_state == :not_started\n      while running_state == :running\n        begin\n          an_rpc = @server.request_call\n          break if (!an_rpc.nil?) && an_rpc.call.nil?\n          active_call = new_active_server_call(an_rpc)\n          unless active_call.nil?\n            @pool.schedule(active_call) do |ac|\n              c, mth = ac\n              begin\n                rpc_descs[mth].run_server_method(\n                  c,\n                  rpc_handlers[mth],\n                  @interceptors.build_context\n                )\n              rescue StandardError\n                c.send_status(GRPC::Core::StatusCodes::INTERNAL,\n                              'Server handler failed')\n              end\n            end\n          end\n        rescue Core::CallError, RuntimeError => e\n          # these might happen for various reasons.  The correct behavior of\n          # the server is to log them and continue, if it's not shutting down.\n          if running_state == :running\n            GRPC.logger.warn(\"server call failed: #{e}\")\n          end\n          next\n        end\n      end\n      # @running_state should be :stopping here\n      @run_mutex.synchronize do\n        transition_running_state(:stopped)\n        GRPC.logger.info(\"stopped: #{self}\")\n        @server.close\n      end\n    end", "label": 4}
{"code": "public function readRow($rowKey, array $options = [])\n    {\n        return $this->readRows(\n            ['rowKeys' => [$rowKey]] + $options + $this->options\n        )\n            ->readAll()\n            ->current();\n    }", "label": 2}
{"code": "public function getFilters(): Collection\n    {\n        $filters = collect();\n        foreach ($this->filters() as $filter) {\n            $filter = new $filter($this);\n            $filters->push($filter);\n        }\n\n        return $filters;\n    }", "label": 2}
{"code": "func GetCgroupPathByPid(pid int, controller string) (string, error) {\n\tparts, err := parseCgroupController(fmt.Sprintf(\"/proc/%d/cgroup\", pid), controller)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn parts[2], nil\n}", "label": 5}
{"code": "public function setResourceDescriptors($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Api\\MonitoredResourceDescriptor::class);\n        $this->resource_descriptors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function insertBatch(array $traces, array $options = [])\n    {\n        $spans = [];\n        foreach ($traces as $trace) {\n            foreach ($trace->spans() as $span) {\n                $spans[] = $this->transformSpan($span);\n            }\n        }\n        // throws ServiceException on failure\n        $this->connection->traceBatchWrite([\n            'projectsId' => $this->projectId,\n            'spans' => $spans\n        ] + $options);\n        return true;\n    }", "label": 2}
{"code": "func getRunningImages() ([]string, error) {\n\tvar runningImages []string\n\tvar errors []error\n\terr := pkgPod.WalkPods(getDataDir(), pkgPod.IncludeMostDirs, func(p *pkgPod.Pod) {\n\t\tvar pm schema.PodManifest\n\t\tif p.State() != pkgPod.Running {\n\t\t\treturn\n\t\t}\n\t\tif !p.PodManifestAvailable() {\n\t\t\treturn\n\t\t}\n\t\t_, manifest, err := p.PodManifest()\n\t\tif err != nil {\n\t\t\terrors = append(errors, newPodListReadError(p, err))\n\t\t\treturn\n\t\t}\n\t\tpm = *manifest\n\t\tfor _, app := range pm.Apps {\n\t\t\trunningImages = append(runningImages, app.Image.ID.String())\n\t\t}\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(errors) > 0 {\n\t\treturn nil, errors[0]\n\t}\n\treturn runningImages, nil\n}", "label": 5}
{"code": "func (sink *influxdbSink) checkSanitizedMetricName(name string) error {\n\tif !metricAllowedChars.MatchString(name) {\n\t\treturn fmt.Errorf(\"Invalid metric name %q\", name)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "private static void checkSorted(int[] sorted) {\r\n    for (int i = 0; i < sorted.length-1; i++) {\r\n      if (sorted[i] > sorted[i+1]) {\r\n        throw new RuntimeException(\"input must be sorted!\");\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "public function loadConfig()\n    {\n        $result = $this->configStorage->lock();\n        if ($result === false) {\n            throw new \\RuntimeException('Failed to lock the configStorage');\n        }\n        try {\n            $result = $this->configStorage->load();\n        } catch (\\RuntimeException $e) {\n            $this->configStorage->clear();\n            throw $e;\n        } finally {\n            $this->configStorage->unlock();\n        }\n\n        $this->config = $result;\n        return true;\n    }", "label": 2}
{"code": "func (s *ClusterConfigurationService) GetAuthPreference() (services.AuthPreference, error) {\n\titem, err := s.Get(context.TODO(), backend.Key(authPrefix, preferencePrefix, generalPrefix))\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn nil, trace.NotFound(\"authentication preference not found\")\n\t\t}\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.GetAuthPreferenceMarshaler().Unmarshal(item.Value,\n\t\tservices.WithResourceID(item.ID), services.WithExpires(item.Expires))\n}", "label": 5}
{"code": "func RawCombinedOutput(args ...string) error {\n\tif output, err := Raw(args...); err != nil || len(output) != 0 {\n\t\treturn fmt.Errorf(\"%s (%v)\", string(output), err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func (*TeleportOIDCConnectorMarshaler) MarshalOIDCConnector(c OIDCConnector, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttype connv1 interface {\n\t\tV1() *OIDCConnectorV1\n\t}\n\n\ttype connv2 interface {\n\t\tV2() *OIDCConnectorV2\n\t}\n\tversion := cfg.GetVersion()\n\tswitch version {\n\tcase V1:\n\t\tv, ok := c.(connv1)\n\t\tif !ok {\n\t\t\treturn nil, trace.BadParameter(\"don't know how to marshal %v\", V1)\n\t\t}\n\t\treturn json.Marshal(v.V1())\n\tcase V2:\n\t\tv, ok := c.(connv2)\n\t\tif !ok {\n\t\t\treturn nil, trace.BadParameter(\"don't know how to marshal %v\", V2)\n\t\t}\n\t\tv2 := v.V2()\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *v2\n\t\t\tcopy.SetResourceID(0)\n\t\t\tv2 = &copy\n\t\t}\n\t\treturn utils.FastMarshal(v2)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"version %v is not supported\", version)\n\t}\n}", "label": 5}
{"code": "function (viewId, requirePath, err) {\n            var that = this,\n                message = 'View Not Found. Searched for \"' + viewId + '\" via path \"' + requirePath + '\".';\n\n            return system.defer(function(dfd) {\n                dfd.resolve(that.processMarkup('<div class=\"durandal-view-404\">' + message + '</div>'));\n            }).promise();\n        }", "label": 3}
{"code": "function render({ document }) {\n  console.debug(\"rendering\");\n  document.querySelectorAll(\".replace-with-pubcontrol\").forEach(el => {\n    el.innerHTML = `\n    <div>\n      <h2>pubcontrol default export</h2>\n      <pre>${JSON.stringify(objectSchema(PubControl), null, 2)}</pre>\n    </div>\n    `;\n  });\n}", "label": 3}
{"code": "public void synchTransaction(SimpleFeatureStore featureStore) {\n\t\t// check if transaction is active, otherwise do nothing (auto-commit mode)\n\t\tif (TransactionSynchronizationManager.isActualTransactionActive()) {\n\t\t\tDataAccess<SimpleFeatureType, SimpleFeature> dataStore = featureStore.getDataStore();\n\t\t\tif (!transactions.containsKey(dataStore)) {\n\t\t\t\tTransaction transaction = null;\n\t\t\t\tif (dataStore instanceof JDBCDataStore) {\n\t\t\t\t\tJDBCDataStore jdbcDataStore = (JDBCDataStore) dataStore;\n\t\t\t\t\ttransaction = jdbcDataStore.buildTransaction(DataSourceUtils\n\t\t\t\t\t\t\t.getConnection(jdbcDataStore.getDataSource()));\n\t\t\t\t} else {\n\t\t\t\t\ttransaction = new DefaultTransaction();\n\t\t\t\t}\n\t\t\t\ttransactions.put(dataStore, transaction);\n\t\t\t}\n\t\t\tfeatureStore.setTransaction(transactions.get(dataStore));\n\t\t}\n\t}", "label": 0}
{"code": "function getEffectiveArgumentType(node, argIndex, arg) {\n            // Decorators provide special arguments, a tagged template expression provides\n            // a special first argument, and string literals get string literal types\n            // unless we're reporting errors\n            if (node.kind === 143 /* Decorator */) {\n                return getEffectiveDecoratorArgumentType(node, argIndex);\n            }\n            else if (argIndex === 0 && node.kind === 176 /* TaggedTemplateExpression */) {\n                return getGlobalTemplateStringsArrayType();\n            }\n            // This is not a synthetic argument, so we return 'undefined'\n            // to signal that the caller needs to check the argument.\n            return undefined;\n        }", "label": 3}
{"code": "func (c *Client) CreateSAMLConnector(connector services.SAMLConnector) error {\n\tdata, err := services.GetSAMLConnectorMarshaler().MarshalSAMLConnector(connector)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"saml\", \"connectors\"), &createSAMLConnectorRawReq{\n\t\tConnector: data,\n\t})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def capture_haml(*args, &block)\n      buffer = eval('if defined? _hamlout then _hamlout else nil end', block.binding) || haml_buffer\n      with_haml_buffer(buffer) do\n        position = haml_buffer.buffer.length\n\n        haml_buffer.capture_position = position\n        value = block.call(*args)\n\n        captured = haml_buffer.buffer.slice!(position..-1)\n\n        if captured == '' and value != haml_buffer.buffer\n          captured = (value.is_a?(String) ? value : nil)\n        end\n\n        captured\n      end\n    ensure\n      haml_buffer.capture_position = nil\n    end", "label": 4}
{"code": "function handleChat(payload) {\n        if (!payload.message) {\n            return Promise.reject(new Error('Event payload did not include chat message'));\n        }\n        const message = ChatRoom.Message.parse(payload.message);\n\n        forum.emit('chatMessage', message);\n        const ids = {\n            post: -1,\n            topic: -1,\n            user: message.from.id,\n            pm: message.room,\n            chat: message.id\n        };\n        return forum.Commands.get(ids, message.content, (content) => message.reply(content))\n            .then((command) => command.execute());\n    }", "label": 3}
{"code": "public function migrate(Extension $extension, $direction = 'up')\n    {\n        $this->app->bind('Illuminate\\Database\\Schema\\Builder', function ($container) {\n            return $container->make('Illuminate\\Database\\ConnectionInterface')->getSchemaBuilder();\n        });\n\n        $extension->migrate($this->migrator, $direction);\n    }", "label": 2}
{"code": "public function write($id, $data)\n    {\n        try {\n            $key = $this->datastore->key(\n                $this->kind,\n                $id,\n                ['namespaceId' => $this->namespaceId]\n            );\n            $entity = $this->datastore->entity(\n                $key,\n                [\n                    'data' => $data,\n                    't' => time()\n                ],\n                $this->options['entityOptions']\n            );\n            $this->transaction->upsert($entity);\n            $this->transaction->commit();\n        } catch (Exception $e) {\n            trigger_error(\n                sprintf('Datastore upsert failed: %s', $e->getMessage()),\n                E_USER_WARNING\n            );\n            return false;\n        }\n        return true;\n    }", "label": 2}
{"code": "function AggregateError(message) {\n  if (!(this instanceof AggregateError)) {\n    return new AggregateError(message);\n  }\n\n  Error.captureStackTrace(this, AggregateError);\n  // Like http://www.ecma-international.org/ecma-262/6.0/#sec-error-message\n  if (message !== undefined) {\n    Object.defineProperty(this, 'message', {\n      value: String(message),\n      configurable: true,\n      writable: true\n    });\n  }\n}", "label": 3}
{"code": "def run_trial_exceptions(self, *args, **kwargs):\n        '''\n        A wrapper for run_trial that catches exceptions and returns them.\n        It is meant for async simulations\n        '''\n        try:\n            return self.run_trial(*args, **kwargs)\n        except Exception as ex:\n            c = ex.__cause__\n            c.message = ''.join(traceback.format_exception(type(c), c, c.__traceback__)[:])\n            return c", "label": 1}
{"code": "public BeanDefinition toInternal(BeanDefinitionInfo beanDefinitionInfo) {\n\t\tif (beanDefinitionInfo instanceof GenericBeanDefinitionInfo) {\n\t\t\tGenericBeanDefinitionInfo genericInfo = (GenericBeanDefinitionInfo) beanDefinitionInfo;\n\t\t\tGenericBeanDefinition def = new GenericBeanDefinition();\n\t\t\tdef.setBeanClassName(genericInfo.getClassName());\n\t\t\tif (genericInfo.getPropertyValues() != null) {\n\t\t\t\tMutablePropertyValues propertyValues = new MutablePropertyValues();\n\t\t\t\tfor (Entry<String, BeanMetadataElementInfo> entry : genericInfo.getPropertyValues().entrySet()) {\n\t\t\t\t\tBeanMetadataElementInfo info = entry.getValue();\n\t\t\t\t\tpropertyValues.add(entry.getKey(), toInternal(info));\n\t\t\t\t}\n\t\t\t\tdef.setPropertyValues(propertyValues);\n\t\t\t}\n\t\t\treturn def;\n\t\t} else if (beanDefinitionInfo instanceof ObjectBeanDefinitionInfo) {\n\t\t\tObjectBeanDefinitionInfo objectInfo = (ObjectBeanDefinitionInfo) beanDefinitionInfo;\n\t\t\treturn createBeanDefinitionByIntrospection(objectInfo.getObject());\n\t\t} else {\n\t\t\tthrow new IllegalArgumentException(\"Conversion to internal of \" + beanDefinitionInfo.getClass().getName()\n\t\t\t\t\t+ \" not implemented\");\n\t\t}\n\t}", "label": 0}
{"code": "def _evaluate_mismatch(self, Ybus, V, Sbus, pq, pvpq):\n        \"\"\" Evaluates the mismatch.\n        \"\"\"\n        mis = (multiply(V, conj(Ybus * V)) - Sbus) / abs(V)\n\n        P = mis[pvpq].real\n        Q = mis[pq].imag\n\n        return P, Q", "label": 1}
{"code": "def upsert_records(conn, records, upsert_statement):\n    \"\"\"Upsert records.\"\"\"\n\n    with conn:\n        with conn.cursor() as cursor:\n            for record in records:\n                cursor.execute(upsert_statement, record)", "label": 1}
{"code": "func Wait(ctx context.Context, c *Collector, obj types.ManagedObjectReference, ps []string, f func([]types.PropertyChange) bool) error {\n\tfilter := new(WaitFilter).Add(obj, obj.Type, ps)\n\n\treturn WaitForUpdates(ctx, c, filter, func(updates []types.ObjectUpdate) bool {\n\t\tfor _, update := range updates {\n\t\t\tif f(update.ChangeSet) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\n\t\treturn false\n\t})\n}", "label": 5}
{"code": "def process(self, versions):\n        \"\"\"Logging version sorted ascending by tool name.\"\"\"\n        for tool_name in sorted(versions.keys()):\n            version = versions[tool_name]\n            self._log(\"Using tool '%s', %s\" % (tool_name, version))", "label": 1}
{"code": "def read_json_base64\n      str = read_json_string\n      m = str.length % 4\n      if m != 0\n        # Add missing padding\n        (4 - m).times do\n          str += '='\n        end\n      end\n      Base64.strict_decode64(str)\n    end", "label": 4}
{"code": "def to_ical(force_utc = false)\n      pieces = []\n      pieces << \"DTSTART#{IcalBuilder.ical_format(start_time, force_utc)}\"\n      pieces.concat recurrence_rules.map { |r| \"RRULE:#{r.to_ical}\" }\n      pieces.concat exception_rules.map  { |r| \"EXRULE:#{r.to_ical}\" }\n      pieces.concat recurrence_times_without_start_time.map { |t| \"RDATE#{IcalBuilder.ical_format(t, force_utc)}\" }\n      pieces.concat exception_times.map  { |t| \"EXDATE#{IcalBuilder.ical_format(t, force_utc)}\" }\n      pieces << \"DTEND#{IcalBuilder.ical_format(end_time, force_utc)}\" if end_time\n      pieces.join(\"\\n\")\n    end", "label": 4}
{"code": "private int[] convertBatch(int[] batch) {\n        int[] conv = new int[batch.length];\n        for (int i=0; i<batch.length; i++) {\n            conv[i] = sample[batch[i]];\n        }\n        return conv;\n    }", "label": 0}
{"code": "def upload_binary_data(apk_path)\n      apk_version_code = nil\n      if apk_path\n        UI.message(\"Preparing apk at path '#{apk_path}' for upload...\")\n        apk_version_code = client.upload_apk(apk_path)\n        UI.user_error!(\"Could not upload #{apk_path}\") unless apk_version_code\n\n        if Supply.config[:obb_main_references_version] && Supply.config[:obb_main_file_size]\n          update_obb(apk_version_code,\n                     'main',\n                     Supply.config[:obb_main_references_version],\n                     Supply.config[:obb_main_file_size])\n        end\n\n        if Supply.config[:obb_patch_references_version] && Supply.config[:obb_patch_file_size]\n          update_obb(apk_version_code,\n                     'patch',\n                     Supply.config[:obb_patch_references_version],\n                     Supply.config[:obb_patch_file_size])\n        end\n\n        upload_obbs(apk_path, apk_version_code)\n\n        if metadata_path\n          all_languages.each do |language|\n            next if language.start_with?('.') # e.g. . or .. or hidden folders\n            upload_changelog(language, apk_version_code)\n          end\n        end\n      else\n        UI.message(\"No apk file found, you can pass the path to your apk using the `apk` option\")\n      end\n      apk_version_code\n    end", "label": 4}
{"code": "func (f *Fpdf) SetHomeXY() {\n\tf.SetY(f.tMargin)\n\tf.SetX(f.lMargin)\n}", "label": 5}
{"code": "protected function filterProviders(array $providers)\n    {\n        if (empty($providers)) {\n            return $this->providers;\n        }\n\n        return array_intersect_key($this->providers, array_flip($providers));\n    }", "label": 2}
{"code": "def duration(self):\n        \"\"\"\n        Calculate how long the stage took.\n\n        Returns:\n            float: (current) duration of the stage\n        \"\"\"\n        duration = 0.0\n        if len(self.events) > 0:\n            first = datetime.fromtimestamp(self.events[0]['timestamp'])\n            last = datetime.fromtimestamp(self.events[-1]['timestamp'])\n            duration = (last - first).total_seconds()\n        return duration", "label": 1}
{"code": "function writeReferencePath(referencedFile, addBundledFileReference, emitOnlyDtsFiles) {\n            var declFileName;\n            var addedBundledEmitReference = false;\n            if (ts.isDeclarationFile(referencedFile)) {\n                // Declaration file, use declaration file name\n                declFileName = referencedFile.fileName;\n            }\n            else {\n                // Get the declaration file path\n                ts.forEachExpectedEmitFile(host, getDeclFileName, referencedFile, emitOnlyDtsFiles);\n            }\n            if (declFileName) {\n                declFileName = ts.getRelativePathToDirectoryOrUrl(ts.getDirectoryPath(ts.normalizeSlashes(declarationFilePath)), declFileName, host.getCurrentDirectory(), host.getCanonicalFileName, \n                /*isAbsolutePathAnUrl*/ false);\n                referencesOutput += \"/// <reference path=\\\"\" + declFileName + \"\\\" />\" + newLine;\n            }\n            return addedBundledEmitReference;\n            function getDeclFileName(emitFileNames, sourceFiles, isBundledEmit) {\n                // Dont add reference path to this file if it is a bundled emit and caller asked not emit bundled file path\n                if (isBundledEmit && !addBundledFileReference) {\n                    return;\n                }\n                ts.Debug.assert(!!emitFileNames.declarationFilePath || ts.isSourceFileJavaScript(referencedFile), \"Declaration file is not present only for javascript files\");\n                declFileName = emitFileNames.declarationFilePath || emitFileNames.jsFilePath;\n                addedBundledEmitReference = isBundledEmit;\n            }\n        }", "label": 3}
{"code": "public static base_responses add(nitro_service client, dnspolicylabel resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdnspolicylabel addresources[] = new dnspolicylabel[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new dnspolicylabel();\n\t\t\t\taddresources[i].labelname = resources[i].labelname;\n\t\t\t\taddresources[i].transform = resources[i].transform;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function confirm_select($nowait = false)\n    {\n        list($class_id, $method_id, $args) = $this->protocolWriter->confirmSelect($nowait);\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        if ($nowait) {\n            return null;\n        }\n\n        $this->wait(array(\n            $this->waitHelper->get_wait('confirm.select_ok')\n        ), false, $this->channel_rpc_timeout);\n        $this->next_delivery_tag = 1;\n    }", "label": 2}
{"code": "func CreateHTTPDownload(req HTTPTransferRequest) (Command, error) {\n\t_, filename, err := req.parseRemoteLocation()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tflags := Flags{\n\t\tTarget: []string{filename},\n\t}\n\n\tcfg := Config{\n\t\tFlags:          flags,\n\t\tUser:           req.User,\n\t\tProgressWriter: req.Progress,\n\t\tRemoteLocation: req.RemoteLocation,\n\t\tFileSystem: &httpFileSystem{\n\t\t\twriter: req.HTTPResponse,\n\t\t},\n\t}\n\n\tcmd, err := CreateDownloadCommand(cfg)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn cmd, nil\n}", "label": 5}
{"code": "private void addTable(TableDef table)\r\n    {\r\n        table.setOwner(this);\r\n        _tableDefs.put(table.getName(), table);\r\n    }", "label": 0}
{"code": "function offListeners(listeners, event, callback)\n  {\n    if (listeners && event in listeners)\n    {\n      var eventListeners = listeners[ event ];\n      var next, node = eventListeners.next;\n\n      while (node !== eventListeners)\n      {\n        next = node.next;\n\n        if (node.callback === callback)\n        {\n          node.remove();\n        }\n\n        node = next;\n      }\n    }\n  }", "label": 3}
{"code": "public Organization getModuleOrganization(final String moduleName, final String moduleVersion) throws GrapesCommunicationException {\n        final Client client = getClient();\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.getModuleOrganizationPath(moduleName, moduleVersion));\n        final ClientResponse response = resource\n                .accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);\n\n        client.destroy();\n        if(ClientResponse.Status.OK.getStatusCode() != response.getStatus()){\n            final String message = \"Failed to get module's organization\";\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n\n        return response.getEntity(Organization.class);\n\n    }", "label": 0}
{"code": "func NewHTTPHandler(c libnetwork.NetworkController) func(w http.ResponseWriter, req *http.Request) {\n\th := &httpHandler{c: c}\n\th.initRouter()\n\treturn h.handleRequest\n}", "label": 5}
{"code": "func UnmarshalReverseTunnel(data []byte, opts ...MarshalOption) (ReverseTunnel, error) {\n\tif len(data) == 0 {\n\t\treturn nil, trace.BadParameter(\"missing tunnel data\")\n\t}\n\tvar h ResourceHeader\n\terr := json.Unmarshal(data, &h)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tswitch h.Version {\n\tcase \"\":\n\t\tvar r ReverseTunnelV1\n\t\terr := json.Unmarshal(data, &r)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tv2 := r.V2()\n\t\tif cfg.ID != 0 {\n\t\t\tv2.SetResourceID(cfg.ID)\n\t\t}\n\t\treturn r.V2(), nil\n\tcase V2:\n\t\tvar r ReverseTunnelV2\n\t\tif cfg.SkipValidation {\n\t\t\tif err := utils.FastUnmarshal(data, &r); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t} else {\n\t\t\tif err := utils.UnmarshalWithSchema(GetReverseTunnelSchema(), &r, data); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t}\n\t\tif err := r.CheckAndSetDefaults(); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tif cfg.ID != 0 {\n\t\t\tr.SetResourceID(cfg.ID)\n\t\t}\n\t\tif !cfg.Expires.IsZero() {\n\t\t\tr.SetExpiry(cfg.Expires)\n\t\t}\n\t\treturn &r, nil\n\t}\n\treturn nil, trace.BadParameter(\"reverse tunnel version %v is not supported\", h.Version)\n}", "label": 5}
{"code": "def get_path_suggestions path\n      return [] if path.nil?\n      result = []\n      result.concat store.get_path_pins(path)\n      # if result.empty?\n      #   lp = live_map.get_path_pin(path)\n      #   result.push lp unless lp.nil?\n      # end\n      resolve_method_aliases(result)\n    end", "label": 4}
{"code": "func (cp *ClientProfile) SaveTo(loc ProfileLocation) error {\n\tbytes, err := yaml.Marshal(&cp)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err = ioutil.WriteFile(loc.Path, bytes, 0660); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif loc.AliasPath != \"\" && filepath.Base(loc.AliasPath) != filepath.Base(loc.Path) {\n\t\tif err := os.Remove(loc.AliasPath); err != nil {\n\t\t\tlog.Warningf(\"Failed to remove symlink alias: %v\", err)\n\t\t}\n\t\terr := os.Symlink(filepath.Base(loc.Path), loc.AliasPath)\n\t\tif err != nil {\n\t\t\tlog.Warningf(\"Failed to create profile alias: %v\", err)\n\t\t}\n\t}\n\t// set 'current' symlink:\n\tif loc.Options&ProfileMakeCurrent != 0 {\n\t\tsymlink := filepath.Join(filepath.Dir(loc.Path), CurrentProfileSymlink)\n\t\tif err := os.Remove(symlink); err != nil {\n\t\t\tlog.Warningf(\"Failed to remove symlink: %v\", err)\n\t\t}\n\t\terr = os.Symlink(filepath.Base(loc.Path), symlink)\n\t}\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def lines_to_display(full_trace)\n      ActiveRecordQueryTrace.lines.zero? ? full_trace : full_trace.first(ActiveRecordQueryTrace.lines)\n    end", "label": 4}
{"code": "public static base_responses clear(nitro_service client, route6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\troute6 clearresources[] = new route6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tclearresources[i] = new route6();\n\t\t\t\tclearresources[i].routetype = resources[i].routetype;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, clearresources,\"clear\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def reindex(pid_type):\n    \"\"\"Reindex all records.\n\n    :param pid_type: Pid type.\n    \"\"\"\n    click.secho('Sending records to indexing queue ...', fg='green')\n\n    query = (x[0] for x in PersistentIdentifier.query.filter_by(\n        object_type='rec', status=PIDStatus.REGISTERED\n    ).filter(\n        PersistentIdentifier.pid_type.in_(pid_type)\n    ).values(\n        PersistentIdentifier.object_uuid\n    ))\n    RecordIndexer().bulk_index(query)\n    click.secho('Execute \"run\" command to process the queue!',\n                fg='yellow')", "label": 1}
{"code": "public static ComplexNumber Divide(ComplexNumber z1, ComplexNumber z2) {\r\n\r\n        ComplexNumber conj = ComplexNumber.Conjugate(z2);\r\n\r\n        double a = z1.real * conj.real + ((z1.imaginary * conj.imaginary) * -1);\r\n        double b = z1.real * conj.imaginary + (z1.imaginary * conj.real);\r\n\r\n        double c = z2.real * conj.real + ((z2.imaginary * conj.imaginary) * -1);\r\n\r\n        return new ComplexNumber(a / c, b / c);\r\n    }", "label": 0}
{"code": "def check_update(from_currency, to_currency):\n\t\"\"\" check if last update is over 30 mins ago. if so return True to update, else False \"\"\"\n\tif from_currency not in ccache: # if currency never get converted before\n\t\tccache[from_currency] = {}\n\tif ccache[from_currency].get(to_currency) is None:\n\t\tccache[from_currency][to_currency] = {'last_update': 0}\n\tlast_update = float(ccache[from_currency][to_currency]['last_update'])\n\tif time.time() - last_update >= 30 * 60: # if last update is more than 30 min ago\n\t\treturn True\n\treturn False", "label": 1}
{"code": "function _gpfRequireLoad (name) {\n    var me = this;\n    return _gpfLoadOrPreload(me, name)\n        .then(function (content) {\n            return me.preprocess({\n                name: name,\n                content: content,\n                type: _gpfPathExtension(name).toLowerCase()\n            });\n        })\n        .then(function (resource) {\n            return _gpfLoadGetProcessor(resource).call(me, resource.name, resource.content);\n        });\n}", "label": 3}
{"code": "public ManagedConnection createManagedConnection(Subject subject, ConnectionRequestInfo info)\r\n\t{\r\n\t\tUtil.log(\"In OTMJCAManagedConnectionFactory.createManagedConnection\");\r\n\t\ttry\r\n\t\t{\r\n\t\t\tKit kit = getKit();\r\n\t\t\tPBKey key = ((OTMConnectionRequestInfo) info).getPbKey();\r\n\t\t\tOTMConnection connection = kit.acquireConnection(key);\r\n\t\t\treturn new OTMJCAManagedConnection(this, connection, key);\r\n\t\t}\r\n\t\tcatch (ResourceException e)\r\n\t\t{\r\n\t\t\tthrow new OTMConnectionRuntimeException(e.getMessage());\r\n\t\t}\r\n\t}", "label": 0}
{"code": "function WrappedUnionType(attrs, opts) {\n  UnionType.call(this, attrs, opts);\n\n  this._constructors = this._types.map(function (type) {\n    // jshint -W054\n    var name = type.getName(true);\n    if (name === 'null') {\n      return null;\n    }\n\n    function ConstructorFunction(name) {\n      return function Branch$(val) {\n        this[`${name}`] = val;\n      }\n    }\n    var constructor = ConstructorFunction(name);\n    constructor.getBranchType = function() { return type; };\n    return constructor;\n  });\n}", "label": 3}
{"code": "public static base_response add(nitro_service client, autoscaleprofile resource) throws Exception {\n\t\tautoscaleprofile addresource = new autoscaleprofile();\n\t\taddresource.name = resource.name;\n\t\taddresource.type = resource.type;\n\t\taddresource.url = resource.url;\n\t\taddresource.apikey = resource.apikey;\n\t\taddresource.sharedsecret = resource.sharedsecret;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "func (o HostNetworkSystem) UpdatePhysicalNicLinkSpeed(ctx context.Context, device string, linkSpeed *types.PhysicalNicLinkInfo) error {\n\treq := types.UpdatePhysicalNicLinkSpeed{\n\t\tThis:      o.Reference(),\n\t\tDevice:    device,\n\t\tLinkSpeed: linkSpeed,\n\t}\n\n\t_, err := methods.UpdatePhysicalNicLinkSpeed(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def _move(self):\n        \"\"\"\n        Called during a PUT request where the action specifies\n        a move operation. Returns resource URI of the destination file.\n        \"\"\"\n        newpath = self.action['newpath']\n        try:\n            self.fs.move(self.fp,newpath)\n        except OSError:\n            raise tornado.web.HTTPError(400)\n        return newpath", "label": 1}
{"code": "public static base_responses add(nitro_service client, nsacl6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnsacl6 addresources[] = new nsacl6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new nsacl6();\n\t\t\t\taddresources[i].acl6name = resources[i].acl6name;\n\t\t\t\taddresources[i].acl6action = resources[i].acl6action;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t\taddresources[i].srcipv6 = resources[i].srcipv6;\n\t\t\t\taddresources[i].srcipop = resources[i].srcipop;\n\t\t\t\taddresources[i].srcipv6val = resources[i].srcipv6val;\n\t\t\t\taddresources[i].srcport = resources[i].srcport;\n\t\t\t\taddresources[i].srcportop = resources[i].srcportop;\n\t\t\t\taddresources[i].srcportval = resources[i].srcportval;\n\t\t\t\taddresources[i].destipv6 = resources[i].destipv6;\n\t\t\t\taddresources[i].destipop = resources[i].destipop;\n\t\t\t\taddresources[i].destipv6val = resources[i].destipv6val;\n\t\t\t\taddresources[i].destport = resources[i].destport;\n\t\t\t\taddresources[i].destportop = resources[i].destportop;\n\t\t\t\taddresources[i].destportval = resources[i].destportval;\n\t\t\t\taddresources[i].ttl = resources[i].ttl;\n\t\t\t\taddresources[i].srcmac = resources[i].srcmac;\n\t\t\t\taddresources[i].protocol = resources[i].protocol;\n\t\t\t\taddresources[i].protocolnumber = resources[i].protocolnumber;\n\t\t\t\taddresources[i].vlan = resources[i].vlan;\n\t\t\t\taddresources[i].Interface = resources[i].Interface;\n\t\t\t\taddresources[i].established = resources[i].established;\n\t\t\t\taddresources[i].icmptype = resources[i].icmptype;\n\t\t\t\taddresources[i].icmpcode = resources[i].icmpcode;\n\t\t\t\taddresources[i].priority = resources[i].priority;\n\t\t\t\taddresources[i].state = resources[i].state;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def dedup_source_list(sources)\n      sources = sources.uniq\n      wild_sources = sources.select { |source| source =~ STAR_REGEXP }\n\n      if wild_sources.any?\n        sources.reject do |source|\n          !wild_sources.include?(source) &&\n            wild_sources.any? { |pattern| File.fnmatch(pattern, source) }\n        end\n      else\n        sources\n      end\n    end", "label": 4}
{"code": "@SuppressWarnings(\"unchecked\")\n    public static <T> T convert(Object fromValue, Class<T> toType) throws TypeCastException {\n        return convert(fromValue, toType, (String) null);\n    }", "label": 0}
{"code": "def _discovery_resp(self, data):\n        \"\"\" Handle a discovery response.\n\n        :param data: Payload.\n        :param addr: Address tuple.\n        :returns: MAC and reversed MAC.\n        \"\"\"\n        if _is_discovery_response(data):\n            _LOGGER.debug(\"Discovered MAC of %s: %s\", self.host,\n                          binascii.hexlify(data[7:13]).decode())\n            return (data[7:13], data[19:25])", "label": 1}
{"code": "function writable(file) {\n  if (!exists(file)) {\n    return writable(path.dirname(file));\n  } else {\n    try {\n      fs.accessSync(file, fs.W_OK);\n    } catch (e) {\n      return false;\n    }\n    return true;\n  }\n}", "label": 3}
{"code": "def parse_multipart(boundary, body)\n      reader = MultipartParser::Reader.new(boundary)\n      result = { errors: [], parts: [] }\n      def result.part(name)\n        hash = self[:parts].detect { |h| h[:part].name == name }\n        [hash[:part], hash[:body].join]\n      end\n\n      reader.on_part do |part|\n        result[:parts] << thispart = {\n          part: part,\n          body: []\n        }\n        part.on_data do |chunk|\n          thispart[:body] << chunk\n        end\n      end\n      reader.on_error do |msg|\n        result[:errors] << msg\n      end\n      reader.write(body)\n      result\n    end", "label": 4}
{"code": "def delete(*args)\n      raise_authentication_error unless authenticated?\n      arguments(args, required: [:id])\n\n      delete_request(\"/authorizations/#{arguments.id}\", arguments.params)\n    end", "label": 4}
{"code": "public function handleData($data, $conn) {\n        try {\n            $this->app->onMessage($conn->decor, $data);\n        } catch (\\Exception $e) {\n            $this->handleError($e, $conn);\n        }\n    }", "label": 2}
{"code": "func AddTerminfo(t *Terminfo) {\n\tdblock.Lock()\n\tterminfos[t.Name] = t\n\tfor _, x := range t.Aliases {\n\t\tterminfos[x] = t\n\t}\n\tdblock.Unlock()\n}", "label": 5}
{"code": "public static String trim(String s, int maxWidth) {\r\n    if (s.length() <= maxWidth) {\r\n      return (s);\r\n    }\r\n    return (s.substring(0, maxWidth));\r\n  }", "label": 0}
{"code": "def category=(channel)\n      channel = @bot.channel(channel)\n      raise ArgumentError, 'Cannot set parent category to a channel that isn\\'t a category' unless channel.category?\n\n      update_channel_data(parent_id: channel.id)\n    end", "label": 4}
{"code": "public function setSparkJob($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1\\SparkJob::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function setColumnRangeFilter($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\ColumnRange::class);\n        $this->writeOneof(7, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function(file, options, callback) {\n        var lines;\n        fs.readFile(file, options, function(err, data) {\n            if (err) {\n                //err\n                return callback(err);\n            }\n            if (/\\r\\n/.test(data.toString())) {\n                lines = data.toString().split('\\r\\n');\n            } else {\n                lines = data.toString().split('\\n');\n            }\n            if (module.exports.verify(lines[0])) {\n                callback(undefined, lines);\n            } else {\n                callback(\"INVALID_SCC_FORMAT\");\n            }\n        });\n    }", "label": 3}
{"code": "func (r RoleMapping) Equals(o RoleMapping) bool {\n\tif r.Remote != o.Remote {\n\t\treturn false\n\t}\n\tif !utils.StringSlicesEqual(r.Local, r.Local) {\n\t\treturn false\n\t}\n\treturn true\n}", "label": 5}
{"code": "function endOperation(cm) {\n    var op = cm.curOp, group = op.ownsGroup;\n    if (!group) return;\n\n    try { fireCallbacksForOps(group); }\n    finally {\n      operationGroup = null;\n      for (var i = 0; i < group.ops.length; i++)\n        group.ops[i].cm.curOp = null;\n      endOperations(group);\n    }\n  }", "label": 3}
{"code": "func (c *remoteConn) OpenChannel(name string, data []byte) (ssh.Channel, error) {\n\tchannel, _, err := c.sconn.OpenChannel(name, data)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn channel, nil\n}", "label": 5}
{"code": "public static lbvserver_dnspolicy64_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_dnspolicy64_binding obj = new lbvserver_dnspolicy64_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_dnspolicy64_binding response[] = (lbvserver_dnspolicy64_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getContrastColor(bgColor, colors) {\n  // We set a rather high cutoff to prefer light text if possible.\n  const cutoff = 0.74;\n\n  // Calculate the perceived luminosity (relative brightness) of the color.\n  const perceivedLuminosity = Color(bgColor).luminosity();\n\n  return perceivedLuminosity >= cutoff ? colors.dark : colors.light;\n}", "label": 3}
{"code": "def load_file(yamlfile)\n      file_queue = [File.expand_path(yamlfile)]\n      loaded_files = {}\n      yaml = {}\n\n      loop do\n        # Check exit condition\n        return yaml if file_queue.empty?\n\n        current_file = file_queue.shift\n        current_yaml = YAML.load_file(current_file)\n        yaml = current_yaml.deep_merge(yaml)\n\n        next unless yaml.key?('inherit')\n\n        buf = []\n        yaml['inherit'].reverse_each do |item|\n          inherit_file = File.expand_path(item, File.dirname(yamlfile))\n\n          # Check loop\n          if loaded_files[inherit_file]\n            raise \"Found circular YAML inheritance '#{inherit_file}' in #{yamlfile}.\"\n          end\n\n          loaded_files[inherit_file] = true\n          buf << inherit_file\n        end\n        yaml.delete('inherit')\n        file_queue = buf + file_queue\n      end\n    end", "label": 4}
{"code": "@SuppressWarnings(\"unchecked\")\n\tprivate void addParameters(Model model, HttpServletRequest request) {\n\t\tfor (Object objectEntry : request.getParameterMap().entrySet()) {\n\t\t\tMap.Entry<String, String[]> entry = (Map.Entry<String, String[]>) objectEntry;\n\t\t\tString key = entry.getKey();\n\t\t\tString[] values = entry.getValue();\n\t\t\tif (null != values && values.length > 0) {\n\t\t\t\tString value  = values[0];\n\t\t\t\ttry {\n\t\t\t\t\tmodel.addAttribute(key, getParameter(key, value));\n\t\t\t\t} catch (ParseException pe) {\n\t\t\t\t\tlog.error(\"Could not parse parameter value {} for {}, ignoring parameter.\", key, value);\n\t\t\t\t} catch (NumberFormatException nfe) {\n\t\t\t\t\tlog.error(\"Could not parse parameter value {} for {}, ignoring parameter.\", key, value);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "label": 0}
{"code": "def manifest_metadata\n      metadata = []\n      Hyrax.config.iiif_metadata_fields.each do |field|\n        metadata << {\n          'label' => I18n.t(\"simple_form.labels.defaults.#{field}\"),\n          'value' => Array.wrap(send(field).map { |f| Loofah.fragment(f.to_s).scrub!(:whitewash).to_s })\n        }\n      end\n      metadata\n    end", "label": 4}
{"code": "def generate(env):\n   \"\"\"\n   Add builders and construction variables for the\n   Doxygen tool.  This is currently for Doxygen 1.4.6.\n   \"\"\"\n   doxyfile_scanner = env.Scanner(\n      DoxySourceScan,\n      \"DoxySourceScan\",\n      scan_check = DoxySourceScanCheck,\n   )\n\n   import SCons.Builder\n   doxyfile_builder = SCons.Builder.Builder(\n      action = \"cd ${SOURCE.dir}  &&  ${DOXYGEN} ${SOURCE.file}\",\n      emitter = DoxyEmitter,\n      target_factory = env.fs.Entry,\n      single_source = True,\n      source_scanner =  doxyfile_scanner,\n   )\n\n   env.Append(BUILDERS = {\n      'Doxygen': doxyfile_builder,\n   })\n\n   env.AppendUnique(\n      DOXYGEN = 'doxygen',\n   )", "label": 1}
{"code": "private function getValue()\n    {\n        $database = 0;\n        $client = null;\n        $event = $this->client->getConnection()->read();\n\n        $callback = function ($matches) use (&$database, &$client) {\n            if (2 === $count = count($matches)) {\n                // Redis <= 2.4\n                $database = (int) $matches[1];\n            }\n\n            if (4 === $count) {\n                // Redis >= 2.6\n                $database = (int) $matches[2];\n                $client = $matches[3];\n            }\n\n            return ' ';\n        };\n\n        $event = preg_replace_callback('/ \\(db (\\d+)\\) | \\[(\\d+) (.*?)\\] /', $callback, $event, 1);\n        @list($timestamp, $command, $arguments) = explode(' ', $event, 3);\n\n        return (object) array(\n            'timestamp' => (float) $timestamp,\n            'database' => $database,\n            'client' => $client,\n            'command' => substr($command, 1, -1),\n            'arguments' => $arguments,\n        );\n    }", "label": 2}
{"code": "public static function unregisterProcessor($processor)\n    {\n        $processors = &self::processors();\n        $key = array_search($processor, $processors, true);\n        if ($key === false) {\n            throw new Exception('Given processor was not registered');\n        }\n        unset($processors[$key]);\n    }", "label": 2}
{"code": "def transaction\n      raise 'This method requires a block' unless block_given?\n      begin_transaction\n      yield\n      commit_transaction\n    rescue Kafka::Producer::AbortTransaction\n      abort_transaction\n    rescue\n      abort_transaction\n      raise\n    end", "label": 4}
{"code": "public static appfwglobal_auditnslogpolicy_binding[] get(nitro_service service) throws Exception{\n\t\tappfwglobal_auditnslogpolicy_binding obj = new appfwglobal_auditnslogpolicy_binding();\n\t\tappfwglobal_auditnslogpolicy_binding response[] = (appfwglobal_auditnslogpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getEntityCollectionName(Entity) {\n  expect(arguments).to.have.length(\n    1,\n    'Invalid arguments length when getting the collection name of an Entity ' +\n    'class (it has to be passed 1 argument)'\n  );\n\n  expect(Entity).to.be.a(\n    'function',\n    'Invalid argument \"Entity\" when getting the collection name of an ' +\n    'Entity (it has to be an Entity class)'\n  );\n\n  expect(classes.isGeneral(entity.models.Entity, Entity)).to.equal(\n    true,\n    'Invalid argument \"Entity\" when getting the collection name of an ' +\n    'Entity (it has to be an Entity class)'\n  );\n\n  while (\n    Entity.General !== null &&\n    !Entity.General.specification.isAbstract\n    ) {\n    Entity = Entity.General;\n  }\n\n  return Entity.dataName;\n}", "label": 3}
{"code": "protected function addTablePrefix($query, $column)\n    {\n        if (strpos($column, '.') === false) {\n            $q = $this->getBaseQueryBuilder($query);\n            if (! $q->from instanceof Expression) {\n                $column = $q->from . '.' . $column;\n            }\n        }\n\n        return $this->wrap($column);\n    }", "label": 2}
{"code": "function createLogger(fn) {\n\treturn function () {\n\t\tvar args = [],\n\t\t\tself = this,\n\t\t\tc;\n\t\tfor (c = 0; c < arguments.length; c++) {\n\t\t\targs[c] = logger.specialObjectClone(arguments[c]);\n\t\t}\n\t\treturn fn.apply(self, args);\n\t};\n}", "label": 3}
{"code": "protected function dissectPhone()\n  {\n      if (($handle = fopen(dirname(__FILE__).'/countries.csv', 'rb')) !== false) {\n          while (($data = fgetcsv($handle, 1000)) !== false) {\n              if (strpos($this->phoneNumber, $data[1]) === 0) {\n                  // Return the first appearance.\n                  fclose($handle);\n\n                  $mcc = explode('|', $data[2]);\n                  $mcc = $mcc[0];\n\n                  //hook:\n                  //fix country code for North America\n                  if ($data[1][0] == '1') {\n                      $data[1] = '1';\n                  }\n\n                  $phone = [\n                      'country' => $data[0],\n                      'cc'      => $data[1],\n                      'phone'   => substr($this->phoneNumber, strlen($data[1]), strlen($this->phoneNumber)),\n                      'mcc'     => $mcc,\n                      'ISO3166' => @$data[3],\n                      'ISO639'  => @$data[4],\n                      'mnc'     => $data[5],\n                  ];\n\n                  $this->eventManager()->fire('onDissectPhone',\n                      [\n                          $this->phoneNumber,\n                          $phone['country'],\n                          $phone['cc'],\n                          $phone['phone'],\n                          $phone['mcc'],\n                          $phone['ISO3166'],\n                          $phone['ISO639'],\n                          $phone['mnc'],\n                      ]\n                  );\n\n                  return $phone;\n              }\n          }\n          fclose($handle);\n      }\n\n      $this->eventManager()->fire('onDissectPhoneFailed',\n          [\n              $this->phoneNumber,\n          ]);\n\n      return false;\n  }", "label": 2}
{"code": "function (pos) {\n                if (this._choice) {\n                    if (undefined === pos) {\n                        pos = this._items.length - 1;\n                    }\n                    return this._items[pos];\n                }\n                return this._items;\n            }", "label": 3}
{"code": "func (r *Rotation) CheckAndSetDefaults(clock clockwork.Clock) error {\n\tswitch r.Phase {\n\tcase \"\", RotationPhaseRollback, RotationPhaseUpdateClients, RotationPhaseUpdateServers:\n\tdefault:\n\t\treturn trace.BadParameter(\"unsupported phase: %q\", r.Phase)\n\t}\n\tswitch r.Mode {\n\tcase \"\", RotationModeAuto, RotationModeManual:\n\tdefault:\n\t\treturn trace.BadParameter(\"unsupported mode: %q\", r.Mode)\n\t}\n\tswitch r.State {\n\tcase \"\":\n\t\tr.State = RotationStateStandby\n\tcase RotationStateStandby:\n\tcase RotationStateInProgress:\n\t\tif r.CurrentID == \"\" {\n\t\t\treturn trace.BadParameter(\"set 'current_id' parameter for in progress rotation\")\n\t\t}\n\t\tif r.Started.IsZero() {\n\t\t\treturn trace.BadParameter(\"set 'started' parameter for in progress rotation\")\n\t\t}\n\tdefault:\n\t\treturn trace.BadParameter(\n\t\t\t\"unsupported rotation 'state': %q, supported states are: %q, %q\",\n\t\t\tr.State, RotationStateStandby, RotationStateInProgress)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def _is_valid(self, value):\n        \"\"\"Return True if the input value is valid for insertion into the\n        inner list.\n\n        Args:\n            value: An object about to be inserted.\n        \"\"\"\n\n        # Entities have an istypeof method that can perform more sophisticated\n        # type checking.\n        if hasattr(self._type, \"istypeof\"):\n            return self._type.istypeof(value)\n        else:\n            return isinstance(value, self._type)", "label": 1}
{"code": "function setCallback (action, callbackContext = null, callbackText = null) {\n        const callbackAction = this.toAbsoluteAction(action);\n\n        this.setState({\n            [ACTION]: callbackAction,\n            [CONTEXT]: callbackContext || DEFAULT,\n            [TEXT]: callbackText\n        });\n\n        return this;\n    }", "label": 3}
{"code": "public function sendPing()\n    {\n        $msgId = $this->createIqId();\n        $pingNode = new ProtocolNode('ping', null, null, null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'w:p',\n                'type'  => 'get',\n                'to'    => Constants::WHATSAPP_SERVER,\n            ], [$pingNode], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "private function computeScheduleInsertsChangeSets()\n    {\n        foreach ($this->entityInsertions as $entity) {\n            $class = $this->em->getClassMetadata(get_class($entity));\n\n            $this->computeChangeSet($class, $entity);\n        }\n    }", "label": 2}
{"code": "function uniqueMatch(string, regexp) {\n  const results = [];\n  let match;\n\n  while ((match = regexp.exec(string))) {\n    results.push({\n      context: match[0],\n      match: match[1] || ''\n    });\n  }\n\n  // Filter duplicates\n  return unique(results, isEqual);\n}", "label": 3}
{"code": "public boolean contains(Vector3 p) {\n\t\tboolean ans = false;\n\t\tif(this.halfplane || p== null) return false;\n\n\t\tif (isCorner(p)) {\n\t\t\treturn true;\n\t\t}\n\n\t\tPointLinePosition a12 = PointLineTest.pointLineTest(a,b,p);\n\t\tPointLinePosition a23 = PointLineTest.pointLineTest(b,c,p);\n\t\tPointLinePosition a31 = PointLineTest.pointLineTest(c,a,p);\n\n\t\tif ((a12 == PointLinePosition.LEFT && a23 == PointLinePosition.LEFT && a31 == PointLinePosition.LEFT ) ||\n\t\t\t\t(a12 == PointLinePosition.RIGHT && a23 == PointLinePosition.RIGHT && a31 == PointLinePosition.RIGHT ) ||\n\t\t\t\t(a12 == PointLinePosition.ON_SEGMENT ||a23 == PointLinePosition.ON_SEGMENT ||  a31 == PointLinePosition.ON_SEGMENT)) {\n\t\t\tans = true;\n\t\t}\n\n\t\treturn ans;\n\t}", "label": 0}
{"code": "def delete_joined_table_sql(qualified_name, removing_qualified_name, primary_key):\n    \"\"\"SQL statement for a joined delete from.\n    Generate SQL statement for deleting the intersection of rows between\n    both tables from table referenced by tablename.\n    \"\"\"\n\n    condition_template = 't.{}=d.{}'\n    where_clause = ' AND '.join(condition_template.format(pkey, pkey)\n                                for pkey in primary_key)\n    delete_statement = (\n        'DELETE FROM {table} t'\n        ' USING {delete_table} d'\n        ' WHERE {where_clause}').format(table=qualified_name,\n                                        delete_table=removing_qualified_name,\n                                        where_clause=where_clause)\n    return delete_statement", "label": 1}
{"code": "public function getIntDc()\n    {\n        $dc = intval($this->dc);\n        if ($this->test) {\n            $dc += 10000;\n        }\n        if (strpos($this->dc, '_media')) {\n            $dc = -$dc;\n        }\n\n        return $dc;\n    }", "label": 2}
{"code": "def deny_role(role):\n    \"\"\"Deny a role identified by an email address.\"\"\"\n    def processor(action, argument):\n        db.session.add(\n            ActionRoles.deny(action, argument=argument, role_id=role.id)\n        )\n    return processor", "label": 1}
{"code": "def info(self):\n        ''' Returns information on all the registered checkers.\n\n        Sorted by namespace and then name\n        :returns a list of CheckerInfo\n        '''\n        return sorted(self._checkers.values(), key=lambda x: (x.ns, x.name))", "label": 1}
{"code": "public static RgbaColor fromRgba(String rgba) {\n        if (rgba.length() == 0) return getDefaultColor();\n\n        String[] parts = getRgbaParts(rgba).split(\",\");\n        if (parts.length == 4) {\n            return new RgbaColor(parseInt(parts[0]),\n                                 parseInt(parts[1]),\n                                 parseInt(parts[2]),\n                                 parseFloat(parts[3]));\n        }\n        else {\n            return getDefaultColor();\n        }\n    }", "label": 0}
{"code": "public static function withoutRecording($callback)\n    {\n        $shouldRecord = static::$shouldRecord;\n\n        static::$shouldRecord = false;\n\n        call_user_func($callback);\n\n        static::$shouldRecord = $shouldRecord;\n    }", "label": 2}
{"code": "public function setFirstPost(Post $post)\n    {\n        $this->created_at = $post->created_at;\n        $this->user_id = $post->user_id;\n        $this->first_post_id = $post->id;\n\n        return $this;\n    }", "label": 2}
{"code": "public void forAllIndexDescriptorDefinitions(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (Iterator it = _curClassDef.getIndexDescriptors(); it.hasNext(); )\r\n        {\r\n            _curIndexDescriptorDef = (IndexDescriptorDef)it.next();\r\n            generate(template);\r\n        }\r\n        _curIndexDescriptorDef = null;\r\n    }", "label": 0}
{"code": "private void doSend(byte[] msg, boolean wait, KNXAddress dst)\r\n\t\tthrows KNXAckTimeoutException, KNXLinkClosedException\r\n\t{\r\n\t\tif (closed)\r\n\t\t\tthrow new KNXLinkClosedException(\"link closed\");\r\n\t\ttry {\r\n\t\t\tlogger.info(\"send message to \" + dst + (wait ? \", wait for ack\" : \"\"));\r\n\t\t\tlogger.trace(\"EMI \" + DataUnitBuilder.toHex(msg, \" \"));\r\n\t\t\tconn.send(msg, wait);\r\n\t\t\tlogger.trace(\"send to \" + dst + \" succeeded\");\r\n\t\t}\r\n\t\tcatch (final KNXPortClosedException e) {\r\n\t\t\tlogger.error(\"send error, closing link\", e);\r\n\t\t\tclose();\r\n\t\t\tthrow new KNXLinkClosedException(\"link closed, \" + e.getMessage());\r\n\t\t}\r\n\t}", "label": 0}
{"code": "public function getStatus(): bool\n    {\n        foreach ($this->requestVersion() as $key => $version) {\n            if (! Str::contains($key, 'dev')) {\n                continue;\n            }\n\n            if (version_compare($version['version'], $this->currentVersion, '>')) {\n                return true;\n            }\n        }\n\n        return false;\n    }", "label": 2}
{"code": "def ordered_routes\n      length = Proc.new { |r| r.path.length * -1 }\n      capture_routes = routes.select { |r| r.path.include?(':') }.sort_by(&length)\n      wildcard_routes = routes.select { |r| r.path.include?('*') }.sort_by(&length)\n      simple_routes = (routes - capture_routes - wildcard_routes).sort_by(&length)\n      simple_routes + capture_routes + wildcard_routes\n    end", "label": 4}
{"code": "def flush_down_connections(self):\n        \"\"\"\n        Marks all connections which were previously listed as unavailable as being up.\n        \"\"\"\n        self._get_db_attempts = 0\n        for db_num in self._down_connections.keys():\n            self.mark_connection_up(db_num)", "label": 1}
{"code": "public static dos_stats get(nitro_service service,  options option) throws Exception{\n\t\tdos_stats obj = new dos_stats();\n\t\tdos_stats[] response = (dos_stats[])obj.stat_resources(service,option);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def main():\n    \"\"\"\n    script to setup folder structures for AIKIF \n    and prepare data tables.\n    \"\"\"\n    print('\\n\\n /------- AIKIF Installation --------\\\\')\n    print(' |  s. show current setup            |')\n    print(' |  f. setup folder structures       |')\n    print(' |  c. create sample data            |')\n    # not yet - wait for beta release print(' w. wipe data and install everything from scratch')\n    print(' |  q. quit                          |')\n    print(' \\\\-----------------------------------/')\n    cmd = input('?')\n    if cmd == 's':\n        show_setup()   \n    elif cmd == 'f':\n        setup_folders()\n    elif cmd == 'c':\n        create_sample_data()   \n    #elif cmd == 'w':\n    #    wipe_and_rebuild_all()\n    elif cmd == 'q':\n        exit(0)\n    main()", "label": 1}
{"code": "function isEmpty(value) {\n        if (value === null) {\n            return true;\n        }\n\n        var type = typeof(value);\n\n        switch (type) {\n            case 'undefined':\n                return true;\n\n            case 'number':\n                return isNaN(value);\n\n            case 'string':\n                return value.trim() === '';\n\n            case 'object':\n                var countKeys = Object.keys(value).length;\n                return countKeys < 1;\n\n            case 'function':\n            case 'boolean':\n                return false;\n\n            default:\n                console.log('Unknown value type: \"' + type + '\"', 'isEmpty.js');\n                return false;\n        }\n    }", "label": 3}
{"code": "public function getStreamableUploader($data, array $options = [])\n    {\n        if ($this->isObjectNameRequired($data) && !isset($options['name'])) {\n            throw new \\InvalidArgumentException('A name is required when data is of type string or null.');\n        }\n\n        return $this->connection->insertObject(\n            $this->formatEncryptionHeaders($options) + $this->identity + [\n                'data' => $data,\n                'streamable' => true,\n                'validate' => false\n            ]\n        );\n    }", "label": 2}
{"code": "def validate_data_provider(value)\n      if value.is_a?(String)\n        unless value =~ /^[a-zA-Z][a-zA-Z0-9_]*$/\n          if value =~ /^[a-zA-Z]/\n            raise ArgumentError, _(\"field 'data_provider' contains non-alphanumeric characters\")\n          else\n            raise ArgumentError, _(\"field 'data_provider' must begin with a letter\")\n          end\n        end\n      else\n        raise ArgumentError, _(\"field 'data_provider' must be a string\")\n      end\n    end", "label": 4}
{"code": "def pluralized_array_from_hash(hash, singular_key, plural_key)\n      [].tap do |array|\n        value = value_from_singular_key(hash, singular_key)\n        value ||= value_from_plural_key(hash, plural_key)\n        array << value\n      end.flatten.compact\n    end", "label": 4}
{"code": "func importPaths(args []string) []string {\n\targs = importPathsNoDotExpansion(args)\n\tvar out []string\n\tfor _, a := range args {\n\t\tif strings.Contains(a, \"...\") {\n\t\t\tif build.IsLocalImport(a) {\n\t\t\t\tout = append(out, allPackagesInFS(a)...)\n\t\t\t} else {\n\t\t\t\tout = append(out, allPackages(a)...)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tout = append(out, a)\n\t}\n\treturn out\n}", "label": 5}
{"code": "public static policyexpression[] get(nitro_service service, policyexpression_args args) throws Exception{\n\t\tpolicyexpression obj = new policyexpression();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tpolicyexpression[] response = (policyexpression[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function updateMedia(array $newMediaArray, string $collectionName = 'default'): Collection\n    {\n        $this->removeMediaItemsNotPresentInArray($newMediaArray, $collectionName);\n\n        return collect($newMediaArray)\n            ->map(function (array $newMediaItem) use ($collectionName) {\n                static $orderColumn = 1;\n\n                $mediaClass = config('medialibrary.media_model');\n                $currentMedia = $mediaClass::findOrFail($newMediaItem['id']);\n\n                if ($currentMedia->collection_name !== $collectionName) {\n                    throw MediaCannotBeUpdated::doesNotBelongToCollection($collectionName, $currentMedia);\n                }\n\n                if (array_key_exists('name', $newMediaItem)) {\n                    $currentMedia->name = $newMediaItem['name'];\n                }\n\n                if (array_key_exists('custom_properties', $newMediaItem)) {\n                    $currentMedia->custom_properties = $newMediaItem['custom_properties'];\n                }\n\n                $currentMedia->order_column = $orderColumn++;\n\n                $currentMedia->save();\n\n                return $currentMedia;\n            });\n    }", "label": 2}
{"code": "public function getName(): string\n    {\n        $string = $this->getStringUri();\n        if ($this->isSecure()) {\n            $string .= ' (TLS)';\n        }\n        $string .= ' DC ';\n        $string .= $this->getDc();\n        $string .= ', via ';\n        $string .= $this->getIpv6() ? 'ipv6' : 'ipv4';\n        $string .= ' using ';\n        foreach (array_reverse($this->nextStreams) as $k => $stream) {\n            if ($k) {\n                $string .= ' => ';\n            }\n            $string .= preg_replace('/.*\\\\\\\\/', '', $stream[0]);\n            if ($stream[1]) {\n                $string .= ' ('.json_encode($stream[1]).')';\n            }\n        }\n\n        return $string;\n    }", "label": 2}
{"code": "def transition_running_state(target_state)\n      state_transitions = {\n        not_started: :running,\n        running: :stopping,\n        stopping: :stopped\n      }\n      if state_transitions[@running_state] == target_state\n        @running_state = target_state\n      else\n        fail \"Bad server state transition: #{@running_state}->#{target_state}\"\n      end\n    end", "label": 4}
{"code": "public function beginRecognizeOperation($audio, array $options = [])\n    {\n        $response = $this->connection->longRunningRecognize(\n            $this->formatRequest($audio, $options)\n        );\n\n        return new Operation(\n            $this->connection,\n            $response['name'],\n            $response\n        );\n    }", "label": 2}
{"code": "def initialize(self,*args,**kwargs):\n        \"\"\"\n        Only try to parse as JSON if the JSON content type\n        header is set.\n        \"\"\"\n        super(JSONHandler,self).initialize(*args,**kwargs)\n        content_type = self.request.headers.get('Content-Type', '')\n        if 'application/json' in content_type.lower():\n            self._parse_json_body_arguments()", "label": 1}
{"code": "private String computeTypeFromMappingSource(String source)\n      throws MtasParserException {\n    if (source.equals(MtasParserMapping.SOURCE_OWN)) {\n      return null;\n    } else if (source.equals(MtasParserMapping.SOURCE_ANCESTOR_GROUP)) {\n      return MAPPING_TYPE_GROUP;\n    } else if (source\n        .equals(MtasParserMapping.SOURCE_ANCESTOR_GROUP_ANNOTATION)) {\n      return MAPPING_TYPE_GROUP_ANNOTATION;\n    } else if (source.equals(MtasParserMapping.SOURCE_ANCESTOR_WORD)) {\n      return MAPPING_TYPE_WORD;\n    } else if (source\n        .equals(MtasParserMapping.SOURCE_ANCESTOR_WORD_ANNOTATION)) {\n      return MAPPING_TYPE_WORD_ANNOTATION;\n    } else if (source.equals(MtasParserMapping.SOURCE_ANCESTOR_RELATION)) {\n      return MAPPING_TYPE_RELATION;\n    } else if (source\n        .equals(MtasParserMapping.SOURCE_ANCESTOR_RELATION_ANNOTATION)) {\n      return MAPPING_TYPE_RELATION_ANNOTATION;\n    } else {\n      throw new MtasParserException(\"unknown source \" + source);\n    }\n  }", "label": 0}
{"code": "function(values, keys)\n  {\n    var valuesResolver = createPropertyResolver( values );\n\n    if ( keys )\n    {\n      var keysResolver = createPropertyResolver( keys );\n      var result = {};\n\n      for (var i = 0; i < this.length; i++)\n      {\n        var model = this[ i ];\n        var value = valuesResolver( model );\n        var key = keysResolver( model );\n\n        result[ key ] = value;\n      }\n\n      return result;\n    }\n    else\n    {\n      var result = [];\n\n      for (var i = 0; i < this.length; i++)\n      {\n        var model = this[ i ];\n        var value = valuesResolver( model );\n\n        result.push( value );\n      }\n\n      return result;\n    }\n  }", "label": 3}
{"code": "public function route($name, $parameters = [])\n    {\n        $path = $this->routes->getPath($name, $parameters);\n        $path = ltrim($path, '/');\n\n        return $this->baseUrl.'/'.$path;\n    }", "label": 2}
{"code": "protected static function targetsFor($job)\n    {\n        switch (true) {\n            case $job instanceof BroadcastEvent:\n                return [$job->event];\n            case $job instanceof CallQueuedListener:\n                return [static::extractEvent($job)];\n            case $job instanceof SendQueuedMailable:\n                return [$job->mailable];\n            case $job instanceof SendQueuedNotifications:\n                return [$job->notification];\n            default:\n                return [$job];\n        }\n    }", "label": 2}
{"code": "func NewClientConnWithDeadline(conn net.Conn, addr string, config *ssh.ClientConfig) (*ssh.Client, error) {\n\tif config.Timeout > 0 {\n\t\tconn.SetReadDeadline(time.Now().Add(config.Timeout))\n\t}\n\tc, chans, reqs, err := ssh.NewClientConn(conn, addr, config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif config.Timeout > 0 {\n\t\tconn.SetReadDeadline(time.Time{})\n\t}\n\treturn ssh.NewClient(c, chans, reqs), nil\n}", "label": 5}
{"code": "function customOverrider (a, b, propertyName) {\n  if (b == null) {\n    return a\n  }\n\n  if (a == null) {\n    // Invoke default overrider\n    return undefined\n  }\n\n  // Some objects have custom overriders\n  if (b._customize_custom_overrider && b._customize_custom_overrider instanceof Function) {\n    return b._customize_custom_overrider(a, b, propertyName)\n  }\n\n  // Arrays should be concatenated\n  if (Array.isArray(a)) {\n    return a.concat(b)\n  }\n\n  // Merge values resolving promises, if they are not leaf-promises\n  if (isPromiseAlike(a) || isPromiseAlike(b)) {\n    return Promise.all([a, b]).then(function ([_a, _b]) {\n      // Merge the promise results\n      return mergeWith({}, { x: _a }, { x: _b }, customOverrider).x\n    })\n  }\n  // None of these options apply. Implicit \"undefined\" return value to invoke default overrider.\n}", "label": 3}
{"code": "function _gpfFunc (params, source) {\n    if (undefined === source) {\n        return _gpfFuncImpl([], params);\n    }\n    return _gpfFuncImpl(params, source);\n}", "label": 3}
{"code": "public void remove(Object pKey)\r\n    {\r\n        Identity id;\r\n        if(pKey instanceof Identity)\r\n        {\r\n            id = (Identity) pKey;\r\n        }\r\n        else\r\n        {\r\n            id = transaction.getBroker().serviceIdentity().buildIdentity(pKey);\r\n        }\r\n        mhtObjectEnvelopes.remove(id);\r\n        mvOrderOfIds.remove(id);\r\n    }", "label": 0}
{"code": "public static authenticationlocalpolicy_authenticationvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationlocalpolicy_authenticationvserver_binding obj = new authenticationlocalpolicy_authenticationvserver_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationlocalpolicy_authenticationvserver_binding response[] = (authenticationlocalpolicy_authenticationvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function isSpecial(key) {\n    if (key.length > 1) {\n        return !!exports.specialKeys.filter(function (specialKey) {\n            var pattern = new RegExp(\"^(\" + specialKey + \")(:(\\\\d+(\\\\.\\\\d+)?))?$\", 'g');\n            return pattern.test(key);\n        }).length;\n    }\n    return false;\n}", "label": 3}
{"code": "function getFilesList(path, includes, excludes){\r\n\t\r\n\t// Init default vars values\r\n\tincludes = (includes === undefined || includes == null || includes == '') ? \"**\" : includes;\r\n\texcludes = (excludes === undefined || excludes == null || excludes == '') ? \"\" : excludes;\r\n\t\r\n\tvar fs = project.createDataType(\"fileset\");\r\n\t\r\n\tfs.setDir(new java.io.File(path));\r\n    \r\n\tif(includes != \"\"){\r\n\t\r\n\t\tfs.setIncludes(includes);\r\n\t}\t\r\n    \r\n    if(excludes != \"\"){\r\n    \r\n    \tfs.setExcludes(excludes);\r\n    }    \r\n\r\n    var srcFiles = fs.getDirectoryScanner(project).getIncludedFiles();\r\n    \r\n    var result = [];\r\n    \r\n    for (var i = 0; i<srcFiles.length; i++){\r\n        \r\n    \tresult.push(srcFiles[i]);\r\n    }\r\n    \r\n    return result;\r\n}", "label": 3}
{"code": "def calc_deviation(values, average):\n    \"\"\"\n    Calculate the standard deviation of a list of values\n    @param values: list(float)\n    @param average:\n    @return:\n    \"\"\"\n    size = len(values)\n    if size < 2:\n        return 0\n    calc_sum = 0.0\n\n    for number in range(0, size):\n        calc_sum += math.sqrt((values[number] - average) ** 2)\n    return math.sqrt((1.0 / (size - 1)) * (calc_sum / size))", "label": 1}
{"code": "def toggle_value(request, name):\n    \"\"\"\n    For manual shortcut links to perform toggle actions\n    \"\"\"\n    obj = service.system.namespace.get(name, None)\n    if not obj or service.read_only:\n        raise Http404\n    new_status = obj.status = not obj.status\n    if service.redirect_from_setters:\n        return HttpResponseRedirect(reverse('set_ready', args=(name, new_status)))\n    else:\n        return set_ready(request, name, new_status)", "label": 1}
{"code": "def schedule(*args, &blk)\n      return if blk.nil?\n      @stop_mutex.synchronize do\n        if @stopped\n          GRPC.logger.warn('did not schedule job, already stopped')\n          return\n        end\n        GRPC.logger.info('schedule another job')\n        fail 'No worker threads available' if @ready_workers.empty?\n        worker_queue = @ready_workers.pop\n\n        fail 'worker already has a task waiting' unless worker_queue.empty?\n        worker_queue << [blk, args]\n      end\n    end", "label": 4}
{"code": "private static byte calculateChecksum(byte[] buffer) {\n\t\tbyte checkSum = (byte)0xFF;\n\t\tfor (int i=1; i<buffer.length-1; i++) {\n\t\t\tcheckSum = (byte) (checkSum ^ buffer[i]);\n\t\t}\n\t\tlogger.trace(String.format(\"Calculated checksum = 0x%02X\", checkSum));\n\t\treturn checkSum;\n\t}", "label": 0}
{"code": "function(snippet, parameters, options) {\n      options = opts(this, options);\n      parameters = merge({}, options.params, parameters);\n      options.params = null;\n      options.snippet = null;\n\n      var call_opts = {\n        action: 'run/' + snippet,\n        type: options.method || 'GET',\n        options: options\n      };\n\n      if(call_opts.type === 'GET')\n        call_opts.query = parameters;\n      else {\n        call_opts.data = JSON.stringify(parameters);\n      }\n\n      return new APICall(call_opts);\n    }", "label": 3}
{"code": "public function setTableReference($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\BigQueryTable::class);\n        $this->table_reference = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "protected static BufferedReader createFileReader(String file_name)\n            throws BeastException {\n        try {\n            return new BufferedReader(new FileReader(file_name));\n        } catch (FileNotFoundException e) {\n            Logger logger = Logger.getLogger(MASReader.class.getName());\n            logger.severe(\"ERROR: \" + e.toString());\n            throw new BeastException(\"ERROR: \" + e.toString(), e);\n        }\n    }", "label": 0}
{"code": "function uniqueArrayHelper (val) {\n        var h = {};\n\n        for (var i = 0, l = val.length; i < l; i++) {\n            var key = JSON.stringify(val[i]);\n            if (h[key]) {\n                return false;\n            }\n            h[key] = true;\n        }\n\n        return true;\n    }", "label": 3}
{"code": "def fa2s2b(fastas):\n    \"\"\"\n    convert fastas to s2b dictionary\n    \"\"\"\n    s2b = {}\n    for fa in fastas:\n        for seq in parse_fasta(fa):\n            s = seq[0].split('>', 1)[1].split()[0]\n            s2b[s] = fa.rsplit('/', 1)[-1].rsplit('.', 1)[0]\n    return s2b", "label": 1}
{"code": "func (d Datastore) DownloadFile(ctx context.Context, path string, file string, param *soap.Download) error {\n\tu, p, err := d.downloadTicket(ctx, path, param)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn d.Client().DownloadFile(ctx, file, u, p)\n}", "label": 5}
{"code": "func (of *OVAFile) Find(filename string) (*tar.Header, error) {\n\tfor {\n\t\theader, err := of.tarFile.Next()\n\t\tif err == io.EOF {\n\t\t\treturn nil, err\n\t\t}\n\t\tif header.Name == filename {\n\t\t\treturn header, nil\n\t\t}\n\t}\n}", "label": 5}
{"code": "public function tx_rollback()\n    {\n        $this->send_method_frame(array(90, 30));\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('tx.rollback_ok')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "public static responderpolicylabel_stats[] get(nitro_service service) throws Exception{\n\t\tresponderpolicylabel_stats obj = new responderpolicylabel_stats();\n\t\tresponderpolicylabel_stats[] response = (responderpolicylabel_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def wait_until_present(depr_timeout = nil, timeout: nil, interval: nil, message: nil)\n      timeout = depr_timeout if depr_timeout\n      Watir.logger.deprecate \"#{self.class}#wait_until_present\",\n                             \"#{self.class}#wait_until(&:present?)\",\n                             ids: [:wait_until_present]\n\n      message ||= proc { |obj| \"waiting for #{obj.inspect} to become present\" }\n      wait_until(timeout: timeout, interval: interval, message: message, element_reset: true, &:present?)\n    end", "label": 4}
{"code": "def b(s):\n    \"\"\"Conversion to bytes\"\"\"\n    if sys.version < '3':\n        if isinstance(s, unicode): #pylint: disable=undefined-variable\n            return s.encode('utf-8')\n    else:\n        return s", "label": 1}
{"code": "def parse_symbol attr_name, xpath\n      v = parse_value xpath\n      v = v.to_sym unless v.nil?\n      send(\"#{attr_name}=\", v)\n    end", "label": 4}
{"code": "func getNetworks(p *pkgPod.Pod) []*v1alpha.Network {\n\tvar networks []*v1alpha.Network\n\tfor _, n := range p.Nets {\n\t\tnetworks = append(networks, &v1alpha.Network{\n\t\t\tName: n.NetName,\n\t\t\t// There will be IPv6 support soon so distinguish between v4 and v6\n\t\t\tIpv4: n.IP.String(),\n\t\t})\n\t}\n\treturn networks\n}", "label": 5}
{"code": "def register(self, uri, prefix):\n        '''Registers the given URI and associates it with the given prefix.\n\n        If the URI has already been registered, this is a no-op.\n\n        :param uri: string\n        :param prefix: string\n        '''\n        if not is_valid_schema_uri(uri):\n            raise KeyError(\n                'cannot register invalid URI {} (prefix {})'.format(\n                    uri, prefix))\n        if not is_valid_prefix(prefix):\n            raise ValueError(\n                'cannot register invalid prefix %q for URI %q'.format(\n                    prefix, uri))\n        if self._uri_to_prefix.get(uri) is None:\n            self._uri_to_prefix[uri] = prefix", "label": 1}
{"code": "def isFinished(self):\n        \"\"\" Is the current episode over?\n        \"\"\"\n        finished = (self.env._step == len(self.env.profile))\n        if finished:\n            logger.info(\"Finished episode.\")\n        return finished", "label": 1}
{"code": "def expires_in(seconds, options = {})\n      response.cache_control.merge!(\n        max_age: seconds,\n        public: options.delete(:public),\n        must_revalidate: options.delete(:must_revalidate),\n        stale_while_revalidate: options.delete(:stale_while_revalidate),\n        stale_if_error: options.delete(:stale_if_error),\n      )\n      options.delete(:private)\n\n      response.cache_control[:extras] = options.map { |k, v| \"#{k}=#{v}\" }\n      response.date = Time.now unless response.date?\n    end", "label": 4}
{"code": "func ReadYAML(reader io.Reader) (interface{}, error) {\n\tdecoder := kyaml.NewYAMLOrJSONDecoder(reader, 32*1024)\n\tvar values []interface{}\n\tfor {\n\t\tvar val interface{}\n\t\terr := decoder.Decode(&val)\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tif len(values) == 0 {\n\t\t\t\t\treturn nil, trace.BadParameter(\"no resources found, empty input?\")\n\t\t\t\t}\n\t\t\t\tif len(values) == 1 {\n\t\t\t\t\treturn values[0], nil\n\t\t\t\t}\n\t\t\t\treturn values, nil\n\t\t\t}\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tvalues = append(values, val)\n\t}\n}", "label": 5}
{"code": "public function setPreference($key, $value)\n    {\n        if (isset(static::$preferences[$key])) {\n            $preferences = $this->preferences;\n\n            if (! is_null($transformer = static::$preferences[$key]['transformer'])) {\n                $preferences[$key] = call_user_func($transformer, $value);\n            } else {\n                $preferences[$key] = $value;\n            }\n\n            $this->preferences = $preferences;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function (checkDictionary) {\n            this._checkDictionary = checkDictionary;\n            var newSources = Object.keys(checkDictionary)\n                .filter(function (name) {\n                    return checkDictionary[name] === \"new\";\n                })\n                .map(function (name) {\n                    return new Source(this, {\n                        name: name,\n                        load: false\n                    }, null);\n                }, this);\n            // Add missing sources after the last loaded one\n            if (newSources.length) {\n                this.sources = this.sources.concat(newSources);\n            }\n        }", "label": 3}
{"code": "public void addBetween(Object attribute, Object value1, Object value2)\r\n    {\r\n\t\t// PAW\r\n\t\t// addSelectionCriteria(ValueCriteria.buildBeweenCriteria(attribute, value1, value2, getAlias()));\r\n\t\taddSelectionCriteria(ValueCriteria.buildBeweenCriteria(attribute, value1, value2, getUserAlias(attribute)));\r\n    }", "label": 0}
{"code": "public static Object instantiate(Class clazz) throws InstantiationException\r\n    {\r\n        Object result = null;\r\n        try\r\n        {\r\n            result = ClassHelper.newInstance(clazz);\r\n        }\r\n        catch(IllegalAccessException e)\r\n        {\r\n            try\r\n            {\r\n                result = ClassHelper.newInstance(clazz, true);\r\n            }\r\n            catch(Exception e1)\r\n            {\r\n                throw new ClassNotPersistenceCapableException(\"Can't instantiate class '\"\r\n                        + (clazz != null ? clazz.getName() : \"null\")\r\n                        + \"', message was: \" + e1.getMessage() + \")\", e1);\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "protected void appendGroupByClause(List groupByFields, StringBuffer buf)\r\n    {\r\n        if (groupByFields == null || groupByFields.size() == 0)\r\n        {\r\n            return;\r\n        }\r\n\r\n        buf.append(\" GROUP BY \");\r\n        for (int i = 0; i < groupByFields.size(); i++)\r\n        {\r\n            FieldHelper cf = (FieldHelper) groupByFields.get(i);\r\n \r\n            if (i > 0)\r\n            {\r\n                buf.append(\",\");\r\n            }\r\n\r\n            appendColName(cf.name, false, null, buf);\r\n        }\r\n    }", "label": 0}
{"code": "def _objectify(field, value, ns_info):\n    \"\"\"Make `value` suitable for a binding object.\n\n    If `value` is an Entity, call to_obj() on it. Otherwise, pass it\n    off to the TypedField for an appropriate value.\n    \"\"\"\n    if (getattr(field.type_, \"_treat_none_as_empty_list\", False) and\n            value is None):\n        return []\n\n    if value is None:\n        return None\n    elif field.type_:\n        return value.to_obj(ns_info=ns_info)\n    return field.binding_value(value)", "label": 1}
{"code": "function ZWritable(options) {\n\tif(options) {\n\t\tif(options.writableObjectMode) {\n\t\t\toptions.objectMode = true;\n\t\t}\n\t\t//Add support for iojs simplified stream constructor\n\t\tif(typeof options.write === 'function') {\n\t\t\tthis._write = options.write;\n\t\t}\n\t\tif(typeof options.flush === 'function') {\n\t\t\tthis._flush = options.flush;\n\t\t}\n\t}\n\tTransform.call(this, options);\n\tstreamMixins.call(this, Transform.prototype, options);\n\twritableMixins.call(this, options);\n\t\n}", "label": 3}
{"code": "function registerPushDevice(registrationId, options) {\n    if (options === void 0) { options = {}; }\n    var user = server.getCurrentAuthorization().name;\n    var pushInitOptions = init.initOptions.push;\n    return device.ready.then(function (info) {\n        var providerType;\n        switch (info.platform.id) {\n            case 'android':\n                providerType = 'GCM';\n                break;\n            case 'ios':\n                // when a senderID is configured,\n                // iOS device is registered at APNS which generates a token registered in turn at GCM,\n                // so that pushes are send using GCM to either type of device.\n                providerType = pushInitOptions.ios.senderID ? 'GCM' : 'APNS';\n                break;\n            case 'windowsphone':\n                providerType = 'WNS';\n                break;\n            case 'blackberry':\n                providerType = 'PAP';\n                break;\n            default:\n                providerType = 'MCAP';\n                break;\n        }\n        diag.debug.assert(!!info.device, 'The current implementation supports mobile devices only!');\n        return {\n            uuid: null,\n            providerType: providerType,\n            token: registrationId,\n            user: user,\n            deviceIdentifier: info.uuid,\n            vendor: info.device.manufacturer,\n            name: info.device.name,\n            osVersion: info.device.version,\n            model: info.device.model,\n            type: info.device.name,\n            appPackageName: info.device.appIdentifier,\n            appVersion: info.device.appVersionCode || info.device.appVersionName,\n            attributes: options.attributes,\n            tags: options.tags,\n            badge: options.badge\n        };\n    }).then(function (device) {\n        diag.debug.assert(device.providerType !== 'PAP', 'Relution Server does not yet support this!');\n        diag.debug.assert(device.providerType !== 'MCAP', 'Relution SDK does not yet implement this!');\n        return web.post(pushUrl + '/registration', device);\n    });\n}", "label": 3}
{"code": "function kill(pid, signal) {\n  signal = _.isUndefined(signal) ? 'SIGINT' : signal;\n  // process.kill does not recognize many of the well known numeric signals,\n  // only by name\n  if (_.isFinite(signal) && _.has(signalsMap, signal)) {\n    signal = signalsMap[signal];\n  }\n\n  if (!_.isFinite(pid)) return false;\n  try {\n    process.kill(pid, signal);\n  } catch (e) {\n    return false;\n  }\n  return true;\n}", "label": 3}
{"code": "func torrentOffsetRequest(torrentLength, pieceSize, chunkSize, offset int64) (\n\tr request, ok bool) {\n\tif offset < 0 || offset >= torrentLength {\n\t\treturn\n\t}\n\tr.Index = pp.Integer(offset / pieceSize)\n\tr.Begin = pp.Integer(offset % pieceSize / chunkSize * chunkSize)\n\tr.Length = pp.Integer(chunkSize)\n\tpieceLeft := pp.Integer(pieceSize - int64(r.Begin))\n\tif r.Length > pieceLeft {\n\t\tr.Length = pieceLeft\n\t}\n\ttorrentLeft := torrentLength - int64(r.Index)*pieceSize - int64(r.Begin)\n\tif int64(r.Length) > torrentLeft {\n\t\tr.Length = pp.Integer(torrentLeft)\n\t}\n\tok = true\n\treturn\n}", "label": 5}
{"code": "def get(path, options = {}, &block)\n      perform_request Net::HTTP::Get, path, options, &block\n    end", "label": 4}
{"code": "def _validate(self, val: list, log: Optional[Logger] = None) -> Tuple[bool, List[str]]:\n        \"\"\" Determine whether val is a valid instance of this array\n\n        :returns: Success indicator and error list \"\"\"\n        errors = []\n        if not isinstance(val, list):\n            errors.append(f\"{self._variable_name}: {repr(val)} is not an array\")\n        else:\n            for i in range(0, len(val)):\n                v = val[i]\n                if not conforms(v, self._type, self._context.NAMESPACE):\n                    errors.append(f\"{self._variable_name} element {i}: {v} is not a {self._type.__name__}\")\n\n            if len(val) < self._min:\n                errors.append(\n                    f\"{self._variable_name}: at least {self._min} value{'s' if self._min > 1 else ''} required - \"\n                    f\"element has {len(val) if len(val) else 'none'}\")\n            if self._max is not None and len(val) > self._max:\n                errors.append(\n                    f\"{self._variable_name}: no more than {self._max} values permitted - element has {len(val)}\")\n\n        if log:\n            for error in errors:\n                log.log(error)\n        return not bool(errors), errors", "label": 1}
{"code": "function getFormIds(req, res, next) {\n  var params = {\n    appId: req.params.projectid || req.params.id\n  };\n\n  forms.getAppFormsForApp(_.extend(req.connectionOptions, params), function(err, appFormResult) {\n    if (err) {\n      return next(err);\n    }\n\n    //Only Want The Form Ids\n    req.appformsResultPayload = {\n      data: _.map(_.compact(appFormResult.forms), function(form) {\n        return form._id.toString();\n      }),\n      type: constants.resultTypes.formProjects\n    };\n\n    next();\n  });\n}", "label": 3}
{"code": "function listProjectSubmissions(req, res, next) {\n  var formId = req.body.formId;\n  var subIds = req.body.subid;\n\n  var params = {\n    wantRestrictions: false,\n    appId: req.params.projectid\n  };\n\n  //Assigning Form Search If Set\n  if (_.isString(formId)) {\n    params.formId = formId;\n  }\n\n  //Assigning Submission Search Params If Set\n  if (_.isArray(subIds)) {\n    params.subid = subIds;\n  } else if (_.isString(subIds)) {\n    params.subid = [subIds];\n  }\n\n  logger.debug(\"Middleware listProjectSubmissions \", {params: params});\n\n  forms.getSubmissions(req.connectionOptions, params, submissionsHandler(constants.resultTypes.submissions, req, next));\n}", "label": 3}
{"code": "function(positions) {\n\tvar xs = [], ys = [], zs = [];\n\tvar xi = {}, yi = {}, zi = {};\n\tfor (var i=0; i<positions.length; i++) {\n\t\tvar p = positions[i];\n\t\tvar x = p[0], y = p[1], z = p[2];\n\n\t\t// Split the positions array into arrays of unique component values.\n\t\t//\n\t\t// Why go through the trouble of using a uniqueness hash table vs\n\t\t// sort and uniq: \n\t\t//\n\t\t// Suppose you've got a million positions in a 100x100x100 grid.\n\t\t//\n\t\t// Using a uniqueness hash table, you're doing 1M array reads, \n\t\t// 3M hash table lookups from 100-element hashes, 300 hash table inserts, then\n\t\t// sorting three 100-element arrays and iterating over them.\n\t\t// Roughly, 1M + 3M * ln(100) + 300 * ln(100/2) + 3 * 100 * ln(100) + 3 * 100 = \n\t\t//          1M + 13.8M + 0.0012M +  0.0014M + 0.0003M \n\t\t//          =~ 15M\n\t\t//\n\t\t// Sort and uniq solution would do 1M array reads, 3M array inserts,\n\t\t// sort three 1M-element arrays and iterate over them.\n\t\t// Roughly, 1M + 3M + 3 * 1M * ln(1M) + 3 * 1M = \n\t\t//          1M + 3M + 41.4M + 3M \n\t\t//          =~ 48.4M\n\t\t//\n\t\t// Guessing that a hard-coded sort & uniq would be faster due to not having\n\t\t// to run a hashing function on everything. More memory usage though \n\t\t// (bunch of small hash tables vs. duplicating the input array.)\n\t\t//\n\t\t// In JS-land, who knows. Maybe xi[x] casts x to string and destroys perf, \n\t\t// maybe numeric keys get special-cased, maybe the object lookups run at near O(1)-speeds.\n\t\t// Maybe the sorting comparison function is expensive to call, maybe it gets inlined or special-cased.\n\t\t//\n\t\t// ... You're probably not going to call this with more than 10k positions anyhow, so this is very academic.\n\t\t//\n\t\tif (!xi[x]) {\n\t\t\txs.push(x);\n\t\t\txi[x] = true;\n\t\t}\n\t\tif (!yi[y]) {\n\t\t\tys.push(y);\n\t\t\tyi[y] = true;\n\t\t}\n\t\tif (!zi[z]) {\n\t\t\tzs.push(z);\n\t\t\tzi[z] = true;\n\t\t}\n\t}\n\tvar xSep = findMinSeparation(xs);\n\tvar ySep = findMinSeparation(ys);\n\tvar zSep = findMinSeparation(zs);\n\tvar minSeparation = Math.min(xSep, ySep, zSep);\n\tif (!isFinite(minSeparation)) {\n\t\treturn 1;\n\t}\n\treturn minSeparation;\n}", "label": 3}
{"code": "func (s *Store) HasFullKey(key string) bool {\n\treturn s.stores[imageManifestType].Has(key)\n}", "label": 5}
{"code": "public function lookup(array $keys, array $options = [])\n    {\n        $options += [\n            'className' => Entity::class,\n            'sort' => false\n        ];\n\n        $serviceKeys = [];\n        $this->validateBatch($keys, Key::class, function ($key) use (&$serviceKeys) {\n            if ($key->state() !== Key::STATE_NAMED) {\n                throw new \\InvalidArgumentException(sprintf(\n                    'Given $key is in an invalid state. Can only lookup records when given a complete key. ' .\n                    'Given path was %s',\n                    (string) $key\n                ));\n            }\n\n            $serviceKeys[] = $key->keyObject();\n        });\n\n        $res = $this->connection->lookup($options + $this->readOptions($options) + [\n            'projectId' => $this->projectId,\n            'keys' => $serviceKeys\n        ]);\n\n        $result = [];\n        if (isset($res['found'])) {\n            foreach ($res['found'] as $found) {\n                $result['found'][] = $this->mapEntityResult($found, $options['className']);\n            }\n\n            if ($options['sort']) {\n                $result['found'] = $this->sortEntities($result['found'], $keys);\n            }\n        }\n\n        if (isset($res['missing'])) {\n            $result['missing'] = [];\n            foreach ($res['missing'] as $missing) {\n                $key = $this->key(\n                    $missing['entity']['key']['path'],\n                    $missing['entity']['key']['partitionId']\n                );\n\n                $result['missing'][] = $key;\n            }\n        }\n\n        if (isset($res['deferred'])) {\n            $result['deferred'] = [];\n            foreach ($res['deferred'] as $deferred) {\n                $key = $this->key(\n                    $deferred['path'],\n                    $deferred['partitionId']\n                );\n\n                $result['deferred'][] = $key;\n            }\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "def convert_nexson_format(blob,\n                          out_nexson_format,\n                          current_format=None,\n                          remove_old_structs=True,\n                          pristine_if_invalid=False,\n                          sort_arbitrary=False):\n    \"\"\"Take a dict form of NexSON and converts its datastructures to\n    those needed to serialize as out_nexson_format.\n    If current_format is not specified, it will be inferred.\n    If `remove_old_structs` is False and different honeybadgerfish varieties\n        are selected, the `blob` will be 'fat\" containing both types\n        of lookup structures.\n    If pristine_if_invalid is False, then the object may be corrupted if it\n        is an invalid nexson struct. Setting this to False can result in\n        faster translation, but if an exception is raised the object may\n        be polluted with partially constructed fields for the out_nexson_format.\n    \"\"\"\n    if not current_format:\n        current_format = detect_nexson_version(blob)\n    out_nexson_format = resolve_nexson_format(out_nexson_format)\n    if current_format == out_nexson_format:\n        if sort_arbitrary:\n            sort_arbitrarily_ordered_nexson(blob)\n        return blob\n    two2zero = _is_by_id_hbf(out_nexson_format) and _is_badgerfish_version(current_format)\n    zero2two = _is_by_id_hbf(current_format) and _is_badgerfish_version(out_nexson_format)\n    if two2zero or zero2two:\n        # go from 0.0 -> 1.0 then the 1.0->1.2 should succeed without nexml...\n        blob = convert_nexson_format(blob,\n                                     DIRECT_HONEY_BADGERFISH,\n                                     current_format=current_format,\n                                     remove_old_structs=remove_old_structs,\n                                     pristine_if_invalid=pristine_if_invalid)\n        current_format = DIRECT_HONEY_BADGERFISH\n    ccdict = {'output_format': out_nexson_format,\n              'input_format': current_format,\n              'remove_old_structs': remove_old_structs,\n              'pristine_if_invalid': pristine_if_invalid}\n    ccfg = ConversionConfig(ccdict)\n    if _is_badgerfish_version(current_format):\n        converter = Badgerfish2DirectNexson(ccfg)\n    elif _is_badgerfish_version(out_nexson_format):\n        assert _is_direct_hbf(current_format)\n        converter = Direct2BadgerfishNexson(ccfg)\n    elif _is_direct_hbf(current_format) and (out_nexson_format == BY_ID_HONEY_BADGERFISH):\n        converter = Direct2OptimalNexson(ccfg)\n    elif _is_direct_hbf(out_nexson_format) and (current_format == BY_ID_HONEY_BADGERFISH):\n        converter = Optimal2DirectNexson(ccfg)\n    else:\n        raise NotImplementedError('Conversion from {i} to {o}'.format(i=current_format, o=out_nexson_format))\n    blob = converter.convert(blob)\n    if sort_arbitrary:\n        sort_arbitrarily_ordered_nexson(blob)\n    return blob", "label": 1}
{"code": "public void checkVersion(ZWaveCommandClass commandClass) {\r\n\t\tZWaveVersionCommandClass versionCommandClass = (ZWaveVersionCommandClass)this.getNode().getCommandClass(CommandClass.VERSION);\r\n\t\t\r\n\t\tif (versionCommandClass == null) {\r\n\t\t\tlogger.error(String.format(\"Version command class not supported on node %d,\" +\r\n\t\t\t\t\t\"reverting to version 1 for command class %s (0x%02x)\", \r\n\t\t\t\t\tthis.getNode().getNodeId(), \r\n\t\t\t\t\tcommandClass.getCommandClass().getLabel(), \r\n\t\t\t\t\tcommandClass.getCommandClass().getKey()));\r\n\t\t\treturn;\r\n\t\t}\r\n\t\t\r\n\t\tthis.getController().sendData(versionCommandClass.getCommandClassVersionMessage(commandClass.getCommandClass()));\r\n\t}", "label": 0}
{"code": "def handle_error(response):\n    \"\"\"Raise appropriate exceptions if necessary.\"\"\"\n    status_code = response.status_code\n\n    if status_code not in A_OK_HTTP_CODES:\n        error_explanation = A_ERROR_HTTP_CODES.get(status_code)\n        raise_error = \"{}: {}\".format(status_code, error_explanation)\n        raise Exception(raise_error)\n    else:\n        return True", "label": 1}
{"code": "function() {\n    var valid = false;\n    var destroy = true;\n    var target = this;\n    Crafty('Card').each(function() {\n      if (this.intersect(target.x + target.w + game.config.cardBuffer, target.y, target.w, target.h) ||\n          this.intersect(target.x - target.w - game.config.cardBuffer, target.y, target.w, target.h) ||\n          this.intersect(target.x, target.y + target.h + game.config.cardBuffer, target.w, target.h) ||\n          this.intersect(target.x, target.y - target.h - game.config.cardBuffer, target.w, target.h)\n        ) {\n        valid = true;\n        destroy = false;\n      }\n      if (this.intersect(target.x, target.y, target.w, target.h)) {\n        destroy = false;\n      }\n    });\n    if (valid) {\n      this.used = false;\n    }\n    else if (destroy) {\n      this.destroy();\n      var currentTarget = this;\n      game.targets = _.reject(game.targets, function(thisTarget) { return _.isEqual(thisTarget, currentTarget); });\n    }\n  }", "label": 3}
{"code": "public static ipset_nsip_binding[] get(nitro_service service, String name) throws Exception{\n\t\tipset_nsip_binding obj = new ipset_nsip_binding();\n\t\tobj.set_name(name);\n\t\tipset_nsip_binding response[] = (ipset_nsip_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def array_to_cells(values, options={})\n      DataTypeValidator.validate :array_to_cells, Array, values\n      types, style, formula_values = options.delete(:types), options.delete(:style), options.delete(:formula_values)\n      values.each_with_index do |value, index|\n        options[:style] = style.is_a?(Array) ? style[index] : style if style\n        options[:type] = types.is_a?(Array) ? types[index] : types if types\n        options[:formula_value] = formula_values[index] if formula_values.is_a?(Array)\n\n        self[index] = Cell.new(self, value, options)\n      end\n    end", "label": 4}
{"code": "public function completions( $_, $assoc_args ) {\n\t\t$line  = substr( $assoc_args['line'], 0, $assoc_args['point'] );\n\t\t$compl = new \\WP_CLI\\Completions( $line );\n\t\t$compl->render();\n\t}", "label": 2}
{"code": "public function setDominantColors($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\DominantColorsAnnotation::class);\n        $this->dominant_colors = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (ipl *IPList) lookup(ip net.IP) (Range, bool) {\n\treturn lookup(func(i int) net.IP {\n\t\treturn ipl.ranges[i].First\n\t}, func(i int) Range {\n\t\treturn ipl.ranges[i]\n\t}, len(ipl.ranges), ip)\n}", "label": 5}
{"code": "def [](key)\n      return @cache[key] if @cache.key?(key)\n\n      path = path_to(hash(key))\n      if disk_cache_enabled? && File.file?(path) && File.readable?(path)\n        @cache[key] = load(path)\n      else\n        raise\n      end\n    end", "label": 4}
{"code": "function(opts) {\n  if(!opts) opts = {};\n  var libpath = opts['path'];\n\n  this._emitter = new events.EventEmitter();\n  this._library = this.createLibrary(libpath);\n  this._initCrypto(opts);\n  this._options = this._createToxOptions(opts);\n  this._initNew(this._options);\n  this._initCallbacks();\n\n  // Create a child ToxOld if specified for old groupchat functionality\n  if(opts.old === true) {\n    this._toxold = new ToxOld({ path: libpath, tox: this });\n  }\n}", "label": 3}
{"code": "func ClientCertPool(client AccessCache, clusterName string) (*x509.CertPool, error) {\n\tpool := x509.NewCertPool()\n\tvar authorities []services.CertAuthority\n\tif clusterName == \"\" {\n\t\thostCAs, err := client.GetCertAuthorities(services.HostCA, false, services.SkipValidation())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tuserCAs, err := client.GetCertAuthorities(services.UserCA, false, services.SkipValidation())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tauthorities = append(authorities, hostCAs...)\n\t\tauthorities = append(authorities, userCAs...)\n\t} else {\n\t\thostCA, err := client.GetCertAuthority(\n\t\t\tservices.CertAuthID{Type: services.HostCA, DomainName: clusterName},\n\t\t\tfalse, services.SkipValidation())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tuserCA, err := client.GetCertAuthority(\n\t\t\tservices.CertAuthID{Type: services.UserCA, DomainName: clusterName},\n\t\t\tfalse, services.SkipValidation())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tauthorities = append(authorities, hostCA)\n\t\tauthorities = append(authorities, userCA)\n\t}\n\n\tfor _, auth := range authorities {\n\t\tfor _, keyPair := range auth.GetTLSKeyPairs() {\n\t\t\tcert, err := tlsca.ParseCertificatePEM(keyPair.Cert)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\tlog.Debugf(\"ClientCertPool -> %v\", CertInfo(cert))\n\t\t\tpool.AddCert(cert)\n\t\t}\n\t}\n\treturn pool, nil\n}", "label": 5}
{"code": "public static int cudnnSoftmaxBackward(\n        cudnnHandle handle, \n        int algo, \n        int mode, \n        Pointer alpha, \n        cudnnTensorDescriptor yDesc, \n        Pointer y, \n        cudnnTensorDescriptor dyDesc, \n        Pointer dy, \n        Pointer beta, \n        cudnnTensorDescriptor dxDesc, \n        Pointer dx)\n    {\n        return checkResult(cudnnSoftmaxBackwardNative(handle, algo, mode, alpha, yDesc, y, dyDesc, dy, beta, dxDesc, dx));\n    }", "label": 0}
{"code": "public function removeStoredConversation($message = null)\n    {\n        /*\n         * Only remove it from the cache if it was not modified\n         * after we loaded the data from the cache.\n         */\n        if ($this->getStoredConversation($message)['time'] == $this->currentConversationData['time']) {\n            $this->cache->pull($this->message->getConversationIdentifier());\n            $this->cache->pull($this->message->getOriginatedConversationIdentifier());\n        }\n    }", "label": 2}
{"code": "public static java.sql.Timestamp getTimestamp(Object value) {\n        try {\n            return toTimestamp(value);\n        } catch (ParseException pe) {\n            pe.printStackTrace();\n            return null;\n        }\n    }", "label": 0}
{"code": "public static base_response delete(nitro_service client, systementitydata resource) throws Exception {\n\t\tsystementitydata deleteresource = new systementitydata();\n\t\tdeleteresource.type = resource.type;\n\t\tdeleteresource.name = resource.name;\n\t\tdeleteresource.alldeleted = resource.alldeleted;\n\t\tdeleteresource.allinactive = resource.allinactive;\n\t\tdeleteresource.datasource = resource.datasource;\n\t\tdeleteresource.core = resource.core;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def run_till_terminated_or_interrupted(signals, wait_interval = 60)\n      @stop_server = false\n      @stop_server_mu = Mutex.new\n      @stop_server_cv = ConditionVariable.new\n\n      @stop_server_thread = Thread.new do\n        loop do\n          break if @stop_server\n          @stop_server_mu.synchronize do\n            @stop_server_cv.wait(@stop_server_mu, wait_interval)\n          end\n        end\n\n        # stop is surrounded by mutex, should handle multiple calls to stop\n        #   correctly\n        stop\n      end\n\n      valid_signals = Signal.list\n\n      # register signal handlers\n      signals.each do |sig|\n        # input validation\n        if sig.class == String\n          sig.upcase!\n          if sig.start_with?('SIG')\n            # cut out the SIG prefix to see if valid signal\n            sig = sig[3..-1]\n          end\n        end\n\n        # register signal traps for all valid signals\n        if valid_signals.value?(sig) || valid_signals.key?(sig)\n          Signal.trap(sig) do\n            @stop_server = true\n            @stop_server_cv.broadcast\n          end\n        else\n          fail \"#{sig} not a valid signal\"\n        end\n      end\n\n      run\n\n      @stop_server_thread.join\n    end", "label": 4}
{"code": "func (f *Finder) ResourcePoolListAll(ctx context.Context, path string) ([]*object.ResourcePool, error) {\n\tpools, err := f.ResourcePoolList(ctx, path)\n\tif err != nil {\n\t\tif _, ok := err.(*NotFoundError); !ok {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tvapps, _ := f.VirtualAppList(ctx, path)\n\n\t\tif len(vapps) == 0 {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor _, vapp := range vapps {\n\t\t\tpools = append(pools, vapp.ResourcePool)\n\t\t}\n\t}\n\n\treturn pools, nil\n}", "label": 5}
{"code": "public function setStart($type, array $start)\n    {\n        $rangeKey = $this->fromDefinition($type, 'start');\n\n        $this->startType = $rangeKey;\n        $this->start = $start;\n    }", "label": 2}
{"code": "protected function callMacro($name, $parameters)\n    {\n        $macro = static::$macros[$name];\n\n        if ($macro instanceof Closure) {\n            return call_user_func_array($macro->bindTo($this, static::class), $parameters);\n        }\n\n        return call_user_func_array($macro, $parameters);\n    }", "label": 2}
{"code": "func LoadRetrievePropertiesResponse(res *types.RetrievePropertiesResponse, dst interface{}) error {\n\trt := reflect.TypeOf(dst)\n\tif rt == nil || rt.Kind() != reflect.Ptr {\n\t\tpanic(\"need pointer\")\n\t}\n\n\trv := reflect.ValueOf(dst).Elem()\n\tif !rv.CanSet() {\n\t\tpanic(\"cannot set dst\")\n\t}\n\n\tisSlice := false\n\tswitch rt.Elem().Kind() {\n\tcase reflect.Struct:\n\tcase reflect.Slice:\n\t\tisSlice = true\n\tdefault:\n\t\tpanic(\"unexpected type\")\n\t}\n\n\tif isSlice {\n\t\tfor _, p := range res.Returnval {\n\t\t\tv, err := ObjectContentToType(p)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tvt := reflect.TypeOf(v)\n\n\t\t\tif !rv.Type().AssignableTo(vt) {\n\t\t\t\t// For example: dst is []ManagedEntity, res is []HostSystem\n\t\t\t\tif field, ok := vt.FieldByName(rt.Elem().Elem().Name()); ok && field.Anonymous {\n\t\t\t\t\trv.Set(reflect.Append(rv, reflect.ValueOf(v).FieldByIndex(field.Index)))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\trv.Set(reflect.Append(rv, reflect.ValueOf(v)))\n\t\t}\n\t} else {\n\t\tswitch len(res.Returnval) {\n\t\tcase 0:\n\t\tcase 1:\n\t\t\tv, err := ObjectContentToType(res.Returnval[0])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tvt := reflect.TypeOf(v)\n\n\t\t\tif !rv.Type().AssignableTo(vt) {\n\t\t\t\t// For example: dst is ComputeResource, res is ClusterComputeResource\n\t\t\t\tif field, ok := vt.FieldByName(rt.Elem().Name()); ok && field.Anonymous {\n\t\t\t\t\trv.Set(reflect.ValueOf(v).FieldByIndex(field.Index))\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\n\t\t\trv.Set(reflect.ValueOf(v))\n\t\tdefault:\n\t\t\t// If dst is not a slice, expect to receive 0 or 1 results\n\t\t\tpanic(\"more than 1 result\")\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def aws_ec2(role, pkcs7, nonce = nil, route = nil)\n      route ||= '/v1/auth/aws-ec2/login'\n      payload = { role: role, pkcs7: pkcs7 }\n      # Set a custom nonce if client is providing one\n      payload[:nonce] = nonce if nonce\n      json = client.post(route, JSON.fast_generate(payload))\n      secret = Secret.decode(json)\n      client.token = secret.auth.client_token\n      return secret\n    end", "label": 4}
{"code": "function init(app) {\n    app.post('/api/v1/connectors/:connection', \n    /**\n     * installs session data such as credentials.\n     *\n     * @param req containing body JSON to pass as input.\n     * @param res result of call is provided as JSON body data.\n     * @param next function to invoke error handling.\n     */\n    function serviceCall(req, res, next) {\n        connector.configureSession(req.params.connection, req.body);\n        res.send(204); // success --> 204 no content\n    });\n    app.post('/api/v1/connectors/:connection/:call', \n    /**\n     * calls directly into a service connection.\n     *\n     * @param req containing body JSON to pass as input.\n     * @param res result of call is provided as JSON body data.\n     * @param next function to invoke error handling.\n     */\n    function serviceCall(req, res, next) {\n        connector.runCall(req.params.connection, req.params.call, req.body).then(res.json.bind(res), next).done();\n    });\n}", "label": 3}
{"code": "def mklink():\n\t\"\"\"\n\tLike cmd.exe's mklink except it will infer directory status of the\n\ttarget.\n\t\"\"\"\n\tfrom optparse import OptionParser\n\tparser = OptionParser(usage=\"usage: %prog [options] link target\")\n\tparser.add_option(\n\t\t'-d', '--directory',\n\t\thelp=\"Target is a directory (only necessary if not present)\",\n\t\taction=\"store_true\")\n\toptions, args = parser.parse_args()\n\ttry:\n\t\tlink, target = args\n\texcept ValueError:\n\t\tparser.error(\"incorrect number of arguments\")\n\tsymlink(target, link, options.directory)\n\tsys.stdout.write(\"Symbolic link created: %(link)s --> %(target)s\\n\" % vars())", "label": 1}
{"code": "public function findRequirements($name)\n    {\n        $requirements = [];\n\n        $module = $this->findOrFail($name);\n\n        foreach ($module->getRequires() as $requirementName) {\n            $requirements[] = $this->findByAlias($requirementName);\n        }\n\n        return $requirements;\n    }", "label": 2}
{"code": "function _gpfPathRelative (from, to) {\n    var length,\n        splitFrom = _gpfPathDecompose(from),\n        splitTo = _gpfPathDecompose(to);\n    _gpfPathShiftIdenticalBeginning(splitFrom, splitTo);\n    // For each remaining part in from, unshift .. in to\n    length = splitFrom.length;\n    while (length--) {\n        splitTo.unshift(\"..\");\n    }\n    return splitTo.join(\"/\");\n}", "label": 3}
{"code": "public static appqoepolicy[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tappqoepolicy obj = new appqoepolicy();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tappqoepolicy[] response = (appqoepolicy[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function(req) {\n\treturn ((req.headers.origin && req.headers.origin !== \"null\") ? req.headers.origin : \"*\");\n}", "label": 3}
{"code": "def authenticate(self, driver):\n        \"\"\"Authenticate using the Console Server protocol specific FSM.\"\"\"\n        #                      0                      1                    2                    3\n        events = [driver.username_re, driver.password_re, self.device.prompt_re, driver.rommon_re,\n                  #       4             5                   6                       7                8\n                  driver.unable_to_connect_re, driver.authentication_error_re, pexpect.TIMEOUT, pexpect.EOF]\n\n        transitions = [\n            (driver.username_re, [0], 1, partial(a_send_username, self.username), 10),\n            (driver.username_re, [1], 1, None, 10),\n            (driver.password_re, [0, 1], 2, partial(a_send_password, self._acquire_password()),\n             _C['first_prompt_timeout']),\n            (driver.username_re, [2], -1, a_authentication_error, 0),\n            (driver.password_re, [2], -1, a_authentication_error, 0),\n            (driver.authentication_error_re, [1, 2], -1, a_authentication_error, 0),\n            (self.device.prompt_re, [0, 1, 2], -1, None, 0),\n            (driver.rommon_re, [0], -1, partial(a_send, \"\\r\\n\"), 0),\n            (pexpect.TIMEOUT, [0], 1, partial(a_send, \"\\r\\n\"), 10),\n            (pexpect.TIMEOUT, [2], -1, None, 0),\n            (pexpect.TIMEOUT, [3, 7], -1, ConnectionTimeoutError(\"Connection Timeout\", self.hostname), 0),\n            (driver.unable_to_connect_re, [0, 1, 2], -1, a_unable_to_connect, 0),\n        ]\n        self.log(\"EXPECTED_PROMPT={}\".format(pattern_to_str(self.device.prompt_re)))\n        fsm = FSM(\"CONSOLE-SERVER-AUTH\", self.device, events, transitions, timeout=_C['connect_timeout'],\n                  init_pattern=self.last_pattern)\n        return fsm.run()", "label": 1}
{"code": "public static authenticationtacacspolicy_vpnvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationtacacspolicy_vpnvserver_binding obj = new authenticationtacacspolicy_vpnvserver_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationtacacspolicy_vpnvserver_binding response[] = (authenticationtacacspolicy_vpnvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function _addRule(conf) {\n    // Attach unique identifier\n    conf.i = id++;\n\n    // Only setup watching when enabled\n    if (conf.watch !== false) {\n        events.push(conf);\n\n        // Only attach event once\n        if (! bound) {\n            const run = _run.bind(this, false, 0, null);\n            bound = 1;\n            events = [conf];\n\n            // Attach resize event\n            _win.addEventListener('resize', run);\n        }\n    }\n\n    // Evaluate rule immediately if not disabled\n    if (conf.init !== false) {\n        _run(true, [conf]);\n    }\n}", "label": 3}
{"code": "def GET\n      fetch_header(\"action_dispatch.request.query_parameters\") do |k|\n        rack_query_params = super || {}\n        # Check for non UTF-8 parameter values, which would cause errors later\n        Request::Utils.check_param_encoding(rack_query_params)\n        set_header k, Request::Utils.normalize_encode_params(rack_query_params)\n      end\n    rescue Rack::Utils::ParameterTypeError, Rack::Utils::InvalidParameterError => e\n      raise ActionController::BadRequest.new(\"Invalid query parameters: #{e.message}\")\n    end", "label": 4}
{"code": "public PromotionEvaluationReport getModulePromotionReport(final String name, final String version) throws GrapesCommunicationException {\n        return getModulePromotionReportRaw(name, version, false, PromotionEvaluationReport.class);\n    }", "label": 0}
{"code": "private void setTableAliasForClassDescriptor(ClassDescriptor aCld, TableAlias anAlias)\r\n    {\r\n        if (m_cldToAlias.get(aCld) == null)\r\n        {\r\n            m_cldToAlias.put(aCld, anAlias);\r\n        }    \r\n    }", "label": 0}
{"code": "def serialize(self, raw=False):\n        '''Encode the private part of the key in a base64 format by default,\n        but when raw is True it will return hex encoded bytes.\n        @return: bytes\n        '''\n        if raw:\n            return self._key.encode()\n        return self._key.encode(nacl.encoding.Base64Encoder)", "label": 1}
{"code": "public static systemcore get(nitro_service service) throws Exception{\n\t\tsystemcore obj = new systemcore();\n\t\tsystemcore[] response = (systemcore[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n    public List<HazeltaskTask<G>> shutdownNow() {\n\t    return (List<HazeltaskTask<G>>) (List) localExecutorPool.shutdownNow();\n\t}", "label": 0}
{"code": "public static base_response unlink(nitro_service client, sslcertkey resource) throws Exception {\n\t\tsslcertkey unlinkresource = new sslcertkey();\n\t\tunlinkresource.certkey = resource.certkey;\n\t\treturn unlinkresource.perform_operation(client,\"unlink\");\n\t}", "label": 0}
{"code": "public ValueContainer[] getKeyValues(ClassDescriptor cld, Identity oid) throws PersistenceBrokerException\r\n    {\r\n        return getKeyValues(cld, oid, true);\r\n    }", "label": 0}
{"code": "public function handleError(\\Exception $e, $conn) {\n        $this->app->onError($conn->decor, $e);\n    }", "label": 2}
{"code": "protected function basic_nack_from_server($reader)\n    {\n        $delivery_tag = $reader->read_longlong();\n        $multiple = (bool) $reader->read_bit();\n\n        if (!isset($this->published_messages[$delivery_tag])) {\n            throw new AMQPRuntimeException(sprintf(\n                'Server nack\\'ed unknown delivery_tag \"%s\"',\n                $delivery_tag\n            ));\n        }\n\n        $this->internal_ack_handler($delivery_tag, $multiple, $this->nack_handler);\n    }", "label": 2}
{"code": "function validateContentType(cb) {\n        if (!_.isUndefined(kontx.args.meta) && !_.isUndefined(kontx.args.meta.type)) {\n            db.contentTypes.getById(kontx.args.meta.type.toString()).then(\n                function(contentType) {\n                    cb(null, contentType);\n                },\n                function() {\n                    cb(createError(400, messages.invalid_content_type));\n                });\n        } else {\n            cb(createError(400, messages.invalid_content_type));\n        }\n\n    }", "label": 3}
{"code": "public static base_responses add(nitro_service client, dbdbprofile resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdbdbprofile addresources[] = new dbdbprofile[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new dbdbprofile();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].interpretquery = resources[i].interpretquery;\n\t\t\t\taddresources[i].stickiness = resources[i].stickiness;\n\t\t\t\taddresources[i].kcdaccount = resources[i].kcdaccount;\n\t\t\t\taddresources[i].conmultiplex = resources[i].conmultiplex;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def process_shell(self, creator, entry, config):\n        \"\"\"Processing a shell entry.\"\"\"\n        self.logger.info(\"Processing Bash code: start\")\n\n        output = []\n        shell = creator(entry, config)\n        for line in shell.process():\n            output.append(line)\n            self.logger.info(\" | %s\", line)\n\n        if shell.success:\n            self.logger.info(\"Processing Bash code: finished\")\n            return {'success': True, 'output': output}\n\n        for line in self.run_cleanup(config.env, shell.exit_code):\n            output.append(line)\n\n        self.logger.error(\"Pipeline has failed: leaving as soon as possible!\")\n        self.event.failed()\n        return {'success': False, 'output': output}", "label": 1}
{"code": "public function setItems($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dialogflow\\V2\\Intent\\Message\\CarouselSelect\\Item::class);\n        $this->items = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function (callback) {\n                var REDUCE_INITIAL_VALUE_INDEX = 1, initialValue = arguments[REDUCE_INITIAL_VALUE_INDEX], thisLength = this.length, index = 0, value;\n                if (undefined === initialValue) {\n                    value = this[index++];\n                } else {\n                    value = initialValue;\n                }\n                for (; index < thisLength; ++index) {\n                    value = callback(value, this[index], index, this);\n                }\n                return value;\n            }", "label": 3}
{"code": "protected function validateAndCompleteManyToOneMapping(ManyToOneAssociationMetadata $property)\n    {\n        // A many-to-one mapping is essentially a one-one backreference\n        if ($property->isOrphanRemoval()) {\n            throw MappingException::illegalOrphanRemoval($this->className, $property->getName());\n        }\n    }", "label": 2}
{"code": "func validateHostSigner(signer ssh.Signer) error {\n\tcert, ok := signer.PublicKey().(*ssh.Certificate)\n\tif !ok {\n\t\treturn trace.BadParameter(\"only host certificates supported\")\n\t}\n\tif len(cert.ValidPrincipals) == 0 {\n\t\treturn trace.BadParameter(\"at least one valid principal is required in host certificate\")\n\t}\n\n\tcertChecker := utils.CertChecker{}\n\terr := certChecker.CheckCert(cert.ValidPrincipals[0], cert)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def poll(timeout_ms)\n      message_ptr = Rdkafka::Bindings.rd_kafka_consumer_poll(@native_kafka, timeout_ms)\n      if message_ptr.null?\n        nil\n      else\n        # Create struct wrapper\n        native_message = Rdkafka::Bindings::Message.new(message_ptr)\n        # Raise error if needed\n        if native_message[:err] != 0\n          raise Rdkafka::RdkafkaError.new(native_message[:err])\n        end\n        # Create a message to pass out\n        Rdkafka::Consumer::Message.new(native_message)\n      end\n    ensure\n      # Clean up rdkafka message if there is one\n      if !message_ptr.nil? && !message_ptr.null?\n        Rdkafka::Bindings.rd_kafka_message_destroy(message_ptr)\n      end\n    end", "label": 4}
{"code": "def _add_uniq_value_to_dict_bf(d, k, v):\n    \"\"\"Like _add_value_to_dict_bf but will not add v if another\n    element in under key `k` has the same value.\n    \"\"\"\n    prev = d.get(k)\n    if prev is None:\n        d[k] = v\n    elif isinstance(prev, list):\n        if not isinstance(v, list):\n            v = [v]\n        for sel in v:\n            found = False\n            for el in prev:\n                if el == sel:\n                    found = True\n                    break\n            if not found:\n                prev.append(sel)\n    else:\n        if isinstance(v, list):\n            prev = [prev]\n            for sel in v:\n                found = False\n                for el in prev:\n                    if el == sel:\n                        found = True\n                        break\n                if not found:\n                    prev.append(sel)\n            if len(prev) > 1:\n                d[k] = prev\n        elif prev != v:\n            d[k] = [prev, v]", "label": 1}
{"code": "public static nsxmlnamespace[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tnsxmlnamespace obj = new nsxmlnamespace();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tnsxmlnamespace[] response = (nsxmlnamespace[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def get(self, thread=None, plugin=None):\n        \"\"\"\n        Get one or more threads.\n\n        :param thread: Name of the thread\n        :type thread: str\n        :param plugin: Plugin object, under which the thread was registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if plugin is not None:\n            if thread is None:\n                threads_list = {}\n                for key in self.threads.keys():\n                    if self.threads[key].plugin == plugin:\n                        threads_list[key] = self.threads[key]\n                return threads_list\n            else:\n                if thread in self.threads.keys():\n                    if self.threads[thread].plugin == plugin:\n                        return self.threads[thread]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if thread is None:\n                return self.threads\n            else:\n                if thread in self.threads.keys():\n                    return self.threads[thread]\n                else:\n                    return None", "label": 1}
{"code": "function _setUserInfoFromSocialAccount(){\n    return db.users.socialAuthentication('twitter', this.socialUserInfo.id_str)\n            .then(function(user){\n                this.userInfo = user;\n            }.bind(this))\n            .catch(function(err){ // If user isn't found surpress error. If found and still error then throw.\n                if(err.code !== 404){\n                    throw(err);\n                }\n            });\n}", "label": 3}
{"code": "def parse_file_to_dict(self, fname):\n        \"\"\"\n        process the file according to the mapping rules.\n        The cols list must match the columns in the filename\n        \"\"\"\n        print('TODO - parse_file_to_dict' + fname)\n        for m in self.maps:\n            if m.tpe == 'file':\n                if m.key[0:3] == 'col':\n                    print('reading column..')", "label": 1}
{"code": "def download(self, id, attid): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Download a device's attachment.\n\n        :param id: Device ID as an int.\n        :param attid: Attachment ID as an int.\n        :rtype: tuple `(io.BytesIO, 'filename')`\n        \"\"\"\n        resp = self.service.get_id(self._base(id), attid, params={'format': 'download'}, stream=True)\n        b = io.BytesIO()\n        stream.stream_response_to_file(resp, path=b)\n        resp.close()\n        b.seek(0)\n        return (b, self.service.filename(resp))", "label": 1}
{"code": "def plotGenCost(generators):\n    \"\"\" Plots the costs of the given generators.\n    \"\"\"\n    figure()\n    plots = []\n    for generator in generators:\n        if generator.pcost_model == PW_LINEAR:\n            x = [x for x, _ in generator.p_cost]\n            y = [y for _, y in generator.p_cost]\n        elif generator.pcost_model == POLYNOMIAL:\n            x = scipy.arange(generator.p_min, generator.p_max, 5)\n            y = scipy.polyval(scipy.array(generator.p_cost), x)\n        else:\n            raise\n        plots.append(plot(x, y))\n        xlabel(\"P (MW)\")\n        ylabel(\"Cost ($)\")\n    legend(plots, [g.name for g in generators])\n    show()", "label": 1}
{"code": "public function start(CommandInterface $cmd, RequestInterface $req)\n    {\n        $ticket = uniqid();\n        $this->entries[$ticket] = [\n            'command'   => $cmd,\n            'request'   => $req,\n            'result'    => null,\n            'exception' => null,\n        ];\n\n        return $ticket;\n    }", "label": 2}
{"code": "def _init_matcher(self, *args, **kwargs):\n        \"\"\" Executes the current matcher appending it to the expression \"\"\"\n\n        # If subject-less expectation are provided as arguments convert them\n        # to plain Hamcrest matchers in order to allow complex compositions\n        fn = lambda x: x.evaluate() if isinstance(x, Expectation) else x\n        args = [fn(x) for x in args]\n        kwargs = dict((k, fn(v)) for k, v in kwargs.items())\n\n        matcher = self.matcher(*args, **kwargs)\n        self.expr.append(matcher)\n        self.matcher = None\n        return matcher", "label": 1}
{"code": "private function getManifestComponentModuleIndex($manifest, $componentId)\n    {\n        $manifest = is_array($manifest)\n            ? $manifest\n            : $this->getManifest($manifest);\n\n        $modules = array_filter($manifest['modules'], function ($module) use ($componentId) {\n            return ($module['id'] === $componentId);\n        });\n\n        return array_keys($modules)[0];\n    }", "label": 2}
{"code": "function(bindInfo, eventKey) {\n      return function() {\n        var result,\n            args = [{\n              args: arguments,\n              type: eventKey\n            }];\n        args.push(bindInfo.indices);\n        result = bindInfo.fn.apply(this, args);\n        this.__processFeedbackThenResult(result, bindInfo.feedbackCellField);\n      };\n    }", "label": 3}
{"code": "def calc_bin_cov(scaffolds, cov):\n    \"\"\"\n    calculate bin coverage\n    \"\"\"\n    bases = sum([cov[i][0] for i in scaffolds if i in cov])\n    length = sum([cov[i][1] for i in scaffolds if i in cov])\n    if length == 0:\n        return 0\n    return float(float(bases)/float(length))", "label": 1}
{"code": "def sendResponse(self, id, result, error):\n        \"\"\"sends a response to the peer\"\"\"\n        self.sendMessage({\"result\":result, \"error\": error, \"id\":id})", "label": 1}
{"code": "public static vpnurl[] get(nitro_service service, String urlname[]) throws Exception{\n\t\tif (urlname !=null && urlname.length>0) {\n\t\t\tvpnurl response[] = new vpnurl[urlname.length];\n\t\t\tvpnurl obj[] = new vpnurl[urlname.length];\n\t\t\tfor (int i=0;i<urlname.length;i++) {\n\t\t\t\tobj[i] = new vpnurl();\n\t\t\t\tobj[i].set_urlname(urlname[i]);\n\t\t\t\tresponse[i] = (vpnurl) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public function setDeidentifyTemplates($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\DeidentifyTemplate::class);\n        $this->deidentify_templates = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setRegexFileSet($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CloudStorageRegexFileSet::class);\n        $this->regex_file_set = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def trace scope: nil, timeout: nil, client_config: nil\n      Google::Cloud.trace @project, @keyfile, scope: scope,\n                                              timeout: (timeout || @timeout),\n                                              client_config: client_config\n    end", "label": 4}
{"code": "private function throwRequired(array $args)\n    {\n        $missing = [];\n        foreach ($this->argDefinitions as $k => $a) {\n            if (empty($a['required'])\n                || isset($a['default'])\n                || isset($args[$k])\n            ) {\n                continue;\n            }\n            $missing[] = $this->getArgMessage($k, $args, true);\n        }\n        $msg = \"Missing required client configuration options: \\n\\n\";\n        $msg .= implode(\"\\n\\n\", $missing);\n        throw new IAE($msg);\n    }", "label": 2}
{"code": "public function setIntents($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dialogflow\\V2\\Intent::class);\n        $this->intents = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static function print_value( $value, $assoc_args = array() ) {\n\t\tif ( \\WP_CLI\\Utils\\get_flag_value( $assoc_args, 'format' ) === 'json' ) {\n\t\t\t$value = json_encode( $value );\n\t\t} elseif ( \\WP_CLI\\Utils\\get_flag_value( $assoc_args, 'format' ) === 'yaml' ) {\n\t\t\t$value = Spyc::YAMLDump( $value, 2, 0 );\n\t\t} elseif ( is_array( $value ) || is_object( $value ) ) {\n\t\t\t$value = var_export( $value, true );\n\t\t}\n\n\t\techo $value . \"\\n\";\n\t}", "label": 2}
{"code": "private boolean isOrdered(FieldDescriptor[] flds, String[] pkFieldNames)\r\n    {\r\n        if((flds.length > 1 && pkFieldNames == null) || flds.length != pkFieldNames.length)\r\n        {\r\n            throw new PersistenceBrokerException(\"pkFieldName length does not match number of defined PK fields.\" +\r\n                    \" Expected number of PK fields is \" + flds.length + \", given number was \" +\r\n                    (pkFieldNames != null ? pkFieldNames.length : 0));\r\n        }\r\n        boolean result = true;\r\n        for(int i = 0; i < flds.length; i++)\r\n        {\r\n            FieldDescriptor fld = flds[i];\r\n            result = result && fld.getPersistentField().getName().equals(pkFieldNames[i]);\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "public static base_response add(nitro_service client, nspbr6 resource) throws Exception {\n\t\tnspbr6 addresource = new nspbr6();\n\t\taddresource.name = resource.name;\n\t\taddresource.td = resource.td;\n\t\taddresource.action = resource.action;\n\t\taddresource.srcipv6 = resource.srcipv6;\n\t\taddresource.srcipop = resource.srcipop;\n\t\taddresource.srcipv6val = resource.srcipv6val;\n\t\taddresource.srcport = resource.srcport;\n\t\taddresource.srcportop = resource.srcportop;\n\t\taddresource.srcportval = resource.srcportval;\n\t\taddresource.destipv6 = resource.destipv6;\n\t\taddresource.destipop = resource.destipop;\n\t\taddresource.destipv6val = resource.destipv6val;\n\t\taddresource.destport = resource.destport;\n\t\taddresource.destportop = resource.destportop;\n\t\taddresource.destportval = resource.destportval;\n\t\taddresource.srcmac = resource.srcmac;\n\t\taddresource.protocol = resource.protocol;\n\t\taddresource.protocolnumber = resource.protocolnumber;\n\t\taddresource.vlan = resource.vlan;\n\t\taddresource.Interface = resource.Interface;\n\t\taddresource.priority = resource.priority;\n\t\taddresource.state = resource.state;\n\t\taddresource.msr = resource.msr;\n\t\taddresource.monitor = resource.monitor;\n\t\taddresource.nexthop = resource.nexthop;\n\t\taddresource.nexthopval = resource.nexthopval;\n\t\taddresource.nexthopvlan = resource.nexthopvlan;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public function objects(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        return new ObjectIterator(\n            new ObjectPageIterator(\n                function (array $object) {\n                    return new StorageObject(\n                        $this->connection,\n                        $object['name'],\n                        $this->identity['bucket'],\n                        isset($object['generation']) ? $object['generation'] : null,\n                        $object + array_filter([\n                            'requesterProjectId' => $this->identity['userProject']\n                        ])\n                    );\n                },\n                [$this->connection, 'listObjects'],\n                $options + $this->identity,\n                ['resultLimit' => $resultLimit]\n            )\n        );\n    }", "label": 2}
{"code": "func (r *reader) SetReadahead(readahead int64) {\n\tr.mu.Lock()\n\tr.readahead = readahead\n\tr.mu.Unlock()\n\tr.t.cl.lock()\n\tdefer r.t.cl.unlock()\n\tr.posChanged()\n}", "label": 5}
{"code": "protected function installFromFile()\n    {\n        if (!file_exists($path = base_path('modules.json'))) {\n            $this->error(\"File 'modules.json' does not exist in your project root.\");\n\n            return;\n        }\n\n        $modules = Json::make($path);\n\n        $dependencies = $modules->get('require', []);\n\n        foreach ($dependencies as $module) {\n            $module = collect($module);\n\n            $this->install(\n                $module->get('name'),\n                $module->get('version'),\n                $module->get('type')\n            );\n        }\n    }", "label": 2}
{"code": "function(userId, applicationId, callerIPAddress) {\n    return new Promise((resolve, reject) => {\n      this._start()\n          .uri('/api/login')\n          .urlSegment(userId)\n          .urlSegment(applicationId)\n          .urlParameter('ipAddress', callerIPAddress)\n          .put()\n          .go(this._responseHandler(resolve, reject));\n    });\n  }", "label": 3}
{"code": "def apply_default_scoping\n      if default_scoping\n        default_scoping.call.selector.each do |field, value|\n          attributes[field] = value unless value.respond_to?(:each)\n        end\n      end\n    end", "label": 4}
{"code": "private void prepare() throws IOException, DocumentException, PrintingException {\n\t\tif (baos == null) {\n\t\t\tbaos = new ByteArrayOutputStream(); // let it grow as much as needed\n\t\t}\n\t\tbaos.reset();\n\t\tboolean resize = false;\n\t\tif (page.getConstraint().getWidth() == 0 || page.getConstraint().getHeight() == 0) {\n\t\t\tresize = true;\n\t\t}\n\t\t// Create a document in the requested ISO scale.\n\t\tDocument document = new Document(page.getBounds(), 0, 0, 0, 0);\n\t\tPdfWriter writer;\n\t\twriter = PdfWriter.getInstance(document, baos);\n\n\t\t// Render in correct colors for transparent rasters\n\t\twriter.setRgbTransparencyBlending(true);\n\n\t\t// The mapView is not scaled to the document, we assume the mapView\n\t\t// has the right ratio.\n\n\t\t// Write document title and metadata\n\t\tdocument.open();\n\t\tPdfContext context = new PdfContext(writer);\n\t\tcontext.initSize(page.getBounds());\n\t\t// first pass of all children to calculate size\n\t\tpage.calculateSize(context);\n\t\tif (resize) {\n\t\t\t// we now know the bounds of the document\n\t\t\t// round 'm up and restart with a new document\n\t\t\tint width = (int) Math.ceil(page.getBounds().getWidth());\n\t\t\tint height = (int) Math.ceil(page.getBounds().getHeight());\n\t\t\tpage.getConstraint().setWidth(width);\n\t\t\tpage.getConstraint().setHeight(height);\n\n\t\t\tdocument = new Document(new Rectangle(width, height), 0, 0, 0, 0);\n\t\t\twriter = PdfWriter.getInstance(document, baos);\n\t\t\t// Render in correct colors for transparent rasters\n\t\t\twriter.setRgbTransparencyBlending(true);\n\n\t\t\tdocument.open();\n\t\t\tbaos.reset();\n\t\t\tcontext = new PdfContext(writer);\n\t\t\tcontext.initSize(page.getBounds());\n\t\t}\n\t\t// int compressionLevel = writer.getCompressionLevel(); // For testing\n\t\t// writer.setCompressionLevel(0);\n\n\t\t// Actual drawing\n\t\tdocument.addTitle(\"Geomajas\");\n\t\t// second pass to layout\n\t\tpage.layout(context);\n\t\t// finally render (uses baos)\n\t\tpage.render(context);\n\n\t\tdocument.add(context.getImage());\n\t\t// Now close the document\n\t\tdocument.close();\n\t}", "label": 0}
{"code": "func (h *Handler) deleteBucket() error {\n\t// first, list and delete all the objects in the bucket\n\tout, err := h.client.ListObjectVersions(&s3.ListObjectVersionsInput{\n\t\tBucket: aws.String(h.Bucket),\n\t})\n\tif err != nil {\n\t\treturn ConvertS3Error(err)\n\t}\n\tfor _, ver := range out.Versions {\n\t\t_, err := h.client.DeleteObject(&s3.DeleteObjectInput{\n\t\t\tBucket:    aws.String(h.Bucket),\n\t\t\tKey:       ver.Key,\n\t\t\tVersionId: ver.VersionId,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn ConvertS3Error(err)\n\t\t}\n\t}\n\t_, err = h.client.DeleteBucket(&s3.DeleteBucketInput{\n\t\tBucket: aws.String(h.Bucket),\n\t})\n\treturn ConvertS3Error(err)\n}", "label": 5}
{"code": "def add_build_configuration(name, type)\n      build_configuration_list = root_object.build_configuration_list\n      if build_configuration = build_configuration_list[name]\n        build_configuration\n      else\n        build_configuration = new(XCBuildConfiguration)\n        build_configuration.name = name\n        common_settings = Constants::PROJECT_DEFAULT_BUILD_SETTINGS\n        settings = ProjectHelper.deep_dup(common_settings[:all])\n        settings.merge!(ProjectHelper.deep_dup(common_settings[type]))\n        build_configuration.build_settings = settings\n        build_configuration_list.build_configurations << build_configuration\n        build_configuration\n      end\n    end", "label": 4}
{"code": "public static <T extends JsonRtn> T parseJsonRtn(String jsonRtn, Class<T> jsonRtnClazz) {\n        T rtn = JSONObject.parseObject(jsonRtn, jsonRtnClazz);\n        appendErrorHumanMsg(rtn);\n        return rtn;\n    }", "label": 0}
{"code": "@SuppressWarnings(\"unchecked\")\n    public static <T extends Serializable> T makeClone(T from) {\n        return (T) SerializationUtils.clone(from);\n    }", "label": 0}
{"code": "def generate_config_file():\n    \"\"\"\n    Generate a config file for a ProTECT run on hg19.\n\n    :return: None\n    \"\"\"\n    shutil.copy(os.path.join(os.path.dirname(__file__), 'input_parameters.yaml'),\n                os.path.join(os.getcwd(), 'ProTECT_config.yaml'))", "label": 1}
{"code": "function Bookmark($txt, $level = 0, $y = 0)\n\t{\n\t\t$txt = $this->purify_utf8_text($txt);\n\t\tif ($this->text_input_as_HTML) {\n\t\t\t$txt = $this->all_entities_to_utf8($txt);\n\t\t}\n\t\tif ($y == -1) {\n\t\t\tif (!$this->ColActive) {\n\t\t\t\t$y = $this->y;\n\t\t\t} else {\n\t\t\t\t$y = $this->y0;\n\t\t\t} // If columns are on - mark top of columns\n\t\t}\n\n\t\t// else y is used as set, or =0 i.e. top of page\n\t\t// DIRECTIONALITY RTL\n\t\t$bmo = ['t' => $txt, 'l' => $level, 'y' => $y, 'p' => $this->page];\n\n\t\tif ($this->keep_block_together) {\n\t\t\t// do nothing\n\t\t} elseif ($this->table_rotate) {\n\t\t\t$this->tbrot_BMoutlines[] = $bmo;\n\t\t} elseif ($this->kwt) {\n\t\t\t$this->kwt_BMoutlines[] = $bmo;\n\t\t} elseif ($this->ColActive) {\n\t\t\t$this->col_BMoutlines[] = $bmo;\n\t\t} else {\n\t\t\t$this->BMoutlines[] = $bmo;\n\t\t}\n\t}", "label": 2}
{"code": "function getBuildFactory(build) {\n  return function createBuild(inputpath, outputname) {\n    const input = path.relative(process.cwd(), inputpath);\n    let parent = build;\n\n    if (!parent.builds.some(build => build.input == input)) {\n      const outputpath = path.join(path.dirname(parent.outputpaths[0]), outputname);\n      const buildConfig = {\n        batch: parent.batch,\n        boilerplate: false,\n        bootstrap: false,\n        browser: parent.browser,\n        bundle: parent.bundle,\n        fileCache: parent.fileCache,\n        index: ++numBuilds,\n        input,\n        inputpaths: [inputpath],\n        isAppServer: false,\n        isDynamicBuild: true,\n        label: '',\n        level: parent.level + 1,\n        output: path.relative(process.cwd(), path.dirname(outputpath)),\n        outputpaths: [outputpath],\n        parent,\n        resolverCache: parent.resolverCache,\n        runtimeOptions: parent.runtimeOptions,\n        type: parent.type,\n        watchOnly: parent.watchOnly\n      };\n      const build = buildFactory(buildConfig);\n\n      build.fileFactoryOptions = getFileFactoryOptions(\n        build,\n        parent,\n        null,\n        null,\n        Object.assign({}, parent.fileFactoryOptions)\n      );\n      build.fileFactory = build.fileFactoryOptions.fileFactory;\n      parent.builds.push(build);\n      parent.childInputpaths.push(inputpath);\n    }\n\n    // Find root build\n    while (parent.parent)\n      parent = parent.parent;\n    parent.processFilesOptions.importBoilerplate = true;\n  };\n}", "label": 3}
{"code": "def determine_drift(self):\n        \"\"\"\n        Determine the drift of the stack.\n\n        Args:\n            None\n\n        Returns:\n            Good or Bad; True or False\n        \"\"\"\n        try:\n            response = self._cloud_formation.detect_stack_drift(StackName=self._stack_name)\n            drift_request_id = response.get('StackDriftDetectionId', None)\n            if drift_request_id:\n                logging.info('drift_request_id: %s - polling', drift_request_id)\n                drift_calc_done = False\n                while not drift_calc_done:\n                    time.sleep(self.nap_time)\n                    response = self._cloud_formation.describe_stack_drift_detection_status(\n                        StackDriftDetectionId=drift_request_id\n                    )\n                    current_state = response.get('DetectionStatus', None)\n                    logging.info(\n                        'describe_stack_drift_detection_status(): {}'.format(current_state)\n                    )\n                    drift_calc_done = current_state in CALC_DONE_STATES\n                    drift_answer = response.get('StackDriftStatus', 'UNKNOWN')\n\n                logging.info('drift of {}: {}'.format(\n                    self._stack_name,\n                    drift_answer\n                ))\n\n                if drift_answer == 'DRIFTED':\n                    if self._verbose:\n                        self._print_drift_report()\n                    return False\n                else:\n                    return True\n            else:\n                logging.warning('drift_request_id is None')\n\n            return False\n        except Exception as wtf:\n            logging.error(wtf, exc_info=True)\n            return False", "label": 1}
{"code": "def normalize_keywords(keywords)\n      keywords = cleanup_strings(keywords)\n      return '' if keywords.blank?\n\n      keywords.each(&:downcase!) if MetaTags.config.keywords_lowercase\n      separator = cleanup_string MetaTags.config.keywords_separator, strip: false\n\n      keywords = truncate_array(keywords, MetaTags.config.keywords_limit, separator)\n      safe_join(keywords, separator)\n    end", "label": 4}
{"code": "func (c *Manager) GetLibraryItemFile(ctx context.Context, id, fileName string) (*File, error) {\n\turl := internal.URL(c, internal.LibraryItemFilePath).WithID(id).WithAction(\"get\")\n\tspec := struct {\n\t\tName string `json:\"name\"`\n\t}{fileName}\n\tvar res File\n\treturn &res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "public static double KullbackLeiblerDivergence(double[] p, double[] q) {\n        boolean intersection = false;\n        double k = 0;\n\n        for (int i = 0; i < p.length; i++) {\n            if (p[i] != 0 && q[i] != 0) {\n                intersection = true;\n                k += p[i] * Math.log(p[i] / q[i]);\n            }\n        }\n\n        if (intersection)\n            return k;\n        else\n            return Double.POSITIVE_INFINITY;\n    }", "label": 0}
{"code": "public static <T extends HasWord> TokenizerFactory<T> factory(LexedTokenFactory<T> factory, String options) {\r\n    return new PTBTokenizerFactory<T>(factory, options);\r\n\r\n  }", "label": 0}
{"code": "def move_manifest\n      if File.exist?(PackageCommandGenerator.manifest_path)\n        FileUtils.mv(PackageCommandGenerator.manifest_path, File.expand_path(Gym.config[:output_directory]), force: true)\n        manifest_path = File.join(File.expand_path(Gym.config[:output_directory]), File.basename(PackageCommandGenerator.manifest_path))\n\n        UI.success(\"Successfully exported the manifest.plist file:\")\n        UI.message(manifest_path)\n        manifest_path\n      end\n    end", "label": 4}
{"code": "def promoted?(emendation)\n      logs = Decidim::ActionLog.where(decidim_component_id: emendation.component)\n                               .where(decidim_user_id: emendation.creator_author)\n                               .where(action: \"promote\")\n\n      logs.select { |log| log.extra[\"promoted_from\"] == emendation.id }.present?\n    end", "label": 4}
{"code": "public function consume(array $requestData)\n    {\n        return $this->messageFactory($requestData, $this->connection, $this->projectId, $this->encode);\n    }", "label": 2}
{"code": "private function do_early_invoke( $when ) {\n\t\tif ( ! isset( $this->early_invoke[ $when ] ) ) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Search the value of @when from the command method.\n\t\t$real_when = '';\n\t\t$r         = $this->find_command_to_run( $this->arguments );\n\t\tif ( is_array( $r ) ) {\n\t\t\tlist( $command, $final_args, $cmd_path ) = $r;\n\n\t\t\tforeach ( $this->early_invoke as $_when => $_path ) {\n\t\t\t\tforeach ( $_path as $cmd ) {\n\t\t\t\t\tif ( $cmd === $cmd_path ) {\n\t\t\t\t\t\t$real_when = $_when;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tforeach ( $this->early_invoke[ $when ] as $path ) {\n\t\t\tif ( $this->cmd_starts_with( $path ) ) {\n\t\t\t\tif ( empty( $real_when ) || ( $real_when && $real_when === $when ) ) {\n\t\t\t\t\t$this->run_command_and_exit();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "public function setIndexConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\Admin\\V1\\Field_IndexConfig::class);\n        $this->index_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func UnmarshalBinary(data []byte, fields ...interface{}) error {\n\tbuf := bytes.NewBuffer(data)\n\n\tfor _, p := range fields {\n\t\tswitch m := p.(type) {\n\t\tcase encoding.BinaryUnmarshaler:\n\t\t\treturn m.UnmarshalBinary(buf.Bytes())\n\t\tcase *[]byte:\n\t\t\t*m = buf.Bytes()\n\t\t\treturn nil\n\t\tdefault:\n\t\t\terr := binary.Read(buf, binary.LittleEndian, p)\n\t\t\tif err != nil {\n\t\t\t\treturn ProtocolError(err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def _enable_lock(func):\n    \"\"\"\n    The decorator for ensuring thread-safe when current cache instance is concurrent status.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        self = args[0]\n        if self.is_concurrent:\n            only_read = kwargs.get('only_read')\n            if only_read is None or only_read:\n                with self._rwlock:\n                    return func(*args, **kwargs)\n            else:\n                self._rwlock.acquire_writer()\n                try:\n                    return func(*args, **kwargs)\n                finally:\n                    self._rwlock.release()\n        else:\n            return func(*args, **kwargs)\n\n    return wrapper", "label": 1}
{"code": "private void checkExtents(ClassDescriptorDef classDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        HashMap            processedClasses = new HashMap();\r\n        InheritanceHelper  helper           = new InheritanceHelper();\r\n        ClassDescriptorDef curExtent;\r\n        boolean            canBeRemoved;\r\n\r\n        for (Iterator it = classDef.getExtentClasses(); it.hasNext();)\r\n        {\r\n            curExtent    = (ClassDescriptorDef)it.next();\r\n            canBeRemoved = false;\r\n            if (classDef.getName().equals(curExtent.getName()))\r\n            {\r\n                throw new ConstraintException(\"The class \"+classDef.getName()+\" specifies itself as an extent-class\");\r\n            }\r\n            else if (processedClasses.containsKey(curExtent))\r\n            {\r\n                canBeRemoved = true;\r\n            }\r\n            else\r\n            {\r\n                try\r\n                {\r\n                    if (!helper.isSameOrSubTypeOf(curExtent, classDef.getName(), false))\r\n                    {\r\n                        throw new ConstraintException(\"The class \"+classDef.getName()+\" specifies an extent-class \"+curExtent.getName()+\" that is not a sub-type of it\");\r\n                    }\r\n                    // now we check whether we already have an extent for a base-class of this extent-class\r\n                    for (Iterator processedIt = processedClasses.keySet().iterator(); processedIt.hasNext();)\r\n                    {\r\n                        if (helper.isSameOrSubTypeOf(curExtent, ((ClassDescriptorDef)processedIt.next()).getName(), false))\r\n                        {\r\n                            canBeRemoved = true;\r\n                            break;\r\n                        }\r\n                    }\r\n                }\r\n                catch (ClassNotFoundException ex)\r\n                {\r\n                    // won't happen because we don't use lookup of the actual classes\r\n                }\r\n            }\r\n            if (canBeRemoved)\r\n            {\r\n                it.remove();\r\n            }\r\n            processedClasses.put(curExtent, null);\r\n        }\r\n    }", "label": 0}
{"code": "def _config(self):\n        \"\"\"Execute git config.\"\"\"\n        cfg_wr = self.repo.config_writer()\n        cfg_wr.add_section('user')\n        cfg_wr.set_value('user', 'name', self.metadata.author)\n        cfg_wr.set_value('user', 'email', self.metadata.email)\n        cfg_wr.release()", "label": 1}
{"code": "func (h Histogram) AsPercentiles() []Percentile {\n\tif h.Count == 0 {\n\t\treturn nil\n\t}\n\tvar percentiles []Percentile\n\tfor _, bucket := range h.Buckets {\n\t\tif bucket.Count == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tif bucket.Count == h.Count || math.IsInf(bucket.UpperBound, 0) {\n\t\t\tpercentiles = append(percentiles, Percentile{\n\t\t\t\tPercentile: 100,\n\t\t\t\tValue:      time.Duration(bucket.UpperBound * float64(time.Second)),\n\t\t\t})\n\t\t\treturn percentiles\n\t\t}\n\t\tpercentiles = append(percentiles, Percentile{\n\t\t\tPercentile: 100 * (float64(bucket.Count) / float64(h.Count)),\n\t\t\tValue:      time.Duration(bucket.UpperBound * float64(time.Second)),\n\t\t})\n\t}\n\treturn percentiles\n}", "label": 5}
{"code": "def from_file(cls, f, filename=None, includedir='', seenfiles=None):\n        '''Create a token stream by reading an input file\n\n        Read tokens from `f`. If an include directive ('@include \"file.cfg\"')\n        is found, read its contents as well.\n\n        The `filename` argument is used for error messages and to detect\n        circular imports. ``includedir`` sets the lookup directory for included\n        files.  ``seenfiles`` is used internally to detect circular includes,\n        and should normally not be supplied by users of is function.\n        '''\n\n        if filename is None:\n            filename = getattr(f, 'name', '<unknown>')\n        if seenfiles is None:\n            seenfiles = set()\n\n        if filename in seenfiles:\n            raise ConfigParseError(\"Circular include: %r\" % (filename,))\n        seenfiles = seenfiles | {filename}  # Copy seenfiles, don't alter it.\n\n        tokenizer = Tokenizer(filename=filename)\n        lines = []\n        tokens = []\n        for line in f:\n            m = re.match(r'@include \"(.*)\"$', line.strip())\n            if m:\n                tokens.extend(tokenizer.tokenize(''.join(lines)))\n                lines = [re.sub(r'\\S', ' ', line)]\n\n                includefilename = decode_escapes(m.group(1))\n                includefilename = os.path.join(includedir, includefilename)\n                try:\n                    includefile = open(includefilename, \"r\")\n                except IOError:\n                    raise ConfigParseError(\"Could not open include file %r\" %\n                                           (includefilename,))\n\n                with includefile:\n                    includestream = cls.from_file(includefile,\n                                                  filename=includefilename,\n                                                  includedir=includedir,\n                                                  seenfiles=seenfiles)\n                tokens.extend(includestream.tokens)\n\n            else:\n                lines.append(line)\n\n        tokens.extend(tokenizer.tokenize(''.join(lines)))\n        return cls(tokens)", "label": 1}
{"code": "public function AnnotateText(\\Google\\Cloud\\Language\\V1\\AnnotateTextRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.cloud.language.v1.LanguageService/AnnotateText',\n        $argument,\n        ['\\Google\\Cloud\\Language\\V1\\AnnotateTextResponse', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "function buildPattern(patternObj, options) {\n  const patternFile = { path: patternObj.path };\n  return Object.assign(patternObj, {\n    name:\n      (patternObj.data && patternObj.data.name) ||\n      titleCase(resourceKey(patternFile))\n  });\n}", "label": 3}
{"code": "public boolean isAlive(Connection conn)\r\n    {\r\n        try\r\n        {\r\n            return con != null ? !con.isClosed() : false;\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            log.error(\"IsAlive check failed, running connection was invalid!!\", e);\r\n            return false;\r\n        }\r\n    }", "label": 0}
{"code": "public static double ChiSquare(double[] histogram1, double[] histogram2) {\n        double r = 0;\n        for (int i = 0; i < histogram1.length; i++) {\n            double t = histogram1[i] + histogram2[i];\n            if (t != 0)\n                r += Math.pow(histogram1[i] - histogram2[i], 2) / t;\n        }\n\n        return 0.5 * r;\n    }", "label": 0}
{"code": "function (cb) {\n\t\t\t\t\tif (o1.options.tempURLKey) {\n\t\t\t\t\t\to1._log('Setting temporary URL key for account...');\n\t\t\t\t\t\to1._client.setTemporaryUrlKey(o1.options.tempURLKey, cb);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcb();\n\t\t\t\t\t}\n\t\t\t\t}", "label": 3}
{"code": "public static <E> double logSum(Counter<E> c) {\r\n    return ArrayMath.logSum(ArrayMath.unbox(c.values()));\r\n  }", "label": 0}
{"code": "function readStrucPerm(on, req, res, next) {\n\t//console.log('readStrucPerm: req.session.user_id = ' + req.session.user_id);\n\t//solo nel caso di favicon.ico non ha le session impostate, non so perch\u00e8,\n\t//quindi bypasso il controllo, perch\u00e8 su favicon non ho nessuna restrizione\n\tif ( !req.session )\n\t{\n\t\tnext();\n\t}\n\telse\n\t{\n\t\t//azzero i permessi\n\t\treq.session.loggedIn = false;\n\t\treq.session.canCreate = false;\n\t\treq.session.canModify = false;\n\t\treq.session.canModifyMyself = false; //questo \u00e8 un permesso che vale solo per l'elemento \"users\"\n\t\t//controllo se sono loggato\n\t\tif (req.session.user_id) {\n\t\t\t//l'utente risulta loggato\n\t\t\t//controllo se i suoi dati di login sono validi\n\t\t\t//(questo controllo va fatto ogni volta, perch\u00e8 se dall'ultimo conrollo l'utente fosse stato cancellato, non me ne accorgerei senza controllo\n\t\t\treq.app.jsl.sess.checkValidUser(req, function(result, user_id) { \n\t\t\t\tif ( result )\n\t\t\t\t{\n\t\t\t\t\t//i dati di login sono validi\n\t\t\t\t\treq.session.loggedIn = true;\n\t\t\t\t\tif ( user_id == 'superadmin' )\n\t\t\t\t\t{\n\t\t\t\t\t\t//se sono super admin, ho sempre permesso di modify su tutti i contenuti, ma non ho il create (a parte sugli users)\n\t\t\t\t\t\t//questo perch\u00e8 quando si crea un contenuto, questo \u00e8 strettamente legato all'utente che lo crea, e il superadmin\n\t\t\t\t\t\t//non \u00e8 un utente vero \u00e8 proprio (non \u00e8 presente nel db, non ha id). il super admin serve solo per poter vedere e modificare tutto, ma non pu\u00f2 creare nulla\n\t\t\t\t\t\treq.session.canModify = true;\n\t\t\t\t\t\treq.session.canModifyMyself = true; //questo serve per permettere al super admin di modificare gli utenti (il form di modifica lo richiede)\n\t\t\t\t\t\t//solo nel caso degli users, il superadmin ha il create, anche se usersCanRegister = false\n\t\t\t\t\t\tif ( on == 'user' )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\treq.session.canCreate = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//la request puo essere processata\n\t\t\t\t\t\tnext();\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t//non sono superadmin\n\t\t\t\t\t\t//siccome si tratta di permessi su elementi della struttura, chiunque (loggato) ha sempre il permesso di create nuovi elementi\n\t\t\t\t\t\t//(tranne per il caso degli \"user\" in cui si creano altri utenti con il bottone \"registrati\", che per\u00f2 non prevede di essere loggati)\n\t\t\t\t\t\tif ( on != 'user' )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\treq.session.canCreate = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//differenzio i permessi di modify in base all'oggetto trattato\n\t\t\t\t\t\tswitch (on)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tcase 'user':\n\t\t\t\t\t\t\t\t//user \u00e8 un elemento della struttura particolare, perch\u00e8, a differenza di tutti gli altri elementi di struttura, ogni utente pu\u00f2 solo modificare\n\t\t\t\t\t\t\t\t//se stesso. inoltre user non ha un \"author\" poich\u00e8 un utente \u00e8 creato da se stesso tramite il bottone \"register\"\n\t\t\t\t\t\t\t\t//nel caso di modifica di users, ho modify solo per modificare me stesso\n\t\t\t\t\t\t\t\tif ( req.params.id == req.session.user_id ) //controllo se l'id dell'utente da modificare \u00e8 quello dell'utente loggato, cio\u00e8 se modifico me stesso\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t//lo user id nella route richiesta corrisponde al mio, quindi posso modificare me stesso (il mio profilo)\n\t\t\t\t\t\t\t\t\treq.session.canModifyMyself = true; \n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\t//ora come ora per tutti gli altri elementi della struttura chiunque ha permesso di modify, ma solo sui propri elementi\n\t\t\t\t\t\t\t\treq.session.canModify = true; \n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//continuo\n\t\t\t\t\t\tnext();\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t//i dati di login non sono validi\n\t\t\t\t\t//console.log('readStrucPerm: login NON valido');\n\t\t\t\t\t//forzo un logout (potrebbe verificarsi il caso in cui un utente \u00e8 loggato, e viene cancellato dal db. in quel caso deve avvenire anche il suo logout)\n\t\t\t\t\tsetSignedOut(req);\n\t\t\t\t\t//vengo mandato in home\n\t\t\t\t\tres.redirect('/');\n\t\t\t\t}\n\t\t\t});\n\t\t\t\n\t\t} else {\n\t\t\t//console.log('readStrucPerm: utente non loggato');\t\t\t\n\t\t\t//non sono loggato. l'unica cosa che posso fare \u00e8 di registrarmi, ovvero creare un nuovo user\n\t\t\t//ma solo se \u00e8 stato previsto nel config\n\t\t\tif ( on == 'user' && req.app.jsl.config.usersCanRegister )\n\t\t\t{\n\t\t\t\treq.session.canCreate = true;\n\t\t\t}\n\t\t\t//non ho nessun permesso, continuo\n\t\t\tnext();\n\t\t}\n\t}\n}", "label": 3}
{"code": "def projection(self, axis):\n        \"\"\"Sums all data along all other axes, then return Hist1D\"\"\"\n        axis = self.get_axis_number(axis)\n        projected_hist = np.sum(self.histogram, axis=self.other_axes(axis))\n        return Hist1d.from_histogram(projected_hist, bin_edges=self.bin_edges[axis])", "label": 1}
{"code": "function () {\n    if (processes && processes.length > 0) {\n        for (var i = processes.length - 1; i >= 0; i--) {\n            processes[i].kill();\n        }\n    }\n}", "label": 3}
{"code": "def del(digest: nil, pattern: nil, count: DEFAULT_COUNT)\n      return delete_by_pattern(pattern, count: count) if pattern\n      return delete_by_digest(digest) if digest\n\n      raise ArgumentError, \"either digest or pattern need to be provided\"\n    end", "label": 4}
{"code": "private function normalizeHeaders(array $headers)\n    {\n        $out = [];\n        foreach ($headers as $name => $value) {\n            $name = strtolower(trim($name));\n            // collapse arrays of values into a comma-separated list.\n            if (!is_array($value)) {\n                $value = [$value];\n            }\n\n            foreach ($value as &$headerValue) {\n                // strip trailing and leading spaces.\n                $headerValue = trim($headerValue);\n\n                // replace newlines with empty strings.\n                $headerValue = str_replace(PHP_EOL, '', $headerValue);\n\n                // collapse multiple whitespace chars to a single space.\n                $headerValue = preg_replace('/\\s+/', ' ', $headerValue);\n            }\n\n            $out[$name] = implode(', ', $value);\n        }\n\n        return $out;\n    }", "label": 2}
{"code": "def language_support(f, attribute, options)\n      return if Fae.languages.blank?\n\n      attribute_array = attribute.to_s.split('_')\n      language_suffix = attribute_array.pop\n      return unless Fae.languages.has_key?(language_suffix.to_sym) || Fae.languages.has_key?(language_suffix)\n\n      label = attribute_array.push(\"(#{language_suffix})\").join(' ').titleize\n      options[:label] = label unless options[:label].present?\n\n      if options[:wrapper_html].present?\n        options[:wrapper_html].deep_merge!({ data: { language: language_suffix } })\n      else\n        options[:wrapper_html] = { data: { language: language_suffix } }\n      end\n    end", "label": 4}
{"code": "func (s *parentStack) push(parents []string) error {\n\tfor i := 0; i < len(parents); i++ {\n\t\tif err := s.p.writeStart(&StartElement{Name: Name{Local: parents[i]}}); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\ts.stack = append(s.stack, parents...)\n\treturn nil\n}", "label": 5}
{"code": "def column_widths(*widths)\n      widths.each_with_index do |value, index|\n        next if value == nil\n        Axlsx::validate_unsigned_numeric(value) unless value == nil\n        find_or_create_column_info(index).width = value\n      end\n    end", "label": 4}
{"code": "private TableAlias getTableAliasForPath(String aPath, String aUserAlias, List hintClasses)\r\n    {\r\n        if (aUserAlias == null)\r\n        {\r\n            return getTableAliasForPath(aPath, hintClasses);\r\n        }\r\n        else\r\n        {\r\n\t\t\treturn getTableAliasForPath(aUserAlias + ALIAS_SEPARATOR + aPath, hintClasses);\r\n        }\r\n    }", "label": 0}
{"code": "func IsValidType(objType ObjectType) bool {\n\tswitch objType {\n\tcase EndpointObject:\n\t\tfallthrough\n\tcase NetworkObject:\n\t\tfallthrough\n\tcase OpaqueObject:\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "func (self *Transcoder) Close() (err error) {\n\tfor _, stream := range self.streams {\n\t\tif stream.aenc != nil {\n\t\t\tstream.aenc.Close()\n\t\t\tstream.aenc = nil\n\t\t}\n\t\tif stream.adec != nil {\n\t\t\tstream.adec.Close()\n\t\t\tstream.adec = nil\n\t\t}\n\t}\n\tself.streams = nil\n\treturn\n}", "label": 5}
{"code": "public static ComponentsMultiThread getComponentsMultiThread() {\n    TransactionLogger instance = getInstance();\n    if (instance == null) {\n      return null;\n    }\n\n    return instance.componentsMultiThread;\n  }", "label": 0}
{"code": "def html_truncate(text, options = {})\n      options[:max_length] = options.delete(:length) || options[:max_length]\n      options[:tail] = options.delete(:separator) || options[:tail] || \"...\"\n      options[:count_tags] ||= false\n      options[:count_tail] ||= false\n      options[:tail_before_final_tag] ||= true\n\n      Truncato.truncate(text, options)\n    end", "label": 4}
{"code": "def datasetsBM(host=biomart_host):\n    \"\"\"\n    Lists BioMart datasets.\n\n    :param host: address of the host server, default='http://www.ensembl.org/biomart'\n\n    :returns: nothing\n\n    \"\"\"\n    stdout_ = sys.stdout #Keep track of the previous value.\n    stream = StringIO()\n    sys.stdout = stream   \n    server = BiomartServer(biomart_host)\n    server.show_datasets()\n    sys.stdout = stdout_ # restore the previous stdout.\n    variable = stream.getvalue() \n    v=variable.replace(\"{\",\" \") \n    v=v.replace(\"}\",\" \") \n    v=v.replace(\": \",\"\\t\")\n    print(v)", "label": 1}
{"code": "def broker_url(self):\n        \"\"\" Returns a \"broker URL\" for use with Celery. \"\"\"\n        return 'amqp://{}:{}@{}/{}'.format(\n            self.user, self.password, self.name, self.vhost)", "label": 1}
{"code": "private function addAllOfProperty(Schema $childSchema, Schema $parentSchema)\n    {\n        $currentSchema = new Schema(['_context' => $childSchema->_context]);\n\n        $currentSchema->mergeProperties($childSchema);\n\n        $defaultValues = get_class_vars(Schema::class);\n\n        foreach (get_object_vars($currentSchema) as $property => $val) {\n            $childSchema->{$property} = $defaultValues[$property];\n        }\n\n        $childSchema->schema = $currentSchema->schema;\n        unset($currentSchema->schema);\n        if ($childSchema->allOf === UNDEFINED) {\n            $childSchema->allOf = [];\n        }\n        $childSchema->allOf[] = new Schema(\n            [\n            '_context' => $parentSchema->_context,\n            'ref' => Components::SCHEMA_REF . $parentSchema->schema\n            ]\n        );\n        $childSchema->allOf[] = $currentSchema;\n    }", "label": 2}
{"code": "function validateThemeNotInUseByApps(cb) {\n    var appThemeModel = models.get(connections.mongooseConnection, models.MODELNAMES.APP_THEMES);\n\n    appThemeModel.count({\"theme\" : options._id}, function(err, countAppsUsingTheme) {\n      if (err) {\n        return cb(err);\n      }\n\n      if (countAppsUsingTheme > 0) {\n        return cb(new Error(\"Cannot delete theme in use by apps. Apps Using this theme\" + countAppsUsingTheme));\n      }\n\n      return cb();\n    });\n  }", "label": 3}
{"code": "func checkIfAvailable(head *sequence, ordinal uint64) (uint64, uint64, error) {\n\tbytePos, bitPos := ordinalToPos(ordinal)\n\n\t// Find the sequence containing this byte\n\tcurrent, _, _, inBlockBytePos := findSequence(head, bytePos)\n\tif current != nil {\n\t\t// Check whether the bit corresponding to the ordinal address is unset\n\t\tbitSel := blockFirstBit >> (inBlockBytePos*8 + bitPos)\n\t\tif current.block&bitSel == 0 {\n\t\t\treturn bytePos, bitPos, nil\n\t\t}\n\t}\n\n\treturn invalidPos, invalidPos, ErrBitAllocated\n}", "label": 5}
{"code": "def run_cli(task_args)\n      cli_args = parse_args\n      logger = quiet ? HamlLint::Logger.silent : HamlLint::Logger.new(STDOUT)\n      result = HamlLint::CLI.new(logger).run(Array(cli_args) + files_to_lint(task_args))\n\n      fail \"#{HamlLint::APP_NAME} failed with exit code #{result}\" unless result == 0\n    end", "label": 4}
{"code": "function getBlock(type) {\n  switch (type) {\n    case 'Radio':\n    case 'Bool':\n      return Radio;\n\n    case 'Checkbox':\n      return Checkbox;\n\n    case 'Number':\n      return Number;\n\n    case 'Select':\n      return Select;\n\n    case 'Image':\n      return Image;\n\n    case 'Text':\n      return Text;\n\n    case 'Input':\n      return Input;\n\n    case 'Textarea':\n      return Textarea;\n\n    case 'Data':\n      return Data;\n\n    case 'Evaluation':\n      return Evaluation;\n\n    case 'FetchOrg':\n      return FetchOrg;\n\n    case 'Table':\n      return Table;\n\n    case 'Signature':\n      return Signature;\n\n    case 'Summary':\n      return Summary;\n\n    case 'Sum':\n      return Sum;\n\n    case 'Switch':\n      return Switch;\n\n    case 'Information':\n      return Information;\n\n    default:\n      return null;\n  }\n}", "label": 3}
{"code": "public static <T> String listToString(List<T> list, final boolean justValue) {\r\n    return listToString(list, justValue, null);\r\n  }", "label": 0}
{"code": "func OptionDefaultAddressPoolConfig(addressPool []*ipamutils.NetworkToSplit) Option {\n\treturn func(c *Config) {\n\t\tc.Daemon.DefaultAddressPool = addressPool\n\t}\n}", "label": 5}
{"code": "func (s *MockStore) List(prefix string) ([]*store.KVPair, error) {\n\treturn nil, ErrNotImplemented\n}", "label": 5}
{"code": "def _convert_to_list(self, value, delimiters):\n        \"\"\"\n        Return a list value translating from other types if necessary.\n\n        :param str value:  The value to convert.\n        \"\"\"\n        if not value:\n            return []\n        if delimiters:\n            return [l.strip() for l in value.split(delimiters)]\n        return [l.strip() for l in value.split()]", "label": 1}
{"code": "def area(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'area_for', &block)\n      define_method(name) do\n        return platform.click_area_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").click\n      end\n    end", "label": 4}
{"code": "func NewConnectionsLimiter(config LimiterConfig) (*ConnectionsLimiter, error) {\n\tlimiter := ConnectionsLimiter{\n\t\tMutex:          &sync.Mutex{},\n\t\tmaxConnections: config.MaxConnections,\n\t\tconnections:    make(map[string]int64),\n\t}\n\n\tipExtractor, err := utils.NewExtractor(\"client.ip\")\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tlimiter.ConnLimiter, err = connlimit.New(\n\t\tnil, ipExtractor, config.MaxConnections)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &limiter, nil\n}", "label": 5}
{"code": "public function walkCoalesceExpression($coalesceExpression)\n    {\n        $sql = 'COALESCE(';\n\n        $scalarExpressions = [];\n\n        foreach ($coalesceExpression->scalarExpressions as $scalarExpression) {\n            $scalarExpressions[] = $this->walkSimpleArithmeticExpression($scalarExpression);\n        }\n\n        return $sql . implode(', ', $scalarExpressions) . ')';\n    }", "label": 2}
{"code": "function(properties, value, equals)\n  {\n    var where = createWhere( properties, value, equals );\n\n    var hasChanges = function( model )\n    {\n      return where( model ) && model.$hasChanges();\n    };\n\n    return this.contains( hasChanges );\n  }", "label": 3}
{"code": "public function tables(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $table) {\n                    return new Table(\n                        $this->connection,\n                        $table['tableReference']['tableId'],\n                        $this->identity['datasetId'],\n                        $this->identity['projectId'],\n                        $this->mapper,\n                        $table\n                    );\n                },\n                [$this->connection, 'listTables'],\n                $options + $this->identity,\n                [\n                    'itemsKey' => 'tables',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "def renew(id, increment = 0)\n      json = client.put(\"/v1/sys/renew/#{id}\", JSON.fast_generate(\n        increment: increment,\n      ))\n      return Secret.decode(json)\n    end", "label": 4}
{"code": "def _agent_from_distribution(distribution, value=-1, agent_id=None):\n    \"\"\"Used in the initialization of agents given an agent distribution.\"\"\"\n    if value < 0:\n        value = random.random()\n    for d in sorted(distribution, key=lambda x: x['threshold']):\n        threshold = d['threshold']\n        # Check if the definition matches by id (first) or by threshold\n        if not ((agent_id is not None and threshold == STATIC_THRESHOLD and agent_id in d['ids']) or \\\n                (value >= threshold[0] and value < threshold[1])):\n            continue\n        state = {}\n        if 'state' in d:\n            state = deepcopy(d['state'])\n        return d['agent_type'], state\n\n    raise Exception('Distribution for value {} not found in: {}'.format(value, distribution))", "label": 1}
{"code": "function process(payload) {\n  var batteryRaw = parseInt(payload.substr(2,2),16) % 64;\n  var temperatureRaw = (parseInt(payload.substr(0,3),16) >> 2) % 256;\n  var battery = ((batteryRaw / 34) + 1.8).toFixed(2) + \"V\";\n  var temperature = ((temperatureRaw - 80) / 2).toFixed(1) + \"C\";\n  return {\n    battery: battery,\n    temperature: temperature\n  };\n}", "label": 3}
{"code": "function isIValueElementNode(node) {\n    return typeof node['getValue'] === 'function' &&\n        typeof node['setValue'] === 'function' &&\n        typeof node.currently['getValue'] === 'function' &&\n        typeof node.currently['hasValue'] === 'function' &&\n        typeof node.currently['hasAnyValue'] === 'function' &&\n        typeof node.currently['containsValue'] === 'function' &&\n        typeof node.wait['hasValue'] === 'function' &&\n        typeof node.wait['hasAnyValue'] === 'function' &&\n        typeof node.wait['containsValue'] === 'function' &&\n        typeof node.eventually['hasValue'] === 'function' &&\n        typeof node.eventually['hasAnyValue'] === 'function' &&\n        typeof node.eventually['containsValue'] === 'function';\n}", "label": 3}
{"code": "def list_order(f, attribute, options)\n      if is_association?(f, attribute) && !options[:collection]\n        begin\n          options[:collection] = to_class(attribute).for_fae_index\n        rescue NameError\n          raise \"Fae::MissingCollection: `#{attribute}` isn't an orderable class, define your order using the `collection` option.\"\n        end\n      end\n    end", "label": 4}
{"code": "function GetFirstBlockFill()\n\t{\n\t\t// Returns the first blocklevel that uses a bgcolor fill\n\t\t$startfill = 0;\n\t\tfor ($i = 1; $i <= $this->blklvl; $i++) {\n\t\t\tif ($this->blk[$i]['bgcolor'] || $this->blk[$i]['border_left']['w'] || $this->blk[$i]['border_right']['w'] || $this->blk[$i]['border_top']['w'] || $this->blk[$i]['border_bottom']['w']) {\n\t\t\t\t$startfill = $i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\treturn $startfill;\n\t}", "label": 2}
{"code": "protected synchronized Object materializeSubject() throws PersistenceBrokerException\r\n\t{\r\n\t\tTemporaryBrokerWrapper tmp = getBroker();\r\n        try\r\n\t\t{\r\n\t\t\tObject realSubject = tmp.broker.getObjectByIdentity(_id);\r\n\t\t\tif (realSubject == null)\r\n\t\t\t{\r\n\t\t\t\tLoggerFactory.getLogger(IndirectionHandler.class).warn(\r\n\t\t\t\t\t\t\"Can not materialize object for Identity \" + _id + \" - using PBKey \" + getBrokerKey());\r\n\t\t\t}\r\n\t\t\treturn realSubject;\r\n\t\t} catch (Exception ex)\r\n\t\t{\r\n\t\t\tthrow new PersistenceBrokerException(ex);\r\n\t\t} finally\r\n\t\t{\r\n\t\t\ttmp.close();\r\n\t\t}\r\n\t}", "label": 0}
{"code": "def _clearPrices(self):\n        \"\"\" Clears prices according to auction type.\n        \"\"\"\n        for offbid in self.offers + self.bids:\n            if self.auctionType == DISCRIMINATIVE:\n                offbid.clearedPrice = offbid.price\n            elif self.auctionType == FIRST_PRICE:\n                offbid.clearedPrice = offbid.lmbda\n            else:\n                raise ValueError", "label": 1}
{"code": "public ApiResponse<TagsEnvelope> getTagCategoriesWithHttpInfo() throws ApiException {\n        com.squareup.okhttp.Call call = getTagCategoriesValidateBeforeCall(null, null);\n        Type localVarReturnType = new TypeToken<TagsEnvelope>(){}.getType();\n        return apiClient.execute(call, localVarReturnType);\n    }", "label": 0}
{"code": "public static vlan_nsip_binding[] get(nitro_service service, Long id) throws Exception{\n\t\tvlan_nsip_binding obj = new vlan_nsip_binding();\n\t\tobj.set_id(id);\n\t\tvlan_nsip_binding response[] = (vlan_nsip_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setCreationRecord($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\MutationRecord::class);\n        $this->creation_record = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public boolean shouldCache(String requestUri) {\n\t\tString uri = requestUri.toLowerCase();\n\t\treturn checkContains(uri, cacheIdentifiers) || checkSuffixes(uri, cacheSuffixes);\n\t}", "label": 0}
{"code": "func (s *PresenceService) DeleteProxy(name string) error {\n\tkey := backend.Key(proxiesPrefix, name)\n\treturn s.Delete(context.TODO(), key)\n}", "label": 5}
{"code": "def with_logger\n        if env = manifest.environment\n          old_logger = env.logger\n          env.logger = @logger\n        end\n        yield\n      ensure\n        env.logger = old_logger if env\n      end", "label": 4}
{"code": "public MapFactory<E, MutableInteger> getMapFactory() {\r\n    return ErasureUtils.<MapFactory<E,MutableInteger>>uncheckedCast(mapFactory);\r\n  }", "label": 0}
{"code": "def send_temporary_message(content, timeout, tts = false, embed = nil)\n      @bot.send_temporary_message(@id, content, timeout, tts, embed)\n    end", "label": 4}
{"code": "private static List<Segment> parseSegments(String origPathStr) {\n        String pathStr = origPathStr;\n        if (!pathStr.startsWith(\"/\")) {\n            pathStr = pathStr + \"/\";\n        }\n\n        List<Segment> result = new ArrayList<>();\n        for (String segmentStr : PATH_SPLITTER.split(pathStr)) {\n            Matcher m = SEGMENT_PATTERN.matcher(segmentStr);\n            if (!m.matches()) {\n                throw new IllegalArgumentException(\"Bad aql path: \" + origPathStr);\n            }\n            Segment segment = new Segment();\n            segment.attribute = m.group(1);\n            segment.nodeId = m.groupCount() >= 3 ? m.group(3) : null;\n            result.add(segment);\n        }\n        return result;\n    }", "label": 0}
{"code": "def parser\n      @parser ||= OptionParser.new do |opts|\n        opts.banner = USAGE\n\n        opts.on('-b', '--build-id BuildID', 'BuildID[sha1] of libc.') do |b|\n          @options[:build_id] = b\n        end\n\n        opts.on('-f', '--[no-]force-file', 'Force search gadgets in file instead of build id first.') do |f|\n          @options[:force_file] = f\n        end\n\n        opts.on('-l', '--level OUTPUT_LEVEL', Integer, 'The output level.',\n                'OneGadget automatically selects gadgets with higher successful probability.',\n                'Increase this level to ask OneGadget show more gadgets it found.',\n                'Default: 0') do |l|\n          @options[:level] = l\n        end\n\n        opts.on('-n', '--near FUNCTIONS/FILE', 'Order gadgets by their distance to the given functions'\\\n                ' or to the GOT functions of the given file.') do |n|\n          @options[:near] = n\n        end\n\n        opts.on('-r', '--[no-]raw', 'Output gadgets offset only, split with one space.') do |v|\n          @options[:raw] = v\n        end\n\n        opts.on('-s', '--script exploit-script', 'Run exploit script with all possible gadgets.',\n                'The script will be run as \\'exploit-script $offset\\'.') do |s|\n          @options[:script] = s\n        end\n\n        opts.on('--info BuildID', 'Show version information given BuildID.') do |b|\n          @options[:info] = b\n        end\n\n        opts.on('--version', 'Current gem version.') do |v|\n          @options[:version] = v\n        end\n      end\n    end", "label": 4}
{"code": "func (p *Panel) SetMenu(w Widget) {\n\tindex := 0\n\tif p.title != nil {\n\t\tindex++\n\t}\n\tif p.menu != nil {\n\t\tp.RemoveWidget(p.menu)\n\t}\n\tp.InsertWidget(index, w, 0.0)\n\tp.menu = w\n}", "label": 5}
{"code": "func (t *proxySubsys) proxyToSite(\n\tctx *srv.ServerContext, site reversetunnel.RemoteSite, remoteAddr net.Addr, ch ssh.Channel) error {\n\n\tconn, err := site.DialAuthServer()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tt.log.Infof(\"Connected to auth server: %v\", conn.RemoteAddr())\n\n\tgo func() {\n\t\tvar err error\n\t\tdefer func() {\n\t\t\tt.close(err)\n\t\t}()\n\t\tdefer ch.Close()\n\t\t_, err = io.Copy(ch, conn)\n\t}()\n\tgo func() {\n\t\tvar err error\n\t\tdefer func() {\n\t\t\tt.close(err)\n\t\t}()\n\t\tdefer conn.Close()\n\t\t_, err = io.Copy(conn, srv.NewTrackingReader(ctx, ch))\n\n\t}()\n\n\treturn nil\n}", "label": 5}
{"code": "def del_piper(self, piper, forced=False):\n        \"\"\"\n        Removes a ``Piper`` from the ``Dagger`` instance.\n\n        Arguments:\n        \n          - piper(``Piper``  or id(``Piper``)) ``Piper`` instance or ``Piper`` \n            instance id.\n          - forced(bool) [default: ``False``] If \"forced\" is ``True``, will not \n            raise a ``DaggerError`` if the ``Piper`` hase outgoing pipes and \n            will also remove it.\n            \n        \"\"\"\n        self.log.debug('%s trying to delete piper %s' % \\\n                      (repr(self), repr(piper)))\n        try:\n            piper = self.resolve(piper, forgive=False)\n        except DaggerError:\n            self.log.error('%s cannot resolve piper from %s' % \\\n                           (repr(self), repr(piper)))\n            raise DaggerError('%s cannot resolve piper from %s' % \\\n                              (repr(self), repr(piper)))\n        if self.incoming_edges(piper) and not forced:\n            self.log.error('%s piper %s has down-stream pipers (use forced =True to override)' % \\\n                           (repr(self), piper))\n            raise DaggerError('%s piper %s has down-stream pipers (use forced =True to override)' % \\\n                              (repr(self), piper))\n        self.del_node(piper)\n        self.log.debug('%s deleted piper %s' % (repr(self), piper))", "label": 1}
{"code": "function tryGetNamedImportsOrExportsForCompletion(contextToken) {\n                if (contextToken) {\n                    switch (contextToken.kind) {\n                        case 15 /* OpenBraceToken */: // import { |\n                        case 24 /* CommaToken */:\n                            switch (contextToken.parent.kind) {\n                                case 233 /* NamedImports */:\n                                case 237 /* NamedExports */:\n                                    return contextToken.parent;\n                            }\n                    }\n                }\n                return undefined;\n            }", "label": 3}
{"code": "def truncate_array(string_array, limit = nil, separator = '', natural_separator = ' ')\n      return string_array if limit.nil? || limit <= 0\n\n      length = 0\n      result = []\n\n      string_array.each do |string|\n        limit_left = calculate_limit_left(limit, length, result, separator)\n\n        if string.length > limit_left\n          result << truncate(string, limit_left, natural_separator)\n          break\n        end\n\n        length += (result.any? ? separator.length : 0) + string.length\n        result << string\n\n        # No more strings will fit\n        break if length + separator.length >= limit\n      end\n\n      result\n    end", "label": 4}
{"code": "function create(options, callback) {\n  var t = new TestObject(options);\n  t.save(null, { success: callback });\n}", "label": 3}
{"code": "function analyzeFile (file, content, filter, depResolve, depth, result) {\n  depth = typeof depth === 'number' ? depth : Infinity\n  result = result || {}\n\n  if (depth < 1) {\n    return\n  }\n\n  if (file in result) {\n    return\n  }\n\n  debug('analyze file: file = %s, depth = %s', file, depth)\n\n  let deps = parseFile(file, content) || []\n  let item = result[file] = {\n    deps: [],\n    relatives: [],\n    modules: []\n  }\n\n  // filter deps\n  if (filter) {\n    deps = deps.filter(dep => filter(dep, file))\n  }\n\n  // convert\n  deps.forEach(dep => {\n    let info = getDepInfo(dep, file, depResolve)\n\n    item.deps.push(info)\n\n    if (info.module && item.modules.indexOf(info.module) < 0) {\n      item.modules.push(info.module)\n    } else if (info.file && item.relatives.indexOf(info.file) < 0) {\n      item.relatives.push(info.file)\n\n      // deep first traversing\n      analyzeFile(info.file, fs.readFileSync(info.file, 'utf8'), filter, depResolve, depth - 1, result)\n    }\n  })\n\n  return result\n}", "label": 3}
{"code": "def body(self, environ, file_like):\n        \"\"\"Pass environ and self.variables in to template.\n\n        self.variables overrides environ so that suprises in environ don't\n        cause unexpected output if you are passing a value in explicitly.\n        \"\"\"\n        variables = environ.copy()\n        variables.update(self.variables)\n        template = string.Template(file_like.read())\n        if self.safe is True:\n            return [template.safe_substitute(variables)]\n        else:\n            return [template.substitute(variables)]", "label": 1}
{"code": "function() {\n\t\tvar origin = _getOrigin(req);\n\t\tSR.REST.reply(res, res_str, {\n\t\t\torigin: origin\n\t\t});\n\t}", "label": 3}
{"code": "def retrieve_dirs(_base, dir, dot_dirs)\n      dot_dirs.each do |file|\n        dir_path = site.in_source_dir(dir, file)\n        rel_path = File.join(dir, file)\n        @site.reader.read_directories(rel_path) unless @site.dest.chomp(\"/\") == dir_path\n      end\n    end", "label": 4}
{"code": "def to_uri(uri, base_uri = nil)\n      case base_uri\n      when nil, ''\n        Utils.normalize_uri(uri.to_s)\n      else\n        Utils.normalize_uri(base_uri) + Utils.normalize_uri(uri.to_s)\n      end\n    rescue URI::Error\n      nil\n    end", "label": 4}
{"code": "func NewMockEmbedded(ctrl *gomock.Controller) *MockEmbedded {\n\tmock := &MockEmbedded{ctrl: ctrl}\n\tmock.recorder = &MockEmbeddedMockRecorder{mock}\n\treturn mock\n}", "label": 5}
{"code": "def lookup_action #:nodoc:\n      @lookup_action ||= begin\n        action = template.controller && template.controller.action_name\n        return unless action\n        action = action.to_s\n        ACTIONS[action] || action\n      end\n    end", "label": 4}
{"code": "function readInteger(width, reader) {\n    return function (start, cb) {\n      var i = Math.floor(start/block_size)\n      var _i = start%block_size\n\n      //if the UInt32BE aligns with in a block\n      //read directly and it's 3x faster.\n      if(_i < block_size - width)\n        get(i, function (err, block) {\n          if(err) return cb(err)\n          var value = reader(block, start%block_size)\n          cb(null, value)\n        })\n      //but handle overlapping reads this easier way\n      //instead of messing around with bitwise ops\n      else\n        read(start, start+width, function (err, buf, bytes_read) {\n          if(err) return cb(err)\n          var value = reader(buf, 0);\n          cb(isNaN(value) ? new Error('Number is too large') : null, value)\n        })\n    }\n  }", "label": 3}
{"code": "function _gpfAddEventListener (event, eventsHandler) {\n    /*jshint validthis:true*/ // will be invoked as an object method\n    var listeners = _gpfAllocateEventDispatcherListeners(this);\n    if (undefined === listeners[event]) {\n        listeners[event] = [];\n    }\n    listeners[event].push(eventsHandler);\n    return this;\n}", "label": 3}
{"code": "function parsePrimaryKey(attrPathList, context) {\n    return attrPathList.split(',').map(attrPath => parseAttributePath(attrPath, context));\n}", "label": 3}
{"code": "func (m *Manager) HistoricalInterval(ctx context.Context) (IntervalList, error) {\n\tvar pm mo.PerformanceManager\n\n\terr := m.Properties(ctx, m.Reference(), []string{\"historicalInterval\"}, &pm)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn IntervalList(pm.HistoricalInterval), nil\n}", "label": 5}
{"code": "function (req, res) {\n        _updateSections({ moveTo: req.body }, req.query.space, req.query.groupId, res);\n    }", "label": 3}
{"code": "def plugin_is_added_as_dependency?(plugin_name)\n      UI.user_error!(\"fastlane plugins must start with '#{self.class.plugin_prefix}' string\") unless plugin_name.start_with?(self.class.plugin_prefix)\n      return available_plugins.include?(plugin_name)\n    end", "label": 4}
{"code": "function (cb) {\n          if (opts.dropCollection) {\n            db.listCollections({name: collectionName})\n              .toArray(function (err, items) {\n                if (err) return cb(err)\n                if (items.length) return coll.drop(cb)\n                cb()\n              })\n          } else cb()\n        }", "label": 3}
{"code": "function fieldValidation (dispatch, getState, fieldValidators, formValue, initialFormValue, all) {\n  let fieldsBeingValidated = []\n  const allValidationPromises = []\n  fieldValidators.forEach(validator => {\n    /**\n     * Field validator definition\n     * @property {String} field field to validate\n     * @property {String[]} fields fields to validate\n     * @property {Function} validator validation function to validate field/fields. Must return field within error/warning\n     * @property {Function[]} validators validation functions to validate field/fields. Must return field within error/warning\n     */\n    const {field, fields, validator: validatorFunc, validators: validatorFuncs} = validator\n\n    const fieldsToValidate = fields || [field]\n    fieldsBeingValidated = fieldsBeingValidated.concat(fieldsToValidate)\n    fieldsToValidate.forEach((field) => {\n      let fieldValidationPromises = []\n      const newValue = _.get(formValue, field)\n      const oldValue = _.get(initialFormValue, field)\n\n      // Check if field value has changed\n      if (!_.isEqual(newValue, oldValue) || !initialFormValue) {\n        dispatchFieldIsValidating(dispatch, field, true)\n        const validations = validatorFuncs || [validatorFunc]\n            // Send validator formValue, the field we're validating against, and the field's value\n        validations.forEach((validatorFunc, index) => {\n          const fieldValidationPromise = validatorFunc(formValue, field, newValue)\n            .then((result) => {\n              const {\n                fieldValidationResult: {\n                  errors: currentErrors = [],\n                  warnings: currentWarnings = []\n                } = {}\n              } = getState()\n              const validationId = `${field}-${index}`\n              const filterOutValidationId = (item) => item.validationId !== validationId\n              const filteredOutErrors = currentErrors.filter(filterOutValidationId)\n              const filteredOutWarnings = currentWarnings.filter(filterOutValidationId)\n\n              // No need to use `aggregateResults as we should never have isRequired\n              const {\n                errors = [], warnings = []\n              } = result.value\n              const attachValidationId = (item) => {\n                return _.assign({\n                  validationId,\n                  field\n                }, item)\n              }\n              const newErrors = filteredOutErrors.concat(errors.map(attachValidationId))\n              const errorsMappedToDotNotation = mapErrorsFromValidation(newErrors)\n\n              dispatch({\n                fieldErrors: errorsMappedToDotNotation,\n                type: VALIDATION_RESOLVED,\n                fieldValidationResult: {\n                  errors: newErrors,\n                  warnings: filteredOutWarnings.concat(warnings.map(attachValidationId))\n                }\n              })\n\n              return result\n            })\n          allValidationPromises.push(fieldValidationPromise)\n          fieldValidationPromises.push(fieldValidationPromise)\n        })\n      }\n      if (fieldValidationPromises.length >= 1) {\n        all(fieldValidationPromises).then(() => {\n          dispatchFieldIsValidating(dispatch, field, false)\n        })\n      }\n    })\n  })\n\n  return allValidationPromises\n}", "label": 3}
{"code": "function( el ) {\r\n      var _errorMessages = {};\r\n      // if el is undefined ( This is the process of resetting all <form> )\r\n      // or el is an object that has element more than one\r\n      // and these elements are not checkbox\r\n      if( typeof el === 'undefined' || ( el.length > 1 && el[0].type !== 'checkbox' ) ) {\r\n        _errorMessages = this.form.querySelectorAll( '.'+ this.options.errorTemplateClass );\r\n      }\r\n      else {\r\n        _errorMessages = this.parents( el[0] ).querySelectorAll( '.'+ this.options.errorTemplateClass );\r\n      }\r\n      for ( var i = 0, _lengthErrorMessages = _errorMessages.length; i < _lengthErrorMessages; i++ ) {\r\n        this.window.close.call( this, _errorMessages[ i ] );\r\n      }\r\n      // set to handler false\r\n      // otherwise at the next validation attempt, submit will not continue even the validation is successful\r\n      this.handler = false;\r\n    }", "label": 3}
{"code": "def create_reaction(reaction)\n      reaction = reaction.to_reaction if reaction.respond_to?(:to_reaction)\n      API::Channel.create_reaction(@bot.token, @channel.id, @id, reaction)\n      nil\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, gslbservice resource) throws Exception {\n\t\tgslbservice updateresource = new gslbservice();\n\t\tupdateresource.servicename = resource.servicename;\n\t\tupdateresource.ipaddress = resource.ipaddress;\n\t\tupdateresource.publicip = resource.publicip;\n\t\tupdateresource.publicport = resource.publicport;\n\t\tupdateresource.cip = resource.cip;\n\t\tupdateresource.cipheader = resource.cipheader;\n\t\tupdateresource.sitepersistence = resource.sitepersistence;\n\t\tupdateresource.siteprefix = resource.siteprefix;\n\t\tupdateresource.maxclient = resource.maxclient;\n\t\tupdateresource.healthmonitor = resource.healthmonitor;\n\t\tupdateresource.maxbandwidth = resource.maxbandwidth;\n\t\tupdateresource.downstateflush = resource.downstateflush;\n\t\tupdateresource.maxaaausers = resource.maxaaausers;\n\t\tupdateresource.viewname = resource.viewname;\n\t\tupdateresource.viewip = resource.viewip;\n\t\tupdateresource.monthreshold = resource.monthreshold;\n\t\tupdateresource.weight = resource.weight;\n\t\tupdateresource.monitor_name_svc = resource.monitor_name_svc;\n\t\tupdateresource.hashid = resource.hashid;\n\t\tupdateresource.comment = resource.comment;\n\t\tupdateresource.appflowlog = resource.appflowlog;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function enableGrantType(GrantTypeInterface $grantType, DateInterval $accessTokenTTL = null)\n    {\n        if ($accessTokenTTL instanceof DateInterval === false) {\n            $accessTokenTTL = new DateInterval('PT1H');\n        }\n\n        $grantType->setAccessTokenRepository($this->accessTokenRepository);\n        $grantType->setClientRepository($this->clientRepository);\n        $grantType->setScopeRepository($this->scopeRepository);\n        $grantType->setDefaultScope($this->defaultScope);\n        $grantType->setPrivateKey($this->privateKey);\n        $grantType->setEmitter($this->getEmitter());\n        $grantType->setEncryptionKey($this->encryptionKey);\n\n        $this->enabledGrantTypes[$grantType->getIdentifier()] = $grantType;\n        $this->grantTypeAccessTokenTTL[$grantType->getIdentifier()] = $accessTokenTTL;\n    }", "label": 2}
{"code": "func DualPipeNetConn(srcAddr net.Addr, dstAddr net.Addr) (*PipeNetConn, *PipeNetConn) {\n\tserver, client := net.Pipe()\n\n\tserverConn := NewPipeNetConn(server, server, server, dstAddr, srcAddr)\n\tclientConn := NewPipeNetConn(client, client, client, srcAddr, dstAddr)\n\n\treturn serverConn, clientConn\n}", "label": 5}
{"code": "public static void registerTinyTypes(Class<?> head, Class<?>... tail) {\n        final Set<HeaderDelegateProvider> systemRegisteredHeaderProviders = stealAcquireRefToHeaderDelegateProviders();\n        register(head, systemRegisteredHeaderProviders);\n        for (Class<?> tt : tail) {\n            register(tt, systemRegisteredHeaderProviders);\n        }\n    }", "label": 0}
{"code": "def h3(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'h3_for', &block)\n      define_method(name) do\n        return platform.h3_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "def list(*args)\n      arguments(args)\n      params = arguments.params\n      token = args.shift\n\n      if token.is_a?(Hash) && !params['token'].nil?\n        token = params.delete('token')\n      elsif token.nil?\n        token = oauth_token\n      end\n\n      if token.nil?\n        raise ArgumentError, 'Access token required'\n      end\n\n      headers = { 'Authorization' => \"token #{token}\" }\n      params['headers'] = headers\n      response = get_request(\"/user\", params)\n      response.headers.oauth_scopes.split(',').map(&:strip)\n    end", "label": 4}
{"code": "func (v TaskView) Collect(ctx context.Context, f func([]types.TaskInfo)) error {\n\t// Using TaskHistoryCollector would be less clunky, but it isn't supported on ESX at all.\n\tref := v.Reference()\n\tfilter := new(property.WaitFilter).Add(ref, \"Task\", []string{\"info\"}, v.TraversalSpec())\n\n\tif v.Watch != nil {\n\t\tfilter.Add(*v.Watch, v.Watch.Type, []string{\"recentTask\"})\n\t}\n\n\tpc := property.DefaultCollector(v.Client())\n\n\tcompleted := make(map[string]bool)\n\n\treturn property.WaitForUpdates(ctx, pc, filter, func(updates []types.ObjectUpdate) bool {\n\t\tvar infos []types.TaskInfo\n\t\tvar prune []types.ManagedObjectReference\n\t\tvar tasks []types.ManagedObjectReference\n\t\tvar reset func()\n\n\t\tfor _, update := range updates {\n\t\t\tfor _, change := range update.ChangeSet {\n\t\t\t\tif change.Name == \"recentTask\" {\n\t\t\t\t\ttasks = change.Val.(types.ArrayOfManagedObjectReference).ManagedObjectReference\n\t\t\t\t\tif len(tasks) != 0 {\n\t\t\t\t\t\treset = func() {\n\t\t\t\t\t\t\t_ = v.Reset(ctx, tasks)\n\n\t\t\t\t\t\t\t// Remember any tasks we've reported as complete already,\n\t\t\t\t\t\t\t// to avoid reporting multiple times when Reset is triggered.\n\t\t\t\t\t\t\trtasks := make(map[string]bool)\n\t\t\t\t\t\t\tfor i := range tasks {\n\t\t\t\t\t\t\t\tif _, ok := completed[tasks[i].Value]; ok {\n\t\t\t\t\t\t\t\t\trtasks[tasks[i].Value] = true\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcompleted = rtasks\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tinfo, ok := change.Val.(types.TaskInfo)\n\t\t\t\tif !ok {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif !completed[info.Task.Value] {\n\t\t\t\t\tinfos = append(infos, info)\n\t\t\t\t}\n\n\t\t\t\tif v.Follow && info.CompleteTime != nil {\n\t\t\t\t\tprune = append(prune, info.Task)\n\t\t\t\t\tcompleted[info.Task.Value] = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif len(infos) != 0 {\n\t\t\tf(infos)\n\t\t}\n\n\t\tif reset != nil {\n\t\t\treset()\n\t\t} else if len(prune) != 0 {\n\t\t\t_ = v.Remove(ctx, prune)\n\t\t}\n\n\t\tif len(tasks) != 0 && len(infos) == 0 {\n\t\t\treturn false\n\t\t}\n\n\t\treturn !v.Follow\n\t})\n}", "label": 5}
{"code": "function findAll() {\n  return jp.dataDirs({ withSysPrefix: true }).then(dirs => {\n    return Promise.all(dirs\n      // get kernel infos for each directory and ignore errors\n      .map(dir => getKernelInfos(path.join(dir, 'kernels')).catch(() => {}))\n    ).then(extractKernelResources)\n  });\n}", "label": 3}
{"code": "function _GpfOldClassDefinition (name, Super, definition) {\n    /*jshint validthis:true*/ // constructor\n    this._uid = ++_gpfClassDefUID;\n    _gpfClassDefinitions[this._uid] = this;\n    this._Subs = [];\n    if (\"function\" === typeof name) {\n        this._name = name.compatibleName() || \"anonymous\";\n        // TODO how do we grab the parent constructor (?)\n        this._Constructor = name;\n    } else {\n        this._name = name;\n        this._Super = Super;\n        this._definition = definition;\n        this._build();\n    }\n}", "label": 3}
{"code": "func (s *PresenceService) GetTrustedCluster(name string) (services.TrustedCluster, error) {\n\tif name == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing trusted cluster name\")\n\t}\n\titem, err := s.Get(context.TODO(), backend.Key(trustedClustersPrefix, name))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.GetTrustedClusterMarshaler().Unmarshal(item.Value, services.WithResourceID(item.ID), services.WithExpires(item.Expires))\n}", "label": 5}
{"code": "def user(id)\n      id = id.resolve_id\n      return @users[id] if @users[id]\n\n      LOGGER.out(\"Resolving user #{id}\")\n      begin\n        response = API::User.resolve(token, id)\n      rescue RestClient::ResourceNotFound\n        return nil\n      end\n      user = User.new(JSON.parse(response), self)\n      @users[id] = user\n    end", "label": 4}
{"code": "public void beforeBatch(PreparedStatement stmt) throws PlatformException\r\n    {\r\n        // Check for Oracle batching support\r\n        final Method methodSetExecuteBatch;\r\n        final Method methodSendBatch;\r\n        methodSetExecuteBatch = ClassHelper.getMethod(stmt, \"setExecuteBatch\", PARAM_TYPE_INTEGER);\r\n        methodSendBatch = ClassHelper.getMethod(stmt, \"sendBatch\", null);\r\n\r\n        final boolean statementBatchingSupported = methodSetExecuteBatch != null && methodSendBatch != null;\r\n        if (statementBatchingSupported)\r\n        {\r\n            try\r\n            {\r\n                // Set number of statements per batch\r\n                methodSetExecuteBatch.invoke(stmt, PARAM_STATEMENT_BATCH_SIZE);\r\n                m_batchStatementsInProgress.put(stmt, methodSendBatch);\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                throw new PlatformException(e.getLocalizedMessage(), e);\r\n            }\r\n        }\r\n        else\r\n        {\r\n            super.beforeBatch(stmt);\r\n        }\r\n    }", "label": 0}
{"code": "public List<T> tokenize() {\r\n    // System.out.println(\"tokenize called\");\r\n    List<T> result = new ArrayList<T>();\r\n    while (hasNext()) {\r\n      result.add(next());\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "def parse_xml(self, xml_file, check_version=True, check_root=True,\n                  encoding=None):\n        \"\"\"Creates a python-stix STIXPackage object from the supplied xml_file.\n\n        Args:\n            xml_file: A filename/path or a file-like object representing a STIX\n                instance document\n            check_version: Inspect the version before parsing.\n            check_root: Inspect the root element before parsing.\n            encoding: The character encoding of the input `xml_file`. If\n                ``None``, an attempt will be made to determine the input\n                character encoding.\n\n        Raises:\n            .UnknownVersionError: If `check_version` is ``True`` and `xml_file`\n                does not contain STIX version information.\n            .UnsupportedVersionError: If `check_version` is ``False`` and\n                `xml_file` contains an unsupported STIX version.\n            .UnsupportedRootElement: If `check_root` is ``True`` and `xml_file`\n                contains an invalid root element.\n\n        \"\"\"\n\n        xml_etree = get_etree(xml_file, encoding=encoding)\n        entity_obj = self.parse_xml_to_obj(\n            xml_file=xml_etree,\n            check_version=check_version,\n            check_root=check_root\n        )\n\n        xml_root_node = xml_etree.getroot()\n        entity = self.get_entity_class(xml_root_node.tag).from_obj(entity_obj)\n\n        # Save the parsed nsmap and schemalocations onto the parsed Entity\n        entity.__input_namespaces__ = dict(iteritems(xml_root_node.nsmap))\n        with ignored(KeyError):\n            pairs = get_schemaloc_pairs(xml_root_node)\n            entity.__input_schemalocations__ = dict(pairs)\n\n        return entity", "label": 1}
{"code": "public function setPartitionId($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\PartitionId::class);\n        $this->partition_id = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function (duration, settings) {\n  // If there's no swing ratio, assume straight eighths\n  var ratio = settings && settings.swingRatio ? settings.swingRatio : 1;\n  return Math.round(ticksPerBeat * duration.value(ratio));\n}", "label": 3}
{"code": "function getFolders(dir) {\n  try {\n    return fs.readdirSync(dir)\n      .filter(function (file) {\n        return exports.isDirectory(path.join(dir, file));\n      });\n  } catch (ex) {\n    return [];\n  }\n}", "label": 3}
{"code": "func (d Datastore) HostContext(ctx context.Context, host *HostSystem) context.Context {\n\treturn context.WithValue(ctx, datastoreServiceTicketHostKey{}, host)\n}", "label": 5}
{"code": "def warn_from_util_logger(msg):\n    \"\"\"Only to be used in this file and peyotl.utility.get_config\"\"\"\n    global _LOG\n    # This check is necessary to avoid infinite recursion when called from get_config, because\n    #   the _read_logging_conf can require reading a conf file.\n    if _LOG is None and _LOGGING_CONF is None:\n        sys.stderr.write('WARNING: (from peyotl before logging is configured) {}\\n'.format(msg))\n        return\n    if _LOG is None:\n        _LOG = get_logger(\"peyotl.utility\")\n    _LOG.warn(msg)", "label": 1}
{"code": "def append_noarchive_attribute(noindex)\n      noarchive_name, noarchive_value = extract_noindex_attribute :noarchive\n      if noarchive_value\n        if noindex[noarchive_name].blank?\n          noindex[noarchive_name] = noarchive_value\n        else\n          noindex[noarchive_name] += \", #{noarchive_value}\"\n        end\n      end\n      noindex\n    end", "label": 4}
{"code": "def set(margins)\n      margins.select do |k, v|\n        next unless [:left, :right, :top, :bottom, :header, :footer].include? k\n        send(\"#{k}=\", v)\n      end\n    end", "label": 4}
{"code": "public static snmpuser[] get(nitro_service service, options option) throws Exception{\n\t\tsnmpuser obj = new snmpuser();\n\t\tsnmpuser[] response = (snmpuser[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "protected function setProcessors(OptionsInterface $options, ProfileInterface $profile)\n    {\n        if (isset($options->prefix) && $profile instanceof RedisProfile) {\n            // NOTE: directly using __get('prefix') is actually a workaround for\n            // HHVM 2.3.0. It's correct and respects the options interface, it's\n            // just ugly. We will remove this hack when HHVM will fix re-entrant\n            // calls to __get() once and for all.\n\n            $profile->setProcessor($options->__get('prefix'));\n        }\n    }", "label": 2}
{"code": "func (f *file) lintExported() {\n\tif f.isTest() {\n\t\treturn\n\t}\n\n\tvar lastGen *ast.GenDecl // last GenDecl entered.\n\n\t// Set of GenDecls that have already had missing comments flagged.\n\tgenDeclMissingComments := make(map[*ast.GenDecl]bool)\n\n\tf.walk(func(node ast.Node) bool {\n\t\tswitch v := node.(type) {\n\t\tcase *ast.GenDecl:\n\t\t\tif v.Tok == token.IMPORT {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t// token.CONST, token.TYPE or token.VAR\n\t\t\tlastGen = v\n\t\t\treturn true\n\t\tcase *ast.FuncDecl:\n\t\t\tf.lintFuncDoc(v)\n\t\t\tif v.Recv == nil {\n\t\t\t\t// Only check for stutter on functions, not methods.\n\t\t\t\t// Method names are not used package-qualified.\n\t\t\t\tf.checkStutter(v.Name, \"func\")\n\t\t\t}\n\t\t\t// Don't proceed inside funcs.\n\t\t\treturn false\n\t\tcase *ast.TypeSpec:\n\t\t\t// inside a GenDecl, which usually has the doc\n\t\t\tdoc := v.Doc\n\t\t\tif doc == nil {\n\t\t\t\tdoc = lastGen.Doc\n\t\t\t}\n\t\t\tf.lintTypeDoc(v, doc)\n\t\t\tf.checkStutter(v.Name, \"type\")\n\t\t\t// Don't proceed inside types.\n\t\t\treturn false\n\t\tcase *ast.ValueSpec:\n\t\t\tf.lintValueSpecDoc(v, lastGen, genDeclMissingComments)\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "public static function interleaved(CommandInterface $command, $prefix)\n    {\n        if ($arguments = $command->getArguments()) {\n            $length = count($arguments);\n\n            for ($i = 0; $i < $length; $i += 2) {\n                $arguments[$i] = \"$prefix{$arguments[$i]}\";\n            }\n\n            $command->setRawArguments($arguments);\n        }\n    }", "label": 2}
{"code": "public function setDeleteFromColumn($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\Mutation_DeleteFromColumn::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function convertToTimestamp(value) {\n    if (value instanceof Date) {\n      return value.getTime();\n    } else if (typeof value === 'number') {\n      return Math.floor(value);\n    } else if (typeof value === 'string') {\n      return Date.parse(value);\n    } else {\n      return NaN;\n    }\n  }", "label": 3}
{"code": "function ensure(files, options) {\n    // Update the global array of represented modules\n    unused = filterRepresented(unused, files, options)\n\n    verbose.writeln('Unrepresented modules list currently at ', unused)\n\n    // Only print message when all targets have been run\n    if (++numRuns === getNumTargets()) {\n      if (unused.length) {\n        if (options.report) {\n          log.writeln('\\nPackages left out:')\n          log.writeln(unused.join('\\n'))\n        }\n      } else if (options.report) {\n        log.ok('All modules have something copied.')\n      }\n    }\n  }", "label": 3}
{"code": "def convert2phylip(convert):\n    \"\"\"\n    convert fasta to phylip because RAxML is ridiculous\n    \"\"\"\n    out = '%s.phy' % (convert.rsplit('.', 1)[0])\n    if check(out) is False:\n        convert = open(convert, 'rU')\n        out_f = open(out, 'w')\n        alignments = AlignIO.parse(convert, \"fasta\")\n        AlignIO.write(alignments, out, \"phylip\")\n    return out", "label": 1}
{"code": "def rake_merge_option(args, defaults)\n      if Hash === args.last\n        defaults.update(args.last)\n        args.pop\n      end\n      args.push defaults\n      args\n    end", "label": 4}
{"code": "def _get_pgen_var(self, generators, base_mva):\n        \"\"\" Returns the generator active power set-point variable.\n        \"\"\"\n        Pg = array([g.p / base_mva for g in generators])\n\n        Pmin = array([g.p_min / base_mva for g in generators])\n        Pmax = array([g.p_max / base_mva for g in generators])\n\n        return Variable(\"Pg\", len(generators), Pg, Pmin, Pmax)", "label": 1}
{"code": "def parse_date(value):\n    \"\"\"Attempts to parse `value` into an instance of ``datetime.date``. If\n    `value` is ``None``, this function will return ``None``.\n\n    Args:\n        value: A timestamp. This can be a string, datetime.date, or\n            datetime.datetime value.\n\n    \"\"\"\n    if not value:\n        return None\n\n    if isinstance(value, datetime.date):\n        return value\n\n    return parse_datetime(value).date()", "label": 1}
{"code": "public static base_responses update(nitro_service client, snmpalarm resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmpalarm updateresources[] = new snmpalarm[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new snmpalarm();\n\t\t\t\tupdateresources[i].trapname = resources[i].trapname;\n\t\t\t\tupdateresources[i].thresholdvalue = resources[i].thresholdvalue;\n\t\t\t\tupdateresources[i].normalvalue = resources[i].normalvalue;\n\t\t\t\tupdateresources[i].time = resources[i].time;\n\t\t\t\tupdateresources[i].state = resources[i].state;\n\t\t\t\tupdateresources[i].severity = resources[i].severity;\n\t\t\t\tupdateresources[i].logging = resources[i].logging;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def inspect\n      img = []\n      @images.each { |image| img << image.inspect }\n      img = '[' + img.join(\",\\n\") + \"]\\nscene=#{@scene}\"\n    end", "label": 4}
{"code": "def swap_anchor(new_anchor)\n      new_anchor.drawing.anchors.delete(new_anchor)\n      @anchor.drawing.anchors[@anchor.drawing.anchors.index(@anchor)] = new_anchor\n      new_anchor.instance_variable_set \"@object\", @anchor.object\n      @anchor = new_anchor\n    end", "label": 4}
{"code": "function defineProperty(obj, propertyName, evaluatorOrOptions) {\n        var computedOptions = { owner: obj, deferEvaluation: true },\n            computed;\n\n        if (typeof evaluatorOrOptions === 'function') {\n            computedOptions.read = evaluatorOrOptions;\n        } else {\n            if ('value' in evaluatorOrOptions) {\n                system.error('For defineProperty, you must not specify a \"value\" for the property. You must provide a \"get\" function.');\n            }\n\n            if (typeof evaluatorOrOptions.get !== 'function') {\n                system.error('For defineProperty, the third parameter must be either an evaluator function, or an options object containing a function called \"get\".');\n            }\n\n            computedOptions.read = evaluatorOrOptions.get;\n            computedOptions.write = evaluatorOrOptions.set;\n        }\n\n        computed = ko.computed(computedOptions);\n        obj[propertyName] = computed;\n\n        return convertProperty(obj, propertyName, computed);\n    }", "label": 3}
{"code": "public static String formatConnectionTerminationMessage(final String connectionName, final String host, final String connectionReason, final String terminationReason) {\n\t\treturn CON_TERMINATION_FORMAT.format(new Object[] { connectionName, host, connectionReason, terminationReason });\n\t}", "label": 0}
{"code": "function wrapIteratorCallback(callback, key)\n{\n  var stream = this;\n\n  return function(error, output)\n  {\n    // don't repeat yourself\n    if (!(key in stream.jobs))\n    {\n      callback(error, output);\n      return;\n    }\n\n    // clean up jobs\n    delete stream.jobs[key];\n\n    return streamer.call(stream, error, {key: key, value: output}, callback);\n  };\n}", "label": 3}
{"code": "def add_current_user_to_menu(menu, priority = 10, html_options = {})\n      if current_user_method\n        menu.add id: 'current_user', priority: priority, html_options: html_options,\n          label: -> { display_name current_active_admin_user },\n          url:   -> { auto_url_for(current_active_admin_user) },\n          if:    :current_active_admin_user?\n      end\n    end", "label": 4}
{"code": "public static Chart getMSDLineChart(Trajectory t, int lagMin, int lagMax,\n\t\t\tAbstractMeanSquaredDisplacmentEvaluator msdeval) {\n\n\t\tdouble[] xData = new double[lagMax - lagMin + 1];\n\t\tdouble[] yData = new double[lagMax - lagMin + 1];\n\t\tmsdeval.setTrajectory(t);\n\t\tmsdeval.setTimelag(lagMin);\n\t\tfor (int i = lagMin; i < lagMax + 1; i++) {\n\t\t\tmsdeval.setTimelag(i);\n\t\t\tdouble msdhelp = msdeval.evaluate()[0];\n\t\t\txData[i - lagMin] = i;\n\t\t\tyData[i - lagMin] = msdhelp;\n\t\t}\n\n\t\t// Create Chart\n\t\tChart chart = QuickChart.getChart(\"MSD Line\", \"LAG\", \"MSD\", \"MSD\",\n\t\t\t\txData, yData);\n\n\t\t// Show it\n\t\t//new SwingWrapper(chart).displayChart();\n\t\treturn chart;\n\t}", "label": 0}
{"code": "public function addReturnTypes(Context $context)\n    {\n        if ($this->return_vars_in_scope !== null) {\n            $this->return_vars_in_scope = TypeAnalyzer::combineKeyedTypes(\n                $context->vars_in_scope,\n                $this->return_vars_in_scope\n            );\n        } else {\n            $this->return_vars_in_scope = $context->vars_in_scope;\n        }\n\n        if ($this->return_vars_possibly_in_scope !== null) {\n            $this->return_vars_possibly_in_scope = array_merge(\n                $context->vars_possibly_in_scope,\n                $this->return_vars_possibly_in_scope\n            );\n        } else {\n            $this->return_vars_possibly_in_scope = $context->vars_possibly_in_scope;\n        }\n    }", "label": 2}
{"code": "def command(operation, opts = {})\n      txn_read_pref = if opts[:session] && opts[:session].in_transaction?\n        opts[:session].txn_read_preference\n      else\n        nil\n      end\n      txn_read_pref ||= opts[:read] || ServerSelector::PRIMARY\n      Lint.validate_underscore_read_preference(txn_read_pref)\n      preference = ServerSelector.get(txn_read_pref)\n\n      client.send(:with_session, opts) do |session|\n        read_with_retry(session, preference) do |server|\n          Operation::Command.new({\n            :selector => operation.dup,\n            :db_name => name,\n            :read => preference,\n            :session => session\n          }).execute(server)\n        end\n      end\n    end", "label": 4}
{"code": "def find_subscription(self, identifier):\n        \"\"\"\n        Finds a subscription\n        by it's identifier.\n        \"\"\"\n        for subscription in self.subscriptions.values():\n            if subscription.identifier == identifier:\n                return subscription", "label": 1}
{"code": "def print_stack_events(self):\n        '''\n        List events from the given stack\n\n        Args:\n            None\n\n        Returns:\n            None\n        '''\n        first_token = '7be7981bd6287dd8112305e8f3822a6f'\n        keep_going = True\n        next_token = first_token\n        current_request_token = None\n        rows = []\n        try:\n            while keep_going and next_token:\n                if next_token == first_token:\n                    response = self._cf_client.describe_stack_events(\n                        StackName=self._stack_name\n                    )\n                else:\n                    response = self._cf_client.describe_stack_events(\n                        StackName=self._stack_name,\n                        NextToken=next_token\n                    )\n\n                next_token = response.get('NextToken', None)\n                for event in response['StackEvents']:\n                    row = []\n                    event_time = event.get('Timestamp')\n                    request_token = event.get('ClientRequestToken', 'unknown')\n                    if current_request_token is None:\n                        current_request_token = request_token\n                    elif current_request_token != request_token:\n                        keep_going = False\n                        break\n\n                    row.append(event_time.strftime('%x %X'))\n                    row.append(event.get('LogicalResourceId'))\n                    row.append(event.get('ResourceStatus'))\n                    row.append(event.get('ResourceStatusReason', ''))\n                    rows.append(row)\n\n            if len(rows) > 0:\n                print('\\nEvents for the current upsert:')\n                print(tabulate(rows, headers=['Time', 'Logical ID', 'Status', 'Message']))\n                return True\n            else:\n                print('\\nNo stack events found\\n')\n        except Exception as wtf:\n            print(wtf)\n\n        return False", "label": 1}
{"code": "func (l *ConnectionsLimiter) WrapHandle(h http.Handler) {\n\tl.ConnLimiter.Wrap(h)\n}", "label": 5}
{"code": "func SystemdVersion(systemdBinaryPath string) (int, error) {\n\tversionBytes, err := exec.Command(systemdBinaryPath, \"--version\").CombinedOutput()\n\tif err != nil {\n\t\treturn -1, errwrap.Wrap(fmt.Errorf(\"unable to probe %s version\", systemdBinaryPath), err)\n\t}\n\tversionStr := strings.SplitN(string(versionBytes), \"\\n\", 2)[0]\n\tvar version int\n\tn, err := fmt.Sscanf(versionStr, \"systemd %d\", &version)\n\tif err != nil || n != 1 {\n\t\treturn -1, fmt.Errorf(\"cannot parse version: %q\", versionStr)\n\t}\n\n\treturn version, nil\n}", "label": 5}
{"code": "func (s *Server) handleAgentForwardNode(req *ssh.Request, ctx *srv.ServerContext) error {\n\t// check if the user's RBAC role allows agent forwarding\n\terr := s.authHandlers.CheckAgentForward(ctx)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// open a channel to the client where the client will serve an agent\n\tauthChannel, _, err := ctx.Conn.OpenChannel(sshutils.AuthAgentRequest, nil)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// save the agent in the context so it can be used later\n\tctx.SetAgent(agent.NewClient(authChannel), authChannel)\n\n\t// serve an agent on a unix socket on this node\n\terr = s.serveAgent(ctx)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public Pair<int[][][], int[]> documentToDataAndLabels(List<IN> document) {\r\n\r\n    int docSize = document.size();\r\n    // first index is position in the document also the index of the\r\n    // clique/factor table\r\n    // second index is the number of elements in the clique/window these\r\n    // features are for (starting with last element)\r\n    // third index is position of the feature in the array that holds them\r\n    // element in data[j][k][m] is the index of the mth feature occurring in\r\n    // position k of the jth clique\r\n    int[][][] data = new int[docSize][windowSize][];\r\n    // index is the position in the document\r\n    // element in labels[j] is the index of the correct label (if it exists) at\r\n    // position j of document\r\n    int[] labels = new int[docSize];\r\n\r\n    if (flags.useReverse) {\r\n      Collections.reverse(document);\r\n    }\r\n\r\n    // System.err.println(\"docSize:\"+docSize);\r\n    for (int j = 0; j < docSize; j++) {\r\n      CRFDatum<List<String>, CRFLabel> d = makeDatum(document, j, featureFactory);\r\n\r\n      List<List<String>> features = d.asFeatures();\r\n      for (int k = 0, fSize = features.size(); k < fSize; k++) {\r\n        Collection<String> cliqueFeatures = features.get(k);\r\n        data[j][k] = new int[cliqueFeatures.size()];\r\n        int m = 0;\r\n        for (String feature : cliqueFeatures) {\r\n          int index = featureIndex.indexOf(feature);\r\n          if (index >= 0) {\r\n            data[j][k][m] = index;\r\n            m++;\r\n          } else {\r\n            // this is where we end up when we do feature threshold cutoffs\r\n          }\r\n        }\r\n        // Reduce memory use when some features were cut out by threshold\r\n        if (m < data[j][k].length) {\r\n          int[] f = new int[m];\r\n          System.arraycopy(data[j][k], 0, f, 0, m);\r\n          data[j][k] = f;\r\n        }\r\n      }\r\n\r\n      IN wi = document.get(j);\r\n      labels[j] = classIndex.indexOf(wi.get(AnswerAnnotation.class));\r\n    }\r\n\r\n    if (flags.useReverse) {\r\n      Collections.reverse(document);\r\n    }\r\n\r\n    // System.err.println(\"numClasses: \"+classIndex.size()+\" \"+classIndex);\r\n    // System.err.println(\"numDocuments: 1\");\r\n    // System.err.println(\"numDatums: \"+data.length);\r\n    // System.err.println(\"numFeatures: \"+featureIndex.size());\r\n\r\n    return new Pair<int[][][], int[]>(data, labels);\r\n  }", "label": 0}
{"code": "def inspector_successfully_received_report(report, inspector)\n      report.issues[0..(NUMBER_OF_ISSUES_INLINE - 1)].each { |issue| print_issue_full(issue) }\n\n      if report.issues.count > NUMBER_OF_ISSUES_INLINE\n        report.url.sub!('\\'', '%27')\n        puts(\"and #{report.total_results - NUMBER_OF_ISSUES_INLINE} more at: #{report.url}\")\n        puts(\"\")\n      end\n\n      print_open_link_hint\n    end", "label": 4}
{"code": "def to_xml_string(str = '')\n      valid = RichTextRun::INLINE_STYLES\n      data = Hash[self.instance_values.map{ |k, v| [k.to_sym, v] }]\n      data = data.select { |key, value| valid.include?(key) && !value.nil? }\n\n      str << '<r><rPr>'\n      data.keys.each do |key|\n        case key\n        when :font_name\n          str << ('<rFont val=\"' << font_name << '\"/>')\n        when :color\n          str << data[key].to_xml_string\n        else\n          str << ('<' << key.to_s << ' val=\"' << xml_value(data[key]) << '\"/>')\n        end\n      end\n      clean_value = Axlsx::trust_input ? @value.to_s : ::CGI.escapeHTML(Axlsx::sanitize(@value.to_s))\n      str << ('</rPr><t>' << clean_value << '</t></r>')\n    end", "label": 4}
{"code": "def redirect_callbacks\n\n      # derive target redirect route from 'resource_class' param, which was set\n      # before authentication.\n      devise_mapping = get_devise_mapping\n      redirect_route = get_redirect_route(devise_mapping)\n\n      # preserve omniauth info for success route. ignore 'extra' in twitter\n      # auth response to avoid CookieOverflow.\n      session['dta.omniauth.auth'] = request.env['omniauth.auth'].except('extra')\n      session['dta.omniauth.params'] = request.env['omniauth.params']\n\n      redirect_to redirect_route\n    end", "label": 4}
{"code": "def newright(name, line=nil, file=nil)\n    add_right( Right.new(name, line, file) )\n  end", "label": 4}
{"code": "public Object materializeObject(ClassDescriptor cld, Identity oid)\r\n        throws PersistenceBrokerException\r\n    {\r\n        final StatementManagerIF sm = broker.serviceStatementManager();\r\n        final SelectStatement sql = broker.serviceSqlGenerator().getPreparedSelectByPkStatement(cld);\r\n        Object result = null;\r\n        PreparedStatement stmt = null;\r\n        ResultSet rs = null;\r\n        try\r\n        {\r\n            stmt = sm.getSelectByPKStatement(cld);\r\n            if (stmt == null)\r\n            {\r\n                logger.error(\"getSelectByPKStatement returned a null statement\");\r\n                throw new PersistenceBrokerException(\"getSelectByPKStatement returned a null statement\");\r\n            }\r\n            /*\r\n            arminw: currently a select by PK could never be a stored procedure,\r\n            thus we can always set 'false'. Is this correct??\r\n            */\r\n            sm.bindSelect(stmt, oid, cld, false);\r\n            rs = stmt.executeQuery();\r\n            // data available read object, else return null\r\n            ResultSetAndStatement rs_stmt = new ResultSetAndStatement(broker.serviceStatementManager(), stmt, rs, sql);\r\n            if (rs.next())\r\n            {\r\n                Map row = new HashMap();\r\n                cld.getRowReader().readObjectArrayFrom(rs_stmt, row);\r\n                result = cld.getRowReader().readObjectFrom(row);\r\n            }\r\n            // close resources\r\n            rs_stmt.close();\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            // release resources on exception\r\n            sm.closeResources(stmt, rs);\r\n            logger.error(\"PersistenceBrokerException during the execution of materializeObject: \" + e.getMessage(), e);\r\n            throw e;\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            // release resources on exception\r\n            sm.closeResources(stmt, rs);\r\n            throw ExceptionHelper.generateException(e, sql.getStatement(), cld, logger, null);\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def publish(self, data, **kwargs):\n        \"\"\"Validate operation type.\"\"\"\n        assert data.get('op') in {'index', 'create', 'delete', 'update'}\n        return super(Producer, self).publish(data, **kwargs)", "label": 1}
{"code": "def _decode_caveat_v2_v3(version, key, caveat):\n    '''Decodes a version 2 or version 3 caveat.\n    '''\n    if (len(caveat) < 1 + _PUBLIC_KEY_PREFIX_LEN +\n            _KEY_LEN + nacl.public.Box.NONCE_SIZE + 16):\n        raise VerificationError('caveat id too short')\n    original_caveat = caveat\n    caveat = caveat[1:]  # skip version (already checked)\n\n    pk_prefix = caveat[:_PUBLIC_KEY_PREFIX_LEN]\n    caveat = caveat[_PUBLIC_KEY_PREFIX_LEN:]\n    if key.public_key.serialize(raw=True)[:_PUBLIC_KEY_PREFIX_LEN] != pk_prefix:\n        raise VerificationError('public key mismatch')\n\n    first_party_pub = caveat[:_KEY_LEN]\n    caveat = caveat[_KEY_LEN:]\n    nonce = caveat[:nacl.public.Box.NONCE_SIZE]\n    caveat = caveat[nacl.public.Box.NONCE_SIZE:]\n    fp_public_key = nacl.public.PublicKey(first_party_pub)\n    box = nacl.public.Box(key.key, fp_public_key)\n    data = box.decrypt(caveat, nonce)\n    root_key, condition, ns = _decode_secret_part_v2_v3(version, data)\n    return ThirdPartyCaveatInfo(\n        condition=condition.decode('utf-8'),\n        first_party_public_key=PublicKey(fp_public_key),\n        third_party_key_pair=key,\n        root_key=root_key,\n        caveat=original_caveat,\n        version=version,\n        id=None,\n        namespace=ns\n    )", "label": 1}
{"code": "def bit_by_bit(self, in_data):\n        \"\"\"\n        Classic simple and slow CRC implementation.  This function iterates bit\n        by bit over the augmented input message and returns the calculated CRC\n        value at the end.\n        \"\"\"\n        # If the input data is a string, convert to bytes.\n        if isinstance(in_data, str):\n            in_data = [ord(c) for c in in_data]\n\n        register = self.NonDirectInit\n        for octet in in_data:\n            if self.ReflectIn:\n                octet = self.reflect(octet, 8)\n            for i in range(8):\n                topbit = register & self.MSB_Mask\n                register = ((register << 1) & self.Mask) | ((octet >> (7 - i)) & 0x01)\n                if topbit:\n                    register ^= self.Poly\n\n        for i in range(self.Width):\n            topbit = register & self.MSB_Mask\n            register = ((register << 1) & self.Mask)\n            if topbit:\n                register ^= self.Poly\n\n        if self.ReflectOut:\n            register = self.reflect(register, self.Width)\n        return register ^ self.XorOut", "label": 1}
{"code": "public static BufferedImage resizeToWidth(BufferedImage originalImage, int widthOut) {\n    \n    int width = originalImage.getWidth();\n    \n    int height = originalImage.getHeight();\n    \n    int widthPercent = (widthOut * 100) / width;\n    \n    int newHeight = (height * widthPercent) / 100;\n    \n    BufferedImage resizedImage =\n        new BufferedImage(widthOut, newHeight, BufferedImage.TYPE_INT_ARGB);\n    Graphics2D g = resizedImage.createGraphics();\n    g.drawImage(originalImage, 0, 0, widthOut, newHeight, null);\n    g.dispose();\n    \n    return resizedImage;\n  }", "label": 0}
{"code": "public static base_response reset(nitro_service client, Interface resource) throws Exception {\n\t\tInterface resetresource = new Interface();\n\t\tresetresource.id = resource.id;\n\t\treturn resetresource.perform_operation(client,\"reset\");\n\t}", "label": 0}
{"code": "def join\n      @threads_mon.synchronize do\n        begin\n          stat :joining\n          @join_cond.wait unless @threads.empty?\n          stat :joined\n        rescue Exception => e\n          stat :joined\n          $stderr.puts e\n          $stderr.print \"Queue contains #{@queue.size} items. \" +\n            \"Thread pool contains #{@threads.count} threads\\n\"\n          $stderr.print \"Current Thread #{Thread.current} status = \" +\n            \"#{Thread.current.status}\\n\"\n          $stderr.puts e.backtrace.join(\"\\n\")\n          @threads.each do |t|\n            $stderr.print \"Thread #{t} status = #{t.status}\\n\"\n            $stderr.puts t.backtrace.join(\"\\n\")\n          end\n          raise e\n        end\n      end\n    end", "label": 4}
{"code": "def convert(self, key, value):\n        \"\"\"Get the serialized value for a given key.\"\"\"\n        if key not in self._dtypes:\n            self.read_types()\n            if key not in self._dtypes:\n                name = utils.name(value)\n                serializer = utils.serializer(name)\n                deserializer = utils.deserializer(name)\n                self._dtypes[key] = (name, serializer, deserializer)\n                with self.db:\n                    self.db.execute(\"replace into value_types (key, value_type) values (?, ?)\", (key, name))\n        return self._dtypes[key][1](value)", "label": 1}
{"code": "func (v VirtualMachine) RevertToSnapshot(ctx context.Context, name string, suppressPowerOn bool) (*Task, error) {\n\tsnapshot, err := v.FindSnapshot(ctx, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq := types.RevertToSnapshot_Task{\n\t\tThis:            snapshot.Reference(),\n\t\tSuppressPowerOn: types.NewBool(suppressPowerOn),\n\t}\n\n\tres, err := methods.RevertToSnapshot_Task(ctx, v.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewTask(v.c, res.Returnval), nil\n}", "label": 5}
{"code": "function assertString(attr, data) {\n  if (data === null || data === undefined) {\n    return null;\n  }\n\n  if (typeof data !== 'string') {\n    throw new ParseError(`Attribute ${attr} must be of type \"string\"`);\n  }\n\n  return data;\n}", "label": 3}
{"code": "def parse_config(config)\n      sections = {\"defaults\" => []}\n      current  = \"defaults\"\n      config.gsub(/#[^\\n]*/, \"\")\n        .split(/\\n/)\n        .map(&:strip)\n        .reject(&:empty?)\n        .each do |line|\n        if IS_SECTION =~ line\n          current = line.match(IS_SECTION)[1].strip\n          sections[current] ||= []\n        else\n          sections[current] << line\n        end\n      end\n      sections\n    end", "label": 4}
{"code": "def inline_i(str)\n      if @book.config.check_version('2', exception: false)\n        macro('textit', escape(str))\n      else\n        macro('reviewit', escape(str))\n      end\n    end", "label": 4}
{"code": "func (d Datastore) NewURL(path string) *url.URL {\n\tu := d.c.URL()\n\n\treturn &url.URL{\n\t\tScheme: u.Scheme,\n\t\tHost:   u.Host,\n\t\tPath:   fmt.Sprintf(\"/folder/%s\", path),\n\t\tRawQuery: url.Values{\n\t\t\t\"dcPath\": []string{d.DatacenterPath},\n\t\t\t\"dsName\": []string{d.Name()},\n\t\t}.Encode(),\n\t}\n}", "label": 5}
{"code": "def handle_specific_variable_ref(reference_criteria)\n      # if there are no referenced children, then it's a variable representing\n      # a single data criteria, so just reference it\n      if reference_criteria.children_criteria.empty?\n        @children_criteria = [reference_criteria.id]\n      # otherwise pull all the data criteria info from the reference\n      else\n        @field_values = reference_criteria.field_values\n        @temporal_references = reference_criteria.temporal_references\n        @subset_operators = reference_criteria.subset_operators\n        @derivation_operator = reference_criteria.derivation_operator\n        @definition = reference_criteria.definition\n        @description = reference_criteria.description\n        @status = reference_criteria.status\n        @children_criteria = reference_criteria.children_criteria\n      end\n    end", "label": 4}
{"code": "static final TimeBasedRollStrategy findRollStrategy(\n      final AppenderRollingProperties properties) {\n    if (properties.getDatePattern() == null) {\n      LogLog.error(\"null date pattern\");\n      return ROLL_ERROR;\n    }\n    // Strip out quoted sections so that we may safely scan the undecorated\n    // pattern for characters that are meaningful to SimpleDateFormat.\n    final LocalizedDateFormatPatternHelper localizedDateFormatPatternHelper = new LocalizedDateFormatPatternHelper(\n        properties.getDatePatternLocale());\n    final String undecoratedDatePattern = localizedDateFormatPatternHelper\n        .excludeQuoted(properties.getDatePattern());\n    if (ROLL_EACH_MINUTE.isRequiredStrategy(localizedDateFormatPatternHelper,\n        undecoratedDatePattern)) {\n      return ROLL_EACH_MINUTE;\n    }\n    if (ROLL_EACH_HOUR.isRequiredStrategy(localizedDateFormatPatternHelper,\n        undecoratedDatePattern)) {\n      return ROLL_EACH_HOUR;\n    }\n    if (ROLL_EACH_HALF_DAY.isRequiredStrategy(localizedDateFormatPatternHelper,\n        undecoratedDatePattern)) {\n      return ROLL_EACH_HALF_DAY;\n    }\n    if (ROLL_EACH_DAY.isRequiredStrategy(localizedDateFormatPatternHelper,\n        undecoratedDatePattern)) {\n      return ROLL_EACH_DAY;\n    }\n    if (ROLL_EACH_WEEK.isRequiredStrategy(localizedDateFormatPatternHelper,\n        undecoratedDatePattern)) {\n      return ROLL_EACH_WEEK;\n    }\n    if (ROLL_EACH_MONTH.isRequiredStrategy(localizedDateFormatPatternHelper,\n        undecoratedDatePattern)) {\n      return ROLL_EACH_MONTH;\n    }\n    return ROLL_ERROR;\n  }", "label": 0}
{"code": "function(to, evt, indexMap) {\n      var result,\n        feedbackToInvoke = _.find(this.feedback, function(feedback) {\n          var toToCheck = feedback.to;\n          if (_.isArray(toToCheck)) {\n            return _.contains(toToCheck, to);\n          } else {\n            return to === toToCheck;\n          }\n        }),\n        feedbackCellField = to;\n      if (feedbackToInvoke) {\n        if (indexMap) {\n          feedbackCellField = this.__substituteIndicesUsingMap(to, indexMap);\n        }\n        result = feedbackToInvoke.then.call(this, evt, indexMap);\n        this.__processFeedbackThenResult(result, feedbackCellField);\n      }\n    }", "label": 3}
{"code": "private function groupByFile(AnalysisResult $analysisResult): array\n\t{\n\t\t$files = [];\n\n\t\t/** @var \\PHPStan\\Analyser\\Error $fileSpecificError */\n\t\tforeach ($analysisResult->getFileSpecificErrors() as $fileSpecificError) {\n\t\t\t$relativeFilePath = $this->relativePathHelper->getRelativePath(\n\t\t\t\t$fileSpecificError->getFile()\n\t\t\t);\n\n\t\t\t$files[$relativeFilePath][] = $fileSpecificError;\n\t\t}\n\n\t\treturn $files;\n\t}", "label": 2}
{"code": "private function maxResult($feature)\n    {\n        return (isset($this->options['maxResults'][$feature]))\n            ? $this->options['maxResults'][$feature]\n            : null;\n    }", "label": 2}
{"code": "function(callback) {\n  // Asynchronously set our name and status message using promises\n  Promise.join(\n    tox.setNameAsync('Bluebird'),\n    tox.setStatusMessageAsync('Some status message')\n  ).then(function() {\n    console.log('Successfully set name and status message!');\n    callback();\n  }).catch(function(err) {\n    console.error('Error (initSelf):', err);\n    callback(err);\n  });\n}", "label": 3}
{"code": "def make_type(cls, basename, cardinality):\n        \"\"\"Build new type name according to CardinalityField naming scheme.\n\n        :param basename:  Type basename of primary type (as string).\n        :param cardinality: Cardinality of the new type (as Cardinality item).\n        :return: Type name with CardinalityField suffix (if needed)\n        \"\"\"\n        if cardinality is Cardinality.one:\n            # -- POSTCONDITION: assert not cls.make_type(type_name)\n            return basename\n        # -- NORMAL CASE: type with CardinalityField suffix.\n        type_name = \"%s%s\" % (basename, cls.to_char_map[cardinality])\n        # -- POSTCONDITION: assert cls.make_type(type_name)\n        return type_name", "label": 1}
{"code": "func New(lDs, gDs interface{}, dfn DriverNotifyFunc, ifn IPAMNotifyFunc, pg plugingetter.PluginGetter) (*DrvRegistry, error) {\n\tr := &DrvRegistry{\n\t\tdrivers:      make(driverTable),\n\t\tipamDrivers:  make(ipamTable),\n\t\tdfn:          dfn,\n\t\tifn:          ifn,\n\t\tpluginGetter: pg,\n\t}\n\n\treturn r, nil\n}", "label": 5}
{"code": "public double loglikelihood(List<IN> lineInfos) {\r\n    double cll = 0.0;\r\n\r\n    for (int i = 0; i < lineInfos.size(); i++) {\r\n      Datum<String, String> d = makeDatum(lineInfos, i, featureFactory);\r\n      Counter<String> c = classifier.logProbabilityOf(d);\r\n\r\n      double total = Double.NEGATIVE_INFINITY;\r\n      for (String s : c.keySet()) {\r\n        total = SloppyMath.logAdd(total, c.getCount(s));\r\n      }\r\n      cll -= c.getCount(d.label()) - total;\r\n    }\r\n    // quadratic prior\r\n    // HN: TODO: add other priors\r\n\r\n    if (classifier instanceof LinearClassifier) {\r\n      double sigmaSq = flags.sigma * flags.sigma;\r\n      LinearClassifier<String, String> lc = (LinearClassifier<String, String>)classifier;\r\n      for (String feature: lc.features()) {\r\n        for (String classLabel: classIndex) {\r\n          double w = lc.weight(feature, classLabel);\r\n          cll += w * w / 2.0 / sigmaSq;\r\n        }\r\n      }\r\n    }\r\n    return cll;\r\n  }", "label": 0}
{"code": "function(name, container, args, events) {\n      /* handling for any default values if args are not specified */\n      var mergeDefaults = function(args, defaults) {\n        var args = args || {};\n\n        if (typeof defaults == 'object') {\n          for (var key in defaults) {\n            if (elation.utils.isNull(args[key])) {\n              args[key] = defaults[key];\n            }\n          }\n        }\n        \n        return args;\n      };\n\n      var realname = name;\n      if (elation.utils.isObject(name)) {\n        // Simple syntax just takes an object with all arguments\n        args = name;\n        realname = elation.utils.any(args.id, args.name, null);\n        container = (!elation.utils.isNull(args.container) ? args.container : null);\n        events = (!elation.utils.isNull(args.events) ? args.events : null);\n      }\n\n      // If no args were passed in, we're probably being used as the base for another \n      // component's prototype, so there's no need to go through full init\n      if (elation.utils.isNull(realname) && !container && !args) {\n        var obj = new component.base(type);\n        \n        // apply default args\n        obj.args = mergeDefaults(obj.args, elation.utils.clone(obj.defaults));\n        \n        return obj;\n      }\n\n      // If no name was passed, use the current object count as a name instead (\"anonymous\" components)\n      if (elation.utils.isNull(realname) || realname === \"\") {\n        realname = component.objcount;\n      }\n\n      if (!component.obj[realname] && !elation.utils.isEmpty(args)) {\n        component.obj[realname] = obj = new component.base(type);\n        component.objcount++;\n      //}\n      // TODO - I think combining this logic would let us use components without needing HTML elements for the container\n      //if (component.obj[realname] && container !== undefined) {\n        component.obj[realname].componentinit(type, realname, container, args, events);\n\n/*\n        if (component.extendclass) {\n          component.obj[realname].initSuperClass(component.extendclass);\n        }\n*/\n        // fix handling for append component infinite recursion issue\n        if (args.append instanceof elation.component.base) \n          args.append = args.append.container;\n\n        if (args.before instanceof elation.component.base) \n          args.before = args.before.container;\n\n        // apply default args\n        try {\n          if (typeof obj.defaults == 'object')\n            args = mergeDefaults(args, elation.utils.clone(obj.defaults));\n\n          var parentclass = component.extendclass;\n\n          // recursively apply inherited defaults\n          while (parentclass) {\n            if (typeof parentclass.defaults == 'object')\n              elation.utils.merge(mergeDefaults(args, elation.utils.clone(parentclass.defaults)),args);\n\n            parentclass = parentclass.extendclass;\n          }\n        } catch (e) {\n          console.log('-!- Error merging component args', e.msg);\n        }\n\n        if (typeof obj.init == 'function') {\n          obj.init(realname, container, args, events);\n        }\n      }\n      return component.obj[realname];\n    }", "label": 3}
{"code": "def parse_selectors(model, fields=None, exclude=None, key_map=None, **options):\n    \"\"\"Validates fields are valid and maps pseudo-fields to actual fields\n    for a given model class.\n    \"\"\"\n    fields = fields or DEFAULT_SELECTORS\n    exclude = exclude or ()\n    key_map = key_map or {}\n    validated = []\n\n    for alias in fields:\n        # Map the output key name to the actual field/accessor name for\n        # the model\n        actual = key_map.get(alias, alias)\n\n        # Validate the field exists\n        cleaned = resolver.get_field(model, actual)\n\n        if cleaned is None:\n            raise AttributeError('The \"{0}\" attribute could not be found '\n                                 'on the model \"{1}\"'.format(actual, model))\n\n        # Mapped value, so use the original name listed in `fields`\n        if type(cleaned) is list:\n            validated.extend(cleaned)\n        elif alias != actual:\n            validated.append(alias)\n        else:\n            validated.append(cleaned)\n\n    return tuple([x for x in validated if x not in exclude])", "label": 1}
{"code": "def warning(self, message, *args, **kwargs):\n        \"\"\"\n        Specialized warnings system. If a warning subclass is passed into\n        the keyword arguments and raise_warnings is True - the warnning will\n        be passed to the warnings module.\n        \"\"\"\n        warncls = kwargs.pop('warning', None)\n        if warncls and self.raise_warnings:\n            warnings.warn(message, warncls)\n\n        return self.log(logging.WARNING, message, *args, **kwargs)", "label": 1}
{"code": "func (p *Decoder) typeForElement(val reflect.Value, start *StartElement) reflect.Type {\n\tt := \"\"\n\tfor i, a := range start.Attr {\n\t\tif a.Name == xmlSchemaInstance || a.Name == xsiType {\n\t\t\tt = a.Value\n\t\t\t// HACK: ensure xsi:type is last in the list to avoid using that value for\n\t\t\t// a \"type\" attribute, such as ManagedObjectReference.Type for example.\n\t\t\t// Note that xsi:type is already the last attribute in VC/ESX responses.\n\t\t\t// This is only an issue with govmomi simulator generated responses.\n\t\t\t// Proper fix will require finding a few needles in this xml package haystack.\n\t\t\t// Note: govmomi uses xmlSchemaInstance, other clients (e.g. rbvmomi) use xsiType.\n\t\t\t// They are the same thing to XML parsers, but not to this hack here.\n\t\t\tx := len(start.Attr) - 1\n\t\t\tif i != x {\n\t\t\t\tstart.Attr[i] = start.Attr[x]\n\t\t\t\tstart.Attr[x] = a\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif t == \"\" {\n\t\t// No type attribute; fall back to looking up type by interface name.\n\t\tt = val.Type().Name()\n\t}\n\n\t// Maybe the type is a basic xsd:* type.\n\ttyp := stringToType(t)\n\tif typ != nil {\n\t\treturn typ\n\t}\n\n\t// Maybe the type is a custom type.\n\tif p.TypeFunc != nil {\n\t\tif typ, ok := p.TypeFunc(t); ok {\n\t\t\treturn typ\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def insert_files(self, rootpath, directoryInFilter=None, directoryExFilter=None, compileInFilter=None, compileExFilter=None, contentInFilter=None, contentExFilter=None):\n        \"\"\"\n        Inserts files by recursive traversing the rootpath and inserting files according the addition filter parameters.\n\n        :param str rootpath:            The absolute path to the root directory.\n        :param list directoryInFilter:  A list of fnmatch expressions to match directories to be included.  A `None` value will default to :attr:`DirectoryInFilter`.\n        :param list directoryExFilter:  A list of fnmatch expressions to match directories to be excluded.  A `None` value will default to :attr:`DirectoryExFilter`.\n        :param list compileInFilter:    A list of fnmatch expressions to match compile files to be included.  A `None` value will default to :attr:`CompileInFilter`.\n        :param list compileExFilter:    A list of fnmatch expressions to match compile files to be excludes.  A `None` value will default to :attr:`CompileExFilter`.\n        :param list contentInFilter:    A list of fnmatch expressions to match content files to be includes.  A `None` value will default to :attr:`ContentInFilter`.\n        :param list contentExFilter:    A list of fnmatch expressions to match content files to be excludes.  A `None` value will default to :attr:`ContentExFilter`.\n        \"\"\"\n        # Overrides\n        directoryInFilter = self.DirectoryInFilter if directoryInFilter is None else directoryInFilter\n        directoryExFilter = self.DirectoryExFilter if directoryExFilter is None else directoryExFilter\n        compileInFilter = self.CompileInFilter if compileInFilter is None else compileInFilter\n        compileExFilter = self.CompileExFilter if compileExFilter is None else compileExFilter\n        contentInFilter = self.ContentInFilter if contentInFilter is None else contentInFilter\n        contentExFilter = self.ContentExFilter if contentExFilter is None else contentExFilter\n\n        def filter(text, filters, explicit):\n            \"\"\"\n            Convience filter function\n\n            :param text text: The target text.\n            :param list filters: The collection of fnmatch expressions\n            :param bool explicit: Flag denoting an the empty filter collection return match failure.\n            \"\"\"\n            if explicit:\n                return any(fnmatch.fnmatch(text, f) for f in filters)\n            return not filters or any(fnmatch.fnmatch(text, f) for f in filters)\n\n        for root, dirnames, filenames in os.walk(rootpath):\n\n            searchdir = os.path.normpath(os.path.normcase(root))\n\n            # If the root dir matches an excluded directory, stop any further searches\n            if filter(searchdir, directoryExFilter, True):\n                dirnames[:] = []\n            elif filter(searchdir, directoryInFilter, False):\n                for filepath in [os.path.join(root, filename) for filename in filenames]:\n                    if filter(filepath, compileInFilter, False) and not filter(filepath, compileExFilter, True):\n                        self.CompileFiles.append(filepath)\n                    elif filter(filepath, contentInFilter, False) and not filter(filepath, contentExFilter, True):\n                        self.ContentFiles.append(filepath)", "label": 1}
{"code": "def _disconnect(cls):\n        \"\"\"\n        Disconnect signal from current model\n        \"\"\"\n        post_save.disconnect(\n            notify_items, sender=cls,\n            dispatch_uid='knocker_{0}'.format(cls.__name__)\n        )", "label": 1}
{"code": "def scopes_picker_tag(name, value, options = {})\n      root = try(:current_participatory_space)&.scope\n      field = options[:field] || name\n\n      scopes_picker_field_tag name, value, id: options[:id] do |scope|\n        { url: decidim.scopes_picker_path(root: root, current: scope&.id, field: field),\n          text: scope_name_for_picker(scope, I18n.t(\"decidim.scopes.global\")) }\n      end\n    end", "label": 4}
{"code": "def warm_all\n      threads = []\n      all_functions.each do |function_name|\n        next if function_name.include?('jets-public_controller') # handled by warm_public_controller_more\n        next if function_name.include?('jets-rack_controller') # handled by warm_rack_controller_more\n        threads << Thread.new do\n          warm(function_name)\n        end\n      end\n      threads.each { |t| t.join }\n\n      # Warm the these controllers more since they can be hit more often\n      warm_public_controller_more\n      warm_rack_controller_more\n\n      # return the funciton names so we can see in the Lambda console\n      # the functions being prewarmed\n      all_functions\n    end", "label": 4}
{"code": "def edit(filename, identifier, data):\n    \"\"\"\n    Update an entry in a BibTeX file.\n\n    :param filename: The name of the BibTeX file to edit.\n    :param identifier: The id of the entry to update, in the BibTeX file.\n    :param data: A dict associating fields and updated values. Fields present \\\n            in the BibTeX file but not in this dict will be kept as is.\n    \"\"\"\n    # Get current bibtex\n    with open(filename, 'r') as fh:\n        bibtex = bibtexparser.load(fh)\n\n    # Update it\n    # TODO: Not working\n    bibtex.entries_dict[identifier] = data.entries[0]\n\n    # Write the resulting BibTeX\n    write(filename, bibtex)", "label": 1}
{"code": "protected function getReplacement($stub)\n    {\n        $replacements = $this->module->config('stubs.replacements');\n\n        if (!isset($replacements[$stub])) {\n            return [];\n        }\n\n        $keys = $replacements[$stub];\n\n        $replaces = [];\n\n        foreach ($keys as $key) {\n            if (method_exists($this, $method = 'get' . ucfirst(Str::studly(strtolower($key))) . 'Replacement')) {\n                $replaces[$key] = $this->$method();\n            } else {\n                $replaces[$key] = null;\n            }\n        }\n\n        return $replaces;\n    }", "label": 2}
{"code": "func MakeDefaultConfig() *Config {\n\treturn &Config{\n\t\tStdout: os.Stdout,\n\t\tStderr: os.Stderr,\n\t\tStdin:  os.Stdin,\n\t}\n}", "label": 5}
{"code": "func NewStore(dir string, store *imagestore.Store) (*Store, error) {\n\t// TODO(sgotti) backward compatibility with the current tree store paths. Needs a migration path to better paths.\n\tts := &Store{dir: filepath.Join(dir, \"tree\"), store: store}\n\n\tts.lockDir = filepath.Join(dir, \"treestorelocks\")\n\tif err := os.MkdirAll(ts.lockDir, 0755); err != nil {\n\t\treturn nil, err\n\t}\n\treturn ts, nil\n}", "label": 5}
{"code": "function (name) {\n        var newName;\n        if (gpf.xml.isValidName(name)) {\n            return name;\n        }\n        // Try with a starting _\n        newName = \"_\" + name;\n        if (!gpf.xml.isValidName(newName)) {\n            gpf.Error.xmlInvalidName();\n        }\n        return newName;\n    }", "label": 3}
{"code": "func (i *bridgeInterface) addresses() ([]netlink.Addr, []netlink.Addr, error) {\n\tv4addr, err := i.nlh.AddrList(i.Link, netlink.FAMILY_V4)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"Failed to retrieve V4 addresses: %v\", err)\n\t}\n\n\tv6addr, err := i.nlh.AddrList(i.Link, netlink.FAMILY_V6)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"Failed to retrieve V6 addresses: %v\", err)\n\t}\n\n\tif len(v4addr) == 0 {\n\t\treturn nil, v6addr, nil\n\t}\n\treturn v4addr, v6addr, nil\n}", "label": 5}
{"code": "func AuthGroupByID(db XODB, id int) (*AuthGroup, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, name ` +\n\t\t`FROM django.auth_group ` +\n\t\t`WHERE id = ?`\n\n\t// run query\n\tXOLog(sqlstr, id)\n\tag := AuthGroup{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, id).Scan(&ag.ID, &ag.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ag, nil\n}", "label": 5}
{"code": "def received(self, data):\n        \"\"\"\n        API for the connection to forward\n        information to this subscription instance.\n\n        :param data: The JSON data which was received.\n        :type data: Message\n        \"\"\"\n        self.logger.debug('Data received: {}'.format(data))\n\n        message_type = None\n\n        if 'type' in data:\n            message_type = data['type']\n\n        if message_type == 'confirm_subscription':\n            self._subscribed()\n        elif message_type == 'reject_subscription':\n            self._rejected()\n        elif self.receive_callback is not None and 'message' in data:\n            self.receive_callback(data['message'])\n        else:\n            self.logger.warning('Message type unknown. ({})'.format(message_type))", "label": 1}
{"code": "public static void printToFile(String filename, String message) {\r\n    printToFile(new File(filename), message, false);\r\n  }", "label": 0}
{"code": "private function getKeyFile(array $config = [])\n    {\n        $config += [\n            'keyFile' => null,\n            'keyFilePath' => null,\n        ];\n\n        if ($config['keyFile']) {\n            return $config['keyFile'];\n        }\n\n        if ($config['keyFilePath']) {\n            if (!file_exists($config['keyFilePath'])) {\n                throw new GoogleException(sprintf(\n                    'Given keyfile path %s does not exist',\n                    $config['keyFilePath']\n                ));\n            }\n\n            try {\n                $keyFileData = $this->jsonDecode(file_get_contents($config['keyFilePath']), true);\n            } catch (\\InvalidArgumentException $ex) {\n                throw new GoogleException(sprintf(\n                    'Given keyfile at path %s was invalid',\n                    $config['keyFilePath']\n                ));\n            }\n\n            return $keyFileData;\n        }\n\n        return CredentialsLoader::fromEnv()\n            ?: CredentialsLoader::fromWellKnownFile();\n    }", "label": 2}
{"code": "func (s *server) CreateSession(sess Session) error {\n\tif err := sess.ID.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif sess.Namespace == \"\" {\n\t\treturn trace.BadParameter(\"session namespace can not be empty\")\n\t}\n\tif sess.Login == \"\" {\n\t\treturn trace.BadParameter(\"session login can not be empty\")\n\t}\n\tif sess.Created.IsZero() {\n\t\treturn trace.BadParameter(\"created can not be empty\")\n\t}\n\tif sess.LastActive.IsZero() {\n\t\treturn trace.BadParameter(\"last_active can not be empty\")\n\t}\n\t_, err := NewTerminalParamsFromInt(sess.TerminalParams.W, sess.TerminalParams.H)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tsess.Parties = nil\n\tdata, err := json.Marshal(sess)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\titem := backend.Item{\n\t\tKey:     activeKey(sess.Namespace, string(sess.ID)),\n\t\tValue:   data,\n\t\tExpires: s.clock.Now().UTC().Add(s.activeSessionTTL),\n\t}\n\t_, err = s.bk.Create(context.TODO(), item)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def stop(self):\n        \"\"\"\n        Stops a paused pipeline. This will a trigger a ``StopIteration`` in the\n        inputs of the pipeline. And retrieve the buffered results. This will\n        stop all ``Pipers`` and ``NuMaps``. Python will not terminate cleanly \n        if a pipeline is running or paused.\n        \n        \"\"\"\n        if self._started.isSet() and \\\n           not self._running.isSet() and \\\n           not self._pausing.isSet():\n            # stops the dagger\n            super(Plumber, self).stop()\n            # disconnects all pipers\n            self.disconnect()\n            self.stats['run_time'] = time() - self.stats['start_time']\n            self._started.clear()\n        else:\n            raise PlumberError", "label": 1}
{"code": "func (c CachePolicy) String() string {\n\tif !c.Enabled {\n\t\treturn \"no cache policy\"\n\t}\n\trecentCachePolicy := \"\"\n\tif c.GetRecentTTL() == 0 {\n\t\trecentCachePolicy = \"will not cache frequently accessed items\"\n\t} else {\n\t\trecentCachePolicy = fmt.Sprintf(\"will cache frequently accessed items for %v\", c.GetRecentTTL())\n\t}\n\tif c.NeverExpires {\n\t\treturn fmt.Sprintf(\"cache that will not expire in case if connection to database is lost, %v\", recentCachePolicy)\n\t}\n\tif c.TTL == 0 {\n\t\treturn fmt.Sprintf(\"cache that will expire after connection to database is lost after %v, %v\", defaults.CacheTTL, recentCachePolicy)\n\t}\n\treturn fmt.Sprintf(\"cache that will expire after connection to database is lost after %v, %v\", c.TTL, recentCachePolicy)\n}", "label": 5}
{"code": "protected function getResponse($host, $query)\n  {\n      // Build the url.\n      $url = $host.'?'.http_build_query($query);\n\n      // Open connection.\n      $ch = curl_init();\n\n      // Configure the connection.\n      curl_setopt($ch, CURLOPT_URL, $url);\n      curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n      curl_setopt($ch, CURLOPT_HEADER, 0);\n      curl_setopt($ch, CURLOPT_USERAGENT, Constants::WHATSAPP_USER_AGENT);\n      curl_setopt($ch, CURLOPT_HTTPHEADER, ['Accept: text/json']);\n      // This makes CURL accept any peer!\n      curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);\n\n      // Get the response.\n      $response = curl_exec($ch);\n\n      // Close the connection.\n      curl_close($ch);\n\n      return json_decode($response);\n  }", "label": 2}
{"code": "def boost_factor(factor, options = {})\n      scoring = options.merge(boost_factor: factor.to_i)\n      chain { criteria.update_scores scoring }\n    end", "label": 4}
{"code": "func (aug *AuthUserGroup) Update(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !aug._exists {\n\t\treturn errors.New(\"update failed: does not exist\")\n\t}\n\n\t// if deleted, bail\n\tif aug._deleted {\n\t\treturn errors.New(\"update failed: marked for deletion\")\n\t}\n\n\t// sql query\n\tconst sqlstr = `UPDATE public.auth_user_groups SET (` +\n\t\t`user_id, group_id` +\n\t\t`) = ( ` +\n\t\t`$1, $2` +\n\t\t`) WHERE id = $3`\n\n\t// run query\n\tXOLog(sqlstr, aug.UserID, aug.GroupID, aug.ID)\n\t_, err = db.Exec(sqlstr, aug.UserID, aug.GroupID, aug.ID)\n\treturn err\n}", "label": 5}
{"code": "function getFields(collection) {\n\n    var message = 'What fields should \"' + collection + '\" have?\\n',\n        config;\n\n    config = {\n        properties: {\n            fields: {\n                description: message.magenta +\n                '   Comma-separated fieldname:fieldtype pairs (ex: id:index, username:username)\\n'.grey,\n                type: 'string',\n                required: true,\n                pattern: FIELDS_REGEXP\n            }\n        }\n    };\n\n    prompt.start();\n    prompt.message = '   >> ';\n    prompt.delimiter = '';\n\n    return new Promise(function(resolve, reject) {\n        prompt.get(config, function(err, result) {\n            if (err) return reject(err);\n            return resolve(result.fields);\n        });\n    }).then(function(input) {\n        return (input.match(FIELDS_REGEXP) || []).reduce(function(prev, curr) {\n            var parts = curr.split(':');\n            prev[parts[0]] = parts[1].replace(/\\+/g, '}~{'); // with \"+\" also support name={fistName}~{lastName} concatenations\n            return prev;\n        }, {});\n    });\n}", "label": 3}
{"code": "def http_error_handler(f):\n    \"\"\"Handle 404 errors returned by the API server\n    \"\"\"\n\n    def hrefs_to_resources(hrefs):\n        for href in hrefs.replace(',', '').split():\n            type, uuid = href.split('/')[-2:]\n            yield Resource(type, uuid=uuid)\n\n    def hrefs_list_to_resources(hrefs_list):\n        for href in eval(hrefs_list):\n            type, uuid = href.split('/')[-2:]\n            yield Resource(type, uuid=uuid)\n\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        try:\n            return f(self, *args, **kwargs)\n        except HttpError as e:\n            if e.http_status == 404:\n                # remove previously created resource\n                # from the cache\n                self.emit('deleted', self)\n                if isinstance(self, Resource):\n                    raise ResourceNotFound(resource=self)\n                elif isinstance(self, Collection):\n                    raise CollectionNotFound(collection=self)\n            elif e.http_status == 409:\n                # contrail 3.2\n                matches = re.match(r'^Delete when children still present: (\\[[^]]*\\])', e.message)\n                if matches:\n                    raise ChildrenExists(\n                        resources=list(hrefs_list_to_resources(matches.group(1))))\n                matches = re.match(r'^Delete when resource still referred: (\\[[^]]*\\])', e.message)\n                if matches:\n                    raise BackRefsExists(\n                        resources=list(hrefs_list_to_resources(matches.group(1))))\n                # contrail 2.21\n                matches = re.match(r'^Children (.*) still exist$', e.message)\n                if matches:\n                    raise ChildrenExists(\n                        resources=list(hrefs_to_resources(matches.group(1))))\n                matches = re.match(r'^Back-References from (.*) still exist$', e.message)\n                if matches:\n                    raise BackRefsExists(\n                        resources=list(hrefs_to_resources(matches.group(1))))\n            raise\n    return wrapper", "label": 1}
{"code": "def start(self):\n        \"\"\"Activate the TypingStream on stdout\"\"\"\n        self.streams.append(sys.stdout)\n        sys.stdout = self.stream", "label": 1}
{"code": "public function merged()\n    {\n        if (!$this->openapi) {\n            throw new Exception('No openapi target set. Run the MergeIntoOpenApi processor');\n        }\n        $unmerged = $this->openapi->_unmerged;\n        $this->openapi->_unmerged = [];\n        $analysis = new Analysis([$this->openapi]);\n        $this->openapi->_unmerged = $unmerged;\n\n        return $analysis;\n    }", "label": 2}
{"code": "public void addBasicSentence(MtasCQLParserBasicSentenceCondition s)\n      throws ParseException {\n    if (!simplified) {\n      List<MtasCQLParserBasicSentencePartCondition> newWordList = s\n          .getPartList();\n      partList.addAll(newWordList);\n    } else {\n      throw new ParseException(\"already simplified\");\n    }\n  }", "label": 0}
{"code": "func (self *Transcoder) Do(pkt av.Packet) (out []av.Packet, err error) {\n\tstream := self.streams[pkt.Idx]\n\tif stream.aenc != nil && stream.adec != nil {\n\t\tif out, err = stream.audioDecodeAndEncode(pkt); err != nil {\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tout = append(out, pkt)\n\t}\n\treturn\n}", "label": 5}
{"code": "function csvWrapForExcel(encoder) {\n  // Pipe the CSV encoder to the ucs2 converter\n  var converter = new Stream.Transform();\n  var csvStream = new Stream.PassThrough();\n  converter._transform = function(chunk, encoding, cb) {\n    this.push(new Buffer(chunk.toString(), 'ucs2'));\n    cb();\n  };\n  // Write the UCS2 BOM http://www.unicode.org/faq/utf_bom.html#bom1\n  csvStream.write(new Buffer([0xFF, 0xFE]));\n  return encoder.pipe(converter).pipe(csvStream);\n}", "label": 3}
{"code": "def get_host(self):\n        \"\"\" \n        returns the host computer running this program \n        \"\"\"\n        import socket\n        host_name = socket.gethostname()\n        for h in hosts:\n            if h['name'] == host_name:\n                return h['type'], h['name']\n        return dict(type='Unknown', name=host_name)", "label": 1}
{"code": "private void deleteDir(File dir)\r\n    {\r\n        if (dir.exists() && dir.isDirectory())\r\n        {\r\n            File[] files = dir.listFiles();\r\n\r\n            for (int idx = 0; idx < files.length; idx++)\r\n            {\r\n                if (!files[idx].exists())\r\n                {\r\n                    continue;\r\n                }\r\n                if (files[idx].isDirectory())\r\n                {\r\n                    deleteDir(files[idx]);\r\n                }\r\n                else\r\n                {\r\n                    files[idx].delete();\r\n                }\r\n            }\r\n            dir.delete();\r\n        }\r\n    }", "label": 0}
{"code": "def load!\n      unless loaded?\n        ActiveSupport::Notifications.publish BeforeLoadEvent, self # before_load hook\n        files.each { |file| load file }                            # load files\n        namespace(default_namespace)                               # init AA resources\n        ActiveSupport::Notifications.publish AfterLoadEvent, self  # after_load hook\n        @@loaded = true\n      end\n    end", "label": 4}
{"code": "def poly_to_pwl(self, n_points=4):\n        \"\"\" Sets the piece-wise linear cost attribute, converting the\n        polynomial cost variable by evaluating at zero and then at n_points\n        evenly spaced points between p_min and p_max.\n        \"\"\"\n        assert self.pcost_model == POLYNOMIAL\n        p_min = self.p_min\n        p_max = self.p_max\n        p_cost = []\n\n        if p_min > 0.0:\n            # Make the first segment go from the origin to p_min.\n            step = (p_max - p_min) / (n_points - 2)\n\n            y0 = self.total_cost(0.0)\n            p_cost.append((0.0, y0))\n\n            x = p_min\n            n_points -= 1\n        else:\n            step = (p_max - p_min) / (n_points - 1)\n            x = 0.0\n\n        for _ in range(n_points):\n            y = self.total_cost(x)\n            p_cost.append((x, y))\n            x += step\n\n        # Change the cost model and set the new cost.\n        self.pcost_model = PW_LINEAR\n        self.p_cost = p_cost", "label": 1}
{"code": "func (c *Client) UpsertTunnelConnection(conn services.TunnelConnection) error {\n\tdata, err := services.MarshalTunnelConnection(conn)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\targs := &upsertTunnelConnectionRawReq{\n\t\tTunnelConnection: data,\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"tunnelconnections\"), args)\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "public function getAttribute($attribute_name)\n    {\n        $params = [\n            ':name' => $attribute_name,\n            ':id' => $this->id,\n        ];\n\n        return $this->executor->execute(\n            DriverCommand::GET_ELEMENT_ATTRIBUTE,\n            $params\n        );\n    }", "label": 2}
{"code": "def read_map(fname):\n    \"\"\"\n    reads a saved text file to list\n    \"\"\"\n    lst = []\n    with open(fname, \"r\") as f:\n        for line in f:\n            lst.append(line)\n    return lst", "label": 1}
{"code": "def ck2respth(argv=None):\n    \"\"\"Command-line entry point for converting a ChemKED YAML file to a ReSpecTh XML file.\n    \"\"\"\n    parser = ArgumentParser(\n        description='Convert a ChemKED YAML file to a ReSpecTh XML file.'\n        )\n    parser.add_argument('-i', '--input',\n                        type=str,\n                        required=True,\n                        help='Input filename (e.g., \"file1.xml\")'\n                        )\n    parser.add_argument('-o', '--output',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='Output filename (e.g., \"file1.yaml\")'\n                        )\n\n    args = parser.parse_args(argv)\n\n    c = chemked.ChemKED(yaml_file=args.input)\n    c.convert_to_ReSpecTh(args.output)", "label": 1}
{"code": "public static base_responses delete(nitro_service client, String selectorname[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (selectorname != null && selectorname.length > 0) {\n\t\t\tcacheselector deleteresources[] = new cacheselector[selectorname.length];\n\t\t\tfor (int i=0;i<selectorname.length;i++){\n\t\t\t\tdeleteresources[i] = new cacheselector();\n\t\t\t\tdeleteresources[i].selectorname = selectorname[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected function serializeCriterion($criterion)\n    {\n        try {\n            serialize($criterion);\n\n            return $criterion;\n        } catch (Exception $e) {\n            // We want to take care of the closure serialization errors,\n            // other than that we will simply re-throw the exception.\n            if ($e->getMessage() !== \"Serialization of 'Closure' is not allowed\") {\n                throw $e;\n            }\n\n            $r = new ReflectionObject($criterion);\n\n            return [\n                'hash' => md5((string) $r),\n                'properties' => $r->getProperties(),\n            ];\n        }\n    }", "label": 2}
{"code": "public function setAuthenticationInfo($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Audit\\AuthenticationInfo::class);\n        $this->authentication_info = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function includeCSRFToken ({ method, csrf=true, headers }) {\n  if (!csrf || !CSRF_METHODS.includes(method)) return\n  const token = getTokenFromDocument(csrf)\n  if (!token) return\n  return {\n    headers: { ...headers, 'X-CSRF-Token': token }\n  }\n}", "label": 3}
{"code": "private function databaseIdFromName($name)\n    {\n        try {\n            $parsed = FirestoreGapicClient::parseName($name);\n        } catch (ValidationException $e) {\n            return null;\n        }\n\n        return isset($parsed['database'])\n            ? $parsed['database']\n            : null;\n    }", "label": 2}
{"code": "function setIfPresent(docEl, nodeName){\n\tvar node = getBaseElement(docEl, nodeName);\n\n\tif(node) {\n\t\tdocument[nodeName] = node;\n\t}\n}", "label": 3}
{"code": "private ArrayList handleDependentCollections(Identity oid, Object obj,\r\n            Object[] origCollections, Object[] newCollections,\r\n            Object[] newCollectionsOfObjects)\r\n            throws LockingException\r\n    {\r\n        ClassDescriptor mif = _pb.getClassDescriptor(obj.getClass());\r\n        Collection colDescs = mif.getCollectionDescriptors();\r\n        ArrayList newObjects = new ArrayList();\r\n        int count = 0;\r\n\r\n        for (Iterator it = colDescs.iterator(); it.hasNext(); count++)\r\n        {\r\n            CollectionDescriptor cds = (CollectionDescriptor) it.next();\r\n\r\n            if (cds.getOtmDependent())\r\n            {\r\n                ArrayList origList = (origCollections == null ? null\r\n                                        : (ArrayList) origCollections[count]);\r\n                ArrayList newList = (ArrayList) newCollections[count];\r\n\r\n                if (origList != null)\r\n                {\r\n                    for (Iterator it2 = origList.iterator(); it2.hasNext(); )\r\n                    {\r\n                        Identity origOid = (Identity) it2.next();\r\n\r\n                        if ((newList == null) || !newList.contains(origOid))\r\n                        {\r\n                            markDelete(origOid, oid, true);\r\n                        }\r\n                    }\r\n                }\r\n\r\n                if (newList != null)\r\n                {\r\n                    int countElem = 0;\r\n                    for (Iterator it2 = newList.iterator(); it2.hasNext(); countElem++)\r\n                    {\r\n                        Identity newOid = (Identity) it2.next();\r\n\r\n                        if ((origList == null) || !origList.contains(newOid))\r\n                        {\r\n                            ContextEntry entry = (ContextEntry) _objects.get(newOid);\r\n\r\n                            if (entry == null)\r\n                            {\r\n                                ArrayList relCol = (ArrayList)\r\n                                        newCollectionsOfObjects[count];\r\n                                Object relObj = relCol.get(countElem);\r\n                                insertInternal(newOid, relObj, LockType.WRITE_LOCK,\r\n                                               true, null, new Stack());\r\n                                newObjects.add(newOid);\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        return newObjects;\r\n    }", "label": 0}
{"code": "func (t *Torrent) newMetaInfo() metainfo.MetaInfo {\n\treturn metainfo.MetaInfo{\n\t\tCreationDate: time.Now().Unix(),\n\t\tComment:      \"dynamic metainfo from client\",\n\t\tCreatedBy:    \"go.torrent\",\n\t\tAnnounceList: t.metainfo.UpvertedAnnounceList(),\n\t\tInfoBytes: func() []byte {\n\t\t\tif t.haveInfo() {\n\t\t\t\treturn t.metadataBytes\n\t\t\t} else {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}(),\n\t}\n}", "label": 5}
{"code": "function (options, iterationInfo) {\n        var files;\n        var modules = {};\n        var result = {};\n\n        // remember the starting directory\n        try {\n            files = fs.readdirSync(iterationInfo.dirName);\n        } catch (e) {\n            if (options.optional)\n                return {};\n            else\n                throw new Error('Directory not found: ' + iterationInfo.dirName);\n        }\n\n        // iterate through files in the current directory\n        files.forEach(function (fileName) {\n            iterationInfo.dirName = iterationInfo.initialDirName + '/' + fileName + '/' + options.moduleDir;\n            iterationInfo.projectDir = iterationInfo.initialDirName + '/' + fileName;\n            result = _.assign(doInterations(options, iterationInfo), result);\n        });\n\n        return result;\n    }", "label": 3}
{"code": "private function assoc_array_to_rows( $fields ) {\n\t\t$rows = array();\n\n\t\tforeach ( $fields as $field => $value ) {\n\n\t\t\tif ( ! is_string( $value ) ) {\n\t\t\t\t$value = json_encode( $value );\n\t\t\t}\n\n\t\t\t$rows[] = (object) array(\n\t\t\t\t'Field' => $field,\n\t\t\t\t'Value' => $value,\n\t\t\t);\n\t\t}\n\n\t\treturn $rows;\n\t}", "label": 2}
{"code": "func (cn *connection) bestPeerNumPieces() pieceIndex {\n\tif cn.t.haveInfo() {\n\t\treturn cn.t.numPieces()\n\t}\n\treturn cn.peerMinPieces\n}", "label": 5}
{"code": "def stop(self):\n        \"\"\"\n        Stops the ``Pipers`` according to pipeline topology.\n        \n        \"\"\"\n        self.log.debug('%s begins stopping routine' % repr(self))\n        self.log.debug('%s triggers stopping in input pipers' % repr(self))\n        inputs = self.get_inputs()\n        for piper in inputs:\n            piper.stop(forced=True)\n        self.log.debug('%s pulls output pipers until stop' % repr(self))\n        outputs = self.get_outputs()\n        while outputs:\n            for piper in outputs:\n                try:\n                    # for i in xrange(stride)?\n                    piper.next()\n                except StopIteration:\n                    outputs.remove(piper)\n                    self.log.debug(\"%s stopped output piper: %s\" % \\\n                                   (repr(self), repr(piper)))\n                    continue\n                except Exception, excp:\n                    self.log.debug(\"%s %s raised an exception: %s\" % \\\n                                   (repr(self), piper, excp))\n        self.log.debug(\"%s stops the remaining pipers\" % repr(self))\n        postorder = self.postorder()\n        for piper in postorder:\n            if piper not in inputs:\n                piper.stop(ends=[0])\n        self.log.debug(\"%s finishes stopping of input pipers\" % repr(self))\n        for piper in inputs:\n            if hasattr(piper.imap, 'stop'):\n                piper.imap.stop(ends=[0])\n        self.log.debug('%s finishes stopping routine' % repr(self))", "label": 1}
{"code": "def append(self, value):\n        \"\"\"\n        Append a value to the stats list\n\n        Parameters\n        ----------\n        value : float\n            The value to add\n        \"\"\"\n        self.count += 1\n\n        if self.count == 1:\n            self.old_m = self.new_m = value\n            self.old_s = 0\n        else:\n            self.new_m = self.old_m + (value - self.old_m) / self.count\n            self.new_s = self.old_s + (value - self.old_m) * (value - self.new_m)\n\n            self.old_m = self.new_m\n            self.old_s = self.new_s", "label": 1}
{"code": "public Headers toHeaders() {\n        Headers headers = new Headers();\n        if (!getMatch().isEmpty()) {\n            headers = headers.add(new Header(HeaderConstants.IF_MATCH, buildTagHeaderValue(getMatch())));\n        }\n        if (!getNoneMatch().isEmpty()) {\n            headers = headers.add(new Header(HeaderConstants.IF_NONE_MATCH, buildTagHeaderValue(getNoneMatch())));\n        }\n        if (modifiedSince.isPresent()) {\n            headers = headers.set(HeaderUtils.toHttpDate(HeaderConstants.IF_MODIFIED_SINCE, modifiedSince.get()));\n        }\n        if (unModifiedSince.isPresent()) {\n            headers = headers.set(HeaderUtils.toHttpDate(HeaderConstants.IF_UNMODIFIED_SINCE, unModifiedSince.get()));\n        }\n\n        return headers;\n    }", "label": 0}
{"code": "def unregister(self, recipe):\n        \"\"\"\n        Unregisters an existing recipe, so that this recipe is no longer available.\n\n        This function is mainly used during plugin deactivation.\n\n        :param recipe: Name of the recipe\n        \"\"\"\n        if recipe not in self.recipes.keys():\n            self.__log.warning(\"Can not unregister recipe %s\" % recipe)\n        else:\n            del (self.recipes[recipe])\n            self.__log.debug(\"Recipe %s got unregistered\" % recipe)", "label": 1}
{"code": "def watched(*args)\n      arguments(args)\n      params = arguments.params\n\n      response = if (user_name = params.delete('user'))\n        get_request(\"/users/#{user_name}/subscriptions\", params)\n      else\n        get_request('/user/subscriptions', params)\n      end\n      return response unless block_given?\n      response.each { |el| yield el }\n    end", "label": 4}
{"code": "function getModelProperty(model) {\n    const className = model.constructor.name;\n    const propsForModel = getProperties(model);\n    return (prop) => {\n        return propsForModel.find(value => {\n            return value.property === prop;\n        });\n    };\n}", "label": 3}
{"code": "function _gpfSerialPropertyCheck (property) {\n    var clonedProperty = Object.assign(property);\n    [\n        _gpfSerialPropertyCheckName,\n        _gpfSerialPropertyCheckType,\n        _gpfSerialPropertyCheckRequired,\n        _gpfSerialPropertyCheckReadOnly\n    ].forEach(function (checkFunction) {\n        checkFunction(clonedProperty);\n    });\n    return clonedProperty;\n}", "label": 3}
{"code": "def _l_cv_and_skew(self, catchment):\n        \"\"\"\n        Calculate L-CV and L-SKEW for a gauged catchment. Uses `lmoments3` library.\n\n        Methodology source: Science Report SC050050, para. 6.7.5\n        \"\"\"\n        z = self._dimensionless_flows(catchment)\n        l1, l2, t3 = lm.lmom_ratios(z, nmom=3)\n        return l2 / l1, t3", "label": 1}
{"code": "func (s *CA) UpsertCertAuthority(ca services.CertAuthority) error {\n\tif err := ca.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tvalue, err := services.GetCertAuthorityMarshaler().MarshalCertAuthority(ca)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\titem := backend.Item{\n\t\tKey:     backend.Key(authoritiesPrefix, string(ca.GetType()), ca.GetName()),\n\t\tValue:   value,\n\t\tExpires: ca.Expiry(),\n\t\tID:      ca.GetResourceID(),\n\t}\n\n\t_, err = s.Put(context.TODO(), item)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def delete filename\n      detach filename\n      result = false\n      mutex.synchronize do\n        result = workspace.remove(filename)\n        @synchronized = !result if synchronized?\n      end\n      result\n    end", "label": 4}
{"code": "def write_file_content(path, data)\n      ::File.open(::File.join(path), \"wb\") do |f|\n        data.each do |item|\n          f.write(\"[#{item[:header]}]\\n\")\n          f.write(\"#{item[:content]}\\n\")\n        end\n      end\n    end", "label": 4}
{"code": "def generate_barcodes(nIds, codeLen=12):\n    \"\"\"\n    Given a list of sample IDs generate unique n-base barcodes for each.\n    Note that only 4^n unique barcodes are possible.\n    \"\"\"\n    def next_code(b, c, i):\n        return c[:i] + b + (c[i+1:] if i < -1 else '')\n\n    def rand_base():\n        return random.choice(['A', 'T', 'C', 'G'])\n\n    def rand_seq(n):\n        return ''.join([rand_base() for _ in range(n)])\n\n    # homopolymer filter regex: match if 4 identical bases in a row\n    hpf = re.compile('aaaa|cccc|gggg|tttt', re.IGNORECASE)\n\n    while True:\n        codes = [rand_seq(codeLen)]\n        if (hpf.search(codes[0]) is None):\n            break\n    idx = 0\n\n    while len(codes) < nIds:\n        idx -= 1\n        if idx < -codeLen:\n            idx = -1\n            codes.append(rand_seq(codeLen))\n        else:\n            nc = next_code(rand_base(), codes[-1], idx)\n            if hpf.search(nc) is None:\n                codes.append(nc)\n        codes = list(set(codes))\n\n    return codes", "label": 1}
{"code": "def shush_backtraces\n      Kernel.module_eval do\n        old_raise = Kernel.method(:raise)\n        remove_method :raise\n        define_method :raise do |*args|\n          begin\n            old_raise.call(*args)\n          ensure\n            if $!\n              lib = File.expand_path(\"..\", __FILE__)\n              $!.backtrace.reject! { |line| line.start_with?(lib) }\n            end\n          end\n        end\n        private :raise\n      end\n    end", "label": 4}
{"code": "private ClassDescriptor[] getMultiJoinedClassDescriptors(ClassDescriptor cld)\r\n    {\r\n        DescriptorRepository repository = cld.getRepository();\r\n        Class[] multiJoinedClasses = repository.getSubClassesMultipleJoinedTables(cld, true);\r\n        ClassDescriptor[] result = new ClassDescriptor[multiJoinedClasses.length];\r\n\r\n        for (int i = 0 ; i < multiJoinedClasses.length; i++)\r\n        {\r\n            result[i] = repository.getDescriptorFor(multiJoinedClasses[i]);\r\n         }\r\n\r\n        return result;\r\n    }", "label": 0}
{"code": "public static base_response flush(nitro_service client, cachecontentgroup resource) throws Exception {\n\t\tcachecontentgroup flushresource = new cachecontentgroup();\n\t\tflushresource.name = resource.name;\n\t\tflushresource.query = resource.query;\n\t\tflushresource.host = resource.host;\n\t\tflushresource.selectorvalue = resource.selectorvalue;\n\t\tflushresource.force = resource.force;\n\t\treturn flushresource.perform_operation(client,\"flush\");\n\t}", "label": 0}
{"code": "def match(tokens, definitions)\n      token_index = 0\n      @pattern.each do |elements|\n        was_optional = false\n        elements = [elements] unless elements.is_a?(Array)\n\n        elements.each_index do |i|\n          name = elements[i].to_s\n          optional = name[-1, 1] == '?'\n          name = name.chop if optional\n\n          case elements[i]\n          when Symbol\n            if tags_match?(name, tokens, token_index)\n              token_index += 1\n              break\n            else\n              if optional\n                was_optional = true\n                next\n              elsif i + 1 < elements.count\n                next\n              else\n                return false unless was_optional\n              end\n            end\n\n          when String\n            return true if optional && token_index == tokens.size\n\n            if definitions.key?(name.to_sym)\n              sub_handlers = definitions[name.to_sym]\n            else\n              raise \"Invalid subset #{name} specified\"\n            end\n\n            sub_handlers.each do |sub_handler|\n              return true if sub_handler.match(tokens[token_index..tokens.size], definitions)\n            end\n          else\n            raise \"Invalid match type: #{elements[i].class}\"\n          end\n        end\n\n      end\n\n      return false if token_index != tokens.size\n      return true\n    end", "label": 4}
{"code": "public function setReferenceImage($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\ReferenceImage::class);\n        $this->reference_image = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private static boolean containsGreekLetter(String s) {\r\n    Matcher m = biogreek.matcher(s);\r\n    return m.find();\r\n  }", "label": 0}
{"code": "function abstractBetweennessCentrality(assign, graph, options) {\n  if (!isGraph(graph))\n    throw new Error('graphology-centrality/beetweenness-centrality: the given graph is not a valid graphology instance.');\n\n  var centralities = {};\n\n  // Solving options\n  options = defaults({}, options, DEFAULTS);\n\n  var weightAttribute = options.attributes.weight,\n      centralityAttribute = options.attributes.centrality,\n      normalized = options.normalized,\n      weighted = options.weighted;\n\n  var shortestPath = weighted ?\n    dijkstraShotestPath.brandes :\n    unweightedShortestPath.brandes;\n\n  var nodes = graph.nodes(),\n      node,\n      result,\n      S,\n      P,\n      sigma,\n      delta,\n      coefficient,\n      i,\n      j,\n      l,\n      m,\n      v,\n      w;\n\n  // Initializing centralities\n  for (i = 0, l = nodes.length; i < l; i++)\n    centralities[nodes[i]] = 0;\n\n  // Iterating over each node\n  for (i = 0, l = nodes.length; i < l; i++) {\n    node = nodes[i];\n\n    result = shortestPath(graph, node, weightAttribute);\n\n    S = result[0];\n    P = result[1];\n    sigma = result[2];\n\n    delta = {};\n\n    // Accumulating\n    for (j = 0, m = S.length; j < m; j++)\n      delta[S[j]] = 0;\n\n    while (S.length) {\n      w = S.pop();\n      coefficient = (1 + delta[w]) / sigma[w];\n\n      for (j = 0, m = P[w].length; j < m; j++) {\n        v = P[w][j];\n        delta[v] += sigma[v] * coefficient;\n      }\n\n      if (w !== node)\n        centralities[w] += delta[w];\n    }\n  }\n\n  // Rescaling\n  var n = graph.order,\n      scale = null;\n\n  if (normalized)\n    scale = n <= 2 ? null : (1 / ((n - 1) * (n - 2)));\n  else\n    scale = graph.type === 'undirected' ? 0.5 : null;\n\n  if (scale !== null) {\n    for (node in centralities)\n      centralities[node] *= scale;\n  }\n\n  if (assign) {\n    for (node in centralities)\n      graph.setNodeAttribute(node, centralityAttribute, centralities[node]);\n  }\n\n  return centralities;\n}", "label": 3}
{"code": "def all_paths\n      results = []\n      paths = routes.map(&:path)\n      paths.each do |p|\n        sub_paths = []\n        parts = p.split('/')\n        until parts.empty?\n          parts.pop\n          sub_path = parts.join('/')\n          sub_paths << sub_path unless sub_path == ''\n        end\n        results += sub_paths\n      end\n      @all_paths = (results + paths).sort.uniq\n    end", "label": 4}
{"code": "public function map(array $attributes)\n    {\n        foreach ($attributes as $key => $value) {\n            $this->{$key} = $value;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function svgs(req, res) {\n  const bundle = new Bundle(\n    req.url.slice(1, -5).split('-').map(function map(name) {\n      return assets[name];\n    })\n  );\n\n  bundle.run(function (err, output) {\n    if (err) throw err;\n\n    res.setHeader('Content-Length', Buffer(output).length);\n    res.writeHead(200, { 'Content-Type': 'text/plain' });\n\n    res.end(output);\n  });\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, route6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\troute6 addresources[] = new route6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new route6();\n\t\t\t\taddresources[i].network = resources[i].network;\n\t\t\t\taddresources[i].gateway = resources[i].gateway;\n\t\t\t\taddresources[i].vlan = resources[i].vlan;\n\t\t\t\taddresources[i].weight = resources[i].weight;\n\t\t\t\taddresources[i].distance = resources[i].distance;\n\t\t\t\taddresources[i].cost = resources[i].cost;\n\t\t\t\taddresources[i].advertise = resources[i].advertise;\n\t\t\t\taddresources[i].msr = resources[i].msr;\n\t\t\t\taddresources[i].monitor = resources[i].monitor;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def fetch_order(self, order_id: str) -> Order:\n        \"\"\"Fetch an order by ID.\"\"\"\n        return self._fetch(f'order id={order_id}', exc=OrderNotFound)(self._order)(order_id)", "label": 1}
{"code": "public function setTransaction($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\V1\\Transaction::class);\n        $this->transaction = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def change_token(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Change a user's token.\n\n        :param id: User ID as an int.\n        :return: :class:`users.User <users.User>` object\n        :rtype: users.User\n        \"\"\"\n        schema = UserSchema(exclude=('password', 'password_confirm'))\n        resp = self.service.post(self.base+str(id)+'/token/')\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function removeTypesFromUnionOrIntersection(type, typesToRemove) {\n            var reducedTypes = [];\n            for (var _i = 0, _a = type.types; _i < _a.length; _i++) {\n                var t = _a[_i];\n                if (!typeIdenticalToSomeType(t, typesToRemove)) {\n                    reducedTypes.push(t);\n                }\n            }\n            return type.flags & 524288 /* Union */ ? getUnionType(reducedTypes) : getIntersectionType(reducedTypes);\n        }", "label": 3}
{"code": "def statistic_record(self, desc=True, timeout=3, is_async=False, only_read=True, *keys):\n        \"\"\"\n        Returns a list that each element is a dictionary of the statistic info of the cache item.\n        \"\"\"\n        if len(keys) == 0:\n            records = self._generate_statistic_records()\n        else:\n            records = self._generate_statistic_records_by_keys(keys)\n        return sorted(records, key=lambda t: t['hit_counts'], reverse=desc)", "label": 1}
{"code": "function (cb) {\n    // check if we have a custom index file set\n    if (settings.index) {\n      // generate the real index file path\n      var indexFile = process.cwd() + '/' + settings.index;\n\n      // check if the file exists, throw an error otherwise\n      if (!grunt.file.exists(indexFile)) {\n        grunt.log.error('Index file: \"' + indexFile + '\" not found');\n        cb('Index file: \"' + indexFile + '\" not found');\n        return;\n      }\n\n      // load the file contents\n      sourceFile = grunt.file.read(indexFile);\n    }\n\n    // modify the sourcefile css according to the settings\n    var css = settings.css.map(function (file) {   \n      if (settings.snapshot && file.search('http://') !== -1) {\n        return '<link rel=\"stylesheet\" type=\"text/css\" href=\"' + path.basename(file) + '\"/>';\n      } else {\n        return '<link rel=\"stylesheet\" type=\"text/css\" href=\"' + file + '\"/>';\n      }\n    });\n    sourceFile = sourceFile.replace('{{css}}', css.join(''));\n\n    // spit out the default sourcefile\n    cb(sourceFile);\n  }", "label": 3}
{"code": "def max_insertion(seqs, gene, domain):\n    \"\"\"\n    length of largest insertion\n    \"\"\"\n    seqs = [i[2] for i in list(seqs.values()) if i[2] != [] and i[0] == gene and i[1] == domain]\n    lengths = []\n    for seq in seqs:\n        for ins in seq:\n            lengths.append(int(ins[2]))\n    if lengths == []:\n        return 100 \n    return max(lengths)", "label": 1}
{"code": "def insert(index, *args)\n      args.each { |image| is_an_image image }\n      current = get_current\n      @images.insert(index, *args)\n      set_current current\n      self\n    end", "label": 4}
{"code": "def mount_tune(path, data = {})\n      json = client.post(\"/v1/sys/mounts/#{encode_path(path)}/tune\", JSON.fast_generate(data))\n      return true\n    end", "label": 4}
{"code": "function (ip_port, onDone) {\n\n\tif (l_appConnector === undefined) {\n\t\tLOG.warn('appConnector not init, cannot connect');\n\t\treturn;\n\t}\n\t\n\t// retrieve from previous connect attempt, also store for later connect attempt\n\t// TODO: will need to change when lobby port becomes not fixed\n\tip_port = ip_port || l_ip_port;\n\tl_ip_port = ip_port;\n\t\n\t// store callback to be called later\n\t// TODO: better approach?\n\tl_onDone = onDone || l_onDone;\n\t\n\tl_appConnector.connect(ip_port, function (err, socket) {\n\t\tif (err) {\n\t\t\tLOG.error('connection to manager: ' + ip_port.IP + ':' + ip_port.port + ' fail, try again in ' + l_timeoutReconnect + ' ms');\n\t\t\t\n\t\t\t// TODO: do not keep trying, but rather try to re-connect after being notified by monitor server\n\t\t\tsetTimeout(l_connect, l_timeoutReconnect);\n\t\t}\n\t\t// connection is successful\n\t\telse {\n\t\t\tLOG.warn('connection to manager: ' + ip_port.IP + ':' + ip_port.port + ' established');\n\t\t\tl_register();\n\t\t}\n\t});\n}", "label": 3}
{"code": "func (ep *endpoint) enableService() {\n\tep.Lock()\n\tdefer ep.Unlock()\n\tep.serviceEnabled = true\n}", "label": 5}
{"code": "def get_sources(arxiv_id):\n    \"\"\"\n    Download sources on arXiv for a given preprint.\n\n    .. note::\n\n        Bulk download of sources from arXiv is not permitted by their API. \\\n                You should have a look at http://arxiv.org/help/bulk_data_s3.\n\n    :param eprint: The arXiv id (e.g. ``1401.2910`` or ``1401.2910v1``) in a \\\n            canonical form.\n    :returns: A ``TarFile`` object of the sources of the arXiv preprint or \\\n            ``None``.\n    \"\"\"\n    try:\n        request = requests.get(ARXIV_EPRINT_URL.format(arxiv_id=arxiv_id))\n        request.raise_for_status()\n        file_object = io.BytesIO(request.content)\n        return tarfile.open(fileobj=file_object)\n    except (RequestException, AssertionError, tarfile.TarError):\n        return None", "label": 1}
{"code": "public function get( $args, $assoc_args ) {\n\t\tlist( $alias ) = $args;\n\n\t\t$aliases = WP_CLI::get_runner()->aliases;\n\n\t\tif ( empty( $aliases[ $alias ] ) ) {\n\t\t\tWP_CLI::error( \"No alias found with key '{$alias}'.\" );\n\t\t}\n\n\t\tforeach ( $aliases[ $alias ] as $key => $value ) {\n\t\t\tWP_CLI::log( \"{$key}: {$value}\" );\n\t\t}\n\t}", "label": 2}
{"code": "func getStage1Entrypoint(cdir string, entrypoint string) (string, error) {\n\tb, err := ioutil.ReadFile(common.Stage1ManifestPath(cdir))\n\tif err != nil {\n\t\treturn \"\", errwrap.Wrap(errors.New(\"error reading pod manifest\"), err)\n\t}\n\n\ts1m := schema.ImageManifest{}\n\tif err := json.Unmarshal(b, &s1m); err != nil {\n\t\treturn \"\", errwrap.Wrap(errors.New(\"error unmarshaling stage1 manifest\"), err)\n\t}\n\n\tif ep, ok := s1m.Annotations.Get(entrypoint); ok {\n\t\treturn ep, nil\n\t}\n\n\treturn \"\", fmt.Errorf(\"entrypoint %q not found\", entrypoint)\n}", "label": 5}
{"code": "async function validateDirPathForCLI (dirPath) {\n  try {\n    await validateDirPath(dirPath);\n  } catch (error) {\n    if (!error.userError) throw error;\n    if (error.details[0].startsWith('Source path must be a directory')) {\n      const args = process.argv.reduce((acc, o, idx) => {\n        // Discard the first 2 arguments.\n        if (idx < 1) return acc;\n        if (o === dirPath) return acc.concat(path.dirname(dirPath));\n        return acc.concat(o);\n      }, []);\n\n      throw userError([\n        'Source path must be a directory. Try running with the following instead:',\n        '',\n        `  node ${args.join(' ')}`,\n        ''\n      ]);\n    }\n    throw error;\n  }\n}", "label": 3}
{"code": "func CreateCertificate(principal string, certType uint32) (*ssh.Certificate, ssh.Signer, error) {\n\t// Create RSA key for CA and certificate to be signed by CA.\n\tcaKey, err := rsa.GenerateKey(rand.Reader, teleport.RSAKeySize)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\tkey, err := rsa.GenerateKey(rand.Reader, teleport.RSAKeySize)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\tcert, certSigner, err := createCertificate(principal, certType, caKey, key)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\treturn cert, certSigner, nil\n}", "label": 5}
{"code": "public function reload(array $options = [])\n    {\n        $res = $this->connection->get([\n            'name' => $this->name,\n        ] + $options);\n\n        $this->result = null;\n        $this->error = null;\n        if (isset($res['done']) && $res['done']) {\n            $type = $res['metadata']['typeUrl'];\n            $this->result = $this->executeDoneCallback($type, $res['response']);\n            $this->error = (isset($res['error']))\n                ? $res['error']\n                : null;\n        }\n\n        return $this->info = $res;\n    }", "label": 2}
{"code": "public function setGroupByFields($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->group_by_fields = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def validate_interval_lock(time, start_time)\n      t0 = starting_unit(start_time)\n      t1 = time.send(type)\n      t0 >= t1 ? t0 - t1 : INTERVALS[type] - t1 + t0\n    end", "label": 4}
{"code": "def shard_key_selector\n      selector = {}\n      shard_key_fields.each do |field|\n        selector[field.to_s] = new_record? ? send(field) : attribute_was(field)\n      end\n      selector\n    end", "label": 4}
{"code": "def view(x, y, width, height)\n      view = View.new(self, x, y, width, height)\n\n      return view unless block_given?\n\n      begin\n        yield(view)\n      ensure\n        view.sync\n      end\n      nil\n    end", "label": 4}
{"code": "public static base_response unset(nitro_service client, callhome resource, String[] args) throws Exception{\n\t\tcallhome unsetresource = new callhome();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "func (tc *TeleportClient) connectToProxy(ctx context.Context) (*ProxyClient, error) {\n\tvar err error\n\n\tproxyPrincipal := tc.getProxySSHPrincipal()\n\tsshConfig := &ssh.ClientConfig{\n\t\tUser:            proxyPrincipal,\n\t\tHostKeyCallback: tc.HostKeyCallback,\n\t}\n\n\t// helper to create a ProxyClient struct\n\tmakeProxyClient := func(sshClient *ssh.Client, m ssh.AuthMethod) *ProxyClient {\n\t\treturn &ProxyClient{\n\t\t\tteleportClient:  tc,\n\t\t\tClient:          sshClient,\n\t\t\tproxyAddress:    tc.Config.SSHProxyAddr,\n\t\t\tproxyPrincipal:  proxyPrincipal,\n\t\t\thostKeyCallback: sshConfig.HostKeyCallback,\n\t\t\tauthMethod:      m,\n\t\t\thostLogin:       tc.Config.HostLogin,\n\t\t\tsiteName:        tc.Config.SiteName,\n\t\t\tclientAddr:      tc.ClientAddr,\n\t\t}\n\t}\n\tsuccessMsg := fmt.Sprintf(\"Successful auth with proxy %v\", tc.Config.SSHProxyAddr)\n\t// try to authenticate using every non interactive auth method we have:\n\tfor i, m := range tc.authMethods() {\n\t\tlog.Infof(\"Connecting proxy=%v login='%v' method=%d\", tc.Config.SSHProxyAddr, sshConfig.User, i)\n\t\tvar sshClient *ssh.Client\n\n\t\tsshConfig.Auth = []ssh.AuthMethod{m}\n\t\tsshClient, err = ssh.Dial(\"tcp\", tc.Config.SSHProxyAddr, sshConfig)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tlog.Infof(successMsg)\n\t\treturn makeProxyClient(sshClient, m), nil\n\t}\n\t// we have exhausted all auth existing auth methods and local login\n\t// is disabled in configuration, or the user refused connecting to untrusted hosts\n\tif err == nil {\n\t\terr = trace.BadParameter(\"failed to authenticate with proxy %v\", tc.Config.SSHProxyAddr)\n\t}\n\treturn nil, trace.Wrap(err)\n}", "label": 5}
{"code": "public static base_response update(nitro_service client, sslocspresponder resource) throws Exception {\n\t\tsslocspresponder updateresource = new sslocspresponder();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.url = resource.url;\n\t\tupdateresource.cache = resource.cache;\n\t\tupdateresource.cachetimeout = resource.cachetimeout;\n\t\tupdateresource.batchingdepth = resource.batchingdepth;\n\t\tupdateresource.batchingdelay = resource.batchingdelay;\n\t\tupdateresource.resptimeout = resource.resptimeout;\n\t\tupdateresource.respondercert = resource.respondercert;\n\t\tupdateresource.trustresponder = resource.trustresponder;\n\t\tupdateresource.producedattimeskew = resource.producedattimeskew;\n\t\tupdateresource.signingcert = resource.signingcert;\n\t\tupdateresource.usenonce = resource.usenonce;\n\t\tupdateresource.insertclientcert = resource.insertclientcert;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "function runPrompts (opts) {\n  if (opts.questionnaire && this.init.configure) {\n    this.sprout.emit('msg', 'running questionnaire function')\n    const unansweredConfig = lodash.filter(this.init.configure, (q) => {\n      return !lodash.includes(lodash.keys(this.config), q.name)\n    })\n    return opts.questionnaire(unansweredConfig)\n      .then((answers) => { return lodash.assign(this.config, answers) })\n  }\n}", "label": 3}
{"code": "function getChangelog(log) {\n      var data = {\n        date: moment().format('YYYY-MM-DD'),\n        features: getChanges(log, options.featureRegex),\n        fixes: getChanges(log, options.fixRegex)\n      };\n\n      return template(data);\n    }", "label": 3}
{"code": "def find(path, id, params = {})\n      response = get(\"/#{path.to_s.pluralize}/#{id}\", params)\n      trello_class = class_from_path(path)\n      trello_class.parse response do |data|\n        data.client = self\n      end\n    end", "label": 4}
{"code": "func (s *Server) Wait(ctx context.Context) {\n\tselect {\n\tcase <-s.closeContext.Done():\n\tcase <-ctx.Done():\n\t}\n}", "label": 5}
{"code": "function _onKeyDown(e) {\n  var keyCode = e.keyCode;\n\n  if (keyCode === 13 || keyCode === 32) {\n    this.keyDownFlag = true; // if host element does not naturally trigger a click event on spacebar, we can force one to trigger here.\n    // careful! if host already triggers click events naturally, we end up with a \"double-click\".\n\n    if (keyCode === 32 && this.options.simulateSpacebarClick === true) {\n      this.hostEl.click();\n    }\n  }\n}", "label": 3}
{"code": "function (size) {\n\n\tsize = size || 1;\n\tLOG.warn('trying to assign ' + size + ' new ports...', 'SR.Monitor');\n\t\n\t// find first available port\n\tvar port = SR.Settings.PORT_APP_RANGE_START;\n\tvar last_port = SR.Settings.PORT_APP_RANGE_END;\n\n\t// first port found\n\tvar first_port = undefined;\n\tvar results = [];\n\t\n\twhile (port <= last_port) {\n\t\t\n\t\tif (l_ports.hasOwnProperty(port) === false || l_ports[port] === null) {\n\t\t\t// found a unique port\n\t\t\tif (!first_port)\n\t\t\t\tfirst_port = port;\n\t\t\t\n\t\t\t// mark the port as assigned\n\t\t\tl_ports[port] = first_port;\n\t\t\tresults.push(port);\n\t\t\t\n\t\t\tLOG.warn('assigning port: ' + port, 'SR.Monitor');\t\n\t\t\t\n\t\t\tif (--size === 0)\n\t\t\t\tbreak;\n\t\t}\n\t\tport++;\n\t}\n\n\t// no available ports found, or not enough ports found\n\tif (port > last_port)\n\t\treturn 0;\n\t\n\tif (results.length > 1)\n\t\treturn results;\n\telse\n\t\treturn results[0];\n}", "label": 3}
{"code": "def remove_prefix(self, prefix):\n        \"\"\"Removes prefix from this set.  This is a no-op if the prefix\n        doesn't exist in it.\n        \"\"\"\n        if prefix not in self.__prefix_map:\n            return\n\n        ni = self.__lookup_prefix(prefix)\n        ni.prefixes.discard(prefix)\n        del self.__prefix_map[prefix]\n\n        # If we removed the preferred prefix, find a new one.\n        if ni.preferred_prefix == prefix:\n            ni.preferred_prefix = next(iter(ni.prefixes), None)", "label": 1}
{"code": "def choose!(context = nil)\n      @user.cleanup_old_experiments!\n      # Only run the process once\n      return alternative if @alternative_choosen\n\n      if override_is_alternative?\n        self.alternative = @options[:override]\n        if should_store_alternative? && !@user[@experiment.key]\n          self.alternative.increment_participation\n        end\n      elsif @options[:disabled] || Split.configuration.disabled?\n        self.alternative = @experiment.control\n      elsif @experiment.has_winner?\n        self.alternative = @experiment.winner\n      else\n        cleanup_old_versions\n\n        if exclude_user?\n          self.alternative = @experiment.control\n        else\n          self.alternative = @user[@experiment.key]\n          if alternative.nil?\n            self.alternative = @experiment.next_alternative\n\n            # Increment the number of participants since we are actually choosing a new alternative\n            self.alternative.increment_participation\n\n            run_callback context, Split.configuration.on_trial_choose\n          end\n        end\n      end\n\n      @user[@experiment.key] = alternative.name if !@experiment.has_winner? && should_store_alternative?\n      @alternative_choosen = true\n      run_callback context, Split.configuration.on_trial unless @options[:disabled] || Split.configuration.disabled?\n      alternative\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, nspbr6 resource) throws Exception {\n\t\tnspbr6 updateresource = new nspbr6();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.action = resource.action;\n\t\tupdateresource.srcipv6 = resource.srcipv6;\n\t\tupdateresource.srcipop = resource.srcipop;\n\t\tupdateresource.srcipv6val = resource.srcipv6val;\n\t\tupdateresource.srcport = resource.srcport;\n\t\tupdateresource.srcportop = resource.srcportop;\n\t\tupdateresource.srcportval = resource.srcportval;\n\t\tupdateresource.destipv6 = resource.destipv6;\n\t\tupdateresource.destipop = resource.destipop;\n\t\tupdateresource.destipv6val = resource.destipv6val;\n\t\tupdateresource.destport = resource.destport;\n\t\tupdateresource.destportop = resource.destportop;\n\t\tupdateresource.destportval = resource.destportval;\n\t\tupdateresource.srcmac = resource.srcmac;\n\t\tupdateresource.protocol = resource.protocol;\n\t\tupdateresource.protocolnumber = resource.protocolnumber;\n\t\tupdateresource.vlan = resource.vlan;\n\t\tupdateresource.Interface = resource.Interface;\n\t\tupdateresource.priority = resource.priority;\n\t\tupdateresource.msr = resource.msr;\n\t\tupdateresource.monitor = resource.monitor;\n\t\tupdateresource.nexthop = resource.nexthop;\n\t\tupdateresource.nexthopval = resource.nexthopval;\n\t\tupdateresource.nexthopvlan = resource.nexthopvlan;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def vim():\n    '''Customize vim, install package manager pathogen and some vim-packages.\n\n    pathogen will be installed as a git repo at ~/repos/vim-pathogen and\n    activated in vim by a symbolic link at ~/.vim/autoload/pathogen.vim\n\n    A ~/.vimrc will be installed which loads the package manager within of vim.\n\n    The vim packages vim-colors-solarized, nerdtree, and tagbar are installed\n    as git repos placed at dir ~/.vim/bundle/\n\n    If you want to install more vim packages also place them at this dir, cf.\n    https://logicalfriday.com/2011/07/18/using-vim-with-pathogen/\n    '''\n    install_package('vim')\n\n    print_msg('## install ~/.vimrc\\n')\n    install_file_legacy('~/.vimrc')\n\n    print_msg('\\n## set up pathogen\\n')\n    run('mkdir -p  ~/.vim/autoload  ~/.vim/bundle')\n    checkup_git_repo_legacy(url='https://github.com/tpope/vim-pathogen.git')\n    run('ln -snf  ~/repos/vim-pathogen/autoload/pathogen.vim  '\n        '~/.vim/autoload/pathogen.vim')\n\n    print_msg('\\n## install vim packages\\n')\n    install_package('ctags')  # required by package tagbar\n    repos = [\n        {\n            'name': 'vim-colors-solarized',\n            'url': 'git://github.com/altercation/vim-colors-solarized.git',\n        },\n        {\n            'name': 'nerdtree',\n            'url': 'https://github.com/scrooloose/nerdtree.git',\n        },\n        {\n            'name': 'vim-nerdtree-tabs',\n            'url': 'https://github.com/jistr/vim-nerdtree-tabs.git',\n        },\n        {\n            'name': 'tagbar',\n            'url': 'https://github.com/majutsushi/tagbar.git',\n        },\n    ]\n    checkup_git_repos_legacy(repos, base_dir='~/.vim/bundle')", "label": 1}
{"code": "def inline_content_is_string?(node)\n      tag_with_inline_content = tag_with_inline_text(node)\n      inline_content = inline_node_content(node)\n\n      index = tag_with_inline_content.rindex(inline_content) - 1\n\n      %w[' \"].include?(tag_with_inline_content[index])\n    end", "label": 4}
{"code": "def _vec_alpha(self, donor_catchments):\n        \"\"\"\n        Return vector alpha which is the weights for donor model errors\n\n        Methodology source: Kjeldsen, Jones & Morris 2014, eq 10\n\n        :param donor_catchments: Catchments to use as donors\n        :type donor_catchments: list of :class:`Catchment`\n        :return: Vector of donor weights\n        :rtype: :class:`numpy.ndarray`\n        \"\"\"\n        return np.dot(linalg.inv(self._matrix_omega(donor_catchments)), self._vec_b(donor_catchments))", "label": 1}
{"code": "function getPropertyOrder (properties) {\n  const primitiveProps = []\n  const complexProps = []\n\n  _.forIn(properties, (prop, propName) => {\n    if (prop.type === 'object' || prop.type === 'array') {\n      complexProps.push(propName)\n    } else {\n      primitiveProps.push(propName)\n    }\n  })\n\n  return primitiveProps.concat(complexProps)\n}", "label": 3}
{"code": "public function sendGetCipherKeysFromUser($numbers, $replaceKey = false)\n    {\n        if (!is_array($numbers)) {\n            $numbers = [$numbers];\n        }\n\n        $this->replaceKey = $replaceKey;\n        $msgId = $this->nodeId['cipherKeys'] = $this->createIqId();\n\n        $userNode = [];\n        foreach ($numbers as $number) {\n            $userNode[] = new ProtocolNode('user',\n              [\n                  'jid' => $this->getJID($number),\n              ], null, null);\n        }\n        $keyNode = new ProtocolNode('key', null, $userNode, null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'encrypt',\n                'type'  => 'get',\n                'to'    => Constants::WHATSAPP_SERVER,\n            ], [$keyNode], null);\n\n        $this->sendNode($node);\n        $this->waitForServer($msgId);\n    }", "label": 2}
{"code": "func (fs *FSLocalKeyStore) AddKey(host, username string, key *Key) error {\n\tdirPath, err := fs.dirFor(host, true)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\twriteBytes := func(fname string, data []byte) error {\n\t\tfp := filepath.Join(dirPath, fname)\n\t\terr := ioutil.WriteFile(fp, data, keyFilePerms)\n\t\tif err != nil {\n\t\t\tfs.log.Error(err)\n\t\t}\n\t\treturn err\n\t}\n\tif err = writeBytes(username+fileExtCert, key.Cert); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err = writeBytes(username+fileExtTLSCert, key.TLSCert); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err = writeBytes(username+fileExtPub, key.Pub); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err = writeBytes(username, key.Priv); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def version(self):\n        \"\"\"\n        Returns the node's RPC version\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.version()\n        {\n            \"rpc_version\": 1,\n            \"store_version\": 10,\n            \"node_vendor\": \"RaiBlocks 9.0\"\n        }\n\n        \"\"\"\n\n        resp = self.call('version')\n\n        for key in ('rpc_version', 'store_version'):\n            resp[key] = int(resp[key])\n\n        return resp", "label": 1}
{"code": "public static int getMemberDimension() throws XDocletException\r\n    {\r\n        if (getCurrentField() != null) {\r\n            return getCurrentField().getDimension();\r\n        }\r\n        else if (getCurrentMethod() != null) {\r\n            XMethod method = getCurrentMethod();\r\n\r\n            if (MethodTagsHandler.isGetterMethod(method)) {\r\n                return method.getReturnType().getDimension();\r\n            }\r\n            else if (MethodTagsHandler.isSetterMethod(method)) {\r\n                XParameter param = (XParameter)method.getParameters().iterator().next();\r\n\r\n                return param.getDimension();\r\n            }\r\n        }\r\n        return 0;\r\n    }", "label": 0}
{"code": "protected function getDisallowedOperations()\n    {\n        return array(\n            'SHUTDOWN' => true,\n            'INFO' => true,\n            'DBSIZE' => true,\n            'LASTSAVE' => true,\n            'CONFIG' => true,\n            'MONITOR' => true,\n            'SLAVEOF' => true,\n            'SAVE' => true,\n            'BGSAVE' => true,\n            'BGREWRITEAOF' => true,\n            'SLOWLOG' => true,\n        );\n    }", "label": 2}
{"code": "function (commandName, args, result, error) {\n    if (error) {\n      if ( error.type ) {\n        errorType = error.type\n      } else if ( error.toString().indexOf(\"Error: An element could not be located on the page using the given search parameters\") > -1 ) {\n        errorType = true\n      }\n\n      try {\n        const screenshot = browser.saveScreenshot() // returns base64 string buffer\n\n        const screenshotFolder = path.join(process.env.WDIO_WORKFLO_RUN_PATH, 'allure-results')\n        const screenshotFilename = `${screenshotFolder}/${global.screenshotId}.png`\n\n        global.errorScreenshotFilename = screenshotFilename\n\n        fs.writeFileSync(screenshotFilename, screenshot)\n      } catch (err) {\n        console.log(`Failed to take screenshot: ${err.message}`)\n        console.log(err.stack)\n      }\n    }\n\n    if (typeof workfloConf.afterCommand === 'function') {\n      return workfloConf.afterCommand(commandName, args, result, error)\n    }\n  }", "label": 3}
{"code": "func (p *PAM) Close() error {\n\t// Close the PAM session. Closing a session can entail anything from\n\t// unmounting a home directory and updating auth.log.\n\tp.retval = C._pam_close_session(pamHandle, p.pamh, 0)\n\tif p.retval != C.PAM_SUCCESS {\n\t\treturn p.codeToError(p.retval)\n\t}\n\n\t// Terminate the PAM transaction.\n\tretval := C._pam_end(pamHandle, p.pamh, p.retval)\n\tif retval != C.PAM_SUCCESS {\n\t\treturn p.codeToError(retval)\n\t}\n\n\t// Unregister handler index at the package level.\n\tunregisterHandler(p.handlerIndex)\n\n\t// Release the memory allocated for the conversation function.\n\tC.free(unsafe.Pointer(p.conv))\n\n\t// Release strings that were allocated when opening the PAM context.\n\tC.free(unsafe.Pointer(p.service_name))\n\tC.free(unsafe.Pointer(p.user))\n\n\treturn nil\n}", "label": 5}
{"code": "function readDirsParallel(dirs, cb) {\n  var funcs = [];\n  dirs.forEach(function(dir) {\n    funcs.push(readDirAbs.bind(null, dir));\n  });\n  async.parallel(funcs, function(err, results) {\n    if (err) {\n      return cb(err, null);\n    }\n    // Flatten results and return\n    var flat = [].concat.apply([], results);\n    cb(null, flat);\n  }\n  );\n}", "label": 3}
{"code": "def get_break_type(id, opts = {})\n      data, _status_code, _headers = get_break_type_with_http_info(id, opts)\n      return data\n    end", "label": 4}
{"code": "func (tc *TeleportClient) SendEvent(ctx context.Context, e events.EventFields) error {\n\t// Try and send the event to the eventsCh. If blocking, keep blocking until\n\t// the passed in context in canceled.\n\tselect {\n\tcase tc.eventsCh <- e:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\treturn trace.Wrap(ctx.Err())\n\t}\n}", "label": 5}
{"code": "def stream_timeout(stream, timeout, timeout_msg=None):\n    \"\"\"\n    Iterate over items in a streaming response from the Docker client within\n    a timeout.\n\n    :param ~docker.types.daemon.CancellableStream stream:\n        Stream from the Docker client to consume items from.\n    :param timeout:\n        Timeout value in seconds.\n    :param timeout_msg:\n        Message to raise in the exception when a timeout occurs.\n    \"\"\"\n    timed_out = threading.Event()\n\n    def timeout_func():\n        timed_out.set()\n        stream.close()\n\n    timer = threading.Timer(timeout, timeout_func)\n    try:\n        timer.start()\n        for item in stream:\n            yield item\n\n        # A timeout looks the same as the loop ending. So we need to check a\n        # flag to determine whether a timeout occurred or not.\n        if timed_out.is_set():\n            raise TimeoutError(timeout_msg)\n    finally:\n        timer.cancel()\n        # Close the stream's underlying response object (if it has one) to\n        # avoid potential socket leaks.\n        # This method seems to have more success at preventing ResourceWarnings\n        # than just stream.close() (should this be improved upstream?)\n        # FIXME: Potential race condition if Timer thread closes the stream at\n        # the same time we do here, but hopefully not with serious side effects\n        if hasattr(stream, '_response'):\n            stream._response.close()", "label": 1}
{"code": "function (req) {\n\tvar session = l_getSession(req);\n\tif (session.hasOwnProperty('_user')) {\n\t\tvar login = session._user;\n\t\tlogin.admin = (session._user.account === 'admin');\n\t\treturn login;\n\t}\n\t\n\tLOG.warn('user not yet logined...');\n\treturn {control: {groups: [], permissions: []}};\n}", "label": 3}
{"code": "func (process *TeleportProcess) newLocalCacheForProxy(clt auth.ClientI, cacheName []string) (auth.AccessPoint, error) {\n\treturn process.newLocalCache(clt, cache.ForProxy, cacheName)\n}", "label": 5}
{"code": "public function count()\n    {\n        return $this->collection->count() > $this->totalRecords ? $this->totalRecords : $this->collection->count();\n    }", "label": 2}
{"code": "public void executeDelete(ClassDescriptor cld, Object obj) throws PersistenceBrokerException\r\n    {\r\n        if (logger.isDebugEnabled())\r\n        {\r\n            logger.debug(\"executeDelete: \" + obj);\r\n        }\r\n\r\n        final StatementManagerIF sm = broker.serviceStatementManager();\r\n        PreparedStatement stmt = null;\r\n        try\r\n        {\r\n            stmt = sm.getDeleteStatement(cld);\r\n            if (stmt == null)\r\n            {\r\n                logger.error(\"getDeleteStatement returned a null statement\");\r\n                throw new PersistenceBrokerException(\"JdbcAccessImpl: getDeleteStatement returned a null statement\");\r\n            }\r\n\r\n            sm.bindDelete(stmt, cld, obj);\r\n            if (logger.isDebugEnabled())\r\n                logger.debug(\"executeDelete: \" + stmt);\r\n\r\n            // @todo: clearify semantics\r\n            // thma: the following check is not secure. The object could be deleted *or* changed.\r\n            // if it was deleted it makes no sense to throw an OL exception.\r\n            // does is make sense to throw an OL exception if the object was changed?\r\n            if (stmt.executeUpdate() == 0 && cld.isLocking()) //BRJ\r\n            {\r\n                /**\r\n                 * Kuali Foundation modification -- 6/19/2009\r\n                 */\r\n            \tString objToString = \"\";\r\n            \ttry {\r\n            \t\tobjToString = obj.toString();\r\n            \t} catch (Exception ex) {}\r\n                throw new OptimisticLockException(\"Object has been modified or deleted by someone else: \" + objToString, obj);\r\n                /**\r\n                 * End of Kuali Foundation modification\r\n                 */\r\n            }\r\n\r\n            // Harvest any return values.\r\n            harvestReturnValues(cld.getDeleteProcedure(), obj, stmt);\r\n        }\r\n        catch (OptimisticLockException e)\r\n        {\r\n            // Don't log as error\r\n            if (logger.isDebugEnabled())\r\n                logger.debug(\"OptimisticLockException during the execution of delete: \"\r\n                        + e.getMessage(), e);\r\n            throw e;\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            logger.error(\"PersistenceBrokerException during the execution of delete: \"\r\n                    + e.getMessage(), e);\r\n            throw e;\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            final String sql = broker.serviceSqlGenerator().getPreparedDeleteStatement(cld).getStatement();\r\n            throw ExceptionHelper.generateException(e, sql, cld, logger, obj);\r\n        }\r\n        finally\r\n        {\r\n            sm.closeResources(stmt, null);\r\n        }\r\n    }", "label": 0}
{"code": "def client_streamer(requests, metadata: {})\n      raise_error_if_already_executed\n      begin\n        send_initial_metadata(metadata)\n        requests.each { |r| @call.run_batch(SEND_MESSAGE => @marshal.call(r)) }\n      rescue GRPC::Core::CallError => e\n        receive_and_check_status # check for Cancelled\n        raise e\n      rescue => e\n        set_input_stream_done\n        raise e\n      ensure\n        set_output_stream_done\n      end\n\n      batch_result = @call.run_batch(\n        SEND_CLOSE_FROM_CLIENT => nil,\n        RECV_INITIAL_METADATA => nil,\n        RECV_MESSAGE => nil,\n        RECV_STATUS_ON_CLIENT => nil\n      )\n\n      set_input_stream_done\n\n      @call.metadata = batch_result.metadata\n      attach_status_results_and_complete_call(batch_result)\n      get_message_from_batch_result(batch_result)\n    end", "label": 4}
{"code": "def setup_default_values(hqmf_contents, use_default_measure_period)\n      @id_generator = IdGenerator.new\n      @doc = @entry = Document.parse(hqmf_contents)\n\n      @id = attr_val('cda:QualityMeasureDocument/cda:id/@extension') ||\n            attr_val('cda:QualityMeasureDocument/cda:id/@root').upcase\n      @hqmf_set_id = attr_val('cda:QualityMeasureDocument/cda:setId/@extension') ||\n                     attr_val('cda:QualityMeasureDocument/cda:setId/@root').upcase\n      @hqmf_version_number = attr_val('cda:QualityMeasureDocument/cda:versionNumber/@value')\n\n      # TODO: -- figure out if this is the correct thing to do -- probably not, but is\n      # necessary to get the bonnie comparison to work.  Currently\n      # defaulting measure period to a period of 1 year from 2012 to 2013 this is overriden during\n      # calculation with correct year information .  Need to investigate parsing mp from meaures.\n      @measure_period = extract_measure_period_or_default(use_default_measure_period)\n\n      # Extract measure attributes\n      # TODO: Review\n      @attributes = @doc.xpath('/cda:QualityMeasureDocument/cda:subjectOf/cda:measureAttribute', NAMESPACES)\n                    .collect do |attribute|\n        read_attribute(attribute)\n      end\n\n      @data_criteria = []\n      @source_data_criteria = []\n      @data_criteria_references = {}\n      @occurrences_map = {}\n\n      # Used to keep track of referenced data criteria ids\n      @reference_ids = []\n    end", "label": 4}
{"code": "public Object lookup(Identity oid)\r\n    {\r\n        Object ret = null;\r\n        if (oid != null)\r\n        {\r\n            ObjectCache cache = getCache(oid, null, METHOD_LOOKUP);\r\n            if (cache != null)\r\n            {\r\n                ret = cache.lookup(oid);\r\n            }\r\n        }\r\n        return ret;\r\n    }", "label": 0}
{"code": "function(args, callback) {\n    if (!config.i18n.spreadsheet_id) {\n      return callback('Missing config.i18n.spreadsheet_id');\n    }\n    const path = 'https://spreadsheets.google.com/feeds/list/' +\n                  config.i18n.spreadsheet_id +\n                  '/default/public/values?alt=json';\n\n    // request json data\n    request(path, (err, res, body) => {\n      if (err) {\n        return callback(err);\n      }\n      const json = JSON.parse(body);\n      //console.dir(json);\n      const translations = {};\n\n      // parse\n      json.feed.entry.forEach(entry => {\n        //\n        const key = _.get(entry, 'gsx$key.$t');\n        config.i18n.whitelist.forEach((lang) => {\n          const value = _.get(entry, 'gsx$' + lang + '.$t');\n          if (value) {\n            _.setWith(translations, lang + '.' + key, value, Object);\n          }\n        });\n\n      });\n\n      // write translation files\n      config.i18n.whitelist.forEach((lang) => {\n        const dir = `./locales/${lang}`;\n        if (!fs.existsSync(dir)) {\n          console.warn('Missing directory: ' + dir);\n          return;\n        }\n        translations[lang]._meta = {\n          generated_at: new Date(),\n          lang\n        };\n        const data = JSON.stringify(translations[lang], null, 2);\n        const filename = `${dir}/translation.json`;\n        console.log('Writing ' + filename);\n        fs.writeFileSync(filename, data );\n      });\n\n      callback();\n    });\n  }", "label": 3}
{"code": "private void cascadeMarkedForInsert()\r\n    {\r\n        // This list was used to avoid endless recursion on circular references\r\n        List alreadyPrepared = new ArrayList();\r\n        for(int i = 0; i < markedForInsertList.size(); i++)\r\n        {\r\n            ObjectEnvelope mod = (ObjectEnvelope) markedForInsertList.get(i);\r\n            // only if a new object was found we cascade to register the dependent objects\r\n            if(mod.needsInsert())\r\n            {\r\n                cascadeInsertFor(mod, alreadyPrepared);\r\n                alreadyPrepared.clear();\r\n            }\r\n        }\r\n        markedForInsertList.clear();\r\n    }", "label": 0}
{"code": "func (cs callSet) Add(call *Call) {\n\tkey := callSetKey{call.receiver, call.method}\n\tm := cs.expected\n\tif call.exhausted() {\n\t\tm = cs.exhausted\n\t}\n\tm[key] = append(m[key], call)\n}", "label": 5}
{"code": "def default_hash(env = ActiveRecord::ConnectionHandling::DEFAULT_ENV.call.to_s)\n      default = find_db_config(env)\n      default.config if default\n    end", "label": 4}
{"code": "function deploy(connections, dataSource, cb) {\n\n  async.waterfall([\n    function validateParams(cb) {\n      var dataSourceValidator = validate(dataSource);\n      //The data source parameter should have an ID property.\n      dataSourceValidator.has(CONSTANTS.DATA_SOURCE_ID, function(err) {\n        if (err) {\n          return cb(buildErrorResponse({error: new Error(\"An ID Parameter Is Required To Deploy A Data Source\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n        }\n\n        cb(undefined, dataSource);\n      });\n    },\n    function findDataSource(dataSource, cb) {\n      var query = {\n\n      };\n\n      //Searching By ID.\n      query[CONSTANTS.DATA_SOURCE_ID] = dataSource[CONSTANTS.DATA_SOURCE_ID];\n\n      //Looking up a full data source document as we are updating\n      lookUpDataSources(connections, {\n        query: query,\n        lean: false\n      }, function(err, dataSources) {\n        if (err) {\n          return cb(buildErrorResponse({\n            error: err,\n            userDetail: \"Unexpected Error When Searching For A Data Source\",\n            code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n          }));\n        }\n\n        //If no data sources found create, otherwise update.\n        if (dataSources.length === 0) {\n          connections.deploy = true;\n          create(connections, dataSource, cb);\n        } else {\n          update(connections, dataSource, cb);\n        }\n      });\n    }\n  ], cb);\n}", "label": 3}
{"code": "func StartCmd(wdPath, uuid, kernelPath string, nds []kvm.NetDescriber, cpu, mem int64, debug bool) []string {\n\tmachineID := strings.Replace(uuid, \"-\", \"\", -1)\n\tdriverConfiguration := hypervisor.KvmHypervisor{\n\t\tBin: \"./lkvm\",\n\t\tKernelParams: []string{\n\t\t\t\"systemd.default_standard_error=journal+console\",\n\t\t\t\"systemd.default_standard_output=journal+console\",\n\t\t\t\"systemd.machine_id=\" + machineID,\n\t\t},\n\t}\n\n\tdriverConfiguration.InitKernelParams(debug)\n\n\tstartCmd := []string{\n\t\tfilepath.Join(wdPath, driverConfiguration.Bin),\n\t\t\"run\",\n\t\t\"--name\", \"rkt-\" + uuid,\n\t\t\"--no-dhcp\",\n\t\t\"--cpu\", strconv.Itoa(int(cpu)),\n\t\t\"--mem\", strconv.Itoa(int(mem)),\n\t\t\"--console=virtio\",\n\t\t\"--kernel\", kernelPath,\n\t\t\"--disk\", \"stage1/rootfs\", // relative to run/pods/uuid dir this is a place where systemd resides\n\t\t\"--params\", strings.Join(driverConfiguration.KernelParams, \" \"),\n\t}\n\treturn append(startCmd, kvmNetArgs(nds)...)\n}", "label": 5}
{"code": "def seek_to_default(topic, partition)\n      # Remove any cached offset, in case things have changed broker-side.\n      clear_resolved_offset(topic)\n\n      offset = resolve_offset(topic, partition)\n\n      seek_to(topic, partition, offset)\n    end", "label": 4}
{"code": "private static function make_github_api_request( $url, $args = array() ) {\n\t\t$headers = array(\n\t\t\t'Accept'     => 'application/vnd.github.v3+json',\n\t\t\t'User-Agent' => 'WP-CLI',\n\t\t);\n\t\t$token   = getenv( 'GITHUB_TOKEN' );\n\t\tif ( false !== $token ) {\n\t\t\t$headers['Authorization'] = 'token ' . $token;\n\t\t}\n\t\t$response = Utils\\http_request( 'GET', $url, $args, $headers );\n\t\tif ( 200 !== $response->status_code ) {\n\t\t\tWP_CLI::error( sprintf( 'GitHub API returned: %s (HTTP code %d)', $response->body, $response->status_code ) );\n\t\t}\n\t\treturn array( json_decode( $response->body ), $response->headers );\n\t}", "label": 2}
{"code": "function (method, methodName, superMembers) {\n        // Keep signature\n        var description = _gpfFunctionDescribe(method);\n        description.body = this._superifiedBody;\n        return _gpfFunctionBuild(description, this._getSuperifiedContext(method, methodName, superMembers));\n    }", "label": 3}
{"code": "public function setParent($parent_id = null): self\n    {\n        $parent_id = ((int) $parent_id > 0) ? (int) $parent_id : null;\n\n        $this->setAttribute('parent_id', $parent_id);\n\n        return $this;\n    }", "label": 2}
{"code": "public boolean deleteExisting(final File file) {\n    if (!file.exists()) {\n      return true;\n    }\n    boolean deleted = false;\n    if (file.canWrite()) {\n      deleted = file.delete();\n    } else {\n      LogLog.debug(file + \" is not writeable for delete (retrying)\");\n    }\n    if (!deleted) {\n      if (!file.exists()) {\n        deleted = true;\n      } else {\n        file.delete();\n        deleted = (!file.exists());\n      }\n    }\n    return deleted;\n  }", "label": 0}
{"code": "func (p *Party) String() string {\n\treturn fmt.Sprintf(\n\t\t\"party(id=%v, remote=%v, user=%v, server=%v, last_active=%v)\",\n\t\tp.ID, p.RemoteAddr, p.User, p.ServerID, p.LastActive,\n\t)\n}", "label": 5}
{"code": "def specific_occurrence_source_data_criteria(force_sources=nil)\n      return [] if @source_data_criteria.nil?\n      matching = @source_data_criteria.select {|dc| !dc.specific_occurrence.nil?}\n\n      if force_sources\n        existing = matching.map(&:id)\n        matching.concat @source_data_criteria.select {|dc| !existing.include?(dc.id) && force_sources.include?(dc.id)} \n      end\n\n      matching\n    end", "label": 4}
{"code": "protected function escapeColumns(array $output)\n    {\n        return array_map(function ($row) {\n            if ($this->escapeColumns == '*') {\n                $row = $this->escapeRow($row);\n            } elseif (is_array($this->escapeColumns)) {\n                $columns = array_diff($this->escapeColumns, $this->rawColumns);\n                foreach ($columns as $key) {\n                    array_set($row, $key, e(array_get($row, $key)));\n                }\n            }\n\n            return $row;\n        }, $output);\n    }", "label": 2}
{"code": "public function update(array $metadata, array $options = [])\n    {\n        $options += $metadata;\n\n        // can only set predefinedAcl or acl\n        if (isset($options['predefinedAcl'])) {\n            $options['acl'] = null;\n        }\n\n        return $this->info = $this->connection->patchObject($options + array_filter($this->identity));\n    }", "label": 2}
{"code": "def write_document(self, gh_user, doc_id, file_content, branch, author, commit_msg=None):\n        \"\"\"Given a document id, temporary filename of content, branch and auth_info\n\n        Deprecated but needed until we merge api local-dep to master...\n\n        \"\"\"\n        parent_sha = None\n        fc = tempfile.NamedTemporaryFile()\n        # N.B. we currently assume file_content is text/JSON, or should be serialized from a dict\n        if is_str_type(file_content):\n            fc.write(file_content)\n        else:\n            write_as_json(file_content, fc)\n        fc.flush()\n        try:\n            doc_filepath = self.path_for_doc(doc_id)\n            doc_dir = os.path.split(doc_filepath)[0]\n            if parent_sha is None:\n                self.checkout_master()\n                parent_sha = self.get_master_sha()\n            branch = self.create_or_checkout_branch(gh_user, doc_id, parent_sha, force_branch_name=True)\n            # create a document directory if this is a new doc EJM- what if it isn't?\n            if not os.path.isdir(doc_dir):\n                os.makedirs(doc_dir)\n            shutil.copy(fc.name, doc_filepath)\n            git(self.gitdir, self.gitwd, \"add\", doc_filepath)\n            if commit_msg is None:\n                commit_msg = \"Update document '%s' via OpenTree API\" % doc_id\n            try:\n                git(self.gitdir,\n                    self.gitwd,\n                    \"commit\",\n                    author=author,\n                    message=commit_msg)\n            except Exception as e:\n                # We can ignore this if no changes are new,\n                # otherwise raise a 400\n                if \"nothing to commit\" in e.message:  # @EJM is this dangerous?\n                    pass\n                else:\n                    _LOG.exception('\"git commit\" failed')\n                    self.reset_hard()\n                    raise\n            new_sha = git(self.gitdir, self.gitwd, \"rev-parse\", \"HEAD\")\n        except Exception as e:\n            _LOG.exception('write_document exception')\n            raise GitWorkflowError(\"Could not write to document #%s ! Details: \\n%s\" % (doc_id, e.message))\n        finally:\n            fc.close()\n        return new_sha", "label": 1}
{"code": "public static function zip_error_msg( $error_code ) {\n\t\t// From https://github.com/php/php-src/blob/php-5.3.0/ext/zip/php_zip.c#L2623-L2646\n\t\tstatic $zip_err_msgs = array(\n\t\t\tZipArchive::ER_OK          => 'No error',\n\t\t\tZipArchive::ER_MULTIDISK   => 'Multi-disk zip archives not supported',\n\t\t\tZipArchive::ER_RENAME      => 'Renaming temporary file failed',\n\t\t\tZipArchive::ER_CLOSE       => 'Closing zip archive failed',\n\t\t\tZipArchive::ER_SEEK        => 'Seek error',\n\t\t\tZipArchive::ER_READ        => 'Read error',\n\t\t\tZipArchive::ER_WRITE       => 'Write error',\n\t\t\tZipArchive::ER_CRC         => 'CRC error',\n\t\t\tZipArchive::ER_ZIPCLOSED   => 'Containing zip archive was closed',\n\t\t\tZipArchive::ER_NOENT       => 'No such file',\n\t\t\tZipArchive::ER_EXISTS      => 'File already exists',\n\t\t\tZipArchive::ER_OPEN        => 'Can\\'t open file',\n\t\t\tZipArchive::ER_TMPOPEN     => 'Failure to create temporary file',\n\t\t\tZipArchive::ER_ZLIB        => 'Zlib error',\n\t\t\tZipArchive::ER_MEMORY      => 'Malloc failure',\n\t\t\tZipArchive::ER_CHANGED     => 'Entry has been changed',\n\t\t\tZipArchive::ER_COMPNOTSUPP => 'Compression method not supported',\n\t\t\tZipArchive::ER_EOF         => 'Premature EOF',\n\t\t\tZipArchive::ER_INVAL       => 'Invalid argument',\n\t\t\tZipArchive::ER_NOZIP       => 'Not a zip archive',\n\t\t\tZipArchive::ER_INTERNAL    => 'Internal error',\n\t\t\tZipArchive::ER_INCONS      => 'Zip archive inconsistent',\n\t\t\tZipArchive::ER_REMOVE      => 'Can\\'t remove file',\n\t\t\tZipArchive::ER_DELETED     => 'Entry has been deleted',\n\t\t);\n\n\t\tif ( isset( $zip_err_msgs[ $error_code ] ) ) {\n\t\t\treturn sprintf( '%s (%d)', $zip_err_msgs[ $error_code ], $error_code );\n\t\t}\n\t\treturn $error_code;\n\t}", "label": 2}
{"code": "def status(self):\n        \"\"\"Development status.\"\"\"\n        return {self._acronym_status(l): l for l in self.resp_text.split('\\n')\n                if l.startswith(self.prefix_status)}", "label": 1}
{"code": "public function stream_open($path, $mode, $flags, &$openedPath)\n    {\n        $client = $this->openPath($path);\n\n        // strip off 'b' or 't' from the mode\n        $mode = rtrim($mode, 'bt');\n\n        $options = [];\n        if ($this->context) {\n            $contextOptions = stream_context_get_options($this->context);\n            if (array_key_exists($this->protocol, $contextOptions)) {\n                $options = $contextOptions[$this->protocol] ?: [];\n            }\n        }\n\n        if ($mode == 'w') {\n            $this->stream = new WriteStream(null, $options);\n            $this->stream->setUploader(\n                $this->bucket->getStreamableUploader(\n                    $this->stream,\n                    $options + ['name' => $this->file]\n                )\n            );\n        } elseif ($mode == 'r') {\n            try {\n                // Lazy read from the source\n                $options['restOptions']['stream'] = true;\n                $this->stream = new ReadStream(\n                    $this->bucket->object($this->file)->downloadAsStream($options)\n                );\n\n                // Wrap the response in a caching stream to make it seekable\n                if (!$this->stream->isSeekable() && ($flags & STREAM_MUST_SEEK)) {\n                    $this->stream = new CachingStream($this->stream);\n                }\n            } catch (ServiceException $ex) {\n                return $this->returnError($ex->getMessage(), $flags);\n            }\n        } else {\n            return $this->returnError('Unknown stream_open mode.', $flags);\n        }\n\n        if ($flags & STREAM_USE_PATH) {\n            $openedPath = $path;\n        }\n        return true;\n    }", "label": 2}
{"code": "def get_uri_prefix_map(self):\n        \"\"\"Constructs and returns a map from namespace URI to prefix,\n        representing all namespaces in this set.  The prefix chosen for each\n        namespace is its preferred prefix if it's not None.  If the preferred\n        prefix is None, one is chosen from the set of registered\n        prefixes.  In the latter situation, if no prefixes are registered,\n        an exception is raised.\n        \"\"\"\n        mapping = {}\n        \n        for ni in six.itervalues(self.__ns_uri_map):\n            if ni.preferred_prefix:\n                mapping[ni.uri] = ni.preferred_prefix\n            elif len(ni.prefixes) > 0:\n                mapping[ni.uri] = next(iter(ni.prefixes))\n            else:\n                # The reason I don't let any namespace map to None here is that\n                # I don't think generateDS supports it.  It requires prefixes\n                # for all namespaces.\n                raise NoPrefixesError(ni.uri)\n\n        return mapping", "label": 1}
{"code": "public function isInheritedProperty($fieldName)\n    {\n        $declaringClass = $this->declaredProperties[$fieldName]->getDeclaringClass();\n\n        return $declaringClass->className !== $this->className;\n    }", "label": 2}
{"code": "private String addIndexInputToList(String name, IndexInput in,\n      String postingsFormatName) throws IOException {\n    if (indexInputList.get(name) != null) {\n      indexInputList.get(name).close();\n    }\n    if (in != null) {\n      String localPostingsFormatName = postingsFormatName;\n      if (localPostingsFormatName == null) {\n        localPostingsFormatName = in.readString();\n      } else if (!in.readString().equals(localPostingsFormatName)) {\n        throw new IOException(\"delegate codec \" + name + \" doesn't equal \"\n            + localPostingsFormatName);\n      }\n      indexInputList.put(name, in);\n      indexInputOffsetList.put(name, in.getFilePointer());\n      return localPostingsFormatName;\n    } else {\n      log.debug(\"no \" + name + \" registered\");\n      return null;\n    }\n  }", "label": 0}
{"code": "func (a *allocator) RequestPool(addressSpace, pool, subPool string, options map[string]string, v6 bool) (string, *net.IPNet, map[string]string, error) {\n\treq := &api.RequestPoolRequest{AddressSpace: addressSpace, Pool: pool, SubPool: subPool, Options: options, V6: v6}\n\tres := &api.RequestPoolResponse{}\n\tif err := a.call(\"RequestPool\", req, res); err != nil {\n\t\treturn \"\", nil, nil, err\n\t}\n\tretPool, err := types.ParseCIDR(res.Pool)\n\treturn res.PoolID, retPool, res.Data, err\n}", "label": 5}
{"code": "def start(self, activity, action):\n        '''\n        Mark an action as started\n\n        :param activity: The virtualenv activity name\n        :type  activity: ``str``\n\n        :param action: The virtualenv action\n        :type  action: :class:`tox.session.Action`\n        '''\n        try:\n            self._start_action(activity, action)\n        except ValueError:\n            retox_log.debug(\"Could not find action %s in env %s\" % (activity, self.name))\n        self.refresh()", "label": 1}
{"code": "def _make_request(self, endpoint, params):\n        \"\"\"\n        Prepares the request and catches common errors and returns tuple of data and the request response.\n\n        Read more about error codes: https://docs.polrproject.org/en/latest/developer-guide/api/#http-error-codes\n\n        :param endpoint: full endpoint url\n        :type endpoint: str\n        :param params: parameters for the given endpoint\n        :type params: dict\n        :return: Tuple of response data, and the response instance\n        :rtype: dict, requests.Response\n        \"\"\"\n        # params = {\n        #     **self._base_params,  # Mind order to allow params to overwrite base params\n        #     **params\n        # }\n        full_params = self._base_params.copy()\n        full_params.update(params)\n        try:\n            r = requests.get(endpoint, full_params)\n            data = r.json()\n            if r.status_code == 401 and not endpoint.endswith('lookup'):\n                raise exceptions.UnauthorizedKeyError\n            elif r.status_code == 400 and not endpoint.endswith('shorten'):\n                raise exceptions.BadApiRequest\n            elif r.status_code == 500:\n                raise exceptions.ServerOrConnectionError\n            return data, r\n        except ValueError as e:\n            raise exceptions.BadApiResponse(e)\n        except requests.RequestException:\n            raise exceptions.ServerOrConnectionError", "label": 1}
{"code": "def base64_asset_data_uri(asset)\n      data = Rack::Utils.escape(EncodingUtils.base64(asset.source))\n      \"data:#{asset.content_type};base64,#{data}\"\n    end", "label": 4}
{"code": "public static nsconfig diff(nitro_service client, nsconfig resource) throws Exception {\n\t\tnsconfig diffresource = new nsconfig();\n\t\tdiffresource.config1 = resource.config1;\n\t\tdiffresource.config2 = resource.config2;\n\t\tdiffresource.outtype = resource.outtype;\n\t\tdiffresource.template = resource.template;\n\t\tdiffresource.ignoredevicespecific = resource.ignoredevicespecific;\n\t\treturn (nsconfig)diffresource.perform_operationEx(client,\"diff\");\n\t}", "label": 0}
{"code": "func (tc *TeleportClient) u2fLogin(ctx context.Context, pub []byte) (*auth.SSHLoginResponse, error) {\n\t// U2F login requires the official u2f-host executable\n\t_, err := exec.LookPath(\"u2f-host\")\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tpassword, err := tc.AskPassword()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tresponse, err := tc.credClient.SSHAgentU2FLogin(\n\t\tctx,\n\t\ttc.Config.Username,\n\t\tpassword,\n\t\tpub,\n\t\ttc.KeyTTL,\n\t\ttc.CertificateFormat)\n\n\treturn response, trace.Wrap(err)\n}", "label": 5}
{"code": "def validate_words(word_list):\n    '''\n    Checks for each edited word in word_list if that word is a valid english word.abs\n    Returns all validated words as a set instance.\n    '''\n    if word_list is None:\n        return {}\n    elif isinstance(word_list, list):\n        if not word_list:\n            return {}\n        else:\n            return set(word for word in word_list if word in WORD_DISTRIBUTION)\n    else:\n        raise InputError(\"list variable not passed as argument to validate_words\")", "label": 1}
{"code": "public static base_responses add(nitro_service client, dnsaaaarec resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdnsaaaarec addresources[] = new dnsaaaarec[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new dnsaaaarec();\n\t\t\t\taddresources[i].hostname = resources[i].hostname;\n\t\t\t\taddresources[i].ipv6address = resources[i].ipv6address;\n\t\t\t\taddresources[i].ttl = resources[i].ttl;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function CompassCompiler(inputTree, files, options) {\n  options = arguments.length > 2 ? (options || {}) : (files || {});\n  if (arguments.length > 2) {\n    console.log('[broccoli-compass] DEPRECATION: passing files to broccoli-compass constructor as second parameter is deprecated, ' +\n                'use options.files instead');\n    options.files = files;\n  }\n\n  if (!(this instanceof CompassCompiler)) {\n    return new CompassCompiler(inputTree, options);\n  }\n\n  if (options.exclude) {\n    console.log('[broccoli-compass] DEPRECATION: The exclude option has been deprecated in favour of the `cleanOutput` option');\n  }\n\n  this.options = merge(true, this.defaultOptions);\n  merge(this.options, options);\n  options = this.options;\n  options.files = (options.files instanceof Array) ? options.files : [];\n  this.generateCmdLine();\n  this.inputTree = inputTree;\n}", "label": 3}
{"code": "def async_state(handles)\n      response = @client.GetOperationStatus(\n        Hive2::Thrift::TGetOperationStatusReq.new(operationHandle: prepare_operation_handle(handles))\n      )\n\n      case response.operationState\n      when Hive2::Thrift::TOperationState::FINISHED_STATE\n        return :finished\n      when Hive2::Thrift::TOperationState::INITIALIZED_STATE\n        return :initialized\n      when Hive2::Thrift::TOperationState::RUNNING_STATE\n        return :running\n      when Hive2::Thrift::TOperationState::CANCELED_STATE\n        return :cancelled\n      when Hive2::Thrift::TOperationState::CLOSED_STATE\n        return :closed\n      when Hive2::Thrift::TOperationState::ERROR_STATE\n        return :error\n      when Hive2::Thrift::TOperationState::UKNOWN_STATE\n        return :unknown\n      when Hive2::Thrift::TOperationState::PENDING_STATE\n        return :pending\n      when nil\n        raise \"No operation state found for handles - has the session been closed?\"\n      else\n        return :state_not_in_protocol\n      end\n    end", "label": 4}
{"code": "function(cssFile, config, cb) {\n        var imgRegex = /url\\s?\\(['\"]?(.*?)(?=['\"]?\\))/gi,\n            css = null,\n            img = null,\n            inlineImgPath = null,\n            imgPath = null,\n            base = _.isUndefined(config.base) ? '' : config.base,\n            processedImages = 0,\n            match = [],\n            mimetype = null;\n\n        // read css file contents\n        css = fs.readFileSync(cssFile, 'utf-8');\n\n        // find all occurences of images in the css file\n        while (match = imgRegex.exec(css)) {\n            imgPath = path.join(path.dirname(cssFile), match[1]);\n            inlineImgPath = imgPath;\n\n            // remove any query params from path (for cache busting etc.)\n            if (imgPath.lastIndexOf('?') !== -1) {\n                inlineImgPath = imgPath.substr(0, imgPath.lastIndexOf('?'));\n            }\n            // make sure that were only importing images\n            if (path.extname(inlineImgPath) !== '.css') {\n                try {\n                    // try to load the file without a given base path,\n                    // if that doesn\u00b4t work, try with\n                    try {\n                        img = fs.readFileSync(inlineImgPath, 'base64');\n                    } catch (err) {\n                        img = fs.readFileSync(base + '/' + path.basename(inlineImgPath), 'base64');\n                    }\n\n                    // replace file with bas64 data\n\n                    mimetype = mime.lookup(inlineImgPath);\n\n                    // check file size and ie8 compat mode\n                    if (img.length > 32768 && config.ie8 === true) {\n                        // i hate to write this, but can\u00b4t wrap my head around\n                        // how to do this better: DO NOTHING\n                    } else {\n                        css = css.replace(match[1], 'data:' + mimetype + ';base64,' + img);\n                        processedImages++;\n                    }\n                } catch (err) {\n                    // Catch image file not found error\n                    grunt.verbose.error('Image file not found: ' + match[1]);\n                }\n            }\n        }\n\n        // check if a callback is given\n        if (_.isFunction(cb)) {\n            grunt.log.ok('Inlined: ' + processedImages + ' Images in file: ' + cssFile);\n            cb(cssFile, css);\n        }\n    }", "label": 3}
{"code": "function (inherit) {\n            // IE9-11 doesn't handle visibilty:inherit well, so we remove the attribute instead (#2881)\n            if (inherit && this.element.namespaceURI === SVG_NS) {\n                this.element.removeAttribute('visibility');\n            } else {\n                this.attr({ visibility: inherit ? 'inherit' : VISIBLE });\n            }\n            return this;\n        }", "label": 3}
{"code": "public void cache(Identity oid, Object obj)\r\n    {\r\n        try\r\n        {\r\n            jcsCache.put(oid.toString(), obj);\r\n        }\r\n        catch (CacheException e)\r\n        {\r\n            throw new RuntimeCacheException(e);\r\n        }\r\n    }", "label": 0}
{"code": "private void copyObjectAndUpdateStats(int id, IndexInput in, Long inRef,\n      IndexOutput out) throws IOException {\n    int mtasId;\n    int objectFlags;\n    // read\n    in.seek(inRef);\n    mtasId = in.readVInt();\n    assert id == mtasId : \"wrong id detected while copying object\";\n    objectFlags = in.readVInt();\n    out.writeVInt(mtasId);\n    out.writeVInt(objectFlags);\n    if ((objectFlags\n        & MtasCodecPostingsFormat.MTAS_OBJECT_HAS_PARENT) == MtasCodecPostingsFormat.MTAS_OBJECT_HAS_PARENT) {\n      out.writeVInt(in.readVInt());\n    }\n    if ((objectFlags\n        & MtasCodecPostingsFormat.MTAS_OBJECT_HAS_POSITION_RANGE) == MtasCodecPostingsFormat.MTAS_OBJECT_HAS_POSITION_RANGE) {\n      int minPos = in.readVInt();\n      int maxPos = in.readVInt();\n      out.writeVInt(minPos);\n      out.writeVInt(maxPos);\n      tokenStatsAdd(minPos, maxPos);\n    } else if ((objectFlags\n        & MtasCodecPostingsFormat.MTAS_OBJECT_HAS_POSITION_SET) == MtasCodecPostingsFormat.MTAS_OBJECT_HAS_POSITION_SET) {\n      int size = in.readVInt();\n      out.writeVInt(size);\n      SortedSet<Integer> list = new TreeSet<>();\n      int previousPosition = 0;\n      for (int t = 0; t < size; t++) {\n        int pos = in.readVInt();\n        out.writeVInt(pos);\n        previousPosition = (pos + previousPosition);\n        list.add(previousPosition);\n      }\n      assert list.size() == size : \"duplicate positions in set are not allowed\";\n      tokenStatsAdd(list.first(), list.last());\n    } else {\n      int pos = in.readVInt();\n      out.writeVInt(pos);\n      tokenStatsAdd(pos, pos);\n    }\n    if ((objectFlags\n        & MtasCodecPostingsFormat.MTAS_OBJECT_HAS_OFFSET) == MtasCodecPostingsFormat.MTAS_OBJECT_HAS_OFFSET) {\n      out.writeVInt(in.readVInt());\n      out.writeVInt(in.readVInt());\n    }\n    if ((objectFlags\n        & MtasCodecPostingsFormat.MTAS_OBJECT_HAS_REALOFFSET) == MtasCodecPostingsFormat.MTAS_OBJECT_HAS_REALOFFSET) {\n      out.writeVInt(in.readVInt());\n      out.writeVInt(in.readVInt());\n    }\n    if ((objectFlags\n        & MtasCodecPostingsFormat.MTAS_OBJECT_HAS_PAYLOAD) == MtasCodecPostingsFormat.MTAS_OBJECT_HAS_PAYLOAD) {\n      int length = in.readVInt();\n      out.writeVInt(length);\n      byte[] payload = new byte[length];\n      in.readBytes(payload, 0, length);\n      out.writeBytes(payload, payload.length);\n    }\n    out.writeVLong(in.readVLong());\n  }", "label": 0}
{"code": "func (tc *TeleportClient) getTargetNodes(ctx context.Context, proxy *ProxyClient) ([]string, error) {\n\tvar (\n\t\terr    error\n\t\tnodes  []services.Server\n\t\tretval = make([]string, 0)\n\t)\n\tif tc.Labels != nil && len(tc.Labels) > 0 {\n\t\tnodes, err = proxy.FindServersByLabels(ctx, tc.Namespace, tc.Labels)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tfor i := 0; i < len(nodes); i++ {\n\t\t\tretval = append(retval, nodes[i].GetAddr())\n\t\t}\n\t}\n\tif len(nodes) == 0 {\n\t\tretval = append(retval, net.JoinHostPort(tc.Host, strconv.Itoa(tc.HostPort)))\n\t}\n\treturn retval, nil\n}", "label": 5}
{"code": "func (c *Connector) Close() error {\n\tif c.Client != nil {\n\t\treturn c.Close()\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def connect(self):\n        \"\"\" Establish a connection to the device.\n\n        Purpose: This method is used to make a connection to the junos\n               | device. The internal property conn_type is what\n               | determines the type of connection we make to the device.\n               | - 'paramiko' is used for operational commands (to allow\n               |            pipes in commands)\n               | - 'scp' is used for copying files\n               | - 'shell' is used for to send shell commands\n               | - 'root' is used when logging into the device as root, and\n               |            wanting to send operational commands\n               | - 'ncclient' is used for the rest (commit, compare_config,\n               |            commit_check)\n\n        @returns: None\n        @rtype: None\n        \"\"\"\n        if self.conn_type == 'paramiko':\n            self._session = paramiko.SSHClient()\n            # These two lines set the paramiko logging to Critical to\n            # remove extra messages from being sent to the user output.\n            logger = logging.Logger.manager.getLogger('paramiko.transport')\n            logger.setLevel(logging.CRITICAL)\n            self._session.set_missing_host_key_policy(\n                paramiko.AutoAddPolicy())\n            self._session.connect(hostname=self.host,\n                                  username=self.username,\n                                  password=self.password,\n                                  port=self.port,\n                                  timeout=self.connect_timeout)\n        if self.conn_type == 'scp':\n            self._scp_session = paramiko.SSHClient()\n            logger = logging.Logger.manager.getLogger('paramiko.transport')\n            logger.setLevel(logging.CRITICAL)\n            self._scp_session.set_missing_host_key_policy(\n                paramiko.AutoAddPolicy())\n            self._scp_session.connect(hostname=self.host,\n                                      username=self.username,\n                                      password=self.password,\n                                      port=self.port,\n                                      timeout=self.connect_timeout)\n            self._scp = SCPClient(self._scp_session.get_transport())\n        elif self.conn_type == \"ncclient\":\n            self._session = manager.connect(\n                host=self.host,\n                port=self.port,\n                username=self.username,\n                password=self.password,\n                timeout=self.connect_timeout,\n                device_params={'name': 'junos'},\n                hostkey_verify=False\n            )\n        elif self.conn_type == 'shell':\n            if not self._session:\n                self.conn_type = 'paramiko'\n                self.connect()\n                self.conn_type = 'shell'\n            if not self._shell:\n                self._shell = self._session.invoke_shell()\n                time.sleep(2)\n                if self.username != 'root' and not self._in_cli:\n                    self._in_cli = True\n            if not self.cli_to_shell():\n                self._shell.recv(9999)\n        elif self.conn_type == 'root':\n            # open the shell if necessary, and move into CLI\n            if not self._shell:\n                self._shell = self._session.invoke_shell()\n                time.sleep(2)\n            if not self.shell_to_cli():\n                self._shell.recv(9999)\n        self._update_timeout(self.session_timeout)", "label": 1}
{"code": "protected function parseClientList($data)\n    {\n        $clients = array();\n\n        foreach (explode(\"\\n\", $data, -1) as $clientData) {\n            $client = array();\n\n            foreach (explode(' ', $clientData) as $kv) {\n                @list($k, $v) = explode('=', $kv);\n                $client[$k] = $v;\n            }\n\n            $clients[] = $client;\n        }\n\n        return $clients;\n    }", "label": 2}
{"code": "def run_snpeff(job, merged_mutation_file, univ_options, snpeff_options):\n    \"\"\"\n    This module will run snpeff on the aggregated mutation calls.  Currently the only mutations\n    called are SNPs hence SnpEff suffices. This node will be replaced in the future with another\n    translator.\n\n    ARGUMENTS\n    1. merged_mutation_file: <JSid for merged vcf>\n    2. univ_options: Dict of universal arguments used by almost all tools\n         univ_options\n                +- 'dockerhub': <dockerhub to use>\n    3. snpeff_options: Dict of parameters specific to snpeff\n         snpeff_options\n                +- 'index_tar': <JSid for the snpEff index tarball>\n\n    RETURN VALUES\n    1. output_file: <JSid for the snpeffed vcf>\n\n    This node corresponds to node 16 on the tree\n    \"\"\"\n    job.fileStore.logToMaster('Running snpeff on %s' % univ_options['patient'])\n    work_dir = job.fileStore.getLocalTempDir()\n    input_files = {\n        'merged_mutations.vcf': merged_mutation_file,\n        'snpeff_index.tar.gz': snpeff_options['index_tar']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    parameters = ['eff',\n                  '-dataDir', input_files['snpeff_index'],\n                  '-c', '/'.join([input_files['snpeff_index'], 'snpEff_hg19_gencode.config']),\n                  '-no-intergenic',\n                  '-no-downstream',\n                  '-no-upstream',\n                  #'-canon',\n                  '-noStats',\n                  'hg19_gencode',\n                  input_files['merged_mutations.vcf']]\n    Xmx = snpeff_options['java_Xmx'] if snpeff_options['java_Xmx'] else univ_options['java_Xmx']\n    with open('/'.join([work_dir, 'snpeffed_mutations.vcf']), 'w') as snpeff_file:\n        docker_call(tool='snpeff', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], java_opts=Xmx, outfile=snpeff_file)\n    output_file = job.fileStore.writeGlobalFile(snpeff_file.name)\n    return output_file", "label": 1}
{"code": "def log_trans(table):\n    \"\"\"\n    log transform each value in table\n    \"\"\"\n    t = []\n    all = [item for sublist in table for item in sublist]\n    if min(all) == 0:\n        scale = min([i for i in all if i != 0]) * 10e-10\n    else:\n        scale = 0\n    for i in table:\n        t.append(np.ndarray.tolist(np.log10([j + scale for j in i])))\n    return t", "label": 1}
{"code": "def timedelta_seconds(timedelta):\r\n    \"\"\"Returns the total timedelta duration in seconds.\"\"\"\r\n    return (timedelta.total_seconds() if hasattr(timedelta, \"total_seconds\")\r\n            else timedelta.days * 24 * 3600 + timedelta.seconds +\r\n                 timedelta.microseconds / 1000000.)", "label": 1}
{"code": "function extractLiteralFromDef(stats, element) {\n    if (validLiteral(element)) {\n        stats.setPath(element.value);\n        let arrayLiteral = element.value.split('/');\n        let length = arrayLiteral.length;\n        if (length > 0) {\n            const index = validIndex(arrayLiteral);\n            stats.setPackageName(arrayLiteral[index].split(\"$\")[0]);\n            stats.setVersion(arrayLiteral[index].split(\"$\")[1] || '');\n            stats.setFileName(arrayLiteral.splice(index + 1, length).join('/'));\n        }\n    }\n    return stats;\n}", "label": 3}
{"code": "def load_settings(path, type)\n      # Load fixture\n      base_path = Pathname(fixture_path(\"CommonBuildSettings/configs/#{path}\"))\n      config_fixture = base_path + \"#{path}_#{type}.xcconfig\"\n      config = Xcodeproj::Config.new(config_fixture)\n      settings = config.to_hash\n\n      # Filter exclusions\n      settings = apply_exclusions(settings, EXCLUDED_KEYS)\n      project_defaults_by_config = Xcodeproj::Constants::PROJECT_DEFAULT_BUILD_SETTINGS\n      project_defaults = project_defaults_by_config[:all]\n      project_defaults.merge(project_defaults_by_config[type]) unless type == :base\n      settings = apply_exclusions(settings, project_defaults)\n\n      settings\n    end", "label": 4}
{"code": "func ParseOnOff(parameterName, val string, defaultValue bool) (bool, error) {\n\tswitch val {\n\tcase teleport.On:\n\t\treturn true, nil\n\tcase teleport.Off:\n\t\treturn false, nil\n\tcase \"\":\n\t\treturn defaultValue, nil\n\tdefault:\n\t\treturn false, trace.BadParameter(\"bad %q parameter value: %q, supported values are on or off\", parameterName, val)\n\t}\n}", "label": 5}
{"code": "def update\n      config.update(:remotes) do |rmts|\n        yield(rmts || {}).tap do |new_rmts|\n          raise_invalid unless validate(new_rmts)\n        end\n      end\n    end", "label": 4}
{"code": "function numberFormat(number, decimals, decPoint, thousandsSep) {\n        var externalFn = Highcharts.numberFormat,\n          lang = defaultOptions.lang,\n        // http://kevin.vanzonneveld.net/techblog/article/javascript_equivalent_for_phps_number_format/\n          n = +number || 0,\n          c = decimals === -1 ?\n            (n.toString().split('.')[1] || '').length : // preserve decimals\n            (isNaN(decimals = mathAbs(decimals)) ? 2 : decimals),\n          d = decPoint === undefined ? lang.decimalPoint : decPoint,\n          t = thousandsSep === undefined ? lang.thousandsSep : thousandsSep,\n          s = n < 0 ? \"-\" : \"\",\n          i = String(pInt(n = mathAbs(n).toFixed(c))),\n          j = i.length > 3 ? i.length % 3 : 0;\n\n        return externalFn !== numberFormat ?\n          externalFn(number, decimals, decPoint, thousandsSep) :\n          (s + (j ? i.substr(0, j) + t : \"\") + i.substr(j).replace(/(\\d{3})(?=\\d)/g, \"$1\" + t) +\n          (c ? d + mathAbs(n - i).toFixed(c).slice(2) : \"\"));\n    }", "label": 3}
{"code": "def configure_logger(options)\n      log.color_enabled = options.fetch(:color, log.tty?)\n      log.summary_enabled = options.fetch(:summary, true)\n    end", "label": 4}
{"code": "public void init(Configuration configuration) {\n        if (devMode && reload && !listeningToDispatcher) {\n            // this is the only way I found to be able to get added to to\n            // ConfigurationProvider list\n            // listening to events in Dispatcher\n            listeningToDispatcher = true;\n            Dispatcher.addDispatcherListener(this);\n        }\n    }", "label": 0}
{"code": "function processRow(row) {\n        if (!row) row = {};\n        for (var i = 0; i < hooks.length; i++) {\n            if (hooks[i].call(row, req, row) === true) return false;\n        }\n        return true;\n    }", "label": 3}
{"code": "public static gslbdomain_stats[] get(nitro_service service) throws Exception{\n\t\tgslbdomain_stats obj = new gslbdomain_stats();\n\t\tgslbdomain_stats[] response = (gslbdomain_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setAlertPolicy($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\AlertPolicy::class);\n        $this->alert_policy = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function process(data) {\n  var flags = parseInt(data, 16);\n  var result = [];\n  if(flags & 0x01) {\n    result.push(BIT0_NAME);\n  }\n  if(flags & 0x02) {\n    result.push(BIT1_NAME);\n  }\n  if(flags & 0x04) {\n    result.push(BIT2_NAME);\n  }\n  if(flags & 0x08) {\n    result.push(BIT3_NAME);\n  }\n  if(flags & 0x10) {\n    result.push(BIT4_NAME);\n  }\n  if(flags & 0x20) {\n    result.push(BIT5_NAME);\n  }\n  return result;\n}", "label": 3}
{"code": "def readpartial(size = BUFFER_SIZE)\n      return unless @pending_response\n\n      chunk = @parser.read(size)\n      return chunk if chunk\n\n      finished = (read_more(size) == :eof) || @parser.finished?\n      chunk    = @parser.read(size)\n      finish_response if finished\n\n      chunk.to_s\n    end", "label": 4}
{"code": "public RedwoodConfiguration rootHandler(final LogRecordHandler handler){\r\n    tasks.add(new Runnable(){ public void run(){ Redwood.appendHandler(handler); } });\r\n    Redwood.appendHandler(handler);\r\n    return this;\r\n  }", "label": 0}
{"code": "func readUntil(r io.Reader, b []byte) error {\n\tb1 := make([]byte, len(b))\n\ti := 0\n\tfor {\n\t\t_, err := io.ReadFull(r, b1[i:])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ti = suffixMatchLen(b1, b)\n\t\tif i == len(b) {\n\t\t\tbreak\n\t\t}\n\t\tif copy(b1, b1[len(b1)-i:]) != i {\n\t\t\tpanic(\"wat\")\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def options\n      opts    = fetch('options', {})\n      headers = fetch('headers', {})\n      if value = accept\n        headers[:accept] = value\n      end\n      opts[:raw]     = key?('raw') ? self['raw'] : false\n      opts[:headers] = headers unless headers.empty?\n      opts\n    end", "label": 4}
{"code": "private function paramType(\n        $value,\n        $givenType = null,\n        $definition = null,\n        $allowMixedArrayType = false\n    ) {\n        $valueType = gettype($value);\n\n        // If a definition is provided, the type is set to `array` to force\n        // the value to be interpreted as an array or a struct, even if null.\n        if ($definition !== null) {\n            $valueType = 'array';\n        }\n\n        switch ($valueType) {\n            case 'boolean':\n                $type = $this->typeObject($givenType ?: self::TYPE_BOOL);\n                break;\n\n            case 'integer':\n                $value = (string) $value;\n                $type = $this->typeObject($givenType ?: self::TYPE_INT64);\n                break;\n\n            case 'double':\n                $type = $this->typeObject($givenType ?: self::TYPE_FLOAT64);\n                switch ($value) {\n                    case INF:\n                        $value = 'Infinity';\n                        break;\n\n                    case -INF:\n                        $value = '-Infinity';\n                        break;\n                }\n\n                if (!is_string($value) && is_nan($value)) {\n                    $value = 'NaN';\n                }\n\n                break;\n\n            case 'string':\n                $type = $this->typeObject($givenType ?: self::TYPE_STRING);\n                break;\n\n            case 'resource':\n                $type = $this->typeObject($givenType ?: self::TYPE_BYTES);\n                $value = base64_encode(stream_get_contents($value));\n                break;\n\n            case 'object':\n                list ($type, $value) = $this->objectParam($value);\n                break;\n\n            case 'array':\n                if ($givenType === Database::TYPE_STRUCT) {\n                    if (!($definition instanceof StructType)) {\n                        throw new \\InvalidArgumentException(\n                            'Struct parameter types must be declared explicitly, and must '.\n                            'be an instance of Google\\Cloud\\Spanner\\StructType.'\n                        );\n                    }\n\n                    if ($value instanceof \\stdClass) {\n                        $value = (array) $value;\n                    }\n\n                    list ($value, $type) = $this->structParam($value, $definition);\n                } else {\n                    if (!($definition instanceof ArrayType)) {\n                        throw new \\InvalidArgumentException(\n                            'Array parameter types must be an instance of Google\\Cloud\\Spanner\\ArrayType.'\n                        );\n                    }\n\n                    list ($value, $type) = $this->arrayParam($value, $definition, $allowMixedArrayType);\n                }\n\n                break;\n\n            case 'NULL':\n                $type = $this->typeObject($givenType);\n                break;\n\n            default:\n                throw new \\InvalidArgumentException(sprintf(\n                    'Unrecognized value type %s. ' .\n                    'Please ensure you are using the latest version of google/cloud or google/cloud-spanner.',\n                    get_class($value)\n                ));\n                break;\n        }\n\n        return [$value, $type];\n    }", "label": 2}
{"code": "def write\n      each_site_file do |item|\n        item.write(dest) if regenerator.regenerate?(item)\n      end\n      regenerator.write_metadata\n      Jekyll::Hooks.trigger :site, :post_write, self\n    end", "label": 4}
{"code": "func (cn *connection) Post(msg pp.Message) {\n\ttorrent.Add(fmt.Sprintf(\"messages posted of type %s\", msg.Type.String()), 1)\n\t// We don't need to track bytes here because a connection.w Writer wrapper\n\t// takes care of that (although there's some delay between us recording\n\t// the message, and the connection writer flushing it out.).\n\tcn.writeBuffer.Write(msg.MustMarshalBinary())\n\t// Last I checked only Piece messages affect stats, and we don't post\n\t// those.\n\tcn.wroteMsg(&msg)\n\tcn.tickleWriter()\n}", "label": 5}
{"code": "function create(content, url) {\n  url = url || '<source>';\n  const map = new SourceMapGenerator({ file: url });\n  const lines = content.split('\\n');\n\n  for (let l = 1, n = lines.length; l <= n; l++) {\n    // Skip empty\n    if (lines[l - 1]) {\n      map.addMapping({\n        source: url,\n        original: { line: l, column: 0 },\n        generated: { line: l, column: 0 }\n      });\n    }\n  }\n\n  map.setSourceContent(url, content);\n  return map;\n}", "label": 3}
{"code": "function swap(arr, i1, i2) {\n  const tmp = arr[i1];\n  arr[i1] = arr[i2];\n  arr[i2] = tmp;\n}", "label": 3}
{"code": "def _file_like(self, full_path):\n        \"\"\"Return the appropriate file object.\"\"\"\n        magic = self._match_magic(full_path)\n        if magic is not None:\n            return magic.file_like(full_path, self.encoding)\n        else:\n            return open(full_path, 'rb')", "label": 1}
{"code": "function meaningfulTime() {\n  if (moduleRef) {\n    var parts = processRef.hrtime();\n    return (((parts[0]*1000)+(parts[1]/1000000))%10000).toFixed(2) + 'ms';\n  } else {\n    return performance.now().toFixed(2)+'ms';\n  }\n}", "label": 3}
{"code": "func ParseID(id string) (*ID, error) {\n\tval := uuid.Parse(id)\n\tif val == nil {\n\t\treturn nil, trace.BadParameter(\"'%v' is not a valid Time UUID v1\", id)\n\t}\n\tif ver, ok := val.Version(); !ok || ver != 1 {\n\t\treturn nil, trace.BadParameter(\"'%v' is not a be a valid Time UUID v1\", id)\n\t}\n\tuid := ID(id)\n\treturn &uid, nil\n}", "label": 5}
{"code": "def save(self, filename, content):\n        \"\"\"\n        default is to save a file from list of lines\n        \"\"\"\n        with open(filename, \"w\") as f:\n            if hasattr(content, '__iter__'):\n                f.write('\\n'.join([row for row in content]))\n            else:\n                print('WRINGI CONTWETESWREWR')\n                f.write(str(content))", "label": 1}
{"code": "def _do_get(self, uri, **kwargs):\n        \"\"\"\n        Convinient method for GET requests\n        Returns http request status value from a POST request\n        \"\"\"\n        #TODO:\n        # Add error handling. Check for HTTP status here would be much more conveinent than in each calling method\n        scaleioapi_get_headers = {'Content-type':'application/json','Version':'1.0'}\n        self.logger.debug(\"_do_get() \" + \"{}/{}\".format(self._api_url,uri))\n        \n        if kwargs:\n            for key, value in kwargs.iteritems():\n                if key == 'headers':\n                    scaleio_get_headersvalue = value\n\n        try:\n            #response = self._im_session.get(\"{}/{}\".format(self._api_url, uri), headers = scaleioapi_get_headers, payload = scaleio_payload).json()\n            response = self._im_session.get(\"{}/{}\".format(self._api_url, uri), **kwargs).json()\n            #response = self._session.get(url, headers=scaleioapi_post_headers, **kwargs)\n            if response.status_code == requests.codes.ok:\n                return response\n            else:\n                raise RuntimeError(\"_do_get() - HTTP response error\" + response.status_code)\n        except:\n            raise RuntimeError(\"_do_get() - Communication error with ScaleIO gateway\")\n        return response", "label": 1}
{"code": "func (a *AuthServer) GetDomainName() (string, error) {\n\tclusterName, err := a.GetClusterName()\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\treturn clusterName.GetClusterName(), nil\n}", "label": 5}
{"code": "protected function loadMigrationFiles($module)\n    {\n        $path = $this->laravel['modules']->getModulePath($module) . $this->getMigrationGeneratorPath();\n\n        $files = $this->laravel['files']->glob($path . '/*_*.php');\n\n        foreach ($files as $file) {\n            $this->laravel['files']->requireOnce($file);\n        }\n    }", "label": 2}
{"code": "def _has_changed_related(instance):\n    \"\"\"\n    Check if some related tracked fields have changed\n    \"\"\"\n    tracked_related_fields = getattr(\n        instance,\n        '_tracked_related_fields',\n        {}\n    ).keys()\n    for field, value in instance._original_fields.items():\n        if field != 'pk' and \\\n           not isinstance(instance._meta.get_field(field), ManyToManyField):\n            if field in tracked_related_fields:\n                if isinstance(instance._meta.get_field(field), ForeignKey):\n                    if getattr(instance, '{0}_id'.format(field)) != value:\n                        return True\n                else:\n                    if getattr(instance, field) != value:\n                        return True\n    return False", "label": 1}
{"code": "function(handleObj) {\n      var el = $(this);\n      var fired = false;\n\n      // Mark element as being in transition\n      el.data(\"trend\", true);\n\n      // Calculate a fallback duration. + 20 because some browsers fire\n      // timeouts faster than transitionend.\n      var time =\n        parseProperties(el, transitionDurationProperties) +\n        parseProperties(el, transitionDelayProperties) +\n        20;\n\n      var cb = function(e) {\n        // transitionend events can be sent for each property. Let's just\n        // skip all but the first. Also handles the timeout callback.\n        if (fired) return;\n\n        // Child elements that also have transitions can be fired before we\n        // complete. This will catch and ignore those. Unfortunately, we'll\n        // have to rely on the timeout in these cases.\n        if (e && e.srcElement !== el[0]) return;\n\n        // Mark element has not being in transition\n        el.data(\"trend\", false);\n\n        // Callback\n        fired = true;\n        if (handleObj.handler) handleObj.handler();\n      };\n\n      el.one(transitionEndEvents, cb);\n      el.data(\"trend-timeout\", window.setTimeout(cb, time));\n    }", "label": 3}
{"code": "public function setAppEngineHttpTarget($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Scheduler\\V1\\AppEngineHttpTarget::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "private static Clique valueOfHelper(int[] relativeIndices) {\r\n    // if clique already exists, return that one\r\n    Clique c = new Clique();\r\n    c.relativeIndices = relativeIndices;\r\n    return intern(c);\r\n  }", "label": 0}
{"code": "func (f *Fpdf) OutputFileAndClose(fileStr string) error {\n\tif f.err == nil {\n\t\tpdfFile, err := os.Create(fileStr)\n\t\tif err == nil {\n\t\t\tf.Output(pdfFile)\n\t\t\tpdfFile.Close()\n\t\t} else {\n\t\t\tf.err = err\n\t\t}\n\t}\n\treturn f.err\n}", "label": 5}
{"code": "func (b *SyncBuffer) Close() error {\n\terr := b.reader.Close()\n\terr2 := b.writer.Close()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn err2\n}", "label": 5}
{"code": "function(deferred, options) {\n      var staleModels,\n        formModel = this,\n        responsesSucceeded = 0,\n        responsesFailed = 0,\n        responses = {},\n        oldValues = {},\n        models = formModel.getTrackedModels(),\n        numberOfSaves = models.length;\n      // If we're not forcing a save, then throw an error if the models are stale\n      if (!options.force) {\n        staleModels = formModel.checkIfModelsAreStale();\n        if (staleModels.length > 0) {\n          throw {\n            name: 'Stale data',\n            staleModels: staleModels\n          };\n        }\n      }\n      // Callback for each response\n      function responseCallback(response, model, success) {\n        // Add response to a hash that will eventually be returned through the promise\n        responses[model.cid] = {\n            success: success,\n            response: response\n          };\n        // If we have reached the total of number of expected responses, then resolve or reject the promise\n        if (responsesFailed + responsesSucceeded === numberOfSaves) {\n          if (responsesFailed > 0) {\n            // Rollback if any responses have failed\n            if (options.rollback) {\n              _.each(formModel.getTrackedModels(), function(model) {\n                model.set(oldValues[model.cid]);\n                if (responses[model.cid].success) {\n                  model.save();\n                }\n              });\n            }\n            formModel.trigger('save-fail', responses);\n            deferred.reject(responses);\n          } else {\n            formModel.trigger('save-success', responses);\n            deferred.resolve(responses);\n          }\n        }\n      }\n      // Grab the current values of the object models\n      _.each(models, function(model) {\n        oldValues[model.cid] = formModel.__getTrackedModelFields(model);\n      });\n      // Push the form model values to the object models\n      formModel.push();\n      // Call save on each object model\n      _.each(models, function(model) {\n        model.save().fail(function() {\n          responsesFailed++;\n          responseCallback(arguments, model, false);\n        }).done(function() {\n          responsesSucceeded++;\n          responseCallback(arguments, model, true);\n        });\n      });\n    }", "label": 3}
{"code": "public void compact() {\r\n    if (keys.length > size) {\r\n      Class<?>[] newKeys = new Class<?>[size];\r\n      Object[] newVals = new Object[size];\r\n      System.arraycopy(keys, 0, newKeys, 0, size);\r\n      System.arraycopy(values, 0, newVals, 0, size);\r\n      keys = newKeys;\r\n      values = newVals;\r\n    }\r\n  }", "label": 0}
{"code": "private void cascadeInsertFor(ObjectEnvelope mod, List alreadyPrepared)\r\n    {\r\n        // avoid endless recursion, so use List for registration\r\n        if(alreadyPrepared.contains(mod.getIdentity())) return;\r\n        alreadyPrepared.add(mod.getIdentity());\r\n\r\n        ClassDescriptor cld = getTransaction().getBroker().getClassDescriptor(mod.getObject().getClass());\r\n\r\n        List refs = cld.getObjectReferenceDescriptors(true);\r\n        cascadeInsertSingleReferences(mod, refs, alreadyPrepared);\r\n\r\n        List colls = cld.getCollectionDescriptors(true);\r\n        cascadeInsertCollectionReferences(mod, colls, alreadyPrepared);\r\n    }", "label": 0}
{"code": "func (c *Client) dialer(_ string, timeout time.Duration) (net.Conn, error) {\n\tconn, err := netAddrDialer(c.address)(\"\", timeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If we have a TLS config we wrap our connection. We only do this\n\t// for net/rpc since gRPC uses its own mechanism for TLS.\n\tif c.protocol == ProtocolNetRPC && c.config.TLSConfig != nil {\n\t\tconn = tls.Client(conn, c.config.TLSConfig)\n\t}\n\n\treturn conn, nil\n}", "label": 5}
{"code": "public static base_response update(nitro_service client, appfwlearningsettings resource) throws Exception {\n\t\tappfwlearningsettings updateresource = new appfwlearningsettings();\n\t\tupdateresource.profilename = resource.profilename;\n\t\tupdateresource.starturlminthreshold = resource.starturlminthreshold;\n\t\tupdateresource.starturlpercentthreshold = resource.starturlpercentthreshold;\n\t\tupdateresource.cookieconsistencyminthreshold = resource.cookieconsistencyminthreshold;\n\t\tupdateresource.cookieconsistencypercentthreshold = resource.cookieconsistencypercentthreshold;\n\t\tupdateresource.csrftagminthreshold = resource.csrftagminthreshold;\n\t\tupdateresource.csrftagpercentthreshold = resource.csrftagpercentthreshold;\n\t\tupdateresource.fieldconsistencyminthreshold = resource.fieldconsistencyminthreshold;\n\t\tupdateresource.fieldconsistencypercentthreshold = resource.fieldconsistencypercentthreshold;\n\t\tupdateresource.crosssitescriptingminthreshold = resource.crosssitescriptingminthreshold;\n\t\tupdateresource.crosssitescriptingpercentthreshold = resource.crosssitescriptingpercentthreshold;\n\t\tupdateresource.sqlinjectionminthreshold = resource.sqlinjectionminthreshold;\n\t\tupdateresource.sqlinjectionpercentthreshold = resource.sqlinjectionpercentthreshold;\n\t\tupdateresource.fieldformatminthreshold = resource.fieldformatminthreshold;\n\t\tupdateresource.fieldformatpercentthreshold = resource.fieldformatpercentthreshold;\n\t\tupdateresource.xmlwsiminthreshold = resource.xmlwsiminthreshold;\n\t\tupdateresource.xmlwsipercentthreshold = resource.xmlwsipercentthreshold;\n\t\tupdateresource.xmlattachmentminthreshold = resource.xmlattachmentminthreshold;\n\t\tupdateresource.xmlattachmentpercentthreshold = resource.xmlattachmentpercentthreshold;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def http_client(self, port=None):\n        \"\"\"\n        Construct an HTTP client for this container.\n        \"\"\"\n        # Local import to avoid potential circularity.\n        from seaworthy.client import ContainerHttpClient\n        client = ContainerHttpClient.for_container(self, container_port=port)\n        self._http_clients.append(client)\n        return client", "label": 1}
{"code": "public function dropDatabase()\n    {\n        $dropSchemaSql = $this->getDropDatabaseSQL();\n        $conn          = $this->em->getConnection();\n\n        foreach ($dropSchemaSql as $sql) {\n            $conn->executeQuery($sql);\n        }\n    }", "label": 2}
{"code": "def url_is(white_list):\n    \"\"\"\n    Function generator.\n\n    Args:\n        white_list (dict): dict with PREFIXES and CONSTANTS keys (list values).\n\n    Returns:\n        func: a function to check if a URL is...\n    \"\"\"\n    def func(url):\n        prefixes = white_list.get('PREFIXES', ())\n        for prefix in prefixes:\n            if url.startswith(prefix):\n                return True\n        constants = white_list.get('CONSTANTS', ())\n        for exact_url in constants:\n            if url == exact_url:\n                return True\n        return False\n    return func", "label": 1}
{"code": "public static void compareAndCheck(String[] list, String[] original,\n      String nameNew, String nameOriginal, Boolean unique) throws IOException {\n    if (list != null) {\n      if (list.length != original.length) {\n        throw new IOException(\n            \"unequal size \" + nameNew + \" and \" + nameOriginal);\n      }\n      if (unique) {\n        Set<String> set = new HashSet<>();\n        for (int i = 0; i < list.length; i++) {\n          set.add(list[i]);\n        }\n        if (set.size() < list.length) {\n          throw new IOException(\"duplicate \" + nameNew);\n        }\n      }\n    }\n  }", "label": 0}
{"code": "def aggregate(self, On=None, AggFuncDict=None, AggFunc=None, AggList =\n                  None, returnsort=False,KeepOthers=True, keyfuncdict=None):\n        \"\"\"\n        Aggregate a tabarray on columns for given functions.\n\n        Method wraps::\n\n                tabular.spreadsheet.aggregate(self, On, AggFuncDict, AggFunc, returnsort)\n\n        \"\"\"\n        if returnsort:\n            [data, s] = spreadsheet.aggregate(X=self, \n                     On=On, \n                     AggFuncDict=AggFuncDict, \n                     AggFunc=AggFunc, \n                     AggList=AggList, \n                     returnsort=returnsort, \n                     keyfuncdict=keyfuncdict)\n        else:\n            data = spreadsheet.aggregate(X=self, On=On, AggFuncDict=AggFuncDict, \n                     AggFunc=AggFunc, AggList = AggList, returnsort=returnsort, \n                     KeepOthers=KeepOthers,\n                     keyfuncdict=keyfuncdict)\n        data = data.view(tabarray)\n        data.coloring = self.coloring\n        if returnsort:\n            return [data, s]\n        else:\n            return data", "label": 1}
{"code": "public static <T> boolean containsAny(Collection<T> collection, Collection<T> toCheck){\r\n    for(T c: toCheck){\r\n      if(collection.contains(c))\r\n        return true;\r\n    }\r\n    return false;\r\n    \r\n  }", "label": 0}
{"code": "function cleanupStickitData(node) {\n    var $node = $(node);\n    var stickitValue = $node.data('stickit-bind-val');\n    if (node.tagName === 'OPTION' && node.value !== undefined && stickitValue !== node.value) {\n      $node.removeData('stickit-bind-val');\n    }\n  }", "label": 3}
{"code": "public static base_responses add(nitro_service client, policymap resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tpolicymap addresources[] = new policymap[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new policymap();\n\t\t\t\taddresources[i].mappolicyname = resources[i].mappolicyname;\n\t\t\t\taddresources[i].sd = resources[i].sd;\n\t\t\t\taddresources[i].su = resources[i].su;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t\taddresources[i].tu = resources[i].tu;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def format_result(line, line_num, txt):\n    \"\"\" highlight the search result \"\"\"\n    \n    return '&nbsp;&nbsp;' + str(line_num) + ': ' + line.replace(txt, '<span style=\"background-color: #FFFF00\">' + txt + '</span>')", "label": 1}
{"code": "func GenerateSelfSignedCert(hostNames []string) (*TLSCredentials, error) {\n\tpriv, err := rsa.GenerateKey(rand.Reader, teleport.RSAKeySize)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tnotBefore := time.Now()\n\tnotAfter := notBefore.Add(time.Hour * 24 * 365 * 10) // 10 years\n\n\tserialNumberLimit := new(big.Int).Lsh(big.NewInt(1), 128)\n\tserialNumber, err := rand.Int(rand.Reader, serialNumberLimit)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tentity := pkix.Name{\n\t\tCommonName:   \"localhost\",\n\t\tCountry:      []string{\"US\"},\n\t\tOrganization: []string{\"localhost\"},\n\t}\n\n\ttemplate := x509.Certificate{\n\t\tSerialNumber:          serialNumber,\n\t\tIssuer:                entity,\n\t\tSubject:               entity,\n\t\tNotBefore:             notBefore,\n\t\tNotAfter:              notAfter,\n\t\tKeyUsage:              x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature | x509.KeyUsageCertSign,\n\t\tBasicConstraintsValid: true,\n\t\tIsCA: true,\n\t}\n\n\t// collect IP addresses localhost resolves to and add them to the cert. template:\n\ttemplate.DNSNames = append(hostNames, \"localhost.local\")\n\tips, _ := net.LookupIP(\"localhost\")\n\tif ips != nil {\n\t\ttemplate.IPAddresses = ips\n\t}\n\tderBytes, err := x509.CreateCertificate(rand.Reader, &template, &template, &priv.PublicKey, priv)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tpublicKeyBytes, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &TLSCredentials{\n\t\tPublicKey:  pem.EncodeToMemory(&pem.Block{Type: \"RSA PUBLIC KEY\", Bytes: publicKeyBytes}),\n\t\tPrivateKey: pem.EncodeToMemory(&pem.Block{Type: \"RSA PRIVATE KEY\", Bytes: x509.MarshalPKCS1PrivateKey(priv)}),\n\t\tCert:       pem.EncodeToMemory(&pem.Block{Type: \"CERTIFICATE\", Bytes: derBytes}),\n\t}, nil\n}", "label": 5}
{"code": "protected function prepareQuery()\n    {\n        if (! $this->prepared) {\n            $this->totalRecords = $this->totalCount();\n\n            if ($this->totalRecords) {\n                $this->filterRecords();\n                $this->ordering();\n                $this->paginate();\n            }\n        }\n\n        $this->prepared = true;\n    }", "label": 2}
{"code": "public static boolean streamHasText(InputStream in, String text) {\n    final byte[] readBuffer = new byte[8192];\n\n    StringBuffer sb = new StringBuffer();\n    try {\n      if (in.available() > 0) {\n        int bytesRead = 0;\n        while ((bytesRead = in.read(readBuffer)) != -1) {\n          sb.append(new String(readBuffer, 0, bytesRead));\n\n          if (sb.toString().contains(text)) {\n            sb = null;\n            return true;\n          }\n        }\n      }\n    } catch (Exception e) {\n      e.printStackTrace();\n    } finally {\n      try {\n        in.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n\n    return false;\n  }", "label": 0}
{"code": "func (t *Torrent) offsetRequest(off int64) (req request, ok bool) {\n\treturn torrentOffsetRequest(*t.length, t.info.PieceLength, int64(t.chunkSize), off)\n}", "label": 5}
{"code": "public function sendDemoteParticipants($gId, $participant)\n    {\n        $msgId = $this->createMsgId();\n        $this->sendGroupsChangeParticipants($gId, $participant, 'demote', $msgId);\n    }", "label": 2}
{"code": "protected function getHeaders()\n    {\n        return [\n            'X-RateLimit-Limit' => $this->handler->getThrottleLimit(),\n            'X-RateLimit-Remaining' => $this->handler->getRemainingLimit(),\n            'X-RateLimit-Reset' => $this->handler->getRateLimitReset(),\n        ];\n    }", "label": 2}
{"code": "def associated_comments\n      @associated_comments ||= begin\n        result = {}\n        Parser::Source::Comment.associate_locations(node, comments).each_pair do |loc, all|\n          block = all #.select{ |l| l.document? || code.lines[l.loc.line].strip.start_with?('#')}\n          next if block.empty?\n          result[loc.line] ||= []\n          result[loc.line].concat block\n        end\n        result\n      end\n    end", "label": 4}
{"code": "def check_key(request):\n    \"\"\"\n    Check to see if we already have an access_key stored,\n    if we do then we have already gone through\n    OAuth. If not then we haven't and we probably need to.\n    \"\"\"\n    try:\n        access_key = request.session.get('oauth_token', None)\n        if not access_key:\n            return False\n    except KeyError:\n        return False\n    return True", "label": 1}
{"code": "protected function headers($headers)\n    {\n        $headers = collect($headers)->map(function ($header) {\n            return $header[0];\n        })->toArray();\n\n        return $this->hideParameters($headers,\n            Telescope::$hiddenRequestHeaders\n        );\n    }", "label": 2}
{"code": "function getModuleBody(flapjack) {\n    if (!flapjack) { return ''; }\n\n    var str = flapjack.toString();\n    var openingCurly = str.indexOf('{');\n    var closingCurly = str.lastIndexOf('}');\n\n    // if can't find the opening or closing curly, just return the entire string\n    if (openingCurly < 0 || closingCurly < 0) {\n        return str;\n    }\n\n    var body = str.substring(openingCurly + 1, closingCurly);\n    return body.replace(/\\n/g, '\\n\\t');\n}", "label": 3}
{"code": "private function getFieldNameForColumn($tableName, $columnName, $fk = false)\n    {\n        if (isset($this->fieldNamesForColumns[$tableName], $this->fieldNamesForColumns[$tableName][$columnName])) {\n            return $this->fieldNamesForColumns[$tableName][$columnName];\n        }\n\n        $columnName = strtolower($columnName);\n\n        // Replace _id if it is a foreignkey column\n        if ($fk) {\n            $columnName = str_replace('_id', '', $columnName);\n        }\n\n        return Inflector::camelize($columnName);\n    }", "label": 2}
{"code": "func sanitize(s string) string {\n\tt := \"\"\n\tfor _, r := range s {\n\t\tif t == \"\" {\n\t\t\tif unicode.IsLetter(r) || r == '_' {\n\t\t\t\tt += string(r)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t} else {\n\t\t\tif unicode.IsLetter(r) || unicode.IsDigit(r) || r == '_' {\n\t\t\t\tt += string(r)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tt += \"_\"\n\t}\n\tif t == \"_\" {\n\t\tt = \"x\"\n\t}\n\treturn t\n}", "label": 5}
{"code": "def lounge_update_license(self):\n        \"\"\"Download & install a license for your CDRouter system from the\n        CDRouter Support Lounge.\n\n        :return: :class:`system.Upgrade <system.Upgrade>` object\n        :rtype: system.Upgrade\n        \"\"\"\n        schema = UpgradeSchema()\n        resp = self.service.post(self.base+'license/')\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function compareMappingsDeep(mapping1, mapping2) {\n  return _.isEqualWith(mapping1, mapping2, (object1, object2, prop) => {\n    let mapping1 = { [prop]: object1 }\n    let mapping2 = { [prop]: object2 }\n    if (prop == \"from\" || prop == \"to\") {\n      if (!_.isEqual(Object.getOwnPropertyNames(_.get(object1, prop, {})), Object.getOwnPropertyNames(_.get(object2, prop, {})))) {\n        return false\n      }\n      return _.isEqualWith(conceptsOfMapping(mapping1, prop), conceptsOfMapping(mapping2, prop), (concept1, concept2, index) => {\n        if (index != undefined) {\n          return compare(concept1, concept2)\n        }\n        return undefined\n      })\n    }\n    if (prop == \"fromScheme\" || prop == \"toScheme\") {\n      return compare(object1, object2)\n    }\n    // Let lodash's isEqual do the comparison\n    return undefined\n  })\n}", "label": 3}
{"code": "public static base_response add(nitro_service client, policystringmap resource) throws Exception {\n\t\tpolicystringmap addresource = new policystringmap();\n\t\taddresource.name = resource.name;\n\t\taddresource.comment = resource.comment;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def config\n      @config ||= begin\n        conf = Bolt::Config.new(Bolt::Boltdir.new('.'), {})\n        conf.modulepath = [modulepath].flatten\n        conf\n      end\n    end", "label": 4}
{"code": "def add_resource_fragment(fragment, include_related)\n      init_included_relationships(fragment, include_related)\n\n      fragment.related_from.each do |rid|\n        @source_resource_id_tree.fragments[rid].add_related_identity(parent_relationship.name, fragment.identity)\n      end\n\n      @fragments[fragment.identity] = fragment\n    end", "label": 4}
{"code": "function getHtml(methods) {\n    return [\n        '<!doctype html>',\n        '<html lang=\"en\">',\n            '<head>',\n                '<title>API Index</title>',\n                '<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>',\n                '<link rel=\"stylesheet\" href=\"//yastatic.net/bootstrap/3.1.1/css/bootstrap.min.css\"/>',\n            '</head>',\n            '<body class=\"container\">',\n                '<div class=\"col-md-7\">',\n                    Object.keys(methods).map(function (name) {\n                        return getMethodHtml(methods[name]);\n                    }).join(''),\n                '</div>',\n            '</body>',\n        '</html>'\n    ].join('');\n}", "label": 3}
{"code": "func (s *Service) RegisterSDK(r *Registry) {\n\tif s.ServeMux == nil {\n\t\ts.ServeMux = http.NewServeMux()\n\t}\n\n\ts.sdk[r.Path] = r\n\ts.ServeMux.HandleFunc(r.Path, s.ServeSDK)\n}", "label": 5}
{"code": "function (req, res) {\n\t\tLOG.warn('handle_request');\n\n\t\t// attach custom res methods (borrowed from express)\n\t\tres = UTIL.mixin(res, response);\n\n\t\tLOG.sys('HTTP req received, header', 'SR.REST');\n\t\tLOG.sys(req.headers, 'SR.REST');\n\t\t\n\t\tvar content_type = req.headers['content-type'];\n\n\t\t// NOTE: multi-part needs to be handled first, because req.on('data') will not be able to process correctly\n\t\tif (typeof content_type === 'string' && content_type.startsWith('multipart/form-data; boundary=')) { \n\t\t\tLOG.warn('parsing form request...', 'SR.REST');\n\t\t\troute(req, res);\n\t\t\treturn;\n\t\t}\n\t\t\n\t\t// temp buffer for incoming request\n\t\tvar data = '';\n\t\tvar JSONobj = undefined;\n\t\t\n\t\treq.on('data', function (chunk) {\n\t\t\tdata += chunk;\n\t\t});\n\n\t\treq.on('end', function () {\n\t\t\t\n\t\t\tvar JSONobj = undefined;\n\t\t\t\n\t\t\ttry {\n\t\t\t\tif (data !== '') {\n\t\t\t\t\t\t\n\t\t\t\t\tif (content_type.startsWith('application/x-www-form-urlencoded')) {\n\t\t\t\t\t\tJSONobj = qs.parse(data);\n\t\t\t\t\t} else if (content_type.startsWith('application/json')) {\n\t\t\t\t\t\tJSONobj = UTIL.convertJSON(decodeURIComponent(data));\n\t\t\t\t\t} else if (content_type.startsWith('application/sdp')) {\n\t\t\t\t\t\tJSONobj = data;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tvar msg = 'content type not known: ' + content_type;\n\t\t\t\t\t\tLOG.warn(msg, 'SR.REST');\n\t\t\t\t\t\tSR.REST.reply(res, msg);\n\t\t\t\t\t\t//res.writeHead(200, {'Content-Type': 'text/plain'});\n\t\t\t\t\t\t//res.end(msg);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\tvar msg = 'JSON parsing error for data: ' + data + '\\n content_type: ' + content_type;\n\t\t\t\tLOG.error(msg, 'SR.REST');\n\t\t\t\t//res.writeHead(200, {'Content-Type': 'text/plain'});\n\t\t\t\t//res.end(msg);\n\t\t\t\tSR.REST.reply(res, msg);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\troute(req, res, JSONobj);\n\t\t})\n\t}", "label": 3}
{"code": "def _process_consensus_mhcii(mhc_file, normal=False):\n    \"\"\"\n    Process the results from running IEDB MHCII binding predictions using the consensus method into\n    a pandas dataframe.\n\n    :param str mhc_file: Output file containing consensus mhcii:peptide binding predictions\n    :param bool normal: Is this processing the results of a normal?\n    :return: Results in a tabular format\n    :rtype: pandas.DataFrame\n    \"\"\"\n    core_col = None  # Variable to hold the column number with the core\n    results = pandas.DataFrame(columns=['allele', 'pept', 'tumor_pred', 'core'])\n    with open(mhc_file, 'r') as mf:\n        peptides = set()\n        for line in mf:\n            # Skip header lines\n            if not line.startswith('HLA'):\n                continue\n            line = line.strip().split('\\t')\n            allele = line[0]\n            pept = line[4]\n            pred = line[6]\n            if core_col:\n                core = line[core_col]\n            else:\n                methods = line[5].lstrip('Consensus(').rstrip(')')\n                methods = methods.split(',')\n                if 'NN' in methods:\n                    core_col = 13\n                elif 'netMHCIIpan' in methods:\n                    core_col = 17\n                elif 'Sturniolo' in methods:\n                    core_col = 19\n                elif 'SMM' in methods:\n                    core_col = 10\n                core = line[core_col] if core_col else 'NOCORE'\n            if float(pred) > 5.00 and not normal:\n                continue\n            results.loc[len(results)] = [allele, pept, pred, core]\n    results.drop_duplicates(inplace=True)\n    return results", "label": 1}
{"code": "private void buildMultiJoinTree(TableAlias left, ClassDescriptor cld, String name, boolean useOuterJoin)\r\n    {\r\n        DescriptorRepository repository = cld.getRepository();\r\n        Class[] multiJoinedClasses = repository.getSubClassesMultipleJoinedTables(cld, false);\r\n\r\n        for (int i = 0; i < multiJoinedClasses.length; i++)\r\n        {\r\n            ClassDescriptor subCld = repository.getDescriptorFor(multiJoinedClasses[i]);\r\n            SuperReferenceDescriptor srd = subCld.getSuperReference();\r\n            if (srd != null)\r\n            {\r\n                FieldDescriptor[] leftFields = subCld.getPkFields();\r\n                FieldDescriptor[] rightFields = srd.getForeignKeyFieldDescriptors(subCld);\r\n                TableAlias base_alias = getTableAliasForPath(name, null, null);\r\n\r\n                String aliasName = String.valueOf(getAliasChar()) + m_aliasCount++;\r\n                TableAlias right = new TableAlias(subCld, aliasName, false, null);\r\n\r\n                Join join1to1 = new Join(left, leftFields, right, rightFields, useOuterJoin, \"subClass\");\r\n                base_alias.addJoin(join1to1);\r\n\r\n                buildMultiJoinTree(right, subCld, name, useOuterJoin);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public void forAllProcedures(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (Iterator it = _curClassDef.getProcedures(); it.hasNext(); )\r\n        {\r\n            _curProcedureDef = (ProcedureDef)it.next();\r\n            generate(template);\r\n        }\r\n        _curProcedureDef = null;\r\n    }", "label": 0}
{"code": "func (s *localSite) findMatchingConn(principals []string) (*remoteConn, bool) {\n\tfor _, principal := range principals {\n\t\trconn, err := s.getConn(principal)\n\t\tif err == nil {\n\t\t\treturn rconn, true\n\t\t}\n\t}\n\treturn nil, false\n}", "label": 5}
{"code": "def invoke_select(object, question, *args, &block)\n      options = Utils.extract_options!(args)\n      choices = if block\n                  []\n                elsif args.empty?\n                  possible = options.dup\n                  options = {}\n                  possible\n                elsif args.size == 1 && args[0].is_a?(Hash)\n                  Utils.extract_options!(args)\n                else\n                  args.flatten\n                end\n\n      list = object.new(self, options)\n      list.(question, choices, &block)\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, systemcollectionparam resource) throws Exception {\n\t\tsystemcollectionparam updateresource = new systemcollectionparam();\n\t\tupdateresource.communityname = resource.communityname;\n\t\tupdateresource.loglevel = resource.loglevel;\n\t\tupdateresource.datapath = resource.datapath;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "function (chart, options) {\n            var series = this,\n              eventType,\n              events,\n              chartSeries = chart.series,\n              sortByIndex = function (a, b) {\n                  return pick(a.options.index, a._i) - pick(b.options.index, b._i);\n              };\n\n            series.chart = chart;\n            series.options = options = series.setOptions(options); // merge with plotOptions\n            series.linkedSeries = [];\n\n            // bind the axes\n            series.bindAxes();\n\n            // set some variables\n            extend(series, {\n                name: options.name,\n                state: NORMAL_STATE,\n                pointAttr: {},\n                visible: options.visible !== false, // true by default\n                selected: options.selected === true // false by default\n            });\n\n            // special\n            if (useCanVG) {\n                options.animation = false;\n            }\n\n            // register event listeners\n            events = options.events;\n            for (eventType in events) {\n                addEvent(series, eventType, events[eventType]);\n            }\n            if (\n              (events && events.click) ||\n              (options.point && options.point.events && options.point.events.click) ||\n              options.allowPointSelect\n            ) {\n                chart.runTrackerClick = true;\n            }\n\n            series.getColor();\n            series.getSymbol();\n\n            // Set the data\n            each(series.parallelArrays, function (key) {\n                series[key + 'Data'] = [];\n            });\n            series.setData(options.data, false);\n\n            // Mark cartesian\n            if (series.isCartesian) {\n                chart.hasCartesianSeries = true;\n            }\n\n            // Register it in the chart\n            chartSeries.push(series);\n            series._i = chartSeries.length - 1;\n\n            // Sort series according to index option (#248, #1123, #2456)\n            stableSort(chartSeries, sortByIndex);\n            if (this.yAxis) {\n                stableSort(this.yAxis.series, sortByIndex);\n            }\n\n            each(chartSeries, function (series, i) {\n                series.index = i;\n                series.name = series.name || 'Series ' + (i + 1);\n            });\n\n        }", "label": 3}
{"code": "public static tunnelip_stats[] get(nitro_service service) throws Exception{\n\t\ttunnelip_stats obj = new tunnelip_stats();\n\t\ttunnelip_stats[] response = (tunnelip_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static filterpolicy get(nitro_service service, String name) throws Exception{\n\t\tfilterpolicy obj = new filterpolicy();\n\t\tobj.set_name(name);\n\t\tfilterpolicy response = (filterpolicy) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _check_root_tag(self, root):\n        \"\"\"Check that the XML element tree has a supported root element.\n\n        Args:\n            root (etree.Element)\n\n        Raises:\n            UnsupportedRootElementError\n        \"\"\"\n        supported = self.supported_tags()\n        if root.tag in supported:\n            return\n\n        error = \"Document root element ({0}) not one of ({1})\"\n        raise UnsupportedRootElementError(\n            message=error.format(root.tag, supported),\n            expected=supported,\n            found=root.tag,\n        )", "label": 1}
{"code": "function getWordLengthFromCollection( string, collection, dateObject ) {\n\n        // Grab the first word from the string.\n        var word = string.match( /\\w+/ )[ 0 ]\n\n        // If there's no month index, add it to the date object\n        if ( !dateObject.mm && !dateObject.m ) {\n            dateObject.m = collection.indexOf( word ) + 1\n        }\n\n        // Return the length of the word.\n        return word.length\n    }", "label": 3}
{"code": "func (c *Client) LoadThumbprints(file string) error {\n\tif file == \"\" {\n\t\treturn nil\n\t}\n\n\tfor _, name := range filepath.SplitList(file) {\n\t\terr := c.loadThumbprints(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function setAuthInfo($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\UptimeCheckConfig_HttpCheck_BasicAuthentication::class);\n        $this->auth_info = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public double distanceToPlane(Point3d p) {\n        return normal.x * p.x + normal.y * p.y + normal.z * p.z - planeOffset;\n    }", "label": 0}
{"code": "def facets(params = nil)\n      raise RemovedFeature, 'removed in elasticsearch 2.0' if Runtime.version >= '2.0'\n      if params\n        chain { criteria.update_facets params }\n      else\n        _response['facets'] || {}\n      end\n    end", "label": 4}
{"code": "def cors_headers\n      rack = Jets::Controller::Middleware::Cors.new(Jets.application)\n      rack.cors_headers(true)\n    end", "label": 4}
{"code": "func (c *Config) LoadDefaultScopes(dataDir string) {\n\tfor k, v := range datastore.DefaultScopes(dataDir) {\n\t\tif _, ok := c.Scopes[k]; !ok {\n\t\t\tc.Scopes[k] = v\n\t\t}\n\t}\n}", "label": 5}
{"code": "public static <T> T columnStringToObject(Class objClass, String str, String delimiterRegex, String[] fieldNames)\r\n          throws InstantiationException, IllegalAccessException, NoSuchFieldException, NoSuchMethodException, InvocationTargetException\r\n  {\r\n    Pattern delimiterPattern = Pattern.compile(delimiterRegex);\r\n    return StringUtils.<T>columnStringToObject(objClass, str, delimiterPattern, fieldNames);\r\n  }", "label": 0}
{"code": "func GetMacCopy(from net.HardwareAddr) net.HardwareAddr {\n\tif from == nil {\n\t\treturn nil\n\t}\n\tto := make(net.HardwareAddr, len(from))\n\tcopy(to, from)\n\treturn to\n}", "label": 5}
{"code": "def iterations=(n)\n      n = Integer(n)\n      Kernel.raise ArgumentError, 'iterations must be between 0 and 65535' if n < 0 || n > 65_535\n      @images.each { |f| f.iterations = n }\n      self\n    end", "label": 4}
{"code": "def from_obj(cls, cls_obj):\n        \"\"\"Parse the generateDS object and return an Entity instance.\n\n        This will attempt to extract type information from the input\n        object and pass it to entity_class to resolve the correct class\n        for the type.\n\n        Args:\n            cls_obj: A generateDS object.\n\n        Returns:\n            An Entity instance.\n        \"\"\"\n        if not cls_obj:\n            return None\n\n        typekey = cls.objkey(cls_obj)\n        klass   = cls.entity_class(typekey)\n        return klass.from_obj(cls_obj)", "label": 1}
{"code": "private FieldDescriptor getFldFromJoin(TableAlias aTableAlias, String aColName)\r\n    {\r\n        FieldDescriptor fld = null;\r\n\r\n        // Search Join Structure for attribute\r\n        if (aTableAlias.joins != null)\r\n        {\r\n            Iterator itr = aTableAlias.joins.iterator();\r\n            while (itr.hasNext())\r\n            {\r\n                Join join = (Join) itr.next();\r\n                ClassDescriptor cld = join.right.cld;\r\n\r\n                if (cld != null)\r\n                {\r\n                    fld = cld.getFieldDescriptorByName(aColName);\r\n                    if (fld != null)\r\n                    {\r\n                        break;\r\n                    }\r\n\r\n                }\r\n            }\r\n        }\r\n        return fld;\r\n    }", "label": 0}
{"code": "func (b *BoxLayout) SetView(view View) {\n\tb.changed = true\n\tb.view = view\n\tfor _, c := range b.cells {\n\t\tc.view.SetView(view)\n\t}\n}", "label": 5}
{"code": "def open_connection(ip, username, password, function, args, write=False,\n                    conn_timeout=5, sess_timeout=300, port=22):\n    \"\"\" Open a Jaide session with the device.\n\n    To open a Jaide session to the device, and run the appropriate function\n    against the device. Arguments for the downstream function are passed\n    through.\n\n    @param ip: String of the IP or hostname of the device to connect to.\n    @type ip: str\n    @param username: The string username used to connect to the device.\n    @type useranme: str\n    @param password: The string password used to connect to the device.\n    @type password: str\n    @param function: The downstream jaide.wrap function we'll be handing\n                   | off the jaide.Jaide() object to execute the command\n                   | once we've established the connection.\n    @type function: function pointer.\n    @param args: The arguments that we will hand off to the downstream\n               | function.\n    @type args: list\n    @param write: If set, it would be a tuple that we pass back as part of\n                | our return statement, so that any callback function\n                | can know how and where to put the output from the device.\n    @type write: False or tuple.\n    @param conn_timeout: Sets the connection timeout value. This is how\n                       | we'll wait when connecting before classifying\n                       | the device unreachable.\n    @type conn_timeout: int\n    @param sess_timeout: Sets the session timeout value. A higher value may\n                       | be desired for long running commands, such as\n                       | 'request system snapshot slice alternate'\n    @type sess_timeout: int\n    @param port: The port to connect to the device on. Defaults to 22.\n    @type port: int\n\n    @returns: We could return either just a string of the output from the\n            | device, or a tuple containing the information needed to write\n            | to a file and the string output from the device.\n    @rtype: Tuple or str\n    \"\"\"\n    # start with the header line on the output.\n    output = color('=' * 50 + '\\nResults from device: %s\\n' % ip, 'yel')\n    try:\n        # create the Jaide session object for the device.\n        conn = Jaide(ip, username, password, connect_timeout=conn_timeout,\n                     session_timeout=sess_timeout, port=port)\n        if write is not False:\n            return write, output + function(conn, *args)\n        else:\n            return output + function(conn, *args)\n    except errors.SSHError:\n        output += color('Unable to connect to port %s on device: %s\\n' %\n                        (str(port), ip), 'red')\n    except errors.AuthenticationError:  # NCClient auth failure\n        output += color('Authentication failed for device: %s' % ip, 'red')\n    except AuthenticationException:  # Paramiko auth failure\n        output += color('Authentication failed for device: %s' % ip, 'red')\n    except SSHException as e:\n        output += color('Error connecting to device: %s\\nError: %s' %\n                        (ip, str(e)), 'red')\n    except socket.timeout:\n        output += color('Timeout exceeded connecting to device: %s' % ip, 'red')\n    except socket.gaierror:\n        output += color('No route to host, or invalid hostname: %s' % ip, 'red')\n    except socket.error:\n        output += color('The device refused the connection on port %s, or '\n                        'no route to host.' % port, 'red')\n    if write is not False:\n        return write, output\n    else:\n        return output", "label": 1}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getTable($options + $this->identity);\n    }", "label": 2}
{"code": "public static double JensenShannonDivergence(double[] p, double[] q) {\n        double[] m = new double[p.length];\n        for (int i = 0; i < m.length; i++) {\n            m[i] = (p[i] + q[i]) / 2;\n        }\n\n        return (KullbackLeiblerDivergence(p, m) + KullbackLeiblerDivergence(q, m)) / 2;\n    }", "label": 0}
{"code": "def set_request_body!(request)\n      case @request_format\n        when :json then request.body = (camelize_keys! @body).to_json\n        when :form then request.set_form_data @body\n        when :file then request.body_stream = @body\n      end if @body\n    end", "label": 4}
{"code": "public MtasCQLParserSentenceCondition createFullSentence()\n      throws ParseException {\n    if (fullCondition == null) {\n      if (secondSentencePart == null) {\n        if (firstBasicSentence != null) {\n          fullCondition = new MtasCQLParserSentenceCondition(firstBasicSentence,\n              ignoreClause, maximumIgnoreLength);\n\n        } else {\n          fullCondition = firstSentence;\n        }\n        fullCondition.setOccurence(firstMinimumOccurence,\n            firstMaximumOccurence);\n        if (firstOptional) {\n          fullCondition.setOptional(firstOptional);\n        }\n        return fullCondition;\n      } else {\n        if (!orOperator) {\n          if (firstBasicSentence != null) {\n            firstBasicSentence.setOccurence(firstMinimumOccurence,\n                firstMaximumOccurence);\n            firstBasicSentence.setOptional(firstOptional);\n            fullCondition = new MtasCQLParserSentenceCondition(\n                firstBasicSentence, ignoreClause, maximumIgnoreLength);\n          } else {\n            firstSentence.setOccurence(firstMinimumOccurence,\n                firstMaximumOccurence);\n            firstSentence.setOptional(firstOptional);\n            fullCondition = new MtasCQLParserSentenceCondition(firstSentence,\n                ignoreClause, maximumIgnoreLength);\n          }\n          fullCondition.addSentenceToEndLatestSequence(\n              secondSentencePart.createFullSentence());\n        } else {\n          MtasCQLParserSentenceCondition sentence = secondSentencePart\n              .createFullSentence();\n          if (firstBasicSentence != null) {\n            sentence.addSentenceAsFirstOption(\n                new MtasCQLParserSentenceCondition(firstBasicSentence,\n                    ignoreClause, maximumIgnoreLength));\n          } else {\n            sentence.addSentenceAsFirstOption(firstSentence);\n          }\n          fullCondition = sentence;\n        }\n        return fullCondition;\n      }\n    } else {\n      return fullCondition;\n    }\n  }", "label": 0}
{"code": "public void drawImage(Image img, Rectangle rect, Rectangle clipRect, float opacity) {\n\t\ttry {\n\t\t\ttemplate.saveState();\n\t\t\t// opacity\n\t\t\tPdfGState state = new PdfGState();\n\t\t\tstate.setFillOpacity(opacity);\n\t\t\tstate.setBlendMode(PdfGState.BM_NORMAL);\n\t\t\ttemplate.setGState(state);\n\t\t\t// clipping code\n\t\t\tif (clipRect != null) {\n\t\t\t\ttemplate.rectangle(clipRect.getLeft() + origX, clipRect.getBottom() + origY, clipRect.getWidth(),\n\t\t\t\t\t\tclipRect.getHeight());\n\t\t\t\ttemplate.clip();\n\t\t\t\ttemplate.newPath();\n\t\t\t}\n\t\t\ttemplate.addImage(img, rect.getWidth(), 0, 0, rect.getHeight(), origX + rect.getLeft(), origY\n\t\t\t\t\t+ rect.getBottom());\n\t\t} catch (DocumentException e) {\n\t\t\tlog.warn(\"could not draw image\", e);\n\t\t} finally {\n\t\t\ttemplate.restoreState();\n\t\t}\n\t}", "label": 0}
{"code": "def reset(self):\n        \"\"\" Resets the state of the expression \"\"\"\n        self.expr = []\n        self.matcher = None\n        self.last_matcher = None\n        self.description = None", "label": 1}
{"code": "public function getSignedCookie($url = null, $expires = null, $policy = null)\n    {\n        if ($url) {\n            $this->validateUrl($url);\n        }\n\n        $cookieParameters = [];\n        $signature = $this->signer->getSignature($url, $expires, $policy);\n        foreach ($signature as $key => $value) {\n            $cookieParameters[\"CloudFront-$key\"] = $value;\n        }\n\n        return $cookieParameters;\n    }", "label": 2}
{"code": "public void deletePersistent(Object object)\r\n    {\r\n        if (!this.isOpen())\r\n        {\r\n            throw new DatabaseClosedException(\"Database is not open\");\r\n        }\r\n        TransactionImpl tx = getTransaction();\r\n        if (tx == null || !tx.isOpen())\r\n        {\r\n            throw new TransactionNotInProgressException(\"No transaction in progress, cannot delete persistent\");\r\n        }\r\n        RuntimeObject rt = new RuntimeObject(object, tx);\r\n        tx.deletePersistent(rt);\r\n//        tx.moveToLastInOrderList(rt.getIdentity());\r\n    }", "label": 0}
{"code": "function get(connections, params, cb) {\n  var failed = validate(params).has(CONSTANTS.DATA_TARGET_ID);\n\n  if (failed) {\n    return cb(buildErrorResponse({error: new Error(\"An ID Parameter Is Required To Get A Data Target\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n  }\n\n  if (!misc.checkId(params._id)) {\n    return cb(buildErrorResponse({error: new Error(\"Invalid ID Paramter\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n  }\n\n  async.waterfall([\n    function findDataTargets(cb) {\n      var query = {\n\n      };\n\n      //Searching By ID.\n      query[CONSTANTS.DATA_TARGET_ID] = params._id;\n\n      lookUpDataTargets(connections, {\n        query: query,\n        lean: true\n      }, function(err, dataTargets) {\n        if (err) {\n          return cb(buildErrorResponse({\n            error: err,\n            userDetail: \"Unexpected Error When Searching For A Data Target\",\n            code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n          }));\n        }\n\n        //Checking if the Data Target exists. Should be only one\n        if (dataTargets.length !== 1) {\n          return cb(buildErrorResponse({\n            error: new Error(\"Data Target Not Found\"),\n            systemDetail: \"Requested ID: \"  + params[CONSTANTS.DATA_TARGET_ID],\n            code: ERROR_CODES.FH_FORMS_NOT_FOUND\n          }));\n        }\n\n        return cb(undefined, dataTargets[0]);\n      });\n    },\n    function checkForms(dataTargetJSON, cb) {\n      //Checking For Any Forms Associated With The Data Target\n      checkFormsUsingDataTarget(connections, dataTargetJSON, cb);\n    }\n  ], cb);\n}", "label": 3}
{"code": "def get(self, id, seq, line): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param line: Line number in TestResult's logfile as an int.\n        :return: :class:`highlights.Highlight <highlights.Highlight>` object\n        \"\"\"\n        schema = HighlightSchema()\n        resp = self.service.get_id(self._base(id, seq), line)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "def method(self, symbol):\n        '''\n        Symbol decorator.\n        '''\n        assert issubclass(symbol, SymbolBase)\n        def wrapped(fn):\n            setattr(symbol, fn.__name__, fn)\n        return wrapped", "label": 1}
{"code": "def process_build_metrics(context, build_processors):\n    \"\"\"use processors to collect build metrics.\"\"\"\n    build_metrics = OrderedDict()\n\n    # reset all processors\n    for p in build_processors:\n        p.reset()\n\n    # collect metrics from all processors\n    for p in build_processors:\n        build_metrics.update(p.build_metrics)\n\n    return build_metrics", "label": 1}
{"code": "public static function referenceImageName($project, $location, $product, $referenceImage)\n    {\n        return self::getReferenceImageNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'product' => $product,\n            'reference_image' => $referenceImage,\n        ]);\n    }", "label": 2}
{"code": "public static base_response enable(nitro_service client) throws Exception {\n\t\treporting enableresource = new reporting();\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "function env(environment) {\n  environment = environment || {};\n\n  if ('object' === typeof process && 'object' === typeof process.env) {\n    env.merge(environment, process.env);\n  }\n\n  if ('undefined' !== typeof window) {\n    if ('string' === window.name && window.name.length) {\n      env.merge(environment, env.parse(window.name));\n    }\n\n    if (window.localStorage) {\n      try { env.merge(environment, env.parse(window.localStorage.env || window.localStorage.debug)); }\n      catch (e) {}\n    }\n\n    if (\n         'object' === typeof window.location\n      && 'string' === typeof window.location.hash\n      && window.location.hash.length\n    ) {\n      env.merge(environment, env.parse(window.location.hash.charAt(0) === '#'\n        ? window.location.hash.slice(1)\n        : window.location.hash\n      ));\n    }\n  }\n\n  //\n  // Also add lower case variants to the object for easy access.\n  //\n  var key, lower;\n  for (key in environment) {\n    lower = key.toLowerCase();\n\n    if (!(lower in environment)) {\n      environment[lower] = environment[key];\n    }\n  }\n\n  return environment;\n}", "label": 3}
{"code": "def _create_tracked_field(event, instance, field, fieldname=None):\n    \"\"\"\n    Create a TrackedFieldModification for the instance.\n\n    :param event: The TrackingEvent on which to add TrackingField\n    :param instance: The instance on which the field is\n    :param field: The field name to track\n    :param fieldname: The displayed name for the field. Default to field.\n    \"\"\"\n    fieldname = fieldname or field\n    if isinstance(instance._meta.get_field(field), ForeignKey):\n        # We only have the pk, we need to get the actual object\n        model = instance._meta.get_field(field).remote_field.model\n        pk = instance._original_fields[field]\n        try:\n            old_value = model.objects.get(pk=pk)\n        except model.DoesNotExist:\n            old_value = None\n    else:\n        old_value = instance._original_fields[field]\n    return TrackedFieldModification.objects.create(\n        event=event,\n        field=fieldname,\n        old_value=_serialize_field(old_value),\n        new_value=_serialize_field(getattr(instance, field))\n    )", "label": 1}
{"code": "function commentStrip(string) {\n  // Remove commented lines\n  string = string.replace(RE_COMMENT_SINGLE_LINE, '');\n  string = string.replace(RE_COMMENT_MULTI_LINES, '');\n  return string;\n}", "label": 3}
{"code": "public Set<ConstraintViolation> validate(int record) {\r\n\t\tSet<ConstraintViolation> errors = new LinkedHashSet<ConstraintViolation>();\r\n\t\tfor (int ds = 0; ds < 250; ++ds) {\r\n\t\t\ttry {\r\n\t\t\t\tDataSetInfo dataSetInfo = dsiFactory.create(IIM.DS(record, ds));\r\n\t\t\t\terrors.addAll(validate(dataSetInfo));\r\n\t\t\t} catch (InvalidDataSetException ignored) {\r\n\t\t\t\t// DataSetFactory doesn't know about this ds, so will skip it\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn errors;\r\n\t}", "label": 0}
{"code": "function initBLModel(soajs, cb) {\n    let modelName = driverConfig.model;\n    if (soajs.servicesConfig && soajs.servicesConfig.model) {\n        modelName = soajs.servicesConfig.model;\n    }\n    if (process.env.SOAJS_TEST && soajs.inputmaskData && soajs.inputmaskData.model) {\n        modelName = soajs.inputmaskData.model;\n    }\n\n    let modelPath = __dirname + \"/model/\" + modelName + \".js\";\n    return requireModel(modelPath, cb);\n\n    /**\n     * checks if model file exists, requires it and returns it.\n     * @param filePath\n     * @param cb\n     */\n    function requireModel(filePath, cb) {\n        //check if file exist. if not return error\n        fs.exists(filePath, function (exists) {\n            if (!exists) {\n                soajs.log.error('Requested Model Not Found!');\n                return cb(601);\n            }\n\n            driver.model = require(filePath);\n            return cb();\n        });\n    }\n\n}", "label": 3}
{"code": "public static base_response add(nitro_service client, appfwxmlcontenttype resource) throws Exception {\n\t\tappfwxmlcontenttype addresource = new appfwxmlcontenttype();\n\t\taddresource.xmlcontenttypevalue = resource.xmlcontenttypevalue;\n\t\taddresource.isregex = resource.isregex;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def fq_name(self):\n        \"\"\"Return FQDN of the resource\n\n        :rtype: FQName\n        \"\"\"\n        return self.get('fq_name', self.get('to', super(Resource, self).fq_name))", "label": 1}
{"code": "def prepare_shell_data(self, shells, key, entry):\n        \"\"\"Prepare one shell or docker task.\"\"\"\n        if self.can_process_shell(entry):\n            if key in ['python']:\n                entry['type'] = key\n\n            if 'with' in entry and isinstance(entry['with'], str):\n                rendered_with = ast.literal_eval(render(entry['with'],\n                                                        variables=self.pipeline.variables,\n                                                        model=self.pipeline.model,\n                                                        env=self.get_merged_env(include_os=True)))\n            elif 'with' in entry:\n                rendered_with = entry['with']\n            else:\n                rendered_with = ['']\n\n            for item in rendered_with:\n                shells.append({\n                    'id': self.next_task_id,\n                    'creator': key,\n                    'entry': entry,\n                    'model': self.pipeline.model,\n                    'env': self.get_merged_env(),\n                    'item': item,\n                    'dry_run': self.pipeline.options.dry_run,\n                    'debug': self.pipeline.options.debug,\n                    'strict': self.pipeline.options.strict,\n                    'variables': self.pipeline.variables,\n                    'temporary_scripts_path': self.pipeline.options.temporary_scripts_path})\n                self.next_task_id += 1", "label": 1}
{"code": "function line_number(index, source) {\n  // To speed things up, remember the index until which we counted,\n  // then next time just begin counting from there.  This way we\n  // only count each line once.\n  var i = start_index;\n  var count = 0;\n  while (i < index) {\n    if (source[i] === \"\\n\") {\n      count++;\n    }\n    i++;\n  }\n\n  start_linenr = count + start_linenr;\n  start_index = index;\n\n  return start_linenr;\n}", "label": 3}
{"code": "public function setVariableTable($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Debugger\\V2\\Variable::class);\n        $this->variable_table = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (a *ArgType) colname(col *models.Column) string {\n\tif a.EscapeColumnNames {\n\t\treturn a.Loader.Escape(ColumnEsc, col.ColumnName)\n\t}\n\n\treturn col.ColumnName\n}", "label": 5}
{"code": "function shouldRenameDeclaration(name, path, binding, rootScope) {\n  const isRootScope = path.scope === rootScope;\n  const isGlobal = isRootScope && name in rootScope.globals;\n  const program = rootScope.path;\n\n  if (isGlobal) return false;\n\n  if (!isRootScope) {\n    const functionParent = path.getFunctionParent();\n    const declarationParent = getDeclarationParent(path);\n\n    // Bail if not a declaration or is property/key of object\n    if (!declarationParent || isPropertyOrKey(path)) return false;\n\n    if (declarationParent.isBlockScoped()) {\n      // Handle function declaration (which defines it's own scope)\n      if (declarationParent.isFunctionDeclaration()) {\n        return declarationParent.parentPath.scope === rootScope && declarationParent.node.id === path.node;\n      }\n      // Skip let/const in block scope\n      return false;\n      // Handle re-assignment of root bound declaration (ignore function expressions)\n    } else if (declarationParent.isAssignmentExpression() && !path.parentPath.isFunctionExpression()) {\n      const declarationBinding = declarationParent.scope.getBinding(name);\n\n      return declarationBinding ? declarationBinding.scope === rootScope : false;\n      // Skip if in function scope\n    } else if (functionParent !== program) {\n      return false;\n    }\n  }\n\n  // Skip if property or key of object\n  return !isPropertyOrKey(path);\n}", "label": 3}
{"code": "function (uid, token) {\n\t\t\n\t\t// TODO: check if local account already exists, or replace existing one\n\t\t\n\t\t// multiple accounts storable for one local server\n\t\t// NOTE: field name is a variable\n\t\t// ref: http://stackoverflow.com/questions/11133912/how-to-use-a-variable-as-a-field-name-in-mongodb-native-findandmodify\t\t\n\t\tvar field = 'data.accounts.' + server + '.' + uid;\n\t\t\n\t\tvar onUpdated = function (error) {\n\t\t\tif (error) {\n\t\t\t\tvar err = new Error(\"ADD_LOCAL_ACCOUNT_FAIL: \" + account);\n\t\t\t\terr.name = \"addLocal Error\";\n\t\t\t\terr.code = 1;\n\t\t\t\tUTIL.safeCall(onDone, err);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tUTIL.safeCall(onDone, null, {code: 0, msg: 'ADD_LOCAL_ACCOUNT_SUCCESS: ' + account});\n\t\t\t}\n\t\t};\n\t\tl_updateUser({account: account}, field, token, onUpdated);\n\t}", "label": 3}
{"code": "@PostConstruct\n\tprotected void checkPluginDependencies() throws GeomajasException {\n\t\tif (\"true\".equals(System.getProperty(\"skipPluginDependencyCheck\"))) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (null == declaredPlugins) {\n\t\t\treturn;\n\t\t}\n\n\t\t// start by going through all plug-ins to build a map of versions for plug-in keys\n\t\t// includes verification that each key is only used once\n\t\tMap<String, String> versions = new HashMap<String, String>();\n\t\tfor (PluginInfo plugin : declaredPlugins.values()) {\n\t\t\tString name = plugin.getVersion().getName();\n\t\t\tString version = plugin.getVersion().getVersion();\n\t\t\t// check for multiple plugin with same name but different versions (duplicates allowed for jar+source dep)\n\t\t\tif (null != version) {\n\t\t\t\tString otherVersion = versions.get(name);\n\t\t\t\tif (null != otherVersion) {\n\t\t\t\t\tif (!version.startsWith(EXPR_START)) {\n\t\t\t\t\t\tif (!otherVersion.startsWith(EXPR_START) && !otherVersion.equals(version)) {\n\t\t\t\t\t\t\tthrow new GeomajasException(ExceptionCode.DEPENDENCY_CHECK_INVALID_DUPLICATE,\n\t\t\t\t\t\t\t\t\tname, version, versions.get(name));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tversions.put(name, version);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tversions.put(name, version);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Check dependencies\n\t\tStringBuilder message = new StringBuilder();\n\t\tString backendVersion = versions.get(\"Geomajas\");\n\t\tfor (PluginInfo plugin : declaredPlugins.values()) {\n\t\t\tString name = plugin.getVersion().getName();\n\t\t\tmessage.append(checkVersion(name, \"Geomajas back-end\", plugin.getBackendVersion(), backendVersion));\n\t\t\tList<PluginVersionInfo> dependencies = plugin.getDependencies();\n\t\t\tif (null != dependencies) {\n\t\t\t\tfor (PluginVersionInfo dependency : plugin.getDependencies()) {\n\t\t\t\t\tString depName = dependency.getName();\n\t\t\t\t\tmessage.append(checkVersion(name, depName, dependency.getVersion(), versions.get(depName)));\n\t\t\t\t}\n\t\t\t}\n\t\t\tdependencies = plugin.getOptionalDependencies();\n\t\t\tif (null != dependencies) {\n\t\t\t\tfor (PluginVersionInfo dependency : dependencies) {\n\t\t\t\t\tString depName = dependency.getName();\n\t\t\t\t\tString availableVersion = versions.get(depName);\n\t\t\t\t\tif (null != availableVersion) {\n\t\t\t\t\t\tmessage.append(checkVersion(name, depName, dependency.getVersion(), versions.get(depName)));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (message.length() > 0) {\n\t\t\tthrow new GeomajasException(ExceptionCode.DEPENDENCY_CHECK_FAILED, message.toString());\n\t\t}\n\n\t\trecorder.record(GROUP, VALUE);\n\t}", "label": 0}
{"code": "public static function parse(string $msg): Message\n    {\n        $obj = new self;\n        $parts = explode(\"\\r\\n\", $msg);\n        $obj->body = MessageBody::parse(array_pop($parts));\n        foreach ($parts as $line) {\n            if ($line) {\n                $pair = explode(': ', $line);\n                $obj->headers[$pair[0]] = $pair[1];\n            }\n        }\n        return $obj;\n    }", "label": 2}
{"code": "function(opt_randFunc) {\n    var randFunc = opt_randFunc || randInt;\n    var strong = randFunc(3);\n    var color = 0xFF;\n    for (var ii = 0; ii < 3; ++ii) {\n      color = (color << 8) | (randFunc(128) + (ii === strong ? 128 : 64));\n    }\n    return color;\n  }", "label": 3}
{"code": "private function mapEntityResult(array $result, $class)\n    {\n        $entity = $result['entity'];\n\n        $namespaceId = (isset($entity['key']['partitionId']['namespaceId']))\n            ? $entity['key']['partitionId']['namespaceId']\n            : null;\n\n        $key = new Key($this->projectId, [\n            'path' => $entity['key']['path'],\n            'namespaceId' => $namespaceId\n        ]);\n\n        if (is_array($class)) {\n            $lastPathElement = $key->pathEnd();\n            if (!array_key_exists($lastPathElement['kind'], $class)) {\n                throw new \\InvalidArgumentException(sprintf(\n                    'No class found for kind %s',\n                    $lastPathElement['kind']\n                ));\n            }\n\n            $className = $class[$lastPathElement['kind']];\n        } else {\n            $className = $class;\n        }\n\n        $properties = [];\n        $excludes = [];\n        $meanings = [];\n\n        if (isset($entity['properties'])) {\n            $res = $this->entityMapper->responseToEntityProperties($entity['properties'], $className);\n\n            $properties = $res['properties'];\n            $excludes = $res['excludes'];\n            $meanings = $res['meanings'];\n        }\n\n        return $this->entity($key, $properties, [\n            'cursor' => (isset($result['cursor']))\n                ? $result['cursor']\n                : null,\n            'baseVersion' => (isset($result['version']))\n                ? $result['version']\n                : null,\n            'className' => $className,\n            'populatedByService' => true,\n            'excludeFromIndexes' => $excludes,\n            'meanings' => $meanings\n        ]);\n    }", "label": 2}
{"code": "public void insertBefore(Vertex vtx, Vertex next) {\n        vtx.prev = next.prev;\n        if (next.prev == null) {\n            head = vtx;\n        } else {\n            next.prev.next = vtx;\n        }\n        vtx.next = next;\n        next.prev = vtx;\n    }", "label": 0}
{"code": "func AuthUserByUsername(db XODB, username sql.NullString) (*AuthUser, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, password, last_login, is_superuser, username, first_name, last_name, email, is_staff, is_active, date_joined ` +\n\t\t`FROM django.auth_user ` +\n\t\t`WHERE username = :1`\n\n\t// run query\n\tXOLog(sqlstr, username)\n\tau := AuthUser{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, username).Scan(&au.ID, &au.Password, &au.LastLogin, &au.IsSuperuser, &au.Username, &au.FirstName, &au.LastName, &au.Email, &au.IsStaff, &au.IsActive, &au.DateJoined)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &au, nil\n}", "label": 5}
{"code": "def dependency_list(self, tkn: str) -> List[str]:\n        \"\"\"Return a list all of the grammarelts that depend on tkn\n\n        :param tkn: \n        :return:\n        \"\"\"\n        if tkn not in self.dependency_map:\n            self.dependency_map[tkn] = [tkn]        # Force a circular reference\n            self.dependency_map[tkn] = self.reference(tkn).dependency_list()\n        return self.dependency_map[tkn]", "label": 1}
{"code": "def search(options={}, type='people')\n\n      path = \"/#{type.to_s}-search\"\n\n      if options.is_a?(Hash)\n        fields = options.delete(:fields)\n        path += field_selector(fields) if fields\n      end\n\n      options = { :keywords => options } if options.is_a?(String)\n      options = format_options_for_query(options)\n\n      result_json = get(to_uri(path, options))\n\n      Mash.from_json(result_json)\n    end", "label": 4}
{"code": "public void retrieveReferences(Object newObj, ClassDescriptor cld, boolean forced) throws PersistenceBrokerException\r\n    {\r\n        Iterator i = cld.getObjectReferenceDescriptors().iterator();\r\n\r\n        // turn off auto prefetching for related proxies\r\n        final Class saveClassToPrefetch = classToPrefetch;\r\n        classToPrefetch = null;\r\n\r\n        pb.getInternalCache().enableMaterializationCache();\r\n        try\r\n        {\r\n            while (i.hasNext())\r\n            {\r\n                ObjectReferenceDescriptor rds = (ObjectReferenceDescriptor) i.next();\r\n                retrieveReference(newObj, cld, rds, forced);\r\n            }\r\n\r\n            pb.getInternalCache().disableMaterializationCache();\r\n        }\r\n        catch(RuntimeException e)\r\n        {\r\n            pb.getInternalCache().doLocalClear();\r\n            throw e;\r\n        }\r\n        finally\r\n        {\r\n            classToPrefetch = saveClassToPrefetch;\r\n        }\r\n    }", "label": 0}
{"code": "function setRandomData(data){\n\n    // Include each key with a small chance\n    var randomKeys = Object.keys(data[0]).filter(function(d){\n          return Math.random() < 0.5;\n        }),\n\n        // Make a copy of the objects with only the\n        // random keys included.\n        dataWithRandomKeys = data.map(function (d) {\n          var e = {};\n          randomKeys.forEach(function (key) {\n            e[key] = d[key];\n          });\n          return e;\n        }),\n\n        // Include each element with a small chance\n        randomSample = dataWithRandomKeys.filter(function(d){\n          return Math.random() < 0.1;\n        });\n\n    // Update the table with the random data.\n    table.set({\n      data: randomSample,\n      columns: randomKeys.map(function (key) {\n        return {\n          title: capitalize(key),\n          property: key\n        };\n      })\n    });\n  }", "label": 3}
{"code": "public function get($name)\n    {\n        if (isset($this->properties[$name])) {\n            return $this->properties[$name];\n        }\n\n        if (isset($this->delivery_info[$name])) {\n            return $this->delivery_info[$name];\n        }\n\n        throw new \\OutOfBoundsException(sprintf(\n            'No \"%s\" property',\n            $name\n        ));\n    }", "label": 2}
{"code": "function pad(value, length) {\n  value = String(value);\n  length = length || 2;\n\n  while (value.length < length) {\n    value = '0' + value;\n  }\n\n  return value;\n}", "label": 3}
{"code": "function Rescuetime(apiKey, options) {\n\n    // The api key is required\n    if (!apiKey) {\n        throw new RescuetimeError('Invalid API Key: ' + apiKey);\n    }\n\n    // Copy over the relavant data\n    this.apiKey = apiKey;\n\n    // Extend the defaults\n    this.options = _.defaults(options || {}, Rescuetime.defaultOptions);\n\n    // Contruct the endpoint with the correct auth from the appId and apiKey\n    this.endpoint = this.options.endpoint;\n}", "label": 3}
{"code": "public function takeScreenshot($save_as = null)\n    {\n        $screenshot = base64_decode(\n            $this->execute(DriverCommand::SCREENSHOT)\n        );\n        if ($save_as) {\n            file_put_contents($save_as, $screenshot);\n        }\n\n        return $screenshot;\n    }", "label": 2}
{"code": "def get_price(ctx, currency):\n    \"\"\"Prints out market item price.\"\"\"\n    appid = ctx.obj['appid']\n    title = ctx.obj['title']\n\n    item_ = Item(appid, title)\n    item_.get_price_data(currency)\n\n    click.secho('Lowest price: %s %s' % (item_.price_lowest, item_.price_currency), fg='green')", "label": 1}
{"code": "def paginated_item_list(page_array:)\n        Kaminari.paginate_array(page_array, total_count: page_array.size).page(current_page).per(rows_from_params)\n      end", "label": 4}
{"code": "function(properties)\n  {\n    if ( !isValue( properties ) )\n    {\n      return this.length;\n    }\n\n    var resolver = createPropertyResolver( properties );\n    var result = 0;\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var resolved = resolver( this[ i ] );\n\n      if ( isValue( resolved ) )\n      {\n        result++;\n      }\n    }\n\n    return result;\n  }", "label": 3}
{"code": "func (s *Server) Dispatch(packet []byte) ([]byte, error) {\n\treq := &Packet{}\n\n\terr := req.UnmarshalBinary(packet)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif Trace {\n\t\tfmt.Fprintf(os.Stderr, \"[hgfs] request  %#v\\n\", req.Header)\n\t}\n\n\tvar res interface{}\n\n\thandler, ok := s.handlers[req.Op]\n\tif ok {\n\t\tres, err = handler(req)\n\t} else {\n\t\terr = &Status{\n\t\t\tCode: StatusOperationNotSupported,\n\t\t\tErr:  fmt.Errorf(\"unsupported Op(%d)\", req.Op),\n\t\t}\n\t}\n\n\treturn req.Reply(res, err)\n}", "label": 5}
{"code": "def wait_for(func):\n    \"\"\"\n    A decorator to invoke a function periodically until it returns a truthy\n    value.\n    \"\"\"\n\n    def wrapped(*args, **kwargs):\n        timeout = kwargs.pop('timeout', 15)\n\n        start = time()\n        result = None\n\n        while time() - start < timeout:\n            result = func(*args, **kwargs)\n            if result:\n                break\n            sleep(0.2)\n\n        return result\n\n    return wrapped", "label": 1}
{"code": "func GetKubeConfig(configPath string) (*rest.Config, error) {\n\t// if path to kubeconfig was provided, init config from it\n\tif configPath != \"\" {\n\t\treturn clientcmd.BuildConfigFromFlags(\"\", configPath)\n\t}\n\treturn rest.InClusterConfig()\n}", "label": 5}
{"code": "def render_refresh(tags)\n      refresh = meta_tags.extract(:refresh)\n      tags << Tag.new(:meta, 'http-equiv' => 'refresh', content: refresh.to_s) if refresh.present?\n    end", "label": 4}
{"code": "def itermonthdays2(cls, year, month):\n        \"\"\"Similar to itermonthdays2 but returns tuples of day and weekday.\n        \"\"\"\n        for day in NepCal.itermonthdates(year, month):\n            if day.month == month:\n                yield (day.day, day.weekday())\n            else:\n                yield (0, day.weekday())", "label": 1}
{"code": "function setConversationEtagHeader(res, conversationInfo) {\n    var copy = JSON.parse(JSON.stringify(conversationInfo));\n    delete copy.participants;\n    delete copy.createdOn;\n    delete copy.updatedOn;\n    setEtagHeader(res, copy);\n}", "label": 3}
{"code": "function _getMiddlewareForShadowRoute (controllerId, blueprintId) {\n\n        // Allow custom actions defined in controller to override blueprint actions.\n        return sails.middleware.controllers[controllerId][blueprintId.toLowerCase()] || hook.middleware[blueprintId.toLowerCase()];\n      }", "label": 3}
{"code": "def redis(redis_pool = nil)\n      if redis_pool\n        redis_pool.with { |conn| yield conn }\n      else\n        Sidekiq.redis { |conn| yield conn }\n      end\n    end", "label": 4}
{"code": "public static clusternodegroup_binding get(nitro_service service, String name) throws Exception{\n\t\tclusternodegroup_binding obj = new clusternodegroup_binding();\n\t\tobj.set_name(name);\n\t\tclusternodegroup_binding response = (clusternodegroup_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func ForProxy(cfg Config) Config {\n\tcfg.Watches = []services.WatchKind{\n\t\t{Kind: services.KindCertAuthority, LoadSecrets: false},\n\t\t{Kind: services.KindClusterName},\n\t\t{Kind: services.KindClusterConfig},\n\t\t{Kind: services.KindUser},\n\t\t{Kind: services.KindRole},\n\t\t{Kind: services.KindNamespace},\n\t\t{Kind: services.KindNode},\n\t\t{Kind: services.KindProxy},\n\t\t{Kind: services.KindAuthServer},\n\t\t{Kind: services.KindReverseTunnel},\n\t\t{Kind: services.KindTunnelConnection},\n\t}\n\tcfg.QueueSize = defaults.ProxyQueueSize\n\treturn cfg\n}", "label": 5}
{"code": "function isSymbolAccessible(symbol, enclosingDeclaration, meaning, shouldComputeAliasesToMakeVisible) {\n            if (symbol && enclosingDeclaration && !(symbol.flags & 262144 /* TypeParameter */)) {\n                var initialSymbol = symbol;\n                var meaningToLook = meaning;\n                while (symbol) {\n                    // Symbol is accessible if it by itself is accessible\n                    var accessibleSymbolChain = getAccessibleSymbolChain(symbol, enclosingDeclaration, meaningToLook, /*useOnlyExternalAliasing*/ false);\n                    if (accessibleSymbolChain) {\n                        var hasAccessibleDeclarations = hasVisibleDeclarations(accessibleSymbolChain[0], shouldComputeAliasesToMakeVisible);\n                        if (!hasAccessibleDeclarations) {\n                            return {\n                                accessibility: 1 /* NotAccessible */,\n                                errorSymbolName: symbolToString(initialSymbol, enclosingDeclaration, meaning),\n                                errorModuleName: symbol !== initialSymbol ? symbolToString(symbol, enclosingDeclaration, 1920 /* Namespace */) : undefined\n                            };\n                        }\n                        return hasAccessibleDeclarations;\n                    }\n                    // If we haven't got the accessible symbol, it doesn't mean the symbol is actually inaccessible.\n                    // It could be a qualified symbol and hence verify the path\n                    // e.g.:\n                    // module m {\n                    //     export class c {\n                    //     }\n                    // }\n                    // const x: typeof m.c\n                    // In the above example when we start with checking if typeof m.c symbol is accessible,\n                    // we are going to see if c can be accessed in scope directly.\n                    // But it can't, hence the accessible is going to be undefined, but that doesn't mean m.c is inaccessible\n                    // It is accessible if the parent m is accessible because then m.c can be accessed through qualification\n                    meaningToLook = getQualifiedLeftMeaning(meaning);\n                    symbol = getParentOfSymbol(symbol);\n                }\n                // This could be a symbol that is not exported in the external module\n                // or it could be a symbol from different external module that is not aliased and hence cannot be named\n                var symbolExternalModule = ts.forEach(initialSymbol.declarations, getExternalModuleContainer);\n                if (symbolExternalModule) {\n                    var enclosingExternalModule = getExternalModuleContainer(enclosingDeclaration);\n                    if (symbolExternalModule !== enclosingExternalModule) {\n                        // name from different external module that is not visible\n                        return {\n                            accessibility: 2 /* CannotBeNamed */,\n                            errorSymbolName: symbolToString(initialSymbol, enclosingDeclaration, meaning),\n                            errorModuleName: symbolToString(symbolExternalModule)\n                        };\n                    }\n                }\n                // Just a local name that is not accessible\n                return {\n                    accessibility: 1 /* NotAccessible */,\n                    errorSymbolName: symbolToString(initialSymbol, enclosingDeclaration, meaning)\n                };\n            }\n            return { accessibility: 0 /* Accessible */ };\n            function getExternalModuleContainer(declaration) {\n                for (; declaration; declaration = declaration.parent) {\n                    if (hasExternalModuleSymbol(declaration)) {\n                        return getSymbolOfNode(declaration);\n                    }\n                }\n            }\n        }", "label": 3}
{"code": "function(callback) {\n\t\t\tthis.face.stop();\n\t\t\tthis.timer.stop(callback);\n\t\t\t\n\t\t\tfor(var x in this.lists) {\n\t\t\t\tthis.lists[x].stop();\n\t\t\t}\t\n\t\t}", "label": 3}
{"code": "func (l *DiagnosticLog) Seek(ctx context.Context, nlines int32) error {\n\th, err := l.m.BrowseLog(ctx, l.Host, l.Key, math.MaxInt32, 0)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tl.Start = h.LineEnd - nlines\n\n\treturn nil\n}", "label": 5}
{"code": "def window(*args, &blk)\n      win = Window.new self, extract_selector(args)\n\n      win.use(&blk) if block_given?\n\n      win\n    end", "label": 4}
{"code": "func EndpointURL(ctx context.Context, c *vim25.Client, path string, filter *types.LookupServiceRegistrationFilter) string {\n\tif lu, err := NewClient(ctx, c); err == nil {\n\t\tinfo, _ := lu.List(ctx, filter)\n\t\tif len(info) != 0 && len(info[0].ServiceEndpoints) != 0 {\n\t\t\tendpoint := &info[0].ServiceEndpoints[0]\n\t\t\tpath = endpoint.Url\n\n\t\t\tif u, err := url.Parse(path); err == nil {\n\t\t\t\tif c.Thumbprint(u.Host) == \"\" {\n\t\t\t\t\tc.SetThumbprint(u.Host, endpointThumbprint(endpoint))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn path\n}", "label": 5}
{"code": "func (c *Client) Logout(ctx context.Context) error {\n\t// Close any idle connections after logging out.\n\tdefer c.Client.CloseIdleConnections()\n\treturn c.SessionManager.Logout(ctx)\n}", "label": 5}
{"code": "function validation() {\n  const target = this._obj;\n  this.assert(_.isObject(target), '#{this} is not a Joi validation because it must be an object');\n  this.assert(!_.isEmpty(target), '#{this} is not a Joi validation because it is an empty object');\n  const fields = _.keys(target);\n  const allFieldsPresent = _.every(FIELDS_TO_VALIDATE.map(field => _.includes(fields, field)));\n\n  this.assert(\n    allFieldsPresent,\n    `${this} is not a validation because it does not contain expected keys`\n  );\n}", "label": 3}
{"code": "public static base_response update(nitro_service client, aaapreauthenticationparameter resource) throws Exception {\n\t\taaapreauthenticationparameter updateresource = new aaapreauthenticationparameter();\n\t\tupdateresource.preauthenticationaction = resource.preauthenticationaction;\n\t\tupdateresource.rule = resource.rule;\n\t\tupdateresource.killprocess = resource.killprocess;\n\t\tupdateresource.deletefiles = resource.deletefiles;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (h *Handler) WithClusterAuth(fn ClusterHandler) httprouter.Handle {\n\treturn httplib.MakeHandler(func(w http.ResponseWriter, r *http.Request, p httprouter.Params) (interface{}, error) {\n\t\tctx, err := h.AuthenticateRequest(w, r, true)\n\t\tif err != nil {\n\t\t\tlog.Info(err)\n\t\t\t// clear session just in case if the authentication request is not valid\n\t\t\tClearSession(w)\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tsiteName := p.ByName(\"site\")\n\t\tif siteName == currentSiteShortcut {\n\t\t\tres, err := h.cfg.ProxyClient.GetClusterName()\n\t\t\tif err != nil {\n\t\t\t\tlog.Warn(err)\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\n\t\t\tsiteName = res.GetClusterName()\n\t\t}\n\t\tsite, err := h.cfg.Proxy.GetSite(siteName)\n\t\tif err != nil {\n\t\t\tlog.Warn(err)\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\n\t\treturn fn(w, r, p, ctx, site)\n\t})\n}", "label": 5}
{"code": "def traverse_inventory(self, item_filter=None):\n        \"\"\"Generates market Item objects for each inventory item.\n\n        :param str item_filter: See `TAG_ITEM_CLASS_` contants from .market module.\n\n        \"\"\"\n        not self._intentory_raw and self._get_inventory_raw()\n\n        for item in self._intentory_raw['rgDescriptions'].values():\n            tags = item['tags']\n            for tag in tags:\n                internal_name = tag['internal_name']\n                if item_filter is None or internal_name == item_filter:\n\n                    item_type = Item\n                    if internal_name == TAG_ITEM_CLASS_CARD:\n                        item_type = Card\n\n                    appid = item['market_fee_app']\n                    title = item['name']\n\n                    yield item_type(appid, title)", "label": 1}
{"code": "func (s *APIServer) upsertServer(auth ClientI, role teleport.Role, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tvar req upsertServerRawReq\n\tif err := httplib.ReadJSON(r, &req); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar kind string\n\tswitch role {\n\tcase teleport.RoleNode:\n\t\tkind = services.KindNode\n\tcase teleport.RoleAuth:\n\t\tkind = services.KindAuthServer\n\tcase teleport.RoleProxy:\n\t\tkind = services.KindProxy\n\t}\n\tserver, err := services.GetServerMarshaler().UnmarshalServer(req.Server, kind)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\t// if server sent \"local\" IP address to us, replace the ip/host part with the remote address we see\n\t// on the socket, but keep the original port:\n\tserver.SetAddr(utils.ReplaceLocalhost(server.GetAddr(), r.RemoteAddr))\n\tif req.TTL != 0 {\n\t\tserver.SetTTL(s, req.TTL)\n\t}\n\tswitch role {\n\tcase teleport.RoleNode:\n\t\tnamespace := p.ByName(\"namespace\")\n\t\tif !services.IsValidNamespace(namespace) {\n\t\t\treturn nil, trace.BadParameter(\"invalid namespace %q\", namespace)\n\t\t}\n\t\tserver.SetNamespace(namespace)\n\t\thandle, err := auth.UpsertNode(server)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn handle, nil\n\tcase teleport.RoleAuth:\n\t\tif err := auth.UpsertAuthServer(server); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\tcase teleport.RoleProxy:\n\t\tif err := auth.UpsertProxy(server); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\treturn message(\"ok\"), nil\n}", "label": 5}
{"code": "func (l *LiteBackend) getInTransaction(ctx context.Context, key []byte, tx *sql.Tx, item *backend.Item) error {\n\tnow := l.clock.Now().UTC()\n\tq, err := tx.PrepareContext(ctx,\n\t\t\"SELECT key, value, expires, modified FROM kv WHERE key = ? AND (expires IS NULL OR expires > ?) LIMIT 1\")\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\trow := q.QueryRowContext(ctx, string(key), now)\n\tvar expires NullTime\n\tif err := row.Scan(&item.Key, &item.Value, &expires, &item.ID); err != nil {\n\t\tif err == sql.ErrNoRows {\n\t\t\treturn trace.NotFound(\"key %v is not found\", string(key))\n\t\t}\n\t\treturn trace.Wrap(err)\n\t}\n\titem.Expires = expires.Time\n\treturn nil\n}", "label": 5}
{"code": "func (p *Panel) SetContent(w Widget) {\n\tindex := 0\n\tif p.title != nil {\n\t\tindex++\n\t}\n\tif p.menu != nil {\n\t\tindex++\n\t}\n\tif p.content != nil {\n\t\tp.RemoveWidget(p.content)\n\t}\n\tp.InsertWidget(index, w, 1.0)\n\tp.content = w\n}", "label": 5}
{"code": "public ManageableCollection getCollectionByQuery(Class collectionClass, Query query, boolean lazy) throws PersistenceBrokerException\r\n    {\r\n        ManageableCollection result;\r\n\r\n        try\r\n        {\r\n            // BRJ: return empty Collection  for null query\r\n            if (query == null)\r\n            {\r\n                result = (ManageableCollection)collectionClass.newInstance();\r\n            }\r\n            else\r\n            {\r\n                if (lazy)\r\n                {\r\n                    result = pb.getProxyFactory().createCollectionProxy(pb.getPBKey(), query, collectionClass);\r\n                }\r\n                else\r\n                {\r\n                    result = getCollectionByQuery(collectionClass, query.getSearchClass(), query);\r\n                }\r\n            }\r\n            return result;\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            if(e instanceof PersistenceBrokerException)\r\n            {\r\n                throw (PersistenceBrokerException) e;\r\n            }\r\n            else\r\n            {\r\n                throw new PersistenceBrokerException(e);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public function setState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\Application_ApplicationState::class);\n        $this->state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (l VirtualDeviceList) FindCdrom(name string) (*types.VirtualCdrom, error) {\n\tif name != \"\" {\n\t\td := l.Find(name)\n\t\tif d == nil {\n\t\t\treturn nil, fmt.Errorf(\"device '%s' not found\", name)\n\t\t}\n\t\tif c, ok := d.(*types.VirtualCdrom); ok {\n\t\t\treturn c, nil\n\t\t}\n\t\treturn nil, fmt.Errorf(\"%s is not a cdrom device\", name)\n\t}\n\n\tc := l.SelectByType((*types.VirtualCdrom)(nil))\n\tif len(c) == 0 {\n\t\treturn nil, errors.New(\"no cdrom device found\")\n\t}\n\n\treturn c[0].(*types.VirtualCdrom), nil\n}", "label": 5}
{"code": "func FastUnmarshal(data []byte, v interface{}) error {\n\titer := jsoniter.ConfigFastest.BorrowIterator(data)\n\tdefer jsoniter.ConfigFastest.ReturnIterator(iter)\n\n\titer.ReadVal(v)\n\tif iter.Error != nil {\n\t\treturn trace.Wrap(iter.Error)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function BasicQuery(query) {\n\tassign(this, query);\n\tif (!this.filter) {\n\t\tthis.filter = set.UNIVERSAL;\n\t}\n\tif (!this.page) {\n\t\tthis.page = new RecordRange();\n\t}\n\tif (!this.sort) {\n\t\tthis.sort = \"id\";\n\t}\n\tif (typeof this.sort === \"string\") {\n\t\tthis.sort = new DefaultSort(this.sort);\n\t}\n}", "label": 3}
{"code": "def act_on_options(options)\n      configure_logger(options)\n\n      if options[:help]\n        print_help(options)\n        Sysexits::EX_OK\n      elsif options[:version] || options[:verbose_version]\n        print_version(options)\n        Sysexits::EX_OK\n      elsif options[:show_linters]\n        print_available_linters\n        Sysexits::EX_OK\n      elsif options[:show_reporters]\n        print_available_reporters\n        Sysexits::EX_OK\n      else\n        scan_for_lints(options)\n      end\n    end", "label": 4}
{"code": "public static base_response add(nitro_service client, snmpmanager resource) throws Exception {\n\t\tsnmpmanager addresource = new snmpmanager();\n\t\taddresource.ipaddress = resource.ipaddress;\n\t\taddresource.netmask = resource.netmask;\n\t\taddresource.domainresolveretry = resource.domainresolveretry;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def include_events(container)\n      handlers = container.instance_variable_get '@event_handlers'\n      return unless handlers\n\n      @event_handlers ||= {}\n      @event_handlers.merge!(handlers) { |_, old, new| old + new }\n    end", "label": 4}
{"code": "public ApiResponse<TokenInfoSuccessResponse> tokenInfoWithHttpInfo() throws ApiException {\n        com.squareup.okhttp.Call call = tokenInfoValidateBeforeCall(null, null);\n        Type localVarReturnType = new TypeToken<TokenInfoSuccessResponse>(){}.getType();\n        return apiClient.execute(call, localVarReturnType);\n    }", "label": 0}
{"code": "private function validateRowInProgress(CellChunk $chunk)\n    {\n        $this->validateResetRow($chunk);\n        $newRowKey = $chunk->getRowKey();\n        $this->isError(\n            $chunk->getRowKey() && $newRowKey !== $this->rowKey,\n            'A commit is required between row keys.'\n        );\n        $this->isError(\n            $chunk->getFamilyName() && !$chunk->getQualifier(),\n            'A qualifier must be specified.'\n        );\n        $this->validateValueSizeAndCommitRow($chunk);\n    }", "label": 2}
{"code": "def update(data)\n      process_name(data) if data['name']\n      process_version(data) if data['version']\n      process_source(data) if data['source']\n      process_data_provider(data) if data['data_provider']\n      merge_dependencies(data) if data['dependencies']\n\n      @data.merge!(data)\n      return self\n    end", "label": 4}
{"code": "public static csparameter get(nitro_service service) throws Exception{\n\t\tcsparameter obj = new csparameter();\n\t\tcsparameter[] response = (csparameter[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public function getObjectAsync(array $args)\n    {\n        $provider = $this->getMaterialsProvider($args);\n        unset($args['@MaterialsProvider']);\n\n        $instructionFileSuffix = $this->getInstructionFileSuffix($args);\n        unset($args['@InstructionFileSuffix']);\n\n        $strategy = $this->getMetadataStrategy($args, $instructionFileSuffix);\n        unset($args['@MetadataStrategy']);\n\n        $saveAs = null;\n        if (!empty($args['SaveAs'])) {\n            $saveAs = $args['SaveAs'];\n        }\n\n        $promise = $this->client->getObjectAsync($args)\n            ->then(\n                function ($result) use (\n                    $provider,\n                    $instructionFileSuffix,\n                    $strategy,\n                    $args\n                ) {\n                    if ($strategy === null) {\n                        $strategy = $this->determineGetObjectStrategy(\n                            $result,\n                            $instructionFileSuffix\n                        );\n                    }\n\n                    $envelope = $strategy->load($args + [\n                        'Metadata' => $result['Metadata']\n                    ]);\n\n                    $provider = $provider->fromDecryptionEnvelope($envelope);\n\n                    $result['Body'] = $this->decrypt(\n                        $result['Body'],\n                        $provider,\n                        $envelope,\n                        isset($args['@CipherOptions'])\n                            ? $args['@CipherOptions']\n                            : []\n                    );\n                    return $result;\n                }\n            )->then(\n                function ($result) use ($saveAs) {\n                    if (!empty($saveAs)) {\n                        file_put_contents(\n                            $saveAs,\n                            (string)$result['Body'],\n                            LOCK_EX\n                        );\n                    }\n                    return $result;\n                }\n            );\n\n        return $promise;\n    }", "label": 2}
{"code": "def _construct_form(self, i, **kwargs):\n        \"\"\"\n        Construct the form, overriding the initial value for `language_code`.\n        \"\"\"\n        if not settings.HIDE_LANGUAGE:\n            self._construct_available_languages()\n\n        form = super(TranslationFormSet, self)._construct_form(i, **kwargs)\n\n        if settings.HIDE_LANGUAGE:\n            form.instance.language_code = settings.DEFAULT_LANGUAGE\n        else:\n            language_code = form.instance.language_code\n\n            if language_code:\n                logger.debug(\n                    u'Removing translation choice %s for instance %s'\n                    u' in form %d', language_code, form.instance, i\n                )\n\n                self.available_languages.remove(language_code)\n\n            else:\n                initial_language_code = self._get_default_language()\n\n                logger.debug(\n                    u'Preselecting language code %s for form %d',\n                    initial_language_code, i\n                )\n\n                form.initial['language_code'] = initial_language_code\n\n        return form", "label": 1}
{"code": "func getOVAFileInfo(ovafile string, filename string) (int64, string, error) {\n\tof, err := NewOVAFile(ovafile)\n\tif err != nil {\n\t\treturn 0, \"\", err\n\t}\n\n\thdr, err := of.Find(filename)\n\tif err != nil {\n\t\treturn 0, \"\", err\n\t}\n\n\thash := md5.New()\n\t_, err = io.Copy(hash, of)\n\tif err != nil {\n\t\treturn 0, \"\", err\n\t}\n\tmd5String := hex.EncodeToString(hash.Sum(nil)[:16])\n\n\treturn hdr.Size, md5String, nil\n}", "label": 5}
{"code": "@PostConstruct\n    public void initDatabase() {\n        MongoDBInit.LOGGER.info(\"initializing MongoDB\");\n        String dbName = System.getProperty(\"mongodb.name\");\n        if (dbName == null) {\n            throw new RuntimeException(\"Missing database name; Set system property 'mongodb.name'\");\n        }\n        MongoDatabase db = this.mongo.getDatabase(dbName);\n\n        try {\n            PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();\n            Resource[] resources = resolver.getResources(\"classpath*:mongodb/*.ndjson\");\n            MongoDBInit.LOGGER.info(\"Scanning for collection data\");\n            for (Resource res : resources) {\n                String filename = res.getFilename();\n                String collection = filename.substring(0, filename.length() - 7);\n                MongoDBInit.LOGGER.info(\"Found collection file: {}\", collection);\n                MongoCollection<DBObject> dbCollection = db.getCollection(collection, DBObject.class);\n                try (Scanner scan = new Scanner(res.getInputStream(), \"UTF-8\")) {\n                    int lines = 0;\n                    while (scan.hasNextLine()) {\n                        String json = scan.nextLine();\n                        Object parse = JSON.parse(json);\n                        if (parse instanceof DBObject) {\n                            DBObject dbObject = (DBObject) parse;\n                            dbCollection.insertOne(dbObject);\n                        } else {\n                            MongoDBInit.LOGGER.error(\"Invalid object found: {}\", parse);\n                            throw new RuntimeException(\"Invalid object\");\n                        }\n                        lines++;\n                    }\n                    MongoDBInit.LOGGER.info(\"Imported {} objects into collection {}\", lines, collection);\n                }\n            }\n        } catch (IOException e) {\n            throw new RuntimeException(\"Error importing objects\", e);\n        }\n    }", "label": 0}
{"code": "func (s *grpcControllerServer) Shutdown(ctx context.Context, _ *plugin.Empty) (*plugin.Empty, error) {\n\tresp := &plugin.Empty{}\n\n\t// TODO: figure out why GracefullStop doesn't work.\n\ts.server.Stop()\n\treturn resp, nil\n}", "label": 5}
{"code": "func (c *Context) SetSession(session Session, login bool) {\n\tsession.UserAgent = c.req.UserAgent()\n\tsession.IpAddress = strings.Split(c.req.RemoteAddr, \":\")[0]\n\tsession.LastActiveTime = time.Now()\n\tsession.CallCount++\n\n\tc.svc.sm.sessions[session.Key] = session\n\tc.Session = &session\n\n\tif login {\n\t\thttp.SetCookie(c.res, &http.Cookie{\n\t\t\tName:  soap.SessionCookieName,\n\t\t\tValue: session.Key,\n\t\t})\n\n\t\tc.postEvent(&types.UserLoginSessionEvent{\n\t\t\tSessionId: session.Key,\n\t\t\tIpAddress: session.IpAddress,\n\t\t\tUserAgent: session.UserAgent,\n\t\t\tLocale:    session.Locale,\n\t\t})\n\t}\n}", "label": 5}
{"code": "function coverage(data, type) {\n  var comparisionFunc;\n  var n = 0;\n\n  function isCovered(val) {\n    return (val > 0);\n  }\n\n  function isMissed(val) {\n    return !isCovered(val);\n  }\n\n  if (type === 'covered') {\n    comparisionFunc = isCovered;\n  }\n  else if (type === 'missed') {\n    comparisionFunc = isMissed;\n  }\n  else {\n    throw new Error('Invalid type: ' + type);\n  }\n\n  var len = Object.keys(data.lines).length;\n\n  for (var i = 0; i < len; ++i) {\n    if (data.lines[i] !== null && comparisionFunc(data.lines[i])) {\n      ++n;\n    }\n  }\n\n  return n;\n}", "label": 3}
{"code": "function wrapError(message, cause) {\n  var err = new Error(f('%s: %s', message, cause.message));\n  err.cause = cause;\n  return err;\n}", "label": 3}
{"code": "function generateCSVHeader(csv, field, headerName, fieldRepeatIndex) {\n\n  //If the previous csv value is set, then a ',' is needed to separate.\n  if (csv) {\n    csv += ',';\n  }\n\n  // Sanity check after the headers to ensure we don't have a double ,, appearing\n  // The above if is necessary and cannot be removed\n  if (endsWith(csv, ',,')) {\n    csv = csv.slice(0, -1);\n  }\n\n  csv += generateFieldHeader(field, headerName, fieldRepeatIndex);\n\n  return csv;\n}", "label": 3}
{"code": "def custom_reader(key)\n      default_proc.call(self, key) if default_proc && !key?(key)\n      value = regular_reader(convert_key(key))\n      yield value if block_given?\n      value\n    end", "label": 4}
{"code": "def pad_array(in1):\n    \"\"\"\n    Simple convenience function to pad arrays for linear convolution.\n\n    INPUTS:\n    in1     (no default):   Input array which is to be padded.\n\n    OUTPUTS:\n    out1                    Padded version of the input.\n    \"\"\"\n\n    padded_size = 2*np.array(in1.shape)\n\n    out1 = np.zeros([padded_size[0],padded_size[1]])\n    out1[padded_size[0]/4:3*padded_size[0]/4,padded_size[1]/4:3*padded_size[1]/4] = in1\n\n    return out1", "label": 1}
{"code": "func UnmarshalTunnelConnection(data []byte, opts ...MarshalOption) (TunnelConnection, error) {\n\tif len(data) == 0 {\n\t\treturn nil, trace.BadParameter(\"missing tunnel connection data\")\n\t}\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar h ResourceHeader\n\terr = utils.FastUnmarshal(data, &h)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch h.Version {\n\tcase V2:\n\t\tvar r TunnelConnectionV2\n\n\t\tif cfg.SkipValidation {\n\t\t\tif err := utils.FastUnmarshal(data, &r); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t} else {\n\t\t\tif err := utils.UnmarshalWithSchema(GetTunnelConnectionSchema(), &r, data); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t}\n\n\t\tif err := r.CheckAndSetDefaults(); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tif cfg.ID != 0 {\n\t\t\tr.SetResourceID(cfg.ID)\n\t\t}\n\t\tif !cfg.Expires.IsZero() {\n\t\t\tr.SetExpiry(cfg.Expires)\n\t\t}\n\t\treturn &r, nil\n\t}\n\treturn nil, trace.BadParameter(\"reverse tunnel version %v is not supported\", h.Version)\n}", "label": 5}
{"code": "def remove_amendment(self, first_arg, sec_arg, third_arg, fourth_arg=None, commit_msg=None):\n        \"\"\"Remove an amendment\n        Given a amendment_id, branch and optionally an\n        author, remove an amendment on the given branch\n        and attribute the commit to author.\n        Returns the SHA of the commit on branch.\n        \"\"\"\n        if fourth_arg is None:\n            amendment_id, branch_name, author = first_arg, sec_arg, third_arg\n            gh_user = branch_name.split('_amendment_')[0]\n            parent_sha = self.get_master_sha()\n        else:\n            gh_user, amendment_id, parent_sha, author = first_arg, sec_arg, third_arg, fourth_arg\n        if commit_msg is None:\n            commit_msg = \"Delete Amendment '%s' via OpenTree API\" % amendment_id\n        return self._remove_document(gh_user, amendment_id, parent_sha, author, commit_msg)", "label": 1}
{"code": "public static lbmonitor_binding get(nitro_service service, String monitorname) throws Exception{\n\t\tlbmonitor_binding obj = new lbmonitor_binding();\n\t\tobj.set_monitorname(monitorname);\n\t\tlbmonitor_binding response = (lbmonitor_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setPartitionOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\V1\\PartitionOptions::class);\n        $this->partition_options = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def load_file(file)\n      config = self.class.load_from_file(file, default: false, logger: @log)\n      config = self.class.default_configuration.merge(config)\n\n      if @options.fetch(:verify) { config.verify_signatures? }\n        verify_signatures(config)\n      end\n\n      config\n    rescue Overcommit::Exceptions::ConfigurationSignatureChanged\n      raise\n    rescue StandardError => error\n      raise Overcommit::Exceptions::ConfigurationError,\n            \"Unable to load configuration from '#{file}': #{error}\",\n            error.backtrace\n    end", "label": 4}
{"code": "function _sanitizeCoefficients(coefficients) {\n  if (coefficients == undefined) {\n    coefficients = {};\n  }\n  for (let property in Utils.DEFAULT_ROOM_MATERIALS) {\n    if (!(coefficients.hasOwnProperty(property))) {\n      // If element is not present, use default coefficients.\n      coefficients[property] = Utils.ROOM_MATERIAL_COEFFICIENTS[\n        Utils.DEFAULT_ROOM_MATERIALS[property]];\n    }\n  }\n  return coefficients;\n}", "label": 3}
{"code": "func Add(name string, fn commandFn) Entrypoint {\n\tif _, ok := commands[name]; ok {\n\t\tpanic(fmt.Errorf(\"command with name %q already exists\", name))\n\t}\n\tcommands[name] = fn\n\treturn Entrypoint(name)\n}", "label": 5}
{"code": "function () {\n        Shared.initialize('/config', process.argv[2]);\n        Shared.setAppHttp(appHttp);\n        Shared.setAppHttps(appHttps);\n        Shared.setExpress(express);\n\n        // Init memcached\n        var memcached = Shared.memcached();\n\n        // Init redis cache\n        var redis = Shared.redis(true);\n\n        //Enable gzip compression\n        appHttp.use(compression());\n        appHttp.disable('x-powered-by');\n        appHttps.use(compression());\n        appHttps.disable('x-powered-by');\n\n        var env = Shared.config(\"environment\");\n        var maxLag = env.maxLag;\n        if (maxLag) {\n            toobusy.maxLag(maxLag);\n        }\n\n        appHttp.use(function (req, res, next) {\n            if (maxLag && toobusy()) {\n                Logger.error(\"Server is busy, rejected request\");\n                res.status(503).send(\"I'm busy right now, sorry.\");\n            } else {\n                next();\n            }\n        });\n\n        appHttps.use(function (req, res, next) {\n            if (maxLag && toobusy()) {\n                Logger.error(\"Server is busy, rejected request\");\n                res.status(503).send(\"I'm busy right now, sorry.\");\n            } else {\n                next();\n            }\n        });\n\n        return Q();\n    }", "label": 3}
{"code": "def generate_any_value?(lm, hm)\n      (lm.nil? || lm.is_a?(HQMF::AnyValue)) && (hm.nil? || hm.is_a?(HQMF::AnyValue))\n    end", "label": 4}
{"code": "async def anext(*args):\n    \"\"\"Return the next item from an async iterator.\n\n    Args:\n        iterable: An async iterable.\n        default: An optional default value to return if the iterable is empty.\n\n    Return:\n        The next value of the iterable.\n\n    Raises:\n        TypeError: The iterable given is not async.\n\n    This function will return the next value form an async iterable. If the\n    iterable is empty the StopAsyncIteration will be propogated. However, if\n    a default value is given as a second argument the exception is silenced and\n    the default value is returned instead.\n    \"\"\"\n    if not args:\n\n        raise TypeError('anext() expected at least 1 arguments, got 0')\n\n    if len(args) > 2:\n\n        raise TypeError(\n            'anext() expected at most 2 arguments, got {}'.format(len(args))\n        )\n\n    iterable, default, has_default = args[0], None, False\n    if len(args) == 2:\n\n        iterable, default = args\n        has_default = True\n\n    try:\n\n        return await iterable.__anext__()\n\n    except StopAsyncIteration as exc:\n\n        if has_default:\n\n            return default\n\n        raise StopAsyncIteration() from exc", "label": 1}
{"code": "def wait_until(waiter_name, params = {}, options = {})\n      w = waiter(waiter_name, options)\n      yield(w.waiter) if block_given? # deprecated\n      w.wait(params)\n    end", "label": 4}
{"code": "public function setDeviceRegistries($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Iot\\V1\\DeviceRegistry::class);\n        $this->device_registries = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setTables($entityTables, $manyToManyTables)\n    {\n        $this->tables = $this->manyToManyTables = $this->classToTableNames = [];\n\n        foreach ($entityTables as $table) {\n            $className = $this->getClassNameForTable($table->getName());\n\n            $this->classToTableNames[$className] = $table->getName();\n            $this->tables[$table->getName()]     = $table;\n        }\n\n        foreach ($manyToManyTables as $table) {\n            $this->manyToManyTables[$table->getName()] = $table;\n        }\n    }", "label": 2}
{"code": "def rw_config(key, value, default_value = nil)\n      if value.nil?\n        acts_as_authentic_config.include?(key) ? acts_as_authentic_config[key] : default_value\n      else\n        self.acts_as_authentic_config = acts_as_authentic_config.merge(key => value)\n        value\n      end\n    end", "label": 4}
{"code": "def process_mutect_vcf(job, mutect_vcf, work_dir, univ_options):\n    \"\"\"\n    Process the MuTect vcf for accepted calls.\n\n    :param toil.fileStore.FileID mutect_vcf: fsID for a MuTect generated chromosome vcf\n    :param str work_dir: Working directory\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :return: Path to the processed vcf\n    :rtype: str\n    \"\"\"\n    mutect_vcf = job.fileStore.readGlobalFile(mutect_vcf)\n\n    with open(mutect_vcf, 'r') as infile, open(mutect_vcf + 'mutect_parsed.tmp', 'w') as outfile:\n        for line in infile:\n            line = line.strip()\n            if line.startswith('#'):\n                print(line, file=outfile)\n                continue\n            line = line.split('\\t')\n            if line[6] != 'REJECT':\n                print('\\t'.join(line), file=outfile)\n    return outfile.name", "label": 1}
{"code": "function (path, action, options) {\n            options = options || routeOpts;\n            options = _.extend({}, options, {action: action, controller: controllerId});\n            sails.router.bind ( path, _getAction(action), null, options);\n\n          }", "label": 3}
{"code": "def country country_code, definition, options = {}\n      return unless Phony.config.load?(country_code)\n      \n      definition.with country_code, options\n      Phony::CountryCodes.instance.add country_code, definition\n    end", "label": 4}
{"code": "def weekday(cls, year, month, day):\n        \"\"\"Returns the weekday of the date. 0 = aaitabar\"\"\"\n        return NepDate.from_bs_date(year, month, day).weekday()", "label": 1}
{"code": "public void removePropertyChangeListener (String propertyName, java.beans.PropertyChangeListener listener)\r\n    {\r\n        this.propertyChangeDelegate.removePropertyChangeListener(propertyName, listener);\r\n    }", "label": 0}
{"code": "public PreparedStatement getDeleteStatement(ClassDescriptor cld) throws PersistenceBrokerSQLException, PersistenceBrokerException\r\n    {\r\n        try\r\n        {\r\n            return cld.getStatementsForClass(m_conMan).getDeleteStmt(m_conMan.getConnection());\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            throw new PersistenceBrokerSQLException(\"Could not build statement ask for\", e);\r\n        }\r\n        catch (LookupException e)\r\n        {\r\n            throw new PersistenceBrokerException(\"Used ConnectionManager instance could not obtain a connection\", e);\r\n        }\r\n    }", "label": 0}
{"code": "public function setDocumentLocation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\DocumentLocation::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function (callback, thisArg) {\n            var me = this;\n            this._sources.forEach(function (source, index) {\n                callback(me._update(source), index);\n            }, thisArg);\n        }", "label": 3}
{"code": "function getNodesToShow(node) {\n        var nodeArray = [], config = this.config;\n        node = node || this.clickedNode;\n        this.clickedNode.eachLevel(0, config.levelsToShow, function(n) {\n            if(config.multitree && !('$orn' in n.data) \n            \t\t&& n.anySubnode(function(ch){ return ch.exist && !ch.drawn; })) {\n            \tnodeArray.push(n);\n            } else if(n.drawn && !n.anySubnode(\"drawn\")) {\n              nodeArray.push(n);\n            }\n        });\n        return nodeArray;\n     }", "label": 3}
{"code": "public function setParamType($param_name, $php_type, $new_type, $phpdoc_type, $is_php_compatible)\n    {\n        $new_type = str_replace(['<mixed, mixed>', '<array-key, mixed>', '<empty, empty>'], '', $new_type);\n\n        if ($php_type) {\n            $this->new_php_param_types[$param_name] = $php_type;\n        }\n        $this->new_phpdoc_param_types[$param_name] = $phpdoc_type;\n        $this->new_psalm_param_types[$param_name] = $new_type;\n        $this->param_type_is_php_compatible[$param_name] = $is_php_compatible;\n    }", "label": 2}
{"code": "private FieldDescriptorDef cloneField(FieldDescriptorDef fieldDef, String prefix)\r\n    {\r\n        FieldDescriptorDef copyFieldDef = new FieldDescriptorDef(fieldDef, prefix);\r\n\r\n        copyFieldDef.setOwner(this);\r\n        // we remove properties that are only relevant to the class the features are declared in\r\n        copyFieldDef.setProperty(PropertyHelper.OJB_PROPERTY_IGNORE, null);\r\n\r\n        Properties mod = getModification(copyFieldDef.getName());\r\n\r\n        if (mod != null)\r\n        {\r\n            if (!PropertyHelper.toBoolean(mod.getProperty(PropertyHelper.OJB_PROPERTY_IGNORE), false) &&\r\n                hasFeature(copyFieldDef.getName()))\r\n            {\r\n                LogHelper.warn(true,\r\n                               ClassDescriptorDef.class,\r\n                               \"process\",\r\n                               \"Class \"+getName()+\" has a feature that has the same name as its included field \"+\r\n                               copyFieldDef.getName()+\" from class \"+fieldDef.getOwner().getName()); \r\n            }\r\n            copyFieldDef.applyModifications(mod);\r\n        }\r\n        return copyFieldDef;\r\n    }", "label": 0}
{"code": "def call(env)\n      organization = detect_current_organization(env)\n      if organization\n        env[\"decidim.current_organization\"] = organization\n        @app.call(env)\n      else\n        organization = find_secondary_host_org(env)\n        return @app.call(env) unless organization\n\n        location = new_location_for(env, organization.host)\n\n        [301, { \"Location\" => location, \"Content-Type\" => \"text/html\", \"Content-Length\" => \"0\" }, []]\n      end\n    end", "label": 4}
{"code": "def exit_on_fail(message, code = 1)\n    yield\n  # First, we need to check and see if we are catching a SystemExit error.  These will be raised\n  #  when we daemonize/fork, and they do not necessarily indicate a failure case.\n  rescue SystemExit => err\n    raise err\n\n  # Now we need to catch *any* other kind of exception, because we may be calling third-party\n  #  code (e.g. webrick), and we have no idea what they might throw.\n  rescue Exception => err\n    ## NOTE: when debugging spec failures, these two lines can be very useful\n    #puts err.inspect\n    #puts Puppet::Util.pretty_backtrace(err.backtrace)\n    Puppet.log_exception(err, \"#{message}: #{err}\")\n    Puppet::Util::Log.force_flushqueue()\n    exit(code)\n  end", "label": 4}
{"code": "public static double Entropy( int[] values ){\n        int     n = values.length;\n        int     total = 0;\n        double  entropy = 0;\n        double  p;\n\n        // calculate total amount of hits\n        for ( int i = 0; i < n; i++ )\n        {\n            total += values[i];\n        }\n\n        if ( total != 0 )\n        {\n            // for all values\n            for ( int i = 0; i < n; i++ )\n            {\n                // get item's probability\n                p = (double) values[i] / total;\n                // calculate entropy\n                if ( p != 0 )\n                    entropy += ( -p * (Math.log10(p)/Math.log10(2)) );\n            }\n        }\n        return entropy;\n    }", "label": 0}
{"code": "private void storeToDb(Object obj, ClassDescriptor cld, Identity oid, boolean insert, boolean ignoreReferences)\n    {\n        // 1. link and store 1:1 references\n        storeReferences(obj, cld, insert, ignoreReferences);\n\n        Object[] pkValues = oid.getPrimaryKeyValues();\n        if (!serviceBrokerHelper().assertValidPksForStore(cld.getPkFields(), pkValues))\n        {\n            // BRJ: fk values may be part of pk, but the are not known during\n            // creation of Identity. so we have to get them here\n            pkValues = serviceBrokerHelper().getKeyValues(cld, obj);\n            if (!serviceBrokerHelper().assertValidPksForStore(cld.getPkFields(), pkValues))\n            {\n                String append = insert ? \" on insert\" : \" on update\" ;\n                throw new PersistenceBrokerException(\"assertValidPkFields failed for Object of type: \" + cld.getClassNameOfObject() + append);\n            }\n        }\n\n        // get super class cld then store it with the object\n        /*\n        now for multiple table inheritance\n        1. store super classes, topmost parent first\n        2. go down through heirarchy until current class\n        3. todo: store to full extent?\n\n// arminw: TODO: The extend-attribute feature dosn't work, should we remove this stuff?\n        This if-clause will go up the inheritance heirarchy to store all the super classes.\n        The id for the top most super class will be the id for all the subclasses too\n         */\n        if(cld.getSuperClass() != null)\n        {\n\n            ClassDescriptor superCld = getDescriptorRepository().getDescriptorFor(cld.getSuperClass());\n            storeToDb(obj, superCld, oid, insert);\n            // arminw: why this?? I comment out this section\n            // storeCollections(obj, cld.getCollectionDescriptors(), insert);\n        }\n\n        // 2. store primitive typed attributes (Or is THIS step 3 ?)\n        // if obj not present in db use INSERT\n        if (insert)\n        {\n            dbAccess.executeInsert(cld, obj);\n            if(oid.isTransient())\n            {\n                // Create a new Identity based on the current set of primary key values.\n                oid = serviceIdentity().buildIdentity(cld, obj);\n            }\n        }\n        // else use UPDATE\n        else\n        {\n            try\n            {\n                dbAccess.executeUpdate(cld, obj);\n            }\n            catch(OptimisticLockException e)\n            {\n                // ensure that the outdated object be removed from cache\n                objectCache.remove(oid);\n                throw e;\n            }\n        }\n        // cache object for symmetry with getObjectByXXX()\n        // Add the object to the cache.\n        objectCache.doInternalCache(oid, obj, ObjectCacheInternal.TYPE_WRITE);\n        // 3. store 1:n and m:n associations\n        if(!ignoreReferences) storeCollections(obj, cld, insert);\n    }", "label": 0}
{"code": "def create_map_from_file(self, data_filename):\n        \"\"\"\n        reads the data_filename into a matrix and calls the main\n        function '' to generate a  .rule file based on the data in the map\n        \n        For all datafiles mapped, there exists a .rule file to define it\n        \n        \"\"\"\n        \n        op_filename = data_filename + '.rule'\n        \n        dataset = mod_datatable.DataTable(data_filename, ',')\n        dataset.load_to_array()\n        l_map = self.generate_map_from_dataset(dataset)\n        with open(op_filename, 'w') as f:\n            f.write('# rules file autogenerated by mapper.py v0.1\\n')\n            f.write('filename:source=' + data_filename + '\\n')\n            f.write('filename:rule=' + op_filename + '\\n\\n')\n            for row in l_map:\n                #print('ROW = ' , row)\n                if type(row) is str:\n                    f.write(row + '\\n')\n                else:\n                    for v in row:\n                        f.write(v)", "label": 1}
{"code": "public void setSessionFactory(SessionFactory sessionFactory) throws HibernateLayerException {\n\t\ttry {\n\t\t\tthis.sessionFactory = sessionFactory;\n\t\t\tif (null != layerInfo) {\n\t\t\t\tentityMetadata = sessionFactory.getClassMetadata(layerInfo.getFeatureInfo().getDataSourceName());\n\t\t\t}\n\t\t} catch (Exception e) { // NOSONAR\n\t\t\tthrow new HibernateLayerException(e, ExceptionCode.HIBERNATE_NO_SESSION_FACTORY);\n\t\t}\n\t}", "label": 0}
{"code": "public static dnsglobal_binding get(nitro_service service) throws Exception{\n\t\tdnsglobal_binding obj = new dnsglobal_binding();\n\t\tdnsglobal_binding response = (dnsglobal_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function initialize()\n    {\n        if ($this->isInitialized()) {\n            return;\n        }\n\n        if (!$this->nodes) {\n            throw new EmptyRingException('Cannot initialize an empty hashring.');\n        }\n\n        $this->ring = array();\n        $totalWeight = $this->computeTotalWeight();\n        $nodesCount = count($this->nodes);\n\n        foreach ($this->nodes as $node) {\n            $weightRatio = $node['weight'] / $totalWeight;\n            $this->addNodeToRing($this->ring, $node, $nodesCount, $this->replicas, $weightRatio);\n        }\n\n        ksort($this->ring, SORT_NUMERIC);\n        $this->ringKeys = array_keys($this->ring);\n        $this->ringKeysCount = count($this->ringKeys);\n    }", "label": 2}
{"code": "public static base_responses add(nitro_service client, tmtrafficaction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\ttmtrafficaction addresources[] = new tmtrafficaction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new tmtrafficaction();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].apptimeout = resources[i].apptimeout;\n\t\t\t\taddresources[i].sso = resources[i].sso;\n\t\t\t\taddresources[i].formssoaction = resources[i].formssoaction;\n\t\t\t\taddresources[i].persistentcookie = resources[i].persistentcookie;\n\t\t\t\taddresources[i].initiatelogout = resources[i].initiatelogout;\n\t\t\t\taddresources[i].kcdaccount = resources[i].kcdaccount;\n\t\t\t\taddresources[i].samlssoprofile = resources[i].samlssoprofile;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func DeleteConntrackEntries(nlh *netlink.Handle, ipv4List []net.IP, ipv6List []net.IP) (uint, uint, error) {\n\tif !IsConntrackProgrammable(nlh) {\n\t\treturn 0, 0, ErrConntrackNotConfigurable\n\t}\n\n\tvar totalIPv4FlowPurged uint\n\tfor _, ipAddress := range ipv4List {\n\t\tflowPurged, err := purgeConntrackState(nlh, syscall.AF_INET, ipAddress)\n\t\tif err != nil {\n\t\t\tlogrus.Warnf(\"Failed to delete conntrack state for %s: %v\", ipAddress, err)\n\t\t\tcontinue\n\t\t}\n\t\ttotalIPv4FlowPurged += flowPurged\n\t}\n\n\tvar totalIPv6FlowPurged uint\n\tfor _, ipAddress := range ipv6List {\n\t\tflowPurged, err := purgeConntrackState(nlh, syscall.AF_INET6, ipAddress)\n\t\tif err != nil {\n\t\t\tlogrus.Warnf(\"Failed to delete conntrack state for %s: %v\", ipAddress, err)\n\t\t\tcontinue\n\t\t}\n\t\ttotalIPv6FlowPurged += flowPurged\n\t}\n\n\tlogrus.Debugf(\"DeleteConntrackEntries purged ipv4:%d, ipv6:%d\", totalIPv4FlowPurged, totalIPv6FlowPurged)\n\treturn totalIPv4FlowPurged, totalIPv6FlowPurged, nil\n}", "label": 5}
{"code": "func (f *Fpdf) SetAutoPageBreak(auto bool, margin float64) {\n\tf.autoPageBreak = auto\n\tf.bMargin = margin\n\tf.pageBreakTrigger = f.h - margin\n}", "label": 5}
{"code": "private void setLockingValues(ClassDescriptor cld, Object obj, ValueContainer[] oldLockingValues)\r\n    {\r\n        FieldDescriptor fields[] = cld.getLockingFields();\r\n\r\n        for (int i=0; i<fields.length; i++)\r\n        {\r\n            PersistentField field = fields[i].getPersistentField();\r\n            Object lockVal = oldLockingValues[i].getValue();\r\n\r\n            field.set(obj, lockVal);\r\n        }\r\n    }", "label": 0}
{"code": "private function retryCommandOnFailure(CommandInterface $command, $method)\n    {\n        RETRY_COMMAND: {\n            try {\n                $connection = $this->getConnection($command);\n                $response = $connection->$method($command);\n\n                if ($response instanceof ResponseErrorInterface && $response->getErrorType() === 'LOADING') {\n                    throw new ConnectionException($connection, \"Redis is loading the dataset in memory [$connection]\");\n                }\n            } catch (ConnectionException $exception) {\n                $connection = $exception->getConnection();\n                $connection->disconnect();\n\n                if ($connection === $this->master && !$this->autoDiscovery) {\n                    // Throw immediately when master connection is failing, even\n                    // when the command represents a read-only operation, unless\n                    // automatic discovery has been enabled.\n                    throw $exception;\n                } else {\n                    // Otherwise remove the failing slave and attempt to execute\n                    // the command again on one of the remaining slaves...\n                    $this->remove($connection);\n                }\n\n                // ... that is, unless we have no more connections to use.\n                if (!$this->slaves && !$this->master) {\n                    throw $exception;\n                } elseif ($this->autoDiscovery) {\n                    $this->discover();\n                }\n\n                goto RETRY_COMMAND;\n            } catch (MissingMasterException $exception) {\n                if ($this->autoDiscovery) {\n                    $this->discover();\n                } else {\n                    throw $exception;\n                }\n\n                goto RETRY_COMMAND;\n            }\n        }\n\n        return $response;\n    }", "label": 2}
{"code": "def modify_offset(multiplicator)\n      # Format: \"+133+50\"\n      hash = offset['offset']\n      x = hash.split(\"+\")[1].to_f * multiplicator\n      y = hash.split(\"+\")[2].to_f * multiplicator\n      new_offset = \"+#{x.round}+#{y.round}\"\n      @offset_information['offset'] = new_offset\n    end", "label": 4}
{"code": "def submit_form_id(step, id):\n    \"\"\"\n    Submit the form having given id.\n    \"\"\"\n    form = world.browser.find_element_by_xpath(str('id(\"{id}\")'.format(id=id)))\n    form.submit()", "label": 1}
{"code": "def attachments\n      attachments = Attachment.from_response client.get(\"/cards/#{id}/attachments\")\n      MultiAssociation.new(self, attachments).proxy\n    end", "label": 4}
{"code": "protected static function processNumsub(array $channels)\n    {\n        $processed = array();\n        $count = count($channels);\n\n        for ($i = 0; $i < $count; ++$i) {\n            $processed[$channels[$i]] = $channels[++$i];\n        }\n\n        return $processed;\n    }", "label": 2}
{"code": "func NewTrustedCluster(name string, spec TrustedClusterSpecV2) (TrustedCluster, error) {\n\treturn &TrustedClusterV2{\n\t\tKind:    KindTrustedCluster,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName:      name,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: spec,\n\t}, nil\n}", "label": 5}
{"code": "private void ensureCollectionClass(CollectionDescriptorDef collDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        if (collDef.hasProperty(PropertyHelper.OJB_PROPERTY_ARRAY_ELEMENT_CLASS_REF))\r\n        {\r\n            // an array cannot have a collection-class specified \r\n            if (collDef.hasProperty(PropertyHelper.OJB_PROPERTY_COLLECTION_CLASS))\r\n            {\r\n                throw new ConstraintException(\"Collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" is an array but does specify collection-class\");\r\n            }\r\n            else\r\n            {\r\n                // no further processing necessary as its an array\r\n                return;\r\n            }\r\n        }\r\n\r\n        if (CHECKLEVEL_STRICT.equals(checkLevel))\r\n        {    \r\n            InheritanceHelper helper         = new InheritanceHelper();\r\n            ModelDef          model          = (ModelDef)collDef.getOwner().getOwner();\r\n            String            specifiedClass = collDef.getProperty(PropertyHelper.OJB_PROPERTY_COLLECTION_CLASS);\r\n            String            variableType   = collDef.getProperty(PropertyHelper.OJB_PROPERTY_VARIABLE_TYPE);\r\n    \r\n            try\r\n            {\r\n                if (specifiedClass != null)\r\n                {\r\n                    // if we have a specified class then it has to implement the manageable collection and be a sub type of the variable type\r\n                    if (!helper.isSameOrSubTypeOf(specifiedClass, variableType))\r\n                    {\r\n                        throw new ConstraintException(\"The type \"+specifiedClass+\" specified as collection-class of the collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" is not a sub type of the variable type \"+variableType);\r\n                    }\r\n                    if (!helper.isSameOrSubTypeOf(specifiedClass, MANAGEABLE_COLLECTION_INTERFACE))\r\n                    {\r\n                        throw new ConstraintException(\"The type \"+specifiedClass+\" specified as collection-class of the collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" does not implement \"+MANAGEABLE_COLLECTION_INTERFACE);\r\n                    }\r\n                }\r\n                else\r\n                {\r\n                    // no collection class specified so the variable type has to be a collection type\r\n                    if (helper.isSameOrSubTypeOf(variableType, MANAGEABLE_COLLECTION_INTERFACE))\r\n                    {\r\n                        // we can specify it as a collection-class as it is an manageable collection\r\n                        collDef.setProperty(PropertyHelper.OJB_PROPERTY_COLLECTION_CLASS, variableType);\r\n                    }\r\n                    else if (!helper.isSameOrSubTypeOf(variableType, JAVA_COLLECTION_INTERFACE))\r\n                    {\r\n                        throw new ConstraintException(\"The collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" needs the collection-class attribute as its variable type does not implement \"+JAVA_COLLECTION_INTERFACE);\r\n                    }\r\n                }\r\n            }\r\n            catch (ClassNotFoundException ex)\r\n            {\r\n                throw new ConstraintException(\"Could not find the class \"+ex.getMessage()+\" on the classpath while checking the collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName());\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def read_links_file(self,file_path):\n        '''\n        Read links and associated categories for specified articles \n        in text file seperated by a space\n\n        Args:\n            file_path (str): The path to text file with news article links\n                             and category\n\n        Returns:\n            articles: Array of tuples that contains article link & cateogory\n                      ex. [('IPO','www.cs.columbia.edu')]\n        '''\n\n        articles = []\n        with open(file_path) as f:\n            for line in f:\n                line = line.strip()\n                #Ignore blank lines\n                if len(line) != 0:\n                    link,category = line.split(' ')\n                    articles.append((category.rstrip(),link.strip()))\n\n        return articles", "label": 1}
{"code": "function isCollection(object) {\n    if (!object || typeof object !== 'object') {\n        return false;\n    }\n    else if ('isCollection' in object) {\n        diag.debug.assert(function () { return object.isCollection === Collection.prototype.isPrototypeOf(object); });\n        return object.isCollection;\n    }\n    else {\n        return Collection.prototype.isPrototypeOf(object);\n    }\n}", "label": 3}
{"code": "function _assign (target, source) {\n  var s, from, key;\n  var to = Object(target);\n  for (s = 1; s < arguments.length; s++) {\n    from = Object(arguments[s]);\n    for (key in from) {\n      if (own(from, key)) {\n        to[key] = from[key];\n      }\n    }\n  }\n  return to\n}", "label": 3}
{"code": "function cleanup()\n    {\n      if(chan.timer) clearTimeout(chan.timer);\n      chan.timer = setTimeout(function(){\n        chan.state = \"gone\"; // in case an app has a reference\n        x.channels[chan.id] = {state:\"gone\"}; // remove our reference for gc\n      }, chan.timeout);\n    }", "label": 3}
{"code": "public void setProductModules(final String name, final List<String> moduleNames) {\n        final DbProduct dbProduct = getProduct(name);\n        dbProduct.setModules(moduleNames);\n        repositoryHandler.store(dbProduct);\n    }", "label": 0}
{"code": "public function url_stat($path, $flags)\n    {\n        $this->initProtocol($path);\n\n        // Some paths come through as S3:// for some reason.\n        $split = explode('://', $path);\n        $path = strtolower($split[0]) . '://' . $split[1];\n\n        // Check if this path is in the url_stat cache\n        if ($value = $this->getCacheStorage()->get($path)) {\n            return $value;\n        }\n\n        $stat = $this->createStat($path, $flags);\n\n        if (is_array($stat)) {\n            $this->getCacheStorage()->set($path, $stat);\n        }\n\n        return $stat;\n    }", "label": 2}
{"code": "def give_str(self):\n        \"\"\"\n            Give string representation of the callable.\n        \"\"\"\n        args = self._args[:]\n        kwargs = self._kwargs\n        return self._give_str(args, kwargs)", "label": 1}
{"code": "def update_fields(fields)\n      attributes[:id] = fields['id'] || attributes[:id]\n      attributes[:name] = fields['name'] || fields[:name] || attributes[:name]\n      attributes[:description] = fields['desc'] || attributes[:description]\n      attributes[:closed] = fields['closed'] if fields.has_key?('closed')\n      attributes[:url] = fields['url'] || attributes[:url]\n      attributes[:check_items] = fields['checkItems'] if fields.has_key?('checkItems')\n      attributes[:position] = fields['pos'] || attributes[:position]\n      attributes[:board_id] = fields['idBoard'] || attributes[:board_id]\n      attributes[:card_id] = fields['idCard'] || fields[:card_id] || attributes[:card_id]\n      attributes[:list_id] = fields['idList'] || attributes[:list_id]\n      attributes[:member_ids] = fields['idMembers'] || attributes[:member_ids]\n      self\n    end", "label": 4}
{"code": "function _gpfRequireAllocate(parentContext, options) {\n        var context = Object.create(parentContext),\n            // cache content is shared but other properties are protected\n            require = {};\n        require.define = _gpfRequireDefine.bind(context);\n        require.resolve = _gpfRequireResolve.bind(context);\n        require.configure = _gpfRequireConfigure.bind(context);\n        if (options) {\n            require.configure(options);\n        }\n        return require;\n    }", "label": 3}
{"code": "def convert_from_bytes_if_necessary(prefix, suffix):\n    \"\"\"\n    Depending on how we extract data from pysam we may end up with either\n    a string or a byte array of nucleotides. For consistency and simplicity,\n    we want to only use strings in the rest of our code.\n    \"\"\"\n    if isinstance(prefix, bytes):\n        prefix = prefix.decode('ascii')\n\n    if isinstance(suffix, bytes):\n        suffix = suffix.decode('ascii')\n\n    return prefix, suffix", "label": 1}
{"code": "def after_connect(self):\n        \"\"\"Execute after connect.\"\"\"\n        # TODO: check if this works.\n        show_users = self.device.send(\"show users\", timeout=120)\n        result = re.search(pattern_manager.pattern(self.platform, 'connected_locally'), show_users)\n        if result:\n            self.log('Locally connected to Calvados. Exiting.')\n            self.device.send('exit')\n            return True\n        return False", "label": 1}
{"code": "def add_group_users(user_ids)\n      raise 'Attempted to add a user to a non-group channel!' unless group?\n\n      user_ids = [user_ids] unless user_ids.is_a? Array\n      user_ids.each do |user_id|\n        API::Channel.add_group_user(@bot.token, @id, user_id.resolve_id)\n      end\n      self\n    end", "label": 4}
{"code": "func (s *remoteSite) deleteConnectionRecord() {\n\ts.localAccessPoint.DeleteTunnelConnection(s.connInfo.GetClusterName(), s.connInfo.GetName())\n}", "label": 5}
{"code": "func (process *TeleportProcess) WaitWithContext(ctx context.Context) {\n\tlocal, cancel := context.WithCancel(ctx)\n\tgo func() {\n\t\tdefer cancel()\n\t\tprocess.Supervisor.Wait()\n\t}()\n\tselect {\n\tcase <-local.Done():\n\t\treturn\n\t}\n}", "label": 5}
{"code": "function yep(data) {\n          var err;\n\n          if (data instanceof Error) err = data;\n          if (!err && data) backup = collection.content = data;\n          else collection.content = backup;\n\n          self.logger.debug(\n              'Received a'+ (err ? 'n error' : ' processed')\n            + ' response from the '+ layer.id +' plugin '\n            + (collection.length ? 'for a '+ collection.extension +' file' : '')\n          );\n\n          if (err) err.stack.split('\\n').forEach(function print(line) {\n            self.logger.error(line);\n          });\n\n          // Clean up before we continue\n          layer.destroy();\n          capture.dispose();\n\n          processed = collection;\n          done(err, processed);\n        }", "label": 3}
{"code": "public function addCustomStringFunction(string $functionName, $classNameOrFactory) : void\n    {\n        $this->customStringFunctions[strtolower($functionName)] = $classNameOrFactory;\n    }", "label": 2}
{"code": "private static String wordShapeDigits(final String s) {\r\n    char[] outChars = null;\r\n\r\n    for (int i = 0; i < s.length(); i++) {\r\n      char c = s.charAt(i);\r\n      if (Character.isDigit(c)) {\r\n        if (outChars == null) {\r\n          outChars = s.toCharArray();\r\n        }\r\n        outChars[i] = '9';\r\n      }\r\n    }\r\n    if (outChars == null) {\r\n      // no digit found\r\n      return s;\r\n    } else {\r\n      return new String(outChars);\r\n    }\r\n  }", "label": 0}
{"code": "function generateColors(conf) {\n  for (var key in conf.color) {\n    if (typeof conf.color[key] !== 'string') continue;\n    conf.color[key] = new Color(conf.color[key]);\n  }\n  return conf;\n}", "label": 3}
{"code": "func UpdateEventFields(event Event, fields EventFields, clock clockwork.Clock, uid utils.UID) (err error) {\n\tadditionalFields := make(map[string]interface{})\n\tif fields.GetType() == \"\" {\n\t\tadditionalFields[EventType] = event.Name\n\t}\n\tif fields.GetID() == \"\" {\n\t\tadditionalFields[EventID] = uid.New()\n\t}\n\tif fields.GetTimestamp().IsZero() {\n\t\tadditionalFields[EventTime] = clock.Now().UTC().Round(time.Second)\n\t}\n\tif event.Code != \"\" {\n\t\tadditionalFields[EventCode] = event.Code\n\t}\n\tfor k, v := range additionalFields {\n\t\tfields[k] = v\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def attribute_will_change!(attr)\n      unless changed_attributes.key?(attr)\n        changed_attributes[attr] = read_raw_attribute(attr).__deep_copy__\n      end\n    end", "label": 4}
{"code": "def http_cache_forever(public: false)\n      expires_in 100.years, public: public\n\n      yield if stale?(etag: request.fullpath,\n                      last_modified: Time.new(2011, 1, 1).utc,\n                      public: public)\n    end", "label": 4}
{"code": "func (s *AuthServer) PreAuthenticatedSignIn(user string) (services.WebSession, error) {\n\tsess, err := s.NewWebSession(user)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif err := s.UpsertWebSession(user, sess); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn sess.WithoutSecrets(), nil\n}", "label": 5}
{"code": "func PgPolicyByOid(db XODB, oid pgtypes.Oid) (*PgPolicy, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, polname, polrelid, polcmd, polroles, polqual, polwithcheck ` +\n\t\t`FROM pg_catalog.pg_policy ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpp := PgPolicy{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pp.Tableoid, &pp.Cmax, &pp.Xmax, &pp.Cmin, &pp.Xmin, &pp.Oid, &pp.Ctid, &pp.Polname, &pp.Polrelid, &pp.Polcmd, &pp.Polroles, &pp.Polqual, &pp.Polwithcheck)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pp, nil\n}", "label": 5}
{"code": "def truncate(string, len = 128)\n      stripped = string.strip[0..len]\n      if stripped.length > len\n        stripped.gsub(/\\s+?(\\S+)?$/, \"\") + \"...\"\n      else\n        stripped\n      end\n    end", "label": 4}
{"code": "def __purge():\n    \"\"\"Remove all dead signal receivers from the global receivers collection.\n\n    Note:\n        It is assumed that the caller holds the __lock.\n    \"\"\"\n    global __receivers\n    newreceivers = collections.defaultdict(list)\n\n    for signal, receivers in six.iteritems(__receivers):\n        alive = [x for x in receivers if not __is_dead(x)]\n        newreceivers[signal] = alive\n\n    __receivers = newreceivers", "label": 1}
{"code": "function convertToBase64(input) {\n        var result = \"\";\n        var charCodes = getExpandedCharCodes(input);\n        var i = 0;\n        var length = charCodes.length;\n        var byte1, byte2, byte3, byte4;\n        while (i < length) {\n            // Convert every 6-bits in the input 3 character points\n            // into a base64 digit\n            byte1 = charCodes[i] >> 2;\n            byte2 = (charCodes[i] & 3) << 4 | charCodes[i + 1] >> 4;\n            byte3 = (charCodes[i + 1] & 15) << 2 | charCodes[i + 2] >> 6;\n            byte4 = charCodes[i + 2] & 63;\n            // We are out of characters in the input, set the extra\n            // digits to 64 (padding character).\n            if (i + 1 >= length) {\n                byte3 = byte4 = 64;\n            }\n            else if (i + 2 >= length) {\n                byte4 = 64;\n            }\n            // Write to the output\n            result += base64Digits.charAt(byte1) + base64Digits.charAt(byte2) + base64Digits.charAt(byte3) + base64Digits.charAt(byte4);\n            i += 3;\n        }\n        return result;\n    }", "label": 3}
{"code": "function getGlyphs($originalGlyphIdx, &$start, &$glyphSet, &$subsetglyphs)\n\t{\n\t\t$glyphPos = $this->glyphPos[$originalGlyphIdx];\n\t\t$glyphLen = $this->glyphPos[$originalGlyphIdx + 1] - $glyphPos;\n\t\tif (!$glyphLen) {\n\t\t\treturn;\n\t\t}\n\t\t$this->seek($start + $glyphPos);\n\t\t$numberOfContours = $this->read_short();\n\t\tif ($numberOfContours < 0) {\n\t\t\t$this->skip(8);\n\t\t\t$flags = GlyphOperator::MORE;\n\t\t\twhile ($flags & GlyphOperator::MORE) {\n\t\t\t\t$flags = $this->read_ushort();\n\t\t\t}\n\t\t\t$glyphIdx = $this->read_ushort();\n\t\t\tif (!isset($glyphSet[$glyphIdx])) {\n\t\t\t\t$glyphSet[$glyphIdx] = count($subsetglyphs); // old glyphID to new glyphID\n\t\t\t\t$subsetglyphs[$glyphIdx] = true;\n\t\t\t}\n\t\t\t$savepos = ftell($this->fh);\n\t\t\t$this->getGlyphs($glyphIdx, $start, $glyphSet, $subsetglyphs);\n\t\t\t$this->seek($savepos);\n\t\t\tif ($flags & GlyphOperator::WORDS) {\n\t\t\t\t$this->skip(4);\n\t\t\t} else {\n\t\t\t\t$this->skip(2);\n\t\t\t}\n\t\t\tif ($flags & GlyphOperator::SCALE) {\n\t\t\t\t$this->skip(2);\n\t\t\t} else {\n\t\t\t\tif ($flags & GlyphOperator::XYSCALE) {\n\t\t\t\t\t$this->skip(4);\n\t\t\t\t} else {\n\t\t\t\t\tif ($flags & GlyphOperator::TWOBYTWO) {\n\t\t\t\t\t\t$this->skip(8);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "public static double J(int n, double x) {\r\n        int j, m;\r\n        double ax, bj, bjm, bjp, sum, tox, ans;\r\n        boolean jsum;\r\n\r\n        double ACC = 40.0;\r\n        double BIGNO = 1.0e+10;\r\n        double BIGNI = 1.0e-10;\r\n\r\n        if (n == 0) return J0(x);\r\n        if (n == 1) return J(x);\r\n\r\n        ax = Math.abs(x);\r\n        if (ax == 0.0) return 0.0;\r\n        else if (ax > (double) n) {\r\n            tox = 2.0 / ax;\r\n            bjm = J0(ax);\r\n            bj = J(ax);\r\n            for (j = 1; j < n; j++) {\r\n                bjp = j * tox * bj - bjm;\r\n                bjm = bj;\r\n                bj = bjp;\r\n            }\r\n            ans = bj;\r\n        } else {\r\n            tox = 2.0 / ax;\r\n            m = 2 * ((n + (int) Math.sqrt(ACC * n)) / 2);\r\n            jsum = false;\r\n            bjp = ans = sum = 0.0;\r\n            bj = 1.0;\r\n            for (j = m; j > 0; j--) {\r\n                bjm = j * tox * bj - bjp;\r\n                bjp = bj;\r\n                bj = bjm;\r\n                if (Math.abs(bj) > BIGNO) {\r\n                    bj *= BIGNI;\r\n                    bjp *= BIGNI;\r\n                    ans *= BIGNI;\r\n                    sum *= BIGNI;\r\n                }\r\n                if (jsum) sum += bj;\r\n                jsum = !jsum;\r\n                if (j == n) ans = bjp;\r\n            }\r\n            sum = 2.0 * sum - bj;\r\n            ans /= sum;\r\n        }\r\n\r\n        return x < 0.0 && n % 2 == 1 ? -ans : ans;\r\n    }", "label": 0}
{"code": "func (process *TeleportProcess) createListener(listenerType, address string) (net.Listener, error) {\n\tlistener, err := net.Listen(\"tcp\", address)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tprocess.Lock()\n\tdefer process.Unlock()\n\tr := RegisteredListener{Type: listenerType, Address: address, Listener: listener}\n\tprocess.registeredListeners = append(process.registeredListeners, r)\n\treturn listener, nil\n}", "label": 5}
{"code": "public function setKind($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\KindExpression::class);\n        $this->kind = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def add(name, value)\n      name = normalize_header name.to_s\n      Array(value).each { |v| @pile << [name, validate_value(v)] }\n    end", "label": 4}
{"code": "func NewHandle(app string, ds datastore.DataStore, id string, numElements uint64) (*Handle, error) {\n\th := &Handle{\n\t\tapp:        app,\n\t\tid:         id,\n\t\tstore:      ds,\n\t\tbits:       numElements,\n\t\tunselected: numElements,\n\t\thead: &sequence{\n\t\t\tblock: 0x0,\n\t\t\tcount: getNumBlocks(numElements),\n\t\t},\n\t}\n\n\tif h.store == nil {\n\t\treturn h, nil\n\t}\n\n\t// Get the initial status from the ds if present.\n\tif err := h.store.GetObject(datastore.Key(h.Key()...), h); err != nil && err != datastore.ErrKeyNotFound {\n\t\treturn nil, err\n\t}\n\n\t// If the handle is not in store, write it.\n\tif !h.Exists() {\n\t\tif err := h.writeToStore(); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to write bitsequence to store: %v\", err)\n\t\t}\n\t}\n\n\treturn h, nil\n}", "label": 5}
{"code": "function yamlFileGet(file, keyPath, options) {\n  if (_.isPlainObject(keyPath) && arguments.length === 2) {\n    options = keyPath;\n    keyPath = undefined;\n  }\n  options = _.sanitize(options, {encoding: 'utf-8', default: ''});\n  const content = yaml.safeLoad(read(file, _.pick(options, 'encoding')));\n  const value = _extractValue(content, keyPath);\n  return _.isUndefined(value) ? options.default : value;\n}", "label": 3}
{"code": "def print_version(options)\n      log.log \"#{HamlLint::APP_NAME} #{HamlLint::VERSION}\"\n\n      if options[:verbose_version]\n        log.log \"haml #{Gem.loaded_specs['haml'].version}\"\n        log.log \"rubocop #{Gem.loaded_specs['rubocop'].version}\"\n        log.log RUBY_DESCRIPTION\n      end\n    end", "label": 4}
{"code": "function(regex) {\n  var self = this; var re = new RegExp(regex);\n  var keys = {};\n  self.init = function() { keys = {}; };\n  self.accumulate = function(line) {\n    var m = re.exec(line);\n    if (m == null) return;\n    var k = m[1]; // use 1st group as key\n    var v = keys[k];\n    if (v) keys[k] = v+1; else keys[k] = 1; // count by key\n  };\n  self.compensate = function(line) {\n    var m = re.exec(line);\n    if (m == null) return;\n    var k = m[1]; // use 1st group as key\n    var v = keys[k];\n    if (v) keys[k] = v-1; else keys[k] = 1;\n  };\n  self.emit = function() {\n    return keys;\n  };\n  self.make = function() { return new WideFinderFunction(regex); };\n}", "label": 3}
{"code": "function handleMessages(file, messages, options) {\n\tvar success = true;\n\tvar errorText = colors.bold(colors.red('HTML Error:'));\n\tvar warningText = colors.bold(colors.yellow('HTML Warning:'));\n\tvar infoText = colors.bold(colors.green('HTML Info:'));\n\tvar lines = file.contents.toString().split(/\\r\\n|\\r|\\n/g);\n\n\tif (!Array.isArray(messages)) {\n\t\tfancyLog(warningText, 'Failed to run validation on', file.relative);\n\n\t\t// Not sure whether this should be true or false\n\t\treturn true;\n\t}\n\n\tmessages.forEach(function (message) {\n\n\t\t// allows you to intercept info, warnings or errors, using `options.verifyMessage` methed, returning false will skip the log output \n\t\tif(options.verifyMessage && !options.verifyMessage(message.type, message.message)) return;\n\n\t\tif (message.type === 'info' && !options.showInfo) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (message.type === 'error') {\n\t\t\tsuccess = false;\n\t\t}\n\n\t\tvar type = (message.type === 'error') ? errorText : ((message.type === 'info') ? infoText : warningText);\n\n\t\tvar location = 'Line ' + (message.lastLine || 0) + ', Column ' + (message.lastColumn || 0) + ':';\n\n\t\tvar erroredLine = lines[message.lastLine - 1];\n\n\t\t// If this is false, stream was changed since validation\n\t\tif (erroredLine) {\n\t\t\tvar errorColumn = message.lastColumn;\n\n\t\t\t// Trim before if the error is too late in the line\n\t\t\tif (errorColumn > 60) {\n\t\t\t\terroredLine = erroredLine.slice(errorColumn - 50);\n\t\t\t\terrorColumn = 50;\n\t\t\t}\n\n\t\t\t// Trim after so the line is not too long\n\t\t\terroredLine = erroredLine.slice(0, 60);\n\n\t\t\t// Highlight character with error\n\t\t\terroredLine =\n\t\t\t\tcolors.grey(erroredLine.substring(0, errorColumn - 1)) +\n\t\t\t\tcolors.bold(colors.red(erroredLine[ errorColumn - 1 ])) +\n\t\t\t\tcolors.grey(erroredLine.substring(errorColumn));\n\t\t}\n\n\t\tif (typeof(message.lastLine) !== 'undefined' || typeof(lastColumn) !== 'undefined') {\n\t\t\tfancyLog(type, file.relative, location, message.message);\n\t\t} else {\n\t\t\tfancyLog(type, file.relative, message.message);\n\t\t}\n\n\t\tif (erroredLine) {\n\t\t\tfancyLog(erroredLine);\n\t\t}\n\t});\n\n\treturn success;\n}", "label": 3}
{"code": "func (h *AuthHandlers) CheckAgentForward(ctx *ServerContext) error {\n\tif err := ctx.Identity.RoleSet.CheckAgentForward(ctx.Identity.Login); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "private String getIndirectionTableColName(TableAlias mnAlias, String path)\r\n    {\r\n        int dotIdx = path.lastIndexOf(\".\");\r\n        String column = path.substring(dotIdx);\r\n        return mnAlias.alias + column;\r\n    }", "label": 0}
{"code": "public void addCommandClass(ZWaveCommandClass commandClass) {\r\n\t\tZWaveCommandClass.CommandClass key = commandClass.getCommandClass();\r\n\t\tif (!supportedCommandClasses.containsKey(key)) {\r\n\t\t\tsupportedCommandClasses.put(key, commandClass);\r\n\t\t}\r\n\t}", "label": 0}
{"code": "function _getFindFunction(CurrentEntity) {\n  return function (query, params) {\n    expect(arguments).to.have.length.within(\n      1,\n      2,\n      'Invalid arguments length when finding an Entity ' +\n      '(it has to be passed 1 or 2 arguments)'\n    );\n\n    expect(query).to.be.an(\n      'object',\n      'Invalid argument when finding an Entity (it has to be an object)'\n    );\n\n    return Promise.try(function () {\n      var adapter = CurrentEntity.adapter;\n      return adapter.findObjects(CurrentEntity, query, params);\n    });\n  };\n}", "label": 3}
{"code": "function() {\n            var messages = app.database.messages.find({ threadId: this.uid }, ok(this.set.bind(this, \"messages\")));\n\n            // update unreadMessageCount whenever the messages collection\n            // changes\n            messages.watch(function() {\n                this.set(\"unreadMessageCount\", messages.filter(function(message) {\n                    return !message.read;\n                }).length);\n            }.bind(this));\n        }", "label": 3}
{"code": "public function connect_to_all_dcs_async(): \\Generator\n    {\n        $this->datacenter->__construct($this, $this->settings['connection'], $this->settings['connection_settings']);\n        $dcs = [];\n        foreach ($this->datacenter->get_dcs() as $new_dc) {\n            $dcs[] = $this->datacenter->dc_connect_async($new_dc);\n        }\n        yield $dcs;\n        yield $this->init_authorization_async();\n        $dcs = [];\n        foreach ($this->datacenter->get_dcs(false) as $new_dc) {\n            $dcs[] = $this->datacenter->dc_connect_async($new_dc);\n        }\n        yield $dcs;\n        yield $this->init_authorization_async();\n        if (!$this->phoneConfigWatcherId) {\n            $this->phoneConfigWatcherId = Loop::repeat(24 * 3600 * 1000, [$this, 'get_phone_config_async']);\n        }\n\n        yield $this->get_phone_config_async();\n        $this->logger->logger(\"Started phone config fetcher\");\n    }", "label": 2}
{"code": "def run(self, output=None, error=None):\n        \"\"\" Runs pylint on all python files in the current directory \"\"\"\n\n        pylint_output = output if output is not None else sys.stdout\n        pylint_error = error if error is not None else sys.stderr\n        savedout, savederr = sys.__stdout__, sys.__stderr__\n        sys.stdout = pylint_output\n        sys.stderr = pylint_error\n\n        pylint_files = self.get_files_from_dir(os.curdir)\n        self._print_line(\n            \"Using pylint \"\n            + colorama.Fore.RED\n            + pylint.__version__\n            + colorama.Fore.RESET\n            + \" for python \"\n            + colorama.Fore.RED\n            + PYTHON_VERSION\n            + colorama.Fore.RESET\n        )\n\n        self._print_line(\"pylint running on the following files:\")\n        for pylint_file in pylint_files:\n            # we need to recast this as a string, else pylint enters an endless recursion\n            split_file = str(pylint_file).split(\"/\")\n            split_file[-1] = colorama.Fore.CYAN + split_file[-1] + colorama.Fore.RESET\n            pylint_file = \"/\".join(split_file)\n            self._print_line(\"- \" + pylint_file)\n        self._print_line(\"----\")\n\n        if not self._is_using_default_rcfile():\n            self.args += [\"--rcfile={}\".format(self.rcfile)]\n\n        exit_kwarg = {\"do_exit\": False}\n\n        run = pylint.lint.Run(self.args + pylint_files, **exit_kwarg)\n        sys.stdout = savedout\n        sys.stderr = savederr\n\n        sys.exit(run.linter.msg_status)", "label": 1}
{"code": "protected void removeSequence(String sequenceName)\r\n    {\r\n        // lookup the sequence map for calling DB\r\n        Map mapForDB = (Map) sequencesDBMap.get(getBrokerForClass()\r\n                .serviceConnectionManager().getConnectionDescriptor().getJcdAlias());\r\n        if(mapForDB != null)\r\n        {\r\n            synchronized(SequenceManagerHighLowImpl.class)\r\n            {\r\n                mapForDB.remove(sequenceName);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "function traverseFilters(config, levels, levelIdx) {\n    var lastIdx = levels.length - 1;\n    var val, filters;\n\n    if (!config || levelIdx > lastIdx) { return null; }\n\n    val = config[levels[levelIdx]];\n\n\n    if (levelIdx === lastIdx) {\n        if (val) {\n            return val;\n        }\n        else {\n            return config.all;\n        }\n    }\n    else {\n        filters = traverseFilters(val, levels, levelIdx + 1);\n        if (!filters) {\n            filters = traverseFilters(config.all, levels, levelIdx + 1);\n        }\n        return filters;\n    }\n}", "label": 3}
{"code": "def label_rotation=(v)\n      Axlsx::validate_int(v)\n      adjusted = v.to_i * 60000\n      Axlsx::validate_angle(adjusted)\n      @label_rotation = adjusted\n    end", "label": 4}
{"code": "public function getResize()\n    {\n        $ratio = 1.0;\n        $image = request('img');\n\n        $original_image = Image::make($this->lfm->setName($image)->path('absolute'));\n        $original_width = $original_image->width();\n        $original_height = $original_image->height();\n\n        $scaled = false;\n\n        // FIXME size should be configurable\n        if ($original_width > 600) {\n            $ratio = 600 / $original_width;\n            $width = $original_width * $ratio;\n            $height = $original_height * $ratio;\n            $scaled = true;\n        } else {\n            $width = $original_width;\n            $height = $original_height;\n        }\n\n        if ($height > 400) {\n            $ratio = 400 / $original_height;\n            $width = $original_width * $ratio;\n            $height = $original_height * $ratio;\n            $scaled = true;\n        }\n\n        return view('laravel-filemanager::resize')\n            ->with('img', $this->lfm->pretty($image))\n            ->with('height', number_format($height, 0))\n            ->with('width', $width)\n            ->with('original_height', $original_height)\n            ->with('original_width', $original_width)\n            ->with('scaled', $scaled)\n            ->with('ratio', $ratio);\n    }", "label": 2}
{"code": "protected static function collectUpdates($batchId)\n    {\n        return collect(static::$updatesQueue)\n            ->each(function ($entry) use ($batchId) {\n                $entry->change(['updated_batch_id' => $batchId]);\n            });\n    }", "label": 2}
{"code": "protected Tree determineNonTrivialHead(Tree t, Tree parent) {\r\n    Tree theHead = null;\r\n    String motherCat = tlp.basicCategory(t.label().value());\r\n    if (DEBUG) {\r\n      System.err.println(\"Looking for head of \" + t.label() +\r\n                         \"; value is |\" + t.label().value() + \"|, \" +\r\n                         \" baseCat is |\" + motherCat + '|');\r\n    }\r\n    // We know we have nonterminals underneath\r\n    // (a bit of a Penn Treebank assumption, but).\r\n\r\n    // Look at label.\r\n    // a total special case....\r\n    // first look for POS tag at end\r\n    // this appears to be redundant in the Collins case since the rule already would do that\r\n    //    Tree lastDtr = t.lastChild();\r\n    //    if (tlp.basicCategory(lastDtr.label().value()).equals(\"POS\")) {\r\n    //      theHead = lastDtr;\r\n    //    } else {\r\n    String[][] how = nonTerminalInfo.get(motherCat);\r\n    if (how == null) {\r\n      if (DEBUG) {\r\n        System.err.println(\"Warning: No rule found for \" + motherCat +\r\n                           \" (first char: \" + motherCat.charAt(0) + ')');\r\n        System.err.println(\"Known nonterms are: \" + nonTerminalInfo.keySet());\r\n      }\r\n      if (defaultRule != null) {\r\n        if (DEBUG) {\r\n          System.err.println(\"  Using defaultRule\");\r\n        }\r\n        return traverseLocate(t.children(), defaultRule, true);\r\n      } else {\r\n        return null;\r\n      }\r\n    }\r\n    for (int i = 0; i < how.length; i++) {\r\n      boolean lastResort = (i == how.length - 1);\r\n      theHead = traverseLocate(t.children(), how[i], lastResort);\r\n      if (theHead != null) {\r\n        break;\r\n      }\r\n    }\r\n    if (DEBUG) {\r\n      System.err.println(\"  Chose \" + theHead.label());\r\n    }\r\n    return theHead;\r\n  }", "label": 0}
{"code": "def valid_message?(signed_message)\n      return if signed_message.nil? || !signed_message.valid_encoding? || signed_message.blank?\n\n      data, digest = signed_message.split(\"--\")\n      data.present? && digest.present? && ActiveSupport::SecurityUtils.secure_compare(digest, generate_digest(data))\n    end", "label": 4}
{"code": "public static base_response add(nitro_service client, nslimitselector resource) throws Exception {\n\t\tnslimitselector addresource = new nslimitselector();\n\t\taddresource.selectorname = resource.selectorname;\n\t\taddresource.rule = resource.rule;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function (logLevel, args) {\n            const time = dateFormat(new Date(), 'dd/mm/yyyy, h:MM:ss.l tt');\n            // Each logger can have its own name. If this is\n            // not provided, it will default to Unknown.\n            const loggerName = __private.name || Constants.LOG_UNKNOWN_APP_ID;\n            return [ (logLevel.name.length === 4 ? ' ' : '') +\n                getLogLabel(logLevel)('[' + logLevel.name + ']'), time, '-',\n            loggerName.padEnd(Constants.LOG_APP_ID_WIDTH), ':'].concat(Object.values(args));\n        }", "label": 3}
{"code": "public function insertBatch(array $entities)\n    {\n        $entities = $this->operation->allocateIdsToEntities($entities);\n        foreach ($entities as $entity) {\n            $this->mutations[] = $this->operation->mutation('insert', $entity, Entity::class);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def set(opts)\n      # Store new window attributes, or ignore if nil\n      @title           = opts[:title]           || @title\n      if Color.is_valid? opts[:background]\n        @background    = Color.new(opts[:background])\n      end\n      @icon            = opts[:icon]            || @icon\n      @width           = opts[:width]           || @width\n      @height          = opts[:height]          || @height\n      @fps_cap         = opts[:fps_cap]         || @fps_cap\n      @viewport_width  = opts[:viewport_width]  || @viewport_width\n      @viewport_height = opts[:viewport_height] || @viewport_height\n      @resizable       = opts[:resizable]       || @resizable\n      @borderless      = opts[:borderless]      || @borderless\n      @fullscreen      = opts[:fullscreen]      || @fullscreen\n      @highdpi         = opts[:highdpi]         || @highdpi\n      unless opts[:diagnostics].nil?\n        @diagnostics = opts[:diagnostics]\n        ext_diagnostics(@diagnostics)\n      end\n    end", "label": 4}
{"code": "public function toRegionTimeZone(DateTimeInterface $date = null)\n    {\n        $tz = $this->toRegionName($date);\n\n        if ($tz === false) {\n            if (Carbon::isStrictModeEnabled()) {\n                throw new InvalidArgumentException('Unknown timezone for offset '.$this->getOffset($date ?: Carbon::now($this)).' seconds.');\n            }\n\n            return false;\n        }\n\n        return new static($tz);\n    }", "label": 2}
{"code": "public function batch()\n    {\n        return new WriteBatch(\n            $this->connection,\n            $this->valueMapper,\n            $this->databaseName(\n                $this->projectId,\n                $this->database\n            )\n        );\n    }", "label": 2}
{"code": "public static clusternodegroup_nslimitidentifier_binding[] get(nitro_service service, String name) throws Exception{\n\t\tclusternodegroup_nslimitidentifier_binding obj = new clusternodegroup_nslimitidentifier_binding();\n\t\tobj.set_name(name);\n\t\tclusternodegroup_nslimitidentifier_binding response[] = (clusternodegroup_nslimitidentifier_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static Bounds getSymmetricBounds(int dim, double l, double u) {\n        double [] L = new double[dim];\n        double [] U = new double[dim];\n        for(int i=0; i<dim; i++) {\n            L[i] = l;\n            U[i] = u;\n        }\n        return new Bounds(L, U);\n    }", "label": 0}
{"code": "public function setAvailableZones($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Redis\\V1\\ZoneMetadata::class);\n        $this->available_zones = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func totalBytesEstimate(tc *torrent.Client) (ret int64) {\n\tvar noInfo, hadInfo int64\n\tfor _, t := range tc.Torrents() {\n\t\tinfo := t.Info()\n\t\tif info == nil {\n\t\t\tnoInfo++\n\t\t\tcontinue\n\t\t}\n\t\tret += info.TotalLength()\n\t\thadInfo++\n\t}\n\tif hadInfo != 0 {\n\t\t// Treat each torrent without info as the average of those with,\n\t\t// rounded up.\n\t\tret += (noInfo*ret + hadInfo - 1) / hadInfo\n\t}\n\treturn\n}", "label": 5}
{"code": "protected function loadMessagesFromFile($locale)\n    {\n        if (isset($this->messages[$locale])) {\n            return true;\n        }\n\n        return $this->resetMessages($locale);\n    }", "label": 2}
{"code": "public static base_response add(nitro_service client, appflowcollector resource) throws Exception {\n\t\tappflowcollector addresource = new appflowcollector();\n\t\taddresource.name = resource.name;\n\t\taddresource.ipaddress = resource.ipaddress;\n\t\taddresource.port = resource.port;\n\t\taddresource.netprofile = resource.netprofile;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public function reuse($str)\n    {\n        $this->str = $str;\n        $this->str_length = mb_strlen($this->str, 'ASCII');\n        $this->offset = 0;\n        $this->bitcount = $this->bits = 0;\n    }", "label": 2}
{"code": "func lookup(\n\tfirst func(i int) net.IP,\n\tfull func(i int) Range,\n\tn int,\n\tip net.IP,\n) (\n\tr Range, ok bool,\n) {\n\t// Find the index of the first range for which the following range exceeds\n\t// it.\n\ti := sort.Search(n, func(i int) bool {\n\t\tif i+1 >= n {\n\t\t\treturn true\n\t\t}\n\t\treturn bytes.Compare(ip, first(i+1)) < 0\n\t})\n\tif i == n {\n\t\treturn\n\t}\n\tr = full(i)\n\tok = bytes.Compare(r.First, ip) <= 0 && bytes.Compare(ip, r.Last) <= 0\n\treturn\n}", "label": 5}
{"code": "function getTimeIntervalMeasurementUnits(localeData, restrictedSetOfUnits)\n{\n\t// All available time interval measurement units.\n\tlet units = Object.keys(localeData)\n\n\t// If only a specific set of available\n\t// time measurement units can be used.\n\tif (restrictedSetOfUnits) {\n\t\t// Reduce available time interval measurement units\n\t\t// based on user's preferences.\n\t\tunits = restrictedSetOfUnits.filter(_ => units.indexOf(_) >= 0)\n\t}\n\n\t// Stock `Intl.RelativeTimeFormat` locale data doesn't have \"now\" units.\n\t// So either \"now\" is present in extended locale data\n\t// or it's taken from \".second.current\".\n\tif ((!restrictedSetOfUnits || restrictedSetOfUnits.indexOf('now') >= 0) &&\n\t\tunits.indexOf('now') < 0) {\n\t\tif (localeData.second.current) {\n\t\t\tunits.unshift('now')\n\t\t}\n\t}\n\n\treturn units\n}", "label": 3}
{"code": "func AuthPermissionByID(db XODB, id int) (*AuthPermission, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, name, content_type_id, codename ` +\n\t\t`FROM public.auth_permission ` +\n\t\t`WHERE id = $1`\n\n\t// run query\n\tXOLog(sqlstr, id)\n\tap := AuthPermission{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, id).Scan(&ap.ID, &ap.Name, &ap.ContentTypeID, &ap.Codename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ap, nil\n}", "label": 5}
{"code": "public static aaapreauthenticationpolicy_aaaglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\taaapreauthenticationpolicy_aaaglobal_binding obj = new aaapreauthenticationpolicy_aaaglobal_binding();\n\t\tobj.set_name(name);\n\t\taaapreauthenticationpolicy_aaaglobal_binding response[] = (aaapreauthenticationpolicy_aaaglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func addIntToIP(array []byte, ordinal uint64) {\n\tfor i := len(array) - 1; i >= 0; i-- {\n\t\tarray[i] |= (byte)(ordinal & 0xff)\n\t\tordinal >>= 8\n\t}\n}", "label": 5}
{"code": "public function read_value($fieldType, $collectionsAsObjects = false)\n    {\n        $this->bitcount = $this->bits = 0;\n\n        switch ($fieldType) {\n            case AMQPAbstractCollection::T_INT_SHORTSHORT:\n                //according to AMQP091 spec, 'b' is not bit, it is short-short-int, also valid for rabbit/qpid\n                //$val=$this->read_bit();\n                $val = $this->read_signed_octet();\n                break;\n            case AMQPAbstractCollection::T_INT_SHORTSHORT_U:\n                $val = $this->read_octet();\n                break;\n            case AMQPAbstractCollection::T_INT_SHORT:\n                $val = $this->read_signed_short();\n                break;\n            case AMQPAbstractCollection::T_INT_SHORT_U:\n                $val = $this->read_short();\n                break;\n            case AMQPAbstractCollection::T_INT_LONG:\n                $val = $this->read_signed_long();\n                break;\n            case AMQPAbstractCollection::T_INT_LONG_U:\n                $val = $this->read_long();\n                break;\n            case AMQPAbstractCollection::T_INT_LONGLONG:\n                $val = $this->read_signed_longlong();\n                break;\n            case AMQPAbstractCollection::T_INT_LONGLONG_U:\n                $val = $this->read_longlong();\n                break;\n            case AMQPAbstractCollection::T_DECIMAL:\n                $e = $this->read_octet();\n                $n = $this->read_signed_long();\n                $val = new AMQPDecimal($n, $e);\n                break;\n            case AMQPAbstractCollection::T_TIMESTAMP:\n                $val = $this->read_timestamp();\n                break;\n            case AMQPAbstractCollection::T_BOOL:\n                $val = $this->read_octet();\n                break;\n            case AMQPAbstractCollection::T_STRING_SHORT:\n                $val = $this->read_shortstr();\n                break;\n            case AMQPAbstractCollection::T_STRING_LONG:\n                $val = $this->read_longstr();\n                break;\n            case AMQPAbstractCollection::T_ARRAY:\n                $val = $this->read_array($collectionsAsObjects);\n                break;\n            case AMQPAbstractCollection::T_TABLE:\n                $val = $this->read_table($collectionsAsObjects);\n                break;\n            case AMQPAbstractCollection::T_VOID:\n                $val = null;\n                break;\n            case AMQPAbstractCollection::T_BYTES:\n                $val = $this->read_longstr();\n                break;\n            default:\n                throw new AMQPInvalidArgumentException(sprintf(\n                    'Unsupported type \"%s\"',\n                    $fieldType\n                ));\n        }\n\n        return isset($val) ? $val : null;\n    }", "label": 2}
{"code": "def _add_mermaid_js(self):\n        \"\"\"add js libraries and css files of mermaid js_file\"\"\"\n        self.add_javascripts('{}/js/jquery-1.11.3.min.js'.format(self.resources_path))\n        self.add_javascripts('{}/js/mermaid.min.js'.format(self.resources_path))\n        self.add_stylesheets('{}/css/mermaid.css'.format(self.resources_path))\n        self.main_soup.script.append('mermaid.initialize({startOnLoad:true  });')", "label": 1}
{"code": "def pbf(self, bbox, geo_col=None, scale=4096):\n        \"\"\"Returns tranlated and scaled geometries suitable for Mapbox vector\n        tiles.\n        \"\"\"\n        col = geo_col or self.geo_field.name\n        w, s, e, n = bbox.extent\n        trans = self._trans_scale(col, -w, -s,\n                                  scale / (e - w),\n                                  scale / (n - s))\n        g = AsText(trans)\n        return self.annotate(pbf=g)", "label": 1}
{"code": "def summarise(self):\n        \"\"\" \n        extrapolate a human readable summary of the contexts \n        \"\"\"\n        res = ''\n        if self.user == 'Developer': \n            if self.host == 'Home PC':\n                res += 'At Home'\n            else:\n                res += 'Away from PC'\n        elif self.user == 'User' and self.host == 'Home PC':\n            res += 'Remote desktop into home PC'\n        res += '\\n'\n        res += self.transport\n        return res", "label": 1}
{"code": "def uniq(input, property = nil)\n      ary = InputIterator.new(input)\n\n      if property.nil?\n        ary.uniq\n      elsif ary.empty? # The next two cases assume a non-empty array.\n        []\n      elsif ary.first.respond_to?(:[])\n        begin\n          ary.uniq { |a| a[property] }\n        rescue TypeError\n          raise_property_error(property)\n        end\n      end\n    end", "label": 4}
{"code": "function () {\n            var result = [];\n            _gpfObjectForEach(this._members, function (attributes, member) {\n                _gpfIgnore(attributes);\n                result.push(_gpfDecodeAttributeMember(member));\n            });\n            return result;\n        }", "label": 3}
{"code": "protected function createFilterTuple(array $parameters)\n    {\n        $method = array_shift($parameters);\n\n        if (!$this->isCarbonPredicateMethod($method)) {\n            return [$method, array_shift($parameters)];\n        }\n\n        return [function ($date) use ($method, $parameters) {\n            return call_user_func_array([$date, $method], $parameters);\n        }, $method];\n    }", "label": 2}
{"code": "function windowReadiness({ document }) {\n  if (document.readyState === \"loading\") {\n    // Loading hasn't finished yet\n    return new Promise((resolve, reject) =>\n      document.addEventListener(\"DOMContentLoaded\", resolve)\n    );\n  }\n  // it's ready\n}", "label": 3}
{"code": "func cleanupStage1(appName *types.ACName, enterCmd []string) error {\n\t// TODO(lucab): re-evaluate once/if we support systemd as non-pid1 (eg. host pid-ns inheriting)\n\tmnts, err := mountinfo.ParseMounts(1)\n\tif err != nil {\n\t\treturn err\n\t}\n\tappRootFs := filepath.Join(\"/opt/stage2\", appName.String(), \"rootfs\")\n\tmnts = mnts.Filter(mountinfo.HasPrefix(appRootFs))\n\n\t// soft-errors here, stage0 may still be able to continue with the removal anyway\n\tfor _, m := range mnts {\n\t\t// unlink first to avoid back-propagation\n\t\t_ = syscall.Mount(\"\", m.MountPoint, \"\", syscall.MS_PRIVATE|syscall.MS_REC, \"\")\n\t\t// simple unmount, it may fail if the target is busy (eg. overlapping children)\n\t\tif e := syscall.Unmount(m.MountPoint, 0); e != nil {\n\t\t\t// if busy, just detach here and let the kernel clean it once free\n\t\t\t_ = syscall.Unmount(m.MountPoint, syscall.MNT_DETACH)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def navactive(request, url, exact=0, use_resolver=1):\n    \"\"\"\n    Returns ``active`` if the given URL is in the url path, otherwise ''.\n\n    Usage::\n\n        {% load libs_tags %}\n        ...\n        <li class=\"{% navactive request \"/news/\" exact=1 %}\">\n\n    :param request: A request instance.\n    :param url: A string representing a part of the URL that needs to exist\n      in order for this method to return ``True``.\n    :param exact: If ``1`` then the parameter ``url`` must be equal to\n      ``request.path``, otherwise the parameter ``url`` can just be a part of\n      ``request.path``.\n    :use_resolver: If ``0`` we will not try to compare ``url`` with existing\n      view names but we will only compare it with ``request.path``.\n\n    \"\"\"\n    if use_resolver:\n        try:\n            if url == resolve(request.path).url_name:\n                # Checks the url pattern in case a view_name is posted\n                return 'active'\n            elif url == request.path:\n                # Workaround to catch URLs with more than one part, which don't\n                # raise a Resolver404 (e.g. '/index/info/')\n                match = request.path\n            else:\n                return ''\n        except Resolver404:\n            # Indicates, that a simple url string is used (e.g. '/index/')\n            match = request.path\n    else:\n        match = request.path\n\n    if exact and url == match:\n        return 'active'\n    elif not exact and url in request.path:\n        return 'active'\n    return ''", "label": 1}
{"code": "public static function keyRingName($project, $location, $keyRing)\n    {\n        return self::getKeyRingNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'key_ring' => $keyRing,\n        ]);\n    }", "label": 2}
{"code": "func (f *Fpdf) CreateTemplate(fn func(*Tpl)) Template {\n\treturn newTpl(PointType{0, 0}, f.curPageSize, f.defOrientation, f.unitStr, f.fontDirStr, fn, f)\n}", "label": 5}
{"code": "public function serialize()\n    {\n        $debugOutputResource = null;\n        if (is_resource($this->debugOutputResource)) {\n            $metadata = stream_get_meta_data($this->debugOutputResource);\n            $debugOutputResource = [\n                'uri' => $metadata['uri'],\n                'mode' => $metadata['mode']\n            ];\n        }\n\n        return serialize([\n            $this->messageKey,\n            $this->batchEnabled,\n            $this->metadataProvider,\n            $this->debugOutput,\n            $this->clientConfig,\n            $this->batchMethod,\n            $this->logName,\n            $debugOutputResource\n        ]);\n    }", "label": 2}
{"code": "def _validate_isvalid_composition(self, isvalid_composition, field, value):\n        \"\"\"Checks for valid specification of composition.\n\n        Args:\n            isvalid_composition (bool): flag from schema indicating\n                composition to be checked.\n            field (str): 'composition'\n            value (dict): dictionary of composition\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_composition': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'dict'}}\n        \"\"\"\n        sum_amount = 0.0\n        if value['kind'] in ['mass fraction', 'mole fraction']:\n            low_lim = 0.0\n            up_lim = 1.0\n            total_amount = 1.0\n        elif value['kind'] in ['mole percent']:\n            low_lim = 0.0\n            up_lim = 100.0\n            total_amount = 100.0\n        else:\n            self._error(field, 'composition kind must be \"mole percent\", \"mass fraction\", or '\n                        '\"mole fraction\"')\n            return False\n\n        for sp in value['species']:\n            amount = sp['amount'][0]\n            sum_amount += amount\n\n            # Check that amount within bounds, based on kind specified\n            if amount < low_lim:\n                self._error(field, 'Species ' + sp['species-name'] + ' ' +\n                            value['kind'] + ' must be greater than {:.1f}'.format(low_lim)\n                            )\n            elif amount > up_lim:\n                self._error(field, 'Species ' + sp['species-name'] + ' ' +\n                            value['kind'] + ' must be less than {:.1f}'.format(up_lim)\n                            )\n\n        # Make sure mole/mass fraction sum to 1\n        if not np.isclose(total_amount, sum_amount):\n            self._error(field, 'Species ' + value['kind'] +\n                        's do not sum to {:.1f}: '.format(total_amount) +\n                        '{:f}'.format(sum_amount)\n                        )", "label": 1}
{"code": "def modified_files\n      @modified_files ||= begin\n        @modified_files = []\n\n        rewritten_commits.each do |rewritten_commit|\n          refs = \"#{rewritten_commit.old_hash} #{rewritten_commit.new_hash}\"\n          @modified_files |= Overcommit::GitRepo.modified_files(refs: refs)\n        end\n\n        filter_modified_files(@modified_files)\n      end\n    end", "label": 4}
{"code": "func newGRPCClient(doneCtx context.Context, c *Client) (*GRPCClient, error) {\n\tconn, err := dialGRPCConn(c.config.TLSConfig, c.dialer)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Start the broker.\n\tbrokerGRPCClient := newGRPCBrokerClient(conn)\n\tbroker := newGRPCBroker(brokerGRPCClient, c.config.TLSConfig)\n\tgo broker.Run()\n\tgo brokerGRPCClient.StartStream()\n\n\tcl := &GRPCClient{\n\t\tConn:       conn,\n\t\tPlugins:    c.config.Plugins,\n\t\tdoneCtx:    doneCtx,\n\t\tbroker:     broker,\n\t\tcontroller: plugin.NewGRPCControllerClient(conn),\n\t}\n\n\treturn cl, nil\n}", "label": 5}
{"code": "def strip_frontmatter(source)\n      frontmatter = /\n        # From the start of the string\n        \\A\n        # First-capture match --- followed by optional whitespace up\n        # to a newline then 0 or more chars followed by an optional newline.\n        # This matches the --- and the contents of the frontmatter\n        (---\\s*\\n.*?\\n?)\n        # From the start of the line\n        ^\n        # Second capture match --- or ... followed by optional whitespace\n        # and newline. This matches the closing --- for the frontmatter.\n        (---|\\.\\.\\.)\\s*$\\n?/mx\n\n      if config['skip_frontmatter'] && match = source.match(frontmatter)\n        newlines = match[0].count(\"\\n\")\n        source.sub!(frontmatter, \"\\n\" * newlines)\n      end\n\n      source\n    end", "label": 4}
{"code": "@SuppressWarnings({\"unchecked\", \"unused\"})\n    public static <T> T[] object2Array(final Class<T> clazz, final Object obj) {\n        return (T[]) obj;\n    }", "label": 0}
{"code": "def paint_agent_trail(self, y, x, val):\n        \"\"\"\n        paint an agent trail as ONE pixel to allow for multiple agent\n        trails to be seen in the same cell\n        \"\"\"\n        for j in range(1,self.cell_height-1):\n            for i in range(1,self.cell_width-1):\n                self.img.put(self.agent_color(val), (x*self.cell_width+i, y*self.cell_height+j))", "label": 1}
{"code": "def completions_at filename, line, column\n      position = Position.new(line, column)\n      cursor = Source::Cursor.new(checkout(filename), position)\n      api_map.clip(cursor).complete\n    end", "label": 4}
{"code": "def doctree_read_handler(app, doctree):\n    \"\"\"\n    Add 'orphan' to metadata for partials\n\n    :type app: sphinx.application.Sphinx\n    :type doctree: docutils.nodes.document\n    \"\"\"\n    # noinspection PyProtectedMember\n    docname = sys._getframe(2).f_locals['docname']\n    if docname.startswith('_partial'):\n        app.env.metadata[docname]['orphan'] = True", "label": 1}
{"code": "public static dnssuffix[] get(nitro_service service) throws Exception{\n\t\tdnssuffix obj = new dnssuffix();\n\t\tdnssuffix[] response = (dnssuffix[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function(next) {\n            if (options.noDns || core.noDns) return next();\n            core.loadDnsConfig(options, next);\n        }", "label": 3}
{"code": "private function getSizeFromMetadata()\n    {\n        foreach ($this->stream->getMetadata('wrapper_data') as $value) {\n            if (substr($value, 0, 15) == \"Content-Length:\") {\n                return (int) substr($value, 16);\n            }\n        }\n        return 0;\n    }", "label": 2}
{"code": "function parseAll(options) {\n  return Promise.all([\n    parseData(options),\n    parsePages(options),\n    parsePatterns(options),\n    parseTemplates(options)\n  ]).then(\n    allData => parseTree(allData, options),\n    error => DrizzleError.error(error, options.debug)\n  );\n}", "label": 3}
{"code": "public void link(Object targetObject, ClassDescriptor cld, ObjectReferenceDescriptor rds, Object referencedObject, boolean insert)\n    {\n        // MBAIRD: we have 'disassociated' this object from the referenced object,\n        // the object represented by the reference descriptor is now null, so set\n        // the fk in the target object to null.\n        // arminw: if an insert was done and ref object was null, we should allow\n        // to pass FK fields of main object (maybe only the FK fields are set)\n        if (referencedObject == null)\n        {\n            /*\n            arminw:\n            if update we set FK fields to 'null', because reference was disassociated\n            We do nothing on insert, maybe only the FK fields of main object (without\n            materialization of the reference object) are set by the user\n            */\n            if(!insert)\n            {\n                unlinkFK(targetObject, cld, rds);\n            }\n        }\n        else\n        {\n            setFKField(targetObject, cld, rds, referencedObject);\n        }\n    }", "label": 0}
{"code": "func (c *connection) useful() bool {\n\tt := c.t\n\tif c.closed.IsSet() {\n\t\treturn false\n\t}\n\tif !t.haveInfo() {\n\t\treturn c.supportsExtension(\"ut_metadata\")\n\t}\n\tif t.seeding() && c.PeerInterested {\n\t\treturn true\n\t}\n\tif c.peerHasWantedPieces() {\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "func (c *Client) Login(ctx context.Context, u *url.Userinfo) error {\n\treturn c.SessionManager.Login(ctx, u)\n}", "label": 5}
{"code": "public function getRoutes($version = null)\n    {\n        $routes = $this->adapter->getIterableRoutes($version);\n\n        if (! is_null($version)) {\n            $routes = [$version => $routes];\n        }\n\n        $collections = [];\n\n        foreach ($routes as $key => $value) {\n            $collections[$key] = new RouteCollection($this->container['request']);\n\n            foreach ($value as $route) {\n                $route = $this->createRoute($route);\n\n                $collections[$key]->add($route);\n            }\n        }\n\n        return is_null($version) ? $collections : $collections[$version];\n    }", "label": 2}
{"code": "public int[] executeBatch(PreparedStatement stmt) throws PlatformException\r\n    {\r\n        // Check for Oracle batching support\r\n        final Method methodSendBatch = (Method) m_batchStatementsInProgress.remove(stmt);\r\n        final boolean statementBatchingSupported = methodSendBatch != null;\r\n\r\n        int[] retval = null;\r\n        if (statementBatchingSupported)\r\n        {\r\n            try\r\n            {\r\n                // sendBatch() returns total row count as an Integer\r\n                methodSendBatch.invoke(stmt, null);\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                throw new PlatformException(e.getLocalizedMessage(), e);\r\n            }\r\n        }\r\n        else\r\n        {\r\n            retval = super.executeBatch(stmt);\r\n        }\r\n        return retval;\r\n    }", "label": 0}
{"code": "def pack(content, app_id)\n      random = SecureRandom.hex(8)\n      text = content.force_encoding('ASCII-8BIT')\n      msg_len = [text.length].pack('N')\n\n      encode_padding(\"#{random}#{msg_len}#{text}#{app_id}\")\n    end", "label": 4}
{"code": "public function setRepoId($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\DevTools\\Source\\V1\\RepoId::class);\n        $this->repo_id = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, vpnurl resource) throws Exception {\n\t\tvpnurl updateresource = new vpnurl();\n\t\tupdateresource.urlname = resource.urlname;\n\t\tupdateresource.linkname = resource.linkname;\n\t\tupdateresource.actualurl = resource.actualurl;\n\t\tupdateresource.clientlessaccess = resource.clientlessaccess;\n\t\tupdateresource.comment = resource.comment;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function getSingleIdentifierFieldName()\n    {\n        if ($this->isIdentifierComposite()) {\n            throw MappingException::singleIdNotAllowedOnCompositePrimaryKey($this->className);\n        }\n\n        if (! isset($this->identifier[0])) {\n            throw MappingException::noIdDefined($this->className);\n        }\n\n        return $this->identifier[0];\n    }", "label": 2}
{"code": "def cta_button_path\n      if current_organization.cta_button_path.present?\n        current_organization.cta_button_path\n      elsif Decidim::ParticipatoryProcess.where(organization: current_organization).published.any?\n        decidim_participatory_processes.participatory_processes_path\n      elsif current_user\n        decidim.account_path\n      elsif current_organization.sign_up_enabled?\n        decidim.new_user_registration_path\n      else\n        decidim.new_user_session_path\n      end\n    end", "label": 4}
{"code": "public InputStream getStream(String url, RasterLayer layer) throws IOException {\n\t\tif (layer instanceof ProxyLayerSupport) {\n\t\t\tProxyLayerSupport proxyLayer = (ProxyLayerSupport) layer;\n\t\t\tif (proxyLayer.isUseCache() && null != cacheManagerService) {\n\t\t\t\tObject cachedObject = cacheManagerService.get(proxyLayer, CacheCategory.RASTER, url);\n\t\t\t\tif (null != cachedObject) {\n\t\t\t\t\ttestRecorder.record(TEST_RECORDER_GROUP, TEST_RECORDER_GET_FROM_CACHE);\n\t\t\t\t\treturn new ByteArrayInputStream((byte[]) cachedObject);\n\t\t\t\t} else {\n\t\t\t\t\ttestRecorder.record(TEST_RECORDER_GROUP, TEST_RECORDER_PUT_IN_CACHE);\n\t\t\t\t\tInputStream stream = super.getStream(url, proxyLayer);\n\t\t\t\t\tByteArrayOutputStream os = new ByteArrayOutputStream();\n\t\t\t\t\tint b;\n\t\t\t\t\twhile ((b = stream.read()) >= 0) {\n\t\t\t\t\t\tos.write(b);\n\t\t\t\t\t}\n\t\t\t\t\tcacheManagerService.put(proxyLayer, CacheCategory.RASTER, url, os.toByteArray(),\n\t\t\t\t\t\t\tgetLayerEnvelope(proxyLayer));\n\t\t\t\t\treturn new ByteArrayInputStream((byte[]) os.toByteArray());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn super.getStream(url, layer);\n\t}", "label": 0}
{"code": "func (fs *FlagSet) FlagCountUndeprecated() int {\n\tcount := 0\n\tfor _, flag := range sortFlags(fs.formal) {\n\t\tfor _, name := range flag.Names {\n\t\t\tif name[0] != '#' {\n\t\t\t\tcount++\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn count\n}", "label": 5}
{"code": "def transform(self, word, column=Profile.GRAPHEME_COL, error=errors.replace):\n        \"\"\"\n        Transform a string's graphemes into the mappings given in a different column\n        in the orthography profile.\n\n        Parameters\n        ----------\n        word : str\n            The input string to be tokenized.\n\n        column : str (default = \"Grapheme\")\n            The label of the column to transform to. Default it to tokenize with\n            orthography profile.\n\n        Returns\n        -------\n        result : list of lists\n            Result of the transformation.\n\n        \"\"\"\n        assert self.op, 'method can only be called with orthography profile.'\n\n        if column != Profile.GRAPHEME_COL and column not in self.op.column_labels:\n            raise ValueError(\"Column {0} not found in profile.\".format(column))\n\n        word = self.op.tree.parse(word, error)\n        if column == Profile.GRAPHEME_COL:\n            return word\n        out = []\n        for token in word:\n            try:\n                target = self.op.graphemes[token][column]\n            except KeyError:\n                target = self._errors['replace'](token)\n            if target is not None:\n                if isinstance(target, (tuple, list)):\n                    out.extend(target)\n                else:\n                    out.append(target)\n        return out", "label": 1}
{"code": "def add_back_ref(self, back_ref, attr=None):\n        \"\"\"Add reference from back_ref to self\n\n        :param back_ref: back_ref to add\n        :type back_ref: Resource\n\n        :rtype: Resource\n        \"\"\"\n        back_ref.add_ref(self, attr)\n        return self.fetch()", "label": 1}
{"code": "public static lbvserver get(nitro_service service, String name) throws Exception{\n\t\tlbvserver obj = new lbvserver();\n\t\tobj.set_name(name);\n\t\tlbvserver response = (lbvserver) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function load_wordpress() {\n\t\tstatic $wp_cli_is_loaded;\n\t\t// Globals not explicitly globalized in WordPress\n\t\tglobal $site_id, $wpdb, $public, $current_site, $current_blog, $path, $shortcode_tags;\n\n\t\tif ( ! empty( $wp_cli_is_loaded ) ) {\n\t\t\treturn;\n\t\t}\n\n\t\t$wp_cli_is_loaded = true;\n\n\t\tWP_CLI::debug( 'Begin WordPress load', 'bootstrap' );\n\t\tWP_CLI::do_hook( 'before_wp_load' );\n\n\t\t$this->check_wp_version();\n\n\t\t$wp_config_path = Utils\\locate_wp_config();\n\t\tif ( ! $wp_config_path ) {\n\t\t\tWP_CLI::error(\n\t\t\t\t\"'wp-config.php' not found.\\n\" .\n\t\t\t\t'Either create one manually or use `wp config create`.'\n\t\t\t);\n\t\t}\n\n\t\tWP_CLI::debug( 'wp-config.php path: ' . $wp_config_path, 'bootstrap' );\n\t\tWP_CLI::do_hook( 'before_wp_config_load' );\n\n\t\t// Load wp-config.php code, in the global scope\n\t\t$wp_cli_original_defined_vars = get_defined_vars();\n\n\t\teval( $this->get_wp_config_code() ); // phpcs:ignore Squiz.PHP.Eval.Discouraged\n\n\t\tforeach ( get_defined_vars() as $key => $var ) {\n\t\t\tif ( array_key_exists( $key, $wp_cli_original_defined_vars ) || 'wp_cli_original_defined_vars' === $key ) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t// phpcs:ignore PHPCompatibility.Variables.ForbiddenGlobalVariableVariable.NonBareVariableFound\n\t\t\tglobal ${$key};\n\t\t\t// phpcs:ignore WordPress.NamingConventions.PrefixAllGlobals.NonPrefixedVariableFound\n\t\t\t${$key} = $var;\n\t\t}\n\n\t\t$this->maybe_update_url_from_domain_constant();\n\t\tWP_CLI::do_hook( 'after_wp_config_load' );\n\t\t$this->do_early_invoke( 'after_wp_config_load' );\n\n\t\t// Prevent error notice from wp_guess_url() when core isn't installed\n\t\tif ( $this->cmd_starts_with( array( 'core', 'is-installed' ) )\n\t\t\t&& ! defined( 'COOKIEHASH' ) ) {\n\t\t\tdefine( 'COOKIEHASH', md5( 'wp-cli' ) );\n\t\t}\n\n\t\t// Load WP-CLI utilities\n\t\trequire WP_CLI_ROOT . '/php/utils-wp.php';\n\n\t\t// Set up WordPress bootstrap actions and filters\n\t\t$this->setup_bootstrap_hooks();\n\n\t\t// Load Core, mu-plugins, plugins, themes etc.\n\t\tif ( Utils\\wp_version_compare( '4.6-alpha-37575', '>=' ) ) {\n\t\t\tif ( $this->cmd_starts_with( array( 'help' ) ) ) {\n\t\t\t\t// Hack: define `WP_DEBUG` and `WP_DEBUG_DISPLAY` to get `wpdb::bail()` to `wp_die()`.\n\t\t\t\tif ( ! defined( 'WP_DEBUG' ) ) {\n\t\t\t\t\tdefine( 'WP_DEBUG', true );\n\t\t\t\t}\n\t\t\t\tif ( ! defined( 'WP_DEBUG_DISPLAY' ) ) {\n\t\t\t\t\tdefine( 'WP_DEBUG_DISPLAY', true );\n\t\t\t\t}\n\t\t\t}\n\t\t\trequire ABSPATH . 'wp-settings.php';\n\t\t} else {\n\t\t\trequire WP_CLI_ROOT . '/php/wp-settings-cli.php';\n\t\t}\n\n\t\t// Fix memory limit. See http://core.trac.wordpress.org/ticket/14889\n\t\t// phpcs:ignore WordPress.PHP.IniSet.memory_limit_Blacklisted -- This is perfectly fine for CLI usage.\n\t\tini_set( 'memory_limit', -1 );\n\n\t\t// Load all the admin APIs, for convenience\n\t\trequire ABSPATH . 'wp-admin/includes/admin.php';\n\n\t\tadd_filter(\n\t\t\t'filesystem_method',\n\t\t\tfunction() {\n\t\t\t\treturn 'direct';\n\t\t\t},\n\t\t\t99\n\t\t);\n\n\t\t// Re-enable PHP error reporting to stderr if testing.\n\t\tif ( getenv( 'BEHAT_RUN' ) ) {\n\t\t\t$this->enable_error_reporting();\n\t\t}\n\n\t\tWP_CLI::debug( 'Loaded WordPress', 'bootstrap' );\n\t\tWP_CLI::do_hook( 'after_wp_load' );\n\n\t}", "label": 2}
{"code": "function getError (type, expected, actual) {\n        return {\n            attribute: type,\n            expected: expected,\n            actual: actual,\n            message: getMsg(type, expected)\n        };\n    }", "label": 3}
{"code": "function onPushNotificationError(error) {\n    Q(pushCallback(error)).done(undefined, function (e) {\n        diag.debug.assert(e === error, 'push callback failed: ' + e.message);\n    });\n}", "label": 3}
{"code": "public void forObjectCache(String template, Properties attributes) throws XDocletException\r\n    {\r\n        _curObjectCacheDef = _curClassDef.getObjectCache();\r\n        if (_curObjectCacheDef != null)\r\n        {\r\n            generate(template);\r\n            _curObjectCacheDef = null;\r\n        }\r\n    }", "label": 0}
{"code": "def send_file(file, caption = nil, filename: nil, spoiler: nil)\n      pm.send_file(file, caption: caption, filename: filename, spoiler: spoiler)\n    end", "label": 4}
{"code": "def full_error(attribute_name, options = {})\n      options = options.dup\n\n      options[:error_prefix] ||= if object.class.respond_to?(:human_attribute_name)\n        object.class.human_attribute_name(attribute_name.to_s)\n      else\n        attribute_name.to_s.humanize\n      end\n\n      error(attribute_name, options)\n    end", "label": 4}
{"code": "def dress(sexp, comment_map)\n      return sexp unless sexp.is_a? ::Parser::AST::Node\n\n      type = sexp.type\n      children = sexp.children.map { |child| dress(child, comment_map) }\n      comments = comment_map[sexp]\n      klass_map.klass_for(type).new(type, children,\n                                    location: sexp.loc, comments: comments)\n    end", "label": 4}
{"code": "public static streamidentifier_stats get(nitro_service service, String name) throws Exception{\n\t\tstreamidentifier_stats obj = new streamidentifier_stats();\n\t\tobj.set_name(name);\n\t\tstreamidentifier_stats response = (streamidentifier_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def upload_metadata\n      upload_metadata = UploadMetadata.new\n      upload_screenshots = UploadScreenshots.new\n\n      # First, collect all the things for the HTML Report\n      screenshots = upload_screenshots.collect_screenshots(options)\n      upload_metadata.load_from_filesystem(options)\n\n      # Assign \"default\" values to all languages\n      upload_metadata.assign_defaults(options)\n\n      # Handle app icon / watch icon\n      prepare_app_icons(options)\n\n      # Validate\n      validate_html(screenshots)\n\n      # Commit\n      upload_metadata.upload(options)\n      upload_screenshots.upload(options, screenshots)\n      UploadPriceTier.new.upload(options)\n      UploadAssets.new.upload(options) # e.g. app icon\n    end", "label": 4}
{"code": "def promote(self, cls, update=False, preserve=True):\n\t\t\"\"\"Transform this record into an instance of a more specialized subclass.\"\"\"\n\t\t\n\t\tif not issubclass(cls, self.__class__):\n\t\t\traise TypeError(\"Must promote to a subclass of \" + self.__class__.__name__)\n\t\t\n\t\treturn self._as(cls, update, preserve)", "label": 1}
{"code": "public static function add_hook( $when, $callback ) {\n\t\tif ( array_key_exists( $when, self::$hooks_passed ) ) {\n\t\t\tself::debug(\n\t\t\t\tsprintf(\n\t\t\t\t\t'Immediately invoking on passed hook \"%s\": %s',\n\t\t\t\t\t$when,\n\t\t\t\t\tUtils\\describe_callable( $callback )\n\t\t\t\t),\n\t\t\t\t'hooks'\n\t\t\t);\n\t\t\tcall_user_func_array( $callback, (array) self::$hooks_passed[ $when ] );\n\t\t}\n\n\t\tself::$hooks[ $when ][] = $callback;\n\t}", "label": 2}
{"code": "public function setSetToServerValue($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Firestore\\V1beta1\\DocumentTransform_FieldTransform_ServerValue::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def cannot(action = nil, subject = nil, *attributes_and_conditions, &block)\n      add_rule(Rule.new(false, action, subject, *attributes_and_conditions, &block))\n    end", "label": 4}
{"code": "def check_root_ruleset_indent(node, actual_indent)\n      # Whether node is a ruleset not nested within any other ruleset.\n      if @indent == 0 && node.is_a?(Sass::Tree::RuleNode)\n        unless actual_indent % @indent_width == 0\n          add_lint(node.line, lint_message(\"a multiple of #{@indent_width}\", actual_indent))\n          return true\n        end\n      end\n\n      false\n    end", "label": 4}
{"code": "public static nslimitidentifier_binding get(nitro_service service, String limitidentifier) throws Exception{\n\t\tnslimitidentifier_binding obj = new nslimitidentifier_binding();\n\t\tobj.set_limitidentifier(limitidentifier);\n\t\tnslimitidentifier_binding response = (nslimitidentifier_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def execute_script(script, *args)\n      args.map! do |e|\n        e.is_a?(Element) ? e.wait_until(&:exists?).wd : e\n      end\n      returned = driver.execute_script(script, *args)\n\n      browser.wrap_elements_in(self, returned)\n    end", "label": 4}
{"code": "function isIndependentInterface(symbol) {\n            for (var _i = 0, _a = symbol.declarations; _i < _a.length; _i++) {\n                var declaration = _a[_i];\n                if (declaration.kind === 222 /* InterfaceDeclaration */) {\n                    if (declaration.flags & 16384 /* ContainsThis */) {\n                        return false;\n                    }\n                    var baseTypeNodes = ts.getInterfaceBaseTypeNodes(declaration);\n                    if (baseTypeNodes) {\n                        for (var _b = 0, baseTypeNodes_1 = baseTypeNodes; _b < baseTypeNodes_1.length; _b++) {\n                            var node = baseTypeNodes_1[_b];\n                            if (ts.isEntityNameExpression(node.expression)) {\n                                var baseSymbol = resolveEntityName(node.expression, 793064 /* Type */, /*ignoreErrors*/ true);\n                                if (!baseSymbol || !(baseSymbol.flags & 64 /* Interface */) || getDeclaredTypeOfClassOrInterface(baseSymbol).thisType) {\n                                    return false;\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            return true;\n        }", "label": 3}
{"code": "public function setGerrit($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\DevTools\\Source\\V1\\GerritSourceContext::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function getParameters(flapjack) {\n\n    if (!_.isFunction(flapjack)) {\n        throw new Error('Flapjack not a function ' + JSON.stringify(flapjack));\n    }\n\n    var str = flapjack.toString();\n    var pattern = /(?:\\()([^\\)]*)(?:\\))/;\n    var matches = pattern.exec(str);\n\n    if (matches === null || matches.length < 2) {\n        throw new Error('Invalid flapjack: ' + str.substring(0, 200));\n    }\n\n    var unfiltered = matches[1].replace(/\\s/g, '').split(',');\n    var params = [], i;\n\n    for (i = 0; i < unfiltered.length; i++) {\n        if (unfiltered[i]) {\n            params.push(unfiltered[i]);\n        }\n    }\n\n    return params;\n}", "label": 3}
{"code": "func URL(c CloneURL, path string) *Resource {\n\tr := &Resource{u: c.URL()}\n\tr.u.Path = Path + path\n\treturn r\n}", "label": 5}
{"code": "def __live_receivers(signal):\n    \"\"\"Return all signal handlers that are currently still alive for the\n    input `signal`.\n\n    Args:\n        signal: A signal name.\n\n    Returns:\n        A list of callable receivers for the input signal.\n    \"\"\"\n    with __lock:\n        __purge()\n        receivers = [funcref() for funcref in __receivers[signal]]\n\n    return receivers", "label": 1}
{"code": "func handleEvents() {\n\tfor {\n\t\tevent, ok := <-eventsIn\n\t\tif !ok {\n\t\t\tlog.Println()\n\t\t\tlog.Println(\"Stopped event handler!\")\n\t\t\tbreak\n\t\t}\n\n\t\tbee := GetBee(event.Bee)\n\t\t(*bee).LogEvent()\n\n\t\tlog.Println()\n\t\tlog.Println(\"Event received:\", event.Bee, \"/\", event.Name, \"-\", GetEventDescriptor(&event).Description)\n\t\tfor _, v := range event.Options {\n\t\t\tlog.Println(\"\\tOptions:\", v)\n\t\t}\n\n\t\tgo func() {\n\t\t\tdefer func() {\n\t\t\t\tif e := recover(); e != nil {\n\t\t\t\t\tlog.Printf(\"Fatal chain event: %s %s\", e, debug.Stack())\n\t\t\t\t}\n\t\t\t}()\n\n\t\t\texecChains(&event)\n\t\t}()\n\t}\n}", "label": 5}
{"code": "public function setSsmlGender($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\TextToSpeech\\V1\\SsmlVoiceGender::class);\n        $this->ssml_gender = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function resolvePath (moduleName, relativePath)\n{\n  if (! moduleName) {\n    return null;\n  }\n\n  if (! relativePath) {\n    return null;\n  }\n\n  const mainPath = require.resolve(moduleName);\n  if (! mainPath) {\n    return null;\n  }\n\n  const rootLocations = [];\n  const dirs = mainPath.split(path.sep);\n  let lastSegment = dirs.pop();\n  while (lastSegment) {\n    const location = dirs.concat(['package.json']).join(path.sep);\n    rootLocations.push(location);\n    lastSegment = dirs.pop();\n  }\n\n  for(const location of rootLocations) {\n    if (fs.existsSync(location)) {\n      const cli = path.resolve(path.dirname(location), relativePath);\n      if (fs.existsSync(cli)) {\n        return cli;\n      }\n    }\n  }\n\n  return null;\n}", "label": 3}
{"code": "function equals(x, y) {\n    var a = isFunction(x) ? x() : x;\n    var b = isFunction(y) ? y() : y;\n    var aKeys;\n    if (a == b)\n      return true;\n    else if (a == _null || b == _null)\n      return false;\n    else if (isValue(a) || isValue(b))\n      return isDate(a) && isDate(b) && +a==+b;\n    else if (isList(a)) {\n      return (a.length == b.length) &&\n             !find(a, function(val, index) {\n               if (!equals(val, b[index]))\n                 return true;\n             });\n    }\n    else {\n      return !isList(b) &&\n             ((aKeys = keys(a)).length == keyCount(b)) &&\n             !find(aKeys, function(key) {\n               if (!equals(a[key],b[key]))\n                 return true;\n             });\n    }\n  }", "label": 3}
{"code": "public function downloadToFile($path, array $options = [])\n    {\n        $destination = Psr7\\stream_for(fopen($path, 'w'));\n\n        Psr7\\copy_to_stream(\n            $this->downloadAsStream($options),\n            $destination\n        );\n\n        $destination->seek(0);\n\n        return $destination;\n    }", "label": 2}
{"code": "public function setSupportedCompressions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::ENUM, \\Google\\Cloud\\WebRisk\\V1beta1\\CompressionType::class);\n        $this->supported_compressions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def show_graph_summary(g):\n    \"\"\" display sample data from a graph \"\"\"\n    sample_data = []\n    print(\"list(g[RDFS.Class]) = \" + str(len(list(g[RDFS.Class]))))\n    # Get Subject Lists\n    num_subj = 0\n    for subj in g.subjects(RDF.type):\n        num_subj += 1\n        if num_subj < 5:\n            sample_data.append(\"subjects.subject: \" + get_string_from_rdf(subj))\n    print(\"g.subjects(RDF.type) = \" + str(num_subj))\n    \n    # Get Sample of Subjects, Predicates, Objects\n    num_subj = 0\n    for subj, pred, obj in g:\n        num_subj += 1\n        if num_subj < 5:\n            sample_data.append(\"g.subject   : \" + get_string_from_rdf(pred))\n            sample_data.append(\"g.predicate : \" + get_string_from_rdf(subj))\n            sample_data.append(\"g.object    : \" + get_string_from_rdf(obj))\n            \n    print(\"g.obj(RDF.type) = \" + str(num_subj))\n    \n    \n    print (\"------ Sample Data ------\")\n    for line in sample_data:\n        print(line)", "label": 1}
{"code": "def from_dict(cls, info_dict):\n        '''Create a new instance of WebBrowserInteractionInfo, as expected\n        by the Error.interaction_method method.\n        @param info_dict The deserialized JSON object\n        @return a new WebBrowserInteractionInfo object.\n        '''\n        return WebBrowserInteractionInfo(\n            visit_url=info_dict.get('VisitURL'),\n            wait_token_url=info_dict.get('WaitTokenURL'))", "label": 1}
{"code": "def _fetch_app_role_token(vault_url, role_id, secret_id):\n        \"\"\"Get a Vault token, using the RoleID and SecretID\"\"\"\n        url = _url_joiner(vault_url, 'v1/auth/approle/login')\n        resp = requests.post(url, data={'role_id': role_id, 'secret_id': secret_id})\n        resp.raise_for_status()\n        data = resp.json()\n        if data.get('errors'):\n            raise VaultException(u'Error fetching Vault token: {}'.format(data['errors']))\n        return data['auth']['client_token']", "label": 1}
{"code": "function submitFormData(req, res, next) {\n  var submission = req.body || {};\n\n  submission.appId = req.params.projectid;\n  submission.appEnvironment = req.params.environment;\n  submission.deviceId = submission.deviceId || \"Device Unknown\";\n\n  var submissionParams = {\n    submission: submission\n  };\n\n  logger.debug(\"Middleware: form submitFormData: \", {params: submissionParams});\n\n  forms.submitFormData(_.extend(submissionParams, req.connectionOptions), formsResultHandlers(constants.resultTypes.submissions, req, next));\n}", "label": 3}
{"code": "function extendFormatExtensions (extensionName, extensionValue) {\n        if (typeof extensionName !== 'string' || !(extensionValue instanceof RegExp)) {\n            throw new Error('extensionName or extensionValue undefined or not correct type');\n        }\n\n        if (revalidator.validate.formats.hasOwnProperty(extensionName) ||\n            revalidator.validate.formats.hasOwnProperty(extensionName)) {\n            var msg = 'extensionName: ' + extensionName + ' already exists in formatExtensions.';\n            throw  new Error(msg);\n        }\n\n        revalidator.validate.formatExtensions[extensionName] = extensionValue;\n    }", "label": 3}
{"code": "def edit(filename, connection=None):\n    \"\"\"Checks out a file into the default changelist\n\n    :param filename: File to check out\n    :type filename: str\n    :param connection: Connection object to use\n    :type connection: :py:class:`Connection`\n    \"\"\"\n    c = connection or connect()\n    rev = c.ls(filename)\n    if rev:\n        rev[0].edit()", "label": 1}
{"code": "public function buckets(array $options = [])\n    {\n        if (!$this->projectId) {\n            throw new GoogleException(\n                'No project ID was provided, ' .\n                'and we were unable to detect a default project ID.'\n            );\n        }\n\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n        $bucketUserProject = $this->pluck('bucketUserProject', $options, false);\n        $bucketUserProject = !is_null($bucketUserProject)\n            ? $bucketUserProject\n            : true;\n        $userProject = (isset($options['userProject']) && $bucketUserProject)\n            ? $options['userProject']\n            : null;\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $bucket) use ($userProject) {\n                    return new Bucket(\n                        $this->connection,\n                        $bucket['name'],\n                        $bucket + ['requesterProjectId' => $userProject]\n                    );\n                },\n                [$this->connection, 'listBuckets'],\n                $options + ['project' => $this->projectId],\n                ['resultLimit' => $resultLimit]\n            )\n        );\n    }", "label": 2}
{"code": "public static filteraction get(nitro_service service, String name) throws Exception{\n\t\tfilteraction obj = new filteraction();\n\t\tobj.set_name(name);\n\t\tfilteraction response = (filteraction) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function addEntityResult($class, $alias, $resultAlias = null)\n    {\n        $this->aliasMap[$alias]       = $class;\n        $this->entityMappings[$alias] = $resultAlias;\n\n        if ($resultAlias !== null) {\n            $this->isMixed = true;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def fragments_data(record, page_path)\n      record.fragments.collect do |frag|\n        header = \"#{frag.tag} #{frag.identifier}\"\n        content =\n          case frag.tag\n          when \"datetime\", \"date\"\n            frag.datetime\n          when \"checkbox\"\n            frag.boolean\n          when \"file\", \"files\"\n            frag.attachments.map do |attachment|\n              ::File.open(::File.join(page_path, attachment.filename.to_s), \"wb\") do |f|\n                f.write(attachment.download)\n              end\n              attachment.filename\n            end.join(\"\\n\")\n          else\n            frag.content\n          end\n\n        { header: header, content: content }\n      end\n    end", "label": 4}
{"code": "def fetch_trades_since(self, since: int) -> List[Trade]:\n        \"\"\"Fetch trades since given timestamp.\"\"\"\n        return self._fetch_since('trades', self.market.code)(self._trades_since)(since)", "label": 1}
{"code": "def delete(self, filepath):\n        \"\"\"\n        Delete the specified file.\n        \"\"\"\n        try:\n            self.fs.delete(filepath)\n            self.write({'msg':'File deleted at {}'.format(filepath)})\n        except OSError:\n            raise tornado.web.HTTPError(404)", "label": 1}
{"code": "private function parseEndpoint($endpoint)\n    {\n        $parsed = parse_url($endpoint);\n\n        // parse_url() will correctly parse full URIs with schemes\n        if (isset($parsed['host'])) {\n            return $parsed;\n        }\n\n        // parse_url() will put host & path in 'path' if scheme is not provided\n        if (isset($parsed['path'])) {\n            $split = explode('/', $parsed['path'], 2);\n            $parsed['host'] = $split[0];\n            if (isset($split[1])) {\n                $parsed['path'] = $split[1];\n            } else {\n                $parsed['path'] = '';\n            }\n            return $parsed;\n        }\n\n        throw new UnresolvedEndpointException(\"The supplied endpoint '\"\n            . \"{$endpoint}' is invalid.\");\n    }", "label": 2}
{"code": "def image2working(self,i):\n        \"\"\"Transform images i provided into the specified working\n        color space.\"\"\"\n        return self.colorspace.convert(self.image_space,\n                                       self.working_space, i)", "label": 1}
{"code": "def revision\n      clazz = auditable_type.constantize\n      (clazz.find_by_id(auditable_id) || clazz.new).tap do |m|\n        self.class.assign_revision_attributes(m, self.class.reconstruct_attributes(ancestors).merge(audit_version: version))\n      end\n    end", "label": 4}
{"code": "public function executeCommandOnNodes(CommandInterface $command)\n    {\n        $responses = array();\n\n        foreach ($this->pool as $connection) {\n            $responses[] = $connection->executeCommand($command);\n        }\n\n        return $responses;\n    }", "label": 2}
{"code": "def generate_deliver_file(deliver_path, options)\n      v = options[:app].latest_version\n      metadata_path = options[:metadata_path] || File.join(deliver_path, 'metadata')\n      generate_metadata_files(v, metadata_path)\n\n      # Generate the final Deliverfile here\n      return File.read(deliverfile_path)\n    end", "label": 4}
{"code": "def verify_enroll(self, response):\n        \"\"\"Verifies and saves U2F enroll\"\"\"\n\n        seed = session.pop('_u2f_enroll_')\n        try:\n            new_device, cert = complete_register(seed, response, self.__facets_list)\n        except Exception as e:\n            if self.__call_fail_enroll:\n                self.__call_fail_enroll(e)\n\n            return {\n                'status' : 'failed', \n                'error'  : 'Invalid key handle!'\n            }\n\n        finally:\n            pass\n\n        \n\n        devices = self.__get_u2f_devices()\n\n        # Setting new device counter to 0\n        new_device['counter'] = 0\n        new_device['index']   = 0\n\n        for device in devices:\n            if new_device['index'] <= device['index']:\n                new_device['index'] = device['index'] + 1\n\n        devices.append(new_device)\n\n        self.__save_u2f_devices(devices)\n        \n        self.__call_success_enroll()\n\n        return {'status': 'ok', 'message': 'Successfully enrolled new U2F device!'}", "label": 1}
{"code": "public static int cudnnGetReductionIndicesSize(\n        cudnnHandle handle, \n        cudnnReduceTensorDescriptor reduceTensorDesc, \n        cudnnTensorDescriptor aDesc, \n        cudnnTensorDescriptor cDesc, \n        long[] sizeInBytes)\n    {\n        return checkResult(cudnnGetReductionIndicesSizeNative(handle, reduceTensorDesc, aDesc, cDesc, sizeInBytes));\n    }", "label": 0}
{"code": "def resume(list)\n      unless list.is_a?(TopicPartitionList)\n        raise TypeError.new(\"list has to be a TopicPartitionList\")\n      end\n      tpl = list.to_native_tpl\n      response = Rdkafka::Bindings.rd_kafka_resume_partitions(@native_kafka, tpl)\n      if response != 0\n        raise Rdkafka::RdkafkaError.new(response, \"Error resume '#{list.to_h}'\")\n      end\n    end", "label": 4}
{"code": "function(cb) {\n            var lockFile = path.join(repoDir, '.git', 'index.lock');\n            path.exists(lockFile, function(exists) {\n                if (exists) {\n                    fs.unlink(lockFile, function(err) {\n                        if (err) {\n                            log.warn('removing file ' + lockFile + ' failed with:', err);\n                        }\n                        else {\n                            log.info('removed lock file: ' + lockFile);\n                        }\n                        cb(err, {removelock: 'remove git lock ' + lockFile + ', result ' + err});\n                    });\n                    return;\n                }\n                log.log('There is no lock file left, which is a good thing');\n                cb(null, {removelock: 'no lock was present'});\n            });\n        }", "label": 3}
{"code": "func execFilter(filter string, opts map[string]interface{}) bool {\n\tf := *filters.GetFilter(\"template\")\n\tlog.Println(\"\\tExecuting filter:\", filter)\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tlog.Println(\"Fatal filter event:\", e)\n\t\t}\n\t}()\n\n\treturn f.Passes(opts, filter)\n}", "label": 5}
{"code": "function Watcher(square, port, silent) {\n  var self = this;\n\n  this.square = square;\n  this.silent = silent || false;\n  this.socket = this.live.call(this, port);\n  this.config = path.resolve(process.env.PWD, this.square.package.location);\n\n  // Initialize the live reload, also trigger watching and process the file list.\n  this.init = function init() {\n    self.watch.apply(self, arguments[1]);\n  };\n\n  // Require fs.notify and findit, trigger the watch.\n  async.parallel([canihaz['fs.notify'], canihaz.findit], this.init);\n}", "label": 3}
{"code": "def validate_samesite_boolean_config!\n      if config[:samesite].key?(:lax) && config[:samesite][:lax].is_a?(TrueClass) && config[:samesite].key?(:strict)\n        raise CookiesConfigError.new(\"samesite cookie config is invalid, combination use of booleans and Hash to configure lax and strict enforcement is not permitted.\")\n      elsif config[:samesite].key?(:strict) && config[:samesite][:strict].is_a?(TrueClass) && config[:samesite].key?(:lax)\n        raise CookiesConfigError.new(\"samesite cookie config is invalid, combination use of booleans and Hash to configure lax and strict enforcement is not permitted.\")\n      end\n    end", "label": 4}
{"code": "public function createCredentials(Result $result)\n    {\n        if (!$result->hasKey('Credentials')) {\n            throw new \\InvalidArgumentException('Result contains no credentials');\n        }\n\n        $c = $result['Credentials'];\n\n        return new Credentials(\n            $c['AccessKeyId'],\n            $c['SecretAccessKey'],\n            isset($c['SessionToken']) ? $c['SessionToken'] : null,\n            isset($c['Expiration']) && $c['Expiration'] instanceof \\DateTimeInterface\n                ? (int) $c['Expiration']->format('U')\n                : null\n        );\n    }", "label": 2}
{"code": "func (i *Handle) NewDestination(s *Service, d *Destination) error {\n\treturn i.doCmd(s, d, ipvsCmdNewDest)\n}", "label": 5}
{"code": "function (latest_log) {\n\t\tif (latest_log !== null && latest_log.type !== \"SYSTEM_DOWN\") {\n\t\t\tLOG.warn(\"server crashed last time\", 'handlers.system');\n\t\t\tLOG.event(\"SYSTEM_CRASHED\", SR.Settings.SERVER_INFO);\n\t\t}\n\n\t\tLOG.event(\"SYSTEM_UP\", SR.Settings.SERVER_INFO);\n\t}", "label": 3}
{"code": "public void subscriptionRequestReceived(SubscriptionRequest sr) throws SubscriptionException {\n\n        LOG.info(\"Subscriber -> (Hub), new subscription request received.\", sr.getCallback());\n\n        try {\n\n            verifySubscriberRequestedSubscription(sr);\n\n            if (\"subscribe\".equals(sr.getMode())) {\n                LOG.info(\"Adding callback {} to the topic {}\", sr.getCallback(), sr.getTopic());\n                addCallbackToTopic(sr.getCallback(), sr.getTopic());\n            } else if (\"unsubscribe\".equals(sr.getMode())) {\n                LOG.info(\"Removing callback {} from the topic {}\", sr.getCallback(), sr.getTopic());\n                removeCallbackToTopic(sr.getCallback(), sr.getTopic());\n            }\n\n        } catch (Exception e) {\n            throw new SubscriptionException(e);\n        }\n\n    }", "label": 0}
{"code": "function triggerListeners(listeners, event, args)\n  {\n    if (listeners && event in listeners)\n    {\n      var eventListeners = listeners[ event ];\n      var triggerGroup = ++triggerId;\n      var next, node = eventListeners.next;\n\n      while (node !== eventListeners)\n      {\n        next = node.next;\n        node.trigger( triggerGroup, args, false );\n        node = next;\n      }\n\n      node = eventListeners.next;\n\n      while (node !== eventListeners)\n      {\n        next = node.next;\n        node.trigger( triggerGroup, args, true );\n        node = next;\n      }\n    }\n  }", "label": 3}
{"code": "def mytoc\n      @title = CGI.escapeHTML(@producer.res.v('toctitle'))\n\n      @body = %Q(  <h1 class=\"toc-title\">#{CGI.escapeHTML(@producer.res.v('toctitle'))}</h1>\\n)\n      if @producer.config['epubmaker']['flattoc'].nil?\n        @body << hierarchy_ncx('ul')\n      else\n        @body << flat_ncx('ul', @producer.config['epubmaker']['flattocindent'])\n      end\n\n      @language = @producer.config['language']\n      @stylesheets = @producer.config['stylesheet']\n      tmplfile = if @producer.config['htmlversion'].to_i == 5\n                   File.expand_path('./html/layout-html5.html.erb', ReVIEW::Template::TEMPLATE_DIR)\n                 else\n                   File.expand_path('./html/layout-xhtml1.html.erb', ReVIEW::Template::TEMPLATE_DIR)\n                 end\n      tmpl = ReVIEW::Template.load(tmplfile)\n      tmpl.result(binding)\n    end", "label": 4}
{"code": "def ffd(items, targets, **kwargs):\n    \"\"\"First-Fit Decreasing\n\n    This is perhaps the simplest packing heuristic;\n    it simply packs items in the next available bin.\n\n    This algorithm differs only from Next-Fit Decreasing\n    in having a 'sort'; that is, the items are pre-sorted\n    (largest to smallest).\n\n    Complexity O(n^2)\n    \"\"\"\n    sizes = zip(items, weight(items, **kwargs))\n    sizes = sorted(sizes, key=operator.itemgetter(1), reverse=True)\n    items = map(operator.itemgetter(0), sizes)\n    return ff(items, targets)", "label": 1}
{"code": "def _identify_datatype(self, input_data):\n        \"\"\"\n        uses the input data, which may be a string, list, number\n        or file to work out how to load the data (this can be \n        overridden by passing the data_type on the command line\n        \"\"\"\n        if isinstance(input_data, (int, float)) :\n            self.data_type = 'number'\n        elif isinstance(input_data, (list)): #, set\n            self.data_type = 'list'\n        elif isinstance(input_data, dict):\n            self.data_type = 'dict'\n        elif type(input_data) is str:\n            if self.input_data[0:4] == 'http':\n                self.data_type = 'url'\n            elif os.path.exists(input_data):\n                self.data_type = 'file'\n            else:\n                self.data_type = 'str'\n                \n        lg.record_result('_identify_datatype', self.name + ' is ' + self.data_type)", "label": 1}
{"code": "private function sendEventData(array $eventData)\n    {\n        $socket = $this->prepareSocket();\n        $datagram = json_encode($eventData);\n        $result = socket_write($socket, $datagram, strlen($datagram));\n        if ($result === false) {\n            $this->prepareSocket(true);\n        }\n        return $result;\n    }", "label": 2}
{"code": "def save_dot(self, fd):\n        \"\"\" Saves a representation of the case in the Graphviz DOT language.\n        \"\"\"\n        from pylon.io import DotWriter\n        DotWriter(self).write(fd)", "label": 1}
{"code": "function clean(args) {\n\treturn Array.prototype.filter.call(args, v => v !== INVALIDATE);\n}", "label": 3}
{"code": "def textfield(value)\n      return ele_index EDIT_TEXT, value if value.is_a? Numeric\n\n      complex_find_contains EDIT_TEXT, value\n    end", "label": 4}
{"code": "public function setQuery($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1\\Target_QueryTarget::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function HttpTool(){\n        this.settings = {};\n        this.urlObject = {};\n        this.dataToWrite = '';\n        // ********** Helper Functions/Members **********\n        \n        var validMethods = ['GET', 'PUT', 'POST', 'DELETE', 'PATCH'];\n        \n        /**\n        * Make sure that settings has at least property of url and method.\n        * @return {boolean} whether settings is valid.\n        */ \n        this.isSettingValid = function(settings){\n            if (_.isEmpty(settings)) {\n                return false;\n            }\n            if ( ! (settings.hasOwnProperty('url') && settings.hasOwnProperty('method'))) {\n                return false;\n            }\n            if (_.isEmpty(settings.url) || _.isEmpty(settings.method)) {\n                return false;\n            }\n            if (_.indexOf(validMethods, settings.method) === -1) {\n                return false;    \n            }\n\n            return true;\n        };\n\n        /**\n        * Parse and convert setting into a urlObject that suitable for \n        * http/https module in NodeJs.\n        * @return {object} - the object that suitable for Node http/https module.\n        */\n        this.setupUrlOptions = function(settings) {\n                \n            var urlTool = require('url');\n            var urlObject = {};\n\n            // Parse the string into url options\n            if (typeof (settings.url) === 'string') {\n                urlObject = urlTool.parse(settings.url);\n            }\n            else {\n                urlObject = settings.url;\n            }\n            // set the REST options\n            urlObject.method = settings.method;\n        \n            // set up the REST headers\n            if (! _.isEmpty(settings.headers)){\n                urlObject.headers = settings.headers;\n            }\n            else {\n                urlObject.headers = {};\n            }\n            \n            urlObject.headers['Content-Length'] = 0;\n            if (settings.hasOwnProperty('data')){\n                switch (typeof settings.data) {\n                    case 'object':\n                        this.dataToWrite = JSON.stringify(settings.data);\n                        urlObject.headers['Content-Type'] = 'application/json';\n                        break;\n                    case 'string':\n                        this.dataToWrite = settings.data;\n                        break;\n                    default:\n                        throw new TypeError(\"Data field can only be object or string,\" + \n                                            \" but got \" + (typeof settings.data));\n                                        }\n                urlObject.headers['Content-Length'] = Buffer.byteLength(this.dataToWrite);\n            }\n            \n            if (! _.isEmpty(settings.credential)){\n                if (!_.isEmpty(settings.credential.password) &&\n                    _.isEmpty(settings.credential.username)) {\n                    throw new Error('Please provide username and password '+\n                                    'for basic authentication.');\n                }\n                else {\n                    urlObject.auth = settings.credential.username +':'+\n                    settings.credential.password;\n                }\n            }\n            \n            // set the protolcol paramter\n            if (urlObject.protocol.substr(-1) !== ':') {\n                urlObject.protocol = urlObject.protocol + ':';\n            }\n\n            urlObject.rejectUnauthorized = settings.verifySSL || false;\n            urlObject.recvTimeoutMs = settings.recvTimeoutMs;\n\n            return urlObject;\n        };\n    }", "label": 3}
{"code": "func (ctrl *Controller) Call(receiver interface{}, method string, args ...interface{}) []interface{} {\n\tctrl.T.Helper()\n\n\t// Nest this code so we can use defer to make sure the lock is released.\n\tactions := func() []func([]interface{}) []interface{} {\n\t\tctrl.T.Helper()\n\t\tctrl.mu.Lock()\n\t\tdefer ctrl.mu.Unlock()\n\n\t\texpected, err := ctrl.expectedCalls.FindMatch(receiver, method, args)\n\t\tif err != nil {\n\t\t\torigin := callerInfo(2)\n\t\t\tctrl.T.Fatalf(\"Unexpected call to %T.%v(%v) at %s because: %s\", receiver, method, args, origin, err)\n\t\t}\n\n\t\t// Two things happen here:\n\t\t// * the matching call no longer needs to check prerequite calls,\n\t\t// * and the prerequite calls are no longer expected, so remove them.\n\t\tpreReqCalls := expected.dropPrereqs()\n\t\tfor _, preReqCall := range preReqCalls {\n\t\t\tctrl.expectedCalls.Remove(preReqCall)\n\t\t}\n\n\t\tactions := expected.call(args)\n\t\tif expected.exhausted() {\n\t\t\tctrl.expectedCalls.Remove(expected)\n\t\t}\n\t\treturn actions\n\t}()\n\n\tvar rets []interface{}\n\tfor _, action := range actions {\n\t\tif r := action(args); r != nil {\n\t\t\trets = r\n\t\t}\n\t}\n\n\treturn rets\n}", "label": 5}
{"code": "function (values, schema, options) {\n    var virtualList = find(schema, 'virtual');\n\n    //Set default value for virtual if not exists in values\n    if (options && options.query === true) {\n    }\n    else {\n        for (var virtual in virtualList) {\n\n            if (_.isArray(virtualList[virtual])) {\n\n                for (var thisVirtual in virtualList[virtual]) {\n\n                    if (_.isArray(values[virtual])) {\n                        for (var thisValue in values[virtual]) {\n                            setVirtuals(values[virtual][thisValue], virtualList[virtual][thisVirtual], options);\n                        }\n                    }\n                }\n            }\n            else {\n                if (values[virtual] === undefined && virtualList[virtual] && virtualList[virtual].hasOwnProperty('default') && options && options.partial !== true) {\n                    values[virtual] = (virtualList[virtual]).default;\n                }\n            }\n        }\n    }\n\n    for (var value in values) {\n\n        if (virtualList[value] && virtualList[value].virtual) {\n\n            var setFunction = virtualList[value].virtual;\n\n            //Check for setter and getter\n            if (virtualList[value].virtual.set) {\n                setFunction = virtualList[value].virtual.set;\n            }\n\n            //Check conditions and apply virtual\n            rulesMatch(value, values[value], setFunction, null, function (err, data) {\n                if (!err) {\n                    if (_.isFunction(setFunction)) {\n                        var virtualResult = setFunction(values[value]);\n                        if (_.isObject(virtualResult) && !_.isEmpty(virtualResult)) {\n                            //Check if virtual values does not exists in given values list. Do not overwrite given\n                            for (var vValue in virtualResult) {\n                                {\n                                    if (vValue == 'this') {\n                                        virtualResult[value] = virtualResult[vValue];\n                                        delete(virtualResult[vValue]);\n                                    }\n                                    else {\n                                        // Prevent overwrite of given values\n                                        if (values[vValue] !== undefined) {\n                                            delete(virtualResult[vValue]);\n                                        }\n                                    }\n                                }\n                            }\n                            values = _.assign(values, virtualResult);\n                        }\n                    }\n                }\n            });\n        }\n    }\n    return values;\n}", "label": 3}
{"code": "def validate(config, hash, options)\n      @options = options.dup\n      @log = options[:logger]\n\n      hash = convert_nils_to_empty_hashes(hash)\n      ensure_hook_type_sections_exist(hash)\n      check_hook_name_format(hash)\n      check_hook_env(hash)\n      check_for_missing_enabled_option(hash) unless @options[:default]\n      check_for_too_many_processors(config, hash)\n      check_for_verify_plugin_signatures_option(hash)\n\n      hash\n    end", "label": 4}
{"code": "function populateFieldDataFromDataSources(populatedForms, cb) {\n    logger.debug(\"populateFieldDataFromDataSources\", populatedForms);\n    var DataSource = models.get(connections.mongooseConnection, models.MODELNAMES.DATA_SOURCE);\n    //If no data source cache data is expected, then there is no need to load the Data Source Cache Data.\n\n    if (!options.expectDataSourceCache) {\n      return cb(undefined, populatedForms);\n    }\n    var dataSourceIds = getDataSourceIds(populatedForms);\n\n    logger.debug(\"populateFieldDataFromDataSources\", {dataSourceIds: dataSourceIds});\n\n    //If none of the forms refer to any data sources, then no need to search\n    if (dataSourceIds.length === 0) {\n      return cb(undefined, populatedForms);\n    }\n\n    var query = {\n      _id: {\n        \"$in\": dataSourceIds\n      }\n    };\n\n    //One query to populate all data sources\n    DataSource.find(query).exec(function(err, dataSources) {\n      if (err) {\n        logger.error(\"Error Finding Data Sources\", {error: err, dataSourceIds:dataSourceIds});\n        return cb(err);\n      }\n\n      logger.debug(\"populateFieldDataFromDataSources\", {dataSources: dataSources});\n\n      var validatonError = _validateReturnedDataSources(dataSourceIds, dataSources);\n\n      if (validatonError) {\n        logger.error(\"Error Getting Form With Data Sources\", {error: validatonError});\n        return cb(validatonError);\n      }\n\n      var cacheEntries = {};\n\n      //Assigning a lookup for cache entries\n      _.each(dataSources, function(dataSource) {\n        cacheEntries[dataSource._id] = dataSource.cache[0].data;\n      });\n\n      //Overriding field options for a field with data source data if the field is defined as being sourced from a data source.\n      populatedForms = _.map(populatedForms, function(populatedForm) {\n        populatedForm.pages = _.map(populatedForm.pages, function(page) {\n          page.fields =  _.map(page.fields, function(field) {\n            //If it is a data source type field, then return the data source data\n            if (field.dataSourceType === models.FORM_CONSTANTS.DATA_SOURCE_TYPE_DATA_SOURCE) {\n              //No guarantee these are set\n              field.fieldOptions = field.fieldOptions || {};\n              field.fieldOptions.definition = field.fieldOptions.definition || {};\n\n              //Setting the data source data\n              field.fieldOptions.definition.options = models.convertDSCacheToFieldOptions(field.type, cacheEntries[field.dataSource]);\n            }\n            return field;\n          });\n          return page;\n        });\n\n        return populatedForm;\n      });\n\n      logger.debug(\"populateFieldDataFromDataSources\", {populatedForms: JSON.stringify(populatedForms)});\n\n      //Finished, return the merged forms\n      return cb(undefined, populatedForms);\n    });\n\n  }", "label": 3}
{"code": "func (s *ProvisioningService) DeleteAllTokens() error {\n\tstartKey := backend.Key(tokensPrefix)\n\treturn s.DeleteRange(context.TODO(), startKey, backend.RangeEnd(startKey))\n}", "label": 5}
{"code": "def find_converter_instance(klass)\n      @find_converter_instance ||= {}\n      @find_converter_instance[klass] ||= begin\n        converters.find { |converter| converter.instance_of?(klass) } || \\\n          raise(\"No Converters found for #{klass}\")\n      end\n    end", "label": 4}
{"code": "private function waitNextInvocation(): array\n    {\n        if ($this->handler === null) {\n            $this->handler = curl_init(\"http://{$this->apiUrl}/2018-06-01/runtime/invocation/next\");\n            curl_setopt($this->handler, CURLOPT_FOLLOWLOCATION, true);\n            curl_setopt($this->handler, CURLOPT_FAILONERROR, true);\n        }\n\n        // Retrieve invocation ID\n        $contextBuilder = new ContextBuilder;\n        curl_setopt($this->handler, CURLOPT_HEADERFUNCTION, function ($ch, $header) use ($contextBuilder) {\n            if (! preg_match('/:\\s*/', $header)) {\n                return strlen($header);\n            }\n            [$name, $value] = preg_split('/:\\s*/', $header, 2);\n            $name = strtolower($name);\n            $value = trim($value);\n            if ($name === 'lambda-runtime-aws-request-id') {\n                $contextBuilder->setAwsRequestId($value);\n            }\n            if ($name === 'lambda-runtime-deadline-ms') {\n                $contextBuilder->setDeadlineMs(intval($value));\n            }\n            if ($name === 'lambda-runtime-invoked-function-arn') {\n                $contextBuilder->setInvokedFunctionArn($value);\n            }\n            if ($name === 'lambda-runtime-trace-id') {\n                $contextBuilder->setTraceId($value);\n            }\n\n            return strlen($header);\n        });\n\n        // Retrieve body\n        $body = '';\n        curl_setopt($this->handler, CURLOPT_WRITEFUNCTION, function ($ch, $chunk) use (&$body) {\n            $body .= $chunk;\n\n            return strlen($chunk);\n        });\n\n        curl_exec($this->handler);\n        if (curl_errno($this->handler) > 0) {\n            $message = curl_error($this->handler);\n            $this->closeHandler();\n            throw new \\Exception('Failed to fetch next Lambda invocation: ' . $message);\n        }\n        if ($body === '') {\n            throw new \\Exception('Empty Lambda runtime API response');\n        }\n\n        $context = $contextBuilder->buildContext();\n\n        if ($context->getAwsRequestId() === '') {\n            throw new \\Exception('Failed to determine the Lambda invocation ID');\n        }\n\n        $event = json_decode($body, true);\n\n        return [$event, $context];\n    }", "label": 2}
{"code": "public function setTense($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1\\PartOfSpeech_Tense::class);\n        $this->tense = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function broadcast($msg, array $exclude = array(), array $eligible = array()) {\n        $useEligible = (bool)count($eligible);\n        foreach ($this->subscribers as $client) {\n            if (in_array($client->WAMP->sessionId, $exclude)) {\n                continue;\n            }\n\n            if ($useEligible && !in_array($client->WAMP->sessionId, $eligible)) {\n                continue;\n            }\n\n            $client->event($this->id, $msg);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function renameFilesIOS (oldPackageName, newPackageName) {\n  const filesAndFolders = [\n    `ios/${oldPackageName}.xcodeproj/xcshareddata/xcschemes/<?>-tvOS.xcscheme`,\n    `ios/${oldPackageName}.xcodeproj/xcshareddata/xcschemes/<?>.xcscheme`,\n    'ios/<?>.xcodeproj',\n    `ios/${oldPackageName}/<?>.entitlements`,\n    'ios/<?>',\n    'ios/<?>-tvOS',\n    'ios/<?>-tvOSTests',\n    `ios/${oldPackageName}Tests/<?>Tests.m`,\n    'ios/<?>Tests',\n    'ios/<?>.xcworkspace',\n  ]\n\n  for (let i = 0; i < filesAndFolders.length; i++) {\n    const element = filesAndFolders[i]\n    const srcFile = fullPath(element.replace('<?>', oldPackageName))\n\n    console.log(`From ${relative(srcFile)}`)\n    if (fs.existsSync(srcFile)) {\n      const destFile = fullPath(element.replace('<?>', newPackageName))\n\n      fs.renameSync(srcFile, destFile)\n      console.log(`  to ${relative(destFile)}`)\n    } else {\n      console.log(`${srcFile} does not exists.`)\n    }\n  }\n}", "label": 3}
{"code": "def fetch_messages(topic:, partition:, offset: :latest, max_wait_time: 5, min_bytes: 1, max_bytes: 1048576, retries: 1)\n      operation = FetchOperation.new(\n        cluster: @cluster,\n        logger: @logger,\n        min_bytes: min_bytes,\n        max_bytes: max_bytes,\n        max_wait_time: max_wait_time,\n      )\n\n      operation.fetch_from_partition(topic, partition, offset: offset, max_bytes: max_bytes)\n\n      attempt = 1\n\n      begin\n        operation.execute.flat_map {|batch| batch.messages }\n      rescue Kafka::Error => e\n        @cluster.mark_as_stale!\n\n        if attempt >= (retries + 1)\n          raise\n        else\n          attempt += 1\n          @logger.warn \"Error while fetching messages, #{e.class}: #{e.message}; retrying...\"\n          retry\n        end\n      end\n    end", "label": 4}
{"code": "def DisplayIndexAsDictionary(word_occurrences):\n    \"\"\" \n    print the index as a dict \n    \"\"\"\n    word_keys = word_occurrences.keys()\n    for num, word in enumerate(word_keys):\n        line_nums = word_occurrences[word]\n        print(word + \" \")\n        if num > 3:\n            break", "label": 1}
{"code": "def extend_identity(identity, groups):\n    \"\"\"Extend identity with roles based on CERN groups.\"\"\"\n    provides = set([UserNeed(current_user.email)] + [\n        RoleNeed('{0}@cern.ch'.format(name)) for name in groups\n    ])\n    identity.provides |= provides\n    session[OAUTHCLIENT_CERN_SESSION_KEY] = provides", "label": 1}
{"code": "function vowExec(cmd) {\n    var defer = vow.defer();\n    exec(cmd, function (err, stdout, stderr) {\n        if (err) {\n            defer.reject({err: err, stderr: stderr});\n        } else {\n            defer.resolve(stdout.trim());\n        }\n    });\n    return defer.promise();\n}", "label": 3}
{"code": "func (p *PortAllocator) ReleasePort(ip net.IP, proto string, port int) error {\n\tp.mutex.Lock()\n\tdefer p.mutex.Unlock()\n\n\tif ip == nil {\n\t\tip = defaultIP\n\t}\n\tprotomap, ok := p.ipMap[ip.String()]\n\tif !ok {\n\t\treturn nil\n\t}\n\tdelete(protomap[proto].p, port)\n\treturn nil\n}", "label": 5}
{"code": "func (enc *Encoder) EncodeElement(v interface{}, start StartElement) error {\n\terr := enc.p.marshalValue(reflect.ValueOf(v), nil, &start)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn enc.p.Flush()\n}", "label": 5}
{"code": "function shouldFormatNode(node, profile) {\n\tif (!profile.get('format')) {\n\t\treturn false;\n\t}\n\n\tif (node.parent.isTextOnly\n\t\t&& node.parent.children.length === 1\n\t\t&& parseFields(node.parent.value).fields.length) {\n\t\t// Edge case: do not format the only child of text-only node,\n\t\t// but only if parent contains fields\n\t\treturn false;\n\t}\n\n\treturn isInline(node, profile) ? shouldFormatInline(node, profile) : true;\n}", "label": 3}
{"code": "public function setArguments($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Debugger\\V2\\Variable::class);\n        $this->arguments = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func ParseConfigOptions(cfgOptions ...Option) *Config {\n\tcfg := &Config{\n\t\tDaemon: DaemonCfg{\n\t\t\tDriverCfg: make(map[string]interface{}),\n\t\t},\n\t\tScopes: make(map[string]*datastore.ScopeCfg),\n\t}\n\n\tcfg.ProcessOptions(cfgOptions...)\n\tcfg.LoadDefaultScopes(cfg.Daemon.DataDir)\n\n\treturn cfg\n}", "label": 5}
{"code": "public Feature toDto(InternalFeature feature, int featureIncludes) throws GeomajasException {\n\t\tif (feature == null) {\n\t\t\treturn null;\n\t\t}\n\t\tFeature dto = new Feature(feature.getId());\n\t\tif ((featureIncludes & VectorLayerService.FEATURE_INCLUDE_ATTRIBUTES) != 0 && null != feature.getAttributes()) {\n\t\t\t// need to assure lazy attributes are converted to non-lazy attributes\n\t\t\tMap<String, Attribute> attributes = new HashMap<String, Attribute>();\n\t\t\tfor (Map.Entry<String, Attribute> entry : feature.getAttributes().entrySet()) {\n\t\t\t\tAttribute value = entry.getValue();\n\t\t\t\tif (value instanceof LazyAttribute) {\n\t\t\t\t\tvalue = ((LazyAttribute) value).instantiate();\n\t\t\t\t}\n\t\t\t\tattributes.put(entry.getKey(), value);\n\t\t\t}\n\t\t\tdto.setAttributes(attributes);\n\t\t}\n\t\tif ((featureIncludes & VectorLayerService.FEATURE_INCLUDE_LABEL) != 0) {\n\t\t\tdto.setLabel(feature.getLabel());\n\t\t}\n\t\tif ((featureIncludes & VectorLayerService.FEATURE_INCLUDE_GEOMETRY) != 0) {\n\t\t\tdto.setGeometry(toDto(feature.getGeometry()));\n\t\t}\n\t\tif ((featureIncludes & VectorLayerService.FEATURE_INCLUDE_STYLE) != 0 && null != feature.getStyleInfo()) {\n\t\t\tdto.setStyleId(feature.getStyleInfo().getStyleId());\n\t\t}\n\t\tInternalFeatureImpl vFeature = (InternalFeatureImpl) feature;\n\t\tdto.setClipped(vFeature.isClipped());\n\t\tdto.setUpdatable(feature.isEditable());\n\t\tdto.setDeletable(feature.isDeletable());\n\t\treturn dto;\n\t}", "label": 0}
{"code": "public function setTag($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1beta2\\PartOfSpeech_Tag::class);\n        $this->tag = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_responses update(nitro_service client, snmptrap resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmptrap updateresources[] = new snmptrap[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new snmptrap();\n\t\t\t\tupdateresources[i].trapclass = resources[i].trapclass;\n\t\t\t\tupdateresources[i].trapdestination = resources[i].trapdestination;\n\t\t\t\tupdateresources[i].destport = resources[i].destport;\n\t\t\t\tupdateresources[i].version = resources[i].version;\n\t\t\t\tupdateresources[i].communityname = resources[i].communityname;\n\t\t\t\tupdateresources[i].srcip = resources[i].srcip;\n\t\t\t\tupdateresources[i].severity = resources[i].severity;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static systemcountergroup[] get(nitro_service service, systemcountergroup_args args) throws Exception{\n\t\tsystemcountergroup obj = new systemcountergroup();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tsystemcountergroup[] response = (systemcountergroup[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function isglob(str, { strict = true } = {}) {\n  if (str === '') return false;\n  let match, rgx = strict ? STRICT : RELAXED;\n\n  while ((match = rgx.exec(str))) {\n    if (match[2]) return true;\n    let idx = match.index + match[0].length;\n\n    // if an open bracket/brace/paren is escaped,\n    // set the index to the next closing character\n    let open = match[1];\n    let close = open ? CHARS[open] : null;\n    if (open && close) {\n      let n = str.indexOf(close, idx);\n      if (n !== -1)  idx = n + 1;\n    }\n\n    str = str.slice(idx);\n  }\n  return false;\n}", "label": 3}
{"code": "public function info()\n    {\n        $data = [\n            'displayName' => [\n                'value' => $this->name\n            ],\n            'spanId' => $this->spanId,\n            'startTime' => $this->startTime,\n            'endTime' => $this->endTime\n        ];\n        if ($this->parentSpanId) {\n            $data['parentSpanId'] = $this->parentSpanId;\n        }\n        if ($this->attributes) {\n            $data['attributes'] = $this->attributes->info();\n        }\n        if ($this->timeEvents) {\n            $data['timeEvents'] = [\n                'timeEvent' => array_map(function ($timeEvent) {\n                    return $timeEvent->info();\n                }, $this->timeEvents)\n            ];\n        }\n        if ($this->links) {\n            $data['links'] = [\n                'link' => array_map(function ($link) {\n                    return $link->info();\n                }, $this->links)\n            ];\n        }\n        if ($this->status) {\n            $data['status'] = $this->status->info();\n        }\n        if ($this->stackTrace) {\n            $data['stackTrace'] = $this->stackTrace->info();\n        }\n        if ($this->sameProcessAsParentSpan !== null) {\n            $data['sameProcessAsParentSpan'] = $this->sameProcessAsParentSpan;\n        }\n        return $data;\n    }", "label": 2}
{"code": "func (t *Torrent) bytesCompleted() int64 {\n\tif !t.haveInfo() {\n\t\treturn 0\n\t}\n\treturn t.info.TotalLength() - t.bytesLeft()\n}", "label": 5}
{"code": "def apply(cell)\n      return false unless cell\n      filter_items.each do |filter|\n        return false if cell.value == filter.val\n      end\n      true\n    end", "label": 4}
{"code": "public function toggle()\n    {\n        if ($this->cache->get('telescope:pause-recording')) {\n            $this->cache->forget('telescope:pause-recording');\n        } else {\n            $this->cache->put('telescope:pause-recording', true, now()->addDays(30));\n        }\n    }", "label": 2}
{"code": "def print_pairwise(pw, median = False):\n    \"\"\"\n    print matrix of pidents to stdout\n    \"\"\"\n    names = sorted(set([i for i in pw]))\n    if len(names) != 0:\n        if '>' in names[0]:\n            yield ['#'] + [i.split('>')[1] for i in names if '>' in i]\n        else:\n            yield ['#'] + names\n        for a in names:\n            if '>' in a:\n                yield [a.split('>')[1]] + [pw[a][b] for b in names]\n            else:\n                out = []\n                for b in names:\n                    if b in pw[a]:\n                        if median is False:\n                            out.append(max(pw[a][b]))\n                        else:\n                            out.append(np.median(pw[a][b]))\n                    else:\n                        out.append('-')\n                yield [a] + out", "label": 1}
{"code": "protected function x_tune_ok($channel_max, $frame_max, $heartbeat)\n    {\n        $args = new AMQPWriter();\n        $args->write_short($channel_max);\n        $args->write_long($frame_max);\n        $args->write_short($heartbeat);\n        $this->send_method_frame(array(10, 31), $args);\n        $this->wait_tune_ok = false;\n    }", "label": 2}
{"code": "function _equals(a, b) {\n    if (a === b) {\n        return true;\n    }\n\n    const aType = $type(a);\n\n    if (aType != $type(b)) {\n        return false;\n    }\n\n    if (aType == 'array') {\n        return _arrEquals(a, b);\n    }\n\n    if (aType == 'object') {\n        return _objEquals(a, b);\n    }\n\n    if (aType == 'date') {\n        return +a == +b;\n    }\n\n    return false;\n}", "label": 3}
{"code": "func (ca *CertAuthorityV2) Checkers() ([]ssh.PublicKey, error) {\n\tout := make([]ssh.PublicKey, 0, len(ca.Spec.CheckingKeys))\n\tfor _, keyBytes := range ca.Spec.CheckingKeys {\n\t\tkey, _, _, _, err := ssh.ParseAuthorizedKey(keyBytes)\n\t\tif err != nil {\n\t\t\treturn nil, trace.BadParameter(\"invalid authority public key (len=%d): %v\", len(keyBytes), err)\n\t\t}\n\t\tout = append(out, key)\n\t}\n\treturn out, nil\n}", "label": 5}
{"code": "def payment_end(self, account, wallet):\n        \"\"\"\n        End a payment session.  Marks the account as available for use in a\n        payment session.\n\n        :param account: Account to mark available\n        :type account: str\n\n        :param wallet: Wallet to end payment session for\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.payment_end(\n        ...     account=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n        ...     wallet=\"FFFD1BAEC8EC20814BBB9059B393051AAA8380F9B5A2E6B2489A277D81789EEE\"\n        ... )\n        True\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"account\": account, \"wallet\": wallet}\n\n        resp = self.call('payment_end', payload)\n\n        return resp == {}", "label": 1}
{"code": "public function send($controller, User $actor = null, array $queryParams = [], array $body = []): ResponseInterface\n    {\n        $request = ServerRequestFactory::fromGlobals(null, $queryParams, $body);\n\n        $request = $request->withAttribute('actor', $actor);\n\n        if (is_string($controller)) {\n            $controller = $this->container->make($controller);\n        }\n\n        if (! ($controller instanceof RequestHandlerInterface)) {\n            throw new InvalidArgumentException(\n                'Endpoint must be an instance of '.RequestHandlerInterface::class\n            );\n        }\n\n        try {\n            return $controller->handle($request);\n        } catch (Exception $e) {\n            if (! $this->errorHandler) {\n                throw $e;\n            }\n\n            return $this->errorHandler->handle($e);\n        }\n    }", "label": 2}
{"code": "func (s *Server) DestroySessionV4(p *Packet) (interface{}, error) {\n\tif s.removeSession(p.SessionID) {\n\t\treturn &ReplyDestroySessionV4{}, nil\n\t}\n\n\treturn nil, &Status{Code: StatusStaleSession}\n}", "label": 5}
{"code": "func (sink *influxdbSink) keyToSelector(key core.HistoricalKey) string {\n\ttypeSel := fmt.Sprintf(\"type = '%s'\", key.ObjectType)\n\tswitch key.ObjectType {\n\tcase core.MetricSetTypeNode:\n\t\treturn fmt.Sprintf(\"%s AND %s = '%s'\", typeSel, core.LabelNodename.Key, key.NodeName)\n\tcase core.MetricSetTypeSystemContainer:\n\t\treturn fmt.Sprintf(\"%s AND %s = '%s' AND %s = '%s'\", typeSel, core.LabelContainerName.Key, key.ContainerName, core.LabelNodename.Key, key.NodeName)\n\tcase core.MetricSetTypeCluster:\n\t\treturn typeSel\n\tcase core.MetricSetTypeNamespace:\n\t\treturn fmt.Sprintf(\"%s AND %s = '%s'\", typeSel, core.LabelNamespaceName.Key, key.NamespaceName)\n\tcase core.MetricSetTypePod:\n\t\tif key.PodId != \"\" {\n\t\t\treturn fmt.Sprintf(\"%s AND %s = '%s'\", typeSel, core.LabelPodId.Key, key.PodId)\n\t\t} else {\n\t\t\treturn fmt.Sprintf(\"%s AND %s = '%s' AND %s = '%s'\", typeSel, core.LabelNamespaceName.Key, key.NamespaceName, core.LabelPodName.Key, key.PodName)\n\t\t}\n\tcase core.MetricSetTypePodContainer:\n\t\tif key.PodId != \"\" {\n\t\t\treturn fmt.Sprintf(\"%s AND %s = '%s' AND %s = '%s'\", typeSel, core.LabelPodId.Key, key.PodId, core.LabelContainerName.Key, key.ContainerName)\n\t\t} else {\n\t\t\treturn fmt.Sprintf(\"%s AND %s = '%s' AND %s = '%s' AND %s = '%s'\", typeSel, core.LabelNamespaceName.Key, key.NamespaceName, core.LabelPodName.Key, key.PodName, core.LabelContainerName.Key, key.ContainerName)\n\t\t}\n\t}\n\n\t// These are assigned by the API, so it shouldn't be possible to reach this unless things are really broken\n\tpanic(fmt.Sprintf(\"Unknown metric type %q\", key.ObjectType))\n}", "label": 5}
{"code": "public function setText($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Language\\V1\\TextSpan::class);\n        $this->text = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static void scanClassPathForFormattingAnnotations() {\n\n\t\tExecutorService executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors() * 2);\n\n\t\t// scan classpath and filter out classes that don't begin with \"com.nds\"\n\t\tReflections reflections = new Reflections(\"com.nds\",\"com.cisco\");\n\n\t\tSet<Class<?>> annotated = reflections.getTypesAnnotatedWith(DefaultFormat.class);\n\n//        Reflections ciscoReflections = new Reflections(\"com.cisco\");\n//\n//        annotated.addAll(ciscoReflections.getTypesAnnotatedWith(DefaultFormat.class));\n\n\t\tfor (Class<?> markerClass : annotated) {\n\n\t\t\t// if the marker class is indeed implementing FoundationLoggingMarker\n\t\t\t// interface\n\t\t\tif (FoundationLoggingMarker.class.isAssignableFrom(markerClass)) {\n\n\t\t\t\tfinal Class<? extends FoundationLoggingMarker> clazz = (Class<? extends FoundationLoggingMarker>) markerClass;\n\n\t\t\t\texecutorService.execute(new Runnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\n\t\t\t\t\t\tif (markersMap.get(clazz) == null) {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t// generate formatter class for this marker\n\t\t\t\t\t\t\t\t// class\n\t\t\t\t\t\t\t\tgenerateAndUpdateFormatterInMap(clazz);\n\t\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\t\tLOGGER.trace(\"problem generating formatter class from static scan method. error is: \" + e.toString());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t} else {// if marker class does not implement FoundationLoggingMarker\n\t\t\t\t\t// interface, log ERROR\n\n\t\t\t\t// verify the LOGGER was initialized. It might not be as this\n\t\t\t\t// Method is called in a static block\n\t\t\t\tif (LOGGER == null) {\n\t\t\t\t\tLOGGER = LoggerFactory.getLogger(AbstractFoundationLoggingMarker.class);\n\t\t\t\t}\n\t\t\t\tLOGGER.error(\"Formatter annotations should only appear on foundationLoggingMarker implementations\");\n\t\t\t}\n\t\t}\n\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(30);\n\t\t} catch (InterruptedException e) {\n\t\t\tLOGGER.trace(e.toString(), e);\n\t\t}\n\t\texecutorService.shutdown();\n\t\t// try {\n\t\t// executorService.awaitTermination(15, TimeUnit.SECONDS);\n\t\t// } catch (InterruptedException e) {\n\t\t// LOGGER.error(\"creation of formatters has been interrupted\");\n\t\t// }\n\t}", "label": 0}
{"code": "func getLines(input []byte, commentMarker []byte) [][]byte {\n\tlines := bytes.Split(input, []byte(\"\\n\"))\n\tvar output [][]byte\n\tfor _, currentLine := range lines {\n\t\tvar commentIndex = bytes.Index(currentLine, commentMarker)\n\t\tif commentIndex == -1 {\n\t\t\toutput = append(output, currentLine)\n\t\t} else {\n\t\t\toutput = append(output, currentLine[:commentIndex])\n\t\t}\n\t}\n\treturn output\n}", "label": 5}
{"code": "func mkns(ns string, obj interface{}, name ...*xml.Name) string {\n\tns += \":\"\n\tfor i := range name {\n\t\tname[i].Space = \"\"\n\t\tif !strings.HasPrefix(name[i].Local, ns) {\n\t\t\tname[i].Local = ns + name[i].Local\n\t\t}\n\t}\n\n\treturn Marshal(obj)\n}", "label": 5}
{"code": "function (member) {\n        if (\"[\" !== member.charAt(0) || \"]\" !== member.charAt(member.length - 1)) {\n            return \"\";\n        }\n        return _gpfEncodeAttributeMember(member.substr(1, member.length - 2)); // Extract & encode member name\n    }", "label": 3}
{"code": "def contextual_price_with_currency(rent_or_sale)\n      contextual_price = self.contextual_price rent_or_sale\n\n      if contextual_price.zero?\n        return nil\n      else\n        return contextual_price.format(no_cents: true)\n      end\n      # return contextual_price.zero? ? nil : contextual_price.format(:no_cents => true)\n    end", "label": 4}
{"code": "func (v VirtualMachine) AddDevice(ctx context.Context, device ...types.BaseVirtualDevice) error {\n\treturn v.configureDevice(ctx, types.VirtualDeviceConfigSpecOperationAdd, types.VirtualDeviceConfigSpecFileOperationCreate, device...)\n}", "label": 5}
{"code": "def merge_default(defaults)\n      if defaults && !defaults.empty?\n        defaults.each do |key, value|\n          self[key] = value unless self.key?(key)\n        end\n      end\n      self\n    end", "label": 4}
{"code": "public static function fromJson(array $data)\n    {\n        if (array_key_exists('members', $data)) {\n            $data['members'] = array_map([static::class, 'fromJson'], $data['members']);\n        }\n        if (array_key_exists('status', $data)) {\n            $data['status'] = StatusMessage::fromJson($data['status']);\n        }\n        return new static($data['name'], $data['type'], $data);\n    }", "label": 2}
{"code": "func ParseMagnetURI(uri string) (m Magnet, err error) {\n\tu, err := url.Parse(uri)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"error parsing uri: %s\", err)\n\t\treturn\n\t}\n\tif u.Scheme != \"magnet\" {\n\t\terr = fmt.Errorf(\"unexpected scheme: %q\", u.Scheme)\n\t\treturn\n\t}\n\txt := u.Query().Get(\"xt\")\n\tif !strings.HasPrefix(xt, xtPrefix) {\n\t\terr = fmt.Errorf(\"bad xt parameter\")\n\t\treturn\n\t}\n\tinfoHash := xt[len(xtPrefix):]\n\n\t// BTIH hash can be in HEX or BASE32 encoding\n\t// will assign appropriate func judging from symbol length\n\tvar decode func(dst, src []byte) (int, error)\n\tswitch len(infoHash) {\n\tcase 40:\n\t\tdecode = hex.Decode\n\tcase 32:\n\t\tdecode = base32.StdEncoding.Decode\n\t}\n\n\tif decode == nil {\n\t\terr = fmt.Errorf(\"unhandled xt parameter encoding: encoded length %d\", len(infoHash))\n\t\treturn\n\t}\n\tn, err := decode(m.InfoHash[:], []byte(infoHash))\n\tif err != nil {\n\t\terr = fmt.Errorf(\"error decoding xt: %s\", err)\n\t\treturn\n\t}\n\tif n != 20 {\n\t\tpanic(n)\n\t}\n\tm.DisplayName = u.Query().Get(\"dn\")\n\tm.Trackers = u.Query()[\"tr\"]\n\treturn\n}", "label": 5}
{"code": "def find_alias(action_name)\n      Actions.alias_actions.each do |key, v|\n        next unless Actions.alias_actions[key]\n        next unless Actions.alias_actions[key].include?(action_name)\n        return key\n      end\n      nil\n    end", "label": 4}
{"code": "def update_page(location_id, page_id, body, opts = {})\n      data, _status_code, _headers = update_page_with_http_info(location_id, page_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "func (d Datastore) NewFileManager(dc *Datacenter, force bool) *DatastoreFileManager {\n\tc := d.Client()\n\n\tm := &DatastoreFileManager{\n\t\tDatacenter:         dc,\n\t\tDatastore:          &d,\n\t\tFileManager:        NewFileManager(c),\n\t\tVirtualDiskManager: NewVirtualDiskManager(c),\n\t\tForce:              force,\n\t\tDatacenterTarget:   dc,\n\t}\n\n\treturn m\n}", "label": 5}
{"code": "public function setSize(WebDriverDimension $size)\n    {\n        $params = [\n            'width' => $size->getWidth(),\n            'height' => $size->getHeight(),\n            ':windowHandle' => 'current',\n        ];\n        $this->executor->execute(DriverCommand::SET_WINDOW_SIZE, $params);\n\n        return $this;\n    }", "label": 2}
{"code": "def get_action_cache(self, action_key):\n        \"\"\"Get action needs and excludes from cache.\n\n        .. note:: It returns the action if a cache system is defined.\n\n        :param action_key: The unique action name.\n        :returns: The action stored in cache or ``None``.\n        \"\"\"\n        data = None\n        if self.cache:\n            data = self.cache.get(\n                self.app.config['ACCESS_ACTION_CACHE_PREFIX'] +\n                action_key\n            )\n        return data", "label": 1}
{"code": "func CreateOptionService(name, id string, vip net.IP, ingressPorts []*PortConfig, aliases []string) EndpointOption {\n\treturn func(ep *endpoint) {\n\t\tep.svcName = name\n\t\tep.svcID = id\n\t\tep.virtualIP = vip\n\t\tep.ingressPorts = ingressPorts\n\t\tep.svcAliases = aliases\n\t}\n}", "label": 5}
{"code": "def ext_from_filename(filename):\n    \"\"\" Scan a filename for it's extension.\n\n    :param filename: string of the filename\n    :return: the extension off the end (empty string if it can't find one)\n    \"\"\"\n    try:\n        base, ext = filename.lower().rsplit(\".\", 1)\n    except ValueError:\n        return ''\n    ext = \".{0}\".format(ext)\n    all_exts = [x.extension for x in chain(magic_header_array,\n                                           magic_footer_array)]\n\n    if base[-4:].startswith(\".\"):\n        # For double extensions like like .tar.gz\n        long_ext = base[-4:] + ext\n        if long_ext in all_exts:\n            return long_ext\n    return ext", "label": 1}
{"code": "public function setImage($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\Image::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "protected List splitInCriteria(Object attribute, Collection values, boolean negative, int inLimit)\r\n    {\r\n        List result = new ArrayList();\r\n        Collection inCollection = new ArrayList();\r\n\r\n        if (values == null || values.isEmpty())\r\n        {\r\n            // OQL creates empty Criteria for late binding\r\n            result.add(buildInCriteria(attribute, negative, values));\r\n        }\r\n        else\r\n        {\r\n            Iterator iter = values.iterator();\r\n\r\n            while (iter.hasNext())\r\n            {\r\n                inCollection.add(iter.next());\r\n                if (inCollection.size() == inLimit || !iter.hasNext())\r\n                {\r\n                    result.add(buildInCriteria(attribute, negative, inCollection));\r\n                    inCollection = new ArrayList();\r\n                }\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def make_tmpdir_name(base)\n      t = Time.now.strftime('%Y%m%d')\n      name = \"#{base}#{t}-#{Process.pid}-#{rand(0x100000000).to_s(36)}\"\n      File.join(Dir.tmpdir, name)\n    end", "label": 4}
{"code": "def serialize\n      {\n        \"job_class\"  => self.class.name,\n        \"job_id\"     => job_id,\n        \"provider_job_id\" => provider_job_id,\n        \"queue_name\" => queue_name,\n        \"priority\"   => priority,\n        \"arguments\"  => serialize_arguments_if_needed(arguments),\n        \"executions\" => executions,\n        \"exception_executions\" => exception_executions,\n        \"locale\"     => I18n.locale.to_s,\n        \"timezone\"   => Time.zone.try(:name),\n        \"enqueued_at\" => Time.now.utc.iso8601\n      }\n    end", "label": 4}
{"code": "public function fromBigQuery(array $value, array $schema)\n    {\n        $value = $value['v'];\n\n        if (isset($schema['mode'])) {\n            if ($schema['mode'] === 'REPEATED') {\n                return $this->repeatedValueFromBigQuery($value, $schema);\n            }\n\n            if ($schema['mode'] === 'NULLABLE' && $value === null) {\n                return $value;\n            }\n        }\n\n        switch ($schema['type']) {\n            case self::TYPE_BOOLEAN:\n                return $value === 'true';\n            case self::TYPE_INTEGER:\n                return $this->returnInt64AsObject\n                    ? new Int64($value)\n                    : (int) $value;\n            case self::TYPE_FLOAT:\n                return (float) $value;\n            case self::TYPE_NUMERIC:\n                return new Numeric($value);\n            case self::TYPE_STRING:\n                return (string) $value;\n            case self::TYPE_BYTES:\n                return new Bytes(base64_decode($value));\n            case self::TYPE_DATE:\n                return new Date(new \\DateTime($value));\n            case self::TYPE_DATETIME:\n                return new \\DateTime($value);\n            case self::TYPE_TIME:\n                return new Time(new \\DateTime($value));\n            case self::TYPE_TIMESTAMP:\n                return $this->timestampFromBigQuery($value);\n            case self::TYPE_RECORD:\n                return $this->recordFromBigQuery($value, $schema['fields']);\n            default:\n                throw new \\InvalidArgumentException(sprintf(\n                    'Unrecognized value type %s. Please ensure you are using the latest version of google/cloud.',\n                    $schema['type']\n                ));\n\n                break;\n        }\n    }", "label": 2}
{"code": "def namespace(name)\n      name ||= :root\n\n      namespace = namespaces[name] ||= begin\n        namespace = Namespace.new(self, name)\n        ActiveSupport::Notifications.publish ActiveAdmin::Namespace::RegisterEvent, namespace\n        namespace\n      end\n\n      yield(namespace) if block_given?\n\n      namespace\n    end", "label": 4}
{"code": "function (reInit = false) {\n        //load routes\n        var environment = Shared.config(\"environment\");\n        var hosts = environment.hosts;\n        if (hosts) {\n            if (!_.isArray(hosts)) {\n                hosts = [hosts];\n            }\n            for (var host in hosts) {\n                _parseHosts(hosts[host], reInit);\n            }\n        }\n        _vhosts[\"*\"] = {\n            host: '*',\n            router: new express.Router()\n        };\n\n        _applyRouterConfig(_vhosts[\"*\"][\"router\"]);\n        _customInitFuncton(_vhosts[\"*\"][\"router\"]);\n\n        return RoutesHandler.initializeRoutes(_vhosts, reInit === false);\n    }", "label": 3}
{"code": "function(htmlFile, config, cb) {\n        var html = fs.readFileSync(htmlFile, 'utf-8'),\n            processedImages = 0,\n            $ = cheerio.load(html);\n\n        // grab all <img/> elements from the document\n        $('img').each(function (idx, elm) {\n            var src = $(elm).attr('src'),\n                imgPath = null,\n                img = null,\n                mimetype = null,\n                inlineImgPath = null;\n\n            // check if the image src is already a data attribute\n            if (src.substr(0, 5) !== 'data:') {\n                // figure out the image path and load it\n                inlineImgPath = imgPath = path.join(path.dirname(htmlFile), src);\n                img = fs.readFileSync(imgPath, 'base64');\n\n                mimetype = mime.lookup(inlineImgPath);\n\n                // check file size and ie8 compat mode\n                if (img.length > 32768 && config.ie8 === true) {\n                    // i hate to write this, but can\u00b4t wrap my head around\n                    // how to do this better: DO NOTHING\n                } else {\n                    $(elm).attr('src', 'data:' + mimetype + ';base64,' + img);\n                    processedImages++;\n                }\n            }\n\n        });\n        html = $.html();\n\n        // check if a callback is given\n        if (_.isFunction(cb)) {\n            grunt.log.ok('Inlined: ' + processedImages + ' Images in file: ' + htmlFile);\n            cb(htmlFile, html);\n        }\n    }", "label": 3}
{"code": "func (l VirtualDeviceList) Find(name string) types.BaseVirtualDevice {\n\tfor _, device := range l {\n\t\tif l.Name(device) == name {\n\t\t\treturn device\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func (l VirtualDeviceList) SelectByBackingInfo(backing types.BaseVirtualDeviceBackingInfo) VirtualDeviceList {\n\tt := reflect.TypeOf(backing)\n\n\treturn l.Select(func(device types.BaseVirtualDevice) bool {\n\t\tdb := device.GetVirtualDevice().Backing\n\t\tif db == nil {\n\t\t\treturn false\n\t\t}\n\n\t\tif reflect.TypeOf(db) != t {\n\t\t\treturn false\n\t\t}\n\n\t\tif reflect.ValueOf(backing).IsNil() {\n\t\t\t// selecting by backing type\n\t\t\treturn true\n\t\t}\n\n\t\tswitch a := db.(type) {\n\t\tcase *types.VirtualEthernetCardNetworkBackingInfo:\n\t\t\tb := backing.(*types.VirtualEthernetCardNetworkBackingInfo)\n\t\t\treturn a.DeviceName == b.DeviceName\n\t\tcase *types.VirtualEthernetCardDistributedVirtualPortBackingInfo:\n\t\t\tb := backing.(*types.VirtualEthernetCardDistributedVirtualPortBackingInfo)\n\t\t\treturn a.Port.SwitchUuid == b.Port.SwitchUuid &&\n\t\t\t\ta.Port.PortgroupKey == b.Port.PortgroupKey\n\t\tcase *types.VirtualDiskFlatVer2BackingInfo:\n\t\t\tb := backing.(*types.VirtualDiskFlatVer2BackingInfo)\n\t\t\tif a.Parent != nil && b.Parent != nil {\n\t\t\t\treturn a.Parent.FileName == b.Parent.FileName\n\t\t\t}\n\t\t\treturn a.FileName == b.FileName\n\t\tcase *types.VirtualSerialPortURIBackingInfo:\n\t\t\tb := backing.(*types.VirtualSerialPortURIBackingInfo)\n\t\t\treturn a.ServiceURI == b.ServiceURI\n\t\tcase types.BaseVirtualDeviceFileBackingInfo:\n\t\t\tb := backing.(types.BaseVirtualDeviceFileBackingInfo)\n\t\t\treturn a.GetVirtualDeviceFileBackingInfo().FileName == b.GetVirtualDeviceFileBackingInfo().FileName\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t})\n}", "label": 5}
{"code": "public function setEntityResults($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Datastore\\V1\\EntityResult::class);\n        $this->entity_results = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_responses update(nitro_service client, route6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\troute6 updateresources[] = new route6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new route6();\n\t\t\t\tupdateresources[i].network = resources[i].network;\n\t\t\t\tupdateresources[i].gateway = resources[i].gateway;\n\t\t\t\tupdateresources[i].vlan = resources[i].vlan;\n\t\t\t\tupdateresources[i].weight = resources[i].weight;\n\t\t\t\tupdateresources[i].distance = resources[i].distance;\n\t\t\t\tupdateresources[i].cost = resources[i].cost;\n\t\t\t\tupdateresources[i].advertise = resources[i].advertise;\n\t\t\t\tupdateresources[i].msr = resources[i].msr;\n\t\t\t\tupdateresources[i].monitor = resources[i].monitor;\n\t\t\t\tupdateresources[i].td = resources[i].td;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static Organization createOrganization(final String name){\n        final Organization organization = new Organization();\n        organization.setName(name);\n\n        return organization;\n\n    }", "label": 0}
{"code": "@Override\n    public int getShadowSize() {\n\tElement shadowElement = shadow.getElement();\n\tshadowElement.setScrollTop(10000);\n\treturn shadowElement.getScrollTop();\n    }", "label": 0}
{"code": "function stop(id, formatted) {\n  const elapsed = timers[id].elapsed + msDiff(process.hrtime(), timers[id].start);\n\n  clear(id);\n  return formatted ? format(elapsed) : elapsed;\n}", "label": 3}
{"code": "public void setOccurence(int min, int max) throws ParseException {\n    if (!simplified) {\n      if ((min < 0) || (min > max) || (max < 1)) {\n        throw new ParseException(\"Illegal number {\" + min + \",\" + max + \"}\");\n      }\n      if (min == 0) {\n        optional = true;\n      }\n      minimumOccurence = Math.max(1, min);\n      maximumOccurence = max;\n    } else {\n      throw new ParseException(\"already simplified\");\n    }\n  }", "label": 0}
{"code": "public function show(EntriesRepository $storage, $id)\n    {\n        return response($storage->find($id)->content['raw'], 200, [\n            'Content-Type' => 'message/rfc822',\n            'Content-Disposition' => 'attachment; filename=\"mail-'.$id.'.eml\"',\n        ]);\n    }", "label": 2}
{"code": "def is_branch?(branch)\n      branch_names = self.branches.map {|b| b.name}\n      branch_names.include?(branch)\n    end", "label": 4}
{"code": "def release(self, force=False):\n\t\t\"\"\"Release an exclusive lock on this integration task.\n\t\t\n\t\tUnless forcing, if we are not the current owners of the lock a Locked exception will be raised.\n\t\t\"\"\"\n\t\t\n\t\tD = self.__class__\n\t\tcollection = self.get_collection()\n\t\tidentity = self.Lock()\n\t\t\n\t\tquery = D.id == self\n\t\t\n\t\tif not force:\n\t\t\tquery &= D.lock.instance == identity.instance\n\t\t\n\t\tprevious = collection.find_one_and_update(query, {'$unset': {~D.lock: True}}, {~D.lock: True})\n\t\t\n\t\tif previous is None:\n\t\t\tlock = getattr(self.find_one(self, projection={~D.lock: True}), 'lock', None)\n\t\t\traise self.Locked(\"Unable to release lock.\", lock)\n\t\t\n\t\tlock = self.Lock.from_mongo(previous[~D.lock])\n\t\t\n\t\tif lock and lock.expires <= identity.time:\n\t\t\tlock.expired(self)\n\t\t\n\t\tidentity.released(self, force)", "label": 1}
{"code": "def display_gadgets(gadgets, raw)\n      if raw\n        show(gadgets.map(&:offset).join(' '))\n      else\n        show(gadgets.map(&:inspect).join(\"\\n\"))\n      end\n    end", "label": 4}
{"code": "def run_mutation_aggregator(job, mutation_results, univ_options):\n    \"\"\"\n    Aggregate all the called mutations.\n\n    :param dict mutation_results: Dict of dicts of the various mutation callers in a per chromosome\n           format\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :returns: fsID for the merged mutations file\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    # Setup an input data structure for the merge function\n    out = {}\n    for chrom in mutation_results['mutect'].keys():\n        out[chrom] = job.addChildJobFn(merge_perchrom_mutations, chrom, mutation_results,\n                                       univ_options).rv()\n    merged_snvs = job.addFollowOnJobFn(merge_perchrom_vcfs, out, 'merged', univ_options)\n    job.fileStore.logToMaster('Aggregated mutations for %s successfully' % univ_options['patient'])\n    return merged_snvs.rv()", "label": 1}
{"code": "func (s *PresenceService) KeepAliveNode(ctx context.Context, h services.KeepAlive) error {\n\tif err := h.CheckAndSetDefaults(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\terr := s.KeepAlive(ctx, backend.Lease{\n\t\tID:  h.LeaseID,\n\t\tKey: backend.Key(nodesPrefix, h.Namespace, h.ServerName),\n\t}, h.Expires)\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def edit_link(link, action, subject, extra_context = {})\n      return unless current_user\n      return unless admin_allowed_to?(action, subject, extra_context)\n      return if content_for?(:edit_link)\n\n      content_for(:edit_link, link)\n    end", "label": 4}
{"code": "private void beginInternTransaction()\r\n    {\r\n        if (log.isDebugEnabled()) log.debug(\"beginInternTransaction was called\");\r\n        J2EETransactionImpl tx = (J2EETransactionImpl) super.currentTransaction();\r\n        if (tx == null) tx = newInternTransaction();\r\n        if (!tx.isOpen())\r\n        {\r\n            // start the transaction\r\n            tx.begin();\r\n            tx.setInExternTransaction(true);\r\n        }\r\n    }", "label": 0}
{"code": "public function setTransferConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferConfig::class);\n        $this->transfer_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public void build(double[] coords, int nump) throws IllegalArgumentException {\n        if (nump < 4) {\n            throw new IllegalArgumentException(\"Less than four input points specified\");\n        }\n        if (coords.length / 3 < nump) {\n            throw new IllegalArgumentException(\"Coordinate array too small for specified number of points\");\n        }\n        initBuffers(nump);\n        setPoints(coords, nump);\n        buildHull();\n    }", "label": 0}
{"code": "function convertForPackage(context, pkg) {\n\tvar name = pkg.name;\n\tvar version = pkg.version;\n\n\tvar conv = context.deferredConversions;\n\tvar pkgConv = conv[name];\n\tvar depPkg, fns, keys = 0;\n\tif(pkgConv) {\n\t\tfor(var range in pkgConv) {\n\t\t\tdepPkg = crawl.matchedVersion(context, name, range);\n\t\t\tif(depPkg) {\n\t\t\t\tfns = pkgConv[range];\n\t\t\t\tfor(var i = 0, len = fns.length; i < len; i++) {\n\t\t\t\t\tfns[i].call(context);\n\t\t\t\t}\n\t\t\t\tdelete pkgConv[range];\n\t\t\t} else {\n\t\t\t\tkeys++;\n\t\t\t}\n\t\t}\n\t\tif(keys === 0) {\n\t\t\tdelete conv[name];\n\t\t}\n\t}\n}", "label": 3}
{"code": "def load_configuration_file(config_file_name = nil, block_for_missing = nil, skip_printing_values = false)\n      return unless config_file_name\n\n      self.config_file_name = config_file_name\n\n      path = FastlaneCore::Configuration.find_configuration_file_path(config_file_name: config_file_name)\n      return if path.nil?\n\n      begin\n        configuration_file = ConfigurationFile.new(self, path, block_for_missing, skip_printing_values)\n        options = configuration_file.options\n      rescue FastlaneCore::ConfigurationFile::ExceptionWhileParsingError => e\n        options = e.recovered_options\n        wrapped_exception = e.wrapped_exception\n      end\n\n      # Make sure all the values set in the config file pass verification\n      options.each do |key, val|\n        option = self.verify_options_key!(key)\n        option.verify!(val)\n      end\n\n      # Merge the new options into the old ones, keeping all previously set keys\n      self.config_file_options = options.merge(self.config_file_options)\n\n      verify_conflicts # important, since user can set conflicting options in configuration file\n\n      # Now that everything is verified, re-raise an exception that was raised in the config file\n      raise wrapped_exception unless wrapped_exception.nil?\n\n      configuration_file\n    end", "label": 4}
{"code": "function _objEquals(a, b) {\n    const aKeys = Object.keys(a);\n\n    return _arrEquals(aKeys.sort(), Object.keys(b).sort()) &&\n        aKeys.every(i => _equals(a[i], b[i]));\n}", "label": 3}
{"code": "func (cli *NetworkCli) CmdNetworkLs(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"ls\", \"\", \"Lists all the networks created by the user\", false)\n\tquiet := cmd.Bool([]string{\"q\", \"-quiet\"}, false, \"Only display numeric IDs\")\n\tnoTrunc := cmd.Bool([]string{\"#notrunc\", \"-no-trunc\"}, false, \"Do not truncate the output\")\n\tnLatest := cmd.Bool([]string{\"l\", \"-latest\"}, false, \"Show the latest network created\")\n\tlast := cmd.Int([]string{\"n\"}, -1, \"Show n last created networks\")\n\terr := cmd.ParseFlags(args, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\tobj, _, err := readBody(cli.call(\"GET\", \"/networks\", nil, nil))\n\tif err != nil {\n\t\treturn err\n\t}\n\tif *last == -1 && *nLatest {\n\t\t*last = 1\n\t}\n\n\tvar networkResources []networkResource\n\terr = json.Unmarshal(obj, &networkResources)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\twr := tabwriter.NewWriter(cli.out, 20, 1, 3, ' ', 0)\n\n\t// unless quiet (-q) is specified, print field titles\n\tif !*quiet {\n\t\tfmt.Fprintln(wr, \"NETWORK ID\\tNAME\\tTYPE\")\n\t}\n\n\tfor _, networkResource := range networkResources {\n\t\tID := networkResource.ID\n\t\tnetName := networkResource.Name\n\t\tif !*noTrunc {\n\t\t\tID = stringid.TruncateID(ID)\n\t\t}\n\t\tif *quiet {\n\t\t\tfmt.Fprintln(wr, ID)\n\t\t\tcontinue\n\t\t}\n\t\tnetType := networkResource.Type\n\t\tfmt.Fprintf(wr, \"%s\\t%s\\t%s\\t\",\n\t\t\tID,\n\t\t\tnetName,\n\t\t\tnetType)\n\t\tfmt.Fprint(wr, \"\\n\")\n\t}\n\twr.Flush()\n\treturn nil\n}", "label": 5}
{"code": "def start(self):\n        '''\n        Starts execution of the script\n        '''\n        # invoke the appropriate sub-command as requested from command-line\n        try:\n            self.args.func()\n        except SystemExit as e:\n            if e.code != 0:\n                raise\n        except KeyboardInterrupt:\n            self.log.warning(\"exited via keyboard interrupt\")\n        except:\n            self.log.exception(\"exited start function\")\n            # set exit code so we know it did not end successfully\n            # TODO different exit codes based on signals ?\n        finally:\n            self._flush_metrics_q.put(None, block=True)\n            self._flush_metrics_q.put(None, block=True, timeout=1)\n\n        self.log.debug(\"exited_successfully\")", "label": 1}
{"code": "public static linkset[] get(nitro_service service) throws Exception{\n\t\tlinkset obj = new linkset();\n\t\tlinkset[] response = (linkset[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function createStrings(input) {\n  return new Promise((resolve, reject) => {\n    try {\n      if (!input) {\n        return resolve(null);\n      }\n\n      const importsString = input.imports.length ? `${input.imports.join('\\n')}\\n\\n` : '';\n      const exportsString = input.exports.length ? `${input.exports.join('\\n')}\\n` : '';\n      const indexString = `${importsString}${exportsString}`.replace('\\n\\n\\n', '\\n\\n');\n\n      return resolve(indexString.length ? indexString : null);\n    } catch (e) {\n      return reject(new Error(t('STRINGS_COULD_NOT_BE_CREATED')));\n    }\n  });\n}", "label": 3}
{"code": "function logWrap(level) {\n    return function log() {\n      let context, message, args, trace, err;\n\n      if (arguments[0] instanceof Error) {\n        // log.<level>(err, ...)\n        context = API.getContext();\n        args = Array.prototype.slice.call(arguments, 1);\n        if (!args.length) {\n          // log.<level>(err)\n          err = arguments[0];\n          message = err.name + ': ' + err.message;\n        } else {\n          // log.<level>(err, \"More %s\", \"things\")\n          // Use the err as context information\n          err = arguments[0];\n          message = arguments[1];\n          args = Array.prototype.slice.call(args, 1);\n        }\n      } else if (arguments[0] == null || (typeof (arguments[0]) !== 'object' && arguments[0] !== null) ||\n          Array.isArray(arguments[0])) {\n        // log.<level>(msg, ...)\n        context = API.getContext();\n        message = arguments[0];\n        args = Array.prototype.slice.call(arguments, 1);\n      } else {\n        // log.<level>(fields, msg, ...)\n        context = merge(API.getContext(), arguments[0]);\n        message = arguments[1];\n        args = Array.prototype.slice.call(arguments, 2);\n      }\n\n      trace = API.format(level, context || {}, message, args, err);\n      API.stream.write(trace + '\\n');\n    };\n  }", "label": 3}
{"code": "function (soajs, data, cb) {\n        let token = data.token;\n        let openam;\n\n        if (soajs.servicesConfig.urac && soajs.servicesConfig.urac.openam) {\n            openam = soajs.servicesConfig.urac.openam;\n        }\n        else {\n            return cb({\"code\": 712, \"msg\": soajs.config.errors[712]});\n        }\n\n        let openamAttributesURL = openam.attributesURL;\n        let openamAttributesMap = openam.attributesMap;\n        let openamTimeout = openam.timeout || 10000;\n\n        request.post(openamAttributesURL, {\n            form: {subjectid: token},\n            timeout: openamTimeout\n        }, function (error, response, body) {\n            let userRecord;\n\n            if (error) {\n                soajs.log.error(error);\n                return cb({\"code\": 710, \"msg\": soajs.config.errors[710]});\n            }\n\n            if (!response || response.statusCode !== 200) {\n                soajs.log.error(\"OpenAM token invalid!\");\n                return cb({\"code\": 711, \"msg\": soajs.config.errors[711]});\n            }\n\n            try {\n                userRecord = JSON.parse(body);\n            } catch (err) {\n                soajs.log.error(\"OpenAM response invalid!\");\n                return cb({\"code\": 712, \"msg\": soajs.config.errors[712]});\n            }\n\n            soajs.log.debug('Authenticated!');\n\n            initBLModel(soajs, function (err) {\n                if (err) {\n                    return cb(err);\n                }\n                utilities.saveUser(soajs, driver.model, 'openam', {\n                    userRecord: userRecord,\n                    attributesMap: openamAttributesMap\n                }, function (error, record) {\n                    return cb(null, record);\n                });\n            });\n        });\n    }", "label": 3}
{"code": "function _gpfJsonParsePolyfill(text, reviver) {\n        var result = _gpfFunc(\"return \" + text)();\n        if (reviver) {\n            return _gpfJsonParseApplyReviver(result, \"\", reviver);\n        }\n        return result;\n    }", "label": 3}
{"code": "def _check_request(self, msg):\n        \"\"\"Checks that the request json is well-formed.\n\n        :param msg: The request's json data\n        :type msg: dict[str, object]\n        \"\"\"\n        if \"jsonrpc\" not in msg:\n            raise InvalidRequestError(\"'\\\"jsonrpc\\\": \\\"2.0\\\"' must be included.\")\n        if msg[\"jsonrpc\"] != \"2.0\":\n            raise InvalidRequestError(\"'jsonrpc' must be exactly the string '2.0', but it was '{}'.\"\n                                      .format(msg[\"jsonrpc\"]))\n        if \"method\" not in msg:\n            raise InvalidRequestError(\"No method specified.\")\n        if \"id\" in msg:\n            if msg[\"id\"] is None:\n                raise InvalidRequestError(\"typedjsonrpc does not allow id to be None.\")\n            if isinstance(msg[\"id\"], float):\n                raise InvalidRequestError(\"typedjsonrpc does not support float ids.\")\n            if not isinstance(msg[\"id\"], (six.string_types, six.integer_types)):\n                raise InvalidRequestError(\"id must be a string or integer; '{}' is of type {}.\"\n                                          .format(msg[\"id\"], type(msg[\"id\"])))\n        if msg[\"method\"] not in self._name_to_method_info:\n            raise MethodNotFoundError(\"Could not find method '{}'.\".format(msg[\"method\"]))", "label": 1}
{"code": "public String getArtifactLastVersion(final String gavc) {\n        final List<String> versions = getArtifactVersions(gavc);\n\n        final VersionsHandler versionHandler = new VersionsHandler(repositoryHandler);\n        final String viaCompare = versionHandler.getLastVersion(versions);\n\n        if (viaCompare != null) {\n            return viaCompare;\n        }\n\n        //\n        // These versions cannot be compared\n        // Let's use the Collection.max() method by default, so goingo for a fallback\n        // mechanism.\n        //\n        LOG.info(\"The versions cannot be compared\");\n        return Collections.max(versions);\n\n    }", "label": 0}
{"code": "def move_ipa\n      FileUtils.mv(PackageCommandGenerator.ipa_path, File.expand_path(Gym.config[:output_directory]), force: true)\n      ipa_path = File.expand_path(File.join(Gym.config[:output_directory], File.basename(PackageCommandGenerator.ipa_path)))\n\n      UI.success(\"Successfully exported and signed the ipa file:\")\n      UI.message(ipa_path)\n      ipa_path\n    end", "label": 4}
{"code": "func NewActionsParser(ctx RuleContext) (predicate.Parser, error) {\n\treturn predicate.NewParser(predicate.Def{\n\t\tOperators: predicate.Operators{},\n\t\tFunctions: map[string]interface{}{\n\t\t\t\"log\": NewLogActionFn(ctx),\n\t\t},\n\t\tGetIdentifier: ctx.GetIdentifier,\n\t\tGetProperty:   predicate.GetStringMapValue,\n\t})\n}", "label": 5}
{"code": "@Api\n\tpublic void setNamedRoles(Map<String, List<NamedRoleInfo>> namedRoles) {\n\t\tthis.namedRoles = namedRoles;\n\t\tldapRoleMapping = new HashMap<String, Set<String>>();\n\t\tfor (String roleName : namedRoles.keySet()) {\n\t\t\tif (!ldapRoleMapping.containsKey(roleName)) {\n\t\t\t\tldapRoleMapping.put(roleName, new HashSet<String>());\n\t\t\t}\n\t\t\tfor (NamedRoleInfo role : namedRoles.get(roleName)) {\n\t\t\t\tldapRoleMapping.get(roleName).add(role.getName());\n\t\t\t}\n\t\t}\n\t}", "label": 0}
{"code": "func (s *ServicesTestSuite) EventsClusterConfig(c *check.C) {\n\ttestCases := []eventTest{\n\t\t{\n\t\t\tname: \"Cluster config\",\n\t\t\tkind: services.WatchKind{\n\t\t\t\tKind: services.KindClusterConfig,\n\t\t\t},\n\t\t\tcrud: func() services.Resource {\n\t\t\t\tconfig, err := services.NewClusterConfig(services.ClusterConfigSpecV3{})\n\t\t\t\tc.Assert(err, check.IsNil)\n\n\t\t\t\terr = s.ConfigS.SetClusterConfig(config)\n\t\t\t\tc.Assert(err, check.IsNil)\n\n\t\t\t\tout, err := s.ConfigS.GetClusterConfig()\n\t\t\t\tc.Assert(err, check.IsNil)\n\n\t\t\t\terr = s.ConfigS.DeleteClusterConfig()\n\t\t\t\tc.Assert(err, check.IsNil)\n\n\t\t\t\treturn out\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Cluster name\",\n\t\t\tkind: services.WatchKind{\n\t\t\t\tKind: services.KindClusterName,\n\t\t\t},\n\t\t\tcrud: func() services.Resource {\n\t\t\t\tclusterName, err := services.NewClusterName(services.ClusterNameSpecV2{\n\t\t\t\t\tClusterName: \"example.com\",\n\t\t\t\t})\n\t\t\t\tc.Assert(err, check.IsNil)\n\n\t\t\t\terr = s.ConfigS.SetClusterName(clusterName)\n\t\t\t\tc.Assert(err, check.IsNil)\n\n\t\t\t\tout, err := s.ConfigS.GetClusterName()\n\t\t\t\tc.Assert(err, check.IsNil)\n\n\t\t\t\terr = s.ConfigS.DeleteClusterName()\n\t\t\t\tc.Assert(err, check.IsNil)\n\t\t\t\treturn out\n\t\t\t},\n\t\t},\n\t}\n\ts.runEventsTests(c, testCases)\n}", "label": 5}
{"code": "function coerceElementMatchingCallback(value) {\n  // Element Name\n  if (typeof value === 'string') {\n    return element => element.element === value;\n  }\n\n  // Element Type\n  if (value.constructor && value.extend) {\n    return element => element instanceof value;\n  }\n\n  return value;\n}", "label": 3}
{"code": "function isIterable (v) {\n  return type.call(v) == OBJECT || type.call(v) == ARRAY\n}", "label": 3}
{"code": "def execute_closing_transaction(statements: Iterable):\n    \"\"\"Open a connection, commit a transaction, and close it.\"\"\"\n\n    with closing(connect()) as conn:\n        with conn.cursor() as cursor:\n            for statement in statements:\n                cursor.execute(statement)", "label": 1}
{"code": "public static base_response rename(nitro_service client, responderpolicy resource, String new_name) throws Exception {\n\t\tresponderpolicy renameresource = new responderpolicy();\n\t\trenameresource.name = resource.name;\n\t\treturn renameresource.rename_resource(client,new_name);\n\t}", "label": 0}
{"code": "public function getPaginatorConfig($name)\n    {\n        static $defaults = [\n            'input_token'  => null,\n            'output_token' => null,\n            'limit_key'    => null,\n            'result_key'   => null,\n            'more_results' => null,\n        ];\n\n        if ($this->hasPaginator($name)) {\n            return $this->paginators[$name] + $defaults;\n        }\n\n        throw new \\UnexpectedValueException(\"There is no {$name} \"\n            . \"paginator defined for the {$this->serviceName} service.\");\n    }", "label": 2}
{"code": "public void forAllCollectionDefinitions(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (Iterator it = _curClassDef.getCollections(); it.hasNext(); )\r\n        {\r\n            _curCollectionDef = (CollectionDescriptorDef)it.next();\r\n            if (!isFeatureIgnored(LEVEL_COLLECTION) &&\r\n                !_curCollectionDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_IGNORE, false))\r\n            {\r\n                generate(template);\r\n            }\r\n        }\r\n        _curCollectionDef = null;\r\n    }", "label": 0}
{"code": "public static base_response expire(nitro_service client, cacheobject resource) throws Exception {\n\t\tcacheobject expireresource = new cacheobject();\n\t\texpireresource.locator = resource.locator;\n\t\texpireresource.url = resource.url;\n\t\texpireresource.host = resource.host;\n\t\texpireresource.port = resource.port;\n\t\texpireresource.groupname = resource.groupname;\n\t\texpireresource.httpmethod = resource.httpmethod;\n\t\treturn expireresource.perform_operation(client,\"expire\");\n\t}", "label": 0}
{"code": "def _get_qgen_var(self, generators, base_mva):\n        \"\"\" Returns the generator reactive power variable set.\n        \"\"\"\n        Qg = array([g.q / base_mva for g in generators])\n\n        Qmin = array([g.q_min / base_mva for g in generators])\n        Qmax = array([g.q_max / base_mva for g in generators])\n\n        return Variable(\"Qg\", len(generators), Qg, Qmin, Qmax)", "label": 1}
{"code": "public Automaton getAutomatonById(String id) throws IOException {\n    if (idToVersion.containsKey(id)) {\n      List<BytesRef> bytesArray = new ArrayList<>();\n      Set<String> data = get(id);\n      if (data != null) {\n        Term term;\n        for (String item : data) {\n          term = new Term(\"dummy\", item);\n          bytesArray.add(term.bytes());\n        }\n        Collections.sort(bytesArray);\n        return Automata.makeStringUnion(bytesArray);\n      }\n    }\n    return null;\n  }", "label": 0}
{"code": "protected function createMsgId()\n    {\n        $msg = hex2bin($this->messageId);\n        $chars = str_split($msg);\n        $chars_val = array_map('ord', $chars);\n        $pos = count($chars_val) - 1;\n        while (true) {\n            if ($chars_val[$pos] < 255) {\n                $chars_val[$pos]++;\n                break;\n            } else {\n                $chars_val[$pos] = 0;\n                $pos--;\n            }\n        }\n        $chars = array_map('chr', $chars_val);\n        $msg = bin2hex(implode($chars));\n        $this->messageId = $msg;\n\n        return $this->messageId;\n    }", "label": 2}
{"code": "public function gatherRouteMiddlewares($route)\n    {\n        if (method_exists($this->router, 'gatherRouteMiddleware')) {\n            return $this->router->gatherRouteMiddleware($route);\n        }\n\n        return $this->router->gatherRouteMiddlewares($route);\n    }", "label": 2}
{"code": "public static base_response convert(nitro_service client, sslpkcs12 resource) throws Exception {\n\t\tsslpkcs12 convertresource = new sslpkcs12();\n\t\tconvertresource.outfile = resource.outfile;\n\t\tconvertresource.Import = resource.Import;\n\t\tconvertresource.pkcs12file = resource.pkcs12file;\n\t\tconvertresource.des = resource.des;\n\t\tconvertresource.des3 = resource.des3;\n\t\tconvertresource.export = resource.export;\n\t\tconvertresource.certfile = resource.certfile;\n\t\tconvertresource.keyfile = resource.keyfile;\n\t\tconvertresource.password = resource.password;\n\t\tconvertresource.pempassphrase = resource.pempassphrase;\n\t\treturn convertresource.perform_operation(client,\"convert\");\n\t}", "label": 0}
{"code": "def find_remote_by_client_id(client_id):\n    \"\"\"Return a remote application based with given client ID.\"\"\"\n    for remote in current_oauthclient.oauth.remote_apps.values():\n        if remote.name == 'cern' and remote.consumer_key == client_id:\n            return remote", "label": 1}
{"code": "function fireOnce(fn) {\n  var fired = false;\n  return function wrapped() {\n    if (!fired) {\n      fired = true;\n      fn.apply(null, arguments);\n    }\n  };\n}", "label": 3}
{"code": "def all_field_factories\n      all_field_factories = []\n      all_field_factories.concat(field_factories).concat(text_field_factories).concat(dynamic_field_factories)\n      all_field_factories\n    end", "label": 4}
{"code": "def matching_lines(re)\n      @lines.each_with_index.select{|text, linenum| re.match(text)}.map{\n        |i| i[1]+1}\n    end", "label": 4}
{"code": "def convert_using_api(from_currency, to_currency):\n\t\"\"\" convert from from_currency to to_currency by requesting API \"\"\"\n\tconvert_str = from_currency + '_' + to_currency\n\toptions = {'compact': 'ultra', 'q': convert_str}\n\tapi_url = 'https://free.currencyconverterapi.com/api/v5/convert'\n\tresult = requests.get(api_url, params=options).json()\n\treturn result[convert_str]", "label": 1}
{"code": "def inline_node_content(node)\n      inline_content = node.script\n\n      if contains_interpolation?(inline_content)\n        strip_surrounding_quotes(inline_content)\n      else\n        inline_content\n      end\n    end", "label": 4}
{"code": "function getDeclarationName(node) {\n            if (node.name) {\n                if (ts.isAmbientModule(node)) {\n                    return ts.isGlobalScopeAugmentation(node) ? \"__global\" : \"\\\"\" + node.name.text + \"\\\"\";\n                }\n                if (node.name.kind === 140 /* ComputedPropertyName */) {\n                    var nameExpression = node.name.expression;\n                    // treat computed property names where expression is string/numeric literal as just string/numeric literal\n                    if (ts.isStringOrNumericLiteral(nameExpression.kind)) {\n                        return nameExpression.text;\n                    }\n                    ts.Debug.assert(ts.isWellKnownSymbolSyntactically(nameExpression));\n                    return ts.getPropertyNameForKnownSymbolName(nameExpression.name.text);\n                }\n                return node.name.text;\n            }\n            switch (node.kind) {\n                case 148 /* Constructor */:\n                    return \"__constructor\";\n                case 156 /* FunctionType */:\n                case 151 /* CallSignature */:\n                    return \"__call\";\n                case 157 /* ConstructorType */:\n                case 152 /* ConstructSignature */:\n                    return \"__new\";\n                case 153 /* IndexSignature */:\n                    return \"__index\";\n                case 236 /* ExportDeclaration */:\n                    return \"__export\";\n                case 235 /* ExportAssignment */:\n                    return node.isExportEquals ? \"export=\" : \"default\";\n                case 187 /* BinaryExpression */:\n                    switch (ts.getSpecialPropertyAssignmentKind(node)) {\n                        case 2 /* ModuleExports */:\n                            // module.exports = ...\n                            return \"export=\";\n                        case 1 /* ExportsProperty */:\n                        case 4 /* ThisProperty */:\n                            // exports.x = ... or this.y = ...\n                            return node.left.name.text;\n                        case 3 /* PrototypeProperty */:\n                            // className.prototype.methodName = ...\n                            return node.left.expression.name.text;\n                    }\n                    ts.Debug.fail(\"Unknown binary declaration kind\");\n                    break;\n                case 220 /* FunctionDeclaration */:\n                case 221 /* ClassDeclaration */:\n                    return node.flags & 512 /* Default */ ? \"default\" : undefined;\n                case 269 /* JSDocFunctionType */:\n                    return ts.isJSDocConstructSignature(node) ? \"__new\" : \"__call\";\n                case 142 /* Parameter */:\n                    // Parameters with names are handled at the top of this function.  Parameters\n                    // without names can only come from JSDocFunctionTypes.\n                    ts.Debug.assert(node.parent.kind === 269 /* JSDocFunctionType */);\n                    var functionType = node.parent;\n                    var index = ts.indexOf(functionType.parameters, node);\n                    return \"p\" + index;\n                case 279 /* JSDocTypedefTag */:\n                    var parentNode = node.parent && node.parent.parent;\n                    var nameFromParentNode = void 0;\n                    if (parentNode && parentNode.kind === 200 /* VariableStatement */) {\n                        if (parentNode.declarationList.declarations.length > 0) {\n                            var nameIdentifier = parentNode.declarationList.declarations[0].name;\n                            if (nameIdentifier.kind === 69 /* Identifier */) {\n                                nameFromParentNode = nameIdentifier.text;\n                            }\n                        }\n                    }\n                    return nameFromParentNode;\n            }\n        }", "label": 3}
{"code": "func (s *Server) IsDiagnosticEnabled() bool {\n\ts.Lock()\n\tdefer s.Unlock()\n\treturn s.enable == 1\n}", "label": 5}
{"code": "protected function splitshInstall(OutputInterface $output, RunShell $shell, $execDir, $binaryPath)\n    {\n        if ($binaryPath) {\n            $output->writeln('<comment>[info]</comment> Using User-Provided Splitsh binary.');\n            return $binaryPath;\n        }\n\n        $output->writeln('<comment>[info]</comment> Compiling Splitsh');\n        $this->writeDiv($output);\n\n        $install = new SplitInstall($shell, $execDir);\n\n        $res = $install->installFromSource($this->rootPath);\n\n        $output->writeln(sprintf(\n            '<comment>[info]</comment> Splitsh Installer says <info>%s</info>',\n            $res[0]\n        ));\n\n        return $res[1];\n    }", "label": 2}
{"code": "function CompoundDuplex(writable, readable, options) {\n\tvar self = this;\n\tvar convertToZStream = require('../index');\t// for circular dependencies\n\n\tif(!readable || typeof readable.read !== 'function') {\n\t\toptions = readable;\n\t\treadable = writable;\n\t\twritable = null;\n\t}\n\n\tif(writable && !writable._isZStream) {\n\t\twritable = convertToZStream(writable);\n\t}\n\tif(!readable._isZStream) {\n\t\treadable = convertToZStream(readable);\n\t}\n\n\tif(!writable) {\n\t\tif(typeof readable.getStreamChain !== 'function') {\n\t\t\tthrow new Error('Can only use shorthand CompoundDuplex constructor if pipeline is all zstreams');\n\t\t}\n\t\twritable = readable.getStreamChain().getStreams()[0];\n\t}\n\n\tif(!options) options = {};\n\n\toptions.readableObjectMode = readable.isReadableObjectMode();\n\toptions.writableObjectMode = writable.isWritableObjectMode();\n\tDuplex.call(this, options);\n\n\tthis._compoundReadable = readable;\n\tthis._compoundWritable = writable;\n\n\tthis._waitingForReadableData = false;\n\n\twritable.on('chainerror', function(error) {\n\t\t// Forward the error on; if the chain is to be destructed, the compound stream's _abortStream() method will be called\n\t\tthis.ignoreError();\n\t\tself.emit('error', error);\n\t});\n\n\treadable.on('readable', function() {\n\t\tif(self._waitingForReadableData) {\n\t\t\tself._waitingForReadableData = false;\n\t\t\tself._readSomeData();\n\t\t}\n\t});\n\n\treadable.on('end', function() {\n\t\tself.push(null);\n\t});\n}", "label": 3}
{"code": "function _GpfDate() {\n        var firstArgument = arguments[_GPF_START], values = _gpfIsISO8601String(firstArgument);\n        if (values) {\n            return new _GpfGenuineDate(_GpfGenuineDate.UTC.apply(_GpfGenuineDate.UTC, values));\n        }\n        return _gpfNewApply(_GpfGenuineDate, arguments);\n    }", "label": 3}
{"code": "public function sort()\n    {\n        foreach ($this->nodeList as $vertex) {\n            if ($vertex->state !== self::NOT_VISITED) {\n                continue;\n            }\n\n            $this->visit($vertex);\n        }\n\n        $sortedList = $this->sortedNodeList;\n\n        $this->nodeList       = [];\n        $this->sortedNodeList = [];\n\n        return array_reverse($sortedList);\n    }", "label": 2}
{"code": "function evalBlacklist(notification) {\n        return new Promise((resolve, reject) => {\n            const ignoreCategories = forum.config.core.ignoreCategories || [];\n\n            //if there's no blacklist, we can ignore the hit for getting the category\n            if (ignoreCategories.length) {\n                if (ignoreCategories.some((elem) => elem.toString() === notification.categoryId.toString())) {\n                    forum.emit('log', `Notification from category ${notification.categoryId} ignored`);\n                    return reject('Ignoring notification');\n                }\n            }\n            return resolve(notification);\n        });\n    }", "label": 3}
{"code": "def gunzip(input_gzip_file, block_size=1024):\n    \"\"\"\n    Gunzips the input file to the same directory\n\n    :param input_gzip_file: File to be gunzipped\n    :return: path to the gunzipped file\n    :rtype: str\n    \"\"\"\n    assert os.path.splitext(input_gzip_file)[1] == '.gz'\n    assert is_gzipfile(input_gzip_file)\n    with gzip.open(input_gzip_file) as infile:\n        with open(os.path.splitext(input_gzip_file)[0], 'w') as outfile:\n            while True:\n                block = infile.read(block_size)\n                if block == '':\n                    break\n                else:\n                    outfile.write(block)\n    return outfile.name", "label": 1}
{"code": "public AssemblyResponse cancelAssembly(String url)\n            throws RequestException, LocalOperationException {\n        Request request = new Request(this);\n        return new AssemblyResponse(request.delete(url, new HashMap<String, Object>()));\n    }", "label": 0}
{"code": "def move_to(x_coord, y_coord)\n      Selenium::WebDriver::Point.new(Integer(x_coord), Integer(y_coord)).tap do |point|\n        use { @driver.manage.window.position = point }\n      end\n    end", "label": 4}
{"code": "def _route(self, attr, args, kwargs, **fkwargs):\n        \"\"\"\n        Perform routing and return db_nums\n        \"\"\"\n        return self.cluster.hosts.keys()", "label": 1}
{"code": "public function addTimeEvent(TimeEvent $event)\n    {\n        if (!$this->timeEvents) {\n            $this->timeEvents = [];\n        }\n        $this->timeEvents[] = $event;\n    }", "label": 2}
{"code": "def upload(*args)\n      arguments(args, required: [:owner, :repo, :id, :filepath]) do\n        permit VALID_ASSET_PARAM_NAMES\n      end\n      params = arguments.params\n\n      unless type = params['content_type']\n        type = infer_media(arguments.filepath)\n      end\n\n      file = Faraday::UploadIO.new(arguments.filepath, type)\n      options = {\n        headers: { content_type: type },\n        endpoint: upload_endpoint,\n        query: {'name' => params['name']}\n      }\n      params['data']    = file.read\n      params['options'] = options\n\n      post_request(\"/repos/#{arguments.owner}/#{arguments.repo}/releases/#{arguments.id}/assets\", params)\n    ensure\n      file.close if file\n    end", "label": 4}
{"code": "public function executeScript($script, array $arguments = [])\n    {\n        $params = [\n            'script' => $script,\n            'args' => $this->prepareScriptArguments($arguments),\n        ];\n\n        return $this->execute(DriverCommand::EXECUTE_SCRIPT, $params);\n    }", "label": 2}
{"code": "func (p *PTYReqParams) Check() error {\n\tif p.W > maxSize || p.W < minSize {\n\t\treturn trace.BadParameter(\"bad width: %v\", p.W)\n\t}\n\tif p.H > maxSize || p.H < minSize {\n\t\treturn trace.BadParameter(\"bad height: %v\", p.H)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function(element, event, callback, capturePhase) {\n    if (!element.id) element.id = $.uuid()\n    if (!ChuiEventCache.elements[element.id]) {\n      ChuiEventCache.elements[element.id] = []\n    }\n    ChuiEventCache.elements[element.id].push({\n      event: event,\n      callback: callback\n    })\n    element.addEventListener(event, callback, capturePhase)\n  }", "label": 3}
{"code": "def service_state(service_name)\n      state = nil\n      open_service(service_name, SC_MANAGER_CONNECT, SERVICE_QUERY_STATUS) do |service|\n        query_status(service) do |status|\n          state = SERVICE_STATES[status[:dwCurrentState]]\n        end\n      end\n      if state.nil?\n        raise Puppet::Error.new(_(\"Unknown Service state '%{current_state}' for '%{service_name}'\") % { current_state: state.to_s, service_name: service_name})\n      end\n      state\n    end", "label": 4}
{"code": "def detect!\n      guest_name = @machine.config.vm.guest\n      initialize_capabilities!(guest_name, @guests, @capabilities, @machine)\n    rescue Errors::CapabilityHostExplicitNotDetected => e\n      raise Errors::GuestExplicitNotDetected, value: e.extra_data[:value]\n    rescue Errors::CapabilityHostNotDetected\n      raise Errors::GuestNotDetected\n    end", "label": 4}
{"code": "def _wait_for_token(self, ctx, wait_token_url):\n        ''' Returns a token from a the wait token URL\n        @param wait_token_url URL to wait for (string)\n        :return DischargeToken\n        '''\n        resp = requests.get(wait_token_url)\n        if resp.status_code != 200:\n            raise InteractionError('cannot get {}'.format(wait_token_url))\n        json_resp = resp.json()\n        kind = json_resp.get('kind')\n        if kind is None:\n            raise InteractionError(\n                'cannot get kind token from {}'.format(wait_token_url))\n        token_val = json_resp.get('token')\n        if token_val is None:\n            token_val = json_resp.get('token64')\n            if token_val is None:\n                raise InteractionError(\n                    'cannot get token from {}'.format(wait_token_url))\n            token_val = base64.b64decode(token_val)\n        return DischargeToken(kind=kind, value=token_val)", "label": 1}
{"code": "func (l *httpFileSystem) OpenFile(filePath string) (io.ReadCloser, error) {\n\tif l.reader == nil {\n\t\treturn nil, trace.BadParameter(\"missing reader\")\n\t}\n\n\treturn l.reader, nil\n}", "label": 5}
{"code": "public void classifyAndWriteViterbiSearchGraph(String testFile, String searchGraphPrefix, DocumentReaderAndWriter<IN> readerAndWriter) throws IOException {\r\n    Timing timer = new Timing();\r\n    ObjectBank<List<IN>> documents =\r\n      makeObjectBankFromFile(testFile, readerAndWriter);\r\n    int numWords = 0;\r\n    int numSentences = 0;\r\n\r\n    for (List<IN> doc : documents) {\r\n      DFSA<String, Integer> tagLattice = getViterbiSearchGraph(doc, AnswerAnnotation.class);\r\n      numWords += doc.size();\r\n      PrintWriter latticeWriter = new PrintWriter(new FileOutputStream(searchGraphPrefix + '.' + numSentences\r\n          + \".wlattice\"));\r\n      PrintWriter vsgWriter = new PrintWriter(new FileOutputStream(searchGraphPrefix + '.' + numSentences + \".lattice\"));\r\n      if (readerAndWriter instanceof LatticeWriter)\r\n        ((LatticeWriter) readerAndWriter).printLattice(tagLattice, doc, latticeWriter);\r\n      tagLattice.printAttFsmFormat(vsgWriter);\r\n      latticeWriter.close();\r\n      vsgWriter.close();\r\n      numSentences++;\r\n    }\r\n\r\n    long millis = timer.stop();\r\n    double wordspersec = numWords / (((double) millis) / 1000);\r\n    NumberFormat nf = new DecimalFormat(\"0.00\"); // easier way!\r\n    System.err.println(this.getClass().getName() + \" tagged \" + numWords + \" words in \" + numSentences\r\n        + \" documents at \" + nf.format(wordspersec) + \" words per second.\");\r\n  }", "label": 0}
{"code": "public static base_response update(nitro_service client, systemuser resource) throws Exception {\n\t\tsystemuser updateresource = new systemuser();\n\t\tupdateresource.username = resource.username;\n\t\tupdateresource.password = resource.password;\n\t\tupdateresource.externalauth = resource.externalauth;\n\t\tupdateresource.promptstring = resource.promptstring;\n\t\tupdateresource.timeout = resource.timeout;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def render_open_search(tags)\n      open_search = meta_tags.extract(:open_search)\n      return unless open_search\n\n      href = open_search[:href]\n      title = open_search[:title]\n\n      type = \"application/opensearchdescription+xml\"\n      tags << Tag.new(:link, rel: 'search', type: type, href: href, title: title) if href.present?\n    end", "label": 4}
{"code": "def path(name, *args)\n      Utils::Escape::SafeString.new(@routes.path(name, *args))\n    end", "label": 4}
{"code": "function getUserGroups(user) {\n  try {\n    const output = runProgram('groups', [user]).trim();\n    const groupsText = isBusyboxCommand('groups') ? output : output.split(':')[1].trim();\n    return groupsText.split(/\\s+/);\n  } catch (e) {\n    throw new Error(`Cannot resolve user ${user}`);\n  }\n}", "label": 3}
{"code": "def annotate_exception(exc, options = {})\n      notes = (exc.instance_variable_defined?(:@__raven_context) && exc.instance_variable_get(:@__raven_context)) || {}\n      Raven::Utils::DeepMergeHash.deep_merge!(notes, options)\n      exc.instance_variable_set(:@__raven_context, notes)\n      exc\n    end", "label": 4}
{"code": "def expand_actions(self, actions):\n        \"\"\"\n        Accepts an array of actions and returns an array of actions which match\n        \"\"\"\n        r = []\n        for action in actions:\n            r.append(action)\n            if action in self.aliased_actions:\n                r.extend(self.aliased_actions[action])\n        return r", "label": 1}
{"code": "function(module, memory) {\n  // @str\n  module.str = function(address) {\n    let view = memory.F32.subarray(address >> 2, (address >> 2) + 16);\n    let out = \"\";\n    for (let ii = 0; ii < 16; ++ii) {\n      if (ii + 1 < 16) out += view[ii] + \", \";\n      else out += view[ii];\n    }\n    return \"mat4(\" + out + \")\";\n  };\n  // @view\n  module.view = function(address) {\n    let view = memory.F32.subarray(address >> 2, (address >> 2) + 16);\n    //view.address = address;\n    return view;\n  };\n  // @exactEquals\n  let _exactEquals = module.exactEquals;\n  module.exactEquals = function(a, b) {\n    return !!_exactEquals(a, b);\n  };\n  // @equals\n  let _equals = module.equals;\n  module.equals = function(a, b) {\n    return !!_equals(a, b);\n  };\n}", "label": 3}
{"code": "def working_on(job)\n      data = encode \\\n        :queue   => job.queue,\n        :run_at  => Time.now.utc.iso8601,\n        :payload => job.payload\n      data_store.set_worker_payload(self,data)\n    end", "label": 4}
{"code": "function(i, delaySort)\n  {\n    var removing;\n\n    if (i >= 0 && i < this.length)\n    {\n      removing = this[ i ];\n\n      AP.splice.call( this, i, 1 );\n      this.trigger( Collection.Events.Remove, [this, removing, i] );\n\n      if ( !delaySort )\n      {\n        this.sort( undefined, undefined, true );\n      }\n    }\n\n    return removing;\n  }", "label": 3}
{"code": "def convert_options(opts)\n      converted = {}\n\n      opts.each_pair do |name, value|\n        if /_/ =~ name\n          name = name.to_s.gsub(/_\\w/) { |i| i.delete(\"_\").upcase }.to_sym\n        end\n        value = convert_options(value) if value.is_a? Hash\n        converted[name] = value\n      end\n\n      converted\n    end", "label": 4}
{"code": "def serialisasi(self):\n        \"\"\"Mengembalikan hasil serialisasi objek Entri ini.\n\n        :returns: Dictionary hasil serialisasi\n        :rtype: dict\n        \"\"\"\n\n        return {\n            \"nama\": self.nama,\n            \"nomor\": self.nomor,\n            \"kata_dasar\": self.kata_dasar,\n            \"pelafalan\": self.pelafalan,\n            \"bentuk_tidak_baku\": self.bentuk_tidak_baku,\n            \"varian\": self.varian,\n            \"makna\": [makna.serialisasi() for makna in self.makna]\n        }", "label": 1}
{"code": "def benchmark(method, *args)\n      start = Time.now\n      result = yield\n      Dynamoid.logger.debug \"(#{((Time.now - start) * 1000.0).round(2)} ms) #{method.to_s.split('_').collect(&:upcase).join(' ')}#{\" - #{args.inspect}\" unless args.nil? || args.empty?}\"\n      result\n    end", "label": 4}
{"code": "def align_dna(job, fastqs, sample_type, univ_options, bwa_options):\n    \"\"\"\n    A wrapper for the entire dna alignment subgraph.\n\n    :param list fastqs: The input fastqs for alignment\n    :param str sample_type: Description of the sample to inject into the filename\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict bwa_options: Options specific to bwa\n    :return: Dict containing output bam and bai\n             output_files:\n                 |- '<sample_type>_fix_pg_sorted.bam': fsID\n                 +- '<sample_type>_fix_pg_sorted.bam.bai': fsID\n    :rtype: dict\n    \"\"\"\n    # The mkdup and regroup steps use picard that allots heap space using the Xmx key in the\n    # univ_options dictionary. This should reflect in the job allotment. Since We want all these\n    # jobs to occur on the same node, we ened to give them all the same memory requirements.\n\n    bwa = job.wrapJobFn(run_bwa, fastqs, sample_type, univ_options, bwa_options,\n                        disk=PromisedRequirement(bwa_disk, fastqs, bwa_options['index']),\n                        memory=univ_options['java_Xmx'],\n                        cores=bwa_options['n'])\n    sam2bam = job.wrapJobFn(bam_conversion, bwa.rv(), sample_type, univ_options,\n                            bwa_options['samtools'],\n                            disk=PromisedRequirement(sam2bam_disk, bwa.rv()),\n                            memory=univ_options['java_Xmx'])\n    # reheader takes the same disk as sam2bam so we can serialize this on the same worker.\n    reheader = job.wrapJobFn(fix_bam_header, sam2bam.rv(), sample_type, univ_options,\n                             bwa_options['samtools'],\n                             disk=PromisedRequirement(sam2bam_disk, bwa.rv()),\n                             memory=univ_options['java_Xmx'])\n    regroup = job.wrapJobFn(add_readgroups, reheader.rv(), sample_type, univ_options,\n                            bwa_options['picard'],\n                            disk=PromisedRequirement(regroup_disk, reheader.rv()),\n                            memory=univ_options['java_Xmx'])\n    mkdup = job.wrapJobFn(mark_duplicates, regroup.rv(), sample_type, univ_options,\n                          bwa_options['picard'],\n                          disk=PromisedRequirement(mkdup_disk, regroup.rv()),\n                          memory=univ_options['java_Xmx'])\n    index = job.wrapJobFn(index_bamfile, mkdup.rv(), sample_type, univ_options,\n                          bwa_options['samtools'], sample_info='fix_pg_sorted',\n                          disk=PromisedRequirement(index_disk, mkdup.rv()),\n                          memory=univ_options['java_Xmx'])\n    job.addChild(bwa)\n    bwa.addChild(sam2bam)\n    sam2bam.addChild(reheader)\n    reheader.addChild(regroup)\n    regroup.addChild(mkdup)\n    mkdup.addChild(index)\n    return index.rv()", "label": 1}
{"code": "private function deleteJoinedEntityCollection(PersistentCollection $collection)\n    {\n        $association     = $collection->getMapping();\n        $targetClass     = $this->em->getClassMetadata($association->getTargetEntity());\n        $rootClass       = $this->em->getClassMetadata($targetClass->getRootClassName());\n        $sourcePersister = $this->uow->getEntityPersister($association->getSourceEntity());\n\n        // 1) Build temporary table DDL\n        $tempTable         = $this->platform->getTemporaryTableName($rootClass->getTemporaryIdTableName());\n        $idColumns         = $rootClass->getIdentifierColumns($this->em);\n        $idColumnNameList  = implode(', ', array_keys($idColumns));\n        $columnDefinitions = [];\n\n        foreach ($idColumns as $columnName => $column) {\n            $type = $column->getType();\n\n            $columnDefinitions[$columnName] = [\n                'notnull' => true,\n                'type'    => $type,\n            ];\n        }\n\n        $statement = $this->platform->getCreateTemporaryTableSnippetSQL() . ' ' . $tempTable\n            . ' (' . $this->platform->getColumnDeclarationListSQL($columnDefinitions) . ')';\n\n        $this->conn->executeUpdate($statement);\n\n        // 2) Build insert table records into temporary table\n        $dql   = ' SELECT t0.' . implode(', t0.', $rootClass->getIdentifierFieldNames())\n               . ' FROM ' . $targetClass->getClassName() . ' t0 WHERE t0.' . $association->getMappedBy() . ' = :owner';\n        $query = $this->em->createQuery($dql)->setParameter('owner', $collection->getOwner());\n\n        $statement  = 'INSERT INTO ' . $tempTable . ' (' . $idColumnNameList . ') ' . $query->getSQL();\n        $parameters = array_values($sourcePersister->getIdentifier($collection->getOwner()));\n        $numDeleted = $this->conn->executeUpdate($statement, $parameters);\n\n        // 3) Create statement used in DELETE ... WHERE ... IN (subselect)\n        $deleteSQLTemplate = sprintf(\n            'DELETE FROM %%s WHERE (%s) IN (SELECT %s FROM %s)',\n            $idColumnNameList,\n            $idColumnNameList,\n            $tempTable\n        );\n\n        // 4) Delete records on each table in the hierarchy\n        $hierarchyClasses = array_merge(\n            array_map(\n                function ($className) {\n                    return $this->em->getClassMetadata($className);\n                },\n                array_reverse($targetClass->getSubClasses())\n            ),\n            [$targetClass],\n            $targetClass->getAncestorsIterator()->getArrayCopy()\n        );\n\n        foreach ($hierarchyClasses as $class) {\n            $statement = sprintf($deleteSQLTemplate, $class->table->getQuotedQualifiedName($this->platform));\n\n            $this->conn->executeUpdate($statement);\n        }\n\n        // 5) Drop temporary table\n        $statement = $this->platform->getDropTemporaryTableSQL($tempTable);\n\n        $this->conn->executeUpdate($statement);\n\n        return $numDeleted;\n    }", "label": 2}
{"code": "public void actionPerformed(java.awt.event.ActionEvent actionEvent)\r\n    {\r\n        new Thread()\r\n        {\r\n            public void run()\r\n            {\r\n                final java.sql.Connection conn = new JDlgDBConnection(containingFrame, false).showAndReturnConnection();\r\n                if (conn != null)\r\n                {\r\n                    javax.swing.SwingUtilities.invokeLater(new Runnable()\r\n                    {\r\n                        public void run()\r\n                        {\r\n                            JIFrmDatabase frm = new JIFrmDatabase(conn);\r\n                            containingFrame.getContentPane().add(frm);\r\n                            frm.setVisible(true);\r\n                        }\r\n                    });\r\n                }\r\n            }\r\n        }.start();\r\n    }", "label": 0}
{"code": "func (c *Client) checkProtoVersion(protoVersion string) (int, PluginSet, error) {\n\tserverVersion, err := strconv.Atoi(protoVersion)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"Error parsing protocol version %q: %s\", protoVersion, err)\n\t}\n\n\t// record these for the error message\n\tvar clientVersions []int\n\n\t// all versions, including the legacy ProtocolVersion have been added to\n\t// the versions set\n\tfor version, plugins := range c.config.VersionedPlugins {\n\t\tclientVersions = append(clientVersions, version)\n\n\t\tif serverVersion != version {\n\t\t\tcontinue\n\t\t}\n\t\treturn version, plugins, nil\n\t}\n\n\treturn 0, nil, fmt.Errorf(\"Incompatible API version with plugin. \"+\n\t\t\"Plugin version: %d, Client versions: %d\", serverVersion, clientVersions)\n}", "label": 5}
{"code": "public LuaScript endScript(LuaScriptConfig config) {\n        if (!endsWithReturnStatement()) {\n            add(new LuaAstReturnStatement());\n        }\n        String scriptText = buildScriptText();\n        return new BasicLuaScript(scriptText, config);\n    }", "label": 0}
{"code": "function echoWarningsAndErrors(antWarnings, antErrors){\r\n\t\r\n\t//Define the echo task to use for warnings and errors\r\n\tvar echo = project.createTask(\"echo\");\r\n\tvar error = new org.apache.tools.ant.taskdefs.Echo.EchoLevel();\r\n\terror.setValue(\"error\");\r\n\techo.setLevel(error);\r\n\r\n\t//Display all the detected warnings\r\n\tfor(var i = 0; i < antWarnings.length; i++){\r\n\r\n\t\techo.setMessage(\"WARNING: \" + antWarnings[i]);\r\n\t\techo.perform();\r\n\t}\r\n\r\n\t//Display all the detected errors\r\n\tfor(i = 0; i < antErrors.length; i++){\r\n\r\n\t\techo.setMessage(\"ERROR: \" + antErrors[i]);\r\n\t\techo.perform();\r\n\t}\r\n\r\n\t//Set a failure to the ant build if errors are present\r\n\tif(antErrors.length > 0){\r\n\r\n\t\tproject.setProperty(\"javascript.fail.message\", \"Source analisis detected errors.\");\r\n\t}\r\n}", "label": 3}
{"code": "function handleVote(link) {\n    if (!opts.voting) {\n      showError(\"You'll need to login to vote.\");\n      return;\n    }\n\n    var id = link.attr('id');\n    if (!id) {\n      // Didn't click on one of the voting arrows.\n      return;\n    }\n    // If it is an unvote, the new vote value is 0,\n    // Otherwise it's 1 for an upvote, or -1 for a downvote.\n    var value = 0;\n    if (id.charAt(1) != 'u') {\n      value = id.charAt(0) == 'u' ? 1 : -1;\n    }\n    // The data to be sent to the server.\n    var d = {\n      comment_id: id.substring(2),\n      value: value\n    };\n\n    // Swap the vote and unvote links.\n    link.hide();\n    $('#' + id.charAt(0) + (id.charAt(1) == 'u' ? 'v' : 'u') + d.comment_id)\n      .show();\n\n    // The div the comment is displayed in.\n    var div = $('div#cd' + d.comment_id);\n    var data = div.data('comment');\n\n    // If this is not an unvote, and the other vote arrow has\n    // already been pressed, unpress it.\n    if ((d.value !== 0) && (data.vote === d.value * -1)) {\n      $('#' + (d.value == 1 ? 'd' : 'u') + 'u' + d.comment_id).hide();\n      $('#' + (d.value == 1 ? 'd' : 'u') + 'v' + d.comment_id).show();\n    }\n\n    // Update the comments rating in the local data.\n    data.rating += (data.vote === 0) ? d.value : (d.value - data.vote);\n    data.vote = d.value;\n    div.data('comment', data);\n\n    // Change the rating text.\n    div.find('.rating:first')\n      .text(data.rating + ' point' + (data.rating == 1 ? '' : 's'));\n\n    // Send the vote information to the server.\n    $.ajax({\n      type: \"POST\",\n      url: opts.processVoteURL,\n      data: d,\n      error: function(request, textStatus, error) {\n        showError('Oops, there was a problem casting that vote.');\n      }\n    });\n  }", "label": 3}
{"code": "func (flag *ClientFlag) WithCancel(ctx context.Context, f func(context.Context) error) error {\n\tsig := make(chan os.Signal, 1)\n\tsignal.Notify(sig, syscall.SIGINT)\n\n\twctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tdone := make(chan bool)\n\tvar werr error\n\n\tgo func() {\n\t\tdefer close(done)\n\t\twerr = f(wctx)\n\t}()\n\n\tselect {\n\tcase <-sig:\n\t\tcancel()\n\t\t<-done // Wait for f() to complete\n\tcase <-done:\n\t}\n\n\treturn werr\n}", "label": 5}
{"code": "def get_command(self, ctx, cmd_name):\n        \"\"\" Allow for partial commands. \"\"\"\n        rv = click.Group.get_command(self, ctx, cmd_name)\n        if rv is not None:\n            return rv\n        matches = [x for x in self.list_commands(ctx)\n                   if x.startswith(cmd_name)]\n        if not matches:\n            return None\n        elif len(matches) == 1:\n            return click.Group.get_command(self, ctx, matches[0])\n        ctx.fail('Command ambiguous, could be: %s' %\n                 ', '.join(sorted(matches)))", "label": 1}
{"code": "function reposition(marker) {\n        // remember the tile coordinate so we don't have to reproject every time\n        if (!marker.coord) marker.coord = m.map.locationCoordinate(marker.location);\n        var pos = m.map.coordinatePoint(marker.coord);\n        var pos_loc, new_pos;\n\n        // If this point has wound around the world, adjust its position\n        // to the new, onscreen location\n        if (pos.x < 0) {\n            pos_loc = new MM.Location(marker.location.lat, marker.location.lon);\n            pos_loc.lon += Math.ceil((left.lon - marker.location.lon) / 360) * 360;\n            new_pos = m.map.locationPoint(pos_loc);\n            if (new_pos.x < m.map.dimensions.x) {\n                pos = new_pos;\n                marker.coord = m.map.locationCoordinate(pos_loc);\n            }\n        } else if (pos.x > m.map.dimensions.x) {\n            pos_loc = new MM.Location(marker.location.lat, marker.location.lon);\n            pos_loc.lon -= Math.ceil((marker.location.lon - right.lon) / 360) * 360;\n            new_pos = m.map.locationPoint(pos_loc);\n            if (new_pos.x > 0) {\n                pos = new_pos;\n                marker.coord = m.map.locationCoordinate(pos_loc);\n            }\n        }\n\n        pos.scale = 1;\n        pos.width = pos.height = 0;\n        MM.moveElement(marker.element, pos);\n    }", "label": 3}
{"code": "func deduplicateMPs(mounts []schema.Mount) []schema.Mount {\n\tvar res []schema.Mount\n\tseen := make(map[string]struct{})\n\tfor _, m := range mounts {\n\t\tcleanPath := path.Clean(m.Path)\n\t\tif _, ok := seen[cleanPath]; !ok {\n\t\t\tres = append(res, m)\n\t\t\tseen[cleanPath] = struct{}{}\n\t\t}\n\t}\n\treturn res\n}", "label": 5}
{"code": "function getCurrentValue(stream, key) {\n\tif (stream._currentEvent && stream._currentEvent.type === key) {\n\t\treturn stream._currentEvent.value;\n\t} else {\n\t\tvar names = keyNames[key];\n\t\tif (!names) {\n\t\t\treturn stream[key];\n\t\t}\n\t\tvar VALUE,\n\t\t\tvalueHandler = function(value) {\n\t\t\t\tVALUE = value;\n\t\t\t};\n\t\tstream[names.on](valueHandler);\n\t\tstream[names.off](valueHandler);\n\t\treturn VALUE;\n\t}\n}", "label": 3}
{"code": "public static base_response delete(nitro_service client, String acl6name) throws Exception {\n\t\tnsacl6 deleteresource = new nsacl6();\n\t\tdeleteresource.acl6name = acl6name;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "function normalizePathParts(parts) {\n\n        // IMPORTANT: It is assumed that parts[0] === \"\" because this method is used to\n        // join an absolute path to a relative path\n        var i;\n        var len = 0;\n\n        var numParts = parts.length;\n\n        for (i = 0; i < numParts; i++) {\n            var part = parts[i];\n\n            if (part === '.') {\n                // ignore parts with just \".\"\n                /*\n                // if the \".\" is at end of parts (e.g. [\"a\", \"b\", \".\"]) then trim it off\n                if (i === numParts - 1) {\n                    //len--;\n                }\n                */\n            } else if (part === '..') {\n                // overwrite the previous item by decrementing length\n                len--;\n            } else {\n                // add this part to result and increment length\n                parts[len] = part;\n                len++;\n            }\n        }\n\n        if (len === 1) {\n            // if we end up with just one part that is empty string\n            // (which can happen if input is [\"\", \".\"]) then return\n            // string with just the leading slash\n            return '/';\n        } else if (len > 2) {\n            // parts i s\n            // [\"\", \"a\", \"\"]\n            // [\"\", \"a\", \"b\", \"\"]\n            if (parts[len - 1].length === 0) {\n                // last part is an empty string which would result in trailing slash\n                len--;\n            }\n        }\n\n        // truncate parts to remove unused\n        parts.length = len;\n        return parts.join('/');\n    }", "label": 3}
{"code": "public TileMap getCapabilities(TmsLayer layer) throws TmsLayerException {\n\t\ttry {\n\t\t\t// Create a JaxB unmarshaller:\n\t\t\tJAXBContext context = JAXBContext.newInstance(TileMap.class);\n\t\t\tUnmarshaller um = context.createUnmarshaller();\n\n\t\t\t// Find out where to retrieve the capabilities and unmarshall:\n\t\t\tif (layer.getBaseTmsUrl().startsWith(CLASSPATH)) {\n\t\t\t\tString location = layer.getBaseTmsUrl().substring(CLASSPATH.length());\n\t\t\t\tif (location.length() > 0 && location.charAt(0) == '/') {\n\t\t\t\t\t// classpath resources should not start with a slash, but they often do\n\t\t\t\t\tlocation = location.substring(1);\n\t\t\t\t}\n\t\t\t\tClassLoader cl = Thread.currentThread().getContextClassLoader();\n\t\t\t\tif (null == cl) {\n\t\t\t\t\tcl = getClass().getClassLoader(); // NOSONAR fallback from proper behaviour for some environments\n\t\t\t\t}\n\t\t\t\tInputStream is = cl.getResourceAsStream(location);\n\t\t\t\tif (null != is) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn (TileMap) um.unmarshal(is);\n\t\t\t\t\t} finally {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tis.close();\n\t\t\t\t\t\t} catch (IOException ioe) {\n\t\t\t\t\t\t\t// ignore, just closing the stream\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tthrow new TmsLayerException(TmsLayerException.COULD_NOT_FIND_FILE, layer.getBaseTmsUrl());\n\t\t\t}\n\n\t\t\t// Normal case, find the URL and unmarshal:\n\t\t\treturn (TileMap) um.unmarshal(httpService.getStream(layer.getBaseTmsUrl(), layer));\n\t\t} catch (JAXBException e) {\n\t\t\tthrow new TmsLayerException(e, TmsLayerException.COULD_NOT_READ_FILE, layer.getBaseTmsUrl());\n\t\t} catch (IOException e) {\n\t\t\tthrow new TmsLayerException(e, TmsLayerException.COULD_NOT_READ_FILE, layer.getBaseTmsUrl());\n\t\t}\n\t}", "label": 0}
{"code": "public static wisite_accessmethod_binding[] get(nitro_service service, String sitepath) throws Exception{\n\t\twisite_accessmethod_binding obj = new wisite_accessmethod_binding();\n\t\tobj.set_sitepath(sitepath);\n\t\twisite_accessmethod_binding response[] = (wisite_accessmethod_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func OptionDNSSearch(search string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.dnsSearchList = append(sb.config.dnsSearchList, search)\n\t}\n}", "label": 5}
{"code": "func (s *Server) EmitAuditEvent(event events.Event, fields events.EventFields) {\n\tlog.Debugf(\"server.EmitAuditEvent(%v)\", event.Name)\n\talog := s.alog\n\tif alog != nil {\n\t\t// record the event time with ms precision\n\t\tfields[events.EventTime] = s.clock.Now().In(time.UTC).Round(time.Millisecond)\n\t\tif err := alog.EmitAuditEvent(event, fields); err != nil {\n\t\t\tlog.Error(trace.DebugReport(err))\n\t\t}\n\t} else {\n\t\tlog.Warn(\"SSH server has no audit log\")\n\t}\n}", "label": 5}
{"code": "func (opts BeeOptions) Bind(name string, dst interface{}) error {\n\tv := opts.Value(name)\n\tif v == nil {\n\t\treturn errors.New(\"Option with name \" + name + \" not found\")\n\t}\n\n\treturn ConvertValue(v, dst)\n}", "label": 5}
{"code": "def format_op_hdr():\n    \"\"\"\n    Build the header\n    \"\"\"\n    txt = 'Base Filename'.ljust(36) + ' '\n    txt += 'Lines'.rjust(7) + ' '\n    txt += 'Words'.rjust(7) + '  '\n    txt += 'Unique'.ljust(8) + ''\n    return txt", "label": 1}
{"code": "def save_extended_data_file\n      extended = {\n        Phonelib::Core::EXT_PREFIXES => @prefixes,\n        Phonelib::Core::EXT_GEO_NAMES => @geo_names,\n        Phonelib::Core::EXT_COUNTRY_NAMES => @countries,\n        Phonelib::Core::EXT_TIMEZONES => @timezones,\n        Phonelib::Core::EXT_CARRIERS => @carriers\n      }\n      File.open(file_path(Phonelib::Core::FILE_EXT_DATA), 'wb+') do |f|\n        Marshal.dump(extended, f)\n      end\n      puts 'DATA SAVED'\n    end", "label": 4}
{"code": "def get_subcommand_kwargs(mgr, name, namespace):\n    \"\"\"Get subcommand options from global parsed\n    arguments.\n    \"\"\"\n    subcmd = mgr.get(name)\n    subcmd_kwargs = {}\n    for opt in list(subcmd.args.values()) + list(subcmd.options.values()):\n        if hasattr(namespace, opt.dest):\n            subcmd_kwargs[opt.dest] = getattr(namespace, opt.dest)\n    return (subcmd, subcmd_kwargs)", "label": 1}
{"code": "public function setTimeFrom($date = null)\n    {\n        $date = $this->resolveCarbon($date);\n\n        return $this->setTime($date->hour, $date->minute, $date->second, $date->microsecond);\n    }", "label": 2}
{"code": "def link(*urls)\n      opts          = urls.last.respond_to?(:to_hash) ? urls.pop : {}\n      opts[:rel]    = urls.shift unless urls.first.respond_to? :to_str\n      options       = opts.map { |k, v| \" #{k}=#{v.to_s.inspect}\" }\n      html_pattern  = \"<link href=\\\"%s\\\"#{options.join} />\"\n      http_pattern  = [\"<%s>\", *options].join \";\"\n      link          = (response[\"Link\"] ||= \"\")\n\n      urls.map do |url|\n        link << \",\\n\" unless link.empty?\n        link << (http_pattern % url)\n        html_pattern % url\n      end.join \"\\n\"\n    end", "label": 4}
{"code": "public function doesTagExist($target, $tagName)\n    {\n        $res = $this->client->get(sprintf(\n            self::GITHUB_RELEASES_ENDPOINT,\n            $this->cleanTarget($target), $tagName\n        ), [\n            'http_errors' => false,\n            'auth' => [null, $this->token]\n        ]);\n\n        return ($res->getStatusCode() === 200);\n    }", "label": 2}
{"code": "public function setRecordKey($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\RecordKey::class);\n        $this->record_key = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def ensure_csrf(klass)\n      if csrf_cache[klass]\n        self.csrf_tokens = csrf_cache[klass]\n        return\n      end\n\n      self.csrf_tokens = nil\n\n      # If we directly create a new resource (e.g. app) without querying anything before\n      # we don't have a valid csrf token, that's why we have to do at least one request\n      block_given? ? yield : klass.all\n\n      csrf_cache[klass] = self.csrf_tokens\n    end", "label": 4}
{"code": "func OrParseType(args *internal.ArgType, dt string, nullable bool) (int, string, string) {\n\tnilVal := \"nil\"\n\n\tdt = strings.ToLower(dt)\n\n\t// extract precision\n\tdt, precision, scale := args.ParsePrecision(dt)\n\n\tvar typ string\n\t// strip remaining length (on things like timestamp)\n\tswitch OrLenRE.ReplaceAllString(dt, \"\") {\n\tcase \"char\", \"nchar\", \"varchar\", \"varchar2\", \"nvarchar2\",\n\t\t\"long\",\n\t\t\"clob\", \"nclob\",\n\t\t\"rowid\":\n\t\tnilVal = `\"\"`\n\t\ttyp = \"string\"\n\n\tcase \"shortint\":\n\t\tnilVal = \"0\"\n\t\ttyp = \"int16\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\tcase \"integer\":\n\t\tnilVal = \"0\"\n\t\ttyp = args.Int32Type\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\tcase \"longinteger\":\n\t\tnilVal = \"0\"\n\t\ttyp = \"int64\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\ttyp = \"sql.NullInt64\"\n\t\t}\n\n\tcase \"float\", \"shortdecimal\":\n\t\tnilVal = \"0.0\"\n\t\ttyp = \"float32\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullFloat64{}\"\n\t\t\ttyp = \"sql.NullFloat64\"\n\t\t}\n\n\tcase \"number\", \"decimal\":\n\t\tnilVal = \"0.0\"\n\t\tif 0 < precision && precision < 18 && scale > 0 {\n\t\t\ttyp = \"float64\"\n\t\t\tif nullable {\n\t\t\t\tnilVal = \"sql.NullFloat64{}\"\n\t\t\t\ttyp = \"sql.NullFloat64\"\n\t\t\t}\n\t\t} else if 0 < precision && precision <= 19 && scale == 0 {\n\t\t\ttyp = \"int64\"\n\t\t\tif nullable {\n\t\t\t\tnilVal = \"sql.NullInt64{}\"\n\t\t\t\ttyp = \"sql.NullInt64\"\n\t\t\t}\n\t\t} else {\n\t\t\tnilVal = `\"\"`\n\t\t\ttyp = \"string\"\n\t\t}\n\n\tcase \"blob\", \"long raw\", \"raw\":\n\t\ttyp = \"[]byte\"\n\n\tcase \"date\", \"timestamp\", \"timestamp with time zone\":\n\t\ttyp = \"time.Time\"\n\t\tnilVal = \"time.Time{}\"\n\n\tdefault:\n\t\t// bail\n\t\tfmt.Fprintf(os.Stderr, \"error: unknown type %q\\n\", dt)\n\t\tos.Exit(1)\n\t}\n\n\t// special case for bool\n\tif typ == \"int\" && precision == 1 {\n\t\tnilVal = \"false\"\n\t\ttyp = \"bool\"\n\t\tif nullable {\n\t\t\tnilVal = \"sql.NullBool{}\"\n\t\t\ttyp = \"sql.NullBool\"\n\t\t}\n\t}\n\n\treturn precision, nilVal, typ\n}", "label": 5}
{"code": "public function recordCommand(CommandStarting $event)\n    {\n        if (! Telescope::isRecording() ||\n            $event->command !== 'schedule:run' &&\n            $event->command !== 'schedule:finish') {\n            return;\n        }\n\n        collect(app(Schedule::class)->events())->each(function ($event) {\n            $event->then(function () use ($event) {\n                Telescope::recordScheduledCommand(IncomingEntry::make([\n                    'command' => $event instanceof CallbackEvent ? 'Closure' : $event->command,\n                    'description' => $event->description,\n                    'expression' => $event->expression,\n                    'timezone' => $event->timezone,\n                    'user' => $event->user,\n                    'output' => $this->getEventOutput($event),\n                ]));\n            });\n        });\n    }", "label": 2}
{"code": "protected function getVersion()\n    {\n        $version = $this->option('use-version') ?: $this->version;\n\n        if (! $version) {\n            $this->comment('A version for the documentation was not supplied. Use the --use-version option or set a default in the configuration.');\n\n            exit;\n        }\n\n        return $version;\n    }", "label": 2}
{"code": "public function setType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\DataSourceParameter_Type::class);\n        $this->type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def options=(options)\n      if options\n        options.each_pair do |option, value|\n          Validators::Option.validate(option)\n          send(\"#{option}=\", value)\n        end\n      end\n    end", "label": 4}
{"code": "func (a *Agent) connectedToRightProxy() bool {\n\tfor _, proxy := range a.DiscoverProxies {\n\t\tif a.connectedTo(proxy) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "function validateParams(dataSources, cb) {\n  dataSources = _.map(dataSources, function(dataSourceUpdateData) {\n    var failed = validate(dataSourceUpdateData).has(CONSTANTS.DATA_SOURCE_ID);\n\n    if (failed) {\n      dataSourceUpdateData.error = buildErrorResponse({error: new Error(\"Invalid Parameters For Updating Data Source Data Cache\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS});\n    }\n\n    if (!misc.checkId(dataSourceUpdateData._id)) {\n      dataSourceUpdateData.error = buildErrorResponse({error: new Error(\"Invalid ID Paramter \" + dataSourceUpdateData._id), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS});\n    }\n\n    return dataSourceUpdateData;\n  });\n\n  //Filter out any data sources with invalid parameters.\n\n  cb(undefined, dataSources);\n}", "label": 3}
{"code": "def get_complex_type_methods type, context = '', internal = false\n      # This method does not qualify the complex type's namespace because\n      # it can cause conflicts between similar names, e.g., `Foo` vs.\n      # `Other::Foo`. It still takes a context argument to determine whether\n      # protected and private methods are visible.\n      return [] if type.undefined? || type.void?\n      result = []\n      if type.duck_type?\n        type.select(&:duck_type?).each do |t|\n          result.push Pin::DuckMethod.new(nil, t.tag[1..-1])\n        end\n        result.concat get_methods('Object')\n      else\n        unless type.nil? || type.name == 'void'\n          visibility = [:public]\n          if type.namespace == context || super_and_sub?(type.namespace, context)\n            visibility.push :protected\n            visibility.push :private if internal\n          end\n          result.concat get_methods(type.namespace, scope: type.scope, visibility: visibility)\n        end\n      end\n      result\n    end", "label": 4}
{"code": "public static String httpRequest(String stringUrl, String method, Map<String, String> parameters,\n      String input, String charset) throws IOException {\n    URL url = new URL(stringUrl);\n    HttpURLConnection conn = (HttpURLConnection) url.openConnection();\n    conn.setDoOutput(true);\n    conn.setRequestMethod(method);\n\n    if (parameters != null) {\n      for (Entry<String, String> entry : parameters.entrySet()) {\n        conn.addRequestProperty(entry.getKey(), entry.getValue());\n      }\n    }\n\n    if (input != null) {\n      OutputStream output = null;\n      try {\n        output = conn.getOutputStream();\n        output.write(input.getBytes(charset));\n      } finally {\n        if (output != null) {\n          output.close();\n        }\n      }\n    }\n\n    return MyStreamUtils.readContent(conn.getInputStream());\n  }", "label": 0}
{"code": "func (mi *MetaInfo) Magnet(displayName string, infoHash Hash) (m Magnet) {\n\tfor t := range mi.UpvertedAnnounceList().DistinctValues() {\n\t\tm.Trackers = append(m.Trackers, t)\n\t}\n\tm.DisplayName = displayName\n\tm.InfoHash = infoHash\n\treturn\n}", "label": 5}
{"code": "func SetClock(clock clockwork.Clock) KeygenOption {\n\treturn func(k *Keygen) error {\n\t\tk.clock = clock\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "def line_numbers\n      return (line..line) unless @value && text\n\n      end_line = line + lines.count\n      end_line = nontrivial_end_line if line == end_line\n\n      (line..end_line)\n    end", "label": 4}
{"code": "def process_name(data)\n      validate_name(data['name'])\n      author, @module_name = data['name'].split(/[-\\/]/, 2)\n\n      data['author'] ||= author if @data['author'] == DEFAULTS['author']\n    end", "label": 4}
{"code": "func (fs *FlagSet) ReportError(str string, withHelp bool) {\n\tif withHelp {\n\t\tif os.Args[0] == fs.Name() {\n\t\t\tstr += \".\\nSee '\" + os.Args[0] + \" --help'\"\n\t\t} else {\n\t\t\tstr += \".\\nSee '\" + os.Args[0] + \" \" + fs.Name() + \" --help'\"\n\t\t}\n\t}\n\tfmt.Fprintf(fs.Out(), \"%s: %s.\\n\", os.Args[0], str)\n}", "label": 5}
{"code": "func NewRateLimiter(config LimiterConfig) (*RateLimiter, error) {\n\tlimiter := RateLimiter{\n\t\tMutex: &sync.Mutex{},\n\t}\n\n\tipExtractor, err := utils.NewExtractor(\"client.ip\")\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tlimiter.rates = ratelimit.NewRateSet()\n\tfor _, rate := range config.Rates {\n\t\terr := limiter.rates.Add(rate.Period, rate.Average, rate.Burst)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\tif len(config.Rates) == 0 {\n\t\terr := limiter.rates.Add(time.Second, DefaultRate, DefaultRate)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\n\tif config.Clock == nil {\n\t\tconfig.Clock = &timetools.RealTime{}\n\t}\n\tlimiter.clock = config.Clock\n\n\tlimiter.TokenLimiter, err = ratelimit.New(nil, ipExtractor,\n\t\tlimiter.rates, ratelimit.Clock(config.Clock))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tmaxNumberOfUsers := config.MaxNumberOfUsers\n\tif maxNumberOfUsers <= 0 {\n\t\tmaxNumberOfUsers = DefaultMaxNumberOfUsers\n\t}\n\tlimiter.rateLimits, err = ttlmap.NewMap(\n\t\tmaxNumberOfUsers, ttlmap.Clock(config.Clock))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &limiter, nil\n}", "label": 5}
{"code": "function _ensureExists(dir, callback) {\n    dir = path.resolve(dir); // make full path\n    \n    path.exists(dir, function(exists) {\n        if (!exists) {\n            // ensure that the parent dir exists\n            _ensureExists(path.dirname(dir), function(err) {\n                if (err) {\n                    callback(err);\n                    return;\n                }\n                \n                // make the dir\n                log.log('Creating ' + dir);\n                fs.mkdir(dir, function(err) {\n                    if (err) {\n                        callback(err);\n                        return;\n                    }\n                    \n                    callback(null);\n                });\n            });\n        }\n        else {\n            callback(null);\n        }\n    });\n}", "label": 3}
{"code": "public static base_responses unset(nitro_service client, bridgetable resources[],  String[] args) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tbridgetable unsetresources[] = new bridgetable[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tunsetresources[i] = new bridgetable();\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static lbvserver_scpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_scpolicy_binding obj = new lbvserver_scpolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_scpolicy_binding response[] = (lbvserver_scpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (v *ViewPort) MakeVisible(x, y int) {\n\tif x < v.limx && x >= v.viewx+v.width {\n\t\tv.viewx = x - (v.width - 1)\n\t}\n\tif x >= 0 && x < v.viewx {\n\t\tv.viewx = x\n\t}\n\tif y < v.limy && y >= v.viewy+v.height {\n\t\tv.viewy = y - (v.height - 1)\n\t}\n\tif y >= 0 && y < v.viewy {\n\t\tv.viewy = y\n\t}\n\tv.ValidateView()\n}", "label": 5}
{"code": "func (f *Fpdf) SetKeywords(keywordsStr string, isUTF8 bool) {\n\tif isUTF8 {\n\t\tkeywordsStr = utf8toutf16(keywordsStr)\n\t}\n\tf.keywords = keywordsStr\n}", "label": 5}
{"code": "public function next()\n    {\n        $this->pageIndex++;\n        $this->position++;\n\n        if (count($this->pageIterator->current()) <= $this->pageIndex && $this->nextResultToken()) {\n            $this->pageIterator->next();\n            $this->pageIndex = 0;\n        }\n    }", "label": 2}
{"code": "protected void rehash(int newCapacity) {\r\n\tint oldCapacity = table.length;\r\n\t//if (oldCapacity == newCapacity) return;\r\n\t\r\n\tlong oldTable[] = table;\r\n\tint oldValues[] = values;\r\n\tbyte oldState[] = state;\r\n\r\n\tlong newTable[] = new long[newCapacity];\r\n\tint newValues[] = new int[newCapacity];\r\n\tbyte newState[] = new byte[newCapacity];\r\n\r\n\tthis.lowWaterMark  = chooseLowWaterMark(newCapacity,this.minLoadFactor);\r\n\tthis.highWaterMark = chooseHighWaterMark(newCapacity,this.maxLoadFactor);\r\n\r\n\tthis.table = newTable;\r\n\tthis.values = newValues;\r\n\tthis.state = newState;\r\n\tthis.freeEntries = newCapacity-this.distinct; // delta\r\n\t\r\n\tfor (int i = oldCapacity ; i-- > 0 ;) {\r\n\t\tif (oldState[i]==FULL) {\r\n\t\t\tlong element = oldTable[i];\r\n\t\t\tint index = indexOfInsertion(element);\r\n\t\t\tnewTable[index]=element;\r\n\t\t\tnewValues[index]=oldValues[i];\r\n\t\t\tnewState[index]=FULL;\r\n\t\t}\r\n\t}\r\n}", "label": 0}
{"code": "function avg(arr, idx, range) {\n  return sum(arr.slice(idx - range, idx)) / range;\n}", "label": 3}
{"code": "def request(self, requests):\n        \"\"\"Requests resources from Mesos.\n\n        (see mesos.proto for a description of Request and how, for example, to\n        request resources from specific slaves.)\n\n        Any resources available are offered to the framework via\n        Scheduler.resourceOffers callback, asynchronously.\n        \"\"\"\n        logging.info('Request resources from Mesos')\n        return self.driver.requestResources(map(encode, requests))", "label": 1}
{"code": "public static protocolhttpband[] get(nitro_service service, protocolhttpband_args args) throws Exception{\n\t\tprotocolhttpband obj = new protocolhttpband();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tprotocolhttpband[] response = (protocolhttpband[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (a *HistoricalApi) availableClusterMetrics(request *restful.Request, response *restful.Response) {\n\tkey := core.HistoricalKey{ObjectType: core.MetricSetTypeCluster}\n\ta.processMetricNamesRequest(key, response)\n}", "label": 5}
{"code": "public static snmpgroup[] get(nitro_service service) throws Exception{\n\t\tsnmpgroup obj = new snmpgroup();\n\t\tsnmpgroup[] response = (snmpgroup[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void addRegexRoute(String urlPattern, Class<? extends Actor> actorClass) throws RouteAlreadyMappedException {\n        addRoute(new Route(urlPattern, true), actorClass);\n    }", "label": 0}
{"code": "function _normalizePath(path, parent, ancestors) {\n    if (path === '/') {\n        return path;\n    }\n\n    path = path.replace(/\\/$/, '');\n\n    // If path begins with / then assume it is independent route\n    if (path[0] === '/') {\n        return path;\n    }\n\n    // If no parent, and route doesn't start with /, then prepend /\n    if (! parent) {\n        return `/${path}`;\n    }\n\n    if (ancestors) {\n        return _cleanPath(`${ancestors.join('/')}/${path}`);\n    }\n\n    return _cleanPath(`${parent.path}/${path}`);\n}", "label": 3}
{"code": "function fillArrayWithNull( arr, toIndex ) {\n   for( let i = arr.length; i < toIndex; ++i ) {\n      arr[ i ] = null;\n   }\n}", "label": 3}
{"code": "protected function getBinding($class)\n    {\n        if ($this->isCollection($class) && ! $class->isEmpty()) {\n            return $this->getBindingFromCollection($class);\n        }\n\n        $class = is_object($class) ? get_class($class) : $class;\n\n        if (! $this->hasBinding($class)) {\n            throw new RuntimeException('Unable to find bound transformer for \"'.$class.'\" class.');\n        }\n\n        return $this->bindings[$class];\n    }", "label": 2}
{"code": "func (cn *connection) setRW(rw io.ReadWriter) {\n\tcn.r = rw\n\tcn.w = rw\n}", "label": 5}
{"code": "def update_workweek_config(id, body, opts = {})\n      data, _status_code, _headers = update_workweek_config_with_http_info(id, body, opts)\n      return data\n    end", "label": 4}
{"code": "public function setMessages($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dialogflow\\V2\\Intent\\Message::class);\n        $this->messages = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function isQuantifierNext(pattern, pos, flags) {\n        return nativ.test.call(\n            flags.indexOf('x') > -1 ?\n                // Ignore any leading whitespace, line comments, and inline comments\n                /^(?:\\s+|#.*|\\(\\?#[^)]*\\))*(?:[?*+]|{\\d+(?:,\\d*)?})/ :\n                // Ignore any leading inline comments\n                /^(?:\\(\\?#[^)]*\\))*(?:[?*+]|{\\d+(?:,\\d*)?})/,\n            pattern.slice(pos)\n        );\n    }", "label": 3}
{"code": "def run\n      unless stack_exists?(@stack_name)\n        puts \"The stack #{@stack_name.color(:green)} does not exist.\"\n        return\n      end\n\n      resp = cloudformation.describe_stacks(stack_name: @stack_name)\n      stack = resp.stacks.first\n\n      puts \"The current status for the stack #{@stack_name.color(:green)} is #{stack.stack_status.color(:green)}\"\n\n      status_poller = Stack::Status.new(@stack_name)\n\n      if stack.stack_status =~ /_IN_PROGRESS$/\n        puts \"Stack events (tailing):\"\n        # tail all events until done\n        status_poller.hide_time_took = true\n        status_poller.wait\n      else\n        puts \"Stack events:\"\n        # show the last events that was user initiated\n        status_poller.refresh_events\n        status_poller.show_events(true)\n      end\n    end", "label": 4}
{"code": "public function resetFilters()\n    {\n        $this->filters = [];\n\n        if ($this->endDate !== null) {\n            $this->filters[] = [static::END_DATE_FILTER, null];\n        }\n\n        if ($this->recurrences !== null) {\n            $this->filters[] = [static::RECURRENCES_FILTER, null];\n        }\n\n        $this->handleChangedParameters();\n\n        return $this;\n    }", "label": 2}
{"code": "def colstack(seq, mode='abort',returnnaming=False):\n    \"\"\"\n    Horizontally stack a sequence of numpy ndarrays with structured dtypes\n\n    Analog of numpy.hstack for recarrays.\n\n    Implemented by the tabarray method \n    :func:`tabular.tab.tabarray.colstack` which uses \n    :func:`tabular.tabarray.tab_colstack`.\n\n    **Parameters**\n\n            **seq** :  sequence of numpy ndarray with structured dtype\n\n                    List, tuple, etc. of numpy recarrays to stack vertically.\n\n            **mode** :  string in ['first','drop','abort','rename']\n\n                    Denotes how to proceed if when multiple recarrays share the \n                    same column name:\n\n                    *   if `mode` == ``first``, take the column from the first\n                        recarray in `seq` containing the shared column name.\n\n                    *   elif `mode` == ``abort``, raise an error when the \n                        recarrays to stack share column names; this is the\n                        default mode.\n\n                    *   elif `mode` == ``drop``, drop any column that shares    \n                        its name with any other column among the sequence of \n                        recarrays.\n\n                    *   elif `mode` == ``rename``, for any set of all columns\n                        sharing the same name, rename all columns by appending \n                        an underscore, '_', followed by an integer, starting \n                        with '0' and incrementing by 1 for each subsequent \n                        column.\n\n    **Returns**\n\n            **out** :  numpy ndarray with structured dtype\n\n                    Result of horizontally stacking the arrays in `seq`.\n\n    **See also:**  `numpy.hstack \n    <http://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html>`_.\n\n    \"\"\"\n    assert mode in ['first','drop','abort','rename'], \\\n       'mode argument must take on value \"first\",\"drop\", \"rename\", or \"abort\".'\n\n    AllNames = utils.uniqify(utils.listunion(\n                                           [list(l.dtype.names) for l in seq]))\n    NameList = [(x, [i for i in range(len(seq)) if x in seq[i].dtype.names]) \n                     for x in AllNames]\n    Commons = [x[0] for x in NameList if len(x[1]) > 1]\n\n    if len(Commons) > 0 or mode == 'first':\n        if mode == 'abort':\n            raise ValueError('There are common column names with differing ' +              \n                             'values in the columns')\n        elif mode == 'drop':\n            Names = [(L[0], x,x) for (x, L) in NameList if x not in Commons]\n        elif mode == 'rename':\n            NameDict = dict(NameList)\n            Names = utils.listunion([[(i,n,n) if len(NameDict[n]) == 1 else \\\n               (i,n,n + '_' + str(i)) for n in s.dtype.names] \\\n                                   for (i,s) in enumerate(seq)])                           \n    else:\n        Names = [(L[0], x,x) for (x, L) in NameList]\n    \n    if returnnaming:\n        return  utils.fromarrays([seq[i][x] for (i, x,y) in Names], \n                 type= np.ndarray,names=zip(*Names)[2]),Names\n    else:\n        return utils.fromarrays([seq[i][x] for (i, x,y) in Names], \n                 type= np.ndarray,names=zip(*Names)[2])", "label": 1}
{"code": "func (uw *UnitWriter) WriteUnit(path string, errmsg string, opts ...*unit.UnitOption) {\n\tif uw.err != nil {\n\t\treturn\n\t}\n\n\tfile, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0644)\n\tif err != nil {\n\t\tuw.err = errwrap.Wrap(errors.New(errmsg), err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tif _, err = io.Copy(file, unit.Serialize(opts)); err != nil {\n\t\tuw.err = errwrap.Wrap(errors.New(errmsg), err)\n\t\treturn\n\t}\n\tif err := user.ShiftFiles([]string{path}, &uw.p.UidRange); err != nil {\n\t\tuw.err = errwrap.Wrap(errors.New(errmsg), err)\n\t\treturn\n\t}\n}", "label": 5}
{"code": "public function writeBatch(array $entries, array $options = [])\n    {\n        $this->validateBatch($entries, Entry::class);\n\n        foreach ($entries as &$entry) {\n            $entry = $entry->info();\n        }\n\n        $this->connection->writeEntries($options + ['entries' => $entries]);\n    }", "label": 2}
{"code": "function renameRootDeclarations(path, namespace) {\n  const { scope } = path;\n  const oldName = path.node.name;\n  const rootScope = scope.getProgramParent();\n  const isRootScope = scope === rootScope;\n  const newName = `${namespace}${oldName}`;\n  let binding = scope.getBinding(oldName);\n\n  if (binding) {\n    if (!path.isReferenced() && shouldRenameDeclaration(oldName, path, binding, rootScope)) {\n      path.node.name = newName;\n      if (!isRootScope) {\n        const declarationParent = getDeclarationParent(path);\n\n        // Function declaration defines own scope, so switch to parent\n        if (declarationParent.isFunctionDeclaration()) {\n          binding = declarationParent.scope.parent.getBinding(oldName);\n        }\n      }\n      // Handle references\n      if (binding.referenced) {\n        binding.referencePaths.forEach(path => {\n          path.node.name = newName;\n        });\n      }\n    }\n  }\n}", "label": 3}
{"code": "def [](branch_name)\n      @branches.values.inject(@branches) do |branches, branch|\n        branches[branch.full] ||= branch\n\n        # This is how Git (version 1.7.9.5) works. \n        # Lets you ignore the 'remotes' if its at the beginning of the branch full name (even if is not a real remote branch). \n        branches[branch.full.sub('remotes/', '')] ||= branch if branch.full =~ /^remotes\\/.+/\n        \n        branches\n      end[branch_name.to_s]\n    end", "label": 4}
{"code": "okhttp3.Response get(String url, Map<String, Object> params)\n            throws RequestException, LocalOperationException {\n\n        String fullUrl = getFullUrl(url);\n        okhttp3.Request request = new okhttp3.Request.Builder()\n                .url(addUrlParams(fullUrl, toPayload(params)))\n                .addHeader(\"Transloadit-Client\", version)\n                .build();\n\n        try {\n            return httpClient.newCall(request).execute();\n        } catch (IOException e) {\n            throw new RequestException(e);\n        }\n    }", "label": 0}
{"code": "public void strokeRoundRectangle(Rectangle rect, Color color, float linewidth, float r) {\n\t\ttemplate.saveState();\n\t\tsetStroke(color, linewidth, null);\n\t\ttemplate.roundRectangle(origX + rect.getLeft(), origY + rect.getBottom(), rect.getWidth(), rect.getHeight(), r);\n\t\ttemplate.stroke();\n\t\ttemplate.restoreState();\n\t}", "label": 0}
{"code": "def s_demand(self, bus):\n        \"\"\" Returns the total complex power demand.\n        \"\"\"\n        Svl = array([complex(g.p, g.q) for g in self.generators if\n                    (g.bus == bus) and g.is_load], dtype=complex64)\n\n        Sd = complex(bus.p_demand, bus.q_demand)\n\n        return -sum(Svl) + Sd", "label": 1}
{"code": "protected function config($item, $instantiate = true)\n    {\n        $value = $this->app['config']->get('api.'.$item);\n\n        if (is_array($value)) {\n            return $instantiate ? $this->instantiateConfigValues($item, $value) : $value;\n        }\n\n        return $instantiate ? $this->instantiateConfigValue($item, $value) : $value;\n    }", "label": 2}
{"code": "def aggregate_in(self, On=None, AggFuncDict=None, AggFunc=None,\n                 AggList=None, interspersed=True):\n        \"\"\"\n        Aggregate a tabarray and include original data in the result.\n\n        See the :func:`aggregate` method.\n\n        Method wraps::\n\n                tabular.summarize.aggregate_in(self, On, AggFuncDict, AggFunc, interspersed)\n\n        \"\"\"\n        data = spreadsheet.aggregate_in(Data=self, On=On, \n               AggFuncDict=AggFuncDict, AggFunc=AggFunc, \n               AggList = AggList, interspersed=interspersed)\n        data = data.view(tabarray)\n        data.view = self.coloring\n        return data", "label": 1}
{"code": "private void appendLikeCriteria(TableAlias alias, PathInfo pathInfo, LikeCriteria c, StringBuffer buf)\r\n    {\r\n        appendColName(alias, pathInfo, c.isTranslateAttribute(), buf);\r\n        buf.append(c.getClause());\r\n        appendParameter(c.getValue(), buf);\r\n\r\n        buf.append(m_platform.getEscapeClause(c));\r\n    }", "label": 0}
{"code": "private MtasParserObject[] computeObjectFromMappingValue(\n      MtasParserObject object, Map<String, String> mappingValue,\n      Map<String, List<MtasParserObject>> currentList)\n      throws MtasParserException {\n    MtasParserObject[] checkObjects = null;\n    MtasParserObject checkObject;\n    Integer ancestorNumber = null;\n    String ancestorType = null;\n    // try to get relevant object\n    if (mappingValue.get(MAPPING_VALUE_SOURCE)\n        .equals(MtasParserMapping.SOURCE_OWN)) {\n      checkObjects = new MtasParserObject[] { object };\n    } else {\n      ancestorNumber = mappingValue.get(MAPPING_VALUE_ANCESTOR) != null\n          ? Integer.parseInt(mappingValue.get(MAPPING_VALUE_ANCESTOR)) : null;\n      ancestorType = computeTypeFromMappingSource(\n          mappingValue.get(MAPPING_VALUE_SOURCE));\n      // get ancestor object\n      if (ancestorType != null) {\n        int s = currentList.get(ancestorType).size();\n        // check existence ancestor for conditions\n        if (ancestorNumber != null) {\n          if ((s > 0) && (ancestorNumber < s) && (checkObject = currentList\n              .get(ancestorType).get((s - ancestorNumber - 1))) != null) {\n            checkObjects = new MtasParserObject[] { checkObject };\n          }\n        } else {\n          checkObjects = new MtasParserObject[s];\n          for (int i = s - 1; i >= 0; i--) {\n            checkObjects[s - i - 1] = currentList.get(ancestorType).get(i);\n          }\n        }\n      }\n    }\n    return checkObjects;\n  }", "label": 0}
{"code": "def revert(*migration_classes)\n      run(*migration_classes.reverse, revert: true) unless migration_classes.empty?\n      if block_given?\n        if connection.respond_to? :revert\n          connection.revert { yield }\n        else\n          recorder = command_recorder\n          @connection = recorder\n          suppress_messages do\n            connection.revert { yield }\n          end\n          @connection = recorder.delegate\n          recorder.replay(self)\n        end\n      end\n    end", "label": 4}
{"code": "public function getEmulatorBaseUri($baseUri, $emulatorHost = null)\n    {\n        if ($emulatorHost) {\n            $baseUri = $this->emulatorBaseUri($emulatorHost);\n        }\n\n        return $baseUri;\n    }", "label": 2}
{"code": "def load_data_subject_areas(subject_file):\n    \"\"\"\n    reads the subject file to a list, to confirm config is setup\n    \"\"\"\n    lst = []\n    if os.path.exists(subject_file):\n        with open(subject_file, 'r') as f:\n            for line in f:\n                lst.append(line.strip())\n    else:\n        print('MISSING DATA FILE (subject_file) ' , subject_file)\n        print('update your config.py or config.txt')\n    return lst", "label": 1}
{"code": "protected Map<String, Map<Integer, Set<String>>> createUpdateList() {\n    Map<String, Map<Integer, Set<String>>> updateList = new HashMap<>();\n    updateList.put(UPDATE_TYPE_OFFSET, new HashMap<>());\n    updateList.put(UPDATE_TYPE_POSITION, new HashMap<>());\n    updateList.put(UPDATE_TYPE_LOCAL_REF_POSITION_START, new HashMap<>());\n    updateList.put(UPDATE_TYPE_LOCAL_REF_POSITION_END, new HashMap<>());\n    updateList.put(UPDATE_TYPE_LOCAL_REF_OFFSET_START, new HashMap<>());\n    updateList.put(UPDATE_TYPE_LOCAL_REF_OFFSET_END, new HashMap<>());\n    updateList.put(UPDATE_TYPE_VARIABLE, new HashMap<>());\n    return updateList;\n  }", "label": 0}
{"code": "public static <E> double crossEntropy(Counter<E> from, Counter<E> to) {\r\n    double tot2 = to.totalCount();\r\n    double result = 0.0;\r\n    for (E key : from.keySet()) {\r\n      double count1 = from.getCount(key);\r\n      if (count1 == 0.0) {\r\n        continue;\r\n      }\r\n      double count2 = to.getCount(key);\r\n      double logFract = Math.log(count2 / tot2);\r\n      if (logFract == Double.NEGATIVE_INFINITY) {\r\n        return Double.NEGATIVE_INFINITY; // can't recover\r\n      }\r\n      result += count1 * (logFract / LOG_E_2); // express it in log base 2\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "func populateGithubClaims(client githubAPIClientI) (*services.GithubClaims, error) {\n\t// find out the username\n\tuser, err := client.getUser()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to query Github user info\")\n\t}\n\t// build team memberships\n\tteams, err := client.getTeams()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to query Github user teams\")\n\t}\n\tlog.Debugf(\"Retrieved %v teams for GitHub user %v.\", len(teams), user.Login)\n\n\torgToTeams := make(map[string][]string)\n\tfor _, team := range teams {\n\t\torgToTeams[team.Org.Login] = append(\n\t\t\torgToTeams[team.Org.Login], team.Slug)\n\t}\n\tif len(orgToTeams) == 0 {\n\t\treturn nil, trace.AccessDenied(\n\t\t\t\"list of user teams is empty, did you grant access?\")\n\t}\n\tclaims := &services.GithubClaims{\n\t\tUsername:            user.Login,\n\t\tOrganizationToTeams: orgToTeams,\n\t}\n\tlog.WithFields(logrus.Fields{trace.Component: \"github\"}).Debugf(\n\t\t\"Claims: %#v.\", claims)\n\treturn claims, nil\n}", "label": 5}
{"code": "function takeToken(cm, pos, precise, asArray) {\n    function getObj(copy) {\n      return {start: stream.start, end: stream.pos,\n              string: stream.current(),\n              type: style || null,\n              state: copy ? copyState(doc.mode, state) : state};\n    }\n\n    var doc = cm.doc, mode = doc.mode, style;\n    pos = clipPos(doc, pos);\n    var line = getLine(doc, pos.line), state = getStateBefore(cm, pos.line, precise);\n    var stream = new StringStream(line.text, cm.options.tabSize), tokens;\n    if (asArray) tokens = [];\n    while ((asArray || stream.pos < pos.ch) && !stream.eol()) {\n      stream.start = stream.pos;\n      style = readToken(mode, stream, state);\n      if (asArray) tokens.push(getObj(true));\n    }\n    return asArray ? tokens : getObj();\n  }", "label": 3}
{"code": "def accepts_attachments_for(collection_name, collection_class:, accessor_prefix:, attachment: :file, append: false)\n      include MultipleAttachments.new(\n        collection_name,\n        collection_class: collection_class,\n        name: accessor_prefix,\n        attachment: attachment,\n        append: append\n      )\n    end", "label": 4}
{"code": "function listents(seneca, entmap, qent, q, done) {\n  var list = []\n\n  var canon = qent.canon$({ object: true })\n  var base = canon.base\n  var name = canon.name\n\n  var entset = entmap[base] ? entmap[base][name] : null\n\n  if (entset) {\n    if (_.isString(q)) {\n      var ent = entset[q]\n      if (ent) {\n        list.push(ent)\n      }\n    }\n    if (_.isArray(q)) {\n      _.each(q, function(id) {\n        var ent = entset[id]\n        if (ent) {\n          ent = qent.make$(ent)\n          list.push(ent)\n        }\n      })\n    }\n    if (_.isObject(q)) {\n      _.keys(entset).forEach(function(id) {\n        var ent = entset[id]\n        for (var p in q) {\n          if (!~p.indexOf('$') && q[p] !== ent[p]) {\n            return\n          }\n        }\n        ent = qent.make$(ent)\n        list.push(ent)\n      })\n    }\n  }\n\n  // Always sort first, this is the 'expected' behaviour.\n  if (q.sort$) {\n    for (var sf in q.sort$) {\n      break\n    }\n\n    var sd = q.sort$[sf] < 0 ? -1 : 1\n    list = list.sort(function(a, b) {\n      return sd * (a[sf] < b[sf] ? -1 : a[sf] === b[sf] ? 0 : 1)\n    })\n  }\n\n  // Skip before limiting.\n  if (q.skip$ && q.skip$ > 0) {\n    list = list.slice(q.skip$)\n  }\n\n  // Limited the possibly sorted and skipped list.\n  if (q.limit$ && q.limit$ >= 0) {\n    list = list.slice(0, q.limit$)\n  }\n\n  // Prune fields\n  if (q.fields$) {\n    for (var i = 0; i < list.length; i++) {\n      var entfields = list[i].fields$()\n      for (var j = 0; j < entfields.length; j++) {\n        if ('id' !== entfields[j] && -1 == q.fields$.indexOf(entfields[j])) {\n          delete list[i][entfields[j]]\n        }\n      }\n    }\n  }\n\n  // Return the resulting list to the caller.\n  done.call(seneca, null, list)\n}", "label": 3}
{"code": "private ArrayList<String> getFiles(String dir, String subDir) {\n    ArrayList<String> files = new ArrayList<>();\n    String fullDir = subDir == null ? dir : dir + File.separator + subDir;\n    File[] listOfFiles = (new File(fullDir)).listFiles();\n    if (listOfFiles != null) {\n      for (File file : listOfFiles) {\n        String fullName = subDir == null ? file.getName() : subDir + File.separator + file.getName();\n        if (file.isFile()) {\n          files.add(fullName);\n        } else if (file.isDirectory()) {\n          files.addAll(getFiles(dir, fullName));\n        }\n      }\n    }\n    return files;\n  }", "label": 0}
{"code": "private void setBelief(String bName, Object value) {\n        introspector.setBeliefValue(this.getLocalName(), bName, value, null);\n    }", "label": 0}
{"code": "def _setup_signal_handler(self):\n        \"\"\" Register signal handlers \"\"\"\n        signal.signal(signal.SIGTERM, self._signal_handler)\n        signal.signal(signal.SIGINT, self._signal_handler)\n        signal.signal(signal.SIGQUIT, self._signal_handler)", "label": 1}
{"code": "public static aaagroup_vpnintranetapplication_binding[] get(nitro_service service, String groupname) throws Exception{\n\t\taaagroup_vpnintranetapplication_binding obj = new aaagroup_vpnintranetapplication_binding();\n\t\tobj.set_groupname(groupname);\n\t\taaagroup_vpnintranetapplication_binding response[] = (aaagroup_vpnintranetapplication_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (rd *Redirector) callback(w http.ResponseWriter, r *http.Request) (*auth.SSHLoginResponse, error) {\n\tif r.URL.Path != \"/callback\" {\n\t\treturn nil, trace.NotFound(\"path not found\")\n\t}\n\n\t// Decrypt ciphertext to get login response.\n\tplaintext, err := rd.key.Open([]byte(r.URL.Query().Get(\"response\")))\n\tif err != nil {\n\t\treturn nil, trace.BadParameter(\"failed to decrypt response: in %v, err: %v\", r.URL.String(), err)\n\t}\n\n\tvar re *auth.SSHLoginResponse\n\terr = json.Unmarshal(plaintext, &re)\n\tif err != nil {\n\t\treturn nil, trace.BadParameter(\"failed to decrypt response: in %v, err: %v\", r.URL.String(), err)\n\t}\n\n\treturn re, nil\n}", "label": 5}
{"code": "public function setOutputPath($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CloudStoragePath::class);\n        $this->output_path = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setQuery($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Datastore\\V1\\Query::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public String name(Properties attributes) throws XDocletException\r\n    {\r\n        return getDefForLevel(attributes.getProperty(ATTRIBUTE_LEVEL)).getName();\r\n    }", "label": 0}
{"code": "def commit_all(message, opts = {})\n      opts = {:add_all => true}.merge(opts)\n      self.lib.commit(message, opts)\n    end", "label": 4}
{"code": "func (s *SecureConfig) Check(filePath string) (bool, error) {\n\tif len(s.Checksum) == 0 {\n\t\treturn false, ErrSecureConfigNoChecksum\n\t}\n\n\tif s.Hash == nil {\n\t\treturn false, ErrSecureConfigNoHash\n\t}\n\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tdefer file.Close()\n\n\t_, err = io.Copy(s.Hash, file)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tsum := s.Hash.Sum(nil)\n\n\treturn subtle.ConstantTimeCompare(sum, s.Checksum) == 1, nil\n}", "label": 5}
{"code": "function updateDataSourceCaches(params, dsWithDocuments, dsWithNoDocuments, cb) {\n  //Updating All Of The Data Sources\n  //Generating Hashes For The Incoming Data Set. Useful for determining if the stored data set has changed.\n  dsWithDocuments = _.map(dsWithDocuments, function(dataSourceData) {\n    dataSourceData.dataHash = dataSourceData.error ? null : misc.generateHash(dataSourceData.data);\n    return dataSourceData;\n  });\n\n  async.map(dsWithDocuments, function(dataSourceWithDocument, cb) {\n    return updateDataSourceEntry(params, dataSourceWithDocument, cb);\n  }, function(err, updatedDocuments) {\n\n    logger.debug(\"ARGUMENTS\", arguments);\n    //Documents are now either updated or failed\n    var validInvalidDataSources = updateValidAndInvalidDataSources(updatedDocuments, dsWithNoDocuments);\n\n    return cb(undefined, validInvalidDataSources.valid, validInvalidDataSources.invalid);\n  });\n}", "label": 3}
{"code": "private function get_arg_or_param_args( $regex ) {\n\t\t$bits       = explode( \"\\n\", $this->doc_comment );\n\t\t$within_arg = false;\n\t\t$within_doc = false;\n\t\t$document   = array();\n\t\tforeach ( $bits as $bit ) {\n\t\t\tif ( preg_match( $regex, $bit ) ) {\n\t\t\t\t$within_arg = true;\n\t\t\t}\n\n\t\t\tif ( $within_arg && $within_doc && '---' === $bit ) {\n\t\t\t\t$within_doc = false;\n\t\t\t}\n\n\t\t\tif ( $within_arg && ! $within_doc && '---' === $bit ) {\n\t\t\t\t$within_doc = true;\n\t\t\t}\n\n\t\t\tif ( $within_doc ) {\n\t\t\t\t$document[] = $bit;\n\t\t\t}\n\n\t\t\tif ( $within_arg && '' === $bit ) {\n\t\t\t\t$within_arg = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif ( $document ) {\n\t\t\treturn Spyc::YAMLLoadString( implode( \"\\n\", $document ) );\n\t\t}\n\t\treturn null;\n\t}", "label": 2}
{"code": "func (r *Registry) SearchIndex() *SearchIndex {\n\treturn r.Get(r.content().SearchIndex.Reference()).(*SearchIndex)\n}", "label": 5}
{"code": "def all(path, type)\n      defaults = {}\n      old_scope = nil\n      matching_sets(path, type).each do |set|\n        if has_precedence?(old_scope, set[\"scope\"])\n          defaults = Utils.deep_merge_hashes(defaults, set[\"values\"])\n          old_scope = set[\"scope\"]\n        else\n          defaults = Utils.deep_merge_hashes(set[\"values\"], defaults)\n        end\n      end\n      defaults\n    end", "label": 4}
{"code": "def merge!(other)\n      self.class.coerce(other).to_h.each { |name, values| set name, values }\n    end", "label": 4}
{"code": "public CollectionValuedMap<K, V> deltaClone() {\r\n    CollectionValuedMap<K, V> result = new CollectionValuedMap<K, V>(null, cf, true);\r\n    result.map = new DeltaMap<K, Collection<V>>(this.map);\r\n    return result;\r\n  }", "label": 0}
{"code": "public double convert(double value, double temperatur, double viscosity){\n\t\treturn temperatur*kB / (Math.PI*viscosity*value);\n\t}", "label": 0}
{"code": "def col_style(index, style, options={})\n      offset = options.delete(:row_offset) || 0\n      cells = @rows[(offset..-1)].map { |row| row[index] }.flatten.compact\n      cells.each { |cell| cell.style = style }\n    end", "label": 4}
{"code": "def container_elem_type(container_type, params):\n    \"\"\"\n    Returns container element type\n\n    :param container_type:\n    :param params:\n    :return:\n    \"\"\"\n    elem_type = params[0] if params else None\n    if elem_type is None:\n        elem_type = container_type.ELEM_TYPE\n    return elem_type", "label": 1}
{"code": "public void addNotIn(String attribute, Query subQuery)\r\n    {\r\n\t\t// PAW\r\n\t\t// addSelectionCriteria(ValueCriteria.buildNotInCriteria(attribute, subQuery, getAlias()));\r\n\t\taddSelectionCriteria(ValueCriteria.buildNotInCriteria(attribute, subQuery, getUserAlias(attribute)));\r\n    }", "label": 0}
{"code": "function getResult (err) {\n        var res = {\n            valid: true,\n            errors: []\n        };\n\n        if (err !== null) {\n            res.valid = false;\n            res.errors.push(err);\n        }\n\n        return res;\n    }", "label": 3}
{"code": "func Init() error {\n\toutMode = OutputNormal\n\tif s, e := tcell.NewScreen(); e != nil {\n\t\treturn e\n\t} else if e = s.Init(); e != nil {\n\t\treturn e\n\t} else {\n\t\tscreen = s\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public static appfwlearningsettings[] get(nitro_service service) throws Exception{\n\t\tappfwlearningsettings obj = new appfwlearningsettings();\n\t\tappfwlearningsettings[] response = (appfwlearningsettings[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (arg) {\n\t\t\t\t\t\tif ( ! arg.allow ){\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tvar exist = false;\n\t\t\t\t\t\tfor (var i in data.allow) {\n\t\t\t\t\t\t\tif (data.allow[i] === arg.allow) {\n\t\t\t\t\t\t\t\texist = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ( exist === false ) {\n\t\t\t\t\t\t\tdata.allow[data.allow.length] = arg.allow;\n\t\t\t\t\t\t}\n\t\t\t\t\t}", "label": 3}
{"code": "func (t *Tracer) Stop() *Tracer {\n\tlog.Debugf(\"Tracer completed %v in %v.\", t.Description, time.Now().Sub(t.Started))\n\treturn t\n}", "label": 5}
{"code": "def tree_diff(a, b, n=5, sort=False):\n    \"\"\"Dump any data-structure or object, traverse\n    it depth-first in-order and apply a unified diff.\n\n    Depth-first in-order is just like structure would be printed.\n\n    :param             a: data_structure a\n    :param             b: data_structure b\n    :param             n: lines of context\n    :type              n: int\n    :param          sort: sort the data-structure\n\n    ATTENTION: Sorting means changing the data-structure. The test-result may\n    differ. But in case of dictionaries the results become comparable because\n    the sorting negates the hash-algorithms \"de-sorting\".\n\n    >>> a = recursive_sort(freeze([\n    ...     'a',\n    ...     [3, 4],\n    ...     {'a': [3, {'w' : set([4, '3', frozenset([3,5,2])])}]},\n    ...     []\n    ... ]))\n    >>> b = recursive_sort(freeze([\n    ...     'a',\n    ...     [7, 3],\n    ...     {'a': [3, {'w' : set([4, '3', frozenset([2,5,3])])}]},\n    ...     []\n    ... ]))\n    >>> transparent_repr(\"\\\\n\".join(tree_diff(a, b).split(\"\\\\n\")[2:]))\n    @@ -7,6 +7,6 @@\n           'w'),),\n         3),\n        'a'),),\n      'a',\n      (3,\n    -  4))\n    +  7))\n\n    >>> a = [\n    ...     'a',\n    ...     [3, 4],\n    ...     {'a': [3, {'w' : set([4, '3', frozenset([3,5,2])])}]},\n    ...     []\n    ... ]\n    >>> b = [\n    ...     'a',\n    ...     [7, 3],\n    ...     {'a': [3, {'w' : set([4, '3', frozenset([2,5,3])])}]},\n    ...     []\n    ... ]\n    >>> transparent_repr(\"\\\\n\".join(\n    ...     tree_diff(a, b, sort=True\n    ... ).split(\"\\\\n\")[2:]))\n    @@ -11,6 +11,6 @@\n               '3',\n               4)]),)],\n          3)),)],\n      'a',\n      (3,\n    -  4))\n    +  7))\n\n    \"\"\"\n    a = dump(a)\n    b = dump(b)\n    if not sort:\n        a = vformat(a).split(\"\\n\")\n        b = vformat(b).split(\"\\n\")\n    else:\n        a = vformat(recursive_sort(a)).split(\"\\n\")\n        b = vformat(recursive_sort(b)).split(\"\\n\")\n    return \"\\n\".join(difflib.unified_diff(a, b, n=n, lineterm=\"\"))", "label": 1}
{"code": "def init(filename=ConfigPath):\r\n    \"\"\"Loads INI configuration into this module's attributes.\"\"\"\r\n    section, parts = \"DEFAULT\", filename.rsplit(\":\", 1)\r\n    if len(parts) > 1 and os.path.isfile(parts[0]): filename, section = parts\r\n    if not os.path.isfile(filename): return\r\n\r\n    vardict, parser = globals(), configparser.RawConfigParser()\r\n    parser.optionxform = str # Force case-sensitivity on names\r\n    try:\r\n        def parse_value(raw):\r\n            try: return json.loads(raw) # Try to interpret as JSON\r\n            except ValueError: return raw # JSON failed, fall back to raw\r\n        txt = open(filename).read() # Add DEFAULT section if none present\r\n        if not re.search(\"\\\\[\\\\w+\\\\]\", txt): txt = \"[DEFAULT]\\n\" + txt\r\n        parser.readfp(StringIO.StringIO(txt), filename)\r\n        for k, v in parser.items(section): vardict[k] = parse_value(v)\r\n    except Exception:\r\n        logging.warn(\"Error reading config from %s.\", filename, exc_info=True)", "label": 1}
{"code": "func (r *ForwardRecorder) Write(data []byte) (int, error) {\n\t// we are copying buffer to prevent data corruption:\n\t// io.Copy allocates single buffer and calls multiple writes in a loop\n\t// our PostSessionSlice is async and sends reader wrapping buffer\n\t// to the channel. This can lead to cases when the buffer is re-used\n\t// and data is corrupted unless we copy the data buffer in the first place\n\tdataCopy := make([]byte, len(data))\n\tcopy(dataCopy, data)\n\t// post the chunk of bytes to the audit log:\n\tchunk := &SessionChunk{\n\t\tEventType: SessionPrintEvent,\n\t\tData:      dataCopy,\n\t\tTime:      time.Now().UTC().UnixNano(),\n\t}\n\tif err := r.AuditLog.PostSessionSlice(SessionSlice{\n\t\tNamespace: r.Namespace,\n\t\tSessionID: string(r.SessionID),\n\t\tChunks:    []*SessionChunk{chunk},\n\t}); err != nil {\n\t\tr.Error(trace.DebugReport(err))\n\t}\n\treturn len(data), nil\n}", "label": 5}
{"code": "def store_payload!(old_events, result)\n      case interpolated['mode'].presence\n      when 'on_change'\n        result_json = result.to_json\n        if found = old_events.find { |event| event.payload.to_json == result_json }\n          found.update!(expires_at: new_event_expiration_date)\n          false\n        else\n          true\n        end\n      when 'all', 'merge', ''\n        true\n      else\n        raise \"Illegal options[mode]: #{interpolated['mode']}\"\n      end\n    end", "label": 4}
{"code": "public function recordCacheMissed(CacheMissed $event)\n    {\n        if (! Telescope::isRecording() || $this->shouldIgnore($event)) {\n            return;\n        }\n\n        Telescope::recordCache(IncomingEntry::make([\n            'type' => 'missed',\n            'key' => $event->key,\n        ]));\n    }", "label": 2}
{"code": "def next(self):\n        \"\"\"\n        Returns the next sequence of results, given stride and n.\n        \n        \"\"\"\n        try:\n            results = self._stride_buffer.pop()\n        except (IndexError, AttributeError):\n            self._rebuffer()\n            results = self._stride_buffer.pop()\n        if not results:\n            raise StopIteration\n        return results", "label": 1}
{"code": "public static base_responses update(nitro_service client, nsrpcnode resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnsrpcnode updateresources[] = new nsrpcnode[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new nsrpcnode();\n\t\t\t\tupdateresources[i].ipaddress = resources[i].ipaddress;\n\t\t\t\tupdateresources[i].password = resources[i].password;\n\t\t\t\tupdateresources[i].srcip = resources[i].srcip;\n\t\t\t\tupdateresources[i].secure = resources[i].secure;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static double TopsoeDivergence(double[] p, double[] q) {\n        double r = 0;\n        for (int i = 0; i < p.length; i++) {\n            if (p[i] != 0 && q[i] != 0) {\n                double den = p[i] + q[i];\n                r += p[i] * Math.log(2 * p[i] / den) + q[i] * Math.log(2 * q[i] / den);\n            }\n        }\n        return r;\n    }", "label": 0}
{"code": "public static base_responses add(nitro_service client, inat resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tinat addresources[] = new inat[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new inat();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].publicip = resources[i].publicip;\n\t\t\t\taddresources[i].privateip = resources[i].privateip;\n\t\t\t\taddresources[i].tcpproxy = resources[i].tcpproxy;\n\t\t\t\taddresources[i].ftp = resources[i].ftp;\n\t\t\t\taddresources[i].tftp = resources[i].tftp;\n\t\t\t\taddresources[i].usip = resources[i].usip;\n\t\t\t\taddresources[i].usnip = resources[i].usnip;\n\t\t\t\taddresources[i].proxyip = resources[i].proxyip;\n\t\t\t\taddresources[i].mode = resources[i].mode;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (f *Fpdf) AddFontFromReader(familyStr, styleStr string, r io.Reader) {\n\tif f.err != nil {\n\t\treturn\n\t}\n\t// dbg(\"Adding family [%s], style [%s]\", familyStr, styleStr)\n\tvar ok bool\n\tfontkey := getFontKey(familyStr, styleStr)\n\t_, ok = f.fonts[fontkey]\n\tif ok {\n\t\treturn\n\t}\n\tvar info fontDefType\n\tinfo = f.loadfont(r)\n\tif f.err != nil {\n\t\treturn\n\t}\n\tif len(info.Diff) > 0 {\n\t\t// Search existing encodings\n\t\tn := -1\n\t\tfor j, str := range f.diffs {\n\t\t\tif str == info.Diff {\n\t\t\t\tn = j + 1\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif n < 0 {\n\t\t\tf.diffs = append(f.diffs, info.Diff)\n\t\t\tn = len(f.diffs)\n\t\t}\n\t\tinfo.DiffN = n\n\t}\n\t// dbg(\"font [%s], type [%s]\", info.File, info.Tp)\n\tif len(info.File) > 0 {\n\t\t// Embedded font\n\t\tif info.Tp == \"TrueType\" {\n\t\t\tf.fontFiles[info.File] = fontFileType{length1: int64(info.OriginalSize)}\n\t\t} else {\n\t\t\tf.fontFiles[info.File] = fontFileType{length1: int64(info.Size1), length2: int64(info.Size2)}\n\t\t}\n\t}\n\tf.fonts[fontkey] = info\n\treturn\n}", "label": 5}
{"code": "def pack_tups(*args):\n    \"\"\"Pack an arbitrary set of iterables and non-iterables into tuples.\n\n    Function packs a set of inputs with arbitrary iterability into tuples.\n    Iterability is tested with :func:`iterable`. Non-iterable inputs\n    are repeated in each output tuple. Iterable inputs are expanded\n    uniformly across the output tuples.  For consistency, all iterables must\n    be the same length.\n\n    The input arguments are parsed such that bare strings are treated as\n    **NON-ITERABLE**, through the use of a local subclass of |str| that\n    cripples the ``__iter__()`` method. Any strings passed are returned\n    in the packed tuples as standard, **ITERABLE** instances of |str|, however.\n\n    The order of the input arguments is retained within each output tuple.\n\n    No structural conversion is attempted on the arguments.\n\n    If all inputs are non-iterable, a list containing a single |tuple| will be\n    returned.\n\n    Parameters\n    ----------\n    \\*args\n        Arbitrary number of arbitrary mix of iterable and non-iterable\n        objects to be packed into tuples.\n\n    Returns\n    -------\n    tups\n        |list| of |tuple| --\n        Number of tuples returned is equal to the length of the iterables\n        passed in `*args`\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If any iterable objects are of different lengths\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Debug flag\n    _DEBUG = False\n\n    # Marker value for non-iterable items\n    NOT_ITER = -1\n\n    # Uninitialized test value\n    UNINIT_VAL = -1\n\n    # Print the input if in debug mode\n    if _DEBUG: # pragma: no cover\n        print(\"args = {0}\".format(args))\n\n    # Non-iterable subclass of str\n    class StrNoIter(str):\n        \"\"\" Non-iterable subclass of |str|. \"\"\"\n        def __iter__(self):\n            raise NotImplementedError(\"Non-iterable string\")\n        ## end def __iter__\n    ## end class StrNoIter\n\n    # Re-wrap input arguments with non-iterable strings if required\n    mod_args = [(StrNoIter(a) if isinstance(a, str) else a) for a in args]\n\n    # Determine the length or non-iterable status of each item and store\n    #  the maximum value (depends on NOT_ITER < 0)\n    iterlens = [(len(a) if iterable(a) else NOT_ITER) for a in mod_args]\n    maxiter = max(iterlens)\n\n    # Check to ensure all iterables are the same length\n    if not all(map(lambda v: v in (NOT_ITER, maxiter), iterlens)):\n        raise ValueError(\"All iterable items must be of equal length\")\n    ## end if\n\n    # If everything is non-iterable, just return the args tuple wrapped in\n    #  a list (as above, depends on NOT_ITER < 0)\n    if maxiter == NOT_ITER:\n        return [args]\n    ## end if\n\n    # Swap any non-iterables for a suitable length repeat, and zip to\n    #  tuples for return\n    tups = list(zip(*[(np.repeat(a, maxiter) if l == NOT_ITER else a)\n            for (a,l) in zip(mod_args, iterlens)]))\n\n    # Dump the resulting tuples, if in debug mode\n    if _DEBUG:  # pragma: no cover\n        print(\"tups = {0}\".format(tups))\n    ## end if\n\n    # Return the tuples\n    return tups", "label": 1}
{"code": "def create_missing_types(cls, schema, type_dict, type_builder=None):\n        \"\"\"Creates missing types for fields with a CardinalityField part.\n        It is assumed that the primary type converter for cardinality=1\n        is registered in the type dictionary.\n\n        :param schema:  Parse schema (or format) for parser (as string).\n        :param type_dict:  Type dictionary with type converters.\n        :param type_builder: Type builder to use for missing types.\n        :return: Type dictionary with missing types. Empty, if none.\n        :raises: MissingTypeError,\n                if a primary type converter with cardinality=1 is missing.\n        \"\"\"\n        if not type_builder:\n            type_builder = cls.type_builder\n\n        missing = cls.extract_missing_special_type_names(schema, type_dict)\n        return type_builder.create_type_variants(missing, type_dict)", "label": 1}
{"code": "def contain? position\n      position = Position.normalize(position)\n      return false if position.line < start.line || position.line > ending.line\n      return false if position.line == start.line && position.character < start.character\n      return false if position.line == ending.line && position.character > ending.character\n      true\n    end", "label": 4}
{"code": "public static <X, Y> Pair<X, Y> makePair(X x, Y y) {\r\n    return new Pair<X, Y>(x, y);\r\n  }", "label": 0}
{"code": "def process_role(ctx, param, value):\n    \"\"\"Return a role if it exists.\"\"\"\n    role = Role.query.filter(Role.name == value).first()\n    if not role:\n        raise click.BadParameter('Role with name \\'%s\\' not found.', value)\n    return role", "label": 1}
{"code": "func (c *NodeCommand) Invite(client auth.ClientI) error {\n\t// parse --roles flag\n\troles, err := teleport.ParseRoles(c.roles)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\ttoken, err := client.GenerateToken(auth.GenerateTokenRequest{Roles: roles, TTL: c.ttl, Token: c.token})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// Calculate the CA pin for this cluster. The CA pin is used by the client\n\t// to verify the identity of the Auth Server.\n\tcaPin, err := calculateCAPin(client)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tauthServers, err := client.GetAuthServers()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif len(authServers) == 0 {\n\t\treturn trace.Errorf(\"This cluster does not have any auth servers running.\")\n\t}\n\n\t// output format swtich:\n\tif c.format == \"text\" {\n\t\tif roles.Include(teleport.RoleTrustedCluster) || roles.Include(teleport.LegacyClusterTokenType) {\n\t\t\tfmt.Printf(trustedClusterMessage, token, int(c.ttl.Minutes()))\n\t\t} else {\n\t\t\tfmt.Printf(nodeMessage,\n\t\t\t\ttoken,\n\t\t\t\tint(c.ttl.Minutes()),\n\t\t\t\tstrings.ToLower(roles.String()),\n\t\t\t\ttoken,\n\t\t\t\tcaPin,\n\t\t\t\tauthServers[0].GetAddr(),\n\t\t\t\tint(c.ttl.Minutes()),\n\t\t\t\tauthServers[0].GetAddr(),\n\t\t\t)\n\t\t}\n\t} else {\n\t\t// Always return a list, otherwise we'll break users tooling. See #1846 for\n\t\t// more details.\n\t\ttokens := []string{token}\n\t\tout, err := json.Marshal(tokens)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err, \"failed to marshal token\")\n\t\t}\n\t\tfmt.Printf(string(out))\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static double Y(double x) {\r\n        if (x < 8.0) {\r\n            double y = x * x;\r\n            double ans1 = x * (-0.4900604943e13 + y * (0.1275274390e13\r\n                    + y * (-0.5153438139e11 + y * (0.7349264551e9\r\n                    + y * (-0.4237922726e7 + y * 0.8511937935e4)))));\r\n            double ans2 = 0.2499580570e14 + y * (0.4244419664e12\r\n                    + y * (0.3733650367e10 + y * (0.2245904002e8\r\n                    + y * (0.1020426050e6 + y * (0.3549632885e3 + y)))));\r\n            return (ans1 / ans2) + 0.636619772 * (J(x) * Math.log(x) - 1.0 / x);\r\n        } else {\r\n            double z = 8.0 / x;\r\n            double y = z * z;\r\n            double xx = x - 2.356194491;\r\n            double ans1 = 1.0 + y * (0.183105e-2 + y * (-0.3516396496e-4\r\n                    + y * (0.2457520174e-5 + y * (-0.240337019e-6))));\r\n            double ans2 = 0.04687499995 + y * (-0.2002690873e-3\r\n                    + y * (0.8449199096e-5 + y * (-0.88228987e-6\r\n                    + y * 0.105787412e-6)));\r\n            return Math.sqrt(0.636619772 / x) *\r\n                    (Math.sin(xx) * ans1 + z * Math.cos(xx) * ans2);\r\n        }\r\n    }", "label": 0}
{"code": "public static base_response add(nitro_service client, systemuser resource) throws Exception {\n\t\tsystemuser addresource = new systemuser();\n\t\taddresource.username = resource.username;\n\t\taddresource.password = resource.password;\n\t\taddresource.externalauth = resource.externalauth;\n\t\taddresource.promptstring = resource.promptstring;\n\t\taddresource.timeout = resource.timeout;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public void localRollback()\r\n    {\r\n        log.info(\"Rollback was called, do rollback on current connection \" + con);\r\n        if (!this.isInLocalTransaction)\r\n        {\r\n            throw new PersistenceBrokerException(\"Not in transaction, cannot abort\");\r\n        }\r\n        try\r\n        {\r\n            //truncate the local transaction\r\n            this.isInLocalTransaction = false;\r\n            if(!broker.isManaged())\r\n            {\r\n                if (batchCon != null)\r\n                {\r\n                    batchCon.rollback();\r\n                }\r\n                else if (con != null && !con.isClosed())\r\n                {\r\n                    con.rollback();\r\n                }\r\n            }\r\n            else\r\n            {\r\n                if(log.isEnabledFor(Logger.INFO)) log.info(\r\n                        \"Found managed environment setting in PB, will ignore rollback call on connection, this should be done by JTA\");\r\n            }\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            log.error(\"Rollback on the underlying connection failed\", e);\r\n        }\r\n        finally\r\n        {\r\n            try\r\n            {\r\n            \trestoreAutoCommitState();\r\n\t\t    }\r\n            catch(OJBRuntimeException ignore)\r\n            {\r\n\t\t\t    // Ignore or log exception\r\n\t\t    }\r\n            releaseConnection();\r\n        }\r\n    }", "label": 0}
{"code": "def get_single_allele_from_reads(allele_reads):\n    \"\"\"\n    Given a sequence of AlleleRead objects, which are expected to all have\n    the same allele, return that allele.\n    \"\"\"\n    allele_reads = list(allele_reads)\n\n    if len(allele_reads) == 0:\n        raise ValueError(\"Expected non-empty list of AlleleRead objects\")\n\n    seq = allele_reads[0].allele\n    if any(read.allele != seq for read in allele_reads):\n        raise ValueError(\"Expected all AlleleRead objects to have same allele '%s', got %s\" % (\n            seq, allele_reads))\n    return seq", "label": 1}
{"code": "public static <E> Counter<E> asCounter(FixedPrioritiesPriorityQueue<E> p) {\r\n    FixedPrioritiesPriorityQueue<E> pq = p.clone();\r\n    ClassicCounter<E> counter = new ClassicCounter<E>();\r\n    while (pq.hasNext()) {\r\n      double priority = pq.getPriority();\r\n      E element = pq.next();\r\n      counter.incrementCount(element, priority);\r\n    }\r\n    return counter;\r\n  }", "label": 0}
{"code": "def process_queue_item      #:nodoc:\n      return false if @queue.empty?\n\n      # Even though we just asked if the queue was empty, it\n      # still could have had an item which by this statement\n      # is now gone. For this reason we pass true to Queue#deq\n      # because we will sleep indefinitely if it is empty.\n      promise = @queue.deq(true)\n      stat :dequeued, item_id: promise.object_id\n      promise.work\n      return true\n\n    rescue ThreadError # this means the queue is empty\n      false\n    end", "label": 4}
{"code": "public function save(MetadataEnvelope $envelope, array $args)\n    {\n        foreach ($envelope as $header=>$value) {\n            $args['Metadata'][$header] = $value;\n        }\n\n        return $args;\n    }", "label": 2}
{"code": "func (c *Manager) DeleteLibraryItemUpdateSession(ctx context.Context, id string) error {\n\turl := internal.URL(c, internal.LibraryItemUpdateSession).WithID(id)\n\treturn c.Do(ctx, url.Request(http.MethodDelete), nil)\n}", "label": 5}
{"code": "def add_cell(value = '', options = {})\n      c = Cell.new(self, value, options)\n      self << c\n      worksheet.send(:update_column_info, self, [])\n      c\n    end", "label": 4}
{"code": "def argv(cls, name, short_name=None, type=None, help=None):\n        \"\"\" Set command line arguments as a source\n\n        Parses the command line arguments described by the parameters.\n\n        Args:\n            name: the long name of the argument (foo)\n            short_name: the optional short name of the argument (f)\n            type: the optional type of the argument, defaults to bool\n            help: the optional help text for the argument\n        \"\"\"\n        cls.__hierarchy.append(argv.Argv(name, short_name, type, help))", "label": 1}
{"code": "public static authenticationlocalpolicy_systemglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationlocalpolicy_systemglobal_binding obj = new authenticationlocalpolicy_systemglobal_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationlocalpolicy_systemglobal_binding response[] = (authenticationlocalpolicy_systemglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (w *Wrapper) UpsertProxy(s services.Server) error {\n\treturn w.Write.UpsertProxy(s)\n}", "label": 5}
{"code": "def compile_attribute(key, values)\n      if values.all? { |v| Temple::StaticAnalyzer.static?(v.to_literal) }\n        return static_build(values)\n      end\n\n      case key\n      when 'id', 'class'\n        compile_id_or_class_attribute(key, values)\n      else\n        compile_common_attribute(key, values)\n      end\n    end", "label": 4}
{"code": "def print_single(line, rev):\n    \"\"\"\n    print single reads to stderr\n    \"\"\"\n    if rev is True:\n        seq = rc(['', line[9]])[1]\n        qual = line[10][::-1]\n    else:\n        seq = line[9]\n        qual = line[10]\n    fq = ['@%s' % line[0], seq, '+%s' % line[0], qual]\n    print('\\n'.join(fq), file = sys.stderr)", "label": 1}
{"code": "func (m *AgentPool) removeDisconnected() {\n\tfor agentKey, agentSlice := range m.agents {\n\t\t// Filter and close all disconnected agents.\n\t\tvalidAgents := filterAndClose(agentSlice, func(agent *Agent) bool {\n\t\t\tif agent.getState() == agentStateDisconnected {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\n\t\t// Update (or delete) agent key with filter applied.\n\t\tif len(validAgents) > 0 {\n\t\t\tm.agents[agentKey] = validAgents\n\t\t} else {\n\t\t\tdelete(m.agents, agentKey)\n\t\t}\n\t}\n}", "label": 5}
{"code": "def _initial_interior_point(self, buses, generators, xmin, xmax, ny):\n        \"\"\" Selects an interior initial point for interior point solver.\n        \"\"\"\n        Va = self.om.get_var(\"Va\")\n        va_refs = [b.v_angle * pi / 180.0 for b in buses\n                   if b.type == REFERENCE]\n        x0 = (xmin + xmax) / 2.0\n\n        x0[Va.i1:Va.iN + 1] = va_refs[0] # Angles set to first reference angle.\n\n        if ny > 0:\n            yvar = self.om.get_var(\"y\")\n\n            # Largest y-value in CCV data\n            c = []\n            for g in generators:\n                if g.pcost_model == PW_LINEAR:\n                    for _, y in g.p_cost:\n                        c.append(y)\n\n\n            x0[yvar.i1:yvar.iN + 1] = max(c) * 1.1\n\n        return x0", "label": 1}
{"code": "def get_json_data(latitude=52.091579, longitude=5.119734):\n    \"\"\"Get buienradar json data and return results.\"\"\"\n    final_result = {SUCCESS: False,\n                    MESSAGE: None,\n                    CONTENT: None,\n                    RAINCONTENT: None}\n\n    log.info(\"Getting buienradar json data for latitude=%s, longitude=%s\",\n             latitude, longitude)\n    result = __get_ws_data()\n\n    if result[SUCCESS]:\n        # store json data:\n        final_result[CONTENT] = result[CONTENT]\n        final_result[SUCCESS] = True\n    else:\n        if STATUS_CODE in result and MESSAGE in result:\n            msg = \"Status: %d, Msg: %s\" % (result[STATUS_CODE],\n                                           result[MESSAGE])\n        elif MESSAGE in result:\n            msg = \"Msg: %s\" % (result[MESSAGE])\n        else:\n            msg = \"Something went wrong (reason unknown).\"\n\n        log.warning(msg)\n        final_result[MESSAGE] = msg\n\n    # load forecasted precipitation:\n    result = __get_precipfc_data(latitude,\n                                 longitude)\n    if result[SUCCESS]:\n        final_result[RAINCONTENT] = result[CONTENT]\n    else:\n        if STATUS_CODE in result and MESSAGE in result:\n            msg = \"Status: %d, Msg: %s\" % (result[STATUS_CODE],\n                                           result[MESSAGE])\n        elif MESSAGE in result:\n            msg = \"Msg: %s\" % (result[MESSAGE])\n        else:\n            msg = \"Something went wrong (reason unknown).\"\n\n        log.warning(msg)\n        final_result[MESSAGE] = msg\n\n    return final_result", "label": 1}
{"code": "private void addMembersInclSupertypes(Collection memberNames, HashMap members, XClass type, String tagName, String paramName, String paramValue) throws XDocletException\r\n    {\r\n        addMembers(memberNames, members, type, tagName, paramName, paramValue);\r\n        if (type.getInterfaces() != null) {\r\n            for (Iterator it = type.getInterfaces().iterator(); it.hasNext(); ) {\r\n                addMembersInclSupertypes(memberNames, members, (XClass)it.next(), tagName, paramName, paramValue);\r\n            }\r\n        }\r\n        if (!type.isInterface() && (type.getSuperclass() != null)) {\r\n            addMembersInclSupertypes(memberNames, members, type.getSuperclass(), tagName, paramName, paramValue);\r\n        }\r\n    }", "label": 0}
{"code": "def lemmatize(text_string):\n    '''\n        Returns base from of text_string using NLTK's WordNetLemmatizer as type str.\n\n        Keyword argument:\n\n        - text_string: string instance\n\n        Exceptions raised:\n\n        - InputError: occurs should a non-string argument be passed\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        return LEMMATIZER.lemmatize(text_string)\n    else:\n        raise InputError(\"string not passed as primary argument\")", "label": 1}
{"code": "def remove(self, container, force=True, volumes=True):\n        \"\"\"\n        Remove a container.\n\n        :param container: The container to remove.\n        :param force:\n            Whether to force the removal of the container, even if it is\n            running. Note that this defaults to True, unlike the Docker\n            default.\n        :param volumes:\n            Whether to remove any volumes that were created implicitly with\n            this container, i.e. any volumes that were created due to\n            ``VOLUME`` directives in the Dockerfile. External volumes that were\n            manually created will not be removed. Note that this defaults to\n            True, unlike the Docker default (where the equivalent parameter,\n            ``v``, defaults to False).\n        \"\"\"\n        super().remove(container, force=force, v=volumes)", "label": 1}
{"code": "public static String[] allLowerCase(String... strings){\n\t\tString[] tmp = new String[strings.length];\n\t\tfor(int idx=0;idx<strings.length;idx++){\n\t\t\tif(strings[idx] != null){\n\t\t\t\ttmp[idx] = strings[idx].toLowerCase();\n\t\t\t}\n\t\t}\n\t\treturn tmp;\n\t}", "label": 0}
{"code": "func (c *crontime) nextValidMonth(baseTime time.Time) {\n\tfor _, mon := range c.month {\n\t\tif mon >= int(c.calculatedTime.Month()) {\n\t\t\t//log.Print(\"Inside Month\", mon, c.calculatedTime)\n\t\t\tc.calculatedTime = setMonth(c.calculatedTime, mon)\n\t\t\t//log.Println(\" :: and out\", c.calculatedTime)\n\t\t\treturn\n\t\t}\n\t}\n\t// If no result was found try it again in the following year\n\tc.calculatedTime = c.calculatedTime.AddDate(1, 0, 0)\n\tc.calculatedTime = setMonth(c.calculatedTime, c.month[0])\n\t//log.Println(\"Cronbee: Month\", c.calculatedTime, baseTime, c.month)\n\tc.nextValidMonth(baseTime)\n}", "label": 5}
{"code": "public DescriptorRepository readDescriptorRepository(String fileName)\r\n    {\r\n        try\r\n        {\r\n            RepositoryPersistor persistor = new RepositoryPersistor();\r\n            return persistor.readDescriptorRepository(fileName);\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            throw new MetadataException(\"Can not read repository \" + fileName, e);\r\n        }\r\n    }", "label": 0}
{"code": "def check_resolved_type(type, object, ctx = :__undefined__)\n      if ctx == :__undefined__\n        # Old method signature\n        ctx = object\n        object = type\n        type = nil\n      end\n\n      if object.is_a?(GraphQL::Schema::Object)\n        object = object.object\n      end\n\n      if type.respond_to?(:graphql_definition)\n        type = type.graphql_definition\n      end\n\n      # Prefer a type-local function; fall back to the schema-level function\n      type_proc = type && type.resolve_type_proc\n      type_result = if type_proc\n        type_proc.call(object, ctx)\n      else\n        yield(type, object, ctx)\n      end\n\n      if type_result.nil?\n        nil\n      else\n        after_lazy(type_result) do |resolved_type_result|\n          if resolved_type_result.respond_to?(:graphql_definition)\n            resolved_type_result = resolved_type_result.graphql_definition\n          end\n          if !resolved_type_result.is_a?(GraphQL::BaseType)\n            type_str = \"#{resolved_type_result} (#{resolved_type_result.class.name})\"\n            raise \"resolve_type(#{object}) returned #{type_str}, but it should return a GraphQL type\"\n          else\n            resolved_type_result\n          end\n        end\n      end\n    end", "label": 4}
{"code": "function renderProblemFiles(files, currDir) {\n\treturn _.map(files, function(fileDetails) {\n\t\treturn filesTemplate({\n\t\t\tfileId: _.camelCase(fileDetails.filePath),\n\t\t\tfilePath: fileDetails.filePath.replace(currDir, ''),\n\t\t\terrorCount: fileDetails.errorCount,\n\t\t\twarningCount: fileDetails.warningCount\n\t\t});\n\t}).join('\\n');\n}", "label": 3}
{"code": "public function validate($name, Shape $shape, array $input)\n    {\n        $this->dispatch($shape, $input);\n\n        if ($this->errors) {\n            $message = sprintf(\n                \"Found %d error%s while validating the input provided for the \"\n                    . \"%s operation:\\n%s\",\n                count($this->errors),\n                count($this->errors) > 1 ? 's' : '',\n                $name,\n                implode(\"\\n\", $this->errors)\n            );\n            $this->errors = [];\n\n            throw new \\InvalidArgumentException($message);\n        }\n    }", "label": 2}
{"code": "protected void associateBatched(Collection owners, Collection children)\r\n    {\r\n        ObjectReferenceDescriptor ord = getObjectReferenceDescriptor();\r\n        ClassDescriptor cld = getOwnerClassDescriptor();\r\n        Object owner;\r\n        Object relatedObject;\r\n        Object fkValues[];\r\n        Identity id;\r\n        PersistenceBroker pb = getBroker();\r\n        PersistentField field = ord.getPersistentField();\r\n        Class topLevelClass = pb.getTopLevelClass(ord.getItemClass());\r\n        HashMap childrenMap = new HashMap(children.size());\r\n\r\n\r\n        for (Iterator it = children.iterator(); it.hasNext(); )\r\n        {\r\n            relatedObject = it.next();\r\n            childrenMap.put(pb.serviceIdentity().buildIdentity(relatedObject), relatedObject);\r\n        }\r\n\r\n        for (Iterator it = owners.iterator(); it.hasNext(); )\r\n        {\r\n            owner = it.next();\r\n            fkValues = ord.getForeignKeyValues(owner,cld);\r\n            if (isNull(fkValues))\r\n            {\r\n                field.set(owner, null);\r\n                continue;\r\n            }\r\n            id = pb.serviceIdentity().buildIdentity(null, topLevelClass, fkValues);\r\n            relatedObject = childrenMap.get(id);\r\n            field.set(owner, relatedObject);\r\n        }\r\n    }", "label": 0}
{"code": "def request(verb, path, opts = {}, &block)\n      url = client.connection.build_url(path, opts[:params]).to_s\n\n      opts[:headers] ||= {}\n      opts[:headers]['Authorization'] = header(verb, url)\n\n      @client.request(verb, path, opts, &block)\n    end", "label": 4}
{"code": "func (a *ACL) Valid() error {\n\tacl_valid, err := getSymbolPointer(a.lib.handle, \"acl_valid\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tret, err := C.my_acl_valid(acl_valid, a.a)\n\tif ret < 0 {\n\t\treturn errwrap.Wrap(errors.New(\"invalid acl\"), err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function (sourceName, referenceSourceName) {\n            var sourceToMove,\n                sourcePos,\n                referenceSourcePos;\n            if (!this._sources.every(function (source, index) {\n                var name = source.getName();\n                if (name === sourceName) {\n                    sourceToMove = source;\n                    sourcePos = index;\n                } else if (name === referenceSourceName) {\n                    referenceSourcePos = index;\n                }\n                return sourcePos === undefined || referenceSourcePos === undefined;\n            })) {\n                var KEEP_ITEM = 0,\n                    REMOVE_ITEM = 1;\n                this._sources.splice(sourcePos, REMOVE_ITEM);\n                if (sourcePos > referenceSourcePos) {\n                    ++referenceSourcePos;\n                }\n                this._sources.splice(referenceSourcePos, KEEP_ITEM, sourceToMove);\n                this._rebuildSourcesIndex();\n            }\n        }", "label": 3}
{"code": "function removeWildcardFilesWithLowerPriorityExtension(file, wildcardFiles, extensions, keyMapper) {\n        var extensionPriority = ts.getExtensionPriority(file, extensions);\n        var nextExtensionPriority = ts.getNextLowestExtensionPriority(extensionPriority);\n        for (var i = nextExtensionPriority; i < extensions.length; i++) {\n            var lowerPriorityExtension = extensions[i];\n            var lowerPriorityPath = keyMapper(ts.changeExtension(file, lowerPriorityExtension));\n            delete wildcardFiles[lowerPriorityPath];\n        }\n    }", "label": 3}
{"code": "public static function rmdir( $dir ) {\n\t\t$files = new RecursiveIteratorIterator(\n\t\t\tnew RecursiveDirectoryIterator( $dir, RecursiveDirectoryIterator::SKIP_DOTS ),\n\t\t\tRecursiveIteratorIterator::CHILD_FIRST\n\t\t);\n\n\t\tforeach ( $files as $fileinfo ) {\n\t\t\t$todo = $fileinfo->isDir() ? 'rmdir' : 'unlink';\n\t\t\t$todo( $fileinfo->getRealPath() );\n\t\t}\n\t\trmdir( $dir );\n\t}", "label": 2}
{"code": "def get_signature_challenge(self):\n        \"\"\"Returns new signature challenge\"\"\"\n\n        devices = [DeviceRegistration.wrap(device) for device in self.__get_u2f_devices()]\n\n        if devices == []:\n            return {\n                'status' : 'failed', \n                'error'  : 'No devices been associated with the account!'\n            }\n\n        challenge = start_authenticate(devices)\n        challenge['status'] = 'ok'\n\n        session['_u2f_challenge_'] = challenge.json\n\n        return challenge", "label": 1}
{"code": "function validateFieldType(fieldsCollection){\n        var err;\n\n        // ensure fieldsCollection is an array.\n        if(!_.isArray(fieldsCollection)) {\n            err = new Error('content type fields collection must be an array of field objects.');\n        }\n\n        if(!err) {\n            _.each(fieldsCollection, function(field){\n                err = isValidField(field);\n            });\n        }\n\n        return _.isUndefined(err);\n    }", "label": 3}
{"code": "public function setSinks($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Logging\\V2\\LogSink::class);\n        $this->sinks = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def connection_adapter(custom_adapter = nil, options = nil)\n      if custom_adapter.nil?\n        default_options[:connection_adapter]\n      else\n        default_options[:connection_adapter] = custom_adapter\n        default_options[:connection_adapter_options] = options\n      end\n    end", "label": 4}
{"code": "public static base_response add(nitro_service client, lbroute resource) throws Exception {\n\t\tlbroute addresource = new lbroute();\n\t\taddresource.network = resource.network;\n\t\taddresource.netmask = resource.netmask;\n\t\taddresource.gatewayname = resource.gatewayname;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public static base_responses update(nitro_service client, onlinkipv6prefix resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tonlinkipv6prefix updateresources[] = new onlinkipv6prefix[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new onlinkipv6prefix();\n\t\t\t\tupdateresources[i].ipv6prefix = resources[i].ipv6prefix;\n\t\t\t\tupdateresources[i].onlinkprefix = resources[i].onlinkprefix;\n\t\t\t\tupdateresources[i].autonomusprefix = resources[i].autonomusprefix;\n\t\t\t\tupdateresources[i].depricateprefix = resources[i].depricateprefix;\n\t\t\t\tupdateresources[i].decrementprefixlifetimes = resources[i].decrementprefixlifetimes;\n\t\t\t\tupdateresources[i].prefixvalidelifetime = resources[i].prefixvalidelifetime;\n\t\t\t\tupdateresources[i].prefixpreferredlifetime = resources[i].prefixpreferredlifetime;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static base_response update(nitro_service client, ipv6 resource) throws Exception {\n\t\tipv6 updateresource = new ipv6();\n\t\tupdateresource.ralearning = resource.ralearning;\n\t\tupdateresource.routerredirection = resource.routerredirection;\n\t\tupdateresource.ndbasereachtime = resource.ndbasereachtime;\n\t\tupdateresource.ndretransmissiontime = resource.ndretransmissiontime;\n\t\tupdateresource.natprefix = resource.natprefix;\n\t\tupdateresource.dodad = resource.dodad;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def reposition_parts!\n      reload.parts.each_with_index do |part, index|\n        part.update_columns position: index\n      end\n    end", "label": 4}
{"code": "public static streamidentifier_binding get(nitro_service service, String name) throws Exception{\n\t\tstreamidentifier_binding obj = new streamidentifier_binding();\n\t\tobj.set_name(name);\n\t\tstreamidentifier_binding response = (streamidentifier_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private void addSequence(String sequenceName, HighLowSequence seq)\r\n    {\r\n        // lookup the sequence map for calling DB\r\n        String jcdAlias = getBrokerForClass()\r\n                .serviceConnectionManager().getConnectionDescriptor().getJcdAlias();\r\n        Map mapForDB = (Map) sequencesDBMap.get(jcdAlias);\r\n        if(mapForDB == null)\r\n        {\r\n            mapForDB = new HashMap();\r\n        }\r\n        mapForDB.put(sequenceName, seq);\r\n        sequencesDBMap.put(jcdAlias, mapForDB);\r\n    }", "label": 0}
{"code": "function StatelessEmitter(ptcl, writableFactory, opts) {\n  MessageEmitter.call(this, ptcl, opts);\n  this._writableFactory = writableFactory;\n\n  if (!opts || !opts.noPing) {\n    // Ping the server to check whether the remote protocol is compatible.\n    this.emitMessage('', {}, function (err) {\n      if (err) {\n        this.emit('error', err);\n      }\n    });\n  }\n}", "label": 3}
{"code": "def dump_img(fname):\n    \"\"\" output the image as text \"\"\"\n    img = Image.open(fname)\n    width, _ = img.size\n    txt = ''\n    pixels = list(img.getdata())\n    for col in range(width):\n        txt += str(pixels[col:col+width])\n    return txt", "label": 1}
{"code": "public static cmppolicylabel[] get(nitro_service service) throws Exception{\n\t\tcmppolicylabel obj = new cmppolicylabel();\n\t\tcmppolicylabel[] response = (cmppolicylabel[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function () {\n            each(this.series, function (serie) {\n                serie.translate();\n                if (serie.setTooltipPoints) {\n                    serie.setTooltipPoints();\n                }\n                serie.render();\n            });\n        }", "label": 3}
{"code": "public void check(ModelDef modelDef, String checkLevel) throws ConstraintException\r\n    {\r\n        ensureReferencedKeys(modelDef, checkLevel);\r\n        checkReferenceForeignkeys(modelDef, checkLevel);\r\n        checkCollectionForeignkeys(modelDef, checkLevel);\r\n        checkKeyModifications(modelDef, checkLevel);\r\n    }", "label": 0}
{"code": "function openModal(src, width) {\n\tif ( !width ) width = 680;\n\t//var elementId = 'orcodio';\n\tvar originalYScroll = window.pageYOffset;\n\t//var modalFrame = $.modal('<iframe id=\"'+ elementId +'\" src=\"' + src + '\" width=\"' + width + '\" onload=\"centerModal(this,' + originalYScroll + ')\" style=\"border:0\">', {\n\tvar modalFrame = $.modal('<iframe src=\"' + src + '\" width=\"' + width + '\" onload=\"centerModal(this,' + originalYScroll + ')\" style=\"border:0\">', {\n\t\tcloseHTML:'',\n\t\tcontainerCss:{\n\t\t\tbackgroundColor:\"#fff\",\n\t\t\tborderColor:\"#fff\",\n\t\t\twidth:width,\n\t\t\tpadding:0,\n\t\t\tmargin:0\n\t\t},\n\t\toverlayClose:true,\n\t\tautoPosition:false,\n\t\tmodal:true,\n\t\topacity:70\n\t});\n}", "label": 3}
{"code": "public static Identity fromByteArray(final byte[] anArray) throws PersistenceBrokerException\r\n    {\r\n        // reverse of the serialize() algorithm:\r\n        // read from byte[] with a ByteArrayInputStream, decompress with\r\n        // a GZIPInputStream and then deserialize by reading from the ObjectInputStream\r\n        try\r\n        {\r\n            final ByteArrayInputStream bais = new ByteArrayInputStream(anArray);\r\n            final GZIPInputStream gis = new GZIPInputStream(bais);\r\n            final ObjectInputStream ois = new ObjectInputStream(gis);\r\n            final Identity result = (Identity) ois.readObject();\r\n            ois.close();\r\n            gis.close();\r\n            bais.close();\r\n            return result;\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            throw new PersistenceBrokerException(ex);\r\n        }\r\n    }", "label": 0}
{"code": "def cas(key, ttl=nil, options=nil, &block)\n      cas_core(key, false, ttl, options, &block)\n    end", "label": 4}
{"code": "public function createSynthesizeSpeechPreSignedUrl(array $args)\n    {\n        $uri = new Uri($this->getEndpoint());\n        $uri = $uri->withPath('/v1/speech');\n\n        // Formatting parameters follows rest-json protocol\n        $this->formatter = $this->formatter ?: new JsonBody($this->getApi());\n        $queryArray = json_decode(\n            $this->formatter->build(\n                $this->getApi()->getOperation('SynthesizeSpeech')->getInput(),\n                $args\n            ),\n            true\n        );\n\n        // Mocking a 'GET' request in pre-signing the Url\n        $query = Psr7\\build_query($queryArray);\n        $uri = $uri->withQuery($query);\n\n        $request = new Request('GET', $uri);\n        $request = $request->withBody(Psr7\\stream_for(''));\n        $signer = new SignatureV4('polly', $this->getRegion());\n        return (string) $signer->presign(\n            $request,\n            $this->getCredentials()->wait(),\n            '+15 minutes'\n        )->getUri();\n    }", "label": 2}
{"code": "public void retrieveCollections(Object newObj, ClassDescriptor cld, boolean forced) throws PersistenceBrokerException\r\n    {\r\n        doRetrieveCollections(newObj, cld, forced, false);\r\n    }", "label": 0}
{"code": "private float max(float x, float y, float z) {\n        if (x > y) {\n            // not y\n            if (x > z) {\n                return x;\n            }\n            else {\n                return z;\n            }\n        }\n        else {\n            // not x\n            if (y > z) {\n                return y;\n            }\n            else {\n                return z;\n            }\n        }\n    }", "label": 0}
{"code": "public IPlan[] getAgentPlans(final String agent_name, Connector connector) {\n        ((IExternalAccess) connector.getAgentsExternalAccess(agent_name))\n                .scheduleStep(new IComponentStep<Plan>() {\n\n                    public IFuture<Plan> execute(IInternalAccess ia) {\n\n                        IBDIInternalAccess bia = (IBDIInternalAccess) ia;\n                        plans = bia.getPlanbase().getPlans();\n                        return null;\n                    }\n                }).get(new ThreadSuspendable());\n\n        return plans;\n    }", "label": 0}
{"code": "public <T> T convert(ConversionContext context, Object source,\r\n\t\t\tTypeReference<T> destinationType) throws ConverterException {\r\n\t\ttry {\r\n\t\t\treturn (T) multiConverter.convert(context, source, destinationType);\r\n\t\t} catch (ConverterException e) {\r\n\t\t\tthrow e;\r\n\t\t} catch (Exception e) {\r\n\t\t\t// There is a problem with one converter. This should not happen.\r\n\t\t\t// Either there is a bug in this converter or it is not properly\r\n\t\t\t// configured\r\n\t\t\tthrow new ConverterException(\r\n\t\t\t\t\tMessageFormat\r\n\t\t\t\t\t\t\t.format(\r\n\t\t\t\t\t\t\t\t\t\"Could not convert given object with class ''{0}'' to object with type signature ''{1}''\",\r\n\t\t\t\t\t\t\t\t\tsource == null ? \"null\" : source.getClass()\r\n\t\t\t\t\t\t\t\t\t\t\t.getName(), destinationType), e);\r\n\t\t}\r\n\t}", "label": 0}
{"code": "def expand\n      @expand ||= Racc.set_closure(@heads.dup) do |ptr|\n        if (sym = ptr.symbol) && sym.nonterminal?\n          sym.heads\n        end\n      end.freeze\n    end", "label": 4}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo]) do\n        permit VALID_MILESTONE_INPUTS\n        assert_required %w[ title ]\n      end\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/milestones\", arguments.params)\n    end", "label": 4}
{"code": "def preprocess_text(text_string, function_list):\n    '''\n    Given each function within function_list, applies the order of functions put forward onto\n    text_string, returning the processed string as type str.\n\n    Keyword argument:\n\n    - function_list: list of functions available in preprocessing.text\n    - text_string: string instance\n\n    Exceptions raised:\n    \n    - FunctionError: occurs should an invalid function be passed within the list of functions\n    - InputError: occurs should text_string be non-string, or function_list be non-list\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        if isinstance(function_list, list):\n            for func in function_list:\n                try:\n                    text_string = func(text_string)\n                except (NameError, TypeError):\n                    raise FunctionError(\"invalid function passed as element of function_list\")\n                except:\n                    raise\n            return text_string\n        else:\n            raise InputError(\"list of functions not passed as argument for function_list\")\n    else:\n        raise InputError(\"string not passed as argument for text_string\")", "label": 1}
{"code": "def save\n      # If we have an id, just update our fields.\n      return update! if id\n\n      from_response client.post(\"/webhooks\", {\n        description: description,\n        idModel: id_model,\n        callbackURL: callback_url\n      })\n    end", "label": 4}
{"code": "def reflect_table(conn, table_name, schema='public'):\n    \"\"\"Reflect basic table attributes.\"\"\"\n\n    column_meta = list(get_column_metadata(conn, table_name, schema=schema))\n    primary_key_columns = list(get_primary_keys(conn, table_name, schema=schema))\n\n    columns = [Column(**column_data) for column_data in column_meta]\n    primary_key = PrimaryKey(primary_key_columns)\n\n    return Table(table_name, columns, primary_key, schema=schema)", "label": 1}
{"code": "function RotatingFileHandler(filename, mode, maxBytes, backupCount,\n                             encoding, delay) {\n\tmode = mode || 'a';\n\tmaxBytes = typeof maxBytes !== 'undefined' ? maxBytes : 0;\n\tbackupCount = typeof backupCount !== 'undefined' ? backupCount : 0;\n\tencoding = typeof encoding !== 'undefined' ? encoding : 'utf8';\n\tdelay = typeof delay !== 'undefined' ? delay : false;\n\n\tif (maxBytes > 0) {\n\t\tmode = 'a';\n\t}\n\n\tFileHandler.call(this, filename, mode, encoding, delay);\n\n\t/**\n\t * @private\n\t * @type {number}\n\t */\n\tthis._maxBytes = maxBytes;\n\n\t/**\n\t * @private\n\t * @type {number}\n\t */\n\tthis._backupCount = backupCount;\n\n\t/**\n\t * @private\n\t * @type {Promise}\n\t */\n\tthis._chain = Promise.resolve();\n}", "label": 3}
{"code": "public function setDatastoreOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\DatastoreOptions::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def render_next_step(self, form, **kwargs):\n        \"\"\"\n        When using the NamedUrlFormWizard, we have to redirect to update the\n        browser's URL to match the shown step.\n        \"\"\"\n        next_step = self.get_next_step()\n        self.storage.current_step = next_step\n        return redirect(self.url_name, step=next_step)", "label": 1}
{"code": "public Triple<Double, Integer, Integer> getAccuracyInfo()\r\n  {\r\n    int totalCorrect = tokensCorrect;\r\n    int totalWrong = tokensCount - tokensCorrect;\r\n    return new Triple<Double, Integer, Integer>((((double) totalCorrect) / tokensCount),\r\n            totalCorrect, totalWrong);\r\n  }", "label": 0}
{"code": "def current_branch(self):\n        \"\"\"Return the current branch name\"\"\"\n        branch_name = git(self.gitdir, self.gitwd, \"symbolic-ref\", \"HEAD\")\n        return branch_name.replace('refs/heads/', '').strip()", "label": 1}
{"code": "public function getLocation()\n    {\n        $location = $this->executor->execute(\n            DriverCommand::GET_ELEMENT_LOCATION,\n            [':id' => $this->id]\n        );\n\n        return new WebDriverPoint($location['x'], $location['y']);\n    }", "label": 2}
{"code": "def diff(*args)\n      args.unshift(parents.first) if args.size == 1 && args.first.is_a?(Hash)\n      self.tree.diff(*args)\n    end", "label": 4}
{"code": "func (ctrl *Controller) Finish() {\n\tctrl.T.Helper()\n\n\tctrl.mu.Lock()\n\tdefer ctrl.mu.Unlock()\n\n\tif ctrl.finished {\n\t\tctrl.T.Fatalf(\"Controller.Finish was called more than once. It has to be called exactly once.\")\n\t}\n\tctrl.finished = true\n\n\t// If we're currently panicking, probably because this is a deferred call,\n\t// pass through the panic.\n\tif err := recover(); err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Check that all remaining expected calls are satisfied.\n\tfailures := ctrl.expectedCalls.Failures()\n\tfor _, call := range failures {\n\t\tctrl.T.Errorf(\"missing call(s) to %v\", call)\n\t}\n\tif len(failures) != 0 {\n\t\tctrl.T.Fatalf(\"aborting test due to missing call(s)\")\n\t}\n}", "label": 5}
{"code": "public function diffInRealMicroseconds($date = null, $absolute = true)\n    {\n        /** @var CarbonInterface $date */\n        $date = $this->resolveCarbon($date);\n        $value = ($date->timestamp - $this->timestamp) * static::MICROSECONDS_PER_SECOND +\n            $date->micro - $this->micro;\n\n        return $absolute ? abs($value) : $value;\n    }", "label": 2}
{"code": "public function setCropHintsParams($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\CropHintsParams::class);\n        $this->crop_hints_params = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "@ArgumentsChecked\n\t@Throws({ IllegalNullArgumentException.class, IllegalNumberArgumentException.class })\n\tpublic static void isNumber(final boolean condition, @Nonnull final String value) {\n\t\tif (condition) {\n\t\t\tCheck.isNumber(value);\n\t\t}\n\t}", "label": 0}
{"code": "def inject_provisional_community(sender, json=None, record=None, index=None,\n                                 **kwargs):\n    \"\"\"Inject 'provisional_communities' key to ES index.\"\"\"\n    if index and not index.startswith(\n            current_app.config['COMMUNITIES_INDEX_PREFIX']):\n        return\n\n    json['provisional_communities'] = list(sorted([\n        r.id_community for r in InclusionRequest.get_by_record(record.id)\n    ]))", "label": 1}
{"code": "def extract_options(args)\n      options = args.last\n      options.respond_to?(:to_hash) ? options.to_hash.dup : {}\n    end", "label": 4}
{"code": "public void setObjectForStatement(PreparedStatement ps, int index,\r\n                                      Object value, int sqlType) throws SQLException\r\n    {\r\n        if (sqlType == Types.TINYINT)\r\n        {\r\n            ps.setByte(index, ((Byte) value).byteValue());\r\n        }\r\n        else\r\n        {\r\n            super.setObjectForStatement(ps, index, value, sqlType);\r\n        }\r\n    }", "label": 0}
{"code": "func (i *TeleInstance) AddUserWithRole(username string, role services.Role) *User {\n\tuser := &User{\n\t\tUsername: username,\n\t\tRoles:    []services.Role{role},\n\t}\n\ti.Secrets.Users[username] = user\n\treturn user\n}", "label": 5}
{"code": "def update_modifier_list(location_id, modifier_list_id, body, opts = {})\n      data, _status_code, _headers = update_modifier_list_with_http_info(location_id, modifier_list_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "private function configureAuthentication(array $config)\n    {\n        $config['keyFile'] = $this->getKeyFile($config);\n        $this->projectId = $this->detectProjectId($config);\n\n        return $config;\n    }", "label": 2}
{"code": "function(modulesPath, viewsPath, areasPath) {\n            modulesPath = modulesPath || 'viewmodels';\n            viewsPath = viewsPath || 'views';\n            areasPath = areasPath || viewsPath;\n\n            var reg = new RegExp(escape(modulesPath), 'gi');\n\n            this.convertModuleIdToViewId = function (moduleId) {\n                return moduleId.replace(reg, viewsPath);\n            };\n\n            this.translateViewIdToArea = function (viewId, area) {\n                if (!area || area == 'partial') {\n                    return areasPath + '/' + viewId;\n                }\n                \n                return areasPath + '/' + area + '/' + viewId;\n            };\n        }", "label": 3}
{"code": "public function setInspectResult($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\InspectResult::class);\n        $this->inspect_result = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setUsed($name)\n    {\n        $module = $this->findOrFail($name);\n\n        $this->app['files']->put($this->getUsedStoragePath(), $module);\n    }", "label": 2}
{"code": "def parse_datetime(value):\n    \"\"\"Attempts to parse `value` into an instance of ``datetime.datetime``. If\n    `value` is ``None``, this function will return ``None``.\n\n    Args:\n        value: A timestamp. This can be a string or datetime.datetime value.\n\n    \"\"\"\n    if not value:\n        return None\n    elif isinstance(value, datetime.datetime):\n        return value\n    return dateutil.parser.parse(value)", "label": 1}
{"code": "def stop(self, message):\n        \"\"\"\n        Manually stops timer with the message.\n\n        :param message:  The display message.\n        \"\"\"\n        self._stop = time.clock()\n        VSGLogger.info(\"{0:<20} - Finished [{1}s]\".format(message, self.pprint(self._stop - self._start)))", "label": 1}
{"code": "public function setFilter($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\ExistenceFilter::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def input_has_value(step, field_name, value):\n    \"\"\"\n    Check that the form input element has given value.\n    \"\"\"\n    with AssertContextManager(step):\n        text_field = find_any_field(world.browser,\n                                    DATE_FIELDS + TEXT_FIELDS,\n                                    field_name)\n        assert_false(step, text_field is False,\n                     'Can not find a field named \"%s\"' % field_name)\n        assert_equals(text_field.get_attribute('value'), value)", "label": 1}
{"code": "public function createTransaction(Session $session, array $res = [], array $options = [])\n    {\n        $res += [\n            'id' => null\n        ];\n\n        $options['isRetry'] = isset($options['isRetry'])\n            ? $options['isRetry']\n            : false;\n\n        return new Transaction($this, $session, $res['id'], $options['isRetry']);\n    }", "label": 2}
{"code": "public static function error_to_string( $errors ) {\n\t\tif ( is_string( $errors ) ) {\n\t\t\treturn $errors;\n\t\t}\n\n\t\t// Only json_encode() the data when it needs it\n\t\t$render_data = function( $data ) {\n\t\t\tif ( is_array( $data ) || is_object( $data ) ) {\n\t\t\t\treturn json_encode( $data );\n\t\t\t}\n\n\t\t\treturn '\"' . $data . '\"';\n\t\t};\n\n\t\tif ( is_object( $errors ) && is_a( $errors, 'WP_Error' ) ) {\n\t\t\tforeach ( $errors->get_error_messages() as $message ) {\n\t\t\t\tif ( $errors->get_error_data() ) {\n\t\t\t\t\treturn $message . ' ' . $render_data( $errors->get_error_data() );\n\t\t\t\t}\n\n\t\t\t\treturn $message;\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "func NewHostCertificateManager(c *vim25.Client, ref types.ManagedObjectReference, host types.ManagedObjectReference) *HostCertificateManager {\n\treturn &HostCertificateManager{\n\t\tCommon: NewCommon(c, ref),\n\t\tHost:   NewHostSystem(c, host),\n\t}\n}", "label": 5}
{"code": "def routes(&block)\n      @routes ||= ActionDispatch::Routing::RouteSet.new_with_config(config)\n      @routes.append(&block) if block_given?\n      @routes\n    end", "label": 4}
{"code": "func (nDB *NetworkDB) addNetworkNode(nid string, nodeName string) {\n\tnodes := nDB.networkNodes[nid]\n\tfor _, node := range nodes {\n\t\tif node == nodeName {\n\t\t\treturn\n\t\t}\n\t}\n\n\tnDB.networkNodes[nid] = append(nDB.networkNodes[nid], nodeName)\n}", "label": 5}
{"code": "func PgLanguageByLanname(db XODB, lanname pgtypes.Name) (*PgLanguage, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, lanname, lanowner, lanispl, lanpltrusted, lanplcallfoid, laninline, lanvalidator, lanacl ` +\n\t\t`FROM pg_catalog.pg_language ` +\n\t\t`WHERE lanname = $1`\n\n\t// run query\n\tXOLog(sqlstr, lanname)\n\tpl := PgLanguage{}\n\n\terr = db.QueryRow(sqlstr, lanname).Scan(&pl.Tableoid, &pl.Cmax, &pl.Xmax, &pl.Cmin, &pl.Xmin, &pl.Oid, &pl.Ctid, &pl.Lanname, &pl.Lanowner, &pl.Lanispl, &pl.Lanpltrusted, &pl.Lanplcallfoid, &pl.Laninline, &pl.Lanvalidator, &pl.Lanacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pl, nil\n}", "label": 5}
{"code": "def make_hop_info_from_url(url, verify_reachability=None):\n    \"\"\"Build HopInfo object from url.\n\n    It allows only telnet and ssh as a valid protocols.\n\n    Args:\n        url (str): The url string describing the node. i.e.\n            telnet://username@1.1.1.1. The protocol, username and address\n            portion of url is mandatory. Port and password is optional.\n            If port is missing the standard protocol -> port mapping is done.\n            The password is optional i.e. for TS access directly to console\n            ports.\n            The path part is treated as additional password required for some\n            systems, i.e. enable password for IOS devices.:\n            telnet://<username>:<password>@<host>:<port>/<enable_password>\n            <enable_password> is optional\n\n        verify_reachability: This is optional callable returning boolean\n            if node is reachable. It can be used to verify reachability\n            of the node before making a connection. It can speedup the\n            connection process when node not reachable especially with\n            telnet having long timeout.\n\n    Returns:\n        HopInfo object or None if url is invalid or protocol not supported\n\n    \"\"\"\n    parsed = urlparse(url)\n    username = None if parsed.username is None else unquote(parsed.username)  # It's None if not exists\n    password = None if parsed.password is None else unquote(parsed.password)  # It's None if not exists\n\n    try:\n        enable_password = parse_qs(parsed.query)[\"enable_password\"][0]\n    except KeyError:\n        enable_password = None\n\n    hop_info = HopInfo(\n        parsed.scheme,\n        parsed.hostname,\n        username,\n        password,\n        parsed.port,\n        enable_password,\n        verify_reachability=verify_reachability\n    )\n    if hop_info.is_valid():\n        return hop_info\n    raise InvalidHopInfoError", "label": 1}
{"code": "def arrays(self, field_name=None):\n        \"\"\"Returns a list of ndarrays.\n\n        Keyword args:\n        field_name -- raster field name as str\n        \"\"\"\n        fieldname = field_name or self.raster_field.name\n        arrays = []\n        for obj in self:\n            arr = getattr(obj, fieldname)\n            if isinstance(arr, np.ndarray):\n                arrays.append(arr)\n            else:\n                arrays.append(obj.array())\n        return arrays", "label": 1}
{"code": "def run(&block)\n      start\n      begin\n        yield\n      rescue Exception\n        ObjectSpace.trace_object_allocations_stop\n        GC.enable\n        raise\n      else\n        stop\n      end\n    end", "label": 4}
{"code": "def delete(self):\n        \"\"\"Mark the community for deletion.\n\n        :param delete_time: DateTime after which to delete the community.\n        :type delete_time: datetime.datetime\n        :raises: CommunitiesError\n        \"\"\"\n        if self.deleted_at is not None:\n            raise CommunitiesError(community=self)\n        else:\n            self.deleted_at = datetime.utcnow()", "label": 1}
{"code": "def request(verb, uri, opts = {}) # rubocop:disable Style/OptionHash\n      opts = @default_options.merge(opts)\n      req = build_request(verb, uri, opts)\n      res = perform(req, opts)\n      return res unless opts.follow\n\n      Redirector.new(opts.follow).perform(req, res) do |request|\n        perform(request, opts)\n      end\n    end", "label": 4}
{"code": "func (h *portForwardProxy) portForward(p *httpStreamPair) {\n\tdefer p.dataStream.Close()\n\tdefer p.errorStream.Close()\n\n\tportString := p.dataStream.Headers().Get(PortHeader)\n\tport, _ := strconv.ParseInt(portString, 10, 32)\n\n\th.Debugf(\"Forwrarding port %v -> %v.\", p.requestID, portString)\n\terr := h.forwardStreamPair(p, port)\n\th.Debugf(\"Completed forwrarding port %v -> %v.\", p.requestID, portString)\n\n\tif err != nil {\n\t\tmsg := fmt.Errorf(\"error forwarding port %d to pod %s: %v\", port, h.podName, err)\n\t\tfmt.Fprint(p.errorStream, msg.Error())\n\t}\n}", "label": 5}
{"code": "def main():\n    \"\"\"\n    This is the main function for the UCSC Precision Immuno pipeline.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--config_file', dest='config_file', help='Config file to be used in the' +\n                        'run.', type=str, required=True, default=None)\n    Job.Runner.addToilOptions(parser)\n    params = parser.parse_args()\n    START = Job.wrapJobFn(parse_config_file, params.config_file).encapsulate()\n    Job.Runner.startToil(START, params)\n    return None", "label": 1}
{"code": "def color(string, status=True, warning=False, bold=True):\n    \"\"\"\n    Change text color for the linux terminal, defaults to green.\n    Set \"warning=True\" for red.\n    \"\"\"\n    attr = []\n    if status:\n        # green\n        attr.append('32')\n    if warning:\n        # red\n        attr.append('31')\n    if bold:\n        attr.append('1')\n    return '\\x1b[%sm%s\\x1b[0m' % (';'.join(attr), string)", "label": 1}
{"code": "public void printProbs(String filename,\r\n                         DocumentReaderAndWriter<IN> readerAndWriter) {\r\n    // only for the OCR data does this matter\r\n    flags.ocrTrain = false;\r\n\r\n    ObjectBank<List<IN>> docs =\r\n      makeObjectBankFromFile(filename, readerAndWriter);\r\n    printProbsDocuments(docs);\r\n  }", "label": 0}
{"code": "def find_lib(lib):\n\tr\"\"\"\n\tFind the DLL for a given library.\n\n\tAccepts a string or loaded module\n\n\t>>> print(find_lib('kernel32').lower())\n\tc:\\windows\\system32\\kernel32.dll\n\t\"\"\"\n\tif isinstance(lib, str):\n\t\tlib = getattr(ctypes.windll, lib)\n\n\tsize = 1024\n\tresult = ctypes.create_unicode_buffer(size)\n\tlibrary.GetModuleFileName(lib._handle, result, size)\n\treturn result.value", "label": 1}
{"code": "def instantiate(data, blueprint):\n    \"\"\"\n    Instantiate the given data using the blueprinter.\n\n    Arguments\n    ---------\n\n        blueprint (collections.Mapping):\n\n            a blueprint (JSON Schema with Seep properties)\n    \"\"\"\n\n    Validator = jsonschema.validators.validator_for(blueprint)\n    blueprinter = extend(Validator)(blueprint)\n    return blueprinter.instantiate(data)", "label": 1}
{"code": "public void addSubmodule(final Module submodule) {\n        if (!submodules.contains(submodule)) {\n            submodule.setSubmodule(true);\n\n            if (promoted) {\n                submodule.setPromoted(promoted);\n            }\n\n            submodules.add(submodule);\n        }\n    }", "label": 0}
{"code": "public static appfwpolicy_stats get(nitro_service service, String name) throws Exception{\n\t\tappfwpolicy_stats obj = new appfwpolicy_stats();\n\t\tobj.set_name(name);\n\t\tappfwpolicy_stats response = (appfwpolicy_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (s *Config) CheckAndSetDefaults() error {\n\tif s.Directory == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter Directory\")\n\t}\n\tif !utils.IsDir(s.Directory) {\n\t\treturn trace.BadParameter(\"path %q does not exist or is not a directory\", s.Directory)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "final public Boolean checkRealOffset() {\n    if ((tokenRealOffset == null) || !provideRealOffset) {\n      return false;\n    } else if (tokenOffset == null) {\n      return true;\n    } else if (tokenOffset.getStart() == tokenRealOffset.getStart()\n        && tokenOffset.getEnd() == tokenRealOffset.getEnd()) {\n      return false;\n    } else {\n      return true;\n    }\n  }", "label": 0}
{"code": "func (r *Linear) Duration() time.Duration {\n\ta := r.First + time.Duration(r.attempt)*r.Step\n\tif a < 0 {\n\t\treturn 0\n\t}\n\tif a <= r.Max {\n\t\treturn a\n\t}\n\treturn r.Max\n}", "label": 5}
{"code": "public function setSecurityCenterProperties($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\SecurityCenter\\V1\\Asset_SecurityCenterProperties::class);\n        $this->security_center_properties = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function slug($slug = null): self\n    {\n        if (! empty($slug)) {\n            // set this slug to be used in with callback\n            $this->slug = $slug;\n\n            // exception to filter on specific slug\n            $exception = function ($query) {\n                $query->where('slug', '=', $this->slug);\n            };\n\n            // load term to filter\n            return $this->whereHas('term', $exception);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "private function validateAbstractSchemaName($schemaName) : void\n    {\n        if (class_exists($schemaName, true) || interface_exists($schemaName, true)) {\n            return;\n        }\n\n        try {\n            $this->getEntityManager()->getClassMetadata($schemaName);\n\n            return;\n        } catch (MappingException $mappingException) {\n            $this->semanticalError(\n                sprintf('Class %s could not be mapped', $schemaName),\n                $this->lexer->token\n            );\n        }\n\n        $this->semanticalError(sprintf(\"Class '%s' is not defined.\", $schemaName), $this->lexer->token);\n    }", "label": 2}
{"code": "function nameVersionInstallStrategy(baseDir) {\n\treturn (name, version) => {\n\t\tif (!version) {\n\t\t\tthrow Error('hey I need a version!');\n\t\t}\n\t\t// todo - should probably instead instantiate the appropriate library repository\n\t\t// so we get reuse and consistency\n\t\treturn path.join(baseDir, name+'@'+version);\n\t};\n}", "label": 3}
{"code": "function VarianceFunction(win) {\n  var self = this, m, m2, d, n;\n  self.name = \"vars\";\n  self.type = \"simple\";\n  self.init = function() { m = 0; m2 = 0; d = 0; n = 0; };\n  self.accumulate = function(v) { n+=1; d = v - m; m = d/n + m; m2 = m2 + d*(v - m); };\n  self.compensate = function(v) { n-=1; d = m - v; m = m + d/n; m2 = d*(v - m) + m2; };\n  self.emit = function()  { return m2/(n-1); };\n  self.make = function(win) { return new VarianceFunction(win); };\n}", "label": 3}
{"code": "public static ComplexNumber Multiply(ComplexNumber z1, double scalar) {\r\n        return new ComplexNumber(z1.real * scalar, z1.imaginary * scalar);\r\n    }", "label": 0}
{"code": "func MustCreateTunnelConnection(name string, spec TunnelConnectionSpecV2) TunnelConnection {\n\tconn, err := NewTunnelConnection(name, spec)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn conn\n}", "label": 5}
{"code": "function parseString(xml, cb) {\n    return fastxml2js.parseString(xml, function(err, data) {\n        //So that it's asynchronous\n        process.nextTick(function() {\n            cb(err, data);\n        });\n    });\n}", "label": 3}
{"code": "def goto(uri)\n      uri = \"http://#{uri}\" unless uri =~ URI::DEFAULT_PARSER.make_regexp\n\n      @driver.navigate.to uri\n      @after_hooks.run\n\n      uri\n    end", "label": 4}
{"code": "def repackage(path)\n      @logger.debug(\"Repackaging box '#{@name}' to: #{path}\")\n\n      Util::SafeChdir.safe_chdir(@directory) do\n        # Find all the files in our current directory and tar it up!\n        files = Dir.glob(File.join(\".\", \"**\", \"*\")).select { |f| File.file?(f) }\n\n        # Package!\n        Util::Subprocess.execute(\"bsdtar\", \"-czf\", path.to_s, *files)\n      end\n\n      @logger.info(\"Repackaged box '#{@name}' successfully: #{path}\")\n\n      true\n    end", "label": 4}
{"code": "function (criteria) {\n            var identity = this.identity;\n\n            return this.findOne(criteria).then(function (record) {\n                if (!record) {\n                    throw new Errors.NotFoundError(\n                        'Could not find %s with criteria %j.'.format(\n                            pluralize.singular(identity),\n                            criteria\n                        ), {\n                            criteria: criteria,\n                            collection: identity\n                        });\n                }\n\n                return record;\n            });\n        }", "label": 3}
{"code": "def save(self, fname=''):\n        \"\"\"\n        Save the list of tools to AIKIF core and optionally to local file fname\n        \"\"\"\n        if fname != '':\n            with open(fname, 'w') as f:\n                for t in self.lstTools:\n                    self.verify(t)\n                    f.write(self.tool_as_string(t))", "label": 1}
{"code": "function applyContrastColors(config) {\n  const { colors } = config;\n\n  return {\n    ...config,\n    colors: {\n      ...colors,\n      primaryContrast: getContrastColor(colors.primary, colors),\n      accentContrast: getContrastColor(colors.accent, colors),\n      focus: getFocusColor(colors),\n    },\n  };\n}", "label": 3}
{"code": "function findUser(user, options) {\n  options = _.opts(options, {refresh: true, throwIfNotFound: true});\n  if (_.isString(user) && user.match(/^[0-9]+$/)) {\n    user = parseInt(user, 10);\n  }\n  return _findUser(user, options);\n}", "label": 3}
{"code": "public function setPosition($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\Position::class);\n        $this->position = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def finish\n    # Call post_compile hook on every parameter that implements it. This includes all subclasses\n    # of parameter including, but not limited to, regular parameters, metaparameters, relationship\n    # parameters, and properties.\n    eachparameter do |parameter|\n      parameter.post_compile if parameter.respond_to? :post_compile\n    end\n\n    # Make sure all of our relationships are valid.  Again, must be done\n    # when the entire catalog is instantiated.\n    self.class.relationship_params.collect do |klass|\n      if param = @parameters[klass.name]\n        param.validate_relationship\n      end\n    end.flatten.reject { |r| r.nil? }\n  end", "label": 4}
{"code": "public function getFullIsoName(): string\n    {\n        if (!$this->isoName) {\n            $this->isoName = $this->getNames()['isoName'];\n        }\n\n        return $this->isoName;\n    }", "label": 2}
{"code": "public function findOrFail($id, User $actor = null)\n    {\n        $query = Group::where('id', $id);\n\n        return $this->scopeVisibleTo($query, $actor)->firstOrFail();\n    }", "label": 2}
{"code": "def bind(var, typ, force: false)\n      raise RuntimeError, \"Can't update variable with fixed type\" if !force && @env[var] && @env[var][:fixed]\n      result = Env.new\n      result.env = @env.merge(var => {type: typ, fixed: false})\n      return result\n    end", "label": 4}
{"code": "def resize_frame!\n      screenshot_width = self.screenshot.portrait? ? screenshot.size[0] : screenshot.size[1]\n\n      multiplicator = (screenshot_width.to_f / offset['width'].to_f) # by how much do we have to change this?\n      new_frame_width = multiplicator * frame.width # the new width for the frame\n      frame.resize(\"#{new_frame_width.round}x\") # resize it to the calculated width\n      modify_offset(multiplicator) # modify the offset to properly insert the screenshot into the frame later\n    end", "label": 4}
{"code": "function (err) {\n      log.error(\"Redis client closed \" + (err ? err.message : ''));\n      this.connected = false;\n      this.emit('close', err);\n      this.backoff.reset();\n      this.backoff.backoff();\n    }", "label": 3}
{"code": "public String getDefaultTableName()\r\n    {\r\n        String name          = getName();\r\n        int    lastDotPos    = name.lastIndexOf('.');\r\n        int    lastDollarPos = name.lastIndexOf('$');\r\n\r\n        return lastDollarPos > lastDotPos ? name.substring(lastDollarPos + 1) : name.substring(lastDotPos + 1);\r\n    }", "label": 0}
{"code": "func (t *FpdfTpl) GobDecode(buf []byte) error {\n\tr := bytes.NewBuffer(buf)\n\tdecoder := gob.NewDecoder(r)\n\n\tfirstClassTemplates := make([]*FpdfTpl, 0)\n\terr := decoder.Decode(&firstClassTemplates)\n\tt.templates = make([]Template, len(firstClassTemplates))\n\n\tfor x := 0; x < len(t.templates); x++ {\n\t\tt.templates[x] = Template(firstClassTemplates[x])\n\t}\n\n\tfirstClassImages := t.childrenImages()\n\n\tt.templates = append(t.childrensTemplates(), t.templates...)\n\n\tt.images = make(map[string]*ImageInfoType)\n\tif err == nil {\n\t\terr = decoder.Decode(&t.images)\n\t}\n\n\tfor k, v := range firstClassImages {\n\t\tt.images[k] = v\n\t}\n\n\tif err == nil {\n\t\terr = decoder.Decode(&t.corner)\n\t}\n\tif err == nil {\n\t\terr = decoder.Decode(&t.size)\n\t}\n\tif err == nil {\n\t\terr = decoder.Decode(&t.bytes)\n\t}\n\tif err == nil {\n\t\terr = decoder.Decode(&t.page)\n\t}\n\n\treturn err\n}", "label": 5}
{"code": "func copyAppManifest(cdir string, appName types.ACName, dest string) error {\n\tappInfoDir := common.AppInfoPath(cdir, appName)\n\tsourceFn := filepath.Join(appInfoDir, \"manifest\")\n\tdestFn := filepath.Join(dest, \"manifest\")\n\tif err := fileutil.CopyRegularFile(sourceFn, destFn); err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"error copying image manifest\"), err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static Chart getMSDLineWithPowerModelChart(Trajectory t, int lagMin,\n\t\t\tint lagMax, double timelag, double a, double D) {\n\n\t\tdouble[] xData = new double[lagMax - lagMin + 1];\n\t\tdouble[] yData = new double[lagMax - lagMin + 1];\n\t\tdouble[] modelData = new double[lagMax - lagMin + 1];\n\t\tMeanSquaredDisplacmentFeature msdeval = new MeanSquaredDisplacmentFeature(\n\t\t\t\tt, lagMin);\n\t\tmsdeval.setTrajectory(t);\n\t\tmsdeval.setTimelag(lagMin);\n\t\tfor (int i = lagMin; i < lagMax + 1; i++) {\n\t\t\tmsdeval.setTimelag(i);\n\t\t\tdouble msdhelp = msdeval.evaluate()[0];\n\t\t\txData[i - lagMin] = i;\n\t\t\tyData[i - lagMin] = msdhelp;\n\t\t\tmodelData[i - lagMin] = 4 * D * Math.pow(i * timelag, a);\n\t\t}\n\n\t\t// Create Chart\n\t\tChart chart = QuickChart.getChart(\"MSD Line\", \"LAG\", \"MSD\", \"MSD\",\n\t\t\t\txData, yData);\n\t\tchart.addSeries(\"y=4*D*t^alpha\", xData, modelData);\n\n\t\t// Show it\n\t\t//new SwingWrapper(chart).displayChart();\n\t\treturn chart;\n\t}", "label": 0}
{"code": "public static List<CompiledAutomaton> createAutomata(String prefix,\n      String regexp, Map<String, Automaton> automatonMap) throws IOException {\n    List<CompiledAutomaton> list = new ArrayList<>();\n    Automaton automatonRegexp = null;\n    if (regexp != null) {\n      RegExp re = new RegExp(prefix + MtasToken.DELIMITER + regexp + \"\\u0000*\");\n      automatonRegexp = re.toAutomaton();\n    }\n    int step = 500;\n    List<String> keyList = new ArrayList<>(automatonMap.keySet());\n    for (int i = 0; i < keyList.size(); i += step) {\n      int localStep = step;\n      boolean success = false;\n      CompiledAutomaton compiledAutomaton = null;\n      while (!success) {\n        success = true;\n        int next = Math.min(keyList.size(), i + localStep);\n        List<Automaton> listAutomaton = new ArrayList<>();\n        for (int j = i; j < next; j++) {\n          listAutomaton.add(automatonMap.get(keyList.get(j)));\n        }\n        Automaton automatonList = Operations.union(listAutomaton);\n        Automaton automaton;\n        if (automatonRegexp != null) {\n          automaton = Operations.intersection(automatonList, automatonRegexp);\n        } else {\n          automaton = automatonList;\n        }\n        try {\n          compiledAutomaton = new CompiledAutomaton(automaton);\n        } catch (TooComplexToDeterminizeException e) {\n          log.debug(e);\n          success = false;\n          if (localStep > 1) {\n            localStep /= 2;\n          } else {\n            throw new IOException(\"TooComplexToDeterminizeException\");\n          }\n        }\n      }\n      list.add(compiledAutomaton);\n    }\n    return list;\n  }", "label": 0}
{"code": "@SuppressWarnings(\"unchecked\")\n    public <T> DistributedFuture<GROUP, T> createFuture(HazeltaskTask<GROUP> task) {\n        DistributedFuture<GROUP, T> future = new DistributedFuture<GROUP, T>(topologyService, task.getGroup(), task.getId());\n        this.futures.put(task.getId(), (DistributedFuture<GROUP, Serializable>) future);\n        return future;\n    }", "label": 0}
{"code": "public static base_response disable(nitro_service client, nsmode resource) throws Exception {\n\t\tnsmode disableresource = new nsmode();\n\t\tdisableresource.mode = resource.mode;\n\t\treturn disableresource.perform_operation(client,\"disable\");\n\t}", "label": 0}
{"code": "def plugin_files_by_dir(plugin_dir = Ohai.config[:plugin_path])\n      Array(plugin_dir).map do |path|\n        if Dir.exist?(path)\n          Ohai::Log.trace(\"Searching for Ohai plugins in #{path}\")\n\n          escaped = ChefConfig::PathHelper.escape_glob_dir(path)\n          Dir[File.join(escaped, \"**\", \"*.rb\")]\n        else\n          Ohai::Log.debug(\"The plugin path #{path} does not exist. Skipping...\")\n          []\n        end\n      end.flatten\n    end", "label": 4}
{"code": "public void deleteById(String id) {\n    if (idToVersion.containsKey(id)) {\n      String version = idToVersion.remove(id);\n      expirationVersion.remove(version);\n      versionToItem.remove(version);\n      if (collectionCachePath != null\n          && !collectionCachePath.resolve(version).toFile().delete()) {\n        log.debug(\"couldn't delete \" + version);\n      }\n    }\n  }", "label": 0}
{"code": "public function insertRows(array $rows, array $options = [])\n    {\n        if (count($rows) === 0) {\n            throw new \\InvalidArgumentException('Must provide at least a single row.');\n        }\n\n        foreach ($rows as $row) {\n            if (!isset($row['data'])) {\n                throw new \\InvalidArgumentException('A row must have a data key.');\n            }\n\n            if (!isset($options['retries']) && !isset($row['insertId'])) {\n                $options['retries'] = 0;\n            }\n\n            foreach ($row['data'] as $key => $item) {\n                $row['data'][$key] = $this->mapper->toBigQuery($item);\n            }\n\n            $row['json'] = $row['data'];\n            unset($row['data']);\n            $options['rows'][] = $row;\n        }\n\n        return new InsertResponse(\n            $this->handleInsert($options),\n            $options['rows']\n        );\n    }", "label": 2}
{"code": "public static base_responses add(nitro_service client, onlinkipv6prefix resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tonlinkipv6prefix addresources[] = new onlinkipv6prefix[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new onlinkipv6prefix();\n\t\t\t\taddresources[i].ipv6prefix = resources[i].ipv6prefix;\n\t\t\t\taddresources[i].onlinkprefix = resources[i].onlinkprefix;\n\t\t\t\taddresources[i].autonomusprefix = resources[i].autonomusprefix;\n\t\t\t\taddresources[i].depricateprefix = resources[i].depricateprefix;\n\t\t\t\taddresources[i].decrementprefixlifetimes = resources[i].decrementprefixlifetimes;\n\t\t\t\taddresources[i].prefixvalidelifetime = resources[i].prefixvalidelifetime;\n\t\t\t\taddresources[i].prefixpreferredlifetime = resources[i].prefixpreferredlifetime;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setSynonyms($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->synonyms = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static dnstxtrec[] get(nitro_service service, String domain[]) throws Exception{\n\t\tif (domain !=null && domain.length>0) {\n\t\t\tdnstxtrec response[] = new dnstxtrec[domain.length];\n\t\t\tdnstxtrec obj[] = new dnstxtrec[domain.length];\n\t\t\tfor (int i=0;i<domain.length;i++) {\n\t\t\t\tobj[i] = new dnstxtrec();\n\t\t\t\tobj[i].set_domain(domain[i]);\n\t\t\t\tresponse[i] = (dnstxtrec) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public static rewriteglobal_binding get(nitro_service service) throws Exception{\n\t\trewriteglobal_binding obj = new rewriteglobal_binding();\n\t\trewriteglobal_binding response = (rewriteglobal_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (d *Decoder) RawToken() (Token, error) {\n\tif d.unmarshalDepth > 0 {\n\t\treturn nil, errRawToken\n\t}\n\treturn d.rawToken()\n}", "label": 5}
{"code": "function(obj) {\r\n    if (obj.anchor) {\r\n      // obj is a plane or line\r\n      var P = this.elements.slice();\r\n      var C = obj.pointClosestTo(P).elements;\r\n      return Vector.create([C[0] + (C[0] - P[0]), C[1] + (C[1] - P[1]), C[2] + (C[2] - (P[2] || 0))]);\r\n    } else {\r\n      // obj is a point\r\n      var Q = obj.elements || obj;\r\n      if (this.elements.length != Q.length) { return null; }\r\n      return this.map(function(x, i) { return Q[i-1] + (Q[i-1] - x); });\r\n    }\r\n  }", "label": 3}
{"code": "def build_exclusive_url(url = nil, params = nil, params_encoder = nil)\n      url = nil if url.respond_to?(:empty?) && url.empty?\n      base = url_prefix\n      if url && base.path && base.path !~ %r{/$}\n        base = base.dup\n        base.path = base.path + '/' # ensure trailing slash\n      end\n      uri = url ? base + url : base\n      if params\n        uri.query = params.to_query(params_encoder || options.params_encoder)\n      end\n      # rubocop:disable Style/SafeNavigation\n      uri.query = nil if uri.query && uri.query.empty?\n      # rubocop:enable Style/SafeNavigation\n      uri\n    end", "label": 4}
{"code": "function mappingMembers(mapping) {\n  const { from, to } = mapping\n  const memberUris = [ from, to ].filter(Boolean)\n    .map(bundle => reduceSet(bundle[memberField(bundle)] || []))\n  return [].concat(...memberUris).sort()\n}", "label": 3}
{"code": "public function apply($builder, array $args)\n    {\n        /*\n         * Call the queryFilter for backwards compatibility\n         * @deprecated\n         */\n        $this->queryFilter->filter($builder, $args);\n\n        foreach ($args as $key => $value) {\n            /** @var \\Nuwave\\Lighthouse\\Support\\Contracts\\ArgBuilderDirective $builderDirective */\n            if ($builderDirective = Arr::get($this->builderDirectives, $key)) {\n                $builder = $builderDirective->handleBuilder($builder, $value);\n            }\n        }\n\n        foreach ($this->scopes as $scope) {\n            call_user_func([$builder, $scope], $args);\n        }\n\n        return $builder;\n    }", "label": 2}
{"code": "def predict_mhcii_binding(job, peptfile, allele, univ_options, mhcii_options):\n    \"\"\"\n    Predict binding for each peptide in `peptfile` to `allele` using the IEDB mhcii binding\n    prediction tool.\n\n    :param toil.fileStore.FileID peptfile: The input peptide fasta\n    :param str allele: Allele to predict binding against\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict mhcii_options: Options specific to mhcii binding prediction\n    :return: tuple of fsID for file containing the predictions and the predictor used\n    :rtype: tuple(toil.fileStore.FileID, str|None)\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'peptfile.faa': peptfile}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    peptides = read_peptide_file(os.path.join(os.getcwd(), 'peptfile.faa'))\n    parameters = [mhcii_options['pred'],\n                  allele,\n                  input_files['peptfile.faa']]\n    if not peptides:\n        return job.fileStore.writeGlobalFile(job.fileStore.getLocalTempFile()), None\n    with open('/'.join([work_dir, 'predictions.tsv']), 'w') as predfile:\n        docker_call(tool='mhcii', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=predfile, interactive=True,\n                    tool_version=mhcii_options['version'])\n    run_netmhciipan = True\n    predictor = None\n    with open(predfile.name, 'r') as predfile:\n        for line in predfile:\n            if not line.startswith('HLA'):\n                continue\n            if line.strip().split('\\t')[5] == 'NetMHCIIpan':\n                break\n            # If the predictor type is sturniolo then it needs to be processed differently\n            elif line.strip().split('\\t')[5] == 'Sturniolo':\n                predictor = 'Sturniolo'\n            else:\n                predictor = 'Consensus'\n            run_netmhciipan = False\n            break\n    if run_netmhciipan:\n        netmhciipan = job.addChildJobFn(predict_netmhcii_binding, peptfile, allele, univ_options,\n                                        mhcii_options['netmhciipan'], disk='100M', memory='100M',\n                                        cores=1)\n        job.fileStore.logToMaster('Ran mhcii on %s:%s successfully'\n                                  % (univ_options['patient'], allele))\n        return netmhciipan.rv()\n    else:\n        output_file = job.fileStore.writeGlobalFile(predfile.name)\n        job.fileStore.logToMaster('Ran mhcii on %s:%s successfully'\n                                  % (univ_options['patient'], allele))\n        return output_file, predictor", "label": 1}
{"code": "func (t *TeleportClusterConfigMarshaler) Unmarshal(bytes []byte, opts ...MarshalOption) (ClusterConfig, error) {\n\tvar clusterConfig ClusterConfigV3\n\n\tif len(bytes) == 0 {\n\t\treturn nil, trace.BadParameter(\"missing resource data\")\n\t}\n\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tif cfg.SkipValidation {\n\t\tif err := utils.FastUnmarshal(bytes, &clusterConfig); err != nil {\n\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t}\n\t} else {\n\t\terr = utils.UnmarshalWithSchema(GetClusterConfigSchema(\"\"), &clusterConfig, bytes)\n\t\tif err != nil {\n\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t}\n\t}\n\n\terr = clusterConfig.CheckAndSetDefaults()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tif cfg.ID != 0 {\n\t\tclusterConfig.SetResourceID(cfg.ID)\n\t}\n\tif !cfg.Expires.IsZero() {\n\t\tclusterConfig.SetExpiry(cfg.Expires)\n\t}\n\treturn &clusterConfig, nil\n}", "label": 5}
{"code": "function insertIntoDB() {\n                    lastQry = connection.query('INSERT INTO ?? SET ?', [req.params.table , insertJson] , function (err, rows) {\n                        if (err) {\n                            console.error(err);\n                            res.statusCode = 500;\n                            res.send({\n                                result: 'error',\n                                err: err.code\n                            });\n                        } else {\n                            sendSuccessAnswer(req.params.table , res, rows.insertId);\n                        }\n\n                    });\n                }", "label": 3}
{"code": "public static <E> Counter<E> toCounter(Map<Integer, ? extends Number> counts, Index<E> index) {\r\n\r\n    Counter<E> counter = new ClassicCounter<E>();\r\n    for (Map.Entry<Integer, ? extends Number> entry : counts.entrySet()) {\r\n      counter.setCount(index.get(entry.getKey()), entry.getValue().doubleValue());\r\n    }\r\n    return counter;\r\n  }", "label": 0}
{"code": "protected function exception(ConnectionInterface $connection, ErrorResponseInterface $response)\n    {\n        $connection->disconnect();\n        $message = $response->getMessage();\n\n        throw new ServerException($message);\n    }", "label": 2}
{"code": "function groupExists(group) {\n  if (isPlatform('windows')) {\n    throw new Error('Don\\'t know how to check for group existence on Windows');\n  } else {\n    if (_.isEmpty(findGroup(group, {refresh: true, throwIfNotFound: false}))) {\n      return false;\n    } else {\n      return true;\n    }\n  }\n}", "label": 3}
{"code": "def run_filter_radia(job, bams, radia_file, univ_options, radia_options, chrom):\n    \"\"\"\n    This module will run filterradia on the RNA and DNA bams.\n\n    ARGUMENTS\n    1. bams: REFER ARGUMENTS of run_radia()\n    2. univ_options: REFER ARGUMENTS of run_radia()\n    3. radia_file: <JSid of vcf generated by run_radia()>\n    3. radia_options: REFER ARGUMENTS of run_radia()\n    4. chrom: REFER ARGUMENTS of run_radia()\n\n    RETURN VALUES\n    1. Dict of filtered radia output vcf and logfile\n        |- 'radia_filtered_CHROM.vcf': <JSid>\n        +- 'radia_filtered_CHROM_radia.log': <JSid>\n    \"\"\"\n    job.fileStore.logToMaster('Running filter-radia on %s:%s' % (univ_options['patient'], chrom))\n    work_dir = job.fileStore.getLocalTempDir()\n    input_files = {\n        'rna.bam': bams['tumor_rna'],\n        'rna.bam.bai': bams['tumor_rnai'],\n        'tumor.bam': bams['tumor_dna'],\n        'tumor.bam.bai': bams['tumor_dnai'],\n        'normal.bam': bams['normal_dna'],\n        'normal.bam.bai': bams['normal_dnai'],\n        'radia.vcf': radia_file,\n        'genome.fasta': radia_options['genome_fasta'],\n        'genome.fasta.fai': radia_options['genome_fai']\n        }\n    input_files = get_files_from_filestore(job, input_files, work_dir,\n                                           docker=True)\n    filterradia_output = ''.join(['radia_filtered_', chrom, '.vcf'])\n    filterradia_log = ''.join([work_dir, '/radia_filtered_', chrom, '_radia.log'\n                              ])\n    parameters = [univ_options['patient'],  # shortID\n                  chrom.lstrip('chr'),\n                  input_files['radia.vcf'],\n                  '/data',\n                  '/home/radia/scripts',\n                  '-b', '/home/radia/data/hg19/blacklists/1000Genomes/phase1/',\n                  '-d', '/home/radia/data/hg19/snp135',\n                  '-r', '/home/radia/data/hg19/retroGenes/',\n                  '-p', '/home/radia/data/hg19/pseudoGenes/',\n                  '-c', '/home/radia/data/hg19/cosmic/',\n                  '-t', '/home/radia/data/hg19/gaf/2_1',\n                  '--noSnpEff',\n                  '--rnaGeneBlckFile', '/home/radia/data/rnaGeneBlacklist.tab',\n                  '--rnaGeneFamilyBlckFile',\n                  '/home/radia/data/rnaGeneFamilyBlacklist.tab',\n                  '-f', input_files['genome.fasta'],\n                  '--log=INFO',\n                  '-g', docker_path(filterradia_log)]\n    docker_call(tool='filterradia', tool_parameters=parameters,\n                work_dir=work_dir, dockerhub=univ_options['dockerhub'])\n    output_files = defaultdict()\n    output_files[filterradia_output] = \\\n        job.fileStore.writeGlobalFile(''.join([work_dir, '/',\n                                               univ_options['patient'], '_',\n                                               chrom, '.vcf']))\n    output_files[os.path.basename(filterradia_log)] = \\\n        job.fileStore.writeGlobalFile(filterradia_log)\n    return output_files", "label": 1}
{"code": "function(version) {\n    var command = 'node_modules/.bin/bower uninstall ember && node_modules/.bin/bower install ember#' + version;\n\n    grunt.log.writeln('Running bower install', command);\n\n    try {\n      var resultBower = execSync(command);\n      grunt.log.writeln(resultBower);\n    } catch (e) {\n      grunt.fail.warn(e);\n    }\n  }", "label": 3}
{"code": "func (o HostNetworkSystem) UpdateVirtualNic(ctx context.Context, device string, nic types.HostVirtualNicSpec) error {\n\treq := types.UpdateVirtualNic{\n\t\tThis:   o.Reference(),\n\t\tDevice: device,\n\t\tNic:    nic,\n\t}\n\n\t_, err := methods.UpdateVirtualNic(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def parse(media)\n      version = 'v3'\n      media.sub!(/^[.]*|[.]*$/,\"\")\n      media = media.include?('+') ? media.split('+')[0] : media\n      version, media = media.split('.') if media.include?('.')\n      media_type = lookup_media(media)\n      \"application/vnd.github.#{version}.#{media_type}\"\n    end", "label": 4}
{"code": "def query_values(return_type=Hash)\n      empty_accumulator = Array == return_type ? [] : {}\n      if return_type != Hash && return_type != Array\n        raise ArgumentError, \"Invalid return type. Must be Hash or Array.\"\n      end\n      return nil if self.query == nil\n      split_query = self.query.split(\"&\").map do |pair|\n        pair.split(\"=\", 2) if pair && !pair.empty?\n      end.compact\n      return split_query.inject(empty_accumulator.dup) do |accu, pair|\n        # I'd rather use key/value identifiers instead of array lookups,\n        # but in this case I really want to maintain the exact pair structure,\n        # so it's best to make all changes in-place.\n        pair[0] = URI.unencode_component(pair[0])\n        if pair[1].respond_to?(:to_str)\n          # I loathe the fact that I have to do this. Stupid HTML 4.01.\n          # Treating '+' as a space was just an unbelievably bad idea.\n          # There was nothing wrong with '%20'!\n          # If it ain't broke, don't fix it!\n          pair[1] = URI.unencode_component(pair[1].to_str.gsub(/\\+/, \" \"))\n        end\n        if return_type == Hash\n          accu[pair[0]] = pair[1]\n        else\n          accu << pair\n        end\n        accu\n      end\n    end", "label": 4}
{"code": "func ascURLFromImgURL(u *url.URL) *url.URL {\n\tcopy := *u\n\tcopy.Path = ascPathFromImgPath(copy.Path)\n\treturn &copy\n}", "label": 5}
{"code": "function formatNode(node) {\n  var log = node.type\n  var location = node.position || {}\n  var position = stringify(location.start, location.end)\n  var key\n  var values = []\n  var value\n\n  if (node.children) {\n    log += dim('[') + yellow(node.children.length) + dim(']')\n  } else if (typeof node.value === 'string') {\n    log += dim(': ') + green(JSON.stringify(node.value))\n  }\n\n  if (position) {\n    log += ' (' + position + ')'\n  }\n\n  for (key in node) {\n    value = node[key]\n\n    if (\n      ignore.indexOf(key) !== -1 ||\n      value === null ||\n      value === undefined ||\n      (typeof value === 'object' && isEmpty(value))\n    ) {\n      continue\n    }\n\n    values.push('[' + key + '=' + JSON.stringify(value) + ']')\n  }\n\n  if (values.length !== 0) {\n    log += ' ' + values.join('')\n  }\n\n  return log\n}", "label": 3}
{"code": "public function getHttpHeaders()\n    {\n        $headers = [\n            'Content-type' => 'application/json',\n        ];\n\n        // Add \"WWW-Authenticate\" header\n        //\n        // RFC 6749, section 5.2.:\n        // \"If the client attempted to authenticate via the 'Authorization'\n        // request header field, the authorization server MUST\n        // respond with an HTTP 401 (Unauthorized) status code and\n        // include the \"WWW-Authenticate\" response header field\n        // matching the authentication scheme used by the client.\n        // @codeCoverageIgnoreStart\n        if ($this->errorType === 'invalid_client' && array_key_exists('HTTP_AUTHORIZATION', $_SERVER) !== false) {\n            $authScheme = strpos($_SERVER['HTTP_AUTHORIZATION'], 'Bearer') === 0 ? 'Bearer' : 'Basic';\n\n            $headers['WWW-Authenticate'] = $authScheme . ' realm=\"OAuth\"';\n        }\n        // @codeCoverageIgnoreEnd\n        return $headers;\n    }", "label": 2}
{"code": "public static base_response delete(nitro_service client, String trapclass) throws Exception {\n\t\tsnmptrap deleteresource = new snmptrap();\n\t\tdeleteresource.trapclass = trapclass;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def _actionsiter(self, message_iterator):\n        \"\"\"Iterate bulk actions.\n\n        :param message_iterator: Iterator yielding messages from a queue.\n        \"\"\"\n        for message in message_iterator:\n            payload = message.decode()\n            try:\n                if payload['op'] == 'delete':\n                    yield self._delete_action(payload)\n                else:\n                    yield self._index_action(payload)\n                message.ack()\n            except NoResultFound:\n                message.reject()\n            except Exception:\n                message.reject()\n                current_app.logger.error(\n                    \"Failed to index record {0}\".format(payload.get('id')),\n                    exc_info=True)", "label": 1}
{"code": "def new_url_query_values?(uri, paths_with_queries)\n      queries = uri.query_values.keys.join('-')\n      domain_path = extract_domain_path(uri)\n      if paths_with_queries[domain_path].nil?\n        paths_with_queries[domain_path] = [queries]\n        true\n      elsif !paths_with_queries[domain_path].include?(queries)\n        paths_with_queries[domain_path] << queries\n        true\n      else\n        false\n      end\n    end", "label": 4}
{"code": "function searchForArrowCloudLogDir() {\n\tif (isWritable('/ctlog')) {\n\t\treturn '/ctlog';\n\t}\n\tif (process.env.HOME && isWritable(path.join(process.env.HOME, 'ctlog'))) {\n\t\treturn path.join(process.env.HOME, 'ctlog');\n\t}\n\tif (process.env.USERPROFILE && isWritable(path.join(process.env.USERPROFILE, 'ctlog'))) {\n\t\treturn path.join(process.env.USERPROFILE, 'ctlog');\n\t}\n\tif (isWritable('./logs')) {\n\t\treturn path.resolve('./logs');\n\t}\n\tthrow new Error('No writable logging directory was found.');\n}", "label": 3}
{"code": "def loadSVrecs(fname, uselines=None, skiprows=0, linefixer=None, \n               delimiter_regex=None, verbosity=DEFAULT_VERBOSITY, **metadata):\n    \"\"\"\n    Load a separated value text file to a list of lists of strings of records.\n\n    Takes a tabular text file with a specified delimeter and end-of-line \n    character, and return data as a list of lists of strings corresponding to \n    records (rows).  Also uses and returns metadata (including column names, \n    formats, coloring, &c.) if these items are determined during the loading \n    process.   \n\n    **Parameters**\n\n        **fname** :  string or file object\n\n            Path (or file object) corresponding to a separated variable\n            (CSV) text file.\n \n        **delimiter** : single-character string\n        \n            When reading text file, character to use as delimiter to split \n            fields.  If not specified, the delimiter is determined first by \n            looking for special-format metadata specifying the delimiter, and \n            then if no specification is found, attempts are made to infer \n            delimiter from file contents.  (See **inflines** parameter below.)  \n            \n        **delimiter_regex** : regular expression (compiled or in string format)                    \n         \n            Regular expression to use to recognize delimiters, in place of a \n            single character.  (For instance, to have whitespace delimiting, \n            using delimiter_regex = '[\\s*]+')\n                         \n        **lineterminator** : single-character string\n        \n            Line terminator to use when reading in using SVfile.\n            \n        **skipinitialspace** : boolean\n        \n            If true, strips whitespace following the delimiter from field.   \n            \n       The **delimiter**, **linterminator** and **skipinitialspace** \n       parameters are passed on as parameters to the python CSV module, which is \n       used for reading in delimited text files.  Additional parameters from \n       that interface that are replicated in this constructor include \n       **quotechar**, **escapechar**, **quoting**, **doublequote** and \n       **dialect** (see CSV module documentation for more information).\n\n        **skiprows** :  non-negative integer, optional\n\n            When reading from a text file, the first `skiprows` lines are \n            ignored.  Default is 0, e.g no rows are skipped. \n\n        **uselines** : pair of non-negative integer, optional\n        \n            When reading from a text file, range of lines of data to load.  (In \n            contrast to **skiprows**, which specifies file rows to ignore \n            before looking for header information, **uselines** specifies which \n            data (non-header) lines to use, after header has been striped and \n            processed.)  See **headerlines** below.\n            \n        **comments** : single-character string, optional\n            \n            When reading from a text file, character used to distinguish header \n            lines.  If specified, any lines beginning with this character at the \n            top of the file are assumed to contain header information and not \n            row data. \n      \n        **headerlines** : integer, optional\n\n            When reading from a text file, the number of lines at the top of the \n            file (after the first  `skiprows` lines) corresponding to the header \n            of the file, where metadata can be found.  Lines after headerlines \n            are assumed to contain row contents.  If not specified, value is \n            determined first by looking for special metametadata  in first line \n            of file (see Tabular reference documentation for more information \n            about this), and if no such metadata is found, is inferred by \n            looking at file contents.    \n            \n        **namesinheader** : Boolean, optional\n\n            When reading from a text file, if `namesinheader == True`, then \n            assume the column names are in the last header line (unless \n            overridden by existing metadata or metametadata directive).  Default \n            is True.                        \n            \n        **linefixer** : callable, optional\n\n           This callable is applied to every line in the file.  If specified, \n           the called is applied directly to the strings in the file, after \n           they're split in lines but before they're split into fields.  The \n           purpose is to make lines with errors or mistakes amenable to \n           delimiter inference and field-splitting. \n            \n        **inflines** :  integer, optional\n        \n            Number of lines of file to use as sample data when inferring \n            delimiter and header.   \n\n        **metametadata** :  dictionary of integers or pairs of integers\n            \n            Specifies supplementary metametadata information for use \n            with SVfile loading.  See Tabular reference documentation for more \n            information\n            \n    **Returns**\n\n            **records** :  list of lists of strings\n\n                List of lists corresponding to records (rows) of data.\n\n            **metadata** :  dictionary\n\n                Metadata read and constructed during process of reading file.\n\n    **See Also:**\n\n            :func:`tabular.io.loadSV`, :func:`tabular.io.saveSV`, \n            :func:`tabular.io.DEFAULT_TYPEINFERER`\n\n    \"\"\"\n    if delimiter_regex and isinstance(delimiter_regex, types.StringType):\n        import re\n        delimiter_regex = re.compile(delimiter_regex) \n   \n    [metadata, inferedlines, WHOLETHING] = getmetadata(fname, skiprows=skiprows,\n                                                linefixer=linefixer, \n                                                delimiter_regex=delimiter_regex, \n                                                verbosity=verbosity, **metadata)\n\n    if uselines is None:\n        uselines = (0,False)\n    \n    if is_string_like(fname):\n        fh = file(fname, 'rU')\n    elif hasattr(fname, 'readline'):\n        fh = fname\n    else:\n        raise ValueError('fname must be a string or file handle') \n \n    for _ind in range(skiprows+uselines[0] + metadata['headerlines']):\n        fh.readline()\n        \n    if linefixer or delimiter_regex:\n        fh2 = tempfile.TemporaryFile('w+b')\n        F = fh.read().strip('\\n').split('\\n')\n        if linefixer:\n            F = map(linefixer,F)\n        if delimiter_regex:\n            F = map(lambda line: \n                    delimiter_regex.sub(metadata['dialect'].delimiter, line), F)       \n        fh2.write('\\n'.join(F))        \n        fh2.seek(0)\n        fh = fh2        \n\n    reader = csv.reader(fh, dialect=metadata['dialect'])\n\n    if uselines[1]:\n        linelist = []\n        for ln in reader:\n            if reader.line_num <= uselines[1] - uselines[0]:\n                linelist.append(ln)\n            else:\n                break\n    else:\n        linelist = list(reader)\n      \n    fh.close()\n\n    if linelist[-1] == []:\n        linelist.pop(-1)\n\n    return [linelist,metadata]", "label": 1}
{"code": "def execute\n      return unless @start && @limit\n      @next_to_insert = @start\n      while @next_to_insert <= @limit\n        stride = @throttler.stride\n        affected_rows = @connection.update(copy(bottom, top(stride)))\n\n        if @throttler && affected_rows > 0\n          @throttler.run\n        end\n\n        @printer.notify(bottom, @limit)\n        @next_to_insert = top(stride) + 1\n        break if @start == @limit\n      end\n      @printer.end\n    end", "label": 4}
{"code": "def atomic_pulls\n      pulls = {}\n      delayed_atomic_pulls.each_pair do |_, docs|\n        path = nil\n        ids = docs.map do |doc|\n          path ||= doc.flag_as_destroyed\n          doc._id\n        end\n        pulls[path] = { \"_id\" => { \"$in\" => ids }} and path = nil\n      end\n      pulls\n    end", "label": 4}
{"code": "function getDataSource(node) {\n    const config = Object.assign({}, copyXmlAttributes(node));\n\n    if (node.childNodes.length) {\n        // parse datasource options\n        for (let i = 0; i < node.childNodes.length; ++i) {\n            const childNode = node.childNodes.item(i);\n\n            if (childNode.nodeType === TEXT_NODE && childNode.textContent.trim().length > 0) {\n                throw new ImplementationError(`dataSource contains useless text: \"${childNode.textContent.trim()}\"`);\n            }\n\n            if (\n                childNode.nodeType === ELEMENT_NODE &&\n                childNode.namespaceURI === 'urn:flora:options' &&\n                childNode.localName === 'option'\n            ) {\n                if (childNode.attributes.length !== 1)\n                    throw new Error('flora:option element requires a name attribute');\n\n                const attr = childNode.attributes.item(0);\n                if (attr.localName !== 'name') throw new Error('flora:option element requires a name attribute');\n                if (config[attr.value]) throw new Error(`Data source option \"${attr.value}\" already defined`);\n\n                config[attr.value] = childNode.textContent.trim();\n            }\n        }\n    }\n\n    const name = config.name ? config.name : 'primary';\n    if (config.name) delete config.name;\n\n    return { name, config };\n}", "label": 3}
{"code": "func NewServer(handler http.Handler) *Server {\n\tts := NewUnstartedServer(handler, \"\")\n\tts.Start()\n\treturn ts\n}", "label": 5}
{"code": "public static base_response update(nitro_service client, rnat resource) throws Exception {\n\t\trnat updateresource = new rnat();\n\t\tupdateresource.network = resource.network;\n\t\tupdateresource.netmask = resource.netmask;\n\t\tupdateresource.natip = resource.natip;\n\t\tupdateresource.td = resource.td;\n\t\tupdateresource.aclname = resource.aclname;\n\t\tupdateresource.redirectport = resource.redirectport;\n\t\tupdateresource.natip2 = resource.natip2;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "function onPushNotificationRegistration(response) {\n    if (resolveRegistrationEventResponse) {\n        diag.debug.assert(!!rejectRegistrationEventResponse);\n        resolveRegistrationEventResponse(response);\n        resolveRegistrationEventResponse = undefined;\n        rejectRegistrationEventResponse = undefined;\n    }\n    else {\n        promiseRegistrationEventResponse = Q.resolve(response);\n    }\n    return promiseRegistrationEventResponse.done();\n}", "label": 3}
{"code": "func DjangoMigrationByID(db XODB, id float64) (*DjangoMigration, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, app, name, applied ` +\n\t\t`FROM django.django_migrations ` +\n\t\t`WHERE id = :1`\n\n\t// run query\n\tXOLog(sqlstr, id)\n\tdm := DjangoMigration{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, id).Scan(&dm.ID, &dm.App, &dm.Name, &dm.Applied)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dm, nil\n}", "label": 5}
{"code": "function(email, options) {\n      options = opts(this, options);\n      options.applevel = true;\n      var payload = JSON.stringify({\n        email: email\n      });\n\n      return new APICall({\n        action: 'account/password/reset',\n        type: 'POST',\n        options: options,\n        processResponse: APICall.basicResponse,\n        data: payload\n      });\n    }", "label": 3}
{"code": "function sendSuccessAnswer(table, res, id, field) {\n    if(typeof field === \"undefined\") {\n        if(id === 0) {\n            //Just assume that everything went okay. It looks like a non numeric primary key.\n            res.send({\n                result: 'success',\n                table: table\n            });\n            return;\n        } else {\n            field = \"id\";\n        }\n    }\n    lastQry = connection.query('SELECT * FROM ?? WHERE ?? = ?', [table, field, id] , function (err, rows) {\n        if (err) {\n            sendError(res, err.code)\n        } else {\n            res.send({\n                result: 'success',\n                json: rows,\n                table: table\n            });\n        }\n    });\n}", "label": 3}
{"code": "public static base_responses expire(nitro_service client, cacheobject resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcacheobject expireresources[] = new cacheobject[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\texpireresources[i] = new cacheobject();\n\t\t\t\texpireresources[i].locator = resources[i].locator;\n\t\t\t\texpireresources[i].url = resources[i].url;\n\t\t\t\texpireresources[i].host = resources[i].host;\n\t\t\t\texpireresources[i].port = resources[i].port;\n\t\t\t\texpireresources[i].groupname = resources[i].groupname;\n\t\t\t\texpireresources[i].httpmethod = resources[i].httpmethod;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, expireresources,\"expire\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def rake_check_options(options, *optdecl)\n      h = options.dup\n      optdecl.each do |name|\n        h.delete name\n      end\n      raise ArgumentError, \"no such option: #{h.keys.join(' ')}\" unless\n        h.empty?\n    end", "label": 4}
{"code": "def remove(host)\n      address = Address.new(host)\n      removed_servers = @servers.select { |s| s.address == address }\n      @update_lock.synchronize { @servers = @servers - removed_servers }\n      removed_servers.each do |server|\n        if server.connected?\n          server.disconnect!\n          publish_sdam_event(\n            Monitoring::SERVER_CLOSED,\n            Monitoring::Event::ServerClosed.new(address, topology)\n          )\n        end\n      end\n      removed_servers.any?\n    end", "label": 4}
{"code": "public function psrLogger($name, array $options = [])\n    {\n        $messageKey = null;\n\n        if (isset($options['messageKey'])) {\n            $messageKey = $options['messageKey'];\n            unset($options['messageKey']);\n        }\n\n        $psrLoggerOptions = $this->pluckArray([\n            'metadataProvider',\n            'batchEnabled',\n            'debugOutput',\n            'batchOptions',\n            'clientConfig',\n            'batchRunner',\n            'closureSerializer',\n            'debugOutputResource'\n        ], $options);\n\n        return new PsrLogger(\n            $this->logger($name, $options),\n            $messageKey,\n            $psrLoggerOptions + [\n                'clientConfig' => $this->config\n            ]\n        );\n    }", "label": 2}
{"code": "func (t *Torrent) reconcileHandshakeStats(c *connection) {\n\tif c.stats != (ConnStats{\n\t\t// Handshakes should only increment these fields:\n\t\tBytesWritten: c.stats.BytesWritten,\n\t\tBytesRead:    c.stats.BytesRead,\n\t}) {\n\t\tpanic(\"bad stats\")\n\t}\n\tc.postHandshakeStats(func(cs *ConnStats) {\n\t\tcs.BytesRead.Add(c.stats.BytesRead.Int64())\n\t\tcs.BytesWritten.Add(c.stats.BytesWritten.Int64())\n\t})\n\tc.reconciledHandshakeStats = true\n}", "label": 5}
{"code": "def _control_resp(self, data, state):\n        \"\"\" Handle a control response.\n\n        :param data: Payload.\n        :param state: Requested state.\n        :returns: Acknowledged state.\n        \"\"\"\n        if _is_control_response(data):\n            ack_state = bytes([data[22]])\n            if state == ack_state:\n                _LOGGER.debug(\"Received state ack from %s, state: %s\",\n                              self.host, ord(ack_state))\n                return ack_state", "label": 1}
{"code": "function getRequestFileParameters(req, res, next) {\n  //A valid getForms request must have an appId parameter set\n  var submitFileParams = {};\n  submitFileParams.fileDetails = {};\n\n  //Get the content body for normal parameter\n  var filesInRequest = req.files;\n\n  if (_.size(filesInRequest) === 0) {\n    logger.error(\"Middleware: getRequestFileParameters, Expected A File To Have Been Sent \", {params: req.params});\n    return next(new Error(\"Expected A File To Have Been Submitted\"));\n  }\n\n  var fileDetails = _.map(filesInRequest, function(fileValue) {\n    return fileValue;\n  });\n\n  fileDetails = _.first(fileDetails);\n\n  logger.debug(\"Middleware: getRequestFileParameters \", {fileDetails: fileDetails, body: req.body});\n\n  submitFileParams.fileDetails = {\n    fileStream: fileDetails.path,\n    fileName: fileDetails.originalname || fileDetails.name,\n    fileType: fileDetails.mimetype,\n    fileSize: fileDetails.size\n  };\n\n  req.appformsResultPayload = {\n    data: submitFileParams,\n    type: constants.resultTypes.submissions\n  };\n\n  logger.debug(\"Middleware: getRequestFileParameters \", {params: req.appformsResultPayload});\n\n  return next();\n}", "label": 3}
{"code": "public function defer(Closure $resolver, string $path)\n    {\n        if ($data = Arr::get($this->result, \"data.{$path}\")) {\n            return $data;\n        }\n\n        if ($this->isDeferred($path) || ! $this->acceptFurtherDeferring) {\n            return $this->resolve($resolver, $path);\n        }\n\n        $this->deferred[$path] = $resolver;\n    }", "label": 2}
{"code": "function checkRateRange(num) {\n    var numString = num.substring(0, num.length - 1);\n    var parseNum = parseInt(numString);\n    if (parseNum < 20) {\n        throw new Error(\"The minimum rate is twenty percentage. Received: \" + parseNum);\n    }\n}", "label": 3}
{"code": "def parse_str(self, s):\n        \"\"\"\n        Parse string and return relevant object\n\n        :param s: string to parse\n        :type s: str\n        :return: Parsed object\n        \"\"\"\n        self.object = self.parsed_class()\n        in_section = None  # Holds name of FEH file section while traversing through file.\n        for line in s.split('\\n'):\n            if line.lower().startswith('[end]'):\n                # Leave section\n                in_section = None\n            elif line.startswith('['):\n                # Enter section, sanitise `[Section Name]` to `section_name`\n                in_section = line.strip().strip('[]').lower().replace(' ', '_')\n            elif in_section:\n                try:\n                    # Call method `_section_section_name(line)`\n                    getattr(self, '_section_' + in_section)(line.strip())\n                except AttributeError:\n                    pass  # Skip unsupported section\n        return self.object", "label": 1}
{"code": "func Handshake(conn net.Conn) (string, error) {\n\t// Read in the version and reject anything other than SOCKS5.\n\tversion, err := readByte(conn)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\tif version != socks5Version {\n\t\treturn \"\", trace.BadParameter(\"only SOCKS5 is supported\")\n\t}\n\n\t// Read in the authentication method requested by the client and write back\n\t// the method that was selected. At the moment only \"no authentication\n\t// required\" is supported.\n\tauthMethods, err := readAuthenticationMethod(conn)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\tif !byteSliceContains(authMethods, socks5AuthNotRequired) {\n\t\treturn \"\", trace.BadParameter(\"only 'no authentication required' is supported\")\n\t}\n\terr = writeMethodSelection(conn)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\n\t// Read in the request from the client and make sure the requested command\n\t// is supported and extract the remote address. If everything is good, write\n\t// out a success response.\n\tremoteAddr, err := readRequest(conn)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\terr = writeReply(conn)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\n\treturn remoteAddr, nil\n}", "label": 5}
{"code": "protected function githubClient(OutputInterface $output, RunShell $shell, Client $guzzle, $token)\n    {\n        $output->writeln('<comment>[info]</comment> Instantiating GitHub API Wrapper.');\n\n        return new GitHub($shell, $guzzle, $token);\n    }", "label": 2}
{"code": "func (aSpace *addrSpace) contains(space string, nw *net.IPNet) bool {\n\tfor k, v := range aSpace.subnets {\n\t\tif space == k.AddressSpace && k.ChildSubnet == \"\" {\n\t\t\tif nw.Contains(v.Pool.IP) || v.Pool.Contains(nw.IP) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "function buildCompositeForm(formSubmissionModel, formId, singleFormQuery, statusUpdaterFunction, cb) {\n  var mergedFields = {};\n  mergedFields[formId] = {};\n\n  logger.debug(\"buildCompositeForm start\");\n\n  statusUpdaterFunction({\n    message: \"Creating form metadata for submissions with form ID: \" + formId\n  });\n\n  var mapReduceOptions = {\n    map: function() {\n      //The only difference will be the \"lastUpdated\" timestamp.\n      emit(this.formSubmittedAgainst.lastUpdated, this.formSubmittedAgainst); // eslint-disable-line no-undef\n    },\n    reduce: function(lastUpdatedTimestamp, formEntries) {\n      //Only want one of each form definition for each different timestamp\n      var formEntry = formEntries[0];\n\n      //Only need the pages, _id and name\n      if (formEntry && formEntry.pages) {\n        return {\n          _id: formEntry._id,\n          name: formEntry.name,\n          pages: formEntry.pages\n        };\n      } else {\n        return null;\n      }\n    },\n    query: singleFormQuery\n  };\n\n  formSubmissionModel.mapReduce(mapReduceOptions, function(err, subFormsSubmittedAgainst) {\n    if (err) {\n      logger.error(\"Error Using mapReduce \", err);\n      return cb(err);\n    }\n\n    statusUpdaterFunction({\n      message: \"Finished Creating form metadata for submissions with form ID: \" + formId\n    });\n\n    logger.debug(\"buildCompositeForm finish\");\n\n    var formName = \"\";\n\n    _.each(subFormsSubmittedAgainst, function(subFormSubmittedAgainst) {\n      formName = formName || subFormSubmittedAgainst.value.name;\n      mergedFields[formId] = mergeFormFields(mergedFields[formId] || {}, subFormSubmittedAgainst.value);\n    });\n\n    return cb(null, mergedFields, formName);\n  });\n}", "label": 3}
{"code": "public function psubscribe($pattern /* ... */)\n    {\n        $this->writeRequest(self::PSUBSCRIBE, func_get_args());\n        $this->statusFlags |= self::STATUS_PSUBSCRIBED;\n    }", "label": 2}
{"code": "def monthdatescalendar(cls, year, month):\n        \"\"\" Returns a list of week in a month. A week is a list of NepDate objects \"\"\"\n        weeks = []\n        week = []\n        for day in NepCal.itermonthdates(year, month):\n            week.append(day)\n            if len(week) == 7:\n                weeks.append(week)\n                week = []\n        if len(week) > 0:\n            weeks.append(week)\n        return weeks", "label": 1}
{"code": "function buildDep(file, pkg){\n  var files = [];\n\n  if (file.processed || file.package != pkg)\n    return files;\n\n  file.processed = true;\n\n  for (var i = 0, depFile; depFile = file.deps[i++];)\n    files.push.apply(files, buildDep(depFile, file.package));\n\n  files.push(file);\n\n  return files;\n}", "label": 3}
{"code": "def _update_nrfa_metadata(remote_config):\n    \"\"\"\n    Save NRFA metadata to local config file using retrieved config data\n\n    :param remote_config: Downloaded JSON data, not a ConfigParser object!\n    \"\"\"\n    config['nrfa']['oh_json_url'] = remote_config['nrfa_oh_json_url']\n    config['nrfa']['version'] = remote_config['nrfa_version']\n    config['nrfa']['url'] = remote_config['nrfa_url']\n    config.set_datetime('nrfa', 'published_on', datetime.utcfromtimestamp(remote_config['nrfa_published_on']))\n    config.set_datetime('nrfa', 'downloaded_on', datetime.utcnow())\n    config.set_datetime('nrfa', 'update_checked_on', datetime.utcnow())\n    config.save()", "label": 1}
{"code": "function handleKeydownEvent( event ) {\n\n        var keycode = event.keyCode,\n\n            // Check if one of the delete keys was pressed.\n            isKeycodeDelete = /^(8|46)$/.test(keycode)\n\n        // For some reason IE clears the input value on \u201cescape\u201d.\n        if ( keycode == 27 ) {\n            P.close()\n            return false\n        }\n\n        // Check if `space` or `delete` was pressed or the picker is closed with a key movement.\n        if ( keycode == 32 || isKeycodeDelete || !STATE.open && P.component.key[keycode] ) {\n\n            // Prevent it from moving the page and bubbling to doc.\n            event.preventDefault()\n            event.stopPropagation()\n\n            // If `delete` was pressed, clear the values and close the picker.\n            // Otherwise open the picker.\n            if ( isKeycodeDelete ) { P.clear().close() }\n            else { P.open() }\n        }\n    }", "label": 3}
{"code": "private function newQuery(array $additionalConfig, $overrideTopLevelKeys = false)\n    {\n        $query = $this->query;\n\n        if ($overrideTopLevelKeys) {\n            $keys = array_keys($additionalConfig);\n            foreach ($keys as $key) {\n                unset($query[$key]);\n            }\n        }\n\n        $query = $this->arrayMergeRecursive($query, $additionalConfig);\n\n        return new self(\n            $this->connection,\n            $this->valueMapper,\n            $this->parent,\n            $query\n        );\n    }", "label": 2}
{"code": "def fetch(reload = false, query_params = {})\n      return if expanded? && !reload\n      response = client.get(url_with_query_params(url, query_params))\n      set_attrs_from_response(response)\n      @expanded = true\n    end", "label": 4}
{"code": "func (st StateType) Put(pdf *Fpdf) {\n\tpdf.SetDrawColor(st.clrDraw.R, st.clrDraw.G, st.clrDraw.B)\n\tpdf.SetFillColor(st.clrFill.R, st.clrFill.G, st.clrFill.B)\n\tpdf.SetTextColor(st.clrText.R, st.clrText.G, st.clrText.B)\n\tpdf.SetLineWidth(st.lineWd)\n\tpdf.SetFontUnitSize(st.fontSize)\n\tpdf.SetAlpha(st.alpha, st.blendStr)\n\tpdf.SetCellMargin(st.cellMargin)\n}", "label": 5}
{"code": "function profileServiceFactory(\n    Constants, \n    Promise, \n    _, \n    DbRenderable,\n    Util ) \n{\n    Util.inherits(ProfileService, DbRenderable);\n\n    /**\n     * ProfileService is a singleton object which provides key/value store\n     * access to profile files loaded from disk via FileLoader.\n     * @constructor\n     * @extends {FileLoader}\n     */\n    function ProfileService () {\n        DbRenderable.call(this, {\n            directory: Constants.Profiles.Directory,\n            collectionName: 'profiles'\n        });\n    }\n\n    ProfileService.prototype.get = function (name, raw, scope ) {\n        return ProfileService.super_.prototype.get.call(this, name, scope)\n            .then(function(profile) {\n                if (profile && raw) {\n                    return profile.contents;\n                } else {\n                    return profile;\n                }\n            });\n    };\n\n    return new ProfileService();\n}", "label": 3}
{"code": "def read(path, options = {})\n      headers = extract_headers!(options)\n      json = client.get(\"/v1/#{encode_path(path)}\", {}, headers)\n      return Secret.decode(json)\n    rescue HTTPError => e\n      return nil if e.code == 404\n      raise\n    end", "label": 4}
{"code": "public function setLoginProfile($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\OsLogin\\V1\\LoginProfile::class);\n        $this->login_profile = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function addAnother(schema) {\n\n    var config = {\n        properties: {\n            another: {\n                description: 'Add another collection? (y/n)'.magenta\n            }\n        }\n    };\n\n    prompt.start();\n    prompt.message = ' > ';\n    prompt.delimiter = '';\n\n    return new Promise(function(resolve, reject) {\n        prompt.get(config, function(err, result) {\n\n            if (err) return reject(err);\n\n            switch (result.another.toLowerCase()) {\n                case 'n':\n                    return resolve({\n                        answer: false,\n                        schema: schema\n                    });\n                case 'y':\n                default:\n                    return resolve({\n                        answer: true,\n                        schema: schema\n                    });\n            }\n        });\n    });\n}", "label": 3}
{"code": "def relationships\n      r = Relationships.new\n      child_objects.each { |child| r << child.relationship }\n      r\n    end", "label": 4}
{"code": "private static String wordShapeChris2Long(String s, boolean omitIfInBoundary, int len, Collection<String> knownLCWords) {\r\n    final char[] beginChars = new char[BOUNDARY_SIZE];\r\n    final char[] endChars = new char[BOUNDARY_SIZE];\r\n    int beginUpto = 0;\r\n    int endUpto = 0;\r\n    final Set<Character> seenSet = new TreeSet<Character>();  // TreeSet guarantees stable ordering; has no size parameter\r\n\r\n    boolean nonLetters = false;\r\n\r\n    for (int i = 0; i < len; i++) {\r\n      int iIncr = 0;\r\n      char c = s.charAt(i);\r\n      char m = c;\r\n      if (Character.isDigit(c)) {\r\n        m = 'd';\r\n      } else if (Character.isLowerCase(c)) {\r\n        m = 'x';\r\n      } else if (Character.isUpperCase(c) || Character.isTitleCase(c)) {\r\n        m = 'X';\r\n      }\r\n      for (String gr : greek) {\r\n        if (s.startsWith(gr, i)) {\r\n          m = 'g';\r\n          //System.out.println(s + \"  ::  \" + s.substring(i+1));\r\n          iIncr = gr.length() - 1;\r\n          break;\r\n        }\r\n      }\r\n      if (m != 'x' && m != 'X') {\r\n        nonLetters = true;\r\n      }\r\n\r\n      if (i < BOUNDARY_SIZE) {\r\n        beginChars[beginUpto++] = m;\r\n      } else if (i < len - BOUNDARY_SIZE) {\r\n        seenSet.add(Character.valueOf(m));\r\n      } else {\r\n        endChars[endUpto++] = m;\r\n      }\r\n      i += iIncr;\r\n      // System.out.println(\"Position skips to \" + i);\r\n    }\r\n\r\n    // Calculate size. This may be an upperbound, but is often correct\r\n    int sbSize = beginUpto + endUpto + seenSet.size();\r\n    if (knownLCWords != null) { sbSize++; }\r\n    final StringBuilder sb = new StringBuilder(sbSize);\r\n    // put in the beginning chars\r\n    sb.append(beginChars, 0, beginUpto);\r\n    // put in the stored ones sorted\r\n    if (omitIfInBoundary) {\r\n      for (Character chr : seenSet) {\r\n        char ch = chr.charValue();\r\n        boolean insert = true;\r\n        for (int i = 0; i < beginUpto; i++) {\r\n          if (beginChars[i] == ch) {\r\n            insert = false;\r\n            break;\r\n          }\r\n        }\r\n        for (int i = 0; i < endUpto; i++) {\r\n          if (endChars[i] == ch) {\r\n            insert = false;\r\n            break;\r\n          }\r\n        }\r\n        if (insert) {\r\n          sb.append(ch);\r\n        }\r\n      }\r\n    } else {\r\n      for (Character chr : seenSet) {\r\n        sb.append(chr.charValue());\r\n      }\r\n    }\r\n    // and add end ones\r\n    sb.append(endChars, 0, endUpto);\r\n\r\n    if (knownLCWords != null) {\r\n      if (!nonLetters && knownLCWords.contains(s.toLowerCase())) {\r\n        sb.append('k');\r\n      }\r\n    }\r\n    // System.out.println(s + \" became \" + sb);\r\n    return sb.toString();\r\n  }", "label": 0}
{"code": "func PgPltemplateByTmplname(db XODB, tmplname pgtypes.Name) (*PgPltemplate, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, tmplname, tmpltrusted, tmpldbacreate, tmplhandler, tmplinline, tmplvalidator, tmpllibrary, tmplacl ` +\n\t\t`FROM pg_catalog.pg_pltemplate ` +\n\t\t`WHERE tmplname = $1`\n\n\t// run query\n\tXOLog(sqlstr, tmplname)\n\tpp := PgPltemplate{}\n\n\terr = db.QueryRow(sqlstr, tmplname).Scan(&pp.Tableoid, &pp.Cmax, &pp.Xmax, &pp.Cmin, &pp.Xmin, &pp.Ctid, &pp.Tmplname, &pp.Tmpltrusted, &pp.Tmpldbacreate, &pp.Tmplhandler, &pp.Tmplinline, &pp.Tmplvalidator, &pp.Tmpllibrary, &pp.Tmplacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pp, nil\n}", "label": 5}
{"code": "private function imageError($file, $firsttime, $msg)\n\t{\n\t\t$this->failedImages[$file] = true;\n\n\t\tif ($firsttime && ($this->mpdf->showImageErrors || $this->mpdf->debug)) {\n\t\t\tthrow new \\Mpdf\\MpdfImageException(sprintf('%s (%s)', $msg, $file));\n\t\t}\n\n\t\t$this->logger->warning(sprintf('%s (%s)', $msg, $file), ['context' => LogContext::IMAGES]);\n\t}", "label": 2}
{"code": "public void addLicense(final String gavc, final String licenseId) {\n        final DbArtifact dbArtifact = getArtifact(gavc);\n\n        // Try to find an existing license that match the new one\n        final LicenseHandler licenseHandler = new LicenseHandler(repositoryHandler);\n        final DbLicense license = licenseHandler.resolve(licenseId);\n\n        // If there is no existing license that match this one let's use the provided value but\n        // only if the artifact has no license  yet. Otherwise it could mean that users has already\n        // identify the license manually.\n        if(license == null){\n            if(dbArtifact.getLicenses().isEmpty()){\n                LOG.warn(\"Add reference to a non existing license called \" + licenseId + \" in  artifact \" + dbArtifact.getGavc());\n                repositoryHandler.addLicenseToArtifact(dbArtifact, licenseId);\n            }\n        }\n        // Add only if the license is not already referenced\n        else if(!dbArtifact.getLicenses().contains(license.getName())){\n            repositoryHandler.addLicenseToArtifact(dbArtifact, license.getName());\n        }\n    }", "label": 0}
{"code": "public function GetJob(\\Google\\Cloud\\Talent\\V4beta1\\GetJobRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.cloud.talent.v4beta1.JobService/GetJob',\n        $argument,\n        ['\\Google\\Cloud\\Talent\\V4beta1\\Job', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "func isLte(fl FieldLevel) bool {\n\n\tfield := fl.Field()\n\tparam := fl.Param()\n\n\tswitch field.Kind() {\n\n\tcase reflect.String:\n\t\tp := asInt(param)\n\n\t\treturn int64(utf8.RuneCountInString(field.String())) <= p\n\n\tcase reflect.Slice, reflect.Map, reflect.Array:\n\t\tp := asInt(param)\n\n\t\treturn int64(field.Len()) <= p\n\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\tp := asInt(param)\n\n\t\treturn field.Int() <= p\n\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:\n\t\tp := asUint(param)\n\n\t\treturn field.Uint() <= p\n\n\tcase reflect.Float32, reflect.Float64:\n\t\tp := asFloat(param)\n\n\t\treturn field.Float() <= p\n\n\tcase reflect.Struct:\n\n\t\tif field.Type() == timeType {\n\n\t\t\tnow := time.Now().UTC()\n\t\t\tt := field.Interface().(time.Time)\n\n\t\t\treturn t.Before(now) || t.Equal(now)\n\t\t}\n\t}\n\n\tpanic(fmt.Sprintf(\"Bad field type %T\", field.Interface()))\n}", "label": 5}
{"code": "def print_data(data):\n    \"\"\"Prints object key-value pairs in a custom format\n\n    :param data: The dict to print\n    :type data: dict\n    :rtype: None\n    \"\"\"\n    print(\", \".join([\"{}=>{}\".format(key, value) for key, value in data]))", "label": 1}
{"code": "def push(*metajobs)\n      Que.internal_log(:job_buffer_push, self) do\n        {\n          maximum_size:  maximum_size,\n          ids:           metajobs.map(&:id),\n          current_queue: to_a,\n        }\n      end\n\n      sync do\n        return metajobs if _stopping?\n\n        @array.concat(metajobs).sort!\n\n        # Relying on the hash's contents being sorted, here.\n        priority_queues.reverse_each do |_, pq|\n          pq.waiting_count.times do\n            job = _shift_job(pq.priority)\n            break if job.nil? # False would mean we're stopping.\n            pq.push(job)\n          end\n        end\n\n        # If we passed the maximum buffer size, drop the lowest sort keys and\n        # return their ids to be unlocked.\n        overage = -_buffer_space\n        pop(overage) if overage > 0\n      end\n    end", "label": 4}
{"code": "function findDataSource(connections, dataSource, cb) {\n  var query = {\n\n  };\n\n  //Searching By ID.\n  query[CONSTANTS.DATA_SOURCE_ID] = dataSource[CONSTANTS.DATA_SOURCE_ID];\n\n  //Looking up a full data source document as we are updating\n  lookUpDataSources(connections, {\n    query: query,\n    lean: false\n  }, function(err, dataSources) {\n    if (err) {\n      return cb(buildErrorResponse({\n        error: err,\n        userDetail: \"Unexpected Error When Searching For A Data Source\",\n        code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n      }));\n    }\n\n    //Should only be one data source\n    if (dataSources.length !== 1) {\n      return cb(buildErrorResponse({\n        error: new Error(\"Data Source Not Found\"),\n        systemDetail: \"Requested ID: \"  + dataSource[CONSTANTS.DATA_SOURCE_ID],\n        code: ERROR_CODES.FH_FORMS_NOT_FOUND\n      }));\n    }\n\n    return cb(undefined, dataSource, dataSources[0]);\n  });\n}", "label": 3}
{"code": "def check_overlap(pos, ins, thresh):\n    \"\"\"\n    make sure thresh % feature is contained within insertion\n    \"\"\"\n    ins_pos = ins[0]\n    ins_len = ins[2]\n    ol = overlap(ins_pos, pos)\n    feat_len = pos[1] - pos[0] + 1\n#    print float(ol) / float(feat_len)\n    if float(ol) / float(feat_len) >= thresh:\n        return True\n    return False", "label": 1}
{"code": "public static base_responses add(nitro_service client, appfwjsoncontenttype resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwjsoncontenttype addresources[] = new appfwjsoncontenttype[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new appfwjsoncontenttype();\n\t\t\t\taddresources[i].jsoncontenttypevalue = resources[i].jsoncontenttypevalue;\n\t\t\t\taddresources[i].isregex = resources[i].isregex;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setArgs($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->args = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_responses delete(nitro_service client, String aliasname[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (aliasname != null && aliasname.length > 0) {\n\t\t\tdnscnamerec deleteresources[] = new dnscnamerec[aliasname.length];\n\t\t\tfor (int i=0;i<aliasname.length;i++){\n\t\t\t\tdeleteresources[i] = new dnscnamerec();\n\t\t\t\tdeleteresources[i].aliasname = aliasname[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static appfwxmlcontenttype get(nitro_service service, String xmlcontenttypevalue) throws Exception{\n\t\tappfwxmlcontenttype obj = new appfwxmlcontenttype();\n\t\tobj.set_xmlcontenttypevalue(xmlcontenttypevalue);\n\t\tappfwxmlcontenttype response = (appfwxmlcontenttype) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function parent(str, { strict = false } = {}) {\n  str = path.normalize(str).replace(/\\/|\\\\/, '/');\n\n  // special case for strings ending in enclosure containing path separator\n  if (/[\\{\\[].*[\\/]*.*[\\}\\]]$/.test(str)) str += '/';\n\n  // preserves full path in case of trailing path separator\n  str += 'a';\n\n  do {str = path.dirname(str)}\n  while (isglob(str, {strict}) || /(^|[^\\\\])([\\{\\[]|\\([^\\)]+$)/.test(str));\n\n  // remove escape chars and return result\n  return str.replace(/\\\\([\\*\\?\\|\\[\\]\\(\\)\\{\\}])/g, '$1');\n}", "label": 3}
{"code": "function (soajs, data, cb) {\n        initBLModel(soajs, function (err) {\n            if (err) {\n                return cb(err);\n            }\n            driver.model.initConnection(soajs);\n            let criteria = null;\n            if (!(data.username || data.id)) {\n                return cb(411);\n            }\n            if (data.username) {\n                criteria = {\n                    'username': data.username\n                };\n            }\n            else {\n                let id = null;\n                try {\n                    id = driver.model.validateId(soajs, data.id);\n                    criteria = {\n                        '_id': id\n                    };\n                }\n                catch (e) {\n                    return cb(411);\n                }\n            }\n            if (!criteria)\n                return cb(403);\n\n            utilities.findRecord(soajs, driver.model, criteria, cb, function (record) {\n                delete record.password;\n\n                let groupInfo = checkUserTenantAccess(record, soajs.tenant);\n                if (groupInfo && groupInfo.groups && Array.isArray(groupInfo.groups) && groupInfo.groups.length !== 0) {\n                    record.groups = groupInfo.groups;\n                    record.tenant = groupInfo.tenant;\n                    utilities.findGroups(soajs, driver.model, record, function (record) {\n                        returnUser(record);\n                    });\n                }\n                else {\n                    returnUser(record);\n                }\n\n                function returnUser(record) {\n                    utilities.assureConfig(soajs, record);\n                    driver.model.closeConnection(soajs);\n                    return cb(null, record);\n                }\n            });\n        });\n    }", "label": 3}
{"code": "function (memberName) {\n        var visibility = this._defaultVisibility;\n        if (_GPF_VISIBILITY_UNKNOWN === visibility) {\n            if (memberName.charAt(0) === \"_\") {\n                visibility = _GPF_VISIBILITY_PROTECTED;\n            } else {\n                visibility = _GPF_VISIBILITY_PUBLIC;\n            }\n        }\n        return visibility;\n    }", "label": 3}
{"code": "public Map<String, Object> getModuleFieldsFilters() {\n        final Map<String, Object> params = new HashMap<String, Object>();\n\n        for(final Filter filter: filters){\n            params.putAll(filter.moduleFilterFields());\n        }\n\n        return params;\n    }", "label": 0}
{"code": "def query(self, files=True):\n        \"\"\"Queries the depot to get the current status of the changelist\"\"\"\n        if self._change:\n            cl = str(self._change)\n            self._p4dict = {camel_case(k): v for k, v in six.iteritems(self._connection.run(['change', '-o', cl])[0])}\n\n        if files:\n            self._files = []\n            if self._p4dict.get('status') == 'pending' or self._change == 0:\n                change = self._change or 'default'\n                data = self._connection.run(['opened', '-c', str(change)])\n                self._files = [Revision(r, self._connection) for r in data]\n            else:\n                data = self._connection.run(['describe', str(self._change)])[0]\n                depotfiles = []\n                for k, v in six.iteritems(data):\n                    if k.startswith('depotFile'):\n                        depotfiles.append(v)\n                self._files = self._connection.ls(depotfiles)", "label": 1}
{"code": "function getTheme(req, res, next) {\n  var params = {\n    appId: req.params.projectid || req.params.id\n  };\n  forms.getAppTheme(_.extend(req.connectionOptions, params), function(err, theme) {\n    if (err) {\n      return next(err);\n    }\n\n    req.appformsResultPayload = req.appformsResultPayload || {};\n\n    if (_.isObject(req.appformsResultPayload.data) && theme && !req.getFullTheme) {\n      req.appformsResultPayload.data.theme = theme._id;\n    } else {\n      //Want the full theme definition\n      req.appformsResultPayload = {\n        data: theme\n      };\n    }\n\n    next();\n  });\n}", "label": 3}
{"code": "def object_type(self):\n        \"\"\"\n            A read-only property that gives the object type as string; sensor, actuator, program, other.\n            Used by WEB interface templates.\n        \"\"\"\n\n        from .statusobject import AbstractSensor, AbstractActuator\n        from .program import Program\n        if isinstance(self, AbstractSensor):\n            return 'sensor'\n        elif isinstance(self, AbstractActuator):\n            return 'actuator'\n        elif isinstance(self, Program):\n            return 'program'\n        else:\n            return 'other'", "label": 1}
{"code": "def bind_jobs\n      @deployment_plan.releases.each do |release|\n        release.bind_jobs\n      end\n\n      @deployment_plan.instance_groups.each(&:validate_package_names_do_not_collide!)\n      @deployment_plan.instance_groups.each(&:validate_exported_from_matches_stemcell!)\n    end", "label": 4}
{"code": "def dflt_interval(self, cd_id: str) -> (int, int):\n        \"\"\"\n        Return default non-revocation interval from latest 'to' times on delta frames\n        of revocation cache entries on indices stemming from input cred def id.\n\n        Compute the 'from'/'to' values as the earliest/latest 'to' values of all\n        cached delta frames on all rev reg ids stemming from the input cred def id.\n\n        E.g., on frames for\n            rev-reg-0: -[xx]---[xxxx]-[x]---[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]--> time\n            rev-reg-1: ----------------------[xxxx]----[xxx]---[xxxxxxxxxxxxxxxxxxxx]---------> time\n            rev-reg-2: -------------------------------------------[xx]-----[xxxx]-----[xxxxx]-> time\n            rev-reg-3: -----------------------------------------------------------[xxxxxxxx]--> time\n\n        return the most recent interval covering all matching revocation registries in the cache; i.e.,:\n            interval:  -------------------------------------------------------------[*******]-> time\n\n        Raise CacheIndex if there are no matching entries.\n\n        :param cd_id: cred def identifier to match\n        :return: default non-revocation interval as 2-tuple (fro, to)\n        \"\"\"\n\n        LOGGER.debug('RevocationCache.dflt_interval >>>')\n\n        fro = None\n        to = None\n\n        for rr_id in self:\n            if cd_id != rev_reg_id2cred_def_id(rr_id):\n                continue\n            entry = self[rr_id]\n            if entry.rr_delta_frames:\n                to = max(entry.rr_delta_frames, key=lambda f: f.to).to\n                fro = min(fro or to, to)\n\n        if not (fro and to):\n            LOGGER.debug(\n                'RevocationCache.dflt_interval <!< No data for default non-revoc interval on cred def id %s',\n                cd_id)\n            raise CacheIndex('No data for default non-revoc interval on cred def id {}'.format(cd_id))\n\n        rv = (fro, to)\n        LOGGER.debug('RevocationCache.dflt_interval <<< %s', rv)\n        return rv", "label": 1}
{"code": "public function setEntityTypeBatchInline($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\EntityTypeBatch::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def _assertion(self, matcher, value):\n        \"\"\" Perform the actual assertion for the given matcher and value. Override\n            this method to apply a special configuration when performing the assertion.\n            If the assertion fails it should raise an AssertionError.\n        \"\"\"\n        # To support the syntax `any_of(subject) | should ...` we check if the\n        # value to check is an Expectation object and if it is we use the descriptor\n        # protocol to bind the value's assertion logic to this expectation.\n        if isinstance(value, Expectation):\n            assertion = value._assertion.__get__(self, Expectation)\n            assertion(matcher, value.value)\n        else:\n            hc.assert_that(value, matcher)", "label": 1}
{"code": "public static function createXMLMetadataConfiguration(array $paths, $isDevMode = false, $proxyDir = null, ?Cache $cache = null)\n    {\n        $config = self::createConfiguration($isDevMode, $proxyDir, $cache);\n        $config->setMetadataDriverImpl(new XmlDriver($paths));\n\n        return $config;\n    }", "label": 2}
{"code": "private function executeCall()\n    {\n        $call = $this->call;\n        list($results, $shouldContinue) = $this->mapResults(\n            $call($this->callOptions)\n        );\n\n        $this->set(\n            $this->resultTokenPath,\n            $this->callOptions,\n            $this->determineNextResultToken($results, $shouldContinue)\n        );\n\n        return $results;\n    }", "label": 2}
{"code": "function convertDSCacheToFieldOptions(fieldType, cacheEntries) {\n  //Radio and Dropdown only allow the first option to be selected\n  //Checkboxes can have multiple options selected.\n\n  var alreadySelected = false;\n  return _.map(cacheEntries, function(cacheEntry, index) {\n    var valToReturn = {\n      key: cacheEntry.key || index,\n      label: cacheEntry.value,\n      checked: cacheEntry.selected && (!alreadySelected || fieldType === CONSTANTS.FORM_CONSTANTS.FIELD_TYPE_CHECKBOXES)\n    };\n    if (valToReturn.checked) {\n      alreadySelected = true;\n    }\n    return valToReturn;\n  });\n}", "label": 3}
{"code": "def filter_variant_sequences(\n        variant_sequences,\n        preferred_sequence_length,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,):\n    \"\"\"\n    Drop variant sequences which are shorter than request or don't have\n    enough supporting reads.\n    \"\"\"\n    variant_sequences = trim_variant_sequences(\n        variant_sequences, min_variant_sequence_coverage)\n\n    return filter_variant_sequences_by_length(\n        variant_sequences=variant_sequences,\n        preferred_sequence_length=preferred_sequence_length)", "label": 1}
{"code": "public function create(array $options = [])\n    {\n        $options += [\n            'statements' => [],\n        ];\n\n        $databaseId = DatabaseAdminClient::parseName($this->name())['database'];\n        $statement = sprintf('CREATE DATABASE `%s`', $databaseId);\n\n        $operation = $this->connection->createDatabase([\n            'instance' => $this->instance->name(),\n            'createStatement' => $statement,\n            'extraStatements' => $options['statements']\n        ]);\n\n        return $this->resumeOperation($operation['name'], $operation);\n    }", "label": 2}
{"code": "func Run() {\n\tfor _, f := range appflags {\n\t\tswitch f.Value.(type) {\n\t\tcase string:\n\t\t\tflag.StringVar((f.V).(*string), f.Name, f.Value.(string), f.Desc)\n\t\tcase bool:\n\t\t\tflag.BoolVar((f.V).(*bool), f.Name, f.Value.(bool), f.Desc)\n\t\t}\n\t}\n\n\tflag.Parse()\n}", "label": 5}
{"code": "def condense_otus(otuF, nuniqueF):\n    \"\"\"\n    Traverse the input otu-sequence file, collect the non-unique OTU IDs and\n    file the sequences associated with then under the unique OTU ID as defined\n    by the input matrix.\n\n    :@type otuF: file\n    :@param otuF: The output file from QIIME's pick_otus.py\n    :@type nuniqueF: file\n    :@param nuniqueF: The matrix of unique OTU IDs associated to the list of\n                      non-unique OTU IDs they replaced.\n\n    :@rtype: dict\n    :@return: The new condensed table of unique OTU IDs and the sequence IDs\n              associated with them.\n    \"\"\"\n    uniqueOTUs = set()\n    nuOTUs = {}\n\n    # parse non-unique otu matrix\n    for line in nuniqueF:\n        line = line.split()\n        uOTU = line[0]\n        for nuOTU in line[1:]:\n            nuOTUs[nuOTU] = uOTU\n        uniqueOTUs.add(uOTU)\n\n    otuFilter = defaultdict(list)\n    # parse otu sequence file\n    for line in otuF:\n        line = line.split()\n        otuID, seqIDs = line[0], line[1:]\n        if otuID in uniqueOTUs:\n            otuFilter[otuID].extend(seqIDs)\n        elif otuID in nuOTUs:\n            otuFilter[nuOTUs[otuID]].extend(seqIDs)\n\n    return otuFilter", "label": 1}
{"code": "def touch(key, ttl=nil)\n      resp = perform(:touch, key, ttl_or_default(ttl))\n      resp.nil? ? nil : true\n    end", "label": 4}
{"code": "function ClassicWritable(stream, options) {\n\tvar self = this;\n\n\tPassThrough.call(this, options);\n\tclassicMixins.call(this, stream, options);\n\n\tstream.on('error', function(error) {\n\t\tself.emit('error', error);\n\t});\n\n\tself._isClosed = false;\n\tstream.on('close', function() {\n\t\tself._isClosed = true;\n\t});\n\tif (!stream.end) stream.end = () => { /* do nothing */ };\n\tthis._zSuperObj.pipe.call(this, stream);\n}", "label": 3}
{"code": "public static <E, C extends Counter<E>> C L2Normalize(C c) {\r\n    return scale(c, 1.0 / L2Norm(c));\r\n  }", "label": 0}
{"code": "public function queryObject()\n    {\n        $bindingType = $this->options['bindingType'];\n\n        $queryObj = [];\n        $queryObj['queryString'] = $this->query;\n        $queryObj['allowLiterals'] = (bool) $this->options['allowLiterals'];\n\n        $bindings = $this->mapBindings($bindingType, $this->options['bindings']);\n        if (!empty($bindings)) {\n            $queryObj[$this->options['bindingType']] = $bindings;\n        }\n\n        return $queryObj;\n    }", "label": 2}
{"code": "func (l VirtualDeviceList) FindByKey(key int32) types.BaseVirtualDevice {\n\tfor _, device := range l {\n\t\tif device.GetVirtualDevice().Key == key {\n\t\t\treturn device\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function setShotAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\VideoSegment::class);\n        $this->shot_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function infer(val, opts) {\n  opts = opts || {};\n\n  // Optional custom inference hook.\n  if (opts.valueHook) {\n    var type = opts.valueHook(val, opts);\n    if (type !== undefined) {\n      if (!types.Type.isType(type)) {\n        throw new Error(f('invalid value hook return value: %j', type));\n      }\n      return type;\n    }\n  }\n\n  // Default inference logic.\n  switch (typeof val) {\n    case 'string':\n      return createType('string', opts);\n    case 'boolean':\n      return createType('boolean', opts);\n    case 'number':\n      if ((val | 0) === val) {\n        return createType('int', opts);\n      } else if (Math.abs(val) < 9007199254740991) {\n        return createType('float', opts);\n      }\n      return createType('double', opts);\n    case 'object':\n      if (val === null) {\n        return createType('null', opts);\n      } else if (Array.isArray(val)) {\n        if (!val.length) {\n          return EMPTY_ARRAY_TYPE;\n        }\n        return createType({\n          type: 'array',\n          items: combine(val.map(function (v) { return infer(v, opts); }))\n        }, opts);\n      } else if (Buffer.isBuffer(val)) {\n        return createType('bytes', opts);\n      }\n      var fieldNames = Object.keys(val);\n      if (fieldNames.some(function (s) { return !types.isValidName(s); })) {\n        // We have to fall back to a map.\n        return createType({\n          type: 'map',\n          values: combine(fieldNames.map(function (s) {\n            return infer(val[s], opts);\n          }), opts)\n        }, opts);\n      }\n      return createType({\n        type: 'record',\n        fields: fieldNames.map(function (s) {\n          return {name: s, type: infer(val[s], opts)};\n        })\n      }, opts);\n    default:\n      throw new Error(f('cannot infer type from: %j', val));\n  }\n}", "label": 3}
{"code": "public static ComplexNumber Sin(ComplexNumber z1) {\r\n        ComplexNumber result = new ComplexNumber();\r\n\r\n        if (z1.imaginary == 0.0) {\r\n            result.real = Math.sin(z1.real);\r\n            result.imaginary = 0.0;\r\n        } else {\r\n            result.real = Math.sin(z1.real) * Math.cosh(z1.imaginary);\r\n            result.imaginary = Math.cos(z1.real) * Math.sinh(z1.imaginary);\r\n        }\r\n\r\n        return result;\r\n    }", "label": 0}
{"code": "def comments\n      parse unless @parsed\n      comments = get_comments\n      if comments.nil? || comments.none?\n        nil\n      else\n        comments.map { |c| c.squeeze(Constants::SPACE) }\n      end\n    end", "label": 4}
{"code": "func mod2mask(cks uint32) ModMask {\n\tmm := ModNone\n\t// Left or right control\n\tif (cks & (0x0008 | 0x0004)) != 0 {\n\t\tmm |= ModCtrl\n\t}\n\t// Left or right alt\n\tif (cks & (0x0002 | 0x0001)) != 0 {\n\t\tmm |= ModAlt\n\t}\n\t// Any shift\n\tif (cks & 0x0010) != 0 {\n\t\tmm |= ModShift\n\t}\n\treturn mm\n}", "label": 5}
{"code": "function query(base, q, callback) {\n    // Added unescape to fix URI errors resulting from hexadecimal escape sequences\n    var url = util.format(\"%s?%s\", base, querystring.unescape(querystring.stringify(q)));\n    request(url, function (err, response) {\n        if (err) return callback(err);\n        callback(null, response.body);\n    });\n}", "label": 3}
{"code": "public function appendSign(callable $middleware, $name = null)\n    {\n        $this->add(self::SIGN, $name, $middleware);\n    }", "label": 2}
{"code": "function split (data, w, h) {\n  var colors = {};\n\n  var pos = 0;\n\n  for (var y = 0; y < h; ++y) {\n    for (var x = 0; x < w; ++x) {\n      pos = (y * w + x) * 4;\n      if (data[pos + 3] > 0) {\n        set(x, y, data[pos], data[pos + 1], data[pos + 2]);\n      }\n    }\n  }\n\n  return {\n    w: w,\n    h: h,\n    colors: colors\n  };\n\n  function set (x, y, r, g, b) {\n    var hex = \"#\" + [r, g, b].map(hexaze).join(\"\");\n\n    if (!colors[hex]) {\n      colors[hex] = new Array(h);\n\n      for (var i = 0; i < h; ++i) {\n        colors[hex][i] = new Uint8Array(w);\n      }\n    }\n\n    colors[hex][y][x] = 1;\n  }\n}", "label": 3}
{"code": "public function recordRequest(RequestHandled $event)\n    {\n        if (! Telescope::isRecording()) {\n            return;\n        }\n\n        Telescope::recordRequest(IncomingEntry::make([\n            'uri' => str_replace($event->request->root(), '', $event->request->fullUrl()) ?: '/',\n            'method' => $event->request->method(),\n            'controller_action' => optional($event->request->route())->getActionName(),\n            'middleware' => array_values(optional($event->request->route())->gatherMiddleware() ?? []),\n            'headers' => $this->headers($event->request->headers->all()),\n            'payload' => $this->payload($this->input($event->request)),\n            'session' => $this->payload($this->sessionVariables($event->request)),\n            'response_status' => $event->response->getStatusCode(),\n            'response' => $this->response($event->response),\n            'duration' => defined('LARAVEL_START') ? floor((microtime(true) - LARAVEL_START) * 1000) : null,\n        ]));\n    }", "label": 2}
{"code": "func (s *PresenceService) GetProxies() ([]services.Server, error) {\n\treturn s.getServers(services.KindProxy, proxiesPrefix)\n}", "label": 5}
{"code": "def _magic_data(filename=os.path.join(here, 'magic_data.json')):\n    \"\"\" Read the magic file\"\"\"\n    with open(filename) as f:\n        data = json.load(f)\n    headers = [_create_puremagic(x) for x in data['headers']]\n    footers = [_create_puremagic(x) for x in data['footers']]\n    return headers, footers", "label": 1}
{"code": "public static base_response unset(nitro_service client, csparameter resource, String[] args) throws Exception{\n\t\tcsparameter unsetresource = new csparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function getExportSpecifierLocalTargetSymbol(node) {\n            return node.parent.parent.moduleSpecifier ?\n                getExternalModuleMember(node.parent.parent, node) :\n                resolveEntityName(node.propertyName || node.name, 107455 /* Value */ | 793064 /* Type */ | 1920 /* Namespace */ | 8388608 /* Alias */);\n        }", "label": 3}
{"code": "public static function databaseName($project, $instance, $database)\n    {\n        return self::getDatabaseNameTemplate()->render([\n            'project' => $project,\n            'instance' => $instance,\n            'database' => $database,\n        ]);\n    }", "label": 2}
{"code": "def role_admin():\n    \"\"\"View only allowed to admin role.\"\"\"\n    identity = g.identity\n    actions = {}\n    for action in access.actions.values():\n        actions[action.value] = DynamicPermission(action).allows(identity)\n\n    message = 'You are opening a page requiring the \"admin-access\" permission'\n    return render_template(\"invenio_access/limited.html\",\n                           message=message,\n                           actions=actions,\n                           identity=identity)", "label": 1}
{"code": "def format_errors(details)\n      errors = {messages: [], details: []}\n\n      if details && !details.key?(:finished_count)\n        details.each do |step, report|\n          if step == \"content\"\n            parse_content(report, errors)\n          else\n            parse_generic(report, errors)\n          end\n        end\n      end\n\n      errors\n    end", "label": 4}
{"code": "function Link(properties) {\n                this.signatures = [];\n                if (properties)\n                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n                        if (properties[keys[i]] != null)\n                            this[keys[i]] = properties[keys[i]];\n            }", "label": 3}
{"code": "public static function checkStatic(\n        $method_id,\n        $self_call,\n        $is_context_dynamic,\n        Codebase $codebase,\n        CodeLocation $code_location,\n        array $suppressed_issues,\n        &$is_dynamic_this_method = false\n    ) {\n        $codebase_methods = $codebase->methods;\n\n        if ($method_id === 'Closure::fromcallable') {\n            return true;\n        }\n\n        $original_method_id = $method_id;\n\n        $method_id = $codebase_methods->getDeclaringMethodId($method_id);\n\n        if (!$method_id) {\n            throw new \\LogicException('Declaring method for ' . $original_method_id . ' should not be null');\n        }\n\n        $storage = $codebase_methods->getStorage($method_id);\n\n        if (!$storage->is_static) {\n            if ($self_call) {\n                if (!$is_context_dynamic) {\n                    if (IssueBuffer::accepts(\n                        new NonStaticSelfCall(\n                            'Method ' . $codebase_methods->getCasedMethodId($method_id) .\n                                ' is not static, but is called ' .\n                                'using self::',\n                            $code_location\n                        ),\n                        $suppressed_issues\n                    )) {\n                        return false;\n                    }\n                } else {\n                    $is_dynamic_this_method = true;\n                }\n            } else {\n                if (IssueBuffer::accepts(\n                    new InvalidStaticInvocation(\n                        'Method ' . $codebase_methods->getCasedMethodId($method_id) .\n                            ' is not static, but is called ' .\n                            'statically',\n                        $code_location\n                    ),\n                    $suppressed_issues\n                )) {\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }", "label": 2}
{"code": "func (l VirtualDeviceList) newNVMEBusNumber() int32 {\n\tvar used []int\n\n\tfor _, d := range l.SelectByType((*types.VirtualNVMEController)(nil)) {\n\t\tnum := d.(types.BaseVirtualController).GetVirtualController().BusNumber\n\t\tif num >= 0 {\n\t\t\tused = append(used, int(num))\n\t\t} // else caller is creating a new vm using NVMEControllerTypes\n\t}\n\n\tsort.Ints(used)\n\n\tfor i, n := range nvmeBusNumbers {\n\t\tif i == len(used) || n != used[i] {\n\t\t\treturn int32(n)\n\t\t}\n\t}\n\n\treturn -1\n}", "label": 5}
{"code": "function getClasses(element) {\n    const className = element.className;\n    const classes = {};\n    if (className !== null && className.length > 0) {\n        className.split(' ').forEach((className) => {\n            if (className.trim().length) {\n                classes[className.trim()] = true;\n            }\n        });\n    }\n    return classes;\n}", "label": 3}
{"code": "public function clear() {\n\t\tif ( ! $this->enabled ) {\n\t\t\treturn false;\n\t\t}\n\n\t\t$finder = $this->get_finder();\n\n\t\tforeach ( $finder as $file ) {\n\t\t\tunlink( $file->getRealPath() );\n\t\t}\n\n\t\treturn true;\n\t}", "label": 2}
{"code": "public static function set_url( $url ) {\n\t\tself::debug( 'Set URL: ' . $url, 'bootstrap' );\n\t\t$url_parts = Utils\\parse_url( $url );\n\t\tself::set_url_params( $url_parts );\n\t}", "label": 2}
{"code": "function cloneWrap(obj, circularValue) {\n  circularValue = safeDeepClone(undefined, [], circularValue);\n  return safeDeepClone(circularValue, [], obj);\n}", "label": 3}
{"code": "func ProvisionTokensFromV1(in []ProvisionTokenV1) []ProvisionToken {\n\tif in == nil {\n\t\treturn nil\n\t}\n\tout := make([]ProvisionToken, len(in))\n\tfor i := range in {\n\t\tout[i] = in[i].V2()\n\t}\n\treturn out\n}", "label": 5}
{"code": "def get(self, name):\n        \"\"\"Get a tag.\n\n        :param name: Tag name as string.\n        :return: :class:`tags.Tag <tags.Tag>` object\n        :rtype: tags.Tag\n        \"\"\"\n        schema = TagSchema()\n        resp = self.service.get_id(self.base, name)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function resolvePluginsForBrowsers(browsers) {\n  const plugins = [];\n\n  if (!Array.isArray(browsers)) browsers = [browsers];\n\n  browsers.forEach(browser => {\n    const name = Object.keys(browser)[0];\n    const version = browser[name];\n\n    for (const pluginName in babelPluginsByEnvironmentVersion) {\n      if (\n        !babelPluginsByEnvironmentVersion[pluginName][name] ||\n        babelPluginsByEnvironmentVersion[pluginName][name] > version\n      ) {\n        plugins.push(`babel-plugin-${pluginName}`);\n      }\n    }\n  });\n\n  return plugins;\n}", "label": 3}
{"code": "func OptionHostname(name string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.hostName = name\n\t}\n}", "label": 5}
{"code": "public RgbaColor opacify(float amount) {\n        return new RgbaColor(r, g, b, alphaCheck(a + amount));\n    }", "label": 0}
{"code": "def setup_package():\n    \"\"\"\n    Setup the package.\n    \"\"\"\n    with open('requirements.txt', 'r') as req_file:\n        install_reqs = req_file.read().split('\\n')\n\n    cmdclass_ = {'antlr': AntlrBuildCommand}\n    cmdclass_.update(versioneer.get_cmdclass())\n\n    setup(\n        version=versioneer.get_version(),\n        name='pymoca',\n        maintainer=\"James Goppert\",\n        maintainer_email=\"james.goppert@gmail.com\",\n        description=DOCLINES[0],\n        long_description=\"\\n\".join(DOCLINES[2:]),\n        url='https://github.com/pymoca/pymoca',\n        author='James Goppert',\n        author_email='james.goppert@gmail.com',\n        download_url='https://github.com/pymoca/pymoca',\n        license='BSD',\n        classifiers=[_f for _f in CLASSIFIERS.split('\\n') if _f],\n        platforms=[\"Windows\", \"Linux\", \"Solaris\", \"Mac OS-X\", \"Unix\"],\n        install_requires=install_reqs,\n        tests_require=['coverage >= 3.7.1', 'nose >= 1.3.1'],\n        test_suite='nose.collector',\n        python_requires='>=3.5',\n        packages=find_packages(\"src\"),\n        package_dir={\"\": \"src\"},\n        include_package_data=True,\n        cmdclass=cmdclass_\n    )", "label": 1}
{"code": "func (ag *AuthGroup) Update(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !ag._exists {\n\t\treturn errors.New(\"update failed: does not exist\")\n\t}\n\n\t// if deleted, bail\n\tif ag._deleted {\n\t\treturn errors.New(\"update failed: marked for deletion\")\n\t}\n\n\t// sql query\n\tconst sqlstr = `UPDATE auth_group SET ` +\n\t\t`name = ?` +\n\t\t` WHERE id = ?`\n\n\t// run query\n\tXOLog(sqlstr, ag.Name, ag.ID)\n\t_, err = db.Exec(sqlstr, ag.Name, ag.ID)\n\treturn err\n}", "label": 5}
{"code": "public function versionCompare($frameworkVersion, $compareVersion, $operator = null)\n    {\n        // Lumen (5.5.2) (Laravel Components 5.5.*)\n        $lumenPattern = '/Lumen \\((\\d\\.\\d\\.[\\d|\\*])\\)( \\(Laravel Components (\\d\\.\\d\\.[\\d|\\*])\\))?/';\n\n        if (preg_match($lumenPattern, $frameworkVersion, $matches)) {\n            $frameworkVersion = isset($matches[3]) ? $matches[3] : $matches[1]; // Prefer Laravel Components version.\n        }\n\n        return version_compare($frameworkVersion, $compareVersion, $operator);\n    }", "label": 2}
{"code": "def start_upsert(ini_data):\n    \"\"\"\n    Helper function to facilitate upsert.\n\n    Args:\n        ini_date - the dictionary of info to run upsert\n\n   Exit:\n       0 - good\n       1 - bad\n    \"\"\"\n    stack_driver = CloudStackUtility(ini_data)\n    poll_stack = not ini_data.get('no_poll', False)\n    if stack_driver.upsert():\n        logging.info('stack create/update was started successfully.')\n\n        if poll_stack:\n            stack_tool = None\n            try:\n                profile = ini_data.get('environment', {}).get('profile')\n                if profile:\n                    boto3_session = boto3.session.Session(profile_name=profile)\n                else:\n                    boto3_session = boto3.session.Session()\n\n                region = ini_data['environment']['region']\n                stack_name = ini_data['environment']['stack_name']\n\n                cf_client = stack_driver.get_cloud_formation_client()\n\n                if not cf_client:\n                    cf_client = boto3_session.client('cloudformation', region_name=region)\n\n                stack_tool = stack_tool = StackTool(\n                    stack_name,\n                    region,\n                    cf_client\n                )\n            except Exception as wtf:\n                logging.warning('there was a problems creating stack tool: {}'.format(wtf))\n\n            if stack_driver.poll_stack():\n                try:\n                    logging.info('stack create/update was finished successfully.')\n                    stack_tool.print_stack_info()\n                except Exception as wtf:\n                    logging.warning('there was a problems printing stack info: {}'.format(wtf))\n\n                sys.exit(0)\n            else:\n                try:\n                    logging.error('stack create/update was did not go well.')\n                    stack_tool.print_stack_events()\n                except Exception as wtf:\n                    logging.warning('there was a problems printing stack events: {}'.format(wtf))\n                sys.exit(1)\n    else:\n        logging.error('start of stack create/update did not go well.')\n        sys.exit(1)", "label": 1}
{"code": "def move_app_thinning\n      if File.exist?(PackageCommandGenerator.app_thinning_path)\n        FileUtils.mv(PackageCommandGenerator.app_thinning_path, File.expand_path(Gym.config[:output_directory]), force: true)\n        app_thinning_path = File.join(File.expand_path(Gym.config[:output_directory]), File.basename(PackageCommandGenerator.app_thinning_path))\n\n        UI.success(\"Successfully exported the app-thinning.plist file:\")\n        UI.message(app_thinning_path)\n        app_thinning_path\n      end\n    end", "label": 4}
{"code": "func TimeoutErrorf(format string, params ...interface{}) error {\n\treturn timeout(fmt.Sprintf(format, params...))\n}", "label": 5}
{"code": "public function isTypeContainedByType(\n        Type\\Union $input_type,\n        Type\\Union $container_type\n    ): bool {\n        return TypeAnalyzer::isContainedBy($this, $input_type, $container_type);\n    }", "label": 2}
{"code": "public function setQuasiIdsValues($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\Value::class);\n        $this->quasi_ids_values = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def append_attribute(node, attribute, value)\n      current_value = node.get_attribute(attribute) || ''\n      current_values = current_value.split(/\\s+/)\n      updated_value = current_values | [value]\n      node.set_attribute(attribute, updated_value.join(' '))\n    end", "label": 4}
{"code": "public static float Sum(float[] data) {\r\n        float sum = 0;\r\n        for (int i = 0; i < data.length; i++) {\r\n            sum += data[i];\r\n        }\r\n        return sum;\r\n    }", "label": 0}
{"code": "public static dnssuffix[] get(nitro_service service, String Dnssuffix[]) throws Exception{\n\t\tif (Dnssuffix !=null && Dnssuffix.length>0) {\n\t\t\tdnssuffix response[] = new dnssuffix[Dnssuffix.length];\n\t\t\tdnssuffix obj[] = new dnssuffix[Dnssuffix.length];\n\t\t\tfor (int i=0;i<Dnssuffix.length;i++) {\n\t\t\t\tobj[i] = new dnssuffix();\n\t\t\t\tobj[i].set_Dnssuffix(Dnssuffix[i]);\n\t\t\t\tresponse[i] = (dnssuffix) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public static appqoepolicy_binding get(nitro_service service, String name) throws Exception{\n\t\tappqoepolicy_binding obj = new appqoepolicy_binding();\n\t\tobj.set_name(name);\n\t\tappqoepolicy_binding response = (appqoepolicy_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "async function sleep(seconds) {\n    let ms = seconds * 1000;\n    while (ms > _maxTimeout) {\n        // Support sleeping longer than the javascript max setTimeout...\n        await new Promise(resolve => setTimeout(resolve, _maxTimeout));\n        ms -= _maxTimeout;\n    }\n    return await new Promise(resolve => setTimeout(resolve, ms, seconds));\n}", "label": 3}
{"code": "public static <E> Set<E> diff(Set<E> s1, Set<E> s2) {\r\n    Set<E> s = new HashSet<E>();\r\n    for (E o : s1) {\r\n      if (!s2.contains(o)) {\r\n        s.add(o);\r\n      }\r\n    }\r\n    return s;\r\n  }", "label": 0}
{"code": "function(out)\n  {\n    var target = out || {};\n    var keys = this.keys;\n    var values = this.values;\n\n    for (var i = 0; i < keys.length; i++)\n    {\n      target[ keys[ i ] ] = values[ i ];\n    }\n\n    return target;\n  }", "label": 3}
{"code": "private void createResultSubClassesMultipleJoinedTables(List result, ClassDescriptor cld, boolean wholeTree)\r\n    {\r\n        List tmp = (List) superClassMultipleJoinedTablesMap.get(cld.getClassOfObject());\r\n        if(tmp != null)\r\n        {\r\n            result.addAll(tmp);\r\n            if(wholeTree)\r\n            {\r\n                for(int i = 0; i < tmp.size(); i++)\r\n                {\r\n                    Class subClass = (Class) tmp.get(i);\r\n                    ClassDescriptor subCld = getDescriptorFor(subClass);\r\n                    createResultSubClassesMultipleJoinedTables(result, subCld, wholeTree);\r\n                }\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def fetch_withdrawals(self, limit: int) -> List[Withdrawal]:\n        \"\"\"Fetch latest withdrawals, must provide a limit.\"\"\"\n        return self._transactions(self._withdrawals, 'withdrawals', limit)", "label": 1}
{"code": "def register_host():\n    \"\"\"Register supported hosts\"\"\"\n    pyblish.api.register_host(\"hython\")\n    pyblish.api.register_host(\"hpython\")\n    pyblish.api.register_host(\"houdini\")", "label": 1}
{"code": "public function addCollection($key, RouteCollection $routes, $prefix = null)\n    {\n        $this->routes[$key] = new RouteCollectionUrlGenerator(\n            $this->app->url($prefix),\n            $routes\n        );\n\n        return $this;\n    }", "label": 2}
{"code": "def format_hdr(self, delim=',', qu='\"'):\n        \"\"\"\n        Prepares the header in CSV format\n        \"\"\"\n        res = ''\n        if self.header:\n            for d in self.header:\n                res += qu + str(d) + qu + delim\n        return res + '\\n'", "label": 1}
{"code": "def omniauth_params\n      unless defined?(@_omniauth_params)\n        if request.env['omniauth.params'] && request.env['omniauth.params'].any?\n          @_omniauth_params = request.env['omniauth.params']\n        elsif session['dta.omniauth.params'] && session['dta.omniauth.params'].any?\n          @_omniauth_params ||= session.delete('dta.omniauth.params')\n          @_omniauth_params\n        elsif params['omniauth_window_type']\n          @_omniauth_params = params.slice('omniauth_window_type', 'auth_origin_url', 'resource_class', 'origin')\n        else\n          @_omniauth_params = {}\n        end\n      end\n      @_omniauth_params\n\n    end", "label": 4}
{"code": "func isDataURI(fl FieldLevel) bool {\n\n\turi := strings.SplitN(fl.Field().String(), \",\", 2)\n\n\tif len(uri) != 2 {\n\t\treturn false\n\t}\n\n\tif !dataURIRegex.MatchString(uri[0]) {\n\t\treturn false\n\t}\n\n\treturn base64Regex.MatchString(uri[1])\n}", "label": 5}
{"code": "func (i *TeleInstance) NewClientWithCreds(cfg ClientConfig, creds UserCreds) (tc *client.TeleportClient, err error) {\n\tclt, err := i.NewUnauthenticatedClient(cfg)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\terr = SetupUserCreds(clt, i.Config.Proxy.SSHAddr.Addr, creds)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn clt, nil\n}", "label": 5}
{"code": "function removeMethod (char, method) {\n  if (!hasKeybinding(char, method)) return;\n  var fnIndex = bindings[char].methods.indexOf(method);\n  window.removeEventListener('keyup', bindings[char].listeners[fnIndex]);\n  bindings[char].methods.splice(fnIndex, 1);\n  bindings[char].listeners.splice(fnIndex, 1);\n\n  if (!bindings[char].methods.length) {\n    delete bindings[char];\n  } else if (fnIndex === 0) {\n    window.addEventListener('keyup', bindings[char].listeners[0]);\n  }\n}", "label": 3}
{"code": "def decrypt_if_necessary(\n      zip_file,\n      content_entry,\n      roo_content_xml_path, options\n    )\n      # Check if content.xml is encrypted by extracting manifest.xml\n      # and searching for a manifest:encryption-data element\n\n      if (manifest_entry = zip_file.glob('META-INF/manifest.xml').first)\n        roo_manifest_xml_path = File.join(@tmpdir, 'roo_manifest.xml')\n        manifest_entry.extract(roo_manifest_xml_path)\n        manifest        = ::Roo::Utils.load_xml(roo_manifest_xml_path)\n\n        # XPath search for manifest:encryption-data only for the content.xml\n        # file\n\n        encryption_data = manifest.xpath(\n          \"//manifest:file-entry[@manifest:full-path='content.xml']\"\\\n        \"/manifest:encryption-data\"\n        ).first\n\n        # If XPath returns a node, then we know content.xml is encrypted\n\n        unless encryption_data.nil?\n\n          # Since we know it's encrypted, we check for the password option\n          # and if it doesn't exist, raise an argument error\n\n          password = options[:password]\n          if !password.nil?\n            perform_decryption(\n              encryption_data,\n              password,\n              content_entry,\n              roo_content_xml_path\n            )\n          else\n            fail ArgumentError, 'file is encrypted but password was not supplied'\n          end\n        end\n      else\n        fail ArgumentError, 'file missing required META-INF/manifest.xml'\n      end\n    end", "label": 4}
{"code": "def sub_sam(sam, percent, sort = True, sbuffer = False):\n    \"\"\"\n    randomly subset sam file\n    \"\"\"\n    mapping = sort_sam(sam, sort)\n    pool = [1 for i in range(0, percent)] + [0 for i in range(0, 100 - percent)]\n    c = cycle([1, 2])\n    for line in mapping:\n        line = line.strip().split()\n        if line[0].startswith('@'): # get the sam header\n            yield line\n            continue\n        if int(line[1]) <= 20: # is this from a single read?\n            if random.choice(pool) == 1:\n                yield line\n        else:\n            n = next(c)\n            if n == 1:\n                prev = line\n            if n == 2 and random.choice(pool) == 1:\n                yield prev\n                yield line", "label": 1}
{"code": "def push_mark(pos = @point)\n      @mark = new_mark\n      @mark.location = pos\n      @mark_ring.push(@mark)\n      if self != Buffer.minibuffer\n        global_mark_ring = Buffer.global_mark_ring\n        if global_mark_ring.empty? || global_mark_ring.current.buffer != self\n          push_global_mark(pos)\n        end\n      end\n    end", "label": 4}
{"code": "func (cl *Client) AddTorrentInfoHashWithStorage(infoHash metainfo.Hash, specStorage storage.ClientImpl) (t *Torrent, new bool) {\n\tcl.lock()\n\tdefer cl.unlock()\n\tt, ok := cl.torrents[infoHash]\n\tif ok {\n\t\treturn\n\t}\n\tnew = true\n\n\tt = cl.newTorrent(infoHash, specStorage)\n\tcl.eachDhtServer(func(s *dht.Server) {\n\t\tgo t.dhtAnnouncer(s)\n\t})\n\tcl.torrents[infoHash] = t\n\tcl.clearAcceptLimits()\n\tt.updateWantPeersEvent()\n\t// Tickle Client.waitAccept, new torrent may want conns.\n\tcl.event.Broadcast()\n\treturn\n}", "label": 5}
{"code": "def mv(self, local_file, target_file, acl='public-read', overwrite=True, invalidate=False):\n        \"\"\"\n        Similar to Linux mv command.\n\n        Move the file to the S3 and deletes the local copy\n\n        It is basically s3utils.cp that has del_after_upload=True\n\n        Examples\n        --------\n            >>> s3utils.mv(\"path/to/folder\",\"/test/\")\n            moving /path/to/myfolder/test2.txt to test/myfolder/test2.txt\n            moving /path/to/myfolder/test.txt to test/myfolder/test.txt\n            moving /path/to/myfolder/hoho/photo.JPG to test/myfolder/hoho/photo.JPG\n            moving /path/to/myfolder/hoho/haha/ff to test/myfolder/hoho/haha/ff\n\n        **Returns:**\n\n        Nothing on success, otherwise what went wrong.\n\n        Return type:\n        dict\n\n        \"\"\"\n        self.cp(local_file, target_file, acl=acl, del_after_upload=True, overwrite=overwrite, invalidate=invalidate)", "label": 1}
{"code": "public void setSpecificDeviceClass(Specific specificDeviceClass) throws IllegalArgumentException {\r\n\t\t\r\n\t\t// The specific Device class does not match the generic device class.\r\n\t\tif (specificDeviceClass.genericDeviceClass != Generic.NOT_KNOWN && \r\n\t\t\t\tspecificDeviceClass.genericDeviceClass != this.genericDeviceClass)\r\n\t\t\tthrow new IllegalArgumentException(\"specificDeviceClass\");\r\n\t\t\r\n\t\tthis.specificDeviceClass = specificDeviceClass;\r\n\t}", "label": 0}
{"code": "public static base_response clear(nitro_service client, rnat resource) throws Exception {\n\t\trnat clearresource = new rnat();\n\t\tclearresource.network = resource.network;\n\t\tclearresource.netmask = resource.netmask;\n\t\tclearresource.aclname = resource.aclname;\n\t\tclearresource.redirectport = resource.redirectport;\n\t\tclearresource.natip = resource.natip;\n\t\tclearresource.td = resource.td;\n\t\treturn clearresource.perform_operation(client,\"clear\");\n\t}", "label": 0}
{"code": "def text_fields_hash\n      @text_fields_hash ||=\n        setups.inject({}) do |hash, setup|\n          setup.all_text_fields.each do |text_field|\n            (hash[text_field.name] ||= Set.new) << text_field\n          end\n          hash\n        end\n    end", "label": 4}
{"code": "def get_prop(self, prop):\n        \"\"\" Calls the getter with no arguments and returns its value \"\"\"\n\n        if self._parser is None:\n            raise ConfigurationError('Cannot call ParserProperty.\"get_prop\" with no parser configured')\n\n        return self._parser(prop) if prop else self._parser()", "label": 1}
{"code": "function (child, parent, context) {\n            var theDialog = dialog.getDialog(context.model);\n            var $child = $(child);\n            var loadables = $child.find(\"img\").filter(function () {\n                //Remove images with known width and height\n                var $this = $(this);\n                return !(this.style.width && this.style.height) && !($this.attr(\"width\") && $this.attr(\"height\"));\n            });\n\n            $child.data(\"predefinedWidth\", $child.get(0).style.width);\n\n            var setDialogPosition = function () {\n                //Setting a short timeout is need in IE8, otherwise we could do this straight away\n                setTimeout(function () {\n                    //We will clear and then set width for dialogs without width set \n                    if (!$child.data(\"predefinedWidth\")) {\n                        $child.css({ width: '' }); //Reset width\n                    }\n                    var width = $child.outerWidth(false);\n                    var height = $child.outerHeight(false);\n                    var windowHeight = $(window).height();\n                    var constrainedHeight = Math.min(height, windowHeight);\n\n                    $child.css({\n                        'margin-top': (-constrainedHeight / 2).toString() + 'px',\n                        'margin-left': (-width / 2).toString() + 'px'\n                    });\n\n                    if (!$child.data(\"predefinedWidth\")) {\n                        //Ensure the correct width after margin-left has been set\n                        $child.outerWidth(width);\n                    }\n\n                    if (height > windowHeight) {\n                        $child.css(\"overflow-y\", \"auto\");\n                    } else {\n                        $child.css(\"overflow-y\", \"\");\n                    }\n\n                    $(theDialog.host).css('opacity', 1);\n                    $child.css(\"visibility\", \"visible\");\n\n                    $child.find('.autofocus').first().focus();\n                }, 1);\n            };\n\n            setDialogPosition();\n            loadables.load(setDialogPosition);\n\n            if ($child.hasClass('autoclose')) {\n                $(theDialog.blockout).click(function () {\n                    theDialog.close();\n                });\n            }\n        }", "label": 3}
{"code": "function collapse(d) {\n    if (d.children) {\n      d._children = d.children;\n      d._children.forEach(collapse);\n      d.children = null;\n    }\n  }", "label": 3}
{"code": "protected void ensureColumns(List columns, List existingColumns)\r\n    {\r\n        if (columns == null || columns.isEmpty())\r\n        {\r\n            return;\r\n        }\r\n        \r\n        Iterator iter = columns.iterator();\r\n\r\n        while (iter.hasNext())\r\n        {\r\n            FieldHelper cf = (FieldHelper) iter.next();\r\n            if (!existingColumns.contains(cf.name))\r\n            {\r\n                getAttributeInfo(cf.name, false, null, getQuery().getPathClasses());\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def raw_abundance(biomf, sampleIDs=None, sample_abd=True):\n    \"\"\"\n    Calculate the total number of sequences in each OTU or SampleID.\n\n    :type biomf: A BIOM file.\n    :param biomf: OTU table format.\n\n    :type sampleIDs: List\n    :param sampleIDs: A list of column id's from BIOM format OTU table. By default, the\n                      list has been set to None.\n\n    :type sample_abd: Boolean\n    :param sample_abd: A boolean operator to provide output for OTUID's or SampleID's. By\n                       default, the output will be provided for SampleID's.\n\n    :rtype: dict\n    :return: Returns a dictionary keyed on either OTUID's or SampleIDs and their\n             respective abundance as values.\n    \"\"\"\n    results = defaultdict(int)\n    if sampleIDs is None:\n        sampleIDs = biomf.ids()\n    else:\n        try:\n            for sid in sampleIDs:\n                assert sid in biomf.ids()\n        except AssertionError:\n            raise ValueError(\n                \"\\nError while calculating raw total abundances: The sampleIDs provided \"\n                \"do not match the sampleIDs in biom file. Please double check the \"\n                \"sampleIDs provided.\\n\")\n    otuIDs = biomf.ids(axis=\"observation\")\n\n    for sampleID in sampleIDs:\n        for otuID in otuIDs:\n            abd = biomf.get_value_by_ids(otuID, sampleID)\n            if sample_abd:\n                results[sampleID] += abd\n            else:\n                results[otuID] += abd\n    return results", "label": 1}
{"code": "def s_supply(self, bus):\n        \"\"\" Returns the total complex power generation capacity.\n        \"\"\"\n        Sg = array([complex(g.p, g.q) for g in self.generators if\n                   (g.bus == bus) and not g.is_load], dtype=complex64)\n\n        if len(Sg):\n            return sum(Sg)\n        else:\n            return 0 + 0j", "label": 1}
{"code": "public function setDeidentifyTemplate($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\DeidentifyTemplate::class);\n        $this->deidentify_template = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function runQuery(QueryInterface $query, array $options = [])\n    {\n        $options += [\n            'className' => Entity::class,\n            'namespaceId' => $this->namespaceId\n        ];\n\n        $iteratorConfig = [\n            'itemsKey' => 'batch.entityResults',\n            'resultTokenKey' => 'query.startCursor',\n            'nextResultTokenKey' => 'batch.endCursor',\n            'setNextResultTokenCondition' => function ($res) use ($query) {\n                if (isset($res['batch']['moreResults'])) {\n                    $moreResultsType = $res['batch']['moreResults'];\n                    // Transform gRPC enum to string\n                    if (is_numeric($moreResultsType)) {\n                        $moreResultsType = MoreResultsType::name($moreResultsType);\n                    }\n\n                    return $query->canPaginate() && $moreResultsType === 'NOT_FINISHED';\n                }\n\n                return false;\n            }\n        ];\n\n        $runQueryObj = clone $query;\n        $runQueryFn = function (array $args = []) use (&$runQueryObj, $options) {\n            $args += [\n                'query' => []\n            ];\n\n            // The iterator provides the startCursor for subsequent pages as an argument.\n            $requestQueryArr = $args['query'] + $runQueryObj->queryObject();\n            $request = [\n                'projectId' => $this->projectId,\n                'partitionId' => $this->partitionId($this->projectId, $options['namespaceId']),\n                $runQueryObj->queryKey() => $requestQueryArr\n            ] + $this->readOptions($options) + $options;\n\n            $res = $this->connection->runQuery($request);\n\n            // When executing a GQL Query, the server will compute a query object\n            // and return it with the first response batch.\n            // Automatic pagination with GQL is accomplished by requesting\n            // subsequent pages with this query object, and discarding the GQL\n            // query. This is done by replacing the GQL object with a Query\n            // instance prior to the next iteration of the page.\n            if (isset($res['query'])) {\n                $runQueryObj = new Query($this->entityMapper, $res['query']);\n            }\n\n            return $res;\n        };\n\n        return new EntityIterator(\n            new EntityPageIterator(\n                function (array $entityResult) use ($options) {\n                    return $this->mapEntityResult($entityResult, $options['className']);\n                },\n                $runQueryFn,\n                [],\n                $iteratorConfig\n            )\n        );\n    }", "label": 2}
{"code": "protected static function modelsFor(array $targets)\n    {\n        $models = [];\n\n        foreach ($targets as $target) {\n            $models[] = collect((new ReflectionClass($target))->getProperties())->map(function ($property) use ($target) {\n                $property->setAccessible(true);\n\n                $value = $property->getValue($target);\n\n                if ($value instanceof Model) {\n                    return [$value];\n                } elseif ($value instanceof EloquentCollection) {\n                    return $value->flatten();\n                }\n            })->collapse()->filter()->all();\n        }\n\n        return collect(Arr::collapse($models))->unique();\n    }", "label": 2}
{"code": "public List<Cluster> cluster(final Collection<Point2D> points) {\n    \tfinal List<Cluster> clusters = new ArrayList<Cluster>();\n        final Map<Point2D, PointStatus> visited = new HashMap<Point2D, DBScan.PointStatus>();\n\n        KDTree<Point2D> tree = new KDTree<Point2D>(2);\n        \n        // Populate the kdTree\n        for (final Point2D point : points) {\n        \tdouble[] key = {point.x, point.y};\n        \ttree.insert(key, point);\n        }\n                \n        for (final Point2D point : points) {\n            if (visited.get(point) != null) {\n                continue;\n            }\n            final List<Point2D> neighbors = getNeighbors(point, tree);\n            if (neighbors.size() >= minPoints) {\n                // DBSCAN does not care about center points\n                final Cluster cluster = new Cluster(clusters.size());\n                clusters.add(expandCluster(cluster, point, neighbors, tree, visited));\n            } else {\n                visited.put(point, PointStatus.NOISE);\n            }\n        }\n\n        for (Cluster cluster : clusters) {\n        \tcluster.calculateCentroid();\n        }\n        \n        return clusters;\n    }", "label": 0}
{"code": "private function formatCommand($command, $parameters)\n    {\n        $parameters = collect($parameters)->map(function ($parameter) {\n            if (is_array($parameter)) {\n                return collect($parameter)->map(function ($value, $key) {\n                    return is_int($key) ? $value : \"{$key} {$value}\";\n                })->implode(' ');\n            }\n\n            return $parameter;\n        })->implode(' ');\n\n        return \"{$command} {$parameters}\";\n    }", "label": 2}
{"code": "protected function getColumnSearchKeyword($i, $raw = false)\n    {\n        $keyword = $this->request->columnKeyword($i);\n        if ($raw || $this->request->isRegex($i)) {\n            return $keyword;\n        }\n\n        return $this->setupKeyword($keyword);\n    }", "label": 2}
{"code": "function emit(retry) {\n    if (self._interrupted) {\n      // The request's callback will already have been called.\n      return;\n    }\n\n    var hreq = self._createHandshakeRequest(adapter, !retry);\n\n    var writable = self._writableFactory.call(self, function (err, readable) {\n      if (err) {\n        cb(err);\n        return;\n      }\n      readable.on('data', function (obj) {\n        debug('received response %s', obj.id);\n        // We don't check that the prefix matches since the ID likely hasn't\n        // been propagated to the response (see default stateless codec).\n        var buf = Buffer.concat(obj.payload);\n        try {\n          var parts = readHead(HANDSHAKE_RESPONSE_TYPE, buf);\n          var hres = parts.head;\n          if (hres.serverHash) {\n            adapter = self._getAdapter(hres);\n          }\n        } catch (err) {\n          cb(err);\n          return;\n        }\n        self.emit('handshake', hreq, hres);\n        if (hres.match === 'NONE') {\n          process.nextTick(function() { emit(true); });\n          return;\n        }\n        // Change the default adapter.\n        self._adapter = adapter;\n        cb(null, parts.tail, adapter);\n      });\n    });\n\n    writable.write({\n      id: id,\n      payload: [HANDSHAKE_REQUEST_TYPE.toBuffer(hreq), reqBuf]\n    });\n    if (self._endWritable) {\n      writable.end();\n    }\n  }", "label": 3}
{"code": "def haml_bind_proc(&proc)\n      _hamlout = haml_buffer\n      #double assignment is to avoid warnings\n      _erbout = _erbout = _hamlout.buffer\n      proc { |*args| proc.call(*args) }\n    end", "label": 4}
{"code": "def _linear_constraints(self, om):\n        \"\"\" Returns the linear problem constraints.\n        \"\"\"\n        A, l, u = om.linear_constraints() # l <= A*x <= u\n\n        # Indexes for equality, greater than (unbounded above), less than\n        # (unbounded below) and doubly-bounded box constraints.\n#        ieq = flatnonzero( abs(u - l) <= EPS )\n#        igt = flatnonzero( (u >=  1e10) & (l > -1e10) )\n#        ilt = flatnonzero( (l <= -1e10) & (u <  1e10) )\n#        ibx = flatnonzero( (abs(u - l) > EPS) & (u < 1e10) & (l > -1e10) )\n\n        # Zero-sized sparse matrices not supported.  Assume equality\n        # constraints exist.\n##        AA = A[ieq, :]\n##        if len(ilt) > 0:\n##            AA = vstack([AA, A[ilt, :]], \"csr\")\n##        if len(igt) > 0:\n##            AA = vstack([AA, -A[igt, :]], \"csr\")\n##        if len(ibx) > 0:\n##            AA = vstack([AA, A[ibx, :], -A[ibx, :]], \"csr\")\n#\n#        if len(ieq) or len(igt) or len(ilt) or len(ibx):\n#            sig_idx = [(1, ieq), (1, ilt), (-1, igt), (1, ibx), (-1, ibx)]\n#            AA = vstack([sig * A[idx, :] for sig, idx in sig_idx if len(idx)])\n#        else:\n#            AA = None\n#\n#        bb = r_[u[ieq, :], u[ilt], -l[igt], u[ibx], -l[ibx]]\n#\n#        self._nieq = ieq.shape[0]\n#\n#        return AA, bb\n\n        return A, l, u", "label": 1}
{"code": "function(req, res) {\n    var params = URL.parse(req.url, true).query\n      , code = params.code\n      , state = params.state\n    ;\n\n    if(!code) {\n      res.writeHead(400, {'Content-Type': 'text/plain'});\n      return res.end('The \"code\" parameter is missing.');\n    }\n    if(!state) {\n      res.writeHead(400, {'Content-Type': 'text/plain'});\n      return res.end('The \"state\" parameter is missing.');\n    }\n    try {\n      state = this.serializer.parse(state);\n    } catch(err) {\n      res.writeHead(400, {'Content-Type': 'text/plain'});\n      return res.end('The \"state\" parameter is invalid.');\n    }\n    var data = {\n      oauth2_server_id: state[0]\n      , next_url: state[1]\n      , state: state[2]\n    }\n    var methods = this.methods[data.oauth2_server_id];\n    methods.valid_grant(data, code, function(err, token) {\n      if (err) return server_error(res, err);\n      if(!token) {\n        res.writeHead(400, {'Content-Type': 'text/plain'});\n        res.end('Invalid grant.');\n        return;\n      }\n      data.token = token;\n      methods.treat_access_token(data, req, res, function() {\n        redirect(res, data.next_url);\n      }, function(err){server_error(res, err)});\n    });\n  }", "label": 3}
{"code": "func (ts *Store) Check(id string) (string, error) {\n\ttreeStoreKeyLock, err := lock.SharedKeyLock(ts.lockDir, id)\n\tif err != nil {\n\t\treturn \"\", errwrap.Wrap(errors.New(\"error locking tree store\"), err)\n\t}\n\tdefer treeStoreKeyLock.Close()\n\n\treturn ts.check(id)\n}", "label": 5}
{"code": "def add_path(self, path, path_filter=None):\n        \"\"\"\n        Adding all files from given path to the object.\n\n        Args:\n            path (str): valid, existing directory\n        \"\"\"\n        for root, _, files in os.walk(path):\n            for filename in files:\n                full_path_and_filename = os.path.join(root, filename)\n                if path_filter is None or path_filter(full_path_and_filename):\n                    relative_path_and_filename = full_path_and_filename.replace(path + '/', '')\n                    with open(full_path_and_filename, 'rb') as handle:\n                        self.files[relative_path_and_filename] = b64encode(handle.read()).decode('utf-8')", "label": 1}
{"code": "function(grouping)\n  {\n    var by = createPropertyResolver( grouping.by );\n    var having = createWhere( grouping.having, grouping.havingValue, grouping.havingEquals );\n    var select = grouping.select || {};\n    var map = {};\n\n    if ( isString( grouping.by ) )\n    {\n      if ( !(grouping.by in select) )\n      {\n        select[ grouping.by ] = 'first';\n      }\n    }\n    else if ( isArray( grouping.by ) )\n    {\n      for (var prop in grouping.by)\n      {\n        if ( !(prop in select) )\n        {\n          select[ prop ] = 'first';\n        }\n      }\n    }\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var model = this[ i ];\n      var key = by( model );\n      var group = map[ key ];\n\n      if ( !group )\n      {\n        group = map[ key ] = this.cloneEmpty();\n      }\n\n      group.add( model, true );\n    }\n\n    var groupings = this.cloneEmpty();\n\n    groupings.setComparator( grouping.comparator, grouping.comparatorNullsFirst );\n\n    for (var key in map)\n    {\n      var grouped = {};\n      var groupArray = map[ key ];\n\n      for (var propName in select)\n      {\n        var aggregator = select[ propName ];\n\n        if ( isString( aggregator ) )\n        {\n          grouped[ propName ] = groupArray[ aggregator ]( propName );\n        }\n        else if ( isFunction( aggregator ) )\n        {\n          grouped[ propName ] = aggregator( groupArray, propName );\n        }\n      }\n\n      if ( grouping.track !== false )\n      {\n        grouped.$group = groupArray;\n      }\n\n      if ( grouping.count !== false )\n      {\n        grouped.$count = groupArray.length;\n      }\n\n      if ( having( grouped, groupArray ) )\n      {\n        groupings.push( grouped );\n      }\n    }\n\n    groupings.sort();\n\n    return groupings;\n  }", "label": 3}
{"code": "function ResonanceAudio(context, options) {\n  // Public variables.\n  /**\n   * Binaurally-rendered stereo (2-channel) output {@link\n   * https://developer.mozilla.org/en-US/docs/Web/API/AudioNode AudioNode}.\n   * @member {AudioNode} output\n   * @memberof ResonanceAudio\n   * @instance\n   */\n  /**\n   * Ambisonic (multichannel) input {@link\n   * https://developer.mozilla.org/en-US/docs/Web/API/AudioNode AudioNode}\n   * (For rendering input soundfields).\n   * @member {AudioNode} ambisonicInput\n   * @memberof ResonanceAudio\n   * @instance\n   */\n  /**\n   * Ambisonic (multichannel) output {@link\n   * https://developer.mozilla.org/en-US/docs/Web/API/AudioNode AudioNode}\n   * (For allowing external rendering / post-processing).\n   * @member {AudioNode} ambisonicOutput\n   * @memberof ResonanceAudio\n   * @instance\n   */\n\n  // Use defaults for undefined arguments.\n  if (options == undefined) {\n    options = {};\n  }\n  if (options.ambisonicOrder == undefined) {\n    options.ambisonicOrder = Utils.DEFAULT_AMBISONIC_ORDER;\n  }\n  if (options.listenerPosition == undefined) {\n    options.listenerPosition = Utils.DEFAULT_POSITION.slice();\n  }\n  if (options.listenerForward == undefined) {\n    options.listenerForward = Utils.DEFAULT_FORWARD.slice();\n  }\n  if (options.listenerUp == undefined) {\n    options.listenerUp = Utils.DEFAULT_UP.slice();\n  }\n  if (options.dimensions == undefined) {\n    options.dimensions = {};\n    Object.assign(options.dimensions, Utils.DEFAULT_ROOM_DIMENSIONS);\n  }\n  if (options.materials == undefined) {\n    options.materials = {};\n    Object.assign(options.materials, Utils.DEFAULT_ROOM_MATERIALS);\n  }\n  if (options.speedOfSound == undefined) {\n    options.speedOfSound = Utils.DEFAULT_SPEED_OF_SOUND;\n  }\n\n  // Create member submodules.\n  this._ambisonicOrder = Encoder.validateAmbisonicOrder(options.ambisonicOrder);\n  this._sources = [];\n  this._room = new Room(context, {\n    listenerPosition: options.listenerPosition,\n    dimensions: options.dimensions,\n    materials: options.materials,\n    speedOfSound: options.speedOfSound,\n  });\n  this._listener = new Listener(context, {\n    ambisonicOrder: options.ambisonicOrder,\n    position: options.listenerPosition,\n    forward: options.listenerForward,\n    up: options.listenerUp,\n  });\n\n  // Create auxillary audio nodes.\n  this._context = context;\n  this.output = context.createGain();\n  this.ambisonicOutput = context.createGain();\n  this.ambisonicInput = this._listener.input;\n\n  // Connect audio graph.\n  this._room.output.connect(this._listener.input);\n  this._listener.output.connect(this.output);\n  this._listener.ambisonicOutput.connect(this.ambisonicOutput);\n}", "label": 3}
{"code": "function registerPlugin(resource, config, silent) {\n  let module;\n\n  try {\n    module = 'string' == typeof resource ? require(resource) : resource;\n  } catch (err) {\n    return warn(`unable to load plugin ${strong(resource)}`);\n  }\n\n  if (!('register' in module)) return warn(`invalid plugin ${strong(resource)}`);\n\n  module.register(config);\n  if (!silent) print(`registered plugin ${strong(module.name)}`, 0);\n}", "label": 3}
{"code": "private function mergeValues(array $set1, array $set2)\n    {\n        // `$set2` may be empty if an array value is chunked at the end of the\n        // list. Handling it normally results in an additional `null` value\n        // being pushed onto the list of values. Since this method is only\n        // called in cases where two chunks must be merged, we can safely\n        // short-circuit the operation of the second chunk is empty.\n        if (empty($set2)) {\n            return $set1;\n        }\n\n        $lastItemSet1 = array_pop($set1);\n        $firstItemSet2 = array_shift($set2);\n        $item = $firstItemSet2;\n\n        if (is_string($lastItemSet1) && is_string($firstItemSet2)) {\n            $item = $lastItemSet1 . $firstItemSet2;\n        } elseif (is_array($lastItemSet1)) {\n            $item = $this->mergeValues($lastItemSet1, $firstItemSet2);\n        } else {\n            array_push($set1, $lastItemSet1);\n        }\n\n        array_push($set1, $item);\n        return array_merge($set1, $set2);\n    }", "label": 2}
{"code": "func (l VirtualDeviceList) Type(device types.BaseVirtualDevice) string {\n\tswitch device.(type) {\n\tcase types.BaseVirtualEthernetCard:\n\t\treturn DeviceTypeEthernet\n\tcase *types.ParaVirtualSCSIController:\n\t\treturn \"pvscsi\"\n\tcase *types.VirtualLsiLogicSASController:\n\t\treturn \"lsilogic-sas\"\n\tcase *types.VirtualNVMEController:\n\t\treturn \"nvme\"\n\tdefault:\n\t\treturn l.deviceName(device)\n\t}\n}", "label": 5}
{"code": "def license_contents\n      matched_files.reject { |f| f == package_file }\n                   .group_by(&:content)\n                   .map { |content, files| { \"sources\" => license_content_sources(files), \"text\" => content } }\n    end", "label": 4}
{"code": "def state\n      result = @provider.state\n      raise Errors::MachineStateInvalid if !result.is_a?(MachineState)\n\n      # Update our state cache if we have a UUID and an entry in the\n      # master index.\n      uuid = index_uuid\n      if uuid\n        # active_machines provides access to query this info on each machine\n        # from a different thread, ensure multiple machines do not access\n        # the locked entry simultaneously as this triggers a locked machine\n        # exception.\n        @state_mutex.synchronize do\n          entry = @env.machine_index.get(uuid)\n          if entry\n            entry.state = result.short_description\n            @env.machine_index.set(entry)\n            @env.machine_index.release(entry)\n          end\n        end\n      end\n\n      result\n    end", "label": 4}
{"code": "function () {\n        this.addResult = function (event) {\n            var fullUrl = event.homeURL + url;\n            http.get(fullUrl, function (response) {\n                var content = \"\";\n                response.on(\"data\", function (chunk) {\n                    content += chunk;\n                });\n                response.on(\"end\", function () {\n                    callback(content);\n                });\n            });\n        };\n        this.checkFinished = function () {\n            return false;\n        };\n        events.EventEmitter.call(this);\n    }", "label": 3}
{"code": "def formatted_version\n        stringified = @version.to_s\n        return stringified unless stringified.length == 14\n        stringified.insert(4, \"_\").insert(7, \"_\").insert(10, \"_\")\n      end", "label": 4}
{"code": "def encode_path(path)\n      path.b.gsub(%r!([^a-zA-Z0-9_.-/]+)!) { |m|\n        '%' + m.unpack('H2' * m.bytesize).join('%').upcase\n      }\n    end", "label": 4}
{"code": "def name=(v)\n      DataTypeValidator.validate :table_name, [String], v\n      if v.is_a?(String)\n        @name = v\n      end\n    end", "label": 4}
{"code": "public function identity()\n    {\n        $databaseParts = explode('/', $this->name);\n        $instanceParts = explode('/', $this->instance->name());\n\n        return [\n            'projectId' => $this->projectId,\n            'database' => end($databaseParts),\n            'instance' => end($instanceParts),\n        ];\n    }", "label": 2}
{"code": "func (p *Pod) UnlockManifest() error {\n\tif p.manifestLock == nil {\n\t\treturn nil\n\t}\n\n\tif err := p.manifestLock.Close(); err != nil {\n\t\treturn err\n\t}\n\tp.manifestLock = nil\n\treturn nil\n}", "label": 5}
{"code": "public <TYPE> TYPE get(String key, Class<TYPE> type) {\n\t\treturn cache.get(key, type);\n\t}", "label": 0}
{"code": "def read_regexp\n      string = read_string(cache: false)\n      options = read_byte\n\n      result = Regexp.new(string, options)\n      @object_cache << result\n      result\n    end", "label": 4}
{"code": "def execute(subscription_id, event, object)\n      # Lookup the saved data for this subscription\n      query_data = read_subscription(subscription_id)\n      # Fetch the required keys from the saved data\n      query_string = query_data.fetch(:query_string)\n      variables = query_data.fetch(:variables)\n      context = query_data.fetch(:context)\n      operation_name = query_data.fetch(:operation_name)\n      # Re-evaluate the saved query\n      result = @schema.execute(\n        {\n          query: query_string,\n          context: context,\n          subscription_topic: event.topic,\n          operation_name: operation_name,\n          variables: variables,\n          root_value: object,\n        }\n      )\n      deliver(subscription_id, result)\n    rescue GraphQL::Schema::Subscription::NoUpdateError\n      # This update was skipped in user code; do nothing.\n    rescue GraphQL::Schema::Subscription::UnsubscribedError\n      # `unsubscribe` was called, clean up on our side\n      # TODO also send `{more: false}` to client?\n      delete_subscription(subscription_id)\n    end", "label": 4}
{"code": "func (o HostNetworkSystem) AddPortGroup(ctx context.Context, portgrp types.HostPortGroupSpec) error {\n\treq := types.AddPortGroup{\n\t\tThis:    o.Reference(),\n\t\tPortgrp: portgrp,\n\t}\n\n\t_, err := methods.AddPortGroup(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function(context, pkg, isRoot) {\n\t\tvar deps = crawl.getDependencies(context.loader, pkg, isRoot);\n\n\t\treturn Promise.all(utils.filter(utils.map(deps, function(childPkg){\n\t\t\treturn crawl.fetchDep(context, pkg, childPkg, isRoot);\n\t\t}), truthy)).then(function(packages){\n \t\t\t// at this point all dependencies of pkg have been loaded, it's ok to get their children\n\n\t\t\treturn Promise.all(utils.map(packages, function(childPkg){\n\t\t\t\t// Also load 'steal' so that the builtins will be configured\n\t\t\t\tif(childPkg && childPkg.name === 'steal') {\n\t\t\t\t\treturn crawl.deps(context, childPkg);\n\t\t\t\t}\n\t\t\t})).then(function(){\n\t\t\t\treturn packages;\n\t\t\t});\n\t\t});\n\t}", "label": 3}
{"code": "def send_community_request_email(increq):\n    \"\"\"Signal for sending emails after community inclusion request.\"\"\"\n    from flask_mail import Message\n    from invenio_mail.tasks import send_email\n\n    msg_body = format_request_email_body(increq)\n    msg_title = format_request_email_title(increq)\n\n    sender = current_app.config['COMMUNITIES_REQUEST_EMAIL_SENDER']\n\n    msg = Message(\n        msg_title,\n        sender=sender,\n        recipients=[increq.community.owner.email, ],\n        body=msg_body\n    )\n\n    send_email.delay(msg.__dict__)", "label": 1}
{"code": "public static function getCascadeFactors()\n    {\n        return static::$cascadeFactors ?: [\n            'milliseconds' => [Carbon::MICROSECONDS_PER_MILLISECOND, 'microseconds'],\n            'seconds' => [Carbon::MILLISECONDS_PER_SECOND, 'milliseconds'],\n            'minutes' => [Carbon::SECONDS_PER_MINUTE, 'seconds'],\n            'hours' => [Carbon::MINUTES_PER_HOUR, 'minutes'],\n            'dayz' => [Carbon::HOURS_PER_DAY, 'hours'],\n            'months' => [Carbon::DAYS_PER_WEEK * Carbon::WEEKS_PER_MONTH, 'dayz'],\n            'years' => [Carbon::MONTHS_PER_YEAR, 'months'],\n        ];\n    }", "label": 2}
{"code": "function pathJoin(...args) {\n    return args\n        .reduce((prev, val) => {\n        if (typeof prev === \"undefined\") {\n            return;\n        }\n        if (val === undefined) {\n            return prev;\n        }\n        return typeof val === \"string\" || typeof val === \"number\"\n            ? joinStringsWithSlash(prev, \"\" + val) // if string or number just keep as is\n            : Array.isArray(val)\n                ? joinStringsWithSlash(prev, pathJoin.apply(null, val)) // handle array with recursion\n                : console.error(errorStr(typeof val));\n    }, \"\")\n        .replace(moreThanThreePeriods, \"..\"); // join the resulting array together\n}", "label": 3}
{"code": "public void unbind(T service, Map<String, Object> props) {\n    synchronized (serviceMap) {\n      serviceMap.remove(ServiceUtil.getComparableForServiceRanking(props));\n      updateSortedServices();\n    }\n  }", "label": 0}
{"code": "func (cli *NetworkCli) getMethod(args ...string) (func(string, ...string) error, bool) {\n\tcamelArgs := make([]string, len(args))\n\tfor i, s := range args {\n\t\tif len(s) == 0 {\n\t\t\treturn nil, false\n\t\t}\n\t\tcamelArgs[i] = strings.ToUpper(s[:1]) + strings.ToLower(s[1:])\n\t}\n\tmethodName := \"Cmd\" + strings.Join(camelArgs, \"\")\n\tmethod := reflect.ValueOf(cli).MethodByName(methodName)\n\tif !method.IsValid() {\n\t\treturn nil, false\n\t}\n\treturn method.Interface().(func(string, ...string) error), true\n}", "label": 5}
{"code": "func NewRGBColor(r, g, b int32) Color {\n\treturn NewHexColor(((r & 0xff) << 16) | ((g & 0xff) << 8) | (b & 0xff))\n}", "label": 5}
{"code": "public function setResourceType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Monitoring\\V3\\GroupResourceType::class);\n        $this->resource_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public void forAllColumns(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (Iterator it = _curTableDef.getColumns(); it.hasNext(); )\r\n        {\r\n            _curColumnDef = (ColumnDef)it.next();\r\n            generate(template);\r\n        }\r\n        _curColumnDef = null;\r\n    }", "label": 0}
{"code": "func PgReplicationOriginByRoname(db XODB, roname string) (*PgReplicationOrigin, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, roident, roname ` +\n\t\t`FROM pg_catalog.pg_replication_origin ` +\n\t\t`WHERE roname = $1`\n\n\t// run query\n\tXOLog(sqlstr, roname)\n\tpro := PgReplicationOrigin{}\n\n\terr = db.QueryRow(sqlstr, roname).Scan(&pro.Tableoid, &pro.Cmax, &pro.Xmax, &pro.Cmin, &pro.Xmin, &pro.Ctid, &pro.Roident, &pro.Roname)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pro, nil\n}", "label": 5}
{"code": "function filterListeners (listenerCollection) {\n        return function(filters) {\n            var handlers = [];\n\n            _.each(listenerCollection, function(listener){\n                handlers = handlers.concat( findMatch(filters, listener) );\n            });\n\n            return handlers;\n        };\n    }", "label": 3}
{"code": "func (c *CertAuthorityV2) Clone() CertAuthority {\n\tout := *c\n\tout.Spec.CheckingKeys = utils.CopyByteSlices(c.Spec.CheckingKeys)\n\tout.Spec.SigningKeys = utils.CopyByteSlices(c.Spec.SigningKeys)\n\tfor i, kp := range c.Spec.TLSKeyPairs {\n\t\tout.Spec.TLSKeyPairs[i] = TLSKeyPair{\n\t\t\tKey:  utils.CopyByteSlice(kp.Key),\n\t\t\tCert: utils.CopyByteSlice(kp.Cert),\n\t\t}\n\t}\n\tout.Spec.Roles = utils.CopyStrings(c.Spec.Roles)\n\treturn &out\n}", "label": 5}
{"code": "func (h *ArchiveHandler) newArchiveToGuest(u *url.URL) (File, error) {\n\tr, w := io.Pipe()\n\n\tbuf := bufio.NewReader(r)\n\n\ta := &archive{\n\t\tname:   u.Path,\n\t\tReader: buf,\n\t\tWriter: w,\n\t}\n\n\tvar cerr error\n\tvar wg sync.WaitGroup\n\n\ta.done = func() error {\n\t\t_ = w.Close()\n\t\t// We need to wait for unpack to finish to complete its work\n\t\t// and to propagate the error if any to Close.\n\t\twg.Wait()\n\t\treturn cerr\n\t}\n\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\n\t\tc := func() error {\n\t\t\t// Drain the pipe of tar trailer data (two null blocks)\n\t\t\tif cerr == nil {\n\t\t\t\t_, _ = io.Copy(ioutil.Discard, a.Reader)\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\n\t\theader, _ := buf.Peek(len(gzipHeader))\n\n\t\tif bytes.Equal(header, gzipHeader) {\n\t\t\tgz, err := gzip.NewReader(a.Reader)\n\t\t\tif err != nil {\n\t\t\t\t_ = r.CloseWithError(err)\n\t\t\t\tcerr = err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tc = gz.Close\n\t\t\ta.Reader = gz\n\t\t}\n\n\t\ttr := tar.NewReader(a.Reader)\n\n\t\tcerr = h.Read(u, tr)\n\n\t\t_ = c()\n\t\t_ = r.CloseWithError(cerr)\n\t}()\n\n\treturn a, nil\n}", "label": 5}
{"code": "public static function frameToBeAvailableAndSwitchToIt($frame_locator)\n    {\n        return new static(\n            function (WebDriver $driver) use ($frame_locator) {\n                try {\n                    return $driver->switchTo()->frame($frame_locator);\n                } catch (NoSuchFrameException $e) {\n                    return false;\n                }\n            }\n        );\n    }", "label": 2}
{"code": "public function setTextDetectionConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\VideoIntelligence\\V1\\TextDetectionConfig::class);\n        $this->text_detection_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def get(postcode):\n    \"\"\"\n    Request data associated with `postcode`.\n\n    :param postcode: the postcode to search for. The postcode may \n                     contain spaces (they will be removed).\n\n    :returns: a dict of the nearest postcode's data or None if no \n              postcode data is found.\n    \"\"\"\n    postcode = quote(postcode.replace(' ', ''))\n    url = '%s/postcode/%s.json' % (END_POINT, postcode)\n    return _get_json_resp(url)", "label": 1}
{"code": "func NewTunnelConnection(name string, spec TunnelConnectionSpecV2) (TunnelConnection, error) {\n\tconn := &TunnelConnectionV2{\n\t\tKind:    KindTunnelConnection,\n\t\tSubKind: spec.ClusterName,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName:      name,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: spec,\n\t}\n\tif err := conn.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn conn, nil\n}", "label": 5}
{"code": "function(query, options) {\n      options = opts(this, options);\n\n      if(!options.session_token) throw new Error(\"Must be logged in to perform a social query\");\n      if(query.headers && !isObject(query.headers)) throw new Error(\"Headers must be an object\");\n      if(query.params && !isObject(query.params)) throw new Error(\"Extra parameters must be an object\");\n\n      var url = \"social/\"+query.network+\"/\"+query.endpoint;\n\n      var urlParams = {};\n\n      if(query.headers) urlParams.headers = query.headers;\n      if(query.params) urlParams.params = query.params;\n\n      var apicall = new APICall({\n        action: url,\n        type: query.method,\n        query: urlParams,\n        options: options,\n        data: query.data,\n        contentType: 'application/octet-stream'\n      });\n\n      return apicall;\n    }", "label": 3}
{"code": "function parens(parent, child) {\n  if (precedence(parent) >= precedence(child))\n    return to_s(child);\n  else\n    return \"(\" + to_s(child) + \")\";\n}", "label": 3}
{"code": "public static String getPunctClass(String punc) {\r\n    if(punc.equals(\"%\") || punc.equals(\"-PLUS-\"))//-PLUS- is an escape for \"+\" in the ATB\r\n      return \"perc\";\r\n    else if(punc.startsWith(\"*\"))\r\n      return \"bullet\";\r\n    else if(sfClass.contains(punc))\r\n      return \"sf\";\r\n    else if(colonClass.contains(punc) || pEllipsis.matcher(punc).matches())\r\n      return \"colon\";\r\n    else if(commaClass.contains(punc))\r\n      return \"comma\";\r\n    else if(currencyClass.contains(punc))\r\n      return \"curr\";\r\n    else if(slashClass.contains(punc))\r\n      return \"slash\";\r\n    else if(lBracketClass.contains(punc))\r\n      return \"lrb\";\r\n    else if(rBracketClass.contains(punc))\r\n      return \"rrb\";\r\n    else if(quoteClass.contains(punc))\r\n      return \"quote\";\r\n    \r\n    return \"\";\r\n  }", "label": 0}
{"code": "func (c *Manager) CreateLibraryItemUpdateSession(ctx context.Context, session UpdateSession) (string, error) {\n\turl := internal.URL(c, internal.LibraryItemUpdateSession)\n\tspec := struct {\n\t\tCreateSpec UpdateSession `json:\"create_spec\"`\n\t}{session}\n\tvar res string\n\treturn res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "func sliceCompress(data []byte) []byte {\n\tvar buf bytes.Buffer\n\tcmp, _ := zlib.NewWriterLevel(&buf, zlib.BestSpeed)\n\tcmp.Write(data)\n\tcmp.Close()\n\treturn buf.Bytes()\n}", "label": 5}
{"code": "public function setDesiredMasterAuthorizedNetworksConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\MasterAuthorizedNetworksConfig::class);\n        $this->desired_master_authorized_networks_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static function model(string $key, string $default = null)\n    {\n        return Arr::get(static::$options, 'models.'.$key, $default ?? $key);\n    }", "label": 2}
{"code": "function runCall(name, call, input) {\n    return web.post(connectorsUrl + '/' + name + '/' + call, input);\n}", "label": 3}
{"code": "def ifancestor(parser, token):\n    \"\"\"\n    Returns the contents of the tag if the provided path consitutes the\n    base of the current pages path.\n\n    There are two ways to provide arguments to this tag. Firstly one may\n    provide a single argument that starts with a forward slash. e.g.\n\n        {% ifancestor '/path/to/page' %}...{% endifancestor}\n        {% ifancestor path_variable %}...{% endifancestor}\n\n    In this case the provided path will be used directly.\n\n    Alternatively any arguments accepted by the standard \"url\" tag may\n    be provided. They will be passed to the url tag and the resultant\n    path will be used. e.g.\n\n        {% ifancestor 'core:model:detail' model.pk %}...{% endifancestor}\n\n    Ultimately the provided path is matched against the path of the\n    current page. If the provided path is found at the root of the current\n    path it will be considered an anscestor, and the contents of this tag\n    will be rendered.\n\n    \"\"\"\n    # Grab the contents between\n    contents = parser.parse(('endifancestor',))\n    parser.delete_first_token()\n\n    # If there is only one argument (2 including tag name)\n    # parse it as a variable\n    bits = token.split_contents()\n    if len(bits) == 2:\n        arg = parser.compile_filter(bits[1])\n    else:\n        arg = None\n\n    # Also pass all arguments to the original url tag\n    url_node = url(parser, token)\n\n    return AncestorNode(url_node, arg=arg, contents=contents)", "label": 1}
{"code": "private ClassLoaderInterface getClassLoader() {\n\t\tMap<String, Object> application = ActionContext.getContext().getApplication();\n\t\tif (application != null) {\n\t\t\treturn (ClassLoaderInterface) application.get(ClassLoaderInterface.CLASS_LOADER_INTERFACE);\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "function spinner(silent) {\n      var interval = 100\n        , frames = spinner.frames\n        , len = frames.length\n        , i = 0;\n\n      if (silent) return;\n\n      spinner.interval = setInterval(function tick() {\n        process.stdout.write(\n            '\\r'\n          + frames[i++ % len]\n          + 'Waiting for file changes'.white\n        );\n      }, interval);\n    }", "label": 3}
{"code": "def update_iap!(app_id: nil, purchase_id: nil, data: nil)\n      with_tunes_retry do\n        r = request(:put) do |req|\n          req.url(\"ra/apps/#{app_id}/iaps/#{purchase_id}\")\n          req.body = data.to_json\n          req.headers['Content-Type'] = 'application/json'\n        end\n        handle_itc_response(r.body)\n      end\n    end", "label": 4}
{"code": "function (criteria, document) {\n            var self = this;\n\n            return this.needOne(criteria).then(function (target) {\n                return self.update(target.id, document).then(function (documents) {\n                    return documents[0];\n                });\n            });\n        }", "label": 3}
{"code": "public static base_response unset(nitro_service client, route resource, String[] args) throws Exception{\n\t\troute unsetresource = new route();\n\t\tunsetresource.network = resource.network;\n\t\tunsetresource.netmask = resource.netmask;\n\t\tunsetresource.gateway = resource.gateway;\n\t\tunsetresource.td = resource.td;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "func (fst fileTorrentImplIO) ReadAt(b []byte, off int64) (n int, err error) {\n\tfor _, fi := range fst.fts.info.UpvertedFiles() {\n\t\tfor off < fi.Length {\n\t\t\tn1, err1 := fst.readFileAt(fi, b, off)\n\t\t\tn += n1\n\t\t\toff += int64(n1)\n\t\t\tb = b[n1:]\n\t\t\tif len(b) == 0 {\n\t\t\t\t// Got what we need.\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif n1 != 0 {\n\t\t\t\t// Made progress.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\terr = err1\n\t\t\tif err == io.EOF {\n\t\t\t\t// Lies.\n\t\t\t\terr = io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\toff -= fi.Length\n\t}\n\terr = io.EOF\n\treturn\n}", "label": 5}
{"code": "function _encodeBlob(blob) {\n    return new Promise$1(function (resolve, reject) {\n        var reader = new FileReader();\n        reader.onerror = reject;\n        reader.onloadend = function (e) {\n            var base64 = btoa(e.target.result || '');\n            resolve({\n                __local_forage_encoded_blob: true,\n                data: base64,\n                type: blob.type\n            });\n        };\n        reader.readAsBinaryString(blob);\n    });\n}", "label": 3}
{"code": "private static boolean isAssignableFrom(Type from, ParameterizedType to,\n\t\t\tMap<String, Type> typeVarMap) {\n\n\t\tif (from == null) {\n\t\t\treturn false;\n\t\t}\n\n\t\tif (to.equals(from)) {\n\t\t\treturn true;\n\t\t}\n\n\t\t// First figure out the class and any type information.\n\t\tClass<?> clazz = getRawType(from);\n\t\tParameterizedType ptype = null;\n\t\tif (from instanceof ParameterizedType) {\n\t\t\tptype = (ParameterizedType) from;\n\t\t}\n\n\t\t// Load up parameterized variable info if it was parameterized.\n\t\tif (ptype != null) {\n\t\t\tType[] tArgs = ptype.getActualTypeArguments();\n\t\t\tTypeVariable<?>[] tParams = clazz.getTypeParameters();\n\t\t\tfor (int i = 0; i < tArgs.length; i++) {\n\t\t\t\tType arg = tArgs[i];\n\t\t\t\tTypeVariable<?> var = tParams[i];\n\t\t\t\twhile (arg instanceof TypeVariable) {\n\t\t\t\t\tTypeVariable<?> v = (TypeVariable<?>) arg;\n\t\t\t\t\targ = typeVarMap.get(v.getName());\n\t\t\t\t}\n\t\t\t\ttypeVarMap.put(var.getName(), arg);\n\t\t\t}\n\n\t\t\t// check if they are equivalent under our current mapping.\n\t\t\tif (typeEquals(ptype, to, typeVarMap)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\tfor (Type itype : clazz.getGenericInterfaces()) {\n\t\t\tif (isAssignableFrom(itype, to, new HashMap<String, Type>(\n\t\t\t\t\ttypeVarMap))) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\t// Interfaces didn't work, try the superclass.\n\t\tType sType = clazz.getGenericSuperclass();\n\t\tif (isAssignableFrom(sType, to, new HashMap<String, Type>(typeVarMap))) {\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}", "label": 0}
{"code": "def log_level(level)\n      levels = { :debug => 0, :info => 1, :warn => 2, :error => 3, :fatal => 4 }\n\n      unless levels.include? level\n        raise ArgumentError, \"Invalid log level: #{level.inspect}\\n\" \\\n                             \"Expected one of: #{levels.keys.inspect}\"\n      end\n\n      @options[:logger].level = levels[level]\n    end", "label": 4}
{"code": "function(el, template, context, opts) {\n      opts = opts || {};\n      if (_.isString(template)) {\n        opts.newHTML = template;\n      }\n      templateRenderer.render(el, template, context, opts);\n    }", "label": 3}
{"code": "def reference(self, tkn: str):\n        \"\"\" Return the element that tkn represents\"\"\"\n        return self.grammarelts[tkn] if tkn in self.grammarelts else UndefinedElement(tkn)", "label": 1}
{"code": "function (metadata) {\n        var key;\n        if (metadata) {\n            this.name = metadata.name;\n            this.size = metadata.size || 0;\n            this.mime = metadata.mime || '';\n            this.isPublic = metadata.isPublic || false;\n            this.tags = metadata.tags || [];\n            this.content = metadata.content;\n            this.contentType = metadata.contentType || BlobMetadata.CONTENT_TYPES.OBJECT;\n            if (this.contentType === BlobMetadata.CONTENT_TYPES.COMPLEX) {\n                for (key in this.content) {\n                    if (this.content.hasOwnProperty(key)) {\n                        if (BlobConfig.hashRegex.test(this.content[key].content) === false) {\n                            throw new Error('BlobMetadata is malformed: hash \\'' + this.content[key].content +\n                                '\\'is invalid');\n                        }\n                    }\n                }\n            }\n        } else {\n            throw new Error('metadata parameter is not defined');\n        }\n    }", "label": 3}
{"code": "function insertComment(comment) {\n    var div = createCommentDiv(comment);\n\n    // To avoid stagnating data, don't store the comments children in data.\n    comment.children = null;\n    div.data('comment', comment);\n\n    var ul = $('#cl' + (comment.node || comment.parent));\n    var siblings = getChildren(ul);\n\n    var li = $(document.createElement('li'));\n    li.hide();\n\n    // Determine where in the parents children list to insert this comment.\n    for(i=0; i < siblings.length; i++) {\n      if (comp(comment, siblings[i]) <= 0) {\n        $('#cd' + siblings[i].id)\n          .parent()\n          .before(li.html(div));\n        li.slideDown('fast');\n        return;\n      }\n    }\n\n    // If we get here, this comment rates lower than all the others,\n    // or it is the only comment in the list.\n    ul.append(li.html(div));\n    li.slideDown('fast');\n  }", "label": 3}
{"code": "def language\n      @language = Produce.config[:language]\n\n      converted = Spaceship::Tunes::LanguageConverter.from_itc_readable_to_itc(@language)\n      @language = converted if converted # overwrite it with the actual value\n\n      unless AvailableDefaultLanguages.all_languages.include?(@language)\n        UI.user_error!(\"Please enter one of available languages: #{AvailableDefaultLanguages.all_languages}\")\n      end\n\n      return @language\n    end", "label": 4}
{"code": "public static ipv6 get(nitro_service service) throws Exception{\n\t\tipv6 obj = new ipv6();\n\t\tipv6[] response = (ipv6[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def check_for_too_many_processors(config, hash)\n      concurrency = config.concurrency\n\n      errors = []\n      Overcommit::Utils.supported_hook_type_classes.each do |hook_type|\n        hash.fetch(hook_type) { {} }.each do |hook_name, hook_config|\n          processors = hook_config.fetch('processors') { 1 }\n          if processors > concurrency\n            errors << \"#{hook_type}::#{hook_name} `processors` value \" \\\n                      \"(#{processors}) is larger than the global `concurrency` \" \\\n                      \"option (#{concurrency})\"\n          end\n        end\n      end\n\n      if errors.any?\n        if @log\n          @log.error errors.join(\"\\n\")\n          @log.newline\n        end\n        raise Overcommit::Exceptions::ConfigurationError,\n              'One or more hooks had invalid `processor` value configured'\n      end\n    end", "label": 4}
{"code": "async function generateTypedef(config) {\n  const {\n    source,\n    destination = source,\n    writable,\n  } = config\n  try {\n    if (!source && !writable) {\n      console.log('Please specify a JavaScript file or a pass a stream.')\n      process.exit(1)\n    }\n\n    const s = createReadStream(source)\n    const readable = createJsReplaceStream()\n    s.pipe(readable)\n\n    const p = whichStream({\n      source,\n      readable,\n      destination: writable ? undefined : destination,\n      writable,\n    })\n\n    await new Promise((r, j) => {\n      readable.on('error', e => { LOG('Error in Replaceable'); j(e) })\n      s.on('error', e => { LOG('Error in Read'); j(e) })\n      readable.on('end', r)\n    })\n\n    await p\n\n    if (writable) {\n      LOG('%s written to stream', source)\n    } else if (source == destination) {\n      console.error('Updated %s to include types.', source)\n    } else if (destination == '-') {\n      console.error('Written %s to stdout.', source)\n    } else {\n      console.error('Saved output to %s', destination)\n    }\n  } catch (err) {\n    catcher(err)\n  }\n}", "label": 3}
{"code": "public static String getFlowContext() {\n    TransactionLogger instance = getInstance();\n    if (instance == null) {\n      return null;\n    }\n\n    return instance.flowContext;\n  }", "label": 0}
{"code": "function _gpfWebTagCreateFunction (nodeName) {\n    if (!nodeName) {\n        gpf.Error.missingNodeName();\n    }\n    return function (firstParam) {\n        var sliceFrom = 0,\n            attributes;\n        if (_gpfIsLiteralObject(firstParam)) {\n            attributes = firstParam;\n            ++sliceFrom;\n        }\n        return new _GpfWebTag(nodeName, attributes, _gpfArraySlice(arguments, sliceFrom));\n    };\n}", "label": 3}
{"code": "function(timeStamp) {\n        var secondsPerStamp = 1.001,\n            timesplit = timeStamp.split(':'),\n            timestampSeconds = (parseInt(timesplit[0], 10) * 3600 +\n                parseInt(timesplit[1], 10) * 60 +\n                parseInt(timesplit[2], 10) +\n                parseInt(timesplit[3], 10) / 30),\n            seconds = timestampSeconds * secondsPerStamp,\n            microSeconds = seconds * 1000 * 1000;\n        return (microSeconds > 0) ? microSeconds : 0;\n    }", "label": 3}
{"code": "public function iam()\n    {\n        if (!$this->iam) {\n            $iamConnection = new IamTopic($this->connection);\n            $this->iam = new Iam($iamConnection, $this->name);\n        }\n\n        return $this->iam;\n    }", "label": 2}
{"code": "def class_methods(&class_methods_module_definition)\n      mod = const_defined?(:ClassMethods, false) ?\n        const_get(:ClassMethods) :\n        const_set(:ClassMethods, Module.new)\n\n      mod.module_eval(&class_methods_module_definition)\n    end", "label": 4}
{"code": "def register(keyword, command)\n      @aliases.register(keyword.to_sym) do\n        lambda do |args|\n          # directly execute shell commands\n          if command.start_with?(\"!\")\n            return Util::SafeExec.exec \"#{command[1..-1]} #{args.join(\" \")}\".strip\n          end\n\n          return CLI.new(command.split.concat(args), @env).execute\n        end\n      end\n    end", "label": 4}
{"code": "func (cl *Client) receiveHandshakes(c *connection) (t *Torrent, err error) {\n\tdefer perf.ScopeTimerErr(&err)()\n\tvar rw io.ReadWriter\n\trw, c.headerEncrypted, c.cryptoMethod, err = handleEncryption(c.rw(), cl.forSkeys, cl.config.EncryptionPolicy)\n\tc.setRW(rw)\n\tif err == nil || err == mse.ErrNoSecretKeyMatch {\n\t\tif c.headerEncrypted {\n\t\t\ttorrent.Add(\"handshakes received encrypted\", 1)\n\t\t} else {\n\t\t\ttorrent.Add(\"handshakes received unencrypted\", 1)\n\t\t}\n\t} else {\n\t\ttorrent.Add(\"handshakes received with error while handling encryption\", 1)\n\t}\n\tif err != nil {\n\t\tif err == mse.ErrNoSecretKeyMatch {\n\t\t\terr = nil\n\t\t}\n\t\treturn\n\t}\n\tif cl.config.ForceEncryption && !c.headerEncrypted {\n\t\terr = errors.New(\"connection not encrypted\")\n\t\treturn\n\t}\n\tih, ok, err := cl.connBTHandshake(c, nil)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"error during bt handshake: %s\", err)\n\t\treturn\n\t}\n\tif !ok {\n\t\treturn\n\t}\n\tcl.lock()\n\tt = cl.torrents[ih]\n\tcl.unlock()\n\treturn\n}", "label": 5}
{"code": "func (nDB *NetworkDB) ClusterPeers() []PeerInfo {\n\tnDB.RLock()\n\tdefer nDB.RUnlock()\n\tpeers := make([]PeerInfo, 0, len(nDB.nodes))\n\tfor _, node := range nDB.nodes {\n\t\tpeers = append(peers, PeerInfo{\n\t\t\tName: node.Name,\n\t\t\tIP:   node.Node.Addr.String(),\n\t\t})\n\t}\n\treturn peers\n}", "label": 5}
{"code": "public static Pair<String, String> stringIntern(Pair<String, String> p) {\r\n    return new MutableInternedPair(p);\r\n  }", "label": 0}
{"code": "func (c *SessionContext) GetUserClient(site reversetunnel.RemoteSite) (auth.ClientI, error) {\n\t// get the name of the current cluster\n\tclt, err := c.GetClient()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tcn, err := clt.GetClusterName()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// if we're trying to access the local cluster, pass back the local client.\n\tif cn.GetClusterName() == site.GetName() {\n\t\treturn clt, nil\n\t}\n\n\t// look to see if we already have a connection to this cluster\n\tremoteClt, ok := c.getRemoteClient(site.GetName())\n\tif !ok {\n\t\trClt, rConn, err := c.newRemoteClient(site)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\n\t\t// add a closer for the underlying connection\n\t\tif rConn != nil {\n\t\t\tc.AddClosers(rConn)\n\t\t}\n\n\t\t// we'll save the remote client in our session context so we don't have to\n\t\t// build a new connection next time. all remote clients will be closed when\n\t\t// the session context is closed.\n\t\tc.addRemoteClient(site.GetName(), rClt)\n\n\t\treturn rClt, nil\n\t}\n\n\treturn remoteClt, nil\n}", "label": 5}
{"code": "func (s *APIServer) getRemoteClusters(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tclusters, err := auth.GetRemoteClusters()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\titems := make([]json.RawMessage, len(clusters))\n\tfor i, cluster := range clusters {\n\t\tdata, err := services.MarshalRemoteCluster(cluster, services.WithVersion(version), services.PreserveResourceID())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\titems[i] = data\n\t}\n\treturn items, nil\n}", "label": 5}
{"code": "def update(table, values, where=(), **kwargs):\r\n    \"\"\"Convenience wrapper for database UPDATE.\"\"\"\r\n    where = dict(where, **kwargs).items()\r\n    sql, args = makeSQL(\"UPDATE\", table, values=values, where=where)\r\n    return execute(sql, args).rowcount", "label": 1}
{"code": "def enumerate_occurrences(opening_time, closing_time = nil, options = {})\n      opening_time = TimeUtil.match_zone(opening_time, start_time)\n      closing_time = TimeUtil.match_zone(closing_time, start_time)\n      opening_time += TimeUtil.subsec(start_time) - TimeUtil.subsec(opening_time)\n      opening_time = start_time if opening_time < start_time\n      spans = options[:spans] == true && duration != 0\n      Enumerator.new do |yielder|\n        reset\n        t1 = full_required? ? start_time : opening_time\n        t1 -= duration if spans\n        t1 = start_time if t1 < start_time\n        loop do\n          break unless (t0 = next_time(t1, closing_time))\n          break if closing_time && t0 > closing_time\n          if (spans ? (t0.end_time > opening_time) : (t0 >= opening_time))\n            yielder << (block_given? ? yield(t0) : t0)\n          end\n          t1 = t0 + 1\n        end\n      end\n    end", "label": 4}
{"code": "func UnicodeTranslator(r io.Reader) (f func(string) string, err error) {\n\tm := make(map[rune]byte)\n\tvar uPos, cPos uint32\n\tvar lineStr, nameStr string\n\tsc := bufio.NewScanner(r)\n\tfor sc.Scan() {\n\t\tlineStr = sc.Text()\n\t\tlineStr = strings.TrimSpace(lineStr)\n\t\tif len(lineStr) > 0 {\n\t\t\t_, err = fmt.Sscanf(lineStr, \"!%2X U+%4X %s\", &cPos, &uPos, &nameStr)\n\t\t\tif err == nil {\n\t\t\t\tif cPos >= 0x80 {\n\t\t\t\t\tm[rune(uPos)] = byte(cPos)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif err == nil {\n\t\tf = repClosure(m)\n\t} else {\n\t\tf = doNothing\n\t}\n\treturn\n}", "label": 5}
{"code": "public static sslfipskey get(nitro_service service, String fipskeyname) throws Exception{\n\t\tsslfipskey obj = new sslfipskey();\n\t\tobj.set_fipskeyname(fipskeyname);\n\t\tsslfipskey response = (sslfipskey) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setMetric($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Logging\\V2\\LogMetric::class);\n        $this->metric = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function (area, layer) {\n\t\n\t// check if layer exists\n\tif (l_layers.hasOwnProperty(layer) === false)\n\t\treturn [];\n\t\n\t// get all current subscriptions at this layer\n\tvar subs = l_layers[layer];\n\t\n\t// prepare list of connection of subscribers matching / covering the area\n\tvar connections = [];\n\t\n\t// check each subscription to see if it overlaps with the given area\n\tfor (var id in subs) {\n\t\tvar subscription = subs[id];\n\t\t\n\t\t// check for overlaps (distance between the two centers is less than sum of radii)\n\t\tif (l_dist(subscription, para) <= (subscription.r + para.r))\n\t\t\tconnections.push(subscription.conn);\n\t}\n\t\n\treturn connections;\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, autoscaleaction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tautoscaleaction addresources[] = new autoscaleaction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new autoscaleaction();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].type = resources[i].type;\n\t\t\t\taddresources[i].profilename = resources[i].profilename;\n\t\t\t\taddresources[i].parameters = resources[i].parameters;\n\t\t\t\taddresources[i].vmdestroygraceperiod = resources[i].vmdestroygraceperiod;\n\t\t\t\taddresources[i].quiettime = resources[i].quiettime;\n\t\t\t\taddresources[i].vserver = resources[i].vserver;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setProjectIds($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->project_ids = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function (actualArgs, expectedArgs) {\n    var i;\n    if (actualArgs.length !== expectedArgs.length) {\n      return false;\n    }\n    for (i = 0; i < expectedArgs.length; i++) {\n      if (actualArgs[i] !== expectedArgs[i]) {\n        return false;\n      }\n    }\n    return true;\n  }", "label": 3}
{"code": "function _gpfSortOnDt(a, b) {\n        if (a.dt === b.dt) {\n            return a.id - b.id;\n        }\n        return a.dt - b.dt;\n    }", "label": 3}
{"code": "def median_kneighbour_distance(X, k=5):\n    \"\"\"\n    Calculate the median kneighbor distance.\n\n    Find the distance between a set of random datapoints and\n    their kth nearest neighbours. This is a heuristic for setting the\n    kernel length scale.\n    \"\"\"\n    N_all = X.shape[0]\n    k = min(k, N_all)\n    N_subset = min(N_all, 2000)\n    sample_idx_train = np.random.permutation(N_all)[:N_subset]\n    nn = neighbors.NearestNeighbors(k)\n    nn.fit(X[sample_idx_train, :])\n    d, idx = nn.kneighbors(X[sample_idx_train, :])\n    return np.median(d[:, -1])", "label": 1}
{"code": "public function create(array $options = [])\n    {\n        if (!$this->info['subscription']) {\n            throw new \\BadMethodCallException('A subscription is required to create a snapshot.');\n        }\n\n        return $this->info = $this->connection->createSnapshot([\n            'project' => $this->formatName('project', $this->projectId),\n            'name' => $this->name,\n            'subscription' => $this->info['subscription']\n        ]);\n    }", "label": 2}
{"code": "private function fromDefinition($type, $startOrEnd)\n    {\n        if (!array_key_exists($type, $this->definition)) {\n            throw new \\InvalidArgumentException(sprintf(\n                'Invalid KeyRange %s type. Allowed values are %s.',\n                $startOrEnd,\n                implode(', ', array_keys($this->definition))\n            ));\n        }\n\n        return $this->definition[$type][$startOrEnd];\n    }", "label": 2}
{"code": "def process_file(self, language, key, token_list):\n        \"\"\"\n        Initiate processing for each token.\n\n        Override this if you want tt control the processing of the tokens yourself.\n        \"\"\"\n        self.language = language\n        for tok in token_list:\n            self.process_token(tok)", "label": 1}
{"code": "public boolean isMaterialized(Object object)\r\n    {\r\n        IndirectionHandler handler = getIndirectionHandler(object);\r\n\r\n        return handler == null || handler.alreadyMaterialized();\r\n    }", "label": 0}
{"code": "def update(self, status):\n        \"\"\"Sends a status update to the framework scheduler.\n\n        Retrying as necessary until an acknowledgement has been received or the\n        executor is terminated (in which case, a TASK_LOST status update will be\n        sent).\n        See Scheduler.statusUpdate for more information about status update\n        acknowledgements.\n        \"\"\"\n        logging.info('Executor sends status update {} for task {}'.format(\n                     status.state, status.task_id))\n        return self.driver.sendStatusUpdate(encode(status))", "label": 1}
{"code": "function executableBy(file, user) {\n  if (!exists(file)) {\n    return false;\n  }\n  const userData = findUser(user);\n  if (userData.id === 0) {\n    // Root can do anything but execute a file with no exec permissions\n    const mode = fs.lstatSync(file).mode;\n    return !!(mode & parseInt('00111', 8));\n  } else if (userData.id === process.getuid()) {\n    return executable(file);\n  } else {\n    return _accesibleByUser(userData, file, fs.X_OK);\n  }\n}", "label": 3}
{"code": "def loads_loader(load_module: types.ModuleType, pairs: Dict[str, str]) -> Optional[JSGValidateable]:\n    \"\"\"json loader objecthook\n\n    :param load_module: Module that contains the various types\n    :param pairs: key/value tuples (In our case, they are str/str)\n    :return:\n    \"\"\"\n    cntxt = load_module._CONTEXT\n\n    # If the type element is a member of the JSON, load it\n    possible_type = pairs[cntxt.TYPE] if cntxt.TYPE in pairs else None\n    target_class = getattr(load_module, possible_type, None) if isinstance(possible_type, str) else None\n    if target_class:\n        return target_class(**pairs)\n\n    # See whether there are any exception types that are valid for the incoming data\n    for type_exception in cntxt.TYPE_EXCEPTIONS:\n        if not hasattr(load_module, type_exception):\n            raise ValueError(UNKNOWN_TYPE_EXCEPTION.format(type_exception))\n        target_class = getattr(load_module, type_exception)\n        target_strict = target_class._strict\n        target_class._strict = False\n        try:\n            rval = target_class(**pairs)\n        finally:\n            target_class._strict = target_strict\n        if is_valid(rval):\n            return rval\n\n    # If there is not a type variable and nothing fits, just load up the first (and perhaps only) exception\n    # It will later fail any is_valid tests\n    if not cntxt.TYPE and cntxt.TYPE_EXCEPTIONS:\n        return getattr(load_module, cntxt.TYPE_EXCEPTIONS[0])(**pairs)\n\n    if cntxt.TYPE in pairs:\n        raise ValueError(f'Unknown reference type: \"{cntxt.TYPE}\": \"{pairs[cntxt.TYPE]}\"')\n    else:\n        raise ValueError(f'Missing \"{cntxt.TYPE}\" element')", "label": 1}
{"code": "def atomic_update(clazz, updates = {})\n      @adds += updates.keys.length\n      indexer.add_atomic_update(clazz, updates)\n    end", "label": 4}
{"code": "function getTypeFromObjectBindingPattern(pattern, includePatternInType, reportErrors) {\n            var members = ts.createMap();\n            var hasComputedProperties = false;\n            ts.forEach(pattern.elements, function (e) {\n                var name = e.propertyName || e.name;\n                if (isComputedNonLiteralName(name)) {\n                    // do not include computed properties in the implied type\n                    hasComputedProperties = true;\n                    return;\n                }\n                var text = getTextOfPropertyName(name);\n                var flags = 4 /* Property */ | 67108864 /* Transient */ | (e.initializer ? 536870912 /* Optional */ : 0);\n                var symbol = createSymbol(flags, text);\n                symbol.type = getTypeFromBindingElement(e, includePatternInType, reportErrors);\n                symbol.bindingElement = e;\n                members[symbol.name] = symbol;\n            });\n            var result = createAnonymousType(undefined, members, emptyArray, emptyArray, undefined, undefined);\n            if (includePatternInType) {\n                result.pattern = pattern;\n            }\n            if (hasComputedProperties) {\n                result.flags |= 536870912 /* ObjectLiteralPatternWithComputedProperties */;\n            }\n            return result;\n        }", "label": 3}
{"code": "public static sslpolicylabel_binding get(nitro_service service, String labelname) throws Exception{\n\t\tsslpolicylabel_binding obj = new sslpolicylabel_binding();\n\t\tobj.set_labelname(labelname);\n\t\tsslpolicylabel_binding response = (sslpolicylabel_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _qmed_from_descriptors_2008(self, as_rural=False, donor_catchments=None):\n        \"\"\"\n        Return QMED estimation based on FEH catchment descriptors, 2008 methodology.\n\n        Methodology source: Science Report SC050050, p. 36\n\n        :param as_rural: assume catchment is fully rural. Default: false.\n        :type as rural: bool\n        :param donor_catchments: override donor catchment to improve QMED catchment. If `None` (default),\n        donor catchment will be searched automatically, if empty list, no donors will be used.\n        :type donor_catchments: :class:`Catchment`\n        :return: QMED in m\u00b3/s\n        :rtype: float\n        \"\"\"\n        try:\n            # Basis rural QMED from descriptors\n            lnqmed_rural = 2.1170 \\\n                           + 0.8510 * log(self.catchment.descriptors.dtm_area) \\\n                           - 1.8734 * 1000 / self.catchment.descriptors.saar \\\n                           + 3.4451 * log(self.catchment.descriptors.farl) \\\n                           - 3.0800 * self.catchment.descriptors.bfihost ** 2.0\n            qmed_rural = exp(lnqmed_rural)\n\n            # Log intermediate results\n            self.results_log['qmed_descr_rural'] = qmed_rural\n\n            if donor_catchments is None:\n                # If no donor catchments are provided, find the nearest 25\n                donor_catchments = self.find_donor_catchments()\n            if donor_catchments:\n                # If found multiply rural estimate with weighted adjustment factors from all donors\n\n                weights = self._vec_alpha(donor_catchments)\n                errors = self._vec_lnqmed_residuals(donor_catchments)\n                correction = np.dot(weights, errors)\n\n                lnqmed_rural += correction\n                qmed_rural = exp(lnqmed_rural)\n\n                # Log intermediate results\n                self.results_log['donors'] = donor_catchments\n                for i, donor in enumerate(self.results_log['donors']):\n                    donor.weight = weights[i]\n                    donor.factor = exp(errors[i])\n                self.results_log['donor_adj_factor'] = exp(correction)\n                self.results_log['qmed_adj_rural'] = qmed_rural\n\n            if as_rural:\n                return qmed_rural\n            else:\n                # Apply urbanisation adjustment\n                urban_adj_factor = self.urban_adj_factor()\n\n                # Log intermediate results\n                self.results_log['qmed_descr_urban'] = self.results_log['qmed_descr_rural'] * urban_adj_factor\n                return qmed_rural * urban_adj_factor\n        except (TypeError, KeyError):\n            raise InsufficientDataError(\"Catchment `descriptors` attribute must be set first.\")", "label": 1}
{"code": "function netcdfGcms(data, options = {}) {\n  let reader = new NetCDFReader(data);\n  const globalAttributes = reader.globalAttributes;\n\n  let instrument_mfr = reader.getDataVariableAsString('instrument_mfr');\n  let dataset_origin = reader.attributeExists('dataset_origin');\n  let mass_values = reader.dataVariableExists('mass_values');\n  let detector_name = reader.getAttribute('detector_name');\n  let aia_template_revision = reader.attributeExists('aia_template_revision');\n  let source_file_format = reader.getAttribute('source_file_format');\n\n  let ans;\n\n  if (mass_values && dataset_origin) {\n    ans = agilentGCMS(reader);\n  } else if (\n    mass_values &&\n    instrument_mfr &&\n    instrument_mfr.match(/finnigan/i)\n  ) {\n    ans = finniganGCMS(reader);\n  } else if (mass_values && instrument_mfr && instrument_mfr.match(/bruker/i)) {\n    ans = brukerGCMS(reader);\n  } else if (\n    mass_values &&\n    source_file_format &&\n    source_file_format.match(/shimadzu/i)\n  ) {\n    ans = shimadzuGCMS(reader);\n  } else if (detector_name && detector_name.match(/(dad|tic)/i)) {\n    // diode array agilent HPLC\n    ans = agilentHPLC(reader);\n  } else if (aia_template_revision) {\n    ans = aiaTemplate(reader);\n  } else {\n    throw new TypeError('Unknown file format');\n  }\n\n  if (options.meta) {\n    ans.meta = addMeta(globalAttributes);\n  }\n\n  if (options.variables) {\n    ans.variables = addVariables(reader);\n  }\n\n  return ans;\n}", "label": 3}
{"code": "def log!(action)\n      case action\n      when :started\n        Logger.info \"Performing Backup for '#{label} (#{trigger})'!\\n\" \\\n            \"[ backup #{VERSION} : #{RUBY_DESCRIPTION} ]\"\n\n      when :finished\n        if exit_status > 1\n          ex = exit_status == 2 ? Error : FatalError\n          err = ex.wrap(exception, \"Backup for #{label} (#{trigger}) Failed!\")\n          Logger.error err\n          Logger.error \"\\nBacktrace:\\n\\s\\s\" + err.backtrace.join(\"\\n\\s\\s\") + \"\\n\\n\"\n\n          Cleaner.warnings(self)\n        else\n          msg = \"Backup for '#{label} (#{trigger})' \"\n          if exit_status == 1\n            msg << \"Completed Successfully (with Warnings) in #{duration}\"\n            Logger.warn msg\n          else\n            msg << \"Completed Successfully in #{duration}\"\n            Logger.info msg\n          end\n        end\n      end\n    end", "label": 4}
{"code": "function closest(node, parentSelector) {\n  var cursor = node;\n\n  if (!parentSelector || typeof parentSelector !== 'string') {\n    throw new Error('Please specify a selector to match against!');\n  }\n\n  while (cursor && !matches(cursor, parentSelector)) {\n    cursor = cursor.parentNode;\n  }\n\n  if (!cursor) {\n    return null;\n  } else {\n    return cursor;\n  }\n}", "label": 3}
{"code": "function promisify(f, args) {\n  return new Promise((resolve, reject) => f.apply(this, args.concat((err, x) => err ? reject(err) : resolve(x))));\n}", "label": 3}
{"code": "def b64decode(s):\n    '''Base64 decodes a base64-encoded string in URL-safe\n    or normal format, with or without padding.\n    The argument may be string or bytes.\n\n    @param s bytes decode\n    @return bytes decoded\n    @raises ValueError on failure\n    '''\n    # add padding if necessary.\n    s = to_bytes(s)\n    if not s.endswith(b'='):\n        s = s + b'=' * (-len(s) % 4)\n    try:\n        if '_' or '-' in s:\n            return base64.urlsafe_b64decode(s)\n        else:\n            return base64.b64decode(s)\n    except (TypeError, binascii.Error) as e:\n        raise ValueError(str(e))", "label": 1}
{"code": "private void internalCleanup()\r\n    {\r\n        if(hasBroker())\r\n        {\r\n            PersistenceBroker broker = getBroker();\r\n            if(log.isDebugEnabled())\r\n            {\r\n                log.debug(\"Do internal cleanup and close the internal used connection without\" +\r\n                        \" closing the used broker\");\r\n            }\r\n            ConnectionManagerIF cm = broker.serviceConnectionManager();\r\n            if(cm.isInLocalTransaction())\r\n            {\r\n                /*\r\n                arminw:\r\n                in managed environment this call will be ignored because, the JTA transaction\r\n                manager control the connection status. But to make connectionManager happy we\r\n                have to complete the \"local tx\" of the connectionManager before release the\r\n                connection\r\n                */\r\n                cm.localCommit();\r\n            }\r\n            cm.releaseConnection();\r\n        }\r\n    }", "label": 0}
{"code": "public static sslcipher get(nitro_service service, String ciphergroupname) throws Exception{\n\t\tsslcipher obj = new sslcipher();\n\t\tobj.set_ciphergroupname(ciphergroupname);\n\t\tsslcipher response = (sslcipher) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (b *BoltBackend) GetItems(path []string, opts ...legacy.OpOption) ([]legacy.Item, error) {\n\tcfg, err := legacy.CollectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif cfg.Recursive {\n\t\treturn b.getItemsRecursive(path)\n\t}\n\n\tkeys, err := b.GetKeys(path)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// This is a very inefficient approach. It's here to satisfy the\n\t// backend.Backend interface since the Bolt backend is slated for removal\n\t// in 2.7.0 anyway.\n\titems := make([]legacy.Item, 0, len(keys))\n\tfor _, e := range keys {\n\t\tval, err := b.GetVal(path, e)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\titems = append(items, legacy.Item{\n\t\t\tKey:   e,\n\t\t\tValue: val,\n\t\t})\n\t}\n\n\treturn items, nil\n}", "label": 5}
{"code": "def init(*plugin_names)\n      env = Cli::Environments::Valid.new(options)\n      exitcode = env.initialize_guardfile(plugin_names)\n      exit(exitcode)\n    end", "label": 4}
{"code": "def path\n      # Static file is from a collection inside custom collections directory\n      if !@collection.nil? && !@site.config[\"collections_dir\"].empty?\n        File.join(*[@base, @site.config[\"collections_dir\"], @dir, @name].compact)\n      else\n        File.join(*[@base, @dir, @name].compact)\n      end\n    end", "label": 4}
{"code": "func startBee(bee *BeeInterface, fatals int) {\n\tif fatals >= 3 {\n\t\tlog.Println(\"Terminating evil bee\", (*bee).Name(), \"after\", fatals, \"failed tries!\")\n\t\t(*bee).Stop()\n\t\treturn\n\t}\n\n\t(*bee).WaitGroup().Add(1)\n\tdefer (*bee).WaitGroup().Done()\n\n\tdefer func(bee *BeeInterface) {\n\t\tif e := recover(); e != nil {\n\t\t\tlog.Println(\"Fatal bee event:\", e, fatals)\n\t\t\tgo startBee(bee, fatals+1)\n\t\t}\n\t}(bee)\n\n\t(*bee).Run(eventsIn)\n}", "label": 5}
{"code": "function extractSchemaLabel(schema, limit) {\n\t\tlimit = typeof limit === 'undefined' ? strimLimit : limit;\n\t\tvar label = '';\n\t\tif (schema.id) {\n\t\t\tlabel = style.accent(schema.id);\n\t\t}\n\t\tif (schema.title) {\n\t\t\tlabel += style.accent(label ? ' (' + schema.title + ')' : style.accent(schema.title));\n\t\t}\n\n\t\tif (!label) {\n\t\t\tif (schema.description) {\n\t\t\t\tlabel = style.accent('<no id>') + ' ' + valueStrim(schema.description, limit);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tlabel = style.accent('<no id>') + ' ' + valueStrim(schema, limit);\n\t\t\t}\n\t\t}\n\t\treturn label;\n\t}", "label": 3}
{"code": "public static <E> Counter<E> division(Counter<E> c1, Counter<E> c2) {\r\n    Counter<E> result = c1.getFactory().create();\r\n    for (E key : Sets.union(c1.keySet(), c2.keySet())) {\r\n      result.setCount(key, c1.getCount(key) / c2.getCount(key));\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "def on_complete(env)\n      status_code   = env[:status].to_i\n      service_error = Github::Error::ServiceError\n      error_class = service_error.error_mapping[status_code]\n      if !error_class and (400...600) === status_code\n        error_class = service_error\n      end\n      raise error_class.new(env) if error_class\n    end", "label": 4}
{"code": "def lazy_result(f):\n    \"\"\"Decorate function to return LazyProxy.\"\"\"\n    @wraps(f)\n    def decorated(ctx, param, value):\n        return LocalProxy(lambda: f(ctx, param, value))\n    return decorated", "label": 1}
{"code": "public function walkGeneralCaseExpression(AST\\GeneralCaseExpression $generalCaseExpression)\n    {\n        $sql = 'CASE';\n\n        foreach ($generalCaseExpression->whenClauses as $whenClause) {\n            $sql .= ' WHEN ' . $this->walkConditionalExpression($whenClause->caseConditionExpression);\n            $sql .= ' THEN ' . $this->walkSimpleArithmeticExpression($whenClause->thenScalarExpression);\n        }\n\n        $sql .= ' ELSE ' . $this->walkSimpleArithmeticExpression($generalCaseExpression->elseScalarExpression) . ' END';\n\n        return $sql;\n    }", "label": 2}
{"code": "public function json($content)\n    {\n        if (is_array($content)) {\n            $content = json_encode($content);\n        }\n\n        $this->content = $content;\n\n        return $this->header('Content-Type', 'application/json');\n    }", "label": 2}
{"code": "func seconds(ttl time.Duration) int64 {\n\ti := int64(ttl / time.Second)\n\tif i <= 0 {\n\t\ti = 1\n\t}\n\treturn i\n}", "label": 5}
{"code": "def find(name, providers, version)\n      providers = Array(providers)\n\n      # Build up the requirements we have\n      requirements = version.to_s.split(\",\").map do |v|\n        Gem::Requirement.new(v.strip)\n      end\n\n      with_collection_lock do\n        box_directory = @directory.join(dir_name(name))\n        if !box_directory.directory?\n          @logger.info(\"Box not found: #{name} (#{providers.join(\", \")})\")\n          return nil\n        end\n\n        # Keep a mapping of Gem::Version mangled versions => directories.\n        # ie. 0.1.0.pre.alpha.2 => 0.1.0-alpha.2\n        # This is so we can sort version numbers properly here, but still\n        # refer to the real directory names in path checks below and pass an\n        # unmangled version string to Box.new\n        version_dir_map = {}\n\n        versions = box_directory.children(true).map do |versiondir|\n          next if !versiondir.directory?\n          next if versiondir.basename.to_s.start_with?(\".\")\n\n          version = Gem::Version.new(versiondir.basename.to_s)\n          version_dir_map[version.to_s] = versiondir.basename.to_s\n          version\n        end.compact\n\n        # Traverse through versions with the latest version first\n        versions.sort.reverse.each do |v|\n          if !requirements.all? { |r| r.satisfied_by?(v) }\n            # Unsatisfied version requirements\n            next\n          end\n\n          versiondir = box_directory.join(version_dir_map[v.to_s])\n          providers.each do |provider|\n            provider_dir = versiondir.join(provider.to_s)\n            next if !provider_dir.directory?\n            @logger.info(\"Box found: #{name} (#{provider})\")\n\n            metadata_url = nil\n            metadata_url_file = box_directory.join(\"metadata_url\")\n            metadata_url = metadata_url_file.read if metadata_url_file.file?\n\n            if metadata_url && @hook\n              hook_env     = @hook.call(\n                :authenticate_box_url, box_urls: [metadata_url])\n              metadata_url = hook_env[:box_urls].first\n            end\n\n            return Box.new(\n              name, provider, version_dir_map[v.to_s], provider_dir,\n              metadata_url: metadata_url,\n            )\n          end\n        end\n      end\n\n      nil\n    end", "label": 4}
{"code": "func (s *Server) GetattrV2(p *Packet) (interface{}, error) {\n\tres := &ReplyGetattrV2{}\n\n\treq := new(RequestGetattrV2)\n\terr := UnmarshalBinary(p.Payload, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tname := req.FileName.Path()\n\tinfo, err := s.Stat(name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres.Attr.Stat(info)\n\n\treturn res, nil\n}", "label": 5}
{"code": "function onClick (ev, elements) {\n  var model = this._Ampersandview.model;\n  var partition = model.filter.partitions.get(1, 'rank');\n\n  if (elements.length > 0) {\n    partition.updateSelection(partition.groups.models[elements[0]._index]);\n    model.filter.updateDataFilter();\n    app.me.dataview.getData();\n  }\n}", "label": 3}
{"code": "def get_functions(fname):\n    \"\"\" get a list of functions from a Python program \"\"\"\n    txt = '' \n    with open(fname, 'r') as f:\n        for line in f:\n            if line.strip()[0:4] == 'def ':\n                txt += '<PRE>' + strip_text_after_string(strip_text_after_string(line, '#')[4:], ':') + '</PRE>\\n'\n            if line[0:5] == 'class':\n                txt += '<PRE>' + strip_text_after_string(strip_text_after_string(line, '#'), ':') + '</PRE>\\n'\n    return txt + '<BR>'", "label": 1}
{"code": "function(args)\n    {\n        var i, max, match, log;\n        \n        // Convert argument list to real array\n        args = Array.prototype.slice.call(arguments, 0);\n        \n        // First argument is the log method to call\n        log = args.shift();\n        \n        max = args.length;\n        if (max > 1 && window[\"__consoleShimTest__\"] !== false)\n        {\n            // When first parameter is not a string then add a format string to\n            // the argument list so we are able to modify it in the next stop\n            if (typeof(args[0]) != \"string\")\n            {\n                args.unshift(\"%o\");\n                max += 1;\n            }\n            \n            // For each additional parameter which has no placeholder in the\n            // format string we add another placeholder separated with a\n            // space character.\n            match = args[0].match(/%[a-z]/g);\n            for (i = match ? match.length + 1 : 1; i < max; i += 1)\n            {\n                args[0] += \" %o\";\n            }\n        }\n        Function.apply.call(log, console, args);\n    }", "label": 3}
{"code": "public static int Maximum(ImageSource fastBitmap, int startX, int startY, int width, int height) {\r\n        int max = 0;\r\n\r\n        if (fastBitmap.isGrayscale()) {\r\n            for (int i = startX; i < height; i++) {\r\n                for (int j = startY; j < width; j++) {\r\n                    int gray = fastBitmap.getRGB(j, i);\r\n                    if (gray > max) {\r\n                        max = gray;\r\n                    }\r\n                }\r\n            }\r\n        } else {\r\n            for (int i = startX; i < height; i++) {\r\n                for (int j = startY; j < width; j++) {\r\n                    int gray = fastBitmap.getG(j, i);\r\n                    if (gray > max) {\r\n                        max = gray;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        return max;\r\n    }", "label": 0}
{"code": "func (a *allocator) ReleaseAddress(poolID string, address net.IP) error {\n\tlogrus.Debugf(\"ReleaseAddress(%s, %v)\", poolID, address)\n\treturn nil\n}", "label": 5}
{"code": "def validate!\n      identify\n    rescue MiniMagick::Error => error\n      raise MiniMagick::Invalid, error.message\n    end", "label": 4}
{"code": "function (range) {\n        var coeff = 1000 * 60 * range;\n        return new Date(Math.ceil(new Date(Date.now()).getTime() / coeff) * coeff).getTime() / 1000;\n    }", "label": 3}
{"code": "def create_function_f_J(self):\n        \"\"\"Jacobian for state integration\"\"\"\n        return ca.Function(\n            'J',\n            [self.t, self.x, self.y, self.m, self.p, self.c, self.ng, self.nu],\n            [ca.jacobian(self.f_x_rhs, self.x)],\n            ['t', 'x', 'y', 'm', 'p', 'c', 'ng', 'nu'], ['J'], self.func_opt)", "label": 1}
{"code": "public static authenticationvserver_authenticationtacacspolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationvserver_authenticationtacacspolicy_binding obj = new authenticationvserver_authenticationtacacspolicy_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationvserver_authenticationtacacspolicy_binding response[] = (authenticationvserver_authenticationtacacspolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def update(*args)\n      raise_authentication_error unless authenticated?\n      arguments(args, required: [:id])\n\n      patch_request(\"/authorizations/#{arguments.id}\", arguments.params)\n    end", "label": 4}
{"code": "func (flag *OutputFlag) Log(s string) (int, error) {\n\tif len(s) > 0 && s[0] == '\\r' {\n\t\tflag.Write([]byte{'\\r', 033, '[', 'K'})\n\t\ts = s[1:]\n\t}\n\n\treturn flag.WriteString(time.Now().Format(\"[02-01-06 15:04:05] \") + s)\n}", "label": 5}
{"code": "function(callback) {\n    bootstrap(behaviour, (bootstrapErr, bootstrapRes) => {\n      if (bootstrapErr) api.emit(\"error\", bootstrapErr);\n      if (bootstrapRes && bootstrapRes.virgin) {\n        bootstrapRes.connection.on(\"error\", (err) => api.emit(\"error\", err));\n        bootstrapRes.connection.on(\"close\", (why) => api.emit(\"error\", why));\n        api.emit(\"connected\");\n        bootstrapRes.pubChannel.on(\"error\", (err) => api.emit(\"error\", err));\n        bootstrapRes.subChannel.on(\"error\", (err) => api.emit(\"error\", err));\n        bootstrapRes.pubChannel.assertExchange(behaviour.exchange, \"topic\");\n      }\n      callback(bootstrapErr, bootstrapRes);\n    });\n  }", "label": 3}
{"code": "def deserialize_namespace(data):\n    ''' Deserialize a Namespace object.\n\n    :param data: bytes or str\n    :return: namespace\n    '''\n    if isinstance(data, bytes):\n        data = data.decode('utf-8')\n    kvs = data.split()\n    uri_to_prefix = {}\n    for kv in kvs:\n        i = kv.rfind(':')\n        if i == -1:\n            raise ValueError('no colon in namespace '\n                             'field {}'.format(repr(kv)))\n        uri, prefix = kv[0:i], kv[i + 1:]\n        if not is_valid_schema_uri(uri):\n            # Currently this can't happen because the only invalid URIs\n            # are those which contain a space\n            raise ValueError(\n                'invalid URI {} in namespace '\n                'field {}'.format(repr(uri), repr(kv)))\n        if not is_valid_prefix(prefix):\n            raise ValueError(\n                'invalid prefix {} in namespace field'\n                ' {}'.format(repr(prefix), repr(kv)))\n        if uri in uri_to_prefix:\n            raise ValueError(\n                'duplicate URI {} in '\n                'namespace {}'.format(repr(uri), repr(data)))\n        uri_to_prefix[uri] = prefix\n    return Namespace(uri_to_prefix)", "label": 1}
{"code": "public function setQuickReplies($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->quick_replies = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def format_paragraph(text, len = 72, indent = 2)\n      sentences = [[]]\n\n      text.split.each do |word|\n        if sentences.first.present? && (sentences.last + [word]).join(\" \").length > len\n          sentences << [word]\n        else\n          sentences.last << word\n        end\n      end\n\n      indentation = \" \" * indent\n      sentences.map! { |sentence|\n        \"#{indentation}#{sentence.join(' ')}\"\n      }.join \"\\n\"\n    end", "label": 4}
{"code": "func OptionDefaultNetwork(dn string) Option {\n\treturn func(c *Config) {\n\t\tlogrus.Debugf(\"Option DefaultNetwork: %s\", dn)\n\t\tc.Daemon.DefaultNetwork = strings.TrimSpace(dn)\n\t}\n}", "label": 5}
{"code": "func getFirstAvailable(head *sequence, start uint64) (uint64, uint64, error) {\n\t// Find sequence which contains the start bit\n\tbyteStart, bitStart := ordinalToPos(start)\n\tcurrent, _, precBlocks, inBlockBytePos := findSequence(head, byteStart)\n\t// Derive the this sequence offsets\n\tbyteOffset := byteStart - inBlockBytePos\n\tbitOffset := inBlockBytePos*8 + bitStart\n\tfor current != nil {\n\t\tif current.block != blockMAX {\n\t\t\t// If the current block is not full, check if there is any bit\n\t\t\t// from the current bit in the current block. If not, before proceeding to the\n\t\t\t// next block node, make sure we check for available bit in the next\n\t\t\t// instance of the same block. Due to RLE same block signature will be\n\t\t\t// compressed.\n\t\tretry:\n\t\t\tbytePos, bitPos, err := current.getAvailableBit(bitOffset)\n\t\t\tif err != nil && precBlocks == current.count-1 {\n\t\t\t\t// This is the last instance in the same block node,\n\t\t\t\t// so move to the next block.\n\t\t\t\tgoto next\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\t// There are some more instances of the same block, so add the offset\n\t\t\t\t// and be optimistic that you will find the available bit in the next\n\t\t\t\t// instance of the same block.\n\t\t\t\tbitOffset = 0\n\t\t\t\tbyteOffset += blockBytes\n\t\t\t\tprecBlocks++\n\t\t\t\tgoto retry\n\t\t\t}\n\t\t\treturn byteOffset + bytePos, bitPos, err\n\t\t}\n\t\t// Moving to next block: Reset bit offset.\n\tnext:\n\t\tbitOffset = 0\n\t\tbyteOffset += (current.count * blockBytes) - (precBlocks * blockBytes)\n\t\tprecBlocks = 0\n\t\tcurrent = current.next\n\t}\n\treturn invalidPos, invalidPos, ErrNoBitAvailable\n}", "label": 5}
{"code": "def set_clock_type(type):\n    \"\"\"\n    Sets the internal clock type for timing. Profiler shall not have any previous stats.\n    Otherwise an exception is thrown.\n    \"\"\"\n    type = type.upper()\n    if type not in CLOCK_TYPES:\n        raise YappiError(\"Invalid clock type:%s\" % (type))\n        \n    _yappi.set_clock_type(CLOCK_TYPES[type])", "label": 1}
{"code": "public static vpntrafficpolicy_vpnglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpntrafficpolicy_vpnglobal_binding obj = new vpntrafficpolicy_vpnglobal_binding();\n\t\tobj.set_name(name);\n\t\tvpntrafficpolicy_vpnglobal_binding response[] = (vpntrafficpolicy_vpnglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (s *server) GetSession(namespace string, id ID) (*Session, error) {\n\titem, err := s.bk.Get(context.TODO(), activeKey(namespace, string(id)))\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn nil, trace.NotFound(\"session(%v, %v) is not found\", namespace, id)\n\t\t}\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar sess Session\n\tif err := json.Unmarshal(item.Value, &sess); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &sess, nil\n}", "label": 5}
{"code": "public function getConnectionById($connectionID)\n    {\n        if (!$this->connection instanceof AggregateConnectionInterface) {\n            throw new NotSupportedException(\n                'Retrieving connections by ID is supported only by aggregate connections.'\n            );\n        }\n\n        return $this->connection->getConnectionById($connectionID);\n    }", "label": 2}
{"code": "protected function queueRequest($verb, $uri, $parameters, $content = '')\n    {\n        if (! empty($content)) {\n            $this->content = $content;\n        }\n\n        // Sometimes after setting the initial request another request might be made prior to\n        // internally dispatching an API request. We need to capture this request as well\n        // and add it to the request stack as it has become the new parent request to\n        // this internal request. This will generally occur during tests when\n        // using the crawler to navigate pages that also make internal\n        // requests.\n        if (end($this->requestStack) != $this->container['request']) {\n            $this->requestStack[] = $this->container['request'];\n        }\n\n        $this->requestStack[] = $request = $this->createRequest($verb, $uri, $parameters);\n\n        return $this->dispatch($request);\n    }", "label": 2}
{"code": "public void check(ClassDescriptorDef classDef, String checkLevel) throws ConstraintException\r\n    {\r\n        ensureNoTableInfoIfNoRepositoryInfo(classDef, checkLevel);\r\n        checkModifications(classDef, checkLevel);\r\n        checkExtents(classDef, checkLevel);\r\n        ensureTableIfNecessary(classDef, checkLevel);\r\n        checkFactoryClassAndMethod(classDef, checkLevel);\r\n        checkInitializationMethod(classDef, checkLevel);\r\n        checkPrimaryKey(classDef, checkLevel);\r\n        checkProxyPrefetchingLimit(classDef, checkLevel);\r\n        checkRowReader(classDef, checkLevel);\r\n        checkObjectCache(classDef, checkLevel);\r\n        checkProcedures(classDef, checkLevel);\r\n    }", "label": 0}
{"code": "def sort(input, property = nil, nils = \"first\")\n      raise ArgumentError, \"Cannot sort a null object.\" if input.nil?\n\n      if property.nil?\n        input.sort\n      else\n        if nils == \"first\"\n          order = - 1\n        elsif nils == \"last\"\n          order = + 1\n        else\n          raise ArgumentError, \"Invalid nils order: \" \\\n            \"'#{nils}' is not a valid nils order. It must be 'first' or 'last'.\"\n        end\n\n        sort_input(input, property, order)\n      end\n    end", "label": 4}
{"code": "def run_snpeff(job, merged_mutation_file, univ_options, snpeff_options):\n    \"\"\"\n    Run snpeff on an input vcf.\n\n    :param toil.fileStore.FileID merged_mutation_file: fsID for input vcf\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict snpeff_options: Options specific to snpeff\n    :return: fsID for the snpeffed vcf\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'merged_mutations.vcf': merged_mutation_file,\n        'snpeff_index.tar.gz': snpeff_options['index']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n    input_files['snpeff_index'] = untargz(input_files['snpeff_index.tar.gz'], work_dir)\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    parameters = ['eff',\n                  '-dataDir', input_files['snpeff_index'],\n                  '-c', '/'.join([input_files['snpeff_index'],\n                                  'snpEff_' + univ_options['ref'] + '_gencode.config']),\n                  '-no-intergenic',\n                  '-no-downstream',\n                  '-no-upstream',\n                  # '-canon',\n                  '-noStats',\n                  univ_options['ref'] + '_gencode',\n                  input_files['merged_mutations.vcf']]\n    xmx = snpeff_options['java_Xmx'] if snpeff_options['java_Xmx'] else univ_options['java_Xmx']\n    with open('/'.join([work_dir, 'mutations.vcf']), 'w') as snpeff_file:\n        docker_call(tool='snpeff', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], java_xmx=xmx, outfile=snpeff_file,\n                    tool_version=snpeff_options['version'])\n    output_file = job.fileStore.writeGlobalFile(snpeff_file.name)\n    export_results(job, output_file, snpeff_file.name, univ_options, subfolder='mutations/snpeffed')\n    job.fileStore.logToMaster('Ran snpeff on %s successfully' % univ_options['patient'])\n    return output_file", "label": 1}
{"code": "function commentNode(outNode, options) {\n\tconst node = outNode.node;\n\n\tif (!options.enabled || !options.trigger || !node.name) {\n\t\treturn;\n\t}\n\n\tconst attrs = outNode.node.attributes.reduce((out, attr) => {\n\t\tif (attr.name && attr.value != null) {\n\t\t\tout[attr.name.toUpperCase().replace(/-/g, '_')] = attr.value;\n\t\t}\n\n\t\treturn out;\n\t}, {});\n\n\t// add comment only if attribute trigger is present\n\tfor (let i = 0, il = options.trigger.length; i < il; i++) {\n\t\tif (options.trigger[i].toUpperCase() in attrs) {\n\t\t\toutNode.open = template(options.before, attrs) + outNode.open;\n\t\t\tif (outNode.close) {\n\t\t\t\toutNode.close += template(options.after, attrs);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}", "label": 3}
{"code": "public static String convertToSQL92(char escape, char multi, char single, String pattern)\n\t\t\tthrows IllegalArgumentException {\n\t\tif ((escape == '\\'') || (multi == '\\'') || (single == '\\'')) {\n\t\t\tthrow new IllegalArgumentException(\"do not use single quote (') as special char!\");\n\t\t}\n\t\t\n\t\tStringBuilder result = new StringBuilder(pattern.length() + 5);\n\t\tint i = 0;\n\t\twhile (i < pattern.length()) {\n\t\t\tchar chr = pattern.charAt(i);\n\t\t\tif (chr == escape) {\n\t\t\t\t// emit the next char and skip it\n\t\t\t\tif (i != (pattern.length() - 1)) {\n\t\t\t\t\tresult.append(pattern.charAt(i + 1));\n\t\t\t\t}\n\t\t\t\ti++; // skip next char\n\t\t\t} else if (chr == single) {\n\t\t\t\tresult.append('_');\n\t\t\t} else if (chr == multi) {\n\t\t\t\tresult.append('%');\n\t\t\t} else if (chr == '\\'') {\n\t\t\t\tresult.append('\\'');\n\t\t\t\tresult.append('\\'');\n\t\t\t} else {\n\t\t\t\tresult.append(chr);\n\t\t\t}\n\t\t\ti++;\n\t\t}\n\n\t\treturn result.toString();\n\t}", "label": 0}
{"code": "def to_json_hash\n      result = {}\n\n      @values.each_key do |field_name|\n        value = self[field_name]\n        field = self.class.get_field(field_name, true)\n\n        # NB: to_json_hash_value should come before json_encode so as to handle\n        # repeated fields without extra logic.\n        hashed_value = if value.respond_to?(:to_json_hash_value)\n                         value.to_json_hash_value\n                       elsif field.respond_to?(:json_encode)\n                         field.json_encode(value)\n                       else\n                         value\n                       end\n\n        result[field.name] = hashed_value\n      end\n\n      result\n    end", "label": 4}
{"code": "public Response getBill(int month, int year)\n            throws RequestException, LocalOperationException {\n        Request request = new Request(this);\n        return new Response(request.get(\"/bill/\" + year + String.format(\"-%02d\", month)));\n    }", "label": 0}
{"code": "func (u *UpdateRequest) Check() error {\n\tif err := u.ID.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif u.Namespace == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter Namespace\")\n\t}\n\tif u.TerminalParams != nil {\n\t\t_, err := NewTerminalParamsFromInt(u.TerminalParams.W, u.TerminalParams.H)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function (url, options) {\n      return Object.keys(options).reduce(this._replacePlaceholderInUrl.bind(this, options), url);\n    }", "label": 3}
{"code": "function clientNow() {\n  var d = new Date();\n  var offset = -1 * d.getTimezoneOffset();\n\n  d.setUTCMinutes(d.getUTCMinutes() + offset);\n  return d.toISOString().replace('Z', minutesToOffsetString(offset));\n}", "label": 3}
{"code": "public function getRequest()\n    {\n        $request = $this->container['request'];\n\n        if ($request instanceof IlluminateRequest && ! $request instanceof Request) {\n            $request = (new Request())->createFromIlluminate($request);\n        }\n\n        return $request;\n    }", "label": 2}
{"code": "func (f *Fpdf) SetPageBox(t string, x, y, wd, ht float64) {\n\tf.SetPageBoxRec(t, PageBox{SizeType{Wd: wd, Ht: ht}, PointType{X: x, Y: y}})\n}", "label": 5}
{"code": "func (f *Fpdf) GetFillSpotColor() (name string, c, m, y, k byte) {\n\treturn f.returnSpotColor(f.color.fill)\n}", "label": 5}
{"code": "def basic_setup\n      @status = attr_val('./*/cda:statusCode/@code')\n      @id_xpath = './*/cda:id/@extension'\n      @id = \"#{attr_val('./*/cda:id/@extension')}_#{attr_val('./*/cda:id/@root')}\"\n      @comments = @entry.xpath(\"./#{CRITERIA_GLOB}/cda:text/cda:xml/cda:qdmUserComments/cda:item/text()\",\n                               HQMF2::Document::NAMESPACES).map(&:content)\n      @code_list_xpath = './*/cda:code'\n      @value_xpath = './*/cda:value'\n      @is_derived_specific_occurrence_variable = false\n      simple_extractions = DataCriteriaBaseExtractions.new(@entry)\n      @template_ids = simple_extractions.extract_template_ids\n      @local_variable_name = simple_extractions.extract_local_variable_name\n      @temporal_references = simple_extractions.extract_temporal_references\n      @derivation_operator = simple_extractions.extract_derivation_operator\n      @children_criteria = simple_extractions.extract_child_criteria\n      @subset_operators = simple_extractions.extract_subset_operators\n      @negation, @negation_code_list_id = simple_extractions.extract_negation\n    end", "label": 4}
{"code": "def unwrap(wrapper)\n      client.with_token(wrapper) do |client|\n        json = client.get(\"/v1/cubbyhole/response\")\n        secret = Secret.decode(json)\n\n        # If there is nothing in the cubbyhole, return early.\n        if secret.nil? || secret.data.nil? || secret.data[:response].nil?\n          return nil\n        end\n\n        # Extract the response and parse it into a new secret.\n        json = JSON.parse(secret.data[:response], symbolize_names: true)\n        secret = Secret.decode(json)\n        return secret\n      end\n    rescue HTTPError => e\n      return nil if e.code == 404\n      raise\n    end", "label": 4}
{"code": "def parse_unifrac_v1_9(unifrac, file_data):\n    \"\"\"\n    Function to parse data from newer version of unifrac file obtained from Qiime version\n    1.9 and later.\n\n    :type unifracFN: str\n    :param unifracFN: The path to the unifrac results file\n\n    :type file_data: list\n    :param file_data: Unifrac data lines after stripping whitespace characters.\n    \"\"\"\n    unifrac[\"eigvals\"] = [float(entry) for entry in file_data[0].split(\"\\t\")]\n    unifrac[\"varexp\"] = [float(entry)*100 for entry in file_data[3].split(\"\\t\")]\n\n    for line in file_data[8:]:\n        if line == \"\":\n            break\n        line = line.split(\"\\t\")\n        unifrac[\"pcd\"][line[0]] = [float(e) for e in line[1:]]\n    return unifrac", "label": 1}
{"code": "private void ensureReferencedPKs(ModelDef modelDef, CollectionDescriptorDef collDef) throws ConstraintException\r\n    {\r\n        String             elementClassName   = collDef.getProperty(PropertyHelper.OJB_PROPERTY_ELEMENT_CLASS_REF);\r\n        ClassDescriptorDef elementClassDef    = modelDef.getClass(elementClassName);\r\n        String             indirTable         = collDef.getProperty(PropertyHelper.OJB_PROPERTY_INDIRECTION_TABLE);\r\n        String             localKey           = collDef.getProperty(PropertyHelper.OJB_PROPERTY_FOREIGNKEY);\r\n        String             remoteKey          = collDef.getProperty(PropertyHelper.OJB_PROPERTY_REMOTE_FOREIGNKEY);\r\n        boolean            hasRemoteKey       = remoteKey != null;\r\n        ArrayList          fittingCollections = new ArrayList();\r\n\r\n        // we're checking for the fitting remote collection(s) and also\r\n        // use their foreignkey as remote-foreignkey in the original collection definition\r\n        for (Iterator it = elementClassDef.getAllExtentClasses(); it.hasNext();)\r\n        {\r\n            ClassDescriptorDef subTypeDef = (ClassDescriptorDef)it.next();\r\n\r\n            // find the collection in the element class that has the same indirection table\r\n            for (Iterator collIt = subTypeDef.getCollections(); collIt.hasNext();)\r\n            {\r\n                CollectionDescriptorDef curCollDef = (CollectionDescriptorDef)collIt.next();\r\n\r\n                if (indirTable.equals(curCollDef.getProperty(PropertyHelper.OJB_PROPERTY_INDIRECTION_TABLE)) &&\r\n                    (collDef != curCollDef) &&\r\n                    (!hasRemoteKey || CommaListIterator.sameLists(remoteKey, curCollDef.getProperty(PropertyHelper.OJB_PROPERTY_FOREIGNKEY))) &&\r\n                    (!curCollDef.hasProperty(PropertyHelper.OJB_PROPERTY_REMOTE_FOREIGNKEY) ||\r\n                         CommaListIterator.sameLists(localKey, curCollDef.getProperty(PropertyHelper.OJB_PROPERTY_REMOTE_FOREIGNKEY))))\r\n                {\r\n                    fittingCollections.add(curCollDef);\r\n                }\r\n            }\r\n        }\r\n        if (!fittingCollections.isEmpty())\r\n        {\r\n            // if there is more than one, check that they match, i.e. that they all have the same foreignkeys\r\n            if (!hasRemoteKey && (fittingCollections.size() > 1))\r\n            {\r\n                CollectionDescriptorDef firstCollDef = (CollectionDescriptorDef)fittingCollections.get(0);\r\n                String                  foreignKey   = firstCollDef.getProperty(PropertyHelper.OJB_PROPERTY_FOREIGNKEY);\r\n\r\n                for (int idx = 1; idx < fittingCollections.size(); idx++)\r\n                {\r\n                    CollectionDescriptorDef curCollDef = (CollectionDescriptorDef)fittingCollections.get(idx);\r\n\r\n                    if (!CommaListIterator.sameLists(foreignKey, curCollDef.getProperty(PropertyHelper.OJB_PROPERTY_FOREIGNKEY)))\r\n                    {\r\n                        throw new ConstraintException(\"Cannot determine the element-side collection that corresponds to the collection \"+\r\n                                                      collDef.getName()+\" in type \"+collDef.getOwner().getName()+\r\n                                                      \" because there are at least two different collections that would fit.\"+\r\n                                                      \" Specifying remote-foreignkey in the original collection \"+collDef.getName()+\r\n                                                      \" will perhaps help\");\r\n                    }\r\n                }\r\n                // store the found keys at the collections\r\n                collDef.setProperty(PropertyHelper.OJB_PROPERTY_REMOTE_FOREIGNKEY, foreignKey);\r\n                for (int idx = 0; idx < fittingCollections.size(); idx++)\r\n                {\r\n                    CollectionDescriptorDef curCollDef = (CollectionDescriptorDef)fittingCollections.get(idx);\r\n\r\n                    curCollDef.setProperty(PropertyHelper.OJB_PROPERTY_REMOTE_FOREIGNKEY, localKey);\r\n                }\r\n            }\r\n        }\r\n\r\n        // copy subclass pk fields into target class (if not already present)\r\n        ensurePKsFromHierarchy(elementClassDef);\r\n    }", "label": 0}
{"code": "public static appfwwsdl get(nitro_service service, String name) throws Exception{\n\t\tappfwwsdl obj = new appfwwsdl();\n\t\tobj.set_name(name);\n\t\tappfwwsdl response = (appfwwsdl) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (s SearchIndex) FindByDnsName(ctx context.Context, dc *Datacenter, dnsName string, vmSearch bool) (Reference, error) {\n\treq := types.FindByDnsName{\n\t\tThis:     s.Reference(),\n\t\tDnsName:  dnsName,\n\t\tVmSearch: vmSearch,\n\t}\n\tif dc != nil {\n\t\tref := dc.Reference()\n\t\treq.Datacenter = &ref\n\t}\n\n\tres, err := methods.FindByDnsName(ctx, s.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif res.Returnval == nil {\n\t\treturn nil, nil\n\t}\n\treturn NewReference(s.c, *res.Returnval), nil\n}", "label": 5}
{"code": "public final void debug(Object pObject)\r\n\t{\r\n\t\tgetLogger().log(FQCN, Level.DEBUG, pObject, null);\r\n\t}", "label": 0}
{"code": "public static base_response update(nitro_service client, nsdiameter resource) throws Exception {\n\t\tnsdiameter updateresource = new nsdiameter();\n\t\tupdateresource.identity = resource.identity;\n\t\tupdateresource.realm = resource.realm;\n\t\tupdateresource.serverclosepropagation = resource.serverclosepropagation;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public static appfwprofile[] get(nitro_service service) throws Exception{\n\t\tappfwprofile obj = new appfwprofile();\n\t\tappfwprofile[] response = (appfwprofile[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def list_csv(self, filter=None, type=None, sort=None, limit=None, page=None): # pylint: disable=redefined-builtin\n        \"\"\"Get a list of results as CSV.\n\n        :param filter: (optional) Filters to apply as a string list.\n        :param type: (optional) `union` or `inter` as string.\n        :param sort: (optional) Sort fields to apply as string list.\n        :param limit: (optional) Limit returned list length.\n        :param page: (optional) Page to return.\n        :rtype: string\n        \"\"\"\n        return self.service.list(self.base, filter, type, sort, limit, page, format='csv').text", "label": 1}
{"code": "public void moveRectangleTo(Rectangle rect, float x, float y) {\n\t\tfloat width = rect.getWidth();\n\t\tfloat height = rect.getHeight();\n\t\trect.setLeft(x);\n\t\trect.setBottom(y);\n\t\trect.setRight(rect.getLeft() + width);\n\t\trect.setTop(rect.getBottom() + height);\n\t}", "label": 0}
{"code": "def index_buses(self, buses=None, start=0):\n        \"\"\" Updates the indices of all buses.\n\n        @param start: Starting index, typically 0 or 1.\n        @type start: int\n        \"\"\"\n        bs = self.connected_buses if buses is None else buses\n        for i, b in enumerate(bs):\n            b._i = start + i", "label": 1}
{"code": "function readConfig(options) {\n  return new Promise((resolve, reject) => {\n    const {\n      type,\n      config,\n      importsStart = null,\n      importsEnd = null,\n      exportsStart = 'export default {',\n      exportsEnd = '};',\n      isArray = false,\n    } = options;\n\n    if (!config || !isPlainObject(config)) {\n      return reject(new TypeError(t('SUPPLIED_CONFIG_IS_NOT_AN_OBJECT', {\n        typeofConfig: typeof config,\n      })));\n    }\n\n    const imports = importsStart ? [importsStart] : []; // Holds the import strings.\n    const exports = [exportsStart]; // Holds the export strings.\n\n    // eslint-disable-next-line global-require, import/no-dynamic-require\n    const themePackage = require(`${themes.getPath()}/package.json`);\n\n    if (\n      (type === TYPE_PORTALS || type === TYPE_WIDGETS) &&\n      has(themePackage.dependencies, 'react-loadable')\n    ) {\n      imports.push('import Loadable from \\'react-loadable\\';');\n      imports.push('import Loading from \\'@shopgate/pwa-common/components/Loading\\';');\n      imports.push('');\n    }\n\n    try {\n      Object.keys(config).forEach((id) => {\n        const component = config[id];\n        const componentPath = isDev ? component.path.replace('/dist/', '/src/') : component.path;\n\n        if (!componentExists(componentPath)) {\n          return;\n        }\n\n        const variableName = getVariableName(id);\n\n        const isPortalsOrWidgets = (\n          (type === TYPE_PORTALS && component.target !== 'app.routes')\n        || type === TYPE_WIDGETS\n        );\n\n        if (isPortalsOrWidgets && has(themePackage.dependencies, 'react-loadable')) {\n          imports.push(`const ${variableName} = Loadable({\\n  loader: () => import('${componentPath}'),\\n  loading: Loading,\\n});\\n`);\n        } else {\n          imports.push(`import ${variableName} from '${componentPath}';`);\n        }\n\n        if (isArray) {\n          exports.push(`  ${variableName},`);\n          return;\n        }\n\n        exports.push(`  '${id}': ${variableName},`);\n      });\n    } catch (e) {\n      return reject(e);\n    }\n\n    if (importsEnd) {\n      imports.push(importsEnd);\n    }\n\n    exports.push(exportsEnd);\n\n    return resolve({\n      imports,\n      exports,\n    });\n  });\n}", "label": 3}
{"code": "private static String convertISO88591toUTF8(String value) {\n    try {\n      return new String(value.getBytes(CharEncoding.ISO_8859_1), CharEncoding.UTF_8);\n    }\n    catch (UnsupportedEncodingException ex) {\n      // ignore and fallback to original encoding\n      return value;\n    }\n  }", "label": 0}
{"code": "def fetch_errors_in_data(data_section: nil, sub_section_name: nil, keys: nil)\n      if data_section && sub_section_name\n        sub_section = data_section[sub_section_name]\n      else\n        sub_section = data_section\n      end\n\n      unless sub_section\n        return {}\n      end\n\n      error_map = {}\n      keys.each do |key|\n        errors = sub_section.fetch(key, [])\n        error_map[key] = errors if errors.count > 0\n      end\n      return error_map\n    end", "label": 4}
{"code": "func (h *AuthHandlers) fetchRoleSet(cert *ssh.Certificate, ca services.CertAuthority, teleportUser string, clusterName string) (services.RoleSet, error) {\n\t// for local users, go and check their individual permissions\n\tvar roles services.RoleSet\n\tif clusterName == ca.GetClusterName() {\n\t\tu, err := h.AccessPoint.GetUser(teleportUser)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\t// Pass along the traits so we get the substituted roles for this user.\n\t\troles, err = services.FetchRoles(u.GetRoles(), h.AccessPoint, u.GetTraits())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t} else {\n\t\tcertRoles, err := extractRolesFromCert(cert)\n\t\tif err != nil {\n\t\t\treturn nil, trace.AccessDenied(\"failed to parse certificate roles\")\n\t\t}\n\t\troleNames, err := ca.CombinedMapping().Map(certRoles)\n\t\tif err != nil {\n\t\t\treturn nil, trace.AccessDenied(\"failed to map roles\")\n\t\t}\n\t\t// pass the principals on the certificate along as the login traits\n\t\t// to the remote cluster.\n\t\ttraits := map[string][]string{\n\t\t\tteleport.TraitLogins: cert.ValidPrincipals,\n\t\t}\n\t\troles, err = services.FetchRoles(roleNames, h.AccessPoint, traits)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\n\treturn roles, nil\n}", "label": 5}
{"code": "func fullProfileName(profileDir string, proxyHost string) (string, error) {\n\tvar err error\n\tvar profileName string\n\n\t// If no profile name was passed in, try and extract the active profile from\n\t// the ~/.tsh/profile symlink. If one was passed in, append .yaml to name.\n\tif proxyHost == \"\" {\n\t\tprofileName, err = os.Readlink(filepath.Join(profileDir, \"profile\"))\n\t\tif err != nil {\n\t\t\treturn \"\", trace.ConvertSystemError(err)\n\t\t}\n\t} else {\n\t\tprofileName = proxyHost + \".yaml\"\n\t}\n\n\t// Make sure the profile requested actually exists.\n\t_, err = os.Stat(filepath.Join(profileDir, profileName))\n\tif err != nil {\n\t\treturn \"\", trace.ConvertSystemError(err)\n\t}\n\n\treturn profileName, nil\n}", "label": 5}
{"code": "public static nd6[] get(nitro_service service) throws Exception{\n\t\tnd6 obj = new nd6();\n\t\tnd6[] response = (nd6[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def login(remote_app):\n    \"\"\"Send user to remote application for authentication.\"\"\"\n    oauth = current_app.extensions['oauthlib.client']\n\n    if remote_app not in oauth.remote_apps:\n        return abort(404)\n\n    # Get redirect target in safe manner.\n    next_param = get_safe_redirect_target(arg='next')\n\n    # Redirect URI - must be registered in the remote service.\n    callback_url = url_for(\n        '.authorized',\n        remote_app=remote_app,\n        _external=True,\n    )\n\n    # Create a JSON Web Token that expires after OAUTHCLIENT_STATE_EXPIRES\n    # seconds.\n    state_token = serializer.dumps({\n        'app': remote_app,\n        'next': next_param,\n        'sid': _create_identifier(),\n    })\n\n    return oauth.remote_apps[remote_app].authorize(\n        callback=callback_url,\n        state=state_token,\n    )", "label": 1}
{"code": "def add_media(device_types, media_type, paths)\n      media_type = media_type.to_s\n\n      device_types.each do |device_type|\n        UI.verbose(\"Adding #{media_type}s to #{device_type}...\")\n        device_udid = TestCommandGenerator.device_udid(device_type)\n\n        UI.message(\"Launch Simulator #{device_type}\")\n        Helper.backticks(\"xcrun instruments -w #{device_udid} &> /dev/null\")\n\n        paths.each do |path|\n          UI.message(\"Adding '#{path}'\")\n\n          # Attempting addmedia since addphoto and addvideo are deprecated\n          output = Helper.backticks(\"xcrun simctl addmedia #{device_udid} #{path.shellescape} &> /dev/null\")\n\n          # Run legacy addphoto and addvideo if addmedia isn't found\n          # Output will be empty strin gif it was a success\n          # Output will contain \"usage: simctl\" if command not found\n          if output.include?('usage: simctl')\n            Helper.backticks(\"xcrun simctl add#{media_type} #{device_udid} #{path.shellescape} &> /dev/null\")\n          end\n        end\n      end\n    end", "label": 4}
{"code": "public function action_setup_theme_wp_cli_skip_themes() {\n\t\t$wp_cli_filter_active_theme = function( $value ) {\n\t\t\t$skipped_themes = WP_CLI::get_runner()->config['skip-themes'];\n\t\t\tif ( true === $skipped_themes ) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\tif ( ! is_array( $skipped_themes ) ) {\n\t\t\t\t$skipped_themes = explode( ',', $skipped_themes );\n\t\t\t}\n\n\t\t\t$checked_value = $value;\n\t\t\t// Always check against the stylesheet value\n\t\t\t// This ensures a child theme can be skipped when template differs\n\t\t\tif ( false !== stripos( current_filter(), 'option_template' ) ) {\n\t\t\t\t$checked_value = get_option( 'stylesheet' );\n\t\t\t}\n\n\t\t\tif ( '' === $checked_value || in_array( $checked_value, $skipped_themes, true ) ) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\treturn $value;\n\t\t};\n\t\t$hooks                      = array(\n\t\t\t'pre_option_template',\n\t\t\t'option_template',\n\t\t\t'pre_option_stylesheet',\n\t\t\t'option_stylesheet',\n\t\t);\n\t\tforeach ( $hooks as $hook ) {\n\t\t\tadd_filter( $hook, $wp_cli_filter_active_theme, 999 );\n\t\t}\n\t\t// Clean up after the TEMPLATEPATH and STYLESHEETPATH constants are defined\n\t\tWP_CLI::add_wp_hook(\n\t\t\t'after_setup_theme',\n\t\t\tfunction() use ( $hooks, $wp_cli_filter_active_theme ) {\n\t\t\t\tforeach ( $hooks as $hook ) {\n\t\t\t\t\tremove_filter( $hook, $wp_cli_filter_active_theme, 999 );\n\t\t\t\t}\n\t\t\t},\n\t\t\t0\n\t\t);\n\t}", "label": 2}
{"code": "function _processExportResponse(csvs, res, next) {\n  var zip = archiver('zip');\n\n  // convert csv entries to in-memory zip file and stream response\n  res.setHeader('Content-type', 'application/zip');\n  res.setHeader('Content-disposition', 'attachment; filename=submissions.zip');\n  zip.pipe(res);\n\n  for (var form in csvs) { // eslint-disable-line guard-for-in\n    var csv = csvs[form];\n    zip.append(csv, {name: form + '.csv'});\n  }\n\n  var respSent = false;\n  zip.on('error', function(err) {\n    logger.error(\"_processExportResponse \", {error: err});\n    if (err) {\n      if (!respSent) {\n        respSent = true;\n        return next(err);\n      }\n    }\n  });\n\n  zip.finalize(function(err) {\n    if (err) {\n      logger.error(\"_processExportResponse finalize\", {error: err});\n      if (!respSent) {\n        respSent = true;\n        return next(err);\n      }\n\n      logger.debug(\"_processExportResponse finalize headers sent\");\n    }\n\n    logger.debug(\"_processExportResponse finalize finished\");\n  });\n}", "label": 3}
{"code": "public static dnscnamerec get(nitro_service service, String aliasname) throws Exception{\n\t\tdnscnamerec obj = new dnscnamerec();\n\t\tobj.set_aliasname(aliasname);\n\t\tdnscnamerec response = (dnscnamerec) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function loadWithCallback (options, callback) {\n  const endpoint = options.endpoint ? URL.parse(options.endpoint) : DEFAULT_URL\n  const name = options.name || options.application\n  const context = options.context\n  const client = endpoint.protocol === 'https:' ? https : http\n\n  client.request({\n    protocol: endpoint.protocol,\n    hostname: endpoint.hostname,\n    port: endpoint.port,\n    path: getPath(endpoint.path, name, options.profiles, options.label),\n    auth: getAuth(options.auth, endpoint),\n    rejectUnauthorized: options.rejectUnauthorized !== false,\n    agent: options.agent\n  }, (res) => {\n    if (res.statusCode !== 200) { // OK\n      res.resume() // it consumes response\n      return callback(new Error('Invalid response: ' + res.statusCode))\n    }\n    let response = ''\n    res.setEncoding('utf8')\n    res.on('data', (data) => {\n      response += data\n    })\n    res.on('end', () => {\n      try {\n        const body = JSON.parse(response)\n        callback(null, new Config(body, context))\n      } catch (e) {\n        callback(e)\n      }\n    })\n  }).on('error', callback).end()\n}", "label": 3}
{"code": "private String parseLayerId(HttpServletRequest request) {\n\t\tStringTokenizer tokenizer = new StringTokenizer(request.getRequestURI(), \"/\");\n\t\tString token = \"\";\n\t\twhile (tokenizer.hasMoreTokens()) {\n\t\t\ttoken = tokenizer.nextToken();\n\t\t}\n\t\treturn token;\n\t}", "label": 0}
{"code": "func (ap *AuthPermission) Delete(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !ap._exists {\n\t\treturn nil\n\t}\n\n\t// if deleted, bail\n\tif ap._deleted {\n\t\treturn nil\n\t}\n\n\t// sql query\n\tconst sqlstr = `DELETE FROM auth_permission WHERE id = ?`\n\n\t// run query\n\tXOLog(sqlstr, ap.ID)\n\t_, err = db.Exec(sqlstr, ap.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// set deleted\n\tap._deleted = true\n\n\treturn nil\n}", "label": 5}
{"code": "def find_or_create_provider_intent(link_provider:, link_original_name:, link_type:)\n      intent = Bosh::Director::Models::Links::LinkProviderIntent.find(\n        link_provider: link_provider,\n        original_name: link_original_name,\n      )\n\n      if intent.nil?\n        intent = Bosh::Director::Models::Links::LinkProviderIntent.create(\n          link_provider: link_provider,\n          original_name: link_original_name,\n          type: link_type,\n        )\n      else\n        intent.type = link_type\n      end\n\n      intent.serial_id = @serial_id if intent.serial_id != @serial_id\n      intent.save\n    end", "label": 4}
{"code": "def replace_one(filter, replacement, options = {})\n      find(filter, options).replace_one(replacement, options)\n    end", "label": 4}
{"code": "def emit(signal, *args, **kwargs):\n    \"\"\"Emit a signal by serially calling each registered signal receiver for\n    the `signal`.\n\n    Note:\n        The receiver must accept the *args and/or **kwargs that have been\n        passed to it. There expected parameters are not dictated by\n        mixbox.\n        \n    Args:\n        signal: A signal identifier or name.\n        *args: A variable-length argument list to pass to the receiver.\n        **kwargs: Keyword-arguments to pass to the receiver.\n    \"\"\"\n    if signal not in __receivers:\n        return\n\n    receivers = __live_receivers(signal)\n\n    for func in receivers:\n        func(*args, **kwargs)", "label": 1}
{"code": "public static policymap[] get(nitro_service service, String mappolicyname[]) throws Exception{\n\t\tif (mappolicyname !=null && mappolicyname.length>0) {\n\t\t\tpolicymap response[] = new policymap[mappolicyname.length];\n\t\t\tpolicymap obj[] = new policymap[mappolicyname.length];\n\t\t\tfor (int i=0;i<mappolicyname.length;i++) {\n\t\t\t\tobj[i] = new policymap();\n\t\t\t\tobj[i].set_mappolicyname(mappolicyname[i]);\n\t\t\t\tresponse[i] = (policymap) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def gid\n      URI::GID.build(app: GlobalID.app, model_name: model_name.name.parameterize.to_sym, model_id: id).to_s if id\n    end", "label": 4}
{"code": "func removeCurrentIfEmpty(head **sequence, previous, current *sequence) {\n\tif current.count == 0 {\n\t\tif current == *head {\n\t\t\t*head = current.next\n\t\t} else {\n\t\t\tprevious.next = current.next\n\t\t\tcurrent = current.next\n\t\t}\n\t}\n}", "label": 5}
{"code": "function tryFile(fileName, failedLookupLocation, onlyRecordFailures, state) {\n        if (!onlyRecordFailures && state.host.fileExists(fileName)) {\n            if (state.traceEnabled) {\n                ts.trace(state.host, ts.Diagnostics.File_0_exist_use_it_as_a_name_resolution_result, fileName);\n            }\n            return fileName;\n        }\n        else {\n            if (state.traceEnabled) {\n                ts.trace(state.host, ts.Diagnostics.File_0_does_not_exist, fileName);\n            }\n            failedLookupLocation.push(fileName);\n            return undefined;\n        }\n    }", "label": 3}
{"code": "func (l *ConnectionsLimiter) AcquireConnection(token string) error {\n\tl.Lock()\n\tdefer l.Unlock()\n\n\tif l.maxConnections == 0 {\n\t\treturn nil\n\t}\n\n\tnumberOfConnections, exists := l.connections[token]\n\tif !exists {\n\t\tl.connections[token] = 1\n\t\treturn nil\n\t}\n\tif numberOfConnections >= l.maxConnections {\n\t\treturn trace.LimitExceeded(\n\t\t\t\"too many connections from %v: %v, max is %v\",\n\t\t\ttoken, numberOfConnections, l.maxConnections)\n\t}\n\tl.connections[token] = numberOfConnections + 1\n\treturn nil\n}", "label": 5}
{"code": "public static function fromXml($xml): array\n    {\n        if (!$xml) {\n            throw new InvalidArgumentException('Convert To Array Error! Invalid Xml!');\n        }\n\n        libxml_disable_entity_loader(true);\n\n        return json_decode(json_encode(simplexml_load_string($xml, 'SimpleXMLElement', LIBXML_NOCDATA), JSON_UNESCAPED_UNICODE), true);\n    }", "label": 2}
{"code": "func (c *GithubConnectorV3) SetTTL(clock clockwork.Clock, ttl time.Duration) {\n\tc.Metadata.SetTTL(clock, ttl)\n}", "label": 5}
{"code": "public function read_longlong()\n    {\n        $this->bitcount = $this->bits = 0;\n\n        list(, $hi, $lo) = unpack('N2', $this->rawread(8));\n        $msb = self::getLongMSB($hi);\n\n        if (empty($this->is64bits)) {\n            if ($msb) {\n                $hi = sprintf('%u', $hi);\n            }\n            if (self::getLongMSB($lo)) {\n                $lo = sprintf('%u', $lo);\n            }\n        }\n\n        return bcadd($this->is64bits && !$msb ? $hi << 32 : bcmul($hi, '4294967296', 0), $lo, 0);\n    }", "label": 2}
{"code": "def capability(cap_name, *args)\n      cap_mod = capability_module(cap_name.to_sym)\n      if !cap_mod\n        raise Errors::CapabilityNotFound,\n          cap:  cap_name.to_s,\n          host: @cap_host_chain[0][0].to_s\n      end\n\n      cap_method = nil\n      begin\n        cap_method = cap_mod.method(cap_name)\n      rescue NameError\n        raise Errors::CapabilityInvalid,\n          cap: cap_name.to_s,\n          host: @cap_host_chain[0][0].to_s\n      end\n\n      args = @cap_args + args\n      @cap_logger.info(\n        \"Execute capability: #{cap_name} #{args.inspect} (#{@cap_host_chain[0][0]})\")\n      cap_method.call(*args)\n    end", "label": 4}
{"code": "func (l VirtualDeviceList) DisconnectSerialPort(device *types.VirtualSerialPort) *types.VirtualSerialPort {\n\tl.setDefaultSerialPortBacking(device)\n\treturn device\n}", "label": 5}
{"code": "func (fs *FSLocalKeyStore) DeleteKeys() error {\n\tdirPath := filepath.Join(fs.KeyDir, sessionKeyDir)\n\n\terr := os.RemoveAll(dirPath)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def write(self, message, autoerase=True):\n        \"\"\"Send something for stdout and erased after delay\"\"\"\n        super(Animation, self).write(message)\n        self.last_message = message\n        if autoerase:\n            time.sleep(self.interval)\n            self.erase(message)", "label": 1}
{"code": "function normalizeArrayOptions (cell, cellDefinitions) {\n  const arrayOptions = _.clone(cell.arrayOptions)\n  if (arrayOptions.itemCell) {\n    if (Array.isArray(arrayOptions.itemCell)) {\n      arrayOptions.itemCell = arrayOptions.itemCell.map(cell => normalizeCell(cell, cellDefinitions))\n    } else {\n      arrayOptions.itemCell = normalizeCell(arrayOptions.itemCell, cellDefinitions)\n    }\n  }\n  if (arrayOptions.tupleCells) {\n    arrayOptions.tupleCells = arrayOptions.tupleCells.map(cell => normalizeCell(cell, cellDefinitions))\n  }\n  return arrayOptions\n}", "label": 3}
{"code": "public function set(array $fields, array $options = [])\n    {\n        return $this->writeResult(\n            $this->batchFactory()\n                ->set($this->name, $fields, $options)\n                ->commit($options)\n        );\n    }", "label": 2}
{"code": "def write_outfile(method_name, file)\n      schema = @load_schema.call(self)\n      context = @load_context.call(self)\n      result = schema.public_send(method_name, only: @only, except: @except, context: context)\n      dir = File.dirname(file)\n      FileUtils.mkdir_p(dir)\n      File.write(file, result)\n    end", "label": 4}
{"code": "def _get_default_projection(cls):\n\t\t\"\"\"Construct the default projection document.\"\"\"\n\t\t\n\t\tprojected = []  # The fields explicitly requested for inclusion.\n\t\tneutral = []  # Fields returning neutral (None) status.\n\t\tomitted = False  # Have any fields been explicitly omitted?\n\t\t\n\t\tfor name, field in cls.__fields__.items():\n\t\t\tif field.project is None:\n\t\t\t\tneutral.append(name)\n\t\t\telif field.project:\n\t\t\t\tprojected.append(name)\n\t\t\telse:\n\t\t\t\tomitted = True\n\t\t\n\t\tif not projected and not omitted:\n\t\t\t# No preferences specified.\n\t\t\treturn None\n\t\t\t\n\t\telif not projected and omitted:\n\t\t\t# No positive inclusions given, but negative ones were.\n\t\t\tprojected = neutral\n\t\t\n\t\treturn {field: True for field in projected}", "label": 1}
{"code": "public static <T extends Annotation> List<T> searchForAnnotation(Method method, Class<T> annotation) {\n        if (method == null) {\n            return Lists.newArrayList();\n        }\n        return searchClasses(method, annotation, method.getDeclaringClass());\n    }", "label": 0}
{"code": "func (c *Client) KeepAliveNode(ctx context.Context, keepAlive services.KeepAlive) error {\n\treturn trace.BadParameter(\"not implemented, use StreamKeepAlives instead\")\n}", "label": 5}
{"code": "public function sendGetPrivacyBlockedList()\n    {\n        $msgId = $this->nodeId['privacy'] = $this->createIqId();\n        $child = new ProtocolNode('list',\n            [\n                'name' => 'default',\n            ], null, null);\n\n        $child2 = new ProtocolNode('query', [], [$child], null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'jabber:iq:privacy',\n                'type'  => 'get',\n            ], [$child2], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "public function checkPassword($password)\n    {\n        $valid = static::$dispatcher->until(new CheckingPassword($this, $password));\n\n        if ($valid !== null) {\n            return $valid;\n        }\n\n        return static::$hasher->check($password, $this->password);\n    }", "label": 2}
{"code": "func CreateEllipticCertificate(principal string, certType uint32) (*ssh.Certificate, ssh.Signer, error) {\n\t// Create ECDSA key for CA and certificate to be signed by CA.\n\tcaKey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\tkey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\tcert, certSigner, err := createCertificate(principal, certType, caKey, key)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\treturn cert, certSigner, nil\n}", "label": 5}
{"code": "def read_json_string(skipContext = false)\n      # This string's characters must match up with the elements in escape_char_vals.\n      # I don't have '/' on this list even though it appears on www.json.org --\n      # it is not in the RFC -> it is. See RFC 4627\n      escape_chars = \"\\\"\\\\/bfnrt\"\n\n      # The elements of this array must match up with the sequence of characters in\n      # escape_chars\n      escape_char_vals = [\n        \"\\\"\", \"\\\\\", \"\\/\", \"\\b\", \"\\f\", \"\\n\", \"\\r\", \"\\t\",\n      ]\n\n      if !skipContext\n        @context.read(@reader)\n      end\n      read_json_syntax_char(@@kJSONStringDelimiter)\n      ch = \"\"\n      str = \"\"\n      while (true)\n        ch = @reader.read\n        if (ch == @@kJSONStringDelimiter)\n          break\n        end\n        if (ch == @@kJSONBackslash)\n          ch = @reader.read\n          if (ch == 'u')\n            ch = read_json_escape_char\n          else\n            pos = escape_chars.index(ch);\n            if (pos.nil?) # not found\n              raise ProtocolException.new(ProtocolException::INVALID_DATA, \"Expected control char, got \\'#{ch}\\'.\")\n            end\n            ch = escape_char_vals[pos]\n          end\n        end\n        str += ch\n      end\n      return str\n    end", "label": 4}
{"code": "function getAuthenticationObject () {\n    const authString = url.parse(parts[0]).auth;\n\n    if (authString) {\n      return {\n        source: getName(),\n        user: authString.split(':')[0],\n        pass: authString.split(':')[1]\n      };\n    } else {\n      return {};\n    }\n  }", "label": 3}
{"code": "public function setDegreeType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\DegreeType::class);\n        $this->degree_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function relinkUniforms(gl, program, locations, uniforms) {\n  for(var i=0; i<uniforms.length; ++i) {\n    locations[i] = gl.getUniformLocation(program, uniforms[i].name)\n  }\n}", "label": 3}
{"code": "function list(req, res, next) {\n  var notStats = req.query && (req.query.notStats === 'true' || req.query.notStats === true);\n  var opts = _.extend(req.connectionOptions, { notStats: notStats });\n\n  logger.debug(\"List Forms Middleware \", opts);\n  forms.getAllForms(opts, formsResultHandlers(constants.resultTypes.forms, req, next));\n}", "label": 3}
{"code": "func protocolVersion(opts *ServeConfig) (int, Protocol, PluginSet) {\n\tprotoVersion := int(opts.ProtocolVersion)\n\tpluginSet := opts.Plugins\n\tprotoType := ProtocolNetRPC\n\t// Check if the client sent a list of acceptable versions\n\tvar clientVersions []int\n\tif vs := os.Getenv(\"PLUGIN_PROTOCOL_VERSIONS\"); vs != \"\" {\n\t\tfor _, s := range strings.Split(vs, \",\") {\n\t\t\tv, err := strconv.Atoi(s)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"server sent invalid plugin version %q\", s)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tclientVersions = append(clientVersions, v)\n\t\t}\n\t}\n\n\t// We want to iterate in reverse order, to ensure we match the newest\n\t// compatible plugin version.\n\tsort.Sort(sort.Reverse(sort.IntSlice(clientVersions)))\n\n\t// set the old un-versioned fields as if they were versioned plugins\n\tif opts.VersionedPlugins == nil {\n\t\topts.VersionedPlugins = make(map[int]PluginSet)\n\t}\n\n\tif pluginSet != nil {\n\t\topts.VersionedPlugins[protoVersion] = pluginSet\n\t}\n\n\t// Sort the version to make sure we match the latest first\n\tvar versions []int\n\tfor v := range opts.VersionedPlugins {\n\t\tversions = append(versions, v)\n\t}\n\n\tsort.Sort(sort.Reverse(sort.IntSlice(versions)))\n\n\t// See if we have multiple versions of Plugins to choose from\n\tfor _, version := range versions {\n\t\t// Record each version, since we guarantee that this returns valid\n\t\t// values even if they are not a protocol match.\n\t\tprotoVersion = version\n\t\tpluginSet = opts.VersionedPlugins[version]\n\n\t\t// If we have a configured gRPC server we should select a protocol\n\t\tif opts.GRPCServer != nil {\n\t\t\t// All plugins in a set must use the same transport, so check the first\n\t\t\t// for the protocol type\n\t\t\tfor _, p := range pluginSet {\n\t\t\t\tswitch p.(type) {\n\t\t\t\tcase GRPCPlugin:\n\t\t\t\t\tprotoType = ProtocolGRPC\n\t\t\t\tdefault:\n\t\t\t\t\tprotoType = ProtocolNetRPC\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tfor _, clientVersion := range clientVersions {\n\t\t\tif clientVersion == protoVersion {\n\t\t\t\treturn protoVersion, protoType, pluginSet\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return the lowest version as the fallback.\n\t// Since we iterated over all the versions in reverse order above, these\n\t// values are from the lowest version number plugins (which may be from\n\t// a combination of the Handshake.ProtocolVersion and ServeConfig.Plugins\n\t// fields). This allows serving the oldest version of our plugins to a\n\t// legacy client that did not send a PLUGIN_PROTOCOL_VERSIONS list.\n\treturn protoVersion, protoType, pluginSet\n}", "label": 5}
{"code": "func isMAC(fl FieldLevel) bool {\n\n\t_, err := net.ParseMAC(fl.Field().String())\n\n\treturn err == nil\n}", "label": 5}
{"code": "public static List<Integer> toIntegerList(List<String> strList, boolean failOnException){\n\t\tList<Integer> intList = new ArrayList<Integer>();\n\t\tfor(String str : strList){\n\t\t\ttry{\n\t\t\t\tintList.add(Integer.parseInt(str));\n\t\t\t}\n\t\t\tcatch(NumberFormatException nfe){\n\t\t\t\tif(failOnException){\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t\telse{\n\t\t\t\t\tintList.add(null);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn intList;\n\t}", "label": 0}
{"code": "def occurs_on?(date)\n      date = TimeUtil.ensure_date(date)\n      begin_time = TimeUtil.beginning_of_date(date, start_time)\n      closing_time = TimeUtil.end_of_date(date, start_time)\n      occurs_between?(begin_time, closing_time)\n    end", "label": 4}
{"code": "public function instance($name, array $instance = [])\n    {\n        return new Instance(\n            $this->connection,\n            $this->lroConnection,\n            $this->lroCallables,\n            $this->projectId,\n            $name,\n            $this->returnInt64AsObject,\n            $instance\n        );\n    }", "label": 2}
{"code": "def signup_handler(remote, *args, **kwargs):\n    \"\"\"Handle extra signup information.\n\n    :param remote: The remote application.\n    :returns: Redirect response or the template rendered.\n    \"\"\"\n    # User already authenticated so move on\n    if current_user.is_authenticated:\n        return redirect('/')\n\n    # Retrieve token from session\n    oauth_token = token_getter(remote)\n    if not oauth_token:\n        return redirect('/')\n\n    session_prefix = token_session_key(remote.name)\n\n    # Test to see if this is coming from on authorized request\n    if not session.get(session_prefix + '_autoregister', False):\n        return redirect(url_for('.login', remote_app=remote.name))\n\n    form = create_registrationform(request.form)\n\n    if form.validate_on_submit():\n        account_info = session.get(session_prefix + '_account_info')\n        response = session.get(session_prefix + '_response')\n\n        # Register user\n        user = oauth_register(form)\n\n        if user is None:\n            raise OAuthError('Could not create user.', remote)\n\n        # Remove session key\n        session.pop(session_prefix + '_autoregister', None)\n\n        # Link account and set session data\n        token = token_setter(remote, oauth_token[0], secret=oauth_token[1],\n                             user=user)\n        handlers = current_oauthclient.signup_handlers[remote.name]\n\n        if token is None:\n            raise OAuthError('Could not create token for user.', remote)\n\n        if not token.remote_account.extra_data:\n            account_setup = handlers['setup'](token, response)\n            account_setup_received.send(\n                remote, token=token, response=response,\n                account_setup=account_setup\n            )\n            # Registration has been finished\n            db.session.commit()\n            account_setup_committed.send(remote, token=token)\n        else:\n            # Registration has been finished\n            db.session.commit()\n\n        # Authenticate the user\n        if not oauth_authenticate(remote.consumer_key, user,\n                                  require_existing_link=False):\n            # Redirect the user after registration (which doesn't include the\n            # activation), waiting for user to confirm his email.\n            return redirect(url_for('security.login'))\n\n        # Remove account info from session\n        session.pop(session_prefix + '_account_info', None)\n        session.pop(session_prefix + '_response', None)\n\n        # Redirect to next\n        next_url = get_session_next_url(remote.name)\n        if next_url:\n            return redirect(next_url)\n        else:\n            return redirect('/')\n\n    # Pre-fill form\n    account_info = session.get(session_prefix + '_account_info')\n    if not form.is_submitted():\n        form = fill_form(form, account_info['user'])\n\n    return render_template(\n        current_app.config['OAUTHCLIENT_SIGNUP_TEMPLATE'],\n        form=form,\n        remote=remote,\n        app_title=current_app.config['OAUTHCLIENT_REMOTE_APPS'][\n            remote.name].get('title', ''),\n        app_description=current_app.config['OAUTHCLIENT_REMOTE_APPS'][\n            remote.name].get('description', ''),\n        app_icon=current_app.config['OAUTHCLIENT_REMOTE_APPS'][\n            remote.name].get('icon', None),\n    )", "label": 1}
{"code": "def next_occurrences(num, from = nil, options = {})\n      from = TimeUtil.match_zone(from, start_time) || TimeUtil.now(start_time)\n      enumerate_occurrences(from + 1, nil, options).take(num)\n    end", "label": 4}
{"code": "func PgGetColOrder(db XODB, schema string, index string) (*PgColOrder, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`i.indkey ` + // ::varchar AS ord\n\t\t`FROM pg_index i ` +\n\t\t`JOIN ONLY pg_class c ON c.oid = i.indrelid ` +\n\t\t`JOIN ONLY pg_namespace n ON n.oid = c.relnamespace ` +\n\t\t`JOIN ONLY pg_class ic ON ic.oid = i.indexrelid ` +\n\t\t`WHERE n.nspname = $1 AND ic.relname = $2`\n\n\t// run query\n\tXOLog(sqlstr, schema, index)\n\tvar pco PgColOrder\n\terr = db.QueryRow(sqlstr, schema, index).Scan(&pco.Ord)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pco, nil\n}", "label": 5}
{"code": "protected function discoverFromMaster(NodeConnectionInterface $connection, FactoryInterface $connectionFactory)\n    {\n        $response = $connection->executeCommand(RawCommand::create('INFO', 'REPLICATION'));\n        $replication = $this->handleInfoResponse($response);\n\n        if ($replication['role'] !== 'master') {\n            throw new ClientException(\"Role mismatch (expected master, got slave) [$connection]\");\n        }\n\n        $this->slaves = array();\n\n        foreach ($replication as $k => $v) {\n            $parameters = null;\n\n            if (strpos($k, 'slave') === 0 && preg_match('/ip=(?P<host>.*),port=(?P<port>\\d+)/', $v, $parameters)) {\n                $slaveConnection = $connectionFactory->create(array(\n                    'host' => $parameters['host'],\n                    'port' => $parameters['port'],\n                ));\n\n                $this->add($slaveConnection);\n            }\n        }\n    }", "label": 2}
{"code": "func GetAuthPreferenceSchema(extensionSchema string) string {\n\tvar authPreferenceSchema string\n\tif authPreferenceSchema == \"\" {\n\t\tauthPreferenceSchema = fmt.Sprintf(AuthPreferenceSpecSchemaTemplate, \"\")\n\t} else {\n\t\tauthPreferenceSchema = fmt.Sprintf(AuthPreferenceSpecSchemaTemplate, \",\"+extensionSchema)\n\t}\n\treturn fmt.Sprintf(V2SchemaTemplate, MetadataSchema, authPreferenceSchema, DefaultDefinitions)\n}", "label": 5}
{"code": "def save_excursion\n      old_point = new_mark\n      old_mark = @mark&.dup\n      old_column = @goal_column\n      begin\n        yield\n      ensure\n        point_to_mark(old_point)\n        old_point.delete\n        if old_mark\n          @mark.location = old_mark.location\n          old_mark.delete\n        end\n        @goal_column = old_column\n      end\n    end", "label": 4}
{"code": "public function setLogLevel($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Debugger\\V2\\Breakpoint_LogLevel::class);\n        $this->log_level = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func InitCLIParser(appName, appHelp string) (app *kingpin.Application) {\n\tapp = kingpin.New(appName, appHelp)\n\n\t// hide \"--help\" flag\n\tapp.HelpFlag.Hidden()\n\tapp.HelpFlag.NoEnvar()\n\n\t// set our own help template\n\treturn app.UsageTemplate(defaultUsageTemplate)\n}", "label": 5}
{"code": "def decode(s)\n    ts = lex(s)\n    v, ts = textparse(ts)\n    if ts.length > 0\n      raise Error, 'trailing garbage'\n    end\n    v\n  end", "label": 4}
{"code": "function applyListeners(emitter, listeners) {\n    Object.keys(listeners).forEach(function(name) {\n      emitter.addEventListener(name, listeners[name]);\n    });\n  }", "label": 3}
{"code": "func (a *Allocator) ReleaseAddress(poolID string, address net.IP) error {\n\tlogrus.Debugf(\"ReleaseAddress(%s, %v)\", poolID, address)\n\tk := SubnetKey{}\n\tif err := k.FromString(poolID); err != nil {\n\t\treturn types.BadRequestErrorf(\"invalid pool id: %s\", poolID)\n\t}\n\n\tif err := a.refresh(k.AddressSpace); err != nil {\n\t\treturn err\n\t}\n\n\taSpace, err := a.getAddrSpace(k.AddressSpace)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\taSpace.Lock()\n\tp, ok := aSpace.subnets[k]\n\tif !ok {\n\t\taSpace.Unlock()\n\t\treturn types.NotFoundErrorf(\"cannot find address pool for poolID:%s\", poolID)\n\t}\n\n\tif address == nil {\n\t\taSpace.Unlock()\n\t\treturn types.BadRequestErrorf(\"invalid address: nil\")\n\t}\n\n\tif !p.Pool.Contains(address) {\n\t\taSpace.Unlock()\n\t\treturn ipamapi.ErrIPOutOfRange\n\t}\n\n\tc := p\n\tfor c.Range != nil {\n\t\tk = c.ParentKey\n\t\tc = aSpace.subnets[k]\n\t}\n\taSpace.Unlock()\n\n\tmask := p.Pool.Mask\n\n\th, err := types.GetHostPartIP(address, mask)\n\tif err != nil {\n\t\treturn types.InternalErrorf(\"failed to release address %s: %v\", address.String(), err)\n\t}\n\n\tbm, err := a.retrieveBitmask(k, c.Pool)\n\tif err != nil {\n\t\treturn types.InternalErrorf(\"could not find bitmask in datastore for %s on address %v release from pool %s: %v\",\n\t\t\tk.String(), address, poolID, err)\n\t}\n\tdefer logrus.Debugf(\"Released address PoolID:%s, Address:%v Sequence:%s\", poolID, address, bm.String())\n\n\treturn bm.Unset(ipToUint64(h))\n}", "label": 5}
{"code": "def remove_number_words(text_string):\n    '''\n    Removes any integer represented as a word within text_string and returns the new string as\n    type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a non-string argument be passed\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        for word in NUMBER_WORDS:\n            text_string = re.sub(r'[\\S]*\\b'+word+r'[\\S]*', \"\", text_string)\n        return \" \".join(text_string.split())\n    else:\n        raise InputError(\"string not passed as argument\")", "label": 1}
{"code": "function () {\n\t\t\tif (queue.length > 0) {\n\t\t\t\tif (queue.length % 500 === 0)\n\t\t\t\t\tLOG.warn('socketio queue: ' + queue.length);\n\t\t\t\t\n\t\t\t\tvar item = queue.shift();\n\t\t\t\tsocket.busy = true;\n\t\t\t\tsocket.emit('SRR', item);\n\t\t\t}\n\t\t}", "label": 3}
{"code": "def _read_fasta(fasta_file, output_dict):\n    \"\"\"\n    Read the peptide fasta into an existing dict.\n\n    :param str fasta_file: The peptide file\n    :param dict output_dict: The dict to appends results to.\n    :return: output_dict\n    :rtype: dict\n    \"\"\"\n    read_name = None\n    with open(fasta_file, 'r') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            if line.startswith('>'):\n                read_name = line.lstrip('>')\n            else:\n                assert read_name is not None, line\n                output_dict[read_name].append(line.strip())\n    return output_dict", "label": 1}
{"code": "func NewAddrDialer(addrs []utils.NetAddr) DialContext {\n\tdialer := net.Dialer{\n\t\tTimeout:   defaults.DefaultDialTimeout,\n\t\tKeepAlive: defaults.ReverseTunnelAgentHeartbeatPeriod,\n\t}\n\treturn func(in context.Context, network, _ string) (net.Conn, error) {\n\t\tvar err error\n\t\tvar conn net.Conn\n\t\tfor _, addr := range addrs {\n\t\t\tconn, err = dialer.DialContext(in, network, addr.Addr)\n\t\t\tif err == nil {\n\t\t\t\treturn conn, nil\n\t\t\t}\n\t\t\tlog.Errorf(\"Failed to dial auth server %v: %v.\", addr.Addr, err)\n\t\t}\n\t\t// not wrapping on purpose to preserve the original error\n\t\treturn nil, err\n\t}\n}", "label": 5}
{"code": "func setIPVlanMode(mode string) (netlink.IPVlanMode, error) {\n\tswitch mode {\n\tcase modeL2:\n\t\treturn netlink.IPVLAN_MODE_L2, nil\n\tcase modeL3:\n\t\treturn netlink.IPVLAN_MODE_L3, nil\n\tdefault:\n\t\treturn 0, fmt.Errorf(\"Unknown ipvlan mode: %s\", mode)\n\t}\n}", "label": 5}
{"code": "public function setInspectConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\InspectConfig::class);\n        $this->inspect_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func OptionOriginHostsPath(path string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.originHostsPath = path\n\t}\n}", "label": 5}
{"code": "def ap_debug(object, options = {})\n      object.ai(\n        options.merge(html: true)\n      ).sub(\n        /^<pre([\\s>])/,\n        '<pre class=\"debug_dump\"\\\\1'\n      )\n    end", "label": 4}
{"code": "func NewOIDCConnector(name string, spec OIDCConnectorSpecV2) OIDCConnector {\n\treturn &OIDCConnectorV2{\n\t\tKind:    KindOIDCConnector,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName:      name,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: spec,\n\t}\n}", "label": 5}
{"code": "function (chords, settings) {\n  var events = _.reduce(chords, function (arr, obj) {\n    var time = noteLength(obj.duration, settings);\n    var chord = obj.chord.inOctave(settings.chordOctave).chord;\n\n    arr.push(makeChordEvent(0, true, 1, chord, settings.chordVelocity)); // On\n    arr.push(makeChordEvent(time, false, 1, chord, settings.chordVelocity)); // Off\n\n    return arr;\n  }, []);\n\n  return Buffer.concat(events);\n}", "label": 3}
{"code": "def const_regexp(camel_cased_word)\n        parts = camel_cased_word.split(\"::\")\n\n        return Regexp.escape(camel_cased_word) if parts.blank?\n\n        last = parts.pop\n\n        parts.reverse.inject(last) do |acc, part|\n          part.empty? ? acc : \"#{part}(::#{acc})?\"\n        end\n      end", "label": 4}
{"code": "def create_with_role(name, options = {})\n      headers = extract_headers!(options)\n      json = client.post(\"/v1/auth/token/create/#{encode_path(name)}\", JSON.fast_generate(options), headers)\n      return Secret.decode(json)\n    end", "label": 4}
{"code": "public static lbvserver_rewritepolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_rewritepolicy_binding obj = new lbvserver_rewritepolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_rewritepolicy_binding response[] = (lbvserver_rewritepolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function delete($table, KeySet $keySet, array $options = [])\n    {\n        $mutations = [$this->operation->deleteMutation($table, $keySet)];\n\n        return $this->commitInSingleUseTransaction($mutations, $options);\n    }", "label": 2}
{"code": "def track!(date)\n      @subject.with_lock do\n        last_session_at = status.try(:last_session_at) || date\n        current_streak = status.try(:current_streak) || 1\n\n        streak = if last_session_at == date\n                   current_streak\n                 elsif last_session_at == date - 1.day\n                   current_streak + 1\n                 else\n                   1\n                 end\n\n        update_status(date, streak)\n        update_badge(streak)\n      end\n    end", "label": 4}
{"code": "def apply_cli_options\n      config[:cli_options].each do |k, v|\n        setting = config.setting(k.to_sym)\n        next unless setting\n\n        v = setting.options[:import].call(v) if setting.options[:import]\n\n        config[k.to_sym] = v\n      end\n    end", "label": 4}
{"code": "def racc_read_token(t, tok, val)\n      @racc_debug_out.print 'read    '\n      @racc_debug_out.print tok.inspect, '(', racc_token2str(t), ') '\n      @racc_debug_out.puts val.inspect\n      @racc_debug_out.puts\n    end", "label": 4}
{"code": "public function failInitialization(string $message, ?\\Throwable $error = null): void\n    {\n        // Log the exception in CloudWatch\n        echo \"$message\\n\";\n        if ($error) {\n            if ($error instanceof \\Exception) {\n                $errorMessage = get_class($error) . ': ' . $error->getMessage();\n            } else {\n                $errorMessage = $error->getMessage();\n            }\n            printf(\n                \"Fatal error: %s in %s:%d\\nStack trace:\\n%s\",\n                $errorMessage,\n                $error->getFile(),\n                $error->getLine(),\n                $error->getTraceAsString()\n            );\n        }\n\n        $url = \"http://{$this->apiUrl}/2018-06-01/runtime/init/error\";\n        $this->postJson($url, [\n            'errorMessage' => $message . ' ' . ($error ? $error->getMessage() : ''),\n            'errorType' => $error ? get_class($error) : 'Internal',\n            'stackTrace' => $error ? explode(PHP_EOL, $error->getTraceAsString()) : [],\n        ]);\n\n        exit(1);\n    }", "label": 2}
{"code": "public static java.sql.Date toDate(Object value) throws ParseException {\n        if (value == null) {\n            return null;\n        }\n        if (value instanceof java.sql.Date) {\n            return (java.sql.Date) value;\n        }\n        if (value instanceof String) {\n            if (\"\".equals((String) value)) {\n                return null;\n            }\n            return new java.sql.Date(IN_DATE_FORMAT.parse((String) value).getTime());\n        }\n\n        return new java.sql.Date(IN_DATE_FORMAT.parse(value.toString()).getTime());\n    }", "label": 0}
{"code": "def handle_stratifications(population_def, number_of_populations, population, id_def, population_index)\n      # handle stratifications (EP137, EP155)\n      stratifier_criteria_xpath = \"cda:component/cda:stratifierCriteria[not(cda:component/cda:measureAttribute/cda:code[@code  = 'SDE'])]/..\"\n      population_def.xpath(stratifier_criteria_xpath, HQMF2::Document::NAMESPACES)\n        .each_with_index do |criteria_def, criteria_def_index|\n        # Skip this Stratification if any precondition doesn't contain any preconditions\n        next unless PopulationCriteria.new(criteria_def, @document, @id_generator)\n                    .preconditions.all? { |prcn| prcn.preconditions.length > 0 }\n\n        index = number_of_populations + ((population_index - 1) * criteria_def.xpath('./*/cda:precondition').length) +\n                criteria_def_index\n        criteria_id = HQMF::PopulationCriteria::STRAT\n        stratified_population = population.dup\n        stratified_population['stratification'] = criteria_def.at_xpath('./*/cda:id/@root').try(:value) ||\n                                                  \"#{criteria_id}-#{criteria_def_index}\"\n        build_population_criteria(criteria_def, criteria_id, stratified_population)\n\n        stratified_population['id'] = id_def ? \"#{id_def.value} - Stratification #{criteria_def_index + 1}\" : \"Population#{index}\"\n        title_def = population_def.at_xpath('cda:title/@value', HQMF2::Document::NAMESPACES)\n        stratified_population['title'] = title_def ? \"#{title_def.value} - Stratification #{criteria_def_index + 1}\" : \"Population #{index}\"\n        @stratifications << stratified_population\n      end\n    end", "label": 4}
{"code": "def create_cluster(settings):\n    \"\"\"\n    Creates a new Nydus cluster from the given settings.\n\n    :param settings: Dictionary of the cluster settings.\n    :returns: Configured instance of ``nydus.db.base.Cluster``.\n\n    >>> redis = create_cluster({\n    >>>     'backend': 'nydus.db.backends.redis.Redis',\n    >>>     'router': 'nydus.db.routers.redis.PartitionRouter',\n    >>>     'defaults': {\n    >>>         'host': 'localhost',\n    >>>         'port': 6379,\n    >>>     },\n    >>>     'hosts': {\n    >>>         0: {'db': 0},\n    >>>         1: {'db': 1},\n    >>>         2: {'db': 2},\n    >>>     }\n    >>> })\n    \"\"\"\n    # Pull in our client\n    settings = copy.deepcopy(settings)\n    backend = settings.pop('engine', settings.pop('backend', None))\n    if isinstance(backend, basestring):\n        Conn = import_string(backend)\n    elif backend:\n        Conn = backend\n    else:\n        raise KeyError('backend')\n\n    # Pull in our cluster\n    cluster = settings.pop('cluster', None)\n    if not cluster:\n        Cluster = Conn.get_cluster()\n    elif isinstance(cluster, basestring):\n        Cluster = import_string(cluster)\n    else:\n        Cluster = cluster\n\n    # Pull in our router\n    router = settings.pop('router', None)\n    if not router:\n        Router = BaseRouter\n    elif isinstance(router, basestring):\n        Router = import_string(router)\n    else:\n        Router = router\n\n    # Build the connection cluster\n    return Cluster(\n        router=Router,\n        backend=Conn,\n        **settings\n    )", "label": 1}
{"code": "def open_new_window(kind = :tab)\n      window_opened_by do\n        if driver.method(:open_new_window).arity.zero?\n          driver.open_new_window\n        else\n          driver.open_new_window(kind)\n        end\n      end\n    end", "label": 4}
{"code": "function isPortTaken(port, fn) {\n  const net = require('net')\n  const tester = net.createServer()\n    .once('error', function (err) {\n      if (err.code != 'EADDRINUSE') return fn(err)\n      fn(null, true)\n    })\n    .once('listening', function() {\n      tester.once('close', function() { fn(null, false) })\n        .close()\n    })\n    .listen(port)\n}", "label": 3}
{"code": "function( data ) {\n        var ret = {\n            coverage: 0,\n            hits: 0,\n            misses: 0,\n            sloc: 0\n        };\n        for (var i = 0; i < data.source.length; i++) {\n            var line = data.source[i];\n            var num = i + 1;\n            if (data[num] === 0) {\n                ret.misses++;\n                ret.sloc++;\n            } else if (data[num] !== undefined) {\n                ret.hits++;\n                ret.sloc++;\n            }\n        }\n        ret.coverage = ret.hits / ret.sloc * 100;\n\n        return [ret.hits,ret.sloc];\n\n    }", "label": 3}
{"code": "function setupMap( config ) {\n    var layerSettings, defaultSettings,\n      query = '',\n      matchLang = location.search.match( /lang=([-_a-zA-Z]+)/ );\n\n    defaultSettings = {\n      maxzoom: 18,\n\n      // TODO: This is UI text, and needs to be translatable.\n      attribution: 'Map data &copy; <a href=\"http://openstreetmap.org/copyright\">OpenStreetMap contributors</a>'\n    };\n\n    if ( matchLang ) {\n      query = '?lang=' + matchLang[ 1 ];\n    }\n    config = config || {};\n\n    layerSettings = {\n      maxZoom: config.maxzoom !== undefined ? config.maxzoom : defaultSettings.maxzoom,\n\n      // TODO: This is UI text, and needs to be translatable.\n      attribution: config.attribution !== undefined ? config.attribution : defaultSettings.attribution,\n\n      id: 'map-01'\n    };\n\n    // Add a map layer\n    L.tileLayer( style + '/{z}/{x}/{y}' + scalex + '.png' + query, layerSettings ).addTo( map );\n\n    // Add a km/miles scale\n    L.control.scale().addTo( map );\n\n    // Update the zoom level label\n    map.on( 'zoomend', function () {\n      document.getElementById( 'zoom-level' ).innerHTML = 'Zoom Level: ' + map.getZoom();\n    } );\n\n    // Add current location to URL hash\n    new L.Hash( map ); // eslint-disable-line no-new\n  }", "label": 3}
{"code": "def retrieve_employee(employee_id, opts = {})\n      data, _status_code, _headers = retrieve_employee_with_http_info(employee_id, opts)\n      return data\n    end", "label": 4}
{"code": "def request_failed exception, req, connection # :nodoc:\n    due_to = \"(due to #{exception.message} - #{exception.class})\"\n    message = \"too many connection resets #{due_to} #{error_message connection}\"\n\n    finish connection\n\n    raise Error, message, exception.backtrace\n  end", "label": 4}
{"code": "public function setStreamingConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Speech\\V1\\StreamingRecognitionConfig::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function renderCollection(patterns, drizzleData, collectionKey) {\n  const layoutKey = drizzleData.options.layouts.collection;\n  let layoutObj;\n  try {\n    // DeepObj will throw if it fails, which is good and fine...\n    layoutObj = deepObj(idKeys(layoutKey), drizzleData.templates, false);\n  } catch (e) {\n    // But Make this error more friendly and specific\n    DrizzleError.error(\n      new DrizzleError(\n        `Could not find partial for default collection layout\n'${layoutKey}'. Check 'options.layouts.collection' and/or\n'options.src.templates' values to make sure they are OK`,\n        DrizzleError.LEVELS.ERROR\n      ),\n      drizzleData.options.debug\n    );\n  }\n  patterns.collection.contents = applyTemplate(\n    layoutObj.contents,\n    resourceContext(patterns.collection, drizzleData),\n    drizzleData.options\n  );\n  return patterns;\n}", "label": 3}
{"code": "func (ts *Store) remove(id string) error {\n\ttreepath := ts.GetPath(id)\n\t// If tree path doesn't exist we're done\n\t_, err := os.Stat(treepath)\n\tif err != nil && os.IsNotExist(err) {\n\t\treturn nil\n\t}\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"failed to open tree store directory\"), err)\n\t}\n\n\trenderedFilePath := filepath.Join(treepath, renderedfilename)\n\t// The \"rendered\" flag file should be the firstly removed file. So if\n\t// the removal ends with some error leaving some stale files IsRendered()\n\t// will return false.\n\t_, err = os.Stat(renderedFilePath)\n\tif err != nil && !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\tif !os.IsNotExist(err) {\n\t\terr := os.Remove(renderedFilePath)\n\t\t// Ensure that the treepath directory is fsynced after removing the\n\t\t// \"rendered\" flag file\n\t\tf, err := os.Open(treepath)\n\t\tif err != nil {\n\t\t\treturn errwrap.Wrap(errors.New(\"failed to open tree store directory\"), err)\n\t\t}\n\t\tdefer f.Close()\n\t\terr = f.Sync()\n\t\tif err != nil {\n\t\t\treturn errwrap.Wrap(errors.New(\"failed to sync tree store directory\"), err)\n\t\t}\n\t}\n\n\t// Ignore error retrieving image hash\n\tkey, _ := ts.GetImageHash(id)\n\n\tif err := os.RemoveAll(treepath); err != nil {\n\t\treturn err\n\t}\n\n\tif key != \"\" {\n\t\treturn ts.store.UpdateTreeStoreSize(key, 0)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static responderaction get(nitro_service service, String name) throws Exception{\n\t\tresponderaction obj = new responderaction();\n\t\tobj.set_name(name);\n\t\tresponderaction response = (responderaction) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def execute_action_command(command: nil)\n      command_return = @command_executor.execute(command: command, target_object: nil)\n      ## probably need to just return Strings, or ready_for_next with object isn't String\n      return_object = command_return.return_value\n      return_value_type = command_return.return_value_type\n      closure_arg = command_return.closure_argument_value\n\n      return_object = return_value_processor.prepare_object(\n        return_value: return_object,\n        return_value_type: return_value_type\n      )\n\n      if closure_arg.nil?\n        closure_arg = closure_arg.to_s\n      else\n        closure_arg = return_value_processor.prepare_object(\n          return_value: closure_arg,\n          return_value_type: :string # always assume string for closure error_callback\n        )\n      end\n\n      Thread.current[:exception] = nil\n\n      payload = {\n        payload: {\n          status: \"ready_for_next\",\n          return_object: return_object,\n          closure_argument_value: closure_arg\n        }\n      }\n      return JSON.generate(payload)\n    rescue StandardError => e\n      Thread.current[:exception] = e\n\n      exception_array = []\n      exception_array << \"#{e.class}:\"\n      exception_array << e.backtrace\n\n      while e.respond_to?(\"cause\") && (e = e.cause)\n        exception_array << \"cause: #{e.class}\"\n        exception_array << e.backtrace\n      end\n\n      payload = {\n        payload: {\n          status: \"failure\",\n          failure_information: exception_array.flatten\n        }\n      }\n      return JSON.generate(payload)\n    end", "label": 4}
{"code": "def load_or_create(cls, filename=None, no_input=False, create_new=False, **kwargs):\n        \"\"\"\n            Load system from a dump, if dump file exists, or create a new system if it does not exist.\n        \"\"\"\n        parser = argparse.ArgumentParser()\n        parser.add_argument('--no_input', action='store_true')\n        parser.add_argument('--create_new', action='store_true')\n        args = parser.parse_args()\n\n        if args.no_input:\n            print('Parameter --no_input was given')\n            no_input = True\n        if args.create_new:\n            print('Parameter --create_new was given')\n            create_new = True\n            no_input = True\n\n        def savefile_more_recent():\n            time_savefile = os.path.getmtime(filename)\n            time_program = os.path.getmtime(sys.argv[0])\n            return time_savefile > time_program\n\n        def load_pickle():\n            with open(filename, 'rb') as of:\n                statefile_version, data = pickle.load(of)\n\n            if statefile_version != STATEFILE_VERSION:\n                raise RuntimeError(f'Wrong statefile version, please remove state file {filename}')\n            return data\n\n        def load():\n            print('Loading %s' % filename)\n            obj_list, config = load_pickle()\n            system = System(load_state=obj_list, filename=filename, **kwargs)\n\n            return system\n\n        def create():\n            print('Creating new system')\n            config = None\n            if filename:\n                try:\n                    obj_list, config = load_pickle()\n                except FileNotFoundError:\n                    config = None\n            return cls(filename=filename, load_config=config, **kwargs)\n\n        if filename and os.path.isfile(filename):\n            if savefile_more_recent() and not create_new:\n                return load()\n            else:\n                if no_input:\n                    print('Program file more recent. Loading that instead.')\n                    return create()\n                while True:\n                    answer = input('Program file more recent. Do you want to load it? (y/n) ')\n                    if answer == 'y':\n                        return create()\n                    elif answer == 'n':\n                        return load()\n        else:\n            return create()", "label": 1}
{"code": "public function setChecksum($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\WebRisk\\V1beta1\\ComputeThreatListDiffResponse_Checksum::class);\n        $this->checksum = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static appfwprofile_csrftag_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappfwprofile_csrftag_binding obj = new appfwprofile_csrftag_binding();\n\t\tobj.set_name(name);\n\t\tappfwprofile_csrftag_binding response[] = (appfwprofile_csrftag_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static nsspparams get(nitro_service service) throws Exception{\n\t\tnsspparams obj = new nsspparams();\n\t\tnsspparams[] response = (nsspparams[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public static base_response delete(nitro_service client, String hostname) throws Exception {\n\t\tdnsaddrec deleteresource = new dnsaddrec();\n\t\tdeleteresource.hostname = hostname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def auths\n      json = client.get(\"/v1/sys/auth\")\n      json = json[:data] if json[:data]\n      return Hash[*json.map do |k,v|\n        [k.to_s.chomp(\"/\").to_sym, Auth.decode(v)]\n      end.flatten]\n    end", "label": 4}
{"code": "private function initFailureFile()\n    {\n        $this->baseDir = getenv('GOOGLE_CLOUD_BATCH_DAEMON_FAILURE_DIR');\n        if ($this->baseDir === false) {\n            $this->baseDir = sprintf(\n                '%s/batch-daemon-failure',\n                sys_get_temp_dir()\n            );\n        }\n        if (! is_dir($this->baseDir)) {\n            if (@mkdir($this->baseDir, 0700, true) === false) {\n                throw new \\RuntimeException(\n                    sprintf(\n                        'Couuld not create a directory: %s',\n                        $this->baseDir\n                    )\n                );\n            }\n        }\n        // Use getmypid for simplicity.\n        $this->failureFile = sprintf(\n            '%s/failed-items-%d',\n            $this->baseDir,\n            getmypid()\n        );\n    }", "label": 2}
{"code": "def printo(msg, encoding=None, errors='replace', std_type='stdout'):\n    \"\"\"Write msg on stdout. If no encoding is specified\n    the detected encoding of stdout is used. If the encoding\n    can't encode some chars they are replaced by '?'\n\n    :param msg: message\n    :type msg: unicode on python2 | str on python3\n    \"\"\"\n    std = getattr(sys, std_type, sys.stdout)\n    if encoding is None:\n        try:\n            encoding = std.encoding\n        except AttributeError:\n            encoding = None\n    # Fallback to ascii if no encoding is found\n    if encoding is None:\n        encoding = 'ascii'\n    # https://docs.python.org/3/library/sys.html#sys.stdout\n    # write in the binary buffer directly in python3\n    if hasattr(std, 'buffer'):\n        std = std.buffer\n    std.write(msg.encode(encoding, errors=errors))\n    std.write(b'\\n')\n    std.flush()", "label": 1}
{"code": "def app_id(app_id, user_id, options = {})\n      payload = { app_id: app_id, user_id: user_id }.merge(options)\n      json = client.post(\"/v1/auth/app-id/login\", JSON.fast_generate(payload))\n      secret = Secret.decode(json)\n      client.token = secret.auth.client_token\n      return secret\n    end", "label": 4}
{"code": "def sort_into_sections(pull_requests, issues)\n      if @options[:issues]\n        unmapped_issues = sort_labeled_issues(issues)\n        add_unmapped_section(unmapped_issues)\n      end\n      if @options[:pulls]\n        unmapped_pull_requests = sort_labeled_issues(pull_requests)\n        add_unmapped_section(unmapped_pull_requests)\n      end\n      nil\n    end", "label": 4}
{"code": "def map_data(self):\n        \"\"\"\n        provides a mapping from the CSV file to the \n        aikif data structures.\n        \"\"\"\n        with open(self.src_file, \"r\") as f:\n            for line in f:\n                cols = line.split(',')\n                print(cols)", "label": 1}
{"code": "function markdown(options) {\n  return new Remarkable(extend({\n    breaks: false,\n    html: true,\n    langPrefix: 'lang-',\n    linkify: true,\n    typographer: false,\n    xhtmlOut: false\n  }, options));\n}", "label": 3}
{"code": "func (k Key) Open(ciphertext []byte) ([]byte, error) {\n\tvar data sealedData\n\n\terr := json.Unmarshal(ciphertext, &data)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tblock, err := aes.NewCipher(k)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\taesgcm, err := cipher.NewGCM(block)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tplaintext, err := aesgcm.Open(nil, data.Nonce, data.Ciphertext, nil)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn plaintext, nil\n}", "label": 5}
{"code": "public function setTransferType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferType::class);\n        $this->transfer_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function findById(a, id) {\n      for (var i = 0; i < a.length; i++) {\n        if (a[i].id == id) return a[i];\n      }\n      return null;\n    }", "label": 3}
{"code": "func (c *ClusterConfigV3) SetClientIdleTimeout(d time.Duration) {\n\tc.Spec.ClientIdleTimeout = Duration(d)\n}", "label": 5}
{"code": "function(key, value, getTypeId, getConstructor) {\n            var typeId = getTypeId(value);\n            if (typeId) {\n                var ctor = getConstructor(typeId);\n                if (ctor) {\n                    if (ctor.fromJSON) {\n                        return ctor.fromJSON(value);\n                    }\n\n                    return new ctor(value);\n                }\n            }\n\n            return value;\n        }", "label": 3}
{"code": "final void begin() {\n    if (this.properties.isDateRollEnforced()) {\n      final Thread thread = new Thread(this,\n          \"Log4J Time-based File-roll Enforcer\");\n      thread.setDaemon(true);\n      thread.start();\n      this.threadRef = thread;\n    }\n  }", "label": 0}
{"code": "function() {\n      var updateEvents = this.__parseUpdateEvents();\n      _.each(updateEvents, function(parsedUpdateEvent) {\n        this.stopListening(parsedUpdateEvent.idContainer, parsedUpdateEvent.eventName, this.retrieve);\n      }, this);\n    }", "label": 3}
{"code": "function renderResultDetails(sourceCode, messages, parentIndex) {\n\tconst topIssues = messages.length < 10 ? '' : _.groupBy(messages, 'severity');\n\n\treturn resultDetailsTemplate({\n\t\tparentIndex,\n\t\tsourceCode: renderSourceCode(sourceCode, messages, parentIndex),\n\t\tdetailSummary: resultSummaryTemplate({\n\t\t\ttopIssues: renderSummaryDetails(topIssues),\n\t\t\tissues: _.map(messages, renderIssue).join('')\n\t\t})\n\t});\n}", "label": 3}
{"code": "final void dispatchToAppender(final LoggingEvent customLoggingEvent) {\n    // wrap the LoggingEvent in a FileRollEvent to prevent recursion bug\n    final FoundationFileRollingAppender appender = this.getSource();\n    if (appender != null) {\n      appender.append(new FileRollEvent(customLoggingEvent, this));\n    }\n  }", "label": 0}
{"code": "func (l *localFileSystem) OpenFile(filePath string) (io.ReadCloser, error) {\n\tf, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn f, nil\n}", "label": 5}
{"code": "def bgfill\n      if @background_fill.nil?\n        color = Magick::Pixel.new(0, 0, 0, Magick::TransparentOpacity)\n      else\n        color = @background_fill\n        color.opacity = (1.0 - @background_fill_opacity) * Magick::TransparentOpacity\n      end\n      color\n    end", "label": 4}
{"code": "public static base_response unset(nitro_service client, responderparam resource, String[] args) throws Exception{\n\t\tresponderparam unsetresource = new responderparam();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public function parse_args( $arguments ) {\n\t\tlist( $positional_args, $mixed_args, $global_assoc, $local_assoc ) = self::extract_assoc( $arguments );\n\t\tlist( $assoc_args, $runtime_config )                               = $this->unmix_assoc_args( $mixed_args, $global_assoc, $local_assoc );\n\t\treturn array( $positional_args, $assoc_args, $runtime_config );\n\t}", "label": 2}
{"code": "func (g GridType) Pos(xRel, yRel float64) (x, y float64) {\n\tx = g.w*xRel + g.x\n\ty = g.h*(1-yRel) + g.y\n\treturn\n}", "label": 5}
{"code": "def _get_dict_char_count(txt):\r\n\t\"\"\"\r\n\treads the characters in txt and returns a dictionary\r\n\tof all letters\r\n\t\"\"\"\r\n\tdct = {}\r\n\tfor letter in txt:\r\n\t\tif letter in dct:\r\n\t\t\tdct[letter] += 1\r\n\t\telse:\r\n\t\t\tdct[letter] = 1\r\n\treturn dct", "label": 1}
{"code": "def fuzzy_hash_eql?(left, right)\n      return true if (left == right)\n\n      (left.count == right.count) && left.inject(true) do |res, kvp|\n        res && (kvp[1] == right[kvp[0]])\n      end\n    end", "label": 4}
{"code": "func NewReporter(cfg ReporterConfig) (*Reporter, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tr := &Reporter{\n\t\tReporterConfig: cfg,\n\t}\n\treturn r, nil\n}", "label": 5}
{"code": "public function setSetCell($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\Mutation_SetCell::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static vpnvserver_vpnsessionpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_vpnsessionpolicy_binding obj = new vpnvserver_vpnsessionpolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_vpnsessionpolicy_binding response[] = (vpnvserver_vpnsessionpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (i *Handle) doGetConfigCmd() (*Config, error) {\n\tmsg, err := i.doCmdWithoutAttr(ipvsCmdGetConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres, err := i.parseConfig(msg[0])\n\tif err != nil {\n\t\treturn res, err\n\t}\n\treturn res, nil\n}", "label": 5}
{"code": "protected static final Long parseUsingFallbacksWithColon(String text, DateTimeFormat timeFormat) {\n        if (text.indexOf(':') == -1) {\n            text = text.replace(\" \", \"\");\n            int numdigits = 0;\n            int lastdigit = 0;\n            for (int i = 0; i < text.length(); i++) {\n                char c = text.charAt(i);\n                if (Character.isDigit(c)) {\n                    numdigits++;\n                    lastdigit = i;\n                }\n            }\n            if (numdigits == 1 || numdigits == 2) {\n                // insert :00\n                int colon = lastdigit + 1;\n                text = text.substring(0, colon) + \":00\" + text.substring(colon);\n            }\n            else if (numdigits > 2) {\n                // insert :\n                int colon = lastdigit - 1;\n                text = text.substring(0, colon) + \":\" + text.substring(colon);\n            }\n            return parseUsingFallbacks(text, timeFormat);\n        }\n        else {\n            return null;\n        }\n    }", "label": 0}
{"code": "public function jsonSerialize()\n    {\n        return [\n            'id' => $this->id,\n            'sequence' => $this->sequence,\n            'batch_id' => $this->batchId,\n            'type' => $this->type,\n            'content' => $this->content,\n            'tags' => $this->tags,\n            'family_hash' => $this->familyHash,\n            'created_at' => $this->createdAt->toDateTimeString(),\n        ];\n    }", "label": 2}
{"code": "func (e Env) Marshal() (string, error) {\n\tx, err := xml.Marshal(e)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn fmt.Sprintf(\"%s%s\", xml.Header, x), nil\n}", "label": 5}
{"code": "def post(self, path=None, url_kwargs=None, **kwargs):\n        \"\"\"\n        Sends a POST request.\n\n        :param path:\n            The HTTP path (either absolute or relative).\n        :param url_kwargs:\n            Parameters to override in the generated URL. See `~hyperlink.URL`.\n        :param **kwargs:\n            Optional arguments that ``request`` takes.\n        :return: response object\n        \"\"\"\n        return self._session.post(self._url(path, url_kwargs), **kwargs)", "label": 1}
{"code": "public function getErrorDocs($error)\n    {\n        return isset($this->docs['shapes'][$error]['base'])\n            ? $this->docs['shapes'][$error]['base']\n            : null;\n    }", "label": 2}
{"code": "function buildStructureForFile(file) {\n  var names = [];\n  var targetLink;\n\n  if (file.dox.length === 0) { return false; }\n\n  file.dox.forEach(function(method){\n    if (method.ctx && !method.ignore) { names.push(method.ctx.name); }\n  });\n\n  // How deep is your love?\n  // If the splitted currentFile (the file we are currently rendering) path got one folder\n  // in the path or more, add ../ for each level found\n  if(file.currentFile && file.currentFile.split(path.sep).length > 1 ){\n    // Depth of current file\n    var depth = file.currentFile.split(path.sep).length,\n    // Create a prefix with n \"../\"\n    prefix = new Array(depth).join('../');\n    // Set up target link with prefix\n    targetLink = prefix + file.targetFile;\n  } else {\n    // Link does not have to be altered\n    targetLink = file.targetFile;\n  }\n\n  return {\n    source: {\n      full: file.sourceFile,\n      dir: path.dirname(file.sourceFile),\n      file: path.basename(file.sourceFile)\n    },\n    target: file.targetFile,\n    methods: names,\n    link : targetLink\n  };\n}", "label": 3}
{"code": "public function getTaxTotal(): int\n    {\n        $taxTotal = 0;\n\n        foreach ($this->getAdjustments(AdjustmentInterface::TAX_ADJUSTMENT) as $taxAdjustment) {\n            $taxTotal += $taxAdjustment->getAmount();\n        }\n\n        foreach ($this->units as $unit) {\n            $taxTotal += $unit->getTaxTotal();\n        }\n\n        return $taxTotal;\n    }", "label": 2}
{"code": "function validate(archiveDirectory, strict, cb) {\n  // Root validation checks\n  fs.readdir(archiveDirectory, function(err, files) {\n    if (err) {\n      return cb(err);\n    }\n\n    if (files.length < 2 || (files.length !== 2 && strict)) {\n      return cb('Root directory must contain exactly one metadata file and one forms directory');\n    }\n\n    if (files.indexOf('forms') === -1) {\n      return cb('A forms directory should be present in the root of the zip file');\n    }\n\n    if (files.indexOf('metadata.json') === -1) {\n      return cb('A metadata.json file must be present in the root of the zip file');\n    }\n\n    var metadataPath = path.join(archiveDirectory, 'metadata.json');\n\n    async.waterfall([\n      function(callback) {\n        validateMetadata(metadataPath, function(err, formFiles) {\n          callback(err, formFiles);\n        });\n      },\n      function(formFiles, callback) {\n        var forms = [];\n\n        _.each(formFiles, function(formFile) {\n          forms.push(path.join(archiveDirectory, formFile.path));\n        });\n\n        async.each(forms, validateForm, callback);\n      }\n    ], function(err) {\n      cb(err);\n    });\n  });\n}", "label": 3}
{"code": "public function diffInMicroseconds($date = null, $absolute = true)\n    {\n        $diff = $this->diff($this->resolveCarbon($date));\n        $value = (int) round((((($diff->days * static::HOURS_PER_DAY) +\n            $diff->h) * static::MINUTES_PER_HOUR +\n            $diff->i) * static::SECONDS_PER_MINUTE +\n            ($diff->f + $diff->s)) * static::MICROSECONDS_PER_SECOND);\n\n        return $absolute || !$diff->invert ? $value : -$value;\n    }", "label": 2}
{"code": "public function setMicrophoneDistance($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Speech\\V1p1beta1\\RecognitionMetadata_MicrophoneDistance::class);\n        $this->microphone_distance = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func isVariadic(f *ast.FuncType) bool {\n\tnargs := len(f.Params.List)\n\tif nargs == 0 {\n\t\treturn false\n\t}\n\t_, ok := f.Params.List[nargs-1].Type.(*ast.Ellipsis)\n\treturn ok\n}", "label": 5}
{"code": "protected function registerLogService()\n    {\n        $logger = Log::createLogger(\n            $this->config->get('log.file'),\n            'yansongda.pay',\n            $this->config->get('log.level', 'warning'),\n            $this->config->get('log.type', 'daily'),\n            $this->config->get('log.max_file', 30)\n        );\n\n        Log::setLogger($logger);\n    }", "label": 2}
{"code": "def call(html, context = {}, result = nil)\n      context = @default_context.merge(context)\n      context = context.freeze\n      result ||= @result_class.new\n      payload = default_payload filters: @filters.map(&:name),\n                                context: context, result: result\n      instrument 'call_pipeline.html_pipeline', payload do\n        result[:output] =\n          @filters.inject(html) do |doc, filter|\n            perform_filter(filter, doc, context, result)\n          end\n      end\n      result\n    end", "label": 4}
{"code": "public static cspolicy_crvserver_binding[] get(nitro_service service, String policyname) throws Exception{\n\t\tcspolicy_crvserver_binding obj = new cspolicy_crvserver_binding();\n\t\tobj.set_policyname(policyname);\n\t\tcspolicy_crvserver_binding response[] = (cspolicy_crvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function executeUpdate(\n        Session $session,\n        Transaction $transaction,\n        $sql,\n        array $options = []\n    ) {\n        $res = $this->execute($session, $sql, [\n            'transactionId' => $transaction->id()\n        ] + $options);\n\n        // Iterate through the result to ensure we have query statistics available.\n        iterator_to_array($res->rows());\n\n        $stats = $res->stats();\n        if (!$stats) {\n            throw new \\InvalidArgumentException(\n                'Partitioned DML response missing stats, possible due to non-DML statement as input.'\n            );\n        }\n\n        $statsItem = isset($options['statsItem'])\n            ? $options['statsItem']\n            : 'rowCountExact';\n\n        return $stats[$statsItem];\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, vserver resource) throws Exception {\n\t\tvserver updateresource = new vserver();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.backupvserver = resource.backupvserver;\n\t\tupdateresource.redirecturl = resource.redirecturl;\n\t\tupdateresource.cacheable = resource.cacheable;\n\t\tupdateresource.clttimeout = resource.clttimeout;\n\t\tupdateresource.somethod = resource.somethod;\n\t\tupdateresource.sopersistence = resource.sopersistence;\n\t\tupdateresource.sopersistencetimeout = resource.sopersistencetimeout;\n\t\tupdateresource.sothreshold = resource.sothreshold;\n\t\tupdateresource.pushvserver = resource.pushvserver;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func NewProcessManager() *ProcessManager {\n\t// We use pseudo PIDs that don't conflict with OS PIDs, so they can live in the same table.\n\t// For the pseudo PIDs, we use a sync.Pool rather than a plain old counter to avoid the unlikely,\n\t// but possible wrapping should such a counter exceed MaxInt64.\n\tpid := int64(32768) // TODO: /proc/sys/kernel/pid_max\n\n\treturn &ProcessManager{\n\t\texpire:  time.Minute * 5,\n\t\tentries: make(map[int64]*Process),\n\t\tpids: sync.Pool{\n\t\t\tNew: func() interface{} {\n\t\t\t\treturn atomic.AddInt64(&pid, 1)\n\t\t\t},\n\t\t},\n\t}\n}", "label": 5}
{"code": "func FWhen(text string, body func()) bool {\n\tglobalSuite.PushContainerNode(\"when \"+text, body, types.FlagTypeFocused, codelocation.New(1))\n\treturn true\n}", "label": 5}
{"code": "def post_file(self, url, filename, file_stream, *args, **kwargs):\n        \"\"\"Uploads file to provided url.\n\n        Returns contents as text\n\n        Args:\n            **url**: address where to upload file\n\n            **filename**: Name of the uploaded file\n\n            **file_stream**: file like object to upload\n\n            .. versionadded:: 0.3.2\n                **additional_headers**: (optional) Additional headers\n                to be used with request\n\n        Returns:\n            string\n        \"\"\"\n        res = self._conn.post(url, files={filename: file_stream},\n                              headers=self._prepare_headers(**kwargs))\n        if res.status_code == 200 or res.status_code == 201:\n            return res.text\n        else:\n            return None", "label": 1}
{"code": "public InternalTile paint(InternalTile tile) throws RenderException {\n\t\tif (tile.getContentType().equals(VectorTileContentType.URL_CONTENT)) {\n\t\t\tif (urlBuilder != null) {\n\t\t\t\tif (paintGeometries) {\n\t\t\t\t\turlBuilder.paintGeometries(paintGeometries);\n\t\t\t\t\turlBuilder.paintLabels(false);\n\t\t\t\t\ttile.setFeatureContent(urlBuilder.getImageUrl());\n\t\t\t\t}\n\t\t\t\tif (paintLabels) {\n\t\t\t\t\turlBuilder.paintGeometries(false);\n\t\t\t\t\turlBuilder.paintLabels(paintLabels);\n\t\t\t\t\ttile.setLabelContent(urlBuilder.getImageUrl());\n\t\t\t\t}\n\t\t\t\treturn tile;\n\t\t\t}\n\t\t}\n\t\treturn tile;\n\t}", "label": 0}
{"code": "protected function publishAssets(Extension $extension)\n    {\n        if ($extension->hasAssets()) {\n            $this->filesystem->copyDirectory(\n                $extension->getPath().'/assets',\n                $this->app->publicPath().'/assets/extensions/'.$extension->getId()\n            );\n        }\n    }", "label": 2}
{"code": "def to_xml_string(str = '')\n      str << '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n      str << ('<Properties xmlns=\"' << APP_NS << '\" xmlns:vt=\"' << APP_NS_VT << '\">')\n      instance_values.each do |key, value|\n        node_name = Axlsx.camel(key)\n        str << \"<#{node_name}>#{value}</#{node_name}>\"\n      end\n      str << '</Properties>'\n    end", "label": 4}
{"code": "private function tags($event)\n    {\n        return array_merge([\n            $this->formatNotifiable($event->notifiable),\n        ], ExtractTags::from($event->notification));\n    }", "label": 2}
{"code": "def function(self,p):\n        \"\"\"Constructs combined pattern out of the individual ones.\"\"\"\n        generators = self._advance_pattern_generators(p)\n\n        assert hasattr(p.operator,'reduce'),repr(p.operator)+\" does not support 'reduce'.\"\n\n        # CEBALERT: mask gets applied by all PGs including the Composite itself\n        # (leads to redundant calculations in current lissom_oo_or usage, but\n        # will lead to problems/limitations in the future).\n        patterns = [pg(xdensity=p.xdensity,ydensity=p.ydensity,\n                       bounds=p.bounds,mask=p.mask,\n                       x=p.x+p.size*(pg.x*np.cos(p.orientation)- pg.y*np.sin(p.orientation)),\n                       y=p.y+p.size*(pg.x*np.sin(p.orientation)+ pg.y*np.cos(p.orientation)),\n                       orientation=pg.orientation+p.orientation,\n                       size=pg.size*p.size)\n                    for pg in generators]\n        image_array = p.operator.reduce(patterns)\n        return image_array", "label": 1}
{"code": "def compare_property_vs_target(property, target)\n      case target\n      when NilClass\n        return true if property.nil?\n      when Liquid::Expression::MethodLiteral # `empty` or `blank`\n        return true if Array(property).join == target.to_s\n      else\n        Array(property).each do |prop|\n          return true if prop.to_s == target.to_s\n        end\n      end\n\n      false\n    end", "label": 4}
{"code": "def notifiers\n      Cli::Environments::EvaluateOnly.new(options).evaluate\n      # TODO: pass the data directly to the notifiers?\n      DslDescriber.new.notifiers\n    end", "label": 4}
{"code": "func (a *AuthServer) activateCertAuthority(t services.TrustedCluster) error {\n\terr := a.ActivateCertAuthority(services.CertAuthID{Type: services.UserCA, DomainName: t.GetName()})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn trace.Wrap(a.ActivateCertAuthority(services.CertAuthID{Type: services.HostCA, DomainName: t.GetName()}))\n}", "label": 5}
{"code": "def push(value)\n      RedisEventStore.instance.lpush(@key, value)\n    rescue Redis::CommandError, Redis::CannotConnectError\n      RedisEventStore.logger.error(\"unable to push event: #{@key}\")\n      nil\n    end", "label": 4}
{"code": "def find_and_delete(options = nil, &block)\n      options = options ? Hash[options] : {}\n      options[:delete_after_find] ||= true\n      find(options, &block)      \n    end", "label": 4}
{"code": "function proxy(func){\n    'use strict';\n\n    // Returns a middleware\n    return function (kontx, next){\n        func(kontx.args).then(\n            function(payload){\n                kontx.payload = payload;\n                next();\n            },\n            function(err){\n                next(err);\n            }\n        );\n    };\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, dnsview resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdnsview addresources[] = new dnsview[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new dnsview();\n\t\t\t\taddresources[i].viewname = resources[i].viewname;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function finalize()\n    {\n        list($usec, $sec) = explode(' ', microtime());\n        $micro = sprintf(\"%06d\", $usec * 1000000);\n        $when = new \\DateTime(date('Y-m-d H:i:s.' . $micro));\n        $when->setTimezone(new \\DateTimeZone('UTC'));\n        $this->finalTime = $when->format('Y-m-d\\TH:i:s.u\\Z');\n        $this->isFinalState = true;\n    }", "label": 2}
{"code": "public static base_responses delete(nitro_service client, String jsoncontenttypevalue[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (jsoncontenttypevalue != null && jsoncontenttypevalue.length > 0) {\n\t\t\tappfwjsoncontenttype deleteresources[] = new appfwjsoncontenttype[jsoncontenttypevalue.length];\n\t\t\tfor (int i=0;i<jsoncontenttypevalue.length;i++){\n\t\t\t\tdeleteresources[i] = new appfwjsoncontenttype();\n\t\t\t\tdeleteresources[i].jsoncontenttypevalue = jsoncontenttypevalue[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def to_xml_string(node_name = '', str = '')\n      str << \"<#{node_name} \"\n      str << instance_values.map { |key, value| Axlsx::camel(key) << '=\"' << value.to_s << '\"' }.join(' ')\n      str << '/>'\n    end", "label": 4}
{"code": "function argMapper(arg, index, array) {\n    var isError = (0, _neTypes.typeOf)(arg) === Error.name;\n    var showStack = /\\bSTACK\\b/i.test(process.env.LATTICE_ERRORS || ''); // $FlowFixMe\n\n    return !isError ? arg : showStack ? arg : arg.message;\n  }", "label": 3}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo]) do\n        permit VALID_COMMIT_PARAM_NAMES\n        assert_required REQUIRED_COMMIT_PARAMS\n      end\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/git/commits\", arguments.params)\n    end", "label": 4}
{"code": "public function setHttpMethod($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Scheduler\\V1beta1\\HttpMethod::class);\n        $this->http_method = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func OptionDNS(dns string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.dnsList = append(sb.config.dnsList, dns)\n\t}\n}", "label": 5}
{"code": "protected function createOptions($options)\n    {\n        if (is_array($options)) {\n            return new Options($options);\n        }\n\n        if ($options instanceof OptionsInterface) {\n            return $options;\n        }\n\n        throw new \\InvalidArgumentException('Invalid type for client options.');\n    }", "label": 2}
{"code": "def authorize\n      raise AuthorizationError, \"Missing data\" unless component && action\n\n      AuthorizationStatusCollection.new(authorization_handlers, user, component, resource)\n    end", "label": 4}
{"code": "function qcertEval(inputConfig) {\n\tconsole.log(\"qcertEval chosen\");\n\tvar handler = function(result) {\n\t\tconsole.log(\"Compiler returned\");\n\t\tconsole.log(result);\n\t\tpostMessage(result.eval);\n\t\tconsole.log(\"reply message posted\");\n\n\t\t// Each spawned worker is designed to be used once\n\t\tclose();\n\t}\n\tqcertWhiskDispatch(inputConfig, handler);\n}", "label": 3}
{"code": "public static tunneltrafficpolicy get(nitro_service service, String name) throws Exception{\n\t\ttunneltrafficpolicy obj = new tunneltrafficpolicy();\n\t\tobj.set_name(name);\n\t\ttunneltrafficpolicy response = (tunneltrafficpolicy) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void characters(char ch[], int start, int length)\r\n    {\r\n        if (m_CurrentString == null)\r\n            m_CurrentString = new String(ch, start, length);\r\n        else\r\n            m_CurrentString += new String(ch, start, length);\r\n    }", "label": 0}
{"code": "function(oauth2_server_id, res, next_url, state) {\n    var sconfig = this.config.servers[oauth2_server_id];\n    var cconfig = this.config.client;\n    var data = {\n      client_id: sconfig.client_id,\n      redirect_uri: cconfig.redirect_uri,\n      response_type: 'code',\n      state: this.serializer.stringify([oauth2_server_id, next_url, state || null])\n    };\n    var url = sconfig.server_authorize_endpoint +'?'+ querystring.stringify(data);\n    redirect(res, url);\n  }", "label": 3}
{"code": "def get_games(ctx):\n    \"\"\"Prints out games owned by a Steam user.\"\"\"\n\n    username = ctx.obj['username']\n    games = User(username).get_games_owned()\n\n    for game in sorted(games.values(), key=itemgetter('title')):\n        click.echo('%s [appid: %s]' % (game['title'], game['appid']))\n\n    click.secho('Total gems owned by `%s`: %d' % (username, len(games)), fg='green')", "label": 1}
{"code": "public function setSourceProperties($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Protobuf\\Value::class);\n        $this->source_properties = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function _createSocialAccount(){\n    return BB\n        .bind(this)\n        .then(function() {\n            return grasshopper.auth('Pinterest', this.params);\n        })\n        .then(function(token) {\n            this.req.session.token = new Buffer(token).toString('base64');\n            this.req.session.save();\n        });\n}", "label": 3}
{"code": "def _platform_patterns(self, platform='generic', compiled=False):\n        \"\"\"Return all the patterns for specific platform.\"\"\"\n        patterns = self._dict_compiled.get(platform, None) if compiled else self._dict_text.get(platform, None)\n        if patterns is None:\n            raise KeyError(\"Unknown platform: {}\".format(platform))\n        return patterns", "label": 1}
{"code": "protected static function addAlwaysFields($fieldObject, array &$select, $parentTable, $forRelation = false)\n    {\n        if(isset($fieldObject->config['always']))\n        {\n            $always = $fieldObject->config['always'];\n\n            if(is_string($always))\n            {\n                $always = explode(',', $always);\n            }\n\n            // Get as 'field' => true\n            foreach($always as $field)\n            {\n                self::addFieldToSelect($field, $select, $parentTable, $forRelation);\n            }\n        }\n    }", "label": 2}
{"code": "public function signedUploadUrl($expires, array $options = [])\n    {\n        $options += [\n            'headers' => []\n        ];\n\n        $options['headers']['x-goog-resumable'] = 'start';\n\n        unset(\n            $options['cname'],\n            $options['saveAsName'],\n            $options['responseDisposition'],\n            $options['responseType']\n        );\n\n        return $this->signedUrl($expires, [\n            'method' => 'POST',\n            'allowPost' => true\n        ] + $options);\n    }", "label": 2}
{"code": "func SqTableColumns(db XODB, table string) ([]*SqColumn, error) {\n\tvar err error\n\n\t// sql query\n\tvar sqlstr = `PRAGMA table_info(` + table + `)`\n\n\t// run query\n\tXOLog(sqlstr)\n\tq, err := db.Query(sqlstr, table)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*SqColumn{}\n\tfor q.Next() {\n\t\tsc := SqColumn{}\n\n\t\t// scan\n\t\terr = q.Scan(&sc.FieldOrdinal, &sc.ColumnName, &sc.DataType, &sc.NotNull, &sc.DefaultValue, &sc.PkColIndex)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &sc)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "protected String sendRequestToDF(String df_service, Object msgContent) {\n\n        IDFComponentDescription[] receivers = getReceivers(df_service);\n        if (receivers.length > 0) {\n            IMessageEvent mevent = createMessageEvent(\"send_request\");\n            mevent.getParameter(SFipa.CONTENT).setValue(msgContent);\n            for (int i = 0; i < receivers.length; i++) {\n                mevent.getParameterSet(SFipa.RECEIVERS).addValue(\n                        receivers[i].getName());\n                logger.info(\"The receiver is \" + receivers[i].getName());\n            }\n            sendMessage(mevent);\n        }\n        logger.info(\"Message sended to \" + df_service + \" to \"\n                + receivers.length + \" receivers\");\n        return (\"Message sended to \" + df_service);\n    }", "label": 0}
{"code": "def get_string_from_rdf(src):\n    \"\"\" extracts the real content from an RDF info object \"\"\"\n    res = src.split(\"/\") #[:-1]\n    return \"\".join([l.replace('\"', '\"\"') for l in res[len(res) - 1]])", "label": 1}
{"code": "def _calculate(numbers, symbols):\n        \"\"\"Calculates a final value given a set of numbers and symbols.\"\"\"\n        if len(numbers) is 1:\n            return numbers[0]\n\n        precedence = [[pow], [mul, div], [add, sub]]\n\n        # Find most important operation\n        for op_group in precedence:\n            for i, op in enumerate(symbols):\n                if op in op_group:\n                    # Apply operation\n                    a = numbers[i]\n                    b = numbers[i + 1]\n                    result = MathService._applyBinary(a, b, op)\n                    new_numbers = numbers[:i] + [result] + numbers[i + 2:]\n                    new_symbols = symbols[:i] + symbols[i + 1:]\n\n                    return MathService._calculate(new_numbers, new_symbols)", "label": 1}
{"code": "func (a *LocalKeyAgent) AddHostSignersToCache(certAuthorities []auth.TrustedCerts) error {\n\tfor _, ca := range certAuthorities {\n\t\tpublicKeys, err := ca.SSHCertPublicKeys()\n\t\tif err != nil {\n\t\t\ta.log.Error(err)\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\ta.log.Debugf(\"Adding CA key for %s\", ca.ClusterName)\n\t\terr = a.keyStore.AddKnownHostKeys(ca.ClusterName, publicKeys)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function propertyExists(\n        string $property_id,\n        bool $read_mode,\n        StatementsSource $source = null,\n        Context $context = null,\n        CodeLocation $code_location = null\n    ) {\n        // remove trailing backslash if it exists\n        $property_id = preg_replace('/^\\\\\\\\/', '', $property_id);\n\n        list($fq_class_name, $property_name) = explode('::$', $property_id);\n\n        if ($this->property_existence_provider->has($fq_class_name)) {\n            $property_exists = $this->property_existence_provider->doesPropertyExist(\n                $fq_class_name,\n                $property_name,\n                $read_mode,\n                $source,\n                $context,\n                $code_location\n            );\n\n            if ($property_exists !== null) {\n                return $property_exists;\n            }\n        }\n\n        $class_storage = $this->classlike_storage_provider->get($fq_class_name);\n\n        if (isset($class_storage->declaring_property_ids[$property_name])) {\n            $declaring_property_class = $class_storage->declaring_property_ids[$property_name];\n\n            if ($context && $context->calling_method_id) {\n                $this->file_reference_provider->addMethodReferenceToClassMember(\n                    $context->calling_method_id,\n                    strtolower($declaring_property_class) . '::$' . $property_name\n                );\n            } elseif ($source) {\n                $this->file_reference_provider->addFileReferenceToClassMember(\n                    $source->getFilePath(),\n                    strtolower($declaring_property_class) . '::$' . $property_name\n                );\n            }\n\n            if ($this->collect_locations && $code_location) {\n                $this->file_reference_provider->addCallingLocationForClassProperty(\n                    $code_location,\n                    strtolower($declaring_property_class) . '::$' . $property_name\n                );\n            }\n\n            return true;\n        }\n\n        if ($context && $context->calling_method_id) {\n            $this->file_reference_provider->addMethodReferenceToMissingClassMember(\n                $context->calling_method_id,\n                strtolower($fq_class_name) . '::$' . $property_name\n            );\n        } elseif ($source) {\n            $this->file_reference_provider->addFileReferenceToMissingClassMember(\n                $source->getFilePath(),\n                strtolower($fq_class_name) . '::$' . $property_name\n            );\n        }\n\n        return false;\n    }", "label": 2}
{"code": "def get_connection(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get information on proxy connection to a device's management interface.\n\n        :param id: Device ID as an int.\n        :return: :class:`devices.Connection <devices.Connection>` object\n        :rtype: devices.Connection\n        \"\"\"\n        schema = ConnectionSchema()\n        resp = self.service.get(self.base+str(id)+'/connect/')\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public static base_response update(nitro_service client, snmpuser resource) throws Exception {\n\t\tsnmpuser updateresource = new snmpuser();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.group = resource.group;\n\t\tupdateresource.authtype = resource.authtype;\n\t\tupdateresource.authpasswd = resource.authpasswd;\n\t\tupdateresource.privtype = resource.privtype;\n\t\tupdateresource.privpasswd = resource.privpasswd;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (l VirtualDeviceList) newUnitNumber(c types.BaseVirtualController) int32 {\n\tunits := make([]bool, 30)\n\n\tswitch sc := c.(type) {\n\tcase types.BaseVirtualSCSIController:\n\t\t//  The SCSI controller sits on its own bus\n\t\tunits[sc.GetVirtualSCSIController().ScsiCtlrUnitNumber] = true\n\t}\n\n\tkey := c.GetVirtualController().Key\n\n\tfor _, device := range l {\n\t\td := device.GetVirtualDevice()\n\n\t\tif d.ControllerKey == key && d.UnitNumber != nil {\n\t\t\tunits[int(*d.UnitNumber)] = true\n\t\t}\n\t}\n\n\tfor unit, used := range units {\n\t\tif !used {\n\t\t\treturn int32(unit)\n\t\t}\n\t}\n\n\treturn -1\n}", "label": 5}
{"code": "def define\n      fail \"Version required (or :noversion)\" if @version.nil?\n      @version = nil if :noversion == @version\n\n      desc \"Build all the packages\"\n      task :package\n\n      desc \"Force a rebuild of the package files\"\n      task repackage: [:clobber_package, :package]\n\n      desc \"Remove package products\"\n      task :clobber_package do\n        rm_r package_dir rescue nil\n      end\n\n      task clobber: [:clobber_package]\n\n      [\n        [need_tar, tgz_file, \"z\"],\n        [need_tar_gz, tar_gz_file, \"z\"],\n        [need_tar_bz2, tar_bz2_file, \"j\"],\n        [need_tar_xz, tar_xz_file, \"J\"]\n      ].each do |need, file, flag|\n        if need\n          task package: [\"#{package_dir}/#{file}\"]\n          file \"#{package_dir}/#{file}\" =>\n            [package_dir_path] + package_files do\n            chdir(package_dir) { sh @tar_command, \"#{flag}cvf\", file, package_name }\n          end\n        end\n      end\n\n      if need_zip\n        task package: [\"#{package_dir}/#{zip_file}\"]\n        file \"#{package_dir}/#{zip_file}\" =>\n          [package_dir_path] + package_files do\n          chdir(package_dir) { sh @zip_command, \"-r\", zip_file, package_name }\n        end\n      end\n\n      directory package_dir_path => @package_files do\n        @package_files.each do |fn|\n          f = File.join(package_dir_path, fn)\n          fdir = File.dirname(f)\n          mkdir_p(fdir) unless File.exist?(fdir)\n          if File.directory?(fn)\n            mkdir_p(f)\n          else\n            rm_f f\n            safe_ln(fn, f)\n          end\n        end\n      end\n      self\n    end", "label": 4}
{"code": "def add_primitives(gc) #:nodoc:\n      raise ArgumentError, 'RVG width or height undefined' if @width.nil? || @height.nil?\n      return self if @width.zero? || @height.zero?\n\n      gc.push\n      add_outermost_primitives(gc)\n      gc.pop\n    end", "label": 4}
{"code": "def getLiteral(self):\n        '''Get a sequence of non-special characters.'''\n        # we are on the first non-special character\n        chars = u''\n        c = self.current()\n        while True:\n            if c and c == u\"\\\\\":\n                c = self.next()\n                if c:\n                    chars += c\n                continue\n            elif not c or (c in self.meta_chars):\n                break\n            else:\n                chars += c\n            if self.lookahead() and self.lookahead() in self.meta_chars:\n                break\n            c = self.next()\n        return StringGenerator.Literal(chars)", "label": 1}
{"code": "def marshal_dump\n      {\n        method: method,\n        body: body,\n        headers: headers,\n        path: path,\n        params: params,\n        options: options\n      }\n    end", "label": 4}
{"code": "def get_cantera_mass_fraction(self, species_conversion=None):\n        \"\"\"Get the mass fractions in a string format suitable for input to Cantera.\n\n        Arguments:\n            species_conversion (`dict`, optional): Mapping of species identifier to a\n                species name. This argument should be supplied when the name of the\n                species in the ChemKED YAML file does not match the name of the same\n                species in a chemical kinetic mechanism. The species identifier (the key\n                of the mapping) can be the name, InChI, or SMILES provided in the ChemKED\n                file, while the value associated with a key should be the desired name in\n                the Cantera format output string.\n\n        Returns:\n            `str`: String of mass fractions in the ``SPEC:AMT, SPEC:AMT`` format\n\n        Raises:\n            `ValueError`: If the composition type is ``'mole fraction'`` or\n                ``'mole percent'``, the conversion cannot be done because no molecular\n                weight information is known\n\n        Examples:\n            >>> dp = DataPoint(properties)\n            >>> dp.get_cantera_mass_fraction()\n            'H2:2.2525e-04, O2:4.4775e-03, Ar:9.9530e-01'\n            >>> species_conversion = {'H2': 'h2', 'O2': 'o2'}\n            >>> dp.get_cantera_mass_fraction(species_conversion)\n            'h2:2.2525e-04, o2:4.4775e-03, Ar:9.9530e-01'\n            >>> species_conversion = {'1S/H2/h1H': 'h2', '1S/O2/c1-2': 'o2'}\n            >>> dp.get_cantera_mass_fraction(species_conversion)\n            'h2:2.2525e-04, o2:4.4775e-03, Ar:9.9530e-01'\n        \"\"\"\n        if self.composition_type in ['mole fraction', 'mole percent']:\n            raise ValueError('Cannot get mass fractions from the given composition.\\n'\n                             '{}'.format(self.composition)\n                             )\n        else:\n            return self.get_cantera_composition_string(species_conversion)", "label": 1}
{"code": "public static List<String> linesFromFile(String filename,String encoding) {\r\n    try {\r\n      List<String> lines = new ArrayList<String>();\r\n      BufferedReader in = new BufferedReader(new EncodingFileReader(filename,encoding));\r\n      String line;\r\n      while ((line = in.readLine()) != null) {\r\n        lines.add(line);\r\n      }\r\n      in.close();\r\n      return lines;\r\n    }\r\n    catch (IOException e) {\r\n      e.printStackTrace();\r\n      return null;\r\n    }\r\n  }", "label": 0}
{"code": "def secret_matches?(input)\n      # return false if either is nil, since secure_compare depends on strings\n      # but Application secrets MAY be nil depending on confidentiality.\n      return false if input.nil? || secret.nil?\n\n      # When matching the secret by comparer function, all is well.\n      return true if secret_strategy.secret_matches?(input, secret)\n\n      # When fallback lookup is enabled, ensure applications\n      # with plain secrets can still be found\n      if fallback_secret_strategy\n        fallback_secret_strategy.secret_matches?(input, secret)\n      else\n        false\n      end\n    end", "label": 4}
{"code": "public boolean shouldCompress(String requestUri) {\n\t\tString uri = requestUri.toLowerCase();\n\t\treturn checkSuffixes(uri, zipSuffixes);\n\t}", "label": 0}
{"code": "function (index, options, questionnaire) {\n\n    this.index         = index;\n    this.options       = options;\n    this.questionnaire = questionnaire;\n    if (options.diagram) {\n      this.diagram = new Diagram(index, options.diagram, this);\n    }\n\n    // Initial state is immutable\n    this.initState = Immutable({\n      validAnswer: false,\n      rightAnswer: false,\n      view:        'question'\n    });\n\n    // Prevent overwriting default properties of state and assign provided properties to initial state\n    if (has(spec, 'addToState')) {\n      if(!has(spec.addToState, 'validAnswer')\n        && !has(spec.addToState, 'rightAnswer')\n        && !has(spec.addToState, 'view')) {\n\n          // Merge immutable with object\n          this.initState = this.initState.merge(spec.addToState);\n      }\n    }\n\n    // Set state to mutable copy of initial state\n    this.state = this.initState.asMutable({deep: true});\n\n  }", "label": 3}
{"code": "public function setWriteResults($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Firestore\\V1beta1\\WriteResult::class);\n        $this->write_results = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function (context) {\n        var parts = context.parts,\n            partsLen = parts.length,\n            startPos = context.startPos,\n            array = this.start,\n            len = array.length,\n            idx;\n        for (idx = 0; idx < len; ++idx) {\n            if (this._matchName(array[idx], parts[startPos])) {\n                if (++startPos >= partsLen) {\n                    // Match if last part of the start and no end\n                    if (idx === len - 1 && !this.end) {\n                        return _GPF_PATHMATCH_OK;\n                    }\n                    return _GPF_PATHMATCH_KO;\n                }\n            } else {\n                return _GPF_PATHMATCH_KO;\n            }\n        }\n        context.startPos = startPos;\n        return _GPF_PATHMATCH_UNKNOWN;\n    }", "label": 3}
{"code": "function prettifyDiffOutput(diffArr) {\n    const res = [];\n    for (const diff of diffArr) {\n        res.push(prettifyDiffObj(diff));\n    }\n    return res;\n}", "label": 3}
{"code": "public function annotateImage($image, $features, $optionalArgs = [])\n    {\n        $image = $this->createImageObject($image);\n        return $this->annotateImageHelper(\n            [$this, 'batchAnnotateImages'],\n            AnnotateImageRequest::class,\n            $image,\n            $features,\n            $optionalArgs\n        );\n    }", "label": 2}
{"code": "def cp_cropduster_image(self, the_image_path, del_after_upload=False, overwrite=False, invalidate=False):\n        \"\"\"\n        Deal with saving cropduster images to S3. Cropduster is a Django library for resizing editorial images.\n        S3utils was originally written to put cropduster images on S3 bucket.\n\n        Extra Items in your Django Settings\n        -----------------------------------\n\n        MEDIA_ROOT : string\n            Django media root.\n            Currently it is ONLY used in cp_cropduster_image method.\n            NOT any other method as this library was originally made to put Django cropduster images on s3 bucket.\n\n        S3_ROOT_BASE : string\n            S3 media root base. This will be the root folder in S3.\n            Currently it is ONLY used in cp_cropduster_image method.\n            NOT any other method as this library was originally made to put Django cropduster images on s3 bucket.\n\n\n        \"\"\"\n\n        local_file = os.path.join(settings.MEDIA_ROOT, the_image_path)\n\n        # only try to upload things if the origin cropduster file exists (so it is not already uploaded to the CDN)\n        if os.path.exists(local_file):\n\n            the_image_crops_path = os.path.splitext(the_image_path)[0]\n            the_image_crops_path_full_path = os.path.join(settings.MEDIA_ROOT, the_image_crops_path)\n\n            self.cp(local_path=local_file,\n                    target_path=os.path.join(settings.S3_ROOT_BASE, the_image_path),\n                    del_after_upload=del_after_upload,\n                    overwrite=overwrite,\n                    invalidate=invalidate,\n                    )\n\n            self.cp(local_path=the_image_crops_path_full_path + \"/*\",\n                    target_path=os.path.join(settings.S3_ROOT_BASE, the_image_crops_path),\n                    del_after_upload=del_after_upload,\n                    overwrite=overwrite,\n                    invalidate=invalidate,\n                    )", "label": 1}
{"code": "function MapType(attrs, opts) {\n  Type.call(this);\n\n  if (!attrs.values) {\n    throw new Error(f('missing map values: %j', attrs));\n  }\n  this._values = createType(attrs.values, opts);\n\n  // Addition by Edwin Elia\n  var keys = attrs.keys;\n  if (!keys) {\n    keys = 'string';\n  }\n  this._keys = createType(keys, opts);\n}", "label": 3}
{"code": "function(models, remoteData)\n  {\n    var map = this.map;\n\n    map.reset();\n\n    if ( isArray( models ) )\n    {\n      for (var i = 0; i < models.length; i++)\n      {\n        var model = models[ i ];\n        var parsed = this.parseModel( model, remoteData );\n\n        if ( parsed )\n        {\n          map.put( parsed.$key(), parsed );\n        }\n      }\n    }\n    else if ( isObject( models ) )\n    {\n      var parsed = this.parseModel( models, remoteData );\n\n      if ( parsed )\n      {\n        map.put( parsed.$key(), parsed );\n      }\n    }\n\n    this.trigger( Collection.Events.Reset, [this] );\n    this.sort();\n\n    return this;\n  }", "label": 3}
{"code": "def bulk_copy(self, ids):\n        \"\"\"Bulk copy a set of packages.\n\n        :param ids: Int list of package IDs.\n        :return: :class:`packages.Package <packages.Package>` list\n        \"\"\"\n        schema = PackageSchema()\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)", "label": 1}
{"code": "public Object getObjectByQuery(Query query) throws PersistenceBrokerException\n    {\n        Object result = null;\n        if (query instanceof QueryByIdentity)\n        {\n            // example obj may be an entity or an Identity\n            Object obj = query.getExampleObject();\n            if (obj instanceof Identity)\n            {\n                Identity oid = (Identity) obj;\n                result = getObjectByIdentity(oid);\n            }\n            else\n            {\n                // TODO: This workaround doesn't allow 'null' for PK fields\n                if (!serviceBrokerHelper().hasNullPKField(getClassDescriptor(obj.getClass()), obj))\n                {\n                    Identity oid = serviceIdentity().buildIdentity(obj);\n                    result = getObjectByIdentity(oid);\n                }\n            }\n        }\n        else\n        {\n            Class itemClass = query.getSearchClass();\n            ClassDescriptor cld = getClassDescriptor(itemClass);\n            /*\n            use OJB intern Iterator, thus we are able to close used\n            resources instantly\n            */\n            OJBIterator it = getIteratorFromQuery(query, cld);\n            /*\n            arminw:\n            patch by Andre Clute, instead of taking the first found result\n            try to get the first found none null result.\n            He wrote:\n            I have a situation where an item with a certain criteria is in my\n            database twice -- once deleted, and then a non-deleted version of it.\n            When I do a PB.getObjectByQuery(), the RsIterator get's both results\n            from the database, but the first row is the deleted row, so my RowReader\n            filters it out, and do not get the right result.\n            */\n            try\n            {\n                while (result==null && it.hasNext())\n                {\n                    result = it.next();\n                }\n            } // make sure that we close the used resources\n            finally\n            {\n                if(it != null) it.releaseDbResources();\n            }\n        }\n        return result;\n    }", "label": 0}
{"code": "def disconnect!(wait=false)\n      begin\n        # For backwards compatibility we disconnect/clear the pool rather\n        # than close it here.\n        pool.disconnect!\n      rescue Error::PoolClosedError\n        # If the pool was already closed, we don't need to do anything here.\n      end\n      monitor.stop!(wait)\n      @connected = false\n      true\n    end", "label": 4}
{"code": "function() {\n    if (Ember.Freezable && Ember.Freezable.detect(this)) {\n      return get(this, 'isFrozen') ? this : this.copy().freeze();\n    } else {\n      throw new Error(Ember.String.fmt(\"%@ does not support freezing\", [this]));\n    }\n  }", "label": 3}
{"code": "public static scpolicy[] get(nitro_service service) throws Exception{\n\t\tscpolicy obj = new scpolicy();\n\t\tscpolicy[] response = (scpolicy[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def stop_old_tasks\n      # only works when deployment is blocking\n      return unless @options[:wait]\n\n      Thread.new do\n        stop = Ufo::Stop.new(@service, @options.merge(mute: true))\n        while true\n          stop.log \"checking for old tasks and waiting for 10 seconds\"\n          stop.run\n          sleep 10\n        end\n      end\n    end", "label": 4}
{"code": "def classify_name(filename)\n      filename.to_s.split(\"_\").map{ |i| i[0...1].upcase + i[1..-1] }.join\n    end", "label": 4}
{"code": "function(models, copy) {\n      _.each(models, function(instance, alias) {\n        this.trackModel(alias, instance, copy);\n      }, this);\n    }", "label": 3}
{"code": "def pair_distance_centile(X, centile, max_pairs=5000):\n    \"\"\"\n    Calculate centiles of distances between random pairs in a dataset.\n\n    This an alternative to the median kNN distance for setting the kernel\n    length scale.\n    \"\"\"\n    N = X.shape[0]\n    n_pairs = min(max_pairs, N**2)\n    # randorder1 = np.random.permutation(N)\n    # randorder2 = np.random.permutation(N)\n\n    dists = np.zeros(n_pairs)\n\n    for i in range(n_pairs):\n        pair = np.random.randint(0, N, 2)\n        pairdiff = X[pair[0], :]-X[pair[1], :]\n        dists[i] = np.dot(pairdiff, pairdiff.T)\n    dists.sort()\n\n    out = dists[int(n_pairs*centile/100.)]\n    return np.sqrt(out)", "label": 1}
{"code": "public function get($fieldPath)\n    {\n        $res = null;\n\n        if (is_string($fieldPath)) {\n            $parts = explode('.', $fieldPath);\n        } elseif ($fieldPath instanceof FieldPath) {\n            $parts = $fieldPath->path();\n        } else {\n            throw new \\InvalidArgumentException('Given path was not a string or instance of FieldPath.');\n        }\n\n        $len = count($parts);\n\n        $fields = $this->data;\n        foreach ($parts as $idx => $part) {\n            if ($idx === $len-1 && isset($fields[$part])) {\n                $res = $fields[$part];\n                break;\n            } else {\n                if (!isset($fields[$part])) {\n                    throw new \\InvalidArgumentException(sprintf(\n                        'Field path `%s` does not exist.',\n                        $fieldPath\n                    ));\n                }\n\n                $fields = $fields[$part];\n            }\n        }\n\n        return $res;\n    }", "label": 2}
{"code": "func PgTsTemplateByTmplnameTmplnamespace(db XODB, tmplname pgtypes.Name, tmplnamespace pgtypes.Oid) (*PgTsTemplate, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, tmplname, tmplnamespace, tmplinit, tmpllexize ` +\n\t\t`FROM pg_catalog.pg_ts_template ` +\n\t\t`WHERE tmplname = $1 AND tmplnamespace = $2`\n\n\t// run query\n\tXOLog(sqlstr, tmplname, tmplnamespace)\n\tptt := PgTsTemplate{}\n\n\terr = db.QueryRow(sqlstr, tmplname, tmplnamespace).Scan(&ptt.Tableoid, &ptt.Cmax, &ptt.Xmax, &ptt.Cmin, &ptt.Xmin, &ptt.Oid, &ptt.Ctid, &ptt.Tmplname, &ptt.Tmplnamespace, &ptt.Tmplinit, &ptt.Tmpllexize)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ptt, nil\n}", "label": 5}
{"code": "def drain_into(result)\n      return if result.is_a?(Discordrb::Message)\n\n      result = (@saved_message.nil? ? '' : @saved_message.to_s) + (result.nil? ? '' : result.to_s)\n      drain\n      result\n    end", "label": 4}
{"code": "function finished(err) {\n    if (err) self.critical('Failed to store %s. %s.', base, err.message);\n    if (fn) fn(err, collection);\n  }", "label": 3}
{"code": "def auto_range(direction)\n      prev_line = processor.prev_line\n\n      if direction == \"=\" || prev_line.nil?\n        source_file_formatter.range_around(frame.line)\n      else\n        source_file_formatter.range_from(move(prev_line, size, direction))\n      end\n    end", "label": 4}
{"code": "function getDatabase() {\n    var mongoAdapter = this;\n\n    expect(arguments).to.have.length(\n      0,\n      'Invalid arguments length when getting a database in a MongoAdapter ' +\n      '(it has to be passed no arguments)'\n    );\n\n    return new Promise(function (resolve, reject) {\n      if (_databaseIsLocked || !_database) {\n        mongoAdapter\n          .openConnection()\n          .then(function () {\n            resolve(_database);\n          })\n          .catch(reject);\n      } else {\n        resolve(_database);\n      }\n    });\n  }", "label": 3}
{"code": "protected function getStatusResponse()\n    {\n        $request = new Request(\n            'PUT',\n            $this->resumeUri,\n            ['Content-Range' => 'bytes */*']\n        );\n\n        return $this->requestWrapper->send($request, $this->requestOptions);\n    }", "label": 2}
{"code": "private function imbTables($n, $size)\n\t{\n\t\t$table = [];\n\t\t$lli = 0; // LUT lower index\n\t\t$lui = $size - 1; // LUT upper index\n\t\tfor ($count = 0; $count < 8192; ++$count) {\n\n\t\t\t$bitCount = 0;\n\t\t\tfor ($bit_index = 0; $bit_index < 13; ++$bit_index) {\n\t\t\t\t$bitCount += (int) (($count & (1 << $bit_index)) != 0);\n\t\t\t}\n\n\t\t\t// if we don't have the right number of bits on, go on to the next value\n\t\t\tif ($bitCount == $n) {\n\t\t\t\t$reverse = ($this->imbReverseUs($count) >> 3);\n\t\t\t\t// if the reverse is less than count, we have already visited this pair before\n\t\t\t\tif ($reverse >= $count) {\n\t\t\t\t\t// If count is symmetric, place it at the first free slot from the end of the list.\n\t\t\t\t\t// Otherwise, place it at the first free slot from the beginning of the list AND place $reverse ath the next free slot from the beginning of the list\n\t\t\t\t\tif ($reverse == $count) {\n\t\t\t\t\t\t$table[$lui] = $count;\n\t\t\t\t\t\t--$lui;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t$table[$lli] = $count;\n\t\t\t\t\t\t++$lli;\n\t\t\t\t\t\t$table[$lli] = $reverse;\n\t\t\t\t\t\t++$lli;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn $table;\n\t}", "label": 2}
{"code": "public void unlinkFK(Object targetObject, ClassDescriptor cld, ObjectReferenceDescriptor rds)\n    {\n        setFKField(targetObject, cld, rds, null);\n    }", "label": 0}
{"code": "def map_args(args, scope, undef_value)\n    args.map {|a| convert(a, scope, undef_value) }\n  end", "label": 4}
{"code": "def old_attributes\n      (audited_changes || {}).inject({}.with_indifferent_access) do |attrs, (attr, values)|\n        attrs[attr] = Array(values).first\n\n        attrs\n      end\n    end", "label": 4}
{"code": "def fixed length, options = {}\n      options[:zero] = true if options[:zero].nil?\n      NationalSplitters::Fixed.instance_for length, options\n    end", "label": 4}
{"code": "func (ve ValidationErrors) Error() string {\n\n\tbuff := bytes.NewBufferString(\"\")\n\n\tvar fe *fieldError\n\n\tfor i := 0; i < len(ve); i++ {\n\n\t\tfe = ve[i].(*fieldError)\n\t\tbuff.WriteString(fe.Error())\n\t\tbuff.WriteString(\"\\n\")\n\t}\n\n\treturn strings.TrimSpace(buff.String())\n}", "label": 5}
{"code": "protected static function intervalHasTime(DateInterval $interval)\n    {\n        // The array_key_exists and get_object_vars are used as a workaround to check microsecond support.\n        // Both isset and property_exists will fail on PHP 7.0.14 - 7.0.21 due to the following bug:\n        // https://bugs.php.net/bug.php?id=74852\n        return $interval->h || $interval->i || $interval->s || array_key_exists('f', get_object_vars($interval)) && $interval->f;\n    }", "label": 2}
{"code": "function getRouteInfo(appName, urlRequest, query, lang, user, referrer) {\n\n    var activeUser = user ? {\n        _id: user._id,\n        name: user.username,\n        role: user.role,\n        user: user\n    } : {};\n\n    // if route info already in cache, return it\n    var cacheKey = appName + '||' + lang + '||' + urlRequest;\n    var cachedRouteInfo = routeInfoCache[cacheKey];\n    if (!user && cachedRouteInfo) {\n        cachedRouteInfo.query = query;  // query shouldn't be cached\n        return cachedRouteInfo;\n    }\n\n    // if urlRequest ends in .html it is an amp request so treat it as such\n    var isAmp = /\\.html$/.test(urlRequest);\n    if (isAmp) {\n        urlRequest = urlRequest.substring(0, urlRequest.length - 5);\n    }\n\n    // get the routes and then find the info that matches the current URL\n    var url = urlRequest.toLowerCase();\n    var i, route, routeInfo;\n    var routes = getRoutes(appName);\n    if (routes) {\n        // loop through routes trying to find the one that matches\n        for (i = 0; i < routes.length; i++) {\n            route = routes[i];\n            // if there is a match, save the info to cache and return it\n            if (route.urlRegex.test(url)) {\n                routeInfo = _.extend({\n                    appName:    appName,\n                    referrer:   referrer,\n                    lang:       lang,\n                    url:        urlRequest,\n                    query:      query,\n                    activeUser: activeUser,\n                    isAmp:      isAmp,\n                    tokens:     getTokenValuesFromUrl(route.urlPattern, urlRequest)\n                }, route);\n\n                // change layout wrapper to amp if request is for amp\n                if (isAmp) {\n                    routeInfo.wrapper = 'amp';\n                }\n\n                // if no user, then save request in cache\n                if (!user) {\n                    routeInfoCache[cacheKey] = routeInfo;\n                }\n\n                return routeInfo;\n            }\n        }\n    }\n\n    // if we get here, then no route found, so throw 404 error\n    throw new Error('404: ' + appName + ' ' + urlRequest + ' is not a valid request');\n}", "label": 3}
{"code": "public function setIpAllocationPolicy($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\IPAllocationPolicy::class);\n        $this->ip_allocation_policy = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private void ensureFields(ClassDescriptorDef classDef, Collection fields) throws ConstraintException\r\n    {\r\n        boolean forceVirtual = !classDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_GENERATE_REPOSITORY_INFO, true);\r\n\r\n        for (Iterator it = fields.iterator(); it.hasNext();)\r\n        {\r\n            FieldDescriptorDef fieldDef = (FieldDescriptorDef)it.next();\r\n\r\n            // First we check whether this field is already present in the class\r\n            FieldDescriptorDef foundFieldDef = classDef.getField(fieldDef.getName());\r\n\r\n            if (foundFieldDef != null)\r\n            {\r\n                if (isEqual(fieldDef, foundFieldDef))\r\n                {\r\n                    if (forceVirtual)\r\n                    {\r\n                        foundFieldDef.setProperty(PropertyHelper.OJB_PROPERTY_VIRTUAL_FIELD, \"true\");\r\n                    }\r\n                    continue;\r\n                }\r\n                else\r\n                {\r\n                    throw new ConstraintException(\"Cannot pull up the declaration of the required field \"+fieldDef.getName()+\r\n                            \" from type \"+fieldDef.getOwner().getName()+\" to basetype \"+classDef.getName()+\r\n                            \" because there is already a different field of the same name\");\r\n                }\r\n            }\r\n\r\n            // perhaps a reference or collection ?\r\n            if (classDef.getCollection(fieldDef.getName()) != null)\r\n            {\r\n                throw new ConstraintException(\"Cannot pull up the declaration of the required field \"+fieldDef.getName()+\r\n                                              \" from type \"+fieldDef.getOwner().getName()+\" to basetype \"+classDef.getName()+\r\n                                              \" because there is already a collection of the same name\");\r\n            }\r\n            if (classDef.getReference(fieldDef.getName()) != null)\r\n            {\r\n                throw new ConstraintException(\"Cannot pull up the declaration of the required field \"+fieldDef.getName()+\r\n                                              \" from type \"+fieldDef.getOwner().getName()+\" to basetype \"+classDef.getName()+\r\n                                              \" because there is already a reference of the same name\");\r\n            }\r\n            classDef.addFieldClone(fieldDef);\r\n            classDef.getField(fieldDef.getName()).setProperty(PropertyHelper.OJB_PROPERTY_VIRTUAL_FIELD, \"true\");\r\n        }\r\n    }", "label": 0}
{"code": "func (info *ImageInfoType) Width() float64 {\n\treturn info.w / (info.scale * info.dpi / 72)\n}", "label": 5}
{"code": "public function create($document, array $fields, array $options = [])\n    {\n        // Record whether the document is empty before any filtering.\n        $emptyDocument = count($fields) === 0;\n\n        list ($fields, $sentinels, $metadata) = $this->filterFields($fields);\n\n        if ($metadata['hasDelete']) {\n            throw new \\InvalidArgumentException('Cannot delete fields when creating a document.');\n        }\n\n        // Cannot create a document that already exists!\n        $precondition = ['exists' => false];\n\n        // Enqueue an update operation if an empty document was provided,\n        // or if there are still fields after filtering.\n        $transformOptions = [];\n        if (!empty($fields) || $emptyDocument) {\n            $this->writes[] = $this->createDatabaseWrite(self::TYPE_UPDATE, $document, [\n                'fields' => $this->valueMapper->encodeValues($fields),\n                'precondition' => $precondition\n            ] + $options);\n        } else {\n            // If no UPDATE mutation is enqueued, we need the precondition applied\n            // to the transform mutation.\n            $transformOptions = [\n                'precondition' => $precondition\n            ];\n        }\n\n        // document transform operations are enqueued as a separate mutation.\n        $this->enqueueTransforms($document, $sentinels, $transformOptions);\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, nsrpcnode resource) throws Exception {\n\t\tnsrpcnode updateresource = new nsrpcnode();\n\t\tupdateresource.ipaddress = resource.ipaddress;\n\t\tupdateresource.password = resource.password;\n\t\tupdateresource.srcip = resource.srcip;\n\t\tupdateresource.secure = resource.secure;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function update(array $metadata, array $options = [])\n    {\n        $options = $this->applyEtagHeader(\n            $options\n            + $metadata\n            + $this->identity\n        );\n\n        if (!isset($options['etag']) && !isset($options['retries'])) {\n            $options['retries'] = 0;\n        }\n\n        return $this->info = $this->connection->patchTable($options);\n    }", "label": 2}
{"code": "def find_and_setup_xcode_project(ask_for_scheme: true)\n      UI.message(\"Parsing your local Xcode project to find the available schemes and the app identifier\")\n      config = {} # this is needed as the first method call will store information in there\n      if self.project_path.end_with?(\"xcworkspace\")\n        config[:workspace] = self.project_path\n      else\n        config[:project] = self.project_path\n      end\n\n      FastlaneCore::Project.detect_projects(config)\n      self.project = FastlaneCore::Project.new(config)\n\n      if ask_for_scheme\n        self.scheme = self.project.select_scheme(preferred_to_include: self.project.project_name)\n      end\n\n      self.app_identifier = self.project.default_app_identifier # These two vars need to be accessed in order to be set\n      if self.app_identifier.to_s.length == 0\n        ask_for_bundle_identifier\n      end\n    end", "label": 4}
{"code": "def format_csv(self, delim=',', qu='\"'):\n        \"\"\"\n        Prepares the data in CSV format\n        \"\"\"\n        res = qu + self.name + qu + delim\n        if self.data:\n            for d in self.data:\n                res += qu + str(d) + qu + delim\n        return res + '\\n'", "label": 1}
{"code": "func assembleService(attrs []syscall.NetlinkRouteAttr) (*Service, error) {\n\n\tvar s Service\n\n\tfor _, attr := range attrs {\n\n\t\tattrType := int(attr.Attr.Type)\n\n\t\tswitch attrType {\n\n\t\tcase ipvsSvcAttrAddressFamily:\n\t\t\ts.AddressFamily = native.Uint16(attr.Value)\n\t\tcase ipvsSvcAttrProtocol:\n\t\t\ts.Protocol = native.Uint16(attr.Value)\n\t\tcase ipvsSvcAttrAddress:\n\t\t\tip, err := parseIP(attr.Value, s.AddressFamily)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\ts.Address = ip\n\t\tcase ipvsSvcAttrPort:\n\t\t\ts.Port = binary.BigEndian.Uint16(attr.Value)\n\t\tcase ipvsSvcAttrFWMark:\n\t\t\ts.FWMark = native.Uint32(attr.Value)\n\t\tcase ipvsSvcAttrSchedName:\n\t\t\ts.SchedName = nl.BytesToString(attr.Value)\n\t\tcase ipvsSvcAttrFlags:\n\t\t\ts.Flags = native.Uint32(attr.Value)\n\t\tcase ipvsSvcAttrTimeout:\n\t\t\ts.Timeout = native.Uint32(attr.Value)\n\t\tcase ipvsSvcAttrNetmask:\n\t\t\ts.Netmask = native.Uint32(attr.Value)\n\t\tcase ipvsSvcAttrStats:\n\t\t\tstats, err := assembleStats(attr.Value)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\ts.Stats = stats\n\t\t}\n\n\t}\n\treturn &s, nil\n}", "label": 5}
{"code": "function RedisPool(opts) {\n\n    if (!(this instanceof RedisPool)) {\n        return new RedisPool(opts);\n    }\n\n    EventEmitter.call(this);\n\n    opts = opts || {};\n    var defaults = {\n        host: '127.0.0.1',\n        port: '6379',\n        max: 50,\n        idleTimeoutMillis: 10000,\n        reapIntervalMillis: 1000,\n        noReadyCheck: false,\n        returnToHead: false,\n        unwatchOnRelease: true,\n        name: 'default',\n        log: false,\n        slowPool: {\n            log: false,\n            elapsedThreshold: 25\n        },\n        emitter: {\n            statusInterval: 60000\n        },\n        commands: []\n    };\n\n    this.options = _.defaults(opts, defaults);\n    this.pools = {};\n    this.elapsedThreshold = this.options.slowPool.elapsedThreshold;\n\n    // add custom Redis commands\n    if (this.options.commands && this.options.commands.length) {\n        this.options.commands.forEach(function(newCommand) {\n            redis.add_command(newCommand);\n        });\n    }\n\n    var self = this;\n    setInterval(function() {\n        Object.keys(self.pools).forEach(function(poolKey) {\n            var pool = self.pools[poolKey];\n            self.emit('status', {\n                name: self.options.name,\n                db: poolKey,\n                count: pool.getPoolSize(),\n                unused: pool.availableObjectsCount(),\n                waiting:  pool.waitingClientsCount()\n            });\n        });\n    }, this.options.emitter.statusInterval);\n}", "label": 3}
{"code": "def rej(vec, vec_onto):\n    \"\"\" Vector rejection.\n\n    Calculated by subtracting from `vec` the projection of `vec` onto\n    `vec_onto`:\n\n    .. math::\n\n        \\\\mathsf{vec} - \\\\mathrm{proj}\\\\left(\\\\mathsf{vec},\n        \\\\ \\\\mathsf{vec\\\\_onto}\\\\right)\n\n    Parameters\n    ----------\n    vec\n        length-R |npfloat_| --\n        Vector to reject\n\n    vec_onto\n        length-R |npfloat_| --\n        Vector onto which `vec` is to be rejected\n\n    Returns\n    -------\n    rej_vec\n        length-R |npfloat_| --\n        Rejection of `vec` onto `vec_onto`\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Calculate and return.\n    rej_vec = vec - proj(vec, vec_onto)\n    return rej_vec", "label": 1}
{"code": "public static base_response unset(nitro_service client, gslbsite resource, String[] args) throws Exception{\n\t\tgslbsite unsetresource = new gslbsite();\n\t\tunsetresource.sitename = resource.sitename;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function(model, cascade, options)\n  {\n    var db = this;\n\n    if ( model.$isDeleted() )\n    {\n      Rekord.debug( Rekord.Debugs.SAVE_DELETED, db, model );\n\n      return;\n    }\n\n    var key = model.$key();\n    var existing = db.models.has( key );\n\n    if ( existing )\n    {\n      db.trigger( Database.Events.ModelUpdated, [model] );\n\n      model.$trigger( Model.Events.UpdateAndSave );\n    }\n    else\n    {\n      db.saveReference( model, key );\n      db.trigger( Database.Events.ModelAdded, [model] );\n      db.updated();\n\n      model.$trigger( Model.Events.CreateAndSave );\n    }\n\n    model.$addOperation( SaveLocal, cascade, options );\n  }", "label": 3}
{"code": "function isOffsetsInSync(notIncrementedTopicPayloads, zookeeperOffsets, kafkaOffsetDiffThreshold, logger) {\n    logger.trace('Monitor Offset: Topics offsets', zookeeperOffsets);\n    let lastErrorToHealthCheck;\n    notIncrementedTopicPayloads.forEach(function (topicPayload) {\n        let {topic, partition, offset} = topicPayload;\n        if (zookeeperOffsets && zookeeperOffsets[topic] && zookeeperOffsets[topic][partition]) {\n            let zkLatestOffset = zookeeperOffsets[topic][partition][0];\n            let unhandledMessages = zkLatestOffset - offset;\n            if (unhandledMessages > kafkaOffsetDiffThreshold) {\n                let state = {\n                    topic: topic,\n                    partition: partition,\n                    partitionLatestOffset: zkLatestOffset,\n                    partitionReadOffset: offset,\n                    unhandledMessages: unhandledMessages\n                };\n\n                logger.error('Monitor Offset: Kafka consumer offsets found to be out of sync', state);\n                lastErrorToHealthCheck = new Error('Monitor Offset: Kafka consumer offsets found to be out of sync:' + JSON.stringify(state));\n            }\n        } else {\n            logger.error('Monitor Offset: Kafka consumer topics/partitions found to be out of sync in topic: ' + topic + ' and in partition:' + partition);\n            lastErrorToHealthCheck = new Error('Monitor Offset: Kafka consumer topics/partitions found to be out of sync in topic: ' + topic + ' and in partition:' + partition);\n        }\n    });\n\n    return lastErrorToHealthCheck;\n}", "label": 3}
{"code": "def fq_merge(R1, R2):\n    \"\"\"\n    merge separate fastq files\n    \"\"\"\n    c = itertools.cycle([1, 2, 3, 4])\n    for r1, r2 in zip(R1, R2):\n        n = next(c)\n        if n == 1:\n            pair = [[], []]\n        pair[0].append(r1.strip())\n        pair[1].append(r2.strip())\n        if n == 4:\n            yield pair", "label": 1}
{"code": "def read_config_info(ini_file):\n    \"\"\"\n    Read the INI file\n\n    Args:\n        ini_file - path to the file\n\n    Returns:\n        A dictionary of stuff from the INI file\n\n    Exits:\n        1 - if problems are encountered\n    \"\"\"\n    try:\n        config = RawConfigParser()\n        config.optionxform = lambda option: option\n        config.read(ini_file)\n        the_stuff = {}\n        for section in config.sections():\n            the_stuff[section] = {}\n            for option in config.options(section):\n                the_stuff[section][option] = config.get(section, option)\n\n        return the_stuff\n    except Exception as wtf:\n        logging.error('Exception caught in read_config_info(): {}'.format(wtf))\n        traceback.print_exc(file=sys.stdout)\n        return sys.exit(1)", "label": 1}
{"code": "public static base_response save(nitro_service client, cachecontentgroup resource) throws Exception {\n\t\tcachecontentgroup saveresource = new cachecontentgroup();\n\t\tsaveresource.name = resource.name;\n\t\treturn saveresource.perform_operation(client,\"save\");\n\t}", "label": 0}
{"code": "def load(self, value):\n        \"\"\"Load a value, converting it to the proper type if validation_type exists.\"\"\"\n        if self.property_type is None:\n            return value\n        elif not isinstance(self.property_type, BaseType):\n            raise TypeError('property_type must be schematics BaseType')\n        else:\n            native_value = self.property_type.to_native(value)\n            self.property_type.validate(native_value)\n            return native_value", "label": 1}
{"code": "function _nodeToXml (node, wrapped) {\n        var\n            name = node.localName(),\n            attributes = node.attributes(),\n            children = node.children(),\n            text = node.textContent(),\n            idx;\n        wrapped.startElement({\n            uri: \"\",\n            localName: name,\n            qName: name\n        }, attributes);\n        // Today the XmlConstNode may not have both children and textual content\n        if (text) {\n            wrapped.characters(text);\n        } else {\n            for (idx = 0; idx < children.length; ++idx) {\n                _nodeToXml(children[idx], wrapped);\n            }\n        }\n        wrapped.endElement();\n    }", "label": 3}
{"code": "private void registerSynchronization(TransactionImpl odmgTrans, Transaction transaction)\r\n    {\r\n        // todo only need for development\r\n        if (odmgTrans == null || transaction == null)\r\n        {\r\n            log.error(\"One of the given parameters was null --> cannot do synchronization!\" +\r\n                    \" omdg transaction was null: \" + (odmgTrans == null) +\r\n                    \", external transaction was null: \" + (transaction == null));\r\n            return;\r\n        }\r\n\r\n        int status = -1; // default status.\r\n        try\r\n        {\r\n            status = transaction.getStatus();\r\n            if (status != Status.STATUS_ACTIVE)\r\n            {\r\n                throw new OJBRuntimeException(\r\n                        \"Transaction synchronization failed - wrong status of external container tx: \" +\r\n                        getStatusString(status));\r\n            }\r\n        }\r\n        catch (SystemException e)\r\n        {\r\n            throw new OJBRuntimeException(\"Can't read status of external tx\", e);\r\n        }\r\n\r\n        try\r\n        {\r\n            //Sequence of the following method calls is significant\r\n            // 1. register the synchronization with the ODMG notion of a transaction.\r\n            transaction.registerSynchronization((J2EETransactionImpl) odmgTrans);\r\n            // 2. mark the ODMG transaction as being in a JTA Transaction\r\n            // Associate external transaction with the odmg transaction.\r\n            txRepository.set(new TxBuffer(odmgTrans, transaction));\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            log.error(\"Cannot associate PersistenceBroker with running Transaction\", e);\r\n            throw new OJBRuntimeException(\r\n                    \"Transaction synchronization failed - wrong status of external container tx\", e);\r\n        }\r\n    }", "label": 0}
{"code": "function parseResponse(cb) {\n  return function parse(err, response, body) {\n    // TODO Handel the errors\n    cb(err, JSON.parse(body))\n  }\n}", "label": 3}
{"code": "def process(self, stage):\n        \"\"\"Processing one stage.\"\"\"\n        self.logger.info(\"Processing pipeline stage '%s'\", self.title)\n        output = []\n        for entry in stage:\n            key = list(entry.keys())[0]\n            if key == \"env\":\n                self.pipeline.data.env_list[1].update(entry[key])\n                self.logger.debug(\"Updating environment at level 1 with %s\",\n                                  self.pipeline.data.env_list[1])\n                continue\n\n            # if not \"env\" then it must be \"tasks\" (schema):\n            tasks = Tasks(self.pipeline, re.match(r\"tasks\\(parallel\\)\", key) is not None)\n            result = tasks.process(entry[key])\n            for line in result['output']:\n                output.append(line)\n            if not result['success']:\n                self.event.failed()\n                return {'success': False, 'output': output}\n\n        self.event.succeeded()\n        return {'success': True, 'output': output}", "label": 1}
{"code": "public function setClusters($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dataproc\\V1\\Cluster::class);\n        $this->clusters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def foreign_key_value(obj, relation, was = false)\n      relation = relation.is_a?(Enumerable) ? relation.dup : [relation]\n      first_relation = relation.first\n      if was\n        first = relation.shift\n        foreign_key_value = attribute_was(obj, relation_foreign_key(first))\n        klass = relation_klass(first, source: obj, was: was)\n        if foreign_key_value\n          value = klass.where(\n            \"#{klass.table_name}.#{relation_primary_key(first, source: obj, was: was)} = ?\",\n            foreign_key_value).first\n        end\n      else\n        value = obj\n      end\n      while !value.nil? && relation.size > 0\n        value = value.send(relation.shift)\n      end\n      return value.try(relation_primary_key(first_relation, source: obj, was: was).try(:to_sym))\n    end", "label": 4}
{"code": "public boolean unlink(D declaration, ServiceReference<S> declarationBinderRef) {\n        S declarationBinder = bindersManager.getDeclarationBinder(declarationBinderRef);\n        try {\n            declarationBinder.removeDeclaration(declaration);\n        } catch (BinderException e) {\n            LOG.debug(declarationBinder + \" throw an exception when removing of it the Declaration \"\n                    + declaration, e);\n            declaration.unhandle(declarationBinderRef);\n            return false;\n        } finally {\n            declaration.unbind(declarationBinderRef);\n        }\n        return true;\n    }", "label": 0}
{"code": "def reset(self):\n        \"\"\"Reset metric counter.\"\"\"\n        self._positions = []\n        self._line = 1\n        self._curr = None  # current scope we are analyzing\n        self._scope = 0\n        self.language = None", "label": 1}
{"code": "public static boolean zipFolder(File folder, String fileName){\n\t\tboolean success = false;\n\t\tif(!folder.isDirectory()){\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\tif(fileName == null){\n\t\t\tfileName = folder.getAbsolutePath()+ZIP_EXT;\n\t\t}\n\t\t\n\t\tZipArchiveOutputStream zipOutput = null;\n\t\ttry {\n\t\t\tzipOutput = new ZipArchiveOutputStream(new File(fileName));\n\t\t\t\n\t\t\tsuccess = addFolderContentToZip(folder,zipOutput,\"\");\n\n\t\t\tzipOutput.close();\n\t\t\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t\treturn false;\n\t\t}\n\t\tfinally{\n\t\t\ttry {\n\t\t\t\tif(zipOutput != null){\n\t\t\t\t\tzipOutput.close();\n\t\t\t\t}\n\t\t\t} catch (IOException e) {}\n\t\t}\n\t\treturn success;\n\t}", "label": 0}
{"code": "def fqname_to_id(self, fq_name, type):\n        \"\"\"\n        Return uuid for fq_name\n\n        :param fq_name: resource fq name\n        :type fq_name: FQName\n        :param type: resource type\n        :type type: str\n\n        :rtype: UUIDv4 str\n        :raises HttpError: fq_name not found\n        \"\"\"\n        data = {\n            \"type\": type,\n            \"fq_name\": list(fq_name)\n        }\n        return self.post_json(self.make_url(\"/fqname-to-id\"), data)[\"uuid\"]", "label": 1}
{"code": "function unwrapReturns(ast, src, result) {\n  const charArray = src.split('');\n\n  const state = {\n    hasReturn: false,\n    source(node) {\n      return src.slice(node.start, node.end);\n    },\n    replace(node, str) {\n      charArray.fill('', node.start, node.end);\n      charArray[node.start] = str;\n    }\n  };\n\n  walk(ast, unwrapReturnsVisitors, state);\n\n  return {\n    before: state.hasReturn ? `var ${result} = ` : '',\n    body: charArray.join(''),\n    after: state.hasReturn ? `;if (${result}) return ${result}.value` : ''\n  };\n}", "label": 3}
{"code": "def sync(self, force=False, safe=True, revision=0, changelist=0):\n        \"\"\"Syncs the file at the current revision\n\n        :param force: Force the file to sync\n        :type force: bool\n        :param safe: Don't sync files that were changed outside perforce\n        :type safe: bool\n        :param revision: Sync to a specific revision\n        :type revision: int\n        :param changelist: Changelist to sync to\n        :type changelist: int\n        \"\"\"\n        cmd = ['sync']\n        if force:\n            cmd.append('-f')\n\n        if safe:\n            cmd.append('-s')\n\n        if revision:\n            cmd.append('{}#{}'.format(self.depotFile, revision))\n        elif changelist:\n            cmd.append('{}@{}'.format(self.depotFile, changelist))\n        else:\n            cmd.append(self.depotFile)\n\n        self._connection.run(cmd)\n\n        self.query()", "label": 1}
{"code": "def load_chunk(filename, bounds, encoding='utf8', slow=False):\n    \"\"\"\n    Load a chunk from file using Bounds info.\n    Pass 'slow=True' for an alternative loading method based on line numbers.\n    \"\"\"\n    if slow:\n        return _load_chunk_slow(filename, bounds, encoding)\n\n    with open(filename, 'rb') as f:\n        f.seek(bounds.byte_start)\n        size = bounds.byte_end - bounds.byte_start\n        return f.read(size).decode(encoding)", "label": 1}
{"code": "public function keepAlive(Session $session)\n    {\n        $this->config['lock']->synchronize(function () use ($session) {\n            $item = $this->cacheItemPool->getItem($this->cacheKey);\n            $data = $item->get();\n            $data['inUse'][$session->name()]['lastActive'] = $this->time();\n\n            $this->cacheItemPool->save($item->set($data));\n        });\n    }", "label": 2}
{"code": "def to_xml_string(str = '')\n      return if empty?\n      str << \"<bookViews>\"\n      each { |view| view.to_xml_string(str) }\n      str << '</bookViews>'\n    end", "label": 4}
{"code": "public function setCompanies($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\Company::class);\n        $this->companies = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func ValidateLockTTL(ttl time.Duration) error {\n\tif ttl == Forever || ttl > MaxLockDuration {\n\t\treturn trace.BadParameter(\"locks cannot exceed %v\", MaxLockDuration)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def save(self, fname=''):\n        \"\"\"\n        Save the list of items to AIKIF core and optionally to local file fname\n        \"\"\"\n        if fname != '':\n            with open(fname, 'w') as f:\n                for i in self.lstPrograms:\n                    f.write(self.get_file_info_line(i, ','))\n\n        \n        # save to standard AIKIF structure\n        \n        filemap = mod_filemap.FileMap([], [])\n        #location_fileList = filemap.get_full_filename(filemap.find_type('LOCATION'), filemap.find_ontology('FILE-PROGRAM')[0])     \n        object_fileList = filemap.get_full_filename(filemap.find_type('OBJECT'), filemap.find_ontology('FILE-PROGRAM')[0])      \n        print('object_fileList = ' + object_fileList + '\\n')\n        if os.path.exists(object_fileList):\n            os.remove(object_fileList)\n        self.lstPrograms.sort()\n\n        try:\n            with open(object_fileList, 'a') as f:\n                f.write('\\n'.join([i[0] for i in self.lstPrograms]))\n        except Exception as ex:\n            print('ERROR = cant write to object_filelist ' , object_fileList, str(ex))", "label": 1}
{"code": "function _storageFactory(type) {\n\tlet storage;\n\n\tif (type === 'local') {\n\t\tstorage = window.localStorage;\n\t} else if (type === 'session') {\n\t\tstorage = window.sessionStorage;\n\t}\n\n\treturn {\n\t\tgetItem(key) {\n\t\t\treturn JSON.parse(storage.getItem(key));\n\t\t},\n\t\tsetItem(key, value) {\n\t\t\tvalue = JSON.stringify(value);\n\n\t\t\treturn storage.setItem(key, value);\n\t\t},\n\t\tremoveItem(key) {\n\t\t\treturn storage.removeItem(key);\n\t\t}\n\t};\n}", "label": 3}
{"code": "protected function executeDeferred(): void\n    {\n        $this->result = app()->call(\n            [$this->graphQL, 'executeRequest']\n        );\n\n        $this->stream->stream(\n            $this->result,\n            $this->resolved,\n            empty($this->deferred)\n        );\n\n        $this->resolved = [];\n    }", "label": 2}
{"code": "def deserialize_json(cls, serialized_json):\n        '''Return a macaroon deserialized from a string\n        @param serialized_json The string to decode {str}\n        @return {Macaroon}\n        '''\n        serialized = json.loads(serialized_json)\n        return Macaroon.from_dict(serialized)", "label": 1}
{"code": "public boolean alsoShow(Object filter){\r\n    switch(this.defaultState){\r\n    case HIDE_ALL:\r\n      return this.deltaPool.add(filter);\r\n    case SHOW_ALL:\r\n      return this.deltaPool.remove(filter);\r\n    default:\r\n      throw new IllegalStateException(\"Unknown default state setting: \" + this.defaultState);\r\n    }\r\n  }", "label": 0}
{"code": "def friendly_created_at\n      current_datetime = Time.current\n\n      if created_at > current_datetime.beginning_of_day\n        I18n.l(created_at, format: :time_of_day)\n      elsif created_at > current_datetime.beginning_of_week\n        I18n.l(created_at, format: :day_of_week)\n      elsif created_at > current_datetime.beginning_of_year\n        I18n.l(created_at, format: :day_of_month)\n      else\n        I18n.l(created_at, format: :day_of_year)\n      end\n    end", "label": 4}
{"code": "func (ctx *Context) GetResource() (Resource, error) {\n\tif ctx.Resource == nil {\n\t\treturn nil, trace.NotFound(\"resource is not set in the context\")\n\t}\n\treturn ctx.Resource, nil\n}", "label": 5}
{"code": "def serialize_text(self):\n        '''Returns a serialized form of the Namepace.\n\n        All the elements in the namespace are sorted by\n        URI, joined to the associated prefix with a colon and\n        separated with spaces.\n        :return: bytes\n        '''\n        if self._uri_to_prefix is None or len(self._uri_to_prefix) == 0:\n            return b''\n        od = collections.OrderedDict(sorted(self._uri_to_prefix.items()))\n        data = []\n        for uri in od:\n            data.append(uri + ':' + od[uri])\n        return ' '.join(data).encode('utf-8')", "label": 1}
{"code": "public static String readUntilTag(Reader r) throws IOException {\r\n    if (!r.ready()) {\r\n      return \"\";\r\n    }\r\n    StringBuilder b = new StringBuilder();\r\n    int c = r.read();\r\n    while (c >= 0 && c != '<') {\r\n      b.append((char) c);\r\n      c = r.read();\r\n    }\r\n    return b.toString();\r\n  }", "label": 0}
{"code": "def delete(key)\n      @cache.delete(key)\n      File.delete(path_to(hash(key))) if disk_cache_enabled?\n    end", "label": 4}
{"code": "public static base_response reset(nitro_service client, sslfips resource) throws Exception {\n\t\tsslfips resetresource = new sslfips();\n\t\treturn resetresource.perform_operation(client,\"reset\");\n\t}", "label": 0}
{"code": "func (v *Validate) RegisterTranslation(tag string, trans ut.Translator, registerFn RegisterTranslationsFunc, translationFn TranslationFunc) (err error) {\n\n\tif v.transTagFunc == nil {\n\t\tv.transTagFunc = make(map[ut.Translator]map[string]TranslationFunc)\n\t}\n\n\tif err = registerFn(trans); err != nil {\n\t\treturn\n\t}\n\n\tm, ok := v.transTagFunc[trans]\n\tif !ok {\n\t\tm = make(map[string]TranslationFunc)\n\t\tv.transTagFunc[trans] = m\n\t}\n\n\tm[tag] = translationFn\n\n\treturn\n}", "label": 5}
{"code": "function parseJson(name, type, value) {\n    try {\n        return typeof value  === 'string' ?\n            JSON.parse(value) :\n            value;\n    } catch (e) {\n        throwError(name, type, value);\n    }\n}", "label": 3}
{"code": "private function getValue(string $key, $value = null)\n    {\n        if (! is_null($this->language)) {\n            $key = $this->language.'.'.$key;\n        }\n\n        if (! is_null($this->prefix)) {\n            $key = $this->prefix.'.'.$key;\n        }\n\n        $data = $this->data->getContent($key);\n\n        // default value\n        if (is_null($data)) {\n            return $value;\n        }\n\n        if ($value instanceof \\Closure) {\n            return $value($data, $this->data);\n        }\n\n        return $data;\n    }", "label": 2}
{"code": "def fetch_comments_async(prs)\n      threads = []\n\n      prs.each_slice(MAX_THREAD_NUMBER) do |prs_slice|\n        prs_slice.each do |pr|\n          threads << Thread.new do\n            pr[\"comments\"] = []\n            iterate_pages(@client, \"issue_comments\", pr[\"number\"]) do |new_comment|\n              pr[\"comments\"].concat(new_comment)\n            end\n            pr[\"comments\"] = pr[\"comments\"].map { |comment| stringify_keys_deep(comment.to_hash) }\n          end\n        end\n        threads.each(&:join)\n        threads = []\n      end\n      nil\n    end", "label": 4}
{"code": "public static nstimeout get(nitro_service service) throws Exception{\n\t\tnstimeout obj = new nstimeout();\n\t\tnstimeout[] response = (nstimeout[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def krai_from_raw(self, amount):\n        \"\"\"\n        Divide a raw amount down by the krai ratio.\n\n        :param amount: Amount in raw to convert to krai\n        :type amount: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.krai_from_raw(amount=1000000000000000000000000000)\n        1\n        \"\"\"\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('krai_from_raw', payload)\n\n        return int(resp['amount'])", "label": 1}
{"code": "function _gpfCreateAbstractFunction (numberOfParameters) {\n    return _gpfFunctionBuild({\n        parameters: _gpfBuildFunctionParameterList(numberOfParameters),\n        body: \"_throw_();\"\n    }, {\n        _throw_: gpf.Error.abstractMethod\n    });\n}", "label": 3}
{"code": "function loadFromFile(filename) {\n  var cfg = {}\n  Object.assign(\n    cfg,\n    loadDefault(),\n    JSON.parse(fs.readFileSync(filename))\n  )\n\n  return cfg\n}", "label": 3}
{"code": "func (s *server) UpdateSession(req UpdateRequest) error {\n\tif err := req.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tkey := activeKey(req.Namespace, string(req.ID))\n\n\t// Try several times, then give up\n\tfor i := 0; i < sessionUpdateAttempts; i++ {\n\t\titem, err := s.bk.Get(context.TODO(), key)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\n\t\tvar session Session\n\t\tif err := json.Unmarshal(item.Value, &session); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\n\t\tif req.TerminalParams != nil {\n\t\t\tsession.TerminalParams = *req.TerminalParams\n\t\t}\n\t\tif req.Active != nil {\n\t\t\tsession.Active = *req.Active\n\t\t}\n\t\tif req.Parties != nil {\n\t\t\tsession.Parties = *req.Parties\n\t\t}\n\t\tnewValue, err := json.Marshal(session)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\tnewItem := backend.Item{\n\t\t\tKey:     key,\n\t\t\tValue:   newValue,\n\t\t\tExpires: s.clock.Now().UTC().Add(s.activeSessionTTL),\n\t\t}\n\n\t\t_, err = s.bk.CompareAndSwap(context.TODO(), *item, newItem)\n\t\tif err != nil {\n\t\t\tif trace.IsCompareFailed(err) || trace.IsConnectionProblem(err) {\n\t\t\t\ts.clock.Sleep(sessionUpdateRetryPeriod)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn trace.Wrap(err)\n\t\t} else {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn trace.ConnectionProblem(nil, \"failed concurrently update the session\")\n}", "label": 5}
{"code": "def add_outermost_primitives(gc) #:nodoc:\n      add_transform_primitives(gc)\n      gc.push\n      add_viewbox_primitives(@width, @height, gc)\n      add_style_primitives(gc)\n      @content.each { |element| element.add_primitives(gc) }\n      gc.pop\n      self\n    end", "label": 4}
{"code": "public void setRoles(List<NamedRoleInfo> roles) {\n\t\tthis.roles = roles;\n\t\tList<AuthorizationInfo> authorizations = new ArrayList<AuthorizationInfo>();\n\t\tfor (NamedRoleInfo role : roles) {\n\t\t\tauthorizations.addAll(role.getAuthorizations());\n\t\t}\n\t\tsuper.setAuthorizations(authorizations);\n\t}", "label": 0}
{"code": "function getMongodbConnection(mongoDbUrl, logger, cb) {\n  logger.debug(\"creating mongodb connection for data_source_update job\", {mongoDbUrl: mongoDbUrl});\n  MongoClient.connect(mongoDbUrl, cb);\n}", "label": 3}
{"code": "def prune(amount, strict = false, &block)\n      raise ArgumentError, 'Can only delete between 1 and 100 messages!' unless amount.between?(1, 100)\n\n      messages =\n        if block_given?\n          history(amount).select(&block).map(&:id)\n        else\n          history_ids(amount)\n        end\n\n      case messages.size\n      when 0\n        0\n      when 1\n        API::Channel.delete_message(@bot.token, @id, messages.first)\n        1\n      else\n        bulk_delete(messages, strict)\n      end\n    end", "label": 4}
{"code": "def _dimension_data(self, buses, branches, generators):\n        \"\"\" Returns the problem dimensions.\n        \"\"\"\n        ipol = [i for i, g in enumerate(generators)\n                if g.pcost_model == POLYNOMIAL]\n        ipwl = [i for i, g in enumerate(generators)\n                if g.pcost_model == PW_LINEAR]\n        nb = len(buses)\n        nl = len(branches)\n        # Number of general cost vars, w.\n        nw = self.om.cost_N\n        # Number of piece-wise linear costs.\n        if \"y\" in [v.name for v in self.om.vars]:\n            ny = self.om.get_var_N(\"y\")\n        else:\n            ny = 0\n        # Total number of control variables of all types.\n        nxyz = self.om.var_N\n\n        return ipol, ipwl, nb, nl, nw, ny, nxyz", "label": 1}
{"code": "def get(name)\n      name = normalize_header name.to_s\n      @pile.select { |k, _| k == name }.map { |_, v| v }\n    end", "label": 4}
{"code": "def delete(self):\n        \"\"\" delete a file, don't really care if it doesn't exist \"\"\"\n        if self.fullname != \"\":\n            try:\n                os.remove(self.fullname)\n            except IOError:\n                print(\"Cant delete \",self.fullname)", "label": 1}
{"code": "protected function formatRedirectUrl(array $config)\n    {\n        $redirect = value($config['redirect']);\n\n        return Str::startsWith($redirect, '/')\n                    ? $this->app['url']->to($redirect)\n                    : $redirect;\n    }", "label": 2}
{"code": "function csv_parse(text) {\n        var header;\n        return csv_parseRows(text, function(row, i) {\n            if (i) {\n                var o = {}, j = -1, m = header.length;\n                while (++j < m) o[header[j]] = row[j];\n                return o;\n            } else {\n                header = row;\n                return null;\n            }\n        });\n    }", "label": 3}
{"code": "private Object readMetadataFromXML(InputSource source, Class target)\r\n            throws MalformedURLException, ParserConfigurationException, SAXException, IOException\r\n    {\r\n        // TODO: make this configurable\r\n        boolean validate = false;\r\n        \r\n        // get a xml reader instance:\r\n        SAXParserFactory factory = SAXParserFactory.newInstance();\r\n        log.info(\"RepositoryPersistor using SAXParserFactory : \" + factory.getClass().getName());\r\n        if (validate)\r\n        {\r\n            factory.setValidating(true);\r\n        }\r\n        SAXParser p = factory.newSAXParser();\r\n        XMLReader reader = p.getXMLReader();\r\n        if (validate)\r\n        {\r\n            reader.setErrorHandler(new OJBErrorHandler());\r\n        }\r\n\r\n        Object result;\r\n        if (DescriptorRepository.class.equals(target))\r\n        {\r\n            // create an empty repository:\r\n            DescriptorRepository repository = new DescriptorRepository();\r\n            // create handler for building the repository structure\r\n            ContentHandler handler = new RepositoryXmlHandler(repository);\r\n            // tell parser to use our handler:\r\n            reader.setContentHandler(handler);\r\n            reader.parse(source);\r\n            result = repository;\r\n        }\r\n        else if (ConnectionRepository.class.equals(target))\r\n        {\r\n            // create an empty repository:\r\n            ConnectionRepository repository = new ConnectionRepository();\r\n            // create handler for building the repository structure\r\n            ContentHandler handler = new ConnectionDescriptorXmlHandler(repository);\r\n            // tell parser to use our handler:\r\n            reader.setContentHandler(handler);\r\n            reader.parse(source);\r\n            //LoggerFactory.getBootLogger().info(\"loading XML took \" + (stop - start) + \" msecs\");\r\n            result = repository;\r\n        }\r\n        else\r\n            throw new MetadataException(\"Could not build a repository instance for '\" + target +\r\n                    \"', using source \" + source);\r\n        return result;\r\n    }", "label": 0}
{"code": "public function pathElement($kind, $identifier = null, array $options = [])\n    {\n        $options += [\n            'identifierType' => null\n        ];\n\n        if (!empty($this->path) && $this->state() !== Key::STATE_NAMED) {\n            throw new InvalidArgumentException(\n                'Cannot add pathElement because the previous element is missing an id or name'\n            );\n        }\n\n        $pathElement = $this->normalizeElement($kind, $identifier, $options['identifierType']);\n\n        $this->path[] = $pathElement;\n\n        return $this;\n    }", "label": 2}
{"code": "function(model) {\n      var allFields,\n        fieldsUsed = {},\n        modelFields = {},\n        modelConfigs = [];\n      _.each(this.__getAllModelConfigs(), function(modelConfig) {\n        if (modelConfig.model && modelConfig.model.cid === model.cid) {\n          modelConfigs.push(modelConfig);\n        }\n      });\n      allFields = _.reduce(modelConfigs, function(result, modelConfig) {\n        return result || !modelConfig.fields;\n      }, false);\n      if (allFields) {\n        modelFields = this.__cloneVal(model.attributes);\n      } else {\n        _.each(modelConfigs, function(modelConfig) {\n          _.each(modelConfig.fields, function(field) {\n            if (!fieldsUsed[field]) {\n              fieldsUsed[field] = true;\n              modelFields[field] = this.__cloneVal(model.get(field));\n            }\n          }, this);\n        }, this);\n      }\n      return modelFields;\n    }", "label": 3}
{"code": "public function updateSchema(array $classes, $saveMode = false)\n    {\n        $updateSchemaSql = $this->getUpdateSchemaSql($classes, $saveMode);\n        $conn            = $this->em->getConnection();\n\n        foreach ($updateSchemaSql as $sql) {\n            $conn->executeQuery($sql);\n        }\n    }", "label": 2}
{"code": "def mtx_rot(ax, theta, reps=1):\n    \"\"\" Generate block-diagonal rotation matrix about ax.\n\n    [copy handedness from somewhere]\n\n    .. todo:: Complete mtx_rot docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n    from ..const import PRM\n\n    # Ensure |ax| is large enough for confident directionality\n    if spla.norm(ax) < PRM.ZERO_VEC_TOL:\n        raise ValueError(\"Norm of 'ax' is too small.\")\n    ## end if\n\n    # Ensure ax is a normalized np.float64 3-vector\n    ax = make_nd_vec(ax, nd=3, t=np.float64, norm=True)\n\n    # Ensure reps is a positive scalar integer\n    if not np.isscalar(reps):\n        raise ValueError(\"'reps' must be scalar.\")\n    ## end if\n    if not np.issubdtype(type(reps), int):\n        raise ValueError(\"'reps' must be an integer.\")\n    ## end if\n    if not reps > 0:\n        raise ValueError(\"'reps' must be a positive integer.\")\n    ## end if\n\n    # Ensure theta is scalar\n    if not np.isscalar(theta):\n        raise ValueError(\"'theta' must be scalar.\")\n    ## end if\n\n    # Assemble the modified Levi-Civita matrix\n    mod_lc = np.array([ [0, -ax[2], ax[1]],\n                    [ax[2], 0, -ax[0]],\n                    [-ax[1], ax[0], 0] ], dtype=np.float64)\n\n    # Compute the outer product of the axis vector\n    ax_oprod = np.dot(ax.reshape((3,1)), ax.reshape((1,3)))\n\n    # Construct the base matrix\n    #  Will need to refer to external math to explain this.\n    base_mtx = np.add(\n                        np.add( (1.0 - np.cos(theta)) * ax_oprod,\n                                            np.cos(theta) * np.eye(3)\n                              ),\n                        np.sin(theta) * mod_lc\n                     )\n\n    # Construct the block-diagonal replicated reflection matrix\n    rot_mtx= spla.block_diag(*[base_mtx for i in range(reps)])\n\n    # Return the result\n    return rot_mtx", "label": 1}
{"code": "public static scpolicy get(nitro_service service, String name) throws Exception{\n\t\tscpolicy obj = new scpolicy();\n\t\tobj.set_name(name);\n\t\tscpolicy response = (scpolicy) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def build_menu(name = DEFAULT_MENU)\n      @menus.before_build do |menus|\n        menus.menu name do |menu|\n          yield menu\n        end\n      end\n    end", "label": 4}
{"code": "def to_tree_hash\n      hash = {}\n      objects_dictionary = {}\n      hash['objects']        =  objects_dictionary\n      hash['archiveVersion'] =  archive_version.to_s\n      hash['objectVersion']  =  object_version.to_s\n      hash['classes']        =  classes\n      hash['rootObject']     =  root_object.to_tree_hash\n      hash\n    end", "label": 4}
{"code": "def table(name=nil, options={}, &block)\n      if block_given?\n        if name.is_a?(Hash)\n          options = name\n        else\n          collection = name\n        end\n\n        table = Table::Builder.build(options, &block)\n      elsif name.is_a?(Trestle::Table)\n        table = name\n      else\n        table = admin.tables.fetch(name) { raise ArgumentError, \"Unable to find table named #{name.inspect}\" }\n      end\n\n      collection ||= options[:collection] || table.options[:collection]\n      collection = collection.call if collection.respond_to?(:call)\n\n      render \"trestle/table/table\", table: table, collection: collection\n    end", "label": 4}
{"code": "def add_column(col_id, filter_type, options = {})\n      columns << FilterColumn.new(col_id, filter_type, options)\n      columns.last\n    end", "label": 4}
{"code": "public function setRuns($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferRun::class);\n        $this->runs = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def walk_files_for(paths, supported_extensions):\n        \"\"\"\n        Iterating files for given extensions.\n\n        Args:\n            supported_extensions (list): supported file extentsion for which to check loc and com.\n\n        Returns:\n            str: yield each full path and filename found.\n        \"\"\"\n        for path in paths:\n            for root, _, files in os.walk(path):\n                if Application.ignore_path(root.replace(path, '')):\n                    continue\n\n                for filename in files:\n                    extension = os.path.splitext(filename)[1]\n                    if extension in supported_extensions:\n                        yield path, os.path.join(root, filename), extension", "label": 1}
{"code": "function list(connections, params, callback) {\n\n  logger.debug(\"Listing Data Sources\", params);\n\n  var currentTime = new Date(params.currentTime);\n  //If listing data sources needing a cache update, need to supply a valid date.\n  if (params.listDataSourcesNeedingUpdate && !params.currentTime && currentTime.toString() !== \"Invalid Date\") {\n    return callback(buildErrorResponse({error: new Error(\"An currentTime Date Object Is Required To List Data Sources Requiring Update\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n  }\n\n  async.waterfall([\n    function findDataSources(cb) {\n      var query = {};\n\n      lookUpDataSources(connections, {\n        query: query,\n        lean: true\n      }, function(err, dataSources) {\n        if (err) {\n          return cb(buildErrorResponse({\n            error: err,\n            userDetail: \"Unexpected Error When Searching For A Data Source\",\n            code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n          }));\n        }\n\n        logger.debug(\"Listing Data Sources\", {dataSources: dataSources});\n\n        //Only return Data Sources with a valid data source update time\n        if (params.listDataSourcesNeedingUpdate) {\n          dataSources = checkUpdateInterval(dataSources, currentTime);\n        }\n\n        logger.debug(\"Listing Data Sources\", {dataSourceAfterFilter: dataSources});\n\n        dataSources = _.map(dataSources, processDataSourceResponse);\n\n        return cb(undefined, dataSources);\n      });\n    },\n    function getFormsUsingDataSources(dataSources, cb) {\n      async.map(dataSources, function(dataSource, cb) {\n        checkFormsUsingDataSource(connections, dataSource, cb);\n      }, cb);\n    }\n  ], callback);\n}", "label": 3}
{"code": "func PgOpclassByOid(db XODB, oid pgtypes.Oid) (*PgOpclass, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, opcmethod, opcname, opcnamespace, opcowner, opcfamily, opcintype, opcdefault, opckeytype ` +\n\t\t`FROM pg_catalog.pg_opclass ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpo := PgOpclass{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&po.Tableoid, &po.Cmax, &po.Xmax, &po.Cmin, &po.Xmin, &po.Oid, &po.Ctid, &po.Opcmethod, &po.Opcname, &po.Opcnamespace, &po.Opcowner, &po.Opcfamily, &po.Opcintype, &po.Opcdefault, &po.Opckeytype)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &po, nil\n}", "label": 5}
{"code": "public static java.sql.Time rollTime(java.util.Date startDate, int period, int amount) {\n        GregorianCalendar gc = new GregorianCalendar();\n        gc.setTime(startDate);\n        gc.add(period, amount);\n        return new java.sql.Time(gc.getTime().getTime());\n    }", "label": 0}
{"code": "def quote_token( str )\n      if str.respond_to?(:force_encoding)\n        original_encoding = str.encoding\n        ascii_str = str.to_s.dup.force_encoding('ASCII-8BIT')\n        if token_safe?( ascii_str )\n          str\n        else\n          dquote(ascii_str).force_encoding(original_encoding)\n        end\n      else\n        token_safe?( str ) ? str : dquote(str)\n      end\n    end", "label": 4}
{"code": "public static rnat[] get(nitro_service service, options option) throws Exception{\n\t\trnat obj = new rnat();\n\t\trnat[] response = (rnat[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setMultiClusterRoutingUseAny($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\Admin\\V2\\AppProfile_MultiClusterRoutingUseAny::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "private function objectParam($value)\n    {\n        if ($value instanceof \\stdClass) {\n            throw new \\InvalidArgumentException(\n                'Values of type `\\stdClass` are interpreted as structs and must define their types.'\n            );\n        }\n\n        if ($value instanceof ValueInterface) {\n            return [\n                $this->typeObject($value->type()),\n                $value->formatAsString()\n            ];\n        }\n\n        if ($value instanceof Int64) {\n            return [\n                $this->typeObject(self::TYPE_INT64),\n                $value->get()\n            ];\n        }\n\n        throw new \\InvalidArgumentException(sprintf(\n            'Unrecognized value type %s. ' .\n            'Please ensure you are using the latest version of google/cloud or google/cloud-spanner.',\n            get_class($value)\n        ));\n    }", "label": 2}
{"code": "func (p *PTYReqParams) CheckAndSetDefaults() error {\n\tif p.W > maxSize || p.W < minSize {\n\t\tp.W = teleport.DefaultTerminalWidth\n\t}\n\tif p.H > maxSize || p.H < minSize {\n\t\tp.H = teleport.DefaultTerminalHeight\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static base_response delete(nitro_service client, application resource) throws Exception {\n\t\tapplication deleteresource = new application();\n\t\tdeleteresource.appname = resource.appname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "function measureTracerOverhead() {\n  var time1 = meaningfulTime();\n  var time2 = meaningfulTime();\n  console.error(\"TRACER OVERHEAD\", timeDiff(time2, time1).toFixed(2)+'ms', 'per timing');\n}", "label": 3}
{"code": "function () {\n        var waterline = this.injector.get('Services.Waterline');\n\n        return bluebird.all(\n            _.map(waterline, function (collection) {\n                if (typeof collection.destroy === 'function') {\n                    return bluebird.fromNode(collection.destroy.bind(collection)).then(function () {\n                        if (collection.adapterDictionary.define !== 'mongo') {\n                            return bluebird.fromNode(\n                                collection.adapter.define.bind(collection.adapter)\n                            );\n                        }\n                    });\n                }\n            })\n        );\n    }", "label": 3}
{"code": "function(text) {\n        return macros.cleanMacros(text.replace(/\\n/g, '{break}').replace(/<i>/g, '{italic}').replace(/<\\/i>/g, '{end-italic}'));\n    }", "label": 3}
{"code": "protected Method resolveTargetMethod(Message message,\n                                         FieldDescriptor payloadField) {\n        Method targetMethod = fieldToMethod.get(payloadField);\n\n        if (targetMethod == null) {\n            // look up and cache target method; this block is called only once\n            // per target method, so synchronized is ok\n            synchronized (this) {\n                targetMethod = fieldToMethod.get(payloadField);\n                if (targetMethod == null) {\n                    String name = payloadField.getName();\n                    for (Method method : service.getClass().getMethods()) {\n                        if (method.getName().equals(name)) {\n                            try {\n                                method.setAccessible(true);\n                            } catch (Exception ex) {\n                                log.log(Level.SEVERE,\"Error accessing RPC method\",ex);\n                            }\n\n                            targetMethod = method;\n                            fieldToMethod.put(payloadField, targetMethod);\n                            break;\n                        }\n                    }\n                }\n            }\n        }\n\n        if (targetMethod != null) {\n            return targetMethod;\n        } else {\n            throw new RuntimeException(\"No matching method found by the name '\"\n                    + payloadField.getName() + \"'\");\n        }\n    }", "label": 0}
{"code": "protected static function validateField($fieldObject)\n    {\n        $selectable = true;\n\n        // If not a selectable field\n        if(isset($fieldObject->config['selectable']) && $fieldObject->config['selectable'] === false)\n        {\n            $selectable = false;\n        }\n\n        if(isset($fieldObject->config['privacy']))\n        {\n            $privacyClass = $fieldObject->config['privacy'];\n\n            // If privacy given as a closure\n            if(is_callable($privacyClass) && call_user_func($privacyClass, self::$args) === false)\n            {\n                $selectable = null;\n            }\n            // If Privacy class given\n            elseif(is_string($privacyClass))\n            {\n                if(array_has(self::$privacyValidations, $privacyClass))\n                {\n                    $validated = self::$privacyValidations[$privacyClass];\n                }\n                else\n                {\n                    $validated = call_user_func([app($privacyClass), 'fire'], self::$args);\n                    self::$privacyValidations[$privacyClass] = $validated;\n                }\n\n                if( ! $validated)\n                {\n                    $selectable = null;\n                }\n            }\n        }\n\n        return $selectable;\n    }", "label": 2}
{"code": "function getValidationFunction (validationOptions) {\n        validationOptions = validationOptions || {};\n\n        return function (doc, schema, options) {\n            doc = doc || {};\n            options = options || {};\n            options.isUpdate = options.isUpdate || false;\n\n            // check is update\n            if (options.isUpdate) {\n                var i,\n                    keys = Object.keys(schema.properties),\n                    length = keys.length;\n\n                for (i = 0; i < length; i++) {\n                    if (!doc.hasOwnProperty(keys[i])) {\n                        // set property required to false\n                        schema.properties[keys[i]].required = false;\n\n                        // remove property from required array\n                        if (Array.isArray(schema.required) && schema.required.indexOf(keys[i]) > -1) {\n                            schema.required.splice(schema.required.indexOf(keys[i]), 1);\n                        }\n                    }\n                }\n            }\n\n            // add default validation options to options object\n            for (var key in validationOptions) {\n                // only add options, do not override\n                if (validationOptions.hasOwnProperty(key) && !options.hasOwnProperty(key)) {\n                    options[key] = validationOptions[key];\n                }\n            }\n\n            // json schema validate\n            return exports.validate(doc, schema, options);\n        };\n    }", "label": 3}
{"code": "public function setOperations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Container\\V1\\Operation::class);\n        $this->operations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function hide(User $actor = null)\n    {\n        if (! $this->hidden_at) {\n            $this->hidden_at = Carbon::now();\n            $this->hidden_user_id = $actor ? $actor->id : null;\n\n            $this->raise(new Hidden($this));\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def submit(self):\n        \"\"\"Submits a chagelist to the depot\"\"\"\n        if self._dirty:\n            self.save()\n\n        self._connection.run(['submit', '-c', str(self._change)], marshal_output=False)", "label": 1}
{"code": "def read_rawFilesTable(filename):\n    \"\"\"parse the 'rawFilesTable.txt' file into a pandas dataframe\"\"\"\n    exp = pd.read_table(filename)\n    expected_columns = {'File', 'Exists', 'Size', 'Data format', 'Parameter group', 'Experiment', 'Fraction'}\n    found_columns = set(exp.columns)\n    if len(expected_columns - found_columns) > 0:\n        message = '\\n'.join(['The raw files table has the wrong format!',\n            'It should contain columns:',\n            ', '.join(sorted(expected_columns)),\n            'Found columns:',\n            ', '.join(sorted(found_columns))])\n        raise ValueError(message)\n    exp['Raw file'] = exp['File'].apply(path.basename).apply(path.splitext).str.get(0)\n    exp['Experiment'] = exp['Experiment'].astype(str)\n    return exp", "label": 1}
{"code": "public static function env()\n    {\n        return function () {\n            // Use credentials from environment variables, if available\n            $enabled = getenv(self::ENV_ENABLED);\n            if ($enabled !== false) {\n                return Promise\\promise_for(\n                    new Configuration(\n                        $enabled,\n                        getenv(self::ENV_PORT) ?: self::DEFAULT_PORT,\n                        getenv(self:: ENV_CLIENT_ID) ?: self::DEFAULT_CLIENT_ID\n                     )\n                );\n            }\n\n            return self::reject('Could not find environment variable CSM config'\n                . ' in ' . self::ENV_ENABLED. '/' . self::ENV_PORT . '/'\n                . self::ENV_CLIENT_ID);\n        };\n    }", "label": 2}
{"code": "func lookupXMLName(typ reflect.Type) (xmlname *fieldInfo) {\n\tfor typ.Kind() == reflect.Ptr {\n\t\ttyp = typ.Elem()\n\t}\n\tif typ.Kind() != reflect.Struct {\n\t\treturn nil\n\t}\n\tfor i, n := 0, typ.NumField(); i < n; i++ {\n\t\tf := typ.Field(i)\n\t\tif f.Name != \"XMLName\" {\n\t\t\tcontinue\n\t\t}\n\t\tfinfo, err := structFieldInfo(typ, &f)\n\t\tif finfo.name != \"\" && err == nil {\n\t\t\treturn finfo\n\t\t}\n\t\t// Also consider errors as a non-existent field tag\n\t\t// and let getTypeInfo itself report the error.\n\t\tbreak\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def health_check(self):\n        \"\"\" Pull health and alarm information from the device.\n\n        Purpose: Grab the cpu/mem usage, system/chassis alarms, top 5\n               | processes, and states if the primary/backup partitions are on\n               | different versions.\n\n        @returns: The output that should be shown to the user.\n        @rtype: str\n        \"\"\"\n        output = 'Chassis Alarms:\\n\\t'\n        # Grab chassis alarms, system alarms, show chassis routing-engine,\n        # 'show system processes extensive', and also xpath to the\n        # relevant nodes on each.\n        chassis_alarms = self._session.command(\"show chassis alarms\")\n        chassis_alarms = chassis_alarms.xpath('//alarm-detail')\n        system_alarms = self._session.command(\"show system alarms\")\n        system_alarms = system_alarms.xpath('//alarm-detail')\n        chass = self._session.command(command=\"show chassis routing-engine\",\n                                      format='text').xpath('//output')[0].text\n        proc = self._session.command(\"show system processes extensive\")\n        proc = proc.xpath('output')[0].text.split('\\n')\n        if chassis_alarms == []:  # Chassis Alarms\n            output += 'No chassis alarms active.\\n'\n        else:\n            for i in chassis_alarms:\n                output += (i.xpath('alarm-class')[0].text.strip() + ' Alarm \\t'\n                           '\\t' + i.xpath('alarm-time')[0].text.strip() +\n                           '\\n\\t' +\n                           i.xpath('alarm-description')[0].text.strip() + '\\n')\n        output += '\\nSystem Alarms: \\n\\t'\n        if system_alarms == []:  # System Alarms\n            output += 'No system alarms active.\\n'\n        else:\n            for i in system_alarms:\n                output += (i.xpath('alarm-class')[0].text.strip() + ' Alarm '\n                           '\\t\\t' + i.xpath('alarm-time')[0].text.strip() +\n                           '\\n\\t' +\n                           i.xpath('alarm-description')[0].text.strip() + '\\n')\n        # add the output of the show chassis routing-engine to the command.\n        output += '\\n' + chass\n        # Grabs the top 5 processes and the header line.\n        output += ('\\n\\nTop 5 busiest processes (high mgd values likely from '\n                   'script execution):\\n')\n        for line_number in range(8, 14):\n            output += proc[line_number] + '\\n'\n        return output", "label": 1}
{"code": "private function convertTableAnnotationToTableMetadata(\n        Annotation\\Table $tableAnnot,\n        Mapping\\TableMetadata $table\n    ) : Mapping\\TableMetadata {\n        if (! empty($tableAnnot->name)) {\n            $table->setName($tableAnnot->name);\n        }\n\n        if (! empty($tableAnnot->schema)) {\n            $table->setSchema($tableAnnot->schema);\n        }\n\n        foreach ($tableAnnot->options as $optionName => $optionValue) {\n            $table->addOption($optionName, $optionValue);\n        }\n\n        foreach ($tableAnnot->indexes as $indexAnnot) {\n            $table->addIndex([\n                'name'    => $indexAnnot->name,\n                'columns' => $indexAnnot->columns,\n                'unique'  => $indexAnnot->unique,\n                'options' => $indexAnnot->options,\n                'flags'   => $indexAnnot->flags,\n            ]);\n        }\n\n        foreach ($tableAnnot->uniqueConstraints as $uniqueConstraintAnnot) {\n            $table->addUniqueConstraint([\n                'name'    => $uniqueConstraintAnnot->name,\n                'columns' => $uniqueConstraintAnnot->columns,\n                'options' => $uniqueConstraintAnnot->options,\n                'flags'   => $uniqueConstraintAnnot->flags,\n            ]);\n        }\n\n        return $table;\n    }", "label": 2}
{"code": "public function get_wp_config_code() {\n\t\t$wp_config_path = Utils\\locate_wp_config();\n\n\t\t$wp_config_code = explode( \"\\n\", file_get_contents( $wp_config_path ) );\n\n\t\t$found_wp_settings = false;\n\n\t\t$lines_to_run = array();\n\n\t\tforeach ( $wp_config_code as $line ) {\n\t\t\tif ( preg_match( '/^\\s*require.+wp-settings\\.php/', $line ) ) {\n\t\t\t\t$found_wp_settings = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t$lines_to_run[] = $line;\n\t\t}\n\n\t\tif ( ! $found_wp_settings ) {\n\t\t\tWP_CLI::error( 'Strange wp-config.php file: wp-settings.php is not loaded directly.' );\n\t\t}\n\n\t\t$source = implode( \"\\n\", $lines_to_run );\n\t\t$source = Utils\\replace_path_consts( $source, $wp_config_path );\n\t\treturn preg_replace( '|^\\s*\\<\\?php\\s*|', '', $source );\n\t}", "label": 2}
{"code": "public static function wrap($region, array $options)\n    {\n        return function (callable $handler) use ($region, $options) {\n            return new self($handler, $region, $options);\n        };\n    }", "label": 2}
{"code": "function _chown(file, uid, gid, options) {\n  options = _.opts(options, {abortOnError: true});\n  uid = parseInt(uid, 10);\n  uid = _.isFinite(uid) ? uid : getUid(_fileStats(file).uid, {refresh: false});\n  gid = parseInt(gid, 10);\n  gid = _.isFinite(gid) ? gid : getGid(_fileStats(file).gid, {refresh: false});\n  try {\n    if (options.abortOnError) {\n      nodeFs.chownSync(file, uid, gid);\n    } else {\n      fs.chownSync(file, uid, gid);\n    }\n  } catch (e) {\n    if (options.abortOnError) {\n      throw e;\n    }\n  }\n}", "label": 3}
{"code": "def find_issues_to_add(all_issues, tag_name)\n      all_issues.select do |issue|\n        if issue[\"milestone\"].nil?\n          false\n        else\n          # check, that this milestone in tag list:\n          milestone_is_tag = @filtered_tags.find do |tag|\n            tag[\"name\"] == issue[\"milestone\"][\"title\"]\n          end\n\n          if milestone_is_tag.nil?\n            false\n          else\n            issue[\"milestone\"][\"title\"] == tag_name\n          end\n        end\n      end\n    end", "label": 4}
{"code": "func fkName(mode FkMode, fkMap map[string]*ForeignKey, fk *ForeignKey) string {\n\tswitch mode {\n\tcase FkModeParent:\n\t\treturn fk.RefType.Name\n\tcase FkModeField:\n\t\treturn fk.RefType.Name + \"By\" + fk.Field.Name\n\tcase FkModeKey:\n\t\treturn fk.RefType.Name + \"By\" + snaker.SnakeToCamelIdentifier(fk.ForeignKey.ForeignKeyName)\n\t}\n\n\t// mode is FkModeSmart\n\t// inspect all foreign keys and use FkModeField if conflict found\n\tfor _, f := range fkMap {\n\t\tif fk != f && fk.Type.Name == f.Type.Name && fk.RefType.Name == f.RefType.Name {\n\t\t\treturn fkName(FkModeField, fkMap, fk)\n\t\t}\n\t}\n\n\t// no conflict, so use FkModeParent\n\treturn fkName(FkModeParent, fkMap, fk)\n}", "label": 5}
{"code": "function updateAngles(xAngle, yAngle, zAngle) {\n  let deg2rad = Math.PI / 180;\n  let euler = new THREE.Euler(\n    xAngle * deg2rad,\n    yAngle * deg2rad,\n    zAngle * deg2rad,\n    'YXZ');\n  let matrix = new THREE.Matrix4().makeRotationFromEuler(euler);\n  camera.setRotationFromMatrix(matrix);\n  if (!audioReady)\n    return;\n\n  if (Date.now() - lastMatrixUpdate > 100) {\n    audioScene.setListenerFromMatrix(camera.matrixWorld);\n  }\n}", "label": 3}
{"code": "def save_and_validate_logo(logo_stream, logo_filename, community_id):\n    \"\"\"Validate if communities logo is in limit size and save it.\"\"\"\n    cfg = current_app.config\n\n    logos_bucket_id = cfg['COMMUNITIES_BUCKET_UUID']\n    logo_max_size = cfg['COMMUNITIES_LOGO_MAX_SIZE']\n    logos_bucket = Bucket.query.get(logos_bucket_id)\n    ext = os.path.splitext(logo_filename)[1]\n    ext = ext[1:] if ext.startswith('.') else ext\n\n    logo_stream.seek(SEEK_SET, SEEK_END)  # Seek from beginning to end\n    logo_size = logo_stream.tell()\n    if logo_size > logo_max_size:\n        return None\n\n    if ext in cfg['COMMUNITIES_LOGO_EXTENSIONS']:\n        key = \"{0}/logo.{1}\".format(community_id, ext)\n        logo_stream.seek(0)  # Rewind the stream to the beginning\n        ObjectVersion.create(logos_bucket, key, stream=logo_stream,\n                             size=logo_size)\n        return ext\n    else:\n        return None", "label": 1}
{"code": "function randomString() {\n      var possibilities = ['Frequency', 'Population', 'Alpha', 'Beta'],\n          i = Math.round(Math.random() * possibilities.length);\n      return possibilities[i];\n    }", "label": 3}
{"code": "func (t *TransportPort) FromString(s string) error {\n\tps := strings.Split(s, \"/\")\n\tif len(ps) == 2 {\n\t\tt.Proto = ParseProtocol(ps[0])\n\t\tif p, err := strconv.ParseUint(ps[1], 10, 16); err == nil {\n\t\t\tt.Port = uint16(p)\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn BadRequestErrorf(\"invalid format for transport port: %s\", s)\n}", "label": 5}
{"code": "def validate_length(self, value):\n        \"\"\"Validate the length of value, if min_length or max_length was specified\"\"\"\n        list_len = len(value) if value else 0\n\n        if self.max_length is not None and list_len > self.max_length:\n            raise ValidationError(\n                u'List has {} values; max length is {}'.format(list_len, self.max_length))\n\n        if self.min_length is not None and list_len < self.min_length:\n            raise ValidationError(\n                u'List has {} values; min length is {}'.format(list_len, self.min_length))", "label": 1}
{"code": "function(aclid, options){\n      options = opts(this, options);\n\n      return new APICall({\n        action: 'access/' + aclid,\n        type: 'DELETE',\n        processResponse: APICall.basicResponse,\n        options: options\n      });\n    }", "label": 3}
{"code": "def item_links_addition(self, data):\n        \"\"\"Add the links for each community.\"\"\"\n        links_item_factory = self.context.get('links_item_factory',\n                                              default_links_item_factory)\n        data['links'] = links_item_factory(data)\n        return data", "label": 1}
{"code": "def configured_require_paths\n      return ['lib'] if directory.empty?\n      return [File.join(directory, 'lib')] if config.require_paths.empty?\n      config.require_paths.map{|p| File.join(directory, p)}\n    end", "label": 4}
{"code": "def doEpisodes(self, number=1):\n        \"\"\" Does the the given number of episodes.\n        \"\"\"\n        env = self.task.env\n        self.Pg = zeros((len(env.case.online_generators), len(env.profile)))\n\n        rewards = super(OPFExperiment, self).doEpisodes(number)\n\n        # Average the set-points for each period.\n        self.Pg = self.Pg / number\n\n        return rewards", "label": 1}
{"code": "func (ph Placeholders) Value(name string) interface{} {\n\tfor _, p := range ph {\n\t\tif p.Name == name {\n\t\t\treturn p.Value\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def reset(self):\n        '''\n        Reset the frame between jobs\n        '''\n        self.palette['title'] = (Screen.COLOUR_WHITE, Screen.A_BOLD, Screen.COLOUR_BLUE)\n        self._completed_view.options = []\n        self._task_view.options = []\n        self.refresh()", "label": 1}
{"code": "function addNodeToSlot (slot, node, insertBefore) {\n  const isInDefaultMode = slot.assignedNodes().length === 0;\n  registerNode(slot, node, insertBefore, eachNode => {\n    if (isInDefaultMode) {\n      slot.__insertBefore(eachNode, insertBefore !== undefined ? insertBefore : null);\n    }\n  });\n}", "label": 3}
{"code": "def upload(options)\n      return if options[:skip_metadata]\n      # it is not possible to create new languages, because\n      # :keywords is not write-able on published versions\n      # therefore skip it.\n      verify_available_languages!(options) unless options[:edit_live]\n\n      app = options[:app]\n\n      details = app.details\n      if options[:edit_live]\n        # not all values are editable when using live_version\n        v = app.live_version(platform: options[:platform])\n        localised_options = LOCALISED_LIVE_VALUES\n        non_localised_options = NON_LOCALISED_LIVE_VALUES\n\n        if v.nil?\n          UI.message(\"Couldn't find live version, editing the current version on App Store Connect instead\")\n          v = app.edit_version(platform: options[:platform])\n          # we don't want to update the localised_options and non_localised_options\n          # as we also check for `options[:edit_live]` at other areas in the code\n          # by not touching those 2 variables, deliver is more consistent with what the option says\n          # in the documentation\n        end\n      else\n        v = app.edit_version(platform: options[:platform])\n        localised_options = (LOCALISED_VERSION_VALUES + LOCALISED_APP_VALUES)\n        non_localised_options = (NON_LOCALISED_VERSION_VALUES + NON_LOCALISED_APP_VALUES)\n      end\n\n      individual = options[:individual_metadata_items] || []\n      localised_options.each do |key|\n        current = options[key]\n        next unless current\n\n        unless current.kind_of?(Hash)\n          UI.error(\"Error with provided '#{key}'. Must be a hash, the key being the language.\")\n          next\n        end\n\n        current.each do |language, value|\n          next unless value.to_s.length > 0\n          strip_value = value.to_s.strip\n          if individual.include?(key.to_s)\n            upload_individual_item(app, v, language, key, strip_value)\n          else\n            v.send(key)[language] = strip_value if LOCALISED_VERSION_VALUES.include?(key)\n            details.send(key)[language] = strip_value if LOCALISED_APP_VALUES.include?(key)\n          end\n        end\n      end\n\n      non_localised_options.each do |key|\n        current = options[key].to_s.strip\n        next unless current.to_s.length > 0\n        v.send(\"#{key}=\", current) if NON_LOCALISED_VERSION_VALUES.include?(key)\n        details.send(\"#{key}=\", current) if NON_LOCALISED_APP_VALUES.include?(key)\n      end\n\n      v.release_on_approval = options[:automatic_release]\n      v.auto_release_date = options[:auto_release_date] unless options[:auto_release_date].nil?\n      v.toggle_phased_release(enabled: !!options[:phased_release]) unless options[:phased_release].nil?\n\n      set_trade_representative_contact_information(v, options)\n      set_review_information(v, options)\n      set_app_rating(v, options)\n      v.ratings_reset = options[:reset_ratings] unless options[:reset_ratings].nil?\n\n      Helper.show_loading_indicator(\"Uploading metadata to App Store Connect\")\n      v.save!\n      Helper.hide_loading_indicator\n      begin\n        details.save!\n        UI.success(\"Successfully uploaded set of metadata to App Store Connect\")\n      rescue Spaceship::TunesClient::ITunesConnectError => e\n        # This makes sure that we log invalid app names as user errors\n        # If another string needs to be checked here we should\n        # figure out a more generic way to handle these cases.\n        if e.message.include?('App Name cannot be longer than 50 characters') || e.message.include?('The app name you entered is already being used')\n          UI.error(\"Error in app name.  Try using 'individual_metadata_items' to identify the problem language.\")\n          UI.user_error!(e.message)\n        else\n          raise e\n        end\n      end\n    end", "label": 4}
{"code": "Object lookup(String key) throws ObjectNameNotFoundException\r\n    {\r\n        Object result = null;\r\n        NamedEntry entry = localLookup(key);\r\n        // can't find local bound object\r\n        if(entry == null)\r\n        {\r\n            try\r\n            {\r\n                PersistenceBroker broker = tx.getBroker();\r\n                // build Identity to lookup entry\r\n                Identity oid = broker.serviceIdentity().buildIdentity(NamedEntry.class, key);\r\n                entry = (NamedEntry) broker.getObjectByIdentity(oid);\r\n            }\r\n            catch(Exception e)\r\n            {\r\n                log.error(\"Can't materialize bound object for key '\" + key + \"'\", e);\r\n            }\r\n        }\r\n        if(entry == null)\r\n        {\r\n            log.info(\"No object found for key '\" + key + \"'\");\r\n        }\r\n        else\r\n        {\r\n            Object obj = entry.getObject();\r\n            // found a persistent capable object associated with that key\r\n            if(obj instanceof Identity)\r\n            {\r\n                Identity objectIdentity = (Identity) obj;\r\n                result = tx.getBroker().getObjectByIdentity(objectIdentity);\r\n                // lock the persistance capable object\r\n                RuntimeObject rt = new RuntimeObject(result, objectIdentity, tx, false);\r\n                tx.lockAndRegister(rt, Transaction.READ, tx.getRegistrationList());\r\n            }\r\n            else\r\n            {\r\n                // nothing else to do\r\n                result = obj;\r\n            }\r\n        }\r\n        if(result == null) throw new ObjectNameNotFoundException(\"Can't find named object for name '\" + key + \"'\");\r\n        return result;\r\n    }", "label": 0}
{"code": "function(value, attr, range, model) {\n        if (!_.isString(value) || value.length < range[0] || value.length > range[1]) {\n          return this.format(getMessageKey(this.msgKey, defaultMessages.rangeLength), this.formatLabel(attr, model), range[0], range[1]);\n        }\n      }", "label": 3}
{"code": "def select_all!(*str_or_rx)\n      results = str_or_rx.flatten.map { |v| select_by!(v, :multiple) }\n      results.first\n    end", "label": 4}
{"code": "func (l VirtualDeviceList) newSCSIBusNumber() int32 {\n\tvar used []int\n\n\tfor _, d := range l.SelectByType((*types.VirtualSCSIController)(nil)) {\n\t\tnum := d.(types.BaseVirtualSCSIController).GetVirtualSCSIController().BusNumber\n\t\tif num >= 0 {\n\t\t\tused = append(used, int(num))\n\t\t} // else caller is creating a new vm using SCSIControllerTypes\n\t}\n\n\tsort.Ints(used)\n\n\tfor i, n := range scsiBusNumbers {\n\t\tif i == len(used) || n != used[i] {\n\t\t\treturn int32(n)\n\t\t}\n\t}\n\n\treturn -1\n}", "label": 5}
{"code": "function (char, chars) {\n                var\n                    first,\n                    last;\n                if (\"^\" === char) {\n                    this._exc = [];\n                } else if (\"]\" === char) {\n                    if (this._inRange) {\n                        gpf.Error.patternInvalidSyntax();\n                    }\n                    return true;\n                } else if (\"-\" === char) {\n                    if (this._inRange || 0 === chars.length) {\n                        gpf.Error.patternInvalidSyntax();\n                    }\n                    this._inRange = true;\n                } else {\n                    if (this._inRange) {\n                        first = chars[chars.length - 1].charCodeAt(0);\n                        last = char.charCodeAt(0);\n                        while (--last > first) {\n                            chars.push(String.fromCharCode(last));\n                        }\n                        chars.push(char);\n                        delete this._inRange;\n                    } else {\n                        // First char of a range\n                        chars.push(char);\n                    }\n                }\n                return false;\n            }", "label": 3}
{"code": "def deprecate(old, new, reference: '', ids: [])\n      return if @ignored.include?('deprecations') || (@ignored & ids.map!(&:to_s)).any?\n\n      msg = ids.empty? ? '' : \"[#{ids.map(&:inspect).join(', ')}] \"\n      ref_msg = reference.empty? ? '.' : \"; see explanation for this deprecation: #{reference}.\"\n      warn \"[DEPRECATION] #{msg}#{old} is deprecated. Use #{new} instead#{ref_msg}\"\n    end", "label": 4}
{"code": "function()\n  {\n    var values = arguments;\n\n    AP.unshift.apply( this, values );\n\n    this.trigger( Collection.Events.Adds, [this, AP.slice.apply(values), 0] );\n\n    this.sort( undefined, undefined, true );\n\n    return this.length;\n  }", "label": 3}
{"code": "def get(self, name=None):\n        \"\"\"\n        Returns commands, which can be filtered by name.\n\n        :param name: name of the command\n        :type name: str\n        :return: None, single command or dict of commands\n        \"\"\"\n        return self.app.commands.get(name, self.plugin)", "label": 1}
{"code": "public function pull(array $options = [])\n    {\n        $messages = [];\n        $options['returnImmediately'] = isset($options['returnImmediately'])\n            ? $options['returnImmediately']\n            : false;\n        $options['maxMessages'] = isset($options['maxMessages'])\n            ? $options['maxMessages']\n            : self::MAX_MESSAGES;\n\n        $response = $this->connection->pull($options + [\n            'subscription' => $this->name\n        ]);\n\n        if (isset($response['receivedMessages'])) {\n            foreach ($response['receivedMessages'] as $message) {\n                $messages[] = $this->messageFactory($message, $this->connection, $this->projectId, $this->encode);\n            }\n        }\n\n        return $messages;\n    }", "label": 2}
{"code": "func newLocalTerminal(ctx *ServerContext) (*terminal, error) {\n\tvar err error\n\n\tt := &terminal{\n\t\tlog: log.WithFields(log.Fields{\n\t\t\ttrace.Component: teleport.ComponentLocalTerm,\n\t\t}),\n\t\tctx: ctx,\n\t}\n\n\t// Open PTY and corresponding TTY.\n\tt.pty, t.tty, err = pty.Open()\n\tif err != nil {\n\t\tlog.Warnf(\"Could not start PTY %v\", err)\n\t\treturn nil, err\n\t}\n\n\t// Set the TTY owner. Failure is not fatal, for example Teleport is running\n\t// on a read-only filesystem, but logging is useful for diagnostic purposes.\n\terr = t.setOwner()\n\tif err != nil {\n\t\tlog.Debugf(\"Unable to set TTY owner: %v.\\n\", err)\n\t}\n\n\treturn t, nil\n}", "label": 5}
{"code": "def post_process_persist(result, options = {})\n      post_persist unless result == false\n      errors.clear unless performing_validations?(options)\n      true\n    end", "label": 4}
{"code": "function process(advertiserData) {\n  var snfBeacon = {};\n  var data = advertiserData.manufacturerSpecificData.data;\n\n  snfBeacon.type = 'SnS Motion';\n  snfBeacon.timestamp = parseInt(pdu.reverseBytes(data.substr(2,8)),16);\n  snfBeacon.temperature = parseInt(data.substr(10,2),16);\n  if(snfBeacon.temperature > 127) {\n    snfBeacon.temperature = 127 - snfBeacon.temperature;\n  }\n  snfBeacon.temperature = snfBeacon.temperature / 2;\n  snfBeacon.temperature += (parseInt(data.substr(41,1),16)) / 4;\n  snfBeacon.batteryVoltage = data.substr(12,2);\n  snfBeacon.eventCounters = [];\n  snfBeacon.eventCounters.push(data.substr(26,1) + data.substr(14,2));\n  snfBeacon.eventCounters.push(data.substr(27,1) + data.substr(16,2));\n  snfBeacon.eventCounters.push(data.substr(28,1) + data.substr(18,2));\n  snfBeacon.eventCounters.push(data.substr(29,1) + data.substr(20,2));\n  snfBeacon.eventCounters.push(data.substr(30,1) + data.substr(22,2));\n  snfBeacon.eventCounters.push(data.substr(31,1) + data.substr(24,2));\n  for(var cCounter = 0; cCounter < 6; cCounter++) {\n    var hexStringCount = snfBeacon.eventCounters[cCounter];\n    snfBeacon.eventCounters[cCounter] = parseInt(hexStringCount,16);\n  }\n  snfBeacon.accelerationX = parseInt((data.substr(32,2) +\n                                      data.substr(38,1)), 16);\n  snfBeacon.accelerationY = parseInt((data.substr(34,2) +\n                                      data.substr(39,1)), 16);\n  snfBeacon.accelerationZ = parseInt((data.substr(36,2) +\n                                      data.substr(40,1)), 16);\n\n  advertiserData.manufacturerSpecificData.snfBeacon = snfBeacon;\n}", "label": 3}
{"code": "public function getRelationDictionary(string $relationName): array\n    {\n        return $this->models\n            ->mapWithKeys(\n                function (Model $model) use ($relationName) {\n                    return [$this->buildKey($model->getKey()) => $model->getRelation($relationName)];\n                }\n            )->all();\n    }", "label": 2}
{"code": "def identify_marker_genes_corr(self, labels=None, n_genes=4000):\n        \"\"\"\n        Ranking marker genes based on their respective magnitudes in the\n        correlation dot products with cluster-specific reference expression\n        profiles. \n\n        Parameters\n        ----------\n\n        labels - numpy.array or str, optional, default None\n            Cluster labels to use for marker gene identification. If None,\n            assumes that one of SAM's clustering algorithms has been run. Can\n            be a string (i.e. 'louvain_clusters', 'kmeans_clusters', etc) to\n            specify specific cluster labels in adata.obs.\n\n        n_genes - int, optional, default 4000\n            By default, computes correlations on the top 4000 SAM-weighted genes.            \n\n        \"\"\"\n        if(labels is None):\n            try:\n                keys = np.array(list(self.adata.obs_keys()))\n                lbls = self.adata.obs[ut.search_string(\n                    keys, '_clusters')[0][0]].get_values()\n            except KeyError:\n                print(\"Please generate cluster labels first or set the \"\n                      \"'labels' keyword argument.\")\n                return\n        elif isinstance(labels, str):\n            lbls = self.adata.obs[labels].get_values().flatten()\n        else:\n            lbls = labels\n\n\n        w=self.adata.var['weights'].values\n        s = StandardScaler()\n        idxg = np.argsort(-w)[:n_genes]\n        y1=s.fit_transform(self.adata.layers['X_disp'][:,idxg].A)*w[idxg]\n        \n        all_gene_names = np.array(list(self.adata.var_names))[idxg]\n\n        markers = {}\n        lblsu=np.unique(lbls)\n        for i in lblsu:\n            Gcells = np.array(list(self.adata.obs_names[lbls==i]))\n            z1 = y1[np.in1d(self.adata.obs_names,Gcells),:]\n            m1 = (z1 - z1.mean(1)[:,None])/z1.std(1)[:,None]            \n            ref = z1.mean(0)\n            ref = (ref-ref.mean())/ref.std()\n            g2 = (m1*ref).mean(0)    \n            markers[i] = all_gene_names[np.argsort(-g2)]\n            \n\n        self.adata.uns['marker_genes_corr'] = markers\n        return markers", "label": 1}
{"code": "def get_file_from_gdc(job, gdc_url, gdc_download_token, write_to_jobstore=True):\n    \"\"\"\n    Download a supplied \"URL\" that points to a file in the NCBI GDC database.  The path to the gdc\n    download token must be provided.  The file is downloaded and written to the jobstore if\n    requested.\n\n    :param str gdc_url: URL for the file (in the form of gdc://<UUID>)\n    :param str gdc_download_token: Path to the gdc download token\n    :param bool write_to_jobstore: Should the file be written to the job store?\n    :return: Path to the downloaded file or fsID (if write_to_jobstore was True)\n    :rtype: list(str|toil.fileStore.FileID)\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n\n    parsed_url = urlparse(gdc_url)\n    assert parsed_url.scheme == 'gdc', 'Unexpected url scheme: %s' % gdc_url\n\n    file_dir = '/'.join([work_dir, parsed_url.netloc])\n\n    # This is common to encrypted and unencrypted downloads\n    currwd = os.getcwd()\n    os.chdir(work_dir)\n    try:\n        download_call = ['gdc-client', 'download', '-t', gdc_download_token, parsed_url.netloc]\n        subprocess.check_call(download_call)\n    finally:\n        os.chdir(currwd)\n\n    assert os.path.exists(file_dir)\n    output_files = [os.path.join(file_dir, x) for x in os.listdir(file_dir)\n                    if not x.endswith('logs')]\n    # NOTE: We only handle vcf and bam+bai\n    if len(output_files) == 1:\n        assert output_files[0].endswith('vcf')\n    else:\n        if not {os.path.splitext(x)[1] for x in output_files} >= {'.bam', '.bai'}:\n            raise ParameterError('Can currently only handle pre-indexed GDC bams.')\n        # Always [bam, bai]\n        output_files = [x for x in output_files if x.endswith(('bam', 'bai'))]\n        output_files = sorted(output_files, key=lambda x: os.path.splitext(x)[1], reverse=True)\n    if write_to_jobstore:\n        output_files = [job.fileStore.writeGlobalFile(f) for f in output_files]\n    return output_files", "label": 1}
{"code": "public static <E> E argmin(Counter<E> c) {\r\n    double min = Double.POSITIVE_INFINITY;\r\n    E argmin = null;\r\n\r\n    for (E key : c.keySet()) {\r\n      double count = c.getCount(key);\r\n      if (argmin == null || count < min) {// || (count == min &&\r\n                                          // tieBreaker.compare(key, argmin) <\r\n                                          // 0)) {\r\n        min = count;\r\n        argmin = key;\r\n      }\r\n    }\r\n    return argmin;\r\n  }", "label": 0}
{"code": "def call(env)\n      start_time = Time.now.to_f\n      time_elapsed = lambda { ((Time.now.to_f - start_time) * 1000).to_i }\n\n      unless ALLOWED_REQUEST_METHODS.include? env['REQUEST_METHOD']\n        return method_not_allowed_response\n      end\n\n      msg = \"Served asset #{env['PATH_INFO']} -\"\n\n      # Extract the path from everything after the leading slash\n      path = Rack::Utils.unescape(env['PATH_INFO'].to_s.sub(/^\\//, ''))\n\n      unless path.valid_encoding?\n        return bad_request_response(env)\n      end\n\n      # Strip fingerprint\n      if fingerprint = path_fingerprint(path)\n        path = path.sub(\"-#{fingerprint}\", '')\n      end\n\n      # URLs containing a `\"..\"` are rejected for security reasons.\n      if forbidden_request?(path)\n        return forbidden_response(env)\n      end\n\n      if fingerprint\n        if_match = fingerprint\n      elsif env['HTTP_IF_MATCH']\n        if_match = env['HTTP_IF_MATCH'][/\"(\\w+)\"$/, 1]\n      end\n\n      if env['HTTP_IF_NONE_MATCH']\n        if_none_match = env['HTTP_IF_NONE_MATCH'][/\"(\\w+)\"$/, 1]\n      end\n\n      # Look up the asset.\n      asset = find_asset(path)\n\n      if asset.nil?\n        status = :not_found\n      elsif fingerprint && asset.etag != fingerprint\n        status = :not_found\n      elsif if_match && asset.etag != if_match\n        status = :precondition_failed\n      elsif if_none_match && asset.etag == if_none_match\n        status = :not_modified\n      else\n        status = :ok\n      end\n\n      case status\n      when :ok\n        logger.info \"#{msg} 200 OK (#{time_elapsed.call}ms)\"\n        ok_response(asset, env)\n      when :not_modified\n        logger.info \"#{msg} 304 Not Modified (#{time_elapsed.call}ms)\"\n        not_modified_response(env, if_none_match)\n      when :not_found\n        logger.info \"#{msg} 404 Not Found (#{time_elapsed.call}ms)\"\n        not_found_response(env)\n      when :precondition_failed\n        logger.info \"#{msg} 412 Precondition Failed (#{time_elapsed.call}ms)\"\n        precondition_failed_response(env)\n      end\n    rescue Exception => e\n      logger.error \"Error compiling asset #{path}:\"\n      logger.error \"#{e.class.name}: #{e.message}\"\n\n      case File.extname(path)\n      when \".js\"\n        # Re-throw JavaScript asset exceptions to the browser\n        logger.info \"#{msg} 500 Internal Server Error\\n\\n\"\n        return javascript_exception_response(e)\n      when \".css\"\n        # Display CSS asset exceptions in the browser\n        logger.info \"#{msg} 500 Internal Server Error\\n\\n\"\n        return css_exception_response(e)\n      else\n        raise\n      end\n    end", "label": 4}
{"code": "def _load_permissions(self):\n        \"\"\"Load permissions associated to actions.\"\"\"\n        result = _P(needs=set(), excludes=set())\n        if not self.allow_by_default:\n            result.needs.update(self.explicit_needs)\n\n        for explicit_need in self.explicit_needs:\n            if explicit_need.method == 'action':\n                action = current_access.get_action_cache(\n                    self._cache_key(explicit_need)\n                )\n                if action is None:\n                    action = _P(needs=set(), excludes=set())\n\n                    actionsusers = ActionUsers.query_by_action(\n                        explicit_need\n                    ).all()\n\n                    actionsroles = ActionRoles.query_by_action(\n                        explicit_need\n                    ).join(\n                        ActionRoles.role\n                    ).all()\n\n                    actionssystem = ActionSystemRoles.query_by_action(\n                        explicit_need\n                    ).all()\n\n                    for db_action in chain(\n                            actionsusers, actionsroles, actionssystem):\n                        if db_action.exclude:\n                            action.excludes.add(db_action.need)\n                        else:\n                            action.needs.add(db_action.need)\n\n                    current_access.set_action_cache(\n                        self._cache_key(explicit_need),\n                        action\n                    )\n                # in-place update of results\n                result.update(action)\n            elif self.allow_by_default:\n                result.needs.add(explicit_need)\n        self._permissions = result", "label": 1}
{"code": "func (cli *NetworkCli) CmdServiceAttach(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"attach\", \"CONTAINER SERVICE[.NETWORK]\", \"Sets a container as a service backend\", false)\n\tflAlias := opts.NewListOpts(netutils.ValidateAlias)\n\tcmd.Var(&flAlias, []string{\"-alias\"}, \"Add alias for another container\")\n\tcmd.Require(flag.Min, 2)\n\terr := cmd.ParseFlags(args, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcontainerID, err := lookupContainerID(cli, cmd.Arg(0))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsandboxID, err := lookupSandboxID(cli, containerID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsn, nn := parseServiceName(cmd.Arg(1))\n\tserviceID, err := lookupServiceID(cli, nn, sn)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnc := serviceAttach{SandboxID: sandboxID, Aliases: flAlias.GetAll()}\n\n\t_, _, err = readBody(cli.call(\"POST\", \"/services/\"+serviceID+\"/backend\", nc, nil))\n\n\treturn err\n}", "label": 5}
{"code": "public static function titleContains($title)\n    {\n        return new static(\n            function (WebDriver $driver) use ($title) {\n                return mb_strpos($driver->getTitle(), $title) !== false;\n            }\n        );\n    }", "label": 2}
{"code": "public static filterpolicy_binding get(nitro_service service, String name) throws Exception{\n\t\tfilterpolicy_binding obj = new filterpolicy_binding();\n\t\tobj.set_name(name);\n\t\tfilterpolicy_binding response = (filterpolicy_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void addArtifact(final Artifact artifact) {\n        if (!artifacts.contains(artifact)) {\n            if (promoted) {\n                artifact.setPromoted(promoted);\n            }\n\n            artifacts.add(artifact);\n        }\n    }", "label": 0}
{"code": "def data=(values=[])\n      @tag_name = values.first.is_a?(Cell) ? :numCache : :numLit\n      values.each do |value|\n        value = value.is_formula? ? 0 : value.value if value.is_a?(Cell)\n        @pt << NumVal.new(:v => value)\n      end\n    end", "label": 4}
{"code": "def clear_working_tree\n      removed_submodules = Overcommit::GitRepo.staged_submodule_removals\n\n      result = Overcommit::Utils.execute(%w[git reset --hard])\n      unless result.success?\n        raise Overcommit::Exceptions::HookCleanupFailed,\n              \"Unable to cleanup working tree after #{hook_script_name} hooks run:\" \\\n              \"\\nSTDOUT:#{result.stdout}\\nSTDERR:#{result.stderr}\"\n      end\n\n      # Hard-resetting a staged submodule removal results in the index being\n      # reset but the submodule being restored as an empty directory. This empty\n      # directory prevents us from stashing on a subsequent run if a hook fails.\n      #\n      # Work around this by removing these empty submodule directories as there\n      # doesn't appear any reason to keep them around.\n      removed_submodules.each do |submodule|\n        FileUtils.rmdir(submodule.path)\n      end\n    end", "label": 4}
{"code": "func CollectOptions(opts []OpOption) (*OpConfig, error) {\n\tcfg := OpConfig{}\n\tfor _, o := range opts {\n\t\tif err := o(&cfg); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\treturn &cfg, nil\n}", "label": 5}
{"code": "func (c *Client) GetSessions(namespace string) ([]session.Session, error) {\n\tif namespace == \"\" {\n\t\treturn nil, trace.BadParameter(MissingNamespaceError)\n\t}\n\tout, err := c.Get(c.Endpoint(\"namespaces\", namespace, \"sessions\"), url.Values{})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar sessions []session.Session\n\tif err := json.Unmarshal(out.Bytes(), &sessions); err != nil {\n\t\treturn nil, err\n\t}\n\treturn sessions, nil\n}", "label": 5}
{"code": "func (f *Fpdf) newobj() {\n\t// dbg(\"newobj\")\n\tf.n++\n\tfor j := len(f.offsets); j <= f.n; j++ {\n\t\tf.offsets = append(f.offsets, 0)\n\t}\n\tf.offsets[f.n] = f.buffer.Len()\n\tf.outf(\"%d 0 obj\", f.n)\n}", "label": 5}
{"code": "protected function getMediaFile($filepath, $maxsizebytes = 5242880)\n    {\n        if (filter_var($filepath, FILTER_VALIDATE_URL) !== false) {\n            $this->mediaFileInfo = [];\n            $this->mediaFileInfo['url'] = $filepath;\n\n            $media = file_get_contents($filepath);\n            $this->mediaFileInfo['filesize'] = strlen($media);\n\n            if ($this->mediaFileInfo['filesize'] < $maxsizebytes) {\n                $this->mediaFileInfo['filepath'] = tempnam($this->dataFolder.Constants::MEDIA_FOLDER, 'WHA');\n                file_put_contents($this->mediaFileInfo['filepath'], $media);\n                $this->mediaFileInfo['filemimetype'] = get_mime($this->mediaFileInfo['filepath']);\n                $this->mediaFileInfo['fileextension'] = getExtensionFromMime($this->mediaFileInfo['filemimetype']);\n\n                return true;\n            } else {\n                return false;\n            }\n        } elseif (file_exists($filepath)) {\n            //Local file\n            $this->mediaFileInfo['filesize'] = filesize($filepath);\n            if ($this->mediaFileInfo['filesize'] < $maxsizebytes) {\n                $this->mediaFileInfo['filepath'] = $filepath;\n                $this->mediaFileInfo['fileextension'] = pathinfo($filepath, PATHINFO_EXTENSION);\n                $this->mediaFileInfo['filemimetype'] = get_mime($filepath);\n\n                return true;\n            } else {\n                return false;\n            }\n        }\n\n        return false;\n    }", "label": 2}
{"code": "function CliPie(r, data, options) {\n    this.data = [];\n    this.radius = r;\n    this.total = 0;\n    this.colors = {};\n    this.cChar = -1;\n    this.options = Ul.deepMerge(options, {\n        flat: true\n      , chr: \" \"\n      , no_ansi: false\n      , circle_opts: {\n            aRatio: 1\n        }\n      , chars: \"abcdefghijklnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\".split(\"\")\n    });\n    if (Array.isArray(data)) {\n        data.forEach(this.add.bind(this));\n    } else if (data && data.constructor === Object) {\n        options = data;\n    }\n}", "label": 3}
{"code": "function MethodDictionary(methods) {\n  expect(arguments).to.have.length.below(\n    2,\n    'Invalid arguments length when creating a new MethodDictionary (it has ' +\n    'to be passed less than 2 arguments)'\n  );\n\n  if (methods) {\n    expect(methods).to.be.an(\n      'object',\n      'Invalid argument type when creating a new MethodDictionary (it has to ' +\n      'be an object)'\n    );\n\n    for (var method in methods) {\n      _addMethod(this, methods[method], method);\n    }\n  }\n\n  Object.preventExtensions(this);\n  Object.seal(this);\n}", "label": 3}
{"code": "public static function fallback()\n    {\n        return function() {\n            return Promise\\promise_for(\n                new Configuration(\n                    self::DEFAULT_ENABLED,\n                    self::DEFAULT_PORT,\n                    self::DEFAULT_CLIENT_ID\n                )\n            );\n        };\n    }", "label": 2}
{"code": "func (v *ViewPort) ScrollDown(rows int) {\n\tv.viewy += rows\n\tv.ValidateViewY()\n}", "label": 5}
{"code": "func (l *Lease) Abort(ctx context.Context, fault *types.LocalizedMethodFault) error {\n\treq := types.HttpNfcLeaseAbort{\n\t\tThis:  l.Reference(),\n\t\tFault: fault,\n\t}\n\n\t_, err := methods.HttpNfcLeaseAbort(ctx, l.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def get_bucket_policy(params = {}, options = {}, &block)\n      req = build_request(:get_bucket_policy, params)\n      req.send_request(options, &block)\n    end", "label": 4}
{"code": "def from_dict(self, data, recursive=1):\n        \"\"\"Populate the resource from a python dict\n\n        :param recursive: level of recursion for fetching resources\n        :type recursive: int\n        \"\"\"\n        # Find other linked resources\n        data = self._encode_resource(data, recursive=recursive)\n        self.data = data", "label": 1}
{"code": "def font(key)\n      single_font = fetch_config[key.to_s]['font']\n      return single_font if single_font\n\n      fonts = fetch_config[key.to_s]['fonts']\n      if fonts\n        fonts.each do |font|\n          if font['supported']\n            font['supported'].each do |language|\n              if screenshot.path.include?(language)\n                return font[\"font\"]\n              end\n            end\n          else\n            # No `supported` array, this will always be true\n            UI.verbose(\"Found a font with no list of supported languages, using this now\")\n            return font[\"font\"]\n          end\n        end\n      end\n\n      UI.verbose(\"No custom font specified for #{screenshot}, using the default one\")\n      return nil\n    end", "label": 4}
{"code": "def reset(self):\n        \"\"\" Sets initial conditions for the experiment.\n        \"\"\"\n        self.stepid = 0\n\n        for task, agent in zip(self.tasks, self.agents):\n            task.reset()\n\n            agent.module.reset()\n            agent.history.reset()", "label": 1}
{"code": "public static function convertGetToPost(RequestInterface $r)\n    {\n        if ($r->getMethod() === 'POST') {\n            return $r;\n        }\n\n        $query = $r->getUri()->getQuery();\n        $req = $r->withMethod('POST')\n            ->withBody(Psr7\\stream_for($query))\n            ->withHeader('Content-Length', strlen($query))\n            ->withHeader('Content-Type', 'application/x-www-form-urlencoded')\n            ->withUri($r->getUri()->withQuery(''));\n        return $req;\n    }", "label": 2}
{"code": "function Position(file, line, column) {\n  this.file = file;\n  this.line = line || 1;\n  this.column = column || 0;\n}", "label": 3}
{"code": "function ReadableSerialOrdered(list, iterator, sortMethod, callback)\n{\n  if (!(this instanceof ReadableSerialOrdered))\n  {\n    return new ReadableSerialOrdered(list, iterator, sortMethod, callback);\n  }\n\n  // turn on object mode\n  ReadableSerialOrdered.super_.call(this, {objectMode: true});\n\n  this._start(serialOrdered, list, iterator, sortMethod, callback);\n}", "label": 3}
{"code": "public function seekToSnapshot(Snapshot $snapshot)\n    {\n        return $this->connection->seek([\n            'subscription' => $this->name,\n            'snapshot' => $snapshot->name()\n        ]);\n    }", "label": 2}
{"code": "def flatten_unique(l: Iterable) -> List:\n    \"\"\" Return a list of UNIQUE non-list items in l \"\"\"\n    rval = OrderedDict()\n    for e in l:\n        if not isinstance(e, str) and isinstance(e, Iterable):\n            for ev in flatten_unique(e):\n                rval[ev] = None\n        else:\n            rval[e] = None\n    return list(rval.keys())", "label": 1}
{"code": "function Loop(messenger)\n{\n  // Messenger we'll use for clock signals\n  this.messenger = messenger || new Messenger();\n\n  this.fixedDuration = 8;\n  this.started       = false;\n\n  // Live stats\n  this.currentTime        = 0;\n  this.fixedStepsPerFrame = 0;\n  this.fixedTimePerFrame  = 0;\n  this.renderTimePerFrame = 0;\n  this.frameTime          = 0;\n}", "label": 3}
{"code": "def ok_response(asset, env)\n        if head_request?(env)\n          [ 200, headers(env, asset, 0), [] ]\n        else\n          [ 200, headers(env, asset, asset.length), asset ]\n        end\n      end", "label": 4}
{"code": "def debug_application(self, environ, start_response):\n        \"\"\"Run the application and preserve the traceback frames.\n\n        :param environ: The environment which is passed into the wsgi application\n        :type environ: dict[str, object]\n        :param start_response: The start_response function of the wsgi application\n        :type start_response: (str, list[(str, str)]) -> None\n        :rtype: generator[str]\n\n        .. versionadded:: 0.1.0\n        \"\"\"\n        adapter = self._debug_map.bind_to_environ(environ)\n        if adapter.test():\n            _, args = adapter.match()\n            return self.handle_debug(environ, start_response, args[\"traceback_id\"])\n        else:\n            return super(DebuggedJsonRpcApplication, self).debug_application(environ,\n                                                                             start_response)", "label": 1}
{"code": "public static base_response clear(nitro_service client) throws Exception {\n\t\tnspbr6 clearresource = new nspbr6();\n\t\treturn clearresource.perform_operation(client,\"clear\");\n\t}", "label": 0}
{"code": "def enforce_available_locales!(locale)\n      if locale != false && config.enforce_available_locales\n        raise I18n::InvalidLocale.new(locale) if !locale_available?(locale)\n      end\n    end", "label": 4}
{"code": "func (t *Torrent) numTotalPeers() int {\n\tpeers := make(map[string]struct{})\n\tfor conn := range t.conns {\n\t\tra := conn.conn.RemoteAddr()\n\t\tif ra == nil {\n\t\t\t// It's been closed and doesn't support RemoteAddr.\n\t\t\tcontinue\n\t\t}\n\t\tpeers[ra.String()] = struct{}{}\n\t}\n\tfor addr := range t.halfOpen {\n\t\tpeers[addr] = struct{}{}\n\t}\n\tt.peers.Each(func(peer Peer) {\n\t\tpeers[fmt.Sprintf(\"%s:%d\", peer.IP, peer.Port)] = struct{}{}\n\t})\n\treturn len(peers)\n}", "label": 5}
{"code": "def validate_exclusive_use_of_hash_constraints!(conf, attribute)\n      return unless is_hash?(conf)\n      if conf.key?(:only) && conf.key?(:except)\n        raise CookiesConfigError.new(\"#{attribute} cookie config is invalid, simultaneous use of conditional arguments `only` and `except` is not permitted.\")\n      end\n    end", "label": 4}
{"code": "public function setLocation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Debugger\\V2\\SourceLocation::class);\n        $this->location = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func parseCAKey(bytes []byte, allowedLogins []string) (services.CertAuthority, services.Role, error) {\n\tcaFormat, err := certificateAuthorityFormat(bytes)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\n\tif caFormat == teleport.AuthorizedKeys {\n\t\treturn parseAuthorizedKeys(bytes, allowedLogins)\n\t}\n\treturn parseKnownHosts(bytes, allowedLogins)\n}", "label": 5}
{"code": "def finished_file(file, lints)\n      super\n\n      if lints.any?\n        lints.each do |lint|\n          linters_with_lints[lint.linter.name] |= [lint.filename]\n          linters_lint_count[lint.linter.name] += 1\n        end\n      end\n    end", "label": 4}
{"code": "public static base_response unset(nitro_service client, sslocspresponder resource, String[] args) throws Exception{\n\t\tsslocspresponder unsetresource = new sslocspresponder();\n\t\tunsetresource.name = resource.name;\n\t\tunsetresource.insertclientcert = resource.insertclientcert;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "private function getSession(array &$data)\n    {\n        $session = array_shift($data['queue']);\n\n        if ($session) {\n            if ($session['expiration'] - self::DURATION_ONE_MINUTE < $this->time()) {\n                return $this->getSession($data);\n            }\n\n            $data['inUse'][$session['name']] = $session + [\n                'lastActive' => $this->time()\n            ];\n\n            if ($this->config['shouldAutoDownsize']) {\n                $this->manageSessionsToDelete($data);\n            }\n        }\n\n        return $session;\n    }", "label": 2}
{"code": "public void sub(Vector3d v1) {\n        x -= v1.x;\n        y -= v1.y;\n        z -= v1.z;\n    }", "label": 0}
{"code": "public Set<String> rangeByRank(final long start, final long end) {\n        return doWithJedis(new JedisCallable<Set<String>>() {\n            @Override\n            public Set<String> call(Jedis jedis) {\n                return jedis.zrange(getKey(), start, end);\n            }\n        });\n    }", "label": 0}
{"code": "public static vlan[] get(nitro_service service) throws Exception{\n\t\tvlan obj = new vlan();\n\t\tvlan[] response = (vlan[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (r *HiveResponse) AddHive(hive *bees.BeeFactoryInterface) {\n\tr.hives[(*hive).Name()] = hive\n}", "label": 5}
{"code": "func isUDPAddrResolvable(fl FieldLevel) bool {\n\n\tif !isIP4Addr(fl) && !isIP6Addr(fl) {\n\t\treturn false\n\t}\n\n\t_, err := net.ResolveUDPAddr(\"udp\", fl.Field().String())\n\n\treturn err == nil\n}", "label": 5}
{"code": "function formatter (fail) {\n      return fail.map(function oops (err) {\n        return {\n            line: err.line\n          , column: err.character\n          , message: err.reason\n          , ref: err\n        };\n      });\n    }", "label": 3}
{"code": "public static int cudnnPoolingForward(\n        cudnnHandle handle, \n        cudnnPoolingDescriptor poolingDesc, \n        Pointer alpha, \n        cudnnTensorDescriptor xDesc, \n        Pointer x, \n        Pointer beta, \n        cudnnTensorDescriptor yDesc, \n        Pointer y)\n    {\n        return checkResult(cudnnPoolingForwardNative(handle, poolingDesc, alpha, xDesc, x, beta, yDesc, y));\n    }", "label": 0}
{"code": "public static base_response unset(nitro_service client, aaaparameter resource, String[] args) throws Exception{\n\t\taaaparameter unsetresource = new aaaparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def load_factor(ts, resolution=None, norm=None):\n    \"\"\"\n    Calculate the ratio of input vs. norm over a given interval.\n\n    Parameters\n    ----------\n    ts : pandas.Series\n        timeseries\n    resolution : str, optional\n        interval over which to calculate the ratio\n        default: resolution of the input timeseries\n    norm : int | float, optional\n        denominator of the ratio\n        default: the maximum of the input timeseries\n\n    Returns\n    -------\n    pandas.Series\n    \"\"\"\n    if norm is None:\n        norm = ts.max()\n\n    if resolution is not None:\n        ts = ts.resample(rule=resolution).mean()\n\n    lf = ts / norm\n\n    return lf", "label": 1}
{"code": "@Api\n\tpublic void setUseCache(boolean useCache) {\n\t\tif (null == cacheManagerService && useCache) {\n\t\t\tlog.warn(\"The caching plugin needs to be available to cache WMS requests. Not setting useCache.\");\n\t\t} else {\n\t\t\tthis.useCache = useCache;\n\t\t}\n\t}", "label": 0}
{"code": "def sort_after(other = nil, lock_permissions = false)\n      raise TypeError, 'other must be one of Channel, NilClass, or #resolve_id' unless other.is_a?(Channel) || other.nil? || other.respond_to?(:resolve_id)\n\n      other = @bot.channel(other.resolve_id) if other\n\n      # Container for the API request payload\n      move_argument = []\n\n      if other\n        raise ArgumentError, 'Can only sort a channel after a channel of the same type!' unless other.category? || (@type == other.type)\n\n        raise ArgumentError, 'Can only sort a channel after a channel in the same server!' unless other.server == server\n\n        # Store `others` parent (or if `other` is a category itself)\n        parent = if category? && other.category?\n                   # If we're sorting two categories, there is no new parent\n                   nil\n                 elsif other.category?\n                   # `other` is the category this channel will be moved into\n                   other\n                 else\n                   # `other`'s parent is the category this channel will be\n                   # moved into (if it exists)\n                   other.parent\n                 end\n      end\n\n      # Collect and sort the IDs within the context (category or not) that we\n      # need to form our payload with\n      ids = if parent\n              parent.children\n            else\n              @server.channels.reject(&:parent_id).select { |c| c.type == @type }\n            end.sort_by(&:position).map(&:id)\n\n      # Move our channel ID after the target ID by deleting it,\n      # getting the index of `other`, and inserting it after.\n      ids.delete(@id) if ids.include?(@id)\n      index = other ? (ids.index { |c| c == other.id } || -1) + 1 : 0\n      ids.insert(index, @id)\n\n      # Generate `move_argument`, making the positions in order from how\n      # we have sorted them in the above logic\n      ids.each_with_index do |id, pos|\n        # These keys are present in each element\n        hash = { id: id, position: pos }\n\n        # Conditionally add `lock_permissions` and `parent_id` if we're\n        # iterating past ourself\n        if id == @id\n          hash[:lock_permissions] = true if lock_permissions\n          hash[:parent_id] = parent.nil? ? nil : parent.id\n        end\n\n        # Add it to the stack\n        move_argument << hash\n      end\n\n      API::Server.update_channel_positions(@bot.token, @server.id, move_argument)\n    end", "label": 4}
{"code": "private function getChecksumsMiddleware()\n    {\n        return function (callable $handler) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler) {\n                // Accept \"ContentSHA256\" with a lowercase \"c\" to match other Glacier params.\n                if (!$command['ContentSHA256'] && $command['contentSHA256']) {\n                    $command['ContentSHA256'] = $command['contentSHA256'];\n                    unset($command['contentSHA256']);\n                }\n\n                // If uploading, then make sure checksums are added.\n                $name = $command->getName();\n                if (($name === 'UploadArchive' || $name === 'UploadMultipartPart')\n                    && (!$command['checksum'] || !$command['ContentSHA256'])\n                ) {\n                    $body = $request->getBody();\n                    if (!$body->isSeekable()) {\n                        throw new CouldNotCreateChecksumException('sha256');\n                    }\n\n                    // Add a tree hash if not provided.\n                    if (!$command['checksum']) {\n                        $body = new HashingStream(\n                            $body, new TreeHash(),\n                            function ($result) use ($command, &$request) {\n                                $request = $request->withHeader(\n                                    'x-amz-sha256-tree-hash',\n                                    bin2hex($result)\n                                );\n                            }\n                        );\n                    }\n\n                    // Add a linear content hash if not provided.\n                    if (!$command['ContentSHA256']) {\n                        $body = new HashingStream(\n                            $body, new PhpHash('sha256'),\n                            function ($result) use ($command) {\n                                $command['ContentSHA256'] = bin2hex($result);\n                            }\n                        );\n                    }\n\n                    // Read the stream in order to calculate the hashes.\n                    while (!$body->eof()) {\n                        $body->read(1048576);\n                    }\n                    $body->seek(0);\n                }\n\n                // Set the content hash header if a value is in the command.\n                if ($command['ContentSHA256']) {\n                    $request = $request->withHeader(\n                        'x-amz-content-sha256',\n                        $command['ContentSHA256']\n                    );\n                }\n\n                return $handler($command, $request);\n            };\n        };\n    }", "label": 2}
{"code": "func (bee *Bee) LogErrorf(format string, args ...interface{}) {\n\ts := fmt.Sprintf(format, args...)\n\tlog.Errorf(\"[%s]: %s\", bee.Name(), s)\n\tLog(bee.Name(), s, 1)\n}", "label": 5}
{"code": "func NewAdminAuthServer(authServer *AuthServer, sessions session.Service, alog events.IAuditLog) (ClientI, error) {\n\tctx, err := NewAdminContext()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &AuthWithRoles{\n\t\tauthServer: authServer,\n\t\tchecker:    ctx.Checker,\n\t\tuser:       ctx.User,\n\t\talog:       alog,\n\t\tsessions:   sessions,\n\t}, nil\n}", "label": 5}
{"code": "protected function connection_tune($args)\n    {\n        $v = $args->read_short();\n        if ($v) {\n            $this->channel_max = $v;\n        }\n\n        $v = $args->read_long();\n        if ($v) {\n            $this->frame_max = $v;\n        }\n\n        // use server proposed value if not set\n        if ($this->heartbeat === null) {\n            $this->heartbeat = $args->read_short();\n        }\n\n        $this->x_tune_ok($this->channel_max, $this->frame_max, $this->heartbeat);\n    }", "label": 2}
{"code": "def bind_collection_to_model_cls(cls):\n        \"\"\"Bind collection to model's class.\n\n        If collection was not specialized in process of model's declaration,\n        subclass of collection will be created.\n        \"\"\"\n        cls.Collection = type('{0}.Collection'.format(cls.__name__),\n                              (cls.Collection,),\n                              {'value_type': cls})\n        cls.Collection.__module__ = cls.__module__", "label": 1}
{"code": "public static <T> Collection<MemberResponse<T>> executeOptimistic(IExecutorService execSvc, Set<Member> members, Callable<T> callable) {\n    \treturn executeOptimistic(execSvc, members, callable, 60, TimeUnit.SECONDS);\n    }", "label": 0}
{"code": "func (p *PortBinding) GetCopy() PortBinding {\n\treturn PortBinding{\n\t\tProto:       p.Proto,\n\t\tIP:          GetIPCopy(p.IP),\n\t\tPort:        p.Port,\n\t\tHostIP:      GetIPCopy(p.HostIP),\n\t\tHostPort:    p.HostPort,\n\t\tHostPortEnd: p.HostPortEnd,\n\t}\n}", "label": 5}
{"code": "function IndexEntry($txt, $xref = '')\n\t{\n\t\tif ($xref) {\n\t\t\t$this->IndexEntrySee($txt, $xref);\n\t\t\treturn;\n\t\t}\n\n\t\t// Search the reference (AND Ref/PageNo) in the array\n\t\t$Present = false;\n\t\tif ($this->keep_block_together) {\n\t\t\t// do nothing\n\t\t} /* -- TABLES -- */ elseif ($this->kwt) {\n\t\t\t$size = count($this->kwt_Reference);\n\t\t\tfor ($i = 0; $i < $size; $i++) {\n\t\t\t\tif (isset($this->kwt_Reference[$i]['t']) && $this->kwt_Reference[$i]['t'] == $txt) {\n\t\t\t\t\t$Present = true;\n\t\t\t\t\tif ($this->page != $this->kwt_Reference[$i]['op']) {\n\t\t\t\t\t\t$this->kwt_Reference[$i]['op'] = $this->page;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!$Present) { // If not found, add it\n\t\t\t\t$this->kwt_Reference[] = ['t' => $txt, 'op' => $this->page];\n\t\t\t}\n\t\t} /* -- END TABLES -- */ else {\n\t\t\t$size = count($this->Reference);\n\t\t\tfor ($i = 0; $i < $size; $i++) {\n\t\t\t\tif (isset($this->Reference[$i]['t']) && $this->Reference[$i]['t'] == $txt) {\n\t\t\t\t\t$Present = true;\n\t\t\t\t\tif (!in_array($this->page, $this->Reference[$i]['p'])) {\n\t\t\t\t\t\t$this->Reference[$i]['p'][] = $this->page;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!$Present) { // If not found, add it\n\t\t\t\t$this->Reference[] = ['t' => $txt, 'p' => [$this->page]];\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "func setKernelBoolParam(path string, on bool) error {\n\tvalue := byte('0')\n\tif on {\n\t\tvalue = byte('1')\n\t}\n\treturn ioutil.WriteFile(path, []byte{value, '\\n'}, 0644)\n}", "label": 5}
{"code": "def read_fixture_files(path)\n        yaml_files = Dir[\"#{path}/{**,*}/*.yml\"].select { |f|\n          ::File.file?(f)\n        } + [yaml_file_path(path)]\n\n        yaml_files.each_with_object({}) do |file, fixtures|\n          FixtureSet::File.open(file) do |fh|\n            self.model_class ||= fh.model_class if fh.model_class\n            fh.each do |fixture_name, row|\n              fixtures[fixture_name] = ActiveRecord::Fixture.new(row, model_class)\n            end\n          end\n        end\n      end", "label": 4}
{"code": "def each_remote_read\n      return enum_for(:each_remote_read) unless block_given?\n      begin\n        loop do\n          resp = remote_read\n          break if resp.nil?  # the last response was received\n          yield resp\n        end\n      ensure\n        set_input_stream_done\n      end\n    end", "label": 4}
{"code": "def before_handling_requests(forked, options)\n      if forked\n        # Reseed pseudo-random number generator for security reasons.\n        srand\n      end\n\n      if options[\"process_title\"] && !options[\"process_title\"].empty?\n        $0 = options[\"process_title\"] + \": \" + options[\"app_group_name\"]\n      end\n\n      # If we were forked from a preloader process then clear or\n      # re-establish ActiveRecord database connections. This prevents\n      # child processes from concurrently accessing the same\n      # database connection handles.\n      if forked && defined?(ActiveRecord::Base)\n        if ActiveRecord::Base.respond_to?(:clear_all_connections!)\n          ActiveRecord::Base.clear_all_connections!\n        elsif ActiveRecord::Base.respond_to?(:clear_active_connections!)\n          ActiveRecord::Base.clear_active_connections!\n        elsif ActiveRecord::Base.respond_to?(:connected?) &&\n              ActiveRecord::Base.connected?\n          ActiveRecord::Base.establish_connection\n        end\n      end\n\n      # Fire off events.\n      PhusionPassenger.call_event(:starting_worker_process, forked)\n      if options[\"pool_account_username\"] && options[\"pool_account_password_base64\"]\n        password = options[\"pool_account_password_base64\"].unpack('m').first\n        PhusionPassenger.call_event(:credentials,\n          options[\"pool_account_username\"], password)\n      else\n        PhusionPassenger.call_event(:credentials, nil, nil)\n      end\n    end", "label": 4}
{"code": "def plot_by_gene_and_domain(name, seqs, tax, id2name):\n    \"\"\"\n    plot insertions for each gene and domain\n    \"\"\"\n    for gene in set([seq[0] for seq in list(seqs.values())]):\n        for domain in set([seq[1] for seq in list(seqs.values())]):\n            plot_insertions(name, seqs, gene, domain, tax, id2name)", "label": 1}
{"code": "def post(self, *args):\n        \"\"\"\n        Start a new filewatcher at the specified path.\n        \"\"\"\n        filepath = self.get_body_argument('filepath')\n        if not self.fs.exists(filepath):\n            raise tornado.web.HTTPError(404)\n\n        Filewatcher.add_directory_to_watch(filepath)\n        self.write({'msg':'Watcher added for {}'.format(filepath)})", "label": 1}
{"code": "public function showNewPassword($token)\n    {\n        try {\n            $token = decrypt($token);\n\n            [$authorId, $token] = explode('|', $token);\n\n            $author = WinkAuthor::findOrFail($authorId);\n        } catch (Throwable $e) {\n            return redirect()->route('wink.password.forgot')->with('invalidResetToken', true);\n        }\n\n        if (cache('password.reset.'.$authorId) != $token) {\n            return redirect()->route('wink.password.forgot')->with('invalidResetToken', true);\n        }\n\n        cache()->forget('password.reset.'.$authorId);\n\n        $author->password = \\Hash::make($password = Str::random());\n\n        $author->save();\n\n        return view('wink::reset-password', [\n            'password' => $password,\n        ]);\n    }", "label": 2}
{"code": "def api_methods_in(klass)\n      methods = klass.send(:instance_methods, false) - [:actions]\n      methods.sort.each_with_object([]) do |method_name, accumulator|\n        unless method_name.to_s.include?('with') ||\n               method_name.to_s.include?('without')\n          accumulator << method_name\n        end\n        accumulator\n      end\n    end", "label": 4}
{"code": "function (key, n) {\n  var int;\n  var numeral;\n\n  try {\n    int = key.getInterval(n);\n  } catch (err) {\n    try {\n      int = key.getInterval(n.clean());\n    } catch (err2) {\n      int = key.getInterval(n.toggleAccidental());\n    }\n  }\n\n  // Although dim7, for example, is a valid interval, we don't want a bbVII in our symbol\n  if (!interval.isPerfect(int.number) && int.quality === 'dim') {\n    int = interval.parse((int.number - 1).toString());\n  }\n\n  numeral = romanNumeral[int.number];\n\n  if (int.quality === 'm' || int.quality === 'dim') numeral = 'b' + numeral;\n  if (int.quality === 'aug') numeral = '#' + numeral;\n\n  return numeral;\n}", "label": 3}
{"code": "func extractRolesFromCert(cert *ssh.Certificate) ([]string, error) {\n\tdata, ok := cert.Extensions[teleport.CertExtensionTeleportRoles]\n\tif !ok {\n\t\t// it's ok to not have any roles in the metadata\n\t\treturn nil, nil\n\t}\n\treturn services.UnmarshalCertRoles(data)\n}", "label": 5}
{"code": "def apply_to_submeasures(subs, type, values, unpaired_type=nil, unpaired_keys=[])\n      new_subs = []\n      subs.each do |sub|\n        # this unless prevents us from forcing an exclusion or excepion onto a measure that has a submeasure without\n        # an exclusion or exception, but other populations with an exclusion or excepion.\n        unless unpaired_keys.include? sub[unpaired_type]\n          # duplicate each new value if it is set, otherwise set this key on each submeasure.\n          values.each do |value|\n            if (sub[type] and sub[type] != value.id)\n              tmp = {}\n              HQMF::PopulationCriteria::ALL_POPULATION_CODES.each do |key|\n                tmp[key] = sub[key] if sub[key]\n              end\n              sub = tmp\n              new_subs << sub\n            end\n            sub[type] = value.id\n          end\n        end\n      end\n      subs.concat(new_subs)\n    end", "label": 4}
{"code": "public void removeLicenseFromArtifact(final String gavc, final String licenseId) {\n        final DbArtifact dbArtifact = getArtifact(gavc);\n\n        //\n        // The artifact may not have the exact string associated with it, but rather one\n        // matching license regexp expression.\n        //\n        repositoryHandler.removeLicenseFromArtifact(dbArtifact, licenseId, licenseMatcher);\n    }", "label": 0}
{"code": "public static void startTimer(final String type) {\n    TransactionLogger instance = getInstance();\n    if (instance == null) {\n      return;\n    }\n\n    instance.components.putIfAbsent(type, new Component(type));\n    instance.components.get(type).startTimer();\n  }", "label": 0}
{"code": "def identify\n      MiniMagick::Tool::Identify.new do |builder|\n        yield builder if block_given?\n        builder << path\n      end\n    end", "label": 4}
{"code": "func (sink *influxdbSink) parseAggregateQueryRow(rawRow influx_models.Row, aggregationLookup map[core.AggregationType]int, bucketSize time.Duration) ([]core.TimestampedAggregationValue, error) {\n\tvals := make([]core.TimestampedAggregationValue, len(rawRow.Values))\n\twasInt := make(map[string]bool, len(aggregationLookup))\n\n\tfor i, rawVal := range rawRow.Values {\n\t\tval := core.TimestampedAggregationValue{\n\t\t\tBucketSize: bucketSize,\n\t\t\tAggregationValue: core.AggregationValue{\n\t\t\t\tAggregations: map[core.AggregationType]core.MetricValue{},\n\t\t\t},\n\t\t}\n\n\t\tif ts, err := time.Parse(time.RFC3339, rawVal[0].(string)); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"Unable to parse timestamp %q in series %q\", rawVal[0].(string), rawRow.Name)\n\t\t} else {\n\t\t\tval.Timestamp = ts\n\t\t}\n\n\t\t// The Influx client decods numeric fields to json.Number (a string), so we have to try decoding to both types of numbers\n\n\t\t// Count is always a uint64\n\t\tif countIndex, ok := aggregationLookup[core.AggregationTypeCount]; ok {\n\t\t\tif err := json.Unmarshal([]byte(rawVal[countIndex].(json.Number).String()), &val.Count); err != nil {\n\t\t\t\tglog.Errorf(\"Unable to parse count value in series %q: %v\", rawRow.Name, err)\n\t\t\t\treturn nil, fmt.Errorf(\"Unable to parse values in series %q\", rawRow.Name)\n\t\t\t}\n\t\t}\n\n\t\t// The rest of the aggregation values can be either float or int, so attempt to parse both\n\t\tif err := populateAggregations(rawRow.Name, rawVal, &val, aggregationLookup, wasInt); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tvals[i] = val\n\t}\n\n\t// figure out whether each aggregation was full of float values, or int values\n\tsetAggregationValueTypes(vals, wasInt)\n\n\treturn vals, nil\n}", "label": 5}
{"code": "func ThisFunction() string {\n\tvar pc [32]uintptr\n\truntime.Callers(2, pc[:])\n\treturn runtime.FuncForPC(pc[0]).Name()\n}", "label": 5}
{"code": "func ServeMux(m ServeMuxMap) {\n\tif len(os.Args) != 2 {\n\t\tfmt.Fprintf(os.Stderr,\n\t\t\t\"Invoked improperly. This is an internal command that shouldn't\\n\"+\n\t\t\t\t\"be manually invoked.\\n\")\n\t\tos.Exit(1)\n\t}\n\n\topts, ok := m[os.Args[1]]\n\tif !ok {\n\t\tfmt.Fprintf(os.Stderr, \"Unknown plugin: %s\\n\", os.Args[1])\n\t\tos.Exit(1)\n\t}\n\n\tServe(opts)\n}", "label": 5}
{"code": "public static sslcertlink[] get(nitro_service service) throws Exception{\n\t\tsslcertlink obj = new sslcertlink();\n\t\tsslcertlink[] response = (sslcertlink[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setMetadata($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->metadata = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private function doDeserialize(\\stdClass $c, $class)\n    {\n        $annotation = new $class([]);\n        foreach ($c as $property => $value) {\n            if ($property === '$ref') {\n                $property = 'ref';\n            }\n\n            if (substr($property, 0, 2) === 'x-') {\n                if ($annotation->x === UNDEFINED) {\n                    $annotation->x = [];\n                }\n                $custom = substr($property, 2);\n                $annotation->x[$custom] = $value;\n            } else {\n                $annotation->$property = $this->doDeserializeProperty($annotation, $property, $value);\n            }\n        }\n        return $annotation;\n    }", "label": 2}
{"code": "public function parse($rules)\n    {\n        $this->rules = $rules;\n        $parsed = [];\n        foreach ($this->getRules() as $rulesArray) {\n            $column = $this->getColumn($rulesArray);\n            $attributes = $this->getAttributes($column, $rulesArray);\n            $parsed[$column] = $attributes;\n        }\n\n        return $parsed;\n    }", "label": 2}
{"code": "def _nama(self):\n        \"\"\"Mengembalikan representasi string untuk nama entri ini.\n\n        :returns: String representasi nama entri\n        :rtype: str\n        \"\"\"\n\n        hasil = self.nama\n        if self.nomor:\n            hasil += \" [{}]\".format(self.nomor)\n        if self.kata_dasar:\n            hasil = \" \u00bb \".join(self.kata_dasar) + \" \u00bb \" + hasil\n        return hasil", "label": 1}
{"code": "public static String determineFieldName(@Nonnull final String methodName) {\n\t\tCheck.notEmpty(methodName, \"methodName\");\n\t\tfinal Matcher m = PATTERN.matcher(methodName);\n\t\tCheck.stateIsTrue(m.find(), \"passed method name '%s' is not applicable\", methodName);\n\t\treturn m.group(2).substring(0, 1).toLowerCase() + m.group(2).substring(1);\n\t}", "label": 0}
{"code": "def remove(self, rev, permanent=False):\n        \"\"\"Removes a revision from this changelist\n\n        :param rev: Revision to remove\n        :type rev: :class:`.Revision`\n        :param permanent: Whether or not we need to set the changelist to default\n        :type permanent: bool\n        \"\"\"\n        if not isinstance(rev, Revision):\n            raise TypeError('argument needs to be an instance of Revision')\n\n        if rev not in self:\n            raise ValueError('{} not in changelist'.format(rev))\n\n        self._files.remove(rev)\n        if not permanent:\n            rev.changelist = self._connection.default", "label": 1}
{"code": "function Formatter(format, timeFormat) {\n\tformat = format || '%(message)';\n\ttimeFormat = timeFormat || '%Y-%m-%d %H:%M:%S';\n\n\t/**\n\t * @private\n\t * @type {string}\n\t */\n\tthis._format = format;\n\n\t/**\n\t * @private\n\t * @type {string}\n\t */\n\tthis._timeFormat = timeFormat;\n}", "label": 3}
{"code": "func PgTableIndexes(db XODB, schema string, table string) ([]*Index, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`DISTINCT ic.relname, ` + // ::varchar AS index_name\n\t\t`i.indisunique, ` + // ::boolean AS is_unique\n\t\t`i.indisprimary, ` + // ::boolean AS is_primary\n\t\t`0, ` + // ::integer AS seq_no\n\t\t`'', ` + // ::varchar AS origin\n\t\t`false ` + // ::boolean AS is_partial\n\t\t`FROM pg_index i ` +\n\t\t`JOIN ONLY pg_class c ON c.oid = i.indrelid ` +\n\t\t`JOIN ONLY pg_namespace n ON n.oid = c.relnamespace ` +\n\t\t`JOIN ONLY pg_class ic ON ic.oid = i.indexrelid ` +\n\t\t`WHERE i.indkey <> '0' AND n.nspname = $1 AND c.relname = $2`\n\n\t// run query\n\tXOLog(sqlstr, schema, table)\n\tq, err := db.Query(sqlstr, schema, table)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*Index{}\n\tfor q.Next() {\n\t\ti := Index{}\n\n\t\t// scan\n\t\terr = q.Scan(&i.IndexName, &i.IsUnique, &i.IsPrimary, &i.SeqNo, &i.Origin, &i.IsPartial)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &i)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "func (m *Manager) GetPubKeyLocations(prefix string) ([]string, error) {\n\tensureLogger(m.Debug)\n\tif prefix == \"\" {\n\t\treturn nil, fmt.Errorf(\"empty prefix\")\n\t}\n\n\tkls, err := m.metaDiscoverPubKeyLocations(prefix)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"prefix meta discovery error\"), err)\n\t}\n\n\tif len(kls) == 0 {\n\t\treturn nil, fmt.Errorf(\"meta discovery on %s resulted in no keys\", prefix)\n\t}\n\n\treturn kls, nil\n}", "label": 5}
{"code": "func CheckRouteOverlaps(toCheck *net.IPNet) error {\n\tif networkGetRoutesFct == nil {\n\t\tnetworkGetRoutesFct = ns.NlHandle().RouteList\n\t}\n\tnetworks, err := networkGetRoutesFct(nil, netlink.FAMILY_V4)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, network := range networks {\n\t\tif network.Dst != nil && NetworkOverlaps(toCheck, network.Dst) {\n\t\t\treturn ErrNetworkOverlaps\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static function localeHasShortUnits($locale)\n    {\n        return static::executeWithLocale($locale, function ($newLocale, TranslatorInterface $translator) {\n            return $newLocale &&\n                (\n                    ($y = static::translateWith($translator, 'y')) !== 'y' &&\n                    $y !== static::translateWith($translator, 'year')\n                ) || (\n                    ($y = static::translateWith($translator, 'd')) !== 'd' &&\n                    $y !== static::translateWith($translator, 'day')\n                ) || (\n                    ($y = static::translateWith($translator, 'h')) !== 'h' &&\n                    $y !== static::translateWith($translator, 'hour')\n                );\n        });\n    }", "label": 2}
{"code": "function(result, feedbackCellField) {\n      var newState = $.extend({}, result);\n      this.feedbackCell.set(feedbackCellField, newState, {silent: true});\n      this.feedbackCell.trigger('change:' + feedbackCellField);\n    }", "label": 3}
{"code": "public RedwoodConfiguration collapseExact(){\r\n    tasks.add(new Runnable() { public void run() { Redwood.spliceHandler(VisibilityHandler.class, new RepeatedRecordHandler(RepeatedRecordHandler.EXACT), OutputHandler.class); } });\r\n    return this;\r\n  }", "label": 0}
{"code": "def addResourceFile(self, pid, resource_file, resource_filename=None, progress_callback=None):\n        \"\"\" Add a new file to an existing resource\n\n        :param pid: The HydroShare ID of the resource\n        :param resource_file: a read-only binary file-like object (i.e. opened with the flag 'rb') or a string\n            representing path to file to be uploaded as part of the new resource\n        :param resource_filename: string representing the filename of the resource file.  Must be specified\n            if resource_file is a file-like object.  If resource_file is a string representing a valid file path,\n            and resource_filename is not specified, resource_filename will be equal to os.path.basename(resource_file).\n            is a string\n        :param progress_callback: user-defined function to provide feedback to the user about the progress\n            of the upload of resource_file.  For more information, see:\n            http://toolbelt.readthedocs.org/en/latest/uploading-data.html#monitoring-your-streaming-multipart-upload\n\n        :return: Dictionary containing 'resource_id' the ID of the resource to which the file was added, and\n                'file_name' the filename of the file added.\n\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n        \"\"\"\n        url = \"{url_base}/resource/{pid}/files/\".format(url_base=self.url_base,\n                                                        pid=pid)\n\n        params = {}\n        close_fd = self._prepareFileForUpload(params, resource_file, resource_filename)\n\n        encoder = MultipartEncoder(params)\n        if progress_callback is None:\n            progress_callback = default_progress_callback\n        monitor = MultipartEncoderMonitor(encoder, progress_callback)\n\n        r = self._request('POST', url, data=monitor, headers={'Content-Type': monitor.content_type})\n\n        if close_fd:\n            fd = params['file'][1]\n            fd.close()\n\n        if r.status_code != 201:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('POST', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'POST', r.status_code))\n\n        response = r.json()\n        # assert(response['resource_id'] == pid)\n\n        return response", "label": 1}
{"code": "func PgAmprocByOid(db XODB, oid pgtypes.Oid) (*PgAmproc, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, amprocfamily, amproclefttype, amprocrighttype, amprocnum, amproc ` +\n\t\t`FROM pg_catalog.pg_amproc ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpa := PgAmproc{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pa.Tableoid, &pa.Cmax, &pa.Xmax, &pa.Cmin, &pa.Xmin, &pa.Oid, &pa.Ctid, &pa.Amprocfamily, &pa.Amproclefttype, &pa.Amprocrighttype, &pa.Amprocnum, &pa.Amproc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "public function setLogEntryErrors($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::INT32, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Rpc\\Status::class);\n        $this->log_entry_errors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def locus_reads_dataframe(*args, **kwargs):\n    \"\"\"\n    Traverse a BAM file to find all the reads overlapping a specified locus.\n\n    Parameters are the same as those for read_locus_generator.\n    \"\"\"\n    df_builder = DataFrameBuilder(\n        LocusRead,\n        variant_columns=False,\n        converters={\n            \"reference_positions\": list_to_string,\n            \"quality_scores\": list_to_string,\n        })\n    for locus_read in locus_read_generator(*args, **kwargs):\n        df_builder.add(variant=None, element=locus_read)\n    return df_builder.to_dataframe()", "label": 1}
{"code": "function makeTypeConstraintsSchema(typeName) {\n  const allTypeConstraints = typeSpecificConstraintSchemas();\n  const constraints = Object.assign({ }, universalConstraintSchemas(typeEqualitySchemas[typeName]), allTypeConstraints[typeName]);\n\n  return joi.object().keys(constraints)\n    // Prevent the use of more than one constraint from the \"required value\" category\n    .without('required', [ 'mustNotBeMissing', 'mustNotBeNull' ])\n    .without('mustNotBeMissing', [ 'required', 'mustNotBeNull' ])\n    .without('mustNotBeNull', [ 'required', 'mustNotBeMissing' ])\n\n    // Prevent the use of more than one constraint from the \"equality\" category\n    .without('mustEqual', [ 'mustEqualStrict', 'mustEqualIgnoreCase' ])\n    .without('mustEqualStrict', [ 'mustEqual', 'mustEqualIgnoreCase' ])\n    .without('mustEqualIgnoreCase', [ 'mustEqual', 'mustEqualStrict' ])\n\n    // Prevent the use of more than one constraint from the \"minimum value\" category\n    .without('minimumValue', [ 'minimumValueExclusive', 'mustEqual', 'mustEqualStrict', 'mustEqualIgnoreCase' ])\n    .without('minimumValueExclusive', [ 'minimumValue', 'mustEqual', 'mustEqualStrict', 'mustEqualIgnoreCase' ])\n\n    // Prevent the use of more than one constraint from the \"maximum value\" category\n    .without('maximumValue', [ 'maximumValueExclusive', 'mustEqualStrict', 'mustEqual', 'mustEqualIgnoreCase' ])\n    .without('maximumValueExclusive', [ 'maximumValue', 'mustEqualStrict', 'mustEqual', 'mustEqualIgnoreCase' ])\n\n    // Prevent the use of more than one constraint from the \"immutability\" category\n    .without('immutable', [ 'immutableStrict', 'immutableWhenSet', 'immutableWhenSetStrict' ])\n    .without('immutableStrict', [ 'immutable', 'immutableWhenSet', 'immutableWhenSetStrict' ])\n    .without('immutableWhenSet', [ 'immutable', 'immutableStrict', 'immutableWhenSetStrict' ])\n    .without('immutableWhenSetStrict', [ 'immutable', 'immutableStrict', 'immutableWhenSet' ])\n\n    // Prevent the use of more than one constraint from the \"skip validation\" category\n    .without('skipValidationWhenValueUnchanged', [ 'skipValidationWhenValueUnchangedStrict' ]);\n}", "label": 3}
{"code": "public function replaceBatch($table, array $dataSet)\n    {\n        $this->enqueue(Operation::OP_REPLACE, $table, $dataSet);\n\n        return $this;\n    }", "label": 2}
{"code": "func (proxy *SCTPProxy) Run() {\n\tquit := make(chan bool)\n\tdefer close(quit)\n\tfor {\n\t\tclient, err := proxy.listener.Accept()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Stopping proxy on sctp/%v for sctp/%v (%s)\", proxy.frontendAddr, proxy.backendAddr, err)\n\t\t\treturn\n\t\t}\n\t\tgo proxy.clientLoop(client.(*sctp.SCTPConn), quit)\n\t}\n}", "label": 5}
{"code": "public function toArray()\n    {\n        if ($this->jobIdPrefix) {\n            $this->config['jobReference']['jobId'] = sprintf(\n                '%s-%s',\n                $this->jobIdPrefix,\n                $this->config['jobReference']['jobId']\n            );\n        }\n\n        return $this->config;\n    }", "label": 2}
{"code": "function renderTemplateToFile(templateFile, destFile, data, options) {\n    renderTemplateTextToFile(read(templateFile), normalizeFile(destFile), data, options);\n  }", "label": 3}
{"code": "def move(*args)\n      arguments(args, required: [:card_id]) do\n        assert_required REQUIRED_MOVE_CARD_PARAMS\n      end\n      params = arguments.params\n\n      params[\"accept\"] ||= ::Github::Client::Projects::PREVIEW_MEDIA\n\n      post_request(\"/projects/columns/cards/#{arguments.card_id}/moves\", params)\n    end", "label": 4}
{"code": "def out_of_date?(stamp)\n      all_prerequisite_tasks.any? { |prereq|\n        prereq_task = application[prereq, @scope]\n        if prereq_task.instance_of?(Rake::FileTask)\n          prereq_task.timestamp > stamp || @application.options.build_all\n        else\n          prereq_task.timestamp > stamp\n        end\n      }\n    end", "label": 4}
{"code": "def key_value_pairs(self):\n        \"\"\"\n        convert list to key value pairs\n        \n        This should also create unique id's to allow for any\n        dataset to be transposed, and then later manipulated\n        r1c1,r1c2,r1c3\n        r2c1,r2c2,r2c3\n        \n        should be converted to \n        ID  COLNUM  VAL\n        r1c1, \n        \"\"\"\n        self.op_data = []\n        hdrs = self.ip_data[0]\n        for row in self.ip_data[1:]:\n            id_col = row[0]\n            for col_num, col in enumerate(row):\n                self.op_data.append([id_col, hdrs[col_num], col])", "label": 1}
{"code": "function yamlFileSet(file, keyPath, value, options) {\n  if (_.isPlainObject(keyPath)) { // key is keyMapping\n    if (!_.isUndefined(options)) {\n      throw new Error('Wrong parameters. Cannot specify a keymapping and a value at the same time.');\n    }\n    if (_.isPlainObject(value)) {\n      options = value;\n      value = null;\n    } else {\n      options = {};\n    }\n  } else if (!_.isString(keyPath) && !_.isArray(keyPath)) {\n    throw new Error('Wrong parameter `keyPath`.');\n  }\n  options = _.sanitize(options, {encoding: 'utf-8', retryOnENOENT: true});\n  if (!exists(file)) {\n    touch(file);\n  }\n\n  let content = yaml.safeLoad(read(file, _.pick(options, 'encoding')));\n  if (_.isUndefined(content)) {\n    content = {};\n  }\n  content = _setValue(content, keyPath, value);\n  write(file, yaml.safeDump(content), options);\n}", "label": 3}
{"code": "def []=(name, value)\n      if name.to_s == 'body'\n        self.body = value\n      elsif name.to_s =~ /content[-_]type/i\n        header[name] = value\n      elsif name.to_s == 'charset'\n        self.charset = value\n      else\n        header[name] = value\n      end\n    end", "label": 4}
{"code": "public function setBlocks($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\Block::class);\n        $this->blocks = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public void setClasspath(Path classpath)\r\n    {\r\n        if (_classpath == null)\r\n        {\r\n            _classpath = classpath;\r\n        }\r\n        else\r\n        {\r\n            _classpath.append(classpath);\r\n        }\r\n        log(\"Verification classpath is \"+ _classpath,\r\n            Project.MSG_VERBOSE);\r\n    }", "label": 0}
{"code": "def find_closest_providers_for(attributes)\n      plugins = []\n      attributes.each do |attribute|\n        parts = normalize_and_validate(attribute)\n        raise Ohai::Exceptions::AttributeNotFound, \"No such attribute: \\'#{attribute}\\'\" unless @map[parts[0]]\n        attrs = select_closest_subtree(@map, attribute)\n        raise Ohai::Exceptions::ProviderNotFound, \"Cannot find plugin providing attribute: \\'#{attribute}\\'\" unless attrs\n        plugins += attrs[:_plugins]\n      end\n      plugins.uniq\n    end", "label": 4}
{"code": "public synchronized void abortTransaction() throws TransactionNotInProgressException\n    {\n        if(isInTransaction())\n        {\n            fireBrokerEvent(BEFORE_ROLLBACK_EVENT);\n            setInTransaction(false);\n            clearRegistrationLists();\n            referencesBroker.removePrefetchingListeners();\n            /*\n            arminw:\n            check if we in local tx, before do local rollback\n            Necessary, because ConnectionManager may do a rollback by itself\n            or in managed environments the used connection is already be closed\n            */\n            if(connectionManager.isInLocalTransaction()) this.connectionManager.localRollback();\n            fireBrokerEvent(AFTER_ROLLBACK_EVENT);\n        }\n    }", "label": 0}
{"code": "public function setTopSensitiveValues($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\ValueFrequency::class);\n        $this->top_sensitive_values = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public SerialMessage getNoMoreInformationMessage() {\r\n\t\tlogger.debug(\"Creating new message for application command WAKE_UP_NO_MORE_INFORMATION for node {}\", this.getNode().getNodeId());\r\n\t\tSerialMessage result = new SerialMessage(this.getNode().getNodeId(), SerialMessage.SerialMessageClass.SendData, SerialMessage.SerialMessageType.Request, SerialMessage.SerialMessageClass.SendData, SerialMessage.SerialMessagePriority.Low);\r\n    \tbyte[] newPayload = { \t(byte) this.getNode().getNodeId(), \r\n    \t\t\t\t\t\t\t2, \r\n\t\t\t\t\t\t\t\t(byte) getCommandClass().getKey(), \r\n\t\t\t\t\t\t\t\t(byte) WAKE_UP_NO_MORE_INFORMATION };\r\n    \tresult.setMessagePayload(newPayload);\r\n\r\n    \treturn result;\r\n\t}", "label": 0}
{"code": "public function removeBinding($role, array $members)\n    {\n        $bindings = $this->bindings;\n        foreach ((array) $bindings as $i => $binding) {\n            if ($binding['role'] == $role) {\n                $newMembers = array_diff($binding['members'], $members);\n                if (count($newMembers) != count($binding['members']) - count($members)) {\n                    throw new InvalidArgumentException('One or more role-members were not found.');\n                }\n                if (empty($newMembers)) {\n                    unset($bindings[$i]);\n                    $bindings = array_values($bindings);\n                } else {\n                    $binding['members'] = array_values($newMembers);\n                    $bindings[$i] = $binding;\n                }\n                $this->bindings = $bindings;\n\n                return $this;\n            }\n        }\n\n        throw new InvalidArgumentException('The role was not found.');\n    }", "label": 2}
{"code": "public void strokeEllipse(Rectangle rect, Color color, float linewidth) {\n\t\ttemplate.saveState();\n\t\tsetStroke(color, linewidth, null);\n\t\ttemplate.ellipse(origX + rect.getLeft(), origY + rect.getBottom(), origX + rect.getRight(),\n\t\t\t\torigY + rect.getTop());\n\t\ttemplate.stroke();\n\t\ttemplate.restoreState();\n\t}", "label": 0}
{"code": "def h4(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'h4_for', &block)\n      define_method(name) do\n        return platform.h4_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "def subtask(*args, **kwargs):\n    '''Decorator which prints out the name of the decorated function on\n    execution.\n    '''\n    depth = kwargs.get('depth', 2)\n    prefix = kwargs.get('prefix', '\\n' + '#' * depth + ' ')\n    tail = kwargs.get('tail', '\\n')\n    doc1 = kwargs.get('doc1', False)\n    color = kwargs.get('color', cyan)\n\n    def real_decorator(func):\n        if doc1:\n            return print_full_name(color=color, prefix=prefix,\n                                   tail=tail)(print_doc1(func))\n        return print_full_name(color=color, prefix=prefix, tail=tail)(func)\n\n    invoked = bool(not args or kwargs)\n    if not invoked:\n        # invoke decorator function which returns the wrapper function\n        return real_decorator(func=args[0])\n    return real_decorator", "label": 1}
{"code": "function _onScroll () {\n        _scrollY = window.scrollY;\n        if (_monitorTop && _dynamicCss) {\n            _updateDynamicCss();\n        }\n        _broadcaster.broadcastEvent(\"scroll\", {\n            top: _scrollY\n        });\n    }", "label": 3}
{"code": "def login(self, schema, username, password):\n        \"\"\"\n        connect here - use the other classes cls_oracle, cls_mysql, etc\n        otherwise this has the credentials used to access a share folder\n        \"\"\"\n        self.schema = schema\n        self.username = username\n        self.password = password\n        self.connection = schema", "label": 1}
{"code": "protected function getConnection()\n    {\n        $connection = $this->getClient()->getConnection();\n\n        if ($connection instanceof ReplicationInterface) {\n            $connection->switchTo('master');\n        }\n\n        return $connection;\n    }", "label": 2}
{"code": "public function setCluster($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\Cluster::class);\n        $this->cluster = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def ctr_mass(geom, masses):\n    \"\"\"Calculate the center of mass of the indicated geometry.\n\n    Take a geometry and atom masses and compute the location of\n    the center of mass.\n\n    Parameters\n    ----------\n    geom\n        length-3N |npfloat_| --\n        Coordinates of the atoms\n\n    masses\n        length-N OR length-3N |npfloat_| --\n        Atomic masses of the atoms. Length-3N option is to allow calculation of\n        a per-coordinate perturbed value.\n\n    Returns\n    -------\n    ctr\n        length-3 |npfloat_| --\n        Vector location of center of mass\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If `geom` & `masses` shapes are inconsistent\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from .base import safe_cast as scast\n\n    # Shape check\n    if len(geom.shape) != 1:\n        raise ValueError(\"Geometry is not a vector\")\n    ## end if\n    if len(masses.shape) != 1:\n        raise ValueError(\"Masses cannot be parsed as a vector\")\n    ## end if\n    if not geom.shape[0] % 3 == 0:\n        raise ValueError(\"Geometry is not length-3N\")\n    ## end if\n    if geom.shape[0] != 3*masses.shape[0] and geom.shape[0] != masses.shape[0]:\n        raise ValueError(\"Inconsistent geometry and masses vector lengths\")\n    ## end if\n\n    # If N masses are provided, expand to 3N; if 3N, retain.\n    if geom.shape[0] == 3*masses.shape[0]:\n        masses = masses.repeat(3)\n    ## end if\n\n    # Calculate the mass-weighted coordinates, reshape to group by coordinate\n    #  column-wise, sum each column, then divide by the sum of masses, which\n    #  must further be divided by three because there are three replicates\n    #  (possibly perturbed) of the mass of each atom.\n    ctr = np.multiply(geom, masses).reshape((geom.shape[0]//3, 3)) \\\n                                .sum(axis=0).squeeze() / (masses.sum() / 3)\n\n    # Return the vector\n    return ctr", "label": 1}
{"code": "def delete(*args)\n      arguments(args, required: [:card_id])\n      params = arguments.params\n\n      params[\"accept\"] ||= ::Github::Client::Projects::PREVIEW_MEDIA\n\n      delete_request(\"/projects/columns/cards/#{arguments.card_id}\", params)\n    end", "label": 4}
{"code": "public function executePartitionedUpdate($statement, array $options = [])\n    {\n        $session = $this->selectSession(SessionPoolInterface::CONTEXT_READWRITE);\n\n        $transaction = $this->operation->transaction($session, [\n            'transactionOptions' => [\n                'partitionedDml' => []\n            ]\n        ]);\n\n        try {\n            return $this->operation->executeUpdate($session, $transaction, $statement, [\n                'statsItem' => 'rowCountLowerBound'\n            ] + $options);\n        } finally {\n            $session->setExpiration();\n        }\n    }", "label": 2}
{"code": "def build_html_listbox(lst, nme):\n    \"\"\"\n    returns the html to display a listbox\n    \"\"\"\n    res = '<select name=\"' + nme + '\" multiple=\"multiple\">\\n'\n    for l in lst:\n        res += '    <option>' + str(l) + '</option>\\n'\n    res += '</select>\\n'\n\n    return res", "label": 1}
{"code": "func (r *DrvRegistry) WalkIPAMs(ifn IPAMWalkFunc) {\n\ttype ipamVal struct {\n\t\tname string\n\t\tdata *ipamData\n\t}\n\n\tr.Lock()\n\tivl := make([]ipamVal, 0, len(r.ipamDrivers))\n\tfor k, v := range r.ipamDrivers {\n\t\tivl = append(ivl, ipamVal{name: k, data: v})\n\t}\n\tr.Unlock()\n\n\tfor _, iv := range ivl {\n\t\tif ifn(iv.name, iv.data.driver, iv.data.capability) {\n\t\t\tbreak\n\t\t}\n\t}\n}", "label": 5}
{"code": "public function batchGetAssetsHistory($parent, $contentType, $readTimeWindow, array $optionalArgs = [])\n    {\n        $request = new BatchGetAssetsHistoryRequest();\n        $request->setParent($parent);\n        $request->setContentType($contentType);\n        $request->setReadTimeWindow($readTimeWindow);\n        if (isset($optionalArgs['assetNames'])) {\n            $request->setAssetNames($optionalArgs['assetNames']);\n        }\n\n        $requestParams = new RequestParamsHeaderDescriptor([\n          'parent' => $request->getParent(),\n        ]);\n        $optionalArgs['headers'] = isset($optionalArgs['headers'])\n            ? array_merge($requestParams->getHeader(), $optionalArgs['headers'])\n            : $requestParams->getHeader();\n\n        return $this->startCall(\n            'BatchGetAssetsHistory',\n            BatchGetAssetsHistoryResponse::class,\n            $optionalArgs,\n            $request\n        )->wait();\n    }", "label": 2}
{"code": "public LuaPreparedScript endPreparedScriptReturn(LuaValue value, LuaScriptConfig config) {\n        add(new LuaAstReturnStatement(argument(value)));\n        return endPreparedScript(config);\n    }", "label": 0}
{"code": "def select_all(*str_or_rx)\n      results = str_or_rx.flatten.map { |v| select_all_by v }\n      results.first\n    end", "label": 4}
{"code": "def audits\n      json = client.get(\"/v1/sys/audit\")\n      json = json[:data] if json[:data]\n      return Hash[*json.map do |k,v|\n        [k.to_s.chomp(\"/\").to_sym, Audit.decode(v)]\n      end.flatten]\n    end", "label": 4}
{"code": "private function addToComponentManifest($version, array $component)\n    {\n        $manifest = $this->getManifest($this->manifest());\n        $index = $this->getManifestComponentModuleIndex($manifest, $component['id']);\n\n        array_unshift($manifest['modules'][$index]['versions'], 'v'. $version);\n\n        $content = json_encode($manifest, JSON_PRETTY_PRINT | JSON_UNESCAPED_SLASHES) .\"\\n\";\n        $result = file_put_contents($this->manifest(), $content);\n        $this->setManifest($manifest);\n\n        if (!$result) {\n            throw new \\RuntimeException('File write failed');\n        }\n    }", "label": 2}
{"code": "func PgTriggersByTgconstraint(db XODB, tgconstraint pgtypes.Oid) ([]*PgTrigger, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, tgrelid, tgname, tgfoid, tgtype, tgenabled, tgisinternal, tgconstrrelid, tgconstrindid, tgconstraint, tgdeferrable, tginitdeferred, tgnargs, tgattr, tgargs, tgqual ` +\n\t\t`FROM pg_catalog.pg_trigger ` +\n\t\t`WHERE tgconstraint = $1`\n\n\t// run query\n\tXOLog(sqlstr, tgconstraint)\n\tq, err := db.Query(sqlstr, tgconstraint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*PgTrigger{}\n\tfor q.Next() {\n\t\tpt := PgTrigger{}\n\n\t\t// scan\n\t\terr = q.Scan(&pt.Tableoid, &pt.Cmax, &pt.Xmax, &pt.Cmin, &pt.Xmin, &pt.Oid, &pt.Ctid, &pt.Tgrelid, &pt.Tgname, &pt.Tgfoid, &pt.Tgtype, &pt.Tgenabled, &pt.Tgisinternal, &pt.Tgconstrrelid, &pt.Tgconstrindid, &pt.Tgconstraint, &pt.Tgdeferrable, &pt.Tginitdeferred, &pt.Tgnargs, &pt.Tgattr, &pt.Tgargs, &pt.Tgqual)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &pt)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public function setLocations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\LocationInfo::class);\n        $this->locations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function parse(node) {\n    const cfg = Object.assign({}, copyXmlAttributes(node));\n\n    for (let i = 0, l = node.childNodes.length; i < l; ++i) {\n        const el = node.childNodes.item(i);\n        if (el.nodeType === ELEMENT_NODE) {\n            if (!el.namespaceURI) {\n                // attribute elements\n                if (!cfg.attributes) cfg.attributes = {};\n                cfg.attributes[el.localName] = el.childNodes.length ? parse(el) : copyXmlAttributes(el);\n            } else if (el.namespaceURI === 'urn:flora:options') {\n                // flora specific elements\n                if (el.localName === 'dataSource') {\n                    const dataSource = getDataSource(el);\n                    if (!cfg.dataSources) cfg.dataSources = {};\n                    if (cfg.dataSources[dataSource.name]) {\n                        throw new Error(`Data source \"${dataSource.name}\" already defined`);\n                    }\n                    cfg.dataSources[dataSource.name] = dataSource.config;\n                }\n                if (el.localName === 'subFilter') {\n                    if (!cfg.subFilters) cfg.subFilters = [];\n                    cfg.subFilters.push(copyXmlAttributes(el));\n                }\n            }\n        } else if (el.nodeType === TEXT_NODE && el.textContent.trim().length > 0) {\n            throw new ImplementationError(`Config contains unnecessary text: \"${el.textContent.trim()}\"`);\n        }\n    }\n\n    return cfg;\n}", "label": 3}
{"code": "private function collectTags($incomingTags)\n    {\n        $allTags = WinkTag::all();\n\n        return collect($incomingTags)->map(function ($incomingTag) use ($allTags) {\n            $tag = $allTags->where('slug', Str::slug($incomingTag['name']))->first();\n\n            if (! $tag) {\n                $tag = WinkTag::create([\n                    'id' => $id = Str::uuid(),\n                    'name' => $incomingTag['name'],\n                    'slug' => Str::slug($incomingTag['name']),\n                ]);\n            }\n\n            return (string) $tag->id;\n        })->toArray();\n    }", "label": 2}
{"code": "def get_form(self, step=None, data=None, files=None):\n        \"\"\"\n        Constructs the form for a given `step`. If no `step` is defined, the\n        current step will be determined automatically.\n\n        The form will be initialized using the `data` argument to prefill the\n        new form. If needed, instance or queryset (for `ModelForm` or\n        `ModelFormSet`) will be added too.\n        \"\"\"\n        if step is None:\n            step = self.steps.current\n        # prepare the kwargs for the form instance.\n        kwargs = self.get_form_kwargs(step)\n        kwargs.update({\n            'data': data,\n            'files': files,\n            'prefix': self.get_form_prefix(step, self.form_list[step]),\n            'initial': self.get_form_initial(step),\n        })\n        if issubclass(self.form_list[step], forms.ModelForm):\n            # If the form is based on ModelForm, add instance if available.\n            kwargs.update({'instance': self.get_form_instance(step)})\n        elif issubclass(self.form_list[step], forms.models.BaseModelFormSet):\n            # If the form is based on ModelFormSet, add queryset if available.\n            kwargs.update({'queryset': self.get_form_instance(step)})\n        return self.form_list[step](**kwargs)", "label": 1}
{"code": "def ll(self, folder=\"\", begin_from_file=\"\", num=-1, all_grant_data=False):\n        \"\"\"\n        Get the list of files and permissions from S3.\n\n        This is similar to LL (ls -lah) in Linux: List of files with permissions.\n\n        Parameters\n        ----------\n\n        folder : string\n            Path to file on S3\n\n        num: integer, optional\n            number of results to return, by default it returns all results.\n\n        begin_from_file : string, optional\n            which file to start from on S3.\n            This is usedful in case you are iterating over lists of files and you need to page the result by\n            starting listing from a certain file and fetching certain num (number) of files.\n\n        all_grant_data : Boolean, optional\n            More detailed file permission data will be returned.\n\n        Examples\n        --------\n\n            >>> from s3utils import S3utils\n            >>> s3utils = S3utils(\n            ... AWS_ACCESS_KEY_ID = 'your access key',\n            ... AWS_SECRET_ACCESS_KEY = 'your secret key',\n            ... AWS_STORAGE_BUCKET_NAME = 'your bucket name',\n            ... S3UTILS_DEBUG_LEVEL = 1,  #change it to 0 for less verbose\n            ... )\n            >>> import json\n            >>> # We use json.dumps to print the results more readable:\n            >>> my_folder_stuff = s3utils.ll(\"/test/\")\n            >>> print(json.dumps(my_folder_stuff, indent=2))\n            {\n              \"test/myfolder/\": [\n                {\n                  \"name\": \"owner's name\",\n                  \"permission\": \"FULL_CONTROL\"\n                }\n              ],\n              \"test/myfolder/em/\": [\n                {\n                  \"name\": \"owner's name\",\n                  \"permission\": \"FULL_CONTROL\"\n                }\n              ],\n              \"test/myfolder/hoho/\": [\n                {\n                  \"name\": \"owner's name\",\n                  \"permission\": \"FULL_CONTROL\"\n                }\n              ],\n              \"test/myfolder/hoho/.DS_Store\": [\n                {\n                  \"name\": \"owner's name\",\n                  \"permission\": \"FULL_CONTROL\"\n                },\n                {\n                  \"name\": null,\n                  \"permission\": \"READ\"\n                }\n              ],\n              \"test/myfolder/hoho/haha/\": [\n                {\n                  \"name\": \"owner's name\",\n                  \"permission\": \"FULL_CONTROL\"\n                }\n              ],\n              \"test/myfolder/hoho/haha/ff\": [\n                {\n                  \"name\": \"owner's name\",\n                  \"permission\": \"FULL_CONTROL\"\n                },\n                {\n                  \"name\": null,\n                  \"permission\": \"READ\"\n                }\n              ],\n              \"test/myfolder/hoho/photo.JPG\": [\n                {\n                  \"name\": \"owner's name\",\n                  \"permission\": \"FULL_CONTROL\"\n                },\n                {\n                  \"name\": null,\n                  \"permission\": \"READ\"\n                }\n              ],\n            }\n\n        \"\"\"\n        return self.ls(folder=folder, begin_from_file=begin_from_file, num=num, get_grants=True, all_grant_data=all_grant_data)", "label": 1}
{"code": "def main_component_path(component)\n      current_params = try(:params) || {}\n      EngineRouter.main_proxy(component).root_path(locale: current_params[:locale])\n    end", "label": 4}
{"code": "def list(*args)\n      params = arguments(args).params\n\n      response = if user_name = arguments.remaining.first\n        get_request(\"/users/#{user_name}/followers\", params)\n      else\n        get_request(\"/user/followers\", params)\n      end\n      return response unless block_given?\n      response.each { |el| yield el }\n    end", "label": 4}
{"code": "func (t *Terminfo) TGoto(col, row int) string {\n\treturn t.TParm(t.SetCursor, row, col)\n}", "label": 5}
{"code": "def require_plugin_files\n      unless site.safe\n        plugins_path.each do |plugin_search_path|\n          plugin_files = Utils.safe_glob(plugin_search_path, File.join(\"**\", \"*.rb\"))\n          Jekyll::External.require_with_graceful_fail(plugin_files)\n        end\n      end\n    end", "label": 4}
{"code": "function convertBrowser(pkg, browser) {\n\tvar type = typeof browser;\n\tif(type === \"string\" || type === \"undefined\") {\n\t\treturn browser;\n\t}\n\tvar map = {};\n\tfor(var fromName in browser) {\n\t\tconvertBrowserProperty(map, pkg, fromName, browser[fromName]);\n\t}\n\treturn map;\n}", "label": 3}
{"code": "public function getErrors()\n    {\n        if ($this->errors === null) {\n            if ($errors = $this['errors']) {\n                foreach ($errors as $key => $error) {\n                    $errors[$key] = $this->shapeFor($error);\n                }\n                $this->errors = $errors;\n            } else {\n                $this->errors = [];\n            }\n        }\n\n        return $this->errors;\n    }", "label": 2}
{"code": "function isUsingDefaultTheme( element ) {\n\n    var theme,\n        prop = 'position'\n\n    // For IE.\n    if ( element.currentStyle ) {\n        theme = element.currentStyle[prop]\n    }\n\n    // For normal browsers.\n    else if ( window.getComputedStyle ) {\n        theme = getComputedStyle( element )[prop]\n    }\n\n    return theme == 'fixed'\n}", "label": 3}
{"code": "def insert_many(conn, tablename, column_names, records, chunksize=2500):\n    \"\"\"Insert many records by chunking data into insert statements.\n\n    Notes\n    -----\n    records should be Iterable collection of namedtuples or tuples.\n    \"\"\"\n\n    groups = chunks(records, chunksize)\n    column_str = ','.join(column_names)\n    insert_template = 'INSERT INTO {table} ({columns}) VALUES {values}'.format(\n        table=tablename, columns=column_str, values='{0}')\n\n    with conn:\n        with conn.cursor() as cursor:\n            for recs in groups:\n                record_group = list(recs)\n                records_template_str = ','.join(['%s'] * len(record_group))\n                insert_query = insert_template.format(records_template_str)\n                cursor.execute(insert_query, record_group)", "label": 1}
{"code": "def breathe_lights(self, color, selector='all',\n        from_color=None, period=1.0, cycles=1.0,\n        persist=False, power_on=True, peak=0.5):\n        \"\"\"Perform breathe effect on lights.\n\n        selector: String\n            The selector to limit which lights will run the effect.\n            default: all\n\n        color: required String\n            Color attributes to use during effect. See set_state for more.\n\n        from_color:\tString\n            The color to start the effect from. See set_state for more.\n            default: current bulb color\n\n        period:\tDouble\n            The time in seconds for one cyles of the effect.\n            default: 1.0\n\n        cycles:\tDouble\n            The number of times to repeat the effect.\n            default: 1.0\n\n        persist: Boolean\n            If false set the light back to its previous\n            value when effect ends, if true leave the last effect color.\n            default: false\n\n        power_on: Boolean\n            If true, turn the bulb on if it is not already on.\n            default: true\n\n        peak: String\n            Defines where in a period the target color is at its maximum.\n            Minimum 0.0, maximum 1.0.\n            default: 0.5\n        \"\"\"\n\n        argument_tuples = [\n            (\"color\", color),\n            (\"from_color\", from_color),\n            (\"period\", period),\n            (\"cycles\", cycles),\n            (\"persist\", persist),\n            (\"power_on\", power_on),\n            (\"peak\", peak),\n        ]\n\n        return self.client.perform_request(\n            method='post', endpoint='lights/{}/effects/breathe',\n            endpoint_args=[selector], argument_tuples=argument_tuples)", "label": 1}
{"code": "function cloneNode(node, location, flags, parent) {\n        // We don't use \"clone\" from core.ts here, as we need to preserve the prototype chain of\n        // the original node. We also need to exclude specific properties and only include own-\n        // properties (to skip members already defined on the shared prototype).\n        var clone = location !== undefined\n            ? ts.createNode(node.kind, location.pos, location.end)\n            : createSynthesizedNode(node.kind);\n        for (var key in node) {\n            if (clone.hasOwnProperty(key) || !node.hasOwnProperty(key)) {\n                continue;\n            }\n            clone[key] = node[key];\n        }\n        if (flags !== undefined) {\n            clone.flags = flags;\n        }\n        if (parent !== undefined) {\n            clone.parent = parent;\n        }\n        return clone;\n    }", "label": 3}
{"code": "function flattenById(obj, keyedObj = {}) {\n  if (obj.hasOwnProperty('id')) {\n    keyedObj[obj.id] = obj;\n  }\n  for (var key in obj) {\n    if (isObject(obj[key])) {\n      flattenById(obj[key], keyedObj);\n    }\n  }\n  return keyedObj;\n}", "label": 3}
{"code": "func (fs *FlagSet) usage() {\n\tif fs == CommandLine {\n\t\tUsage()\n\t} else if fs.Usage == nil {\n\t\tdefaultUsage(fs)\n\t} else {\n\t\tfs.Usage()\n\t}\n}", "label": 5}
{"code": "public static function visibilityOfAnyElementLocated(WebDriverBy $by)\n    {\n        return new static(\n            function (WebDriver $driver) use ($by) {\n                $elements = $driver->findElements($by);\n                $visibleElements = [];\n\n                foreach ($elements as $element) {\n                    try {\n                        if ($element->isDisplayed()) {\n                            $visibleElements[] = $element;\n                        }\n                    } catch (StaleElementReferenceException $e) {\n                    }\n                }\n\n                return count($visibleElements) > 0 ? $visibleElements : null;\n            }\n        );\n    }", "label": 2}
{"code": "public function modifyAckDeadline(Message $message, $seconds, array $options = [])\n    {\n        $this->modifyAckDeadlineBatch([$message], $seconds, $options);\n    }", "label": 2}
{"code": "def lg_mv(self, log_lvl, txt):\n        \"\"\"\n        wrapper for debugging print and log methods\n        \"\"\"\n        if log_lvl <= self.LOG_LEVEL:\n            print(txt + str(self.current_y) + \",\" + str(self.current_x))", "label": 1}
{"code": "def unregister(self, command):\n        \"\"\"\n        Unregisters an existing command, so that this command is no longer available on the command line interface.\n\n        This function is mainly used during plugin deactivation.\n\n        :param command: Name of the command\n        \"\"\"\n        if command not in self._commands.keys():\n            self.log.warning(\"Can not unregister command %s\" % command)\n        else:\n            # Click does not have any kind of a function to unregister/remove/deactivate already added commands.\n            # So we need to delete the related objects manually from the click internal commands dictionary for\n            # our root command.\n            del(self._click_root_command.commands[command])\n            # Finally lets delete the command from our internal dictionary too.\n            del(self._commands[command])\n            self.log.debug(\"Command %s got unregistered\" % command)", "label": 1}
{"code": "function _gpfStreamPipeToFlushableWrite (intermediate, destination) {\n    var state = _gpfStreamPipeAllocateState(intermediate, destination),\n        read = _gpfStreamPipeAllocateRead(state),\n        iFlushableIntermediate = state.iFlushableIntermediate,\n        iFlushableDestination = state.iFlushableDestination,\n        iWritableIntermediate = state.iWritableIntermediate;\n\n    read();\n\n    return {\n\n        flush: function () {\n            return _gpfStreamPipeCheckIfReadError(state) || iFlushableIntermediate.flush()\n                .then(function () {\n                    return iFlushableDestination.flush();\n                });\n        },\n\n        write: function (data) {\n            read();\n            return _gpfStreamPipeCheckIfReadError(state)\n                || _gpfStreamPipeWrapWrite(state, iWritableIntermediate.write(data));\n        }\n\n    };\n}", "label": 3}
{"code": "def display_lines(min, max)\n      puts \"\\n[#{min}, #{max}] in #{frame.file}\"\n\n      puts source_file_formatter.lines(min, max).join\n    end", "label": 4}
{"code": "def updatePassword(self,\n                       user,\n                       currentPassword,\n                       newPassword):\n        \"\"\"Change the password of a user.\"\"\"\n        return self.__post('/api/updatePassword',\n                           data={\n                               'user': user,\n                               'currentPassword': currentPassword,\n                               'newPassword': newPassword\n                           })", "label": 1}
{"code": "def build_app\n      command = BuildCommandGenerator.generate\n      print_command(command, \"Generated Build Command\") if FastlaneCore::Globals.verbose?\n      FastlaneCore::CommandExecutor.execute(command: command,\n                                          print_all: true,\n                                      print_command: !Gym.config[:silent],\n                                              error: proc do |output|\n                                                ErrorHandler.handle_build_error(output)\n                                              end)\n\n      mark_archive_as_built_by_gym(BuildCommandGenerator.archive_path)\n      UI.success(\"Successfully stored the archive. You can find it in the Xcode Organizer.\") unless Gym.config[:archive_path].nil?\n      UI.verbose(\"Stored the archive in: \" + BuildCommandGenerator.archive_path)\n\n      post_build_app\n    end", "label": 4}
{"code": "function exists(file) {\n  try {\n    fs.lstatSync(file);\n    return true;\n  } catch (e) {\n    if (e.code === 'ENOENT' || e.code === 'ENOTDIR') {\n      return false;\n    } else {\n      throw e;\n    }\n  }\n}", "label": 3}
{"code": "def truncate_to(value: Decimal, currency: str) -> Decimal:\n    \"\"\"Truncates a value to the number of decimals corresponding to the currency\"\"\"\n    decimal_places = DECIMALS.get(currency.upper(), 2)\n    return truncate(value, decimal_places)", "label": 1}
{"code": "function factory(pkg, location) {\n  const isProd = process.env.NODE_ENV === \"production\";\n  return [\n    configure(pkg, location, \"development\", \"module\"),\n    isProd && configure(pkg, location, \"development\", \"umd\"),\n    isProd && configure(pkg, location, \"production\", \"umd\")\n  ].filter(Boolean);\n}", "label": 3}
{"code": "function extendExportSymbols(target, source, lookupTable, exportNode) {\n            for (var id in source) {\n                if (id !== \"default\" && !target[id]) {\n                    target[id] = source[id];\n                    if (lookupTable && exportNode) {\n                        lookupTable[id] = {\n                            specifierText: ts.getTextOfNode(exportNode.moduleSpecifier)\n                        };\n                    }\n                }\n                else if (lookupTable && exportNode && id !== \"default\" && target[id] && resolveSymbol(target[id]) !== resolveSymbol(source[id])) {\n                    if (!lookupTable[id].exportsWithDuplicate) {\n                        lookupTable[id].exportsWithDuplicate = [exportNode];\n                    }\n                    else {\n                        lookupTable[id].exportsWithDuplicate.push(exportNode);\n                    }\n                }\n            }\n        }", "label": 3}
{"code": "func (c *Client) UpsertGithubConnector(connector services.GithubConnector) error {\n\tbytes, err := services.GetGithubConnectorMarshaler().Marshal(connector)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = c.PutJSON(c.Endpoint(\"github\", \"connectors\"), &upsertGithubConnectorRawReq{\n\t\tConnector: bytes,\n\t})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function getKernelInfos(directory) {\n  return promisify(fs.readdir, [directory]).then(files =>\n    files.map(fileName => ({\n      name: fileName,\n      resourceDir: path.join(directory, fileName),\n    }))\n  );\n}", "label": 3}
{"code": "def started(topic, event)\n      subscribers_for(topic).each{ |subscriber| subscriber.started(event) }\n    end", "label": 4}
{"code": "public function set(DocumentReference $document, array $fields, array $options = [])\n    {\n        $this->writer->set($document->name(), $fields, $options);\n\n        return $this;\n    }", "label": 2}
{"code": "func urlParse(name string) *url.URL {\n\tvar info os.FileInfo\n\n\tu, err := url.Parse(name)\n\tif err == nil && u.Scheme == \"\" {\n\t\tinfo, err = os.Stat(u.Path)\n\t\tif err == nil && info.IsDir() {\n\t\t\tu.Scheme = ArchiveScheme // special case for IsDir()\n\t\t\treturn u\n\t\t}\n\t}\n\n\tu, err = url.Parse(strings.TrimPrefix(name, \"/\")) // must appear to be an absolute path or hgfs errors\n\tif err != nil {\n\t\tu = &url.URL{Path: name}\n\t}\n\n\tif u.Scheme == \"\" {\n\t\tix := strings.Index(u.Path, \"/\")\n\t\tif ix > 0 {\n\t\t\tu.Scheme = u.Path[:ix]\n\t\t\tu.Path = u.Path[ix:]\n\t\t}\n\t}\n\n\treturn u\n}", "label": 5}
{"code": "function removeCachedFiles(params, cb) {\n  //Cleaning Up Any Files Cached To Render The Submission.\n  logger.debug(\"cacheFiles: mergeSubmissionFiles Removing Cached Files For PDF Generation: \", params.submissionFiles);\n  async.eachSeries(params.submissionFiles || [], function(submissionFileDetails, cb) {\n    logger.debug(\"Removing Cached File: \", submissionFileDetails);\n    fs.unlink(submissionFileDetails.url, function(err) {\n      if (err) {\n        logger.error('Error Removing File At' + submissionFileDetails.url);\n      }\n\n      return cb();\n    });\n  }, cb);\n}", "label": 3}
{"code": "def bulk_copy(self, ids):\n        \"\"\"Bulk copy a set of users.\n\n        :param ids: Int list of user IDs.\n        :return: :class:`users.User <users.User>` list\n        \"\"\"\n        schema = UserSchema()\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)", "label": 1}
{"code": "def get_version(tool_name, tool_command):\n        \"\"\"\n        Get name and version of a tool defined by given command.\n\n        Args:\n            tool_name (str): name of the tool.\n            tool_command (str): Bash one line command to get the version of the tool.\n\n        Returns:\n            dict: tool name and version or empty when no line has been found\n        \"\"\"\n        result = {}\n        for line in Bash(ShellConfig(script=tool_command, internal=True)).process():\n            if line.find(\"command not found\") >= 0:\n                VersionsCheck.LOGGER.error(\"Required tool '%s' not found (stopping pipeline)!\", tool_name)\n                sys.exit(1)\n            else:\n                version = list(re.findall(r'(\\d+(\\.\\d+)+)+', line))[0][0]\n                result = {tool_name: Version(str(version))}\n            break\n        return result", "label": 1}
{"code": "def load_file_to_list(self):\n        \"\"\" load a file to a list \"\"\"\n        lst = []\n        try:\n            with open(self.fullname, 'r') as f:\n                for line in f:\n                    lst.append(line) \n            return lst  \n        except IOError:\n            return lst", "label": 1}
{"code": "func (c *Client) GetTokens(opts ...services.MarshalOption) ([]services.ProvisionToken, error) {\n\tout, err := c.Get(c.Endpoint(\"tokens\"), url.Values{})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar tokens []services.ProvisionTokenV1\n\tif err := json.Unmarshal(out.Bytes(), &tokens); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.ProvisionTokensFromV1(tokens), nil\n}", "label": 5}
{"code": "public function next()\n    {\n        if ($this->current === null) {\n            $this->rewind();\n        }\n\n        if ($this->validationResult !== static::END_ITERATION) {\n            $this->key++;\n\n            $this->incrementCurrentDateUntilValid();\n        }\n    }", "label": 2}
{"code": "function isFile(fp, stat) {\n  if (stat === true) {\n    stat = tryStats(fp);\n  }\n  return !isDir(fp, stat);\n}", "label": 3}
{"code": "func (s *Server) Shutdown(ctx context.Context) error {\n\t// close listener to stop receiving new connections\n\terr := s.Close()\n\ts.Wait(ctx)\n\tactiveConnections := s.trackConnections(0)\n\tif activeConnections == 0 {\n\t\treturn err\n\t}\n\ts.Infof(\"Shutdown: waiting for %v connections to finish.\", activeConnections)\n\tlastReport := time.Time{}\n\tticker := time.NewTicker(s.shutdownPollPeriod)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\tactiveConnections = s.trackConnections(0)\n\t\t\tif activeConnections == 0 {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif time.Now().Sub(lastReport) > 10*s.shutdownPollPeriod {\n\t\t\t\ts.Infof(\"Shutdown: waiting for %v connections to finish.\", activeConnections)\n\t\t\t\tlastReport = time.Now()\n\t\t\t}\n\t\tcase <-ctx.Done():\n\t\t\ts.Infof(\"Context cancelled wait, returning.\")\n\t\t\treturn trace.ConnectionProblem(err, \"context cancelled\")\n\t\t}\n\t}\n}", "label": 5}
{"code": "def play_internal\n      count = 0\n      @playing = true\n\n      # Default play length (ms), will be adjusted later\n      @length = IDEAL_LENGTH\n\n      self.speaking = true\n      loop do\n        # Starting from the tenth packet, perform length adjustment every 100 packets (2 seconds)\n        should_adjust_this_packet = (count % @adjust_interval == @adjust_offset)\n\n        # If we should adjust, start now\n        @length_adjust = Time.now.nsec if should_adjust_this_packet\n\n        break unless @playing\n\n        # If we should skip, get some data, discard it and go to the next iteration\n        if @skips.positive?\n          @skips -= 1\n          yield\n          next\n        end\n\n        # Track packet count, sequence and time (Discord requires this)\n        count += 1\n        increment_packet_headers\n\n        # Get packet data\n        buf = yield\n\n        # Stop doing anything if the stop signal was sent\n        break if buf == :stop\n\n        # Proceed to the next packet if we got nil\n        next unless buf\n\n        # Track intermediate adjustment so we can measure how much encoding contributes to the total time\n        @intermediate_adjust = Time.now.nsec if should_adjust_this_packet\n\n        # Send the packet\n        @udp.send_audio(buf, @sequence, @time)\n\n        # Set the stream time (for tracking how long we've been playing)\n        @stream_time = count * @length / 1000\n\n        if @length_override # Don't do adjustment because the user has manually specified an override value\n          @length = @length_override\n        elsif @length_adjust # Perform length adjustment\n          # Define the time once so it doesn't get inaccurate\n          now = Time.now.nsec\n\n          # Difference between length_adjust and now in ms\n          ms_diff = (now - @length_adjust) / 1_000_000.0\n          if ms_diff >= 0\n            @length = if @adjust_average\n                        (IDEAL_LENGTH - ms_diff + @length) / 2.0\n                      else\n                        IDEAL_LENGTH - ms_diff\n                      end\n\n            # Track the time it took to encode\n            encode_ms = (@intermediate_adjust - @length_adjust) / 1_000_000.0\n            @bot.debug(\"Length adjustment: new length #{@length} (measured #{ms_diff}, #{(100 * encode_ms) / ms_diff}% encoding)\") if @adjust_debug\n          end\n          @length_adjust = nil\n        end\n\n        # If paused, wait\n        sleep 0.1 while @paused\n\n        if @length.positive?\n          # Wait `length` ms, then send the next packet\n          sleep @length / 1000.0\n        else\n          Discordrb::LOGGER.warn('Audio encoding and sending together took longer than Discord expects one packet to be (20 ms)! This may be indicative of network problems.')\n        end\n      end\n\n      @bot.debug('Sending five silent frames to clear out buffers')\n\n      5.times do\n        increment_packet_headers\n        @udp.send_audio(Encoder::OPUS_SILENCE, @sequence, @time)\n\n        # Length adjustments don't matter here, we can just wait 20 ms since nobody is going to hear it anyway\n        sleep IDEAL_LENGTH / 1000.0\n      end\n\n      @bot.debug('Performing final cleanup after stream ended')\n\n      # Final cleanup\n      stop_playing\n\n      # Notify any stop_playing methods running right now that we have actually stopped\n      @has_stopped_playing = true\n    end", "label": 4}
{"code": "def to_hash\n      {\n        :installer => installer,\n        :installer_arguments => installer_arguments,\n        :iso_path => iso_path,\n        :iso_upload_path => iso_upload_path,\n        :iso_mount_point => iso_mount_point,\n        :auto_update => auto_update,\n        :auto_reboot => auto_reboot,\n        :no_install => no_install,\n        :no_remote => no_remote,\n        :yes => yes\n      }\n    end", "label": 4}
{"code": "def ensure_user(data)\n      if @users.include?(data['id'].to_i)\n        @users[data['id'].to_i]\n      else\n        @users[data['id'].to_i] = User.new(data, self)\n      end\n    end", "label": 4}
{"code": "func (a *TestAuthServer) Trust(remote *TestAuthServer, roleMap services.RoleMap) error {\n\tremoteCA, err := remote.AuthServer.GetCertAuthority(services.CertAuthID{\n\t\tType:       services.HostCA,\n\t\tDomainName: remote.ClusterName,\n\t}, false)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\terr = a.AuthServer.UpsertCertAuthority(remoteCA)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tremoteCA, err = remote.AuthServer.GetCertAuthority(services.CertAuthID{\n\t\tType:       services.UserCA,\n\t\tDomainName: remote.ClusterName,\n\t}, false)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tremoteCA.SetRoleMap(roleMap)\n\terr = a.AuthServer.UpsertCertAuthority(remoteCA)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func (cs callSet) Failures() []*Call {\n\tfailures := make([]*Call, 0, len(cs.expected))\n\tfor _, calls := range cs.expected {\n\t\tfor _, call := range calls {\n\t\t\tif !call.satisfied() {\n\t\t\t\tfailures = append(failures, call)\n\t\t\t}\n\t\t}\n\t}\n\treturn failures\n}", "label": 5}
{"code": "def gen_table(self):\n        \"\"\"\n        This function generates the CRC table used for the table_driven CRC\n        algorithm.  The Python version cannot handle tables of an index width\n        other than 8.  See the generated C code for tables with different sizes\n        instead.\n        \"\"\"\n        table_length = 1 << self.TableIdxWidth\n        tbl = [0] * table_length\n        for i in range(table_length):\n            register = i\n            if self.ReflectIn:\n                register = self.reflect(register, self.TableIdxWidth)\n            register = register << (self.Width - self.TableIdxWidth + self.CrcShift)\n            for j in range(self.TableIdxWidth):\n                if register & (self.MSB_Mask << self.CrcShift) != 0:\n                    register = (register << 1) ^ (self.Poly << self.CrcShift)\n                else:\n                    register = (register << 1)\n            if self.ReflectIn:\n                register = self.reflect(register >> self.CrcShift, self.Width) << self.CrcShift\n            tbl[i] = register & (self.Mask << self.CrcShift)\n        return tbl", "label": 1}
{"code": "def count_mismatches_before_variant(reference_prefix, cdna_prefix):\n    \"\"\"\n    Computes the number of mismatching nucleotides between two cDNA sequences before a variant\n    locus.\n\n    Parameters\n    ----------\n    reference_prefix : str\n        cDNA sequence of a reference transcript before a variant locus\n\n    cdna_prefix : str\n        cDNA sequence detected from RNAseq before a variant locus\n    \"\"\"\n    if len(reference_prefix) != len(cdna_prefix):\n        raise ValueError(\n            \"Expected reference prefix '%s' to be same length as %s\" % (\n                reference_prefix, cdna_prefix))\n    return sum(xi != yi for (xi, yi) in zip(reference_prefix, cdna_prefix))", "label": 1}
{"code": "function shallowEqual(objA, objB) {\n  if (objA === objB) {\n    return true;\n  }\n  var key;\n  // Test for A's keys different from B.\n  for (key in objA) {\n    if (objA.hasOwnProperty(key) &&\n        (!objB.hasOwnProperty(key) || objA[key] !== objB[key])) {\n      return false;\n    }\n  }\n  // Test for B's keys missing from A.\n  for (key in objB) {\n    if (objB.hasOwnProperty(key) && !objA.hasOwnProperty(key)) {\n      return false;\n    }\n  }\n  return true;\n}", "label": 3}
{"code": "public function sendBroadcastMessage($targets, $message)\n    {\n        $bodyNode = new ProtocolNode('body', null, null, $message);\n        // Return message ID. Make pull request for this.\n        return $this->sendBroadcast($targets, $bodyNode, 'text');\n    }", "label": 2}
{"code": "function (appID, locationID) {\n\n    // check if location exists\n    if (l_locations.hasOwnProperty(locationID) === false) {\n        LOG.error('locationID: ' + locationID + ' does not exist', 'addApp');\n        return;\n    }\n\n    // check if already exists, ignore action if already exists\n    if (l_apps.hasOwnProperty(appID) === true) {\n        LOG.error('appID: ' + appID + ' already exists', 'addApp');\n        return;\n    }\n\n    // insert new app record for this location\n    l_apps[appID] = {\n        locationID: locationID,\n        users: {}\n    }\n\n    // build mapping from location to app \n    // TODO: (needed? or can simplfiy?)\n    l_locations[locationID].apps[appID] = l_apps[appID];    \n}", "label": 3}
{"code": "def new_attributes\n      (audited_changes || {}).inject({}.with_indifferent_access) do |attrs, (attr, values)|\n        attrs[attr] = values.is_a?(Array) ? values.last : values\n        attrs\n      end\n    end", "label": 4}
{"code": "function(data, name, $field, $el, field, callback) {\n      data[name] = $field.val();\n      if (field.required && !data[name].length) {\n        return apos.afterYield(_.partial(callback, 'required'));\n      }\n      if (field.max && (data[name].length > field.max)) {\n        var $fieldset = self.findFieldset($el, name);\n        $fieldset.addClass('apos-error-max');\n        return apos.afterYield(_.partial(callback, 'max'));\n      }\n      return apos.afterYield(callback);\n    }", "label": 3}
{"code": "func (h *AuthHandlers) IsUserAuthority(cert ssh.PublicKey) bool {\n\tif _, err := h.authorityForCert(services.UserCA, cert); err != nil {\n\t\treturn false\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "function addTracingToResolvers(schema) {\n  // XXX this is a hacky way of making sure that the schema only gets decorated\n  // with tracer once.\n  if (schema._apolloTracerApplied) {\n    // console.log('Tracing already added to resolve functions. Not adding again.');\n    return;\n  }\n  // eslint-disable-next-line no-param-reassign\n  schema._apolloTracerApplied = true;\n\n  forEachField(schema, (field, typeName, fieldName) => {\n    const functionName = `${typeName}.${fieldName}`;\n    if (field.resolve) {\n      // eslint-disable-next-line no-param-reassign\n      field.resolve = decorateWithTracer(\n        field.resolve,\n        { type: 'resolve', functionName },\n      );\n    }\n  });\n}", "label": 3}
{"code": "def diff_stats(self, ids):\n        \"\"\"Compute diff stats for a set of results.\n\n        :param id: Result IDs as int list.\n        :return: :class:`results.DiffStats <results.DiffStats>` object\n        :rtype: results.DiffStats\n        \"\"\"\n        schema = DiffStatsSchema()\n        resp = self.service.post(self.base, params={'stats': 'diff'}, json=[{'id': str(x)} for x in ids])\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "def get_monitor_info(pe, opts={})\n      obj = {}\n\n      # Common plugin information\n      obj['plugin_id'] = pe.plugin_id\n      obj['plugin_category'] = plugin_category(pe)\n      obj['type'] = pe.config['@type']\n      obj['config'] = pe.config if opts[:with_config]\n\n      # run MONITOR_INFO in plugins' instance context and store the info to obj\n      MONITOR_INFO.each_pair {|key,code|\n        begin\n          catch(:skip) do\n            obj[key] = pe.instance_exec(&code)\n          end\n        rescue NoMethodError => e\n          unless @first_warn\n            log.error \"NoMethodError in monitoring plugins\", key: key, plugin: pe.class, error: e\n            log.error_backtrace\n            @first_warn = true\n          end\n        rescue => e\n          log.warn \"unexpected error in monitoring plugins\", key: key, plugin: pe.class, error: e\n        end\n      }\n\n      obj['retry'] = get_retry_info(pe.retry) if opts[:with_retry] and pe.instance_variable_defined?(:@retry)\n\n      # include all instance variables if :with_debug_info is set\n      if opts[:with_debug_info]\n        iv = {}\n        pe.instance_eval do\n          instance_variables.each {|sym|\n            next if IGNORE_ATTRIBUTES.include?(sym)\n            key = sym.to_s[1..-1]  # removes first '@'\n            iv[key] = instance_variable_get(sym)\n          }\n        end\n        obj['instance_variables'] = iv\n      elsif ivars = opts[:ivars]\n        iv = {}\n        ivars.each {|name|\n          iname = \"@#{name}\"\n          iv[name] = pe.instance_variable_get(iname) if pe.instance_variable_defined?(iname)\n        }\n        obj['instance_variables'] = iv\n      end\n\n      obj\n    end", "label": 4}
{"code": "def run_async\n      @ws_thread = Thread.new do\n        Thread.current[:discordrb_name] = 'websocket'\n        connect_loop\n        LOGGER.warn('The WS loop exited! Not sure if this is a good thing')\n      end\n\n      LOGGER.debug('WS thread created! Now waiting for confirmation that everything worked')\n      sleep(0.5) until @ws_success\n      LOGGER.debug('Confirmation received! Exiting run.')\n    end", "label": 4}
{"code": "public function setDatasets($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\AutoMl\\V1beta1\\Dataset::class);\n        $this->datasets = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func SqTables(db models.XODB, schema string, relkind string) ([]*models.Table, error) {\n\tvar err error\n\n\t// get the tables\n\trows, err := models.SqTables(db, relkind)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// get the SQL for the Autoincrement detection\n\tautoIncrements, err := models.SqAutoIncrements(db)\n\tif err != nil {\n\t\t// Set it to an empty set on error.\n\t\tautoIncrements = []*models.SqAutoIncrement{}\n\t}\n\n\t// Add information about manual FK.\n\tvar tables []*models.Table\n\tfor _, row := range rows {\n\t\tmanualPk := true\n\t\t// Look for a match in the table name where it contains the autoincrement\n\t\t// keyword for the given table in the SQL.\n\t\tfor _, autoInc := range autoIncrements {\n\t\t\tlSQL := strings.ToLower(autoInc.SQL)\n\t\t\tif autoInc.TableName == row.TableName && strings.Contains(lSQL, \"autoincrement\") {\n\t\t\t\tmanualPk = false\n\t\t\t} else {\n\t\t\t\tcols, err := SqTableColumns(db, schema, row.TableName)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tfor _, col := range cols {\n\t\t\t\t\tif col.IsPrimaryKey == true {\n\t\t\t\t\t\tdt := strings.ToUpper(col.DataType)\n\t\t\t\t\t\tif dt == \"INTEGER\" {\n\t\t\t\t\t\t\tmanualPk = false\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\ttables = append(tables, &models.Table{\n\t\t\tTableName: row.TableName,\n\t\t\tType:      row.Type,\n\t\t\tManualPk:  manualPk,\n\t\t})\n\t}\n\n\treturn tables, nil\n}", "label": 5}
{"code": "def get(*args)\n      arguments(args, required: [:user, :repo, :label_name])\n      params = arguments.params\n\n      get_request(\"/repos/#{arguments.user}/#{arguments.repo}/labels/#{arguments.label_name}\", params)\n    end", "label": 4}
{"code": "def get_multi_yielder(keys)\n      perform do\n        return {} if keys.empty?\n        ring.lock do\n          begin\n            groups = groups_for_keys(keys)\n            if unfound_keys = groups.delete(nil)\n              Dalli.logger.debug { \"unable to get keys for #{unfound_keys.length} keys because no matching server was found\" }\n            end\n            make_multi_get_requests(groups)\n\n            servers = groups.keys\n            return if servers.empty?\n            servers = perform_multi_response_start(servers)\n\n            start = Time.now\n            while true\n              # remove any dead servers\n              servers.delete_if { |s| s.sock.nil? }\n              break if servers.empty?\n\n              # calculate remaining timeout\n              elapsed = Time.now - start\n              timeout = servers.first.options[:socket_timeout]\n              time_left = (elapsed > timeout) ? 0 : timeout - elapsed\n\n              sockets = servers.map(&:sock)\n              readable, _ = IO.select(sockets, nil, nil, time_left)\n\n              if readable.nil?\n                # no response within timeout; abort pending connections\n                servers.each do |server|\n                  Dalli.logger.debug { \"memcached at #{server.name} did not response within timeout\" }\n                  server.multi_response_abort\n                end\n                break\n\n              else\n                readable.each do |sock|\n                  server = sock.server\n\n                  begin\n                    server.multi_response_nonblock.each_pair do |key, value_list|\n                      yield key_without_namespace(key), value_list\n                    end\n\n                    if server.multi_response_completed?\n                      servers.delete(server)\n                    end\n                  rescue NetworkError\n                    servers.delete(server)\n                  end\n                end\n              end\n            end\n          end\n        end\n      end\n    end", "label": 4}
{"code": "function propsMatch(test, testFields, expected, expectedFields, equals)\n{\n  var equality = equals || Rekord.equals;\n\n  if ( isString( testFields ) ) // && isString( expectedFields )\n  {\n    return equality( test[ testFields ], expected[ expectedFields ] );\n  }\n  else // if ( isArray( testFields ) && isArray( expectedFields ) )\n  {\n    for (var i = 0; i < testFields.length; i++)\n    {\n      var testProp = testFields[ i ];\n      var expectedProp = expectedFields[ i ];\n\n      if ( !equality( test[ testProp ], expected[ expectedProp ] ) )\n      {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  return false;\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, ntpserver resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tntpserver addresources[] = new ntpserver[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new ntpserver();\n\t\t\t\taddresources[i].serverip = resources[i].serverip;\n\t\t\t\taddresources[i].servername = resources[i].servername;\n\t\t\t\taddresources[i].minpoll = resources[i].minpoll;\n\t\t\t\taddresources[i].maxpoll = resources[i].maxpoll;\n\t\t\t\taddresources[i].autokey = resources[i].autokey;\n\t\t\t\taddresources[i].key = resources[i].key;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def continuous_periods(self):\n        \"\"\"\n        Return a list of continuous data periods by removing the data gaps from the overall record.\n        \"\"\"\n        result = []\n\n        # For the first period\n        start_date = self.start_date\n        for gap in self.pot_data_gaps:\n            end_date = gap.start_date - timedelta(days=1)\n            result.append(PotPeriod(start_date, end_date))\n            # For the next period\n            start_date = gap.end_date + timedelta(days=1)\n        # For the last period\n        end_date = self.end_date\n        result.append(PotPeriod(start_date, end_date))\n\n        return result", "label": 1}
{"code": "public function setTextAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\TextAnnotation::class);\n        $this->text_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function month($name, $value = null, $options = [])\n    {\n        if ($value instanceof DateTime) {\n            $value = $value->format('Y-m');\n        }\n\n        return $this->input('month', $name, $value, $options);\n    }", "label": 2}
{"code": "func (p *fileParser) parsePackage(path string) error {\n\tvar pkgs map[string]*ast.Package\n\tif imp, err := build.Import(path, p.srcDir, build.FindOnly); err != nil {\n\t\treturn err\n\t} else if pkgs, err = parser.ParseDir(p.fileSet, imp.Dir, nil, 0); err != nil {\n\t\treturn err\n\t}\n\tfor _, pkg := range pkgs {\n\t\tfile := ast.MergePackageFiles(pkg, ast.FilterFuncDuplicates|ast.FilterUnassociatedComments|ast.FilterImportDuplicates)\n\t\tif _, ok := p.importedInterfaces[path]; !ok {\n\t\t\tp.importedInterfaces[path] = make(map[string]*ast.InterfaceType)\n\t\t}\n\t\tfor ni := range iterInterfaces(file) {\n\t\t\tp.importedInterfaces[path][ni.name.Name] = ni.it\n\t\t}\n\t\timports, _ := importsOfFile(file)\n\t\tfor pkgName, pkgPath := range imports {\n\t\t\tif _, ok := p.imports[pkgName]; !ok {\n\t\t\t\tp.imports[pkgName] = pkgPath\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function setDocument($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Language\\V1\\Document::class);\n        $this->document = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def concatenate(*args, **kwargs):\n    \"\"\"\n    Concatenates the given strings.\n\n    Usage::\n\n        {% load libs_tags %}\n        {% concatenate \"foo\" \"bar\" as new_string %}\n        {% concatenate \"foo\" \"bar\" divider=\"_\" as another_string %}\n\n    The above would result in the strings \"foobar\" and \"foo_bar\".\n\n    \"\"\"\n    divider = kwargs.get('divider', '')\n    result = ''\n    for arg in args:\n        if result == '':\n            result += arg\n        else:\n            result += '{0}{1}'.format(divider, arg)\n    return result", "label": 1}
{"code": "func (i *Handle) DelService(s *Service) error {\n\treturn i.doCmd(s, nil, ipvsCmdDelService)\n}", "label": 5}
{"code": "function getSingleCallSignature(type) {\n            if (type.flags & 2588672 /* ObjectType */) {\n                var resolved = resolveStructuredTypeMembers(type);\n                if (resolved.callSignatures.length === 1 && resolved.constructSignatures.length === 0 &&\n                    resolved.properties.length === 0 && !resolved.stringIndexInfo && !resolved.numberIndexInfo) {\n                    return resolved.callSignatures[0];\n                }\n            }\n            return undefined;\n        }", "label": 3}
{"code": "function getPort(req) {\n\t\tif (req.connection && req.connection.localPort) {\n\t\t\treturn req.connection.localPort.toString();\n\t\t}\n\t\tconst host = req.headers && req.headers.host;\n\t\tlet protocolSrc = 80;\n\t\tif (host && ((host.match(/:/g) || []).length) === 1) {\n\t\t\tconst possiblePort = host.split(':')[1];\n\t\t\tprotocolSrc = isNaN(possiblePort) ? protocolSrc : possiblePort;\n\t\t}\n\t\treturn protocolSrc;\n\t}", "label": 3}
{"code": "public static base_response enable(nitro_service client, nsmode resource) throws Exception {\n\t\tnsmode enableresource = new nsmode();\n\t\tenableresource.mode = resource.mode;\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "func (c *Client) GetSignupTokenData(token string) (user string, otpQRCode []byte, e error) {\n\tout, err := c.Get(c.Endpoint(\"signuptokens\", token), url.Values{})\n\tif err != nil {\n\t\treturn \"\", nil, err\n\t}\n\n\tvar tokenData getSignupTokenDataResponse\n\tif err := json.Unmarshal(out.Bytes(), &tokenData); err != nil {\n\t\treturn \"\", nil, err\n\t}\n\n\treturn tokenData.User, tokenData.QRImg, nil\n}", "label": 5}
{"code": "private function setProperties()\n    {\n        \\danog\\MadelineProto\\Logger::log('Generating properties...', \\danog\\MadelineProto\\Logger::NOTICE);\n        $fixture = DocBlockFactory::createInstance();\n        $class = new \\ReflectionClass(APIFactory::class);\n        $content = file_get_contents($filename = $class->getFileName());\n        foreach ($class->getProperties() as $property) {\n            if ($raw_docblock = $property->getDocComment()) {\n                $docblock = $fixture->create($raw_docblock);\n                if ($docblock->hasTag('internal')) {\n                    $content = str_replace(\"\\n    \".$raw_docblock.\"\\n    public \\$\".$property->getName().';', '', $content);\n                }\n            }\n        }\n        foreach ($this->get_method_namespaces() as $namespace) {\n            $content = preg_replace('/(class( \\\\w+[,]?){0,}\\\\n{\\\\n)/', '${1}'.\"    /**\\n\".\"     * @internal this is a internal property generated by build_docs.php, don't change manually\\n\".\"     *\\n\".\"     * @var {$namespace}\\n\".\"     */\\n\".\"    public \\${$namespace};\\n\", $content);\n        }\n        file_put_contents($filename, $content);\n    }", "label": 2}
{"code": "public function lockRetentionPolicy(array $options = [])\n    {\n        if (!isset($options['ifMetagenerationMatch'])) {\n            if (!isset($this->info['metageneration'])) {\n                throw new \\BadMethodCallException(\n                    'No metageneration value was detected. Please either provide ' .\n                    'a value explicitly or ensure metadata is loaded through a ' .\n                    'call such as Bucket::reload().'\n                );\n            }\n\n            $options['ifMetagenerationMatch'] = $this->info['metageneration'];\n        }\n\n        return $this->info = $this->connection->lockRetentionPolicy(\n            $options + $this->identity\n        );\n    }", "label": 2}
{"code": "private function processCommit(OutputInterface $output, array $commit, array $components)\n    {\n        $output->writeln(sprintf(\n            'Processing Commit: <info>%s</info>',\n            $commit['message']\n        ));\n        $output->writeln(sprintf('View on GitHub: %s', $commit['htmlUrl']));\n        $output->writeln('----------');\n        $output->writeln('');\n\n        $message = trim($this->ask('Enter a release summary for this commit. You can change this later.', $commit['message']));\n\n        $commitRelease = [];\n        foreach ($components as $key => $component) {\n            $componentRelease = isset($commitRelease[$key])\n                ? $commitRelease[$key]\n                : ['level' => self::LEVEL_PATCH, 'message' => '', 'reasons' => []];\n\n            $lowestAllowedLevel = $componentRelease['level'];\n            $suggestedLevel = $lowestAllowedLevel;\n            $allowedLevels = array_filter($this->levels, function ($name, $key) use ($lowestAllowedLevel) {\n                return $key >= $lowestAllowedLevel;\n            }, ARRAY_FILTER_USE_BOTH);\n\n            $output->writeln(sprintf('Component <comment>%s</comment> modified by commit.', $key));\n\n            list ($suggestedLevel, $reasons) =\n                $this->determineSuggestedLevel($allowedLevels, $suggestedLevel, $component['files']);\n\n            $output->writeln(sprintf(\n                'We suggest a <info>%s</info> release because of the following reasons. Please do not use this as an ' .\n                'absolute guide, as this tool is unable to determine the correct outcome in every scenario.',\n                $this->levels[$suggestedLevel]\n            ));\n            $output->writeln('');\n\n            foreach ($reasons as $reason) {\n                $output->writeln('* '. $reason);\n            }\n\n            $output->writeln('');\n\n            $componentRelease['level'] = $suggestedLevel;\n            $componentRelease['message'] = $message .' (#'. $commit['reference'] .')';\n            $componentRelease['reasons'] = array_merge($componentRelease['reasons'], $reasons);\n            $componentRelease['ref'] = $commit['reference'];\n\n            $commitRelease[$key] = $componentRelease;\n        }\n\n        return $commitRelease;\n    }", "label": 2}
{"code": "public function setExtra($extra)\n    {\n        if (isset($extra['user']) && isset($extra['password'])) {\n            $this->header = \\base64_encode($extra['user'].':'.$extra['password']).\"\\r\\n\";\n        }\n    }", "label": 2}
{"code": "func (c *crontime) nextValidMinute(baseTime time.Time) {\n\tfor _, min := range c.minute {\n\t\tif c.calculatedTime.Hour() == baseTime.Hour() {\n\t\t\tif !hasPassed(min, c.calculatedTime.Minute()) {\n\t\t\t\tc.calculatedTime = setMinute(c.calculatedTime, min)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else {\n\t\t\tc.calculatedTime = setMinute(c.calculatedTime, min)\n\t\t\treturn\n\t\t}\n\t}\n\tc.calculatedTime = c.calculatedTime.Add(1 * time.Hour)\n\tc.calculatedTime = setMinute(c.calculatedTime, c.minute[0])\n\t//log.Println(\"Cronbee: Minute\", c.calculatedTime, baseTime)\n\tc.nextValidHour(baseTime)\n\tc.nextValidMinute(baseTime)\n}", "label": 5}
{"code": "func parseNetworkOptions(id string, option options.Generic) (*configuration, error) {\n\tvar (\n\t\terr    error\n\t\tconfig = &configuration{}\n\t)\n\t// parse generic labels first\n\tif genData, ok := option[netlabel.GenericData]; ok && genData != nil {\n\t\tif config, err = parseNetworkGenericOptions(genData); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\t// setting the parent to \"\" will trigger an isolated network dummy parent link\n\tif _, ok := option[netlabel.Internal]; ok {\n\t\tconfig.Internal = true\n\t\t// empty --parent= and --internal are handled the same.\n\t\tconfig.Parent = \"\"\n\t}\n\treturn config, nil\n}", "label": 5}
{"code": "func (n *network) getSubnetforIPv4(ip *net.IPNet) *ipv4Subnet {\n\tfor _, s := range n.config.Ipv4Subnets {\n\t\t_, snet, err := net.ParseCIDR(s.SubnetIP)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\t// first check if the mask lengths are the same\n\t\ti, _ := snet.Mask.Size()\n\t\tj, _ := ip.Mask.Size()\n\t\tif i != j {\n\t\t\tcontinue\n\t\t}\n\t\tif snet.Contains(ip.IP) {\n\t\t\treturn s\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function minutesToOffsetString(minutes) {\n  var t = String(Math.abs(minutes / 60)).split('.');\n  var H = pad(t[0]);\n  var m = t[1] ? parseInt(t[1], 10) * 0.6 : 0;\n  var sign = minutes < 0 ? '-' : '+';\n\n  return '' + sign + H + ':' + pad(m);\n}", "label": 3}
{"code": "def apply_basic_auth(params)\n      headers = params.fetch(:headers, {})\n      headers = basic_auth_header.merge(headers)\n      params.merge(:headers => headers)\n    end", "label": 4}
{"code": "func (l *Linter) LintFiles(files map[string][]byte) ([]Problem, error) {\n\tpkg := &pkg{\n\t\tfset:  token.NewFileSet(),\n\t\tfiles: make(map[string]*file),\n\t}\n\tvar pkgName string\n\tfor filename, src := range files {\n\t\tif isGenerated(src) {\n\t\t\tcontinue // See issue #239\n\t\t}\n\t\tf, err := parser.ParseFile(pkg.fset, filename, src, parser.ParseComments)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif pkgName == \"\" {\n\t\t\tpkgName = f.Name.Name\n\t\t} else if f.Name.Name != pkgName {\n\t\t\treturn nil, fmt.Errorf(\"%s is in package %s, not %s\", filename, f.Name.Name, pkgName)\n\t\t}\n\t\tpkg.files[filename] = &file{\n\t\t\tpkg:      pkg,\n\t\t\tf:        f,\n\t\t\tfset:     pkg.fset,\n\t\t\tsrc:      src,\n\t\t\tfilename: filename,\n\t\t}\n\t}\n\tif len(pkg.files) == 0 {\n\t\treturn nil, nil\n\t}\n\treturn pkg.lint(), nil\n}", "label": 5}
{"code": "def list_databases(filter = {}, name_only = false, opts = {})\n      cmd = { listDatabases: 1 }\n      cmd[:nameOnly] = !!name_only\n      cmd[:filter] = filter unless filter.empty?\n      use(Database::ADMIN).command(cmd, opts).first[Database::DATABASES]\n    end", "label": 4}
{"code": "def run_for_device_and_language(language, locale, device, launch_arguments, retries = 0)\n      return launch_one_at_a_time(language, locale, device, launch_arguments)\n    rescue => ex\n      UI.error(ex.to_s) # show the reason for failure to the user, but still maybe retry\n\n      if retries < launcher_config.number_of_retries\n        UI.important(\"Tests failed, re-trying #{retries + 1} out of #{launcher_config.number_of_retries + 1} times\")\n        run_for_device_and_language(language, locale, device, launch_arguments, retries + 1)\n      else\n        UI.error(\"Backtrace:\\n\\t#{ex.backtrace.join(\"\\n\\t\")}\") if FastlaneCore::Globals.verbose?\n        self.collected_errors << ex\n        raise ex if launcher_config.stop_after_first_error\n        return false # for the results\n      end\n    end", "label": 4}
{"code": "public static vpnclientlessaccesspolicy_binding get(nitro_service service, String name) throws Exception{\n\t\tvpnclientlessaccesspolicy_binding obj = new vpnclientlessaccesspolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnclientlessaccesspolicy_binding response = (vpnclientlessaccesspolicy_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (options) {\n    var pylintArgs = [];\n\n    var enable = options.enable;\n    delete options.enable;\n\n    if (enable) {\n      pylintArgs.push('--enable=' + enable);\n    }\n\n    var disable = options.disable;\n    delete options.disable;\n\n    if (disable) {\n      pylintArgs.push('--disable=' + disable);\n    }\n\n    var messageTemplate = options.messageTemplate;\n    delete options.messageTemplate;\n\n    if (messageTemplate) {\n      var aliases = {\n        'short': \"line {line}: {msg} ({symbol})\",\n        'msvs': \"{path}({line}): [{msg_id}({symbol}){obj}] {msg}\",\n        'parseable': \"{path}:{line}: [{msg_id}({symbol}), {obj}] {msg}\",\n      };\n      if (aliases[messageTemplate] !== undefined) {\n        pylintArgs.push('--msg-template=\"' + aliases[messageTemplate] + '\"');\n      } else {\n        pylintArgs.push('--msg-template=\"' + messageTemplate + '\"');\n      }\n    }\n\n    var outputFormat = options.outputFormat;\n    delete options.outputFormat;\n\n    if (outputFormat) {\n      pylintArgs.push('--output-format=' + outputFormat);\n    }\n\n    var report = options.report;\n    delete options.report;\n\n    // Make compatible with --reports as well\n    if (options.reports) {\n      report = options.reports;\n      delete options.reports;\n    }\n\n    if (report) {\n      pylintArgs.push('--reports=y');\n    } else {\n      pylintArgs.push('--reports=n');\n    }\n\n    var rcfile = options.rcfile;\n    delete options.rcfile;\n\n    if (rcfile) {\n      pylintArgs.push('--rcfile=' + rcfile);\n    }\n\n    var score = options.score;\n    delete options.score;\n\n    if (score) {\n      pylintArgs.push('--score=y');\n    } else {\n      pylintArgs.push('--score=n');\n    }\n\n    var errorsOnly = options.errorsOnly;\n    delete options.errorsOnly;\n\n    if (errorsOnly) {\n      pylintArgs.push('--errors-only');\n    }\n\n    var ignore = options.ignore;\n    delete options.ignore;\n\n    if (ignore) {\n      pylintArgs.push('--ignore=' + ignore);\n    }\n\n    // Fail if there's any options remaining now\n    for (var prop in options) {\n      if (options.hasOwnProperty(prop)) {\n        grunt.fail.warn(\"Unknown option to pylint: '\" + prop + \"'\");\n      }\n    }\n\n    return pylintArgs;\n  }", "label": 3}
{"code": "function AbstractError(message, constr) {\n    Error.apply(this, arguments);\n    Error.captureStackTrace(this, constr || this);\n\n    this.name = 'AbstractError';\n    this.message = message;\n}", "label": 3}
{"code": "function setupStrategies(auth) {\n    var result = {};\n    if (auth.maintenance === 'token') {\n      result = {\n\n        facebook: require('passport-facebook').Strategy,\n        twitter: require('passport-twitter').Strategy\n      };\n    } else {\n      result = {\n        google: require('passport-google-oauth').OAuth2Strategy,\n        facebook: require('passport-facebook').Strategy,\n        twitter: require('passport-twitter').Strategy\n      };\n    }\n    return result;\n  }", "label": 3}
{"code": "func (d *driver) ProgramExternalConnectivity(nid, eid string, options map[string]interface{}) error {\n\tdata := &api.ProgramExternalConnectivityRequest{\n\t\tNetworkID:  nid,\n\t\tEndpointID: eid,\n\t\tOptions:    options,\n\t}\n\terr := d.call(\"ProgramExternalConnectivity\", data, &api.ProgramExternalConnectivityResponse{})\n\tif err != nil && plugins.IsNotFound(err) {\n\t\t// It is not mandatory yet to support this method\n\t\treturn nil\n\t}\n\treturn err\n}", "label": 5}
{"code": "func (c *Client) Wait(ctx context.Context, obj types.ManagedObjectReference, ps []string, f func([]types.PropertyChange) bool) error {\n\treturn property.Wait(ctx, c.PropertyCollector(), obj, ps, f)\n}", "label": 5}
{"code": "function prettifyDiffObj(diff) {\n    const obj = {\n        kind: undefined,\n        path: undefined,\n        expect: undefined,\n        actual: undefined,\n        index: undefined,\n        item: undefined,\n    };\n    if (diff.kind) {\n        switch (diff.kind) {\n            case 'N':\n                obj.kind = 'New';\n                break;\n            case 'D':\n                obj.kind = 'Missing';\n                break;\n            case 'E':\n                obj.kind = 'Changed';\n                break;\n            case 'A':\n                obj.kind = 'Array Canged';\n                break;\n        }\n    }\n    if (diff.path) {\n        let path = diff.path[0];\n        for (let i = 1; i < diff.path.length; i++) {\n            path += `/${diff.path[i]}`;\n        }\n        obj.path = path;\n    }\n    if (typeof diff.lhs !== 'undefined') {\n        obj.expect = diff.lhs;\n    }\n    if (typeof diff.rhs !== 'undefined') {\n        obj.actual = diff.rhs;\n    }\n    if (diff.index) {\n        obj.index = diff.index;\n    }\n    if (diff.item) {\n        obj.item = prettifyDiffObj(diff.item);\n    }\n    return obj;\n}", "label": 3}
{"code": "func AuthUserUserPermissionsByUserID(db XODB, userID float64) ([]*AuthUserUserPermission, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, user_id, permission_id ` +\n\t\t`FROM django.auth_user_user_permissions ` +\n\t\t`WHERE user_id = :1`\n\n\t// run query\n\tXOLog(sqlstr, userID)\n\tq, err := db.Query(sqlstr, userID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*AuthUserUserPermission{}\n\tfor q.Next() {\n\t\tauup := AuthUserUserPermission{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&auup.ID, &auup.UserID, &auup.PermissionID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &auup)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def _match_magic(self, full_path):\n        \"\"\"Return the first magic that matches this path or None.\"\"\"\n        for magic in self.magics:\n            if magic.matches(full_path):\n                return magic", "label": 1}
{"code": "function toArray(x, delimiter)\n{\n  if ( x instanceof Array )\n  {\n    return x;\n  }\n  if ( isString( x ) )\n  {\n    return x.split( delimiter );\n  }\n  if ( isValue( x ) )\n  {\n    return [ x ];\n  }\n\n  return [];\n}", "label": 3}
{"code": "public function with($parameters)\n    {\n        $this->parameters = array_merge($this->parameters, is_array($parameters) ? $parameters : func_get_args());\n\n        return $this;\n    }", "label": 2}
{"code": "func GetCustomFieldsManager(c *vim25.Client) (*CustomFieldsManager, error) {\n\tif c.ServiceContent.CustomFieldsManager == nil {\n\t\treturn nil, ErrNotSupported\n\t}\n\treturn NewCustomFieldsManager(c), nil\n}", "label": 5}
{"code": "public String findPlatformFor(String jdbcSubProtocol, String jdbcDriver)\r\n    {\r\n        String platform = (String)jdbcSubProtocolToPlatform.get(jdbcSubProtocol);\r\n\r\n        if (platform == null)\r\n        {\r\n            platform = (String)jdbcDriverToPlatform.get(jdbcDriver);\r\n        }\r\n        return platform;\r\n    }", "label": 0}
{"code": "def set_date_from_event(event, issue)\n      if event[\"commit_id\"].nil?\n        issue[\"actual_date\"] = issue[\"closed_at\"]\n      else\n        begin\n          commit = @fetcher.fetch_commit(event[\"commit_id\"])\n          issue[\"actual_date\"] = commit[\"commit\"][\"author\"][\"date\"]\n\n          # issue['actual_date'] = commit['author']['date']\n        rescue StandardError\n          puts \"Warning: Can't fetch commit #{event['commit_id']}. It is probably referenced from another repo.\"\n          issue[\"actual_date\"] = issue[\"closed_at\"]\n        end\n      end\n    end", "label": 4}
{"code": "def changes_to(time: nil, version: nil, data: {}, from: 0)\n      raise ArgumentError, \"Time or version must be specified\" if time.nil? && version.nil?\n\n      filter = time.nil? ? method(:version_filter) : method(:time_filter)\n      versions.each_with_object(data.dup) do |v, acc|\n        next if v.version < from\n        break acc if filter.call(v, version, time)\n\n        acc.merge!(v.changes)\n      end\n    end", "label": 4}
{"code": "function (segment) {\n\n            var segmentPath = Series.prototype.getSegmentPath.call(this, segment), // call base method\n              areaSegmentPath = [].concat(segmentPath), // work on a copy for the area path\n              i,\n              options = this.options,\n              segLength = segmentPath.length,\n              translatedThreshold = this.yAxis.getThreshold(options.threshold), // #2181\n              yBottom;\n\n            if (segLength === 3) { // for animation from 1 to two points\n                areaSegmentPath.push(L, segmentPath[1], segmentPath[2]);\n            }\n            if (options.stacking && !this.closedStacks) {\n\n                // Follow stack back. Todo: implement areaspline. A general solution could be to\n                // reverse the entire graphPath of the previous series, though may be hard with\n                // splines and with series with different extremes\n                for (i = segment.length - 1; i >= 0; i--) {\n\n                    yBottom = pick(segment[i].yBottom, translatedThreshold);\n\n                    // step line?\n                    if (i < segment.length - 1 && options.step) {\n                        areaSegmentPath.push(segment[i + 1].plotX, yBottom);\n                    }\n\n                    areaSegmentPath.push(segment[i].plotX, yBottom);\n                }\n\n            } else { // follow zero line back\n                this.closeSegment(areaSegmentPath, segment, translatedThreshold);\n            }\n            this.areaPath = this.areaPath.concat(areaSegmentPath);\n            return segmentPath;\n        }", "label": 3}
{"code": "public static List<Map<String,String>> readCSVWithHeader(String path, char quoteChar, char escapeChar) throws IOException {\r\n    String[] labels = null;\r\n    List<Map<String,String>> rows = Generics.newArrayList();\r\n    for (String line : IOUtils.readLines(path)) {\r\n      System.out.println(\"Splitting \"+line);\r\n      if (labels == null) {\r\n        labels = StringUtils.splitOnCharWithQuoting(line,',','\"',escapeChar);\r\n      } else {\r\n        String[] cells = StringUtils.splitOnCharWithQuoting(line,',',quoteChar,escapeChar);\r\n        assert(cells.length == labels.length);\r\n        Map<String,String> cellMap = new HashMap<String,String>();\r\n        for (int i=0; i<labels.length; i++) cellMap.put(labels[i],cells[i]);\r\n        rows.add(cellMap);\r\n      }\r\n    }\r\n    return rows;\r\n  }", "label": 0}
{"code": "public boolean existsElement(String predicate) throws org.odmg.QueryInvalidException\r\n    {\r\n        DList results = (DList) this.query(predicate);\r\n        if (results == null || results.size() == 0)\r\n            return false;\r\n        else\r\n            return true;\r\n    }", "label": 0}
{"code": "def build_url(url = nil, extra_params = nil)\n      uri = build_exclusive_url(url)\n\n      query_values = params.dup.merge_query(uri.query, options.params_encoder)\n      query_values.update(extra_params) if extra_params\n      uri.query =\n        if query_values.empty?\n          nil\n        else\n          query_values.to_query(options.params_encoder)\n        end\n\n      uri\n    end", "label": 4}
{"code": "function renameIdentifier(ast, oldName, newName, defNode) {\n  // Summary:\n  //  Rename identifiers with oldName in ast\n  const changes = [];\n  if (!defNode) {\n    let scope;\n    traverse(ast, {\n      Identifier(path) {\n        if (path.node.name === oldName) {\n          scope = path.scope;\n          path.stop();\n        }\n      },\n    });\n    if (!scope) return changes;\n    defNode = getDefNode(oldName, scope);\n  }\n\n  function rename(path) {\n    if (\n      path.node.name === oldName &&\n      path.key !== 'imported' && // it should NOT be imported specifier\n      getDefNode(path.node.name, path.scope) === defNode\n    ) {\n      path.node.name = newName;\n      changes.push({\n        start: path.node.start,\n        end: path.node.end,\n        replacement: newName,\n      });\n    }\n  }\n  traverse(ast, {\n    JSXIdentifier: rename,\n    Identifier: rename,\n  });\n  return changes;\n}", "label": 3}
{"code": "func HTTPReply(w http.ResponseWriter, r *HTTPResult, j *JSONOutput) (int, error) {\n\tvar response []byte\n\tif j.enable {\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tvar err error\n\t\tif j.prettyPrint {\n\t\t\tresponse, err = json.MarshalIndent(r, \"\", \"  \")\n\t\t\tif err != nil {\n\t\t\t\tresponse, _ = json.MarshalIndent(FailCommand(err), \"\", \"  \")\n\t\t\t}\n\t\t} else {\n\t\t\tresponse, err = json.Marshal(r)\n\t\t\tif err != nil {\n\t\t\t\tresponse, _ = json.Marshal(FailCommand(err))\n\t\t\t}\n\t\t}\n\t} else {\n\t\tresponse = []byte(r.String())\n\t}\n\treturn fmt.Fprint(w, string(response))\n}", "label": 5}
{"code": "protected function querySentinelForMaster(NodeConnectionInterface $sentinel, $service)\n    {\n        $payload = $sentinel->executeCommand(\n            RawCommand::create('SENTINEL', 'get-master-addr-by-name', $service)\n        );\n\n        if ($payload === null) {\n            throw new ServerException('ERR No such master with that name');\n        }\n\n        if ($payload instanceof ErrorResponseInterface) {\n            $this->handleSentinelErrorResponse($sentinel, $payload);\n        }\n\n        return array(\n            'host' => $payload[0],\n            'port' => $payload[1],\n            'alias' => 'master',\n        );\n    }", "label": 2}
{"code": "def toc_only(html)\n      Jekyll.logger.warn 'Deprecation: toc_only filter is deprecated and will be remove in jekyll-toc v1.0.',\n                         'Use `{% toc %}` instead of `{{ content | toc_only }}`.'\n      return '' unless toc_enabled?\n\n      TableOfContents::Parser.new(html, toc_config).build_toc\n    end", "label": 4}
{"code": "public static base_response restore(nitro_service client, appfwprofile resource) throws Exception {\n\t\tappfwprofile restoreresource = new appfwprofile();\n\t\trestoreresource.archivename = resource.archivename;\n\t\treturn restoreresource.perform_operation(client,\"restore\");\n\t}", "label": 0}
{"code": "public Object getBeliefValue(String agent_name, final String belief_name,\n            Connector connector) {\n\n        ((IExternalAccess) connector.getAgentsExternalAccess(agent_name))\n                .scheduleStep(new IComponentStep<Integer>() {\n\n                    public IFuture<Integer> execute(IInternalAccess ia) {\n                        IBDIInternalAccess bia = (IBDIInternalAccess) ia;\n                        belief_value = bia.getBeliefbase()\n                                .getBelief(belief_name).getFact();\n                        return null;\n                    }\n                }).get(new ThreadSuspendable());\n        return belief_value;\n    }", "label": 0}
{"code": "protected TypeReference<?> getBeanPropertyType(Class<?> clazz,\r\n\t\t\tString propertyName, TypeReference<?> originalType) {\r\n\t\tTypeReference<?> propertyDestinationType = null;\r\n\t\tif (beanDestinationPropertyTypeProvider != null) {\r\n\t\t\tpropertyDestinationType = beanDestinationPropertyTypeProvider\r\n\t\t\t\t\t.getPropertyType(clazz, propertyName, originalType);\r\n\t\t}\r\n\t\tif (propertyDestinationType == null) {\r\n\t\t\tpropertyDestinationType = originalType;\r\n\t\t}\r\n\t\treturn propertyDestinationType;\r\n\t}", "label": 0}
{"code": "public static base_responses disable(nitro_service client, Long clid[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (clid != null && clid.length > 0) {\n\t\t\tclusterinstance disableresources[] = new clusterinstance[clid.length];\n\t\t\tfor (int i=0;i<clid.length;i++){\n\t\t\t\tdisableresources[i] = new clusterinstance();\n\t\t\t\tdisableresources[i].clid = clid[i];\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, disableresources,\"disable\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def trim_by_coverage(self, min_reads):\n        \"\"\"\n        Given the min number of reads overlapping each nucleotide of\n        a variant sequence, trim this sequence by getting rid of positions\n        which are overlapped by fewer reads than specified.\n        \"\"\"\n        read_count_array = self.coverage()\n        logger.info(\"Coverage: %s (len=%d)\" % (\n            read_count_array, len(read_count_array)))\n        sufficient_coverage_mask = read_count_array >= min_reads\n        sufficient_coverage_indices = np.argwhere(sufficient_coverage_mask)\n        if len(sufficient_coverage_indices) == 0:\n            logger.debug(\"No bases in %s have coverage >= %d\" % (self, min_reads))\n            return VariantSequence(prefix=\"\", alt=\"\", suffix=\"\", reads=self.reads)\n        variant_start_index, variant_end_index = self.variant_indices()\n        # assuming that coverage drops off monotonically away from\n        # variant nucleotides\n        first_covered_index = sufficient_coverage_indices.min()\n        last_covered_index = sufficient_coverage_indices.max()\n        # adding 1 to last_covered_index since it's an inclusive index\n        # whereas variant_end_index is the end of a half-open interval\n        if (first_covered_index > variant_start_index or\n                last_covered_index + 1 < variant_end_index):\n            # Example:\n            #   Nucleotide sequence:\n            #       ACCCTTTT|AA|GGCGCGCC\n            #   Coverage:\n            #       12222333|44|33333211\n            # Then the mask for bases covered >= 4x would be:\n            #       ________|**|________\n            # with indices:\n            #       first_covered_index = 9\n            #       last_covered_index = 10\n            #       variant_start_index = 9\n            #       variant_end_index = 11\n            logger.debug(\"Some variant bases in %s don't have coverage >= %d\" % (\n                self, min_reads))\n            return VariantSequence(prefix=\"\", alt=\"\", suffix=\"\", reads=self.reads)\n        return VariantSequence(\n            prefix=self.prefix[first_covered_index:],\n            alt=self.alt,\n            suffix=self.suffix[:last_covered_index - variant_end_index + 1],\n            reads=self.reads)", "label": 1}
{"code": "public function setQueryTextSentiment($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Sentiment::class);\n        $this->query_text_sentiment = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def main():\n    \"\"\"\n    This is the main function for ProTECT.\n    \"\"\"\n    parser = argparse.ArgumentParser(prog='ProTECT',\n                                     description='Prediction of T-Cell Epitopes for Cancer Therapy',\n                                     epilog='Contact Arjun Rao (aarao@ucsc.edu) if you encounter '\n                                     'any problems while running ProTECT')\n    inputs = parser.add_mutually_exclusive_group(required=True)\n    inputs.add_argument('--config_file', dest='config_file', help='Config file to be used in the '\n                        'run.', type=str, default=None)\n    inputs.add_argument('--generate_config', dest='generate_config', help='Generate a config file '\n                        'in the current directory that is pre-filled with references and flags for '\n                        'an hg19 run.', action='store_true', default=False)\n    parser.add_argument('--max-cores-per-job', dest='max_cores', help='Maximum cores to use per '\n                        'job. Aligners and Haplotypers ask for cores dependent on the machine that '\n                        'the launchpad gets assigned to -- In a heterogeneous cluster, this can '\n                        'lead to problems. This value should be set to the number of cpus on the '\n                        'smallest node in a cluster.',\n                        type=int, required=False, default=None)\n    # We parse the args once to see if the user has asked for a config file to be generated.  In\n    # this case, we don't need a jobstore.  To handle the case where Toil arguments are passed to\n    # ProTECT, we parse known args, and if the used specified config_file instead of generate_config\n    # we re-parse the arguments with the added Toil parser.\n    params, others = parser.parse_known_args()\n    if params.generate_config:\n        generate_config_file()\n    else:\n        Job.Runner.addToilOptions(parser)\n        params = parser.parse_args()\n        params.config_file = os.path.abspath(params.config_file)\n        if params.maxCores:\n            if not params.max_cores:\n                params.max_cores = int(params.maxCores)\n            else:\n                if params.max_cores > int(params.maxCores):\n                    print(\"The value provided to max-cores-per-job (%s) was greater than that \"\n                          \"provided to maxCores (%s). Setting max-cores-per-job = maxCores.\" %\n                          (params.max_cores, params.maxCores), file=sys.stderr)\n                    params.max_cores = int(params.maxCores)\n        start = Job.wrapJobFn(parse_config_file, params.config_file, params.max_cores)\n        Job.Runner.startToil(start, params)\n    return None", "label": 1}
{"code": "def _unregisterHandler(self, handler, shutdown=True):\n        \"\"\"\n        Unregisters the logging handler.\n\n        :param handler:  A handler previously registered with this loggger.\n        :param shutdown: Flag to shutdown the handler.\n        \"\"\"\n        if handler in self._handlers:\n            self._handlers.remove(handler)\n            self._logger.removeHandler(handler)\n            if shutdown:\n                try:\n                    handler.close()\n                except KeyError:\n                    # Depending on the Python version, it's possible for this call\n                    # to fail most likely because some logging module objects get\n                    # garbage collected before the VSGLogger object is.\n                    pass", "label": 1}
{"code": "def tinymce_configurations_javascript(options={})\n      javascript = []\n\n      TinyMCE::Rails.each_configuration do |name, config|\n        config = config.merge(options) if options.present?\n        javascript << \"TinyMCERails.configuration.#{name} = #{config.to_javascript};\".html_safe\n      end\n\n      safe_join(javascript, \"\\n\")\n    end", "label": 4}
{"code": "function idStep (obj, name, inherit) {\n    return function (id) {\n        var ctx = obj ? new obj(inherit ? this : undefined) : this;\n        ctx.steps.push(name);\n        ctx.steps.push(id);\n        return ctx;\n    };\n}", "label": 3}
{"code": "func MarshalTunnelConnection(rt TunnelConnection, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch resource := rt.(type) {\n\tcase *TunnelConnectionV2:\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *resource\n\t\t\tcopy.SetResourceID(0)\n\t\t\tresource = &copy\n\t\t}\n\t\treturn utils.FastMarshal(resource)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"unrecognized resource version %T\", rt)\n\t}\n}", "label": 5}
{"code": "function _gpfCleanDefinition (name, shortcut) {\n    /*jshint validthis:true*/ // Bound to the definition below\n    var shortcutValue = this[shortcut];\n    if (undefined !== shortcutValue) {\n        this[name] = shortcutValue;\n        delete this[shortcut];\n    }\n}", "label": 3}
{"code": "def find_nodes(self, query_dict=None, exact=False, verbose=False, **kwargs):\n        \"\"\"Query on node properties. See documentation for _OTIWrapper class.\"\"\"\n        assert self.use_v1\n        return self._do_query('{p}/singlePropertySearchForTreeNodes'.format(p=self.query_prefix),\n                              query_dict=query_dict,\n                              exact=exact,\n                              verbose=verbose,\n                              valid_keys=self.node_search_term_set,\n                              kwargs=kwargs)", "label": 1}
{"code": "def get(cls, community_id, record_uuid):\n        \"\"\"Get an inclusion request.\"\"\"\n        return cls.query.filter_by(\n            id_record=record_uuid, id_community=community_id\n        ).one_or_none()", "label": 1}
{"code": "func (cfg *Config) ApplyToken(token string) bool {\n\tif token != \"\" {\n\t\tcfg.Token = token\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "def doInteractions(self, number=1):\n        \"\"\" Directly maps the agents and the tasks.\n        \"\"\"\n        t0 = time.time()\n\n        for _ in range(number):\n            self._oneInteraction()\n\n        elapsed = time.time() - t0\n        logger.info(\"%d interactions executed in %.3fs.\" % (number, elapsed))\n\n        return self.stepid", "label": 1}
{"code": "func DjangoSessionsByExpireDate(db XODB, expireDate *time.Time) ([]*DjangoSession, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`session_key, session_data, expire_date ` +\n\t\t`FROM django.django_session ` +\n\t\t`WHERE expire_date = ?`\n\n\t// run query\n\tXOLog(sqlstr, expireDate)\n\tq, err := db.Query(sqlstr, expireDate)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*DjangoSession{}\n\tfor q.Next() {\n\t\tds := DjangoSession{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&ds.SessionKey, &ds.SessionData, &ds.ExpireDate)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ds)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def attribute_changed_from_default?(attr)\n      field = fields[attr]\n      return false unless field\n      attributes[attr] != field.eval_default(self)\n    end", "label": 4}
{"code": "func UnlinkCurrentProfile() error {\n\treturn trace.Wrap(os.Remove(filepath.Join(FullProfilePath(\"\"), CurrentProfileSymlink)))\n}", "label": 5}
{"code": "public function uninstall($name)\n    {\n        $extension = $this->getExtension($name);\n\n        $this->disable($name);\n\n        $this->migrateDown($extension);\n\n        $this->unpublishAssets($extension);\n\n        $extension->setInstalled(false);\n\n        $this->dispatcher->dispatch(new Uninstalled($extension));\n    }", "label": 2}
{"code": "public String getPrefixStatsSetPositionPrefixAttribute(String field) {\n    return String.join(MtasToken.DELIMITER, setPositionPrefix.get(field));\n  }", "label": 0}
{"code": "def serve\n      @server_transport.listen\n\n      begin\n        loop do\n          @thread_q.push(:token)\n          Thread.new do\n            begin\n              loop do\n                client = @server_transport.accept\n                trans = @transport_factory.get_transport(client)\n                prot = @protocol_factory.get_protocol(trans)\n                begin\n                  loop do\n                    @processor.process(prot, prot)\n                  end\n                rescue Thrift::TransportException, Thrift::ProtocolException => e\n                ensure\n                  trans.close\n                end\n              end\n            rescue => e\n              @exception_q.push(e)\n            ensure\n              @thread_q.pop # thread died!\n            end\n          end\n        end\n      ensure\n        @server_transport.close\n      end\n    end", "label": 4}
{"code": "func (sink *influxdbSink) GetNodes() ([]string, error) {\n\treturn sink.stringListQuery(fmt.Sprintf(\"SHOW TAG VALUES WITH KEY = %s\", core.LabelNodename.Key), \"Unable to list all nodes\")\n}", "label": 5}
{"code": "function (e) {\n                if (e instanceof java.util.NoSuchElementException || e.message.startsWith(\"java.util.NoSuchElementException\")) {\n                    // Empty stream\n                    return Promise.resolve();\n                }\n                return Promise.reject(e);\n            }", "label": 3}
{"code": "def distinct_values(t_old, t_new):   \n    \"\"\"\n    for all columns, check which values are not in \n    the other table\n    \"\"\"\n    res = []\n    res.append([' -- NOT IN check -- '])\n    for new_col in t_new.header:\n        dist_new = t_new.get_distinct_values_from_cols([new_col])\n        #print('NEW Distinct values for ' + new_col + ' = ' + str(dist_new))\n        for old_col in t_old.header:\n            if old_col == new_col:\n                dist_old = t_old.get_distinct_values_from_cols([old_col])\n                #print('OLD Distinct values for ' + old_col + ' = ' + str(dist_old))\n                \n                # Now compare the old and new values to see what is different\n                not_in_new = [x for x in dist_old[0] if x not in dist_new[0]]\n                if not_in_new != []:\n                    #print(old_col + ' not_in_new = ' , not_in_new)\n                    res.append(['Not in New', old_col, not_in_new])\n                    \n                not_in_old = [x for x in dist_new[0] if x not in dist_old[0]]\n                if not_in_old != []:\n                    #print(new_col + ' not_in_old = ' , not_in_old)\n                    res.append(['Not in Old', new_col, not_in_old])\n                    \n                    \n    \n    return sorted(res)", "label": 1}
{"code": "function determinePartialName(partial_path, source_path, options) {\n  var match, rel, abs,\n    path_reg = /(\\.\\.?\\/)?(.+)/;\n\n  // use a regex to find whether or not this is a relative path  \n  match = path_reg.exec(partial_path);\n  if (match[1]) {\n    // use os-appropriate separator\n    rel = partial_path.replace('/', path.sep);\n\n    // join the root, the source_path, and the relative path, then find the relative path from the root\n    // this is the new \"absolute\"\" path\n    abs = path.relative(options.root, path.join(options.root, source_path, rel));\n  } else {\n    // use os-appropriate separator\n    abs = match[2].replace('/', path.sep);\n  }\n\n  // now use the naming function to get the name\n  return options.namingFn(abs, options);\n}", "label": 3}
{"code": "public static boolean sameLists(String list1, String list2)\r\n    {\r\n        return new CommaListIterator(list1).equals(new CommaListIterator(list2));\r\n    }", "label": 0}
{"code": "func (p *Panel) Draw() {\n\tp.BoxLayout.SetOrientation(Vertical)\n\tp.BoxLayout.Draw()\n}", "label": 5}
{"code": "public static final Date utc2date(Long time) {\n\n        // don't accept negative values\n        if (time == null || time < 0) return null;\n        \n        // add the timezone offset\n        time += timezoneOffsetMillis(new Date(time));\n\n        return new Date(time);\n    }", "label": 0}
{"code": "func (b *BackendStats) SortedTopRequests() []Request {\n\tout := make([]Request, 0, len(b.TopRequests))\n\tfor _, req := range b.TopRequests {\n\t\tout = append(out, req)\n\t}\n\tsort.Slice(out, func(i, j int) bool {\n\t\tif out[i].GetFreq() == out[j].GetFreq() {\n\t\t\treturn out[i].Count > out[j].Count\n\t\t}\n\t\treturn out[i].GetFreq() > out[j].GetFreq()\n\t})\n\treturn out\n}", "label": 5}
{"code": "def run(self, cmd):\n        \"\"\"Runs the appropriate command\"\"\"\n        print datetime.datetime.now()\n        output = subprocess.Popen(cmd, shell=True)\n        output = output.communicate()[0]\n        print output", "label": 1}
{"code": "func (c *TrustedClusterV2) String() string {\n\treturn fmt.Sprintf(\"TrustedCluster(Enabled=%v,Roles=%v,Token=%v,ProxyAddress=%v,ReverseTunnelAddress=%v)\",\n\t\tc.Spec.Enabled, c.Spec.Roles, c.Spec.Token, c.Spec.ProxyAddress, c.Spec.ReverseTunnelAddress)\n}", "label": 5}
{"code": "function (e, point) {\n            if (!this.crosshair) { return; }// Do not draw crosshairs if you don't have too.\n\n            if ((defined(point) || !pick(this.crosshair.snap, true)) === false) {\n                this.hideCrosshair();\n                return;\n            }\n\n            var path,\n              options = this.crosshair,\n              animation = options.animation,\n              pos;\n\n            // Get the path\n            if (!pick(options.snap, true)) {\n                pos = (this.horiz ? e.chartX - this.pos : this.len - e.chartY + this.pos);\n            } else if (defined(point)) {\n                /*jslint eqeq: true*/\n                pos = (this.chart.inverted != this.horiz) ? point.plotX : this.len - point.plotY;\n                /*jslint eqeq: false*/\n            }\n\n            if (this.isRadial) {\n                path = this.getPlotLinePath(this.isXAxis ? point.x : pick(point.stackY, point.y));\n            } else {\n                path = this.getPlotLinePath(null, null, null, null, pos);\n            }\n\n            if (path === null) {\n                this.hideCrosshair();\n                return;\n            }\n\n            // Draw the cross\n            if (this.cross) {\n                this.cross\n                  .attr({ visibility: VISIBLE })[animation ? 'animate' : 'attr']({ d: path }, animation);\n            } else {\n                var attribs = {\n                    'stroke-width': options.width || 1,\n                    stroke: options.color || '#C0C0C0',\n                    zIndex: options.zIndex || 2\n                };\n                if (options.dashStyle) {\n                    attribs.dashstyle = options.dashStyle;\n                }\n                this.cross = this.chart.renderer.path(path).attr(attribs).add();\n            }\n        }", "label": 3}
{"code": "public function setOrganizationSettings($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\SecurityCenter\\V1\\OrganizationSettings::class);\n        $this->organization_settings = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response add(nitro_service client, clusternodegroup resource) throws Exception {\n\t\tclusternodegroup addresource = new clusternodegroup();\n\t\taddresource.name = resource.name;\n\t\taddresource.strict = resource.strict;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def process_shells_parallel(self, shells):\n        \"\"\"Processing a list of shells parallel.\"\"\"\n        output = []\n        success = True\n        with closing(multiprocessing.Pool(multiprocessing.cpu_count())) as pool:\n            for result in [Adapter(entry) for entry in pool.map(worker, [shell for shell in shells])]:\n                output += result.output\n                the_shell = [shell for shell in shells if shell['id'] == result.id][0]\n                self.__handle_variable(the_shell['entry'], result.output)\n                if not result.success:\n                    success = False\n        if success:\n            self.logger.info(\"Parallel Processing Bash code: finished\")\n            return {'success': True, 'output': output}\n\n        for line in self.run_cleanup(shells[0]['env'], 99):\n            output.append(line)\n        self.logger.error(\"Pipeline has failed: immediately leaving!\")\n        self.event.failed()\n        return {'success': False, 'output': output}", "label": 1}
{"code": "func isIP(fl FieldLevel) bool {\n\n\tip := net.ParseIP(fl.Field().String())\n\n\treturn ip != nil\n}", "label": 5}
{"code": "public String getSQL92LikePattern() throws IllegalArgumentException {\n\t\tif (escape.length() != 1) {\n\t\t\tthrow new IllegalArgumentException(\"Like Pattern --> escape char should be of length exactly 1\");\n\t\t}\n\t\tif (wildcardSingle.length() != 1) {\n\t\t\tthrow new IllegalArgumentException(\"Like Pattern --> wildcardSingle char should be of length exactly 1\");\n\t\t}\n\t\tif (wildcardMulti.length() != 1) {\n\t\t\tthrow new IllegalArgumentException(\"Like Pattern --> wildcardMulti char should be of length exactly 1\");\n\t\t}\n\t\treturn LikeFilterImpl.convertToSQL92(escape.charAt(0), wildcardMulti.charAt(0), wildcardSingle.charAt(0),\n\t\t\t\tisMatchingCase(), pattern);\n\t}", "label": 0}
{"code": "func New(u *url.URL, settings []vim.BaseOptionValue) (string, http.Handler) {\n\ts := &handler{\n\t\tServeMux:    http.NewServeMux(),\n\t\tURL:         *u,\n\t\tCategory:    make(map[string]*tags.Category),\n\t\tTag:         make(map[string]*tags.Tag),\n\t\tAssociation: make(map[string]map[internal.AssociatedObject]bool),\n\t\tSession:     make(map[string]*session),\n\t\tLibrary:     make(map[string]content),\n\t\tUpdate:      make(map[string]update),\n\t}\n\n\thandlers := []struct {\n\t\tp string\n\t\tm http.HandlerFunc\n\t}{\n\t\t{internal.SessionPath, s.session},\n\t\t{internal.CategoryPath, s.category},\n\t\t{internal.CategoryPath + \"/\", s.categoryID},\n\t\t{internal.TagPath, s.tag},\n\t\t{internal.TagPath + \"/\", s.tagID},\n\t\t{internal.AssociationPath, s.association},\n\t\t{internal.AssociationPath + \"/\", s.associationID},\n\t\t{internal.LibraryPath, s.library},\n\t\t{internal.LocalLibraryPath, s.library},\n\t\t{internal.LibraryPath + \"/\", s.libraryID},\n\t\t{internal.LocalLibraryPath + \"/\", s.libraryID},\n\t\t{internal.LibraryItemPath, s.libraryItem},\n\t\t{internal.LibraryItemPath + \"/\", s.libraryItemID},\n\t\t{internal.LibraryItemUpdateSession, s.libraryItemUpdateSession},\n\t\t{internal.LibraryItemUpdateSession + \"/\", s.libraryItemUpdateSessionID},\n\t\t{internal.LibraryItemUpdateSessionFile, s.libraryItemUpdateSessionFile},\n\t\t{internal.LibraryItemUpdateSessionFile + \"/\", s.libraryItemUpdateSessionFileID},\n\t\t{internal.LibraryItemAdd + \"/\", s.libraryItemAdd},\n\t\t{internal.LibraryItemFilePath, s.libraryItemFile},\n\t\t{internal.LibraryItemFilePath + \"/\", s.libraryItemFileID},\n\t\t{internal.VCenterOVFLibraryItem + \"/\", s.libraryItemDeployID},\n\t}\n\n\tfor i := range handlers {\n\t\th := handlers[i]\n\t\ts.HandleFunc(internal.Path+h.p, func(w http.ResponseWriter, r *http.Request) {\n\t\t\ts.Lock()\n\t\t\tdefer s.Unlock()\n\n\t\t\tif !s.isAuthorized(r) {\n\t\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\th.m(w, r)\n\t\t})\n\t}\n\n\treturn internal.Path + \"/\", s\n}", "label": 5}
{"code": "func (p *PoolData) UnmarshalJSON(data []byte) error {\n\tvar (\n\t\terr error\n\t\tt   struct {\n\t\t\tParentKey SubnetKey\n\t\t\tPool      string\n\t\t\tRange     *AddressRange `json:\",omitempty\"`\n\t\t\tRefCount  int\n\t\t}\n\t)\n\n\tif err = json.Unmarshal(data, &t); err != nil {\n\t\treturn err\n\t}\n\n\tp.ParentKey = t.ParentKey\n\tp.Range = t.Range\n\tp.RefCount = t.RefCount\n\tif t.Pool != \"\" {\n\t\tif p.Pool, err = types.ParseCIDR(t.Pool); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo, :sha]) do\n        permit VALID_STATUS_PARAM_NAMES, recursive: false\n        assert_required REQUIRED_PARAMS\n      end\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/statuses/#{arguments.sha}\", arguments.params)\n    end", "label": 4}
{"code": "public static base_response add(nitro_service client, snmpgroup resource) throws Exception {\n\t\tsnmpgroup addresource = new snmpgroup();\n\t\taddresource.name = resource.name;\n\t\taddresource.securitylevel = resource.securitylevel;\n\t\taddresource.readviewname = resource.readviewname;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public static base_response add(nitro_service client, dnscnamerec resource) throws Exception {\n\t\tdnscnamerec addresource = new dnscnamerec();\n\t\taddresource.aliasname = resource.aliasname;\n\t\taddresource.canonicalname = resource.canonicalname;\n\t\taddresource.ttl = resource.ttl;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def _unpack_model(self, om):\n        \"\"\" Returns data from the OPF model.\n        \"\"\"\n        buses = om.case.connected_buses\n        branches = om.case.online_branches\n        gens = om.case.online_generators\n\n        cp = om.get_cost_params()\n\n#        Bf = om._Bf\n#        Pfinj = om._Pfinj\n\n        return buses, branches, gens, cp", "label": 1}
{"code": "public static base_responses clear(nitro_service client, bridgetable resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tbridgetable clearresources[] = new bridgetable[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tclearresources[i] = new bridgetable();\n\t\t\t\tclearresources[i].vlan = resources[i].vlan;\n\t\t\t\tclearresources[i].ifnum = resources[i].ifnum;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, clearresources,\"clear\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def relationships\n      r = Relationships.new\n      r + [tables.relationships,\n           worksheet_comments.relationships,\n           hyperlinks.relationships,\n           worksheet_drawing.relationship,\n           pivot_tables.relationships].flatten.compact || []\n      r\n    end", "label": 4}
{"code": "function setSizes(){\n  \n    // Put the scatter plot on the left.\n    scatterPlot.box = {\n      x: 0,\n      y: 0,\n      width: div.clientWidth / 2,\n      height: div.clientHeight\n    };\n\n    // Put the bar chart on the right.\n    barChart.box = {\n      x: div.clientWidth / 2,\n      y: 0,\n      width: div.clientWidth / 2,\n      height: div.clientHeight\n    };\n  }", "label": 3}
{"code": "def load_metadata(**download_options)\n      tf = Tempfile.new(\"vagrant-load-metadata\")\n      tf.close\n\n      url = @metadata_url\n      if File.file?(url) || url !~ /^[a-z0-9]+:.*$/i\n        url = File.expand_path(url)\n        url = Util::Platform.cygwin_windows_path(url)\n        url = \"file:#{url}\"\n      end\n\n      opts = { headers: [\"Accept: application/json\"] }.merge(download_options)\n      Util::Downloader.new(url, tf.path, **opts).download!\n      BoxMetadata.new(File.open(tf.path, \"r\"))\n    rescue Errors::DownloaderError => e\n      raise Errors::BoxMetadataDownloadError,\n        message: e.extra_data[:message]\n    ensure\n      tf.unlink if tf\n    end", "label": 4}
{"code": "def _matrix_sigma_eta(self, donor_catchments):\n        \"\"\"\n        Return model error coveriance matrix Sigma eta\n\n        Methodology source: Kjelsen, Jones & Morris 2014, eqs 2 and 3\n\n        :param donor_catchments: Catchments to use as donors\n        :type donor_catchments: list of :class:`Catchment`\n        :return: 2-Dimensional, symmetric covariance matrix\n        :rtype: :class:`numpy.ndarray`\n        \"\"\"\n        p = len(donor_catchments)\n        sigma = 0.1175 * np.ones((p, p))\n        for i in range(p):\n            for j in range(p):\n                if i != j:\n                    sigma[i, j] *= self._model_error_corr(donor_catchments[i], donor_catchments[j])\n        return sigma", "label": 1}
{"code": "def _growth_curve_single_site(self, distr='glo'):\n        \"\"\"\n        Return flood growth curve function based on `amax_records` from the subject catchment only.\n\n        :return: Inverse cumulative distribution function with one parameter `aep` (annual exceedance probability)\n        :type: :class:`.GrowthCurve`\n        \"\"\"\n        if self.catchment.amax_records:\n            self.donor_catchments = []\n            return GrowthCurve(distr, *self._var_and_skew(self.catchment))\n        else:\n            raise InsufficientDataError(\"Catchment's `amax_records` must be set for a single site analysis.\")", "label": 1}
{"code": "function isFieldStillValidTarget(fieldOrPageIdToCheck, pages, cb) {\n      var fieldExistsInForm = false;\n      var invalidPages = _.filter(pages, function(page) {\n        var currentPageId = page._id.toString();\n\n        if (currentPageId === fieldOrPageIdToCheck) {\n          fieldExistsInForm = true;\n        }\n        var invalidFieldList = _.filter(page.fields, function(field) {\n          var currentFieldId = field._id.toString();\n          if (currentFieldId === fieldOrPageIdToCheck) {\n            //Current field exists\n            fieldExistsInForm = true;\n\n            //Field is admin only, therefore it is an invalid target for a rule.\n            if (field.adminOnly) {\n              return true;\n            } else {\n              return false;\n            }\n          } else {\n            return false;\n          }\n        });\n\n        //If the invalidFieldList is > 0, it means that one of the fields was invalid.\n        return invalidFieldList.length > 0;\n      });\n\n      var invalidField = invalidPages.length > 0;\n\n      //Invalid if either the field is invalid, or it does not exist in the form.\n      if (invalidField === true || !fieldExistsInForm) {\n        return cb(true);\n      } else {\n        return cb();\n      }\n    }", "label": 3}
{"code": "def _matrix_sigma_eps(self, donor_catchments):\n        \"\"\"\n        Return sampling error coveriance matrix Sigma eta\n\n        Methodology source: Kjeldsen & Jones 2009, eq 9\n\n        :param donor_catchments: Catchments to use as donors\n        :type donor_catchments: list of :class:`Catchment`\n        :return: 2-Dimensional, symmetric covariance matrix\n        :rtype: :class:`numpy.ndarray`\n        \"\"\"\n        p = len(donor_catchments)\n        sigma = np.empty((p, p))\n        for i in range(p):\n            beta_i = self._beta(donor_catchments[i])\n            n_i = donor_catchments[i].amax_records_end() - donor_catchments[i].amax_records_start() + 1\n            for j in range(p):\n                beta_j = self._beta(donor_catchments[j])\n                n_j = donor_catchments[j].amax_records_end() - donor_catchments[j].amax_records_start() + 1\n                rho_ij = self._lnqmed_corr(donor_catchments[i], donor_catchments[j])\n                n_ij = min(donor_catchments[i].amax_records_end(), donor_catchments[j].amax_records_end()) - \\\n                       max(donor_catchments[i].amax_records_start(), donor_catchments[j].amax_records_start()) + 1\n                sigma[i, j] = 4 * beta_i * beta_j * n_ij / n_i / n_j * rho_ij\n        return sigma", "label": 1}
{"code": "public function setVoice($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1\\PartOfSpeech_Voice::class);\n        $this->voice = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private Cluster expandCluster(final Cluster cluster,\n                                     final Point2D point,\n                                     final List<Point2D> neighbors,\n                                     final KDTree<Point2D> points,\n                                     final Map<Point2D, PointStatus> visited) {\n        cluster.addPoint(point);\n        visited.put(point, PointStatus.PART_OF_CLUSTER);\n\n        List<Point2D> seeds = new ArrayList<Point2D>(neighbors);\n        int index = 0;\n        while (index < seeds.size()) {\n            Point2D current = seeds.get(index);\n            PointStatus pStatus = visited.get(current);\n            // only check non-visited points\n            if (pStatus == null) {\n                final List<Point2D> currentNeighbors = getNeighbors(current, points);\n                if (currentNeighbors.size() >= minPoints) {\n                    seeds = merge(seeds, currentNeighbors);\n                }\n            }\n\n            if (pStatus != PointStatus.PART_OF_CLUSTER) {\n                visited.put(current, PointStatus.PART_OF_CLUSTER);\n                cluster.addPoint(current);\n            }\n\n            index++;\n        }\n        return cluster;\n    }", "label": 0}
{"code": "public static dbdbprofile[] get(nitro_service service) throws Exception{\n\t\tdbdbprofile obj = new dbdbprofile();\n\t\tdbdbprofile[] response = (dbdbprofile[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (v VirtualMachine) RemoveSnapshot(ctx context.Context, name string, removeChildren bool, consolidate *bool) (*Task, error) {\n\tsnapshot, err := v.FindSnapshot(ctx, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq := types.RemoveSnapshot_Task{\n\t\tThis:           snapshot.Reference(),\n\t\tRemoveChildren: removeChildren,\n\t\tConsolidate:    consolidate,\n\t}\n\n\tres, err := methods.RemoveSnapshot_Task(ctx, v.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewTask(v.c, res.Returnval), nil\n}", "label": 5}
{"code": "public function each(callable $handleResult)\n    {\n        return Promise\\coroutine(function () use ($handleResult) {\n            $nextToken = null;\n            do {\n                $command = $this->createNextCommand($this->args, $nextToken);\n                $result = (yield $this->client->executeAsync($command));\n                $nextToken = $this->determineNextToken($result);\n                $retVal = $handleResult($result);\n                if ($retVal !== null) {\n                    yield Promise\\promise_for($retVal);\n                }\n            } while ($nextToken);\n        });\n    }", "label": 2}
{"code": "func (tc *TeleportClient) GetTrustedCA(ctx context.Context, clusterName string) ([]services.CertAuthority, error) {\n\t// Connect to the proxy.\n\tif !tc.Config.ProxySpecified() {\n\t\treturn nil, trace.BadParameter(\"proxy server is not specified\")\n\t}\n\tproxyClient, err := tc.ConnectToProxy(ctx)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tdefer proxyClient.Close()\n\n\t// Get a client to the Auth Server.\n\tclt, err := proxyClient.ClusterAccessPoint(ctx, clusterName, true)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Get the list of host certificates that this cluster knows about.\n\treturn clt.GetCertAuthorities(services.HostCA, false)\n}", "label": 5}
{"code": "func PgShdependsByDbidClassidObjidObjsubid(db XODB, dbid pgtypes.Oid, classid pgtypes.Oid, objid pgtypes.Oid, objsubid int) ([]*PgShdepend, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, dbid, classid, objid, objsubid, refclassid, refobjid, deptype ` +\n\t\t`FROM pg_catalog.pg_shdepend ` +\n\t\t`WHERE dbid = $1 AND classid = $2 AND objid = $3 AND objsubid = $4`\n\n\t// run query\n\tXOLog(sqlstr, dbid, classid, objid, objsubid)\n\tq, err := db.Query(sqlstr, dbid, classid, objid, objsubid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*PgShdepend{}\n\tfor q.Next() {\n\t\tps := PgShdepend{}\n\n\t\t// scan\n\t\terr = q.Scan(&ps.Tableoid, &ps.Cmax, &ps.Xmax, &ps.Cmin, &ps.Xmin, &ps.Ctid, &ps.Dbid, &ps.Classid, &ps.Objid, &ps.Objsubid, &ps.Refclassid, &ps.Refobjid, &ps.Deptype)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ps)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def update!\n      @previously_changed = changes\n      # extract only new values to build payload\n      payload = Hash[changes.map { |key, values| [SYMBOL_TO_STRING[key.to_sym].to_sym, values[1]] }]\n      @changed_attributes.clear\n\n      client.put(\"/cards/#{id}\", payload)\n    end", "label": 4}
{"code": "public static nspbr get(nitro_service service, String name) throws Exception{\n\t\tnspbr obj = new nspbr();\n\t\tobj.set_name(name);\n\t\tnspbr response = (nspbr) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function load(schema) {\n  var obj;\n  if (typeof schema == 'string' && schema !== 'null') {\n    try {\n      obj = JSON.parse(schema);\n    } catch (err) {\n      // No file loading here.\n    }\n  }\n  if (obj === undefined) {\n    obj = schema;\n  }\n  return obj;\n}", "label": 3}
{"code": "def connect_to(name, options = { read: { mode: :primary }})\n      self.clients = {\n        default: {\n          database: name,\n          hosts: [ \"localhost:27017\" ],\n          options: options\n        }\n      }\n    end", "label": 4}
{"code": "func (u *UUID) decodePlain(t []byte) (err error) {\n\tswitch len(t) {\n\tcase 32:\n\t\treturn u.decodeHashLike(t)\n\tcase 36:\n\t\treturn u.decodeCanonical(t)\n\tdefault:\n\t\treturn fmt.Errorf(\"uuid: incorrrect UUID length: %s\", t)\n\t}\n}", "label": 5}
{"code": "def used_options(self):\n        \"\"\"Return options already used in the\n        command line\n\n        rtype: command.Option generator\n        \"\"\"\n        for option_str in filter(lambda c: c.startswith('-'), self.words):\n            for option in list(self.cmd.options.values()):\n                if option_str in option.option_strings:\n                    yield option", "label": 1}
{"code": "def authorized_default_handler(resp, remote, *args, **kwargs):\n    \"\"\"Store access token in session.\n\n    Default authorized handler.\n\n    :param remote: The remote application.\n    :param resp: The response.\n    :returns: Redirect response.\n    \"\"\"\n    response_token_setter(remote, resp)\n    db.session.commit()\n    return redirect(url_for('invenio_oauthclient_settings.index'))", "label": 1}
{"code": "def register_event(self, *names):\n        \"\"\"Registers new events after instance creation\n\n        Args:\n            *names (str): Name or names of the events to register\n        \"\"\"\n        for name in names:\n            if name in self.__events:\n                continue\n            self.__events[name] = Event(name)", "label": 1}
{"code": "def write(filename, data):\n    \"\"\"\n    Create a new BibTeX file.\n\n    :param filename: The name of the BibTeX file to write.\n    :param data: A ``bibtexparser.BibDatabase`` object.\n    \"\"\"\n    with open(filename, 'w') as fh:\n        fh.write(bibdatabase2bibtex(data))", "label": 1}
{"code": "function () {\n        const cronJobsToStart = _getNamesOfCronJobsToStart();\n        if (!cronJobsToStart && _shouldStartCrons() && Shared.isDbConnectionAvailable() === true) {\n            return CronJobManagerJob.startListening().then(function () {\n                Logger.tag('Cron').info('Cron Job Manager is started. Starting all available cron jobs');\n                return Q();\n            }, function (err) {\n                Logger.tag('Cron').error('Error starting Cron Job Manager ');\n                return Q.reject(err);\n            });\n        } else if (cronJobsToStart && _shouldStartCrons()) {\n\n            Logger.tag('Cron').info('Starting specific cron jobs \"' + cronJobsToStart.join(', ') + '\"');\n\n            try {\n                const cronJobs = Shared.cronModules(cronJobsToStart);\n                let promises = [];\n                for (let cron of cronJobs) {\n                    // Set force run config\n                    cron.forceRun = true;\n                    promises.push(cron.worker(cron, cron));\n                }\n                return Q.all(promises)\n                    .then(() => process.exit())\n                    .catch(() => process.exit(1));\n            } catch (err) {\n                process.exit(1);\n            }\n        } else {\n            Logger.tag('Cron').warn('Cron Manager is disabled for this environment.');\n            return Q();\n        }\n    }", "label": 3}
{"code": "def translated_field_tag(type, object_name, name, value = {}, options = {})\n      locales = available_locales\n\n      field_label = label_tag(name, options[:label])\n\n      if locales.count == 1\n        field_name = \"#{name}_#{locales.first.to_s.gsub(\"-\", \"__\")}\"\n        field_input = send(\n          type,\n          \"#{object_name}[#{field_name}]\",\n          value[locales.first.to_s]\n        )\n\n        return safe_join [field_label, field_input]\n      end\n\n      tabs_id = options[:tabs_id] || \"#{object_name}-#{name}-tabs\".underscore\n      enabled_tabs = options[:enable_tabs].nil? ? true : options[:enable_tabs]\n      tabs_panels_data = enabled_tabs ? { tabs: true } : {}\n\n      label_tabs = content_tag(:div, class: \"label--tabs\") do\n        tabs_panels = \"\".html_safe\n        if options[:label] != false\n          tabs_panels = content_tag(:ul, class: \"tabs tabs--lang\", id: tabs_id, data: tabs_panels_data) do\n            locales.each_with_index.inject(\"\".html_safe) do |string, (locale, index)|\n              string + content_tag(:li, class: tab_element_class_for(\"title\", index)) do\n                title = I18n.with_locale(locale) { I18n.t(\"name\", scope: \"locale\") }\n                element_class = nil\n                element_class = \"is-tab-error\" if form_field_has_error?(options[:object], name_with_locale(name, locale))\n                tab_content_id = \"#{tabs_id}-#{name}-panel-#{index}\"\n                content_tag(:a, title, href: \"##{tab_content_id}\", class: element_class)\n              end\n            end\n          end\n        end\n\n        safe_join [field_label, tabs_panels]\n      end\n\n      tabs_content = content_tag(:div, class: \"tabs-content\", data: { tabs_content: tabs_id }) do\n        locales.each_with_index.inject(\"\".html_safe) do |string, (locale, index)|\n          tab_content_id = \"#{tabs_id}-#{name}-panel-#{index}\"\n          string + content_tag(:div, class: tab_element_class_for(\"panel\", index), id: tab_content_id) do\n            send(type, \"#{object_name}[#{name_with_locale(name, locale)}]\", value[locale.to_s], options.merge(id: \"#{tabs_id}_#{name}_#{locale}\", label: false))\n          end\n        end\n      end\n\n      safe_join [label_tabs, tabs_content]\n    end", "label": 4}
{"code": "func (pm *PortMapper) Unmap(host net.Addr) error {\n\tpm.lock.Lock()\n\tdefer pm.lock.Unlock()\n\n\tkey := getKey(host)\n\tdata, exists := pm.currentMappings[key]\n\tif !exists {\n\t\treturn ErrPortNotMapped\n\t}\n\n\tif data.userlandProxy != nil {\n\t\tdata.userlandProxy.Stop()\n\t}\n\n\tdelete(pm.currentMappings, key)\n\n\tcontainerIP, containerPort := getIPAndPort(data.container)\n\thostIP, hostPort := getIPAndPort(data.host)\n\tif err := pm.DeleteForwardingTableEntry(data.proto, hostIP, hostPort, containerIP.String(), containerPort); err != nil {\n\t\tlogrus.Errorf(\"Error on iptables delete: %s\", err)\n\t}\n\n\tswitch a := host.(type) {\n\tcase *net.TCPAddr:\n\t\treturn pm.Allocator.ReleasePort(a.IP, \"tcp\", a.Port)\n\tcase *net.UDPAddr:\n\t\treturn pm.Allocator.ReleasePort(a.IP, \"udp\", a.Port)\n\tcase *sctp.SCTPAddr:\n\t\tif len(a.IP) == 0 {\n\t\t\treturn ErrSCTPAddrNoIP\n\t\t}\n\t\treturn pm.Allocator.ReleasePort(a.IP[0], \"sctp\", a.Port)\n\t}\n\treturn ErrUnknownBackendAddressType\n}", "label": 5}
{"code": "def quantiles(self, k=5):\n        \"\"\"Returns an ndarray of quantile breaks.\"\"\"\n        arr = self.array()\n        q = list(np.linspace(0, 100, k))\n        return np.percentile(arr.compressed(), q)", "label": 1}
{"code": "def start_transaction(options = nil)\n      if options\n        Lint.validate_read_concern_option(options[:read_concern])\n      end\n\n      check_if_ended!\n\n      if within_states?(STARTING_TRANSACTION_STATE, TRANSACTION_IN_PROGRESS_STATE)\n        raise Mongo::Error::InvalidTransactionOperation.new(\n          Mongo::Error::InvalidTransactionOperation::TRANSACTION_ALREADY_IN_PROGRESS)\n      end\n\n      next_txn_num\n      @txn_options = options || @options[:default_transaction_options] || {}\n\n      if txn_write_concern && WriteConcern.send(:unacknowledged?, txn_write_concern)\n        raise Mongo::Error::InvalidTransactionOperation.new(\n          Mongo::Error::InvalidTransactionOperation::UNACKNOWLEDGED_WRITE_CONCERN)\n      end\n\n      @state = STARTING_TRANSACTION_STATE\n      @already_committed = false\n    end", "label": 4}
{"code": "def _prune(self, fit, p_max):\n        \"\"\"\n        If the fit contains statistically insignificant parameters, remove them.\n        Returns a pruned fit where all parameters have p-values of the t-statistic below p_max\n\n        Parameters\n        ----------\n        fit: fm.ols fit object\n            Can contain insignificant parameters\n        p_max : float\n            Maximum allowed probability of the t-statistic\n\n        Returns\n        -------\n        fit: fm.ols fit object\n            Won't contain any insignificant parameters\n\n        \"\"\"\n\n        def remove_from_model_desc(x, model_desc):\n            \"\"\"\n            Return a model_desc without x\n            \"\"\"\n\n            rhs_termlist = []\n            for t in model_desc.rhs_termlist:\n                if not t.factors:\n                    # intercept, add anyway\n                    rhs_termlist.append(t)\n                elif not x == t.factors[0]._varname:\n                    # this is not the term with x\n                    rhs_termlist.append(t)\n\n            md = ModelDesc(model_desc.lhs_termlist, rhs_termlist)\n            return md\n\n        corrected_model_desc = ModelDesc(fit.model.formula.lhs_termlist[:], fit.model.formula.rhs_termlist[:])\n        pars_to_prune = fit.pvalues.where(fit.pvalues > p_max).dropna().index.tolist()\n        try:\n            pars_to_prune.remove('Intercept')\n        except:\n            pass\n        while pars_to_prune:\n            corrected_model_desc = remove_from_model_desc(pars_to_prune[0], corrected_model_desc)\n            fit = fm.ols(corrected_model_desc, data=self.df).fit()\n            pars_to_prune = fit.pvalues.where(fit.pvalues > p_max).dropna().index.tolist()\n            try:\n                pars_to_prune.remove('Intercept')\n            except:\n                pass\n        return fit", "label": 1}
{"code": "function(digit) {\n\t\t\tvar obj = this.createList(digit, {\n\t\t\t\tclasses: {\n\t\t\t\t\tactive: this.factory.classes.active,\n\t\t\t\t\tbefore: this.factory.classes.before,\n\t\t\t\t\tflip: this.factory.classes.flip\n\t\t\t\t}\n\t\t\t});\n\t\t\t\n\t\t\tobj.$obj.insertBefore(this.factory.lists[0].$obj);\n\t\t\t\t\t\t\t\n\t\t\tthis.factory.lists.unshift(obj);\n\t\t}", "label": 3}
{"code": "function (port, parent_port) {\n\n\t// check if the port wasn't reported\n\tif (l_ports.hasOwnProperty(port) === false) {\n\t\t\n\t\tLOG.warn('recording used port [' + port + ']...', 'SR.Monitor');\t\n\t\tl_ports[port] = parent_port || port;\n\t}\n}", "label": 3}
{"code": "function getExtensionWithKnownPrefixes(gl, name) {\n    for (var ii = 0; ii < browserPrefixes.length; ++ii) {\n      var prefixedName = browserPrefixes[ii] + name;\n      var ext = gl.getExtension(prefixedName);\n      if (ext) {\n        return ext;\n      }\n    }\n    return undefined;\n  }", "label": 3}
{"code": "func NewAgent(cfg AgentConfig) (*Agent, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tctx, cancel := context.WithCancel(cfg.Context)\n\ta := &Agent{\n\t\tAgentConfig: cfg,\n\t\tctx:         ctx,\n\t\tcancel:      cancel,\n\t\tauthMethods: []ssh.AuthMethod{ssh.PublicKeys(cfg.Signers...)},\n\t}\n\tif len(cfg.DiscoverProxies) == 0 {\n\t\ta.state = agentStateConnecting\n\t} else {\n\t\ta.state = agentStateDiscovering\n\t}\n\ta.Entry = log.WithFields(log.Fields{\n\t\ttrace.Component: teleport.ComponentReverseTunnelAgent,\n\t\ttrace.ComponentFields: log.Fields{\n\t\t\t\"target\": cfg.Addr.String(),\n\t\t},\n\t})\n\ta.hostKeyCallback = a.checkHostSignature\n\treturn a, nil\n}", "label": 5}
{"code": "func (h *Handle) SetAny(serial bool) (uint64, error) {\n\tif h.Unselected() == 0 {\n\t\treturn invalidPos, ErrNoBitAvailable\n\t}\n\treturn h.set(0, 0, h.bits-1, true, false, serial)\n}", "label": 5}
{"code": "func (m *Memory) Close() error {\n\tm.cancel()\n\tm.Lock()\n\tdefer m.Unlock()\n\tm.buf.Close()\n\treturn nil\n}", "label": 5}
{"code": "function getBaseDirectoriesFromRootDirs(rootDirs, basePath, scriptPath, ignoreCase) {\n                // Make all paths absolute/normalized if they are not already\n                rootDirs = ts.map(rootDirs, function (rootDirectory) { return ts.normalizePath(ts.isRootedDiskPath(rootDirectory) ? rootDirectory : ts.combinePaths(basePath, rootDirectory)); });\n                // Determine the path to the directory containing the script relative to the root directory it is contained within\n                var relativeDirectory;\n                for (var _i = 0, rootDirs_1 = rootDirs; _i < rootDirs_1.length; _i++) {\n                    var rootDirectory = rootDirs_1[_i];\n                    if (ts.containsPath(rootDirectory, scriptPath, basePath, ignoreCase)) {\n                        relativeDirectory = scriptPath.substr(rootDirectory.length);\n                        break;\n                    }\n                }\n                // Now find a path for each potential directory that is to be merged with the one containing the script\n                return ts.deduplicate(ts.map(rootDirs, function (rootDirectory) { return ts.combinePaths(rootDirectory, relativeDirectory); }));\n            }", "label": 3}
{"code": "def create(klass, author, params, extra_log_info = {})\n      perform_action!(:create, klass, author, extra_log_info) do\n        klass.create(params)\n      end\n    end", "label": 4}
{"code": "def to_grpc_params\n      {\n        pool_size: rpc_pool_size,\n        max_waiting_requests: rpc_max_waiting_requests,\n        poll_period: rpc_poll_period,\n        pool_keep_alive: rpc_pool_keep_alive,\n        server_args: rpc_server_args\n      }\n    end", "label": 4}
{"code": "function getModuleName(nameWithConditional, variation) {\n\t\t\tvar modName;\n\t\t\tvar conditionIndex = nameWithConditional.search(conditionalRegEx);\n\n\t\t\t// look for any \"/\" after the condition\n\t\t\tvar lastSlashIndex = nameWithConditional.indexOf(\"/\",\n\t\t\t\tnameWithConditional.indexOf(\"}\"));\n\n\t\t\t// substitution of a folder name\n\t\t\tif (lastSlashIndex !== -1) {\n\t\t\t\tmodName = nameWithConditional.substr(0, conditionIndex) + variation;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tmodName = nameWithConditional.replace(conditionalRegEx, variation);\n\t\t\t}\n\n\t\t\treturn modName;\n\t\t}", "label": 3}
{"code": "func GetInt(data []byte, keys ...string) (val int64, err error) {\n\tv, t, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn 0, e\n\t}\n\n\tif t != Number {\n\t\treturn 0, fmt.Errorf(\"Value is not a number: %s\", string(v))\n\t}\n\n\treturn ParseInt(v)\n}", "label": 5}
{"code": "function fromQuat (v, q) {\n  var sqx = q[0] * q[0]\n  var sqy = q[1] * q[1]\n  var sqz = q[2] * q[2]\n  var sqw = q[3] * q[3]\n  v[0] = Math.atan2(2 * (q[0] * q[3] - q[1] * q[2]), (sqw - sqx - sqy + sqz))\n  v[1] = Math.asin(clamp(2 * (q[0] * q[2] + q[1] * q[3]), -1, 1))\n  v[2] = Math.atan2(2 * (q[2] * q[3] - q[0] * q[1]), (sqw + sqx - sqy - sqz))\n  return v\n}", "label": 3}
{"code": "def txn_read_preference\n      rp = txn_options && txn_options[:read_preference] ||\n        @client.read_preference\n      Mongo::Lint.validate_underscore_read_preference(rp)\n      rp\n    end", "label": 4}
{"code": "private String filterTag(String tag) {\r\n\t  AttributeValues answerAV = TagSet.getTagSet().fromTag(tag);\r\n\t  answerAV.removeNonlexicalAttributes();\r\n\t  return TagSet.getTagSet().toTag(answerAV);\r\n  }", "label": 0}
{"code": "public static base_response update(nitro_service client, nspbr resource) throws Exception {\n\t\tnspbr updateresource = new nspbr();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.action = resource.action;\n\t\tupdateresource.srcip = resource.srcip;\n\t\tupdateresource.srcipop = resource.srcipop;\n\t\tupdateresource.srcipval = resource.srcipval;\n\t\tupdateresource.srcport = resource.srcport;\n\t\tupdateresource.srcportop = resource.srcportop;\n\t\tupdateresource.srcportval = resource.srcportval;\n\t\tupdateresource.destip = resource.destip;\n\t\tupdateresource.destipop = resource.destipop;\n\t\tupdateresource.destipval = resource.destipval;\n\t\tupdateresource.destport = resource.destport;\n\t\tupdateresource.destportop = resource.destportop;\n\t\tupdateresource.destportval = resource.destportval;\n\t\tupdateresource.nexthop = resource.nexthop;\n\t\tupdateresource.nexthopval = resource.nexthopval;\n\t\tupdateresource.iptunnel = resource.iptunnel;\n\t\tupdateresource.iptunnelname = resource.iptunnelname;\n\t\tupdateresource.srcmac = resource.srcmac;\n\t\tupdateresource.protocol = resource.protocol;\n\t\tupdateresource.protocolnumber = resource.protocolnumber;\n\t\tupdateresource.vlan = resource.vlan;\n\t\tupdateresource.Interface = resource.Interface;\n\t\tupdateresource.priority = resource.priority;\n\t\tupdateresource.msr = resource.msr;\n\t\tupdateresource.monitor = resource.monitor;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "private function updateComponentVersionConstant($version, $componentPath, $componentEntry)\n    {\n        if (is_null($componentEntry)) {\n            return false;\n        }\n\n        $path = $this->rootPath() .'/'. $componentPath .'/'. $componentEntry;\n        if (!file_exists($path)) {\n            throw new \\RuntimeException(sprintf(\n                'Component entry file %s does not exist',\n                $path\n            ));\n        }\n\n        $entry = file_get_contents($path);\n\n        $replacement = sprintf(\"const VERSION = '%s';\", $version);\n\n        $entry = preg_replace(\"/const VERSION = [\\'\\\\\\\"]([0-9.]{0,}|master)[\\'\\\\\\\"]\\;/\", $replacement, $entry);\n\n        $result = file_put_contents($path, $entry);\n\n        if (!$result) {\n            throw new \\RuntimeException('File write failed');\n        }\n\n        return true;\n    }", "label": 2}
{"code": "@Inject(\"struts.json.action.fileProtocols\")\n\tpublic void setFileProtocols(String fileProtocols) {\n\t\tif (StringUtils.isNotBlank(fileProtocols)) {\n\t\t\tthis.fileProtocols = TextParseUtil.commaDelimitedStringToSet(fileProtocols);\n\t\t}\n\t}", "label": 0}
{"code": "func (args Arguments) Get(index int) interface{} {\n\tif index+1 > len(args) {\n\t\tpanic(fmt.Sprintf(\"assert: arguments: Cannot call Get(%d) because there are %d argument(s).\", index, len(args)))\n\t}\n\treturn args[index]\n}", "label": 5}
{"code": "def create_category(location_id, body, opts = {})\n      data, _status_code, _headers = create_category_with_http_info(location_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "function FixedType(attrs, opts) {\n  Type.call(this, attrs, opts);\n\n  if (attrs.size !== (attrs.size | 0) || attrs.size < 1) {\n    throw new Error(f('invalid %s fixed size', this.getName(true)));\n  }\n  this._size = attrs.size | 0;\n}", "label": 3}
{"code": "func (m *AgentPool) reportStats() {\n\tvar logReport bool\n\tif m.cfg.Clock.Now().Sub(m.lastReport) > defaults.ReportingPeriod {\n\t\tm.lastReport = m.cfg.Clock.Now()\n\t\tlogReport = true\n\t}\n\n\tfor key, agents := range m.agents {\n\t\tm.Debugf(\"Outbound tunnel for %v connected to %v proxies.\", key.tunnelID, len(agents))\n\n\t\tcountPerState := map[string]int{\n\t\t\tagentStateConnecting:   0,\n\t\t\tagentStateDiscovering:  0,\n\t\t\tagentStateConnected:    0,\n\t\t\tagentStateDiscovered:   0,\n\t\t\tagentStateDisconnected: 0,\n\t\t}\n\t\tfor _, a := range agents {\n\t\t\tcountPerState[a.getState()]++\n\t\t}\n\t\tfor state, count := range countPerState {\n\t\t\tgauge, err := trustedClustersStats.GetMetricWithLabelValues(key.tunnelID, state)\n\t\t\tif err != nil {\n\t\t\t\tm.Warningf(\"Failed to get gauge: %v.\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tgauge.Set(float64(count))\n\t\t}\n\t\tif logReport {\n\t\t\tm.WithFields(log.Fields{\"target\": key.tunnelID, \"stats\": countPerState}).Info(\"Outbound tunnel stats.\")\n\t\t}\n\t}\n}", "label": 5}
{"code": "public function setJobs($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dataproc\\V1\\OrderedJob::class);\n        $this->jobs = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private function mapBindings($bindingType, array $bindings)\n    {\n        $res = [];\n        foreach ($bindings as $key => $binding) {\n            if ($binding instanceof Cursor) {\n                $value = [\n                    'cursor' => $binding->cursor()\n                ];\n            } else {\n                $value = [\n                    'value' => $this->entityMapper->valueObject($binding)\n                ];\n            }\n\n            if ($bindingType === self::BINDING_NAMED) {\n                $res[$key] = $value;\n            } else {\n                $res[] = $value;\n            }\n        }\n\n        return $res;\n    }", "label": 2}
{"code": "protected String getIsolationLevelAsString()\r\n    {\r\n        if (defaultIsolationLevel == IL_READ_UNCOMMITTED)\r\n        {\r\n            return LITERAL_IL_READ_UNCOMMITTED;\r\n        }\r\n        else if (defaultIsolationLevel == IL_READ_COMMITTED)\r\n        {\r\n            return LITERAL_IL_READ_COMMITTED;\r\n        }\r\n        else if (defaultIsolationLevel == IL_REPEATABLE_READ)\r\n        {\r\n            return LITERAL_IL_REPEATABLE_READ;\r\n        }\r\n        else if (defaultIsolationLevel == IL_SERIALIZABLE)\r\n        {\r\n            return LITERAL_IL_SERIALIZABLE;\r\n        }\r\n        else if (defaultIsolationLevel == IL_OPTIMISTIC)\r\n        {\r\n            return LITERAL_IL_OPTIMISTIC;\r\n        }\r\n        return LITERAL_IL_READ_UNCOMMITTED;\r\n    }", "label": 0}
{"code": "def minimal_rollback_complete?\n      stack = find_stack(stack_name)\n      return false unless stack\n\n      return false unless stack.stack_status == 'ROLLBACK_COMPLETE'\n\n      # Finally check if all the minimal resources in the parent template have been deleted\n      resp = cfn.describe_stack_resources(stack_name: stack_name)\n      resource_statuses = resp.stack_resources.map(&:resource_status).uniq\n      resource_statuses == ['DELETE_COMPLETE']\n    end", "label": 4}
{"code": "public function setVertices($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\NormalizedVertex::class);\n        $this->vertices = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "protected void refresh()\r\n    {\r\n        if (log.isDebugEnabled())\r\n                log.debug(\"Refresh this transaction for reuse: \" + this);\r\n        try\r\n        {\r\n            // we reuse ObjectEnvelopeTable instance\r\n            objectEnvelopeTable.refresh();\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            if (log.isDebugEnabled())\r\n            {\r\n                log.debug(\"error closing object envelope table : \" + e.getMessage());\r\n                e.printStackTrace();\r\n            }\r\n        }\r\n        cleanupBroker();\r\n        // clear the temporary used named roots map\r\n        // we should do that, because same tx instance\r\n        // could be used several times\r\n        broker = null;\r\n        clearRegistrationList();\r\n        unmaterializedLocks.clear();\r\n        txStatus = Status.STATUS_NO_TRANSACTION;\r\n    }", "label": 0}
{"code": "public Object remove(String name) {\n\t\tBean bean = beans.get(name);\n\t\tif (null != bean) {\n\t\t\tbeans.remove(name);\n\t\t\tbean.destructionCallback.run();\n\t\t\treturn bean.object;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def ensure_list(value: Union[T, Sequence[T]]) -> Sequence[T]:\n    \"\"\"Wrap value in list if it is not one.\"\"\"\n    if value is None:\n        return []\n    return value if isinstance(value, list) else [value]", "label": 1}
{"code": "func OptionDriverConfig(networkType string, config map[string]interface{}) Option {\n\treturn func(c *Config) {\n\t\tc.Daemon.DriverCfg[networkType] = config\n\t}\n}", "label": 5}
{"code": "def get_cas(key)\n      (value, cas) = perform(:cas, key)\n      value = (!value || value == 'Not found') ? nil : value\n      if block_given?\n        yield value, cas\n      else\n        [value, cas]\n      end\n    end", "label": 4}
{"code": "public function reload(array $options = [])\n    {\n        $this->info = $this->connection->getInstanceConfig($options + [\n            'name' => $this->name,\n            'projectId' => $this->projectId\n        ]);\n\n        return $this->info;\n    }", "label": 2}
{"code": "public function setNetworkPolicyConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\NetworkPolicyConfig::class);\n        $this->network_policy_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def fmsin(N, fnormin=0.05, fnormax=0.45, period=None, t0=None, fnorm0=0.25, pm1=1):\n    \"\"\"\n    Signal with sinusoidal frequency modulation.\n\n    generates a frequency modulation with a sinusoidal frequency.\n    This sinusoidal modulation is designed such that the instantaneous\n    frequency at time T0 is equal to FNORM0, and the ambiguity between\n    increasing or decreasing frequency is solved by PM1.\n\n    N       : number of points.\n    FNORMIN : smallest normalized frequency          (default: 0.05)\n    FNORMAX : highest normalized frequency           (default: 0.45)\n    PERIOD  : period of the sinusoidal fm            (default: N   )\n    T0      : time reference for the phase           (default: N/2 )\n    FNORM0  : normalized frequency at time T0        (default: 0.25)\n    PM1     : frequency direction at T0 (-1 or +1)       (default: +1  )\n\n    Returns:\n    Y       : signal\n    IFLAW   : its instantaneous frequency law\n\n    Example:\n    z,i=fmsin(140,0.05,0.45,100,20,0.3,-1.0)\n\n    Original MATLAB code F. Auger, July 1995.\n    (note: Licensed under GPL; see main LICENSE file)\n    \"\"\"\n\n    if period==None:\n\tperiod = N\n    if t0==None:\n\tt0 = N/2\n    pm1 = nx.sign(pm1)\n\n    fnormid=0.5*(fnormax+fnormin);\n    delta  =0.5*(fnormax-fnormin);\n    phi    =-pm1*nx.arccos((fnorm0-fnormid)/delta);\n    time   =nx.arange(1,N)-t0;\n    phase  =2*nx.pi*fnormid*time+delta*period*(nx.sin(2*nx.pi*time/period+phi)-nx.sin(phi));\n    y      =nx.exp(1j*phase)\n    iflaw  =fnormid+delta*nx.cos(2*nx.pi*time/period+phi);\n\n    return y,iflaw", "label": 1}
{"code": "public function setTrackingIssues($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\ErrorReporting\\V1beta1\\TrackingIssue::class);\n        $this->tracking_issues = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public void forAllForeignkeyColumnPairs(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (int idx = 0; idx < _curForeignkeyDef.getNumColumnPairs(); idx++)\r\n        {\r\n            _curPairLeft  = _curForeignkeyDef.getLocalColumn(idx);\r\n            _curPairRight = _curForeignkeyDef.getRemoteColumn(idx);\r\n            generate(template);\r\n        }\r\n        _curPairLeft  = null;\r\n        _curPairRight = null;\r\n    }", "label": 0}
{"code": "public static base_response Force(nitro_service client, clustersync resource) throws Exception {\n\t\tclustersync Forceresource = new clustersync();\n\t\treturn Forceresource.perform_operation(client,\"Force\");\n\t}", "label": 0}
{"code": "function (err_toArray, array) {\n\n\t\t\tif (err_toArray) {\n\t\t\t\treturn l_notifyError(clt_name, 'getPage.toArray', err_toArray, cb);\n\t\t\t}\n\n\t\t\t//LOG.sys('array found succces, length: ' + array.length, 'SR.DB');\n\t\t\t// NOTE: probably no need to check\n\t\t\tif (array.length === _opts.limit) {\n\t\t\t\tUTIL.safeCall(cb, null, array, array[array.length - 1]);\n\t\t\t} else {\n\t\t\t\tUTIL.safeCall(cb, null, array, null);\n\t\t\t}\n\t\t}", "label": 3}
{"code": "private function transformSnapshotTimestamps(array $data)\n    {\n        foreach (['createTime', 'updateTime', 'readTime'] as $timestampField) {\n            if (!isset($data[$timestampField])) {\n                continue;\n            }\n\n            list ($dt, $nanos) = $this->parseTimeString($data[$timestampField]);\n\n            $data[$timestampField] = new Timestamp($dt, $nanos);\n        }\n\n        return $data;\n    }", "label": 2}
{"code": "public static String createFolderPath(String path) {\n\n        String[] pathParts = path.split(\"\\\\.\");\n        String path2 = \"\";\n        for (String part : pathParts) {\n            if (path2.equals(\"\")) {\n                path2 = part;\n            } else {\n                path2 = path2 + File.separator\n                        + changeFirstLetterToLowerCase(createClassName(part));\n            }\n        }\n\n        return path2;\n    }", "label": 0}
{"code": "func ConfigGlobalScopeDefaultNetworks(defaultAddressPool []*NetworkToSplit) error {\n\tif defaultAddressPool == nil {\n\t\tdefaultAddressPool = globalScopeDefaultNetworks\n\t}\n\treturn configDefaultNetworks(defaultAddressPool, &PredefinedGlobalScopeDefaultNetworks)\n}", "label": 5}
{"code": "def check_configuration(self, file_path, test_program, custom_args):\n        \"\"\"Checks if configuration is ok.\"\"\"\n        # checking filepath\n        if not os.path.isdir(file_path):\n            raise InvalidFilePath(\"INVALID CONFIGURATION: file path %s is not a directory\" %\n                os.path.abspath(file_path)\n            )\n\n        if not test_program in IMPLEMENTED_TEST_PROGRAMS:\n            raise InvalidTestProgram('The `%s` is unknown, or not yet implemented. Please chose another one.' % test_program)\n\n        if custom_args:\n            if not self.quiet and not ask(\"WARNING!!!\\nYou are about to run the following command\\n\\n   $ %s\\n\\nAre you sure you still want to proceed [y/N]? \" % self.get_cmd()):\n                raise CancelDueToUserRequest('Test cancelled...')", "label": 1}
{"code": "function applyInitiatedOnceArgs(mixins, rtn) {\n\n        /**\n         * added once initiated mixins to return array\n         */\n        function addInitiatedOnce(name, mixin, params) {\n            mixin = mixin.call(this, params || []);\n            // find the name placeholder in the return arr and replace it with the mixin\n            var index = rtn.indexOf(name);\n            rtn.splice(index, 1, mixin);\n        }\n\n        for (var m in mixins) {\n            if (mixins.hasOwnProperty(m)) {\n                addInitiatedOnce(m, _mixins[m], mixins[m]);\n            }\n        }\n    }", "label": 3}
{"code": "public static base_responses restore(nitro_service client, systembackup resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsystembackup restoreresources[] = new systembackup[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\trestoreresources[i] = new systembackup();\n\t\t\t\trestoreresources[i].filename = resources[i].filename;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, restoreresources,\"restore\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def link_file(f, fldr):\n    \"\"\" \n    creates a html link for a file using folder fldr \n    \"\"\"\n    fname = os.path.join(fldr,f)\n    if os.path.isfile(fname):\n        return '<a href=\"/aikif/data/core/' + f + '\">' + f + '</a>'\n    else:\n        return f", "label": 1}
{"code": "public function resolve(Closure $originalResolver, string $path)\n    {\n        $isDeferred = $this->isDeferred($path);\n        $resolver = $isDeferred\n            ? $this->deferred[$path]\n            : $originalResolver;\n\n        if ($isDeferred) {\n            $this->resolved[] = $path;\n\n            unset($this->deferred[$path]);\n        }\n\n        return $resolver();\n    }", "label": 2}
{"code": "function(eventType, callback, context) {\n      if (isFunction(callback)) {\n        context = context || this;\n        if (!this._events[eventType]) this._events[eventType] = [];\n\n        // normal callback not called.\n        var self = this;\n        this._events[eventType].push([callback, context, function() {\n          self.off(eventType, callback, context);\n          callback.apply(this, arguments);\n        }]);\n      }\n      return this;\n    }", "label": 3}
{"code": "func (s *AuthServer) ExtendWebSession(user string, prevSessionID string) (services.WebSession, error) {\n\tprevSession, err := s.GetWebSession(user, prevSessionID)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// consider absolute expiry time that may be set for this session\n\t// by some external identity serivce, so we can not renew this session\n\t// any more without extra logic for renewal with external OIDC provider\n\texpiresAt := prevSession.GetExpiryTime()\n\tif !expiresAt.IsZero() && expiresAt.Before(s.clock.Now().UTC()) {\n\t\treturn nil, trace.NotFound(\"web session has expired\")\n\t}\n\n\tsess, err := s.NewWebSession(user)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tsess.SetExpiryTime(expiresAt)\n\tbearerTokenTTL := utils.MinTTL(utils.ToTTL(s.clock, expiresAt), BearerTokenTTL)\n\tsess.SetBearerTokenExpiryTime(s.clock.Now().UTC().Add(bearerTokenTTL))\n\tif err := s.UpsertWebSession(user, sess); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tsess, err = services.GetWebSessionMarshaler().ExtendWebSession(sess)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn sess, nil\n}", "label": 5}
{"code": "public function setAddresses($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\Address::class);\n        $this->addresses = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function()\n  {\n    var values = AP.slice.apply( arguments );\n    var indices = [];\n\n    for (var i = 0; i < values.length; i++)\n    {\n      var model = this.parseModel( values[ i ] );\n      var key = model.$key();\n\n      this.map.put( key, model );\n      indices.push( this.map.indices[ key ] );\n    }\n\n    this.trigger( Collection.Events.Adds, [this, values, indices] );\n    this.sort();\n\n    return this.length;\n  }", "label": 3}
{"code": "public static vpnglobal_vpnnexthopserver_binding[] get(nitro_service service) throws Exception{\n\t\tvpnglobal_vpnnexthopserver_binding obj = new vpnglobal_vpnnexthopserver_binding();\n\t\tvpnglobal_vpnnexthopserver_binding response[] = (vpnglobal_vpnnexthopserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static base_response unset(nitro_service client, systemuser resource, String[] args) throws Exception{\n\t\tsystemuser unsetresource = new systemuser();\n\t\tunsetresource.username = resource.username;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "func (fs *FileAddrStorage) SetAddresses(addrs []NetAddr) error {\n\tbytes, err := json.Marshal(addrs)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\terr = ioutil.WriteFile(fs.filePath, bytes, 0666)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function parseAttributePath(attrPath, context) {\n    const parsed = attrPath.split('.');\n    parsed.forEach(item => checkIdentifier(item, context));\n    return parsed;\n}", "label": 3}
{"code": "func FastMarshal(v interface{}) ([]byte, error) {\n\tdata, err := jsoniter.ConfigFastest.Marshal(v)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn data, nil\n}", "label": 5}
{"code": "func (app *Application) SetScreen(scr tcell.Screen) {\n\tif app.screen == nil {\n\t\tapp.screen = scr\n\t\tapp.err = nil\n\t}\n}", "label": 5}
{"code": "def text_field(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'text_field_for', &block)\n      define_method(name) do\n        return platform.text_field_value_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").value\n      end\n      define_method(\"#{name}=\") do |value|\n        return platform.text_field_value_set(identifier.clone, value) unless block_given?\n        self.send(\"#{name}_element\").value = value\n      end\n    end", "label": 4}
{"code": "function compareVersions(fstVer, sndVer) {\n    if (semver.lt(fstVer, sndVer)) {\n        return 1;\n    }\n    if (semver.gt(fstVer, sndVer)) {\n        return -1;\n    }\n    return 0;\n}", "label": 3}
{"code": "public double[] calculateDrift(ArrayList<T> tracks){\n\t\tdouble[] result = new double[3];\n\t\t\n\t\tdouble sumX =0;\n\t\tdouble sumY = 0;\n\t\tdouble sumZ = 0;\n\t\tint N=0;\n\t\tfor(int i = 0; i < tracks.size(); i++){\n\t\t\tT t = tracks.get(i);\n\t\t\tTrajectoryValidIndexTimelagIterator it = new TrajectoryValidIndexTimelagIterator(t,1);\n\t\n\t\t\t//for(int j = 1; j < t.size(); j++){\n\t\t\twhile(it.hasNext()) {\n\t\t\t\tint j = it.next();\n\t\t\t\tsumX += t.get(j+1).x - t.get(j).x;\n\t\t\t\tsumY += t.get(j+1).y - t.get(j).y;\n\t\t\t\tsumZ += t.get(j+1).z - t.get(j).z;\n\t\t\t\tN++;\n\t\t\t}\n\t\t}\n\t\tresult[0] = sumX/N;\n\t\tresult[1] = sumY/N;\n\t\tresult[2] = sumZ/N;\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (fs *FSLocalKeyStore) AddKnownHostKeys(hostname string, hostKeys []ssh.PublicKey) error {\n\tfp, err := os.OpenFile(filepath.Join(fs.KeyDir, fileNameKnownHosts), os.O_CREATE|os.O_RDWR, 0640)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdefer fp.Sync()\n\tdefer fp.Close()\n\t// read all existing entries into a map (this removes any pre-existing dupes)\n\tentries := make(map[string]int)\n\toutput := make([]string, 0)\n\tscanner := bufio.NewScanner(fp)\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tif _, exists := entries[line]; !exists {\n\t\t\toutput = append(output, line)\n\t\t\tentries[line] = 1\n\t\t}\n\t}\n\t// add every host key to the list of entries\n\tfor i := range hostKeys {\n\t\tfs.log.Debugf(\"Adding known host %s with key: %v\", hostname, sshutils.Fingerprint(hostKeys[i]))\n\t\tbytes := ssh.MarshalAuthorizedKey(hostKeys[i])\n\t\tline := strings.TrimSpace(fmt.Sprintf(\"%s %s\", hostname, bytes))\n\t\tif _, exists := entries[line]; !exists {\n\t\t\toutput = append(output, line)\n\t\t}\n\t}\n\t// re-create the file:\n\t_, err = fp.Seek(0, 0)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err = fp.Truncate(0); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tfor _, line := range output {\n\t\tfmt.Fprintf(fp, \"%s\\n\", line)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def befriend(self, other_agent, force=False):\n        '''\n        Try to become friends with another agent. The chances of\n        success depend on both agents' openness.\n        '''\n        if force or self['openness'] > random():\n            self.env.add_edge(self, other_agent)\n            self.info('Made some friend {}'.format(other_agent))\n            return True\n        return False", "label": 1}
{"code": "public function getIsoDescription()\n    {\n        $region = $this->getRegionName();\n        $variant = $this->getVariantName();\n\n        return $this->getIsoName().($region ? ' ('.$region.')' : '').($variant ? ' ('.$variant.')' : '');\n    }", "label": 2}
{"code": "public static base_response unset(nitro_service client, nsxmlnamespace resource, String[] args) throws Exception{\n\t\tnsxmlnamespace unsetresource = new nsxmlnamespace();\n\t\tunsetresource.prefix = resource.prefix;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function(adjustment, precision, captions, callback) {\n        //precision should be one of: seconds, milliseconds, microseconds\n        var precisionMultipliers = {\n                \"seconds\": 1000000, //seconds to microseconds\n                \"milliseconds\": 1000, //milliseconds to microseconds\n                \"microseconds\": 1 //microseconds to microseconds\n            },\n            newStartTime,\n            newEndTime,\n            adjuster = adjustment * precisionMultipliers[precision];\n        if (precisionMultipliers[precision] && captions[0].startTimeMicro !== undefined) {\n            //quick check to see if it will zero out the 2nd or 3rd caption\n            // there are cases where the first caption can be 00:00:00:000 and have no text.\n            if ((captions[1].startTimeMicro + adjuster) <= 0 || (captions[2].startTimeMicro + adjuster) <= 0) {\n                return callback(\"ERROR_ADJUSTMENT_ZEROS_CAPTIONS\");\n            }\n            captions.forEach(function(caption) {\n                //calculate new start times...\n                newStartTime = caption.startTimeMicro + adjuster;\n                newEndTime = caption.endTimeMicro + adjuster;\n                if (adjuster > 0) {\n                    caption.startTimeMicro = newStartTime;\n                    caption.endTimeMicro = newEndTime;\n                } else if (newStartTime >= 0 && newEndTime >= 0) {\n                    caption.startTimeMicro = newStartTime;\n                    caption.endTimeMicro = newEndTime;\n                }\n            });\n            callback(undefined, captions);\n        } else {\n            callback('NO_CAPTIONS_OR_PRECISION_PASSED_TO_FUNCTION');\n        }\n    }", "label": 3}
{"code": "def get_hashes(path, exclude=None):\n    '''\n    Get a dictionary of file paths and timestamps.\n\n    Paths matching `exclude` regex will be excluded.\n    '''\n    out = {}\n    for f in Path(path).rglob('*'):\n        if f.is_dir():\n            # We want to watch files, not directories.\n            continue\n        if exclude and re.match(exclude, f.as_posix()):\n            retox_log.debug(\"excluding '{}'\".format(f.as_posix()))\n            continue\n        pytime = f.stat().st_mtime\n        out[f.as_posix()] = pytime\n    return out", "label": 1}
{"code": "public function setResponseType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\WebRisk\\V1beta1\\ComputeThreatListDiffResponse_ResponseType::class);\n        $this->response_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *Cache) setCacheState(err error) error {\n\tif !c.OnlyRecent.Enabled {\n\t\treturn err\n\t}\n\tif err := c.eraseAll(); err != nil {\n\t\tif !c.isClosed() {\n\t\t\tc.Warningf(\"Failed to erase the data: %v.\", err)\n\t\t}\n\t}\n\tc.wrapper.SetReadError(trace.ConnectionProblem(err, \"cache is unavailable\"))\n\treturn err\n}", "label": 5}
{"code": "public function setOverview($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\TransformationOverview::class);\n        $this->overview = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static Map<String, String> getContentMap(File file, String separator) throws IOException {\n    List<String> content = getContentLines(file);\n    Map<String, String> map = new LinkedHashMap<String, String>();\n      \n    for (String line : content) {\n      String[] spl = line.split(separator);\n      if (line.trim().length() > 0) {\n        map.put(spl[0], (spl.length > 1 ? spl[1] : \"\"));\n      }\n    }\n    \n    return map;\n  }", "label": 0}
{"code": "public function processNextEvent(callable $handler): void\n    {\n        /** @var Context $context */\n        [$event, $context] = $this->waitNextInvocation();\n\n        try {\n            $this->sendResponse($context->getAwsRequestId(), $handler($event, $context));\n        } catch (\\Throwable $e) {\n            $this->signalFailure($context->getAwsRequestId(), $e);\n        }\n    }", "label": 2}
{"code": "func Merge(dest *FlagSet, flagsets ...*FlagSet) error {\n\tfor _, fset := range flagsets {\n\t\tif fset.formal == nil {\n\t\t\tcontinue\n\t\t}\n\t\tfor k, f := range fset.formal {\n\t\t\tif _, ok := dest.formal[k]; ok {\n\t\t\t\tvar err error\n\t\t\t\tif fset.name == \"\" {\n\t\t\t\t\terr = fmt.Errorf(\"flag redefined: %s\", k)\n\t\t\t\t} else {\n\t\t\t\t\terr = fmt.Errorf(\"%s flag redefined: %s\", fset.name, k)\n\t\t\t\t}\n\t\t\t\tfmt.Fprintln(fset.Out(), err.Error())\n\t\t\t\t// Happens only if flags are declared with identical names\n\t\t\t\tswitch dest.errorHandling {\n\t\t\t\tcase ContinueOnError:\n\t\t\t\t\treturn err\n\t\t\t\tcase ExitOnError:\n\t\t\t\t\tos.Exit(2)\n\t\t\t\tcase PanicOnError:\n\t\t\t\t\tpanic(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tnewF := *f\n\t\t\tnewF.Value = mergeVal{f.Value, k, fset}\n\t\t\tif dest.formal == nil {\n\t\t\t\tdest.formal = make(map[string]*Flag)\n\t\t\t}\n\t\t\tdest.formal[k] = &newF\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function generateHttpResponse(ResponseInterface $response, $useFragment = false, $jsonOptions = 0)\n    {\n        $headers = $this->getHttpHeaders();\n\n        $payload = $this->getPayload();\n\n        if ($this->redirectUri !== null) {\n            if ($useFragment === true) {\n                $this->redirectUri .= (strstr($this->redirectUri, '#') === false) ? '#' : '&';\n            } else {\n                $this->redirectUri .= (strstr($this->redirectUri, '?') === false) ? '?' : '&';\n            }\n\n            return $response->withStatus(302)->withHeader('Location', $this->redirectUri . http_build_query($payload));\n        }\n\n        foreach ($headers as $header => $content) {\n            $response = $response->withHeader($header, $content);\n        }\n\n        $response->getBody()->write(json_encode($payload, $jsonOptions));\n\n        return $response->withStatus($this->getHttpStatusCode());\n    }", "label": 2}
{"code": "public static tmtrafficpolicy_tmglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\ttmtrafficpolicy_tmglobal_binding obj = new tmtrafficpolicy_tmglobal_binding();\n\t\tobj.set_name(name);\n\t\ttmtrafficpolicy_tmglobal_binding response[] = (tmtrafficpolicy_tmglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function unwrappedOptions()\n    {\n        if (!($this->options instanceof ConfigurationInterface)) {\n            $this->options = ConfigurationProvider::unwrap($this->options);\n        }\n        return $this->options;\n    }", "label": 2}
{"code": "def subtract_business_days(date, delta)\n      date = roll_backward(date)\n      delta.times do\n        begin\n          date -= day_interval_for(date)\n        end until business_day?(date)\n      end\n      date\n    end", "label": 4}
{"code": "def password=(new_password)\n      if new_password && !new_password.respond_to?(:to_str)\n        raise TypeError, \"Can't convert #{new_password.class} into String.\"\n      end\n      @password = new_password ? new_password.to_str : nil\n\n      # You can't have a nil user with a non-nil password\n      @password ||= nil\n      @user ||= nil\n      if @password != nil\n        @user = EMPTY_STR if @user.nil?\n      end\n\n      # Reset dependent values\n      remove_instance_variable(:@userinfo) if defined?(@userinfo)\n      remove_instance_variable(:@normalized_userinfo) if defined?(@normalized_userinfo)\n      remove_instance_variable(:@authority) if defined?(@authority)\n      remove_instance_variable(:@normalized_password) if defined?(@normalized_password)\n      remove_composite_values\n\n      # Ensure we haven't created an invalid URI\n      validate()\n    end", "label": 4}
{"code": "def label(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'label_for', &block)\n      define_method(name) do\n        return platform.label_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "func (c *Conn) initConnection() error {\n\tvar err error\n\n\tc.sysconn, err = dbus.SystemBus()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// This never fails, even if the service is not running atm.\n\tc.sysobj = c.sysconn.Object(dbusInterface, dbus.ObjectPath(dbusPath))\n\n\trule := fmt.Sprintf(\"type='signal',path='%s',interface='%s',sender='%s',member='Reloaded'\",\n\t\tdbusPath, dbusInterface, dbusInterface)\n\tc.sysconn.BusObject().Call(\"org.freedesktop.DBus.AddMatch\", 0, rule)\n\n\trule = fmt.Sprintf(\"type='signal',interface='org.freedesktop.DBus',member='NameOwnerChanged',path='/org/freedesktop/DBus',sender='org.freedesktop.DBus',arg0='%s'\",\n\t\tdbusInterface)\n\tc.sysconn.BusObject().Call(\"org.freedesktop.DBus.AddMatch\", 0, rule)\n\n\tc.signal = make(chan *dbus.Signal, 10)\n\tc.sysconn.Signal(c.signal)\n\n\treturn nil\n}", "label": 5}
{"code": "function declareSymbol(symbolTable, parent, node, includes, excludes) {\n            ts.Debug.assert(!ts.hasDynamicName(node));\n            var isDefaultExport = node.flags & 512 /* Default */;\n            // The exported symbol for an export default function/class node is always named \"default\"\n            var name = isDefaultExport && parent ? \"default\" : getDeclarationName(node);\n            var symbol;\n            if (name === undefined) {\n                symbol = createSymbol(0 /* None */, \"__missing\");\n            }\n            else {\n                // Check and see if the symbol table already has a symbol with this name.  If not,\n                // create a new symbol with this name and add it to the table.  Note that we don't\n                // give the new symbol any flags *yet*.  This ensures that it will not conflict\n                // with the 'excludes' flags we pass in.\n                //\n                // If we do get an existing symbol, see if it conflicts with the new symbol we're\n                // creating.  For example, a 'var' symbol and a 'class' symbol will conflict within\n                // the same symbol table.  If we have a conflict, report the issue on each\n                // declaration we have for this symbol, and then create a new symbol for this\n                // declaration.\n                //\n                // Note that when properties declared in Javascript constructors\n                // (marked by isReplaceableByMethod) conflict with another symbol, the property loses.\n                // Always. This allows the common Javascript pattern of overwriting a prototype method\n                // with an bound instance method of the same type: `this.method = this.method.bind(this)`\n                //\n                // If we created a new symbol, either because we didn't have a symbol with this name\n                // in the symbol table, or we conflicted with an existing symbol, then just add this\n                // node as the sole declaration of the new symbol.\n                //\n                // Otherwise, we'll be merging into a compatible existing symbol (for example when\n                // you have multiple 'vars' with the same name in the same container).  In this case\n                // just add this node into the declarations list of the symbol.\n                symbol = symbolTable[name] || (symbolTable[name] = createSymbol(0 /* None */, name));\n                if (name && (includes & 788448 /* Classifiable */)) {\n                    classifiableNames[name] = name;\n                }\n                if (symbol.flags & excludes) {\n                    if (symbol.isReplaceableByMethod) {\n                        // Javascript constructor-declared symbols can be discarded in favor of\n                        // prototype symbols like methods.\n                        symbol = symbolTable[name] = createSymbol(0 /* None */, name);\n                    }\n                    else {\n                        if (node.name) {\n                            node.name.parent = node;\n                        }\n                        // Report errors every position with duplicate declaration\n                        // Report errors on previous encountered declarations\n                        var message_1 = symbol.flags & 2 /* BlockScopedVariable */\n                            ? ts.Diagnostics.Cannot_redeclare_block_scoped_variable_0\n                            : ts.Diagnostics.Duplicate_identifier_0;\n                        ts.forEach(symbol.declarations, function (declaration) {\n                            if (declaration.flags & 512 /* Default */) {\n                                message_1 = ts.Diagnostics.A_module_cannot_have_multiple_default_exports;\n                            }\n                        });\n                        ts.forEach(symbol.declarations, function (declaration) {\n                            file.bindDiagnostics.push(ts.createDiagnosticForNode(declaration.name || declaration, message_1, getDisplayName(declaration)));\n                        });\n                        file.bindDiagnostics.push(ts.createDiagnosticForNode(node.name || node, message_1, getDisplayName(node)));\n                        symbol = createSymbol(0 /* None */, name);\n                    }\n                }\n            }\n            addDeclarationToSymbol(symbol, node, includes);\n            symbol.parent = parent;\n            return symbol;\n        }", "label": 3}
{"code": "def save(self, file_tag='2016', add_header='N'):\n        \"\"\"\n        save table to folder in appropriate files\n        NOTE - ONLY APPEND AT THIS STAGE - THEN USE DATABASE\n        \"\"\"\n        fname = self.get_filename(file_tag)\n        with open(fname, 'a') as f:\n            if add_header == 'Y':\n                f.write(self.format_hdr())\n                \n            for e in self.table: \n                    f.write(e.format_csv())", "label": 1}
{"code": "func (f *followDatastoreFile) Close() error {\n\tf.o.Do(func() { close(f.c) })\n\treturn nil\n}", "label": 5}
{"code": "function _gpfStreamPipe (source, destination) {\n    _gpfIgnore(destination);\n    var iReadableStream = _gpfStreamQueryReadable(source),\n        iWritableStream = _gpfStreamPipeToWritable(_gpfArrayTail(arguments)),\n        iFlushableStream = _gpfStreamPipeToFlushable(iWritableStream);\n    try {\n        return iReadableStream.read(iWritableStream)\n            .then(function () {\n                return iFlushableStream.flush();\n            });\n    } catch (e) {\n        return Promise.reject(e);\n    }\n}", "label": 3}
{"code": "func (c *StatusCommand) Status(client auth.ClientI) error {\n\tclusterNameResource, err := client.GetClusterName()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tclusterName := clusterNameResource.GetClusterName()\n\n\thostCAs, err := client.GetCertAuthorities(services.HostCA, false)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tuserCAs, err := client.GetCertAuthorities(services.UserCA, false)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// Calculate the CA pin for this cluster. The CA pin is used by the client\n\t// to verify the identity of the Auth Server.\n\tcaPin, err := calculateCAPin(client)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tauthorities := append(userCAs, hostCAs...)\n\tview := func() string {\n\t\ttable := asciitable.MakeHeadlessTable(2)\n\t\ttable.AddRow([]string{\"Cluster\", clusterName})\n\t\tfor _, ca := range authorities {\n\t\t\tif ca.GetClusterName() != clusterName {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tinfo := fmt.Sprintf(\"%v CA \", strings.Title(string(ca.GetType())))\n\t\t\trotation := ca.GetRotation()\n\t\t\tif c.config.Debug {\n\t\t\t\ttable.AddRow([]string{info,\n\t\t\t\t\tfmt.Sprintf(\"%v, update_servers: %v, complete: %v\",\n\t\t\t\t\t\trotation.String(),\n\t\t\t\t\t\trotation.Schedule.UpdateServers.Format(teleport.HumanDateFormatSeconds),\n\t\t\t\t\t\trotation.Schedule.Standby.Format(teleport.HumanDateFormatSeconds),\n\t\t\t\t\t)})\n\t\t\t} else {\n\t\t\t\ttable.AddRow([]string{info, rotation.String()})\n\t\t\t}\n\n\t\t}\n\t\ttable.AddRow([]string{\"CA pin\", caPin})\n\t\treturn table.AsBuffer().String()\n\t}\n\tfmt.Printf(view())\n\n\t// in debug mode, output mode of remote certificate authorities\n\tif c.config.Debug {\n\t\tview := func() string {\n\t\t\ttable := asciitable.MakeHeadlessTable(2)\n\t\t\tfor _, ca := range authorities {\n\t\t\t\tif ca.GetClusterName() == clusterName {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tinfo := fmt.Sprintf(\"Remote %v CA %q\", strings.Title(string(ca.GetType())), ca.GetClusterName())\n\t\t\t\trotation := ca.GetRotation()\n\t\t\t\ttable.AddRow([]string{info, rotation.String()})\n\t\t\t}\n\t\t\treturn \"Remote clusters\\n\\n\" + table.AsBuffer().String()\n\t\t}\n\t\tfmt.Printf(view())\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static String generateQuery(final Map<String,Object> params){\n\t\tfinal StringBuilder sb = new StringBuilder();\n\t\tboolean newEntry = false;\n\t\t\n\t\tsb.append(\"{\");\n\t\tfor(final Entry<String,Object> param: params.entrySet()){\n\t\t\tif(newEntry){\n\t\t\t\tsb.append(\", \");\n\t\t\t}\n\n\t\t\tsb.append(param.getKey());\n\t\t\tsb.append(\": \");\n\t\t\tsb.append(getParam(param.getValue()));\n\t\t\tnewEntry = true;\n\t\t}\n\t\tsb.append(\"}\");\n\t\t\n\t\treturn sb.toString();\n\t}", "label": 0}
{"code": "function build_rules(filters, arr) {\n    var rules = [];\n    for(var i=0; i<arr.length; i++) {\n        var r = arr[i], rule\n        if(!contains_expr(r)) throw OptError('Rule MUST contain an option.');\n        switch(r.length) {\n            case 1:\n                rule = build_rule(filters, r[0]);\n                break;\n            case 2:\n                var expr = LONG_SWITCH_RE.test(r[0]) ? 0 : 1;\n                var alias = expr == 0 ? -1 : 0;\n                var desc = alias == -1 ? 1 : -1;\n                rule = build_rule(filters, r[alias], r[expr], r[desc]);\n                break;\n            case 3:\n                rule = build_rule(filters, r[0], r[1], r[2]);\n                break;\n            default:\n            case 0:\n                continue;\n        }\n        rules.push(rule)\n    }\n    return rules;\n}", "label": 3}
{"code": "public function setWindow($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\MaintenanceWindow::class);\n        $this->window = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func RetrievePropertiesForRequest(ctx context.Context, r soap.RoundTripper, req types.RetrieveProperties, dst interface{}) error {\n\tres, err := methods.RetrieveProperties(ctx, r, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn LoadRetrievePropertiesResponse(res, dst)\n}", "label": 5}
{"code": "function exportSubmissions(req, res, next) {\n  var params = {\n    \"appId\" : req.body.projectId,\n    \"subid\": req.body.subid,\n    \"formId\": req.body.formId,\n    \"fieldHeader\": req.body.fieldHeader,\n    \"downloadUrl\": req.body.fileUrl,\n    \"filter\": req.body.filter,\n    \"query\": req.body.query,\n    \"wantRestrictions\": false\n  };\n\n  logger.debug(\"Middleware exportSubmissions \", {req: req, body: req.body, params: params});\n\n  forms.exportSubmissions(req.connectionOptions, params, function(err, submissionCsvValues) {\n    if (err) {\n      logger.error(\"Middleware Export Submissions \", {error: err});\n      return next(err);\n    }\n\n    logger.debug(\"Middleware exportSubmissions submissionCsvValues\", {submissionCsvValues: submissionCsvValues.length});\n\n    _processExportResponse(submissionCsvValues, res, next);\n  });\n}", "label": 3}
{"code": "func (aug *AuthUserGroup) Save(db XODB) error {\n\tif aug.Exists() {\n\t\treturn aug.Update(db)\n\t}\n\n\treturn aug.Insert(db)\n}", "label": 5}
{"code": "public static sslfipskey[] get(nitro_service service, String fipskeyname[]) throws Exception{\n\t\tif (fipskeyname !=null && fipskeyname.length>0) {\n\t\t\tsslfipskey response[] = new sslfipskey[fipskeyname.length];\n\t\t\tsslfipskey obj[] = new sslfipskey[fipskeyname.length];\n\t\t\tfor (int i=0;i<fipskeyname.length;i++) {\n\t\t\t\tobj[i] = new sslfipskey();\n\t\t\t\tobj[i].set_fipskeyname(fipskeyname[i]);\n\t\t\t\tresponse[i] = (sslfipskey) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def lock(name=\"global\", **opts)\n      f = nil\n\n      # If we don't have a block, then locking is useless, so ignore it\n      return if !block_given?\n\n      # This allows multiple locks in the same process to be nested\n      return yield if @locks[name] || opts[:noop]\n\n      # The path to this lock\n      lock_path = data_dir.join(\"lock.#{name}.lock\")\n\n      @logger.debug(\"Attempting to acquire process-lock: #{name}\")\n      lock(\"dotlock\", noop: name == \"dotlock\", retry: true) do\n        f = File.open(lock_path, \"w+\")\n      end\n\n      # The file locking fails only if it returns \"false.\" If it\n      # succeeds it returns a 0, so we must explicitly check for\n      # the proper error case.\n      while f.flock(File::LOCK_EX | File::LOCK_NB) === false\n        @logger.warn(\"Process-lock in use: #{name}\")\n\n        if !opts[:retry]\n          raise Errors::EnvironmentLockedError,\n            name: name\n        end\n\n        sleep 0.2\n      end\n\n      @logger.info(\"Acquired process lock: #{name}\")\n\n      result = nil\n      begin\n        # Mark that we have a lock\n        @locks[name] = true\n\n        result = yield\n      ensure\n        # We need to make sure that no matter what this is always\n        # reset to false so we don't think we have a lock when we\n        # actually don't.\n        @locks.delete(name)\n        @logger.info(\"Released process lock: #{name}\")\n      end\n\n      # Clean up the lock file, this requires another lock\n      if name != \"dotlock\"\n        lock(\"dotlock\", retry: true) do\n          f.close\n          begin\n            File.delete(lock_path)\n          rescue\n            @logger.error(\n              \"Failed to delete lock file #{lock_path} - some other thread \" +\n              \"might be trying to acquire it. ignoring this error\")\n          end\n        end\n      end\n\n      # Return the result\n      return result\n    ensure\n      begin\n        f.close if f\n      rescue IOError\n      end\n    end", "label": 4}
{"code": "private String[] computeFilteredSplitValues(String[] values, String filter)\n      throws MtasConfigException {\n    if (filter != null) {\n      String[] filters = filter.split(\",\");\n      boolean[] valuesFilter = new boolean[values.length];\n      boolean doSplitFilter = false;\n      for (String item : filters) {\n        if (item.trim().matches(\n            \"^\" + Pattern.quote(MAPPING_FILTER_SPLIT) + \"\\\\([0-9\\\\-]+\\\\)$\")) {\n          doSplitFilter = true;\n          Pattern splitContent = Pattern\n              .compile(\"^\" + Pattern.quote(MAPPING_FILTER_SPLIT)\n                  + \"\\\\(([0-9]+)(-([0-9]+))?\\\\)$\");\n          Matcher splitContentMatcher = splitContent.matcher(item.trim());\n          while (splitContentMatcher.find()) {\n            if (splitContentMatcher.group(3) == null) {\n              int i = Integer.parseInt(splitContentMatcher.group(1));\n              if (i >= 0 && i < values.length) {\n                valuesFilter[i] = true;\n              }\n            } else {\n              int i1 = Integer.parseInt(splitContentMatcher.group(1));\n              int i2 = Integer.parseInt(splitContentMatcher.group(3));\n              for (int i = Math.max(0, i1); i < Math.min(values.length,\n                  i2); i++) {\n                valuesFilter[i] = true;\n              }\n            }\n          }\n        }\n      }\n      if (doSplitFilter) {\n        int number = 0;\n        for (int i = 0; i < valuesFilter.length; i++) {\n          if (valuesFilter[i]) {\n            number++;\n          }\n        }\n        if (number > 0) {\n          String[] newValues = new String[number];\n          number = 0;\n          for (int i = 0; i < valuesFilter.length; i++) {\n            if (valuesFilter[i]) {\n              newValues[number] = values[i];\n              number++;\n            }\n          }\n          return newValues;\n        } else {\n          return new String[] {};\n        }\n      }\n    }\n    return values;\n  }", "label": 0}
{"code": "def verify_signature(message, signature, public_key):\n    \"\"\"\n    Verifies `signature` is correct for a `message` signed with `public_key`\n\n    :param message: message to check\n    :type message: bytes\n\n    :param signature: signature to check\n    :type signature: bytes\n\n    :param public_key: public_key to check\n    :type public_key: bytes\n\n    :return: True if valid, False otherwise\n    :rtype: bool\n    \"\"\"\n\n    try:\n        ed25519_blake2.checkvalid(signature, message, public_key)\n    except ed25519_blake2.SignatureMismatch:\n        return False\n    return True", "label": 1}
{"code": "func (c *Client) GetU2FSignRequest(user string, password []byte) (*u2f.SignRequest, error) {\n\tout, err := c.PostJSON(\n\t\tc.Endpoint(\"u2f\", \"users\", user, \"sign\"),\n\t\tsignInReq{\n\t\t\tPassword: string(password),\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar signRequest *u2f.SignRequest\n\tif err := json.Unmarshal(out.Bytes(), &signRequest); err != nil {\n\t\treturn nil, err\n\t}\n\treturn signRequest, nil\n}", "label": 5}
{"code": "function(elements, parts, isReplacementSearch) {\n            parts = parts || {};\n\n            if (!elements) {\n                return parts;\n            }\n\n            if (elements.length === undefined) {\n                elements = [elements];\n            }\n\n            for (var i = 0, length = elements.length; i < length; i++) {\n                var element = elements[i];\n\n                if (element.getAttribute) {\n                    if(!isReplacementSearch && hasComposition(element)){\n                        continue;\n                    }\n\n                    var id = element.getAttribute(partAttributeName);\n                    if (id) {\n                        parts[id] = element;\n                    }\n\n                    if(!isReplacementSearch && element.hasChildNodes()){\n                        composition.getParts(element.childNodes, parts);\n                    }\n                }\n            }\n\n            return parts;\n        }", "label": 3}
{"code": "def get_report_html(self):\n        \"\"\"\n        formats the project into a report in MD format - WARNING - tables missing BR\n        \"\"\"\n        res = '<h2>Project:' + self.nme  + '</h2>'\n        res += '<p>' + self.desc + '</p>'\n        res += '<p>' + self.fldr + '</p>'\n        \n        res += '<BR><h3>TABLES</h3>'\n        \n        for t in self.datatables:\n            res += '<b>' + t.name + '<b><BR>'\n            res += '<p>' + str(t) + '</p>'\n        return res", "label": 1}
{"code": "def get_featured_or_none(cls, start_date=None):\n        \"\"\"Get the latest featured community.\n\n        :param start_date: Date after which the featuring starts\n        :returns: Community object or None\n        :rtype: `invenio_communities.models.Community` or None\n        \"\"\"\n        start_date = start_date or datetime.utcnow()\n\n        comm = cls.query.filter(\n            FeaturedCommunity.start_date <= start_date\n        ).order_by(\n            cls.start_date.desc()\n        ).first()\n        return comm if comm is None else comm.community", "label": 1}
{"code": "def ser_iuwt_recomposition(in1, scale_adjust, smoothed_array):\n    \"\"\"\n    This function calls the a trous algorithm code to recompose the input into a single array. This is the\n    implementation of the isotropic undecimated wavelet transform recomposition for a single CPU core.\n\n    INPUTS:\n    in1             (no default):   Array containing wavelet coefficients.\n    scale_adjust    (no default):   Indicates the number of truncated array pages.\n    smoothed_array  (default=None): For a complete inverse transform, this must be the smoothest approximation.\n\n    OUTPUTS:\n    recomposition                   Array containing the reconstructed image.\n    \"\"\"\n\n    wavelet_filter = (1./16)*np.array([1,4,6,4,1])      # Filter-bank for use in the a trous algorithm.\n\n    # Determines scale with adjustment and creates a zero array to store the output, unless smoothed_array is given.\n\n    max_scale = in1.shape[0] + scale_adjust\n\n    if smoothed_array is None:\n        recomposition = np.zeros([in1.shape[1], in1.shape[2]])\n    else:\n        recomposition = smoothed_array\n\n    # The following loops call the a trous algorithm code to recompose the input. The first loop assumes that there are\n    # non-zero wavelet coefficients at scales above scale_adjust, while the second loop completes the recomposition\n    # on the scales less than scale_adjust.\n\n    for i in range(max_scale-1, scale_adjust-1, -1):\n        recomposition = ser_a_trous(recomposition, wavelet_filter, i) + in1[i-scale_adjust,:,:]\n\n    if scale_adjust>0:\n        for i in range(scale_adjust-1, -1, -1):\n            recomposition = ser_a_trous(recomposition, wavelet_filter, i)\n\n    return recomposition", "label": 1}
{"code": "def make_key_hippie(obj, typed=True):\n    \"\"\"Return hashable structure from non-hashable structure using hippie means\n\n    dict and set are sorted and their content subjected to same hippie means.\n\n    Note that the key identifies the current content of the structure.\n\n    \"\"\"\n    ftype = type if typed else lambda o: None\n    if is_hashable(obj):\n        ## DO NOT RETURN hash(obj), as hash collision would generate bad\n        ## cache collisions.\n        return obj, ftype(obj)\n    ## should we try to convert to frozen{set,dict} to get the C\n    ## hashing function speed ? But the convertion has a cost also.\n    if isinstance(obj, set):\n        obj = sorted(obj)\n    if isinstance(obj, (list, tuple)):\n        return tuple(make_key_hippie(e, typed) for e in obj)\n    if isinstance(obj, dict):\n        return tuple(sorted(((make_key_hippie(k, typed),\n                              make_key_hippie(v, typed))\n                             for k, v in obj.items())))\n    raise ValueError(\n        \"%r can not be hashed. Try providing a custom key function.\"\n        % obj)", "label": 1}
{"code": "public function setLabelExtractors($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->label_extractors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function detect_doc(docs, customTags) {\n    var ignore_tags = _.union([\"param\", \"return\", \"author\", \"version\", \n                               \"cancelable\", \"bubbles\", \"since\", \"inherits\", \"todo\", \"deprecated\"], customTags);\n    var doc_tags = _.filter(docs, function(tag) { return !_.include(ignore_tags, tag[\"tagname\"]) && !subproperty(tag) });\n    return _.compact(_.map(doc_tags, function(tag) { return tag[\"doc\"] })).join(\" \");\n}", "label": 3}
{"code": "function(callback) {\n      self._getConnection(function(err, connection) {\n        if (err) {\n          callback(new Error('Unable to establish connection with the master ' +\n                             'process'));\n          return;\n        }\n\n        self._connection = connection;\n        callback();\n      });\n    }", "label": 3}
{"code": "func (this *summaryMetricsSource) addIntMetric(metrics *MetricSet, metric *Metric, value *uint64) {\n\tif value == nil {\n\t\tglog.V(9).Infof(\"skipping metric %s because the value was nil\", metric.Name)\n\t\treturn\n\t}\n\tval := MetricValue{\n\t\tValueType:  ValueInt64,\n\t\tMetricType: metric.Type,\n\t\tIntValue:   int64(*value),\n\t}\n\tmetrics.MetricValues[metric.Name] = val\n}", "label": 5}
{"code": "def get_dump_type(value):\n    '''Get the libconfig datatype of a value\n\n    Return values: ``'d'`` (dict), ``'l'`` (list), ``'a'`` (array),\n    ``'i'`` (integer), ``'i64'`` (long integer), ``'b'`` (bool),\n    ``'f'`` (float), or ``'s'`` (string).\n\n    Produces the proper type for LibconfList, LibconfArray, LibconfInt64\n    instances.\n    '''\n\n    if isinstance(value, dict):\n        return 'd'\n    if isinstance(value, tuple):\n        return 'l'\n    if isinstance(value, list):\n        return 'a'\n\n    # Test bool before int since isinstance(True, int) == True.\n    if isinstance(value, bool):\n        return 'b'\n    if isint(value):\n        if is_long_int(value):\n            return 'i64'\n        else:\n            return 'i'\n    if isinstance(value, float):\n        return 'f'\n    if isstr(value):\n        return 's'\n\n    return None", "label": 1}
{"code": "def retrieve_bank_account(location_id, bank_account_id, opts = {})\n      data, _status_code, _headers = retrieve_bank_account_with_http_info(location_id, bank_account_id, opts)\n      return data\n    end", "label": 4}
{"code": "def update_data(new_data)\n      @name = new_data[:name] || new_data['name'] || @name\n      @hoist = new_data['hoist'] unless new_data['hoist'].nil?\n      @hoist = new_data[:hoist] unless new_data[:hoist].nil?\n      @colour = new_data[:colour] || (new_data['color'] ? ColourRGB.new(new_data['color']) : @colour)\n    end", "label": 4}
{"code": "func (l *Linter) Lint(filename string, src []byte) ([]Problem, error) {\n\treturn l.LintFiles(map[string][]byte{filename: src})\n}", "label": 5}
{"code": "func (a *AuthWithRoles) UpsertCertAuthority(ca services.CertAuthority) error {\n\tif ca == nil {\n\t\treturn trace.BadParameter(\"missing certificate authority\")\n\t}\n\tctx := &services.Context{User: a.user, Resource: ca}\n\tif err := a.actionWithContext(ctx, defaults.Namespace, services.KindCertAuthority, services.VerbCreate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := a.actionWithContext(ctx, defaults.Namespace, services.KindCertAuthority, services.VerbUpdate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.UpsertCertAuthority(ca)\n}", "label": 5}
{"code": "public static base_response update(nitro_service client, sslcertkey resource) throws Exception {\n\t\tsslcertkey updateresource = new sslcertkey();\n\t\tupdateresource.certkey = resource.certkey;\n\t\tupdateresource.expirymonitor = resource.expirymonitor;\n\t\tupdateresource.notificationperiod = resource.notificationperiod;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function search($expression)\n    {\n        // Apply JMESPath expression on each result, but as a flat sequence.\n        return flatmap($this, function (Result $result) use ($expression) {\n            return (array) $result->search($expression);\n        });\n    }", "label": 2}
{"code": "public function setBigQueryOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\BigQueryOptions::class);\n        $this->writeOneof(4, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def output_lines(output, encoding='utf-8', error_exc=None):\n    \"\"\"\n    Convert bytestring container output or the result of a container exec\n    command into a sequence of unicode lines.\n\n    :param output:\n        Container output bytes or an\n        :class:`docker.models.containers.ExecResult` instance.\n    :param encoding:\n        The encoding to use when converting bytes to unicode\n        (default ``utf-8``).\n    :param error_exc:\n        Optional exception to raise if ``output`` is an ``ExecResult`` with a\n        nonzero exit code.\n\n    :returns: list[str]\n\n    \"\"\"\n    if isinstance(output, ExecResult):\n        exit_code, output = output\n        if exit_code != 0 and error_exc is not None:\n            raise error_exc(output.decode(encoding))\n\n    return output.decode(encoding).splitlines()", "label": 1}
{"code": "public void fillTile(InternalTile tile, Envelope maxTileExtent)\n\t\t\tthrows GeomajasException {\n\t\tList<InternalFeature> origFeatures = tile.getFeatures();\n\t\ttile.setFeatures(new ArrayList<InternalFeature>());\n\t\tfor (InternalFeature feature : origFeatures) {\n\t\t\tif (!addTileCode(tile, maxTileExtent, feature.getGeometry())) {\n\t\t\t\tlog.debug(\"add feature\");\n\t\t\t\ttile.addFeature(feature);\n\t\t\t}\n\t\t}\n\t}", "label": 0}
{"code": "private function toGrpcValue(array $property)\n    {\n        $type = array_keys($property)[0];\n        $val = $property[$type];\n        if ($val === null) {\n            $val = NullValue::NULL_VALUE;\n        }\n\n        if ($type === 'timestampValue') {\n            $val = $this->formatTimestampForApi($val);\n        }\n\n        if ($type === 'geoPointValue') {\n            $val = $this->arrayFilterRemoveNull($val);\n        }\n\n        return [$type, $val];\n    }", "label": 2}
{"code": "func PgIndexColumns(db models.XODB, schema string, table string, index string) ([]*models.IndexColumn, error) {\n\tvar err error\n\n\t// load columns\n\tcols, err := models.PgIndexColumns(db, schema, index)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// load col order\n\tcolOrd, err := models.PgGetColOrder(db, schema, index)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// build schema name used in errors\n\ts := schema\n\tif s != \"\" {\n\t\ts = s + \".\"\n\t}\n\n\t// put cols in order using colOrder\n\tret := []*models.IndexColumn{}\n\tfor _, v := range strings.Split(colOrd.Ord, \" \") {\n\t\tcid, err := strconv.Atoi(v)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not convert %s%s index %s column %s to int\", s, table, index, v)\n\t\t}\n\n\t\t// find column\n\t\tfound := false\n\t\tvar c *models.IndexColumn\n\t\tfor _, ic := range cols {\n\t\t\tif cid == ic.Cid {\n\t\t\t\tfound = true\n\t\t\t\tc = ic\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// sanity check\n\t\tif !found {\n\t\t\treturn nil, fmt.Errorf(\"could not find %s%s index %s column id %d\", s, table, index, cid)\n\t\t}\n\n\t\tret = append(ret, c)\n\t}\n\n\treturn ret, nil\n}", "label": 5}
{"code": "function reduce(accumulator, iterable, initializer = undefined) {\n\n  if (initializer === undefined) {\n    const iterator = (0, _iter.iter)(iterable);\n    const first = iterator.next();\n\n    if (first.done) {\n      return undefined;\n    }\n\n    return (0, _reduce2._reduce)(accumulator, iterator, first.value);\n  }\n\n  return (0, _reduce2._reduce)(accumulator, iterable, initializer);\n}", "label": 3}
{"code": "public function getShapeDocs($shapeName, $parentName, $ref)\n    {\n        if (!isset($this->docs['shapes'][$shapeName])) {\n            return '';\n        }\n\n        $result = '';\n        $d = $this->docs['shapes'][$shapeName];\n        if (isset($d['refs'][\"{$parentName}\\$${ref}\"])) {\n            $result = $d['refs'][\"{$parentName}\\$${ref}\"];\n        } elseif (isset($d['base'])) {\n            $result = $d['base'];\n        }\n\n        if (isset($d['append'])) {\n            $result .= $d['append'];\n        }\n\n        return $this->clean($result);\n    }", "label": 2}
{"code": "def to_html(input, context = {}, result = nil)\n      result = call(input, context, result = nil)\n      output = result[:output]\n      if output.respond_to?(:to_html)\n        output.to_html\n      else\n        output.to_s\n      end\n    end", "label": 4}
{"code": "public function setAuthorizationType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\DataSource_AuthorizationType::class);\n        $this->authorization_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def from_respecth(cls, filename_xml, file_author='', file_author_orcid=''):\n        \"\"\"Construct a ChemKED instance directly from a ReSpecTh file.\n\n        Arguments:\n            filename_xml (`str`): Filename of the ReSpecTh-formatted XML file to be imported\n            file_author (`str`, optional): File author to be added to the list generated from the\n                XML file\n            file_author_orcid (`str`, optional): ORCID for the file author being added to the list\n                of file authors\n\n        Returns:\n            `ChemKED`: Instance of the `ChemKED` class containing the data in ``filename_xml``.\n\n        Examples:\n            >>> ck = ChemKED.from_respecth('respecth_file.xml')\n            >>> ck = ChemKED.from_respecth('respecth_file.xml', file_author='Bryan W. Weber')\n            >>> ck = ChemKED.from_respecth('respecth_file.xml', file_author='Bryan W. Weber',\n                                           file_author_orcid='0000-0000-0000-0000')\n        \"\"\"\n        properties = ReSpecTh_to_ChemKED(filename_xml, file_author, file_author_orcid,\n                                         validate=False)\n        return cls(dict_input=properties)", "label": 1}
{"code": "func (s *Server) WriteV3(p *Packet) (interface{}, error) {\n\treq := new(RequestWriteV3)\n\terr := UnmarshalBinary(p.Payload, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsession, err := s.getSession(p)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsession.mu.Lock()\n\tfile, ok := session.files[req.Handle]\n\tsession.mu.Unlock()\n\n\tif !ok {\n\t\treturn nil, &Status{Code: StatusInvalidHandle}\n\t}\n\n\tn, err := file.Write(req.Payload)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres := &ReplyWriteV3{\n\t\tActualSize: uint32(n),\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public double determinant() {\n        if (m != n) {\n            throw new IllegalArgumentException(\"Matrix must be square.\");\n        }\n        double d = (double) pivsign;\n        for (int j = 0; j < n; j++) {\n            d *= LU[j][j];\n        }\n        return d;\n    }", "label": 0}
{"code": "func NewCustomDatastoreFlag(ctx context.Context) (*DatastoreFlag, context.Context) {\n\tv := &DatastoreFlag{}\n\tv.DatacenterFlag, ctx = NewDatacenterFlag(ctx)\n\treturn v, ctx\n}", "label": 5}
{"code": "func (t *Torrent) PieceBytesMissing(piece int) int64 {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\n\treturn int64(t.pieces[piece].bytesLeft())\n}", "label": 5}
{"code": "void start(String monitoredDirectory, Long pollingTime) {\n        this.monitoredDirectory = monitoredDirectory;\n        String deployerKlassName;\n        if (klass.equals(ImportDeclaration.class)) {\n            deployerKlassName = ImporterDeployer.class.getName();\n        } else if (klass.equals(ExportDeclaration.class)) {\n            deployerKlassName = ExporterDeployer.class.getName();\n        } else {\n            throw new IllegalStateException(\"\");\n        }\n\n        this.dm = new DirectoryMonitor(monitoredDirectory, pollingTime, deployerKlassName);\n        try {\n            dm.start(getBundleContext());\n        } catch (DirectoryMonitoringException e) {\n            LOG.error(\"Failed to start \" + DirectoryMonitor.class.getName() + \" for the directory \" + monitoredDirectory + \" and polling time \" + pollingTime.toString(), e);\n        }\n    }", "label": 0}
{"code": "def prepare_custom_fields(options)\n      customs = self.class.activity_custom_fields_global.clone\n      customs.merge!(self.activity_custom_fields) if self.activity_custom_fields\n      customs.merge!(options)\n      customs.each do  |k, v|\n        customs[k] = PublicActivity.resolve_value(self, v)\n      end\n    end", "label": 4}
{"code": "func (a *HistoricalApi) namespaceAggregations(request *restful.Request, response *restful.Response) {\n\tkey := core.HistoricalKey{\n\t\tObjectType:    core.MetricSetTypeNamespace,\n\t\tNamespaceName: request.PathParameter(\"namespace-name\"),\n\t}\n\ta.processAggregationRequest(key, request, response)\n}", "label": 5}
{"code": "function (req, res) {\n        let sectionId = req.params.id;\n        let s = server.state.get('sections[' + sectionId + ']');\n        if (Utils.isNullOrEmpty(s)) {\n            log.debug('Unable to read configuration for section id:', sectionId);\n            Utils.sendEmptySuccess(res);\n            return;\n        }\n\n        let section = {\n            id: parseInt(sectionId, 10), x: s.x, y: s.y, w: s.w, h: s.h, space: Object.keys(s.spaces)[0]\n        };\n        const app = s.app;\n        if (app) {\n            section.app = { url: app.url, state: app.state, opacity: app.opacity };\n        }\n        log.debug('Successfully read configuration for section id:', sectionId);\n        Utils.sendMessage(res, HttpStatus.OK, JSON.stringify(section));\n    }", "label": 3}
{"code": "def extract_col(self, col):\n        \"\"\"\n        get column number 'col'\n        \"\"\"\n        new_col = [row[col] for row in self.grid]\n        return new_col", "label": 1}
{"code": "function(apiClient) {\n    this.apiClient = apiClient || ApiClient.instance;\n\n\n\n    /**\n     * Finds organizations page fragment\n     * Finds single organization page fragment \n     * @param {String} organizationId Organization id\n     * @param {String} fragmentId fragment id\n     * @return {Promise} a {@link https://www.promisejs.org/|Promise}, with data of type {@link module:model/Fragment}\n     */\n    this.findOrganizationFragment = function(organizationId, fragmentId) {\n      var postBody = null;\n\n      // verify the required parameter 'organizationId' is set\n      if (organizationId == undefined || organizationId == null) {\n        throw \"Missing the required parameter 'organizationId' when calling findOrganizationFragment\";\n      }\n\n      // verify the required parameter 'fragmentId' is set\n      if (fragmentId == undefined || fragmentId == null) {\n        throw \"Missing the required parameter 'fragmentId' when calling findOrganizationFragment\";\n      }\n\n\n      var pathParams = {\n        'organizationId': organizationId,\n        'fragmentId': fragmentId\n      };\n      var queryParams = {\n      };\n      var headerParams = {\n      };\n      var formParams = {\n      };\n\n      var authNames = ['basicAuth'];\n      var contentTypes = ['application/json;charset=utf-8'];\n      var accepts = ['application/json;charset=utf-8'];\n      var returnType = Fragment;\n\n      return this.apiClient.callApi(\n        '/organizations/{organizationId}/fragments/{fragmentId}', 'GET',\n        pathParams, queryParams, headerParams, formParams, postBody,\n        authNames, contentTypes, accepts, returnType\n      );\n    }\n\n\n    /**\n     * Lists organizations page fragments\n     * Lists organizations page fragments \n     * @param {String} organizationId Organization id\n     * @param {Object} opts Optional parameters\n     * @param {String} opts.slug Filter results by fragment slug\n     * @return {Promise} a {@link https://www.promisejs.org/|Promise}, with data of type {@link Array.<module:model/Fragment>}\n     */\n    this.listOrganizationFragments = function(organizationId, opts) {\n      opts = opts || {};\n      var postBody = null;\n\n      // verify the required parameter 'organizationId' is set\n      if (organizationId == undefined || organizationId == null) {\n        throw \"Missing the required parameter 'organizationId' when calling listOrganizationFragments\";\n      }\n\n\n      var pathParams = {\n        'organizationId': organizationId\n      };\n      var queryParams = {\n        'slug': opts['slug']\n      };\n      var headerParams = {\n      };\n      var formParams = {\n      };\n\n      var authNames = ['basicAuth'];\n      var contentTypes = ['application/json;charset=utf-8'];\n      var accepts = ['application/json;charset=utf-8'];\n      var returnType = [Fragment];\n\n      return this.apiClient.callApi(\n        '/organizations/{organizationId}/fragments', 'GET',\n        pathParams, queryParams, headerParams, formParams, postBody,\n        authNames, contentTypes, accepts, returnType\n      );\n    }\n  }", "label": 3}
{"code": "private function parseClass()\n    {\n        $klass = get_class($this);\n\n        if ($klass === __CLASS__) {\n            return ['', 'Aws\\Exception\\AwsException'];\n        }\n\n        $service = substr($klass, strrpos($klass, '\\\\') + 1, -6);\n\n        return [\n            strtolower($service),\n            \"Aws\\\\{$service}\\\\Exception\\\\{$service}Exception\"\n        ];\n    }", "label": 2}
{"code": "public static authenticationradiusaction get(nitro_service service, String name) throws Exception{\n\t\tauthenticationradiusaction obj = new authenticationradiusaction();\n\t\tobj.set_name(name);\n\t\tauthenticationradiusaction response = (authenticationradiusaction) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function init(options = {}, handlebars) {\n  const opts = deepExtend({}, defaults, options);\n  normalizePaths(opts);\n  opts.handlebars = handlebars || Handlebars.create();\n  return Promise.resolve(opts);\n}", "label": 3}
{"code": "def push_supply(self, tokens):\n        \"\"\" Adds OPF and CPF data to a Generator.\n        \"\"\"\n        logger.debug(\"Pushing supply data: %s\" % tokens)\n\n        bus = self.case.buses[tokens[\"bus_no\"] - 1]\n        n_generators = len([g for g in self.case.generators if g.bus == bus])\n\n        if n_generators == 0:\n            logger.error(\"No generator at bus [%s] for matching supply\" % bus)\n            return\n        elif n_generators > 1:\n            g = [g for g in self.case.generators if g.bus == bus][0]\n            logger.warning(\n                \"More than one generator at bus [%s] for demand. Using the \"\n                \"first one [%s].\" % (bus, g)\n            )\n        else:\n            g = [g for g in self.case.generators if g.bus == bus][0]\n\n        g.pcost_model = \"poly\"\n        g.poly_coeffs = (\n            tokens[\"p_fixed\"],\n            tokens[\"p_proportional\"],\n            tokens[\"p_quadratic\"]\n        )", "label": 1}
{"code": "func ForbiddenErrorf(format string, params ...interface{}) error {\n\treturn forbidden(fmt.Sprintf(format, params...))\n}", "label": 5}
{"code": "public function registerNotificationTypes()\n    {\n        $blueprints = [\n            DiscussionRenamedBlueprint::class => ['alert']\n        ];\n\n        $this->app->make('events')->fire(\n            new ConfigureNotificationTypes($blueprints)\n        );\n\n        foreach ($blueprints as $blueprint => $enabled) {\n            Notification::setSubjectModel(\n                $type = $blueprint::getType(),\n                $blueprint::getSubjectModel()\n            );\n\n            User::addPreference(\n                User::getNotificationPreferenceKey($type, 'alert'),\n                'boolval',\n                in_array('alert', $enabled)\n            );\n\n            if ((new ReflectionClass($blueprint))->implementsInterface(MailableInterface::class)) {\n                User::addPreference(\n                    User::getNotificationPreferenceKey($type, 'email'),\n                    'boolval',\n                    in_array('email', $enabled)\n                );\n            }\n        }\n    }", "label": 2}
{"code": "def find_within(tags, span, pointer)\n      puts \"--#{span}\" if Chronic.debug\n      return span if tags.empty?\n\n      head = tags.shift\n      head.start = (pointer == :future ? span.begin : span.end)\n      h = head.this(:none)\n\n      if span.cover?(h.begin) || span.cover?(h.end)\n        find_within(tags, h, pointer)\n      end\n    end", "label": 4}
{"code": "function (groupId) {\n        server.state.set('groups[' + groupId + ']', []);\n        let hasNonEmptyGroups = false;\n        server.state.get('groups').forEach(function (e) {\n            if (!Utils.isNullOrEmpty(e)) {\n                hasNonEmptyGroups = true;\n            }\n        });\n        if (hasNonEmptyGroups) {\n            log.info('Successfully deleted group:', groupId);\n        } else {\n            server.state.set('groups', []);\n            log.info('Successfully deleted all groups');\n        }\n    }", "label": 3}
{"code": "def _configure_logger(fmt, quiet, level, fpath,\n    pre_hooks, post_hooks, metric_grouping_interval):\n    \"\"\"\n    configures a logger when required write to stderr or a file\n    \"\"\"\n\n    # NOTE not thread safe. Multiple BaseScripts cannot be instantiated concurrently.\n    level = getattr(logging, level.upper())\n\n    global _GLOBAL_LOG_CONFIGURED\n    if _GLOBAL_LOG_CONFIGURED:\n        return\n\n    # since the hooks need to run through structlog, need to wrap them like processors\n    def wrap_hook(fn):\n        @wraps(fn)\n        def processor(logger, method_name, event_dict):\n            fn(event_dict)\n            return event_dict\n\n        return processor\n\n    processors = define_log_processors()\n    processors.extend(\n        [ wrap_hook(h) for h in pre_hooks ]\n    )\n    if metric_grouping_interval:\n        processors.append(metrics_grouping_processor)\n\n    log_renderer = define_log_renderer(fmt, fpath, quiet)\n    stderr_required = (not quiet)\n    pretty_to_stderr = (\n        stderr_required\n        and (\n            fmt == \"pretty\"\n            or (fmt is None and sys.stderr.isatty())\n        )\n    )\n\n    should_inject_pretty_renderer = (\n        pretty_to_stderr\n        and not isinstance(log_renderer, structlog.dev.ConsoleRenderer)\n    )\n    if should_inject_pretty_renderer:\n        stderr_required = False\n        processors.append(StderrConsoleRenderer())\n\n    processors.append(log_renderer)\n    processors.extend(\n        [ wrap_hook(h) for h in post_hooks ]\n    )\n\n    streams = []\n    # we need to use a stream if we are writing to both file and stderr, and both are json\n    if stderr_required:\n        streams.append(sys.stderr)\n\n    if fpath is not None:\n        # TODO handle creating a directory for this log file ?\n        # TODO set mode and encoding appropriately\n        streams.append(open(fpath, 'a'))\n\n    assert len(streams) != 0, \"cannot configure logger for 0 streams\"\n\n    stream = streams[0] if len(streams) == 1 else Stream(*streams)\n    atexit.register(stream.close)\n\n    # a global level struct log config unless otherwise specified.\n    structlog.configure(\n        processors=processors,\n        context_class=dict,\n        logger_factory=LevelLoggerFactory(stream, level=level),\n        wrapper_class=BoundLevelLogger,\n        cache_logger_on_first_use=True,\n    )\n\n    # TODO take care of removing other handlers\n    stdlib_root_log = logging.getLogger()\n    stdlib_root_log.addHandler(StdlibStructlogHandler())\n    stdlib_root_log.setLevel(level)\n\n    _GLOBAL_LOG_CONFIGURED = True", "label": 1}
{"code": "def raw_urlsafe_b64encode(b):\n    '''Base64 encode using URL-safe encoding with padding removed.\n\n    @param b bytes to decode\n    @return bytes decoded\n    '''\n    b = to_bytes(b)\n    b = base64.urlsafe_b64encode(b)\n    b = b.rstrip(b'=')  # strip padding\n    return b", "label": 1}
{"code": "function write(filePath, fileData, options){\n\treturn new Promise((resolve, reject) => {\n\t\tfs.writeFile(filePath, fileData, options, error => {\n\t\t\terror\n\t\t\t\t? reject(error)\n\t\t\t\t: resolve(fileData);\n\t\t});\n\t});\n}", "label": 3}
{"code": "def remove_whitespace(text_string):\n    '''\n    Removes all whitespace found within text_string and returns new string as type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a string or NoneType not be passed as an argument\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        return \" \".join(text_string.split())\n    else:\n        raise InputError(\"none type or string not passed as an argument\")", "label": 1}
{"code": "public static appfwwsdl get(nitro_service service) throws Exception{\n\t\tappfwwsdl obj = new appfwwsdl();\n\t\tappfwwsdl[] response = (appfwwsdl[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "protected ClassDescriptor getClassDescriptor()\r\n    {\r\n        ClassDescriptor cld = (ClassDescriptor) m_classDescriptor.get();\r\n        if(cld == null)\r\n        {\r\n            throw new OJBRuntimeException(\"Requested ClassDescriptor instance was already GC by JVM\");\r\n        }\r\n        return cld;\r\n    }", "label": 0}
{"code": "public function getStreamAsync(string $buffer = ''): \\Generator\n    {\n        list($clazz, $extra) = $this->nextStreams[$this->key--];\n        $obj = new $clazz();\n        if ($obj instanceof ProxyStreamInterface) {\n            $obj->setExtra($extra);\n        }\n        yield $obj->connect($this, $buffer);\n\n        return $obj;\n    }", "label": 2}
{"code": "public function setRegex($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\RegexValidation::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func retry(ctx context.Context, f func() bool, delay time.Duration) error {\n\tif f() {\n\t\treturn nil\n\t}\n\n\tticker := time.NewTicker(delay)\n\terrChan := make(chan error)\n\n\tgo func() {\n\t\tdefer close(errChan)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\terrChan <- ctx.Err()\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\tif f() {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn <-errChan\n}", "label": 5}
{"code": "func typeToString(typ reflect.Type) string {\n\tswitch typ.Kind() {\n\tcase reflect.Bool:\n\t\treturn \"xsd:boolean\"\n\tcase reflect.Int8:\n\t\treturn \"xsd:byte\"\n\tcase reflect.Int16:\n\t\treturn \"xsd:short\"\n\tcase reflect.Int32:\n\t\treturn \"xsd:int\"\n\tcase reflect.Int, reflect.Int64:\n\t\treturn \"xsd:long\"\n\tcase reflect.Uint8:\n\t\treturn \"xsd:unsignedByte\"\n\tcase reflect.Uint16:\n\t\treturn \"xsd:unsignedShort\"\n\tcase reflect.Uint32:\n\t\treturn \"xsd:unsignedInt\"\n\tcase reflect.Uint, reflect.Uint64:\n\t\treturn \"xsd:unsignedLong\"\n\tcase reflect.Float32:\n\t\treturn \"xsd:float\"\n\tcase reflect.Float64:\n\t\treturn \"xsd:double\"\n\tcase reflect.String:\n\t\tname := typ.Name()\n\t\tif name == \"string\" {\n\t\t\treturn \"xsd:string\"\n\t\t}\n\t\treturn name\n\tcase reflect.Struct:\n\t\tif typ == stringToTypeMap[\"xsd:dateTime\"] {\n\t\t\treturn \"xsd:dateTime\"\n\t\t}\n\n\t\t// Expect any other struct to be handled...\n\t\treturn typ.Name()\n\tcase reflect.Slice:\n\t\tif typ.Elem().Kind() == reflect.Uint8 {\n\t\t\treturn \"xsd:base64Binary\"\n\t\t}\n\tcase reflect.Array:\n\t\tif typ.Elem().Kind() == reflect.Uint8 {\n\t\t\treturn \"xsd:base64Binary\"\n\t\t}\n\t}\n\n\tpanic(\"don't know what to do for type: \" + typ.String())\n}", "label": 5}
{"code": "public static void stop(){\r\n    //--Close logger\r\n    isClosed = true; // <- not a thread-safe boolean\r\n    Thread.yield(); //poor man's synchronization attempt (let everything else log that wants to)\r\n    Thread.yield();\r\n    //--Close Tracks\r\n    while(depth > 0){\r\n      depth -= 1;\r\n      //(send signal to handlers)\r\n      handlers.process(null, MessageType.END_TRACK, depth, System.currentTimeMillis());\r\n    }\r\n    //--Shutdown\r\n    handlers.process(null, MessageType.SHUTDOWN, 0, System.currentTimeMillis());\r\n  }", "label": 0}
{"code": "public static sslpolicylabel get(nitro_service service, String labelname) throws Exception{\n\t\tsslpolicylabel obj = new sslpolicylabel();\n\t\tobj.set_labelname(labelname);\n\t\tsslpolicylabel response = (sslpolicylabel) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func OptionExperimental(exp bool) Option {\n\treturn func(c *Config) {\n\t\tlogrus.Debugf(\"Option Experimental: %v\", exp)\n\t\tc.Daemon.Experimental = exp\n\t}\n}", "label": 5}
{"code": "func keyToString(k []byte) string {\n\tif len(k) != lenHash {\n\t\tpanic(fmt.Sprintf(\"bad hash passed to hashToKey: %x\", k))\n\t}\n\treturn fmt.Sprintf(\"%s%x\", hashPrefix, k)[0:lenKey]\n}", "label": 5}
{"code": "def href(self):\n        \"\"\"Return URL of the resource\n\n        :rtype: str\n        \"\"\"\n        url = self.session.base_url + str(self.path)\n        if self.path.is_collection and not self.path.is_root:\n            return url + 's'\n        return url", "label": 1}
{"code": "def error_messages(yard_coverage, error_text)\n      first_message = \"You have a #{yard_coverage}% yard documentation coverage. \"\\\n                      \"#{config['min_coverage_percentage']}% is the minimum required.\"\n\n      # Add the undocumented objects text as error messages\n      messages = [Overcommit::Hook::Message.new(:error, nil, nil, first_message)]\n\n      errors = error_text.strip.split(\"\\n\")\n      errors.each do |undocumented_object|\n        undocumented_object_message, file_info = undocumented_object.split(/:?\\s+/)\n        file_info_match = file_info.match(/^\\(([^:]+):(\\d+)\\)/)\n\n        # In case any compacted error does not follow the format, ignore it\n        if file_info_match\n          file = file_info_match.captures[0]\n          line = file_info_match.captures[1]\n          messages << Overcommit::Hook::Message.new(\n            :error, file, line, \"#{file}:#{line}: #{undocumented_object_message}\"\n          )\n        end\n      end\n      messages\n    end", "label": 4}
{"code": "def validate_dates(prop, value, xpath_map=None):\n    \"\"\" Default validation for Date Types data structure \"\"\"\n\n    if value is not None:\n        validate_type(prop, value, dict)\n\n        date_keys = set(value)\n\n        if date_keys:\n            if DATE_TYPE not in date_keys or DATE_VALUES not in date_keys:\n                if prop in _complex_definitions:\n                    complex_keys = _complex_definitions[prop]\n                else:\n                    complex_keys = _complex_definitions[DATES] if xpath_map is None else xpath_map\n\n                _validation_error(prop, None, value, ('keys: {0}'.format(','.join(complex_keys))))\n\n            date_type = value[DATE_TYPE]\n\n            if date_type not in DATE_TYPES:\n                _validation_error('dates.type', None, date_type, DATE_TYPES)\n\n            date_vals = value[DATE_VALUES]\n\n            validate_type('dates.values', date_vals, list)\n\n            dates_len = len(date_vals)\n\n            if date_type == DATE_TYPE_MISSING and dates_len != 0:\n                _validation_error('len(dates.values)', None, dates_len, 0)\n\n            if date_type == DATE_TYPE_SINGLE and dates_len != 1:\n                _validation_error('len(dates.values)', None, dates_len, 1)\n\n            if date_type == DATE_TYPE_RANGE and dates_len != 2:\n                _validation_error('len(dates.values)', None, dates_len, 2)\n\n            if date_type == DATE_TYPE_MULTIPLE and dates_len < 2:\n                _validation_error('len(dates.values)', None, dates_len, 'at least two')\n\n            for idx, date in enumerate(date_vals):\n                date_key = 'dates.value[' + str(idx) + ']'\n                validate_type(date_key, date, string_types)", "label": 1}
{"code": "protected function updateRouterBindings()\n    {\n        foreach ($this->getRouterBindings() as $key => $binding) {\n            $this->app['api.router.adapter']->getRouter()->bind($key, $binding);\n        }\n    }", "label": 2}
{"code": "func PgIndexByIndexrelid(db XODB, indexrelid pgtypes.Oid) (*PgIndex, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, indexrelid, indrelid, indnatts, indisunique, indisprimary, indisexclusion, indimmediate, indisclustered, indisvalid, indcheckxmin, indisready, indislive, indisreplident, indkey, indcollation, indclass, indoption, indexprs, indpred ` +\n\t\t`FROM pg_catalog.pg_index ` +\n\t\t`WHERE indexrelid = $1`\n\n\t// run query\n\tXOLog(sqlstr, indexrelid)\n\tpi := PgIndex{}\n\n\terr = db.QueryRow(sqlstr, indexrelid).Scan(&pi.Tableoid, &pi.Cmax, &pi.Xmax, &pi.Cmin, &pi.Xmin, &pi.Ctid, &pi.Indexrelid, &pi.Indrelid, &pi.Indnatts, &pi.Indisunique, &pi.Indisprimary, &pi.Indisexclusion, &pi.Indimmediate, &pi.Indisclustered, &pi.Indisvalid, &pi.Indcheckxmin, &pi.Indisready, &pi.Indislive, &pi.Indisreplident, &pi.Indkey, &pi.Indcollation, &pi.Indclass, &pi.Indoption, &pi.Indexprs, &pi.Indpred)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pi, nil\n}", "label": 5}
{"code": "public final void warn(Object pObject)\r\n\t{\r\n\t\tgetLogger().log(FQCN, Level.WARN, pObject, null);\r\n\t}", "label": 0}
{"code": "func (s *Session) RemoveParty(pid ID) bool {\n\tfor i := range s.Parties {\n\t\tif s.Parties[i].ID == pid {\n\t\t\ts.Parties = append(s.Parties[:i], s.Parties[i+1:]...)\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "function(message, signaling_key) {\n        if (signaling_key.byteLength != 52) {\n            throw new Error(\"Got invalid length signaling_key\");\n        }\n        if (message.byteLength < 1 + 16 + 10) {\n            throw new Error(\"Got invalid length message\");\n        }\n        if (message[0] != 1) {\n            throw new Error(\"Got bad version number: \" + message[0]);\n        }\n        var aes_key = signaling_key.slice(0, 32);\n        var mac_key = signaling_key.slice(32, 32 + 20);\n        var iv = message.slice(1, 17);\n        var ciphertext = message.slice(1 + 16, message.byteLength - 10);\n        var ivAndCiphertext = message.slice(0, message.byteLength - 10);\n        var mac = message.slice(message.byteLength - 10, message.byteLength);\n        libsignal.crypto.verifyMAC(ivAndCiphertext, mac_key, mac, 10);\n        return libsignal.crypto.decrypt(aes_key, ciphertext, iv);\n    }", "label": 3}
{"code": "def ellipse(origin_x, origin_y, width, height, arc_start, arc_end)\n      primitive 'ellipse ' + format('%g,%g %g,%g %g,%g',\n                                    origin_x, origin_y, width, height, arc_start, arc_end)\n    end", "label": 4}
{"code": "function getRegularTypeOfObjectLiteral(type) {\n            if (!(type.flags & 16777216 /* FreshObjectLiteral */)) {\n                return type;\n            }\n            var regularType = type.regularType;\n            if (regularType) {\n                return regularType;\n            }\n            var resolved = type;\n            var members = transformTypeOfMembers(type, getRegularTypeOfObjectLiteral);\n            var regularNew = createAnonymousType(resolved.symbol, members, resolved.callSignatures, resolved.constructSignatures, resolved.stringIndexInfo, resolved.numberIndexInfo);\n            regularNew.flags = resolved.flags & ~16777216 /* FreshObjectLiteral */;\n            type.regularType = regularNew;\n            return regularNew;\n        }", "label": 3}
{"code": "func (l *RateLimiter) RegisterRequest(token string) error {\n\tl.Lock()\n\tdefer l.Unlock()\n\n\tbucketSetI, exists := l.rateLimits.Get(token)\n\tvar bucketSet *ratelimit.TokenBucketSet\n\n\tif exists {\n\t\tbucketSet = bucketSetI.(*ratelimit.TokenBucketSet)\n\t\tbucketSet.Update(l.rates)\n\t} else {\n\t\tbucketSet = ratelimit.NewTokenBucketSet(l.rates, l.clock)\n\t\t// We set ttl as 10 times rate period. E.g. if rate is 100 requests/second per client ip\n\t\t// the counters for this ip will expire after 10 seconds of inactivity\n\t\terr := l.rateLimits.Set(token, bucketSet, int(bucketSet.GetMaxPeriod()/time.Second)*10+1)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\tdelay, err := bucketSet.Consume(1)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif delay > 0 {\n\t\treturn &ratelimit.MaxRateError{}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def normalized_scheme\n      return nil unless self.scheme\n      @normalized_scheme ||= begin\n        if self.scheme =~ /^\\s*ssh\\+svn\\s*$/i\n          \"svn+ssh\".dup\n        else\n          Addressable::URI.normalize_component(\n            self.scheme.strip.downcase,\n            Addressable::URI::CharacterClasses::SCHEME\n          )\n        end\n      end\n      # All normalized values should be UTF-8\n      @normalized_scheme.force_encoding(Encoding::UTF_8) if @normalized_scheme\n      @normalized_scheme\n    end", "label": 4}
{"code": "function onClick(instance) {\n    const self = instance;\n    self.wrapperNodes.forEach((n) => {\n      n.addEventListener(ANIMATIONEND, function thisFunction(e) {\n        e.target.classList.remove('bubble');\n        e.target.removeEventListener(ANIMATIONEND, thisFunction);\n      });\n      n.classList.add('bubble');\n    });\n\n    if (tooltip.getCurrentTarget() === self.wrapperNodes[0]) {\n      return;\n    }\n\n    tooltip.createTooltip(self.wrapperNodes[0], self.result.text, false);\n\n    setTimeout(() => {\n      if (tooltip.getCurrentTarget()) {\n        document.addEventListener('click', function thisFunction() {\n          if (tooltip.getCurrentTarget() && tooltip.getCurrentTarget() === self.wrapperNodes[0]) {\n            tooltip.removeTooltip();\n          }\n          document.removeEventListener('click', thisFunction);\n        });\n      }\n    }, 0);\n  }", "label": 3}
{"code": "func isNumber(fl FieldLevel) bool {\n\tswitch fl.Field().Kind() {\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64, reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr, reflect.Float32, reflect.Float64:\n\t\treturn true\n\tdefault:\n\t\treturn numberRegex.MatchString(fl.Field().String())\n\t}\n}", "label": 5}
{"code": "func Colored(val string, color string) string {\n\t// 00 white 01 black 02 blue (navy) 03 green 04 red 05 brown (maroon)\n\t// 06 purple 07 orange (olive) 08 yellow 09 light green (lime)\n\t// 10 teal (a green/blue cyan) 11 light cyan (cyan) (aqua) 12 light blue (royal)\n\t// 13 pink (light purple) (fuchsia) 14 grey 15 light grey (silver)\n\tc := \"01\"\n\tswitch color {\n\tcase \"white\":\n\t\tc = \"00\"\n\tcase \"black\":\n\t\tc = \"01\"\n\tcase \"blue\":\n\t\tc = \"02\"\n\tcase \"green\":\n\t\tc = \"03\"\n\tcase \"red\":\n\t\tc = \"04\"\n\tcase \"brown\":\n\t\tc = \"05\"\n\tcase \"purple\":\n\t\tc = \"06\"\n\tcase \"orange\":\n\t\tc = \"07\"\n\tcase \"yellow\":\n\t\tc = \"08\"\n\tcase \"lime\":\n\t\tc = \"09\"\n\tcase \"teal\":\n\t\tc = \"10\"\n\tcase \"cyan\":\n\t\tc = \"11\"\n\tcase \"lightblue\":\n\t\tc = \"12\"\n\tcase \"pink\":\n\t\tc = \"13\"\n\tcase \"grey\":\n\t\tc = \"14\"\n\tcase \"silver\":\n\t\tc = \"15\"\n\t}\n\n\treturn \"\\x03\" + c + val + \"\\x03\"\n}", "label": 5}
{"code": "function expand(docset, customTags) {\n    docset[\"comment\"] = DocParser.parse(docset[\"comment\"], customTags);\n    docset[\"tagname\"] = DocType.detect(docset[\"comment\"], docset[\"code\"]);\n\n    if (docset[\"tagname\"] == \"class\")\n      return DocExpander.expand(docset);\n    else\n      return docset;\n}", "label": 3}
{"code": "def is_multiline?(text)\n      text && text.length > 1 && text[-1] == MULTILINE_CHAR_VALUE && text[-2] == ?\\s && text !~ BLOCK_WITH_SPACES\n    end", "label": 4}
{"code": "func (f *FkMode) UnmarshalText(text []byte) error {\n\tswitch strings.ToLower(string(text)) {\n\tcase \"smart\", \"default\":\n\t\t*f = FkModeSmart\n\tcase \"parent\":\n\t\t*f = FkModeParent\n\tcase \"field\":\n\t\t*f = FkModeField\n\tcase \"key\":\n\t\t*f = FkModeKey\n\n\tdefault:\n\t\treturn errors.New(\"invalid FkMode\")\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def _qmed_from_area(self):\n        \"\"\"\n        Return QMED estimate based on catchment area.\n\n        TODO: add source of method\n\n        :return: QMED in m\u00b3/s\n        :rtype: float\n        \"\"\"\n        try:\n            return 1.172 * self.catchment.descriptors.dtm_area ** self._area_exponent()  # Area in km\u00b2\n        except (TypeError, KeyError):\n            raise InsufficientDataError(\"Catchment `descriptors` attribute must be set first.\")", "label": 1}
{"code": "function patchHandlebars(Handlebars) {\n  Handlebars.JavaScriptCompiler.prototype.preamble = function() {\n    var out = [];\n\n    if (!this.isChild) {\n      var namespace = this.namespace;\n      // patch for handlebars\n      var copies = [\n        \"helpers = helpers || {};\",\n        \"for (var key in \" + namespace + \".helpers) {\",\n        \"   helpers[key] = helpers[key] || \" + namespace + \".helpers[key];\",\n        \"}\"\n      ].join('\\n');\n      if (this.environment.usePartial) { copies = copies + \" partials = partials || \" + namespace + \".partials;\"; }\n      if (this.options.data) { copies = copies + \" data = data || {};\"; }\n      out.push(copies);\n    } else {\n      out.push('');\n    }\n\n    if (!this.environment.isSimple) {\n      out.push(\", buffer = \" + this.initializeBuffer());\n    } else {\n      out.push(\"\");\n    }\n\n    // track the last context pushed into place to allow skipping the\n    // getContext opcode when it would be a noop\n    this.lastContext = 0;\n    this.source = out;\n  };\n}", "label": 3}
{"code": "public function insertBatch($table, array $dataSet)\n    {\n        $this->enqueue(Operation::OP_INSERT, $table, $dataSet);\n\n        return $this;\n    }", "label": 2}
{"code": "function listen(event, spark) {\n    if ('end' === event) return function end() {\n      if (!spark.streams) return;\n\n      for (var stream in spark.streams) {\n        stream = spark.streams[stream];\n        if (stream.end) stream.end();\n      }\n    };\n\n    if ('readyStateChange' === event) return function change(reason) {\n      if (!spark.streams) return;\n\n      for (var stream in spark.streams) {\n        stream = spark.streams[stream];\n        stream.readyState = spark.readyState;\n        if (stream.emit) emit.call(stream, event, reason);\n      }\n    };\n\n    return function proxy() {\n      if (!spark.streams) return;\n\n      var args = Array.prototype.slice.call(arguments, 0);\n\n      for (var stream in spark.streams) {\n        if (stream.emit) emit.call(stream, [event].concat(args));\n      }\n    };\n  }", "label": 3}
{"code": "func (b *BoxLayout) Resize() {\n\tb.layout()\n\n\t// Now also let the children know we resized.\n\tfor i := range b.cells {\n\t\tb.cells[i].widget.Resize()\n\t}\n\tb.PostEventWidgetResize(b)\n}", "label": 5}
{"code": "func Tickmarks(min, max float64) (list []float64, precision int) {\n\tif max > min {\n\t\tspread := niceNum(max-min, false)\n\t\td := niceNum((spread / 4), true)\n\t\tgraphMin := math.Floor(min/d) * d\n\t\tgraphMax := math.Ceil(max/d) * d\n\t\tprecision = TickmarkPrecision(d)\n\t\tfor x := graphMin; x < graphMax+0.5*d; x += d {\n\t\t\tlist = append(list, x)\n\t\t}\n\t}\n\treturn\n}", "label": 5}
{"code": "func GetTrustedClusterSchema(extensionSchema string) string {\n\tvar trustedClusterSchema string\n\tif extensionSchema == \"\" {\n\t\ttrustedClusterSchema = fmt.Sprintf(TrustedClusterSpecSchemaTemplate, RoleMapSchema, \"\")\n\t} else {\n\t\ttrustedClusterSchema = fmt.Sprintf(TrustedClusterSpecSchemaTemplate, RoleMapSchema, \",\"+extensionSchema)\n\t}\n\treturn fmt.Sprintf(V2SchemaTemplate, MetadataSchema, trustedClusterSchema, DefaultDefinitions)\n}", "label": 5}
{"code": "def calculate_row_format(columns, keys=None):\n    \"\"\"\n    Calculate row format.\n\n    Args:\n        columns (dict): the keys are the column name and the value the max length.\n        keys (list): optional list of keys to order columns as well as to filter for them.\n\n    Returns:\n        str: format for table row\n    \"\"\"\n    row_format = ''\n    if keys is None:\n        keys = columns.keys()\n    else:\n        keys = [key for key in keys if key in columns]\n\n    for key in keys:\n        if len(row_format) > 0:\n            row_format += \"|\"\n        row_format += \"%%(%s)-%ds\" % (key, columns[key])\n\n    return '|' + row_format + '|'", "label": 1}
{"code": "def client(self):\n        \"\"\"The client used in perforce queries\"\"\"\n        if isinstance(self._client, six.string_types):\n            self._client = Client(self._client, self)\n\n        return self._client", "label": 1}
{"code": "public function setResponses($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\AsyncAnnotateFileResponse::class);\n        $this->responses = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function(context, pkg){\n\t\tvar deps = crawl.getDependencyMap(context.loader, pkg, true);\n\n\t\tvar pluginsPromise = crawl.loadPlugins(context, pkg, true, deps, true);\n\t\tvar stealPromise = crawl.loadSteal(context, pkg, true, deps);\n\n\t\treturn Promise.all([pluginsPromise, stealPromise]);\n\t}", "label": 3}
{"code": "def main(ctx, host, password, port, quiet, session_timeout, connect_timeout,\n         username):\n    \"\"\" Manipulate one or more Junos devices.\n\n    Purpose: The main function is the entry point for the jaide tool. Click\n           | handles arguments, commands and options. The parameters passed to\n           | this function are all potential options (required or not) that\n           | must come *before* the command from the group in the command line.\n\n    @param ctx: The click context paramter, for receiving the object dictionary\n              | being manipulated by other previous functions. Needed by any\n              | function with the @click.pass_context decorator.\n    @type ctx: click.Context\n    @param host: The IP(s) or hostname(s) of the devices to connect to.\n    @type host: str\n    @param password: The string password used to connect to the device.\n    @type password: str\n    @param port: The numerical port to establish the connection to. Defauls\n               | to 22.\n    @type port: int\n    @param quiet: An option that the user can set to suppress all output\n                | from jaide.\n    @type quiet: bool\n    @param session_timeout: Sets the session timeout value. A higher value may\n                          | be desired for long running commands, such as\n                          | 'request system snapshot slice alternate'\n    @type session_timeout: int\n    @param connect_timeout: Sets the connection timeout value. This is how\n                          | we'll wait when connecting before classifying\n                          | the device unreachable.\n    @type connect_timeout: int\n    @param username: The string username used to connect to the device.\n    @type useranme: str\n\n    @returns: None. Functions part of click relating to the command group\n            | 'main' do not return anything. Click handles passing context\n            | between the functions and maintaing command order and chaining.\n    \"\"\"\n    # build the list of hosts\n    ctx.obj['hosts'] = [ip for ip in clean_lines(host)]\n    # set the connection parameters\n    ctx.obj['conn'] = {\n        \"username\": username,\n        \"password\": password,\n        \"port\": port,\n        \"session_timeout\": session_timeout,\n        \"connect_timeout\": connect_timeout\n    }\n    if quiet:\n        ctx.obj['out'] = \"quiet\"", "label": 1}
{"code": "def awesome_mongo_mapper_instance(object)\n      return object.inspect if !defined?(::ActiveSupport::OrderedHash)\n      return awesome_object(object) if @options[:raw]\n\n      data = object.keys.keys.sort_by { |k| k }.inject(::ActiveSupport::OrderedHash.new) do |hash, name|\n        hash[name] = object[name]\n        hash\n      end\n\n      # Add in associations\n      if @options[:mongo_mapper][:show_associations]\n        object.associations.each do |name, assoc|\n          data[name.to_s] = if @options[:mongo_mapper][:inline_embedded] and assoc.embeddable?\n                              object.send(name)\n                            else\n                              assoc\n                            end\n        end\n      end\n\n      label = object.to_s\n      label = \"#{colorize('embedded', :assoc)} #{label}\" if object.is_a?(::MongoMapper::EmbeddedDocument)\n\n      \"#{label} \" << awesome_hash(data)\n    end", "label": 4}
{"code": "function getKernelResources(kernelInfo) {\n  return promisify(fs.readdir, [kernelInfo.resourceDir]).then(files => {\n    const kernelJSONIndex = files.indexOf('kernel.json');\n    if (kernelJSONIndex === -1) {\n      throw new Error('kernel.json not found');\n    }\n\n    return promisify(fs.readFile, [path.join(kernelInfo.resourceDir, 'kernel.json')]).then(data => ({\n      name: kernelInfo.name,\n      files: files.map(x => path.join(kernelInfo.resourceDir, x)),\n      resources_dir: kernelInfo.resourceDir, // eslint-disable-line camelcase\n      spec: JSON.parse(data),\n    }));\n  });\n}", "label": 3}
{"code": "function DiscriminateCollection(collection, discriminator, discriminatorsToModel)\n{\n  Class.props( collection,\n  {\n    discriminator: discriminator,\n    discriminatorsToModel: discriminatorsToModel\n  });\n\n  // Original Functions\n  var buildKeyFromInput = collection.buildKeyFromInput;\n  var parseModel = collection.parseModel;\n  var clone = collection.clone;\n  var cloneEmpty = collection.cloneEmpty;\n\n  Class.props( collection,\n  {\n\n    /**\n     * Builds a key from input. Discriminated collections only accept objects as\n     * input - otherwise there's no way to determine the discriminator. If the\n     * discriminator on the input doesn't map to a Rekord instance OR the input\n     * is not an object the input will be returned instead of a model instance.\n     *\n     * @param {modelInput} input -\n     *    The input to create a key for.\n     * @return {Any} -\n     *    The built key or the given input if a key could not be built.\n     */\n    buildKeyFromInput: function(input)\n    {\n      if ( isObject( input ) )\n      {\n        var discriminatedValue = input[ this.discriminator ];\n        var model = this.discriminatorsToModel[ discriminatedValue ];\n\n        if ( model )\n        {\n          return model.Database.keyHandler.buildKeyFromInput( input );\n        }\n      }\n\n      return input;\n    },\n\n    /**\n     * Takes input and returns a model instance. The input is expected to be an\n     * object, any other type will return null.\n     *\n     * @param {modelInput} input -\n     *    The input to parse to a model instance.\n     * @param {Boolean} [remoteData=false] -\n     *    Whether or not the input is coming from a remote source.\n     * @return {Rekord.Model} -\n     *    The model instance parsed or null if none was found.\n     */\n    parseModel: function(input, remoteData)\n    {\n      if ( input instanceof Model )\n      {\n        return input;\n      }\n\n      var discriminatedValue = isValue( input ) ? input[ this.discriminator ] : null;\n      var model = this.discriminatorsToModel[ discriminatedValue ];\n\n      return model ? model.Database.parseModel( input, remoteData ) : null;\n    },\n\n    /**\n     * Returns a clone of this collection.\n     *\n     * @method\n     * @memberof Rekord.Collection#\n     * @return {Rekord.Collection} -\n     *    The reference to a clone collection.\n     */\n    clone: function()\n    {\n      return DiscriminateCollection( clone.apply( this ), discriminator, discriminatorsToModel );\n    },\n\n    /**\n     * Returns an empty clone of this collection.\n     *\n     * @method\n     * @memberof Rekord.Collection#\n     * @return {Rekord.Collection} -\n     *    The reference to a clone collection.\n     */\n    cloneEmpty: function()\n    {\n      return DiscriminateCollection( cloneEmpty.apply( this ), discriminator, discriminatorsToModel );\n    }\n\n  });\n\n  return collection;\n}", "label": 3}
{"code": "func (a *CellView) Draw() {\n\n\tport := a.port\n\tmodel := a.model\n\tport.Fill(' ', a.style)\n\n\tif a.view == nil {\n\t\treturn\n\t}\n\tif model == nil {\n\t\treturn\n\t}\n\tvw, vh := a.view.Size()\n\tfor y := 0; y < vh; y++ {\n\t\tfor x := 0; x < vw; x++ {\n\t\t\ta.view.SetContent(x, y, ' ', nil, a.style)\n\t\t}\n\t}\n\n\tex, ey := model.GetBounds()\n\tvx, vy := port.Size()\n\tif ex < vx {\n\t\tex = vx\n\t}\n\tif ey < vy {\n\t\tey = vy\n\t}\n\n\tcx, cy, en, sh := a.model.GetCursor()\n\tfor y := 0; y < ey; y++ {\n\t\tfor x := 0; x < ex; x++ {\n\t\t\tch, style, comb, wid := model.GetCell(x, y)\n\t\t\tif ch == 0 {\n\t\t\t\tch = ' '\n\t\t\t\tstyle = a.style\n\t\t\t}\n\t\t\tif en && x == cx && y == cy && sh {\n\t\t\t\tstyle = style.Reverse(true)\n\t\t\t}\n\t\t\tport.SetContent(x, y, ch, comb, style)\n\t\t\tx += wid - 1\n\t\t}\n\t}\n}", "label": 5}
{"code": "func (s *APIServer) getRemoteCluster(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tcluster, err := auth.GetRemoteCluster(p.ByName(\"cluster\"))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn rawMessage(services.MarshalRemoteCluster(cluster, services.WithVersion(version), services.PreserveResourceID()))\n}", "label": 5}
{"code": "public function setEndAt($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\Cursor::class);\n        $this->end_at = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static LuaCondition isNull(LuaValue value) {\n        LuaAstExpression expression;\n        if (value instanceof LuaLocal) {\n            expression = new LuaAstLocal(((LuaLocal) value).getName());\n        } else {\n            throw new IllegalArgumentException(\"Unexpected value type: \" + value.getClass().getName());\n        }\n        return new LuaCondition(new LuaAstNot(expression));\n    }", "label": 0}
{"code": "def url_is_project(url, default='not_a_func'):\n    \"\"\"\n    Check if URL is part of the current project's URLs.\n\n    Args:\n        url (str): URL to check.\n        default (callable): used to filter out some URLs attached to function.\n\n    Returns:\n\n    \"\"\"\n    try:\n        u = resolve(url)\n        if u and u.func != default:\n            return True\n    except Resolver404:\n        static_url = settings.STATIC_URL\n        static_url_wd = static_url.lstrip('/')\n        if url.startswith(static_url):\n            url = url[len(static_url):]\n        elif url.startswith(static_url_wd):\n            url = url[len(static_url_wd):]\n        else:\n            return False\n        if finders.find(url):\n            return True\n    return False", "label": 1}
{"code": "public void store(String gavc,\n                      String action,\n                      String commentText,\n                      DbCredential credential,\n                      String entityType) {\n        DbComment comment = new DbComment();\n        comment.setEntityId(gavc);\n        comment.setEntityType(entityType);\n        comment.setDbCommentedBy(credential.getUser());\n        comment.setAction(action);\n\n        if(!commentText.isEmpty()) {\n            comment.setDbCommentText(commentText);\n        }\n\n        comment.setDbCreatedDateTime(new Date());\n\n        repositoryHandler.store(comment);\n    }", "label": 0}
{"code": "function combine(at, shares){\n\tvar setBits, share, x = [], y = [], result = '', idx;\t\n\t\n\tfor(var i=0, len = shares.length; i<len; i++){\n\t\tshare = processShare(shares[i]);\n\t\tif(typeof setBits === 'undefined'){\n\t\t\tsetBits = share['bits'];\n\t\t}else if(share['bits'] !== setBits){\n\t\t\tthrow new Error('Mismatched shares: Different bit settings.')\n\t\t}\n\t\t\n\t\tif(config.bits !== setBits){\n\t\t\tinit(setBits);\n\t\t}\n\t\t\n\t\tif(inArray(x, share['id'])){ // repeated x value?\n\t\t\tcontinue;\n\t\t}\n\t\n\t\tidx = x.push(share['id']) - 1;\n\t\tshare = split(hex2bin(share['value']));\n\t\tfor(var j=0, len2 = share.length; j<len2; j++){\n\t\t\ty[j] = y[j] || [];\n\t\t\ty[j][idx] = share[j];\n\t\t}\n\t}\n\t\n\tfor(var i=0, len=y.length; i<len; i++){\n\t\tresult = padLeft(lagrange(at, x, y[i]).toString(2)) + result;\n\t}\n\n\tif(at===0){// reconstructing the secret\n\t\tvar idx = result.indexOf('1'); //find the first 1\n\t\treturn bin2hex(result.slice(idx+1));\n\t}else{// generating a new share\n\t\treturn bin2hex(result);\n\t}\n}", "label": 3}
{"code": "public static iptunnel get(nitro_service service, String name) throws Exception{\n\t\tiptunnel obj = new iptunnel();\n\t\tobj.set_name(name);\n\t\tiptunnel response = (iptunnel) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function(loader, packageJSON, isRoot){\n\t\tvar config = utils.pkg.config(packageJSON);\n\t\tvar hasConfig = !!config;\n\n\t\t// convert npmIgnore\n\t\tvar npmIgnore = hasConfig && config.npmIgnore;\n\t\tfunction convertToMap(arr) {\n\t\t\tvar npmMap = {};\n\t\t\tfor(var i = 0; i < arr.length; i++) {\n\t\t\t\tnpmMap[arr[i]] = true;\n\t\t\t}\n\t\t\treturn npmMap;\n\t\t}\n\t\tif(npmIgnore && typeof npmIgnore.length === 'number') {\n\t\t\tnpmIgnore = config.npmIgnore = convertToMap(npmIgnore);\n\t\t}\n\t\t// convert npmDependencies\n\t\tvar npmDependencies = hasConfig && config.npmDependencies;\n\t\tif(npmDependencies && typeof npmDependencies.length === \"number\") {\n\t\t\tconfig.npmDependencies = convertToMap(npmDependencies);\n\t\t}\n\t\tnpmIgnore = npmIgnore || {};\n\n\t\tvar deps = {};\n\n\t\taddDeps(packageJSON, packageJSON.peerDependencies || {}, deps,\n\t\t\t\t\"peerDependencies\", {_isPeerDependency: true});\n\n\t\taddDeps(packageJSON, packageJSON.dependencies || {}, deps, \"dependencies\");\n\n\t\tif(isRoot) {\n\t\t\taddDeps(packageJSON, packageJSON.devDependencies || {}, deps,\n\t\t\t\t   \"devDependencies\");\n\t\t}\n\n\t\treturn deps;\n\t}", "label": 3}
{"code": "function _gpfArrayForEachFalsy(array, callback, thisArg) {\n        var result, index = 0, length = array.length;\n        for (; index < length && !result; ++index) {\n            result = callback.call(thisArg, array[index], index, array);\n        }\n        return result;\n    }", "label": 3}
{"code": "func (r *Registry) All(kind string) []mo.Entity {\n\tr.m.Lock()\n\tdefer r.m.Unlock()\n\n\tvar entities []mo.Entity\n\tfor ref, val := range r.objects {\n\t\tif kind == \"\" || ref.Type == kind {\n\t\t\tif e, ok := val.(mo.Entity); ok {\n\t\t\t\tentities = append(entities, e)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn entities\n}", "label": 5}
{"code": "def validate_identifier(self, field):\n        \"\"\"Validate field identifier.\"\"\"\n        if field.data:\n            field.data = field.data.lower()\n            if Community.get(field.data, with_deleted=True):\n                raise validators.ValidationError(\n                    _('The identifier already exists. '\n                      'Please choose a different one.'))", "label": 1}
{"code": "def parse_float attr_name, xpath\n      v = parse_value xpath\n      v = v.to_f if v.respond_to?(:to_f)\n      send(\"#{attr_name}=\", v)\n    end", "label": 4}
{"code": "def _load_data(self, atom_syms, coords, bohrs=True):\n        \"\"\" Internal function for making XYZ object from explicit geom data.\n\n        Parameters\n        ----------\n        atom_syms\n            Squeezes to array of N |str| --\n            Element symbols for the XYZ. Must be valid elements as defined in\n            the keys of :data:`const.atom_num <opan.const.atom_num>`.\n\n        coords\n            Squeezes to array of 3N |npfloat_| castables --\n            Coordinates for the geometry.\n\n        bohrs\n            |bool|, optional --\n            Units of coordinates (default |True|)\n\n        Raises\n        ------\n        ~opan.XYZError\n            (typecode :attr:`~opan.error.XYZError.OVERWRITE`)\n            If :class:`ORCA_XYZ` object has already been initialized.\n\n        ~exceptions.ValueError\n            If atom_syms & coords dimensions are incompatible\n\n        ~exceptions.ValueError\n            If type of `atom_syms` and/or `coords` is invalid\n\n        \"\"\"\n\n        # Imports\n        import numpy as np\n        from .const import atom_num, PHYS\n        from .error import XYZError\n\n        # Gripe if already initialized\n        if 'geoms' in dir(self):\n            raise XYZError(XYZError.OVERWRITE,\n                    \"Cannot overwrite contents of existing OpanXYZ\", \"\")\n        ## end if\n\n        # Check and store dimensions\n        if not len(coords.shape) == 1:\n            raise ValueError(\"Coordinates are not a vector\")\n        ## end if\n        if not len(atom_syms.shape) == 1:\n            raise ValueError(\"Atom symbols are not a simple list\")\n        ## end if\n        if not coords.shape[0] == 3 * atom_syms.shape[0]:\n            raise ValueError(\"len(coords) != 3 * len(atom_syms)\")\n        ## end if\n\n        # Proof the atoms list\n        if not all( (atom_syms[i].upper() in atom_num)\n                                for i in range(atom_syms.shape[0]) ):\n            # Invalid atoms specified\n            raise ValueError(\"Invalid atoms specified: {0}\".format(\n                    [(j, atom_syms[j]) for j in\n                        (i for (i, valid) in\n                            enumerate(map(lambda k: k in atom_num, atom_syms))\n                            if not valid\n                        )\n                    ] ))\n        ## end if\n\n        # Ensure the geometry is all numeric\n        if not all(map(np.isreal, coords)):\n            raise ValueError(\"All coordinates must be real numeric\")\n        ## end if\n\n        # Store the number of atoms. Only one geometry. Standard string\n        #  content for things only relevant to file load.\n        self.num_atoms = atom_syms.shape[0]\n        self.num_geoms = 1\n        self.in_str = self.LOAD_DATA_FLAG\n        self.descs = np.array([self.LOAD_DATA_FLAG])\n        self.XYZ_path = self.LOAD_DATA_FLAG\n\n        # Store the atoms as vector\n        self.atom_syms = list(map(str.upper, list(atom_syms)))\n\n        # Store the single geometry by bracketing with an array\n        self.geoms = [coords / (1.0 if bohrs else PHYS.ANG_PER_BOHR)]", "label": 1}
{"code": "public static base_responses add(nitro_service client, responderaction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tresponderaction addresources[] = new responderaction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new responderaction();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].type = resources[i].type;\n\t\t\t\taddresources[i].target = resources[i].target;\n\t\t\t\taddresources[i].htmlpage = resources[i].htmlpage;\n\t\t\t\taddresources[i].bypasssafetycheck = resources[i].bypasssafetycheck;\n\t\t\t\taddresources[i].comment = resources[i].comment;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def autowidth\n      return if is_formula? || value.nil?\n      if contains_rich_text?\n        string_width('', font_size) + value.autowidth\n      elsif styles.cellXfs[style].alignment && styles.cellXfs[style].alignment.wrap_text\n        max_width = 0\n        value.to_s.split(/\\r?\\n/).each do |line|\n          width = string_width(line, font_size)\n          max_width = width if width > max_width\n        end\n        max_width\n      else\n        string_width(value, font_size)\n      end\n    end", "label": 4}
{"code": "def get_metadata_as_dict(fname):\n    \"\"\" Gets all metadata and puts into dictionary \"\"\"\n    imgdict = {}\n    try:\n        imgdict['filename'] = fname\n        imgdict['size'] = str(os.path.getsize(fname)) \n        imgdict['basename'] = os.path.basename(fname)\n        imgdict['path'] = os.path.dirname(fname)\n        img = Image.open(fname)\n        # get the image's width and height in pixels\n        width, height = img.size\n        imgdict['width'] = str(width)\n        imgdict['height'] = str(height)\n        imgdict['format'] = str(img.format) \n        imgdict['palette'] = str(img.palette)\n        stat = ImageStat.Stat(img)\n         \n        #res = res + q + str(stat.extrema) + q + d\n        imgdict['count'] =  List2String(stat.count, \",\")\n        imgdict['sum'] =  List2String(stat.sum, \",\")\n        imgdict['sum2'] =  List2String(stat.sum2, \",\")\n        imgdict['mean'] =  List2String(stat.mean, \",\") \n        imgdict['median'] =  List2String(stat.median, \",\") \n        imgdict['rms'] =  List2String(stat.rms, \",\") \n        imgdict['var'] =  List2String(stat.var, \",\")\n        imgdict['stddev'] =  List2String(stat.stddev, \",\") \n\n        exif_data = get_exif_data(img)\n        print('exif_data = ', exif_data)\n        (lat, lon) = get_lat_lon(exif_data)\n        print('(lat, lon)', (lat, lon))\n        imgdict['lat'] =  str(lat)\n        imgdict['lon'] =  str(lon)\n    except Exception as ex:\n        print('problem reading image file metadata in ', fname, str(ex))\n        imgdict['lat'] =  'ERROR'\n        imgdict['lon'] =  'ERROR'\n    return imgdict", "label": 1}
{"code": "func (a *Allocator) RequestAddress(poolID string, prefAddress net.IP, opts map[string]string) (*net.IPNet, map[string]string, error) {\n\tlogrus.Debugf(\"RequestAddress(%s, %v, %v)\", poolID, prefAddress, opts)\n\tk := SubnetKey{}\n\tif err := k.FromString(poolID); err != nil {\n\t\treturn nil, nil, types.BadRequestErrorf(\"invalid pool id: %s\", poolID)\n\t}\n\n\tif err := a.refresh(k.AddressSpace); err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\taSpace, err := a.getAddrSpace(k.AddressSpace)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\taSpace.Lock()\n\tp, ok := aSpace.subnets[k]\n\tif !ok {\n\t\taSpace.Unlock()\n\t\treturn nil, nil, types.NotFoundErrorf(\"cannot find address pool for poolID:%s\", poolID)\n\t}\n\n\tif prefAddress != nil && !p.Pool.Contains(prefAddress) {\n\t\taSpace.Unlock()\n\t\treturn nil, nil, ipamapi.ErrIPOutOfRange\n\t}\n\n\tc := p\n\tfor c.Range != nil {\n\t\tk = c.ParentKey\n\t\tc = aSpace.subnets[k]\n\t}\n\taSpace.Unlock()\n\n\tbm, err := a.retrieveBitmask(k, c.Pool)\n\tif err != nil {\n\t\treturn nil, nil, types.InternalErrorf(\"could not find bitmask in datastore for %s on address %v request from pool %s: %v\",\n\t\t\tk.String(), prefAddress, poolID, err)\n\t}\n\t// In order to request for a serial ip address allocation, callers can pass in the option to request\n\t// IP allocation serially or first available IP in the subnet\n\tvar serial bool\n\tif opts != nil {\n\t\tif val, ok := opts[ipamapi.AllocSerialPrefix]; ok {\n\t\t\tserial = (val == \"true\")\n\t\t}\n\t}\n\tip, err := a.getAddress(p.Pool, bm, prefAddress, p.Range, serial)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn &net.IPNet{IP: ip, Mask: p.Pool.Mask}, nil, nil\n}", "label": 5}
{"code": "private static function create_subcommand( $parent, $name, $callable, $reflection ) {\n\t\t$doc_comment = self::get_doc_comment( $reflection );\n\t\t$docparser   = new \\WP_CLI\\DocParser( $doc_comment );\n\n\t\tif ( is_array( $callable ) ) {\n\t\t\tif ( ! $name ) {\n\t\t\t\t$name = $docparser->get_tag( 'subcommand' );\n\t\t\t}\n\n\t\t\tif ( ! $name ) {\n\t\t\t\t$name = $reflection->name;\n\t\t\t}\n\t\t}\n\t\tif ( ! $doc_comment ) {\n\t\t\t\\WP_CLI::debug( null === $doc_comment ? \"Failed to get doc comment for {$name}.\" : \"No doc comment for {$name}.\", 'commandfactory' );\n\t\t}\n\n\t\t$when_invoked = function ( $args, $assoc_args ) use ( $callable ) {\n\t\t\tif ( is_array( $callable ) ) {\n\t\t\t\t$callable[0] = is_object( $callable[0] ) ? $callable[0] : new $callable[0]();\n\t\t\t\tcall_user_func( array( $callable[0], $callable[1] ), $args, $assoc_args );\n\t\t\t} else {\n\t\t\t\tcall_user_func( $callable, $args, $assoc_args );\n\t\t\t}\n\t\t};\n\n\t\treturn new Subcommand( $parent, $name, $docparser, $when_invoked );\n\t}", "label": 2}
{"code": "def available_args(self):\n        \"\"\"Return args that can be used given\n        the current cmd line\n\n        rtype: command.Arg generator\n        \"\"\"\n        used = list(self.used_args)\n        logger.debug('Found used args: %s' % used)\n        for arg in list(self.cmd.args.values()):\n            if (arg.is_multiple or\n                    arg not in used):\n                yield arg\n            elif (type(arg.nargs) is int and\n                    arg.nargs > 1 and\n                    not arg.nargs == used.count(arg)):\n                yield arg", "label": 1}
{"code": "def neto(fastas, algorithm = 'usearch', e = 0.01, bit = 40, length = .65, norm_bit = False):\n    \"\"\"\n    make and split a rbh network\n    \"\"\"\n    thresholds = [e, bit, length, norm_bit]\n    id2desc = get_descriptions(fastas)\n            # get [fasta, description, length] for ORF id\n    id2desc = self_compare(fastas, id2desc, algorithm)\n            # get best possible bit score for each ORF \n            # (comparing with itself) [fasta, description, length, bestbit]\n    hits = compare_genomes(fastas, id2desc, algorithm)\n            # pair wise genome comparisons {genome: {id: [match_type = 'rbh' or 'fbh', scores]}}\n    calc_thresholds(hits, file_name = 'fbh.scores.summary.txt')\n    rbh_network(id2desc, hits, file_name = 'fbh.network.edges.txt')\n    hits, rbh = find_rbh(hits, id2desc)\n            # remove hits that are not reciprocal best blast hits\n    thresholds = calc_thresholds(rbh, 'rbh.scores.summary.txt', thresholds)\n            # print rbh score summary to rbh_score_summary.txt and\n            # calculate normalized bit score cutoff for each pair of\n            # genomes, if desired\n    g = rbh_network(id2desc, rbh, file_name = 'rbh.network.edges.txt')\n    filtered_g, filtered_rbh = rbh_network(id2desc, rbh, 'rbh.filtered.network.edges.txt', thresholds)\n    calc_thresholds(filtered_rbh, file_name = 'rbh.filtered.scores.summary.txt')\n    print_summary(filtered_g, fastas, id2desc, file_name = 'rbh.filtered.network.nodes.txt')\n    print_network_matrix(filtered_g, fastas, id2desc, file_name = 'rbh.filtered.network.matrix.txt')\n    print_genome_matrix(filtered_rbh, fastas, id2desc, file_name = 'rbh.filtered.network.genome_matrix.txt')\n    split_g = split_network(filtered_g, id2desc, file_name = 'rbh.filtered.split.network.edges.txt')\n    print_summary(split_g, fastas, id2desc, file_name = 'rbh.filtered.split.network.nodes.txt')\n    print_network_matrix(split_g, fastas, id2desc, file_name = 'rbh.filtered.split.network.matrix.txt')\n    return split_g", "label": 1}
{"code": "def _configure_logging(self, logger_dict=None):\n        \"\"\"\n        Configures the logging module with a given dictionary, which in most cases was loaded from a configuration\n        file.\n\n        If no dictionary is provided, it falls back to a default configuration.\n\n        See `Python docs\n        <https://docs.python.org/3.5/library/logging.config.html#logging.config.dictConfig>`_ for more information.\n\n        :param logger_dict: dictionary for logger.\n        \"\"\"\n        self.log.debug(\"Configure logging\")\n\n        # Let's be sure, that for our log no handlers are registered anymore\n        for handler in self.log.handlers:\n            self.log.removeHandler(handler)\n        if logger_dict is None:\n            self.log.debug(\"No logger dictionary defined. Doing default logger configuration\")\n            formatter = logging.Formatter(\"%(name)s - %(asctime)s - [%(levelname)s] - %(module)s - %(message)s\")\n            stream_handler = logging.StreamHandler(sys.stdout)\n            stream_handler.setLevel(logging.WARNING)\n            stream_handler.setFormatter(formatter)\n            self.log.addHandler(stream_handler)\n            self.log.setLevel(logging.WARNING)\n        else:\n            self.log.debug(\"Logger dictionary defined. Loading dictConfig for logging\")\n            logging.config.dictConfig(logger_dict)\n            self.log.debug(\"dictConfig loaded\")", "label": 1}
{"code": "public function setMinValue($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Value::class);\n        $this->min_value = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function basic_ack($delivery_tag, $multiple = false)\n    {\n        list($class_id, $method_id, $args) = $this->protocolWriter->basicAck($delivery_tag, $multiple);\n        $this->send_method_frame(array($class_id, $method_id), $args);\n    }", "label": 2}
{"code": "public function terminate($request, $response)\n    {\n        if (! ($request = $this->app['request']) instanceof HttpRequest) {\n            return;\n        }\n\n        // Laravel's route middlewares can be terminated just like application\n        // middleware, so we'll gather all the route middleware here.\n        // On Lumen this will simply be an empty array as it does\n        // not implement terminable route middleware.\n        $middlewares = $this->gatherRouteMiddlewares($request);\n\n        // Because of how middleware is executed on Lumen we'll need to merge in the\n        // application middlewares now so that we can terminate them. Laravel does\n        // not need this as it handles things a little more gracefully so it\n        // can terminate the application ones itself.\n        if (class_exists(Application::class, false)) {\n            $middlewares = array_merge($middlewares, $this->middleware);\n        }\n\n        foreach ($middlewares as $middleware) {\n            if ($middleware instanceof Closure) {\n                continue;\n            }\n\n            list($name, $parameters) = $this->parseMiddleware($middleware);\n\n            $instance = $this->app->make($name);\n\n            if (method_exists($instance, 'terminate')) {\n                $instance->terminate($request, $response);\n            }\n        }\n    }", "label": 2}
{"code": "def spread_value(value: Decimal, spread_p: Decimal) -> Tuple[Decimal, Decimal]:\n    \"\"\"Returns a lower and upper value separated by a spread percentage\"\"\"\n    upper = value * (1 + spread_p)\n    lower = value / (1 + spread_p)\n    return lower, upper", "label": 1}
{"code": "func AuthGroupByName(db XODB, name string) (*AuthGroup, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, name ` +\n\t\t`FROM public.auth_group ` +\n\t\t`WHERE name = $1`\n\n\t// run query\n\tXOLog(sqlstr, name)\n\tag := AuthGroup{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, name).Scan(&ag.ID, &ag.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ag, nil\n}", "label": 5}
{"code": "func NewHostDiscovery(watcher discovery.Watcher) HostDiscovery {\n\treturn &hostDiscovery{watcher: watcher, nodes: mapset.NewSet(), stopChan: make(chan struct{})}\n}", "label": 5}
{"code": "def gw_get(object_dict, name=None, plugin=None):\n    \"\"\"\n    Getter function to retrieve objects from a given object dictionary.\n\n    Used mainly to provide get() inside patterns.\n\n    :param object_dict: objects, which must have 'name' and 'plugin' as attribute\n    :type object_dict: dictionary\n    :param name: name of the object\n    :type name: str\n    :param plugin: plugin name, which registers the object\n    :return: None, single object or dict of objects\n    \"\"\"\n    if plugin is not None:\n        if name is None:\n            object_list = {}\n            for key in object_dict.keys():\n                if object_dict[key].plugin == plugin:\n                    object_list[key] = object_dict[key]\n            return object_list\n        else:\n            if name in object_dict.keys():\n                if object_dict[name].plugin == plugin:\n                    return object_dict[name]\n                else:\n                    return None\n            else:\n                return None\n    else:\n        if name is None:\n            return object_dict\n        else:\n            if name in object_dict.keys():\n                return object_dict[name]\n            else:\n                return None", "label": 1}
{"code": "func (c *CertAuthorityV2) String() string {\n\treturn fmt.Sprintf(\"CA(name=%v, type=%v)\", c.GetClusterName(), c.GetType())\n}", "label": 5}
{"code": "def validate_single_doc(schema, doc)\n      schema = Nokogiri::XML::Schema(File.open(schema))\n      doc = Nokogiri::XML(doc)\n      errors = []\n      schema.validate(doc).each do |error|\n        errors << error\n      end\n      errors\n    end", "label": 4}
{"code": "func (f *File) SetPriority(prio piecePriority) {\n\tf.t.cl.lock()\n\tdefer f.t.cl.unlock()\n\tif prio == f.prio {\n\t\treturn\n\t}\n\tf.prio = prio\n\tf.t.updatePiecePriorities(f.firstPieceIndex(), f.endPieceIndex())\n}", "label": 5}
{"code": "def consumer\n      opaque = Opaque.new\n      config = native_config(opaque)\n\n      if @consumer_rebalance_listener\n        opaque.consumer_rebalance_listener = @consumer_rebalance_listener\n        Rdkafka::Bindings.rd_kafka_conf_set_rebalance_cb(config, Rdkafka::Bindings::RebalanceCallback)\n      end\n\n      kafka = native_kafka(config, :rd_kafka_consumer)\n\n      # Redirect the main queue to the consumer\n      Rdkafka::Bindings.rd_kafka_poll_set_consumer(kafka)\n\n      # Return consumer with Kafka client\n      Rdkafka::Consumer.new(kafka)\n    end", "label": 4}
{"code": "public function disable($name)\n    {\n        $enabled = $this->getEnabled();\n\n        if (($k = array_search($name, $enabled)) === false) {\n            return;\n        }\n\n        $extension = $this->getExtension($name);\n\n        $this->dispatcher->dispatch(new Disabling($extension));\n\n        unset($enabled[$k]);\n\n        $this->setEnabled($enabled);\n\n        $extension->disable($this->app);\n\n        $this->dispatcher->dispatch(new Disabled($extension));\n    }", "label": 2}
{"code": "public static nsacl6_stats get(nitro_service service, String acl6name) throws Exception{\n\t\tnsacl6_stats obj = new nsacl6_stats();\n\t\tobj.set_acl6name(acl6name);\n\t\tnsacl6_stats response = (nsacl6_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def parse_cov(cov_table, scaffold2genome):\n    \"\"\"\n    calculate genome coverage from scaffold coverage table\n    \"\"\"\n    size   = {} # size[genome] = genome size\n    mapped = {} # mapped[genome][sample] = mapped bases\n    # parse coverage files\n    for line in open(cov_table):\n        line = line.strip().split('\\t')\n        if line[0].startswith('#'):\n            samples = line[1:]\n            samples = [i.rsplit('/', 1)[-1].split('.', 1)[0] for i in samples]\n            continue\n        scaffold, length = line[0].split(': ')\n        length = float(length)\n        covs  = [float(i) for i in line[1:]]\n        bases = [c * length for c in covs]\n        if scaffold not in scaffold2genome:\n            continue\n        genome = scaffold2genome[scaffold]\n        if genome not in size:\n            size[genome] = 0\n            mapped[genome] = {sample:0 for sample in samples}\n        # keep track of genome size\n        size[genome] += length\n        # keep track of number of mapped bases\n        for sample, count in zip(samples, bases):\n            mapped[genome][sample] += count\n    # calculate coverage from base counts and genome size\n    coverage = {'genome':[], 'genome size (bp)':[], 'sample':[], 'coverage':[]}\n    for genome, length in size.items():\n        for sample in samples:\n            cov = mapped[genome][sample] / length\n            coverage['genome'].append(genome)\n            coverage['genome size (bp)'].append(length)\n            coverage['sample'].append(sample)\n            coverage['coverage'].append(cov)\n    return pd.DataFrame(coverage)", "label": 1}
{"code": "def summary(processors, metrics, context):\n    \"\"\"Print the summary\"\"\"\n    # display aggregated metric values on language level\n    def display_header(processors, before='', after=''):\n        \"\"\"Display the header for the summary results.\"\"\"\n        print(before, end=' ')\n        for processor in processors:\n            processor.display_header()\n        print(after)\n\n    def display_separator(processors, before='', after=''):\n        \"\"\"Display the header for the summary results.\"\"\"\n        print(before, end=' ')\n        for processor in processors:\n            processor.display_separator()\n        print(after)\n\n    def display_metrics(processors, before='', after='', metrics=[]):\n        \"\"\"Display the header for the summary results.\"\"\"\n        print(before, end=' ')\n        for processor in processors:\n            processor.display_metrics(metrics)\n        print(after)\n\n    summary = {}\n    for m in metrics:\n        lang = metrics[m]['language']\n        has_key = lang in summary\n        if not has_key:\n            summary[lang] = {'file_count': 0, 'language': lang}\n        summary[lang]['file_count'] += 1\n        for i in metrics[m]:\n            if i not in ['sloc', 'comments', 'mccabe']:  # include metrics to be used\n                continue\n            if not has_key:\n                summary[lang][i] = 0\n            summary[lang][i] += metrics[m][i]\n\n    total = {'language': 'Total'}\n    for m in summary:\n        for i in summary[m]:\n            if i == 'language':\n                continue\n            if i not in total:\n                total[i] = 0\n            total[i] += summary[m][i]\n\n    print('Metrics Summary:')\n\n    display_header(processors, 'Files', '')\n    display_separator(processors, '-'*5, '')\n    for k in sorted(summary.keys(), key=str.lower):\n        display_metrics(processors, '%5d' %\n                        summary[k]['file_count'], '', summary[k])\n    display_separator(processors, '-'*5, '')\n    display_metrics(processors, '%5d' % total['file_count'],\n                    '', total)", "label": 1}
{"code": "function include(filename, absolute) {\n            filename = absolute\n                ? filename\n                : __dirname + '/' + filename;\n            var _program  = __program,  // Previous meta program\n                _source   = __source,   // Previous source\n                _filename = __filename, // Previous source file\n                _dirname  = __dirname,  // Previous source directory\n                _indent   = __;         // Previous indentation level\n            var files;\n            if (/(?:^|[^\\\\])\\*/.test(filename)) {\n                files = require(\"glob\").sync(filename, { cwd : __dirname, nosort: true });\n                files.sort(naturalCompare); // Sort these naturally (e.g. int8 < int16)\n            } else {\n                files = [filename];\n            }\n            files.forEach(function(file) {\n                var source = require(\"fs\").readFileSync(file)+\"\";\n                __program = MetaScript.compile(indent(source, __));\n                __source = source;\n                __filename = file;\n                __dirname = dirname(__filename);\n                __runProgram();\n                __program = _program;\n                __source = _source;\n                __filename = _filename;\n                __dirname = _dirname;\n                __ = _indent;\n            });\n        }", "label": 3}
{"code": "def launch(self):\n        \"\"\" launch a file - used for starting html pages \"\"\"\n        #os.system(self.fullname) # gives permission denied seeing it needs to be chmod +x\n        import subprocess\n        try:\n            retcode = subprocess.call(self.fullname, shell=True)\n            if retcode < 0:\n                print(\"Child was terminated by signal\", -retcode, file=sys.stderr)\n                return False\n            else:\n                print(\"Child returned\", retcode, file=sys.stderr)\n                return True\n        except OSError as e:\n            print(\"Execution failed:\", e, file=sys.stderr)\n            return False", "label": 1}
{"code": "public function debugPrint($debugMsg)\n    {\n        if ($this->debug) {\n            if (is_array($debugMsg) || is_object($debugMsg)) {\n                print_r($debugMsg);\n            } else {\n                echo $debugMsg;\n            }\n\n            return true;\n        }\n\n        return false;\n    }", "label": 2}
{"code": "public function setSimpleResponses($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_SimpleResponses::class);\n        $this->writeOneof(7, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *remoteSite) removeInvalidConns() {\n\t// for first pass, do nothing if no connections are marked\n\tcount := 0\n\tfor _, conn := range s.connections {\n\t\tif conn.isInvalid() {\n\t\t\tcount++\n\t\t}\n\t}\n\tif count == 0 {\n\t\treturn\n\t}\n\ts.lastUsed = 0\n\tconns := make([]*remoteConn, 0, len(s.connections)-count)\n\tfor i := range s.connections {\n\t\tif !s.connections[i].isInvalid() {\n\t\t\tconns = append(conns, s.connections[i])\n\t\t} else {\n\t\t\tgo s.connections[i].Close()\n\t\t}\n\t}\n\ts.connections = conns\n}", "label": 5}
{"code": "func ProfileFromFile(filePath string) (*ClientProfile, error) {\n\tbytes, err := ioutil.ReadFile(filePath)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar cp *ClientProfile\n\tif err = yaml.Unmarshal(bytes, &cp); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn cp, nil\n}", "label": 5}
{"code": "function validatefieldCodes() {\n    //Flag for finding a duplicate field code\n    var duplicateFieldCode = false;\n    var invalidFieldCode = false;\n    var fieldCodes = {};\n\n    formData.pages = _.map(formData.pages, function(page) {\n      page.fields = _.map(page.fields, function(field) {\n        var fieldCode = field.fieldCode;\n\n        //If not set, then just return the field.\n        if (fieldCode === null || typeof(fieldCode) === \"undefined\") {\n          return field;\n        }\n\n        //Checking for duplicate field code. It must be a string.\n        if (typeof(fieldCode) === \"string\") {\n          //If the length of the code is 0, then don't save it.\n          if (fieldCode.length === 0) {\n            delete field.fieldCode;\n          } else {\n            //Checking for duplicate field code\n            if (fieldCodes[fieldCode]) {\n              duplicateFieldCode = true;  //Flagging the field as duplicate\n            } else {\n              fieldCodes[fieldCode] = true;\n            }\n          }\n        } else {\n          invalidFieldCode = true; //Field codes must be a string.\n        }\n\n        return field;\n      });\n\n      return page;\n    });\n\n    if (duplicateFieldCode) {\n      return new Error(\"Duplicate Field Codes Detected. Field Codes Must Be Unique In A Form.\");\n    }\n\n    if (invalidFieldCode) {\n      return new Error(\"Invalid Field Code. Field Codes Must Be A String.\");\n    }\n\n    //All valid. can proceed to saving the form.\n    return undefined;\n  }", "label": 3}
{"code": "def vanity_converted(phone)\n      return phone unless Phonelib.vanity_conversion\n\n      (phone || '').gsub(cr('[a-zA-Z]')) do |c|\n        c.upcase!\n        # subtract \"A\"\n        n = (c.ord - 65) / 3\n        # account for #7 & #9 which have 4 chars\n        n -= 1 if c.match(Core::VANITY_4_LETTERS_KEYS_REGEX)\n        (n + 2).to_s\n      end\n    end", "label": 4}
{"code": "function addComment(form) {\n    var node_id = form.find('input[name=\"node\"]').val();\n    var parent_id = form.find('input[name=\"parent\"]').val();\n    var text = form.find('textarea[name=\"comment\"]').val();\n    var proposal = form.find('textarea[name=\"proposal\"]').val();\n\n    if (text == '') {\n      showError('Please enter a comment.');\n      return;\n    }\n\n    // Disable the form that is being submitted.\n    form.find('textarea,input').attr('disabled', 'disabled');\n\n    // Send the comment to the server.\n    $.ajax({\n      type: \"POST\",\n      url: opts.addCommentURL,\n      dataType: 'json',\n      data: {\n        node: node_id,\n        parent: parent_id,\n        text: text,\n        proposal: proposal\n      },\n      success: function(data, textStatus, error) {\n        // Reset the form.\n        if (node_id) {\n          hideProposeChange(node_id);\n        }\n        form.find('textarea')\n          .val('')\n          .add(form.find('input'))\n          .removeAttr('disabled');\n\tvar ul = $('#cl' + (node_id || parent_id));\n        if (ul.data('empty')) {\n          $(ul).empty();\n          ul.data('empty', false);\n        }\n        insertComment(data.comment);\n        var ao = $('#ao' + node_id);\n        ao.find('img').attr({'src': opts.commentBrightImage});\n        if (node_id) {\n          // if this was a \"root\" comment, remove the commenting box\n          // (the user can get it back by reopening the comment popup)\n          $('#ca' + node_id).slideUp();\n        }\n      },\n      error: function(request, textStatus, error) {\n        form.find('textarea,input').removeAttr('disabled');\n        showError('Oops, there was a problem adding the comment.');\n      }\n    });\n  }", "label": 3}
{"code": "func (c *Client) GetAuthServers() ([]services.Server, error) {\n\tout, err := c.Get(c.Endpoint(\"authservers\"), url.Values{})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar items []json.RawMessage\n\tif err := json.Unmarshal(out.Bytes(), &items); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tre := make([]services.Server, len(items))\n\tfor i, raw := range items {\n\t\tserver, err := services.GetServerMarshaler().UnmarshalServer(raw, services.KindAuthServer, services.SkipValidation())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tre[i] = server\n\t}\n\treturn re, nil\n}", "label": 5}
{"code": "def get_booster_stats(ctx, currency):\n    \"\"\"Prints out price stats for booster packs available in Steam user inventory.\"\"\"\n\n    username = ctx.obj['username']\n\n    inventory = User(username)._get_inventory_raw()\n    boosters = {}\n    for item in inventory['rgDescriptions'].values():\n\n        is_booster = False\n        tags = item['tags']\n        for tag in tags:\n            if tag['internal_name'] == TAG_ITEM_CLASS_BOOSTER:\n                is_booster = True\n                break\n\n        if not is_booster:\n            continue\n\n        appid = item['market_fee_app']\n        title = item['name']\n\n        boosters[appid] = title\n\n    if not boosters:\n        click.secho('User `%s` has no booster packs' % username, fg='red', err=True)\n        return\n\n    for appid, title in boosters.items():\n        click.secho('Found booster: `%s`' % title, fg='blue')\n        print_card_prices(appid, currency)", "label": 1}
{"code": "public function seekToTime(Timestamp $timestamp)\n    {\n        return $this->connection->seek([\n            'subscription' => $this->name,\n            'time' => $timestamp->formatAsString()\n        ]);\n    }", "label": 2}
{"code": "public function validateAuthorizationRequest(ServerRequestInterface $request)\n    {\n        foreach ($this->enabledGrantTypes as $grantType) {\n            if ($grantType->canRespondToAuthorizationRequest($request)) {\n                return $grantType->validateAuthorizationRequest($request);\n            }\n        }\n\n        throw OAuthServerException::unsupportedGrantType();\n    }", "label": 2}
{"code": "def download_users(id)\n      doc = permissions_doc(id)\n      return [] if doc.nil?\n      users = Array(doc[self.class.read_user_field]) + Array(doc[self.class.edit_user_field])\n      Rails.logger.debug(\"[CANCAN] download_users: #{users.inspect}\")\n      users\n    end", "label": 4}
{"code": "def set_tile(self, row, col, value):\n        \"\"\"\n        Set the tile at position row, col to have the given value.\n        \"\"\"   \n        #print('set_tile: y=', row, 'x=', col)\n        if col < 0:\n            print(\"ERROR - x less than zero\", col)\n            col = 0\n            #return\n            \n        if col > self.grid_width - 1 :\n            print(\"ERROR - x larger than grid\", col)\n            col = self.grid_width - 1\n            #return\n            \n        if row < 0:\n            print(\"ERROR - y less than zero\", row)\n            row = 0\n            #return\n            \n        if row > self.grid_height - 1:\n            print(\"ERROR - y larger than grid\", row)\n            row = self.grid_height - 1\n\n        self.grid[row][col] = value", "label": 1}
{"code": "func (req *GenerateTokenRequest) CheckAndSetDefaults() error {\n\tfor _, role := range req.Roles {\n\t\tif err := role.Check(); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\tif req.TTL == 0 {\n\t\treq.TTL = defaults.ProvisioningTokenTTL\n\t}\n\tif req.Token == \"\" {\n\t\ttoken, err := utils.CryptoRandomHex(TokenLenBytes)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\treq.Token = token\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func OptionKVProvider(provider string) Option {\n\treturn func(c *Config) {\n\t\tlogrus.Debugf(\"Option OptionKVProvider: %s\", provider)\n\t\tif _, ok := c.Scopes[datastore.GlobalScope]; !ok {\n\t\t\tc.Scopes[datastore.GlobalScope] = &datastore.ScopeCfg{}\n\t\t}\n\t\tc.Scopes[datastore.GlobalScope].Client.Provider = strings.TrimSpace(provider)\n\t}\n}", "label": 5}
{"code": "func (mi *MetaInfo) UpvertedAnnounceList() AnnounceList {\n\tif mi.AnnounceList.OverridesAnnounce(mi.Announce) {\n\t\treturn mi.AnnounceList\n\t}\n\tif mi.Announce != \"\" {\n\t\treturn [][]string{[]string{mi.Announce}}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func NewMockMath(ctrl *gomock.Controller) *MockMath {\n\tmock := &MockMath{ctrl: ctrl}\n\tmock.recorder = &MockMathMockRecorder{mock}\n\treturn mock\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, nsxmlnamespace resource) throws Exception {\n\t\tnsxmlnamespace addresource = new nsxmlnamespace();\n\t\taddresource.prefix = resource.prefix;\n\t\taddresource.Namespace = resource.Namespace;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function rewriteDockerCompose(compose) {\n  const services = compose.services;\n  if (!services) {\n    return compose;\n  }\n  const host = services._host;\n  delete services._host;\n  Object.keys(services).forEach((k) => {\n    if (!isHelperContainer(k)) {\n      mergeWith(services[k], host);\n    }\n  });\n  return compose;\n}", "label": 3}
{"code": "public function setSeverity($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Logging\\Type\\LogSeverity::class);\n        $this->severity = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setProfileEvent($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\ProfileEvent::class);\n        $this->writeOneof(6, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (m HostVsanInternalSystem) QueryVsanObjectUuidsByFilter(ctx context.Context, uuids []string, limit int32, version int32) ([]string, error) {\n\treq := types.QueryVsanObjectUuidsByFilter{\n\t\tThis:    m.Reference(),\n\t\tUuids:   uuids,\n\t\tLimit:   &limit,\n\t\tVersion: version,\n\t}\n\n\tres, err := methods.QueryVsanObjectUuidsByFilter(ctx, m.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn res.Returnval, nil\n}", "label": 5}
{"code": "func (p *PortBinding) String() string {\n\tret := fmt.Sprintf(\"%s/\", p.Proto)\n\tif p.IP != nil {\n\t\tret += p.IP.String()\n\t}\n\tret = fmt.Sprintf(\"%s:%d/\", ret, p.Port)\n\tif p.HostIP != nil {\n\t\tret += p.HostIP.String()\n\t}\n\tret = fmt.Sprintf(\"%s:%d\", ret, p.HostPort)\n\treturn ret\n}", "label": 5}
{"code": "def partial_path(object, view)\n        object = object.to_model if object.respond_to?(:to_model)\n\n        path = if object.respond_to?(:to_partial_path)\n          object.to_partial_path\n        else\n          raise ArgumentError.new(\"'#{object.inspect}' is not an ActiveModel-compatible object. It must implement :to_partial_path.\")\n        end\n\n        if view.prefix_partial_path_with_controller_namespace\n          prefixed_partial_names[path] ||= merge_prefix_into_object_path(@context_prefix, path.dup)\n        else\n          path\n        end\n      end", "label": 4}
{"code": "def visit_tag(node)\n      return unless enabled?\n\n      visit_script(node) ||\n        if node.parsed_attributes.contains_instance_variables?\n          record_lint(node, \"Avoid using instance variables in #{file_types} views\")\n        end\n    end", "label": 4}
{"code": "func (r *DrvRegistry) WalkDrivers(dfn DriverWalkFunc) {\n\ttype driverVal struct {\n\t\tname string\n\t\tdata *driverData\n\t}\n\n\tr.Lock()\n\tdvl := make([]driverVal, 0, len(r.drivers))\n\tfor k, v := range r.drivers {\n\t\tdvl = append(dvl, driverVal{name: k, data: v})\n\t}\n\tr.Unlock()\n\n\tfor _, dv := range dvl {\n\t\tif dfn(dv.name, dv.data.driver, dv.data.capability) {\n\t\t\tbreak\n\t\t}\n\t}\n}", "label": 5}
{"code": "def delete(self):\n        \"\"\"Reverts all files in this changelist then deletes the changelist from perforce\"\"\"\n        try:\n            self.revert()\n        except errors.ChangelistError:\n            pass\n\n        self._connection.run(['change', '-d', str(self._change)])", "label": 1}
{"code": "public static systemdatasource get(nitro_service service) throws Exception{\n\t\tsystemdatasource obj = new systemdatasource();\n\t\tsystemdatasource[] response = (systemdatasource[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public function setColumns($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Bigtable\\V2\\Column::class);\n        $this->columns = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function(client, relayServer, id) {\n  this.client = client;\n  this.relayServer = relayServer;\n  this.id = id;\n\n  debug(\"\" + id + \": start player\");\n\n  var addPlayerToGame = function(data) {\n    var game = this.relayServer.addPlayerToGame(this, data.gameId, data.data);\n    if (!game) {\n      // TODO: Make this URL set from some global so we can set it some place else.\n      debug(\"game does not exist:\", data.gameId);\n      this.disconnect();\n    } else {\n      this.setGame(game);\n    }\n  }.bind(this);\n\n  this.setGame = function(game) {\n    this.game = game;\n  }.bind(this);\n\n  var assignAsServerForGame = function(data) {\n    this.client.on('message', undefined);\n    this.client.on('disconnect', undefined);\n    this.relayServer.assignAsClientForGame(data, this.client);\n  }.bind(this);\n\n  var passMessageFromPlayerToGame = function(data) {\n    if (!this.game) {\n      console.warn(\"player \" + this.id + \" has no game\");\n      return;\n    }\n    this.game.send(this, {\n      cmd: 'update',\n      id: this.id,\n      data: data,\n    });\n  }.bind(this);\n\n  var messageHandlers = {\n    'join':   addPlayerToGame,\n    'server': assignAsServerForGame,\n    'update': passMessageFromPlayerToGame,\n  };\n\n  var onMessage = function(message) {\n    var cmd = message.cmd;\n    var handler = messageHandlers[cmd];\n    if (!handler) {\n      console.error(\"unknown player message: \" + cmd);\n      return;\n    }\n\n    handler(message.data);\n  };\n\n  var onDisconnect = function() {\n    debug(\"\" + this.id + \": disconnected\");\n    if (this.game) {\n      this.game.removePlayer(this);\n    }\n    this.disconnect();\n  }.bind(this);\n\n  client.on('message', onMessage);\n  client.on('disconnect', onDisconnect);\n}", "label": 3}
{"code": "function stripPathElements(filePath, nelements, from) {\n  if (!nelements || nelements <= 0) return filePath;\n  from = from || 'start';\n  filePath = filePath.replace(/\\/+$/, '');\n  let splitPath = split(filePath);\n  if (from === 'start' && path.isAbsolute(filePath) && splitPath[0] === '/') splitPath = splitPath.slice(1);\n  let start = 0;\n  let end = splitPath.length;\n  if (from === 'start') {\n    start = nelements;\n    end = splitPath.length;\n  } else {\n    start = 0;\n    end = splitPath.length - nelements;\n  }\n  return join(splitPath.slice(start, end));\n}", "label": 3}
{"code": "function _loadUserFromToken(){\n    return BB\n        .bind(this)\n        .then(function() {\n            return grasshopper.request(this.token).users.current();\n        })\n        .then(function(user){\n            this.user = user;\n        });\n}", "label": 3}
{"code": "public static base_response unset(nitro_service client, protocolhttpband resource, String[] args) throws Exception{\n\t\tprotocolhttpband unsetresource = new protocolhttpband();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def history_ids(amount, before_id = nil, after_id = nil, around_id = nil)\n      logs = API::Channel.messages(@bot.token, @id, amount, before_id, after_id, around_id)\n      JSON.parse(logs).map { |message| message['id'].to_i }\n    end", "label": 4}
{"code": "public PreparedStatement getSelectByPKStatement(ClassDescriptor cds) throws PersistenceBrokerSQLException, PersistenceBrokerException\r\n    {\r\n        try\r\n        {\r\n            return cds.getStatementsForClass(m_conMan).getSelectByPKStmt(m_conMan.getConnection());\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            throw new PersistenceBrokerSQLException(\"Could not build statement ask for\", e);\r\n        }\r\n        catch (LookupException e)\r\n        {\r\n            throw new PersistenceBrokerException(\"Used ConnectionManager instance could not obtain a connection\", e);\r\n        }\r\n    }", "label": 0}
{"code": "def compare_seqs(seqs):\n    \"\"\"\n    compare pairs of sequences\n    \"\"\"\n    A, B, ignore_gaps = seqs\n    a, b = A[1], B[1] # actual sequences\n    if len(a) != len(b):\n        print('# reads are not the same length', file=sys.stderr)\n        exit()\n    if ignore_gaps is True:\n        pident = calc_pident_ignore_gaps(a, b)\n    else:\n        pident = calc_pident(a, b)\n    return A[0], B[0], pident", "label": 1}
{"code": "func (c *Manager) DeleteCategory(ctx context.Context, category *Category) error {\n\turl := internal.URL(c, internal.CategoryPath).WithID(category.ID)\n\treturn c.Do(ctx, url.Request(http.MethodDelete), nil)\n}", "label": 5}
{"code": "def modified_files\n      unless @modified_files\n        currently_staged = Overcommit::GitRepo.modified_files(staged: true)\n        @modified_files = currently_staged\n\n        # Include files modified in last commit if amending\n        if amendment?\n          subcmd = 'show --format=%n'\n          previously_modified = Overcommit::GitRepo.modified_files(subcmd: subcmd)\n          @modified_files |= filter_modified_files(previously_modified)\n        end\n      end\n      @modified_files\n    end", "label": 4}
{"code": "private function peekBeyondClosingParenthesis($resetPeek = true)\n    {\n        $token        = $this->lexer->peek();\n        $numUnmatched = 1;\n\n        while ($numUnmatched > 0 && $token !== null) {\n            switch ($token['type']) {\n                case Lexer::T_OPEN_PARENTHESIS:\n                    ++$numUnmatched;\n                    break;\n\n                case Lexer::T_CLOSE_PARENTHESIS:\n                    --$numUnmatched;\n                    break;\n\n                default:\n                    // Do nothing\n            }\n\n            $token = $this->lexer->peek();\n        }\n\n        if ($resetPeek) {\n            $this->lexer->resetPeek();\n        }\n\n        return $token;\n    }", "label": 2}
{"code": "func (l *ConnectionsLimiter) ReleaseConnection(token string) {\n\n\tl.Lock()\n\tdefer l.Unlock()\n\n\tif l.maxConnections == 0 {\n\t\treturn\n\t}\n\n\tnumberOfConnections, exists := l.connections[token]\n\tif !exists {\n\t\tlog.Errorf(\"Trying to set negative number of connections\")\n\t} else {\n\t\tif numberOfConnections <= 1 {\n\t\t\tdelete(l.connections, token)\n\t\t} else {\n\t\t\tl.connections[token] = numberOfConnections - 1\n\t\t}\n\t}\n}", "label": 5}
{"code": "protected ValueContainer[] getKeyValues(PersistenceBroker broker, ClassDescriptor cld, Object obj) throws PersistenceBrokerException\r\n    {\r\n        return broker.serviceBrokerHelper().getKeyValues(cld, obj);\r\n    }", "label": 0}
{"code": "function renderColorScaleToCanvas(name, canvas) {\n  /* eslint-disable no-param-reassign */\n  const csDef = colorscales[name];\n  canvas.height = 1;\n  const ctx = canvas.getContext('2d');\n\n  if (Object.prototype.toString.call(csDef) === '[object Object]') {\n    canvas.width = 256;\n    const gradient = ctx.createLinearGradient(0, 0, 256, 1);\n\n    for (let i = 0; i < csDef.colors.length; ++i) {\n      gradient.addColorStop(csDef.positions[i], csDef.colors[i]);\n    }\n    ctx.fillStyle = gradient;\n    ctx.fillRect(0, 0, 256, 1);\n  } else if (Object.prototype.toString.call(csDef) === '[object Uint8Array]') {\n    canvas.width = 256;\n    const imgData = ctx.createImageData(256, 1);\n    imgData.data.set(csDef);\n    ctx.putImageData(imgData, 0, 0);\n  } else {\n    throw new Error('Color scale not defined.');\n  }\n  /* eslint-enable no-param-reassign */\n}", "label": 3}
{"code": "public function setSpoof($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Vision\\V1\\Likelihood::class);\n        $this->spoof = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private function getLocationConstraintMiddleware()\n    {\n        $region = $this->getRegion();\n        return static function (callable $handler) use ($region) {\n            return function (Command $command, $request = null) use ($handler, $region) {\n                if ($command->getName() === 'CreateBucket') {\n                    $locationConstraint = isset($command['CreateBucketConfiguration']['LocationConstraint'])\n                        ? $command['CreateBucketConfiguration']['LocationConstraint']\n                        : null;\n\n                    if ($locationConstraint === 'us-east-1') {\n                        unset($command['CreateBucketConfiguration']);\n                    } elseif ('us-east-1' !== $region && empty($locationConstraint)) {\n                        $command['CreateBucketConfiguration'] = ['LocationConstraint' => $region];\n                    }\n                }\n\n                return $handler($command, $request);\n            };\n        };\n    }", "label": 2}
{"code": "func newBpsLoop(dst *uint64) SinkFunc {\n\tfn := func() chan<- Report {\n\t\tsink := make(chan Report)\n\t\tgo bpsLoop(sink, dst)\n\t\treturn sink\n\t}\n\n\treturn fn\n}", "label": 5}
{"code": "def read_filepath(filepath, encoding='utf-8'):\n    \"\"\"Returns the text content of `filepath`\"\"\"\n    with codecs.open(filepath, 'r', encoding=encoding) as fo:\n        return fo.read()", "label": 1}
{"code": "static SortedSet<String> createStatsItems(String statsType)\n      throws IOException {\n    SortedSet<String> statsItems = new TreeSet<>();\n    SortedSet<String> functionItems = new TreeSet<>();\n    if (statsType != null) {\n      Matcher m = fpStatsItems.matcher(statsType.trim());\n      while (m.find()) {\n        String tmpStatsItem = m.group(2).trim();\n        if (STATS_TYPES.contains(tmpStatsItem)) {\n          statsItems.add(tmpStatsItem);\n        } else if (tmpStatsItem.equals(STATS_TYPE_ALL)) {\n          for (String type : STATS_TYPES) {\n            statsItems.add(type);\n          }\n        } else if (STATS_FUNCTIONS.contains(tmpStatsItem)) {\n          if (m.group(3) == null) {\n            throw new IOException(\"'\" + tmpStatsItem + \"' should be called as '\"\n                + tmpStatsItem + \"()' with an optional argument\");\n          } else {\n            functionItems.add(m.group(1).trim());\n          }\n        } else {\n          throw new IOException(\"unknown statsType '\" + tmpStatsItem + \"'\");\n        }\n      }\n    }\n    if (statsItems.size() == 0 && functionItems.size() == 0) {\n      statsItems.add(STATS_TYPE_SUM);\n      statsItems.add(STATS_TYPE_N);\n      statsItems.add(STATS_TYPE_MEAN);\n    }\n    if (functionItems.size() > 0) {\n      statsItems.addAll(functionItems);\n    }\n    return statsItems;\n  }", "label": 0}
{"code": "function getTimestamps() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tvar trans = db.transaction(['save'], \"read\"),\n\t\t\t\t\t\tstore = trans.objectStore('save'),\n\t\t\t\t\t\trequest = store.getAll();\n\t\t\t\t\t\trequest.onsuccess = function (e) {\n\t\t\t\t\t\t\tvar i = 0, a = event.target.result, l = a.length;\n\t\t\t\t\t\t\tfor (; i < l; i++) {\n\t\t\t\t\t\t\t\ttimestamps[a[i].key] = a[i].timestamp;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\t\t\t\t\tcatch (e) {\n\t\t\t\t\t}\n\t\t\t\t}", "label": 3}
{"code": "def client\n      @client ||= ::OAuth2::Client.new(client_id, client_secret,\n        {\n          :site          => current_options.fetch(:site) { Github.site },\n          :authorize_url => 'login/oauth/authorize',\n          :token_url     => 'login/oauth/access_token',\n          :ssl           => { :verify => false }\n        }\n      )\n    end", "label": 4}
{"code": "function _reduce(accumulator, iterable, initializer) {\n\n  for (let item of iterable) {\n    initializer = accumulator(initializer, item);\n  }\n\n  return initializer;\n}", "label": 3}
{"code": "func Tee(s1, s2 Sinker) Sinker {\n\tfn := func() chan<- Report {\n\t\td1 := s1.Sink()\n\t\td2 := s2.Sink()\n\t\tu := make(chan Report)\n\t\tgo tee(u, d1, d2)\n\t\treturn u\n\t}\n\n\treturn SinkFunc(fn)\n}", "label": 5}
{"code": "function addAdminFieldToSubmission(field) {\n    //Full field object is used in the return as existing fields are populated already.\n    var subObject = {\n      fieldId : field,\n      fieldValues: []\n    };\n\n    submission.formFields.push(subObject);\n  }", "label": 3}
{"code": "public static base_response delete(nitro_service client, String jsoncontenttypevalue) throws Exception {\n\t\tappfwjsoncontenttype deleteresource = new appfwjsoncontenttype();\n\t\tdeleteresource.jsoncontenttypevalue = jsoncontenttypevalue;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "func (m *EventManager) formatMessage(event types.BaseEvent) {\n\tid := reflect.ValueOf(event).Elem().Type().Name()\n\te := event.GetEvent()\n\n\tt, ok := m.templates[id]\n\tif !ok {\n\t\tfor _, info := range m.Description.EventInfo {\n\t\t\tif info.Key == id {\n\t\t\t\tt = template.Must(template.New(id).Parse(info.FullFormat))\n\t\t\t\tm.templates[id] = t\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif t != nil {\n\t\tvar buf bytes.Buffer\n\t\tif err := t.Execute(&buf, event); err != nil {\n\t\t\tlog.Print(err)\n\t\t}\n\t\te.FullFormattedMessage = buf.String()\n\t}\n\n\tif logEvents {\n\t\tlog.Printf(\"[%s] %s\", id, e.FullFormattedMessage)\n\t}\n}", "label": 5}
{"code": "def rstrip!\n      if capture_position.nil?\n        buffer.rstrip!\n        return\n      end\n\n      buffer << buffer.slice!(capture_position..-1).rstrip\n    end", "label": 4}
{"code": "func UnmarshalLicense(bytes []byte) (License, error) {\n\tif len(bytes) == 0 {\n\t\treturn nil, trace.BadParameter(\"missing resource data\")\n\t}\n\n\tschema := fmt.Sprintf(V2SchemaTemplate, MetadataSchema, LicenseSpecV3Template, DefaultDefinitions)\n\n\tvar license LicenseV3\n\terr := utils.UnmarshalWithSchema(schema, &license, bytes)\n\tif err != nil {\n\t\treturn nil, trace.BadParameter(err.Error())\n\t}\n\n\tif license.Version != V3 {\n\t\treturn nil, trace.BadParameter(\"unsupported version %v, expected version %v\", license.Version, V3)\n\t}\n\n\tif err := license.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &license, nil\n}", "label": 5}
{"code": "function (upload) {\n\n\t\t\t\t\t\tif (!upload || !upload.path || !upload.name || !upload.size) {\n\t\t\t\t\t\t\tLOG.error('upload object incomplete:', l_name);\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// record basic file info\n\t\t\t\t\t\tvar arr = upload.path.split('/');\n\t\t\t\t\t\tvar upload_name = arr[arr.length-1];\n\t\t\t\t\t\tvar filename = (preserve_name ? upload.name : upload_name); \n\t\t\t\t\t\tLOG.warn(\"The file \" + upload.name + \" was uploaded as: \" + filename + \". size: \" + upload.size, l_name);\n\t\t\t\t\t\tuploaded.push({name: filename, size: upload.size, type: upload.type});\t\t\t\t\t\t\n\n\t\t\t\t\t\t// check if we might need to re-name\n\t\t\t\t\t\t// default is to rename (preserve upload file names)\n\t\t\t\t\t\tif (preserve_name === false) {\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tvar new_name = SR.path.resolve(form.uploadDir, upload.name);\n\t\t\t\t\t\tSR.fs.rename(upload.path, new_name, function (err) {\n\t\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\t\treturn LOG.error('rename fail: ' + new_name, l_name);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tLOG.warn(\"File \" + upload_name + \" renamed as: \" + upload.name + \" . size: \" + upload.size, l_name);\t\t\t\t\t\t\t\n\t\t\t\t\t\t});\n\t\t\t\t\t}", "label": 3}
{"code": "function(next) {\n           logger.log(\"DeregisterImage:\", images);\n           if (shell.isArg(\"-dry-run\", options)) return next();\n           lib.forEachSeries(images, function(img, next2) {\n               aws.ec2DeregisterImage(img.imageId, { snapshots: 1 }, next2);\n           }, next);\n       }", "label": 3}
{"code": "function _gpfInterfacesPromisify(interfaceSpecifier) {\n        return function (object) {\n            var iInterfaceImpl = _gpfInterfaceQuery(interfaceSpecifier, object);\n            if (!iInterfaceImpl) {\n                gpf.Error.interfaceExpected({ name: _gpfGetFunctionName(interfaceSpecifier) });\n            }\n            return _gpfInterfacesWrap(iInterfaceImpl, interfaceSpecifier, Promise.resolve());\n        };\n    }", "label": 3}
{"code": "public function addStackFrame($stackFrameData)\n    {\n        $stackFrameData += [\n            'function' => '',\n            'locals' => []\n        ];\n\n        $sf = new StackFrame(\n            $stackFrameData['function'],\n            new SourceLocation($stackFrameData['filename'], $stackFrameData['line'])\n        );\n\n        foreach ($stackFrameData['locals'] as $local) {\n            if ($this->variableTable->isFull()) {\n                break;\n            }\n            $value = isset($local['value']) ? $local['value'] : null;\n            $hash = isset($local['id']) ? $local['id'] : null;\n            try {\n                $variable = $this->addVariable($local['name'], $value, $hash);\n            } catch (BufferFullException $e) {\n                $sf->addLocal($this->variableTable->bufferFullVariable());\n                break;\n            }\n            $sf->addLocal($variable);\n        }\n\n        array_push($this->stackFrames, $sf);\n    }", "label": 2}
{"code": "public function flatten(array $array)\n    {\n        $return = [];\n        foreach ($array as $key => $value) {\n            if (in_array($key, $this->exceptions)) {\n                $return[$key] = $value;\n            } else {\n                $return[] = $value;\n            }\n        }\n\n        return $return;\n    }", "label": 2}
{"code": "public static base_responses change(nitro_service client, sslcertkey resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslcertkey updateresources[] = new sslcertkey[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new sslcertkey();\n\t\t\t\tupdateresources[i].certkey = resources[i].certkey;\n\t\t\t\tupdateresources[i].cert = resources[i].cert;\n\t\t\t\tupdateresources[i].key = resources[i].key;\n\t\t\t\tupdateresources[i].password = resources[i].password;\n\t\t\t\tupdateresources[i].fipskey = resources[i].fipskey;\n\t\t\t\tupdateresources[i].inform = resources[i].inform;\n\t\t\t\tupdateresources[i].passplain = resources[i].passplain;\n\t\t\t\tupdateresources[i].nodomaincheck = resources[i].nodomaincheck;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, updateresources,\"update\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def post(self):\n        \"\"\"\n        Create a new directory at the specified path.\n        \"\"\"\n        filepath = self.get_body_argument('filepath')\n\n        try:\n            self.fs.create_directory(filepath)\n            encoded_filepath = tornado.escape.url_escape(filepath,plus=True)\n            resource_uri = self.reverse_url('filesystem:directories-details', encoded_filepath)\n            self.write({'uri':resource_uri})\n        except OSError:\n            raise tornado.web.HTTPError(404)", "label": 1}
{"code": "private function buildVersionsList($service)\n    {\n        $dir = \"{$this->modelsDir}/{$service}/\";\n\n        if (!is_dir($dir)) {\n            return;\n        }\n\n        // Get versions, remove . and .., and sort in descending order.\n        $results = array_diff(scandir($dir, SCANDIR_SORT_DESCENDING), ['..', '.']);\n\n        if (!$results) {\n            $this->manifest[$service] = ['versions' => []];\n        } else {\n            $this->manifest[$service] = [\n                'versions' => [\n                    'latest' => $results[0]\n                ]\n            ];\n            $this->manifest[$service]['versions'] += array_combine($results, $results);\n        }\n    }", "label": 2}
{"code": "def _check_version(self, root):\n        \"\"\"Ensure the root element is a supported version.\n\n        Args:\n            root (etree.Element)\n\n        Raises:\n            UnsupportedVersionError\n        \"\"\"\n        version = self._get_version(root)\n        supported = [StrictVersion(x) for x in\n                     self.supported_versions(root.tag)]\n\n        if version in supported:\n            return\n\n        error = \"Document version ({0}) not in supported versions ({1})\"\n        raise UnsupportedVersionError(\n            message=error.format(version, supported),\n            expected=supported,\n            found=version\n        )", "label": 1}
{"code": "function merge(dest) {\n  if (dest) {\n    Array.prototype.slice.call(arguments, 1).forEach(function(arg) {\n      Object.keys(arg).forEach(function(key) {\n        dest[key] = arg[key]\n      })\n    })\n  }\n\n  return dest\n}", "label": 3}
{"code": "function gainForCommand (cmd) {\n  switch (String(cmd)) {\n    case obciChannelCmdGain1:\n      return 1;\n    case obciChannelCmdGain2:\n      return 2;\n    case obciChannelCmdGain4:\n      return 4;\n    case obciChannelCmdGain6:\n      return 6;\n    case obciChannelCmdGain8:\n      return 8;\n    case obciChannelCmdGain12:\n      return 12;\n    case obciChannelCmdGain24:\n      return 24;\n    default:\n      throw new Error(`Invalid gain setting of ${cmd} gain must be (0,1,2,3,4,5,6)`);\n  }\n}", "label": 3}
{"code": "def total_pages\n      count_without_padding = total_count\n      count_without_padding -= @_padding if defined?(@_padding) && @_padding\n      count_without_padding = 0 if count_without_padding < 0\n\n      total_pages_count = (count_without_padding.to_f / limit_value).ceil\n      max_pages && (max_pages < total_pages_count) ? max_pages : total_pages_count\n    rescue FloatDomainError\n      raise ZeroPerPageOperation, \"The number of total pages was incalculable. Perhaps you called .per(0)?\"\n    end", "label": 4}
{"code": "func FindReference(refs []types.ManagedObjectReference, match ...types.ManagedObjectReference) *types.ManagedObjectReference {\n\tfor _, ref := range refs {\n\t\tfor _, m := range match {\n\t\t\tif ref == m {\n\t\t\t\treturn &ref\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def reload\n      options = { consistent_read: true }\n\n      if self.class.range_key\n        options[:range_key] = range_value\n      end\n\n      self.attributes = self.class.find(hash_key, options).attributes\n      @associations.values.each(&:reset)\n      self\n    end", "label": 4}
{"code": "private String getHierarchyTable(ClassDescriptorDef classDef)\r\n    {\r\n        ArrayList queue     = new ArrayList();\r\n        String    tableName = null;\r\n\r\n        queue.add(classDef);\r\n\r\n        while (!queue.isEmpty())\r\n        {\r\n            ClassDescriptorDef curClassDef = (ClassDescriptorDef)queue.get(0);\r\n\r\n            queue.remove(0);\r\n\r\n            if (curClassDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_GENERATE_TABLE_INFO, true))\r\n            {\r\n                if (tableName != null)\r\n                {\r\n                    if (!tableName.equals(curClassDef.getProperty(PropertyHelper.OJB_PROPERTY_TABLE)))\r\n                    {\r\n                        return null;\r\n                    }\r\n                }\r\n                else\r\n                {\r\n                    tableName = curClassDef.getProperty(PropertyHelper.OJB_PROPERTY_TABLE);\r\n                }\r\n            }\r\n            for (Iterator it = curClassDef.getExtentClasses(); it.hasNext();)\r\n            {\r\n                curClassDef = (ClassDescriptorDef)it.next();\r\n\r\n                if (curClassDef.getReference(\"super\") == null)\r\n                {\r\n                    queue.add(curClassDef);\r\n                }\r\n            }\r\n        }\r\n        return tableName;\r\n    }", "label": 0}
{"code": "def catalog bundle\n      new_map_hash = {}\n      # Bundle always needs to be merged if it adds or removes sources\n      merged = (bundle.sources.length == source_map_hash.values.length)\n      bundle.sources.each do |source|\n        if source_map_hash.key?(source.filename)\n          if source_map_hash[source.filename].code == source.code && source_map_hash[source.filename].source.synchronized? && source.synchronized?\n            new_map_hash[source.filename] = source_map_hash[source.filename]\n          elsif !source.synchronized?\n            new_map_hash[source.filename] = source_map_hash[source.filename]\n            # @todo Smelly instance variable access\n            new_map_hash[source.filename].instance_variable_set(:@source, source)\n          else\n            map = Solargraph::SourceMap.map(source)\n            if source_map_hash[source.filename].try_merge!(map)\n              new_map_hash[source.filename] = source_map_hash[source.filename]\n            else\n              new_map_hash[source.filename] = map\n              merged = false\n            end\n          end\n        else\n          map = Solargraph::SourceMap.map(source)\n          new_map_hash[source.filename] = map\n          merged = false\n        end\n      end\n      return self if merged\n      pins = []\n      reqs = []\n      # @param map [SourceMap]\n      new_map_hash.values.each do |map|\n        pins.concat map.pins\n        reqs.concat map.requires.map(&:name)\n      end\n      reqs.concat bundle.workspace.config.required\n      unless bundle.workspace.require_paths.empty?\n        reqs.delete_if do |r|\n          result = false\n          bundle.workspace.require_paths.each do |l|\n            pn = Pathname.new(bundle.workspace.directory).join(l, \"#{r}.rb\")\n            if new_map_hash.keys.include?(pn.to_s)\n              result = true\n              break\n            end\n          end\n          result\n        end\n      end\n      yard_map.change(reqs)\n      new_store = Store.new(pins + yard_map.pins)\n      @mutex.synchronize {\n        @cache.clear\n        @source_map_hash = new_map_hash\n        @store = new_store\n        @unresolved_requires = yard_map.unresolved_requires\n      }\n      # resolve_method_aliases\n      self\n    end", "label": 4}
{"code": "func (f *FileNameV3) Path() string {\n\treturn (&FileName{Name: f.Name, Length: f.Length}).Path()\n}", "label": 5}
{"code": "function find(id) {\n  let filepath = '';\n\n  if ('string' == typeof id) {\n    try {\n      // Resolve relative to buddy package\n      filepath = require.resolve(id);\n    } catch (err) {\n      // Resolve relative to project package\n      filepath = resolve(path.resolve('package.json'), id);\n    }\n  }\n\n  return filepath;\n}", "label": 3}
{"code": "public function transform($response)\n    {\n        $binding = $this->getBinding($response);\n\n        return $this->adapter->transform($response, $binding->resolveTransformer(), $binding, $this->getRequest());\n    }", "label": 2}
{"code": "protected function filteredCount()\n    {\n        $this->filteredRecords = $this->filteredRecords ?: $this->count();\n        if ($this->skipTotalRecords) {\n            $this->totalRecords = $this->filteredRecords;\n        }\n\n        return $this->filteredRecords;\n    }", "label": 2}
{"code": "function shouldReallyMerge(a, b) {\n                return a.kind === b.kind && (a.kind !== 225 /* ModuleDeclaration */ || areSameModule(a, b));\n                // We use 1 NavNode to represent 'A.B.C', but there are multiple source nodes.\n                // Only merge module nodes that have the same chain. Don't merge 'A.B.C' with 'A'!\n                function areSameModule(a, b) {\n                    if (a.body.kind !== b.body.kind) {\n                        return false;\n                    }\n                    if (a.body.kind !== 225 /* ModuleDeclaration */) {\n                        return true;\n                    }\n                    return areSameModule(a.body, b.body);\n                }\n            }", "label": 3}
{"code": "func (h *Handle) UnmarshalJSON(data []byte) error {\n\tvar (\n\t\tm   map[string]interface{}\n\t\tb   []byte\n\t\terr error\n\t)\n\tif err = json.Unmarshal(data, &m); err != nil {\n\t\treturn err\n\t}\n\th.id = m[\"id\"].(string)\n\tbi, _ := json.Marshal(m[\"sequence\"])\n\tif err := json.Unmarshal(bi, &b); err != nil {\n\t\treturn err\n\t}\n\treturn h.FromByteArray(b)\n}", "label": 5}
{"code": "def _clean(self, value):\n        \"\"\"Validate and clean a candidate value for this field.\"\"\"\n        if value is None:\n            return None\n        elif self.type_ is None:\n            return value\n        elif self.check_type(value):\n            return value\n        elif self.is_type_castable:  # noqa\n            return self.type_(value)\n\n        error_fmt = \"%s must be a %s, not a %s\"\n        error = error_fmt % (self.name, self.type_, type(value))\n        raise TypeError(error)", "label": 1}
{"code": "def get_bibtex(isbn_identifier):\n    \"\"\"\n    Get a BibTeX string for the given ISBN.\n\n    :param isbn_identifier: ISBN to fetch BibTeX entry for.\n    :returns: A BibTeX string or ``None`` if could not fetch it.\n\n    >>> get_bibtex('9783161484100')\n    '@book{9783161484100,\\\\n     title = {Berkeley, Oakland: Albany, Emeryville, Alameda, Kensington},\\\\n    author = {Peekaboo Maps},\\\\n      isbn = {9783161484100},\\\\n      year = {2009},\\\\n publisher = {Peek A Boo Maps}\\\\n}'\n    \"\"\"\n    # Try to find the BibTeX using associated DOIs\n    bibtex = doi.get_bibtex(to_doi(isbn_identifier))\n    if bibtex is None:\n        # In some cases, there are no DOIs for a given ISBN. In this case, try\n        # to fetch bibtex directly from the ISBN, using a combination of\n        # Google Books and worldcat.org results.\n        bibtex = isbnlib.registry.bibformatters['bibtex'](\n            isbnlib.meta(isbn_identifier, 'default'))\n    return bibtex", "label": 1}
{"code": "public static long getMaxIdForClass(\r\n            PersistenceBroker brokerForClass, ClassDescriptor cldForOriginalOrExtent, FieldDescriptor original)\r\n            throws PersistenceBrokerException\r\n    {\r\n        FieldDescriptor field = null;\r\n        if (!original.getClassDescriptor().equals(cldForOriginalOrExtent))\r\n        {\r\n            // check if extent match not the same table\r\n            if (!original.getClassDescriptor().getFullTableName().equals(\r\n                    cldForOriginalOrExtent.getFullTableName()))\r\n            {\r\n                // we have to look for id's in extent class table\r\n                field = cldForOriginalOrExtent.getFieldDescriptorByName(original.getAttributeName());\r\n            }\r\n        }\r\n        else\r\n        {\r\n            field = original;\r\n        }\r\n        if (field == null)\r\n        {\r\n            // if null skip this call\r\n            return 0;\r\n        }\r\n\r\n        String column = field.getColumnName();\r\n        long result = 0;\r\n        ResultSet rs = null;\r\n        Statement stmt = null;\r\n        StatementManagerIF sm = brokerForClass.serviceStatementManager();\r\n        String table = cldForOriginalOrExtent.getFullTableName();\r\n        // String column = cld.getFieldDescriptorByName(fieldName).getColumnName();\r\n        String sql = SM_SELECT_MAX + column + SM_FROM + table;\r\n        try\r\n        {\r\n            //lookup max id for the current class\r\n            stmt = sm.getGenericStatement(cldForOriginalOrExtent, Query.NOT_SCROLLABLE);\r\n            rs = stmt.executeQuery(sql);\r\n            rs.next();\r\n            result = rs.getLong(1);\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            log.warn(\"Cannot lookup max value from table \" + table + \" for column \" + column +\r\n                    \", PB was \" + brokerForClass + \", using jdbc-descriptor \" +\r\n                    brokerForClass.serviceConnectionManager().getConnectionDescriptor(), e);\r\n        }\r\n        finally\r\n        {\r\n            try\r\n            {\r\n                sm.closeResources(stmt, rs);\r\n            }\r\n            catch (Exception ignore)\r\n            {\r\n                // ignore it\r\n           }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "func (enc *Encoder) Indent(prefix, indent string) {\n\tenc.p.prefix = prefix\n\tenc.p.indent = indent\n}", "label": 5}
{"code": "def cleanup(self):\n        \"\"\"\n            Clean up before quitting\n        \"\"\"\n\n        self.pre_exit_trigger = True\n\n        self.logger.info(\"Shutting down %s, please wait a moment.\", self.name)\n        for t in threading.enumerate():\n            if isinstance(t, TimerClass):\n                t.cancel()\n        self.logger.debug('Timers cancelled')\n\n        for i in self.objects:\n            i.cleanup()\n\n        self.logger.debug('Sensors etc cleanups done')\n\n        for ser in (i for i in self.services if isinstance(i, AbstractUserService)):\n            ser.cleanup_system()\n        self.logger.debug('User services cleaned up')\n        if self.worker_thread.is_alive():\n            self.worker_thread.stop()\n        self.logger.debug('Worker thread really stopped')\n\n        for ser in (i for i in self.services if isinstance(i, AbstractSystemService)):\n            ser.cleanup_system()\n        self.logger.debug('System services cleaned up')\n        threads = list(t.name for t in threading.enumerate() if t.is_alive() and not t.daemon)\n        if threads:\n            self.logger.info('After cleanup, we have still the following threads '\n                             'running: %s', ', '.join(threads))", "label": 1}
{"code": "static Parameter createParameter(final String name, final String value) {\n        if (value != null && isQuoted(value)) {\n            return new QuotedParameter(name, value);\n        }\n        return new Parameter(name, value);\n    }", "label": 0}
{"code": "func (c *udpAnnounce) write(h *RequestHeader, body interface{}, trailer []byte) (err error) {\n\tvar buf bytes.Buffer\n\terr = binary.Write(&buf, binary.BigEndian, h)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif body != nil {\n\t\terr = binary.Write(&buf, binary.BigEndian, body)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t}\n\t_, err = buf.Write(trailer)\n\tif err != nil {\n\t\treturn\n\t}\n\tn, err := c.socket.Write(buf.Bytes())\n\tif err != nil {\n\t\treturn\n\t}\n\tif n != buf.Len() {\n\t\tpanic(\"write should send all or error\")\n\t}\n\treturn\n}", "label": 5}
{"code": "protected synchronized PersistenceBroker getBroker() throws PBFactoryException\r\n    {\r\n        /*\r\n            mkalen:\r\n            NB! The loadProfileIfNeeded must be called _before_ acquiring a broker below,\r\n            since some methods in PersistenceBrokerImpl will keep a local reference to\r\n            the descriptor repository that was active during broker construction/refresh\r\n            (not checking the repository beeing used on method invocation).\r\n\r\n            PersistenceBrokerImpl#getClassDescriptor(Class clazz) is such a method,\r\n            that will throw ClassNotPersistenceCapableException on the following scenario:\r\n\r\n            (All happens in one thread only):\r\n            t0: activate per-thread metadata changes\r\n            t1: load, register and activate profile A\r\n            t2: load object O1 witch collection proxy C to objects {O2} (C stores profile key K(A))\r\n            t3: close broker from t2\r\n            t4: load, register and activate profile B\r\n            t5: reference O1.getO2Collection, causing C loadData() to be invoked\r\n            t6: C calls getBroker\r\n                broker B is created and descriptorRepository is set to descriptors from profile B\r\n            t7: C calls loadProfileIfNeeded, re-activating profile A\r\n            t8: C calls B.getCollectionByQuery\r\n            t9: B gets callback (via QueryReferenceBroker) to getClassDescriptor\r\n                the local descriptorRepository from t6 is used!\r\n                => We will now try to query for {O2} with profile B\r\n                    (even though we re-activated profile A in t7)\r\n                    => ClassNotPersistenceCapableException\r\n\r\n            Keeping loadProfileIfNeeded() at the start of this method changes everything from t6:\r\n            t6: C calls loadProfileIfNeeded, re-activating profile A\r\n            t7: C calls getBroker,\r\n                broker B is created and descriptorRepository is set to descriptors from profile A\r\n            t8: C calls B.getCollectionByQuery\r\n            t9: B gets callback to getClassDescriptor,\r\n                the local descriptorRepository from t6 is used\r\n                => We query for {O2} with profile A\r\n                    => All good :-)\r\n        */\r\n        if (_perThreadDescriptorsEnabled)\r\n        {\r\n            loadProfileIfNeeded();\r\n        }\r\n\r\n        PersistenceBroker broker;\r\n        if (getBrokerKey() == null)\r\n        {\r\n            /*\r\n            arminw:\r\n            if no PBKey is set we throw an exception, because we don't\r\n            know which PB (connection) should be used.\r\n            */\r\n            throw new OJBRuntimeException(\"Can't find associated PBKey. Need PBKey to obtain a valid\" +\r\n                                          \"PersistenceBroker instance from intern resources.\");\r\n        }\r\n        // first try to use the current threaded broker to avoid blocking\r\n        broker = PersistenceBrokerThreadMapping.currentPersistenceBroker(getBrokerKey());\r\n        // current broker not found or was closed, create a intern new one\r\n        if (broker == null || broker.isClosed())\r\n        {\r\n            broker = PersistenceBrokerFactory.createPersistenceBroker(getBrokerKey());\r\n            // signal that we use a new internal obtained PB instance to read the\r\n            // data and that this instance have to be closed after use\r\n            _needsClose = true;\r\n        }\r\n        return broker;\r\n    }", "label": 0}
{"code": "function resolvePath(filepath) {\n  filepath = filepath.replace(RE_TRAILING, '');\n  const cwd = process.cwd();\n  const npmPackage = filepath.includes('node_modules');\n\n  // Find nearest node_modules directory\n  if (npmPackage) {\n    const parts = filepath.split(path.sep);\n    let idx = parts.lastIndexOf('node_modules');\n\n    if (idx < parts.length - 1) idx += 2;\n    // Handle scoped\n    if (parts[idx - 1].charAt(0) == '@') idx++;\n\n    const dir = parts.slice(0, idx).join(path.sep);\n\n    // Installed packages must have manifest, otherwise continue\n    if (exists(path.join(dir, 'package.json'))) return dir;\n  }\n\n  // Find nearest directory with node_modules subdirectory\n  if (filepath.includes(cwd)) {\n    let depth = maxFileSystemDepth;\n    let dir = filepath;\n    let parent = '';\n\n    while (true) {\n      parent = path.dirname(dir);\n      // Stop if we hit max file system depth or root\n      // Convert to lowercase to fix problems on Windows\n      if (!--depth || parent.toLowerCase() === dir.toLowerCase()) {\n        break;\n      }\n\n      // Stop at nearest directory with node_modules or cwd\n      if (dir == cwd || exists(path.resolve(dir, 'node_modules'))) return dir;\n\n      // Walk\n      dir = parent;\n    }\n  }\n\n  // Return project directory if file isn't a project file\n  return cwd;\n}", "label": 3}
{"code": "def port(value = nil)\n      if value\n        @port = Integer(value)\n      else\n        return @port if defined?(@port)\n        return @env.port unless @env.default_port?\n        return DEFAULT_SSL_PORT if force_ssl\n        @env.port\n      end\n    end", "label": 4}
{"code": "function checkParameterInitializer(node) {\n            if (ts.getRootDeclaration(node).kind !== 142 /* Parameter */) {\n                return;\n            }\n            var func = ts.getContainingFunction(node);\n            visit(node.initializer);\n            function visit(n) {\n                if (ts.isTypeNode(n) || ts.isDeclarationName(n)) {\n                    // do not dive in types\n                    // skip declaration names (i.e. in object literal expressions)\n                    return;\n                }\n                if (n.kind === 172 /* PropertyAccessExpression */) {\n                    // skip property names in property access expression\n                    return visit(n.expression);\n                }\n                else if (n.kind === 69 /* Identifier */) {\n                    // check FunctionLikeDeclaration.locals (stores parameters\\function local variable)\n                    // if it contains entry with a specified name\n                    var symbol = resolveName(n, n.text, 107455 /* Value */ | 8388608 /* Alias */, /*nameNotFoundMessage*/ undefined, /*nameArg*/ undefined);\n                    if (!symbol || symbol === unknownSymbol || !symbol.valueDeclaration) {\n                        return;\n                    }\n                    if (symbol.valueDeclaration === node) {\n                        error(n, ts.Diagnostics.Parameter_0_cannot_be_referenced_in_its_initializer, ts.declarationNameToString(node.name));\n                        return;\n                    }\n                    // locals map for function contain both parameters and function locals\n                    // so we need to do a bit of extra work to check if reference is legal\n                    var enclosingContainer = ts.getEnclosingBlockScopeContainer(symbol.valueDeclaration);\n                    if (enclosingContainer === func) {\n                        if (symbol.valueDeclaration.kind === 142 /* Parameter */) {\n                            // it is ok to reference parameter in initializer if either\n                            // - parameter is located strictly on the left of current parameter declaration\n                            if (symbol.valueDeclaration.pos < node.pos) {\n                                return;\n                            }\n                            // - parameter is wrapped in function-like entity\n                            var current = n;\n                            while (current !== node.initializer) {\n                                if (ts.isFunctionLike(current.parent)) {\n                                    return;\n                                }\n                                // computed property names/initializers in instance property declaration of class like entities\n                                // are executed in constructor and thus deferred\n                                if (current.parent.kind === 145 /* PropertyDeclaration */ &&\n                                    !(current.parent.flags & 32 /* Static */) &&\n                                    ts.isClassLike(current.parent.parent)) {\n                                    return;\n                                }\n                                current = current.parent;\n                            }\n                        }\n                        error(n, ts.Diagnostics.Initializer_of_parameter_0_cannot_reference_identifier_1_declared_after_it, ts.declarationNameToString(node.name), ts.declarationNameToString(n));\n                    }\n                }\n                else {\n                    return ts.forEachChild(n, visit);\n                }\n            }\n        }", "label": 3}
{"code": "public static base_responses update(nitro_service client, sslcertkey resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslcertkey updateresources[] = new sslcertkey[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new sslcertkey();\n\t\t\t\tupdateresources[i].certkey = resources[i].certkey;\n\t\t\t\tupdateresources[i].expirymonitor = resources[i].expirymonitor;\n\t\t\t\tupdateresources[i].notificationperiod = resources[i].notificationperiod;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public String addExtent(Properties attributes) throws XDocletException\r\n    {\r\n        String name = attributes.getProperty(ATTRIBUTE_NAME);\r\n\r\n        if (!_model.hasClass(name))\r\n        {\r\n            throw new XDocletException(Translator.getString(XDocletModulesOjbMessages.class,\r\n                                       XDocletModulesOjbMessages.COULD_NOT_FIND_TYPE,\r\n                                       new String[]{name}));\r\n        }\r\n        _curClassDef.addExtentClass(_model.getClass(name));\r\n        return \"\";\r\n    }", "label": 0}
{"code": "public final Object getRealObject(Object objectOrProxy)\r\n    {\r\n        if(isNormalOjbProxy(objectOrProxy))\r\n        {\r\n            String msg;\r\n\r\n            try\r\n            {\r\n                return getIndirectionHandler(objectOrProxy).getRealSubject();\r\n            }\r\n            catch(ClassCastException e)\r\n            {\r\n                // shouldn't happen but still ...\r\n                msg = \"The InvocationHandler for the provided Proxy was not an instance of \" + IndirectionHandler.class.getName();\r\n                log.error(msg);\r\n                throw new PersistenceBrokerException(msg, e);\r\n            }\r\n            catch(IllegalArgumentException e)\r\n            {\r\n                msg = \"Could not retrieve real object for given Proxy: \" + objectOrProxy;\r\n                log.error(msg);\r\n                throw new PersistenceBrokerException(msg, e);\r\n            }\r\n            catch(PersistenceBrokerException e)\r\n            {\r\n                log.error(\"Could not retrieve real object for given Proxy: \" + objectOrProxy);\r\n                throw e;\r\n            }\r\n        }\r\n        else if(isVirtualOjbProxy(objectOrProxy))\r\n        {\r\n            try\r\n            {\r\n                return ((VirtualProxy) objectOrProxy).getRealSubject();\r\n            }\r\n            catch(PersistenceBrokerException e)\r\n            {\r\n                log.error(\"Could not retrieve real object for VirtualProxy: \" + objectOrProxy);\r\n                throw e;\r\n            }\r\n        }\r\n        else\r\n        {\r\n            return objectOrProxy;\r\n        }\r\n    }", "label": 0}
{"code": "func (t *TextBar) SetView(view View) {\n\tt.initialize()\n\tt.view = view\n\tt.lview.SetView(view)\n\tt.rview.SetView(view)\n\tt.cview.SetView(view)\n\tt.changed = true\n}", "label": 5}
{"code": "function (scale, note) {\n  return _.findIndex(scale.scale, function (scaleNote) {\n    return scaleNote.enharmonic(note);\n  });\n}", "label": 3}
{"code": "public static base_responses disable(nitro_service client, String id[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (id != null && id.length > 0) {\n\t\t\tInterface disableresources[] = new Interface[id.length];\n\t\t\tfor (int i=0;i<id.length;i++){\n\t\t\t\tdisableresources[i] = new Interface();\n\t\t\t\tdisableresources[i].id = id[i];\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, disableresources,\"disable\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def write(self, file_or_filename):\n        \"\"\" Writes the case data to file.\n        \"\"\"\n        if isinstance(file_or_filename, basestring):\n            file = None\n            try:\n                file = open(file_or_filename, \"wb\")\n            except Exception, detail:\n                logger.error(\"Error opening %s.\" % detail)\n            finally:\n                if file is not None:\n                    self._write_data(file)\n                    file.close()\n        else:\n            file = file_or_filename\n            self._write_data(file)\n\n        return file", "label": 1}
{"code": "protected void addNeighbor(Queue<ColorPoint> queue, int px, int py, int color, Feature component) {\n        if (!inBoundary(px, py, component)) {\n            return;\n        }\n\n        if (!mask.isTouched(px, py)) {\n            queue.add(new ColorPoint(px, py, color));\n        }\n    }", "label": 0}
{"code": "def __deactivate_shared_objects(self, plugin, *args, **kwargs):\n        \"\"\"\n        Callback, which gets executed, if the signal \"plugin_deactivate_post\" was send by the plugin.\n        \"\"\"\n        shared_objects = self.get()\n        for shared_object in shared_objects.keys():\n            self.unregister(shared_object)", "label": 1}
{"code": "def run_bwa(job, fastqs, sample_type, univ_options, bwa_options):\n    \"\"\"\n    Align a pair of fastqs with bwa.\n\n    :param list fastqs: The input fastqs for alignment\n    :param str sample_type: Description of the sample to inject into the filename\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict bwa_options: Options specific to bwa\n    :return: fsID for the generated sam\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'dna_1.fastq': fastqs[0],\n        'dna_2.fastq': fastqs[1],\n        'bwa_index.tar.gz': bwa_options['index']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n    # Handle gzipped file\n    gz = '.gz' if is_gzipfile(input_files['dna_1.fastq']) else ''\n    if gz:\n        for read_file in 'dna_1.fastq', 'dna_2.fastq':\n            os.symlink(read_file, read_file + gz)\n            input_files[read_file + gz] = input_files[read_file] + gz\n    # Untar the index\n    input_files['bwa_index'] = untargz(input_files['bwa_index.tar.gz'], work_dir)\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    parameters = ['mem',\n                  '-t', str(bwa_options['n']),\n                  '-v', '1',  # Don't print INFO messages to the stderr\n                  '/'.join([input_files['bwa_index'], univ_options['ref']]),\n                  input_files['dna_1.fastq' + gz],\n                  input_files['dna_2.fastq' + gz]]\n    with open(''.join([work_dir, '/', sample_type, '.sam']), 'w') as samfile:\n        docker_call(tool='bwa', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=samfile,\n                    tool_version=bwa_options['version'])\n    # samfile.name retains the path info\n    output_file = job.fileStore.writeGlobalFile(samfile.name)\n    job.fileStore.logToMaster('Ran bwa on %s:%s successfully'\n                              % (univ_options['patient'], sample_type))\n    return output_file", "label": 1}
{"code": "function hasKeybinding (key, method) {\n  if (!bindings[key]) return false;\n  return method ? !!~bindings[key].methods.indexOf(method) : true;\n}", "label": 3}
{"code": "public function getAddfolder()\n    {\n        $folder_name = $this->helper->input('name');\n\n        try {\n            if (empty($folder_name)) {\n                return $this->helper->error('folder-name');\n            } elseif ($this->lfm->setName($folder_name)->exists()) {\n                return $this->helper->error('folder-exist');\n            } elseif (config('lfm.alphanumeric_directory') && preg_match('/[^\\w-]/i', $folder_name)) {\n                return $this->helper->error('folder-alnum');\n            } else {\n                $this->lfm->setName($folder_name)->createFolder();\n            }\n        } catch (\\Exception $e) {\n            return $e->getMessage();\n        }\n\n        return parent::$success_response;\n    }", "label": 2}
{"code": "def _control(self, state):\n        \"\"\" Control device state.\n\n        Possible states are ON or OFF.\n\n        :param state: Switch to this state.\n        \"\"\"\n\n        # Renew subscription if necessary\n        if not self._subscription_is_recent():\n            self._subscribe()\n\n        cmd = MAGIC + CONTROL + self._mac + PADDING_1 + PADDING_2 + state\n        _LOGGER.debug(\"Sending new state to %s: %s\", self.host, ord(state))\n        ack_state = self._udp_transact(cmd, self._control_resp, state)\n        if ack_state is None:\n            raise S20Exception(\n                \"Device didn't acknowledge control request: {}\".format(\n                    self.host))", "label": 1}
{"code": "def generate_reporter_options\n      reporter = []\n\n      valid_types = @output_types & SUPPORTED_REPORT_TYPES\n      valid_types.each do |raw_type|\n        type = raw_type.strip\n        output_path = File.join(File.expand_path(@output_directory), determine_output_file_name(type))\n        reporter << \"--report #{type}\"\n        reporter << \"--output '#{output_path}'\"\n\n        if type == \"html\" && @open_report\n          Scan.cache[:open_html_report_path] = output_path\n        end\n      end\n\n      # adds another junit reporter in case the user does not specify one\n      # this will be used to generate a results table and then discarded\n      require 'tempfile'\n      @temp_junit_report = Tempfile.new(\"junit_report\")\n      Scan.cache[:temp_junit_report] = @temp_junit_report.path\n      reporter << \"--report junit\"\n      reporter << \"--output '#{Scan.cache[:temp_junit_report]}'\"\n      return reporter\n    end", "label": 4}
{"code": "function emitEvent(payload, eventNameBase, debugParams) {\n\n        // create a copy of the payload so that nothing modifies the original object\n        try {\n            payload = JSON.parse(JSON.stringify(payload));\n        }\n        catch (err) {\n            /* eslint no-console:0 */\n            console.log('issue parsing during emit ' + JSON.stringify(eventNameBase));\n        }\n\n        // we don't want to emit the potentially huge resource file\n        if (payload && payload.resource) {\n            delete payload.resource;\n        }\n\n        // create the event data and emit the event\n        var name = _.extend({}, eventNameBase, debugParams);\n        var eventData = {\n            name: name,\n            payload: payload\n        };\n        var eventName = name.resource + '.' + name.adapter + '.' + name.method;\n        eventName += debugParams ? '.' + name.type + '.' + name.timing : '';\n        eventBus.emit(eventName, eventData);\n    }", "label": 3}
{"code": "func (r RoleMap) Map(remoteRoles []string) ([]string, error) {\n\t_, err := r.parse()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar outRoles []string\n\t// when no remote roles is specified, assume that\n\t// there is a single empty remote role (that should match wildcards)\n\tif len(remoteRoles) == 0 {\n\t\tremoteRoles = []string{\"\"}\n\t}\n\tfor _, mapping := range r {\n\t\texpression := mapping.Remote\n\t\tfor _, remoteRole := range remoteRoles {\n\t\t\t// never map default implicit role, it is always\n\t\t\t// added by default\n\t\t\tif remoteRole == teleport.DefaultImplicitRole {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, replacementRole := range mapping.Local {\n\t\t\t\treplacement, err := utils.ReplaceRegexp(expression, replacementRole, remoteRole)\n\t\t\t\tswitch {\n\t\t\t\tcase err == nil:\n\t\t\t\t\t// empty replacement can occur when $2 expand refers\n\t\t\t\t\t// to non-existing capture group in match expression\n\t\t\t\t\tif replacement != \"\" {\n\t\t\t\t\t\toutRoles = append(outRoles, replacement)\n\t\t\t\t\t}\n\t\t\t\tcase trace.IsNotFound(err):\n\t\t\t\t\tcontinue\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn outRoles, nil\n}", "label": 5}
{"code": "def download(args):\n    \"\"\"\n    download genomes from NCBI\n    \"\"\"\n    accessions, infoFTP = set(args['g']), args['i']\n    search, exclude = args['s'], args['e']\n    FTPs = getFTPs(accessions, infoFTP, search, exclude, threads = args['t'],\n            convert = args['convert'])\n    if args['test'] is True:\n        for genome in FTPs:\n            print('found:', ';'.join(genome[-1]), genome[0])\n        return FTPs\n    pool = Pool(args['t'])\n    pool = pool.imap_unordered(wgetGenome, FTPs)\n    files = []\n    for f in tqdm(pool, total = len(accessions)):\n        files.append(f)\n    return files", "label": 1}
{"code": "def block_account(self, hash):\n        \"\"\"\n        Returns the account containing block\n\n        :param hash: Hash of the block to return account for\n        :type hash: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.block_account(\n        ...     hash=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n\n        \"\"\"\n\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"hash\": hash}\n\n        resp = self.call('block_account', payload)\n\n        return resp['account']", "label": 1}
{"code": "def build_id_of(path)\n      File.open(path) { |f| ELFTools::ELFFile.new(f).build_id }\n    end", "label": 4}
{"code": "function _gpfDefineEntitiesAdd (entityDefinition) {\n    _gpfAssert(entityDefinition._instanceBuilder !== null, \"Instance builder must be set\");\n    _gpfAssert(!_gpfDefineEntitiesFindByConstructor(entityDefinition.getInstanceBuilder()), \"Already added\");\n    _gpfDefinedEntities.push(entityDefinition);\n}", "label": 3}
{"code": "public static base_responses update(nitro_service client, appfwconfidfield resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwconfidfield updateresources[] = new appfwconfidfield[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new appfwconfidfield();\n\t\t\t\tupdateresources[i].fieldname = resources[i].fieldname;\n\t\t\t\tupdateresources[i].url = resources[i].url;\n\t\t\t\tupdateresources[i].comment = resources[i].comment;\n\t\t\t\tupdateresources[i].state = resources[i].state;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (s *RPCServer) ServeConn(conn io.ReadWriteCloser) {\n\t// First create the yamux server to wrap this connection\n\tmux, err := yamux.Server(conn, nil)\n\tif err != nil {\n\t\tconn.Close()\n\t\tlog.Printf(\"[ERR] plugin: error creating yamux server: %s\", err)\n\t\treturn\n\t}\n\n\t// Accept the control connection\n\tcontrol, err := mux.Accept()\n\tif err != nil {\n\t\tmux.Close()\n\t\tif err != io.EOF {\n\t\t\tlog.Printf(\"[ERR] plugin: error accepting control connection: %s\", err)\n\t\t}\n\n\t\treturn\n\t}\n\n\t// Connect the stdstreams (in, out, err)\n\tstdstream := make([]net.Conn, 2)\n\tfor i, _ := range stdstream {\n\t\tstdstream[i], err = mux.Accept()\n\t\tif err != nil {\n\t\t\tmux.Close()\n\t\t\tlog.Printf(\"[ERR] plugin: accepting stream %d: %s\", i, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Copy std streams out to the proper place\n\tgo copyStream(\"stdout\", stdstream[0], s.Stdout)\n\tgo copyStream(\"stderr\", stdstream[1], s.Stderr)\n\n\t// Create the broker and start it up\n\tbroker := newMuxBroker(mux)\n\tgo broker.Run()\n\n\t// Use the control connection to build the dispenser and serve the\n\t// connection.\n\tserver := rpc.NewServer()\n\tserver.RegisterName(\"Control\", &controlServer{\n\t\tserver: s,\n\t})\n\tserver.RegisterName(\"Dispenser\", &dispenseServer{\n\t\tbroker:  broker,\n\t\tplugins: s.Plugins,\n\t})\n\tserver.ServeConn(control)\n}", "label": 5}
{"code": "func SandboxKeyWalker(out *Sandbox, key string) SandboxWalker {\n\treturn func(sb Sandbox) bool {\n\t\tif sb.Key() == key {\n\t\t\t*out = sb\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}\n}", "label": 5}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getBucket($options + $this->identity);\n    }", "label": 2}
{"code": "public static function urlContains($url)\n    {\n        return new static(\n            function (WebDriver $driver) use ($url) {\n                return mb_strpos($driver->getCurrentURL(), $url) !== false;\n            }\n        );\n    }", "label": 2}
{"code": "def extend(self, iterable):\n        \"\"\"Extend the list by appending all the items in the given list.\"\"\"\n        return super(Collection, self).extend(\n            self._ensure_iterable_is_valid(iterable))", "label": 1}
{"code": "def read\n      text = @filetype.read\n      if text.nil?\n        raise IniParseError, _(\"Cannot read nonexistent file %{file}\") % { file: @file.inspect }\n      end\n      parse(text)\n    end", "label": 4}
{"code": "func (f *Fpdf) OutputAndClose(w io.WriteCloser) error {\n\tf.Output(w)\n\tw.Close()\n\treturn f.err\n}", "label": 5}
{"code": "public static void setEnabled(Element element, boolean enabled) {\n        element.setPropertyBoolean(\"disabled\", !enabled);\n\tsetStyleName(element, \"disabled\", !enabled);\n    }", "label": 0}
{"code": "def extract_custom_settings!(options)\n      @heading = options.key?(:heading) ? options.delete(:heading) : default_heading\n      @sortable_column = options.delete(:sortable)\n      @sortable_start  = options.delete(:sortable_start) || 0\n      @new_record = options.key?(:new_record) ? options.delete(:new_record) : true\n      @destroy_option = options.delete(:allow_destroy)\n      options\n    end", "label": 4}
{"code": "def seed_container_block_content(locale, seed_content)\n      page_part_editor_setup = page_part.editor_setup\n      raise \"Invalid editorBlocks for page_part_editor_setup\" unless page_part_editor_setup && page_part_editor_setup[\"editorBlocks\"].present?\n      # page = page_part.page\n      # page_part_key uniquely identifies a fragment\n      # page_part_key = page_part.page_part_key\n\n      # container for json to be attached to page details\n      locale_block_content_json = {\"blocks\" => {}}\n      # {\"blocks\"=>{\"title_a\"=>{\"content\"=>\"about our agency\"}, \"content_a\"=>{\"content\"=>\"\"}}}\n      page_part_editor_setup[\"editorBlocks\"].each do |configColBlocks|\n        configColBlocks.each do |configRowBlock|\n          row_block_label = configRowBlock[\"label\"]\n          row_block_content = \"\"\n          # find the content for current block from within the seed content\n          if seed_content[row_block_label]\n            if configRowBlock[\"isImage\"]\n              photo = seed_fragment_photo row_block_label, seed_content[row_block_label]\n              if photo.present? && photo.optimized_image_url.present?\n                # optimized_image_url is defined in content_photo and will\n                # return cloudinary url or filesystem url depending on settings\n                row_block_content = photo.optimized_image_url\n              else\n                row_block_content = \"http://via.placeholder.com/350x250\"\n              end\n            else\n              row_block_content = seed_content[row_block_label]\n            end\n          end\n          locale_block_content_json[\"blocks\"][row_block_label] = {\"content\" => row_block_content}\n        end\n      end\n      # # save the block contents (in associated page_part model)\n      # updated_details = container.set_page_part_block_contents page_part_key, locale, locale_block_content_json\n      # # retrieve the contents saved above and use to rebuild html for that page_part\n      # # (and save it in associated page_content model)\n      # fragment_html = container.rebuild_page_content page_part_key, locale\n\n      update_page_part_content locale, locale_block_content_json\n\n      p \" #{page_part_key} content set for #{locale}.\"\n    end", "label": 4}
{"code": "private void cascadeDeleteFor(ObjectEnvelope mod, List alreadyPrepared)\r\n    {\r\n        // avoid endless recursion\r\n        if(alreadyPrepared.contains(mod.getIdentity())) return;\r\n\r\n        alreadyPrepared.add(mod.getIdentity());\r\n\r\n        ClassDescriptor cld = getTransaction().getBroker().getClassDescriptor(mod.getObject().getClass());\r\n\r\n        List refs = cld.getObjectReferenceDescriptors(true);\r\n        cascadeDeleteSingleReferences(mod, refs, alreadyPrepared);\r\n\r\n        List colls = cld.getCollectionDescriptors(true);\r\n        cascadeDeleteCollectionReferences(mod, colls, alreadyPrepared);\r\n    }", "label": 0}
{"code": "func GetUnsafeString(data []byte, keys ...string) (val string, err error) {\n\tv, _, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn \"\", e\n\t}\n\n\treturn bytesToString(&v), nil\n}", "label": 5}
{"code": "private function sortMiddleware()\n    {\n        $this->sorted = [];\n\n        if (!$this->interposeFn) {\n            foreach ($this->steps as $step) {\n                foreach ($step as $fn) {\n                    $this->sorted[] = $fn[0];\n                }\n            }\n            return;\n        }\n\n        $ifn = $this->interposeFn;\n        // Interpose the interposeFn into the handler stack.\n        foreach ($this->steps as $stepName => $step) {\n            foreach ($step as $fn) {\n                $this->sorted[] = $ifn($stepName, $fn[1]);\n                $this->sorted[] = $fn[0];\n            }\n        }\n    }", "label": 2}
{"code": "public static base_response add(nitro_service client, snmpcommunity resource) throws Exception {\n\t\tsnmpcommunity addresource = new snmpcommunity();\n\t\taddresource.communityname = resource.communityname;\n\t\taddresource.permissions = resource.permissions;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function append(source) {\n            if (s === '') return;\n            var index = 0,\n                expr = /\\n/g,\n                s,\n                match;\n            while (match = expr.exec(source)) {\n                s = source.substring(index, match.index+1);\n                if (s !== '') out.push('  write(\\''+escapestr(s)+'\\');\\n');\n                index = match.index+1;\n            }\n            s = source.substring(index, source.length);\n            if (s !== '') out.push('  write(\\''+escapestr(s)+'\\');\\n');\n        }", "label": 3}
{"code": "def find_type(self, txt):\n        \"\"\"\n        top level function used to simply return the \n        ONE ACTUAL string used for data types\n        \"\"\"\n        searchString = txt.upper()\n        match = 'Unknown'\n        for i in self.lst_type:\n            if searchString in i:\n                match = i\n        return match", "label": 1}
{"code": "function validatePage(page, path) {\n  let errors = [];\n\n  // Check for required properties\n  errors = [...errors, ...assertProperties(page, path, requiredProperties[page.type])];\n\n  if (page.children) {\n    // Check that children is an array\n    if (!Array.isArray(page.children)) {\n      errors = [...errors, { path, error: 'Children must be an array' }];\n\n      return errors;\n    }\n\n    page.children.forEach((node, index) => {\n      errors = [...errors, ...validateNode(node, [...path, 'children', index], [page])];\n    });\n  }\n\n  return errors;\n}", "label": 3}
{"code": "public static nsrollbackcmd get(nitro_service service) throws Exception{\n\t\tnsrollbackcmd obj = new nsrollbackcmd();\n\t\tnsrollbackcmd[] response = (nsrollbackcmd[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def prune_clade(self, node_id):\n        \"\"\"Prune `node_id` and the edges and nodes that are tipward of it.\n        Caller must delete the edge to node_id.\"\"\"\n        to_del_nodes = [node_id]\n        while bool(to_del_nodes):\n            node_id = to_del_nodes.pop(0)\n            self._flag_node_as_del_and_del_in_by_target(node_id)\n            ebsd = self._edge_by_source.get(node_id)\n            if ebsd is not None:\n                child_edges = list(ebsd.values())\n                to_del_nodes.extend([i['@target'] for i in child_edges])\n                del self._edge_by_source[\n                    node_id]", "label": 1}
{"code": "public static base_response update(nitro_service client, appfwconfidfield resource) throws Exception {\n\t\tappfwconfidfield updateresource = new appfwconfidfield();\n\t\tupdateresource.fieldname = resource.fieldname;\n\t\tupdateresource.url = resource.url;\n\t\tupdateresource.comment = resource.comment;\n\t\tupdateresource.state = resource.state;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "function(next) {\n            try { process.umask(core.umask); } catch(e) { logger.error(\"umask:\", core.umask, e) }\n\n            // Create all subfolders with permissions, run it before initializing db which may create files in the spool folder\n            if (!cluster.isWorker && !core.worker) {\n                Object.keys(core.path).forEach(function(p) {\n                    var paths = Array.isArray(core.path[p]) ? core.path[p] : [core.path[p]];\n                    paths.forEach(function(x) {\n                        if (!x || path.isAbsolute(x)) return;\n                        lib.mkdirSync(x);\n                        lib.chownSync(this.uid, this.gid, x);\n                    });\n                });\n            }\n            next();\n        }", "label": 3}
{"code": "function augmentScope(bemNode, scope) {\n\n    assert(typeof scope === 'string', 'options.scope must be string');\n\n    if (bemNode.isRoot) {\n        bemNode.block = scope;\n    } else {\n        bemNode.elem = bemNode.block;\n        bemNode.elemMods = bemNode.mods;\n\n        delete bemNode.block;\n        delete bemNode.mods;\n    }\n\n    return bemNode;\n}", "label": 3}
{"code": "def delete(attr)\n    attr = attr.intern\n    if @parameters.has_key?(attr)\n      @parameters.delete(attr)\n    else\n      raise Puppet::DevError.new(_(\"Undefined attribute '%{attribute}' in %{name}\") % { attribute: attr, name: self})\n    end\n  end", "label": 4}
{"code": "public function currentLfmType()\n    {\n        $lfm_type = 'file';\n\n        $request_type = lcfirst(str_singular($this->input('type') ?: ''));\n        $available_types = array_keys($this->config->get('lfm.folder_categories') ?: []);\n\n        if (in_array($request_type, $available_types)) {\n            $lfm_type = $request_type;\n        }\n\n        return $lfm_type;\n    }", "label": 2}
{"code": "func (a *AuthWithRoles) DeleteProxy(name string) error {\n\tif err := a.action(defaults.Namespace, services.KindProxy, services.VerbDelete); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.DeleteProxy(name)\n}", "label": 5}
{"code": "function mergeSubmissionFiles(params, cb) {\n  logger.debug(\"cacheFiles: mergeSubmissionFiles\", params);\n  var submission = params.submission;\n\n  //No submission, cannot continue.\n  if (!_.isObject(submission)) {\n    return cb(buildErrorResponse({\n      err: new Error(\"Expected Submission Object To Cache Files For\"),\n      msg: \"Error Exporting Submission As PDF\",\n      httpCode: 500\n    }));\n  }\n\n  var form = submission.formSubmittedAgainst;\n\n\n  var fileFieldDetails = _.filter(submission.formFields, function(field) {\n    return isFileFieldType(field.fieldId.type);\n  });\n  fileFieldDetails = _.flatten(fileFieldDetails);\n\n\n  var fieldTypes = _.groupBy(fileFieldDetails, function(field) {\n    return field.fieldId.type;\n  });\n\n  //Files That Have To Be Loaded From Mbaas\n  var mbaasTypes = _.union(fieldTypes.photo, fieldTypes.signature);\n\n  //Only Interested In The File Ids To Download\n  var filesToDownload = _.map(mbaasTypes, function(field) {\n    return _.map(field.fieldValues, function(fieldValue) {\n      return fieldValue.groupId;\n    });\n  });\n\n  filesToDownload = _.flatten(filesToDownload);\n\n  logger.debug(\"cacheFiles: mergeSubmissionFiles filesToDownload\", filesToDownload);\n\n\n  //Now download all of the files..\n  async.mapSeries(filesToDownload, function(fileIdOrUrl, cb) {\n    //Only want the callback to be called once.\n    cb = _.once(cb);\n\n    var fileUri = path.join(params.options.pdfExportDir, 'image_binary_' + fileIdOrUrl);\n    var localFile = fs.createWriteStream(fileUri);\n\n    //Loading The Submission File From THe Database / MbaaS\n    cacheSubmissionFile({\n      fileId: fileIdOrUrl,\n      connections: params.connections,\n      options: params.options,\n      submission: submission\n    }, localFile, function(err, fileDetails) {\n      if (err) {\n        logger.error(\"cacheFiles: cacheSubmissionFile\", {error: err});\n      }\n      fileDetails = fileDetails || {};\n      fileDetails.url = \"file://\" + fileUri;\n      fileDetails.fileId = fileIdOrUrl;\n\n      logger.debug(\"cacheFiles: mergeSubmissionFiles fileDetails\", fileDetails);\n\n      return cb(err, _.omit(fileDetails, \"stream\"));\n    });\n  }, function(err, cachedFiles) {\n    if (err) {\n      return cb(buildErrorResponse({\n        error: err,\n        msg: \"Error Cacheing Files For Submission Export\",\n        code: constants.ERROR_CODES.FH_FORMS_ERR_CODE_PDF_GENERATION,\n        httpCode: 500\n      }));\n    }\n\n    //No Errors, all files are now cached for the submission\n\n    submission.formSubmittedAgainst =  populateSubmissionFileData({\n      form: form,\n      submissionFiles: cachedFiles,\n      downloadUrl: params.options.downloadUrl,\n      fileUriPath: params.options.fileUriPath,\n      submission: submission\n    });\n\n    logger.debug(\"cacheFiles: mergeSubmissionFiles submission\", submission);\n\n    cb(undefined, submission);\n  });\n}", "label": 3}
{"code": "public function setLargeCustomDictionary($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\LargeCustomDictionaryConfig::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def __begin_of_list(self, ast_token):\n        \"\"\"Handle begin of a list.\"\"\"\n        self.list_level += 1\n        if self.list_level == 1:\n            self.final_ast_tokens.append(ast_token)", "label": 1}
{"code": "public static nstrafficdomain_binding[] get(nitro_service service, Long td[]) throws Exception{\n\t\tif (td !=null && td.length>0) {\n\t\t\tnstrafficdomain_binding response[] = new nstrafficdomain_binding[td.length];\n\t\t\tnstrafficdomain_binding obj[] = new nstrafficdomain_binding[td.length];\n\t\t\tfor (int i=0;i<td.length;i++) {\n\t\t\t\tobj[i] = new nstrafficdomain_binding();\n\t\t\t\tobj[i].set_td(td[i]);\n\t\t\t\tresponse[i] = (nstrafficdomain_binding) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public function findElement(WebDriverBy $by)\n    {\n        $params = [\n            'using' => $by->getMechanism(),\n            'value' => $by->getValue(),\n            ':id' => $this->id,\n        ];\n        $raw_element = $this->executor->execute(\n            DriverCommand::FIND_CHILD_ELEMENT,\n            $params\n        );\n\n        return $this->newElement($raw_element['ELEMENT']);\n    }", "label": 2}
{"code": "func (h *AuthHandlers) hostKeyCallback(hostname string, remote net.Addr, key ssh.PublicKey) error {\n\t// If strict host key checking is enabled, reject host key fallback.\n\tclusterConfig, err := h.AccessPoint.GetClusterConfig()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif clusterConfig.GetProxyChecksHostKeys() == services.HostKeyCheckYes {\n\t\treturn trace.AccessDenied(\"remote host presented a public key, expected a host certificate\")\n\t}\n\n\t// If strict host key checking is not enabled, log that Teleport trusted an\n\t// insecure key, but allow the request to go through.\n\th.Warn(\"Insecure configuration! Strict host key checking disabled, allowing login without checking host key of type %v.\", key.Type())\n\treturn nil\n}", "label": 5}
{"code": "private Long string2long(String text, DateTimeFormat fmt) {\n        \n        // null or \"\" returns null\n        if (text == null) return null;\n        text = text.trim();\n        if (text.length() == 0) return null;\n        \n        Date date = fmt.parse(text);\n        return date != null ? UTCDateBox.date2utc(date) : null;\n    }", "label": 0}
{"code": "public static rsskeytype get(nitro_service service) throws Exception{\n\t\trsskeytype obj = new rsskeytype();\n\t\trsskeytype[] response = (rsskeytype[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "func (c *Call) SetArg(n int, value interface{}) *Call {\n\tc.t.Helper()\n\n\tmt := c.methodType\n\t// TODO: This will break on variadic methods.\n\t// We will need to check those at invocation time.\n\tif n < 0 || n >= mt.NumIn() {\n\t\tc.t.Fatalf(\"SetArg(%d, ...) called for a method with %d args [%s]\",\n\t\t\tn, mt.NumIn(), c.origin)\n\t}\n\t// Permit setting argument through an interface.\n\t// In the interface case, we don't (nay, can't) check the type here.\n\tat := mt.In(n)\n\tswitch at.Kind() {\n\tcase reflect.Ptr:\n\t\tdt := at.Elem()\n\t\tif vt := reflect.TypeOf(value); !vt.AssignableTo(dt) {\n\t\t\tc.t.Fatalf(\"SetArg(%d, ...) argument is a %v, not assignable to %v [%s]\",\n\t\t\t\tn, vt, dt, c.origin)\n\t\t}\n\tcase reflect.Interface:\n\t\t// nothing to do\n\tcase reflect.Slice:\n\t\t// nothing to do\n\tdefault:\n\t\tc.t.Fatalf(\"SetArg(%d, ...) referring to argument of non-pointer non-interface non-slice type %v [%s]\",\n\t\t\tn, at, c.origin)\n\t}\n\n\tc.addAction(func(args []interface{}) []interface{} {\n\t\tv := reflect.ValueOf(value)\n\t\tswitch reflect.TypeOf(args[n]).Kind() {\n\t\tcase reflect.Slice:\n\t\t\tsetSlice(args[n], v)\n\t\tdefault:\n\t\t\treflect.ValueOf(args[n]).Elem().Set(v)\n\t\t}\n\t\treturn nil\n\t})\n\treturn c\n}", "label": 5}
{"code": "public function sendStatusUpdate($txt)\n    {\n        $child = new ProtocolNode('status', null, null, $txt);\n        $nodeID = $this->createIqId();\n        $node = new ProtocolNode('iq',\n            [\n                'to'    => Constants::WHATSAPP_SERVER,\n                'type'  => 'set',\n                'id'    => $nodeID,\n                'xmlns' => 'status',\n            ], [$child], null);\n\n        $this->sendNode($node);\n        $this->eventManager()->fire('onSendStatusUpdate',\n            [\n                $this->phoneNumber,\n                $txt,\n            ]);\n    }", "label": 2}
{"code": "func (ww *WidgetWatchers) PostEventWidgetResize(w Widget) {\n\tev := &EventWidgetResize{}\n\tev.SetWidget(w)\n\tev.SetEventNow()\n\tww.PostEvent(ev)\n}", "label": 5}
{"code": "def cli_opts():\n    \"\"\" Handle the command line options \"\"\"\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \"--homeassistant-config\",\n        type=str,\n        required=False,\n        dest=\"config\",\n        help=\"Create configuration section for home assistant\",)\n    parser.add_argument(\n        \"-f\",\n        \"--filter\",\n        type=str,\n        required=False,\n        dest=\"filter\",\n        help=\"Ignore events related with these devices\",)\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        type=str,\n        required=False,\n        dest=\"output\",\n        help=\"Send output to file\",)\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        action=\"store_true\",\n        dest=\"verbose\",\n        help=\"Verbose output\",)\n    parser.add_argument('device')\n\n    return parser.parse_args()", "label": 1}
{"code": "public function ddl(array $options = [])\n    {\n        $ddl = $this->connection->getDatabaseDDL($options + [\n            'name' => $this->name\n        ]);\n\n        if (isset($ddl['statements'])) {\n            return $ddl['statements'];\n        }\n\n        return [];\n    }", "label": 2}
{"code": "public function setFrameLabelAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\LabelAnnotation::class);\n        $this->frame_label_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static function cryptoKeyPathName($project, $location, $keyRing, $cryptoKeyPath)\n    {\n        return self::getCryptoKeyPathNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'key_ring' => $keyRing,\n            'crypto_key_path' => $cryptoKeyPath,\n        ]);\n    }", "label": 2}
{"code": "def from_doi(doi):\n    \"\"\"\n    Get the arXiv eprint id for a given DOI.\n\n    .. note::\n\n        Uses arXiv API. Will not return anything if arXiv is not aware of the\n        associated DOI.\n\n    :param doi: The DOI of the resource to look for.\n    :returns: The arXiv eprint id, or ``None`` if not found.\n\n    >>> from_doi('10.1209/0295-5075/111/40005')\n    # Note: Test do not pass due to an arXiv API bug.\n    '1506.06690'\n    \"\"\"\n    try:\n        request = requests.get(\"http://export.arxiv.org/api/query\",\n                               params={\n                                   \"search_query\": \"doi:%s\" % (doi,),\n                                   \"max_results\": 1\n                               })\n        request.raise_for_status()\n    except RequestException:\n        return None\n    root = xml.etree.ElementTree.fromstring(request.content)\n    for entry in root.iter(\"{http://www.w3.org/2005/Atom}entry\"):\n        arxiv_id = entry.find(\"{http://www.w3.org/2005/Atom}id\").text\n        # arxiv_id is an arXiv full URL. We only want the id which is the last\n        # URL component.\n        return arxiv_id.split(\"/\")[-1]\n    return None", "label": 1}
{"code": "def fetch_cluster_info\n      errors = []\n\n      @seed_brokers.shuffle.each do |node|\n        @logger.info \"Fetching cluster metadata from #{node}\"\n\n        begin\n          broker = @broker_pool.connect(node.hostname, node.port)\n          cluster_info = broker.fetch_metadata(topics: @target_topics)\n\n          if cluster_info.brokers.empty?\n            @logger.error \"No brokers in cluster\"\n          else\n            @logger.info \"Discovered cluster metadata; nodes: #{cluster_info.brokers.join(', ')}\"\n\n            @stale = false\n\n            return cluster_info\n          end\n        rescue Error => e\n          @logger.error \"Failed to fetch metadata from #{node}: #{e}\"\n          errors << [node, e]\n        ensure\n          broker.disconnect unless broker.nil?\n        end\n      end\n\n      error_description = errors.map {|node, exception| \"- #{node}: #{exception}\" }.join(\"\\n\")\n\n      raise ConnectionError, \"Could not connect to any of the seed brokers:\\n#{error_description}\"\n    end", "label": 4}
{"code": "func (g *GLogger) Warningf(format string, args ...interface{}) {\n\tg.Entry.Warningf(format, args...)\n}", "label": 5}
{"code": "public function setBreakpoints($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Debugger\\V2\\Breakpoint::class);\n        $this->breakpoints = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function instanceConfiguration($name, array $config = [])\n    {\n        return new InstanceConfiguration($this->connection, $this->projectId, $name, $config);\n    }", "label": 2}
{"code": "public static void endTrack(final String title){\r\n    if(isClosed){ return; }\r\n    //--Make Task\r\n    final long timestamp = System.currentTimeMillis();\r\n    Runnable endTrack = new Runnable(){\r\n      public void run(){\r\n        assert !isThreaded || control.isHeldByCurrentThread();\r\n        //(check name match)\r\n        String expected = titleStack.pop();\r\n        if(!expected.equalsIgnoreCase(title)){\r\n          throw new IllegalArgumentException(\"Track names do not match: expected: \" + expected + \" found: \" + title);\r\n        }\r\n        //(decrement depth)\r\n        depth -= 1;\r\n        //(send signal)\r\n        handlers.process(null, MessageType.END_TRACK, depth, timestamp);\r\n        assert !isThreaded || control.isHeldByCurrentThread();\r\n      }\r\n    };\r\n    //--Run Task\r\n    if(isThreaded){\r\n      //(case: multithreaded)\r\n      long threadId = Thread.currentThread().getId();\r\n      attemptThreadControl( threadId, endTrack );\r\n    } else {\r\n      //(case: no threading)\r\n      endTrack.run();\r\n    }\r\n  }", "label": 0}
{"code": "func (cl *Client) connBTHandshake(c *connection, ih *metainfo.Hash) (ret metainfo.Hash, ok bool, err error) {\n\tres, ok, err := pp.Handshake(c.rw(), ih, cl.peerID, cl.extensionBytes)\n\tif err != nil || !ok {\n\t\treturn\n\t}\n\tret = res.Hash\n\tc.PeerExtensionBytes = res.PeerExtensionBits\n\tc.PeerID = res.PeerID\n\tc.completedHandshake = time.Now()\n\treturn\n}", "label": 5}
{"code": "public static Comment createComment(final String entityId,\n\t\t\t\t\t\t\t\t\t\tfinal String entityType,\n\t\t\t\t\t\t\t\t\t\tfinal String action,\n\t\t\t\t\t\t\t\t\t\tfinal String commentedText,\n\t\t\t\t\t\t\t\t\t\tfinal String user,\n\t\t\t\t\t\t\t\t\t\tfinal Date date) {\n\n\t\tfinal Comment comment = new Comment();\n\t\tcomment.setEntityId(entityId);\n\t\tcomment.setEntityType(entityType);\n\t\tcomment.setAction(action);\n\t\tcomment.setCommentText(commentedText);\n\t\tcomment.setCommentedBy(user);\n\t\tcomment.setCreatedDateTime(date);\n\t\treturn comment;\n\t}", "label": 0}
{"code": "def build_population_criteria(criteria_def, criteria_id, population)\n      criteria = PopulationCriteria.new(criteria_def, @document, @id_generator)\n\n      # check to see if we have an identical population criteria.\n      # this can happen since the hqmf 2.0 will export a DENOM, NUMER, etc for each population, even if identical.\n      # if we have identical, just re-use it rather than creating DENOM_1, NUMER_1, etc.\n      identical = @population_criteria.select { |pc| pc.to_model.hqmf_id == criteria.to_model.hqmf_id }\n\n      @reference_ids.concat(criteria.to_model.referenced_data_criteria)\n\n      if identical.empty?\n        # this section constructs a human readable id.  The first IPP will be IPP, the second will be IPP_1, etc.\n        # This allows the populations to be more readable.  The alternative would be to have the hqmf ids in the\n        # populations, which would work, but is difficult to read the populations.\n        if @ids_by_hqmf_id[\"#{criteria.hqmf_id}-#{population['stratification']}\"]\n          criteria.create_human_readable_id(@ids_by_hqmf_id[\"#{criteria.hqmf_id}-#{population['stratification']}\"])\n        else\n          criteria.create_human_readable_id(population_id_with_counter(criteria_id))\n          @ids_by_hqmf_id[\"#{criteria.hqmf_id}-#{population['stratification']}\"] = criteria.id\n        end\n\n        @population_criteria << criteria\n        population[criteria_id] = criteria.id\n      else\n        population[criteria_id] = identical.first.id\n      end\n    end", "label": 4}
{"code": "public PropertiesEnvelope getUserProperties(String userId, String aid) throws ApiException {\n        ApiResponse<PropertiesEnvelope> resp = getUserPropertiesWithHttpInfo(userId, aid);\n        return resp.getData();\n    }", "label": 0}
{"code": "def _pp(dict_data):\n    \"\"\"Pretty print.\"\"\"\n    for key, val in dict_data.items():\n        # pylint: disable=superfluous-parens\n        print('{0:<11}: {1}'.format(key, val))", "label": 1}
{"code": "protected function resumeHandlingArgDirectives(): void\n    {\n        // copy and reset\n        $snapshots = $this->handleArgDirectivesSnapshots;\n        $this->handleArgDirectivesSnapshots = [];\n\n        foreach ($snapshots as $handlerArgs) {\n            $this->handleArgDirectives(...$handlerArgs);\n        }\n\n        // We might have hit more validation-relevant directives so we recurse\n        if (count($this->handleArgDirectivesSnapshots) > 0) {\n            $this->runArgDirectives();\n        }\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, sslparameter resource) throws Exception {\n\t\tsslparameter updateresource = new sslparameter();\n\t\tupdateresource.quantumsize = resource.quantumsize;\n\t\tupdateresource.crlmemorysizemb = resource.crlmemorysizemb;\n\t\tupdateresource.strictcachecks = resource.strictcachecks;\n\t\tupdateresource.ssltriggertimeout = resource.ssltriggertimeout;\n\t\tupdateresource.sendclosenotify = resource.sendclosenotify;\n\t\tupdateresource.encrypttriggerpktcount = resource.encrypttriggerpktcount;\n\t\tupdateresource.denysslreneg = resource.denysslreneg;\n\t\tupdateresource.insertionencoding = resource.insertionencoding;\n\t\tupdateresource.ocspcachesize = resource.ocspcachesize;\n\t\tupdateresource.pushflag = resource.pushflag;\n\t\tupdateresource.dropreqwithnohostheader = resource.dropreqwithnohostheader;\n\t\tupdateresource.pushenctriggertimeout = resource.pushenctriggertimeout;\n\t\tupdateresource.undefactioncontrol = resource.undefactioncontrol;\n\t\tupdateresource.undefactiondata = resource.undefactiondata;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public function basic_get($queue = '', $no_ack = false, $ticket = null)\n    {\n        $ticket = $this->getTicket($ticket);\n        list($class_id, $method_id, $args) = $this->protocolWriter->basicGet($ticket, $queue, $no_ack);\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('basic.get_ok'),\n            $this->waitHelper->get_wait('basic.get_empty')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "def subscription\n      tpl = FFI::MemoryPointer.new(:pointer)\n      response = Rdkafka::Bindings.rd_kafka_subscription(@native_kafka, tpl)\n      if response != 0\n        raise Rdkafka::RdkafkaError.new(response)\n      end\n      tpl = tpl.read(:pointer).tap { |it| it.autorelease = false }\n\n      begin\n        Rdkafka::Consumer::TopicPartitionList.from_native_tpl(tpl)\n      ensure\n        Rdkafka::Bindings.rd_kafka_topic_partition_list_destroy(tpl)\n      end\n    end", "label": 4}
{"code": "function StringReadableStream(str, options) {\n\tif(!options) options = {};\n\tdelete options.objectMode;\n\tdelete options.readableObjectMode;\n\tReadable.call(this, options);\n\tthis._currentString = str;\n\tthis._currentStringPos = 0;\n\tthis._stringChunkSize = options.chunkSize || 1024;\n}", "label": 3}
{"code": "def paths_in_directory(input_directory):\n    \"\"\"\n    Generate a list of all files in input_directory, each as a list containing path components.\n    \"\"\"\n    paths = []\n    for base_path, directories, filenames in os.walk(input_directory):\n        relative_path = os.path.relpath(base_path, input_directory)\n        path_components = relative_path.split(os.sep)\n        if path_components[0] == \".\":\n            path_components = path_components[1:]\n        if path_components and path_components[0].startswith(\".\"):\n            # hidden dir\n            continue\n        path_components = filter(bool, path_components)  # remove empty components\n        for filename in filenames:\n            if filename.startswith(\".\"):\n                # hidden file\n                continue\n            paths.append(path_components + [filename])\n    return paths", "label": 1}
{"code": "public function queue_bind(\n        $queue,\n        $exchange,\n        $routing_key = '',\n        $nowait = false,\n        $arguments = array(),\n        $ticket = null\n    ) {\n        $ticket = $this->getTicket($ticket);\n\n        list($class_id, $method_id, $args) = $this->protocolWriter->queueBind(\n            $ticket,\n            $queue,\n            $exchange,\n            $routing_key,\n            $nowait,\n            $arguments\n        );\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        if ($nowait) {\n            return null;\n        }\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('queue.bind_ok')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "def configure(**kwargs):\n        \"\"\"Global configuration for event handling.\"\"\"\n        for key in kwargs:\n            if key == 'is_logging_enabled':\n                Event.is_logging_enabled = kwargs[key]\n            elif key == 'collector_queue':\n                Event.collector_queue = kwargs[key]\n            else:\n                Logger.get_logger(__name__).error(\"Unknown key %s in configure or bad type %s\",\n                                                  key, type(kwargs[key]))", "label": 1}
{"code": "function validateTemplate(template) {\n      var hide = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n      var results = new ValidationResults();\n\n      var indent = function indent(string) {\n        var count = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 4;\n        var space = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : ' ';\n        return string.split('\\n').map(function (s) {\n          return s.trim().replace(/(^)/gm, \"$1\".concat(space.repeat(count)));\n        }).join('\\n');\n      };\n\n      if (typeof template.name === 'undefined') {\n        results.errors.push(new Error((0, _neTagFns.customDedent)({\n          dropLowest: true\n        })(_templateObject2())));\n      }\n\n      if (!(0, _neTypes.extendsFrom)(template.name, String)) {\n        results.errors.push(new Error((0, _neTagFns.customDedent)({\n          dropLowest: true\n        })(_templateObject3())));\n      }\n\n      if (typeof template.schema === 'undefined') {\n        results.errors.push(new Error((0, _neTagFns.customDedent)({\n          dropLowest: true\n        })(_templateObject4())));\n      }\n\n      if (!(0, _neTypes.extendsFrom)(template.schema, String)) {\n        results.errors.push(new Error((0, _neTagFns.customDedent)({\n          dropLowest: true\n        })(_templateObject5())));\n      }\n\n      if (!(0, _neTypes.extendsFrom)(template.resolvers, Object) // Supports 95% of objects\n      || (0, _typeof2.default)(template.resolvers) !== 'object' // Supports Object.create(null)\n      ) {\n          results.errors.push(new Error((0, _neTagFns.customDedent)({\n            dropLowest: true\n          })(_templateObject6())));\n        }\n\n      if (typeof template.docs === 'undefined') {\n        results.errors.push(new Error((0, _neTagFns.customDedent)({\n          dropLowest: true\n        })(_templateObject7())));\n      }\n\n      if (!(0, _neTypes.extendsFrom)(template.docs, Object) // Supports 95% of objects\n      || (0, _typeof2.default)(template.docs) !== 'object' // Supports Object.create(null)\n      ) {\n          var dr = '\\x1b[31m',\n              br = '\\x1b[91m';\n          var b1 = '\\x1b[1m',\n              b0 = '\\x1b[22m';\n          var bb = '\\x1b[90m';\n          var dg = '\\x1b[37m',\n              bg = '\\x1b[97m';\n          var a0 = '\\x1b[0m';\n          var gr = '\\x1b[32m',\n              bgr = '\\x1b[92m';\n          results.errors.push(new Error((0, _neTagFns.customDedent)({\n            dropLowest: true\n          })(_templateObject8(), bb, dg, b1, b0, gr, dg, b1, b0, b1, b0, gr, dg, gr, dg, gr, dg, b1, b0, gr, dg, b1, b0, gr, dg)));\n        }\n\n      if (!results.valid) {\n        var errorStrings = [];\n        var _iteratorNormalCompletion = true;\n        var _didIteratorError = false;\n        var _iteratorError = undefined;\n\n        try {\n          for (var _iterator = results.errors[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n            var _error = _step.value;\n            var message = _error.message,\n                stack = _error.stack;\n            stack = stack.trim().split('\\n').splice(message.split('\\n').length).map(function (s) {\n              return s.trim();\n            }).join('\\n');\n            message = message.replace(/(Error:\\s)/, '$1\\n').trim();\n            errorStrings.push(\"\\x1B[31;1m\".concat(message, \"\\x1B[0m\\n\") + indent(stack));\n          }\n        } catch (err) {\n          _didIteratorError = true;\n          _iteratorError = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion && _iterator.return != null) {\n              _iterator.return();\n            }\n          } finally {\n            if (_didIteratorError) {\n              throw _iteratorError;\n            }\n          }\n        }\n\n        var error = new Error((0, _neTagFns.customDedent)({\n          dropLowest: true\n        })(_templateObject9()).replace(/@template/, indent(_i(template))).replace(/@errors/, errorStrings.join('\\n\\n')));\n        error.stack = error.message;\n        error.message = '';\n        if (!hide) throw error;\n      }\n\n      return results;\n    }", "label": 3}
{"code": "public static nstrafficdomain_bridgegroup_binding[] get(nitro_service service, Long td) throws Exception{\n\t\tnstrafficdomain_bridgegroup_binding obj = new nstrafficdomain_bridgegroup_binding();\n\t\tobj.set_td(td);\n\t\tnstrafficdomain_bridgegroup_binding response[] = (nstrafficdomain_bridgegroup_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (m *MockEmbed) ImplicitPackage(arg0 string, arg1 imp1.ImpT, arg2 []imp1.ImpT, arg3 *imp1.ImpT, arg4 chan imp1.ImpT) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"ImplicitPackage\", arg0, arg1, arg2, arg3, arg4)\n}", "label": 5}
{"code": "function createFromMap(mapObject, content, url) {\n  url = url || '<source>';\n  if ('string' == typeof mapObject) {\n    try {\n      mapObject = JSON.parse(mapObject);\n    } catch (err) {\n      mapObject = {\n        version: 3,\n        names: [],\n        mappings: '',\n        file: ''\n      };\n    }\n  }\n  if (emptySources(mapObject)) {\n    mapObject.sources = [url];\n    mapObject.sourcesContent = [content];\n  }\n\n  return SourceMapGenerator.fromSourceMap(new SourceMapConsumer(mapObject));\n}", "label": 3}
{"code": "private static Query buildQuery(ClassDescriptor cld)\r\n    {\r\n        FieldDescriptor[] pkFields = cld.getPkFields();\r\n        Criteria crit = new Criteria();\r\n\r\n        for(int i = 0; i < pkFields.length; i++)\r\n        {\r\n            crit.addEqualTo(pkFields[i].getAttributeName(), null);\r\n        }\r\n        return new QueryByCriteria(cld.getClassOfObject(), crit);\r\n    }", "label": 0}
{"code": "def from_dict(cls, serialized):\n        '''Create a new ErrorInfo object from a JSON deserialized\n        dictionary\n        @param serialized The JSON object {dict}\n        @return ErrorInfo object\n        '''\n        if serialized is None:\n            return None\n        macaroon = serialized.get('Macaroon')\n        if macaroon is not None:\n            macaroon = bakery.Macaroon.from_dict(macaroon)\n        path = serialized.get('MacaroonPath')\n        cookie_name_suffix = serialized.get('CookieNameSuffix')\n        visit_url = serialized.get('VisitURL')\n        wait_url = serialized.get('WaitURL')\n        interaction_methods = serialized.get('InteractionMethods')\n        return ErrorInfo(macaroon=macaroon, macaroon_path=path,\n                         cookie_name_suffix=cookie_name_suffix,\n                         visit_url=visit_url, wait_url=wait_url,\n                         interaction_methods=interaction_methods)", "label": 1}
{"code": "function process(data) {\n  var uuid = data.substr(2,2) + data.substr(0,2);\n\n  // NOTE: this is for legacy compatibility\n  var advertiserData = {\n    serviceData: {\n      uuid: uuid,\n      data: data.substr(4)\n    }\n  };\n\n  gattservices.process(advertiserData);\n\n  return advertiserData.serviceData;\n}", "label": 3}
{"code": "def _build_named_aggs\n      named_aggs = {}\n      @_indexes.each do |index|\n        index.types.each do |type|\n          type._agg_defs.each do |agg_name, prc|\n            named_aggs[agg_name] = prc.call\n          end\n        end\n      end\n      named_aggs\n    end", "label": 4}
{"code": "public static void writeStreamToStream(InputStream input, OutputStream output)\r\n  throws IOException {\r\n    byte[] buffer = new byte[4096];\r\n    while (true) {\r\n      int len = input.read(buffer);\r\n      if (len == -1) {\r\n        break;\r\n      }\r\n      output.write(buffer, 0, len);\r\n    }\r\n  }", "label": 0}
{"code": "def g_subset(g, atwts, atwt,\n            digits=_DEF.SYMM_ATWT_ROUND_DIGITS):\n    \"\"\" Extract a subset of a geometry matching a desired atom.\n\n    .. todo:: Complete g_subset docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Ensure g and atwts are n-D vectors\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n    atwts = make_nd_vec(atwts, nd=None, t=np.float64, norm=False)\n\n    # Ensure dims match (should already be checked at object creation...)\n    if not (len(g) == 3*len(atwts)):\n        raise ValueError(\"Dim mismatch [len(g) != 3*len(ats)].\")\n    ## end if\n\n    # Pull into coordinate groups\n    co = np.split(g, g.shape[0] // 3)\n\n    # Filter by the indicated atomic weight\n    cf = [c for (c,a) in zip(co, atwts) if \\\n                    np.round(a, digits) == np.round(atwt, digits)]\n\n    # Expand back to single vector, if possible\n    if not cf == []:\n        g_sub = np.concatenate(cf, axis=0)\n        g_sub = g_sub.reshape((g_sub.shape[0],1))\n    else:\n        g_sub = []\n    ## end if\n\n    # Return the subset\n    return g_sub", "label": 1}
{"code": "func (v ContainerView) Retrieve(ctx context.Context, kind []string, ps []string, dst interface{}) error {\n\tpc := property.DefaultCollector(v.Client())\n\n\tospec := types.ObjectSpec{\n\t\tObj:  v.Reference(),\n\t\tSkip: types.NewBool(true),\n\t\tSelectSet: []types.BaseSelectionSpec{\n\t\t\t&types.TraversalSpec{\n\t\t\t\tType: v.Reference().Type,\n\t\t\t\tPath: \"view\",\n\t\t\t},\n\t\t},\n\t}\n\n\tvar pspec []types.PropertySpec\n\n\tif len(kind) == 0 {\n\t\tkind = []string{\"ManagedEntity\"}\n\t}\n\n\tfor _, t := range kind {\n\t\tspec := types.PropertySpec{\n\t\t\tType: t,\n\t\t}\n\n\t\tif len(ps) == 0 {\n\t\t\tspec.All = types.NewBool(true)\n\t\t} else {\n\t\t\tspec.PathSet = ps\n\t\t}\n\n\t\tpspec = append(pspec, spec)\n\t}\n\n\treq := types.RetrieveProperties{\n\t\tSpecSet: []types.PropertyFilterSpec{\n\t\t\t{\n\t\t\t\tObjectSet: []types.ObjectSpec{ospec},\n\t\t\t\tPropSet:   pspec,\n\t\t\t},\n\t\t},\n\t}\n\n\tres, err := pc.RetrieveProperties(ctx, req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif d, ok := dst.(*[]types.ObjectContent); ok {\n\t\t*d = res.Returnval\n\t\treturn nil\n\t}\n\n\treturn mo.LoadRetrievePropertiesResponse(res, dst)\n}", "label": 5}
{"code": "def DoxyEmitter(source, target, env):\n   \"\"\"Doxygen Doxyfile emitter\"\"\"\n   # possible output formats and their default values and output locations\n   output_formats = {\n      \"HTML\": (\"YES\", \"html\"),\n      \"LATEX\": (\"YES\", \"latex\"),\n      \"RTF\": (\"NO\", \"rtf\"),\n      \"MAN\": (\"YES\", \"man\"),\n      \"XML\": (\"NO\", \"xml\"),\n   }\n\n   data = DoxyfileParse(source[0].get_contents())\n\n   targets = []\n   out_dir = data.get(\"OUTPUT_DIRECTORY\", \".\")\n   if not os.path.isabs(out_dir):\n      conf_dir = os.path.dirname(str(source[0]))\n      out_dir = os.path.join(conf_dir, out_dir)\n\n   # add our output locations\n   for (k, v) in output_formats.items():\n      if data.get(\"GENERATE_\" + k, v[0]) == \"YES\":\n         targets.append(env.Dir( os.path.join(out_dir, data.get(k + \"_OUTPUT\", v[1]))) )\n\n   # add the tag file if neccessary:\n   tagfile = data.get(\"GENERATE_TAGFILE\", \"\")\n   if tagfile != \"\":\n      if not os.path.isabs(tagfile):\n         conf_dir = os.path.dirname(str(source[0]))\n         tagfile = os.path.join(conf_dir, tagfile)\n      targets.append(env.File(tagfile))\n\n   # don't clobber targets\n   for node in targets:\n      env.Precious(node)\n\n   # set up cleaning stuff\n   for node in targets:\n      env.Clean(node, node)\n\n   return (targets, source)", "label": 1}
{"code": "def emendation_field_value(form, original, key)\n      return params[:amendment][:emendation_params][key] if params[:amendment].present?\n\n      present(form.object.send(original)).send(key)\n    end", "label": 4}
{"code": "def install_file_legacy(path, sudo=False, from_path=None, **substitutions):\n    '''Install file with path on the host target.\n\n    The from file is the first of this list which exists:\n     * custom file\n     * custom file.template\n     * common file\n     * common file.template\n    '''\n    # source paths 'from_custom' and 'from_common'\n    from_path = from_path or path\n    # remove beginning '/' (if any), eg '/foo/bar' -> 'foo/bar'\n    from_tail = join('files', from_path.lstrip(os.sep))\n    if from_path.startswith('~/'):\n        from_tail = join('files', 'home', 'USERNAME',\n                         from_path[2:])  # without beginning '~/'\n    from_common = join(FABFILE_DATA_DIR, from_tail)\n    from_custom = join(FABSETUP_CUSTOM_DIR, from_tail)\n\n    # target path 'to_' (path or tempfile)\n    for subst in ['SITENAME', 'USER', 'ADDON', 'TASK']:\n        sitename = substitutions.get(subst, False)\n        if sitename:\n            path = path.replace(subst, sitename)\n    to_ = path\n    if sudo:\n        to_ = join(os.sep, 'tmp', 'fabsetup_' + os.path.basename(path))\n    path_dir = dirname(path)\n\n    # copy file\n    if isfile(from_custom):\n        run(flo('mkdir -p  {path_dir}'))\n        put(from_custom, to_)\n    elif isfile(from_custom + '.template'):\n        _install_file_from_template_legacy(from_custom + '.template', to_=to_,\n                                    **substitutions)\n    elif isfile(from_common):\n        run(flo('mkdir -p  {path_dir}'))\n        put(from_common, to_)\n    else:\n        _install_file_from_template_legacy(from_common + '.template', to_=to_,\n                                    **substitutions)\n    if sudo:\n        run(flo('sudo mv --force  {to_}  {path}'))", "label": 1}
{"code": "func (l HostFirewallRulesetList) ByRule(rule types.HostFirewallRule) HostFirewallRulesetList {\n\tvar matches HostFirewallRulesetList\n\n\tfor _, rs := range l {\n\t\tfor _, r := range rs.Rule {\n\t\t\tif r.PortType != rule.PortType ||\n\t\t\t\tr.Protocol != rule.Protocol ||\n\t\t\t\tr.Direction != rule.Direction {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif r.EndPort == 0 && rule.Port == r.Port ||\n\t\t\t\trule.Port >= r.Port && rule.Port <= r.EndPort {\n\t\t\t\tmatches = append(matches, rs)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\treturn matches\n}", "label": 5}
{"code": "function normalize(obj, caseType = 'camel') {\n  let ret = obj;\n  const method = methods[caseType];\n\n  if (Array.isArray(obj)) {\n    ret = [];\n    let i = 0;\n\n    while (i < obj.length) {\n      ret.push(normalize(obj[i], caseType));\n      ++i;\n    }\n  } else if (isPlainObject(obj)) {\n    ret = {};\n    // eslint-disable-next-line guard-for-in, no-restricted-syntax\n    for (const k in obj) {\n      ret[method(k)] = normalize(obj[k], caseType);\n    }\n  }\n\n  return ret;\n}", "label": 3}
{"code": "public function createCluster($projectId, $region, $cluster, array $optionalArgs = [])\n    {\n        $request = new CreateClusterRequest();\n        $request->setProjectId($projectId);\n        $request->setRegion($region);\n        $request->setCluster($cluster);\n        if (isset($optionalArgs['requestId'])) {\n            $request->setRequestId($optionalArgs['requestId']);\n        }\n\n        return $this->startOperationsCall(\n            'CreateCluster',\n            $optionalArgs,\n            $request,\n            $this->getOperationsClient()\n        )->wait();\n    }", "label": 2}
{"code": "public static csvserver_appflowpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tcsvserver_appflowpolicy_binding obj = new csvserver_appflowpolicy_binding();\n\t\tobj.set_name(name);\n\t\tcsvserver_appflowpolicy_binding response[] = (csvserver_appflowpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static base_response delete(nitro_service client, dnstxtrec resource) throws Exception {\n\t\tdnstxtrec deleteresource = new dnstxtrec();\n\t\tdeleteresource.domain = resource.domain;\n\t\tdeleteresource.String = resource.String;\n\t\tdeleteresource.recordid = resource.recordid;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def add_atomic_unset(document)\n      document.flagged_for_destroy = true\n      (delayed_atomic_unsets[document.association_name.to_s] ||= []).push(document)\n    end", "label": 4}
{"code": "public static base_responses delete(nitro_service client, String network[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (network != null && network.length > 0) {\n\t\t\troute6 deleteresources[] = new route6[network.length];\n\t\t\tfor (int i=0;i<network.length;i++){\n\t\t\t\tdeleteresources[i] = new route6();\n\t\t\t\tdeleteresources[i].network = network[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def create_group_data_criteria(preconditions, type, value, parent_id, id, standard_category, qds_data_type)\n      extract_group_data_criteria_tree(HQMF::DataCriteria::UNION,preconditions, type, parent_id)\n    end", "label": 4}
{"code": "function(aliasOrModel) {\n      var model,\n        alias = this.__findAlias(aliasOrModel);\n      if (alias) {\n        model = this.__currentObjectModels[alias];\n        delete this.__currentObjectModels[alias];\n        this.__updateCache(model);\n      }\n      this.resetUpdating();\n    }", "label": 3}
{"code": "public function setHttpRequest($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\ErrorReporting\\V1beta1\\HttpRequestContext::class);\n        $this->http_request = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function _validateRootAttributes (view, model, cellValidator) {\n  const results = [\n    _validateCells(view, model, cellValidator)\n  ]\n\n  const knownAttributes = ['version', 'type', 'cells', 'cellDefinitions']\n  const unknownAttributes = _.difference(Object.keys(view), knownAttributes)\n  results.push({\n    errors: [],\n    warnings: _.map(unknownAttributes, (attr) => {\n      return {\n        path: '#',\n        message: `Unrecognized attribute \"${attr}\"`\n      }\n    })\n  })\n\n  return aggregateResults(results)\n}", "label": 3}
{"code": "public function setTranslatedContent($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\TextSnippet::class);\n        $this->translated_content = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function executePartition(PartitionInterface $partition, array $options = [])\n    {\n        if ($partition instanceof QueryPartition) {\n            return $this->executeQuery($partition);\n        } elseif ($partition instanceof ReadPartition) {\n            return $this->executeRead($partition);\n        }\n\n        throw new \\BadMethodCallException('Unsupported partition type.');\n    }", "label": 2}
{"code": "def setup_local_data_path(force=false)\n      if @local_data_path.nil?\n        @logger.warn(\"No local data path is set. Local data cannot be stored.\")\n        return\n      end\n\n      @logger.info(\"Local data path: #{@local_data_path}\")\n\n      # If the local data path is a file, then we are probably seeing an\n      # old (V1) \"dotfile.\" In this case, we upgrade it. The upgrade process\n      # will remove the old data file if it is successful.\n      if @local_data_path.file?\n        upgrade_v1_dotfile(@local_data_path)\n      end\n\n      # If we don't have a root path, we don't setup anything\n      return if !force && root_path.nil?\n\n      begin\n        @logger.debug(\"Creating: #{@local_data_path}\")\n        FileUtils.mkdir_p(@local_data_path)\n        # Create the rgloader/loader file so we can use encoded files.\n        loader_file = @local_data_path.join(\"rgloader\", \"loader.rb\")\n        if !loader_file.file?\n          source_loader = Vagrant.source_root.join(\"templates/rgloader.rb\")\n          FileUtils.mkdir_p(@local_data_path.join(\"rgloader\").to_s)\n          FileUtils.cp(source_loader.to_s, loader_file.to_s)\n        end\n      rescue Errno::EACCES\n        raise Errors::LocalDataDirectoryNotAccessible,\n          local_data_path: @local_data_path.to_s\n      end\n    end", "label": 4}
{"code": "function (batch, xhr) {\n                for (var i = 0, requestId; i < batch.length; i++) {\n                    requestId = this._getRequestId(batch[i].method, batch[i].params);\n                    this._rejectPromise(this._deferreds[requestId], xhr);\n                    delete this._deferreds[requestId];\n                }\n            }", "label": 3}
{"code": "public static base_responses clear(nitro_service client, gslbldnsentries resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tgslbldnsentries clearresources[] = new gslbldnsentries[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tclearresources[i] = new gslbldnsentries();\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, clearresources,\"clear\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func PgDbRoleSettingBySetdatabaseSetrole(db XODB, setdatabase pgtypes.Oid, setrole pgtypes.Oid) (*PgDbRoleSetting, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, setdatabase, setrole, setconfig ` +\n\t\t`FROM pg_catalog.pg_db_role_setting ` +\n\t\t`WHERE setdatabase = $1 AND setrole = $2`\n\n\t// run query\n\tXOLog(sqlstr, setdatabase, setrole)\n\tpdrs := PgDbRoleSetting{}\n\n\terr = db.QueryRow(sqlstr, setdatabase, setrole).Scan(&pdrs.Tableoid, &pdrs.Cmax, &pdrs.Xmax, &pdrs.Cmin, &pdrs.Xmin, &pdrs.Ctid, &pdrs.Setdatabase, &pdrs.Setrole, &pdrs.Setconfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pdrs, nil\n}", "label": 5}
{"code": "def in_use?(index)\n      results = []\n      index.each do |entry|\n        box_data = entry.extra_data[\"box\"]\n        next if !box_data\n\n        # If all the data matches, record it\n        if box_data[\"name\"] == self.name &&\n          box_data[\"provider\"] == self.provider.to_s &&\n          box_data[\"version\"] == self.version.to_s\n          results << entry\n        end\n      end\n\n      return nil if results.empty?\n      results\n    end", "label": 4}
{"code": "def _clearQuantity(self, offbids, gen):\n        \"\"\" Computes the cleared bid quantity from total dispatched quantity.\n        \"\"\"\n        # Filter out offers/bids not applicable to the generator in question.\n        gOffbids = [offer for offer in offbids if offer.generator == gen]\n\n        # Offers/bids within valid price limits (not withheld).\n        valid = [ob for ob in gOffbids if not ob.withheld]\n\n        # Sort offers by price in ascending order and bids in decending order.\n        valid.sort(key=lambda ob: ob.price, reverse=[False, True][gen.is_load])\n\n        acceptedQty = 0.0\n        for ob in valid:\n            # Compute the fraction of the block accepted.\n            accepted = (ob.totalQuantity - acceptedQty) / ob.quantity\n\n            # Clip to the range 0-1.\n            if accepted > 1.0:\n                accepted = 1.0\n            elif accepted < 1.0e-05:\n                accepted = 0.0\n\n            ob.clearedQuantity = accepted * ob.quantity\n\n            ob.accepted = (accepted > 0.0)\n\n            # Log the event.\n#            if ob.accepted:\n#                logger.info(\"%s [%s, %.3f, %.3f] accepted at %.2f MW.\" %\n#                    (ob.__class__.__name__, ob.generator.name, ob.quantity,\n#                     ob.price, ob.clearedQuantity))\n#            else:\n#                logger.info(\"%s [%s, %.3f, %.3f] rejected.\" %\n#                    (ob.__class__.__name__, ob.generator.name, ob.quantity,\n#                     ob.price))\n\n            # Increment the accepted quantity.\n            acceptedQty += ob.quantity", "label": 1}
{"code": "public function lookup(Key $key, array $options = [])\n    {\n        $res = $this->lookupBatch([$key], $options);\n\n        return (isset($res['found'][0]))\n            ? $res['found'][0]\n            : null;\n    }", "label": 2}
{"code": "public function flush(array $items = [])\n    {\n        if (! $this->callFunc($items)) {\n            $this->handleFailure($this->id, $items);\n            return false;\n        }\n        return true;\n    }", "label": 2}
{"code": "func (a *allocator) GetDefaultAddressSpaces() (string, string, error) {\n\tres := &api.GetAddressSpacesResponse{}\n\tif err := a.call(\"GetDefaultAddressSpaces\", nil, res); err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\treturn res.LocalDefaultAddressSpace, res.GlobalDefaultAddressSpace, nil\n}", "label": 5}
{"code": "func NotFoundErrorf(format string, params ...interface{}) error {\n\treturn notFound(fmt.Sprintf(format, params...))\n}", "label": 5}
{"code": "public static void generateJavaFiles(String requirementsFolder,\n            String platformName, String src_test_dir, String tests_package,\n            String casemanager_package, String loggingPropFile)\n            throws Exception {\n\n        File reqFolder = new File(requirementsFolder);\n        if (reqFolder.isDirectory()) {\n            for (File f : reqFolder.listFiles()) {\n                if (f.getName().endsWith(\".story\")) {\n                    try {\n                        SystemReader.generateJavaFilesForOneStory(\n                                f.getCanonicalPath(), platformName,\n                                src_test_dir, tests_package,\n                                casemanager_package, loggingPropFile);\n                    } catch (IOException e) {\n                        String message = \"ERROR: \" + e.getMessage();\n                        logger.severe(message);\n                        throw new BeastException(message, e);\n                    }\n                }\n            }\n            for (File f : reqFolder.listFiles()) {\n                if (f.isDirectory()) {\n                    SystemReader.generateJavaFiles(requirementsFolder\n                            + File.separator + f.getName(), platformName,\n                            src_test_dir, tests_package + \".\" + f.getName(),\n                            casemanager_package, loggingPropFile);\n                }\n            }\n        } else if (reqFolder.getName().endsWith(\".story\")) {\n            SystemReader.generateJavaFilesForOneStory(requirementsFolder,\n                    platformName, src_test_dir, tests_package,\n                    casemanager_package, loggingPropFile);\n        } else {\n            String message = \"No story file found in \" + requirementsFolder;\n            logger.severe(message);\n            throw new BeastException(message);\n        }\n\n    }", "label": 0}
{"code": "public function setStates($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::ENUM, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferState::class);\n        $this->states = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def filter_array_by_labels(all_issues)\n      filtered_issues = include_issues_by_labels(all_issues)\n      filtered_issues = exclude_issues_by_labels(filtered_issues)\n      exclude_issues_without_labels(filtered_issues)\n    end", "label": 4}
{"code": "public static base_response enable(nitro_service client, String id) throws Exception {\n\t\tInterface enableresource = new Interface();\n\t\tenableresource.id = id;\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "function(comparator, nullsFirst, ignorePrimitive)\n  {\n    var cmp = comparator ? createComparator( comparator, nullsFirst ) : this.comparator;\n\n    if ( !isSorted( cmp, this ) || ( !ignorePrimitive && !cmp && isPrimitiveArray( this ) ) )\n    {\n      AP.sort.call( this, cmp );\n\n      this.trigger( Collection.Events.Sort, [this] );\n    }\n\n    return this;\n  }", "label": 3}
{"code": "public Response save() throws RequestException, LocalOperationException {\n        Map<String, Object> templateData = new HashMap<String, Object>();\n        templateData.put(\"name\", name);\n\n        options.put(\"steps\", steps.toMap());\n\n        templateData.put(\"template\", options);\n        Request request = new Request(transloadit);\n        return new Response(request.post(\"/templates\", templateData));\n    }", "label": 0}
{"code": "public static aaagroup_vpnsessionpolicy_binding[] get(nitro_service service, String groupname) throws Exception{\n\t\taaagroup_vpnsessionpolicy_binding obj = new aaagroup_vpnsessionpolicy_binding();\n\t\tobj.set_groupname(groupname);\n\t\taaagroup_vpnsessionpolicy_binding response[] = (aaagroup_vpnsessionpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getNotIncrementedTopicPayloads(previousConsumerReadOffset, consumer) {\n    let notIncrementedTopicPayloads = consumer.topicPayloads.filter((topicPayload) => {\n        let {topic, partition, offset: currentOffset} = topicPayload;\n        let previousTopicPayloadForPartition = _.find(previousConsumerReadOffset, {topic, partition});\n        return previousTopicPayloadForPartition && currentOffset === previousTopicPayloadForPartition.offset;\n    });\n\n    return notIncrementedTopicPayloads;\n}", "label": 3}
{"code": "private synchronized void setFactoryMethod(Method newMethod)\r\n    {\r\n        if (newMethod != null)\r\n        {\r\n            // make sure it's a no argument method\r\n            if (newMethod.getParameterTypes().length > 0)\r\n            {\r\n                throw new MetadataException(\r\n                    \"Factory methods must be zero argument methods: \"\r\n                        + newMethod.getClass().getName()\r\n                        + \".\"\r\n                        + newMethod.getName());\r\n            }\r\n\r\n            // make it accessible if it's not already\r\n            if (!newMethod.isAccessible())\r\n            {\r\n                newMethod.setAccessible(true);\r\n            }\r\n        }\r\n\r\n        this.factoryMethod = newMethod;\r\n    }", "label": 0}
{"code": "def execute_script(file_name, redis_pool, options = {})\n      redis(redis_pool) do |conn|\n        sha = script_sha(conn, file_name)\n        conn.evalsha(sha, options)\n      end\n    end", "label": 4}
{"code": "function compile (extension, content, options, fn) {\n    // allow optional options argument\n    if (_.isFunction(options)) {\n      fn = options;\n      options = {};\n    }\n\n    var config = _.clone(compile.configuration)\n      , args = flags.slice(0)\n      , buffer = ''\n      , errors = ''\n      , compressor;\n\n    if (compile.configuration.type) {\n      config.type = extension;\n    }\n\n    // generate the --key value options, both the key and the value should added\n    // seperately to the `args` array or the child_process will chocke.\n    Object.keys(config).filter(function filter (option) {\n      return config[option];\n    }).forEach(function format (option) {\n      var bool = _.isBoolean(config[option]);\n\n      if (!bool || config[option]) {\n        args.push('--' + option);\n        if (!bool) args.push(config[option]);\n      }\n    });\n\n    // apply the configuration\n    _.extend(config, options);\n\n    // spawn the shit and set the correct encoding\n    compressor = spawn(type, args);\n    compressor.stdout.setEncoding('utf8');\n    compressor.stderr.setEncoding('utf8');\n\n    /**\n     * Buffer up the results so we can concat them once the compression is\n     * finished.\n     *\n     * @param {Buffer} chunk\n     * @api private\n     */\n\n    compressor.stdout.on('data', function data (chunk) {\n      buffer += chunk;\n    });\n\n    compressor.stderr.on('data', function data (err) {\n      errors += err;\n    });\n\n    /**\n     * The compressor has finished can we now process the data and see if it was\n     * a success.\n     *\n     * @param {Number} code\n     * @api private\n     */\n\n    compressor.on('close', function close (code) {\n      // invalid states\n      if (errors.length) return fn(new Error(errors));\n      if (code !== 0) return fn(new Error('process exited with code ' + code));\n      if (!buffer.length) return fn(new Error('no data returned ' + type + args));\n\n      // correctly processed the data\n      fn(null, buffer);\n    });\n\n    // write out the content that needs to be minified\n    compressor.stdin.end(content);\n  }", "label": 3}
{"code": "private TransactionManager getTransactionManager()\r\n    {\r\n        TransactionManager retval = null;\r\n        try\r\n        {\r\n            if (log.isDebugEnabled()) log.debug(\"getTransactionManager called\");\r\n            retval = TransactionManagerFactoryFactory.instance().getTransactionManager();\r\n        }\r\n        catch (TransactionManagerFactoryException e)\r\n        {\r\n            log.warn(\"Exception trying to obtain TransactionManager from Factory\", e);\r\n            e.printStackTrace();\r\n        }\r\n        return retval;\r\n    }", "label": 0}
{"code": "def document_for_full_update(model)\n      RSolr::Xml::Document.new(\n        id: Adapters::InstanceAdapter.adapt(model).index_id,\n        type: Util.superclasses_for(model.class).map(&:name)\n      )\n    end", "label": 4}
{"code": "func ReleasePorts(portMapper *portmapper.PortMapper, bindings []types.PortBinding) error {\n\tvar errorBuf bytes.Buffer\n\n\t// Attempt to release all port bindings, do not stop on failure\n\tfor _, m := range bindings {\n\t\tif err := releasePort(portMapper, m); err != nil {\n\t\t\terrorBuf.WriteString(fmt.Sprintf(\"\\ncould not release %v because of %v\", m, err))\n\t\t}\n\t}\n\n\tif errorBuf.Len() != 0 {\n\t\treturn errors.New(errorBuf.String())\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def to_h\n      self.class.fields.inject({}) do |h, (k, opts)|\n        if opts[:as].nil?\n          h[k] = self.public_send(k)\n        else\n          h[k] = self.public_send(opts[:as])\n        end\n\n        if !h[k].nil? && !h[k].is_a?(Array) && h[k].respond_to?(:to_h)\n          h[k] = h[k].to_h\n        end\n\n        h\n      end\n    end", "label": 4}
{"code": "public function setOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\TransactionOptions::class);\n        $this->options = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func startsWith(fl FieldLevel) bool {\n\treturn strings.HasPrefix(fl.Field().String(), fl.Param())\n}", "label": 5}
{"code": "def page(opts = {})\n      class_name = opts.is_a?(Hash) ? opts.fetch(:class, nil) : opts\n\n      source = get_source\n\n      # current_context may be nil which breaks start_with\n      if current_context && current_context.start_with?('WEBVIEW')\n        parser = @android_html_parser ||= Nokogiri::HTML::SAX::Parser.new(Appium::Common::HTMLElements.new)\n        parser.document.reset\n        parser.document.filter = class_name\n        parser.parse source\n        result = parser.document.result\n        puts result\n        result\n      else\n        parser = Nokogiri::XML::SAX::Parser.new(UITestElementsPrinter.new)\n        if class_name\n          parser.document.filter = class_name.is_a?(Symbol) ? class_name.to_s : class_name\n        end\n        parser.parse source\n        nil\n      end\n    end", "label": 4}
{"code": "public RedwoodConfiguration loggingClass(final String classToIgnoreInTraces){\r\n    tasks.add(new Runnable() { public void run() { Redwood.addLoggingClass(classToIgnoreInTraces); } });\r\n    return this;\r\n  }", "label": 0}
{"code": "public function annotateText($document, $features, array $optionalArgs = [])\n    {\n        $request = new AnnotateTextRequest();\n        $request->setDocument($document);\n        $request->setFeatures($features);\n        if (isset($optionalArgs['encodingType'])) {\n            $request->setEncodingType($optionalArgs['encodingType']);\n        }\n\n        return $this->startCall(\n            'AnnotateText',\n            AnnotateTextResponse::class,\n            $optionalArgs,\n            $request\n        )->wait();\n    }", "label": 2}
{"code": "public function rollback()\n    {\n        $migrations = $this->getLast($this->getMigrations(true));\n\n        $this->requireFiles($migrations->toArray());\n\n        $migrated = [];\n\n        foreach ($migrations as $migration) {\n            $data = $this->find($migration);\n\n            if ($data->count()) {\n                $migrated[] = $migration;\n\n                $this->down($migration);\n\n                $data->delete();\n            }\n        }\n\n        return $migrated;\n    }", "label": 2}
{"code": "public function releaseKey($key)\n    {\n        $this->executor->execute(DriverCommand::SEND_KEYS_TO_ACTIVE_ELEMENT, [\n            'value' => [(string) $key],\n        ]);\n\n        return $this;\n    }", "label": 2}
{"code": "protected boolean checkPackageLocators(String classPackageName) {\n\t\tif (packageLocators != null && !disablePackageLocatorsScanning && classPackageName.length() > 0\n\t\t\t\t&& (packageLocatorsBasePackage == null || classPackageName.startsWith(packageLocatorsBasePackage))) {\n\t\t\tfor (String packageLocator : packageLocators) {\n\t\t\t\tString[] splitted = classPackageName.split(\"\\\\.\");\n\n\t\t\t\tif (es.cenobit.struts2.json.util.StringUtils.contains(splitted, packageLocator, false))\n\t\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "label": 0}
{"code": "def edit(self, resource): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Edit a device's attachment.\n\n        :param resource: :class:`attachments.Attachment <attachments.Attachment>` object\n        :return: :class:`attachments.Attachment <attachments.Attachment>` object\n        :rtype: attachments.Attachment\n        \"\"\"\n        schema = AttachmentSchema(exclude=('id', 'created', 'updated', 'size', 'path', 'device_id'))\n        json = self.service.encode(schema, resource)\n\n        schema = AttachmentSchema()\n        resp = self.service.edit(self._base(resource.device_id), resource.id, json)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public static function getMixedValue(array $data, $param)\n    {\n        $casted = self::castToArray($param);\n\n        $data['model'] = $param;\n\n        foreach ($data as $key => $value) {\n            if (isset($casted[$key])) {\n                $data[$key] = $casted[$key];\n            }\n        }\n\n        return $data;\n    }", "label": 2}
{"code": "def traverse_frozen_data(data_structure):\n    \"\"\"Yields the leaves of the frozen data-structure pre-order.\n\n    It will produce the same order as one would write the data-structure.\"\"\"\n    parent_stack = [data_structure]\n    while parent_stack:\n        node = parent_stack.pop(0)\n        # We don't iterate strings\n        tlen = -1\n        if not isinstance(node, _string_types):\n            # If item has a length we freeze it\n            try:\n                tlen = len(node)\n            except:\n                pass\n        if tlen == -1:\n            yield node\n        else:\n            parent_stack = list(node) + parent_stack", "label": 1}
{"code": "public function read($number)\n    {\n        if ($number > $this->last_read_post_number) {\n            $this->last_read_post_number = $number;\n            $this->last_read_at = Carbon::now();\n\n            $this->raise(new UserRead($this));\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function memoize(fn) {\n  const dataProp = '__data__.string.__data__',\n    memFn = _.memoize.apply(_, _.slice(arguments)),\n    report = _.throttle(reportMemoryLeak, minute),\n    controlFn = function () {\n      const result = memFn.apply(null, _.slice(arguments));\n\n      if (_.size(_.get(memFn, `cache.${dataProp}`)) >= memoryLeakThreshold) {\n        report(fn, _.get(memFn, `cache.${dataProp}`));\n      }\n\n      return result;\n    };\n\n  Object.defineProperty(controlFn, 'cache', defineWritable({\n    get() { return memFn.cache; },\n    set(value) { memFn.cache = value; }\n  }));\n\n  return controlFn;\n}", "label": 3}
{"code": "def update_property(tree_to_update, xpath_root, xpaths, prop, values, supported=None):\n    \"\"\"\n    Either update the tree the default way, or call the custom updater\n\n    Default Way: Existing values in the tree are overwritten. If xpaths contains a single path,\n    then each value is written to the tree at that path. If xpaths contains a list of xpaths,\n    then the values corresponding to each xpath index are written to their respective locations.\n    In either case, empty values are ignored.\n\n    :param tree_to_update: the XML tree compatible with element_utils to be updated\n    :param xpath_root: the XPATH location shared by all the xpaths passed in\n    :param xpaths: a string or a list of strings representing the XPATH location(s) to which to write values\n    :param prop: the name of the property of the parser containing the value(s) with which to update the tree\n    :param values: a single value, or a list of values to write to the specified XPATHs\n\n    :see: ParserProperty for more on custom updaters\n\n    :return: a list of all elements updated by this operation\n    \"\"\"\n\n    if supported and prop.startswith('_') and prop.strip('_') in supported:\n        values = u''  # Remove alternate elements: write values only to primary location\n    else:\n        values = get_default_for(prop, values)  # Enforce defaults as required per property\n\n    if not xpaths:\n        return []\n    elif not isinstance(xpaths, ParserProperty):\n        return _update_property(tree_to_update, xpath_root, xpaths, values)\n    else:\n        # Call ParserProperty.set_prop without xpath_root (managed internally)\n        return xpaths.set_prop(tree_to_update=tree_to_update, prop=prop, values=values)", "label": 1}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getMetric($options + [\n            'metricName' => $this->formattedName\n        ]);\n    }", "label": 2}
{"code": "public static base_responses expire(nitro_service client, cachecontentgroup resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcachecontentgroup expireresources[] = new cachecontentgroup[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\texpireresources[i] = new cachecontentgroup();\n\t\t\t\texpireresources[i].name = resources[i].name;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, expireresources,\"expire\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static base_responses delete(nitro_service client, snmptrap resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmptrap deleteresources[] = new snmptrap[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tdeleteresources[i] = new snmptrap();\n\t\t\t\tdeleteresources[i].trapclass = resources[i].trapclass;\n\t\t\t\tdeleteresources[i].trapdestination = resources[i].trapdestination;\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def diff_config(self, second_host, mode='stanza'):\n        \"\"\" Generate configuration differences with a second device.\n\n        Purpose: Open a second ncclient.manager.Manager with second_host, and\n               | and pull the configuration from it. We then use difflib to\n               | get the delta between the two, and yield the results.\n\n        @param second_host: the IP or hostname of the second device to\n                          | compare against.\n        @type second_host: str\n        @param mode: string to signify 'set' mode or 'stanza' mode.\n        @type mode: str\n\n        @returns: iterable of strings\n        @rtype: str\n        \"\"\"\n        second_conn = manager.connect(\n            host=second_host,\n            port=self.port,\n            username=self.username,\n            password=self.password,\n            timeout=self.connect_timeout,\n            device_params={'name': 'junos'},\n            hostkey_verify=False\n        )\n\n        command = 'show configuration'\n        if mode == 'set':\n            command += ' | display set'\n\n        # get the raw xml config\n        config1 = self._session.command(command, format='text')\n        # for each /configuration-output snippet, turn it to text and join them\n        config1 = ''.join([snippet.text.lstrip('\\n') for snippet in\n                          config1.xpath('//configuration-output')])\n\n        config2 = second_conn.command(command, format='text')\n        config2 = ''.join([snippet.text.lstrip('\\n') for snippet in\n                          config2.xpath('//configuration-output')])\n\n        return difflib.unified_diff(config1.splitlines(), config2.splitlines(),\n                                    self.host, second_host)", "label": 1}
{"code": "func (m *Manager) CounterInfo(ctx context.Context) ([]types.PerfCounterInfo, error) {\n\tm.pm.Lock()\n\tdefer m.pm.Unlock()\n\n\tif len(m.pm.PerfCounter) == 0 {\n\t\terr := m.Properties(ctx, m.Reference(), []string{\"perfCounter\"}, m.pm.PerformanceManager)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn m.pm.PerfCounter, nil\n}", "label": 5}
{"code": "func (l *Handler) Upload(ctx context.Context, sessionID session.ID, reader io.Reader) (string, error) {\n\tpath := l.path(sessionID)\n\t_, err := l.uploader.UploadWithContext(ctx, &s3manager.UploadInput{\n\t\tBucket:               aws.String(l.Bucket),\n\t\tKey:                  aws.String(path),\n\t\tBody:                 reader,\n\t\tServerSideEncryption: aws.String(s3.ServerSideEncryptionAwsKms),\n\t})\n\tif err != nil {\n\t\treturn \"\", ConvertS3Error(err)\n\t}\n\treturn fmt.Sprintf(\"%v://%v/%v\", teleport.SchemeS3, l.Bucket, path), nil\n}", "label": 5}
{"code": "def get_constants namespace, context = ''\n      namespace ||= ''\n      cached = cache.get_constants(namespace, context)\n      return cached.clone unless cached.nil?\n      skip = []\n      result = []\n      bases = context.split('::')\n      while bases.length > 0\n        built = bases.join('::')\n        fqns = qualify(namespace, built)\n        visibility = [:public]\n        visibility.push :private if fqns == context\n        result.concat inner_get_constants(fqns, visibility, skip)\n        bases.pop\n      end\n      fqns = qualify(namespace, '')\n      visibility = [:public]\n      visibility.push :private if fqns == context\n      result.concat inner_get_constants(fqns, visibility, skip)\n      cache.set_constants(namespace, context, result)\n      result\n    end", "label": 4}
{"code": "private function formatListForApi(array $list)\n    {\n        $values = [];\n\n        foreach ($list as $value) {\n            $values[] = $this->formatValueForApi($value);\n        }\n\n        return ['values' => $values];\n    }", "label": 2}
{"code": "function(event_type) {\n\t\t\tvar rest_args = arguments.length > 1 ? rest(arguments) : root,\n\t\t\t\t// no parent, no filter by default\n\t\t\t\tevent = new CJSEvent(false, false, function(transition) {\n\t\t\t\t\tvar targets = [],\n\t\t\t\t\t\ttimeout_id = false,\n\t\t\t\t\t\tevent_type_val = [],\n\t\t\t\t\t\tlistener = bind(this._fire, this),\n\t\t\t\t\t\tfsm = transition.getFSM(),\n\t\t\t\t\t\tfrom = transition.getFrom(),\n\t\t\t\t\t\tstate_selector = new StateSelector(from),\n\t\t\t\t\t\tfrom_state_selector = new TransitionSelector(true, state_selector, new AnyStateSelector()),\n\t\t\t\t\t\ton_listener = function() {\n\t\t\t\t\t\t\teach(event_type_val, function(event_type) {\n\t\t\t\t\t\t\t\t// If the event is 'timeout'\n\t\t\t\t\t\t\t\tif(event_type === timeout_event_type) {\n\t\t\t\t\t\t\t\t\t// clear the previous timeout\n\t\t\t\t\t\t\t\t\tif(timeout_id) {\n\t\t\t\t\t\t\t\t\t\tcTO(timeout_id);\n\t\t\t\t\t\t\t\t\t\ttimeout_id = false;\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\t// and set a new one\n\t\t\t\t\t\t\t\t\tvar delay = cjs.get(rest_args[0]);\n\t\t\t\t\t\t\t\t\tif(!isNumber(delay) || delay < 0) {\n\t\t\t\t\t\t\t\t\t\tdelay = 0;\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\ttimeout_id = sTO(listener, delay);\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\teach(targets, function(target) {\n\t\t\t\t\t\t\t\t\t\t// otherwise, add the event listener to every one of my targets\n\t\t\t\t\t\t\t\t\t\taEL(target, event_type, listener);\n\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t},\n\t\t\t\t\t\toff_listener = function() {\n\t\t\t\t\t\t\teach(event_type_val, function(event_type) {\n\t\t\t\t\t\t\t\teach(targets, function(target) {\n\t\t\t\t\t\t\t\t\tif(event_type === timeout_event_type) {\n\t\t\t\t\t\t\t\t\t\t// If the event is 'timeout'\n\t\t\t\t\t\t\t\t\t\tif(timeout_id) {\n\t\t\t\t\t\t\t\t\t\t\tcTO(timeout_id);\n\t\t\t\t\t\t\t\t\t\t\ttimeout_id = false;\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\trEL(target, event_type, listener);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t},\n\t\t\t\t\t\tlive_fn = cjs.liven(function() {\n\t\t\t\t\t\t\toff_listener();\n\n\t\t\t\t\t\t\tevent_type_val = split_and_trim(cjs.get(event_type));\n\t\t\t\t\t\t\t// only use DOM elements (or the window) as my target\n\t\t\t\t\t\t\ttargets = flatten(map(filter(get_dom_array(rest_args), isElementOrWindow), getDOMChildren , true));\n\n\t\t\t\t\t\t\t// when entering the state, add the event listeners, then remove them when leaving the state\n\t\t\t\t\t\t\tfsm\t.on(state_selector, on_listener)\n\t\t\t\t\t\t\t\t.on(from_state_selector, off_listener);\n\n\t\t\t\t\t\t\tif(fsm.is(from)) {\n\t\t\t\t\t\t\t\t// if the FSM is already in the transition's starting state\n\t\t\t\t\t\t\t\ton_listener();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\treturn live_fn;\n\t\t\t\t});\n\t\t\treturn event;\n\t\t}", "label": 3}
{"code": "def get_current_time(self):\n        \"\"\"\n        Get current time\n\n        :return: datetime.time\n        \"\"\"\n        hms = [int(self.get_current_controller_value(i)) for i in range(406, 409)]\n        return datetime.time(*hms)", "label": 1}
{"code": "public function delete(array $key, $table = null)\n    {\n        $this->queue[] = [\n            'table' => $this->determineTable($table),\n            'data'  => ['DeleteRequest' => ['Key' => $key]],\n        ];\n\n        $this->autoFlush();\n\n        return $this;\n    }", "label": 2}
{"code": "public static <E> double optimizedDotProduct(Counter<E> c1, Counter<E> c2) {\r\n    double dotProd = 0.0;\r\n    int size1 = c1.size();\r\n    int size2 = c2.size();\r\n    if (size1 < size2) {\r\n      for (E key : c1.keySet()) {\r\n        double count1 = c1.getCount(key);\r\n        if (count1 != 0.0) {\r\n          double count2 = c2.getCount(key);\r\n          if (count2 != 0.0)\r\n            dotProd += (count1 * count2);\r\n        }\r\n      }\r\n    } else {\r\n      for (E key : c2.keySet()) {\r\n        double count2 = c2.getCount(key);\r\n        if (count2 != 0.0) {\r\n          double count1 = c1.getCount(key);\r\n          if (count1 != 0.0)\r\n            dotProd += (count1 * count2);\r\n        }\r\n      }\r\n    }\r\n\r\n    return dotProd;\r\n  }", "label": 0}
{"code": "def load_models(app)\n      app.config.paths[\"app/models\"].expanded.each do |path|\n        preload = ::Mongoid.preload_models\n        if preload.resizable?\n          files = preload.map { |model| \"#{path}/#{model.underscore}.rb\" }\n        else\n          files = Dir.glob(\"#{path}/**/*.rb\")\n        end\n\n        files.sort.each do |file|\n          load_model(file.gsub(\"#{path}/\" , \"\").gsub(\".rb\", \"\"))\n        end\n      end\n    end", "label": 4}
{"code": "public static <T> T readObjectFromFileNoExceptions(File file) {\r\n    Object o = null;\r\n    try {\r\n      ObjectInputStream ois = new ObjectInputStream(new BufferedInputStream(\r\n          new GZIPInputStream(new FileInputStream(file))));\r\n      o = ois.readObject();\r\n      ois.close();\r\n    } catch (IOException e) {\r\n      e.printStackTrace();\r\n    } catch (ClassNotFoundException e) {\r\n      e.printStackTrace();\r\n    }\r\n    return ErasureUtils.<T> uncheckedCast(o);\r\n  }", "label": 0}
{"code": "def truncate(input, length = 50, truncate_string = \"...\".freeze)\n      return if input.nil?\n      input_str = input.to_s\n      length = Utils.to_integer(length)\n      truncate_string_str = truncate_string.to_s\n      l = length - truncate_string_str.length\n      l = 0 if l < 0\n      input_str.length > length ? input_str[0...l] + truncate_string_str : input_str\n    end", "label": 4}
{"code": "def ecs_idsKEGG(organism):\n    \"\"\"\n    Uses KEGG to retrieve all ids and respective ecs for a given KEGG organism\n\n    :param organism: an organisms as listed in organismsKEGG()\n\n    :returns: a Pandas dataframe of with 'ec' and 'KEGGid'.\n\n    \"\"\"\n    kegg_ec=urlopen(\"http://rest.kegg.jp/link/\"+organism+\"/enzyme\").read()\n    kegg_ec=kegg_ec.split(\"\\n\")\n    final=[]\n    for k in kegg_ec:\n        final.append(k.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n    df.columns=['ec','KEGGid']\n    return df", "label": 1}
{"code": "function () {\n            var self = this;\n            var indexes = self.$indexes || [];\n\n            return Promise.try (function() {\n                assert.arrayOfObject(indexes, '$indexes should be an array of object');\n\n                //validate and assign default arguments before creating indexes\n                //if necessary, convert the indexes format to fit for different database\n                _.forEach(indexes, function(indexItem) {\n                    assert.object(indexItem.keys, 'Database index keys should be object');\n                    if (indexItem.options) {\n                        assert.object(indexItem.options, 'Database index options should be object');\n                    }\n                    else {\n                        indexItem.options = {};\n                    }\n                });\n\n                return indexes;\n            })\n            .then(function(indexes) {\n                if (_.isEmpty(indexes)) {\n                    return;\n                }\n                switch(self.connection.toString()) {\n                    case 'mongo':\n                        return Promise.map(indexes, function(indexItem) {\n                            return self.createMongoIndexes([indexItem.keys, indexItem.options]);\n                        });\n                    default:\n                        break;\n                }\n            });\n        }", "label": 3}
{"code": "public static lbmonitor_binding[] get(nitro_service service, String monitorname[]) throws Exception{\n\t\tif (monitorname !=null && monitorname.length>0) {\n\t\t\tlbmonitor_binding response[] = new lbmonitor_binding[monitorname.length];\n\t\t\tlbmonitor_binding obj[] = new lbmonitor_binding[monitorname.length];\n\t\t\tfor (int i=0;i<monitorname.length;i++) {\n\t\t\t\tobj[i] = new lbmonitor_binding();\n\t\t\t\tobj[i].set_monitorname(monitorname[i]);\n\t\t\t\tresponse[i] = (lbmonitor_binding) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def would_require? path\n      require_paths.each do |rp|\n        return true if File.exist?(File.join(rp, \"#{path}.rb\"))\n      end\n      false\n    end", "label": 4}
{"code": "private function randomName($parent)\n    {\n        // UUIDs are a pre-existing library dependency, so we'll use that instead\n        // of adding random_compat or something similar.\n        // Generate a UUID, then strip `-` and trim to expected length.\n        // @todo revisit once library requires php >= 7.0 and random_int() can be used without dependency.\n        $rand = substr(str_replace('-', '', Uuid::uuid4()), 0, 20);\n\n        return $this->childPath($parent, $rand);\n    }", "label": 2}
{"code": "def resize_to(width, height)\n      Selenium::WebDriver::Dimension.new(Integer(width), Integer(height)).tap do |dimension|\n        use { @driver.manage.window.size = dimension }\n      end\n    end", "label": 4}
{"code": "def use(*modules)\n      modules.to_a.flatten.compact.map do |object|\n        mod = get_module(object)\n        mod.setup(@model_class) if mod.respond_to?(:setup)\n        @model_class.send(:include, mod) unless uses? object\n      end\n    end", "label": 4}
{"code": "func (b *Log) deleteAllItems() error {\n\tout, err := b.svc.Scan(&dynamodb.ScanInput{TableName: aws.String(b.Tablename)})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tvar requests []*dynamodb.WriteRequest\n\tfor _, item := range out.Items {\n\t\trequests = append(requests, &dynamodb.WriteRequest{\n\t\t\tDeleteRequest: &dynamodb.DeleteRequest{\n\t\t\t\tKey: map[string]*dynamodb.AttributeValue{\n\t\t\t\t\tkeySessionID:  item[keySessionID],\n\t\t\t\t\tkeyEventIndex: item[keyEventIndex],\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t}\n\tif len(requests) == 0 {\n\t\treturn nil\n\t}\n\treq, _ := b.svc.BatchWriteItemRequest(&dynamodb.BatchWriteItemInput{\n\t\tRequestItems: map[string][]*dynamodb.WriteRequest{\n\t\t\tb.Tablename: requests,\n\t\t},\n\t})\n\terr = req.Send()\n\terr = convertError(err)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def query_values=(new_query_values)\n      if new_query_values == nil\n        self.query = nil\n        return nil\n      end\n\n      if !new_query_values.is_a?(Array)\n        if !new_query_values.respond_to?(:to_hash)\n          raise TypeError,\n            \"Can't convert #{new_query_values.class} into Hash.\"\n        end\n        new_query_values = new_query_values.to_hash\n        new_query_values = new_query_values.map do |key, value|\n          key = key.to_s if key.kind_of?(Symbol)\n          [key, value]\n        end\n        # Useful default for OAuth and caching.\n        # Only to be used for non-Array inputs. Arrays should preserve order.\n        new_query_values.sort!\n      end\n\n      # new_query_values have form [['key1', 'value1'], ['key2', 'value2']]\n      buffer = \"\".dup\n      new_query_values.each do |key, value|\n        encoded_key = URI.encode_component(\n          key, CharacterClasses::UNRESERVED\n        )\n        if value == nil\n          buffer << \"#{encoded_key}&\"\n        elsif value.kind_of?(Array)\n          value.each do |sub_value|\n            encoded_value = URI.encode_component(\n              sub_value, CharacterClasses::UNRESERVED\n            )\n            buffer << \"#{encoded_key}=#{encoded_value}&\"\n          end\n        else\n          encoded_value = URI.encode_component(\n            value, CharacterClasses::UNRESERVED\n          )\n          buffer << \"#{encoded_key}=#{encoded_value}&\"\n        end\n      end\n      self.query = buffer.chop\n    end", "label": 4}
{"code": "func (s *APIServer) getNodes(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tnamespace := p.ByName(\"namespace\")\n\tif !services.IsValidNamespace(namespace) {\n\t\treturn nil, trace.BadParameter(\"invalid namespace %q\", namespace)\n\t}\n\tskipValidation, _, err := httplib.ParseBool(r.URL.Query(), \"skip_validation\")\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar opts []services.MarshalOption\n\tif skipValidation {\n\t\topts = append(opts, services.SkipValidation())\n\t}\n\n\tservers, err := auth.GetNodes(namespace, opts...)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn marshalServers(servers, version)\n}", "label": 5}
{"code": "function retro(content) {\n    // Lex incoming markdown file\n    var lexed = lex(content);\n\n    // Break it into sections\n    var newSections = sections.split(lexed)\n    .map(function(section) {\n        // Leave non quiz sections untouched\n        if(!isQuiz(section)) {\n            return section;\n        }\n        // Convert old section to new format\n        return retroSection(section);\n    });\n\n    // Bring sections back together into a list of lexed nodes\n    var newLexed = sections.join(newSections);\n\n    // Render back to markdown\n    return render(newLexed);\n}", "label": 3}
{"code": "protected function controllerUsesHelpersTrait()\n    {\n        if (! $controller = $this->getControllerInstance()) {\n            return false;\n        }\n\n        $traits = [];\n\n        do {\n            $traits = array_merge(class_uses($controller, false), $traits);\n        } while ($controller = get_parent_class($controller));\n\n        foreach ($traits as $trait => $same) {\n            $traits = array_merge(class_uses($trait, false), $traits);\n        }\n\n        return isset($traits[Helpers::class]);\n    }", "label": 2}
{"code": "public function setContext($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\ImageAnnotationContext::class);\n        $this->context = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func GetLastModified() *File {\n\tlastModified.Lock()\n\tdefer lastModified.Unlock()\n\n\treturn &File{Content: lastModified.contents, Hash: lastModified.sha256}\n}", "label": 5}
{"code": "def define_accessors(option, value)\n      setter = proc { |val|  set option, val, true }\n      getter = proc { value }\n\n      define_singleton_method(\"#{option}=\", setter) if setter\n      define_singleton_method(option, getter) if getter\n    end", "label": 4}
{"code": "def mrai_from_raw(self, amount):\n        \"\"\"\n        Divide a raw amount down by the Mrai ratio.\n\n        :param amount: Amount in raw to convert to Mrai\n        :type amount: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.mrai_from_raw(amount=1000000000000000000000000000000)\n        1\n\n        \"\"\"\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('mrai_from_raw', payload)\n\n        return int(resp['amount'])", "label": 1}
{"code": "public function verify($response, $remoteIp = null)\n    {\n        // Discard empty solution submissions\n        if (empty($response)) {\n            $recaptchaResponse = new Response(false, array(self::E_MISSING_INPUT_RESPONSE));\n            return $recaptchaResponse;\n        }\n\n        $params = new RequestParameters($this->secret, $response, $remoteIp, self::VERSION);\n        $rawResponse = $this->requestMethod->submit($params);\n        $initialResponse = Response::fromJson($rawResponse);\n        $validationErrors = array();\n\n        if (isset($this->hostname) && strcasecmp($this->hostname, $initialResponse->getHostname()) !== 0) {\n            $validationErrors[] = self::E_HOSTNAME_MISMATCH;\n        }\n\n        if (isset($this->apkPackageName) && strcasecmp($this->apkPackageName, $initialResponse->getApkPackageName()) !== 0) {\n            $validationErrors[] = self::E_APK_PACKAGE_NAME_MISMATCH;\n        }\n\n        if (isset($this->action) && strcasecmp($this->action, $initialResponse->getAction()) !== 0) {\n            $validationErrors[] = self::E_ACTION_MISMATCH;\n        }\n\n        if (isset($this->threshold) && $this->threshold > $initialResponse->getScore()) {\n            $validationErrors[] = self::E_SCORE_THRESHOLD_NOT_MET;\n        }\n\n        if (isset($this->timeoutSeconds)) {\n            $challengeTs = strtotime($initialResponse->getChallengeTs());\n\n            if ($challengeTs > 0 && time() - $challengeTs > $this->timeoutSeconds) {\n                $validationErrors[] = self::E_CHALLENGE_TIMEOUT;\n            }\n        }\n\n        if (empty($validationErrors)) {\n            return $initialResponse;\n        }\n\n        return new Response(\n            false,\n            array_merge($initialResponse->getErrorCodes(), $validationErrors),\n            $initialResponse->getHostname(),\n            $initialResponse->getChallengeTs(),\n            $initialResponse->getApkPackageName(),\n            $initialResponse->getScore(),\n            $initialResponse->getAction()\n        );\n    }", "label": 2}
{"code": "func (s *SyncString) Value() string {\n\ts.Lock()\n\tdefer s.Unlock()\n\treturn s.string\n}", "label": 5}
{"code": "func (l VirtualDeviceList) Name(device types.BaseVirtualDevice) string {\n\tvar key string\n\tvar UnitNumber int32\n\td := device.GetVirtualDevice()\n\tif d.UnitNumber != nil {\n\t\tUnitNumber = *d.UnitNumber\n\t}\n\n\tdtype := l.Type(device)\n\tswitch dtype {\n\tcase DeviceTypeEthernet:\n\t\tkey = fmt.Sprintf(\"%d\", UnitNumber-7)\n\tcase DeviceTypeDisk:\n\t\tkey = fmt.Sprintf(\"%d-%d\", d.ControllerKey, UnitNumber)\n\tdefault:\n\t\tkey = fmt.Sprintf(\"%d\", d.Key)\n\t}\n\n\treturn fmt.Sprintf(\"%s-%s\", dtype, key)\n}", "label": 5}
{"code": "def _add_default_entries(input_dict, defaults_dict):\n    \"\"\"\n    Add the entries in defaults dict into input_dict if they don't exist in input_dict\n\n    This is based on the accepted answer at\n    http://stackoverflow.com/questions/3232943/update-value-of-a-nested-dictionary-of-varying-depth\n\n    :param dict input_dict: The dict to be updated\n    :param dict defaults_dict: Dict containing the defaults for entries in input_dict\n    :return: updated dict\n    :rtype: dict\n    \"\"\"\n    for key, value in defaults_dict.iteritems():\n        if key == 'patients':\n            print('Cannot default `patients`.')\n            continue\n        if isinstance(value, dict):\n            if key not in input_dict or input_dict[key] is None:\n                # User didn't specify anython for the tool, but the entry was still in there so we\n                # just copy over the whole defaults dict\n                input_dict[key] = value\n            else:\n                r = _add_default_entries(input_dict.get(key, {}), value)\n                input_dict[key] = r\n        else:\n            # Only write if not in input_dict\n            if key not in input_dict or input_dict[key] is None:\n                # Either the user didn't have the entry, or had it without a value\n                input_dict[key] = value\n    return input_dict", "label": 1}
{"code": "def deactivate_program(self, program):\n        \"\"\"\n            Called by program, when it is deactivated.\n        \"\"\"\n        self.logger.debug(\"deactivate_program %s\", program)\n\n        with self._program_lock:\n            self.logger.debug(\"deactivate_program got through %s\", program)\n            if program not in self.program_stack:\n                import ipdb\n                ipdb.set_trace()\n            self.program_stack.remove(program)\n            if program in self.program_status:\n                del self.program_status[program]\n            self._update_program_stack()", "label": 1}
{"code": "func Classic() *ClassicMartini {\n\tr := NewRouter()\n\tm := New()\n\tm.Use(Logger())\n\tm.Use(Recovery())\n\tm.Use(Static(\"public\"))\n\tm.MapTo(r, (*Routes)(nil))\n\tm.Action(r.Handle)\n\treturn &ClassicMartini{m, r}\n}", "label": 5}
{"code": "def clean_message(message)\n      if @server_version && @server_version > 50500\n        message.encode(ENCODE_OPTS)\n      else\n        message.encode(Encoding::UTF_8, ENCODE_OPTS)\n      end\n    end", "label": 4}
{"code": "private function get_update_type_str( $assoc_args ) {\n\t\t$update_type = ' ';\n\t\tforeach ( array( 'major', 'minor', 'patch' ) as $type ) {\n\t\t\tif ( true === \\WP_CLI\\Utils\\get_flag_value( $assoc_args, $type ) ) {\n\t\t\t\t$update_type = ' ' . $type . ' ';\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\treturn $update_type;\n\t}", "label": 2}
{"code": "public static double[] toDouble(int[] array) {\n        double[] n = new double[array.length];\n        for (int i = 0; i < array.length; i++) {\n            n[i] = (double) array[i];\n        }\n        return n;\n    }", "label": 0}
{"code": "public static <E> void divideInPlace(Counter<E> target, Counter<E> denominator) {\r\n    for (E key : target.keySet()) {\r\n      target.setCount(key, target.getCount(key) / denominator.getCount(key));\r\n    }\r\n  }", "label": 0}
{"code": "function( a, b, aParent, bParent, parentProp, compares, options ){\n\t\tvar bType = typeof b;\n\t\tvar hasAdditionalProp = false;\n\t\tif(bType === 'object' || bType === 'function') {\n\t\t\tvar aCopy = assign({}, a);\n\t\t\tif(options.deep === false) {\n\t\t\t\toptions.deep = -1;\n\t\t\t}\n\t\t\t// Check that everything in B is the same as whats in A, or\n\t\t\t// isn't in A.\n\t\t\tfor (var prop in b) {\n\t\t\t\tvar compare = compares[prop] === undefined ? compares['*'] : compares[prop];\n\t\t\t\t// run the comparison no matter what\n\t\t\t\tvar compareResult = loop(a[prop], b[prop], a, b, prop, compare, options );\n\t\t\t\t// if there wasn't a prop (and we didn't run through a compare)\n\t\t\t\tif(compareResult === h.ignoreType) {\n\t\t\t\t\t// do nothing\n\t\t\t\t} else if(!(prop in a) ||  options.performedDifference ) {\n\t\t\t\t\thasAdditionalProp = true;\n\t\t\t\t} else if(!compareResult) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\tdelete aCopy[prop];\n\t\t\t}\n\t\t\t// go through aCopy props ... if there is no compare .. return false\n\t\t\tfor (prop in aCopy) {\n\t\t\t\tif (compares[prop] === undefined || !loop(a[prop], undefined, a, b, prop, compares[prop], options) ) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn hasAdditionalProp;\n\t\t}\n\n\t}", "label": 3}
{"code": "public function setState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Scheduler\\V1\\Job_State::class);\n        $this->state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def print_stack_info(self):\n        '''\n        List resources from the given stack\n\n        Args:\n            None\n\n        Returns:\n            A dictionary filled resources or None if things went sideways\n        '''\n        try:\n            rest_api_id = None\n            deployment_found = False\n\n            response = self._cf_client.describe_stack_resources(\n                StackName=self._stack_name\n            )\n\n            print('\\nThe following resources were created:')\n            rows = []\n            for resource in response['StackResources']:\n                if resource['ResourceType'] == 'AWS::ApiGateway::RestApi':\n                    rest_api_id = resource['PhysicalResourceId']\n                elif resource['ResourceType'] == 'AWS::ApiGateway::Deployment':\n                    deployment_found = True\n\n                row = []\n                row.append(resource['ResourceType'])\n                row.append(resource['LogicalResourceId'])\n                row.append(resource['PhysicalResourceId'])\n                rows.append(row)\n                '''\n                print('\\t{}\\t{}\\t{}'.format(\n                        resource['ResourceType'],\n                        resource['LogicalResourceId'],\n                        resource['PhysicalResourceId']\n                    )\n                )\n                '''\n            print(tabulate(rows, headers=['Resource Type', 'Logical ID', 'Physical ID']))\n\n            if rest_api_id and deployment_found:\n                url = 'https://{}.execute-api.{}.amazonaws.com/{}'.format(\n                    rest_api_id,\n                    self._region,\n                    '<stage>'\n                )\n                print('\\nThe deployed service can be found at this URL:')\n                print('\\t{}\\n'.format(url))\n\n            return response\n        except Exception as wtf:\n            print(wtf)\n            return None", "label": 1}
{"code": "public function setMentions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Language\\V1beta2\\EntityMention::class);\n        $this->mentions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function updateReferences(el) {\n\t\t$.each(mtypes, function (i, pos) {\n\t\t\tvar id = marker_prefix + pos + '_' + el.id;\n\t\t\tvar marker_name = 'marker-'+pos;\n\t\t\tvar marker = getLinked(el, marker_name);\n\t\t\tif (!marker || !marker.attributes.se_type) {return;} // not created by this extension\n\t\t\tvar url = el.getAttribute(marker_name);\n\t\t\tif (url) {\n\t\t\t\tvar len = el.id.length;\n\t\t\t\tvar linkid = url.substr(-len-1, len);\n\t\t\t\tif (el.id != linkid) {\n\t\t\t\t\tvar val = $('#'+pos + '_marker').attr('value');\n\t\t\t\t\taddMarker(id, val);\n\t\t\t\t\tsvgCanvas.changeSelectedAttribute(marker_name, \"url(#\" + id + \")\");\n\t\t\t\t\tif (el.tagName === 'line' && pos == 'mid') {el = convertline(el);}\n\t\t\t\t\tS.call(\"changed\", selElems);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}", "label": 3}
{"code": "func ParseSigningKeyStorePEM(keyPEM, certPEM string) (*SigningKeyStore, error) {\n\t_, err := ParseCertificatePEM([]byte(certPEM))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tkey, err := ParsePrivateKeyPEM([]byte(keyPEM))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\trsaKey, ok := key.(*rsa.PrivateKey)\n\tif !ok {\n\t\treturn nil, trace.BadParameter(\"key of type %T is not supported, only RSA keys are supported for signatures\", key)\n\t}\n\tcertASN, _ := pem.Decode([]byte(certPEM))\n\tif certASN == nil {\n\t\treturn nil, trace.BadParameter(\"expected PEM-encoded block\")\n\t}\n\treturn &SigningKeyStore{privateKey: rsaKey, cert: certASN.Bytes}, nil\n}", "label": 5}
{"code": "def cmd_query(self, txt):\n        \"\"\"\n        search and query the AIKIF\n        \"\"\"\n        self.show_output('Searching for ', txt)\n        res = self.raw.find(txt)\n        for d in res:\n            self.show_output(d)\n        return str(len(res)) + ' results for ' + txt", "label": 1}
{"code": "def get_cmd(self):\n        \"\"\"Returns the full command to be executed at runtime\"\"\"\n\n        cmd = None\n        if self.test_program in ('nose', 'nosetests'):\n            cmd = \"nosetests %s\" % self.file_path\n        elif self.test_program == 'django':\n            executable = \"%s/manage.py\" % self.file_path\n            if os.path.exists(executable):\n                cmd = \"python %s/manage.py test\" % self.file_path\n            else:\n                cmd = \"django-admin.py test\"\n        elif self.test_program == 'py':\n            cmd = 'py.test %s' % self.file_path\n        elif self.test_program == 'symfony':\n            cmd = 'symfony test-all'\n        elif self.test_program == 'jelix':\n            # as seen on http://jelix.org/articles/fr/manuel-1.1/tests_unitaires\n            cmd = 'php tests.php'\n        elif self.test_program == 'phpunit':\n            cmd = 'phpunit'\n        elif self.test_program == 'sphinx':\n            cmd = 'make html'\n        elif self.test_program == 'tox':\n            cmd = 'tox'\n\n        if not cmd:\n            raise InvalidTestProgram(\"The test program %s is unknown. Valid options are: `nose`, `django` and `py`\" % self.test_program)\n\n        # adding custom args\n        if self.custom_args:\n            cmd = '%s %s' % (cmd, self.custom_args)\n        return cmd", "label": 1}
{"code": "public static int cudnnBatchNormalizationBackward(\n        cudnnHandle handle, \n        int mode, \n        Pointer alphaDataDiff, \n        Pointer betaDataDiff, \n        Pointer alphaParamDiff, \n        Pointer betaParamDiff, \n        cudnnTensorDescriptor xDesc, /** same desc for x, dx, dy */\n        Pointer x, \n        cudnnTensorDescriptor dyDesc, \n        Pointer dy, \n        cudnnTensorDescriptor dxDesc, \n        Pointer dx, \n        /** Shared tensor desc for the 4 tensors below */\n        cudnnTensorDescriptor dBnScaleBiasDesc, \n        Pointer bnScale, /** bnBias doesn't affect backpropagation */\n        /** scale and bias diff are not backpropagated below this layer */\n        Pointer dBnScaleResult, \n        Pointer dBnBiasResult, \n        /** Same epsilon as forward pass */\n        double epsilon, \n        /** Optionally cached intermediate results from\n                                           forward pass */\n        Pointer savedMean, \n        Pointer savedInvVariance)\n    {\n        return checkResult(cudnnBatchNormalizationBackwardNative(handle, mode, alphaDataDiff, betaDataDiff, alphaParamDiff, betaParamDiff, xDesc, x, dyDesc, dy, dxDesc, dx, dBnScaleBiasDesc, bnScale, dBnScaleResult, dBnBiasResult, epsilon, savedMean, savedInvVariance));\n    }", "label": 0}
{"code": "public static gslbsite_gslbservice_binding[] get_filtered(nitro_service service, String sitename, filtervalue[] filter) throws Exception{\n\t\tgslbsite_gslbservice_binding obj = new gslbsite_gslbservice_binding();\n\t\tobj.set_sitename(sitename);\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tgslbsite_gslbservice_binding[] response = (gslbsite_gslbservice_binding[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func completeRollingBackRotation(clock clockwork.Clock, ca services.CertAuthority) error {\n\trotation := ca.GetRotation()\n\n\t// clean up the state\n\trotation.Started = time.Time{}\n\trotation.State = services.RotationStateStandby\n\trotation.Phase = services.RotationPhaseStandby\n\trotation.Mode = \"\"\n\trotation.Schedule = services.RotationSchedule{}\n\n\tkeyPairs := ca.GetTLSKeyPairs()\n\t// only keep the original certificate authority as trusted\n\t// and remove everything else.\n\tkeyPairs = []services.TLSKeyPair{keyPairs[0]}\n\n\tca.SetTLSKeyPairs(keyPairs)\n\tca.SetRotation(rotation)\n\treturn nil\n}", "label": 5}
{"code": "function groupOn(f, xs) {\r\n    return groupBy((a, b) => f(a) === f(b), xs);\r\n}", "label": 3}
{"code": "def digestable_hash\n      @item.slice(CLASS_KEY, QUEUE_KEY, UNIQUE_ARGS_KEY).tap do |hash|\n        hash.delete(QUEUE_KEY) if unique_across_queues?\n        hash.delete(CLASS_KEY) if unique_across_workers?\n      end\n    end", "label": 4}
{"code": "public static int Mode( int[] values ){\n        int mode = 0, curMax = 0;\n\n        for ( int i = 0, length = values.length; i < length; i++ )\n        {\n            if ( values[i] > curMax )\n            {\n                curMax = values[i];\n                mode = i;\n            }\n        }\n        return mode;\n    }", "label": 0}
{"code": "func (d *driver) populateNetworks() error {\n\tkvol, err := d.store.List(datastore.Key(macvlanPrefix), &configuration{})\n\tif err != nil && err != datastore.ErrKeyNotFound {\n\t\treturn fmt.Errorf(\"failed to get macvlan network configurations from store: %v\", err)\n\t}\n\t// If empty it simply means no macvlan networks have been created yet\n\tif err == datastore.ErrKeyNotFound {\n\t\treturn nil\n\t}\n\tfor _, kvo := range kvol {\n\t\tconfig := kvo.(*configuration)\n\t\tif err = d.createNetwork(config); err != nil {\n\t\t\tlogrus.Warnf(\"Could not create macvlan network for id %s from persistent state\", config.ID)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function setDeferred($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Datastore\\V1\\Key::class);\n        $this->deferred = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def main():\n    \"\"\"\n    This is the main body of the process that does the work.\n\n    Summary:\n    - load the raw data\n    - read in rules list\n    - create log events for AIKIF according to rules [map]\n    - create new facts / reports based on rules [report]\n    \n    OUTPUT = \n                AIKIF mapping  : Date_of_transaction => event\n                AIKIF mapping  : Amount => fact\n                AIKIF mapping  : Details => location\n                New column     : trans_type = DB WHERE amount > 0 ELSE CR\n                summing        : details contains \"CALTEX\" into Travel Expense\n                Done    \n    \n    \"\"\"\n    \n    print('AIKIF example: Processing Finance data\\n')\n    data = read_bank_statements('your_statement.csv')\n    print(data)\n    maps = load_column_maps()\n    rules = load_rules()\n    \n    for m in maps:\n        print('AIKIF mapping  : ' + m[0] + ' => ' + m[1])\n\n    for rule in rules:\n        #print(rule)\n        if rule[0] == 'agg':\n            print('summing        : ' + rule[1] + ' into ' +  rule[2] )\n        elif rule[0] == 'derive':\n            print('New column     : ' + rule[1] + ' = ' + rule[2] + ' WHERE ' + rule[1] + ' ELSE ' + rule[3] )\n    \n    print('Done\\n')", "label": 1}
{"code": "public static Object toObject(Class<?> clazz, Object value) throws ParseException {\n        if (value == null) {\n            return null;\n        }\n        if (clazz == null) {\n            return value;\n        }\n\n        if (java.sql.Date.class.isAssignableFrom(clazz)) {\n            return toDate(value);\n        }\n        if (java.sql.Time.class.isAssignableFrom(clazz)) {\n            return toTime(value);\n        }\n        if (java.sql.Timestamp.class.isAssignableFrom(clazz)) {\n            return toTimestamp(value);\n        }\n        if (java.util.Date.class.isAssignableFrom(clazz)) {\n            return toDateTime(value);\n        }\n\n        return value;\n    }", "label": 0}
{"code": "function(){\n\t\t\tvar rect, obj, i;\n            for (i=0, l=changed_objs.length; i<l; i++){\n            \tobj = changed_objs[i];\n            \trect = obj._mbr || obj;\n            \tif (obj.staleRect == null)\n            \t\t\tobj.staleRect = {}\n        \t\tobj.staleRect._x = rect._x;\n\t\t\t\tobj.staleRect._y = rect._y;\n\t\t\t\tobj.staleRect._w = rect._w;\n\t\t\t\tobj.staleRect._h = rect._h;\n\n\t\t\t\tobj._changed = false\n            }\n            changed_objs.length = 0;\n            dirty_rects.length = 0\n\n\t\t}", "label": 3}
{"code": "public void addNotBetween(Object attribute, Object value1, Object value2)\r\n    {\r\n        // PAW\r\n\t\t// addSelectionCriteria(ValueCriteria.buildNotBeweenCriteria(attribute, value1, value2, getAlias()));\r\n\t\taddSelectionCriteria(ValueCriteria.buildNotBeweenCriteria(attribute, value1, value2, getUserAlias(attribute)));\r\n    }", "label": 0}
{"code": "def write_bus_data(self, file, padding=\"    \"):\n        \"\"\" Writes bus data to file.\n        \"\"\"\n        for bus in self.case.buses:\n            attrs = ['%s=\"%s\"' % (k, v) for k, v in self.bus_attr.iteritems()]\n#            attrs.insert(0, 'label=\"%s\"' % bus.name)\n            attr_str = \", \".join(attrs)\n\n            file.write(\"%s%s [%s];\\n\" % (padding, bus.name, attr_str))", "label": 1}
{"code": "public static void showChannels(Object... channels){\r\n    // TODO this could share more code with the other show/hide(Only)Channels methods\r\n    for(LogRecordHandler handler : handlers){\r\n      if(handler instanceof VisibilityHandler){\r\n        VisibilityHandler visHandler = (VisibilityHandler) handler;\r\n        for (Object channel : channels) {\r\n          visHandler.alsoShow(channel);\r\n        }\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "public static lbvserver_cmppolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_cmppolicy_binding obj = new lbvserver_cmppolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_cmppolicy_binding response[] = (lbvserver_cmppolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (key, intervalSize, limit) {\n        var deferred = Q.defer()\n            , memcached = Shared.memcached();\n        if (!memcached) {\n            deferred.reject();\n        }\n        else {\n            //Get current rate for ip\n            memcached.get(key, function (err, value) {\n                if (err) {\n                    //Allow access as failover\n                    Logger.warn(\"Rate limit set but memcached error, allow access without limit\", err);\n                    deferred.reject();\n                }\n                else if (_.isUndefined(value)) {\n                    memcached.set(key, 1, 60 * intervalSize, function (err) {\n                        if (err) {\n                            Logger.warn(\"Rate limit set but memcached error, allow access without limit\", err);\n                        }\n                    });\n                    deferred.resolve(1);\n                }\n                else {\n                    //Do not increase rate counter if exceeded anyway\n                    if (value < limit) {\n                        // Increase rate counter by 1\n                        memcached.incr(key, 1, function (err) {\n                            if (err) {\n                                Logger.warn(\"Rate limit set but memcached error, allow access without limit\", err);\n                            }\n                        });\n                    }\n                    deferred.resolve(value + 1);\n                }\n            });\n        }\n        return deferred.promise;\n    }", "label": 3}
{"code": "func (ds *datastore) DeleteTree(kvObject KVObject) error {\n\tif ds.sequential {\n\t\tds.Lock()\n\t\tdefer ds.Unlock()\n\t}\n\n\t// cleanup the cache first\n\tif ds.cache != nil {\n\t\t// If persistent store is skipped, sequencing needs to\n\t\t// happen in cache.\n\t\tds.cache.del(kvObject, kvObject.Skip())\n\t}\n\n\tif kvObject.Skip() {\n\t\treturn nil\n\t}\n\n\treturn ds.store.DeleteTree(Key(kvObject.KeyPrefix()...))\n}", "label": 5}
{"code": "function setComparator() {\n    // If the first three letters are \"asc\", sort in ascending order\n    // and remove the prefix.\n    if (by.substring(0,3) == 'asc') {\n      var i = by.substring(3);\n      comp = function(a, b) { return a[i] - b[i]; };\n    } else {\n      // Otherwise sort in descending order.\n      comp = function(a, b) { return b[by] - a[by]; };\n    }\n\n    // Reset link styles and format the selected sort option.\n    $('a.sel').attr('href', '#').removeClass('sel');\n    $('a.by' + by).removeAttr('href').addClass('sel');\n  }", "label": 3}
{"code": "function Adapter(clientPtcl, serverPtcl, fingerprint) {\n  this._clientPtcl = clientPtcl;\n  this._serverPtcl = serverPtcl;\n  this._fingerprint = fingerprint; // Convenience.\n  this._rsvs = clientPtcl.equals(serverPtcl) ? null : this._createResolvers();\n}", "label": 3}
{"code": "public static Set<String> retainMatchingKeys(Counter<String> counter, List<Pattern> matchPatterns) {\r\n    Set<String> removed = new HashSet<String>();\r\n    for (String key : counter.keySet()) {\r\n      boolean matched = false;\r\n      for (Pattern pattern : matchPatterns) {\r\n        if (pattern.matcher(key).matches()) {\r\n          matched = true;\r\n          break;\r\n        }\r\n      }\r\n      if (!matched) {\r\n        removed.add(key);\r\n      }\r\n    }\r\n    for (String key : removed) {\r\n      counter.remove(key);\r\n    }\r\n    return removed;\r\n  }", "label": 0}
{"code": "def _forwardImplementation(self, inbuf, outbuf):\n        \"\"\" Proportional probability method.\n        \"\"\"\n        assert self.module\n\n        propensities = self.module.getActionValues(0)\n\n        summedProps = sum(propensities)\n        probabilities = propensities / summedProps\n\n        action = eventGenerator(probabilities)\n#        action = drawIndex(probabilities)\n\n        outbuf[:] = scipy.array([action])", "label": 1}
{"code": "public static <T> Set<T> asSet(T[] o) {\r\n    return new HashSet<T>(Arrays.asList(o));\r\n  }", "label": 0}
{"code": "public static function getErrorPrefix($level)\n    {\n        switch ($level) {\n            case E_PARSE:\n                $prefix = 'PHP Parse error';\n                break;\n            case E_ERROR:\n            case E_CORE_ERROR:\n            case E_COMPILE_ERROR:\n                $prefix = 'PHP Fatal error';\n                break;\n            case E_USER_ERROR:\n            case E_RECOVERABLE_ERROR:\n                $prefix = 'PHP error';\n                break;\n            case E_WARNING:\n            case E_CORE_WARNING:\n            case E_COMPILE_WARNING:\n            case E_USER_WARNING:\n                $prefix = 'PHP Warning';\n                break;\n            case E_NOTICE:\n            case E_USER_NOTICE:\n                $prefix = 'PHP Notice';\n                break;\n            case E_STRICT:\n                $prefix = 'PHP Debug';\n                break;\n            default:\n                $prefix = 'PHP Notice';\n        }\n        return $prefix;\n    }", "label": 2}
{"code": "def process_users(users)\n      users.each do |element|\n        user = User.new(element, @bot)\n        @users[user.id] = user\n      end\n    end", "label": 4}
{"code": "public static ResourceKey key(Enum<?> value) {\n        return new ResourceKey(value.getClass().getName(), value.name());\n    }", "label": 0}
{"code": "public function newFromBuilder($attributes = [], $connection = null)\n    {\n        $attributes = (array) $attributes;\n\n        if (! empty($attributes['type'])\n            && isset(static::$models[$attributes['type']])\n            && class_exists($class = static::$models[$attributes['type']])\n        ) {\n            /** @var Post $instance */\n            $instance = new $class;\n            $instance->exists = true;\n            $instance->setRawAttributes($attributes, true);\n            $instance->setConnection($connection ?: $this->connection);\n\n            return $instance;\n        }\n\n        return parent::newFromBuilder($attributes, $connection);\n    }", "label": 2}
{"code": "def _file_details(filename):\n    \"\"\" Grab the start and end of the file\"\"\"\n    max_head, max_foot = _max_lengths()\n    with open(filename, \"rb\") as fin:\n        head = fin.read(max_head)\n        try:\n            fin.seek(-max_foot, os.SEEK_END)\n        except IOError:\n            fin.seek(0)\n        foot = fin.read()\n    return head, foot", "label": 1}
{"code": "func (t *Torrent) startMissingTrackerScrapers() {\n\tif t.cl.config.DisableTrackers {\n\t\treturn\n\t}\n\tt.startScrapingTracker(t.metainfo.Announce)\n\tfor _, tier := range t.metainfo.AnnounceList {\n\t\tfor _, url := range tier {\n\t\t\tt.startScrapingTracker(url)\n\t\t}\n\t}\n}", "label": 5}
{"code": "public function setOperation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Logging\\V2\\LogEntryOperation::class);\n        $this->operation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private String parsePropertyName(String orgPropertyName, Object userData) {\n\t\t// try to assure the correct separator is used\n\t\tString propertyName = orgPropertyName.replace(HibernateLayerUtil.XPATH_SEPARATOR, HibernateLayerUtil.SEPARATOR);\n\n\t\t// split the path (separator is defined in the HibernateLayerUtil)\n\t\tString[] props = propertyName.split(HibernateLayerUtil.SEPARATOR_REGEXP);\n\t\tString finalName;\n\t\tif (props.length > 1 && userData instanceof Criteria) {\n\t\t\t// the criteria API requires an alias for each join table !!!\n\t\t\tString prevAlias = null;\n\t\t\tfor (int i = 0; i < props.length - 1; i++) {\n\t\t\t\tString alias = props[i] + \"_alias\";\n\t\t\t\tif (!aliases.contains(alias)) {\n\t\t\t\t\tCriteria criteria = (Criteria) userData;\n\t\t\t\t\tif (i == 0) {\n\t\t\t\t\t\tcriteria.createAlias(props[0], alias);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcriteria.createAlias(prevAlias + \".\" + props[i], alias);\n\t\t\t\t\t}\n\t\t\t\t\taliases.add(alias);\n\t\t\t\t}\n\t\t\t\tprevAlias = alias;\n\t\t\t}\n\t\t\tfinalName = prevAlias + \".\" + props[props.length - 1];\n\t\t} else {\n\t\t\tfinalName = propertyName;\n\t\t}\n\t\treturn finalName;\n\t}", "label": 0}
{"code": "public function recordCacheHit(CacheHit $event)\n    {\n        if (! Telescope::isRecording() || $this->shouldIgnore($event)) {\n            return;\n        }\n\n        Telescope::recordCache(IncomingEntry::make([\n            'type' => 'hit',\n            'key' => $event->key,\n            'value' => $event->value,\n        ]));\n    }", "label": 2}
{"code": "def mounts\n      json = client.get(\"/v1/sys/mounts\")\n      json = json[:data] if json[:data]\n      return Hash[*json.map do |k,v|\n        [k.to_s.chomp(\"/\").to_sym, Mount.decode(v)]\n      end.flatten]\n    end", "label": 4}
{"code": "def prolong(self):\n\t\t\"\"\"Prolong the working duration of an already held lock.\n\t\t\n\t\tAttempting to prolong a lock not already owned will result in a Locked exception.\n\t\t\"\"\"\n\t\t\n\t\tD = self.__class__\n\t\tcollection = self.get_collection()\n\t\tidentity = self.Lock()\n\t\t\n\t\tquery = D.id == self\n\t\tquery &= D.lock.instance == identity.instance\n\t\tquery &= D.lock.time >= (identity.time - identity.__period__)\n\t\t\n\t\tprevious = collection.find_one_and_update(query, {'$set': {~D.lock.time: identity.time}}, {~D.lock: True})\n\t\t\n\t\tif previous is None:\n\t\t\tlock = getattr(self.find_one(self, projection={~D.lock: True}), 'lock', None)\n\t\t\t\n\t\t\tif lock and lock.expires <= identity.time:\n\t\t\t\tlock.expired(self)\n\t\t\t\n\t\t\traise self.Locked(\"Unable to prolong lock.\", lock)\n\t\t\n\t\tidentity.prolonged(self)\n\t\t\n\t\treturn identity", "label": 1}
{"code": "function ClassicDuplex(stream, options) {\n\tvar readable, writable, classicReadable, classicWritable, self = this;\n\n\treadable = new PassThrough();\n\twritable = new PassThrough();\n\tCompoundDuplex.call(self, writable, readable, options);\n\tclassicMixins.call(this, stream, options);\n\n\tclassicReadable = this._internalReadable = new ClassicReadable(stream, options);\n\tclassicReadable.on('error', this._duplexHandleInternalError.bind(this));\n\n\tclassicWritable = this._internalWritable = new ClassicWritable(stream, options);\n\tclassicWritable.on('error', this._duplexHandleInternalError.bind(this));\n\n\twritable.pipe(classicWritable);\n\tclassicReadable.pipe(readable);\n}", "label": 3}
{"code": "public function updateDdlBatch(array $statements, array $options = [])\n    {\n        $operation = $this->connection->updateDatabaseDdl($options + [\n            'name' => $this->name,\n            'statements' => $statements,\n        ]);\n\n        return $this->resumeOperation($operation['name'], $operation);\n    }", "label": 2}
{"code": "def async_fetch(handles, max_rows = 100)\n      # Can't get data from an unfinished query\n      unless async_is_complete?(handles)\n        raise \"Can't perform fetch on a query in state: #{async_state(handles)}\"\n      end\n      \n      # Fetch and\n      fetch_rows(prepare_operation_handle(handles), :first, max_rows)\n    end", "label": 4}
{"code": "def copy_from_csv(conn, file, qualified_name: str, delimiter=',', encoding='utf8',\n                  null_str='', header=True, escape_str='\\\\', quote_char='\"',\n                  force_not_null=None, force_null=None):\n    \"\"\"Copy file-like object to database table.\n\n    Notes\n    -----\n    Implementation defaults to postgres standard except for encoding.\n    Postgres falls back on client encoding, while function defaults to utf-8.\n\n    References\n    ----------\n    https://www.postgresql.org/docs/current/static/sql-copy.html\n\n    \"\"\"\n\n    copy_sql = copy_from_csv_sql(qualified_name, delimiter, encoding,\n                                 null_str=null_str, header=header,\n                                 escape_str=escape_str, quote_char=quote_char,\n                                 force_not_null=force_not_null,\n                                 force_null=force_null)\n\n    with conn:\n        with conn.cursor() as cursor:\n            cursor.copy_expert(copy_sql, file)", "label": 1}
{"code": "function simpleTypeFilter(newDoc, oldDoc, candidateDocType) {\n    if (oldDoc) {\n      if (newDoc._deleted) {\n        return oldDoc.type === candidateDocType;\n      } else {\n        return newDoc.type === oldDoc.type && oldDoc.type === candidateDocType;\n      }\n    } else {\n      return newDoc.type === candidateDocType;\n    }\n  }", "label": 3}
{"code": "function formatSingle(format, val) {\n        var floatRegex = /f$/,\n          decRegex = /\\.([0-9])/,\n          lang = defaultOptions.lang,\n          decimals;\n\n        if (floatRegex.test(format)) { // float\n            decimals = format.match(decRegex);\n            decimals = decimals ? decimals[1] : -1;\n            if (val !== null) {\n                val = numberFormat(\n                  val,\n                  decimals,\n                  lang.decimalPoint,\n                  format.indexOf(',') > -1 ? lang.thousandsSep : ''\n                );\n            }\n        } else {\n            val = dateFormat(format, val);\n        }\n        return val;\n    }", "label": 3}
{"code": "def _get_filtered_study_ids(shard, include_aliases=False):\n    \"\"\"Optionally filters out aliases from standard doc-id list\"\"\"\n    from peyotl.phylesystem.helper import DIGIT_PATTERN\n    k = shard.get_doc_ids()\n    if shard.has_aliases and (not include_aliases):\n        x = []\n        for i in k:\n            if DIGIT_PATTERN.match(i) or ((len(i) > 1) and (i[-2] == '_')):\n                pass\n            else:\n                x.append(i)\n        return x", "label": 1}
{"code": "def trace_symlink_target(link):\n\t\"\"\"\n\tGiven a file that is known to be a symlink, trace it to its ultimate\n\ttarget.\n\n\tRaises TargetNotPresent when the target cannot be determined.\n\tRaises ValueError when the specified link is not a symlink.\n\t\"\"\"\n\n\tif not is_symlink(link):\n\t\traise ValueError(\"link must point to a symlink on the system\")\n\twhile is_symlink(link):\n\t\torig = os.path.dirname(link)\n\t\tlink = readlink(link)\n\t\tlink = resolve_path(link, orig)\n\treturn link", "label": 1}
{"code": "def init():\n    \"\"\"Initialize the communities file storage.\"\"\"\n    try:\n        initialize_communities_bucket()\n        click.secho('Community init successful.', fg='green')\n    except FilesException as e:\n        click.secho(e.message, fg='red')", "label": 1}
{"code": "public function fromComment($comment, $context = null)\n    {\n        if ($context === null) {\n            $context = new Context(['comment' => $comment]);\n        } else {\n            $context->comment = $comment;\n        }\n        try {\n            self::$context = $context;\n            if ($context->is('annotations') === false) {\n                $context->annotations = [];\n            }\n            $comment = preg_replace_callback(\n                '/^[\\t ]*\\*[\\t ]+/m',\n                function ($match) {\n                    // Replace leading tabs with spaces.\n                    // Workaround for http://www.doctrine-project.org/jira/browse/DCOM-255\n                    return str_replace(\"\\t\", ' ', $match[0]);\n                },\n                $comment\n            );\n            $annotations = $this->docParser->parse($comment, $context);\n            self::$context = null;\n            return $annotations;\n        } catch (Exception $e) {\n            self::$context = null;\n            if (preg_match('/^(.+) at position ([0-9]+) in ' . preg_quote((string)$context, '/') . '\\.$/', $e->getMessage(), $matches)) {\n                $errorMessage = $matches[1];\n                $errorPos = (int)$matches[2];\n                $atPos = strpos($comment, '@');\n                $context->line += substr_count($comment, \"\\n\", 0, $atPos + $errorPos);\n                $lines = explode(\"\\n\", substr($comment, $atPos, $errorPos));\n                $context->character = strlen(array_pop($lines)) + 1; // position starts at 0 character starts at 1\n                Logger::warning(new Exception($errorMessage . ' in ' . $context, $e->getCode(), $e));\n            } else {\n                Logger::warning($e);\n            }\n            return [];\n        }\n    }", "label": 2}
{"code": "def destroy\n      Hyrax::Actors::EmbargoActor.new(curation_concern).destroy\n      flash[:notice] = curation_concern.embargo_history.last\n      if curation_concern.work? && curation_concern.file_sets.present?\n        redirect_to confirm_permission_path\n      else\n        redirect_to edit_embargo_path\n      end\n    end", "label": 4}
{"code": "function _isValid(el, currentPath) {\n\t// Link has no destination URL\n\tif (! el.href) { return false; }\n\n\t// Link opens a new browser window\n\tif (el.target === '_blank') { return false; }\n\n\t// Link is not absolute URL\n\tif (! /https?:/.test(el.href)) { return false; }\n\n\t// Link is a download\n\tif (el.hasAttribute('download')) { return false; }\n\n\t// Link is supposed to be ignored\n\tif (el.hasAttribute('data-static')) { return false; }\n\n\t// Link is external URL\n\tif (el.host && el.host !== location.host) { return false; }\n\n\t// Link is current page, but with a hash added\n\tif (el.hash && el.pathname === currentPath) { return false; }\n\n\treturn true;\n}", "label": 3}
{"code": "protected boolean check(String id, List<String> includes) {\n\t\tif (null != includes) {\n\t\t\tfor (String check : includes) {\n\t\t\t\tif (check(id, check)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "label": 0}
{"code": "func isFile(fl FieldLevel) bool {\n\tfield := fl.Field()\n\n\tswitch field.Kind() {\n\tcase reflect.String:\n\t\tfileInfo, err := os.Stat(field.String())\n\t\tif err != nil {\n\t\t\treturn false\n\t\t}\n\n\t\treturn !fileInfo.IsDir()\n\t}\n\n\tpanic(fmt.Sprintf(\"Bad field type %T\", field.Interface()))\n}", "label": 5}
{"code": "public function close($reply_code = 0, $reply_text = '', $method_sig = array(0, 0))\n    {\n        $this->callbacks = array();\n        if ($this->is_open === false || $this->connection === null) {\n            $this->do_close();\n\n            return null; // already closed\n        }\n        list($class_id, $method_id, $args) = $this->protocolWriter->channelClose(\n            $reply_code,\n            $reply_text,\n            $method_sig[0],\n            $method_sig[1]\n        );\n\n        try {\n            $this->send_method_frame(array($class_id, $method_id), $args);\n        } catch (\\Exception $e) {\n            $this->do_close();\n\n            throw $e;\n        }\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('channel.close_ok')\n        ), false, $this->channel_rpc_timeout );\n    }", "label": 2}
{"code": "def _load_filter(self, config):\n        \"\"\" Load the filter file and populates self._devices accordingly \"\"\"\n        path = pathlib.Path(config)\n        if not path.is_file():\n            return\n\n        with open(config, 'r') as conf:\n            devices = yaml.load(conf)['devices']\n            for ha_id, dev in devices.items():\n                self._devices[dev['scs_id']] = {\n                    ha_id: dev,\n                    'name': dev['name']}", "label": 1}
{"code": "def pattern_to_str(pattern):\n    \"\"\"Convert regex pattern to string.\n\n    If pattern is string it returns itself,\n    if pattern is SRE_Pattern then return pattern attribute\n    :param pattern: pattern object or string\n    :return: str: pattern sttring\n    \"\"\"\n    if isinstance(pattern, str):\n        return repr(pattern)\n    else:\n        return repr(pattern.pattern) if pattern else None", "label": 1}
{"code": "private function commitInSingleUseTransaction(array $mutations, array $options = [])\n    {\n        $options['mutations'] = $mutations;\n\n        return $this->runTransaction(function (Transaction $t) use ($options) {\n            return $t->commit($options);\n        }, [\n            'singleUse' => true\n        ]);\n    }", "label": 2}
{"code": "private function parentPath($name)\n    {\n        $parts = $this->splitName($name);\n        array_pop($parts);\n\n        return implode('/', $parts);\n    }", "label": 2}
{"code": "def _create_update_tracking_event(instance):\n    \"\"\"\n    Create a TrackingEvent and TrackedFieldModification for an UPDATE event.\n    \"\"\"\n    event = _create_event(instance, UPDATE)\n    for field in instance._tracked_fields:\n        if not isinstance(instance._meta.get_field(field), ManyToManyField):\n            try:\n                if isinstance(instance._meta.get_field(field), ForeignKey):\n                    # Compare pk\n                    value = getattr(instance, '{0}_id'.format(field))\n                else:\n                    value = getattr(instance, field)\n                if instance._original_fields[field] != value:\n                    _create_tracked_field(event, instance, field)\n            except TypeError:\n                # Can't compare old and new value, should be different.\n                _create_tracked_field(event, instance, field)", "label": 1}
{"code": "def representatives(self, count=None, sorting=False):\n        \"\"\"\n        Returns a list of pairs of representative and its voting weight\n\n        :param count: Max amount of representatives to return\n        :type count: int\n\n        :param sorting: If true, sorts by weight\n        :type sorting: bool\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.representatives()\n        {\n            \"xrb_1111111111111111111111111111111111111111111111111117353trpda\":\n                3822372327060170000000000000000000000,\n            \"xrb_1111111111111111111111111111111111111111111111111awsq94gtecn\":\n                30999999999999999999999999000000,\n            \"xrb_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\":\n                0\n        }\n\n\n        \"\"\"\n        payload = {}\n\n        if count is not None:\n            payload['count'] = self._process_value(count, 'int')\n\n        if sorting:\n            payload['sorting'] = self._process_value(sorting, 'strbool')\n\n        resp = self.call('representatives', payload)\n\n        representatives = resp.get('representatives') or {}\n\n        for k, v in representatives.items():\n            representatives[k] = int(v)\n\n        return representatives", "label": 1}
{"code": "function npm(cwd, cmd) {\n  console.log(cwd, chalk.blue('running npm', cmd));\n  const npm = process.platform === 'win32' ? 'npm.cmd' : 'npm';\n  return spawn(npm, (cmd || 'install').split(' '), {cwd, env});\n}", "label": 3}
{"code": "def rubyize_format(original_data)\n      data = original_data.to_snake_keys.deep_symbolize_keys\n\n      definitions = data[:container_definitions]\n      definitions.each_with_index do |definition, i|\n        next unless definition[:log_configuration]\n        options = definition[:log_configuration][:options]\n        next unless options\n\n        # LogConfiguration options do not get transformed and keep their original\n        # structure:\n        #   https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/ECS/Types/ContainerDefinition.html\n        original_definition = original_data[\"containerDefinitions\"][i]\n        definition[:log_configuration][:options] = original_definition[\"logConfiguration\"][\"options\"]\n      end\n\n      data\n    end", "label": 4}
{"code": "func NewSpdyRoundTripperWithDialer(cfg roundTripperConfig) *SpdyRoundTripper {\n\treturn &SpdyRoundTripper{tlsConfig: cfg.tlsConfig, followRedirects: cfg.followRedirects, dialWithContext: cfg.dial, ctx: cfg.ctx, authCtx: cfg.authCtx, bearerToken: cfg.bearerToken}\n}", "label": 5}
{"code": "function removeLeadingLinebreaks(text) {\n    let linebreak = determineLinebreaks(text);\n    if (linebreak === \"\") return text;\n\n    while (text.startsWith(linebreak)) {\n        text = text.slice(linebreak.length);\n    }\n\n    return text;\n}", "label": 3}
{"code": "function(name, config, initOptionsFactory){\n            var key,\n                dataKey = 'composition-handler-' + name,\n                handler;\n\n            config = config || ko.bindingHandlers[name];\n            initOptionsFactory = initOptionsFactory || function(){ return undefined;  };\n\n            handler = ko.bindingHandlers[name] = {\n                init: function(element, valueAccessor, allBindingsAccessor, viewModel, bindingContext) {\n                    if(compositionCount > 0){\n                        var data = {\n                            trigger:ko.observable(null)\n                        };\n\n                        composition.current.complete(function(){\n                            if(config.init){\n                                config.init(element, valueAccessor, allBindingsAccessor, viewModel, bindingContext);\n                            }\n\n                            if(config.update){\n                                ko.utils.domData.set(element, dataKey, config);\n                                data.trigger('trigger');\n                            }\n                        });\n\n                        ko.utils.domData.set(element, dataKey, data);\n                    }else{\n                        ko.utils.domData.set(element, dataKey, config);\n\n                        if(config.init){\n                            config.init(element, valueAccessor, allBindingsAccessor, viewModel, bindingContext);\n                        }\n                    }\n\n                    return initOptionsFactory(element, valueAccessor, allBindingsAccessor, viewModel, bindingContext);\n                },\n                update: function (element, valueAccessor, allBindingsAccessor, viewModel, bindingContext) {\n                    var data = ko.utils.domData.get(element, dataKey);\n\n                    if(data.update){\n                        return data.update(element, valueAccessor, allBindingsAccessor, viewModel, bindingContext);\n                    }\n\n                    if(data.trigger){\n                        data.trigger();\n                    }\n                }\n            };\n\n            for (key in config) {\n                if (key !== \"init\" && key !== \"update\") {\n                    handler[key] = config[key];\n                }\n            }\n        }", "label": 3}
{"code": "public function registerDebuggee(array $args = [])\n    {\n        return $this->send([$this->controllerClient, 'registerDebuggee'], [\n            $this->serializer->decodeMessage(\n                new Debuggee(),\n                $this->pluck('debuggee', $args)\n            ),\n            $args\n        ]);\n    }", "label": 2}
{"code": "public function getCalendarFormats($locale = null)\n    {\n        return [\n            'sameDay' => $this->getTranslationMessage('calendar.sameDay', $locale, '[Today at] LT'),\n            'nextDay' => $this->getTranslationMessage('calendar.nextDay', $locale, '[Tomorrow at] LT'),\n            'nextWeek' => $this->getTranslationMessage('calendar.nextWeek', $locale, 'dddd [at] LT'),\n            'lastDay' => $this->getTranslationMessage('calendar.lastDay', $locale, '[Yesterday at] LT'),\n            'lastWeek' => $this->getTranslationMessage('calendar.lastWeek', $locale, '[Last] dddd [at] LT'),\n            'sameElse' => $this->getTranslationMessage('calendar.sameElse', $locale, 'L'),\n        ];\n    }", "label": 2}
{"code": "def _growth_curve_pooling_group(self, distr='glo', as_rural=False):\n        \"\"\"\n        Return flood growth curve function based on `amax_records` from a pooling group.\n\n        :return: Inverse cumulative distribution function with one parameter `aep` (annual exceedance probability)\n        :type: :class:`.GrowthCurve`\n        :param as_rural: assume catchment is fully rural. Default: false.\n        :type as rural: bool\n        \"\"\"\n        if not self.donor_catchments:\n            self.find_donor_catchments()\n        gc = GrowthCurve(distr, *self._var_and_skew(self.donor_catchments))\n\n        # Record intermediate results\n        self.results_log['distr_name'] = distr.upper()\n        self.results_log['distr_params'] = gc.params\n        return gc", "label": 1}
{"code": "def status_codes_by_date_stats():\n    \"\"\"\n    Get stats for status codes by date.\n\n    Returns:\n        list: status codes + date grouped by type: 2xx, 3xx, 4xx, 5xx, attacks.\n    \"\"\"\n\n    def date_counter(queryset):\n        return dict(Counter(map(\n            lambda dt: ms_since_epoch(datetime.combine(\n                make_naive(dt), datetime.min.time())),\n            list(queryset.values_list('datetime', flat=True)))))\n\n    codes = {low: date_counter(\n        RequestLog.objects.filter(status_code__gte=low, status_code__lt=high))\n        for low, high in ((200, 300), (300, 400), (400, 500))}\n    codes[500] = date_counter(RequestLog.objects.filter(status_code__gte=500))\n    codes['attacks'] = date_counter(RequestLog.objects.filter(\n        status_code__in=(400, 444, 502)))\n\n    stats = {}\n    for code in (200, 300, 400, 500, 'attacks'):\n        for date, count in codes[code].items():\n            if stats.get(date, None) is None:\n                stats[date] = {200: 0, 300: 0, 400: 0, 500: 0, 'attacks': 0}\n            stats[date][code] += count\n\n    stats = sorted([(k, v) for k, v in stats.items()], key=lambda x: x[0])\n    return stats", "label": 1}
{"code": "def view_assigns\n      protected_vars = _protected_ivars\n      variables      = instance_variables\n\n      variables.reject! { |s| protected_vars.include? s }\n      variables.each_with_object({}) { |name, hash|\n        hash[name.slice(1, name.length)] = instance_variable_get(name)\n      }\n    end", "label": 4}
{"code": "def setup(context, options, as, block)\n        @options = options\n        @block   = block\n\n        @locals  = options[:locals] || {}\n        @details = extract_details(options)\n\n        partial = options[:partial]\n\n        if String === partial\n          @has_object = options.key?(:object)\n          @object     = options[:object]\n          @collection = collection_from_options\n          @path       = partial\n        else\n          @has_object = true\n          @object = partial\n          @collection = collection_from_object || collection_from_options\n\n          if @collection\n            paths = @collection_data = @collection.map { |o| partial_path(o, context) }\n            if paths.uniq.length == 1\n              @path = paths.first\n            else\n              paths.map! { |path| retrieve_variable(path, as).unshift(path) }\n              @path = nil\n            end\n          else\n            @path = partial_path(@object, context)\n          end\n        end\n\n        self\n      end", "label": 4}
{"code": "public static base_responses add(nitro_service client, sslocspresponder resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslocspresponder addresources[] = new sslocspresponder[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new sslocspresponder();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].url = resources[i].url;\n\t\t\t\taddresources[i].cache = resources[i].cache;\n\t\t\t\taddresources[i].cachetimeout = resources[i].cachetimeout;\n\t\t\t\taddresources[i].batchingdepth = resources[i].batchingdepth;\n\t\t\t\taddresources[i].batchingdelay = resources[i].batchingdelay;\n\t\t\t\taddresources[i].resptimeout = resources[i].resptimeout;\n\t\t\t\taddresources[i].respondercert = resources[i].respondercert;\n\t\t\t\taddresources[i].trustresponder = resources[i].trustresponder;\n\t\t\t\taddresources[i].producedattimeskew = resources[i].producedattimeskew;\n\t\t\t\taddresources[i].signingcert = resources[i].signingcert;\n\t\t\t\taddresources[i].usenonce = resources[i].usenonce;\n\t\t\t\taddresources[i].insertclientcert = resources[i].insertclientcert;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function getResolvedSignature(node, candidatesOutArray) {\n            var links = getNodeLinks(node);\n            // If getResolvedSignature has already been called, we will have cached the resolvedSignature.\n            // However, it is possible that either candidatesOutArray was not passed in the first time,\n            // or that a different candidatesOutArray was passed in. Therefore, we need to redo the work\n            // to correctly fill the candidatesOutArray.\n            var cached = links.resolvedSignature;\n            if (cached && cached !== resolvingSignature && !candidatesOutArray) {\n                return cached;\n            }\n            links.resolvedSignature = resolvingSignature;\n            var result = resolveSignature(node, candidatesOutArray);\n            // If signature resolution originated in control flow type analysis (for example to compute the\n            // assigned type in a flow assignment) we don't cache the result as it may be based on temporary\n            // types from the control flow analysis.\n            links.resolvedSignature = flowLoopStart === flowLoopCount ? result : cached;\n            return result;\n        }", "label": 3}
{"code": "public static vpntrafficpolicy_vpnvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpntrafficpolicy_vpnvserver_binding obj = new vpntrafficpolicy_vpnvserver_binding();\n\t\tobj.set_name(name);\n\t\tvpntrafficpolicy_vpnvserver_binding response[] = (vpntrafficpolicy_vpnvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func ParseSessionsURI(in string) (*url.URL, error) {\n\tif in == \"\" {\n\t\treturn nil, trace.BadParameter(\"uri is empty\")\n\t}\n\tu, err := url.Parse(in)\n\tif err != nil {\n\t\treturn nil, trace.BadParameter(\"failed to parse URI %q: %v\", in, err)\n\t}\n\tif u.Scheme == \"\" {\n\t\tu.Scheme = teleport.SchemeFile\n\t}\n\treturn u, nil\n}", "label": 5}
{"code": "public static File writeObjectToTempFileNoExceptions(Object o, String filename) {\r\n    try {\r\n      return writeObjectToTempFile(o, filename);\r\n    } catch (Exception e) {\r\n      System.err.println(\"Error writing object to file \" + filename);\r\n      e.printStackTrace();\r\n      return null;\r\n    }\r\n  }", "label": 0}
{"code": "private void checkCollectionForeignkeys(ModelDef modelDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        ClassDescriptorDef      classDef;\r\n        CollectionDescriptorDef collDef;\r\n\r\n        for (Iterator it = modelDef.getClasses(); it.hasNext();)\r\n        {\r\n            classDef = (ClassDescriptorDef)it.next();\r\n            for (Iterator collIt = classDef.getCollections(); collIt.hasNext();)\r\n            {\r\n                collDef = (CollectionDescriptorDef)collIt.next();\r\n                if (!collDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_IGNORE, false))\r\n                {\r\n                    if (collDef.hasProperty(PropertyHelper.OJB_PROPERTY_INDIRECTION_TABLE))\r\n                    {\r\n                        checkIndirectionTable(modelDef, collDef);\r\n                    }\r\n                    else\r\n                    {    \r\n                        checkCollectionForeignkeys(modelDef, collDef);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "func CompareIPNet(a, b *net.IPNet) bool {\n\tif a == b {\n\t\treturn true\n\t}\n\tif a == nil || b == nil {\n\t\treturn false\n\t}\n\treturn a.IP.Equal(b.IP) && bytes.Equal(a.Mask, b.Mask)\n}", "label": 5}
{"code": "private function createSessions($count)\n    {\n        $args = [\n            'database' => $this->database->name(),\n            'session' => [\n                'labels' => isset($this->config['labels']) ? $this->config['labels'] : []\n            ]\n        ];\n\n        $promises = [];\n\n        for ($i = 0; $i < $count; $i++) {\n            $promises[] = $this->database->connection()->createSessionAsync($args);\n        }\n\n        $results = Promise\\settle($promises)->wait();\n\n        $sessions = [];\n\n        foreach ($results as $result) {\n            if ($result['state'] === 'fulfilled') {\n                $name = $result['value']->getName();\n                $sessions[] = [\n                    'name' => $name,\n                    'expiration' => $this->time() + SessionPoolInterface::SESSION_EXPIRATION_SECONDS\n                ];\n            }\n        }\n\n        return $sessions;\n    }", "label": 2}
{"code": "public static List<Dependency> getAllDependencies(final Module module) {\n        final Set<Dependency> dependencies = new HashSet<Dependency>();\n        final List<String> producedArtifacts = new ArrayList<String>();\n        for(final Artifact artifact: getAllArtifacts(module)){\n            producedArtifacts.add(artifact.getGavc());\n        }\n\n        dependencies.addAll(getAllDependencies(module, producedArtifacts));\n\n        return new ArrayList<Dependency>(dependencies);\n    }", "label": 0}
{"code": "public function setClassification($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\ClassificationAnnotation::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function setInteractionType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Speech\\V1p1beta1\\RecognitionMetadata_InteractionType::class);\n        $this->interaction_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public Counter<K1> sumInnerCounter() {\r\n    Counter<K1> summed = new ClassicCounter<K1>();\r\n    for (K1 key : this.firstKeySet()) {\r\n      summed.incrementCount(key, this.getCounter(key).totalCount());\r\n    }\r\n    return summed;\r\n  }", "label": 0}
{"code": "def as_python(self, infile, include_original_shex: bool=False):\n        \"\"\" Return the python representation of the document \"\"\"\n        self._context.resolve_circular_references()            # add forwards for any circular entries\n        body = ''\n        for k in self._context.ordered_elements():\n            v = self._context.grammarelts[k]\n            if isinstance(v, (JSGLexerRuleBlock, JSGObjectExpr)):\n                body += v.as_python(k)\n                if isinstance(v, JSGObjectExpr) and not self._context.has_typeid:\n                    self._context.directives.append(f'_CONTEXT.TYPE_EXCEPTIONS.append(\"{k}\")')\n            elif isinstance(v, JSGForwardRef):\n                pass\n            elif isinstance(v, (JSGValueType, JSGArrayExpr)):\n                body += f\"\\n\\n\\n{k} = {v.signature_type()}\"\n            else:\n                raise NotImplementedError(\"Unknown grammar elt for {}\".format(k))\n            self._context.forward_refs.pop(k, None)\n\n        body = '\\n' + '\\n'.join(self._context.directives) + body\n        return _jsg_python_template.format(infile=infile,\n                                           original_shex='# ' + self.text if include_original_shex else \"\",\n                                           version=__version__,\n                                           gendate=datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"),\n                                           body=body)", "label": 1}
{"code": "protected function normalizeRequestUri(Request $request)\n    {\n        $query = $request->server->get('QUERY_STRING');\n\n        $uri = '/'.trim(str_replace('?'.$query, '', $request->server->get('REQUEST_URI')), '/').($query ? '?'.$query : '');\n\n        $request->server->set('REQUEST_URI', $uri);\n    }", "label": 2}
{"code": "public static appqoepolicy_stats[] get(nitro_service service) throws Exception{\n\t\tappqoepolicy_stats obj = new appqoepolicy_stats();\n\t\tappqoepolicy_stats[] response = (appqoepolicy_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (c *Call) isPreReq(other *Call) bool {\n\tfor _, preReq := range c.preReqs {\n\t\tif other == preReq || preReq.isPreReq(other) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "func (a *AuthWithRoles) RotateExternalCertAuthority(ca services.CertAuthority) error {\n\tif ca == nil {\n\t\treturn trace.BadParameter(\"missing certificate authority\")\n\t}\n\tctx := &services.Context{User: a.user, Resource: ca}\n\tif err := a.actionWithContext(ctx, defaults.Namespace, services.KindCertAuthority, services.VerbRotate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.RotateExternalCertAuthority(ca)\n}", "label": 5}
{"code": "def get_builtin_type(self, model):\n        \"\"\"Return built-in type representation of Collection.\n\n        :param DomainModel model:\n        :rtype list:\n        \"\"\"\n        return [item.get_data() if isinstance(item, self.related_model_cls)\n                else item for item in self.get_value(model)]", "label": 1}
{"code": "function bindContainer(node, containerFlags) {\n            // Before we recurse into a node's children, we first save the existing parent, container\n            // and block-container.  Then after we pop out of processing the children, we restore\n            // these saved values.\n            var saveContainer = container;\n            var savedBlockScopeContainer = blockScopeContainer;\n            // Depending on what kind of node this is, we may have to adjust the current container\n            // and block-container.   If the current node is a container, then it is automatically\n            // considered the current block-container as well.  Also, for containers that we know\n            // may contain locals, we proactively initialize the .locals field. We do this because\n            // it's highly likely that the .locals will be needed to place some child in (for example,\n            // a parameter, or variable declaration).\n            //\n            // However, we do not proactively create the .locals for block-containers because it's\n            // totally normal and common for block-containers to never actually have a block-scoped\n            // variable in them.  We don't want to end up allocating an object for every 'block' we\n            // run into when most of them won't be necessary.\n            //\n            // Finally, if this is a block-container, then we clear out any existing .locals object\n            // it may contain within it.  This happens in incremental scenarios.  Because we can be\n            // reusing a node from a previous compilation, that node may have had 'locals' created\n            // for it.  We must clear this so we don't accidentally move any stale data forward from\n            // a previous compilation.\n            if (containerFlags & 1 /* IsContainer */) {\n                container = blockScopeContainer = node;\n                if (containerFlags & 32 /* HasLocals */) {\n                    container.locals = ts.createMap();\n                }\n                addToContainerChain(container);\n            }\n            else if (containerFlags & 2 /* IsBlockScopedContainer */) {\n                blockScopeContainer = node;\n                blockScopeContainer.locals = undefined;\n            }\n            if (containerFlags & 4 /* IsControlFlowContainer */) {\n                var saveCurrentFlow = currentFlow;\n                var saveBreakTarget = currentBreakTarget;\n                var saveContinueTarget = currentContinueTarget;\n                var saveReturnTarget = currentReturnTarget;\n                var saveActiveLabels = activeLabels;\n                var saveHasExplicitReturn = hasExplicitReturn;\n                var isIIFE = containerFlags & 16 /* IsFunctionExpression */ && !!ts.getImmediatelyInvokedFunctionExpression(node);\n                // An IIFE is considered part of the containing control flow. Return statements behave\n                // similarly to break statements that exit to a label just past the statement body.\n                if (isIIFE) {\n                    currentReturnTarget = createBranchLabel();\n                }\n                else {\n                    currentFlow = { flags: 2 /* Start */ };\n                    if (containerFlags & 16 /* IsFunctionExpression */) {\n                        currentFlow.container = node;\n                    }\n                    currentReturnTarget = undefined;\n                }\n                currentBreakTarget = undefined;\n                currentContinueTarget = undefined;\n                activeLabels = undefined;\n                hasExplicitReturn = false;\n                bindChildren(node);\n                // Reset all reachability check related flags on node (for incremental scenarios)\n                // Reset all emit helper flags on node (for incremental scenarios)\n                node.flags &= ~4030464 /* ReachabilityAndEmitFlags */;\n                if (!(currentFlow.flags & 1 /* Unreachable */) && containerFlags & 8 /* IsFunctionLike */ && ts.nodeIsPresent(node.body)) {\n                    node.flags |= 32768 /* HasImplicitReturn */;\n                    if (hasExplicitReturn)\n                        node.flags |= 65536 /* HasExplicitReturn */;\n                }\n                if (node.kind === 256 /* SourceFile */) {\n                    node.flags |= emitFlags;\n                }\n                if (isIIFE) {\n                    addAntecedent(currentReturnTarget, currentFlow);\n                    currentFlow = finishFlowLabel(currentReturnTarget);\n                }\n                else {\n                    currentFlow = saveCurrentFlow;\n                }\n                currentBreakTarget = saveBreakTarget;\n                currentContinueTarget = saveContinueTarget;\n                currentReturnTarget = saveReturnTarget;\n                activeLabels = saveActiveLabels;\n                hasExplicitReturn = saveHasExplicitReturn;\n            }\n            else if (containerFlags & 64 /* IsInterface */) {\n                seenThisKeyword = false;\n                bindChildren(node);\n                node.flags = seenThisKeyword ? node.flags | 16384 /* ContainsThis */ : node.flags & ~16384 /* ContainsThis */;\n            }\n            else {\n                bindChildren(node);\n            }\n            container = saveContainer;\n            blockScopeContainer = savedBlockScopeContainer;\n        }", "label": 3}
{"code": "func (s *APIServer) getTunnelConnections(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tconns, err := auth.GetTunnelConnections(p.ByName(\"cluster\"))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\titems := make([]json.RawMessage, len(conns))\n\tfor i, conn := range conns {\n\t\tdata, err := services.MarshalTunnelConnection(conn, services.WithVersion(version), services.PreserveResourceID())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\titems[i] = data\n\t}\n\treturn items, nil\n}", "label": 5}
{"code": "func DjangoAdminLogsByUserID(db XODB, userID float64) ([]*DjangoAdminLog, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, action_time, object_id, object_repr, action_flag, change_message, content_type_id, user_id ` +\n\t\t`FROM django.django_admin_log ` +\n\t\t`WHERE user_id = :1`\n\n\t// run query\n\tXOLog(sqlstr, userID)\n\tq, err := db.Query(sqlstr, userID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*DjangoAdminLog{}\n\tfor q.Next() {\n\t\tdal := DjangoAdminLog{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&dal.ID, &dal.ActionTime, &dal.ObjectID, &dal.ObjectRepr, &dal.ActionFlag, &dal.ChangeMessage, &dal.ContentTypeID, &dal.UserID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &dal)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def search_star(star):\n    '''\n    It is also possible to query the stars by label, here is an example of querying for the star labeled as Sun.\n\n    http://star-api.herokuapp.com/api/v1/stars/Sun\n    '''\n\n    base_url = \"http://star-api.herokuapp.com/api/v1/stars/\"\n\n    if not isinstance(star, str):\n        raise ValueError(\"The star arg you provided is not the type of str\")\n    else:\n        base_url += star\n\n    return dispatch_http_get(base_url)", "label": 1}
{"code": "public function setExclusion($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Logging\\V2\\LogExclusion::class);\n        $this->exclusion = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setJobs($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\DlpJob::class);\n        $this->jobs = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, dnssrvrec resource) throws Exception {\n\t\tdnssrvrec updateresource = new dnssrvrec();\n\t\tupdateresource.domain = resource.domain;\n\t\tupdateresource.target = resource.target;\n\t\tupdateresource.priority = resource.priority;\n\t\tupdateresource.weight = resource.weight;\n\t\tupdateresource.port = resource.port;\n\t\tupdateresource.ttl = resource.ttl;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "function buildMethodName(req) {\n    return [\n        req.params.service,\n        req.params.subservice\n    ].filter(Boolean).join('-');\n}", "label": 3}
{"code": "public function findByUser(User $user, $limit = null, $offset = 0)\n    {\n        $primaries = Notification::select(\n            app('flarum.db')->raw('MAX(id) AS id'),\n            app('flarum.db')->raw('SUM(read_at IS NULL) AS unread_count')\n        )\n            ->where('user_id', $user->id)\n            ->whereIn('type', $user->getAlertableNotificationTypes())\n            ->where('is_deleted', false)\n            ->whereSubjectVisibleTo($user)\n            ->groupBy('type', 'subject_id')\n            ->orderByRaw('MAX(created_at) DESC')\n            ->skip($offset)\n            ->take($limit);\n\n        return Notification::select('notifications.*', app('flarum.db')->raw('p.unread_count'))\n            ->mergeBindings($primaries->getQuery())\n            ->join(app('flarum.db')->raw('('.$primaries->toSql().') p'), 'notifications.id', '=', app('flarum.db')->raw('p.id'))\n            ->latest()\n            ->get();\n    }", "label": 2}
{"code": "func (c *closerConn) addCloser(closer io.Closer) {\n\tc.closers = append(c.closers, closer)\n}", "label": 5}
{"code": "def bulk_edit(self, _fields, ids=None, filter=None, type=None, all=False, testvars=None): # pylint: disable=redefined-builtin\n        \"\"\"Bulk edit a set of configs.\n\n        :param _fields: :class:`configs.Config <configs.Config>` object\n        :param ids: (optional) Int list of config IDs.\n        :param filter: (optional) String list of filters.\n        :param type: (optional) `union` or `inter` as string.\n        :param all: (optional) Apply to all if bool `True`.\n        :param testvars: (optional) :class:`configs.ConfigTestvars <configs.ConfigTestvars>` list\n        \"\"\"\n        schema = self.EDIT_SCHEMA\n        _fields = self.service.encode(schema, _fields, skip_none=True)\n        return self.service.bulk_edit(self.base, self.RESOURCE,\n                                      _fields, ids=ids, filter=filter, type=type, all=all, testvars=testvars)", "label": 1}
{"code": "public static function tableName($project, $instance, $table)\n    {\n        return self::getTableNameTemplate()->render([\n            'project' => $project,\n            'instance' => $instance,\n            'table' => $table,\n        ]);\n    }", "label": 2}
{"code": "def retry_in(period)\n      return unless que_target\n\n      if id = que_target.que_attrs[:id]\n        values = [period]\n\n        if e = que_target.que_error\n          values << \"#{e.class}: #{e.message}\".slice(0, 500) << e.backtrace.join(\"\\n\").slice(0, 10000)\n        else\n          values << nil << nil\n        end\n\n        Que.execute :set_error, values << id\n      end\n\n      que_target.que_resolved = true\n    end", "label": 4}
{"code": "public function handleChange(OutputInterface $output, array $commitRelease, $level = null)\n    {\n        $choices = array_keys($commitRelease);\n\n        if (count($choices) > 1) {\n            $options = array_merge([\n                'All Components'\n            ], $choices, [\n                'Go Back'\n            ]);\n\n            // By default, all components are batch modified in this method.\n            $q = $this->choice('Choose a component to modify.', $options, $options[0]);\n            $component = $this->removeDefaultFromChoice($this->askQuestion($q));\n\n            if ($component === 'Go Back') {\n                return $commitRelease;\n            }\n\n            if ($component === 'All Components') {\n                $component = null;\n            }\n        } else {\n            $component = $choices[0];\n        }\n\n        if ($level === null) {\n            if ($component) {\n                $componentOverview = sprintf(\n                    '<info>google/%s</info> [<info>%s</info>]:',\n                    $component,\n                    $this->levels[$commitRelease[$component]['level']]\n                );\n\n                $currentMessage = $commitRelease[$component]['message'];\n            } else {\n                $componentOverview = sprintf(\n                    'Modifying <info>%s</info> components.',\n                    count($commitRelease)\n                );\n\n                $currentMessage = current($commitRelease)['message'];\n            }\n\n            $key = 'message';\n            $value = $this->ask(sprintf(\n                '%s Enter a release note message. Do not enter the Pull Request reference number.'.\n                PHP_EOL .'  - Message: <info>%s</info>',\n                $componentOverview,\n                $currentMessage\n            ), $currentMessage);\n\n            $value .= ' (#'. current($commitRelease)['ref'] .')';\n        } elseif (array_key_exists($level, $this->levels)) {\n            $key = 'level';\n            $value = $level;\n        } else {\n            throw new \\Exception('Something went really wrong.');\n        }\n\n        if ($component) {\n            $commitRelease[$component][$key] = $value;\n        } else {\n            foreach ($commitRelease as &$commitComponent) {\n                $commitComponent[$key] = $value;\n            }\n\n        }\n\n        return $commitRelease;\n    }", "label": 2}
{"code": "def set_status(self, name, status):\n        \"\"\"\n            Set sensor ``name`` status to ``status``.\n        \"\"\"\n        getattr(self.system, name).status = status\n        return True", "label": 1}
{"code": "public static autoscalepolicy_stats get(nitro_service service, String name) throws Exception{\n\t\tautoscalepolicy_stats obj = new autoscalepolicy_stats();\n\t\tobj.set_name(name);\n\t\tautoscalepolicy_stats response = (autoscalepolicy_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (f *File) Priority() piecePriority {\n\tf.t.cl.lock()\n\tdefer f.t.cl.unlock()\n\treturn f.prio\n}", "label": 5}
{"code": "def convert(from_currency, to_currency, from_currency_price=1):\n\t\"\"\" convert from from_currency to to_currency using cached info \"\"\"\n\tget_cache()\n\tfrom_currency, to_currency = validate_currency(from_currency, to_currency)\n\tupdate_cache(from_currency, to_currency)\n\treturn ccache[from_currency][to_currency]['value'] * from_currency_price", "label": 1}
{"code": "func (c *Manager) GetLibraries(ctx context.Context) ([]Library, error) {\n\tids, err := c.ListLibraries(ctx)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"get libraries failed for: %s\", err)\n\t}\n\n\tvar libraries []Library\n\tfor _, id := range ids {\n\t\tlibrary, err := c.GetLibraryByID(ctx, id)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"get library %s failed for %s\", id, err)\n\t\t}\n\n\t\tlibraries = append(libraries, *library)\n\n\t}\n\treturn libraries, nil\n}", "label": 5}
{"code": "public static spilloverpolicy[] get(nitro_service service, options option) throws Exception{\n\t\tspilloverpolicy obj = new spilloverpolicy();\n\t\tspilloverpolicy[] response = (spilloverpolicy[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (fullpath, publname) {\n\n    var curr_time = new Date();\n\n    // store script if modified for first time\n    if (fullpath !== undefined && publname !== undefined) {\n\n        if (l_modified_scripts.hasOwnProperty(fullpath) === false) {\n                            \n            LOG.warn('script modified: ' + fullpath, l_name);\n            l_modified_scripts[fullpath] = {\n                time: new Date(curr_time.getTime() + l_reloadTime * 1000),\n                name: publname\n            };\n        }\n        // if already stored, ignore this request\n        else\n            return;\n    }\n    else {\n\n        // check queue for scripts that can be safely reloaded\n        for (var path in l_modified_scripts) {\n        \n            // check if wait time has expired\n            if (curr_time - l_modified_scripts[path].time > 0) {\n\n                // get public name\n                var name = l_modified_scripts[path].name;\n                var notify_msg = 'reloading [' + name + '] from: ' + path;\n\t\t\t\tLOG.warn(notify_msg, l_name);\n\t\t\t\t\n\t\t\t\t// send e-mail notify to project admin (only if specified)\n\t\t\t\tif (SR.Settings.NOTIFY_SCRIPT_RELOAD === true)\n\t\t\t\t\tUTIL.notifyAdmin('script reloading', notify_msg);\n\n\t\t\t\t// save current script in cache as backup\n\t\t\t\tvar backup_script = require.cache[path];\n\n                // NOTE: if 'path' is incorrect, may not delete successfully, and new script won't load\n                delete require.cache[path];\n\t\t\t\t\n\t\t\t\t// NOTE: this will show false\n\t\t\t\t//LOG.warn('after delete, has path: ' + require.cache.hasOwnProperty(path), l_name);\n\t\t\t\t\n                // NOTE: something can go wrong if the script is corrupt\n                try {\n                    // re-require\n\t\t\t\t\tif (l_args.hasOwnProperty(path)) {\n\t\t\t\t\t\tLOG.warn('args exist..', l_name);\n\t\t\t\t\t\trequire(path)(l_args[path]);\n\t\t\t\t\t\tl_loaded[name] = require.cache[path];\n\t\t\t\t\t}\n\t\t\t\t\telse {\n                    \tl_loaded[name] = require(path);\n\t\t\t\t\t\tSR.Handler.add(l_loaded[name]);\t\t\t\t\t\t\n\t\t\t\t\t}\t\t\t\t\t\t\n\t\t\t\t}\n                catch (e) {\n\t\t\t\t\tLOG.error('reload error: ', l_name);\n\t\t\t\t\tLOG.error(UTIL.dumpError(e), l_name);\n\t\t\t\t\t\n\t\t\t\t\tLOG.warn('restoring old script...', l_name);\n\t\t\t\t\trequire.cache[path] = backup_script;\n\t\t\t\t\tl_loaded[name] = require.cache[path];\n\t\t\t\t\t\n\t\t\t\t\t// this will show 'true'\n\t\t\t\t\t//LOG.warn('after restore, has path: ' + require.cache.hasOwnProperty(path), l_name);         \n                }\n\n                // remove file record\n                delete l_modified_scripts[path];\n            }\n        }\n    }\n\n    // reload myself to check later if there are scripts to be loaded\n    if (Object.keys(l_modified_scripts).length > 0) {\n        var timeout = l_reloadTime * 1.5 * 1000;\n        LOG.sys('automatic reloading after: ' + timeout + ' ms', l_name);\n        setTimeout(l_loadScript, timeout);\n    }        \n}", "label": 3}
{"code": "func GetActionDescriptor(action *Action) ActionDescriptor {\n\tbee := GetBee(action.Bee)\n\tif bee == nil {\n\t\tpanic(\"Bee \" + action.Bee + \" not registered\")\n\t}\n\tfactory := (*GetFactory((*bee).Namespace()))\n\tfor _, ac := range factory.Actions() {\n\t\tif ac.Name == action.Name {\n\t\t\treturn ac\n\t\t}\n\t}\n\n\treturn ActionDescriptor{}\n}", "label": 5}
{"code": "def valid_for_deletion?\n      return false if(id.nil? || sync_token.nil?)\n      id.to_i > 0 && !sync_token.to_s.empty? && sync_token.to_i >= 0\n    end", "label": 4}
{"code": "public static responderpolicylabel_binding get(nitro_service service, String labelname) throws Exception{\n\t\tresponderpolicylabel_binding obj = new responderpolicylabel_binding();\n\t\tobj.set_labelname(labelname);\n\t\tresponderpolicylabel_binding response = (responderpolicylabel_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def export(g, csv_fname):\n    \"\"\" export a graph to CSV for simpler viewing \"\"\"\n    with open(csv_fname, \"w\") as f:\n        num_tuples = 0\n        f.write('\"num\",\"subject\",\"predicate\",\"object\"\\n')\n        for subj, pred, obj in g:\n            num_tuples += 1\n            f.write('\"' + str(num_tuples) + '\",')\n            f.write('\"' + get_string_from_rdf(subj) + '\",')\n            f.write('\"' + get_string_from_rdf(pred) + '\",')\n            f.write('\"' + get_string_from_rdf(obj) + '\"\\n')\n    print(\"Finished exporting \" , num_tuples, \" tuples\")", "label": 1}
{"code": "protected function onConnectionError($message, $code = null)\n    {\n        CommunicationException::handle(\n            new ConnectionException($this, static::createExceptionMessage($message), $code)\n        );\n    }", "label": 2}
{"code": "function(configArg) {\n\n      config = _.extend({}, defaults);\n      events = {};\n\n      _(configArg).forEach(function(val, key) {\n        if (key === 'room' ||\n            key === 'lobby') {\n          events[key] = val;\n        }\n        else {\n          config[key] = val;\n        }\n      });\n    }", "label": 3}
{"code": "def text(value)\n      return ele_index TEXT_VIEW, value if value.is_a? Numeric\n\n      complex_find_contains TEXT_VIEW, value\n    end", "label": 4}
{"code": "def import_translations(path, page)\n      old_translations = page.translations.pluck(:locale)\n      new_translations = []\n\n      Dir[\"#{path}content.*.html\"].each do |file_path|\n        locale = File.basename(file_path).match(%r{content\\.(\\w+)\\.html})[1]\n        new_translations << locale\n\n        translation = page.translations.where(locale: locale).first_or_initialize\n\n        next unless fresh_seed?(translation, file_path)\n\n        # reading file content in, resulting in a hash\n        fragments_hash  = parse_file_content(file_path)\n\n        # parsing attributes section\n        attributes_yaml = fragments_hash.delete(\"attributes\")\n        attrs           = YAML.safe_load(attributes_yaml)\n\n        # applying attributes\n        layout = site.layouts.find_by(identifier: attrs.delete(\"layout\")) || page.try(:layout)\n        translation.attributes = attrs.merge(\n          layout: layout\n        )\n\n        # applying fragments\n        old_frag_identifiers = translation.fragments.pluck(:identifier)\n\n        new_frag_identifiers, fragments_attributes =\n          construct_fragments_attributes(fragments_hash, translation, path)\n        translation.fragments_attributes = fragments_attributes\n\n        if translation.save\n          message = \"[CMS SEEDS] Imported Translation \\t #{locale}\"\n          ComfortableMexicanSofa.logger.info(message)\n\n          # cleaning up old fragments\n          frags_to_remove = old_frag_identifiers - new_frag_identifiers\n          translation.fragments.where(identifier: frags_to_remove).destroy_all\n\n        else\n          message = \"[CMS SEEDS] Failed to import Translation \\n#{locale}\"\n          ComfortableMexicanSofa.logger.warn(message)\n        end\n      end\n\n      # Cleaning up removed translations\n      translations_to_remove = old_translations - new_translations\n      page.translations.where(locale: translations_to_remove).destroy_all\n    end", "label": 4}
{"code": "public static function memoize(callable $provider)\n    {\n        return function () use ($provider) {\n            static $result;\n            static $isConstant;\n\n            // Constant config will be returned constantly.\n            if ($isConstant) {\n                return $result;\n            }\n\n            // Create the initial promise that will be used as the cached value\n            // until it expires.\n            if (null === $result) {\n                $result = $provider();\n            }\n\n            // Return config and set flag that provider is already set\n            return $result\n                ->then(function (ConfigurationInterface $config) use (&$isConstant) {\n                    $isConstant = true;\n                    return $config;\n                });\n        };\n    }", "label": 2}
{"code": "def long_description\n      text = @command.long_description\n      return \"\" if text.nil? # empty description\n\n      lines = text.split(\"\\n\")\n      lines.map do |line|\n        # In the CLI help, we use 2 spaces to designate commands\n        # In Markdown we need 4 spaces.\n        line.sub(/^  \\b/, '    ')\n      end.join(\"\\n\")\n    end", "label": 4}
{"code": "func (c *remoteConn) sendDiscoveryRequests(req discoveryRequest) error {\n\tdiscoveryCh, err := c.openDiscoveryChannel()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// Marshal and send the request. If the connection failed, mark the\n\t// connection as invalid so it will be removed later.\n\tpayload, err := marshalDiscoveryRequest(req)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = discoveryCh.SendRequest(chanDiscoveryReq, false, payload)\n\tif err != nil {\n\t\tc.markInvalid(err)\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def write_request(request, notification)\n      message = Kafka::Protocol::RequestMessage.new(\n        api_key: request.api_key,\n        api_version: request.respond_to?(:api_version) ? request.api_version : 0,\n        correlation_id: @correlation_id,\n        client_id: @client_id,\n        request: request,\n      )\n\n      data = Kafka::Protocol::Encoder.encode_with(message)\n      notification[:request_size] = data.bytesize\n\n      @encoder.write_bytes(data)\n\n      nil\n    rescue Errno::ETIMEDOUT\n      @logger.error \"Timed out while writing request #{@correlation_id}\"\n      raise\n    end", "label": 4}
{"code": "def read_json_integer\n      @context.read(@reader)\n      if (@context.escapeNum)\n        read_json_syntax_char(@@kJSONStringDelimiter)\n      end\n      str = read_json_numeric_chars\n\n      begin\n        num = Integer(str);\n      rescue\n        raise ProtocolException.new(ProtocolException::INVALID_DATA, \"Expected numeric value; got \\\"#{str}\\\"\")\n      end\n\n      if (@context.escapeNum)\n        read_json_syntax_char(@@kJSONStringDelimiter)\n      end\n\n      return num\n    end", "label": 4}
{"code": "public boolean rename(final File from, final File to) {\n    boolean renamed = false;\n    if (this.isWriteable(from)) {\n      renamed = from.renameTo(to);\n    } else {\n      LogLog.debug(from + \" is not writeable for rename (retrying)\");\n    }\n    if (!renamed) {\n      from.renameTo(to);\n      renamed = (!from.exists());\n    }\n    return renamed;\n  }", "label": 0}
{"code": "func metadataPieceSize(totalSize int, piece int) int {\n\tret := totalSize - piece*(1<<14)\n\tif ret > 1<<14 {\n\t\tret = 1 << 14\n\t}\n\treturn ret\n}", "label": 5}
{"code": "public function setPerSeriesAligner($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Monitoring\\V3\\Aggregation_Aligner::class);\n        $this->per_series_aligner = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def update(self, item):\n        \"\"\"\n        Add a collector item.\n\n        Args:\n            item (CollectorUpdate): event data like stage, timestampe and status.\n        \"\"\"\n        if item.matrix not in self.data:\n            self.data[item.matrix] = []\n\n        result = Select(self.data[item.matrix]).where(\n            lambda entry: entry.stage == item.stage).build()\n\n        if len(result) > 0:\n            stage = result[0]\n            stage.status = item.status\n            stage.add(item.timestamp, item.information)\n        else:\n            stage = CollectorStage(stage=item.stage, status=item.status)\n            stage.add(item.timestamp, item.information)\n            self.data[item.matrix].append(stage)", "label": 1}
{"code": "func (u *UUID) decodeHashLike(t []byte) (err error) {\n\tsrc := t[:]\n\tdst := u[:]\n\n\tif _, err = hex.Decode(dst, src); err != nil {\n\t\treturn err\n\t}\n\treturn\n}", "label": 5}
{"code": "def static_map_link(resource, options = {})\n      return unless resource.geocoded?\n\n      zoom = options[:zoom] || 17\n      latitude = resource.latitude\n      longitude = resource.longitude\n\n      map_url = \"https://www.openstreetmap.org/?mlat=#{latitude}&mlon=#{longitude}#map=#{zoom}/#{latitude}/#{longitude}\"\n\n      link_to map_url, target: \"_blank\" do\n        image_tag decidim.static_map_path(sgid: resource.to_sgid.to_s)\n      end\n    end", "label": 4}
{"code": "protected void addProcessedData(List<List<CRFDatum<Collection<String>, String>>> processedData, int[][][][] data,\r\n      int[][] labels, int offset) {\r\n    for (int i = 0, pdSize = processedData.size(); i < pdSize; i++) {\r\n      int dataIndex = i + offset;\r\n      List<CRFDatum<Collection<String>, String>> document = processedData.get(i);\r\n      int dsize = document.size();\r\n      labels[dataIndex] = new int[dsize];\r\n      data[dataIndex] = new int[dsize][][];\r\n      for (int j = 0; j < dsize; j++) {\r\n        CRFDatum<Collection<String>, String> crfDatum = document.get(j);\r\n        // add label, they are offset by extra context\r\n        labels[dataIndex][j] = classIndex.indexOf(crfDatum.label());\r\n        // add features\r\n        List<Collection<String>> cliques = crfDatum.asFeatures();\r\n        int csize = cliques.size();\r\n        data[dataIndex][j] = new int[csize][];\r\n        for (int k = 0; k < csize; k++) {\r\n          Collection<String> features = cliques.get(k);\r\n\r\n          // Debug only: Remove\r\n          // if (j < windowSize) {\r\n          // System.err.println(\"addProcessedData: Features Size: \" +\r\n          // features.size());\r\n          // }\r\n\r\n          data[dataIndex][j][k] = new int[features.size()];\r\n\r\n          int m = 0;\r\n          try {\r\n            for (String feature : features) {\r\n              // System.err.println(\"feature \" + feature);\r\n              // if (featureIndex.indexOf(feature)) ;\r\n              if (featureIndex == null) {\r\n                System.out.println(\"Feature is NULL!\");\r\n              }\r\n              data[dataIndex][j][k][m] = featureIndex.indexOf(feature);\r\n              m++;\r\n            }\r\n          } catch (Exception e) {\r\n            e.printStackTrace();\r\n            System.err.printf(\"[index=%d, j=%d, k=%d, m=%d]\\n\", dataIndex, j, k, m);\r\n            System.err.println(\"data.length                    \" + data.length);\r\n            System.err.println(\"data[dataIndex].length         \" + data[dataIndex].length);\r\n            System.err.println(\"data[dataIndex][j].length      \" + data[dataIndex][j].length);\r\n            System.err.println(\"data[dataIndex][j][k].length   \" + data[dataIndex][j].length);\r\n            System.err.println(\"data[dataIndex][j][k][m]       \" + data[dataIndex][j][k][m]);\r\n            return;\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "public function setSymbols($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\Symbol::class);\n        $this->symbols = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def zoom_bbox(self, bbox):\n        \"\"\"Zoom map to geometry extent.\n\n        Arguments:\n        bbox -- OGRGeometry polygon to zoom map extent\n        \"\"\"\n        try:\n            bbox.transform(self.map.srs)\n        except gdal.GDALException:\n            pass\n        else:\n            self.map.zoom_to_box(mapnik.Box2d(*bbox.extent))", "label": 1}
{"code": "def prefer_non_nil_variables pins\n      result = []\n      nil_pins = []\n      pins.each do |pin|\n        if pin.variable? && pin.nil_assignment?\n          nil_pins.push pin\n        else\n          result.push pin\n        end\n      end\n      result + nil_pins\n    end", "label": 4}
{"code": "public static base_response export(nitro_service client, appfwlearningdata resource) throws Exception {\n\t\tappfwlearningdata exportresource = new appfwlearningdata();\n\t\texportresource.profilename = resource.profilename;\n\t\texportresource.securitycheck = resource.securitycheck;\n\t\texportresource.target = resource.target;\n\t\treturn exportresource.perform_operation(client,\"export\");\n\t}", "label": 0}
{"code": "private function convertScopesQueryStringToArray($scopes)\n    {\n        return array_filter(explode(self::SCOPE_DELIMITER_STRING, trim($scopes)), function ($scope) {\n            return !empty($scope);\n        });\n    }", "label": 2}
{"code": "async function collecticonsBundle (params) {\n  const {\n    dirPath,\n    destFile\n  } = params;\n\n  await validateDirPath(dirPath);\n\n  const resultFiles = await collecticonsCompile({\n    dirPath,\n    styleFormats: ['css'],\n    styleDest: './styles',\n    fontDest: './',\n    fontTypes: ['woff', 'woff2'],\n    previewDest: './',\n    noFileOutput: true\n  });\n\n  if (resultFiles === null) return;\n\n  // Create zip.\n  let zip = new JSZip();\n\n  // Add generated files.\n  resultFiles.forEach(file => {\n    zip.file(file.path, file.contents);\n  });\n\n  // Add the icons.\n  const dir = await fs.readdir(dirPath);\n  const svgs = await Promise.all(dir.map(async file => {\n    return file.endsWith('.svg')\n      ? (\n        {\n          path: `icons/${file}`,\n          contents: await fs.readFile(path.resolve(dirPath, file))\n        }\n      )\n      : null;\n  }));\n\n  svgs.forEach(file => {\n    zip.file(file.path, file.contents);\n  });\n\n  await fs.ensureDir(path.dirname(destFile));\n  await fs.writeFile(destFile, zip.generate({ base64: false, compression: 'DEFLATE' }), 'binary');\n}", "label": 3}
{"code": "def render_to_string(*)\n      result = super\n      if result.respond_to?(:each)\n        string = +\"\"\n        result.each { |r| string << r }\n        string\n      else\n        result\n      end\n    end", "label": 4}
{"code": "public static iptunnel[] get(nitro_service service, iptunnel_args args) throws Exception{\n\t\tiptunnel obj = new iptunnel();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tiptunnel[] response = (iptunnel[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setScreenOrientation($orientation)\n    {\n        $orientation = mb_strtoupper($orientation);\n        if (!in_array($orientation, ['PORTRAIT', 'LANDSCAPE'])) {\n            throw new IndexOutOfBoundsException(\n                'Orientation must be either PORTRAIT, or LANDSCAPE'\n            );\n        }\n\n        $this->executor->execute(\n            DriverCommand::SET_SCREEN_ORIENTATION,\n            ['orientation' => $orientation]\n        );\n\n        return $this;\n    }", "label": 2}
{"code": "public static cacheselector[] get(nitro_service service, String selectorname[]) throws Exception{\n\t\tif (selectorname !=null && selectorname.length>0) {\n\t\t\tcacheselector response[] = new cacheselector[selectorname.length];\n\t\t\tcacheselector obj[] = new cacheselector[selectorname.length];\n\t\t\tfor (int i=0;i<selectorname.length;i++) {\n\t\t\t\tobj[i] = new cacheselector();\n\t\t\t\tobj[i].set_selectorname(selectorname[i]);\n\t\t\t\tresponse[i] = (cacheselector) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public function evaluate(array $evaluatedExpressions, array $stackframes, array $options = [])\n    {\n        $this->variableTable->setOptions($options);\n        $this->addEvaluatedExpressions($evaluatedExpressions);\n        $this->addStackFrames($stackframes);\n        $this->finalize();\n    }", "label": 2}
{"code": "func (s *handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tswitch r.Method {\n\tcase http.MethodPost, http.MethodDelete, http.MethodGet, http.MethodPatch, http.MethodPut:\n\tdefault:\n\t\tw.WriteHeader(http.StatusMethodNotAllowed)\n\t\treturn\n\t}\n\n\th, _ := s.Handler(r)\n\th.ServeHTTP(w, r)\n}", "label": 5}
{"code": "async def dump_blob(writer, elem, elem_type, params=None):\n    \"\"\"\n    Dumps blob to a binary stream\n\n    :param writer:\n    :param elem:\n    :param elem_type:\n    :param params:\n    :return:\n    \"\"\"\n    elem_is_blob = isinstance(elem, x.BlobType)\n    data = bytes(getattr(elem, x.BlobType.DATA_ATTR) if elem_is_blob else elem)\n    await dump_varint(writer, len(elem))\n    await writer.awrite(data)", "label": 1}
{"code": "func (sb *sandbox) needDefaultGW() bool {\n\tvar needGW bool\n\n\tfor _, ep := range sb.getConnectedEndpoints() {\n\t\tif ep.endpointInGWNetwork() {\n\t\t\tcontinue\n\t\t}\n\t\tif ep.getNetwork().Type() == \"null\" || ep.getNetwork().Type() == \"host\" {\n\t\t\tcontinue\n\t\t}\n\t\tif ep.getNetwork().Internal() {\n\t\t\tcontinue\n\t\t}\n\t\t// During stale sandbox cleanup, joinInfo may be nil\n\t\tif ep.joinInfo != nil && ep.joinInfo.disableGatewayService {\n\t\t\tcontinue\n\t\t}\n\t\t// TODO v6 needs to be handled.\n\t\tif len(ep.Gateway()) > 0 {\n\t\t\treturn false\n\t\t}\n\t\tfor _, r := range ep.StaticRoutes() {\n\t\t\tif r.Destination != nil && r.Destination.String() == \"0.0.0.0/0\" {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tneedGW = true\n\t}\n\n\treturn needGW\n}", "label": 5}
{"code": "def options(self, path=None, url_kwargs=None, **kwargs):\n        \"\"\"\n        Sends an OPTIONS request.\n\n        :param path:\n            The HTTP path (either absolute or relative).\n        :param url_kwargs:\n            Parameters to override in the generated URL. See `~hyperlink.URL`.\n        :param **kwargs:\n            Optional arguments that ``request`` takes.\n        :return: response object\n        \"\"\"\n        return self._session.options(self._url(path, url_kwargs), **kwargs)", "label": 1}
{"code": "def replace_character_sequence_with_hyphen(string, mode: \"default\")\n      replaceable_char =\n        case mode\n        when \"raw\"\n          SLUGIFY_RAW_REGEXP\n        when \"pretty\"\n          # \"._~!$&'()+,;=@\" is human readable (not URI-escaped) in URL\n          # and is allowed in both extN and NTFS.\n          SLUGIFY_PRETTY_REGEXP\n        when \"ascii\"\n          # For web servers not being able to handle Unicode, the safe\n          # method is to ditch anything else but latin letters and numeric\n          # digits.\n          SLUGIFY_ASCII_REGEXP\n        else\n          SLUGIFY_DEFAULT_REGEXP\n        end\n\n      # Strip according to the mode\n      string.gsub(replaceable_char, \"-\")\n    end", "label": 4}
{"code": "public String format() {\r\n        if (getName().equals(\"*\")) {\r\n            return \"*\";\r\n        }\r\n        else {\r\n            StringBuilder sb = new StringBuilder();\r\n            if (isWeak()) {\r\n                sb.append(\"W/\");\r\n            }\r\n            return sb.append('\"').append(getName()).append('\"').toString();\r\n        }\r\n    }", "label": 0}
{"code": "func (g *GLogger) Infoln(args ...interface{}) {\n\t// GRPC is very verbose, so this is intentionally\n\t// pushes info level statements as Teleport's debug level ones\n\tg.Entry.Debug(fmt.Sprintln(args...))\n}", "label": 5}
{"code": "func (a *AuthWithRoles) DeleteRole(name string) error {\n\tif err := a.action(defaults.Namespace, services.KindRole, services.VerbDelete); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.DeleteRole(name)\n}", "label": 5}
{"code": "func (a *LocalKeyAgent) LoadKey(key Key) (*agent.AddedKey, error) {\n\tagents := []agent.Agent{a.Agent}\n\tif a.sshAgent != nil {\n\t\tagents = append(agents, a.sshAgent)\n\t}\n\n\t// convert keys into a format understood by the ssh agent\n\tagentKeys, err := key.AsAgentKeys()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// remove any keys that the user may already have loaded\n\terr = a.UnloadKey()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// iterate over all teleport and system agent and load key\n\tfor i, _ := range agents {\n\t\tfor _, agentKey := range agentKeys {\n\t\t\terr = agents[i].Add(*agentKey)\n\t\t\tif err != nil {\n\t\t\t\ta.log.Warnf(\"Unable to communicate with agent and add key: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// return the first key because it has the embedded private key in it.\n\t// see docs for AsAgentKeys for more details.\n\treturn agentKeys[0], nil\n}", "label": 5}
{"code": "public function setFaceDetectionConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\VideoIntelligence\\V1beta2\\FaceDetectionConfig::class);\n        $this->face_detection_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def _check_operations(ctx, need_ops, arg):\n    ''' Checks an allow or a deny caveat. The need_ops parameter specifies\n    whether we require all the operations in the caveat to be declared in\n    the context.\n    '''\n    ctx_ops = ctx.get(OP_KEY, [])\n    if len(ctx_ops) == 0:\n        if need_ops:\n            f = arg.split()\n            if len(f) == 0:\n                return 'no operations allowed'\n            return '{} not allowed'.format(f[0])\n        return None\n\n    fields = arg.split()\n    for op in ctx_ops:\n        err = _check_op(op, need_ops, fields)\n        if err is not None:\n            return err\n    return None", "label": 1}
{"code": "def load_annotations(self, aname, sep=','):\n        \"\"\"Loads cell annotations.\n\n        Loads the cell annoations specified by the 'aname' path.\n\n        Parameters\n        ----------\n        aname - string\n            The path to the annotations file. First column should be cell IDs\n            and second column should be the desired annotations.\n\n        \"\"\"\n        ann = pd.read_csv(aname)\n\n        cell_names = np.array(list(self.adata.obs_names))\n        all_cell_names = np.array(list(self.adata_raw.obs_names))\n\n        if(ann.shape[1] > 1):\n            ann = pd.read_csv(aname, index_col=0, sep=sep)\n            if(ann.shape[0] != all_cell_names.size):\n                ann = pd.read_csv(aname, index_col=0, header=None, sep=sep)\n        else:\n            if(ann.shape[0] != all_cell_names.size):\n                ann = pd.read_csv(aname, header=None, sep=sep)\n        ann.index = np.array(list(ann.index.astype('<U100')))\n        ann1 = np.array(list(ann.T[cell_names].T.values.flatten()))\n        ann2 = np.array(list(ann.values.flatten()))\n\n        self.adata_raw.obs['annotations'] = pd.Categorical(ann2)\n        self.adata.obs['annotations'] = pd.Categorical(ann1)", "label": 1}
{"code": "public static Trajectory resample(Trajectory t, int n){\n\t\tTrajectory t1 = new Trajectory(2);\n\t\t\n\t\tfor(int i = 0; i < t.size(); i=i+n){\n\t\t\tt1.add(t.get(i));\n\t\t}\n\t\t\n\t\treturn t1;\n\t}", "label": 0}
{"code": "def extent(self, srid=None):\n        \"\"\"Returns the GeoQuerySet extent as a 4-tuple.\n\n        Keyword args:\n        srid -- EPSG id for for transforming the output geometry.\n        \"\"\"\n        expr = self.geo_field.name\n        if srid:\n            expr = geofn.Transform(expr, srid)\n        expr = models.Extent(expr)\n        clone = self.all()\n        name, val = clone.aggregate(expr).popitem()\n        return val", "label": 1}
{"code": "def deep_merge(*dicts):\n    \"\"\"\n    Recursively merge all input dicts into a single dict.\n    \"\"\"\n    result = {}\n    for d in dicts:\n        if not isinstance(d, dict):\n            raise Exception('Can only deep_merge dicts, got {}'.format(d))\n        for k, v in d.items():\n            # Whenever the value is a dict, we deep_merge it. This ensures that\n            # (a) we only ever merge dicts with dicts and (b) we always get a\n            # deep(ish) copy of the dicts and are thus safe from accidental\n            # mutations to shared state.\n            if isinstance(v, dict):\n                v = deep_merge(result.get(k, {}), v)\n            result[k] = v\n    return result", "label": 1}
{"code": "func (s *handler) DetachTag(id vim.ManagedObjectReference, tag vim.VslmTagEntry) vim.BaseMethodFault {\n\tt := s.findTag(tag)\n\tif t == nil {\n\t\treturn new(vim.NotFound)\n\t}\n\tdelete(s.Association[t.ID], internal.AssociatedObject(id))\n\treturn nil\n}", "label": 5}
{"code": "def trophy_abilities\n        can [:create, :destroy], Trophy do |t|\n          doc = ActiveFedora::Base.search_by_id(t.work_id, fl: 'depositor_ssim')\n          current_user.user_key == doc.fetch('depositor_ssim').first\n        end\n      end", "label": 4}
{"code": "function (job, config, callback) {\n    var task = {\n      job: job,\n      config: config,\n      callback: callback || function () {\n      }\n    };\n\n    task.id = task.job._id;\n\n    // Tasks with identical keys will be prevented from being scheduled concurrently.\n    task.key = task.job.project + branchFromJob(task.job);\n\n    this.tasks.push(task);\n\n    // Defer task execution to the next event loop tick to ensure that the push() function's\n    // callback is *always* invoked asynchronously.\n    // http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony\n    process.nextTick(this.drain.bind(this));\n  }", "label": 3}
{"code": "function($el, template, context, opts) {\n      var newDOM, newHTML,\n          el = $el.get(0);\n      opts = opts || {};\n\n      newHTML = opts.newHTML || template(context);\n      if (opts.force) {\n        $el.html(newHTML);\n      } else {\n        newDOM = this.copyTopElement(el);\n        $(newDOM).html(newHTML);\n        this.hotswapKeepCaret(el, newDOM, opts.ignoreElements);\n      }\n    }", "label": 3}
{"code": "func getEnvBool(v string, def bool) bool {\n\tr := os.Getenv(v)\n\tif r == \"\" {\n\t\treturn def\n\t}\n\n\tswitch strings.ToLower(r[0:1]) {\n\tcase \"t\", \"y\", \"1\":\n\t\treturn true\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "def xml_keys(target)\n      lazy_load_strings\n      @lazy_load_strings.select { |key, _value| key.downcase.include? target.downcase }\n    end", "label": 4}
{"code": "def parse_s2bins(s2bins):\n    \"\"\"\n    parse ggKbase scaffold-to-bin mapping\n        - scaffolds-to-bins and bins-to-scaffolds\n    \"\"\"\n    s2b = {}\n    b2s = {}\n    for line in s2bins:\n        line = line.strip().split()\n        s, b = line[0], line[1]\n        if 'UNK' in b:\n            continue\n        if len(line) > 2:\n            g = ' '.join(line[2:])\n        else:\n            g = 'n/a'\n        b = '%s\\t%s' % (b, g)\n        s2b[s] = b \n        if b not in b2s:\n           b2s[b] = []\n        b2s[b].append(s)\n    return s2b, b2s", "label": 1}
{"code": "protected void setRandom(double lower, double upper, Random generator) {\n        double range = upper - lower;\n\n        x = generator.nextDouble() * range + lower;\n        y = generator.nextDouble() * range + lower;\n        z = generator.nextDouble() * range + lower;\n    }", "label": 0}
{"code": "function (onDone) {\n\n\t// store what to do after connected\n\t// NOTE: may be called repeatedly (if initial attempts fail or disconnect happens)\n\tif (typeof onDone === 'function')\n\t\tl_onConnect = onDone;\n\n\tif (l_ip_port === undefined) {\n\t\tLOG.warn('not init (or already disposed), cannot connect to server');\n\t\treturn;\n\t}\n\n\tif (l_connector === undefined)    \n\t\tl_connector = new SR.Connector(l_config);\n\n    // establish connection\n\tLOG.warn('connecting to: ', l_name);\n\tLOG.warn(l_ip_port, l_name);\n\tl_connector.connect(l_ip_port, function (err, socket) {\n\t\t\n\t\tif (err) {\n\t\t\t// try-again later\n\t\t\tLOG.warn('connect failed, try to re-connect in: ' + l_timeoutConnectRetry + 'ms', l_name);\n\t\t\tsetTimeout(l_connect, l_timeoutConnectRetry);\n\t\t\treturn;\n\t\t}\n\n\t\tLOG.warn('connection to: ' + socket.host + ':' + socket.port + ' established', l_name);\n\t\t\t\t\n\t\tUTIL.safeCall(l_onConnect);\n\t});    \n}", "label": 3}
{"code": "func (ns *NodeSession) watchSignals(shell io.Writer) {\n\texitSignals := make(chan os.Signal, 1)\n\t// catch SIGTERM\n\tsignal.Notify(exitSignals, syscall.SIGTERM)\n\tgo func() {\n\t\tdefer ns.closer.Close()\n\t\t<-exitSignals\n\t}()\n\t// Catch Ctrl-C signal\n\tctrlCSignal := make(chan os.Signal, 1)\n\tsignal.Notify(ctrlCSignal, syscall.SIGINT)\n\tgo func() {\n\t\tfor {\n\t\t\t<-ctrlCSignal\n\t\t\t_, err := shell.Write([]byte{3})\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(err.Error())\n\t\t\t}\n\t\t}\n\t}()\n\t// Catch Ctrl-Z signal\n\tctrlZSignal := make(chan os.Signal, 1)\n\tsignal.Notify(ctrlZSignal, syscall.SIGTSTP)\n\tgo func() {\n\t\tfor {\n\t\t\t<-ctrlZSignal\n\t\t\t_, err := shell.Write([]byte{26})\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(err.Error())\n\t\t\t}\n\t\t}\n\t}()\n}", "label": 5}
{"code": "function getDirectoryFragmentTextSpan(text, textStart) {\n                var index = text.lastIndexOf(ts.directorySeparator);\n                var offset = index !== -1 ? index + 1 : 0;\n                return { start: textStart + offset, length: text.length - offset };\n            }", "label": 3}
{"code": "public function create($name, $extension = null, $table = null, $create = false)\n    {\n        $migrationPath = $this->getMigrationPath($extension);\n\n        $path = $this->getPath($name, $migrationPath);\n\n        $stub = $this->getStub($table, $create);\n\n        $this->files->put($path, $this->populateStub($stub, $table));\n\n        return $path;\n    }", "label": 2}
{"code": "public void addStep(String name, String robot, Map<String, Object> options){\n        steps.addStep(name, robot, options);\n    }", "label": 0}
{"code": "def id=(value)\n      @logger.info(\"New machine ID: #{value.inspect}\")\n\n      id_file = nil\n      if @data_dir\n        # The file that will store the id if we have one. This allows the\n        # ID to persist across Vagrant runs. Also, store the UUID for the\n        # machine index.\n        id_file = @data_dir.join(\"id\")\n      end\n\n      if value\n        if id_file\n          # Write the \"id\" file with the id given.\n          id_file.open(\"w+\") do |f|\n            f.write(value)\n          end\n        end\n\n        if uid_file\n          # Write the user id that created this machine\n          uid_file.open(\"w+\") do |f|\n            f.write(Process.uid.to_s)\n          end\n        end\n\n        # If we don't have a UUID, then create one\n        if index_uuid.nil?\n          # Create the index entry and save it\n          entry = MachineIndex::Entry.new\n          entry.local_data_path = @env.local_data_path\n          entry.name = @name.to_s\n          entry.provider = @provider_name.to_s\n          entry.state = \"preparing\"\n          entry.vagrantfile_path = @env.root_path\n          entry.vagrantfile_name = @env.vagrantfile_name\n\n          if @box\n            entry.extra_data[\"box\"] = {\n              \"name\"     => @box.name,\n              \"provider\" => @box.provider.to_s,\n              \"version\"  => @box.version.to_s,\n            }\n          end\n\n          entry = @env.machine_index.set(entry)\n          @env.machine_index.release(entry)\n\n          # Store our UUID so we can access it later\n          if @index_uuid_file\n            @index_uuid_file.open(\"w+\") do |f|\n              f.write(entry.id)\n            end\n          end\n        end\n      else\n        # Delete the file, since the machine is now destroyed\n        id_file.delete if id_file && id_file.file?\n        uid_file.delete if uid_file && uid_file.file?\n\n        # If we have a UUID associated with the index, remove it\n        uuid = index_uuid\n        if uuid\n          entry = @env.machine_index.get(uuid)\n          @env.machine_index.delete(entry) if entry\n        end\n\n        if @data_dir\n          # Delete the entire data directory contents since all state\n          # associated with the VM is now gone.\n          @data_dir.children.each do |child|\n            begin\n              child.rmtree\n            rescue Errno::EACCES\n              @logger.info(\"EACCESS deleting file: #{child}\")\n            end\n          end\n        end\n      end\n\n      # Store the ID locally\n      @id = value.nil? ? nil : value.to_s\n\n      # Notify the provider that the ID changed in case it needs to do\n      # any accounting from it.\n      @provider.machine_id_changed\n    end", "label": 4}
{"code": "public function setTemplates($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dataproc\\V1\\WorkflowTemplate::class);\n        $this->templates = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *ServerConfig) CheckDefaults() error {\n\tif s.AuthClient == nil {\n\t\treturn trace.BadParameter(\"auth client required\")\n\t}\n\tif s.DataDir == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter DataDir\")\n\t}\n\tif s.UserAgent == nil {\n\t\treturn trace.BadParameter(\"user agent required to connect to remote host\")\n\t}\n\tif s.TargetConn == nil {\n\t\treturn trace.BadParameter(\"connection to target connection required\")\n\t}\n\tif s.SrcAddr == nil {\n\t\treturn trace.BadParameter(\"source address required to identify client\")\n\t}\n\tif s.DstAddr == nil {\n\t\treturn trace.BadParameter(\"destination address required to connect to remote host\")\n\t}\n\tif s.HostCertificate == nil {\n\t\treturn trace.BadParameter(\"host certificate required to act on behalf of remote host\")\n\t}\n\tif s.Clock == nil {\n\t\ts.Clock = clockwork.NewRealClock()\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function isAltBeacon(advertiserData) {\n  var data = advertiserData.manufacturerSpecificData.data;\n  var isCorrectLength = ((data.length + 6) === (LENGTH * 2));\n  var isCorrectCode = (data.substr(0,4) === CODE);\n\n  return isCorrectLength && isCorrectCode;\n}", "label": 3}
{"code": "protected ValueContainer[] getKeyValues(PersistenceBroker broker, ClassDescriptor cld, Identity oid) throws PersistenceBrokerException\r\n    {\r\n        return broker.serviceBrokerHelper().getKeyValues(cld, oid);\r\n    }", "label": 0}
{"code": "public static base_response add(nitro_service client, ntpserver resource) throws Exception {\n\t\tntpserver addresource = new ntpserver();\n\t\taddresource.serverip = resource.serverip;\n\t\taddresource.servername = resource.servername;\n\t\taddresource.minpoll = resource.minpoll;\n\t\taddresource.maxpoll = resource.maxpoll;\n\t\taddresource.autokey = resource.autokey;\n\t\taddresource.key = resource.key;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "protected function getColumnNameByIndex($index)\n    {\n        $name = (isset($this->columns[$index]) && $this->columns[$index] != '*')\n            ? $this->columns[$index] : $this->getPrimaryKeyName();\n\n        return in_array($name, $this->extraColumns, true) ? $this->getPrimaryKeyName() : $name;\n    }", "label": 2}
{"code": "func (of *OVAFile) Read(b []byte) (int, error) {\n\tif of.tarFile == nil {\n\t\treturn 0, io.EOF\n\t}\n\treturn of.tarFile.Read(b)\n}", "label": 5}
{"code": "private function getGaxConfig($version, callable $authHttpHandler = null)\n    {\n        $config = [\n            'libName' => 'gccl',\n            'libVersion' => $version,\n            'transport' => 'grpc'\n        ];\n\n        // GAX v0.32.0 introduced the CredentialsWrapper class and a different\n        // way to configure credentials. If the class exists, use this new method\n        // otherwise default to legacy usage.\n        if (class_exists(CredentialsWrapper::class)) {\n            $config['credentials'] = new CredentialsWrapper(\n                $this->requestWrapper->getCredentialsFetcher(),\n                $authHttpHandler\n            );\n        } else {\n            $config += [\n                'credentialsLoader' => $this->requestWrapper->getCredentialsFetcher(),\n                'authHttpHandler' => $authHttpHandler,\n                'enableCaching' => false\n            ];\n        }\n\n        return $config;\n    }", "label": 2}
{"code": "public static base_responses delete(nitro_service client, String hostname[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (hostname != null && hostname.length > 0) {\n\t\t\tdnsaaaarec deleteresources[] = new dnsaaaarec[hostname.length];\n\t\t\tfor (int i=0;i<hostname.length;i++){\n\t\t\t\tdeleteresources[i] = new dnsaaaarec();\n\t\t\t\tdeleteresources[i].hostname = hostname[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def event(title, text, opts=EMPTY_OPTIONS)\n      send_stat format_event(title, text, opts)\n    end", "label": 4}
{"code": "function renameKey(obj, prevKey, nextKey) {\n  return mapKeys(obj, (_, key) => (key === prevKey ? nextKey : key))\n}", "label": 3}
{"code": "public function setType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1beta2\\Document_Type::class);\n        $this->type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def complex_coverage(data_criteria, check_criteria)\n      same_value = data_criteria.value.nil? ||\n                   data_criteria.value.try(:to_model).try(:to_json) == check_criteria.value.try(:to_model).try(:to_json)\n\n      same_field_values = same_field_values_check(data_criteria, check_criteria)\n\n      same_negation_values = data_criteria.negation_code_list_id.nil? ||\n                             data_criteria.negation_code_list_id == check_criteria.negation_code_list_id\n\n      same_value && same_negation_values && same_field_values\n    end", "label": 4}
{"code": "public function setMatchMode($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\Agent_MatchMode::class);\n        $this->match_mode = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def process(self, document):\n        \"\"\"Logging versions of required tools.\"\"\"\n        content = json.dumps(document)\n\n        versions = {}\n        versions.update({'Spline': Version(VERSION)})\n        versions.update(self.get_version(\"Bash\", self.BASH_VERSION))\n\n        if content.find('\"docker(container)\":') >= 0 or content.find('\"docker(image)\":') >= 0:\n            versions.update(VersionsCheck.get_version(\"Docker\", self.DOCKER_VERSION))\n        if content.find('\"packer\":') >= 0:\n            versions.update(VersionsCheck.get_version(\"Packer\", self.PACKER_VERSION))\n        if content.find('\"ansible(simple)\":') >= 0:\n            versions.update(VersionsCheck.get_version('Ansible', self.ANSIBLE_VERSION))\n\n        return versions", "label": 1}
{"code": "def option_parser\n      @option_parser ||= OptionParser.new(banner, 25) do |opts|\n        opts.banner = banner\n\n        OptionSetter.new(self, opts).setup\n      end\n    end", "label": 4}
{"code": "def execute_transactions(conn, statements: Iterable):\n    \"\"\"Execute several statements each as a single DB transaction.\"\"\"\n\n    with conn.cursor() as cursor:\n        for statement in statements:\n            try:\n                cursor.execute(statement)\n                conn.commit()\n            except psycopg2.ProgrammingError:\n                conn.rollback()", "label": 1}
{"code": "def config_file(*paths)\n      Dir.chdir(root || '.') do\n        paths.each do |pattern|\n          Dir.glob(pattern) do |file|\n            raise UnsupportedConfigType unless ['.yml', '.erb'].include?(File.extname(file))\n            logger.info \"loading config file '#{file}'\" if logging? && respond_to?(:logger)\n            document = ERB.new(IO.read(file)).result\n            yaml = YAML.load(document)\n            config = config_for_env(yaml)\n            config.each_pair { |key, value| set(key, value) }\n          end\n        end\n      end\n    end", "label": 4}
{"code": "func Open(config *Config) (*PAM, error) {\n\tif config == nil {\n\t\treturn nil, trace.BadParameter(\"PAM configuration is required.\")\n\t}\n\terr := config.CheckDefaults()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tp := &PAM{\n\t\tpamh:   nil,\n\t\tstdin:  config.Stdin,\n\t\tstdout: config.Stdout,\n\t\tstderr: config.Stderr,\n\t}\n\n\t// Both config.ServiceName and config.Username convert between Go strings to\n\t// C strings. Since the C strings are allocated on the heap in Go code, this\n\t// memory must be released (and will be on the call to the Close method).\n\tp.service_name = C.CString(config.ServiceName)\n\tp.user = C.CString(config.Username)\n\n\t// C code does not know that this PAM context exists. To ensure the\n\t// conversation function can get messages to the right context, a handle\n\t// registry at the package level is created (handlers). Each instance of the\n\t// PAM context has it's own handle which is used to communicate between C\n\t// and a instance of a PAM context.\n\tp.handlerIndex = registerHandler(p)\n\n\t// Create and initialize a PAM context. The pam_start function will\n\t// allocate pamh if needed and the pam_end function will release any\n\t// allocated memory.\n\tp.retval = C._pam_start(pamHandle, p.service_name, p.user, p.conv, &p.pamh)\n\tif p.retval != C.PAM_SUCCESS {\n\t\treturn nil, p.codeToError(p.retval)\n\t}\n\n\t// Check that the *nix account is valid. Checking an account varies based off\n\t// the PAM modules used in the account stack. Typically this consists of\n\t// checking if the account is expired or has access restrictions.\n\t//\n\t// Note: This function does not perform any authentication!\n\tretval := C._pam_acct_mgmt(pamHandle, p.pamh, 0)\n\tif retval != C.PAM_SUCCESS {\n\t\treturn nil, p.codeToError(retval)\n\t}\n\n\t// Open a user session. Opening a session varies based off the PAM modules\n\t// used in the \"session\" stack. Opening a session typically consists of\n\t// printing the MOTD, mounting a home directory, updating auth.log.\n\tp.retval = C._pam_open_session(pamHandle, p.pamh, 0)\n\tif p.retval != C.PAM_SUCCESS {\n\t\treturn nil, p.codeToError(p.retval)\n\t}\n\n\treturn p, nil\n}", "label": 5}
{"code": "public Class getSearchClass()\r\n\t{\r\n\t\tObject obj = getExampleObject();\r\n\r\n\t\tif (obj instanceof Identity)\r\n\t\t{\r\n\t\t\treturn ((Identity) obj).getObjectsTopLevelClass();\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\treturn obj.getClass();\r\n\t\t}\r\n\t}", "label": 0}
{"code": "protected void afterMaterialization()\r\n\t{\r\n\t\tif (_listeners != null)\r\n\t\t{\r\n\t\t\tMaterializationListener listener;\r\n\r\n\t\t\t// listeners may remove themselves during the afterMaterialization\r\n\t\t\t// callback.\r\n\t\t\t// thus we must iterate through the listeners vector from back to\r\n\t\t\t// front\r\n\t\t\t// to avoid index problems.\r\n\t\t\tfor (int idx = _listeners.size() - 1; idx >= 0; idx--)\r\n\t\t\t{\r\n\t\t\t\tlistener = (MaterializationListener) _listeners.get(idx);\r\n\t\t\t\tlistener.afterMaterialization(this, _realSubject);\r\n\t\t\t}\r\n\t\t}\r\n\t}", "label": 0}
{"code": "def version(version, **opts)\n      requirements = version.split(\",\").map do |v|\n        Gem::Requirement.new(v.strip)\n      end\n\n      providers = nil\n      providers = Array(opts[:provider]).map(&:to_sym) if opts[:provider]\n\n      @version_map.keys.sort.reverse.each do |v|\n        next if !requirements.all? { |r| r.satisfied_by?(v) }\n        version = Version.new(@version_map[v])\n        next if (providers & version.providers).empty? if providers\n        return version\n      end\n\n      nil\n    end", "label": 4}
{"code": "def solve(self):\n        \"\"\" Solves DC optimal power flow and returns a results dict.\n        \"\"\"\n        base_mva = self.om.case.base_mva\n        Bf = self.om._Bf\n        Pfinj = self.om._Pfinj\n        # Unpack the OPF model.\n        bs, ln, gn, cp = self._unpack_model(self.om)\n        # Compute problem dimensions.\n        ipol, ipwl, nb, nl, nw, ny, nxyz = self._dimension_data(bs, ln, gn)\n        # Split the constraints in equality and inequality.\n        AA, ll, uu = self._linear_constraints(self.om)\n        # Piece-wise linear components of the objective function.\n        Npwl, Hpwl, Cpwl, fparm_pwl, any_pwl = self._pwl_costs(ny, nxyz, ipwl)\n        # Quadratic components of the objective function.\n        Npol, Hpol, Cpol, fparm_pol, polycf, npol = \\\n            self._quadratic_costs(gn, ipol, nxyz, base_mva)\n        # Combine pwl, poly and user costs.\n        NN, HHw, CCw, ffparm = \\\n            self._combine_costs(Npwl, Hpwl, Cpwl, fparm_pwl, any_pwl,\n                                Npol, Hpol, Cpol, fparm_pol, npol, nw)\n        # Transform quadratic coefficients for w into coefficients for X.\n        HH, CC, C0 = self._transform_coefficients(NN, HHw, CCw, ffparm, polycf,\n                                                  any_pwl, npol, nw)\n        # Bounds on the optimisation variables.\n        _, xmin, xmax = self._var_bounds()\n\n        # Select an interior initial point for interior point solver.\n        x0 = self._initial_interior_point(bs, gn, xmin, xmax, ny)\n\n        # Call the quadratic/linear solver.\n        s = self._run_opf(HH, CC, AA, ll, uu, xmin, xmax, x0, self.opt)\n\n        # Compute the objective function value.\n        Va, Pg = self._update_solution_data(s, HH, CC, C0)\n\n        # Set case result attributes.\n        self._update_case(bs, ln, gn, base_mva, Bf, Pfinj, Va, Pg, s[\"lmbda\"])\n\n        return s", "label": 1}
{"code": "def download_profile(profile)\n      UI.important(\"Downloading provisioning profile...\")\n      profile_name ||= \"#{profile_type.pretty_type}_#{Sigh.config[:app_identifier]}\"\n\n      if Sigh.config[:platform].to_s == 'tvos'\n        profile_name += \"_tvos\"\n      end\n\n      if Sigh.config[:platform].to_s == 'macos'\n        profile_name += '.provisionprofile'\n      else\n        profile_name += '.mobileprovision'\n      end\n\n      tmp_path = Dir.mktmpdir(\"profile_download\")\n      output_path = File.join(tmp_path, profile_name)\n      File.open(output_path, \"wb\") do |f|\n        f.write(profile.download)\n      end\n\n      UI.success(\"Successfully downloaded provisioning profile...\")\n      return output_path\n    end", "label": 4}
{"code": "public static inat[] get(nitro_service service) throws Exception{\n\t\tinat obj = new inat();\n\t\tinat[] response = (inat[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def subset(self, ns_uris):\n        \"\"\"Return a subset of this NamespaceSet containing only data for the\n        given namespaces.\n\n        Args:\n            ns_uris (iterable): An iterable of namespace URIs which select the\n                namespaces for the subset.\n\n        Returns:\n            The subset\n\n        Raises:\n            NamespaceNotFoundError: If any namespace URIs in `ns_uris` don't\n                match any namespaces in this set.\n        \"\"\"\n        sub_ns = NamespaceSet()\n\n        for ns_uri in ns_uris:\n            ni = self.__lookup_uri(ns_uri)\n            new_ni = copy.deepcopy(ni)\n\n            # We should be able to reach into details of our own\n            # implementation on another obj, right??  This makes the subset\n            # operation faster.  We can set up the innards directly from a\n            # cloned _NamespaceInfo.\n            sub_ns._NamespaceSet__add_namespaceinfo(new_ni)\n\n        return sub_ns", "label": 1}
{"code": "protected function cache($key, $value, $minutes)\n    {\n        $this->cache->add($this->key($key), $value, Carbon::now()->addMinutes($minutes));\n    }", "label": 2}
{"code": "function trimLines(text) {\n    let linebreak = determineLinebreaks(text);\n    if (linebreak === \"\") return text;\n\n    let lines = [];\n    lines = text.split(linebreak);\n    text = \"\";\n\n    for (let i = 0; i < lines.length; i++) {\n        let line = lines[i];\n\n        while (true) {\n            let lastChar = line.slice(line.length-1, line.length);\n            let repeat = false;\n\n            switch (lastChar) {\n                case \" \":\n                case \"\\t\":\n                    line = line.slice(0, -1)\n                    repeat = true;\n            }\n\n            if (!repeat) break;\n        }\n\n        text += line + linebreak;\n    }\n\n    return text;\n}", "label": 3}
{"code": "public String processIndexDescriptor(Properties attributes) throws XDocletException\r\n    {\r\n        String             name     = attributes.getProperty(ATTRIBUTE_NAME);\r\n        IndexDescriptorDef indexDef = _curClassDef.getIndexDescriptor(name);\r\n        String             attrName;\r\n        \r\n        if (indexDef == null)\r\n        {    \r\n            indexDef = new IndexDescriptorDef(name);\r\n            _curClassDef.addIndexDescriptor(indexDef);\r\n        }\r\n\r\n        if ((indexDef.getName() == null) || (indexDef.getName().length() == 0))\r\n        {\r\n            throw new XDocletException(Translator.getString(XDocletModulesOjbMessages.class,\r\n                                       XDocletModulesOjbMessages.INDEX_NAME_MISSING,\r\n                                       new String[]{_curClassDef.getName()}));\r\n        }\r\n        attributes.remove(ATTRIBUTE_NAME);\r\n        for (Enumeration attrNames = attributes.propertyNames(); attrNames.hasMoreElements(); )\r\n        {\r\n            attrName = (String)attrNames.nextElement();\r\n            indexDef.setProperty(attrName, attributes.getProperty(attrName));\r\n        }\r\n        return \"\";\r\n    }", "label": 0}
{"code": "def read\n      @site.layouts = LayoutReader.new(site).read\n      read_directories\n      read_included_excludes\n      sort_files!\n      @site.data = DataReader.new(site).read(site.config[\"data_dir\"])\n      CollectionReader.new(site).read\n      ThemeAssetsReader.new(site).read\n    end", "label": 4}
{"code": "public static base_responses add(nitro_service client, nsxmlnamespace resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnsxmlnamespace addresources[] = new nsxmlnamespace[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new nsxmlnamespace();\n\t\t\t\taddresources[i].prefix = resources[i].prefix;\n\t\t\t\taddresources[i].Namespace = resources[i].Namespace;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (r *Registry) EventManager() *EventManager {\n\treturn r.Get(r.content().EventManager.Reference()).(*EventManager)\n}", "label": 5}
{"code": "def activate(ext_name, options_hash = ::Middleman::EMPTY_HASH, &block)\n      begin\n        extension = ::Middleman::Extensions.load(ext_name)\n      rescue LoadError => e\n        logger.debug \"== Failed Activation `#{ext_name}` : #{e.message}\"\n        return\n      end\n\n      logger.debug \"== Activating: #{ext_name}\"\n\n      if extension.supports_multiple_instances?\n        @activated[ext_name] ||= {}\n        key = \"instance_#{@activated[ext_name].keys.length}\"\n        @activated[ext_name][key] = extension.new(@app, options_hash, &block)\n      elsif active?(ext_name)\n        raise \"#{ext_name} has already been activated and cannot be re-activated.\"\n      else\n        @activated[ext_name] = extension.new(@app, options_hash, &block)\n      end\n    end", "label": 4}
{"code": "def version_id(self):\n        \"\"\"Return the version of the community.\n\n        :returns: hash which encodes the community id and its las update.\n        :rtype: str\n        \"\"\"\n        return hashlib.sha1('{0}__{1}'.format(\n            self.id, self.updated).encode('utf-8')).hexdigest()", "label": 1}
{"code": "public function nanoSeconds()\n    {\n        return $this->nanoSeconds === null\n            ? (int) $this->value->format('u') * 1000\n            : $this->nanoSeconds;\n    }", "label": 2}
{"code": "function phase_hunt (sdate) {\n  if (!sdate) {\n    sdate = new Date()\n  }\n\n  let adate = new Date(sdate.getTime() - (45 * 86400000)) // 45 days prior\n  let k1 = Math.floor(12.3685 * (adate.getFullYear() + (1.0 / 12.0) * adate.getMonth() - 1900))\n  let nt1 = meanphase(adate.getTime(), k1)\n\n  sdate = julian.fromDate(sdate)\n  adate = nt1 + SYNODIC_MONTH\n  let k2 = k1 + 1\n  let nt2 = meanphase(adate, k2)\n  while (nt1 > sdate || sdate >= nt2) {\n    adate += SYNODIC_MONTH\n    k1++\n    k2++\n    nt1 = nt2\n    nt2 = meanphase(adate, k2)\n  }\n\n  return {\n    new_date: truephase(k1, NEW),\n    q1_date: truephase(k1, FIRST),\n    full_date: truephase(k1, FULL),\n    q3_date: truephase(k1, LAST),\n    nextnew_date: truephase(k2, NEW)\n  }\n}", "label": 3}
{"code": "function remove(connections, params, cb) {\n  var failed = validate(params).has(CONSTANTS.DATA_TARGET_ID);\n\n  if (failed) {\n    return cb(buildErrorResponse({error: new Error(\"An ID Parameter Is Required To Remove A Data Target\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n  }\n\n  if (!misc.checkId(params._id)) {\n    return cb(buildErrorResponse({error: new Error(\"Invalid ID Paramter\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n  }\n\n  async.waterfall([\n    function findAssociatedForms(cb) {\n      checkFormsUsingDataTarget(connections, params, cb);\n    },\n    function verifyNoFormsAssociated(updatedDataTarget, cb) {\n      //If there is more than one form using this data target, then do not delete it.\n\n      if (updatedDataTarget.forms.length > 0) {\n        return cb(buildErrorResponse({\n          error: new Error(\"Forms Are Associated With This Data Target. Please Disassociate Forms From This Data Target Before Deleting.\"),\n          code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n        }));\n      }\n\n      return cb(undefined, updatedDataTarget);\n    },\n    function processResponse(updatedDataTarget, cb) {\n      //Removing The Data Target\n      var DataTarget = models.get(connections.mongooseConnection, models.MODELNAMES.DATA_TARGET);\n\n      DataTarget.remove({_id: updatedDataTarget._id}, function(err) {\n        if (err) {\n          return cb(buildErrorResponse({\n            error: err,\n            userDetail: \"Unexpected Error When Removing A Data Target\",\n            code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n          }));\n        }\n\n        //Data Target Removed Successfully\n        return cb();\n      });\n    }\n  ], cb);\n\n}", "label": 3}
{"code": "function (name) {\n            var result, member, mappedName;\n            if (null === this._attributes) {\n                this._members();\n            }\n            if (undefined === name) {\n                result = {};\n                for (member in this._attributes) {\n                    if (this._attributes.hasOwnProperty(member)) {\n                        mappedName = this._attributes[member];\n                        result[mappedName] = this._obj[member];\n                    }\n                }\n                return result;\n            }\n            for (member in this._attributes) {\n                if (this._attributes.hasOwnProperty(member)) {\n                    if (name === this._attributes[member]) {\n                        return this._obj[member];\n                    }\n                }\n            }\n            return undefined;\n        }", "label": 3}
{"code": "public static base_response enable(nitro_service client, String acl6name) throws Exception {\n\t\tnsacl6 enableresource = new nsacl6();\n\t\tenableresource.acl6name = acl6name;\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "func (t *TestTLSServer) NewClient(identity TestIdentity) (*Client, error) {\n\ttlsConfig, err := t.ClientTLSConfig(identity)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\taddrs := []utils.NetAddr{utils.FromAddr(t.Listener.Addr())}\n\treturn NewTLSClient(ClientConfig{Addrs: addrs, TLS: tlsConfig})\n}", "label": 5}
{"code": "def html_to_plain_text(html):\n    \"\"\"Converts html code into formatted plain text.\"\"\"\n    # Use BeautifulSoup to normalize the html\n    soup = BeautifulSoup(html, \"html.parser\")\n    # Init the parser\n    parser = HTML2PlainParser()\n    parser.feed(str(soup.encode('utf-8')))\n    # Strip the end of the plain text\n    result = parser.text.rstrip()\n    # Add footnotes\n    if parser.links:\n        result += '\\n\\n'\n        for link in parser.links:\n            result += '[{}]: {}\\n'.format(link[0], link[1])\n    return result", "label": 1}
{"code": "def find(self, txt):\n        \"\"\"\n        returns a list of records containing text\n        \"\"\"\n        result = []\n        for d in self.data:\n            if txt in d:\n                result.append(d)\n        return result", "label": 1}
{"code": "func (self SampleFormat) IsPlanar() bool {\n\tswitch self {\n\tcase S16P, S32P, FLTP, DBLP:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}", "label": 5}
{"code": "public static Set<Dependency> getAllDependencies(final Module module, final List<String> producedArtifacts) {\n        final Set<Dependency> dependencies = new HashSet<Dependency>();\n\n        for(final Dependency dependency: module.getDependencies()){\n            if(!producedArtifacts.contains(dependency.getTarget().getGavc())){\n                dependencies.add(dependency);\n            }\n        }\n\n        for(final Module subModule: module.getSubmodules()){\n            dependencies.addAll(getAllDependencies(subModule, producedArtifacts));\n        }\n\n        return dependencies;\n    }", "label": 0}
{"code": "def check_mismatches(read, pair, mismatches, mm_option, req_map):\n    \"\"\"\n    - check to see if the read maps with <= threshold number of mismatches\n    - mm_option = 'one' or 'both' depending on whether or not one or both reads\n       in a pair need to pass the mismatch threshold\n    - pair can be False if read does not have a pair\n    - make sure alignment score is not 0, which would indicate that the read was not aligned to the reference\n    \"\"\"\n    # if read is not paired, make sure it is mapped and that mm <= thresh\n    if pair is False:\n        mm = count_mismatches(read)\n        if mm is False:\n            return False\n        # if no threshold is supplied, return True\n        if mismatches is False:\n            return True\n        # passes threshold?\n        if mm <= mismatches:\n            return True\n    # paired reads\n    r_mm = count_mismatches(read)\n    p_mm = count_mismatches(pair)\n    # if neither read is mapped, return False\n    if r_mm is False and p_mm is False:\n        return False\n    # if no threshold, return True\n    if mismatches is False:\n        return True\n    # if req_map is True, both reads have to map\n    if req_map is True:\n        if r_mm is False or p_mm is False:\n            return False\n    ## if option is 'one,' only one read has to pass threshold\n    if mm_option == 'one':\n        if (r_mm is not False and r_mm <= mismatches) or (p_mm is not False and p_mm <= mismatches):\n            return True\n    ## if option is 'both,' both reads have to pass threshold\n    if mm_option == 'both':\n        ## if one read in pair does not map to the scaffold,\n        ## make sure the other read passes threshold\n        if r_mm is False:\n            if p_mm <= mismatches:\n                return True\n        elif p_mm is False:\n            if r_mm <= mismatches:\n                return True\n        elif (r_mm is not False and r_mm <= mismatches) and (p_mm is not False and p_mm <= mismatches):\n            return True\n    return False", "label": 1}
{"code": "def for_linter(linter)\n      linter_name =\n        case linter\n        when Class\n          linter.name.split('::').last\n        when HamlLint::Linter\n          linter.name\n        end\n\n      @hash['linters'].fetch(linter_name, {}).dup.freeze\n    end", "label": 4}
{"code": "private function close(ConnectionInterface $conn, $code = 400, array $additional_headers = []) {\n        $response = new Response($code, array_merge([\n            'X-Powered-By' => \\Ratchet\\VERSION\n        ], $additional_headers));\n\n        $conn->send(gPsr\\str($response));\n        $conn->close();\n    }", "label": 2}
{"code": "func (a *AuthServer) GenerateUserCerts(key []byte, username string, ttl time.Duration, compatibility string) ([]byte, []byte, error) {\n\tuser, err := a.Identity.GetUser(username)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\tchecker, err := services.FetchRoles(user.GetRoles(), a.Access, user.GetTraits())\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\tcerts, err := a.generateUserCert(certRequest{\n\t\tuser:          user,\n\t\troles:         checker,\n\t\tttl:           ttl,\n\t\tcompatibility: compatibility,\n\t\tpublicKey:     key,\n\t})\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\treturn certs.ssh, certs.tls, nil\n}", "label": 5}
{"code": "def permitted_scalar_filter(params, permitted_key)\n        permitted_key = permitted_key.to_s\n\n        if has_key?(permitted_key) && permitted_scalar?(self[permitted_key])\n          params[permitted_key] = self[permitted_key]\n        end\n\n        each_key do |key|\n          next unless key =~ /\\(\\d+[if]?\\)\\z/\n          next unless $~.pre_match == permitted_key\n\n          params[key] = self[key] if permitted_scalar?(self[key])\n        end\n      end", "label": 4}
{"code": "function isInsideWithStatementBody(node) {\n            if (node) {\n                while (node.parent) {\n                    if (node.parent.kind === 212 /* WithStatement */ && node.parent.statement === node) {\n                        return true;\n                    }\n                    node = node.parent;\n                }\n            }\n            return false;\n        }", "label": 3}
{"code": "func GetString(data []byte, keys ...string) (val string, err error) {\n\tv, t, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn \"\", e\n\t}\n\n\tif t != String {\n\t\treturn \"\", fmt.Errorf(\"Value is not a string: %s\", string(v))\n\t}\n\n\t// If no escapes return raw conten\n\tif bytes.IndexByte(v, '\\\\') == -1 {\n\t\treturn string(v), nil\n\t}\n\n\treturn ParseString(v)\n}", "label": 5}
{"code": "func AuthGroupsByName(db XODB, name string) ([]*AuthGroup, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, name ` +\n\t\t`FROM public.auth_group ` +\n\t\t`WHERE name = $1`\n\n\t// run query\n\tXOLog(sqlstr, name)\n\tq, err := db.Query(sqlstr, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*AuthGroup{}\n\tfor q.Next() {\n\t\tag := AuthGroup{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&ag.ID, &ag.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ag)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "function applyObject(src, dst) {\n    Object.keys(src).forEach(function(key) {\n      dst[key] = src[key];\n    });\n    return dst;\n  }", "label": 3}
{"code": "public function getCollection(HasMedia $model, string $collectionName, $filter = []): Collection\n    {\n        return $this->applyFilterToMediaCollection($model->loadMedia($collectionName), $filter);\n    }", "label": 2}
{"code": "public static base_response link(nitro_service client, sslcertkey resource) throws Exception {\n\t\tsslcertkey linkresource = new sslcertkey();\n\t\tlinkresource.certkey = resource.certkey;\n\t\tlinkresource.linkcertkeyname = resource.linkcertkeyname;\n\t\treturn linkresource.perform_operation(client,\"link\");\n\t}", "label": 0}
{"code": "def rstrip_buffer!(index = -1)\n      last = @to_merge[index]\n      if last.nil?\n        push_silent(\"_hamlout.rstrip!\", false)\n        return\n      end\n\n      case last.first\n      when :text\n        last[1] = last[1].rstrip\n        if last[1].empty?\n          @to_merge.slice! index\n          rstrip_buffer! index\n        end\n      when :script\n        last[1].gsub!(/\\(haml_temp, (.*?)\\);$/, '(haml_temp.rstrip, \\1);')\n        rstrip_buffer! index - 1\n      else\n        raise SyntaxError.new(\"[HAML BUG] Undefined entry in Haml::Compiler@to_merge.\")\n      end\n    end", "label": 4}
{"code": "def unlocked(self):\n        \"\"\"``True`` if achievement is unlocked.\n\n        :rtype: bool\n        \"\"\"\n        achieved = CRef.cbool()\n        result = self._iface.get_ach(self.name, achieved)\n\n        if not result:\n            return False\n\n        return bool(achieved)", "label": 1}
{"code": "def create_password_hash(password)\n      encoded_password = encode_password(password)\n\n      password_as_hex = [encoded_password].pack(\"v\")\n      password_as_string = password_as_hex.unpack(\"H*\").first.upcase\n\n      password_as_string[2..3] + password_as_string[0..1]\n    end", "label": 4}
{"code": "def set_matrix_dimensions(self, *args):\n        \"\"\"\n        Subclassed to delete the cached image when matrix dimensions\n        are changed.\n        \"\"\"\n        self._image = None\n        super(FileImage, self).set_matrix_dimensions(*args)", "label": 1}
{"code": "function getCardId(o) {\n  return o.master + '#' + o.combination.front.join(',') + '@' + o.combination.back.join(',');\n}", "label": 3}
{"code": "def get_root_folder():\n    \"\"\"\n    returns the home folder and program root depending on OS\n    \"\"\"\n    locations = {\n     'linux':{'hme':'/home/duncan/', 'core_folder':'/home/duncan/dev/src/python/AIKIF'},\n     'win32':{'hme':'T:\\\\user\\\\',    'core_folder':'T:\\\\user\\\\dev\\\\src\\\\python\\\\AIKIF'},\n     'cygwin':{'hme':os.getcwd() + os.sep,    'core_folder':os.getcwd()},\n     'darwin':{'hme':os.getcwd() + os.sep,    'core_folder':os.getcwd()}\n    }\n    hme = locations[sys.platform]['hme']\n    core_folder = locations[sys.platform]['core_folder']\n\n    if not os.path.exists(core_folder):\n        hme = os.getcwd()        \n        core_folder = os.getcwd()\n        print('config.py : running on CI build (or you need to modify the paths in config.py)')\n    return hme, core_folder", "label": 1}
{"code": "public void bindDelete(PreparedStatement stmt, Identity oid, ClassDescriptor cld) throws SQLException\r\n    {\r\n        Object[] pkValues = oid.getPrimaryKeyValues();\r\n        FieldDescriptor[] pkFields = cld.getPkFields();\r\n        int i = 0;\r\n        try\r\n        {\r\n            for (; i < pkValues.length; i++)\r\n            {\r\n                setObjectForStatement(stmt, i + 1, pkValues[i], pkFields[i].getJdbcType().getType());\r\n            }\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            m_log.error(\"bindDelete failed for: \" + oid.toString() + \", while set value '\" +\r\n                    pkValues[i] + \"' for column \" + pkFields[i].getColumnName());\r\n            throw e;\r\n        }\r\n    }", "label": 0}
{"code": "func (l VirtualDeviceList) PrimaryMacAddress() string {\n\teth0 := l.Find(\"ethernet-0\")\n\n\tif eth0 == nil {\n\t\treturn \"\"\n\t}\n\n\treturn eth0.(types.BaseVirtualEthernetCard).GetVirtualEthernetCard().MacAddress\n}", "label": 5}
{"code": "def query=(new_query)\n      if new_query && !new_query.respond_to?(:to_str)\n        raise TypeError, \"Can't convert #{new_query.class} into String.\"\n      end\n      @query = new_query ? new_query.to_str : nil\n\n      # Reset dependent values\n      remove_instance_variable(:@normalized_query) if defined?(@normalized_query)\n      remove_composite_values\n    end", "label": 4}
{"code": "function fsmEvent (start, events) {\n  if (typeof start === 'object') {\n    events = start\n    start = 'START'\n  }\n  assert.equal(typeof start, 'string')\n  assert.equal(typeof events, 'object')\n  assert.ok(events[start], 'invalid starting state ' + start)\n  assert.ok(fsm.validate(events))\n\n  const emitter = new EventEmitter()\n  emit._graph = fsm.reachable(events)\n  emit._emitter = emitter\n  emit._events = events\n  emit._state = start\n  emit.emit = emit\n  emit.on = on\n\n  return emit\n\n  // set a state listener\n  // str, fn -> null\n  function on (event, cb) {\n    emitter.on(event, cb)\n  }\n\n  // change the state\n  // str -> null\n  function emit (str) {\n    const nwState = emit._events[emit._state][str]\n    if (!reach(emit._state, nwState, emit._graph)) {\n      const err = 'invalid transition: ' + emit._state + ' -> ' + str\n      return emitter.emit('error', err)\n    }\n\n    const leaveEv = emit._state + ':leave'\n    const enterEv = nwState + ':enter'\n\n    if (!emit._state) return enter()\n    return leave()\n\n    function leave () {\n      if (!emitter._events[leaveEv]) enter()\n      else emitter.emit(leaveEv, enter)\n    }\n\n    function enter () {\n      if (!emitter._events[enterEv]) done()\n      else emitter.emit(enterEv, done)\n    }\n\n    function done () {\n      emit._state = nwState\n      emitter.emit(nwState)\n      emitter.emit('done')\n    }\n  }\n}", "label": 3}
{"code": "def read_case(input, format=None):\n    \"\"\" Returns a case object from the given input file object. The data\n    format may be optionally specified.\n    \"\"\"\n    # Map of data file types to readers.\n    format_map = {\"matpower\": MATPOWERReader,\n        \"psse\": PSSEReader, \"pickle\": PickleReader}\n\n    # Read case data.\n    if format_map.has_key(format):\n        reader_klass = format_map[format]\n        reader = reader_klass()\n        case = reader.read(input)\n    else:\n        # Try each of the readers at random.\n        for reader_klass in format_map.values():\n            reader = reader_klass()\n            try:\n                case = reader.read(input)\n                if case is not None:\n                    break\n            except:\n                pass\n        else:\n            case = None\n\n    return case", "label": 1}
{"code": "def idempotent? req\n    case req\n    when Net::HTTP::Delete, Net::HTTP::Get, Net::HTTP::Head,\n         Net::HTTP::Options, Net::HTTP::Put, Net::HTTP::Trace then\n      true\n    end\n  end", "label": 4}
{"code": "def start(self):\n        \"\"\"\n        Starts an agent with standard logging\n        \"\"\"\n        self.running = True\n        self.status = 'RUNNING'\n        self.mylog.record_process('agent', self.name + ' - starting')", "label": 1}
{"code": "public function deleteCluster($projectId, $region, $clusterName, array $optionalArgs = [])\n    {\n        $request = new DeleteClusterRequest();\n        $request->setProjectId($projectId);\n        $request->setRegion($region);\n        $request->setClusterName($clusterName);\n        if (isset($optionalArgs['clusterUuid'])) {\n            $request->setClusterUuid($optionalArgs['clusterUuid']);\n        }\n        if (isset($optionalArgs['requestId'])) {\n            $request->setRequestId($optionalArgs['requestId']);\n        }\n\n        return $this->startOperationsCall(\n            'DeleteCluster',\n            $optionalArgs,\n            $request,\n            $this->getOperationsClient()\n        )->wait();\n    }", "label": 2}
{"code": "function BaseError(message, context) {\n        this.message = message;\n        this.name = this.constructor.name;\n        this.context = context || {};\n\n        Error.captureStackTrace(this, BaseError);\n    }", "label": 3}
{"code": "function groupBy(f, xs) {\r\n    const groups = [];\r\n    for (const x of xs) {\r\n        if (groups.length !== 0 && f(groups[groups.length - 1][0], x)) {\r\n            groups[groups.length - 1].push(x);\r\n        }\r\n        else {\r\n            groups.push([x]);\r\n        }\r\n    }\r\n    return groups;\r\n}", "label": 3}
{"code": "func (r *ActionResource) Register(container *restful.Container, config smolder.APIConfig, context smolder.APIContextFactory) {\n\tr.Name = \"ActionResource\"\n\tr.TypeName = \"action\"\n\tr.Endpoint = \"actions\"\n\tr.Doc = \"Manage actions\"\n\n\tr.Config = config\n\tr.Context = context\n\n\tr.Init(container, r)\n}", "label": 5}
{"code": "public function current()\n    {\n        $page = $this->pageIterator->current();\n\n        return isset($page[$this->pageIndex])\n            ? $page[$this->pageIndex]\n            : null;\n    }", "label": 2}
{"code": "func (a *Api) availableNamespaceMetrics(request *restful.Request, response *restful.Response) {\n\ta.processMetricNamesRequest(core.NamespaceKey(request.PathParameter(\"namespace-name\")), response)\n}", "label": 5}
{"code": "def update_guild_emoji(data)\n      server_id = data['guild_id'].to_i\n      server = @servers[server_id]\n      server.update_emoji_data(data)\n    end", "label": 4}
{"code": "public function send($resource, $method, array $options = [], $whitelisted = false)\n    {\n        $requestOptions = $this->pluckArray([\n            'restOptions',\n            'retries',\n            'requestTimeout'\n        ], $options);\n\n        try {\n            return json_decode(\n                $this->requestWrapper->send(\n                    $this->requestBuilder->build($resource, $method, $options),\n                    $requestOptions\n                )->getBody(),\n                true\n            );\n        } catch (NotFoundException $e) {\n            if ($whitelisted) {\n                throw $this->modifyWhitelistedError($e);\n            }\n\n            throw $e;\n        }\n    }", "label": 2}
{"code": "public function total($unit)\n    {\n        $realUnit = $unit = strtolower($unit);\n\n        if (in_array($unit, ['days', 'weeks'])) {\n            $realUnit = 'dayz';\n        } elseif (!in_array($unit, ['microseconds', 'milliseconds', 'seconds', 'minutes', 'hours', 'dayz', 'months', 'years'])) {\n            throw new InvalidArgumentException(\"Unknown unit '$unit'.\");\n        }\n\n        $result = 0;\n        $cumulativeFactor = 0;\n        $unitFound = false;\n        $factors = static::getFlipCascadeFactors();\n\n        foreach ($factors as $source => [$target, $factor]) {\n            if ($source === $realUnit) {\n                $unitFound = true;\n                $value = $this->$source;\n                if ($source === 'microseconds' && isset($factors['milliseconds'])) {\n                    $value %= Carbon::MICROSECONDS_PER_MILLISECOND;\n                }\n                $result += $value;\n                $cumulativeFactor = 1;\n            }\n\n            if ($factor === false) {\n                if ($unitFound) {\n                    break;\n                }\n\n                $result = 0;\n                $cumulativeFactor = 0;\n\n                continue;\n            }\n\n            if ($target === $realUnit) {\n                $unitFound = true;\n            }\n\n            if ($cumulativeFactor) {\n                $cumulativeFactor *= $factor;\n                $result += $this->$target * $cumulativeFactor;\n\n                continue;\n            }\n\n            $value = $this->$source;\n\n            if ($source === 'microseconds' && isset($factors['milliseconds'])) {\n                $value %= Carbon::MICROSECONDS_PER_MILLISECOND;\n            }\n\n            $result = ($result + $value) / $factor;\n        }\n\n        if (isset($target) && !$cumulativeFactor) {\n            $result += $this->$target;\n        }\n\n        if (!$unitFound) {\n            throw new \\InvalidArgumentException(\"Unit $unit have no configuration to get total from other units.\");\n        }\n\n        if ($unit === 'weeks') {\n            return $result / static::getDaysPerWeek();\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "def determine_api_version(new_file_content: nil, old_file_content: nil)\n      # we know 100% there is a difference, so no need to compare\n      unless old_file_content.length >= new_file_content.length\n        old_api_version = find_api_version_string(content: old_file_content)\n\n        return DEFAULT_API_VERSION_STRING if old_api_version.nil?\n\n        return increment_api_version_string(api_version_string: old_api_version)\n      end\n\n      relevant_old_file_content = old_file_content[0..(new_file_content.length - 1)]\n\n      if relevant_old_file_content == new_file_content\n        # no changes at all, just return the same old api version string\n        return find_api_version_string(content: old_file_content)\n      else\n        # there are differences, so calculate a new api_version_string\n        old_api_version = find_api_version_string(content: old_file_content)\n\n        return DEFAULT_API_VERSION_STRING if old_api_version.nil?\n\n        return increment_api_version_string(api_version_string: old_api_version)\n      end\n    end", "label": 4}
{"code": "protected function instantiateConfigValues($item, array $values)\n    {\n        foreach ($values as $key => $value) {\n            $values[$key] = $this->instantiateConfigValue($item, $value);\n        }\n\n        return $values;\n    }", "label": 2}
{"code": "def combine_modifiers(self, graphemes):\n        \"\"\"\n        Given a string that is space-delimited on Unicode grapheme clusters,\n        group Unicode modifier letters with their preceding base characters,\n        deal with tie bars, etc.\n\n        Parameters\n        ----------\n        string : str\n            A Unicode string tokenized into grapheme clusters to be tokenized into simple\n            IPA.\n\n        \"\"\"\n        result = []\n        temp = \"\"\n        count = len(graphemes)\n        for grapheme in reversed(graphemes):\n            count -= 1\n            if len(grapheme) == 1 and unicodedata.category(grapheme) == \"Lm\" \\\n                    and not ord(grapheme) in [712, 716]:\n                temp = grapheme + temp\n                # hack for the cases where a space modifier is the first character in the\n                # string\n                if count == 0:\n                    result[-1] = temp + result[-1]\n                continue  # pragma: no cover\n            # catch and repair stress marks\n            if len(grapheme) == 1 and ord(grapheme) in [712, 716]:\n                result[-1] = grapheme + result[-1]\n                temp = \"\"\n                continue\n\n            # combine contour tone marks (non-accents)\n            if len(grapheme) == 1 and unicodedata.category(grapheme) == \"Sk\":\n                if len(result) == 0:\n                    result.append(grapheme)\n                    temp = \"\"\n                    continue\n                else:\n                    if unicodedata.category(result[-1][0]) == \"Sk\":\n                        result[-1] = grapheme + result[-1]\n                        temp = \"\"\n                        continue\n\n            result.append(grapheme + temp)\n            temp = \"\"\n\n        # last check for tie bars\n        segments = result[::-1]\n        i = 0\n        r = []\n        while i < len(segments):\n            # tie bars\n            if ord(segments[i][-1]) in [865, 860]:\n                r.append(segments[i] + segments[i + 1])\n                i += 2\n            else:\n                r.append(segments[i])\n                i += 1\n        return r", "label": 1}
{"code": "public boolean add(final String member, final double score) {\n        return doWithJedis(new JedisCallable<Boolean>() {\n            @Override\n            public Boolean call(Jedis jedis) {\n                return jedis.zadd(getKey(), score, member) > 0;\n            }\n        });\n    }", "label": 0}
{"code": "public function getCookieNamed($name)\n    {\n        $cookies = $this->getCookies();\n        foreach ($cookies as $cookie) {\n            if ($cookie['name'] === $name) {\n                return $cookie;\n            }\n        }\n\n        return null;\n    }", "label": 2}
{"code": "function(options) {\n      var mapping,\n        models,\n        defaultMapping = _.result(this, 'mapping'),\n        defaultModels = _.result(this, 'models');\n      mapping = options.mapping || defaultMapping;\n      models = options.models || defaultModels;\n      if (mapping) {\n        this.setMappings(mapping, models);\n      }\n    }", "label": 3}
{"code": "function checkHeightCriteria() {\n\n  var scrollY = scrollElement.hasOwnProperty('pageYOffset') ? scrollElement.pageYOffset : scrollElement.scrollTop;\n  scrollY = scrollY + window.innerHeight * 0.9;\n\n  boxes.forEach(function(box) {\n      if( ! box.mayAutoShow() || box.triggerHeight <= 0 ) {\n          return;\n      }\n\n      if( scrollY > box.triggerHeight ) {\n          // don't bother if another box is currently open\n          if( isAnyBoxVisible() ) {\n              return;\n          }\n\n          // trigger box\n          box.trigger();\n      } \n    \n      // if box may auto-hide and scrollY is less than triggerHeight (with small margin of error), hide box\n      if( box.mayRehide() && scrollY < ( box.triggerHeight - 5 ) ) {\n          box.hide();\n      }\n  });\n}", "label": 3}
{"code": "private function determineState()\n    {\n        // If the state was provided via config, then just use it.\n        if ($this->config['state'] instanceof UploadState) {\n            return $this->config['state'];\n        }\n\n        // Otherwise, construct a new state from the provided identifiers.\n        $required = $this->info['id'];\n        $id = [$required['upload_id'] => null];\n        unset($required['upload_id']);\n        foreach ($required as $key => $param) {\n            if (!$this->config[$key]) {\n                throw new IAE('You must provide a value for \"' . $key . '\" in '\n                    . 'your config for the MultipartUploader for '\n                    . $this->client->getApi()->getServiceFullName() . '.');\n            }\n            $id[$param] = $this->config[$key];\n        }\n        $state = new UploadState($id);\n        $state->setPartSize($this->determinePartSize());\n\n        return $state;\n    }", "label": 2}
{"code": "public function notify(string $method, $params): Promise\n    {\n        return $this->protocolWriter->write(\n            new Message(\n                new AdvancedJsonRpc\\Notification($method, (object)$params)\n            )\n        );\n    }", "label": 2}
{"code": "function readDirs(dir, cb)  {\n  // find top-level module dirs\n  if (Array.isArray(dir)) {\n    // dir is a list of paths\n    readDirsParallel(dir, cb);\n  } else {\n    // dir is a single path value\n    readDirAbs(dir, cb);\n  }\n}", "label": 3}
{"code": "public function debuggees(array $extras = [])\n    {\n        $res = $this->connection->listDebuggees(['project' => $this->projectId] + $extras);\n        if (is_array($res) && array_key_exists('debuggees', $res)) {\n            return array_map(function ($info) {\n                return new Debuggee($this->connection, $info);\n            }, $res['debuggees']);\n        }\n        return [];\n    }", "label": 2}
{"code": "def cling_wrap(package_name, dir_name, **kw):\n    \"\"\"Return a Cling that serves from the given package and dir_name.\n\n    This uses pkg_resources.resource_filename which is not the\n    recommended way, since it extracts the files.\n\n    I think this works fine unless you have some _very_ serious\n    requirements for static content, in which case you probably\n    shouldn't be serving it through a WSGI app, IMHO. YMMV.\n    \"\"\"\n    resource = Requirement.parse(package_name)\n    return Cling(resource_filename(resource, dir_name), **kw)", "label": 1}
{"code": "public function recordCommand(CommandExecuted $event)\n    {\n        if (! Telescope::isRecording() || $this->shouldIgnore($event)) {\n            return;\n        }\n\n        Telescope::recordRedis(IncomingEntry::make([\n            'connection' => $event->connectionName,\n            'command' => $this->formatCommand($event->command, $event->parameters),\n            'time' => number_format($event->time, 2),\n        ]));\n    }", "label": 2}
{"code": "public static <T> Collection<MemberResponse<T>> executeOptimistic(IExecutorService execSvc, Set<Member> members, Callable<T> callable, long maxWaitTime, TimeUnit unit) {\n    \tCollection<MemberResponse<T>> result = new ArrayList<MemberResponse<T>>(members.size());\n    \t\n    \tMap<Member, Future<T>> resultFutures = execSvc.submitToMembers(callable, members);\n    \tfor(Entry<Member, Future<T>> futureEntry : resultFutures.entrySet()) {\n    \t\tFuture<T> future = futureEntry.getValue();\n    \t\tMember member = futureEntry.getKey();\n    \t\t\n    \t\ttry {\n                if(maxWaitTime > 0) {\n                \tresult.add(new MemberResponse<T>(member, future.get(maxWaitTime, unit)));\n                } else {\n                \tresult.add(new MemberResponse<T>(member, future.get()));\n                } \n                //ignore exceptions... return what you can\n            } catch (InterruptedException e) {\n            \tThread.currentThread().interrupt(); //restore interrupted status and return what we have\n            \treturn result;\n            } catch (MemberLeftException e) {\n            \tlog.warn(\"Member {} left while trying to get a distributed callable result\", member);\n            } catch (ExecutionException e) {\n            \tif(e.getCause() instanceof InterruptedException) {\n            \t    //restore interrupted state and return\n            \t    Thread.currentThread().interrupt();\n            \t    return result;\n            \t} else {\n            \t    log.warn(\"Unable to execute callable on \"+member+\". There was an error.\", e);\n            \t}\n            } catch (TimeoutException e) {\n            \tlog.error(\"Unable to execute task on \"+member+\" within 10 seconds.\");\n            } catch (RuntimeException e) {\n            \tlog.error(\"Unable to execute task on \"+member+\". An unexpected error occurred.\", e);\n            }\n    \t}\n        \n        return result;\n    }", "label": 0}
{"code": "func (r *SpecRunner) moveCoverprofiles(runners []*testrunner.TestRunner) {\n\tfor _, runner := range runners {\n\t\t_, filename := filepath.Split(runner.CoverageFile)\n\t\terr := os.Rename(runner.CoverageFile, filepath.Join(r.getOutputDir(), filename))\n\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Unable to move coverprofile %s, %v\\n\", runner.CoverageFile, err)\n\t\t\treturn\n\t\t}\n\t}\n}", "label": 5}
{"code": "function( el ) {\r\n      var upLength = parseInt( el.getAttribute( 'data-vd-parent-up' ), 10 ) || 0;\r\n      for ( var i = 0; i <= upLength ; i++ ) {\r\n        el = el.parentNode;\r\n      }\r\n      return el;\r\n    }", "label": 3}
{"code": "def scan!(sync=true)\n      if sync\n        servers_list.each do |server|\n          server.scan!\n        end\n      else\n        servers_list.each do |server|\n          server.monitor.scan_semaphore.signal\n        end\n      end\n      true\n    end", "label": 4}
{"code": "public static gslbservice[] get(nitro_service service) throws Exception{\n\t\tgslbservice obj = new gslbservice();\n\t\tgslbservice[] response = (gslbservice[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function instrumentSchemaForExpressGraphQL(schema) {\n  addTracingToResolvers(schema);\n  addSchemaLevelResolveFunction(schema, (root, args, ctx, info) => {\n    const operation = print(info.operation);\n    const fragments = Object.keys(info.fragments).map(k => print(info.fragments[k])).join('\\n');\n\n    ctx.tracer.log('request.query', `${operation}\\n${fragments}`);\n    ctx.tracer.log('request.variables', info.variableValues);\n    ctx.tracer.log('request.operationName', info.operation.name);\n    return root;\n  });\n}", "label": 3}
{"code": "def reject_record(self, record):\n        \"\"\"Reject a record for inclusion in the community.\n\n        :param record: Record object.\n        \"\"\"\n        with db.session.begin_nested():\n            req = InclusionRequest.get(self.id, record.id)\n            if req is None:\n                raise InclusionRequestMissingError(community=self,\n                                                   record=record)\n            req.delete()", "label": 1}
{"code": "public void showTrajectoryAndSpline(){\n\t\t\n\t\tif(t.getDimension()==2){\n\t\t \tdouble[] xData = new double[rotatedTrajectory.size()];\n\t\t    double[] yData = new double[rotatedTrajectory.size()];\n\t\t    for(int i = 0; i < rotatedTrajectory.size(); i++){\n\t\t    \txData[i] = rotatedTrajectory.get(i).x;\n\t\t    \tyData[i] = rotatedTrajectory.get(i).y;\t\t    \t\n\t\t    }\n\t\t    // Create Chart\n\t\t    Chart chart = QuickChart.getChart(\"Spline+Track\", \"X\", \"Y\", \"y(x)\", xData, yData);\n\t\t    \n\t\t    //Add spline support points\n\t\t    double[] subxData  = new double[splineSupportPoints.size()];\n\t\t    double[] subyData  = new double[splineSupportPoints.size()];\n\t\t    \n\t\t    for(int i = 0; i < splineSupportPoints.size(); i++){\n\t\t    \tsubxData[i] = splineSupportPoints.get(i).x;\n\t\t    \tsubyData[i] = splineSupportPoints.get(i).y;\n\t\t    }\n\t\t    Series s = chart.addSeries(\"Spline Support Points\", subxData, subyData);\n\t\t    s.setLineStyle(SeriesLineStyle.NONE);\n\t\t    s.setSeriesType(SeriesType.Line);\n\t\t    \n\t\t    //ADd spline points\n\t\t    int numberInterpolatedPointsPerSegment = 20;\n\t\t    int numberOfSplines = spline.getN();\n\t\t    double[] sxData = new double[numberInterpolatedPointsPerSegment*numberOfSplines];\n\t\t    \n\t\t    double[] syData = new double[numberInterpolatedPointsPerSegment*numberOfSplines];\n\t\t    double[] knots = spline.getKnots();\n\t\t    for(int i = 0; i < numberOfSplines; i++){\n\t\t    \tdouble x = knots[i];\n\t\t   \n\t\t    \tdouble stopx = knots[i+1];\n\t\t    \tdouble dx = (stopx-x)/numberInterpolatedPointsPerSegment;\n\t\t    \t\n\t\t    \tfor(int j = 0; j < numberInterpolatedPointsPerSegment; j++){\n\n\t\t    \t\tsxData[i*numberInterpolatedPointsPerSegment+j] = x;\n\t\t    \t\tsyData[i*numberInterpolatedPointsPerSegment+j] = spline.value(x);\n\t\t    \t\tx += dx;\n\t\t    \t}\n\t\t    \t\n\t\t    }\n\t\t    s = chart.addSeries(\"Spline\", sxData, syData);\n\t\t    s.setLineStyle(SeriesLineStyle.DASH_DASH);\n\t\t    s.setMarker(SeriesMarker.NONE);\n\t\t    s.setSeriesType(SeriesType.Line);\n\t\t \n\t\t    \n\t\t    //Show it\n\t\t    new SwingWrapper(chart).displayChart();\n\t\t} \n\t}", "label": 0}
{"code": "def mytoc(wobj)\n      s = @epub.mytoc\n      if !s.nil? && !wobj.nil?\n        wobj.puts s\n      end\n    end", "label": 4}
{"code": "private void handleSendDataRequest(SerialMessage incomingMessage) {\n\t\tlogger.trace(\"Handle Message Send Data Request\");\n\t\t\n\t\tint callbackId = incomingMessage.getMessagePayloadByte(0);\n\t\tTransmissionState status = TransmissionState.getTransmissionState(incomingMessage.getMessagePayloadByte(1));\n\t\tSerialMessage originalMessage = this.lastSentMessage;\n\t\t\n\t\tif (status == null) {\n\t\t\tlogger.warn(\"Transmission state not found, ignoring.\");\n\t\t\treturn;\n\t\t}\n\n\t\tlogger.debug(\"CallBack ID = {}\", callbackId);\n\t\tlogger.debug(String.format(\"Status = %s (0x%02x)\", status.getLabel(), status.getKey()));\n\t\t\n\t\tif (originalMessage == null || originalMessage.getCallbackId() != callbackId) {\n\t\t\tlogger.warn(\"Already processed another send data request for this callback Id, ignoring.\");\n\t\t\treturn;\n\t\t}\n\t\t\n\t\tswitch (status) {\n\t\t\tcase COMPLETE_OK:\n\t\t\t\tZWaveNode node = this.getNode(originalMessage.getMessageNode());\n\t\t\t\tnode.resetResendCount();\n\t\t\t\t\n\t\t\t\t// in case we received a ping response and the node is alive, we proceed with the next node stage for this node.\n\t\t\t\tif (node != null && node.getNodeStage() == NodeStage.NODEBUILDINFO_PING) {\n\t\t\t\t\tnode.advanceNodeStage();\n\t\t\t\t}\n\t\t\t\tif (incomingMessage.getMessageClass() == originalMessage.getExpectedReply() && !incomingMessage.isTransActionCanceled()) {\n\t\t\t\t\tnotifyEventListeners(new ZWaveEvent(ZWaveEventType.TRANSACTION_COMPLETED_EVENT, this.lastSentMessage.getMessageNode(), 1, this.lastSentMessage));\n\t\t\t\t\ttransactionCompleted.release();\n\t\t\t\t\tlogger.trace(\"Released. Transaction completed permit count -> {}\", transactionCompleted.availablePermits());\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\tcase COMPLETE_NO_ACK:\n\t\t\tcase COMPLETE_FAIL:\n\t\t\tcase COMPLETE_NOT_IDLE:\n\t\t\tcase COMPLETE_NOROUTE:\n\t\t\t\ttry {\n\t\t\t\t\thandleFailedSendDataRequest(originalMessage);\n\t\t\t\t} finally {\n\t\t\t\t\ttransactionCompleted.release();\n\t\t\t\t\tlogger.trace(\"Released. Transaction completed permit count -> {}\", transactionCompleted.availablePermits());\n\t\t\t\t}\n\t\t\tdefault:\n\t\t}\n\t}", "label": 0}
{"code": "protected function getResponse(IncomingMessage $message)\n    {\n        $response = $this->http->post($this->apiUrl, [], [\n            'query' => [$message->getText()],\n            'sessionId' => md5($message->getConversationIdentifier()),\n            'lang' => $this->lang,\n        ], [\n            'Authorization: Bearer '.$this->token,\n            'Content-Type: application/json; charset=utf-8',\n        ], true);\n\n        $this->response = json_decode($response->getContent());\n\n        return $this->response;\n    }", "label": 2}
{"code": "private static function fetchProtocolVersion(string $version): string\n    {\n        $v = substr($version, 5);\n\n        if ($v === '2.0') {\n            return '2';\n        }\n\n        // Fallback for values outside of valid protocol versions\n        if (!in_array($v, static::$allowedVersions, true)) {\n            return '1.1';\n        }\n\n        return $v;\n    }", "label": 2}
{"code": "def detect_and_parse(phone, country)\n      result = {}\n      Phonelib.phone_data.each do |key, data|\n        parsed = parse_single_country(phone, data)\n        if (!Phonelib.strict_double_prefix_check || key == country) && double_prefix_allowed?(data, phone, parsed && parsed[key])\n          parsed = parse_single_country(changed_dp_phone(key, phone), data)\n        end\n        result.merge!(parsed) unless parsed.nil?\n      end\n      result\n    end", "label": 4}
{"code": "function _gpfAttributesCheckAppliedOnlyOnce (member, classDefinition, AttributeClass) {\n    var attributes = _gpfAttributesCheckGetMemberAttributes(member, classDefinition, AttributeClass);\n    if (_gpfArrayTail(attributes).length) {\n        gpf.Error.uniqueAttributeUsedTwice();\n    }\n}", "label": 3}
{"code": "def retrieve_item(location_id, item_id, opts = {})\n      data, _status_code, _headers = retrieve_item_with_http_info(location_id, item_id, opts)\n      return data\n    end", "label": 4}
{"code": "def interact(self, client, location, interaction_required_err):\n        '''Implement Interactor.interact by obtaining obtaining\n        a macaroon from the discharger, discharging it with the\n        local private key using the discharged macaroon as\n        a discharge token'''\n        p = interaction_required_err.interaction_method('agent',\n                                                        InteractionInfo)\n        if p.login_url is None or p.login_url == '':\n            raise httpbakery.InteractionError(\n                'no login-url field found in agent interaction method')\n        agent = self._find_agent(location)\n        if not location.endswith('/'):\n            location += '/'\n        login_url = urljoin(location, p.login_url)\n        resp = requests.get(\n            login_url, params={\n                'username': agent.username,\n                'public-key': str(self._auth_info.key.public_key)},\n            auth=client.auth())\n        if resp.status_code != 200:\n            raise httpbakery.InteractionError(\n                'cannot acquire agent macaroon: {} {}'.format(\n                    resp.status_code, resp.text)\n            )\n        m = resp.json().get('macaroon')\n        if m is None:\n            raise httpbakery.InteractionError('no macaroon in response')\n        m = bakery.Macaroon.from_dict(m)\n        ms = bakery.discharge_all(m, None, self._auth_info.key)\n        b = bytearray()\n        for m in ms:\n            b.extend(utils.b64decode(m.serialize()))\n        return httpbakery.DischargeToken(kind='agent', value=bytes(b))", "label": 1}
{"code": "def buy\n      @page = Pwb::Page.find_by_slug \"buy\"\n      @page_title = @current_agency.company_name\n      # @content_to_show = []\n      if @page.present?\n        @page_title = @page.page_title + ' - ' + @current_agency.company_name\n        # TODO: - allow addition of custom content\n        # @page.ordered_visible_page_contents.each do |page_content|\n        #   @content_to_show.push page_content.content.raw\n        # end\n      end\n\n      # @page_title = I18n.t(\"searchForProperties\")\n      # in erb template for this action, I have js that will render search_results template\n      # for properties - like search_ajax action does\n      @operation_type = \"for_sale\"\n      # above used to decide if link to result should be to buy or rent path\n\n      @properties = Prop.visible.for_sale.limit 45\n      # ordering happens clientside\n      # .order('price_sale_current_cents ASC').limit 35\n      @prices_from_collection = @current_website.sale_price_options_from\n      @prices_till_collection = @current_website.sale_price_options_till\n      # @prices_collection = @current_website.sale_price_options_from\n\n      # %W(#{''} 25,000 50,000 75,000 100,000 150,000 250,000 500,000 1,000,000 2,000,000 5,000,000 )\n      # ..\n\n      set_common_search_inputs\n      set_select_picker_texts\n      apply_search_filter filtering_params(params)\n      set_map_markers\n\n      # below allows setting in form of any input values that might have been passed by param\n      @search_defaults = params[:search].present? ? params[:search] : {}\n      # {\"property_type\" => \"\"}\n      # below won't sort right away as the list of results is loaded by js\n      # and so won't be ready for sorting when below is called - but will wire up for sorting button\n      # initial client sort called by       INMOAPP.sortSearchResults();\n      js 'Main/Search#sort' # trigger client-side paloma script\n\n      render \"/pwb/search/buy\"\n    end", "label": 4}
{"code": "def process(self, process_data):\n        \"\"\"Process the pipeline per matrix item.\"\"\"\n        if self.parallel and not process_data.options.dry_run:\n            return self.run_matrix_in_parallel(process_data)\n        return self.run_matrix_ordered(process_data)", "label": 1}
{"code": "public function getFullNativeDescription()\n    {\n        $region = $this->getRegionName();\n        $variant = $this->getVariantName();\n\n        return $this->getFullNativeName().($region ? ' ('.$region.')' : '').($variant ? ' ('.$variant.')' : '');\n    }", "label": 2}
{"code": "def retrieve_location_from_cookie_or_service\n      return GeoLoc.new(YAML.load(cookies[:geo_location])) if cookies[:geo_location]\n      location = Geocoders::MultiGeocoder.geocode(get_ip_address)\n      return location.success ? location : nil\n    end", "label": 4}
{"code": "public function setNetworkPolicy($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\NetworkPolicy::class);\n        $this->network_policy = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function isBetween(lower, upper) {\n\treturn function (val) {\n\t\treturn isNumber(val) && val > lower && val < upper;\n\t}\n}", "label": 3}
{"code": "func (pb *paramsBuffer) End() string {\n\ts := pb.out.String()\n\tpb.lk.Unlock()\n\treturn s\n}", "label": 5}
{"code": "public function commit(array $options = [])\n    {\n        if ($this->state !== self::STATE_ACTIVE) {\n            throw new \\BadMethodCallException('The transaction cannot be committed because it is not active');\n        }\n\n        if (!$this->singleUseState()) {\n            $this->state = self::STATE_COMMITTED;\n        }\n\n        $options += [\n            'mutations' => []\n        ];\n\n        $options['mutations'] += $this->mutations;\n\n        $options['transactionId'] = $this->transactionId;\n\n        $t = $this->transactionOptions($options);\n\n        $options[$t[1]] = $t[0];\n\n        return $this->operation->commit($this->session, $this->pluck('mutations', $options), $options);\n    }", "label": 2}
{"code": "public ListResponse listTemplates(Map<String, Object> options)\n            throws RequestException, LocalOperationException {\n        Request request = new Request(this);\n        return new ListResponse(request.get(\"/templates\", options));\n    }", "label": 0}
{"code": "def team_repo?(*args)\n      arguments(args, required: [:id, :user, :repo])\n\n      response = get_request(\"/teams/#{arguments.id}/repos/#{arguments.user}/#{arguments.repo}\", arguments.params)\n      response.status == 204\n    rescue Github::Error::NotFound\n      false\n    end", "label": 4}
{"code": "public function tx_select()\n    {\n        $this->send_method_frame(array(90, 10));\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('tx.select_ok')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "def ser_iuwt_decomposition(in1, scale_count, scale_adjust, store_smoothed):\n    \"\"\"\n    This function calls the a trous algorithm code to decompose the input into its wavelet coefficients. This is\n    the isotropic undecimated wavelet transform implemented for a single CPU core.\n\n    INPUTS:\n    in1                 (no default):   Array on which the decomposition is to be performed.\n    scale_count         (no default):   Maximum scale to be considered.\n    scale_adjust        (default=0):    Adjustment to scale value if first scales are of no interest.\n    store_smoothed      (default=False):Boolean specifier for whether the smoothed image is stored or not.\n\n    OUTPUTS:\n    detail_coeffs                       Array containing the detail coefficients.\n    C0                  (optional):     Array containing the smoothest version of the input.\n    \"\"\"\n\n    wavelet_filter = (1./16)*np.array([1,4,6,4,1])      # Filter-bank for use in the a trous algorithm.\n\n    # Initialises an empty array to store the coefficients.\n\n    detail_coeffs = np.empty([scale_count-scale_adjust, in1.shape[0], in1.shape[1]])\n\n    C0 = in1    # Sets the initial value to be the input array.\n\n    # The following loop, which iterates up to scale_adjust, applies the a trous algorithm to the scales which are\n    # considered insignificant. This is important as each set of wavelet coefficients depends on the last smoothed\n    # version of the input.\n\n    if scale_adjust>0:\n        for i in range(0, scale_adjust):\n            C0 = ser_a_trous(C0, wavelet_filter, i)\n\n    # The meat of the algorithm - two sequential applications fo the a trous followed by determination and storing of\n    # the detail coefficients. C0 is reassigned the value of C on each loop - C0 is always the smoothest version of the\n    # input image.\n\n    for i in range(scale_adjust,scale_count):\n        C = ser_a_trous(C0, wavelet_filter, i)                                  # Approximation coefficients.\n        C1 = ser_a_trous(C, wavelet_filter, i)                                  # Approximation coefficients.\n        detail_coeffs[i-scale_adjust,:,:] = C0 - C1                             # Detail coefficients.\n        C0 = C\n\n    if store_smoothed:\n        return detail_coeffs, C0\n    else:\n        return detail_coeffs", "label": 1}
{"code": "func (sm *Manager) UserSession(ctx context.Context) (*types.UserSession, error) {\n\tvar mgr mo.SessionManager\n\n\tpc := property.DefaultCollector(sm.client)\n\terr := pc.RetrieveOne(ctx, sm.Reference(), []string{\"currentSession\"}, &mgr)\n\tif err != nil {\n\t\t// It's OK if we can't retrieve properties because we're not authenticated\n\t\tif f, ok := err.(types.HasFault); ok {\n\t\t\tswitch f.Fault().(type) {\n\t\t\tcase *types.NotAuthenticated:\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\treturn mgr.CurrentSession, nil\n}", "label": 5}
{"code": "def merge_dependencies(data)\n      data['dependencies'].each do |dep|\n        add_dependency(dep['name'], dep['version_requirement'], dep['repository'])\n      end\n\n      # Clear dependencies so @data dependencies are not overwritten\n      data.delete 'dependencies'\n    end", "label": 4}
{"code": "public function setAction($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Debugger\\V2\\Breakpoint_Action::class);\n        $this->action = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (a *HistoricalApi) processMetricNamesRequest(key core.HistoricalKey, response *restful.Response) {\n\tif resp, err := a.historicalSource.GetMetricNames(key); err != nil {\n\t\tresponse.WriteError(http.StatusInternalServerError, err)\n\t} else {\n\t\tresponse.WriteEntity(resp)\n\t}\n}", "label": 5}
{"code": "func Init() {\n\tvar err error\n\tinitNs, err = netns.Get()\n\tif err != nil {\n\t\tlogrus.Errorf(\"could not get initial namespace: %v\", err)\n\t}\n\tinitNl, err = netlink.NewHandle(getSupportedNlFamilies()...)\n\tif err != nil {\n\t\tlogrus.Errorf(\"could not create netlink handle on initial namespace: %v\", err)\n\t}\n\terr = initNl.SetSocketTimeout(NetlinkSocketsTimeout)\n\tif err != nil {\n\t\tlogrus.Warnf(\"Failed to set the timeout on the default netlink handle sockets: %v\", err)\n\t}\n}", "label": 5}
{"code": "def resource_types\n      @resource_types ||= %w(\n        Decidim::Accountability::Result\n        Decidim::Blogs::Post\n        Decidim::Comments::Comment\n        Decidim::Consultations::Question\n        Decidim::Debates::Debate\n        Decidim::Meetings::Meeting\n        Decidim::Proposals::Proposal\n        Decidim::Surveys::Survey\n        Decidim::Assembly\n        Decidim::Consultation\n        Decidim::Initiative\n        Decidim::ParticipatoryProcess\n      ).select do |klass|\n        klass.safe_constantize.present?\n      end\n    end", "label": 4}
{"code": "def track_version_codes(track)\n      ensure_active_edit!\n\n      begin\n        result = client.get_track(\n          current_package_name,\n          current_edit.id,\n          track\n        )\n        return result.version_codes || []\n      rescue Google::Apis::ClientError => e\n        return [] if e.status_code == 404 && e.to_s.include?(\"trackEmpty\")\n        raise\n      end\n    end", "label": 4}
{"code": "function (to, callback, param) {\n            _gpfObjectForEach(this._members, function (attributeArray, member) {\n                member = _gpfDecodeAttributeMember(member);\n                attributeArray._array.forEach(function (attribute) {\n                    if (!callback || callback(member, attribute, param)) {\n                        to.add(member, attribute);\n                    }\n                });\n            });\n            return to;\n        }", "label": 3}
{"code": "def run_strelka(job, tumor_bam, normal_bam, univ_options, strelka_options, split=True):\n    \"\"\"\n    Run the strelka subgraph on the DNA bams.  Optionally split the results into per-chromosome\n    vcfs.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict strelka_options: Options specific to strelka\n    :param bool split: Should the results be split into perchrom vcfs?\n    :return: Either the fsID to the genome-level vcf or a dict of results from running strelka\n             on every chromosome\n             perchrom_strelka:\n                 |- 'chr1':\n                 |      |-'snvs': fsID\n                 |      +-'indels': fsID\n                 |- 'chr2':\n                 |      |-'snvs': fsID\n                 |      +-'indels': fsID\n                 |-...\n                 |\n                 +- 'chrM':\n                        |-'snvs': fsID\n                        +-'indels': fsID\n    :rtype: toil.fileStore.FileID|dict\n    \"\"\"\n    if strelka_options['chromosomes']:\n        chromosomes = strelka_options['chromosomes']\n    else:\n        chromosomes = sample_chromosomes(job, strelka_options['genome_fai'])\n    num_cores = min(len(chromosomes), univ_options['max_cores'])\n    strelka = job.wrapJobFn(run_strelka_full, tumor_bam, normal_bam, univ_options,\n                            strelka_options,\n                            disk=PromisedRequirement(strelka_disk,\n                                                     tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n                                                     normal_bam['normal_dna_fix_pg_sorted.bam'],\n                                                     strelka_options['genome_fasta']),\n                            memory='6G',\n                            cores=num_cores)\n    job.addChild(strelka)\n    if split:\n        unmerge_strelka = job.wrapJobFn(wrap_unmerge, strelka.rv(), chromosomes, strelka_options,\n                                        univ_options).encapsulate()\n        strelka.addChild(unmerge_strelka)\n        return unmerge_strelka.rv()\n    else:\n        return strelka.rv()", "label": 1}
{"code": "public function setAdditions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\WebRisk\\V1beta1\\ThreatEntryAdditions::class);\n        $this->additions = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setEntityType($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\EntityType::class);\n        $this->entity_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *Client) CreateSession(sess session.Session) error {\n\tif sess.Namespace == \"\" {\n\t\treturn trace.BadParameter(MissingNamespaceError)\n\t}\n\t_, err := c.PostJSON(c.Endpoint(\"namespaces\", sess.Namespace, \"sessions\"), createSessionReq{Session: sess})\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "function generatePathString(paths) {\n  let pathString = '';\n\n  if (!paths || !paths.length) return pathString;\n\n  if (paths.length > 1) {\n    pathString = paths.map(pathItem => filepathName(pathItem));\n    // Trim long lists\n    if (pathString.length > maxInputStringLength) {\n      const remainder = pathString.length - maxInputStringLength;\n\n      pathString = `${pathString\n        .slice(0, maxInputStringLength)\n        .join(', ')} ...and ${remainder} other${remainder > 1 ? 's' : ''}`;\n    } else {\n      pathString = pathString.join(', ');\n    }\n  } else {\n    pathString = filepathName(paths[0]);\n  }\n\n  return pathString;\n}", "label": 3}
{"code": "def requests(pipeline_params)\n      pipeline_params.each {|params| params.merge!(:pipeline => true, :persistent => true) }\n      pipeline_params.last.merge!(:persistent => @data[:persistent])\n\n      responses = pipeline_params.map do |params|\n        request(params)\n      end.map do |datum|\n        Excon::Response.new(response(datum)[:response])\n      end\n\n      if @data[:persistent]\n        if key = responses.last[:headers].keys.detect {|k| k.casecmp('Connection') == 0 }\n          if responses.last[:headers][key].casecmp('close') == 0\n            reset\n          end\n        end\n      else\n        reset\n      end\n\n      responses\n    end", "label": 4}
{"code": "function simpleSizeForMultiGraphs(graph) {\n  var nodes = graph.nodes(),\n      size = 0,\n      i,\n      l;\n\n  for (i = 0, l = nodes.length; i < l; i++) {\n    size += graph.outNeighbors(nodes[i]).length;\n    size += graph.undirectedNeighbors(nodes[i]).length / 2;\n  }\n\n  return size;\n}", "label": 3}
{"code": "public function setInstance($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\Admin\\Instance\\V1\\Instance::class);\n        $this->instance = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func NewBeeInstance(bee BeeConfig) *BeeInterface {\n\tfactory := GetFactory(bee.Class)\n\tif factory == nil {\n\t\tpanic(\"Unknown bee-class in config file: \" + bee.Class)\n\t}\n\tmod := (*factory).New(bee.Name, bee.Description, bee.Options)\n\tRegisterBee(mod)\n\n\treturn &mod\n}", "label": 5}
{"code": "function toMinorRange(version) {\n    var regex = /^\\d+\\.\\d+/;\n    var range = version.match(regex);\n    if (range) {\n      return '^' + range[0];\n    }\n    else {\n      var regex = /^\\d+\\.x/;\n      var range = version.match(regex);\n      if (range) {\n        return range[0];\n      }\n    }\n\n    return version;\n  }", "label": 3}
{"code": "def reads_generator_to_sequences_generator(\n        variant_and_reads_generator,\n        min_alt_rna_reads=MIN_ALT_RNA_READS,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,\n        preferred_sequence_length=VARIANT_SEQUENCE_LENGTH,\n        variant_sequence_assembly=VARIANT_SEQUENCE_ASSEMBLY):\n    \"\"\"\n    For each variant, collect all possible sequence contexts around the\n    variant which are spanned by at least min_reads.\n\n    Parameters\n    ----------\n    variant_and_reads_generator : generator\n        Sequence of Variant objects paired with a list of reads which\n        overlap that variant.\n\n    min_alt_rna_reads : int\n        Minimum number of RNA reads supporting variant allele\n\n    min_variant_sequence_coverage : int\n        Minimum number of RNA reads supporting each nucleotide of the\n        variant cDNA sequence\n\n    sequence_length : int\n        Desired sequence length, including variant nucleotides\n\n    variant_sequence_assembly : bool\n        Construct variant sequences by merging overlapping reads. If False\n        then variant sequences must be fully spanned by cDNA reads.\n\n    Yields pairs with the following fields:\n        - Variant\n        - list of VariantSequence objects\n    \"\"\"\n    for variant, variant_reads in variant_and_reads_generator:\n        variant_sequences = reads_to_variant_sequences(\n            variant=variant,\n            reads=variant_reads,\n            min_alt_rna_reads=min_alt_rna_reads,\n            min_variant_sequence_coverage=min_variant_sequence_coverage,\n            preferred_sequence_length=preferred_sequence_length,\n            variant_sequence_assembly=variant_sequence_assembly)\n        yield variant, variant_sequences", "label": 1}
{"code": "def lease(self, time_to_live, lease_id=None, timeout=None):\n        \"\"\"\n        Creates a lease which expires if the server does not\n        receive a keep alive within a given time to live period.\n\n        All keys attached to the lease will be expired and deleted if\n        the lease expires.\n\n        Each expired key generates a delete event in the event history.\n\n        :param time_to_live: TTL is the advisory time-to-live in seconds.\n        :type time_to_live: int\n\n        :param lease_id: ID is the requested ID for the lease.\n            If ID is None, the lessor (etcd) chooses an ID.\n        :type lease_id: int or None\n\n        :param timeout: Request timeout in seconds.\n        :type timeout: int\n\n        :returns: A lease object representing the created lease. This\n            can be used for refreshing or revoking the least etc.\n        :rtype: instance of :class:`txaioetcd.Lease`\n        \"\"\"\n        assembler = commons.LeaseRequestAssembler(self._url, time_to_live, lease_id)\n\n        obj = yield self._post(assembler.url, assembler.data, timeout)\n\n        lease = Lease._parse(self, obj)\n\n        returnValue(lease)", "label": 1}
{"code": "public function getGroupsAttribute()\n    {\n        if (! isset($this->attributes['groups'])) {\n            $this->attributes['groups'] = $this->relations['groups'] = Group::where('id', Group::GUEST_ID)->get();\n        }\n\n        return $this->attributes['groups'];\n    }", "label": 2}
{"code": "def oaiset(self):\n        \"\"\"Return the corresponding OAISet for given community.\n\n        If OAIServer is not installed this property will return None.\n\n        :returns: returns OAISet object corresponding to this community.\n        :rtype: `invenio_oaiserver.models.OAISet` or None\n        \"\"\"\n        if current_app.config['COMMUNITIES_OAI_ENABLED']:\n            from invenio_oaiserver.models import OAISet\n            return OAISet.query.filter_by(spec=self.oaiset_spec).one()\n        else:\n            return None", "label": 1}
{"code": "function on(events, callback, context)\n  {\n    return onListeners( this, events, callback, context, EventNode.Types.Persistent );\n  }", "label": 3}
{"code": "public RedwoodConfiguration showOnlyChannels(final Object[] channels){\r\n     tasks.add(new Runnable() { public void run() { Redwood.showOnlyChannels(channels); } });\r\n    return this;\r\n  }", "label": 0}
{"code": "function getContextualTypeForArgument(callTarget, arg) {\n            var args = getEffectiveCallArguments(callTarget);\n            var argIndex = ts.indexOf(args, arg);\n            if (argIndex >= 0) {\n                var signature = getResolvedOrAnySignature(callTarget);\n                return getTypeAtPosition(signature, argIndex);\n            }\n            return undefined;\n        }", "label": 3}
{"code": "def wait(retries_left, &blk)\n      blk.call\n    rescue Exception => e\n      retries_left -= 1\n      if retries_left > 0\n        sleep(0.5)\n        retry\n      else\n        raise\n      end\n    end", "label": 4}
{"code": "function isIndependentType(node) {\n            switch (node.kind) {\n                case 117 /* AnyKeyword */:\n                case 132 /* StringKeyword */:\n                case 130 /* NumberKeyword */:\n                case 120 /* BooleanKeyword */:\n                case 133 /* SymbolKeyword */:\n                case 103 /* VoidKeyword */:\n                case 135 /* UndefinedKeyword */:\n                case 93 /* NullKeyword */:\n                case 127 /* NeverKeyword */:\n                case 166 /* LiteralType */:\n                    return true;\n                case 160 /* ArrayType */:\n                    return isIndependentType(node.elementType);\n                case 155 /* TypeReference */:\n                    return isIndependentTypeReference(node);\n            }\n            return false;\n        }", "label": 3}
{"code": "@SuppressWarnings({ \"unused\", \"unchecked\" })\n  private static void rewriteMergeData(String key, String subKey,\n      NamedList<Object> snl, NamedList<Object> tnl) {\n    if (snl != null) {\n      Object o = tnl.get(key);\n      NamedList<Object> tnnnl;\n      if (o != null && o instanceof NamedList) {\n        tnnnl = (NamedList<Object>) o;\n      } else {\n        tnnnl = new SimpleOrderedMap<>();\n        tnl.add(key, tnnnl);\n      }\n      tnnnl.add(subKey, snl);\n    }\n  }", "label": 0}
{"code": "def query(self):\n        \"\"\"Runs an fstat for this file and repopulates the data\"\"\"\n\n        self._p4dict = self._connection.run(['fstat', '-m', '1', self._p4dict['depotFile']])[0]\n        self._head = HeadRevision(self._p4dict)\n\n        self._filename = self.depotFile", "label": 1}
{"code": "public void put(String key, Object object, Envelope envelope) {\n\t\tindex.put(key, envelope);\n\t\tcache.put(key, object);\n\t}", "label": 0}
{"code": "public function downloadAsStream(array $options = [])\n    {\n        return $this->connection->downloadObject(\n            $this->formatEncryptionHeaders(\n                $options\n                + $this->encryptionData\n                + array_filter($this->identity)\n            )\n        );\n    }", "label": 2}
{"code": "def load_message(message_id)\n      response = API::Channel.message(@bot.token, @id, message_id)\n      Message.new(JSON.parse(response), @bot)\n    rescue RestClient::ResourceNotFound\n      nil\n    end", "label": 4}
{"code": "function (req, res, passport, cb) {\n        let authentication = req.soajs.inputmaskData.strategy;\n\n        passportLib.getDriver(req, false, function (err, passportDriver) {\n            passportDriver.preAuthenticate(req, function () {\n                passport.authenticate(authentication, {session: false}, function (err, user) {\n                    if (err) {\n                        req.soajs.log.error(err);\n                        return cb({\"code\": 499, \"msg\": err.toString()});\n                    }\n                    if (!user) {\n                        cb({\"code\": 403, \"msg\": req.soajs.config.errors[403]});\n                    }\n\n                    req.soajs.inputmaskData.user = user;\n                    initBLModel(req.soajs, function (err) {\n                        if (err) {\n                            return cb(err);\n                        }\n                        let mode = req.soajs.inputmaskData.strategy;\n                        utilities.saveUser(req.soajs, driver.model, mode, user, function (error, data) {\n                            cb(error, data);\n                        });\n                    });\n                })(req, res);\n\n            });\n        });\n\n    }", "label": 3}
{"code": "function(req, res, fromMessage) {\n            var name = req.params.name;\n            var doc  = req.body;\n            var id   = this.toId(req.params.id || doc._id);\n            if (typeof id === 'undefined' || id === '') {\n                return res.send(400, \"invalid id.\");\n            }\n            doc._id   = id;\n            doc._time = new Date().getTime();\n            var collection = new mongodb.Collection(this.db, name);\n            collection.update(\n                { \"_id\" : id },\n                doc,\n                { safe:true, upsert:true },\n                function(err, n) {\n                    if(err) {\n                        res.send(\"Oops!: \" + err);\n                    } else {\n                        if (n==0) {\n                            res.send(404, 'Document not found!');\n                        } else {\n                            var msg = {\n                                method: 'update',\n                                id: doc._id,\n                                time: doc._time,\n                                data: doc\n                            };\n                            rest.onSuccess(name, msg, fromMessage);\n                            res.send(doc);\n                        }\n                    }\n                }\n            );\n        }", "label": 3}
{"code": "def remove_device(self, request):\n        \"\"\"Removes device specified by id\"\"\"\n        \n        devices = self.__get_u2f_devices()\n\n        for i in range(len(devices)):\n            if devices[i]['keyHandle'] == request['id']:\n                del devices[i]\n                self.__save_u2f_devices(devices)\n                \n                return {\n                    'status'  : 'ok', \n                    'message' : 'Successfully deleted your device!'\n                }\n\n        return {\n            'status' : 'failed', \n            'error'  : 'No device with such an id been found!'\n        }", "label": 1}
{"code": "def header(verb, url)\n      timestamp = Time.now.utc.to_i\n      nonce = Digest::MD5.hexdigest([timestamp, SecureRandom.hex].join(':'))\n\n      uri = URI.parse(url)\n\n      raise(ArgumentError, \"could not parse \\\"#{url}\\\" into URI\") unless uri.is_a?(URI::HTTP)\n\n      mac = signature(timestamp, nonce, verb, uri)\n\n      \"MAC id=\\\"#{token}\\\", ts=\\\"#{timestamp}\\\", nonce=\\\"#{nonce}\\\", mac=\\\"#{mac}\\\"\"\n    end", "label": 4}
{"code": "public static base_responses add(nitro_service client, vpath resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tvpath addresources[] = new vpath[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new vpath();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].destip = resources[i].destip;\n\t\t\t\taddresources[i].encapmode = resources[i].encapmode;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function loadModule(modulePath, moduleStack, options) {\n        var newModule, i;\n        options = options || {};\n\n        // if modulePath is null return null\n        if (!modulePath) {\n            return null;\n        }\n\n        // if actual flapjack sent in as the module path then switch things around so modulePath name is unique\n        if (_.isFunction(modulePath)) {\n            options.flapjack = modulePath;\n            modulePath = 'module-' + (new Date()).getTime();\n        }\n        // if we already have a flapjack, make the modulePath unique per the options\n        else if (options.flapjack) {\n            modulePath = (options.app || 'common') + '.' + modulePath + '.' + (options.type || 'default');\n        }\n        // else we need to get code from the file system, so check to see if we need to switch a mapped name to its path\n        else if (this.aliases[modulePath]) {\n            modulePath = this.aliases[modulePath];\n        }\n        // if module name already in the stack, then circular reference\n        moduleStack = moduleStack || [];\n\n\n        if (moduleStack.indexOf(modulePath) >= 0) {\n            throw new Error('Circular reference since ' + modulePath + ' is in ' + JSON.stringify(moduleStack));\n        }\n        // add the path to the stack so we don't have a circular dependency\n        moduleStack.push(modulePath);\n\n        // try to find a factory that can create/get a module for the given path\n\n        for (i = 0; this.factories && i < this.factories.length; i++) {\n            if (this.factories[i].isCandidate(modulePath, options)) {\n                newModule = this.factories[i].create(modulePath, moduleStack, options);\n                break;\n            }\n        }\n\n        // if no module found log error\n        if (!newModule && moduleStack && moduleStack.length > 1) {\n            /* eslint no-console:0 */\n            console.log('ERROR: ' + moduleStack[moduleStack.length - 2] + ' dependency ' + modulePath + ' not found.');\n        }\n\n        // pop the current item off the stack\n        moduleStack.pop();\n\n        // return the new module (or the default {} if no factories found)\n        return newModule;\n    }", "label": 3}
{"code": "func (s *PresenceService) GetReverseTunnels(opts ...services.MarshalOption) ([]services.ReverseTunnel, error) {\n\tstartKey := backend.Key(reverseTunnelsPrefix)\n\tresult, err := s.GetRange(context.TODO(), startKey, backend.RangeEnd(startKey), backend.NoLimit)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttunnels := make([]services.ReverseTunnel, len(result.Items))\n\tfor i, item := range result.Items {\n\t\ttunnel, err := services.GetReverseTunnelMarshaler().UnmarshalReverseTunnel(\n\t\t\titem.Value, services.AddOptions(opts, services.WithResourceID(item.ID), services.WithExpires(item.Expires))...)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\ttunnels[i] = tunnel\n\t}\n\t// sorting helps with tests and makes it all deterministic\n\tsort.Sort(services.SortedReverseTunnels(tunnels))\n\treturn tunnels, nil\n}", "label": 5}
{"code": "public function setRowRanges($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Bigtable\\V2\\RowRange::class);\n        $this->row_ranges = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def delete(*args)\n      arguments(args, required: [:user, :repo, :ref])\n      params = arguments.params\n\n      delete_request(\"/repos/#{arguments.user}/#{arguments.repo}/git/refs/#{arguments.ref}\", params)\n    end", "label": 4}
{"code": "def run\n      Jekyll.logger.debug \"Rendering:\", document.relative_path\n\n      assign_pages!\n      assign_current_document!\n      assign_highlighter_options!\n      assign_layout_data!\n\n      Jekyll.logger.debug \"Pre-Render Hooks:\", document.relative_path\n      document.trigger_hooks(:pre_render, payload)\n\n      render_document\n    end", "label": 4}
{"code": "function(viewPrepare) {\n      var viewContext = viewPrepare() || {};\n      var behaviorContext = _.omit(this.toJSON(), 'view');\n      _.extend(behaviorContext, this.prepare());\n      viewContext[this.alias] = behaviorContext;\n      return viewContext;\n    }", "label": 3}
{"code": "protected void splitCriteria()\r\n    {\r\n        Criteria whereCrit = getQuery().getCriteria();\r\n        Criteria havingCrit = getQuery().getHavingCriteria();\r\n\r\n        if (whereCrit == null || whereCrit.isEmpty())\r\n        {\r\n            getJoinTreeToCriteria().put(getRoot(), null);\r\n        }\r\n        else\r\n        {\r\n            // TODO: parameters list shold be modified when the form is reduced to DNF.\r\n            getJoinTreeToCriteria().put(getRoot(), whereCrit);\r\n            buildJoinTree(whereCrit);\r\n        }\r\n\r\n        if (havingCrit != null && !havingCrit.isEmpty())\r\n        {\r\n            buildJoinTree(havingCrit);\r\n        }\r\n\r\n    }", "label": 0}
{"code": "public function setPigJob($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1\\PigJob::class);\n        $this->writeOneof(7, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function getInput() {\n\n    var account = document.getElementById('account').value; \n\tvar email = (document.getElementById('email') ? document.getElementById('email').value : ''); \n    var password = document.getElementById('password').value;\n\t\n\treturn {account: account, email: email, password: password};\t\n}", "label": 3}
{"code": "func (sink *gcmSink) register(metrics []core.Metric) error {\n\tsink.Lock()\n\tdefer sink.Unlock()\n\tif sink.registered {\n\t\treturn nil\n\t}\n\n\tfor _, metric := range metrics {\n\t\tmetricName := fullMetricName(sink.project, metric.MetricDescriptor.Name)\n\t\tmetricType := fullMetricType(metric.MetricDescriptor.Name)\n\n\t\tif _, err := sink.gcmService.Projects.MetricDescriptors.Delete(metricName).Do(); err != nil {\n\t\t\tglog.Infof(\"[GCM] Deleting metric %v failed: %v\", metricName, err)\n\t\t}\n\t\tlabels := make([]*gcm.LabelDescriptor, 0)\n\n\t\t// Node autoscaling metrics have special labels.\n\t\tif core.IsNodeAutoscalingMetric(metric.MetricDescriptor.Name) {\n\t\t\t// All and autoscaling. Do not populate for other filters.\n\t\t\tif sink.metricFilter != metricsAll &&\n\t\t\t\tsink.metricFilter != metricsOnlyAutoscaling {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfor _, l := range core.GcmNodeAutoscalingLabels() {\n\t\t\t\tlabels = append(labels, &gcm.LabelDescriptor{\n\t\t\t\t\tKey:         l.Key,\n\t\t\t\t\tDescription: l.Description,\n\t\t\t\t})\n\t\t\t}\n\t\t} else {\n\t\t\t// Only all.\n\t\t\tif sink.metricFilter != metricsAll {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfor _, l := range core.GcmLabels() {\n\t\t\t\tlabels = append(labels, &gcm.LabelDescriptor{\n\t\t\t\t\tKey:         l.Key,\n\t\t\t\t\tDescription: l.Description,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\tvar metricKind string\n\n\t\tswitch metric.MetricDescriptor.Type {\n\t\tcase core.MetricCumulative:\n\t\t\tmetricKind = \"CUMULATIVE\"\n\t\tcase core.MetricGauge:\n\t\t\tmetricKind = \"GAUGE\"\n\t\tcase core.MetricDelta:\n\t\t\tmetricKind = \"DELTA\"\n\t\t}\n\n\t\tvar valueType string\n\n\t\tswitch metric.MetricDescriptor.ValueType {\n\t\tcase core.ValueInt64:\n\t\t\tvalueType = \"INT64\"\n\t\tcase core.ValueFloat:\n\t\t\tvalueType = \"DOUBLE\"\n\t\t}\n\n\t\tdesc := &gcm.MetricDescriptor{\n\t\t\tName:        metricName,\n\t\t\tDescription: metric.MetricDescriptor.Description,\n\t\t\tLabels:      labels,\n\t\t\tMetricKind:  metricKind,\n\t\t\tValueType:   valueType,\n\t\t\tType:        metricType,\n\t\t}\n\n\t\tif _, err := sink.gcmService.Projects.MetricDescriptors.Create(fullProjectName(sink.project), desc).Do(); err != nil {\n\t\t\tglog.Errorf(\"Metric registration of %v failed: %v\", desc.Name, err)\n\t\t\treturn err\n\t\t}\n\t}\n\tsink.registered = true\n\treturn nil\n}", "label": 5}
{"code": "func (p *httpStreamPair) add(stream httpstream.Stream) (bool, error) {\n\tp.lock.Lock()\n\tdefer p.lock.Unlock()\n\n\tswitch stream.Headers().Get(StreamType) {\n\tcase StreamTypeError:\n\t\tif p.errorStream != nil {\n\t\t\treturn false, trace.BadParameter(\"error stream already assigned\")\n\t\t}\n\t\tp.errorStream = stream\n\tcase StreamTypeData:\n\t\tif p.dataStream != nil {\n\t\t\treturn false, trace.BadParameter(\"data stream already assigned\")\n\t\t}\n\t\tp.dataStream = stream\n\t}\n\n\tcomplete := p.errorStream != nil && p.dataStream != nil\n\tif complete {\n\t\tclose(p.complete)\n\t}\n\treturn complete, nil\n}", "label": 5}
{"code": "def get_hostname_text(self):\n        \"\"\"Return hostname information from the Unix host.\"\"\"\n        # FIXME: fix it, too complex logic\n        try:\n            hostname_text = self.device.send('hostname', timeout=10)\n            if hostname_text:\n                self.device.hostname = hostname_text.splitlines()[0]\n                return hostname_text\n        except CommandError:\n            self.log(\"Non Unix jumphost type detected\")\n            return None", "label": 1}
{"code": "public boolean containsIteratorForTable(String aTable)\r\n    {\r\n        boolean result = false;\r\n\r\n        if (m_rsIterators != null)\r\n        {\r\n            for (int i = 0; i < m_rsIterators.size(); i++)\r\n            {\r\n                OJBIterator it = (OJBIterator) m_rsIterators.get(i);\r\n                if (it instanceof RsIterator)\r\n                {\r\n                    if (((RsIterator) it).getClassDescriptor().getFullTableName().equals(aTable))\r\n                    {\r\n                        result = true;\r\n                        break;\r\n                    }\r\n                }\r\n                else if (it instanceof ChainingIterator)\r\n                {\r\n                    result = ((ChainingIterator) it).containsIteratorForTable(aTable);\r\n                }\r\n            }\r\n        }\r\n\r\n        return result;\r\n    }", "label": 0}
{"code": "def write_svg(self):\n        \"\"\"\n            Returns PUML from the system as a SVG image. Requires plantuml library.\n        \"\"\"\n        import plantuml\n        puml = self.write_puml()\n        server = plantuml.PlantUML(url=self.url)\n        svg = server.processes(puml)\n        return svg", "label": 1}
{"code": "def load_cache\n      begin\n        file = File.join(\"inline\", File.basename(so_name))\n        if require file then\n          dir = Inline.directory\n          warn \"WAR\\NING: #{dir} exists but is not being used\" if test ?d, dir and $VERBOSE\n          return true\n        end\n      rescue LoadError\n      end\n      return false\n    end", "label": 4}
{"code": "func (d Datastore) Upload(ctx context.Context, f io.Reader, path string, param *soap.Upload) error {\n\tu, p, err := d.uploadTicket(ctx, path, param)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn d.Client().Upload(ctx, f, u, p)\n}", "label": 5}
{"code": "public long remove(final String... fields) {\n        return doWithJedis(new JedisCallable<Long>() {\n            @Override\n            public Long call(Jedis jedis) {\n                return jedis.hdel(getKey(), fields);\n            }\n        });\n    }", "label": 0}
{"code": "public static wisite_translationinternalip_binding[] get(nitro_service service, String sitepath) throws Exception{\n\t\twisite_translationinternalip_binding obj = new wisite_translationinternalip_binding();\n\t\tobj.set_sitepath(sitepath);\n\t\twisite_translationinternalip_binding response[] = (wisite_translationinternalip_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function modularity(graph, options) {\n\n  // Handling errors\n  if (!isGraph(graph))\n    throw new Error('graphology-metrics/modularity: the given graph is not a valid graphology instance.');\n\n  if (graph.multi)\n    throw new Error('graphology-metrics/modularity: multi graphs are not handled.');\n\n  if (!graph.size)\n    throw new Error('graphology-metrics/modularity: the given graph has no edges.');\n\n  // Solving options\n  options = defaults({}, options, DEFAULTS);\n\n  var communities,\n      nodes = graph.nodes(),\n      edges = graph.edges(),\n      i,\n      l;\n\n  // Do we have a community mapping?\n  if (typeof options.communities === 'object') {\n    communities = options.communities;\n  }\n\n  // Else we need to extract it from the graph\n  else {\n    communities = {};\n\n    for (i = 0, l = nodes.length; i < l; i++)\n      communities[nodes[i]] = graph.getNodeAttribute(nodes[i], options.attributes.community);\n  }\n\n  var M = 0,\n      Q = 0,\n      internalW = {},\n      totalW = {},\n      bounds,\n      node1, node2, edge,\n      community1, community2,\n      w, weight;\n\n  for (i = 0, l = edges.length; i < l; i++) {\n    edge = edges[i];\n    bounds = graph.extremities(edge);\n    node1 = bounds[0];\n    node2 = bounds[1];\n\n    if (node1 === node2)\n      continue;\n\n    community1 = communities[node1];\n    community2 = communities[node2];\n\n    if (community1 === undefined)\n      throw new Error('graphology-metrics/modularity: the \"' + node1 + '\" node is not in the partition.');\n\n    if (community2 === undefined)\n      throw new Error('graphology-metrics/modularity: the \"' + node2 + '\" node is not in the partition.');\n\n    w = graph.getEdgeAttribute(edge, options.attributes.weight);\n    weight = isNaN(w) ? 1 : w;\n\n    totalW[community1] = (totalW[community1] || 0) + weight;\n    if (graph.undirected(edge) || !graph.hasDirectedEdge(node2, node1)) {\n      totalW[community2] = (totalW[community2] || 0) + weight;\n      M += 2 * weight;\n    }\n    else {\n      M += weight;\n    }\n\n    if (!graph.hasDirectedEdge(node2, node1))\n      weight *= 2;\n\n    if (community1 === community2)\n      internalW[community1] = (internalW[community1] || 0) + weight;\n  }\n\n  for (community1 in totalW)\n    Q += ((internalW[community1] || 0) - (totalW[community1] * totalW[community1] / M));\n\n  return Q / M;\n}", "label": 3}
{"code": "public function register($class, $resolver, array $parameters = [], Closure $after = null)\n    {\n        return $this->bindings[$class] = $this->createBinding($resolver, $parameters, $after);\n    }", "label": 2}
{"code": "function getOwnerAndGroup(file) {\n  const data = fs.lstatSync(file);\n  const groupname = getGroupname(data.gid, {throwIfNotFound: false}) || null;\n  const username = getUsername(data.uid, {throwIfNotFound: false}) || null;\n  return {uid: data.uid, gid: data.gid, username: username, groupname: groupname};\n}", "label": 3}
{"code": "def adjust_fargate_options(options)\n      task_def = recent_task_definition\n      return options unless task_def[:network_mode] == \"awsvpc\"\n\n      awsvpc_conf = { subnets: network[:ecs_subnets] }\n      if task_def[:requires_compatibilities] == [\"FARGATE\"]\n        awsvpc_conf[:assign_public_ip] = \"ENABLED\"\n        options[:launch_type] = \"FARGATE\"\n      end\n\n      options[:network_configuration] = { awsvpc_configuration: awsvpc_conf }\n      options\n    end", "label": 4}
{"code": "function componentExists(componentPath) {\n  const existsInExtensions = fs.existsSync(path.resolve(EXTENSIONS_PATH, componentPath));\n  const existsInWidgets = fs.existsSync(path.resolve(themes.getPath(), 'widgets', componentPath));\n\n  return !(!existsInExtensions && !existsInWidgets);\n}", "label": 3}
{"code": "function (modules, options, iterationInfo) {\n        // load module into memory (unless `dontLoad` is true)\n\n        var module = true;\n\n        //default is options.dontLoad === false\n        if (options.dontLoad !== true) {\n            //if module is to be loaded\n            module = require(iterationInfo.absoluteFullPath);\n\n            // If a module is found but was loaded as 'undefined', don't include it (since it's probably unusable)\n            if (typeof module === 'undefined') {\n                throw new Error('Invalid module:' + iterationInfo.absoluteFullPath);\n            }\n\n            var identity;\n            //var name;\n            var version;\n\n            if (options.useVersions === true) {\n                if (module.version) {\n                    version = module.version;\n                }\n                else {\n                    version = '1.0';\n                }\n            }\n\n            if (module.identity) {\n                identity = module.identity;\n                //name = identity;\n            }\n            else {\n                identity = generateIdentity(options, iterationInfo);\n                //name = identity;\n            }\n\n            //consider default options.injectIdentity === true\n            if (options.injectIdentity !== false) {\n                module.fileName = iterationInfo.fileName;\n                module.projectDir = iterationInfo.projectDir;\n                module.relativePath = iterationInfo.relativePath;\n                module.relativeFullPath = iterationInfo.relativeFullPath;\n                module.absolutePath = iterationInfo.absolutePath;\n                module.absoluteFullPath = iterationInfo.absoluteFullPath;\n                module.identity = identity;\n                //module.name = name;\n                if (options.useVersions === true) {\n                    module.version = version;\n                }\n            }\n            else {\n                identity = generateIdentity(options, iterationInfo);\n            }\n\n            //check if identity is unique within the collection and add to dictionary\n            if (options.useVersions === true) {\n                if (modules[identity] && modules[identity][version]) {\n                    var anotherModule = modules[identity][version];\n                    throw new Error(\"Identity '\" + identity + \"' with version '\" + version + \"' is already registered by module at '\" + anotherModule.absoluteFullPath + \"'\");\n                }\n                modules[identity] = modules[identity] || {};\n                modules[identity][version] = module;\n            }\n            else {\n                var anotherModule = modules[identity];\n                if (anotherModule) {\n                    throw new Error(\"Identity '\" + identity + \"' is already registered by module at '\" + anotherModule.absoluteFullPath + \"'\");\n                }\n                modules[identity] = module;\n            }\n        }\n    }", "label": 3}
{"code": "def extract_minors_from_setup_py(filename_setup_py):\n    '''Extract supported python minor versions from setup.py and return them\n    as a list of str.\n\n    Return example:\n\n        ['2.6', '2.7', '3.3', '3.4', '3.5', '3.6']\n    '''\n    # eg: minors_str = '2.6\\n2.7\\n3.3\\n3.4\\n3.5\\n3.6'\n    minors_str = fabric.api.local(\n        flo('grep --perl-regexp --only-matching '\n            '\"(?<=Programming Language :: Python :: )\\\\d+\\\\.\\\\d+\" '\n            '{filename_setup_py}'),\n        capture=True)\n    # eg: minors = ['2.6', '2.7', '3.3', '3.4', '3.5', '3.6']\n    minors = minors_str.split()\n    return minors", "label": 1}
{"code": "def add_image(options={})\n      if options[:end_at]\n        TwoCellAnchor.new(self, options).add_pic(options)\n      else\n        OneCellAnchor.new(self, options)\n      end\n      @anchors.last.object\n    end", "label": 4}
{"code": "def deco_args\n      return \"\" if args.empty?\n\n      my_args = args.map do |arg|\n        prefix, default = prefix_and_default(arg[0])\n\n        kls = use_short_style?(arg) ? \"\" : \"##{locals[arg[1]].class}\"\n\n        \"#{prefix}#{arg[1] || default}#{kls}\"\n      end\n\n      \"(#{my_args.join(', ')})\"\n    end", "label": 4}
{"code": "func (a *HistoricalApi) freeContainerMetrics(request *restful.Request, response *restful.Response) {\n\tkey := core.HistoricalKey{\n\t\tObjectType:    core.MetricSetTypeSystemContainer,\n\t\tNodeName:      request.PathParameter(\"node-name\"),\n\t\tContainerName: request.PathParameter(\"container-name\"),\n\t}\n\ta.processMetricRequest(key, request, response)\n}", "label": 5}
{"code": "def roundrectangle(center_x, center_y, width, height, corner_width, corner_height)\n      primitive 'roundrectangle ' + format('%g,%g,%g,%g,%g,%g',\n                                           center_x, center_y, width, height, corner_width, corner_height)\n    end", "label": 4}
{"code": "public function walkSelectStatement(SelectStatement $AST)\n    {\n        if ($this->platformSupportsRowNumber()) {\n            return $this->walkSelectStatementWithRowNumber($AST);\n        }\n\n        return $this->walkSelectStatementWithoutRowNumber($AST);\n    }", "label": 2}
{"code": "func (d directDial) Dial(network string, addr string, config *ssh.ClientConfig) (*ssh.Client, error) {\n\treturn DialWithDeadline(network, addr, config)\n}", "label": 5}
{"code": "def licenses_desc(self):\n        \"\"\"Remove prefix.\"\"\"\n        return {self._acronym_lic(l): l.split(self.prefix_lic)[1]\n                for l in self.resp_text.split('\\n')\n                if l.startswith(self.prefix_lic)}", "label": 1}
{"code": "public static void main(String[] args) throws Exception {\r\n    StringUtils.printErrInvocationString(\"CRFClassifier\", args);\r\n\r\n    Properties props = StringUtils.argsToProperties(args);\r\n    CRFClassifier<CoreLabel> crf = new CRFClassifier<CoreLabel>(props);\r\n    String testFile = crf.flags.testFile;\r\n    String textFile = crf.flags.textFile;\r\n    String loadPath = crf.flags.loadClassifier;\r\n    String loadTextPath = crf.flags.loadTextClassifier;\r\n    String serializeTo = crf.flags.serializeTo;\r\n    String serializeToText = crf.flags.serializeToText;\r\n\r\n    if (loadPath != null) {\r\n      crf.loadClassifierNoExceptions(loadPath, props);\r\n    } else if (loadTextPath != null) {\r\n      System.err.println(\"Warning: this is now only tested for Chinese Segmenter\");\r\n      System.err.println(\"(Sun Dec 23 00:59:39 2007) (pichuan)\");\r\n      try {\r\n        crf.loadTextClassifier(loadTextPath, props);\r\n        // System.err.println(\"DEBUG: out from crf.loadTextClassifier\");\r\n      } catch (Exception e) {\r\n        throw new RuntimeException(\"error loading \" + loadTextPath, e);\r\n      }\r\n    } else if (crf.flags.loadJarClassifier != null) {\r\n      crf.loadJarClassifier(crf.flags.loadJarClassifier, props);\r\n    } else if (crf.flags.trainFile != null || crf.flags.trainFileList != null) {\r\n      crf.train();\r\n    } else {\r\n      crf.loadDefaultClassifier();\r\n    }\r\n\r\n    // System.err.println(\"Using \" + crf.flags.featureFactory);\r\n    // System.err.println(\"Using \" +\r\n    // StringUtils.getShortClassName(crf.readerAndWriter));\r\n\r\n    if (serializeTo != null) {\r\n      crf.serializeClassifier(serializeTo);\r\n    }\r\n\r\n    if (serializeToText != null) {\r\n      crf.serializeTextClassifier(serializeToText);\r\n    }\r\n\r\n    if (testFile != null) {\r\n      DocumentReaderAndWriter<CoreLabel> readerAndWriter = crf.makeReaderAndWriter();\r\n      if (crf.flags.searchGraphPrefix != null) {\r\n        crf.classifyAndWriteViterbiSearchGraph(testFile, crf.flags.searchGraphPrefix, crf.makeReaderAndWriter());\r\n      } else if (crf.flags.printFirstOrderProbs) {\r\n        crf.printFirstOrderProbs(testFile, readerAndWriter);\r\n      } else if (crf.flags.printProbs) {\r\n        crf.printProbs(testFile, readerAndWriter);\r\n      } else if (crf.flags.useKBest) {\r\n        int k = crf.flags.kBest;\r\n        crf.classifyAndWriteAnswersKBest(testFile, k, readerAndWriter);\r\n      } else if (crf.flags.printLabelValue) {\r\n        crf.printLabelInformation(testFile, readerAndWriter);\r\n      } else {\r\n        crf.classifyAndWriteAnswers(testFile, readerAndWriter);\r\n      }\r\n    }\r\n\r\n    if (textFile != null) {\r\n      crf.classifyAndWriteAnswers(textFile);\r\n    }\r\n\r\n    if (crf.flags.readStdin) {\r\n      crf.classifyStdin();\r\n    }\r\n  }", "label": 0}
{"code": "public static systemdatasource[] get(nitro_service service, systemdatasource_args args) throws Exception{\n\t\tsystemdatasource obj = new systemdatasource();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tsystemdatasource[] response = (systemdatasource[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function createReader()\n    {\n        $reader = phpiredis_reader_create();\n\n        phpiredis_reader_set_status_handler($reader, $this->getStatusHandler());\n        phpiredis_reader_set_error_handler($reader, $this->getErrorHandler());\n\n        return $reader;\n    }", "label": 2}
{"code": "function chainHelp(chain) {\n  return chain.validators.map(function(e) {\n                                return e.help;\n                              })\n                         .filter(function(e) {\n                                return e;\n                              });\n}", "label": 3}
{"code": "public function setLikelihood($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dlp\\V2\\Likelihood::class);\n        $this->likelihood = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def days_to_week_start(start_day = Date.beginning_of_week)\n      start_day_number = DAYS_INTO_WEEK.fetch(start_day)\n      (wday - start_day_number) % 7\n    end", "label": 4}
{"code": "public function state(array $options = [])\n    {\n        if (!$this->done($options)) {\n            return self::STATE_IN_PROGRESS;\n        }\n\n        if ($this->done() && $this->result()) {\n            return self::STATE_SUCCESS;\n        }\n\n        return self::STATE_ERROR;\n    }", "label": 2}
{"code": "public static void plotCharts(List<Chart> charts){\n\t\tint numRows =1;\n\t\tint numCols =1;\n\t\tif(charts.size()>1){\n\t\t\tnumRows = (int) Math.ceil(charts.size()/2.0);\n\t\t\tnumCols = 2;\n\t\t}\n\t\t\n\t    final JFrame frame = new JFrame(\"\");\n\t    frame.setDefaultCloseOperation(JFrame.HIDE_ON_CLOSE);\n        frame.getContentPane().setLayout(new GridLayout(numRows, numCols));\n\t    for (Chart chart : charts) {\n\t          if (chart != null) {\n\t            JPanel chartPanel = new XChartPanel(chart);\n\t            frame.add(chartPanel);\n\t          }\n\t          else {\n\t            JPanel chartPanel = new JPanel();\n\t            frame.getContentPane().add(chartPanel);\n\t          }\n\n\t        }\n\t    // Display the window.\n        frame.pack();\n        frame.setVisible(true);\n\t}", "label": 0}
{"code": "def load_image(fname):\n    \"\"\" read an image from file - PIL doesnt close nicely \"\"\"\n    with open(fname, \"rb\") as f:\n        i = Image.open(fname)\n        #i.load()\n        return i", "label": 1}
{"code": "def process_request(env, req, res)\n      start_time = Time.now\n\n      request_path = URI.decode(env['PATH_INFO'].dup)\n      request_path.force_encoding('UTF-8') if request_path.respond_to? :force_encoding\n      request_path = ::Middleman::Util.full_path(request_path, @middleman)\n      full_request_path = File.join(env['SCRIPT_NAME'], request_path) # Path including rack mount\n\n      # Get the resource object for this path\n      resource = @middleman.sitemap.by_destination_path(request_path.gsub(' ', '%20'))\n\n      # Return 404 if not in sitemap\n      return not_found(res, full_request_path) unless resource && !resource.ignored?\n\n      # If this path is a binary file, send it immediately\n      return send_file(resource, env) if resource.binary? || resource.static_file?\n\n      res['Content-Type'] = resource.content_type || 'text/plain'\n\n      begin\n        # Write out the contents of the page\n        res.write resource.render({}, rack: { request: req })\n\n        # Valid content is a 200 status\n        res.status = 200\n      rescue Middleman::TemplateRenderer::TemplateNotFound => e\n        res.write \"Error: #{e.message}\"\n        res.status = 500\n      end\n\n      # End the request\n      logger.debug \"== Finishing Request: #{resource.destination_path} (#{(Time.now - start_time).round(2)}s)\"\n      halt res.finish\n    end", "label": 4}
{"code": "func (c *CertAuthorityV2) TLSCA() (*tlsca.CertAuthority, error) {\n\tif len(c.Spec.TLSKeyPairs) == 0 {\n\t\treturn nil, trace.BadParameter(\"no TLS key pairs found for certificate authority\")\n\t}\n\treturn tlsca.New(c.Spec.TLSKeyPairs[0].Cert, c.Spec.TLSKeyPairs[0].Key)\n}", "label": 5}
{"code": "def validate_price(price):\n\t\"\"\" validation checks for price argument \"\"\"\n\tif isinstance(price, str):\n\t\ttry:\n\t\t\tprice = int(price)\n\t\texcept ValueError: # fallback if convert to int failed\n\t\t\tprice = float(price)\n\tif not isinstance(price, (int, float)):\n\t\traise TypeError('Price should be a number: ' + repr(price))\n\treturn price", "label": 1}
{"code": "func lookupNetworkID(cli *NetworkCli, nameID string) (string, error) {\n\tobj, statusCode, err := readBody(cli.call(\"GET\", \"/networks?name=\"+nameID, nil, nil))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif statusCode != http.StatusOK {\n\t\treturn \"\", fmt.Errorf(\"name query failed for %s due to : statuscode(%d) %v\", nameID, statusCode, string(obj))\n\t}\n\n\tvar list []*networkResource\n\terr = json.Unmarshal(obj, &list)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif len(list) > 0 {\n\t\t// name query filter will always return a single-element collection\n\t\treturn list[0].ID, nil\n\t}\n\n\t// Check for Partial-id\n\tobj, statusCode, err = readBody(cli.call(\"GET\", \"/networks?partial-id=\"+nameID, nil, nil))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif statusCode != http.StatusOK {\n\t\treturn \"\", fmt.Errorf(\"partial-id match query failed for %s due to : statuscode(%d) %v\", nameID, statusCode, string(obj))\n\t}\n\n\terr = json.Unmarshal(obj, &list)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif len(list) == 0 {\n\t\treturn \"\", fmt.Errorf(\"resource not found %s\", nameID)\n\t}\n\tif len(list) > 1 {\n\t\treturn \"\", fmt.Errorf(\"multiple Networks matching the partial identifier (%s). Please use full identifier\", nameID)\n\t}\n\treturn list[0].ID, nil\n}", "label": 5}
{"code": "def sort_sam(sam, sort):\n    \"\"\"\n    sort sam file\n    \"\"\"\n    tempdir = '%s/' % (os.path.abspath(sam).rsplit('/', 1)[0])\n    if sort is True:\n        mapping = '%s.sorted.sam' % (sam.rsplit('.', 1)[0])\n        if sam != '-':\n            if os.path.exists(mapping) is False:\n                os.system(\"\\\n                    sort -k1 --buffer-size=%sG -T %s -o %s %s\\\n                    \" % (sbuffer, tempdir, mapping, sam)) \n        else:\n            mapping = 'stdin-sam.sorted.sam'\n            p = Popen(\"sort -k1 --buffer-size=%sG -T %s -o %s\" \\\n                    % (sbuffer, tempdir, mapping), stdin = sys.stdin, shell = True) \n            p.communicate()\n        mapping = open(mapping)\n    else:\n        if sam == '-':\n            mapping = sys.stdin\n        else:\n            mapping = open(sam)\n    return mapping", "label": 1}
{"code": "function (filePath) {\n                    var\n                        me = this,\n                        extName = _path.extname(filePath).toLowerCase(),\n                        size,\n                        stream;\n                    _fs.stat(filePath, function (err, stats) {\n                        var mimeType;\n                        if (err) {\n                            me._response.plain(500,\n                                \"Unable to access file (\" + err + \")\");\n                            return;\n                        }\n                        if (stats.isDirectory()) {\n                            me._response.plain(200, \"Directory.\");\n                            return;\n                        } else if (!stats.isFile()) {\n                            me._response.plain(200, \"Not a file.\");\n                            return;\n                        }\n                        size = stats.size;\n                        mimeType = gpf.http.getMimeType(extName);\n                        if (me._options.verbose) {\n                            console.log(\"\\tMime type  : \" + mimeType);\n                            console.log(\"\\tFile size  : \" + size);\n                        }\n                        me._response.writeHead(200, {\n                            \"content-type\": mimeType,\n                            \"content-length\": size\n                        });\n                        stream = _fs.createReadStream(filePath);\n                        //stream.on(\"data\", function (chunk) {\n                        //    if (!me._response.write(chunk)) {\n                        //        stream.pause();\n                        //        me._response.once(\"drain\", function () {\n                        //            stream.resume();\n                        //        });\n                        //    }\n                        //});\n                        stream.on(\"end\", function () {\n                            if (me._options.verbose) {\n                                console.log(\"\\tEnd      t+: \"\n                                + ((new Date()) - me._startTimeStamp)\n                                + \"ms\");\n                            }\n                            me._response.statusCode = 200;\n                            me._response.end();\n                        });\n                        stream.pipe(me._response);\n                    });\n                }", "label": 3}
{"code": "func ApplyOSTweaks(osConfig map[string]*OSValue) {\n\tfor k, v := range osConfig {\n\t\t// read the existing property from disk\n\t\toldv, err := readSystemProperty(k)\n\t\tif err != nil {\n\t\t\tlogrus.WithError(err).Errorf(\"error reading the kernel parameter %s\", k)\n\t\t\tcontinue\n\t\t}\n\n\t\tif propertyIsValid(oldv, v.Value, v.CheckFn) {\n\t\t\t// write new prop value to disk\n\t\t\tif err := writeSystemProperty(k, v.Value); err != nil {\n\t\t\t\tlogrus.WithError(err).Errorf(\"error setting the kernel parameter %s = %s, (leaving as %s)\", k, v.Value, oldv)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tlogrus.Debugf(\"updated kernel parameter %s = %s (was %s)\", k, v.Value, oldv)\n\t\t}\n\t}\n}", "label": 5}
{"code": "def raster_field(self):\n        \"\"\"Returns the raster FileField instance on the model.\"\"\"\n        for field in self.model._meta.fields:\n            if isinstance(field, models.FileField):\n                return field\n        return False", "label": 1}
{"code": "def list(self, filter=None, type=None, sort=None, limit=None, page=None): # pylint: disable=redefined-builtin\n        \"\"\"Get a list of configs.\n\n        :param filter: (optional) Filters to apply as a string list.\n        :param type: (optional) `union` or `inter` as string.\n        :param sort: (optional) Sort fields to apply as string list.\n        :param limit: (optional) Limit returned list length.\n        :param page: (optional) Page to return.\n        :return: :class:`configs.Page <configs.Page>` object\n        \"\"\"\n        schema = self.LIST_SCHEMA\n        resp = self.service.list(self.base, filter, type, sort, limit, page)\n        cs, l = self.service.decode(schema, resp, many=True, links=True)\n        return Page(cs, l)", "label": 1}
{"code": "public function get($type, EntryQueryOptions $options)\n    {\n        return EntryModel::on($this->connection)\n            ->withTelescopeOptions($type, $options)\n            ->take($options->limit)\n            ->orderByDesc('sequence')\n            ->get()->reject(function ($entry) {\n                return ! is_array($entry->content);\n            })->map(function ($entry) {\n                return new EntryResult(\n                    $entry->uuid,\n                    $entry->sequence,\n                    $entry->batch_id,\n                    $entry->type,\n                    $entry->family_hash,\n                    $entry->content,\n                    $entry->created_at,\n                    []\n                );\n            })->values();\n    }", "label": 2}
{"code": "def _multiple_field(cls):\n        \"\"\"Return the \"multiple\" TypedField associated with this EntityList.\n\n        This also lazily sets the ``_entitylist_multiplefield`` value if it\n        hasn't been set yet. This is set to a tuple containing one item because\n        if we set the class attribute to the TypedField, we would effectively\n        add a TypedField descriptor to the class, which we don't want.\n\n        Raises:\n            AssertionError: If there is more than one multiple TypedField\n                or the the TypedField type_ is not a subclass of Entity.\n        \"\"\"\n        klassdict = cls.__dict__\n\n        try:\n            # Checking for cls.entitylist_multifield would return any inherited\n            # values, so we check the class __dict__ explicitly.\n            return klassdict[\"_entitylist_multifield\"][0]\n        except (KeyError, IndexError, TypeError):\n            from . import fields\n            multifield_tuple = tuple(fields.find(cls, multiple=True))\n            assert len(multifield_tuple) == 1\n\n            # Make sure that the multiple field actually has an Entity type.\n            multifield = multifield_tuple[0]\n            assert issubclass(multifield.type_, Entity)\n\n            # Store aside the multiple field. We wrap it in a tuple because\n            # just doing ``cls._entitylist_multifield = multifield`` would\n            # assign another TypedField descriptor to this class. We don't\n            # want that.\n            cls._entitylist_multifield =  multifield_tuple\n\n            # Return the multiple TypedField\n            return multifield_tuple[0]", "label": 1}
{"code": "private function extractHeader(\n        $name,\n        Shape $shape,\n        ResponseInterface $response,\n        &$result\n    ) {\n        $value = $response->getHeaderLine($shape['locationName'] ?: $name);\n\n        switch ($shape->getType()) {\n            case 'float':\n            case 'double':\n                $value = (float) $value;\n                break;\n            case 'long':\n                $value = (int) $value;\n                break;\n            case 'boolean':\n                $value = filter_var($value, FILTER_VALIDATE_BOOLEAN);\n                break;\n            case 'blob':\n                $value = base64_decode($value);\n                break;\n            case 'timestamp':\n                try {\n                    if (!empty($shape['timestampFormat'])\n                        && $shape['timestampFormat'] === 'unixTimestamp') {\n                        $value = DateTimeResult::fromEpoch($value);\n                    }\n                    $value = new DateTimeResult($value);\n                    break;\n                } catch (\\Exception $e) {\n                    // If the value cannot be parsed, then do not add it to the\n                    // output structure.\n                    return;\n                }\n            case 'string':\n                if ($shape['jsonvalue']) {\n                    $value = $this->parseJson(base64_decode($value), $response);\n                }\n                break;\n        }\n\n        $result[$name] = $value;\n    }", "label": 2}
{"code": "def browse_catalog_for_a_template(catalog_path, template_name)\n      template_path = catalog_path.join(template_name)\n\n      if Dir.exist?(template_path)\n        return template_path\n      end\n\n      return nil\n    end", "label": 4}
{"code": "public function setExpressions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->expressions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def to_s\n      arr = []\n      if freq = @hash.delete('FREQ')\n        arr << \"FREQ=#{freq.join(',')}\"\n      end\n      arr.concat(@hash.map do |key, value|\n        if value.is_a?(Array)\n          \"#{key}=#{value.join(',')}\"\n        end\n      end.compact)\n      arr.join(';')\n    end", "label": 4}
{"code": "function(options) {\n    options = options || {};\n    if (!('pull' in options)) options.pull = true;\n\n    // no pull means no extra stream processing...\n    if (!options.pull) return this._run();\n\n    return new Promise(function(accept, reject) {\n      // pull the image (or use on in the cache and output status in stdout)\n      var pullStream =\n        utils.pullImageIfMissing(this.docker, this._createConfig.Image);\n\n      // pipe the pull stream into stdout but don't end\n      pullStream.pipe(this.stdout, { end: false });\n\n      pullStream.once('error', reject);\n      pullStream.once('end', function() {\n        pullStream.removeListener('error', reject);\n        this._run().then(accept, reject);\n      }.bind(this));\n    }.bind(this));\n  }", "label": 3}
{"code": "public List<List<IN>> classifyRaw(String str,\r\n                                    DocumentReaderAndWriter<IN> readerAndWriter) {\r\n    ObjectBank<List<IN>> documents =\r\n      makeObjectBankFromString(str, readerAndWriter);\r\n    List<List<IN>> result = new ArrayList<List<IN>>();\r\n\r\n    for (List<IN> document : documents) {\r\n      classify(document);\r\n\r\n      List<IN> sentence = new ArrayList<IN>();\r\n      for (IN wi : document) {\r\n        // TaggedWord word = new TaggedWord(wi.word(), wi.answer());\r\n        // sentence.add(word);\r\n        sentence.add(wi);\r\n      }\r\n      result.add(sentence);\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "function(request) {\n    return new Promise((resolve, reject) => {\n      this._start()\n          .uri('/api/system/audit-log/search')\n          .setJSONBody(request)\n          .post()\n          .go(this._responseHandler(resolve, reject));\n    });\n  }", "label": 3}
{"code": "def _is_under_root(self, full_path):\n        \"\"\"Guard against arbitrary file retrieval.\"\"\"\n        if (path.abspath(full_path) + path.sep)\\\n                .startswith(path.abspath(self.root) + path.sep):\n            return True\n        else:\n            return False", "label": 1}
{"code": "function convertApiError(err) {\n\tif (err.error && err.error.response && err.error.response.text) {\n\t\tconst obj = JSON.parse(err.error.response.text);\n\t\tif (obj.errors && obj.errors.length) {\n\t\t\terr = { message: obj.errors[0].message, error:err.error };\n\t\t}\n\t}\n\treturn err;\n}", "label": 3}
{"code": "func New(instance *ServiceInstance) *Service {\n\ts := &Service{\n\t\treadAll: ioutil.ReadAll,\n\t\tsm:      Map.SessionManager(),\n\t\tsdk:     make(map[string]*Registry),\n\t}\n\n\ts.client, _ = vim25.NewClient(context.Background(), s)\n\n\treturn s\n}", "label": 5}
{"code": "def iter_instances(self):\n        \"\"\"Iterate over the stored objects\n\n        Yields:\n            wrkey: The two-tuple key used to store the object\n            obj: The instance or function object\n        \"\"\"\n        for wrkey in set(self.keys()):\n            obj = self.get(wrkey)\n            if obj is None:\n                continue\n            yield wrkey, obj", "label": 1}
{"code": "private static int getTrimmedYStart(BufferedImage img) {\n    int width = img.getWidth();\n    int height = img.getHeight();\n    int yStart = height;\n\n    for (int i = 0; i < width; i++) {\n      for (int j = 0; j < height; j++) {\n        if (img.getRGB(i, j) != Color.WHITE.getRGB() && j < yStart) {\n          yStart = j;\n          break;\n        }\n      }\n    }\n\n    return yStart;\n  }", "label": 0}
{"code": "public function reportBreakpoints(array $breakpointsInfo)\n    {\n        $client = $this->defaultClient();\n        foreach ($breakpointsInfo as $breakpointInfo) {\n            list($debuggeeId, $breakpoint) = $breakpointInfo;\n            $debuggee = $client->debuggee($debuggeeId);\n\n            $backoff = new ExponentialBackoff();\n            try {\n                $backoff->execute(function () use ($breakpoint, $debuggee) {\n                    $debuggee->updateBreakpoint($breakpoint);\n                });\n            } catch (ServiceException $e) {\n                // Ignore this error for now\n            }\n        }\n    }", "label": 2}
{"code": "protected long getUniqueLong(FieldDescriptor field) throws SequenceManagerException\r\n    {\r\n        boolean needsCommit = false;\r\n        long result = 0;\r\n        /*\r\n        arminw:\r\n        use the associated broker instance, check if broker was in tx or\r\n        we need to commit used connection.\r\n        */\r\n        PersistenceBroker targetBroker = getBrokerForClass();\r\n        if(!targetBroker.isInTransaction())\r\n        {\r\n            targetBroker.beginTransaction();\r\n            needsCommit = true;\r\n        }\r\n        try\r\n        {\r\n            // lookup sequence name\r\n            String sequenceName = calculateSequenceName(field);\r\n            try\r\n            {\r\n                result = buildNextSequence(targetBroker, field.getClassDescriptor(), sequenceName);\r\n                /*\r\n                if 0 was returned we assume that the stored procedure\r\n                did not work properly.\r\n                */\r\n                if (result == 0)\r\n                {\r\n                    throw new SequenceManagerException(\"No incremented value retrieved\");\r\n                }\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                // maybe the sequence was not created\r\n                log.info(\"Could not grab next key, message was \" + e.getMessage() +\r\n                        \" - try to write a new sequence entry to database\");\r\n                try\r\n                {\r\n                    // on create, make sure to get the max key for the table first\r\n                    long maxKey = SequenceManagerHelper.getMaxForExtent(targetBroker, field);\r\n                    createSequence(targetBroker, field, sequenceName, maxKey);\r\n                }\r\n                catch (Exception e1)\r\n                {\r\n                    String eol = SystemUtils.LINE_SEPARATOR;\r\n                    throw new SequenceManagerException(eol + \"Could not grab next id, failed with \" + eol +\r\n                            e.getMessage() + eol + \"Creation of new sequence failed with \" +\r\n                            eol + e1.getMessage() + eol, e1);\r\n                }\r\n                try\r\n                {\r\n                    result = buildNextSequence(targetBroker, field.getClassDescriptor(), sequenceName);\r\n                }\r\n                catch (Exception e1)\r\n                {\r\n                    throw new SequenceManagerException(\"Could not grab next id although a sequence seems to exist\", e);\r\n                }\r\n            }\r\n        }\r\n        finally\r\n        {\r\n            if(targetBroker != null && needsCommit)\r\n            {\r\n                targetBroker.commitTransaction();\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def parse_retry_after_header(header_value)\n      retry_after = begin\n                      Integer(header_value)\n                    rescue TypeError, ArgumentError\n                      begin\n                        DateTime.rfc2822(header_value)\n                      rescue ArgumentError\n                        return nil\n                      end\n                    end\n\n      case retry_after\n      when Integer\n        retry_after\n      when DateTime\n        sleep = (retry_after.to_time - DateTime.now.to_time).to_i\n        (sleep > 0) ? sleep : 0\n      end\n    end", "label": 4}
{"code": "func (b *BoxLayout) SetOrientation(orient Orientation) {\n\tif b.orient != orient {\n\t\tb.orient = orient\n\t\tb.changed = true\n\t\tb.PostEventWidgetContent(b)\n\t}\n}", "label": 5}
{"code": "def slugify(value):\n    \"\"\"\n    Normalizes string, converts to lowercase, removes non-alpha characters,\n    and converts spaces to hyphens to have nice filenames.\n\n    From Django's \"django/template/defaultfilters.py\".\n\n    >>> slugify(\"El ping\u00fcino Wenceslao hizo kil\u00f3metros bajo exhaustiva lluvia y fr\u00edo, a\u00f1oraba a su querido cachorro. ortez ce vieux whisky au juge blond qui fume sur son \u00eele int\u00e9rieure, \u00e0 \u0393\u03b1\u03b6\u03ad\u03b5\u03c2 \u03ba\u03b1\u1f76 \u03bc\u03c5\u03c1\u03c4\u03b9\u1f72\u03c2 \u03b4\u1f72\u03bd \u03b8\u1f70 \u03b2\u03c1\u1ff6 \u03c0\u03b9\u1f70 \u03c3\u03c4\u1f78 \u03c7\u03c1\u03c5\u03c3\u03b1\u03c6\u1f76 \u03be\u03ad\u03c6\u03c9\u03c4\u03bf \u3044\u308d\u306f\u306b\u307b\u3078\u3068\u3061\u308a\u306c\u308b\u3092 Pchn\u0105\u0107 w t\u0119 \u0142\u00f3d\u017a je\u017ca lub o\u015bm skrzy\u0144 fig \u0e01\u0e27\u0e48\u0e32\u0e1a\u0e23\u0e23\u0e14\u0e32\u0e1d\u0e39\u0e07\u0e2a\u0e31\u0e15\u0e27\u0e4c\u0e40\u0e14\u0e23\u0e31\u0e08\u0e09\u0e32\u0e19\")\n    'El_pinguino_Wenceslao_hizo_kilometros_bajo_exhaustiva_lluvia_y_frio_anoraba_a_su_querido_cachorro_ortez_ce_vieux_whisky_au_juge_blond_qui_fume_sur_son_ile_interieure_a_Pchnac_w_te_odz_jeza_lub_osm_skrzyn_fig'\n    \"\"\"\n    try:\n        unicode_type = unicode\n    except NameError:\n        unicode_type = str\n    if not isinstance(value, unicode_type):\n        value = unicode_type(value)\n    value = (unicodedata.normalize('NFKD', value).\n             encode('ascii', 'ignore').decode('ascii'))\n    value = unicode_type(_SLUGIFY_STRIP_RE.sub('', value).strip())\n    return _SLUGIFY_HYPHENATE_RE.sub('_', value)", "label": 1}
{"code": "func (c *Manager) GetLibraryByName(ctx context.Context, name string) (*Library, error) {\n\t// Lookup by name\n\tlibraries, err := c.GetLibraries(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor i := range libraries {\n\t\tif libraries[i].Name == name {\n\t\t\treturn &libraries[i], nil\n\t\t}\n\t}\n\treturn nil, fmt.Errorf(\"library name (%s) not found\", name)\n}", "label": 5}
{"code": "def _to_hash(value)\n      if value.is_a?(Array)\n        value.compact.map{ |v| _to_hash(v) }\n      elsif value.is_a?(Hash)\n        {}.tap do |hash|\n          value.each { |k, v| hash[k] = _to_hash(v) }\n        end\n      elsif value.respond_to? :to_hash\n        value.to_hash\n      else\n        value\n      end\n    end", "label": 4}
{"code": "protected function unpublishAssets(Extension $extension)\n    {\n        $this->filesystem->deleteDirectory($this->app->publicPath().'/assets/extensions/'.$extension->getId());\n    }", "label": 2}
{"code": "def get_relative_abundance(biomfile):\n    \"\"\"\n    Return arcsine transformed relative abundance from a BIOM format file.\n\n    :type biomfile: BIOM format file\n    :param biomfile: BIOM format file used to obtain relative abundances for each OTU in\n                     a SampleID, which are used as node sizes in network plots.\n\n    :type return: Dictionary of dictionaries.\n    :return: Dictionary keyed on SampleID whose value is a dictionarykeyed on OTU Name\n             whose value is the arc sine tranfsormed relative abundance value for that\n             SampleID-OTU Name pair.\n    \"\"\"\n    biomf = biom.load_table(biomfile)\n    norm_biomf = biomf.norm(inplace=False)\n    rel_abd = {}\n    for sid in norm_biomf.ids():\n        rel_abd[sid] = {}\n        for otuid in norm_biomf.ids(\"observation\"):\n            otuname = oc.otu_name(norm_biomf.metadata(otuid, axis=\"observation\")[\"taxonomy\"])\n            otuname = \" \".join(otuname.split(\"_\"))\n            abd = norm_biomf.get_value_by_ids(otuid, sid)\n            rel_abd[sid][otuname] = abd\n    ast_rel_abd = bc.arcsine_sqrt_transform(rel_abd)\n    return ast_rel_abd", "label": 1}
{"code": "public function version($version, $second, $third = null)\n    {\n        if (func_num_args() == 2) {\n            list($version, $callback, $attributes) = array_merge(func_get_args(), [[]]);\n        } else {\n            list($version, $attributes, $callback) = func_get_args();\n        }\n\n        $attributes = array_merge($attributes, ['version' => $version]);\n\n        $this->group($attributes, $callback);\n    }", "label": 2}
{"code": "func (h *Heartbeat) fetch() error {\n\t// failed to fetch server info?\n\t// reset to init state regardless of the current state\n\tserver, err := h.GetServerInfo()\n\tif err != nil {\n\t\th.reset(HeartbeatStateInit)\n\t\treturn trace.Wrap(err)\n\t}\n\tswitch h.state {\n\t// in case of successfull state fetch, move to announce from init\n\tcase HeartbeatStateInit:\n\t\th.current = server\n\t\th.reset(HeartbeatStateAnnounce)\n\t\treturn nil\n\t\t// nothing to do in announce state\n\tcase HeartbeatStateAnnounce:\n\t\treturn nil\n\tcase HeartbeatStateAnnounceWait:\n\t\t// time to announce\n\t\tif h.Clock.Now().UTC().After(h.nextAnnounce) {\n\t\t\th.current = server\n\t\t\th.reset(HeartbeatStateAnnounce)\n\t\t\treturn nil\n\t\t}\n\t\tresult := services.CompareServers(h.current, server)\n\t\t// server update happened, time to announce\n\t\tif result == services.Different {\n\t\t\th.current = server\n\t\t\th.reset(HeartbeatStateAnnounce)\n\t\t}\n\t\treturn nil\n\t\t// nothing to do in keep alive state\n\tcase HeartbeatStateKeepAlive:\n\t\treturn nil\n\t\t// Stay in keep alive state in case\n\t\t// if there are no changes\n\tcase HeartbeatStateKeepAliveWait:\n\t\t// time to send a new keep alive\n\t\tif h.Clock.Now().UTC().After(h.nextKeepAlive) {\n\t\t\th.setState(HeartbeatStateKeepAlive)\n\t\t\treturn nil\n\t\t}\n\t\tresult := services.CompareServers(h.current, server)\n\t\t// server update happened, move to announce\n\t\tif result == services.Different {\n\t\t\th.current = server\n\t\t\th.reset(HeartbeatStateAnnounce)\n\t\t}\n\t\treturn nil\n\tdefault:\n\t\treturn trace.BadParameter(\"unsupported state: %v\", h.state)\n\t}\n}", "label": 5}
{"code": "public function setRedactionColor($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Color::class);\n        $this->redaction_color = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def load_class_by_name(name: str):\n    \"\"\"Given a dotted path, returns the class\"\"\"\n    mod_path, _, cls_name = name.rpartition('.')\n    mod = importlib.import_module(mod_path)\n    cls = getattr(mod, cls_name)\n    return cls", "label": 1}
{"code": "func (c *remoteConn) ChannelConn(channel ssh.Channel) net.Conn {\n\treturn utils.NewChConn(c.sconn, channel)\n}", "label": 5}
{"code": "def orthonorm_check(a, tol=_DEF.ORTHONORM_TOL, report=False):\n    \"\"\"Checks orthonormality of the column vectors of a matrix.\n\n    If a one-dimensional |nparray| is passed to `a`, it is treated as a single\n    column vector, rather than a row matrix of length-one column vectors.\n\n    The matrix `a` does not need to be square, though it must have at least\n    as many rows as columns, since orthonormality is only possible in N-space\n    with a set of no more than N vectors. (This condition is not directly\n    checked.)\n\n    Parameters\n    ----------\n    a\n        R x S |npfloat_| --\n        2-D array of column vectors to be checked for orthonormality.\n\n    tol\n        |npfloat_|, optional --\n        Tolerance for deviation of dot products from one or zero. Default\n        value is :data:`opan.const.DEF.ORTHONORM_TOL`.\n\n    report\n        |bool|, optional --\n        Whether to record and return vectors / vector pairs failing the\n        orthonormality condition. Default is |False|.\n\n    Returns\n    -------\n    o\n        |bool| --\n        Indicates whether column vectors of `a` are orthonormal to within\n        tolerance `tol`.\n\n    n_fail\n        |list| of |int|, or |None| --\n\n        If `report` == |True|:\n\n            A list of indices of column vectors\n            failing the normality condition, or an empty list if all vectors\n            are normalized.\n\n        If `report` == |False|:\n\n            |None|\n\n    o_fail\n        |list| of 2-tuples of |int|, or |None| --\n\n        If `report` == |True|:\n\n            A list of 2-tuples of indices of\n            column vectors failing the orthogonality condition, or an\n            empty list if all vectors are orthogonal.\n\n        If `report` == |False|:\n\n            |None|\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from .base import delta_fxn\n\n    #!TODO? orthonorm_check Must add traps to ensure a is a single array,\n    #    that it is 2D, that it's all real? To enforce the limits stated\n    #    in the docstring?\n\n    # Initialize return variables\n    orth = True\n    n_fail = []\n    o_fail = []\n\n    # Coerce to float_ matrix. Must treat 1-D vector as column vector.\n    #  Should raise an exception for any objects with more than\n    #  two dimensions; real and all-numeric are still not yet checked, but\n    #  will probably be run-time caught if too bad an object is passed.\n    if len(a.shape) == 1:\n        a_mx = np.matrix(a, dtype=np.float_).T\n    else:\n        a_mx = np.matrix(a, dtype=np.float_)\n\n    # Split matrix into separate vectors for convenient indexing.\n    a_split = np.hsplit(a_mx, a_mx.shape[1])\n\n    # Loop over vectors and check orthonormality.\n    for iter1 in range(a_mx.shape[1]):\n        for iter2 in range(iter1,a_mx.shape[1]):\n            if not abs((a_split[iter1].T * a_split[iter2])[0,0] -\n                        np.float_(delta_fxn(iter1, iter2))) <= tol:\n                orth = False\n                if report:\n                    if iter1 == iter2:\n                        n_fail.append(iter1)\n                    else:\n                        o_fail.append((iter1, iter2))\n\n    # Return results\n    if report:\n        return orth, n_fail, o_fail\n    else:\n        return orth, None, None", "label": 1}
{"code": "def entries(self):\n\t\t\"\"\"\n\t\tUsing the table structure, return the array of entries based\n\t\ton the table size.\n\t\t\"\"\"\n\t\ttable = self.get_table()\n\t\tentries_array = self.row_structure * table.num_entries\n\t\tpointer_type = ctypes.POINTER(entries_array)\n\t\treturn ctypes.cast(table.entries, pointer_type).contents", "label": 1}
{"code": "function (width, baseline, alignCorrection, rotation, align) {\n\n                var costheta = rotation ? mathCos(rotation * deg2rad) : 1,\n                  sintheta = rotation ? mathSin(rotation * deg2rad) : 0,\n                  height = pick(this.elemHeight, this.element.offsetHeight),\n                  quad,\n                  nonLeft = align && align !== 'left';\n\n                // correct x and y\n                this.xCorr = costheta < 0 && -width;\n                this.yCorr = sintheta < 0 && -height;\n\n                // correct for baseline and corners spilling out after rotation\n                quad = costheta * sintheta < 0;\n                this.xCorr += sintheta * baseline * (quad ? 1 - alignCorrection : alignCorrection);\n                this.yCorr -= costheta * baseline * (rotation ? (quad ? alignCorrection : 1 - alignCorrection) : 1);\n                // correct for the length/height of the text\n                if (nonLeft) {\n                    this.xCorr -= width * alignCorrection * (costheta < 0 ? -1 : 1);\n                    if (rotation) {\n                        this.yCorr -= height * alignCorrection * (sintheta < 0 ? -1 : 1);\n                    }\n                    css(this.element, {\n                        textAlign: align\n                    });\n                }\n            }", "label": 3}
{"code": "protected DataSource getDataSource(JdbcConnectionDescriptor jcd)\r\n            throws LookupException\r\n    {\r\n        final PBKey key = jcd.getPBKey();\r\n        DataSource ds = (DataSource) dsMap.get(key);\r\n        if (ds == null)\r\n        {\r\n            // Found no pool for PBKey\r\n            try\r\n            {\r\n                synchronized (poolSynch)\r\n                {\r\n                    // Setup new object pool\r\n                    ObjectPool pool = setupPool(jcd);\r\n                    poolMap.put(key, pool);\r\n                    // Wrap the underlying object pool as DataSource\r\n                    ds = wrapAsDataSource(jcd, pool);\r\n                    dsMap.put(key, ds);\r\n                }\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                log.error(\"Could not setup DBCP DataSource for \" + jcd, e);\r\n                throw new LookupException(e);\r\n            }\r\n        }\r\n        return ds;\r\n    }", "label": 0}
{"code": "def commit_transaction(options=nil)\n      check_if_ended!\n      check_if_no_transaction!\n\n      if within_states?(TRANSACTION_ABORTED_STATE)\n        raise Mongo::Error::InvalidTransactionOperation.new(\n          Mongo::Error::InvalidTransactionOperation.cannot_call_after_msg(\n            :abortTransaction, :commitTransaction))\n      end\n\n      options ||= {}\n\n      begin\n        # If commitTransaction is called twice, we need to run the same commit\n        # operation again, so we revert the session to the previous state.\n        if within_states?(TRANSACTION_COMMITTED_STATE)\n          @state = @last_commit_skipped ? STARTING_TRANSACTION_STATE : TRANSACTION_IN_PROGRESS_STATE\n          @already_committed = true\n        end\n\n        if starting_transaction?\n          @last_commit_skipped = true\n        else\n          @last_commit_skipped = false\n\n          write_concern = options[:write_concern] || txn_options[:write_concern]\n          if write_concern && !write_concern.is_a?(WriteConcern::Base)\n            write_concern = WriteConcern.get(write_concern)\n          end\n          write_with_retry(self, write_concern, true) do |server, txn_num, is_retry|\n            if is_retry\n              if write_concern\n                wco = write_concern.options.merge(w: :majority)\n                wco[:wtimeout] ||= 10000\n                write_concern = WriteConcern.get(wco)\n              else\n                write_concern = WriteConcern.get(w: :majority, wtimeout: 10000)\n              end\n            end\n            Operation::Command.new(\n              selector: { commitTransaction: 1 },\n              db_name: 'admin',\n              session: self,\n              txn_num: txn_num,\n              write_concern: write_concern,\n            ).execute(server)\n          end\n        end\n      rescue Mongo::Error::NoServerAvailable, Mongo::Error::SocketError => e\n        e.send(:add_label, Mongo::Error::UNKNOWN_TRANSACTION_COMMIT_RESULT_LABEL)\n        raise e\n      rescue Mongo::Error::OperationFailure => e\n        err_doc = e.instance_variable_get(:@result).send(:first_document)\n\n        if e.write_retryable? || (err_doc['writeConcernError'] &&\n            !UNLABELED_WRITE_CONCERN_CODES.include?(err_doc['writeConcernError']['code']))\n          e.send(:add_label, Mongo::Error::UNKNOWN_TRANSACTION_COMMIT_RESULT_LABEL)\n        end\n\n        raise e\n      ensure\n        @state = TRANSACTION_COMMITTED_STATE\n      end\n    end", "label": 4}
{"code": "private function formatMessage(array $message)\n    {\n        if (isset($message['data']) && $this->encode) {\n            $message['data'] = base64_encode($message['data']);\n        }\n\n        if (!array_key_exists('data', $message) &&\n            !array_key_exists('attributes', $message)) {\n            throw new InvalidArgumentException('At least one of $data or\n                $attributes must be specified on each message, but neither\n                was given.');\n        }\n\n        return $message;\n    }", "label": 2}
{"code": "def recreate(cls, *args, **kwargs):\n        \"\"\"Recreate the class based in your args, multiple uses\"\"\"\n        cls.check_arguments(kwargs)\n        first_is_callable = True if any(args) and callable(args[0]) else False\n        signature = cls.default_arguments()\n        allowed_arguments = {k: v for k, v in kwargs.items() if k in signature}\n        if (any(allowed_arguments) or any(args)) and not first_is_callable:\n            if any(args) and not first_is_callable:\n                return cls(args[0], **allowed_arguments)\n            elif any(allowed_arguments):\n                return cls(**allowed_arguments)\n\n        return cls.instances[-1] if any(cls.instances) else cls()", "label": 1}
{"code": "public function setPartitionedDml($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\V1\\TransactionOptions_PartitionedDml::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def sort_generators(self):\n        \"\"\" Reorders the list of generators according to bus index.\n        \"\"\"\n        self.generators.sort(key=lambda gn: gn.bus._i)", "label": 1}
{"code": "def v1_upgrade(dir)\n      @logger.debug(\"Upgrading box in directory: #{dir}\")\n\n      temp_dir = Pathname.new(Dir.mktmpdir(TEMP_PREFIX, @temp_root))\n      @logger.debug(\"Temporary directory for upgrading: #{temp_dir}\")\n\n      # Move all the things into the temporary directory\n      dir.children(true).each do |child|\n        # Don't move the temp_dir\n        next if child == temp_dir\n\n        # Move every other directory into the temporary directory\n        @logger.debug(\"Copying to upgrade directory: #{child}\")\n        FileUtils.mv(child, temp_dir.join(child.basename))\n      end\n\n      # If there is no metadata.json file, make one, since this is how\n      # we determine if the box is a V2 box.\n      metadata_file = temp_dir.join(\"metadata.json\")\n      if !metadata_file.file?\n        metadata_file.open(\"w\") do |f|\n          f.write(JSON.generate({\n            provider: \"virtualbox\"\n          }))\n        end\n      end\n\n      # Return the temporary directory\n      temp_dir\n    end", "label": 4}
{"code": "function(value, attr, pattern, model) {\n        if (!hasValue(value) || !value.toString().match(defaultPatterns[pattern] || pattern)) {\n          return this.format(getMessageKey(this.msgKey, defaultMessages[pattern]) || defaultMessages.inlinePattern, this.formatLabel(attr, model), pattern);\n        }\n      }", "label": 3}
{"code": "function(model) {\n      if (!model) {\n        this.__cache = {};\n        _.each(this.getTrackedModels(), function(model) {\n          if (model) {\n            this.__updateCache(model);\n          }\n        }, this);\n      } else {\n        this.__cache[model.cid] = this.__generateHashValue(model);\n      }\n    }", "label": 3}
{"code": "async def root_message(self, msg, msg_type=None):\n        \"\"\"\n        Root-level message. First entry in the archive.\n        Archive headers processing\n\n        :return:\n        \"\"\"\n        await self.root()\n        await self.message(msg, msg_type)", "label": 1}
{"code": "def sort_labeled_issues(issues)\n      sorted_issues = []\n      issues.each do |issue|\n        label_names = issue[\"labels\"].collect { |l| l[\"name\"] }\n\n        # Add PRs in the order of the @sections array. This will either be the\n        # default sections followed by any --add-sections sections in\n        # user-defined order, or --configure-sections in user-defined order.\n        # Ignore the order of the issue labels from github which cannot be\n        # controled by the user.\n        @sections.each do |section|\n          unless (section.labels & label_names).empty?\n            section.issues << issue\n            sorted_issues << issue\n            break\n          end\n        end\n      end\n      issues - sorted_issues\n    end", "label": 4}
{"code": "def procedures\n      return [] unless databases.any? || archives.any?\n\n      [-> { prepare! }, databases, archives,\n       -> { package! }, -> { store! }, -> { clean! }]\n    end", "label": 4}
{"code": "def parse_tag(text)\n      match = text.scan(/%([-:\\w]+)([-:\\w.#\\@]*)(.+)?/)[0]\n      raise SyntaxError.new(Error.message(:invalid_tag, text)) unless match\n\n      tag_name, attributes, rest = match\n\n      if !attributes.empty? && (attributes =~ /[.#](\\.|#|\\z)/)\n        raise SyntaxError.new(Error.message(:illegal_element))\n      end\n\n      new_attributes_hash = old_attributes_hash = last_line = nil\n      object_ref = :nil\n      attributes_hashes = {}\n      while rest && !rest.empty?\n        case rest[0]\n        when ?{\n          break if old_attributes_hash\n          old_attributes_hash, rest, last_line = parse_old_attributes(rest)\n          attributes_hashes[:old] = old_attributes_hash\n        when ?(\n          break if new_attributes_hash\n          new_attributes_hash, rest, last_line = parse_new_attributes(rest)\n          attributes_hashes[:new] = new_attributes_hash\n        when ?[\n          break unless object_ref == :nil\n          object_ref, rest = balance(rest, ?[, ?])\n        else; break\n        end\n      end\n\n      if rest && !rest.empty?\n        nuke_whitespace, action, value = rest.scan(/(<>|><|[><])?([=\\/\\~&!])?(.*)?/)[0]\n        if nuke_whitespace\n          nuke_outer_whitespace = nuke_whitespace.include? '>'\n          nuke_inner_whitespace = nuke_whitespace.include? '<'\n        end\n      end\n\n      if @options.remove_whitespace\n        nuke_outer_whitespace = true\n        nuke_inner_whitespace = true\n      end\n\n      if value.nil?\n        value = ''\n      else\n        value.strip!\n      end\n      [tag_name, attributes, attributes_hashes, object_ref, nuke_outer_whitespace,\n       nuke_inner_whitespace, action, value, last_line || @line.index + 1]\n    end", "label": 4}
{"code": "def revert(self, unchanged=False):\n        \"\"\"Reverts any file changes\n\n        :param unchanged: Only revert if the file is unchanged\n        :type unchanged: bool\n        \"\"\"\n        cmd = ['revert']\n        if unchanged:\n            cmd.append('-a')\n\n        wasadd = self.action == 'add'\n\n        cmd.append(self.depotFile)\n\n        self._connection.run(cmd)\n\n        if 'movedFile' in self._p4dict:\n            self._p4dict['depotFile'] = self._p4dict['movedFile']\n\n        if not wasadd:\n            self.query()\n\n        if self._changelist:\n            self._changelist.remove(self, permanent=True)", "label": 1}
{"code": "def make_variant(cls, converters, re_opts=None, compiled=False, strict=True):\n        \"\"\"\n        Creates a type converter for a number of type converter alternatives.\n        The first matching type converter is used.\n\n        REQUIRES: type_converter.pattern attribute\n\n        :param converters: List of type converters as alternatives.\n        :param re_opts:  Regular expression options zu use (=default_re_opts).\n        :param compiled: Use compiled regexp matcher, if true (=False).\n        :param strict:   Enable assertion checks.\n        :return: Type converter function object.\n\n        .. note::\n\n            Works only with named fields in :class:`parse.Parser`.\n            Parser needs group_index delta for unnamed/fixed fields.\n            This is not supported for user-defined types.\n            Otherwise, you need to use :class:`parse_type.parse.Parser`\n            (patched version of the :mod:`parse` module).\n        \"\"\"\n        # -- NOTE: Uses double-dispatch with regex pattern rematch because\n        #          match is not passed through to primary type converter.\n        assert converters, \"REQUIRE: Non-empty list.\"\n        if len(converters) == 1:\n            return converters[0]\n        if re_opts is None:\n            re_opts = cls.default_re_opts\n\n        pattern = r\")|(\".join([tc.pattern for tc in converters])\n        pattern = r\"(\"+ pattern + \")\"\n        group_count = len(converters)\n        for converter in converters:\n            group_count += pattern_group_count(converter.pattern)\n\n        if compiled:\n            convert_variant = cls.__create_convert_variant_compiled(converters,\n                                                                re_opts, strict)\n        else:\n            convert_variant = cls.__create_convert_variant(re_opts, strict)\n        convert_variant.pattern = pattern\n        convert_variant.converters = tuple(converters)\n        # OLD: convert_variant.group_count = group_count\n        convert_variant.regex_group_count = group_count\n        return convert_variant", "label": 1}
{"code": "func (r *Registry) VirtualDiskManager() *VirtualDiskManager {\n\treturn r.Get(r.content().VirtualDiskManager.Reference()).(*VirtualDiskManager)\n}", "label": 5}
{"code": "public static function first(CommandInterface $command, $prefix)\n    {\n        if ($arguments = $command->getArguments()) {\n            $arguments[0] = \"$prefix{$arguments[0]}\";\n            $command->setRawArguments($arguments);\n        }\n    }", "label": 2}
{"code": "function getAttrs(file) {\n  const sstat = fs.lstatSync(file);\n  return {\n    mode: _getUnixPermFromMode(sstat.mode), type: fileType(file),\n    atime: sstat.atime, ctime: sstat.ctime, mtime: sstat.mtime\n  };\n}", "label": 3}
{"code": "func AuthPermissionByContentTypeIDCodename(db XODB, contentTypeID int, codename string) (*AuthPermission, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, name, content_type_id, codename ` +\n\t\t`FROM public.auth_permission ` +\n\t\t`WHERE content_type_id = $1 AND codename = $2`\n\n\t// run query\n\tXOLog(sqlstr, contentTypeID, codename)\n\tap := AuthPermission{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, contentTypeID, codename).Scan(&ap.ID, &ap.Name, &ap.ContentTypeID, &ap.Codename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ap, nil\n}", "label": 5}
{"code": "func (tc *TeleportClient) applyProxySettings(proxySettings ProxySettings) error {\n\t// Kubernetes proxy settings.\n\tif proxySettings.Kube.Enabled && proxySettings.Kube.PublicAddr != \"\" && tc.KubeProxyAddr == \"\" {\n\t\t_, err := utils.ParseAddr(proxySettings.Kube.PublicAddr)\n\t\tif err != nil {\n\t\t\treturn trace.BadParameter(\n\t\t\t\t\"failed to parse value received from the server: %q, contact your administrator for help\",\n\t\t\t\tproxySettings.Kube.PublicAddr)\n\t\t}\n\t\ttc.KubeProxyAddr = proxySettings.Kube.PublicAddr\n\t} else if proxySettings.Kube.Enabled && tc.KubeProxyAddr == \"\" {\n\t\twebProxyHost, _ := tc.WebProxyHostPort()\n\t\ttc.KubeProxyAddr = fmt.Sprintf(\"%s:%d\", webProxyHost, defaults.KubeProxyListenPort)\n\t}\n\n\t// Read in settings for HTTP endpoint of the proxy.\n\tif proxySettings.SSH.PublicAddr != \"\" {\n\t\taddr, err := utils.ParseAddr(proxySettings.SSH.PublicAddr)\n\t\tif err != nil {\n\t\t\treturn trace.BadParameter(\n\t\t\t\t\"failed to parse value received from the server: %q, contact your administrator for help\",\n\t\t\t\tproxySettings.SSH.PublicAddr)\n\t\t}\n\t\ttc.WebProxyAddr = net.JoinHostPort(addr.Host(), strconv.Itoa(addr.Port(defaults.HTTPListenPort)))\n\n\t\t// Update local agent (that reads/writes to ~/.tsh) with the new address\n\t\t// of the web proxy. This will control where the keys are stored on disk\n\t\t// after login.\n\t\ttc.localAgent.UpdateProxyHost(addr.Host())\n\t}\n\t// Read in settings for the SSH endpoint of the proxy.\n\t//\n\t// If listen_addr is set, take host from ProxyWebHost and port from what\n\t// was set. This is to maintain backward compatibility when Teleport only\n\t// supported public_addr.\n\tif proxySettings.SSH.ListenAddr != \"\" {\n\t\taddr, err := utils.ParseAddr(proxySettings.SSH.ListenAddr)\n\t\tif err != nil {\n\t\t\treturn trace.BadParameter(\n\t\t\t\t\"failed to parse value received from the server: %q, contact your administrator for help\",\n\t\t\t\tproxySettings.SSH.ListenAddr)\n\t\t}\n\t\twebProxyHost, _ := tc.WebProxyHostPort()\n\t\ttc.SSHProxyAddr = net.JoinHostPort(webProxyHost, strconv.Itoa(addr.Port(defaults.SSHProxyListenPort)))\n\t}\n\t// If ssh_public_addr is set, override settings from listen_addr.\n\tif proxySettings.SSH.SSHPublicAddr != \"\" {\n\t\taddr, err := utils.ParseAddr(proxySettings.SSH.SSHPublicAddr)\n\t\tif err != nil {\n\t\t\treturn trace.BadParameter(\n\t\t\t\t\"failed to parse value received from the server: %q, contact your administrator for help\",\n\t\t\t\tproxySettings.SSH.ListenAddr)\n\t\t}\n\t\ttc.SSHProxyAddr = net.JoinHostPort(addr.Host(), strconv.Itoa(addr.Port(defaults.SSHProxyListenPort)))\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def read_more(size)\n      return if @parser.finished?\n\n      value = @socket.readpartial(size, @buffer)\n      if value == :eof\n        @parser << \"\"\n        :eof\n      elsif value\n        @parser << value\n      end\n    rescue IOError, SocketError, SystemCallError => ex\n      raise ConnectionError, \"error reading from socket: #{ex}\", ex.backtrace\n    end", "label": 4}
{"code": "def geom_rotate(g, ax, theta):\n    \"\"\" Rotation symmetry operation.\n\n    ax is rotation axis\n    g is assumed already translated to center of mass @ origin\n\n    Sense of rotation is the same as point_rotate\n\n    .. todo:: Complete geom_rotate docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Force g to n-vector\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n\n    # Perform rotation and return\n    rot_g = np.dot(mtx_rot(ax, theta, reps=(g.shape[0] // 3)), g) \\\n                .reshape((g.shape[0],1))\n    return rot_g", "label": 1}
{"code": "public function with($key, $value = '')\n    {\n        if (is_array($key)) {\n            $this->appends = $key;\n        } elseif (is_callable($value)) {\n            $this->appends[$key] = value($value);\n        } else {\n            $this->appends[$key] = value($value);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "func (a *AuthMiddleware) GetUser(r *http.Request) (interface{}, error) {\n\tpeers := r.TLS.PeerCertificates\n\tif len(peers) > 1 {\n\t\t// when turning intermediaries on, don't forget to verify\n\t\t// https://github.com/kubernetes/kubernetes/pull/34524/files#diff-2b283dde198c92424df5355f39544aa4R59\n\t\treturn nil, trace.AccessDenied(\"access denied: intermediaries are not supported\")\n\t}\n\tlocalClusterName, err := a.AccessPoint.GetClusterName()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\t// with no client authentication in place, middleware\n\t// assumes not-privileged Nop role.\n\t// it theoretically possible to use bearer token auth even\n\t// for connections without auth, but this is not active use-case\n\t// therefore it is not allowed to reduce scope\n\tif len(peers) == 0 {\n\t\treturn BuiltinRole{\n\t\t\tGetClusterConfig: a.AccessPoint.GetClusterConfig,\n\t\t\tRole:             teleport.RoleNop,\n\t\t\tUsername:         string(teleport.RoleNop),\n\t\t\tClusterName:      localClusterName.GetClusterName(),\n\t\t}, nil\n\t}\n\tclientCert := peers[0]\n\tcertClusterName, err := tlsca.ClusterName(clientCert.Issuer)\n\tif err != nil {\n\t\tlog.Warnf(\"Failed to parse client certificate %v.\", err)\n\t\treturn nil, trace.AccessDenied(\"access denied: invalid client certificate\")\n\t}\n\n\tidentity, err := tlsca.FromSubject(clientCert.Subject)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\t// If there is any restriction on the certificate usage\n\t// reject the API server request. This is done so some classes\n\t// of certificates issued for kubernetes usage by proxy, can not be used\n\t// against auth server. Later on we can extend more\n\t// advanced cert usage, but for now this is the safest option.\n\tif len(identity.Usage) != 0 && !utils.StringSlicesEqual(a.AcceptedUsage, identity.Usage) {\n\t\tlog.Warningf(\"Restricted certificate of user %q with usage %v rejected while accessing the auth endpoint with acceptable usage %v.\",\n\t\t\tidentity.Username, identity.Usage, a.AcceptedUsage)\n\t\treturn nil, trace.AccessDenied(\"access denied: invalid client certificate\")\n\t}\n\n\t// this block assumes interactive user from remote cluster\n\t// based on the remote certificate authority cluster name encoded in\n\t// x509 organization name. This is a safe check because:\n\t// 1. Trust and verification is established during TLS handshake\n\t// by creating a cert pool constructed of trusted certificate authorities\n\t// 2. Remote CAs are not allowed to have the same cluster name\n\t// as the local certificate authority\n\tif certClusterName != localClusterName.GetClusterName() {\n\t\t// make sure that this user does not have system role\n\t\t// the local auth server can not truste remote servers\n\t\t// to issue certificates with system roles (e.g. Admin),\n\t\t// to get unrestricted access to the local cluster\n\t\tsystemRole := findSystemRole(identity.Groups)\n\t\tif systemRole != nil {\n\t\t\treturn RemoteBuiltinRole{\n\t\t\t\tRole:        *systemRole,\n\t\t\t\tUsername:    identity.Username,\n\t\t\t\tClusterName: certClusterName,\n\t\t\t}, nil\n\t\t}\n\t\treturn RemoteUser{\n\t\t\tClusterName:      certClusterName,\n\t\t\tUsername:         identity.Username,\n\t\t\tPrincipals:       identity.Principals,\n\t\t\tKubernetesGroups: identity.KubernetesGroups,\n\t\t\tRemoteRoles:      identity.Groups,\n\t\t}, nil\n\t}\n\t// code below expects user or service from local cluster, to distinguish between\n\t// interactive users and services (e.g. proxies), the code below\n\t// checks for presence of system roles issued in certificate identity\n\tsystemRole := findSystemRole(identity.Groups)\n\t// in case if the system role is present, assume this is a service\n\t// agent, e.g. Proxy, connecting to the cluster\n\tif systemRole != nil {\n\t\treturn BuiltinRole{\n\t\t\tGetClusterConfig: a.AccessPoint.GetClusterConfig,\n\t\t\tRole:             *systemRole,\n\t\t\tUsername:         identity.Username,\n\t\t\tClusterName:      localClusterName.GetClusterName(),\n\t\t}, nil\n\t}\n\t// otherwise assume that is a local role, no need to pass the roles\n\t// as it will be fetched from the local database\n\treturn LocalUser{\n\t\tUsername: identity.Username,\n\t}, nil\n}", "label": 5}
{"code": "public function sendBroadcastAudio($targets, $path, $storeURLmedia = false, $fsize = 0, $fhash = '')\n    {\n        if (!is_array($targets)) {\n            $targets = [$targets];\n        }\n        // Return message ID. Make pull request for this.\n        return  $this->sendMessageAudio($targets, $path, $storeURLmedia, $fsize, $fhash);\n    }", "label": 2}
{"code": "def write_branch_data(self, file, padding=\"    \"):\n        \"\"\" Writes branch data in Graphviz DOT language.\n        \"\"\"\n        attrs = ['%s=\"%s\"' % (k,v) for k,v in self.branch_attr.iteritems()]\n        attr_str = \", \".join(attrs)\n\n        for br in self.case.branches:\n            file.write(\"%s%s -> %s [%s];\\n\" % \\\n                (padding, br.from_bus.name, br.to_bus.name, attr_str))", "label": 1}
{"code": "def attribute_present?(name)\n      attribute = read_raw_attribute(name)\n      !attribute.blank? || attribute == false\n    rescue ActiveModel::MissingAttributeError\n      false\n    end", "label": 4}
{"code": "function DependencyInjector(opts) {\n    var rootDefault = p.join(__dirname, '../../..');\n    this.rootDir = opts.rootDir || rootDefault;                 // project base dir (default is a guess)\n    this.require = opts.require || require;                     // we need require from the project\n    this.container = opts.container || 'api';                   // resource has diff profiles for diff containers\n    this.servicesDir = opts.servicesDir || 'services';          // dir where services reside\n    this.tplDir = opts.tplDir || 'dist/tpls';                   // precompiled templates\n    this.debug = opts.debug || false;                           // debug mode will have us firing more events\n    this.debugPattern = opts.debugPattern;                      // by default if debug on, we view EVERYTHING\n    this.debugHandler = opts.debugHandler;                      // function used when debug event occurs\n    this.adapters = opts.adapters || {};                        // if client uses plugins, they will pass in adapters\n    this.reactors = opts.reactors || {};                        // if client uses plugins, they will pass in reactors\n    this.adapterMap = this.loadAdapterMap(opts);                // mappings from adapter type to impl\n    this.aliases = this.loadAliases(opts);                      // mapping of names to locations\n    this.factories = this.loadFactories(opts);                  // load all the factories\n}", "label": 3}
{"code": "def find_otu(otuid, tree):\n    \"\"\"\n    Find an OTU ID in a Newick-format tree.\n    Return the starting position of the ID or None if not found.\n    \"\"\"\n    for m in re.finditer(otuid, tree):\n        before, after = tree[m.start()-1], tree[m.start()+len(otuid)]\n        if before in [\"(\", \",\", \")\"] and after in [\":\", \";\"]:\n            return m.start()\n    return None", "label": 1}
{"code": "func (i *Handle) IsServicePresent(s *Service) bool {\n\treturn nil == i.doCmd(s, nil, ipvsCmdGetService)\n}", "label": 5}
{"code": "def field_value_factor(settings, options = {})\n      scoring = options.merge(field_value_factor: settings)\n      chain { criteria.update_scores scoring }\n    end", "label": 4}
{"code": "func (ve ValidationErrors) Translate(ut ut.Translator) ValidationErrorsTranslations {\n\n\ttrans := make(ValidationErrorsTranslations)\n\n\tvar fe *fieldError\n\n\tfor i := 0; i < len(ve); i++ {\n\t\tfe = ve[i].(*fieldError)\n\n\t\t// // in case an Anonymous struct was used, ensure that the key\n\t\t// // would be 'Username' instead of \".Username\"\n\t\t// if len(fe.ns) > 0 && fe.ns[:1] == \".\" {\n\t\t// \ttrans[fe.ns[1:]] = fe.Translate(ut)\n\t\t// \tcontinue\n\t\t// }\n\n\t\ttrans[fe.ns] = fe.Translate(ut)\n\t}\n\n\treturn trans\n}", "label": 5}
{"code": "public function diffInRealMilliseconds($date = null, $absolute = true)\n    {\n        return (int) ($this->diffInRealMicroseconds($date, $absolute) / static::MICROSECONDS_PER_MILLISECOND);\n    }", "label": 2}
{"code": "def copy(path, options = {}, &block)\n      perform_request Net::HTTP::Copy, path, options, &block\n    end", "label": 4}
{"code": "func (c *Config) WebProxyHostPort() (string, int) {\n\tif c.WebProxyAddr != \"\" {\n\t\taddr, err := utils.ParseAddr(c.WebProxyAddr)\n\t\tif err == nil {\n\t\t\treturn addr.Host(), addr.Port(defaults.HTTPListenPort)\n\t\t}\n\t}\n\n\twebProxyHost, _ := c.WebProxyHostPort()\n\treturn webProxyHost, defaults.HTTPListenPort\n}", "label": 5}
{"code": "public static long count(nitro_service service, String ciphergroupname) throws Exception{\n\t\tsslcipher_individualcipher_binding obj = new sslcipher_individualcipher_binding();\n\t\tobj.set_ciphergroupname(ciphergroupname);\n\t\toptions option = new options();\n\t\toption.set_count(true);\n\t\tsslcipher_individualcipher_binding response[] = (sslcipher_individualcipher_binding[]) obj.get_resources(service,option);\n\t\tif (response != null) {\n\t\t\treturn response[0].__count;\n\t\t}\n\t\treturn 0;\n\t}", "label": 0}
{"code": "function puts(file, text, options) {\n  options = _.sanitize(options, {atNewLine: false, encoding: 'utf-8'});\n  append(file, `${text}\\n`, options);\n}", "label": 3}
{"code": "func (c *Client) Valid() bool {\n\tif c == nil {\n\t\treturn false\n\t}\n\n\tif c.Client == nil {\n\t\treturn false\n\t}\n\n\t// Use arbitrary pointer field in the service content.\n\t// Doesn't matter which one, as long as it is populated by default.\n\tif c.ServiceContent.SessionManager == nil {\n\t\treturn false\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "func PgConstraintsByConnameConnamespace(db XODB, conname pgtypes.Name, connamespace pgtypes.Oid) ([]*PgConstraint, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, conname, connamespace, contype, condeferrable, condeferred, convalidated, conrelid, contypid, conindid, confrelid, confupdtype, confdeltype, confmatchtype, conislocal, coninhcount, connoinherit, conkey, confkey, conpfeqop, conppeqop, conffeqop, conexclop, conbin, consrc ` +\n\t\t`FROM pg_catalog.pg_constraint ` +\n\t\t`WHERE conname = $1 AND connamespace = $2`\n\n\t// run query\n\tXOLog(sqlstr, conname, connamespace)\n\tq, err := db.Query(sqlstr, conname, connamespace)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*PgConstraint{}\n\tfor q.Next() {\n\t\tpc := PgConstraint{}\n\n\t\t// scan\n\t\terr = q.Scan(&pc.Tableoid, &pc.Cmax, &pc.Xmax, &pc.Cmin, &pc.Xmin, &pc.Oid, &pc.Ctid, &pc.Conname, &pc.Connamespace, &pc.Contype, &pc.Condeferrable, &pc.Condeferred, &pc.Convalidated, &pc.Conrelid, &pc.Contypid, &pc.Conindid, &pc.Confrelid, &pc.Confupdtype, &pc.Confdeltype, &pc.Confmatchtype, &pc.Conislocal, &pc.Coninhcount, &pc.Connoinherit, &pc.Conkey, &pc.Confkey, &pc.Conpfeqop, &pc.Conppeqop, &pc.Conffeqop, &pc.Conexclop, &pc.Conbin, &pc.Consrc)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &pc)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "@ArgumentsChecked\n\t@Throws(IllegalNullArgumentException.class)\n\tpublic static int checkInteger(@Nonnull final Number number) {\n\t\tCheck.notNull(number, \"number\");\n\t\tif (!isInIntegerRange(number)) {\n\t\t\tthrow new IllegalNumberRangeException(number.toString(), INTEGER_MIN, INTEGER_MAX);\n\t\t}\n\n\t\treturn number.intValue();\n\t}", "label": 0}
{"code": "public static function loadFromXMLFile($file_path, $base_dir)\n    {\n        $file_contents = file_get_contents($file_path);\n\n        if ($file_contents === false) {\n            throw new \\InvalidArgumentException('Cannot open ' . $file_path);\n        }\n\n        try {\n            $config = self::loadFromXML($base_dir, $file_contents);\n            $config->hash = sha1($file_contents);\n        } catch (ConfigException $e) {\n            throw new ConfigException(\n                'Problem parsing ' . $file_path . \":\\n\" . '  ' . $e->getMessage()\n            );\n        }\n\n        return $config;\n    }", "label": 2}
{"code": "def format_all(self):\n        \"\"\"\n        return a trace of parents and children of the obect\n        \"\"\"\n        res = '\\n--- Format all : ' + str(self.name) + ' -------------\\n'\n        res += ' parent = ' + str(self.parent) + '\\n'\n        res += self._get_all_children()    \n        res += self._get_links()\n            \n        return res", "label": 1}
{"code": "function reassignJavadoc(from, to) {\n  if (!(from.doc instanceof Javadoc)) {\n    // Nothing to transfer.\n    return from;\n  }\n  to.doc = from.doc;\n  delete from.doc;\n  return Object.keys(from).length === 1 ? from.type : from;\n}", "label": 3}
{"code": "private function createCurl()\n    {\n        $parameters = $this->getParameters();\n        $timeout = (isset($parameters->timeout) ? (float) $parameters->timeout : 5.0) * 1000;\n\n        if (filter_var($host = $parameters->host, FILTER_VALIDATE_IP)) {\n            $host = \"[$host]\";\n        }\n\n        $options = array(\n            CURLOPT_FAILONERROR => true,\n            CURLOPT_CONNECTTIMEOUT_MS => $timeout,\n            CURLOPT_URL => \"$parameters->scheme://$host:$parameters->port\",\n            CURLOPT_HTTP_VERSION => CURL_HTTP_VERSION_1_1,\n            CURLOPT_POST => true,\n            CURLOPT_WRITEFUNCTION => array($this, 'feedReader'),\n        );\n\n        if (isset($parameters->user, $parameters->pass)) {\n            $options[CURLOPT_USERPWD] = \"{$parameters->user}:{$parameters->pass}\";\n        }\n\n        curl_setopt_array($resource = curl_init(), $options);\n\n        return $resource;\n    }", "label": 2}
{"code": "public function getBotMessages()\n    {\n        return Collection::make($this->getDriver()->getMessages())->filter(function (IncomingMessage $message) {\n            return $message->isFromBot();\n        })->toArray();\n    }", "label": 2}
{"code": "public function setTopic($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\PubSub\\V1\\Topic::class);\n        $this->topic = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def deep_merge_hashes!(target, overwrite)\n      merge_values(target, overwrite)\n      merge_default_proc(target, overwrite)\n      duplicate_frozen_values(target)\n\n      target\n    end", "label": 4}
{"code": "public RedwoodConfiguration loggingClass(final Class<?> classToIgnoreInTraces){\r\n    tasks.add(new Runnable() { public void run() { Redwood.addLoggingClass(classToIgnoreInTraces.getName()); } });\r\n    return this;\r\n  }", "label": 0}
{"code": "public LuaScriptBlock endBlockReturn(LuaValue value) {\n        add(new LuaAstReturnStatement(argument(value)));\n        return new LuaScriptBlock(script);\n    }", "label": 0}
{"code": "def __make_id(receiver):\n    \"\"\"Generate an identifier for a callable signal receiver.\n\n    This is used when disconnecting receivers, where we need to correctly\n    establish equivalence between the input receiver and the receivers assigned\n    to a signal.\n\n    Args:\n        receiver: A callable object.\n\n    Returns:\n        An identifier for the receiver.\n    \"\"\"\n    if __is_bound_method(receiver):\n        return (id(receiver.__func__), id(receiver.__self__))\n    return id(receiver)", "label": 1}
{"code": "def to_dict(self):\n        \"\"\"Convert to a ``dict``\n\n        Subclasses can override this function.\n\n        Returns:\n            Python dict with keys set from this Entity.\n        \"\"\"\n        entity_dict = {}\n\n        for field, val in six.iteritems(self._fields):\n            if field.multiple:\n                if val:\n                    val = [_dictify(field, x) for x in val]\n                else:\n                    val = []\n            else:\n                val = _dictify(field, val)\n\n            # Only add non-None objects or non-empty lists\n            if val is not None and val != []:\n                entity_dict[field.key_name] = val\n\n        self._finalize_dict(entity_dict)\n\n        return entity_dict", "label": 1}
{"code": "private function formatTimeAsString(\\DateTimeInterface $dateTime, $ns)\n    {\n        $dateTime = $dateTime->setTimeZone(new \\DateTimeZone('UTC'));\n        if ($ns === null) {\n            return $dateTime->format(Timestamp::FORMAT);\n        } else {\n            $ns = (string) $ns;\n            $ns = str_pad($ns, 9, '0', STR_PAD_LEFT);\n            if (substr($ns, 6, 3) === '000') {\n                $ns = substr($ns, 0, 6);\n            }\n\n            return sprintf(\n                $dateTime->format(Timestamp::FORMAT_INTERPOLATE),\n                $ns\n            );\n        }\n    }", "label": 2}
{"code": "def new_page(mediabox = [0, 0, 612.0, 792.0], _location = -1)\n      p = PDFWriter.new(mediabox)\n      insert(-1, p)\n      p\n    end", "label": 4}
{"code": "def [](index_value)\n      if index_value.is_a?(Integer)\n        self.fetch(index_value)\n      else\n        self.select { |a| a.filename == index_value }.first\n      end\n    end", "label": 4}
{"code": "func (s *Server) isAuditedAtProxy() bool {\n\t// always be safe, better to double record than not record at all\n\tclusterConfig, err := s.GetAccessPoint().GetClusterConfig()\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tisRecordAtProxy := clusterConfig.GetSessionRecording() == services.RecordAtProxy\n\tisTeleportNode := s.Component() == teleport.ComponentNode\n\n\tif isRecordAtProxy && isTeleportNode {\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "function link(target, location, options) {\n  options = _.sanitize(options, {force: false});\n  if (options.force && isLink(location)) {\n    fileDelete(location);\n  }\n  if (!path.isAbsolute(target)) {\n    const cwd = process.cwd();\n    process.chdir(path.dirname(location));\n    try {\n      fs.symlinkSync(target, path.basename(location));\n    } finally {\n      try { process.chdir(cwd); } catch (e) { /* not empty */ }\n    }\n  } else {\n    fs.symlinkSync(target, location);\n  }\n}", "label": 3}
{"code": "public function pollUntilComplete(array $options = [])\n    {\n        $options += [\n            'pollingIntervalSeconds' => $this::WAIT_INTERVAL,\n            'maxPollingDurationSeconds' => 0.0,\n        ];\n\n        $pollingIntervalMicros = $options['pollingIntervalSeconds'] * 1000000;\n        $maxPollingDuration = $options['maxPollingDurationSeconds'];\n        $hasMaxPollingDuration = $maxPollingDuration > 0.0;\n        $endTime = microtime(true) + $maxPollingDuration;\n\n        do {\n            usleep($pollingIntervalMicros);\n            $this->reload($options);\n        } while (!$this->done() && (!$hasMaxPollingDuration || microtime(true) < $endTime));\n\n        return $this->result;\n    }", "label": 2}
{"code": "func GetACIInfoWithBlobKey(tx *sql.Tx, blobKey string) (*ACIInfo, bool, error) {\n\taciinfo := &ACIInfo{}\n\tfound := false\n\trows, err := tx.Query(\"SELECT * from aciinfo WHERE blobkey == $1\", blobKey)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tdefer rows.Close()\n\tfor rows.Next() {\n\t\tfound = true\n\t\tif err := aciinfoRowScan(rows, aciinfo); err != nil {\n\t\t\treturn nil, false, err\n\t\t}\n\t\t// No more than one row for blobkey must exist.\n\t\tbreak\n\t}\n\tif err := rows.Err(); err != nil {\n\t\treturn nil, false, err\n\t}\n\treturn aciinfo, found, err\n}", "label": 5}
{"code": "public static responderhtmlpage get(nitro_service service, String name) throws Exception{\n\t\tresponderhtmlpage obj = new responderhtmlpage();\n\t\tobj.set_name(name);\n\t\tresponderhtmlpage response = (responderhtmlpage) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def fetch(self, recursive=1, exclude_children=False, exclude_back_refs=False):\n        \"\"\"Fetch resource from the API server\n\n        :param recursive: level of recursion for fetching resources\n        :type recursive: int\n        :param exclude_children: don't get children references\n        :type exclude_children: bool\n        :param exclude_back_refs: don't get back_refs references\n        :type exclude_back_refs: bool\n\n        :rtype: Resource\n        \"\"\"\n        if not self.path.is_resource and not self.path.is_uuid:\n            self.check()\n        params = {}\n        # even if the param is False the API will exclude resources\n        if exclude_children:\n            params['exclude_children'] = True\n        if exclude_back_refs:\n            params['exclude_back_refs'] = True\n        data = self.session.get_json(self.href, **params)[self.type]\n        self.from_dict(data)\n        return self", "label": 1}
{"code": "def parse_s2bs(s2bs):\n    \"\"\"\n    convert s2b files to dictionary\n    \"\"\"\n    s2b = {}\n    for s in s2bs:\n        for line in open(s):\n            line = line.strip().split('\\t')\n            s, b = line[0], line[1]\n            s2b[s] = b\n    return s2b", "label": 1}
{"code": "def insert(conn, qualified_name: str, column_names, records):\n    \"\"\"Insert a collection of namedtuple records.\"\"\"\n\n    query = create_insert_statement(qualified_name, column_names)\n\n    with conn:\n        with conn.cursor(cursor_factory=NamedTupleCursor) as cursor:\n            for record in records:\n                cursor.execute(query, record)", "label": 1}
{"code": "def native_config(opaque=nil)\n      Rdkafka::Bindings.rd_kafka_conf_new.tap do |config|\n        # Create config\n        @config_hash.merge(REQUIRED_CONFIG).each do |key, value|\n          error_buffer = FFI::MemoryPointer.from_string(\" \" * 256)\n          result = Rdkafka::Bindings.rd_kafka_conf_set(\n            config,\n            key.to_s,\n            value.to_s,\n            error_buffer,\n            256\n          )\n          unless result == :config_ok\n            raise ConfigError.new(error_buffer.read_string)\n          end\n        end\n\n        # Set opaque pointer that's used as a proxy for callbacks\n        if opaque\n          pointer = ::FFI::Pointer.new(:pointer, opaque.object_id)\n          Rdkafka::Bindings.rd_kafka_conf_set_opaque(config, pointer)\n\n          # Store opaque with the pointer as key. We use this approach instead\n          # of trying to convert the pointer to a Ruby object because there is\n          # no risk of a segfault this way.\n          Rdkafka::Config.opaques[pointer.to_i] = opaque\n        end\n\n        # Set log callback\n        Rdkafka::Bindings.rd_kafka_conf_set_log_cb(config, Rdkafka::Bindings::LogCallback)\n\n        # Set stats callback\n        Rdkafka::Bindings.rd_kafka_conf_set_stats_cb(config, Rdkafka::Bindings::StatsCallback)\n      end\n    end", "label": 4}
{"code": "def check_preceding_node(node, type)\n      case prev_node(node)\n      when\n        nil,\n        Sass::Tree::FunctionNode,\n        Sass::Tree::MixinNode,\n        Sass::Tree::MixinDefNode,\n        Sass::Tree::RuleNode,\n        Sass::Tree::CommentNode\n        # Ignore\n        nil\n      else\n        unless engine.lines[node.line - 2].strip.empty?\n          add_lint(node.line, MESSAGE_FORMAT % [type, 'preceded'])\n        end\n      end\n    end", "label": 4}
{"code": "public static base_responses add(nitro_service client, dnstxtrec resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdnstxtrec addresources[] = new dnstxtrec[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new dnstxtrec();\n\t\t\t\taddresources[i].domain = resources[i].domain;\n\t\t\t\taddresources[i].String = resources[i].String;\n\t\t\t\taddresources[i].ttl = resources[i].ttl;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static base_response update(nitro_service client, transformpolicy resource) throws Exception {\n\t\ttransformpolicy updateresource = new transformpolicy();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.rule = resource.rule;\n\t\tupdateresource.profilename = resource.profilename;\n\t\tupdateresource.comment = resource.comment;\n\t\tupdateresource.logaction = resource.logaction;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (v *validate) validateStruct(ctx context.Context, parent reflect.Value, current reflect.Value, typ reflect.Type, ns []byte, structNs []byte, ct *cTag) {\n\n\tcs, ok := v.v.structCache.Get(typ)\n\tif !ok {\n\t\tcs = v.v.extractStructCache(current, typ.Name())\n\t}\n\n\tif len(ns) == 0 && len(cs.name) != 0 {\n\n\t\tns = append(ns, cs.name...)\n\t\tns = append(ns, '.')\n\n\t\tstructNs = append(structNs, cs.name...)\n\t\tstructNs = append(structNs, '.')\n\t}\n\n\t// ct is nil on top level struct, and structs as fields that have no tag info\n\t// so if nil or if not nil and the structonly tag isn't present\n\tif ct == nil || ct.typeof != typeStructOnly {\n\n\t\tvar f *cField\n\n\t\tfor i := 0; i < len(cs.fields); i++ {\n\n\t\t\tf = cs.fields[i]\n\n\t\t\tif v.isPartial {\n\n\t\t\t\tif v.ffn != nil {\n\t\t\t\t\t// used with StructFiltered\n\t\t\t\t\tif v.ffn(append(structNs, f.name...)) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\t\t\t\t\t// used with StructPartial & StructExcept\n\t\t\t\t\t_, ok = v.includeExclude[string(append(structNs, f.name...))]\n\n\t\t\t\t\tif (ok && v.hasExcludes) || (!ok && !v.hasExcludes) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tv.traverseField(ctx, parent, current.Field(f.idx), ns, structNs, f, f.cTags)\n\t\t}\n\t}\n\n\t// check if any struct level validations, after all field validations already checked.\n\t// first iteration will have no info about nostructlevel tag, and is checked prior to\n\t// calling the next iteration of validateStruct called from traverseField.\n\tif cs.fn != nil {\n\n\t\tv.slflParent = parent\n\t\tv.slCurrent = current\n\t\tv.ns = ns\n\t\tv.actualNs = structNs\n\n\t\tcs.fn(ctx, v)\n\t}\n}", "label": 5}
{"code": "public static base_responses update(nitro_service client, bridgetable resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tbridgetable updateresources[] = new bridgetable[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new bridgetable();\n\t\t\t\tupdateresources[i].bridgeage = resources[i].bridgeage;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function(obj){\n            var theDialog = this.getDialog(obj);\n            if(theDialog){\n                var rest = Array.prototype.slice.call(arguments, 1);\n                theDialog.close.apply(theDialog, rest);\n            }\n        }", "label": 3}
