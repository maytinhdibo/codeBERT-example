{"code": "private static MtasTreeItem getMtasTreeItem(Long ref,\n      AtomicBoolean isSinglePoint, AtomicBoolean isStoreAdditionalIdAndRef,\n      AtomicLong nodeRefApproxOffset, IndexInput in, long objectRefApproxOffset)\n      throws IOException {\n    try {\n      Boolean isRoot = false;\n      if (nodeRefApproxOffset.get() < 0) {\n        isRoot = true;\n      }\n      in.seek(ref);\n      if (isRoot) {\n        nodeRefApproxOffset.set(in.readVLong());\n        Byte flag = in.readByte();\n        if ((flag\n            & MtasTree.SINGLE_POSITION_TREE) == MtasTree.SINGLE_POSITION_TREE) {\n          isSinglePoint.set(true);\n        }\n        if ((flag\n            & MtasTree.STORE_ADDITIONAL_ID) == MtasTree.STORE_ADDITIONAL_ID) {\n          isStoreAdditionalIdAndRef.set(true);\n        }\n      }\n      int left = in.readVInt();\n      int right = in.readVInt();\n      int max = in.readVInt();\n      Long leftChild = in.readVLong() + nodeRefApproxOffset.get();\n      Long rightChild = in.readVLong() + nodeRefApproxOffset.get();\n      int size = 1;\n      if (!isSinglePoint.get()) {\n        size = in.readVInt();\n      }\n      // initialize\n      long[] objectRefs = new long[size];\n      int[] objectAdditionalIds = null;\n      long[] objectAdditionalRefs = null;\n      // get first\n      long objectRef = in.readVLong();\n      long objectRefPrevious = objectRef + objectRefApproxOffset;\n      objectRefs[0] = objectRefPrevious;\n      if (isStoreAdditionalIdAndRef.get()) {\n        objectAdditionalIds = new int[size];\n        objectAdditionalRefs = new long[size];\n        objectAdditionalIds[0] = in.readVInt();\n        objectAdditionalRefs[0] = in.readVLong();\n      }\n      // get others\n      for (int t = 1; t < size; t++) {\n        objectRef = objectRefPrevious + in.readVLong();\n        objectRefs[t] = objectRef;\n        objectRefPrevious = objectRef;\n        if (isStoreAdditionalIdAndRef.get()) {\n          objectAdditionalIds[t] = in.readVInt();\n          objectAdditionalRefs[t] = in.readVLong();\n        }\n      }\n      return new MtasTreeItem(left, right, max, objectRefs, objectAdditionalIds,\n          objectAdditionalRefs, ref, leftChild, rightChild);\n    } catch (Exception e) {\n      throw new IOException(e.getMessage());\n    }\n  }", "label": 0}
{"code": "public static long count(nitro_service service, String id) throws Exception{\n\t\tlinkset_interface_binding obj = new linkset_interface_binding();\n\t\tobj.set_id(id);\n\t\toptions option = new options();\n\t\toption.set_count(true);\n\t\tlinkset_interface_binding response[] = (linkset_interface_binding[]) obj.get_resources(service,option);\n\t\tif (response != null) {\n\t\t\treturn response[0].__count;\n\t\t}\n\t\treturn 0;\n\t}", "label": 0}
{"code": "public static base_responses unset(nitro_service client, appfwconfidfield resources[],  String[] args) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwconfidfield unsetresources[] = new appfwconfidfield[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tunsetresources[i] = new appfwconfidfield();\n\t\t\t\tunsetresources[i].fieldname = resources[i].fieldname;\n\t\t\t\tunsetresources[i].url = resources[i].url;\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def truncate_money(money: Money) -> Money:\n    \"\"\"Truncates money amount to the number of decimals corresponding to the currency\"\"\"\n    amount = truncate_to(money.amount, money.currency)\n    return Money(amount, money.currency)", "label": 1}
{"code": "def convert_money(self, money: Money, to: str, reverse: bool=False) -> Money:\n        \"\"\"Convert money to another currency\"\"\"\n        converted = self.convert(money.amount, money.currency, to, reverse)\n        return Money(converted, to)", "label": 1}
{"code": "func Init(dc driverapi.DriverCallback, config map[string]interface{}) error {\n\td := newDriver()\n\tif err := d.configure(config); err != nil {\n\t\treturn err\n\t}\n\n\tc := driverapi.Capability{\n\t\tDataScope:         datastore.LocalScope,\n\t\tConnectivityScope: datastore.LocalScope,\n\t}\n\treturn dc.RegisterDriver(networkType, d, c)\n}", "label": 5}
{"code": "func GetIterations() int {\n\tout := os.Getenv(teleport.IterationsEnvVar)\n\tif out == \"\" {\n\t\treturn 1\n\t}\n\titer, err := strconv.Atoi(out)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlog.Debugf(\"Starting tests with %v iterations.\", iter)\n\treturn iter\n}", "label": 5}
{"code": "protected function hasBinding($class)\n    {\n        if ($this->isCollection($class) && ! $class->isEmpty()) {\n            $class = $class->first();\n        }\n\n        $class = is_object($class) ? get_class($class) : $class;\n\n        return isset($this->bindings[$class]);\n    }", "label": 2}
{"code": "func PgDescriptionByObjoidClassoidObjsubid(db XODB, objoid pgtypes.Oid, classoid pgtypes.Oid, objsubid int) (*PgDescription, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, objoid, classoid, objsubid, description ` +\n\t\t`FROM pg_catalog.pg_description ` +\n\t\t`WHERE objoid = $1 AND classoid = $2 AND objsubid = $3`\n\n\t// run query\n\tXOLog(sqlstr, objoid, classoid, objsubid)\n\tpd := PgDescription{}\n\n\terr = db.QueryRow(sqlstr, objoid, classoid, objsubid).Scan(&pd.Tableoid, &pd.Cmax, &pd.Xmax, &pd.Cmin, &pd.Xmin, &pd.Ctid, &pd.Objoid, &pd.Classoid, &pd.Objsubid, &pd.Description)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pd, nil\n}", "label": 5}
{"code": "public function appendBuild(callable $middleware, $name = null)\n    {\n        $this->add(self::BUILD, $name, $middleware);\n    }", "label": 2}
{"code": "func (self *Queue) DelayedTime(dur time.Duration) *QueueCursor {\n\tcursor := self.newCursor()\n\tcursor.init = func(buf *pktque.Buf, videoidx int) pktque.BufPos {\n\t\ti := buf.Tail - 1\n\t\tif buf.IsValidPos(i) {\n\t\t\tend := buf.Get(i)\n\t\t\tfor buf.IsValidPos(i) {\n\t\t\t\tif end.Time-buf.Get(i).Time > dur {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\ti--\n\t\t\t}\n\t\t}\n\t\treturn i\n\t}\n\treturn cursor\n}", "label": 5}
{"code": "def matched_attribute_method(method_name)\n        matches = self.class.send(:attribute_method_matchers_matching, method_name)\n        matches.detect { |match| attribute_method?(match.attr_name) }\n      end", "label": 4}
{"code": "func (n *network) contains(ip net.IP) bool {\n\tfor _, s := range n.subnets {\n\t\tif s.subnetIP.Contains(ip) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "func appendEvent(events []riemanngo.Event, sink *RiemannSink, host, name string, value interface{}, labels map[string]string, timestamp int64) []riemanngo.Event {\n\tevent := riemanngo.Event{\n\t\tTime:        timestamp,\n\t\tService:     name,\n\t\tHost:        host,\n\t\tDescription: \"\",\n\t\tAttributes:  labels,\n\t\tMetric:      value,\n\t\tTtl:         sink.config.Ttl,\n\t\tState:       sink.config.State,\n\t\tTags:        sink.config.Tags,\n\t}\n\t// state everywhere\n\tevents = append(events, event)\n\tif len(events) >= sink.config.BatchSize {\n\t\terr := riemannCommon.SendData(sink.client, events)\n\t\tif err != nil {\n\t\t\tglog.Warningf(\"Error sending events to Riemann: %v\", err)\n\t\t\t// client will reconnect later\n\t\t\tsink.client = nil\n\t\t}\n\t\tevents = nil\n\t}\n\treturn events\n}", "label": 5}
{"code": "def _simpleparsefun(date):\r\n    \"\"\"Simple date parsing function\"\"\"\r\n    if hasattr(date, 'year'):\r\n        return date\r\n    try:\r\n        date = datetime.datetime.strptime(date, '%Y-%m-%d')\r\n    except ValueError:\r\n        date = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\r\n    return date", "label": 1}
{"code": "function buildCollections(patternObj, options, collectionPromises = []) {\n  if (isPattern(patternObj)) {\n    return collectionPromises;\n  }\n  if (isCollection(patternObj)) {\n    collectionPromises.push(buildCollection(patternObj, options));\n  }\n  for (const patternKey in patternObj) {\n    if (patternKey !== 'collection') {\n      buildCollections(patternObj[patternKey], options, collectionPromises);\n    }\n  }\n  return collectionPromises;\n}", "label": 3}
{"code": "public void strokeRectangle(Rectangle rect, Color color, float linewidth) {\n\t\tstrokeRectangle(rect, color, linewidth, null);\n\t}", "label": 0}
{"code": "func GetEnabledControllers() ([]string, error) {\n\tcontrollersFile, err := os.Open(\"/sys/fs/cgroup/cgroup.controllers\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer controllersFile.Close()\n\n\tsc := bufio.NewScanner(controllersFile)\n\n\tsc.Scan()\n\tif err := sc.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn strings.Split(sc.Text(), \" \"), nil\n}", "label": 5}
{"code": "func (p *proxyServer) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\t// Validate http connect parameters.\n\tif r.Method != http.MethodConnect {\n\t\ttrace.WriteError(w, trace.BadParameter(\"%v not supported\", r.Method))\n\t\treturn\n\t}\n\tif r.Host == \"\" {\n\t\ttrace.WriteError(w, trace.BadParameter(\"host not set\"))\n\t\treturn\n\t}\n\n\t// Dial to the target host, this is done before hijacking the connection to\n\t// ensure the target host is accessible.\n\tdconn, err := net.Dial(\"tcp\", r.Host)\n\tif err != nil {\n\t\ttrace.WriteError(w, err)\n\t\treturn\n\t}\n\tdefer dconn.Close()\n\n\t// Once the client receives 200 OK, the rest of the data will no longer be\n\t// http, but whatever protocol is being tunneled.\n\tw.WriteHeader(http.StatusOK)\n\n\t// Hijack request so we can get underlying connection.\n\thj, ok := w.(http.Hijacker)\n\tif !ok {\n\t\ttrace.WriteError(w, trace.AccessDenied(\"unable to hijack connection\"))\n\t\treturn\n\t}\n\tsconn, _, err := hj.Hijack()\n\tif err != nil {\n\t\ttrace.WriteError(w, err)\n\t\treturn\n\t}\n\tdefer sconn.Close()\n\n\t// Success, we're proxying data now.\n\tp.Lock()\n\tp.count = p.count + 1\n\tp.Unlock()\n\n\t// Copy from src to dst and dst to src.\n\terrc := make(chan error, 2)\n\treplicate := func(dst io.Writer, src io.Reader) {\n\t\t_, err := io.Copy(dst, src)\n\t\terrc <- err\n\t}\n\tgo replicate(sconn, dconn)\n\tgo replicate(dconn, sconn)\n\n\t// Wait until done, error, or 10 second.\n\tselect {\n\tcase <-time.After(10 * time.Second):\n\tcase <-errc:\n\t}\n}", "label": 5}
{"code": "def translate(rect, x, y, width=1):\n    \"\"\"\n    Given four points of a rectangle, translate the\n    rectangle to the specified x and y coordinates and,\n    optionally, change the width.\n\n    :type rect: list of tuples\n    :param rect: Four points describing a rectangle.\n    :type x: float\n    :param x: The amount to shift the rectangle along the x-axis.\n    :type y: float\n    :param y: The amount to shift the rectangle along the y-axis.\n    :type width: float\n    :param width: The amount by which to change the width of the\n                  rectangle.\n    \"\"\"\n    return ((rect[0][0]+x, rect[0][1]+y), (rect[1][0]+x, rect[1][1]+y),\n            (rect[2][0]+x+width, rect[2][1]+y), (rect[3][0]+x+width, rect[3][1]+y))", "label": 1}
{"code": "def parse_page_params(uri, attr) # :nodoc:\n      return -1 if uri.nil? || uri.empty?\n      parsed = nil\n      begin\n        parsed = URI.parse(uri)\n      rescue URI::Error\n        return -1\n      end\n      param = parse_query_for_param(parsed.query, attr)\n      return -1 if param.nil? || param.empty?\n      begin\n        return param.to_i\n      rescue ArgumentError\n        return -1\n      end\n    end", "label": 4}
{"code": "public static function addPermissions(array $permissions)\n    {\n        $rows = [];\n\n        foreach ($permissions as $permission => $groups) {\n            foreach ((array) $groups as $group) {\n                $rows[] = [\n                    'group_id' => $group,\n                    'permission' => $permission,\n                ];\n            }\n        }\n\n        return [\n            'up' => function (Builder $schema) use ($rows) {\n                $db = $schema->getConnection();\n\n                foreach ($rows as $row) {\n                    if ($db->table('group_permission')->where($row)->exists()) {\n                        continue;\n                    }\n\n                    if ($db->table('groups')->where('id', $row['group_id'])->doesntExist()) {\n                        continue;\n                    }\n\n                    $db->table('group_permission')->insert($row);\n                }\n            },\n\n            'down' => function (Builder $schema) use ($rows) {\n                $db = $schema->getConnection();\n\n                foreach ($rows as $row) {\n                    $db->table('group_permission')->where($row)->delete();\n                }\n            }\n        ];\n    }", "label": 2}
{"code": "public final Object copy(final Object toCopy, PersistenceBroker broker)\r\n\t{\r\n\t\treturn clone(toCopy, IdentityMapFactory.getIdentityMap(), new HashMap());\r\n\t}", "label": 0}
{"code": "def awesome_ripple_document_instance(object)\n      return object.inspect if !defined?(::ActiveSupport::OrderedHash)\n      return awesome_object(object) if @options[:raw]\n      exclude_assoc = @options[:exclude_assoc] or @options[:exclude_associations]\n\n      data = object.attributes.inject(::ActiveSupport::OrderedHash.new) do |hash, (name, value)|\n        hash[name.to_sym] = object.send(name)\n        hash\n      end\n\n      unless exclude_assoc\n        data = object.class.embedded_associations.inject(data) do |hash, assoc|\n          hash[assoc.name] = object.get_proxy(assoc) # Should always be array or Ripple::EmbeddedDocument for embedded associations\n          hash\n        end\n      end\n\n      \"#{object} \" << awesome_hash(data)\n    end", "label": 4}
{"code": "func (c *TrustedCerts) SSHCertPublicKeys() ([]ssh.PublicKey, error) {\n\tout := make([]ssh.PublicKey, 0, len(c.HostCertificates))\n\tfor _, keyBytes := range c.HostCertificates {\n\t\tpublicKey, _, _, _, err := ssh.ParseAuthorizedKey(keyBytes)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tout = append(out, publicKey)\n\t}\n\treturn out, nil\n}", "label": 5}
{"code": "def allow_user(user):\n    \"\"\"Allow a user identified by an email address.\"\"\"\n    def processor(action, argument):\n        db.session.add(\n            ActionUsers.allow(action, argument=argument, user_id=user.id)\n        )\n    return processor", "label": 1}
{"code": "public function isMonitoring(array $tags)\n    {\n        if (is_null($this->monitoredTags)) {\n            $this->loadMonitoredTags();\n        }\n\n        return count(array_intersect($tags, $this->monitoredTags)) > 0;\n    }", "label": 2}
{"code": "function uploadFile(endpoint, releaseVersion, filePath) {\n  // sentry lets you use the tilde to indicate it just looks at relative locations\n  // instead of relying on the host/domain.\n  var IGNORE_DOMAIN = '~';\n  var staticBase = process.env.STATIC_BASE;\n  var IGNORE_PATH = staticBase ? url.parse(staticBase).path + '/' : '';\n  var CONFLICT_CODE = 409;\n\n  var fileData = path.parse(filePath);\n  var fileName = fileData.name + fileData.ext;\n  var sentryFilePath = IGNORE_DOMAIN + IGNORE_PATH + fileName;\n\n  return new Promise(function(resolve, reject) {\n    superagent\n      .post(endpoint)\n      .set(HEADERS)\n      .attach('file', filePath)\n      .field('name', sentryFilePath)\n      .end(function(err, res) {\n        if (!err) {\n          console.log('Sentry (release: ' + releaseVersion +\n            ') - Successfully uploaded ' + fileName);\n          resolve();\n        } if (err && err.response && err.response.statusCode === CONFLICT_CODE) {\n          console.log('Sentry (' + releaseVersion + ') - ' + fileName +\n            ' already exists.');\n          resolve();\n        } else {\n          reject(err);\n        }\n      });\n  });\n}", "label": 3}
{"code": "def add_prefix(self, ns_uri, prefix, set_as_preferred=False):\n        \"\"\"Adds prefix for the given namespace URI.  The namespace must already\n        exist in this set.  If set_as_preferred is True, also set this\n        namespace as the preferred one.\n\n        ``prefix`` must be non-None; a default preference can't be set this way.\n        See :meth:`set_preferred_prefix_for_namespace` for that.\n\n        Args:\n            ns_uri (str): The namespace URI to add the prefix to\n            prefix (str): The prefix to add (not None)\n            set_as_preferred (bool): Whether to set the new prefix as preferred\n\n        Raises:\n            NamespaceNotFoundError: If namespace ``ns_uri`` isn't in this set\n        \"\"\"\n        assert prefix\n\n        ni = self.__lookup_uri(ns_uri)\n\n        self.__check_prefix_conflict(ni, prefix)\n        ni.prefixes.add(prefix)\n        self.__prefix_map[prefix] = ni\n\n        if set_as_preferred:\n            ni.preferred_prefix = prefix", "label": 1}
{"code": "func (m *Manager) Query(ctx context.Context, spec []types.PerfQuerySpec) ([]types.BasePerfEntityMetricBase, error) {\n\treq := types.QueryPerf{\n\t\tThis:      m.Reference(),\n\t\tQuerySpec: spec,\n\t}\n\n\tres, err := methods.QueryPerf(ctx, m.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn res.Returnval, nil\n}", "label": 5}
{"code": "public void setBeliefValue(String agent_name, final String belief_name,\n            final Object new_value, Connector connector) {\n\n        ((IExternalAccess) connector.getAgentsExternalAccess(agent_name))\n                .scheduleStep(new IComponentStep<Integer>() {\n\n                    public IFuture<Integer> execute(IInternalAccess ia) {\n                        IBDIInternalAccess bia = (IBDIInternalAccess) ia;\n                        bia.getBeliefbase().getBelief(belief_name)\n                                .setFact(new_value);\n                        return null;\n                    }\n                }).get(new ThreadSuspendable());\n    }", "label": 0}
{"code": "def print_mhc_peptide(neoepitope_info, peptides, pepmap, outfile, netmhc=False):\n    \"\"\"\n    Accept data about one neoepitope from merge_mhc_peptide_calls and print it to outfile.  This is\n    a generic module to reduce code redundancy.\n\n    :param pandas.core.frame neoepitope_info: object containing with allele, pept, pred, core,\n           normal_pept, normal_pred\n    :param dict peptides: Dict of pepname: pep sequence for all IARS considered\n    :param dict pepmap: Dict containing teh contents from the peptide map file.\n    :param file outfile: An open file descriptor to the output file\n    :param bool netmhc: Does this record correspond to a netmhcIIpan record? These are processed\n           differently.\n    \"\"\"\n    if netmhc:\n        peptide_names = [neoepitope_info.peptide_name]\n    else:\n        peptide_names = [x for x, y in peptides.items() if neoepitope_info.pept in y]\n    # Convert named tuple to dict so it can be modified\n    neoepitope_info = neoepitope_info._asdict()\n    # Handle fusion peptides (They are characterized by having all N's as the normal partner)\n    if neoepitope_info['normal_pept'] == 'N' * len(neoepitope_info['pept']):\n        neoepitope_info['normal_pept'] = neoepitope_info['normal_pred'] = 'NA'\n    # For each peptide, append the ensembl gene\n    for peptide_name in peptide_names:\n        print('{ni[allele]}\\t'\n              '{ni[pept]}\\t'\n              '{ni[normal_pept]}\\t'\n              '{pname}\\t'\n              '{ni[core]}\\t'\n              '0\\t'\n              '{ni[tumor_pred]}\\t'\n              '{ni[normal_pred]}\\t'\n              '{pmap}'.format(ni=neoepitope_info, pname=peptide_name,\n                                                  pmap=pepmap[peptide_name]), file=outfile)\n    return None", "label": 1}
{"code": "function _gpfHttpGenSetHeaders (methodName) {\n    return function (httpObj, headers) {\n        if (headers) {\n            Object.keys(headers).forEach(function (headerName) {\n                httpObj[methodName](headerName, headers[headerName]);\n            });\n        }\n    };\n}", "label": 3}
{"code": "def env(cls, separator=None, match=None, whitelist=None, parse_values=None, to_lower=None, convert_underscores=None):\n        \"\"\"Set environment variables as a source.\n\n        By default all environment variables available to the process are used.\n        This can be narrowed by the args.\n\n        Args:\n            separator: Keys are split along this character, the resulting\n                splits are considered nested values.\n            match: Regular expression for key matching. Keys matching the\n                expression are considered whitelisted.\n            whitelist: Only use environment variables that are listed in this\n                list.\n            parse_values: Try to parse all variable for well-known types.\n            to_lower: Convert all variable names to lower case.\n            convert_underscores: Convert all underscores in the name to dashes,\n                this takes place after separation via the separator option.\n        \"\"\"\n        cls.__hierarchy.append(env.Env(separator, match, whitelist, parse_values, to_lower, convert_underscores))", "label": 1}
{"code": "public static String determineAccessorName(@Nonnull final AccessorPrefix prefix, @Nonnull final String fieldName) {\n\t\tCheck.notNull(prefix, \"prefix\");\n\t\tCheck.notEmpty(fieldName, \"fieldName\");\n\t\tfinal Matcher m = PATTERN.matcher(fieldName);\n\t\tCheck.stateIsTrue(m.find(), \"passed field name '%s' is not applicable\", fieldName);\n\t\tfinal String name = m.group();\n\t\treturn prefix.getPrefix() + name.substring(0, 1).toUpperCase() + name.substring(1);\n\t}", "label": 0}
{"code": "def emptylineless(parser, token):\n    \"\"\"\n    Removes empty line.\n\n    Example usage::\n\n        {% emptylineless %}\n            test1\n\n            test2\n\n            test3\n        {% endemptylineless %}\n\n    This example would return this HTML::\n\n            test1\n            test2\n            test3\n\n    \"\"\"\n    nodelist = parser.parse(('endemptylineless',))\n    parser.delete_first_token()\n    return EmptylinelessNode(nodelist)", "label": 1}
{"code": "public function setCommuteMethod($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\CommuteMethod::class);\n        $this->commute_method = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static filterpolicy[] get(nitro_service service) throws Exception{\n\t\tfilterpolicy obj = new filterpolicy();\n\t\tfilterpolicy[] response = (filterpolicy[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function _computeDistanceOutsideRoom(distance) {\n  // We apply a linear ramp from 1 to 0 as the source is up to 1m outside.\n  let gain = 1;\n  if (distance > Utils.EPSILON_FLOAT) {\n    gain = 1 - distance / Utils.SOURCE_MAX_OUTSIDE_ROOM_DISTANCE;\n\n    // Clamp gain between 0 and 1.\n    gain = Math.max(0, Math.min(1, gain));\n  }\n  return gain;\n}", "label": 3}
{"code": "public static base_response delete(nitro_service client, String username) throws Exception {\n\t\tsystemuser deleteresource = new systemuser();\n\t\tdeleteresource.username = username;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def selfoss(reset_password=False):\n    '''Install, update and set up selfoss.\n\n    This selfoss installation uses sqlite (selfoss-default), php5-fpm and nginx.\n\n    The connection is https-only and secured by a letsencrypt certificate.  This\n    certificate must be created separately with task setup.server_letsencrypt.\n\n    More infos:\n      https://selfoss.aditu.de/\n      https://github.com/SSilence/selfoss/wiki\n      https://www.heise.de/ct/ausgabe/2016-13-RSS-Reader-Selfoss-hat-die-Nachrichtenlage-im-Blick-3228045.html\n      https://ct.de/yqp7\n    '''\n    hostname = re.sub(r'^[^@]+@', '', env.host)  # without username if any\n    sitename = query_input(\n                   question='\\nEnter site-name of Your trac web service',\n                   default=flo('selfoss.{hostname}'))\n    username = env.user\n\n    site_dir = flo('/home/{username}/sites/{sitename}')\n\n    checkout_latest_release_of_selfoss()\n    create_directory_structure(site_dir)\n\n    restored = install_selfoss(sitename, site_dir, username)\n\n    nginx_site_config(username, sitename, hostname)\n    enable_php5_socket_file()\n\n    if not restored or reset_password:\n        setup_selfoss_user(username, sitename, site_dir)\n\n    print_msg('\\n## reload nginx and restart php\\n')\n    run('sudo service nginx reload')\n    run('sudo service php5-fpm restart')", "label": 1}
{"code": "public function setMessageType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\StreamingRecognitionResult_MessageType::class);\n        $this->message_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function findOrFail($name)\n    {\n        $module = $this->find($name);\n\n        if ($module !== null) {\n            return $module;\n        }\n\n        throw new ModuleNotFoundException(\"Module [{$name}] does not exist!\");\n    }", "label": 2}
{"code": "def current_scope(klass = nil)\n      if klass && Thread.current[CURRENT_SCOPE_KEY].respond_to?(:keys)\n        Thread.current[CURRENT_SCOPE_KEY][\n            Thread.current[CURRENT_SCOPE_KEY].keys.find { |k| k <= klass }\n        ]\n      else\n        Thread.current[CURRENT_SCOPE_KEY]\n      end\n    end", "label": 4}
{"code": "def get_cleaned_data_for_step(self, step):\n        \"\"\"\n        Returns the cleaned data for a given `step`. Before returning the\n        cleaned data, the stored values are being revalidated through the\n        form. If the data doesn't validate, None will be returned.\n        \"\"\"\n        if step in self.form_list:\n            form_obj = self.get_form(step=step,\n                data=self.storage.get_step_data(step),\n                files=self.storage.get_step_files(step))\n            if form_obj.is_valid():\n                return form_obj.cleaned_data\n        return None", "label": 1}
{"code": "function createProtocol(attrs, opts) {\n  opts = opts || {};\n\n  var name = attrs.protocol;\n  if (!name) {\n    throw new Error('missing protocol name');\n  }\n  if (attrs.namespace !== undefined) {\n    opts.namespace = attrs.namespace;\n  } else {\n    var match = /^(.*)\\.[^.]+$/.exec(name);\n    if (match) {\n      opts.namespace = match[1];\n    }\n  }\n  name = types.qualify(name, opts.namespace);\n\n  if (attrs.types) {\n    attrs.types.forEach(function (obj) { types.createType(obj, opts); });\n  }\n\n  var messages = {};\n  if (attrs.messages) {\n    Object.keys(attrs.messages).forEach(function (key) {\n      messages[key] = new Message(key, attrs.messages[key], opts);\n    });\n  }\n  return new Protocol(name, messages, opts.registry || {});\n}", "label": 3}
{"code": "private function beginTransaction(Session $session, array $options = [])\n    {\n        $options += [\n            'transactionOptions' => []\n        ];\n\n        return $this->connection->beginTransaction($options + [\n            'session' => $session->name(),\n            'database' => $session->info()['database']\n        ]);\n    }", "label": 2}
{"code": "def root(value = nil)\n      if value\n        @root = value\n      else\n        Utils::Kernel.Pathname(@root || Dir.pwd).realpath\n      end\n    end", "label": 4}
{"code": "def open_street_map_geoloc_link(data):\n    \"\"\"\n    Get a link to open street map pointing on this IP's geolocation.\n\n    Args:\n        data (str/tuple): IP address or (latitude, longitude).\n\n    Returns:\n        str: a link to open street map pointing on this IP's geolocation.\n    \"\"\"\n    if isinstance(data, str):\n        lat_lon = ip_geoloc(data)\n        if lat_lon is None:\n            return ''\n        lat, lon = lat_lon\n    else:\n        lat, lon = data\n    return 'https://www.openstreetmap.org/search' \\\n           '?query=%s%%2C%s#map=7/%s/%s' % (lat, lon, lat, lon)", "label": 1}
{"code": "def cancel_order(self, order_id: str) -> str:\n        \"\"\"Cancel an order by ID.\"\"\"\n        self.log.debug(f'Canceling order id={order_id} on {self.name}')\n\n        if self.dry_run:  # Don't cancel if dry run\n            self.log.warning(f'DRY RUN: Order cancelled on {self.name}: id={order_id}')\n            return order_id\n\n        try:  # Cancel order\n            self._cancel_order(order_id)\n        except Exception as e:\n            raise self.exception(OrderNotFound, f'Failed to cancel order: id={order_id}', e) from e\n\n        self.log.info(f'Order cancelled on {self.name}: id={order_id}')\n        return order_id", "label": 1}
{"code": "def validate_document(self, definition):\n        \"\"\"\n        Validate given pipeline document.\n\n        The method is trying to load, parse and validate the spline document.\n        The validator verifies the Python structure B{not} the file format.\n\n        Args:\n            definition (str): path and filename of a yaml file containing a valid spline definition.\n\n        Returns:\n            dict: loaded and validated spline document.\n\n        Note:\n            if validation fails the application does exit!\n\n        See Also:\n            spline.validation.Validator\n        \"\"\"\n        initial_document = {}\n        try:\n            initial_document = Loader.load(definition)\n        except RuntimeError as exception:\n            self.logger.error(str(exception))\n            sys.exit(1)\n\n        document = Validator().validate(initial_document)\n        if document is None:\n            self.logger.info(\"Schema validation for '%s' has failed\", definition)\n            sys.exit(1)\n        self.logger.info(\"Schema validation for '%s' succeeded\", definition)\n        return document", "label": 1}
{"code": "func (d *Decoder) DecodeElement(v interface{}, start *StartElement) error {\n\tval := reflect.ValueOf(v)\n\tif val.Kind() != reflect.Ptr {\n\t\treturn errors.New(\"non-pointer passed to Unmarshal\")\n\t}\n\treturn d.unmarshal(val.Elem(), start)\n}", "label": 5}
{"code": "public static nspbr6_stats[] get(nitro_service service, options option) throws Exception{\n\t\tnspbr6_stats obj = new nspbr6_stats();\n\t\tnspbr6_stats[] response = (nspbr6_stats[])obj.stat_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def ok_kwarg(val):\n        \"\"\"Helper method for screening keyword arguments\"\"\"\n\n        import keyword\n\n        try:\n            return str.isidentifier(val) and not keyword.iskeyword(val)\n        except TypeError:\n            # Non-string values are never a valid keyword arg\n            return False", "label": 1}
{"code": "func setAggregationValueTypes(vals []core.TimestampedAggregationValue, wasInt map[string]bool) {\n\tfor _, aggregation := range core.MultiTypedAggregations {\n\t\tif isInt, ok := wasInt[string(aggregation)]; ok && isInt {\n\t\t\tfor i := range vals {\n\t\t\t\tval := vals[i].Aggregations[aggregation]\n\t\t\t\tval.ValueType = core.ValueInt64\n\t\t\t\tvals[i].Aggregations[aggregation] = val\n\t\t\t}\n\t\t} else if ok {\n\t\t\tfor i := range vals {\n\t\t\t\tval := vals[i].Aggregations[aggregation]\n\t\t\t\tval.ValueType = core.ValueFloat\n\t\t\t\tvals[i].Aggregations[aggregation] = val\n\t\t\t}\n\t\t}\n\t}\n}", "label": 5}
{"code": "def undo\n      case action\n      when 'create'\n        # destroys a newly created record\n        auditable.destroy!\n      when 'destroy'\n        # creates a new record with the destroyed record attributes\n        auditable_type.constantize.create!(audited_changes)\n      when 'update'\n        # changes back attributes\n        auditable.update_attributes!(audited_changes.transform_values(&:first))\n      else\n        raise StandardError, \"invalid action given #{action}\"\n      end\n    end", "label": 4}
{"code": "public function getOperations()\n    {\n        $result = [];\n        foreach ($this->definition['operations'] as $name => $definition) {\n            $result[$name] = $this->getOperation($name);\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "func (s *AuthServer) CreateUserWithoutOTP(token string, password string) (services.WebSession, error) {\n\tauthPreference, err := s.GetAuthPreference()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif authPreference.GetSecondFactor() != teleport.OFF {\n\t\treturn nil, trace.AccessDenied(\"missing second factor\")\n\t}\n\ttokenData, err := s.GetSignupToken(token)\n\tif err != nil {\n\t\tlog.Warningf(\"failed to get signup token: %v\", err)\n\t\treturn nil, trace.AccessDenied(\"expired or incorrect signup token\")\n\t}\n\n\terr = s.UpsertPassword(tokenData.User.Name, []byte(password))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// create services.User and services.WebSession\n\twebSession, err := s.createUserAndSession(tokenData)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn webSession, nil\n}", "label": 5}
{"code": "def seq_info(names, id2names, insertions, sequences):\n    \"\"\"\n    get insertion information from header\n    \"\"\"\n    seqs = {} # seqs[id] = [gene, model, [[i-gene_pos, i-model_pos, i-length, iseq, [orfs], [introns]], ...]]\n    for name in names:\n        id = id2names[name]\n        gene = name.split('fromHMM::', 1)[0].rsplit(' ', 1)[1]\n        model = name.split('fromHMM::', 1)[1].split('=', 1)[1].split()[0]\n        i_gene_pos = insertions[id] # coordinates of each insertion wrt gene\n        i_model_pos = name.split('fromHMM::', 1)[1].split('model-pos(ins-len)=')[1].split()[0].split(';') # model overlap\n        i_info = []\n        for i, ins in enumerate(i_gene_pos):\n            model_pos = i_model_pos[i].split('-')[1].split('(')[0]\n            length = i_model_pos[i].split('(')[1].split(')')[0]\n            iheader = '>%s_%s insertion::seq=%s type=insertion strand=n/a gene-pos=%s-%s model-pos=%s'\\\n                    % (id, (i + 1), (i + 1), ins[0], ins[1], model_pos)\n            iseq = sequences[id][1][ins[0]:(ins[1] + 1)]\n            iseq = [iheader, iseq]\n            info = [ins, model_pos, length, iseq, [], []]\n            i_info.append(info)\n        seqs[id] = [gene, model, i_info]\n    return seqs", "label": 1}
{"code": "def pmap(enumerable)\n      return to_enum(:pmap, enumerable) unless block_given?\n      if enumerable.count == 1\n        enumerable.collect { |object| yield(object) }\n      else\n        enumerable.collect { |object| Thread.new { yield(object) } }.collect(&:value)\n      end\n    end", "label": 4}
{"code": "protected function basic_return($reader, $message)\n    {\n        $callback = $this->basic_return_callback;\n        if (!is_callable($callback)) {\n            $this->debug->debug_msg('Skipping unhandled basic_return message');\n            return null;\n        }\n\n        $reply_code = $reader->read_short();\n        $reply_text = $reader->read_shortstr();\n        $exchange = $reader->read_shortstr();\n        $routing_key = $reader->read_shortstr();\n\n        call_user_func_array($callback, array(\n            $reply_code,\n            $reply_text,\n            $exchange,\n            $routing_key,\n            $message,\n        ));\n    }", "label": 2}
{"code": "def stream(socket)\n      include_proxy_headers if using_proxy? && !@uri.https?\n      Request::Writer.new(socket, body, headers, headline).stream\n    end", "label": 4}
{"code": "public static auditmessages[] get(nitro_service service, auditmessages_args args) throws Exception{\n\t\tauditmessages obj = new auditmessages();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tauditmessages[] response = (auditmessages[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function startOf($unit, ...$params)\n    {\n        $ucfUnit = ucfirst(static::singularUnit($unit));\n        $method = \"startOf$ucfUnit\";\n        if (!method_exists($this, $method)) {\n            throw new InvalidArgumentException(\"Unknown unit '$unit'\");\n        }\n\n        return $this->$method(...$params);\n    }", "label": 2}
{"code": "public Constructor<?> getCompatibleConstructor(Class<?> type,\r\n\t\t\tClass<?> argumentType) {\r\n\t\ttry {\r\n\t\t\treturn type.getConstructor(new Class[] { argumentType });\r\n\t\t} catch (Exception e) {\r\n\t\t\t// get public classes and interfaces\r\n\t\t\tClass<?>[] types = type.getClasses();\r\n\r\n\t\t\tfor (int i = 0; i < types.length; i++) {\r\n\t\t\t\ttry {\r\n\t\t\t\t\treturn type.getConstructor(new Class[] { types[i] });\r\n\t\t\t\t} catch (Exception e1) {\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn null;\r\n\t}", "label": 0}
{"code": "def delete_guild_role(data)\n      role_id = data['role_id'].to_i\n      server_id = data['guild_id'].to_i\n      server = @servers[server_id]\n      server.delete_role(role_id)\n    end", "label": 4}
{"code": "private function cleanPostInputs()\n    {\n        $args = [\n            'action'   => FILTER_SANITIZE_STRING,\n            'password' => FILTER_SANITIZE_STRING,\n            'from'     => FILTER_SANITIZE_STRING,\n            'to'       => [\n                'filter' => FILTER_SANITIZE_NUMBER_INT,\n                'flags'  => FILTER_REQUIRE_ARRAY,\n            ],\n            'message'      => FILTER_UNSAFE_RAW,\n            'image'        => FILTER_VALIDATE_URL,\n            'audio'        => FILTER_VALIDATE_URL,\n            'video'        => FILTER_VALIDATE_URL,\n            'locationname' => FILTER_SANITIZE_STRING,\n            'status'       => FILTER_SANITIZE_STRING,\n            'userlat'      => FILTER_SANITIZE_STRING,\n            'userlong'     => FILTER_SANITIZE_STRING,\n        ];\n\n        $myinputs = filter_input_array(INPUT_POST, $args);\n        if (!$myinputs) {\n            throw Exception('Problem Filtering the inputs');\n        }\n\n        return $myinputs;\n    }", "label": 2}
{"code": "public function rewrite($destination, array $options = [])\n    {\n        $options['useCopySourceHeaders'] = true;\n        $destinationKey = isset($options['destinationEncryptionKey']) ? $options['destinationEncryptionKey'] : null;\n        $destinationKeySHA256 = isset($options['destinationEncryptionKeySHA256'])\n            ? $options['destinationEncryptionKeySHA256']\n            : null;\n\n        $options = $this->formatDestinationRequest($destination, $options);\n\n        do {\n            $response = $this->connection->rewriteObject($options);\n            $options['rewriteToken'] = isset($response['rewriteToken']) ? $response['rewriteToken'] : null;\n        } while ($options['rewriteToken']);\n\n        return new StorageObject(\n            $this->connection,\n            $response['resource']['name'],\n            $response['resource']['bucket'],\n            $response['resource']['generation'],\n            $response['resource'] + ['requesterProjectId' => $this->identity['userProject']],\n            $destinationKey,\n            $destinationKeySHA256\n        );\n    }", "label": 2}
{"code": "private void userInfoInit() {\n\t\tboolean first = true;\n\t\tuserId = null;\n\t\tuserLocale = null;\n\t\tuserName = null;\n\t\tuserOrganization = null;\n\t\tuserDivision = null;\n\t\tif (null != authentications) {\n\t\t\tfor (Authentication auth : authentications) {\n\t\t\t\tuserId = combine(userId, auth.getUserId());\n\t\t\t\tuserName = combine(userName, auth.getUserName());\n\t\t\t\tif (first) {\n\t\t\t\t\tuserLocale = auth.getUserLocale();\n\t\t\t\t\tfirst = false;\n\t\t\t\t} else {\n\t\t\t\t\tif (null != auth.getUserLocale() &&\n\t\t\t\t\t\t\t(null == userLocale || !userLocale.equals(auth.getUserLocale()))) {\n\t\t\t\t\t\tuserLocale = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tuserOrganization = combine(userOrganization, auth.getUserOrganization());\n\t\t\t\tuserDivision = combine(userDivision, auth.getUserDivision());\n\t\t\t}\n\t\t}\n\n\t\t// now calculate the \"id\" for this context, this should be independent of the data order, so sort\n\t\tMap<String, List<String>> idParts = new HashMap<String, List<String>>();\n\t\tif (null != authentications) {\n\t\t\tfor (Authentication auth : authentications) {\n\t\t\t\tList<String> auths = new ArrayList<String>();\n\t\t\t\tfor (BaseAuthorization ba : auth.getAuthorizations()) {\n\t\t\t\t\tauths.add(ba.getId());\n\t\t\t\t}\n\t\t\t\tCollections.sort(auths);\n\t\t\t\tidParts.put(auth.getSecurityServiceId(), auths);\n\t\t\t}\n\t\t}\n\t\tStringBuilder sb = new StringBuilder();\n\t\tList<String> sortedKeys = new ArrayList<String>(idParts.keySet());\n\t\tCollections.sort(sortedKeys);\n\t\tfor (String key : sortedKeys) {\n\t\t\tif (sb.length() > 0) {\n\t\t\t\tsb.append('|');\n\t\t\t}\n\t\t\tList<String> auths = idParts.get(key);\n\t\t\tfirst = true;\n\t\t\tfor (String ak : auths) {\n\t\t\t\tif (first) {\n\t\t\t\t\tfirst = false;\n\t\t\t\t} else {\n\t\t\t\t\tsb.append('|');\n\t\t\t\t}\n\t\t\t\tsb.append(ak);\n\t\t\t}\n\t\t\tsb.append('@');\n\t\t\tsb.append(key);\n\t\t}\n\t\tid = sb.toString();\n\t}", "label": 0}
{"code": "def pencil2():\n    '''Install or update latest Pencil version 2, a GUI prototyping tool.\n\n    Tip: For svg exports displayed proper in other programs (eg. inkscape,\n    okular, reveal.js presentations) only use the 'Common Shapes' and\n    'Desktop - Sketchy GUI' elements.\n\n    More info:\n        github repo (forked version 2): https://github.com/prikhi/pencil\n    '''\n    repo_name = 'pencil2'\n    repo_dir = flo('~/repos/{repo_name}')\n\n    print_msg('## fetch latest pencil\\n')\n    checkup_git_repo_legacy(url='https://github.com/prikhi/pencil.git',\n                            name=repo_name)\n\n    print_msg('\\n## build properties\\n')\n    update_or_append_line(flo('{repo_dir}/build/properties.sh'),\n                          prefix='export MAX_VERSION=',\n                          new_line=\"export MAX_VERSION='100.*'\")\n    run(flo('cat {repo_dir}/build/properties.sh'))\n\n    run(flo('cd {repo_dir}/build && ./build.sh  linux'),\n        msg='\\n## build pencil\\n')\n    install_user_command_legacy('pencil2', pencil2_repodir=repo_dir)\n    print_msg('\\nNow You can start pencil version 2 with this command:\\n\\n'\n              '    pencil2')", "label": 1}
{"code": "function(file, lint, isError, isWarning, errorLocation) {\n        var lintId = (isError) ? colors.bgRed(colors.white(lint.id)) : colors.bgYellow(colors.white(lint.id));\n        var message = '';\n        if (errorLocation) {\n            message = file.path + ':' + (errorLocation.line + 1) + ':' + (errorLocation.column + 1) + ' ' + lintId + ' ' + lint.message;\n        } else {\n            message = file.path + ': ' + lintId + ' ' + lint.message;\n        }\n\n        if (isError) {\n            log.error(message);\n        } else {\n            log.warning(message);\n        }\n    }", "label": 3}
{"code": "def to_xml_string(r_index, str = '')\n      serialized_tag('row', str, :r => r_index + 1) do\n        tmp = '' # time / memory tradeoff, lots of calls to rubyzip costs more\n                 # time..\n        each_with_index { |cell, c_index| cell.to_xml_string(r_index, c_index, tmp) }\n        str << tmp\n      end\n    end", "label": 4}
{"code": "public int getCount(Class target)\r\n    {\r\n        PersistenceBroker broker = ((HasBroker) odmg.currentTransaction()).getBroker();\r\n        int result = broker.getCount(new QueryByCriteria(target));\r\n        return result;\r\n    }", "label": 0}
{"code": "private function countPlugins()\n    {\n        if (isset(self::$count)) {\n            return self::$count;\n        }\n\n        $count = count(glob(WPMU_PLUGIN_DIR . '/*/', GLOB_ONLYDIR | GLOB_NOSORT));\n\n        if (!isset(self::$cache['count']) || $count !== self::$cache['count']) {\n            self::$count = $count;\n            $this->updateCache();\n        }\n\n        return self::$count;\n    }", "label": 2}
{"code": "func (c *Client) UpsertProxy(s services.Server) error {\n\tdata, err := services.GetServerMarshaler().MarshalServer(s)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\targs := &upsertServerRawReq{\n\t\tServer: data,\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"proxies\"), args)\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "func DialerFromEnvironment(addr string) Dialer {\n\t// Try and get proxy addr from the environment.\n\tproxyAddr := getProxyAddress(addr)\n\n\t// If no proxy settings are in environment return regular ssh dialer,\n\t// otherwise return a proxy dialer.\n\tif proxyAddr == \"\" {\n\t\tlog.Debugf(\"No proxy set in environment, returning direct dialer.\")\n\t\treturn directDial{}\n\t}\n\tlog.Debugf(\"Found proxy %q in environment, returning proxy dialer.\", proxyAddr)\n\treturn proxyDial{proxyHost: proxyAddr}\n}", "label": 5}
{"code": "public void removePrefetchingListeners()\r\n    {\r\n        if (prefetchingListeners != null)\r\n        {\r\n            for (Iterator it = prefetchingListeners.iterator(); it.hasNext(); )\r\n            {\r\n                PBPrefetchingListener listener = (PBPrefetchingListener) it.next();\r\n                listener.removeThisListener();\r\n            }\r\n            prefetchingListeners.clear();\r\n        }\r\n    }", "label": 0}
{"code": "private function process_aliases( $aliases, $alias, $config_path, $operation = '' ) {\n\t\t// Convert data to YAML string.\n\t\t$yaml_data = Spyc::YAMLDump( $aliases );\n\n\t\t// Add data in config file.\n\t\tif ( file_put_contents( $config_path, $yaml_data ) ) {\n\t\t\tWP_CLI::success( \"$operation '{$alias}' alias.\" );\n\t\t}\n\t}", "label": 2}
{"code": "function process(payload) {\n  payload = payload.toLowerCase();\n\n  var ra28 = new identifier(identifier.RA28, payload.substr(0, 7));\n  var eui64 = ra28.toType(identifier.EUI64);\n  eui64.flags = flags.process(payload.substr(7, 1));\n  if (payload.length === 12) {\n    eui64.data = data.process(payload.substr(8, 4));\n  }\n  return eui64;\n}", "label": 3}
{"code": "public function diffInRealMinutes($date = null, $absolute = true)\n    {\n        return (int) ($this->diffInRealSeconds($date, $absolute) / static::SECONDS_PER_MINUTE);\n    }", "label": 2}
{"code": "def install_extension(conn, extension: str):\n    \"\"\"Install Postgres extension.\"\"\"\n\n    query = 'CREATE EXTENSION IF NOT EXISTS \"%s\";'\n\n    with conn.cursor() as cursor:\n        cursor.execute(query, (AsIs(extension),))\n\n    installed = check_extension(conn, extension)\n\n    if not installed:\n        raise psycopg2.ProgrammingError(\n            'Postgres extension failed installation.', extension\n        )", "label": 1}
{"code": "public static function renameColumns($tableName, array $columnNames)\n    {\n        return [\n            'up' => function (Builder $schema) use ($tableName, $columnNames) {\n                $schema->table($tableName, function (Blueprint $table) use ($columnNames) {\n                    foreach ($columnNames as $from => $to) {\n                        $table->renameColumn($from, $to);\n                    }\n                });\n            },\n            'down' => function (Builder $schema) use ($tableName, $columnNames) {\n                $schema->table($tableName, function (Blueprint $table) use ($columnNames) {\n                    foreach ($columnNames as $to => $from) {\n                        $table->renameColumn($from, $to);\n                    }\n                });\n            }\n        ];\n    }", "label": 2}
{"code": "function isTypeReferenceIdentifier(entityName) {\n            var node = entityName;\n            while (node.parent && node.parent.kind === 139 /* QualifiedName */) {\n                node = node.parent;\n            }\n            return node.parent && (node.parent.kind === 155 /* TypeReference */ || node.parent.kind === 267 /* JSDocTypeReference */);\n        }", "label": 3}
{"code": "protected function recalculateTotal(): void\n    {\n        $this->total = $this->itemsTotal + $this->adjustmentsTotal;\n\n        if ($this->total < 0) {\n            $this->total = 0;\n        }\n    }", "label": 2}
{"code": "def add_bgcolor(self, colname, cmap='copper', mode='absmax',\n            threshold=2):\n        \"\"\"Change column content into HTML paragraph with background color\n\n        :param colname:\n        :param cmap: a colormap (matplotlib) or created using\n            colormap package (from pypi).\n        :param mode: type of normalisation in 'absmax', 'max', 'clip'\n            (see details below)\n        :param threshold: used if mode is set to 'clip'\n\n        Colormap have values between 0 and 1 so we need to normalised the data\n        between 0 and 1. There are 3 mode to normalise the data so far.\n\n        If mode is set to 'absmax', negatives and positives values are\n        expected to be found in a range from -inf to inf. Values are\n        scaled in between [0,1] X' = (X / M +1) /2. where m is the absolute\n        maximum. Ideally a colormap should be made of 3 colors, the first\n        color used for negative values, the second for zeros and third color\n        for positive values.\n\n        If mode is set to 'clip', values are clipped to a max value (parameter\n        *threshold* and values are normalised by that same threshold.\n\n        If mode is set to 'max', values are normalised by the max.\n\n        \"\"\"\n        try:\n            # if a cmap is provided, it may be just a known cmap name\n            cmap = cmap_builder(cmap)\n        except:\n            pass\n\n        data = self.df[colname].values\n\n        if len(data) == 0:\n            return\n\n        if mode == 'clip':\n            data = [min(x, threshold)/float(threshold) for x in data]\n        elif mode == 'absmax':\n            m = abs(data.min())\n            M = abs(data.max())\n            M = max([m, M])\n            if M != 0:\n                data = (data / M + 1)/2.\n        elif mode == 'max':\n            if data.max() != 0:\n                data = data / float(data.max())\n\n        # the expected RGB values for a given data point\n        rgbcolors = [cmap(x)[0:3] for x in data]\n        hexcolors = [rgb2hex(*x, normalised=True) for x in rgbcolors]\n\n        # need to read original data again\n        data = self.df[colname].values\n        # need to set precision since this is going to be a text not a number\n        # so pandas will not use the precision for those cases:\n\n        def prec(x):\n            try:\n                # this may fail if for instance x is nan or inf\n                x = easydev.precision(x, self.pd_options['precision'])\n                return x\n            except:\n                return x\n\n        data = [prec(x) for x in data]\n        html_formatter = '<p style=\"background-color:{0}\">{1}</p>'\n        self.df[colname] = [html_formatter.format(x, y)\n                for x, y in zip(hexcolors, data)]", "label": 1}
{"code": "func createIPVlan(containerIfName, parent, ipvlanMode string) (string, error) {\n\t// Set the ipvlan mode. Default is bridge mode\n\tmode, err := setIPVlanMode(ipvlanMode)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"Unsupported %s ipvlan mode: %v\", ipvlanMode, err)\n\t}\n\t// verify the Docker host interface acting as the macvlan parent iface exists\n\tif !parentExists(parent) {\n\t\treturn \"\", fmt.Errorf(\"the requested parent interface %s was not found on the Docker host\", parent)\n\t}\n\t// Get the link for the master index (Example: the docker host eth iface)\n\tparentLink, err := ns.NlHandle().LinkByName(parent)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error occurred looking up the %s parent iface %s error: %s\", ipvlanType, parent, err)\n\t}\n\t// Create an ipvlan link\n\tipvlan := &netlink.IPVlan{\n\t\tLinkAttrs: netlink.LinkAttrs{\n\t\t\tName:        containerIfName,\n\t\t\tParentIndex: parentLink.Attrs().Index,\n\t\t},\n\t\tMode: mode,\n\t}\n\tif err := ns.NlHandle().LinkAdd(ipvlan); err != nil {\n\t\t// If a user creates a macvlan and ipvlan on same parent, only one slave iface can be active at a time.\n\t\treturn \"\", fmt.Errorf(\"failed to create the %s port: %v\", ipvlanType, err)\n\t}\n\n\treturn ipvlan.Attrs().Name, nil\n}", "label": 5}
{"code": "public static base_response expire(nitro_service client, cachecontentgroup resource) throws Exception {\n\t\tcachecontentgroup expireresource = new cachecontentgroup();\n\t\texpireresource.name = resource.name;\n\t\treturn expireresource.perform_operation(client,\"expire\");\n\t}", "label": 0}
{"code": "private <T> T getBeanOrNull(String name, Class<T> requiredType) {\n\t\tif (name == null || !applicationContext.containsBean(name)) {\n\t\t\treturn null;\n\t\t} else {\n\t\t\ttry {\n\t\t\t\treturn applicationContext.getBean(name, requiredType);\n\t\t\t} catch (BeansException be) {\n\t\t\t\tlog.error(\"Error during getBeanOrNull, not rethrown, \" + be.getMessage(), be);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t}", "label": 0}
{"code": "def fixtures_directory\n      @fixtures_directory ||= begin\n        candidates = config.fixtures_directories.map { |dir| File.join(root_directory, dir) }\n        directory = candidates.find { |d| Aruba.platform.directory? d }\n\n        fail \"No existing fixtures directory found in #{candidates.map { |d| format('\"%s\"', d) }.join(', ')}.\" unless directory\n        directory\n      end\n\n      fail %(Fixtures directory \"#{@fixtures_directory}\" is not a directory) unless Aruba.platform.directory?(@fixtures_directory)\n\n      ArubaPath.new(@fixtures_directory)\n    end", "label": 4}
{"code": "def handle_attribute_code(attribute, code, name)\n      null_flavor = attribute.at_xpath('./cda:code/@nullFlavor', NAMESPACES).try(:value)\n      o_text = attribute.at_xpath('./cda:code/cda:originalText/@value', NAMESPACES).try(:value)\n      code_obj = HQMF::Coded.new(attribute.at_xpath('./cda:code/@xsi:type', NAMESPACES).try(:value) || 'CD',\n                                 attribute.at_xpath('./cda:code/@codeSystem', NAMESPACES).try(:value),\n                                 code,\n                                 attribute.at_xpath('./cda:code/@valueSet', NAMESPACES).try(:value),\n                                 name,\n                                 null_flavor,\n                                 o_text)\n      [code_obj, null_flavor, o_text]\n    end", "label": 4}
{"code": "public function setRecordLocation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\RecordLocation::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *APIServer) getU2FAppID(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tcap, err := auth.GetAuthPreference()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tuniversalSecondFactor, err := cap.GetU2F()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/fido.trusted-apps+json\")\n\treturn universalSecondFactor.AppID, nil\n}", "label": 5}
{"code": "def values_by_name(key, names)\n      vals = {}\n      names.each do |name|\n        FFI::Pointer.from_string_to_wide_string(name) do |subkeyname_ptr|\n          begin\n            _, vals[name] = read(key, subkeyname_ptr)\n          rescue Puppet::Util::Windows::Error => e\n            # ignore missing names, but raise other errors\n            raise e unless e.code == Puppet::Util::Windows::Error::ERROR_FILE_NOT_FOUND\n          end\n        end\n      end\n      vals\n    end", "label": 4}
{"code": "def _connect(cls):\n        \"\"\"\n        Connect signal to current model\n        \"\"\"\n        post_save.connect(\n            notify_items, sender=cls,\n            dispatch_uid='knocker_{0}'.format(cls.__name__)\n        )", "label": 1}
{"code": "func (p *PortList) PopInt() int {\n\ti, err := strconv.Atoi(p.Pop())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn i\n}", "label": 5}
{"code": "public function setFrames($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\LabelFrame::class);\n        $this->frames = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private function autoFlush()\n    {\n        if ($this->config['autoflush']\n            && count($this->queue) >= $this->config['threshold']\n        ) {\n            // Flush only once. Unprocessed items are handled in a later flush.\n            $this->flush(false);\n        }\n    }", "label": 2}
{"code": "protected void modify(Transaction t) {\n        try {\n            this.lock.writeLock().lock();\n            t.perform();\n        } finally {\n            this.lock.writeLock().unlock();\n        }\n    }", "label": 0}
{"code": "func (t *TransportPort) String() string {\n\treturn fmt.Sprintf(\"%s/%d\", t.Proto.String(), t.Port)\n}", "label": 5}
{"code": "def bidi_streamer(requests, metadata: {}, &blk)\n      raise_error_if_already_executed\n      # Metadata might have already been sent if this is an operation view\n      begin\n        send_initial_metadata(metadata)\n      rescue GRPC::Core::CallError => e\n        batch_result = @call.run_batch(RECV_STATUS_ON_CLIENT => nil)\n        set_input_stream_done\n        set_output_stream_done\n        attach_status_results_and_complete_call(batch_result)\n        raise e\n      rescue => e\n        set_input_stream_done\n        set_output_stream_done\n        raise e\n      end\n\n      bd = BidiCall.new(@call,\n                        @marshal,\n                        @unmarshal,\n                        metadata_received: @metadata_received)\n\n      bd.run_on_client(requests,\n                       proc { set_input_stream_done },\n                       proc { set_output_stream_done },\n                       &blk)\n    end", "label": 4}
{"code": "def commit_offsets(recommit = false)\n      offsets = offsets_to_commit(recommit)\n      unless offsets.empty?\n        @logger.debug \"Committing offsets#{recommit ? ' with recommit' : ''}: #{prettify_offsets(offsets)}\"\n\n        @group.commit_offsets(offsets)\n\n        @last_commit = Time.now\n        @last_recommit = Time.now if recommit\n\n        @uncommitted_offsets = 0\n        @committed_offsets = nil\n      end\n    end", "label": 4}
{"code": "public function addEvaluatedExpressions(array $expressions)\n    {\n        foreach ($expressions as $expression => $result) {\n            try {\n                $this->evaluatedExpressions[] = $this->addVariable($expression, $result);\n            } catch (BufferFullException $e) {\n                $this->evaluatedExpressions[] = $this->variableTable->bufferFullVariable();\n            }\n        }\n    }", "label": 2}
{"code": "function convertRenderer (cell) {\n  const {renderer} = cell\n  if (renderer === undefined) {\n    return\n  }\n  const basicRenderers = [\n    'boolean',\n    'string',\n    'number'\n  ]\n  if (basicRenderers.indexOf(renderer) >= 0) {\n    return {name: renderer}\n  }\n  return customRenderer(renderer, cell.properties)\n}", "label": 3}
{"code": "public function userFromTokenAndSecret($token, $secret)\n    {\n        $tokenCredentials = new TokenCredentials();\n\n        $tokenCredentials->setIdentifier($token);\n        $tokenCredentials->setSecret($secret);\n\n        $user = $this->server->getUserDetails(\n            $tokenCredentials, $this->shouldBypassCache($token, $secret)\n        );\n\n        $instance = (new User)->setRaw($user->extra)\n            ->setToken($tokenCredentials->getIdentifier(), $tokenCredentials->getSecret());\n\n        return $instance->map([\n            'id' => $user->uid,\n            'nickname' => $user->nickname,\n            'name' => $user->name,\n            'email' => $user->email,\n            'avatar' => $user->imageUrl,\n        ]);\n    }", "label": 2}
{"code": "public void bindDelete(PreparedStatement stmt, ClassDescriptor cld, Object obj) throws SQLException\r\n    {\r\n        if (cld.getDeleteProcedure() != null)\r\n        {\r\n            this.bindProcedure(stmt, cld, obj, cld.getDeleteProcedure());\r\n        }\r\n        else\r\n        {\r\n            int index = 1;\r\n            ValueContainer[] values, currentLockingValues;\r\n\r\n            currentLockingValues = cld.getCurrentLockingValues(obj);\r\n            // parameters for WHERE-clause pk\r\n            values = getKeyValues(m_broker, cld, obj);\r\n            for (int i = 0; i < values.length; i++)\r\n            {\r\n                setObjectForStatement(stmt, index, values[i].getValue(), values[i].getJdbcType().getType());\r\n                index++;\r\n            }\r\n\r\n            // parameters for WHERE-clause locking\r\n            values = currentLockingValues;\r\n            for (int i = 0; i < values.length; i++)\r\n            {\r\n                setObjectForStatement(stmt, index, values[i].getValue(), values[i].getJdbcType().getType());\r\n                index++;\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def main(arg1=55, arg2='test', arg3=None):\n    \"\"\"\n    This is a sample program to show how a learning agent can\n    be logged using AIKIF. \n    The idea is that this main function is your algorithm, which\n    will run until it finds a successful result. The result is \n    returned and the time taken is logged.\n    \n    There can optionally be have additional functions \n    to call to allow for easy logging access\n    \"\"\"\n    print('Starting dummy AI algorithm with :', arg1, arg2, arg3)\n    \n    if arg3 is None:\n        arg3=[5,6,7,5,4,]\n    result = arg1 + arg3[0] * 7566.545  # dummy result\n    \n    print('Done - returning ', result)\n    return result", "label": 1}
{"code": "public static Integer getAsInteger(Object value) {\n\t\tInteger result = null;\n\n\t\ttry {\n\t\t\tif (value instanceof String) {\n\t\t\t\tresult = Integer.valueOf((String) value);\n\t\t\t} else if (value instanceof Number) {\n\t\t\t\tresult = ((Number) value).intValue();\n\t\t\t} else {\n\t\t\t\tresult = null;\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tresult = null;\n\t\t}\n\n\t\treturn result == null ? 0 : result;\n\t}", "label": 0}
{"code": "function WrapperError(message, innerError) {\n  // supports instantiating the object without the new keyword\n  if (!(this instanceof WrapperError)) {\n    return new WrapperError(message, innerError);\n  }\n\n  Error.call(this);\n  Error.captureStackTrace(this, WrapperError);\n\n  this.message = message;\n  this.innerError = innerError;\n}", "label": 3}
{"code": "function iteratorFactory(callback) {\n  return iterator\n\n  function iterator(parent) {\n    var children = parent && parent.children\n\n    if (!children) {\n      throw new Error('Missing children in `parent` for `modifier`')\n    }\n\n    return iterate(children, callback, parent)\n  }\n}", "label": 3}
{"code": "def click_on_label(step, label):\n    \"\"\"\n    Click on a label\n    \"\"\"\n\n    with AssertContextManager(step):\n        elem = world.browser.find_element_by_xpath(str(\n            '//label[normalize-space(text()) = \"%s\"]' % label))\n        elem.click()", "label": 1}
{"code": "def add_scroller_widget(self, ref, left=1, top=1, right=20, bottom=1, direction=\"h\", speed=1, text=\"Message\"):     \n        \n        \"\"\" Add Scroller Widget \"\"\"\n        \n        if ref not in self.widgets:   \n            widget = ScrollerWidget(screen=self, ref=ref, left=left, top=top, right=right, bottom=bottom, direction=direction, speed=speed, text=text)\n            self.widgets[ref] = widget\n            return self.widgets[ref]", "label": 1}
{"code": "function mergeSubResource(attrNode, subResourceConfig, context) {\n    // Merge options from sub-resource to parent (order is irrelevant here):\n    Object.keys(subResourceConfig).forEach(optionName => {\n        if (optionName === 'attributes') {\n            if (!attrNode.attributes) attrNode.attributes = {};\n        } else if (optionName === 'dataSources') {\n            const newDataSources = Object.assign({}, subResourceConfig.dataSources);\n\n            if (attrNode.dataSources) {\n                Object.keys(attrNode.dataSources).forEach(dataSourceName => {\n                    if (newDataSources[dataSourceName]) {\n                        if (attrNode.dataSources[dataSourceName].inherit) {\n                            if (attrNode.dataSources[dataSourceName].inherit === 'inherit') {\n                                newDataSources[dataSourceName] = Object.assign(\n                                    {},\n                                    newDataSources[dataSourceName],\n                                    attrNode.dataSources[dataSourceName]\n                                );\n                            } else if (attrNode.dataSources[dataSourceName].inherit === 'replace') {\n                                newDataSources[dataSourceName] = attrNode.dataSources[dataSourceName];\n                            }\n                        } else {\n                            throw new ImplementationError(\n                                `Cannot overwrite DataSource \"${dataSourceName}\"` +\n                                    ` in \"${context.attrPath.join('.')}\" (maybe use \"inherit\"?)`\n                            );\n                        }\n                    } else {\n                        newDataSources[dataSourceName] = attrNode.dataSources[dataSourceName];\n                    }\n                });\n            }\n\n            attrNode.dataSources = newDataSources;\n        } else if (typeof subResourceConfig[optionName] === 'object') {\n            attrNode[optionName] = cloneDeep(subResourceConfig[optionName]);\n        } else if (!(optionName in attrNode)) {\n            attrNode[optionName] = subResourceConfig[optionName];\n        }\n    });\n\n    attrNode._origNodes = attrNode._origNodes || [];\n    attrNode._origNodes.push(subResourceConfig);\n}", "label": 3}
{"code": "public void update(Object feature) throws LayerException {\n\t\tSession session = getSessionFactory().getCurrentSession();\n\t\tsession.update(feature);\n\t}", "label": 0}
{"code": "def all_more_like_this_fields\n      @more_like_this_field_factories_cache.values.map do |field_factories| \n        field_factories.map { |field_factory| field_factory.build }\n      end.flatten\n    end", "label": 4}
{"code": "function(url, data) {\n            return $.ajax({\n                url: url,\n                data: ko.toJSON(data),\n                type: 'POST',\n                contentType: 'application/json',\n                dataType: 'json'\n            });\n        }", "label": 3}
{"code": "def request(self, method, params=None, query_continue=None,\n                files=None, auth=None, continuation=False):\n        \"\"\"\n        Sends an HTTP request to the API.\n\n        :Parameters:\n            method : `str`\n                Which HTTP method to use for the request?\n                (Usually \"POST\" or \"GET\")\n            params : `dict`\n                A set of parameters to send with the request.  These parameters\n                will be included in the POST body for post requests or a query\n                string otherwise.\n            query_continue : `dict`\n                A 'continue' field from a past request.  This field represents\n                the point from which a query should be continued.\n            files : `dict`\n                A dictionary of (filename : `str`, data : `bytes`) pairs to\n                send with the request.\n            auth : mixed\n                Auth tuple or callable to enable Basic/Digest/Custom HTTP Auth.\n            continuation : `bool`\n                If true, a continuation will be attempted and a generator of\n                JSON response documents will be returned.\n\n        :Returns:\n            A response JSON documents (or a generator of documents if\n            `continuation == True`)\n        \"\"\"\n        normal_params = _normalize_params(params, query_continue)\n        if continuation:\n            return self._continuation(method, params=normal_params, auth=auth,\n                                      files=files)\n        else:\n            return self._request(method, params=normal_params, auth=auth,\n                                 files=files)", "label": 1}
{"code": "public static base_responses add(nitro_service client, vlan resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tvlan addresources[] = new vlan[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new vlan();\n\t\t\t\taddresources[i].id = resources[i].id;\n\t\t\t\taddresources[i].aliasname = resources[i].aliasname;\n\t\t\t\taddresources[i].ipv6dynamicrouting = resources[i].ipv6dynamicrouting;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func ParseInt(b []byte) (int64, error) {\n\tif v, ok, overflow := parseInt(b); !ok {\n\t\tif overflow {\n\t\t\treturn 0, OverflowIntegerError\n\t\t}\n\t\treturn 0, MalformedValueError\n\t} else {\n\t\treturn v, nil\n\t}\n}", "label": 5}
{"code": "def run_somaticsniper(job, tumor_bam, normal_bam, univ_options, somaticsniper_options, split=True):\n    \"\"\"\n    Run the SomaticSniper subgraph on the DNA bams.  Optionally split the results into\n    per-chromosome vcfs.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict somaticsniper_options: Options specific to SomaticSniper\n    :param bool split: Should the results be split into perchrom vcfs?\n    :return: Either the fsID to the genome-level vcf or a dict of results from running SomaticSniper\n             on every chromosome\n             perchrom_somaticsniper:\n                 |- 'chr1': fsID\n                 |- 'chr2' fsID\n                 |\n                 |-...\n                 |\n                 +- 'chrM': fsID\n    :rtype: toil.fileStore.FileID|dict\n    \"\"\"\n    # Get a list of chromosomes to handle\n    if somaticsniper_options['chromosomes']:\n        chromosomes = somaticsniper_options['chromosomes']\n    else:\n        chromosomes = sample_chromosomes(job, somaticsniper_options['genome_fai'])\n    perchrom_somaticsniper = defaultdict()\n    snipe = job.wrapJobFn(run_somaticsniper_full, tumor_bam, normal_bam, univ_options,\n                          somaticsniper_options,\n                          disk=PromisedRequirement(sniper_disk,\n                                                   tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n                                                   normal_bam['normal_dna_fix_pg_sorted.bam'],\n                                                   somaticsniper_options['genome_fasta']),\n                          memory='6G')\n    pileup = job.wrapJobFn(run_pileup, tumor_bam, univ_options, somaticsniper_options,\n                           disk=PromisedRequirement(pileup_disk,\n                                                    tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n                                                    somaticsniper_options['genome_fasta']),\n                           memory='6G')\n    filtersnipes = job.wrapJobFn(filter_somaticsniper, tumor_bam, snipe.rv(), pileup.rv(),\n                                 univ_options, somaticsniper_options,\n                                 disk=PromisedRequirement(sniper_filter_disk,\n                                                          tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n                                                          somaticsniper_options['genome_fasta']),\n                                 memory='6G')\n\n    job.addChild(snipe)\n    job.addChild(pileup)\n    snipe.addChild(filtersnipes)\n    pileup.addChild(filtersnipes)\n    if split:\n        unmerge_snipes = job.wrapJobFn(unmerge, filtersnipes.rv(), 'somaticsniper', chromosomes,\n                                       somaticsniper_options, univ_options)\n        filtersnipes.addChild(unmerge_snipes)\n        return unmerge_snipes.rv()\n    else:\n        return filtersnipes.rv()", "label": 1}
{"code": "public static base_responses add(nitro_service client, authenticationradiusaction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tauthenticationradiusaction addresources[] = new authenticationradiusaction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new authenticationradiusaction();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].serverip = resources[i].serverip;\n\t\t\t\taddresources[i].serverport = resources[i].serverport;\n\t\t\t\taddresources[i].authtimeout = resources[i].authtimeout;\n\t\t\t\taddresources[i].radkey = resources[i].radkey;\n\t\t\t\taddresources[i].radnasip = resources[i].radnasip;\n\t\t\t\taddresources[i].radnasid = resources[i].radnasid;\n\t\t\t\taddresources[i].radvendorid = resources[i].radvendorid;\n\t\t\t\taddresources[i].radattributetype = resources[i].radattributetype;\n\t\t\t\taddresources[i].radgroupsprefix = resources[i].radgroupsprefix;\n\t\t\t\taddresources[i].radgroupseparator = resources[i].radgroupseparator;\n\t\t\t\taddresources[i].passencoding = resources[i].passencoding;\n\t\t\t\taddresources[i].ipvendorid = resources[i].ipvendorid;\n\t\t\t\taddresources[i].ipattributetype = resources[i].ipattributetype;\n\t\t\t\taddresources[i].accounting = resources[i].accounting;\n\t\t\t\taddresources[i].pwdvendorid = resources[i].pwdvendorid;\n\t\t\t\taddresources[i].pwdattributetype = resources[i].pwdattributetype;\n\t\t\t\taddresources[i].defaultauthenticationgroup = resources[i].defaultauthenticationgroup;\n\t\t\t\taddresources[i].callingstationid = resources[i].callingstationid;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (agp *AuthGroupPermission) Update(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !agp._exists {\n\t\treturn errors.New(\"update failed: does not exist\")\n\t}\n\n\t// if deleted, bail\n\tif agp._deleted {\n\t\treturn errors.New(\"update failed: marked for deletion\")\n\t}\n\n\t// sql query\n\tconst sqlstr = `UPDATE auth_group_permissions SET ` +\n\t\t`group_id = ?, permission_id = ?` +\n\t\t` WHERE id = ?`\n\n\t// run query\n\tXOLog(sqlstr, agp.GroupID, agp.PermissionID, agp.ID)\n\t_, err = db.Exec(sqlstr, agp.GroupID, agp.PermissionID, agp.ID)\n\treturn err\n}", "label": 5}
{"code": "function(timestamp) {\n        if (!timestamp) {\n            return;\n        }\n        //TODO check this\n        //var secondsPerStamp = 1.001,\n        var timesplit = timestamp.replace(',', ':').split(':');\n        return (parseInt(timesplit[0], 10) * 3600 +\n            parseInt(timesplit[1], 10) * 60 +\n            parseInt(timesplit[2], 10) +\n            parseInt(timesplit[3], 10) / 1000) * 1000 * 1000;\n\n    }", "label": 3}
{"code": "def push(name)\n      @logger.info(\"Getting push: #{name}\")\n\n      name = name.to_sym\n\n      pushes = self.vagrantfile.config.push.__compiled_pushes\n      if !pushes.key?(name)\n        raise Vagrant::Errors::PushStrategyNotDefined,\n          name: name,\n          pushes: pushes.keys\n      end\n\n      strategy, config = pushes[name]\n      push_registry = Vagrant.plugin(\"2\").manager.pushes\n      klass, _ = push_registry.get(strategy)\n      if klass.nil?\n        raise Vagrant::Errors::PushStrategyNotLoaded,\n          name: strategy,\n          pushes: push_registry.keys\n      end\n\n      klass.new(self, config).push\n    end", "label": 4}
{"code": "public function getProjectId()\n    {\n        if (!isset($this->projectId)) {\n            $this->projectId = $this->get('project/project-id');\n        }\n\n        return $this->projectId;\n    }", "label": 2}
{"code": "def url_match?(request_url)\n      case base_url\n      when String\n        base_url == request_url\n      when Regexp\n        base_url === request_url\n      when nil\n        true\n      else\n        false\n      end\n    end", "label": 4}
{"code": "public Iterator getAllBaseTypes()\r\n    {\r\n        ArrayList baseTypes = new ArrayList();\r\n\r\n        baseTypes.addAll(_directBaseTypes.values());\r\n\r\n        for (int idx = baseTypes.size() - 1; idx >= 0; idx--)\r\n        {\r\n            ClassDescriptorDef curClassDef = (ClassDescriptorDef)baseTypes.get(idx);\r\n\r\n            for (Iterator it = curClassDef.getDirectBaseTypes(); it.hasNext();)\r\n            {\r\n                ClassDescriptorDef curBaseTypeDef = (ClassDescriptorDef)it.next();\r\n\r\n                if (!baseTypes.contains(curBaseTypeDef))\r\n                {\r\n                    baseTypes.add(0, curBaseTypeDef);\r\n                    idx++;\r\n                }\r\n            }\r\n        }\r\n        return baseTypes.iterator();\r\n    }", "label": 0}
{"code": "public static XClass getMemberType() throws XDocletException\r\n    {\r\n        if (getCurrentField() != null) {\r\n            return getCurrentField().getType();\r\n        }\r\n        else if (getCurrentMethod() != null) {\r\n            XMethod method = getCurrentMethod();\r\n\r\n            if (MethodTagsHandler.isGetterMethod(method)) {\r\n                return method.getReturnType().getType();\r\n            }\r\n            else if (MethodTagsHandler.isSetterMethod(method)) {\r\n                XParameter param = (XParameter)method.getParameters().iterator().next();\r\n\r\n                return param.getType();\r\n            }\r\n        }\r\n        return null;\r\n    }", "label": 0}
{"code": "func (l HostFirewallRulesetList) Keys() []string {\n\tvar keys []string\n\n\tfor _, rs := range l {\n\t\tkeys = append(keys, rs.Key)\n\t}\n\n\treturn keys\n}", "label": 5}
{"code": "func (info *HostCertificateInfo) SubjectName() *pkix.Name {\n\tif info.subjectName != nil {\n\t\treturn info.subjectName\n\t}\n\n\treturn info.toName(info.Subject)\n}", "label": 5}
{"code": "def devices(self):\n        \"\"\"Manages users enrolled u2f devices\"\"\"\n        self.verify_integrity()\n\n        if session.get('u2f_device_management_authorized', False):\n            if request.method == 'GET':\n                return jsonify(self.get_devices()), 200\n\n            elif request.method == 'DELETE':\n                response = self.remove_device(request.json)\n\n                if response['status'] == 'ok':\n                    return jsonify(response), 200\n                else:\n                    return jsonify(response), 404\n\n        return jsonify({'status': 'failed', 'error': 'Unauthorized!'}), 401", "label": 1}
{"code": "def algorithm=(alg)\n      @algorithm = begin\n        case alg.to_s\n        when 'hmac-sha-1'\n          OpenSSL::Digest::SHA1.new\n        when 'hmac-sha-256'\n          OpenSSL::Digest::SHA256.new\n        else\n          raise(ArgumentError, 'Unsupported algorithm')\n        end\n      end\n    end", "label": 4}
{"code": "public static Interface get(nitro_service service, String id) throws Exception{\n\t\tInterface obj = new Interface();\n\t\tobj.set_id(id);\n\t\tInterface response = (Interface) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def pop(self, name, default=SENTINEL):\n\t\t\"\"\"Retrieve and remove a value from the backing store, optionally with a default.\"\"\"\n\t\t\n\t\tif default is SENTINEL:\n\t\t\treturn self.__data__.pop(name)\n\t\t\n\t\treturn self.__data__.pop(name, default)", "label": 1}
{"code": "def matte_fill_to_border(x, y)\n      f = copy\n      f.opacity = Magick::OpaqueOpacity unless f.alpha?\n      f.matte_flood_fill(border_color, TransparentOpacity,\n                         x, y, FillToBorderMethod)\n    end", "label": 4}
{"code": "private TableAlias createTableAlias(String aTable, String aPath, String aUserAlias)\r\n    {\r\n\t\tif (aUserAlias == null)\r\n\t\t{\r\n\t\t\treturn createTableAlias(aTable, aPath);\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\treturn createTableAlias(aTable, aUserAlias + ALIAS_SEPARATOR + aPath);\r\n\t\t}\r\n    }", "label": 0}
{"code": "public function setIndex($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\Admin\\V1\\Index::class);\n        $this->index = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def fill_schema_from_xsd_file(filename, schema):\n    \"\"\"From an xsd file, it fills the schema by creating needed\n    Resource. The generateds idl_parser is used to parse ifmap\n    statements in the xsd file.\n\n    \"\"\"\n    ifmap_statements = _parse_xsd_file(filename)\n    properties_all = []\n\n    for v in ifmap_statements.values():\n        if (isinstance(v[0], IDLParser.Link)):\n            src_name = v[1]\n            target_name = v[2]\n            src = schema._get_or_add_resource(src_name)\n            target = schema._get_or_add_resource(target_name)\n            if \"has\" in v[3]:\n                src.children.append(target_name)\n                target.parent = src_name\n            if \"ref\" in v[3]:\n                src.refs.append(target_name)\n                target.back_refs.append(src_name)\n        elif isinstance(v[0], IDLParser.Property):\n            target_name = v[1][0]\n            prop = ResourceProperty(v[0].name, is_list=v[0].is_list, is_map=v[0].is_map)\n            if target_name != 'all':\n                target = schema._get_or_add_resource(target_name)\n                target.properties.append(prop)\n            else:\n                properties_all.append(prop)\n\n    for r in schema.all_resources():\n        schema.resource(r).properties += properties_all", "label": 1}
{"code": "public function findElements(WebDriverBy $by)\n    {\n        $params = [\n            'using' => $by->getMechanism(),\n            'value' => $by->getValue(),\n            ':id' => $this->id,\n        ];\n        $raw_elements = $this->executor->execute(\n            DriverCommand::FIND_CHILD_ELEMENTS,\n            $params\n        );\n\n        $elements = [];\n        foreach ($raw_elements as $raw_element) {\n            $elements[] = $this->newElement($raw_element['ELEMENT']);\n        }\n\n        return $elements;\n    }", "label": 2}
{"code": "func NewAppc(u *url.URL) (Distribution, error) {\n\tc, err := parseCIMD(u)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot parse URI: %q: %v\", u.String(), err)\n\t}\n\tif c.Type != TypeAppc {\n\t\treturn nil, fmt.Errorf(\"wrong distribution type: %q\", c.Type)\n\t}\n\n\tappcStr := c.Data\n\tfor n, v := range u.Query() {\n\t\tappcStr += fmt.Sprintf(\",%s=%s\", n, v[0])\n\t}\n\tapp, err := discovery.NewAppFromString(appcStr)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"wrong appc image string %q: %v\", u.String(), err)\n\t}\n\n\treturn NewAppcFromApp(app), nil\n}", "label": 5}
{"code": "def geom_find_rotsymm(g, atwts, ax, improp, \\\n        nmax=_DEF.SYMM_MATCH_NMAX, \\\n        tol=_DEF.SYMM_MATCH_TOL):\n    \"\"\" Identify highest-order symmetry for a geometry on a given axis.\n\n    Regular and improper axes possible.\n\n    .. todo:: Complete geom_find_rotsymm docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Vectorize the geometry\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n\n    # Ensure a 3-D axis vector\n    ax = make_nd_vec(ax, nd=3, t=np.float64, norm=True)\n\n    # Loop downward either until a good axis is found or nval < 1\n    #  Should never traverse below n == 1 for regular rotation check;\n    #  could for improper, though.\n    nval = nmax + 1\n    nfac = 1.0\n    while nfac > tol and nval > 0:\n        nval = nval - 1\n        try:\n            nfac = geom_symm_match(g, atwts, ax, \\\n                                    2*np.pi/nval, improp)\n\n        except ZeroDivisionError as zde:\n            # If it's because nval == zero, ignore. Else re-raise.\n            if nval > 0:\n                raise zde\n            ## end if\n        ## end try\n    ## loop\n\n    # Should be good to return\n    return nval, nfac", "label": 1}
{"code": "def isin(X,Y):\n    \"\"\"\n    Indices of elements in a numpy array that appear in another.\n\n    Fast routine for determining indices of elements in numpy array `X` that \n    appear in numpy array `Y`, returning a boolean array `Z` such that::\n\n            Z[i] = X[i] in Y\n\n    **Parameters**\n\n            **X** :  numpy array\n\n                    Numpy array to comapare to numpy array `Y`.  For each \n                    element of `X`, ask if it is in `Y`.\n\n            **Y** :  numpy array\n\n                    Numpy array to which numpy array `X` is compared.  For each \n                    element of `X`, ask if it is in `Y`.\n\n    **Returns**\n\n            **b** :  numpy array (bool)\n\n                    Boolean numpy array, `len(b) = len(X)`.\n\n    **See Also:**\n\n            :func:`tabular.fast.recarrayisin`, \n            :func:`tabular.fast.arraydifference`\n\n    \"\"\"\n    if len(Y) > 0:\n        T = Y.copy()\n        T.sort()\n        D = T.searchsorted(X)\n        T = np.append(T,np.array([0]))\n        W = (T[D] == X)\n        if isinstance(W,bool):\n            return np.zeros((len(X),),bool)\n        else:\n            return (T[D] == X)\n    else:\n        return np.zeros((len(X),),bool)", "label": 1}
{"code": "func (cl *Client) sendInitialMessages(conn *connection, torrent *Torrent) {\n\tif conn.PeerExtensionBytes.SupportsExtended() && cl.extensionBytes.SupportsExtended() {\n\t\tconn.Post(pp.Message{\n\t\t\tType:       pp.Extended,\n\t\t\tExtendedID: pp.HandshakeExtendedID,\n\t\t\tExtendedPayload: func() []byte {\n\t\t\t\tmsg := pp.ExtendedHandshakeMessage{\n\t\t\t\t\tM: map[pp.ExtensionName]pp.ExtensionNumber{\n\t\t\t\t\t\tpp.ExtensionNameMetadata: metadataExtendedId,\n\t\t\t\t\t},\n\t\t\t\t\tV:            cl.config.ExtendedHandshakeClientVersion,\n\t\t\t\t\tReqq:         64, // TODO: Really?\n\t\t\t\t\tYourIp:       pp.CompactIp(conn.remoteAddr.IP),\n\t\t\t\t\tEncryption:   !cl.config.DisableEncryption,\n\t\t\t\t\tPort:         cl.incomingPeerPort(),\n\t\t\t\t\tMetadataSize: torrent.metadataSize(),\n\t\t\t\t\t// TODO: We can figured these out specific to the socket\n\t\t\t\t\t// used.\n\t\t\t\t\tIpv4: pp.CompactIp(cl.config.PublicIp4.To4()),\n\t\t\t\t\tIpv6: cl.config.PublicIp6.To16(),\n\t\t\t\t}\n\t\t\t\tif !cl.config.DisablePEX {\n\t\t\t\t\tmsg.M[pp.ExtensionNamePex] = pexExtendedId\n\t\t\t\t}\n\t\t\t\treturn bencode.MustMarshal(msg)\n\t\t\t}(),\n\t\t})\n\t}\n\tfunc() {\n\t\tif conn.fastEnabled() {\n\t\t\tif torrent.haveAllPieces() {\n\t\t\t\tconn.Post(pp.Message{Type: pp.HaveAll})\n\t\t\t\tconn.sentHaves.AddRange(0, bitmap.BitIndex(conn.t.NumPieces()))\n\t\t\t\treturn\n\t\t\t} else if !torrent.haveAnyPieces() {\n\t\t\t\tconn.Post(pp.Message{Type: pp.HaveNone})\n\t\t\t\tconn.sentHaves.Clear()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tconn.PostBitfield()\n\t}()\n\tif conn.PeerExtensionBytes.SupportsDHT() && cl.extensionBytes.SupportsDHT() && cl.haveDhtServer() {\n\t\tconn.Post(pp.Message{\n\t\t\tType: pp.Port,\n\t\t\tPort: cl.dhtPort(),\n\t\t})\n\t}\n}", "label": 5}
{"code": "func (rt RelType) String() string {\n\tvar s string\n\tswitch rt {\n\tcase Table:\n\t\ts = \"TABLE\"\n\tcase View:\n\t\ts = \"VIEW\"\n\tdefault:\n\t\tpanic(\"unknown RelType\")\n\t}\n\treturn s\n}", "label": 5}
{"code": "function getMedian (args) {\n  if (!args.length) return 0\n  var numbers = args.slice(0).sort(function (a, b) { return a - b })\n  var middle = Math.floor(numbers.length / 2)\n  var isEven = numbers.length % 2 === 0\n  var res = isEven ? (numbers[middle] + numbers[middle - 1]) / 2 : numbers[middle]\n  return Number(res.toFixed(2))\n}", "label": 3}
{"code": "function d3_svg_lineHermite(points, tangents) {\n  if (tangents.length < 1 || (points.length !== tangents.length && points.length !== tangents.length + 2)) {\n    return points;\n  }\n\n  var quad = points.length !== tangents.length,\n      commands = [],\n      p0 = points[0],\n      p = points[1],\n      t0 = tangents[0],\n      t = t0,\n      pi = 1;\n\n  if (quad) {\n    commands.push([\n      p[0] - t0[0] * 2 / 3,\n      p[1] - t0[1] * 2 / 3,\n      p[0],\n      p[1]\n    ]);\n    p0 = points[1];\n    pi = 2;\n  }\n\n  if (tangents.length > 1) {\n    t = tangents[1];\n    p = points[pi];\n    pi++;\n    commands.push([\n      p0[0] + t0[0],\n      p0[1] + t0[1],\n      p[0] - t[0],\n      p[1] - t[1],\n      p[0],\n      p[1]\n    ]);\n\n    for (var i = 2; i < tangents.length; i++, pi++) {\n      p = points[pi];\n      t = tangents[i];\n      let lt = tangents[i - 1];\n      let lp = points[i - 1];\n\n      commands.push([\n        lp[0] + lt[0], // Add the last tangent but reflected\n        lp[1] + lt[1],\n        p[0] - t[0],\n        p[1] - t[1],\n        p[0],\n        p[1]\n      ]);\n    }\n  }\n\n  if (quad) {\n    var lp = points[pi];\n    commands.push([\n      p[0] + t[0] * 2 / 3,\n      p[1] + t[1] * 2 / 3,\n      lp[0],\n      lp[1]\n    ]);\n  }\n\n  return commands;\n}", "label": 3}
{"code": "def to_python(self, value):\n        \"\"\"Returns a GEOS Polygon from bounding box values.\"\"\"\n        value = super(BoundingBoxField, self).to_python(value)\n        try:\n            bbox = gdal.OGRGeometry.from_bbox(value).geos\n        except (ValueError, AttributeError):\n            return []\n        bbox.srid = self.srid\n        return bbox", "label": 1}
{"code": "function (attributeName, attributeValue) {\n        var attributeArray;\n        if (this._definitionAttributes) {\n            attributeArray = this._definitionAttributes[attributeName];\n        } else {\n            this._definitionAttributes = {};\n        }\n        if (undefined === attributeArray) {\n            attributeArray = [];\n        }\n        this._definitionAttributes[attributeName] = attributeArray.concat(attributeValue);\n    }", "label": 3}
{"code": "private function getExceptionMessage(\\Exception $ex)\n    {\n        if ($ex instanceof RequestException && $ex->hasResponse()) {\n            return (string) $ex->getResponse()->getBody();\n\n            try {\n                $this->jsonDecode($res);\n                return $res;\n            } catch (\\InvalidArgumentException $e) {\n                // no-op\n            }\n        }\n\n        return $ex->getMessage();\n    }", "label": 2}
{"code": "def _track_class(cls, fields):\n    \"\"\" Track fields on the specified model \"\"\"\n    # Small tests to ensure everything is all right\n    assert not getattr(cls, '_is_tracked', False)\n\n    for field in fields:\n        _track_class_field(cls, field)\n\n    _add_signals_to_cls(cls)\n\n    # Mark the class as tracked\n    cls._is_tracked = True\n    # Do not directly track related fields (tracked on related model)\n    # or m2m fields (tracked by another signal)\n    cls._tracked_fields = [\n        field for field in fields\n        if '__' not in field\n    ]", "label": 1}
{"code": "protected function getDocName()\n    {\n        $name = $this->option('name') ?: $this->name;\n\n        if (! $name) {\n            $this->comment('A name for the documentation was not supplied. Use the --name option or set a default in the configuration.');\n\n            exit;\n        }\n\n        return $name;\n    }", "label": 2}
{"code": "public function setFinding($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\SecurityCenter\\V1\\Finding::class);\n        $this->finding = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static appqoepolicy get(nitro_service service, String name) throws Exception{\n\t\tappqoepolicy obj = new appqoepolicy();\n\t\tobj.set_name(name);\n\t\tappqoepolicy response = (appqoepolicy) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def list_users(self):\n        \"\"\"\n        Run the ``list_users`` command and return a list of tuples describing\n        the users.\n\n        :return:\n            A list of 2-element tuples. The first element is the username, the\n            second a list of tags for the user.\n        \"\"\"\n        lines = output_lines(self.exec_rabbitmqctl_list('users'))\n        return [_parse_rabbitmq_user(line) for line in lines]", "label": 1}
{"code": "def to_xml_string(str = '')\n      str << '<sheetData>'\n      worksheet.rows.each_with_index do |row, index| \n        row.to_xml_string(index, str) \n      end\n      str << '</sheetData>'\n    end", "label": 4}
{"code": "func (self AudioFrame) Concat(in AudioFrame) (out AudioFrame) {\n\tout = self\n\tout.Data = append([][]byte(nil), out.Data...)\n\tout.SampleCount += in.SampleCount\n\tfor i := range out.Data {\n\t\tout.Data[i] = append(out.Data[i], in.Data[i]...)\n\t}\n\treturn\n}", "label": 5}
{"code": "function(elem) {\n\n\t\ttry {\n\t\t\t// TODO: Fix issue with rotated groups. Currently they work\n\t\t\t// fine in FF, but not in other browsers (same problem mentioned\n\t\t\t// in Issue 339 comment #2).\n\n\t\t\tvar bb = svgedit.utilities.getBBox(elem);\n\t\t\tvar angle = svgedit.utilities.getRotationAngle(elem);\n\n\t\t\tif ((angle && angle % 90) ||\n\t\t\t\tsvgedit.math.hasMatrixTransform(svgedit.transformlist.getTransformList(elem))) {\n\t\t\t\t// Accurate way to get BBox of rotated element in Firefox:\n\t\t\t\t// Put element in group and get its BBox\n\t\t\t\tvar good_bb = false;\n\t\t\t\t// Get the BBox from the raw path for these elements\n\t\t\t\tvar elemNames = ['ellipse', 'path', 'line', 'polyline', 'polygon'];\n\t\t\t\tif (elemNames.indexOf(elem.tagName) >= 0) {\n\t\t\t\t\tbb = good_bb = canvas.convertToPath(elem, true);\n\t\t\t\t} else if (elem.tagName == 'rect') {\n\t\t\t\t\t// Look for radius\n\t\t\t\t\tvar rx = elem.getAttribute('rx');\n\t\t\t\t\tvar ry = elem.getAttribute('ry');\n\t\t\t\t\tif (rx || ry) {\n\t\t\t\t\t\tbb = good_bb = canvas.convertToPath(elem, true);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (!good_bb) {\n\t\t\t\t\t// Must use clone else FF freaks out\n\t\t\t\t\tvar clone = elem.cloneNode(true);\n\t\t\t\t\tvar g = document.createElementNS(NS.SVG, \"g\");\n\t\t\t\t\tvar parent = elem.parentNode;\n\t\t\t\t\tparent.appendChild(g);\n\t\t\t\t\tg.appendChild(clone);\n\t\t\t\t\tbb = svgedit.utilities.bboxToObj(g.getBBox());\n\t\t\t\t\tparent.removeChild(g);\n\t\t\t\t}\n\n\t\t\t\t// Old method: Works by giving the rotated BBox,\n\t\t\t\t// this is (unfortunately) what Opera and Safari do\n\t\t\t\t// natively when getting the BBox of the parent group\n//\t\t\t\t\t\tvar angle = angle * Math.PI / 180.0;\n//\t\t\t\t\t\tvar rminx = Number.MAX_VALUE, rminy = Number.MAX_VALUE, \n//\t\t\t\t\t\t\trmaxx = Number.MIN_VALUE, rmaxy = Number.MIN_VALUE;\n//\t\t\t\t\t\tvar cx = round(bb.x + bb.width/2),\n//\t\t\t\t\t\t\tcy = round(bb.y + bb.height/2);\n//\t\t\t\t\t\tvar pts = [ [bb.x - cx, bb.y - cy], \n//\t\t\t\t\t\t\t\t\t[bb.x + bb.width - cx, bb.y - cy],\n//\t\t\t\t\t\t\t\t\t[bb.x + bb.width - cx, bb.y + bb.height - cy],\n//\t\t\t\t\t\t\t\t\t[bb.x - cx, bb.y + bb.height - cy] ];\n//\t\t\t\t\t\tvar j = 4;\n//\t\t\t\t\t\twhile (j--) {\n//\t\t\t\t\t\t\tvar x = pts[j][0],\n//\t\t\t\t\t\t\t\ty = pts[j][1],\n//\t\t\t\t\t\t\t\tr = Math.sqrt( x*x + y*y );\n//\t\t\t\t\t\t\tvar theta = Math.atan2(y,x) + angle;\n//\t\t\t\t\t\t\tx = round(r * Math.cos(theta) + cx);\n//\t\t\t\t\t\t\ty = round(r * Math.sin(theta) + cy);\n//\t\t\n//\t\t\t\t\t\t\t// now set the bbox for the shape after it's been rotated\n//\t\t\t\t\t\t\tif (x < rminx) rminx = x;\n//\t\t\t\t\t\t\tif (y < rminy) rminy = y;\n//\t\t\t\t\t\t\tif (x > rmaxx) rmaxx = x;\n//\t\t\t\t\t\t\tif (y > rmaxy) rmaxy = y;\n//\t\t\t\t\t\t}\n//\t\t\t\t\t\t\n//\t\t\t\t\t\tbb.x = rminx;\n//\t\t\t\t\t\tbb.y = rminy;\n//\t\t\t\t\t\tbb.width = rmaxx - rminx;\n//\t\t\t\t\t\tbb.height = rmaxy - rminy;\n\t\t\t}\n\t\t\treturn bb;\n\t\t} catch(e) {\n\t\t\tconsole.log(elem, e);\n\t\t\treturn null;\n\t\t}\n\t}", "label": 3}
{"code": "public function replaceBatch($table, array $dataSet, array $options = [])\n    {\n        $mutations = [];\n        foreach ($dataSet as $data) {\n            $mutations[] = $this->operation->mutation(Operation::OP_REPLACE, $table, $data);\n        }\n\n        return $this->commitInSingleUseTransaction($mutations, $options);\n    }", "label": 2}
{"code": "func (l VirtualDeviceList) FindIDEController(name string) (*types.VirtualIDEController, error) {\n\tif name != \"\" {\n\t\td := l.Find(name)\n\t\tif d == nil {\n\t\t\treturn nil, fmt.Errorf(\"device '%s' not found\", name)\n\t\t}\n\t\tif c, ok := d.(*types.VirtualIDEController); ok {\n\t\t\treturn c, nil\n\t\t}\n\t\treturn nil, fmt.Errorf(\"%s is not an IDE controller\", name)\n\t}\n\n\tc := l.PickController((*types.VirtualIDEController)(nil))\n\tif c == nil {\n\t\treturn nil, errors.New(\"no available IDE controller\")\n\t}\n\n\treturn c.(*types.VirtualIDEController), nil\n}", "label": 5}
{"code": "private String getPropertyValue(String level, String name)\r\n    {\r\n        return getDefForLevel(level).getProperty(name);\r\n    }", "label": 0}
{"code": "public function register()\n    {\n        $this->registerAliases();\n\n        $this->registerProviders();\n\n        if ($this->isLoadFilesOnBoot() === false) {\n            $this->registerFiles();\n        }\n\n        $this->fireEvent('register');\n    }", "label": 2}
{"code": "func (m *Mock) AssertCalled(t TestingT, methodName string, arguments ...interface{}) bool {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tm.mutex.Lock()\n\tdefer m.mutex.Unlock()\n\tif !m.methodWasCalled(methodName, arguments) {\n\t\tvar calledWithArgs []string\n\t\tfor _, call := range m.calls() {\n\t\t\tcalledWithArgs = append(calledWithArgs, fmt.Sprintf(\"%v\", call.Arguments))\n\t\t}\n\t\tif len(calledWithArgs) == 0 {\n\t\t\treturn assert.Fail(t, \"Should have called with given arguments\",\n\t\t\t\tfmt.Sprintf(\"Expected %q to have been called with:\\n%v\\nbut no actual calls happened\", methodName, arguments))\n\t\t}\n\t\treturn assert.Fail(t, \"Should have called with given arguments\",\n\t\t\tfmt.Sprintf(\"Expected %q to have been called with:\\n%v\\nbut actual calls were:\\n        %v\", methodName, arguments, strings.Join(calledWithArgs, \"\\n\")))\n\t}\n\treturn true\n}", "label": 5}
{"code": "func iterInterfaces(file *ast.File) <-chan namedInterface {\n\tch := make(chan namedInterface)\n\tgo func() {\n\t\tfor _, decl := range file.Decls {\n\t\t\tgd, ok := decl.(*ast.GenDecl)\n\t\t\tif !ok || gd.Tok != token.TYPE {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, spec := range gd.Specs {\n\t\t\t\tts, ok := spec.(*ast.TypeSpec)\n\t\t\t\tif !ok {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tit, ok := ts.Type.(*ast.InterfaceType)\n\t\t\t\tif !ok {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tch <- namedInterface{ts.Name, it}\n\t\t\t}\n\t\t}\n\t\tclose(ch)\n\t}()\n\treturn ch\n}", "label": 5}
{"code": "def put_into_frame\n      # We have to rotate the screenshot, since the offset information is for portrait\n      # only. Instead of doing the calculations ourselves, it's much easier to let\n      # imagemagick do the hard lifting for landscape screenshots\n      rotation = self.rotation_for_device_orientation\n      frame.rotate(-rotation)\n      @image.rotate(-rotation)\n\n      # Debug Mode: Add filename to frame\n      if self.debug_mode\n        filename = File.basename(@frame_path, \".*\")\n        filename.sub!('Apple', '') # remove 'Apple'\n\n        width = screenshot.size[0]\n        font_size = width / 20 # magic number that works well\n\n        offset_top = offset['offset'].split(\"+\")[2].to_f\n        annotate_offset = \"+0+#{offset_top}\" # magic number that works semi well\n\n        frame.combine_options do |c|\n          c.gravity('North')\n          c.undercolor('#00000080')\n          c.fill('white')\n          c.pointsize(font_size)\n          c.annotate(annotate_offset.to_s, filename.to_s)\n        end\n      end\n\n      @image = frame.composite(image, \"png\") do |c|\n        c.compose(\"DstOver\")\n        c.geometry(offset['offset'])\n      end\n\n      # Revert the rotation from above\n      frame.rotate(rotation)\n      @image.rotate(rotation)\n    end", "label": 4}
{"code": "protected static function addMissingParts($source, $target)\n    {\n        $pattern = '/'.preg_replace('/[0-9]+/', '[0-9]+', preg_quote($target, '/')).'$/';\n\n        $result = preg_replace($pattern, $target, $source, 1, $count);\n\n        return $count ? $result : $target;\n    }", "label": 2}
{"code": "public function addMediaFromBase64(string $base64data, ...$allowedMimeTypes): FileAdder\n    {\n        // strip out data uri scheme information (see RFC 2397)\n        if (strpos($base64data, ';base64') !== false) {\n            [$_, $base64data] = explode(';', $base64data);\n            [$_, $base64data] = explode(',', $base64data);\n        }\n\n        // strict mode filters for non-base64 alphabet characters\n        if (base64_decode($base64data, true) === false) {\n            throw InvalidBase64Data::create();\n        }\n\n        // decoding and then reencoding should not change the data\n        if (base64_encode(base64_decode($base64data)) !== $base64data) {\n            throw InvalidBase64Data::create();\n        }\n\n        $binaryData = base64_decode($base64data);\n\n        // temporarily store the decoded data on the filesystem to be able to pass it to the fileAdder\n        $tmpFile = tempnam(sys_get_temp_dir(), 'medialibrary');\n        file_put_contents($tmpFile, $binaryData);\n\n        $this->guardAgainstInvalidMimeType($tmpFile, $allowedMimeTypes);\n\n        $file = app(FileAdderFactory::class)->create($this, $tmpFile);\n\n        return $file;\n    }", "label": 2}
{"code": "def row(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'row_for', &block)\n      define_method(\"#{name}\") do\n        return platform.row_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "function getGlyphData($originalGlyphIdx, &$maxdepth, &$depth, &$points, &$contours)\n\t{\n\t\t$depth++;\n\t\t$maxdepth = max($maxdepth, $depth);\n\t\tif (count($this->glyphdata[$originalGlyphIdx]['compGlyphs'])) {\n\t\t\tforeach ($this->glyphdata[$originalGlyphIdx]['compGlyphs'] as $glyphIdx) {\n\t\t\t\t$this->getGlyphData($glyphIdx, $maxdepth, $depth, $points, $contours);\n\t\t\t}\n\t\t} else {\n\t\t\tif (($this->glyphdata[$originalGlyphIdx]['nContours'] > 0) && $depth > 0) { // simple\n\t\t\t\t$contours += $this->glyphdata[$originalGlyphIdx]['nContours'];\n\t\t\t\t$points += $this->glyphdata[$originalGlyphIdx]['nPoints'];\n\t\t\t}\n\t\t}\n\t\t$depth--;\n\t}", "label": 2}
{"code": "public function allocateId(Key $key, array $options = [])\n    {\n        $res = $this->allocateIds([$key], $options);\n        return $res[0];\n    }", "label": 2}
{"code": "def process_file(self, filename):\n        \"\"\"Processing one file.\"\"\"\n        if self.config.dry_run:\n            if not self.config.internal:\n                self.logger.info(\"Dry run mode for script %s\", filename)\n            with open(filename) as handle:\n                for line in handle:\n                    yield line[0:-1] if line[-1] == '\\n' else line\n        else:\n            if not self.config.internal:\n                self.logger.info(\"Running script %s\", filename)\n            for line in self.process_script(filename):\n                yield line", "label": 1}
{"code": "def rescue_and_retry(fail_message)\n        Retriable.retriable(retry_options) do\n          return yield\n        end\n      rescue StandardError => exception\n        log_message fail_message\n        log_message \"Last exception #{exception}\"\n      end", "label": 4}
{"code": "def get(self, name=None):\n        \"\"\"\n        Returns the plugin object with the given name.\n        Or if a name is not given, the complete plugin dictionary is returned.\n\n        :param name: Name of a plugin\n        :return: None, single plugin or dictionary of plugins\n        \"\"\"\n        if name is None:\n            return self._plugins\n        else:\n            if name not in self._plugins.keys():\n                return None\n            else:\n                return self._plugins[name]", "label": 1}
{"code": "function (line, block) {\n    if (!block.template) {\n        return;\n    }\n\n    var regex = getRegExp(block.template);\n    var match = regex.exec(line);\n    return match ? match[1] : match;\n}", "label": 3}
{"code": "function(t, utc, lang, tz) {\n        return zeropad(utc ? t.getUTCMinutes() : t.getMinutes())\n    }", "label": 3}
{"code": "@Override\n    public Optional<SoyMapData> toSoyMap(@Nullable final Object model) throws Exception {\n        if (model instanceof SoyMapData) {\n            return Optional.of((SoyMapData) model);\n        }\n        if (model instanceof Map) {\n            return Optional.of(new SoyMapData(model));\n        }\n\n        return Optional.of(new SoyMapData());\n    }", "label": 0}
{"code": "def each\n      @raw_page['records'].each { |record| yield Restforce::Mash.build(record, @client) }\n\n      np = next_page\n      while np\n        np.current_page.each { |record| yield record }\n        np = np.next_page\n      end\n    end", "label": 4}
{"code": "function generatePropertyDefinition(name, path, definitionName) {\n    var property = {};\n    var type = path.options.type ? swagger20TypeFor(path.options.type) : 'string'; // virtuals don't have type\n\n    if (skipProperty(name, path, controller)) {\n      return;\n    }\n    // Configure the property\n    if (path.options.type === mongoose.Schema.Types.ObjectId) {\n      if (\"_id\" === name) {\n        property.type = 'string';\n      }\n      else if (path.options.ref) {\n        property.$ref = '#/definitions/' + utils.capitalize(path.options.ref);  \n      }\n    }\n    else if (path.schema) {\n      //Choice (1. embed schema here or 2. reference and publish as a root definition)\n      property.type = 'array';        \n      property.items = {\n        //2. reference \n        $ref: '#/definitions/'+ definitionName + utils.capitalize(name)\n      };       \n    }\n    else {\n      property.type = type;\n\t  if ('array' === type) {\n\t    if (isArrayOfRefs(path.options.type)) {\n  \t\t  property.items = {\n  \t\t    type: 'string'  //handle references as string (serialization for objectId)\n  \t\t  };    \n  \t\t}\n      else {\n        var resolvedType = referenceForType(path.options.type); \n        if (resolvedType.isPrimitive) {\n          property.items = {\n            type: resolvedType.type\n          };              \n        }\n        else {\n          property.items = {\n            $ref: resolvedType.type\n          };              \n        }\n      }\n\t  }\n      var format = swagger20TypeFormatFor(path.options.type);\n      if (format) {\n        property.format = format;\n      }\n      if ('__v' === name) {\n        property.format = 'int32';\n      }           \n    }\n\n\t/*\n    // Set enum values if applicable\n    if (path.enumValues && path.enumValues.length > 0) {\n      // Pending:  property.allowableValues = { valueType: 'LIST', values: path.enumValues };\n    }\n    // Set allowable values range if min or max is present\n    if (!isNaN(path.options.min) || !isNaN(path.options.max)) {\n      // Pending: property.allowableValues = { valueType: 'RANGE' };\n    }\n    if (!isNaN(path.options.min)) {\n      // Pending: property.allowableValues.min = path.options.min;\n    }\n    if (!isNaN(path.options.max)) {\n      // Pending: property.allowableValues.max = path.options.max;\n    }\n\t*/\n    if (!property.type && !property.$ref) {\n      warnInvalidType(name, path);\n      property.type = 'string';\n    }\n    return property;\n  }", "label": 3}
{"code": "def render_file(file, locs, opts, &block)\n      _render_with_all_renderers(file[:relative_path].to_s, locs, self, opts, &block)\n    end", "label": 4}
{"code": "function indexSubscribers() {\n  const { subscribers = {} } = getComponentsSettings();\n\n  return index({\n    file: 'subscribers.js',\n    config: {\n      type: TYPE_SUBSCRIBERS,\n      config: subscribers,\n      exportsStart: 'export default [',\n      exportsEnd: '];',\n      isArray: true,\n    },\n    defaultContent: 'export default [];\\n',\n    ...getIndexLogTranslations(TYPE_SUBSCRIBERS),\n  });\n}", "label": 3}
{"code": "def tab_join(ToMerge, keycols=None, nullvals=None, renamer=None, \n             returnrenaming=False, Names=None):\n    '''\n    Database-join for tabular arrays.\n\n    Wrapper for :func:`tabular.spreadsheet.join` that deals with the coloring \n    and returns the result as a tabarray.\n\n    Method calls::\n\n            data = tabular.spreadsheet.join\n\n    '''\n\n    [Result,Renaming] = spreadsheet.join(ToMerge, keycols=keycols, \n          nullvals=nullvals, renamer=renamer, returnrenaming=True, Names=Names)\n\n    if isinstance(ToMerge,dict):\n        Names = ToMerge.keys()\n    else:\n        Names = range(len(ToMerge))\n\n    Colorings = dict([(k,ToMerge[k].coloring) if 'coloring' in dir(ToMerge[k])  \n                                              else {} for k in Names])\n    for k in Names:\n        if k in Renaming.keys():\n            l = ToMerge[k]\n            Colorings[k] = \\\n                dict([(g, [n if not n in Renaming[k].keys() else Renaming[k][n] \n                       for n in l.coloring[g]]) for g in Colorings[k].keys()])\n    Coloring = {}\n    for k in Colorings.keys():\n        for j in Colorings[k].keys():\n            if j in Coloring.keys():\n                Coloring[j] = utils.uniqify(Coloring[j] + Colorings[k][j])\n            else:\n                Coloring[j] = utils.uniqify(Colorings[k][j])\n\n    Result = Result.view(tabarray)\n    Result.coloring = Coloring\n\n    if returnrenaming:\n        return [Result,Renaming]\n    else:\n        return Result", "label": 1}
{"code": "public static vpath[] get(nitro_service service) throws Exception{\n\t\tvpath obj = new vpath();\n\t\tvpath[] response = (vpath[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (t *Text) SetText(s string) {\n\tt.width = 0\n\tt.text = []rune(s)\n\tif len(t.widths) < len(t.text) {\n\t\tt.widths = make([]int, len(t.text))\n\t} else {\n\t\tt.widths = t.widths[0:len(t.text)]\n\t}\n\tif len(t.styles) < len(t.text) {\n\t\tt.styles = make([]tcell.Style, len(t.text))\n\t} else {\n\t\tt.styles = t.styles[0:len(t.text)]\n\t}\n\tt.lengths = []int{}\n\tlength := 0\n\tfor i, r := range t.text {\n\t\tt.widths[i] = runewidth.RuneWidth(r)\n\t\tt.styles[i] = t.style\n\t\tif r == '\\n' {\n\t\t\tt.lengths = append(t.lengths, length)\n\t\t\tif length > t.width {\n\t\t\t\tt.width = length\n\t\t\t\tlength = 0\n\t\t\t}\n\n\t\t} else if t.widths[i] == 0 && length == 0 {\n\t\t\t// If first character on line is combining, inject\n\t\t\t// a leading space.  (Shame on the caller!)\n\t\t\tt.widths = append(t.widths, 0)\n\t\t\tcopy(t.widths[i+1:], t.widths[i:])\n\t\t\tt.widths[i] = 1\n\n\t\t\tt.text = append(t.text, ' ')\n\t\t\tcopy(t.text[i+1:], t.text[i:])\n\t\t\tt.text[i] = ' '\n\n\t\t\tt.styles = append(t.styles, t.style)\n\t\t\tcopy(t.styles[i+1:], t.styles[i:])\n\t\t\tt.styles[i] = t.style\n\t\t\tlength++\n\t\t} else {\n\t\t\tlength += t.widths[i]\n\t\t}\n\t}\n\tif length > 0 {\n\t\tt.lengths = append(t.lengths, length)\n\t\tif length > t.width {\n\t\t\tt.width = length\n\t\t}\n\t}\n\tt.height = len(t.lengths)\n\tt.PostEventWidgetContent(t)\n}", "label": 5}
{"code": "def define_actions(config)\n      router.member do\n        config.member_actions.each { |action| build_action(action) }\n      end\n\n      router.collection do\n        config.collection_actions.each { |action| build_action(action) }\n        router.post :batch_action if config.batch_actions_enabled?\n      end\n    end", "label": 4}
{"code": "def retrieve_modifier_list(location_id, modifier_list_id, opts = {})\n      data, _status_code, _headers = retrieve_modifier_list_with_http_info(location_id, modifier_list_id, opts)\n      return data\n    end", "label": 4}
{"code": "def rest(url, req=\"GET\", data=None):\n    \"\"\"Main function to be called from this module.\n\n    send a request using method 'req' and to the url. the _rest() function\n    will add the base_url to this, so 'url' should be something like '/ips'.\n    \"\"\"\n    load_variables()\n\n    return _rest(base_url + url, req, data)", "label": 1}
{"code": "func NewOptionList(permissibleOptions []string, defaultOptions string) (*OptionList, error) {\n\tpermissible := make(map[string]struct{})\n\tol := &OptionList{\n\t\tallOptions:  permissibleOptions,\n\t\tpermissible: permissible,\n\t\ttypeName:    \"OptionList\",\n\t}\n\n\tfor _, o := range permissibleOptions {\n\t\tol.permissible[o] = struct{}{}\n\t}\n\n\tif err := ol.Set(defaultOptions); err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"problem setting defaults\"), err)\n\t}\n\n\treturn ol, nil\n}", "label": 5}
{"code": "public function clear()\n    {\n        $shmid = shm_attach($this->sysvKey, $this->shmSize, $this->perm);\n        shm_remove_var($shmid, self::VAR_KEY);\n    }", "label": 2}
{"code": "public function dropSchema(array $classes)\n    {\n        $dropSchemaSql = $this->getDropSchemaSQL($classes);\n        $conn          = $this->em->getConnection();\n\n        foreach ($dropSchemaSql as $sql) {\n            try {\n                $conn->executeQuery($sql);\n            } catch (Throwable $e) {\n                // ignored\n            }\n        }\n    }", "label": 2}
{"code": "public function before($findName, $withName, callable $middleware)\n    {\n        $this->splice($findName, $withName, $middleware, true);\n    }", "label": 2}
{"code": "func (f *Fetcher) FetchImage(d dist.Distribution, image, ascPath string) (*types.Hash, error) {\n\tensureLogger(f.Debug)\n\tdb := &distBundle{\n\t\tdist:  d,\n\t\timage: image,\n\t}\n\ta := f.getAsc(ascPath)\n\thash, err := f.fetchSingleImage(db, a)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif f.WithDeps {\n\t\terr = f.fetchImageDeps(hash)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// we need to be able to do a chroot and access to the tree store\n\t// directories, we need to\n\t// 1) check if the system supports OverlayFS\n\t// 2) check if we're root\n\tif common.SupportsOverlay() == nil && os.Geteuid() == 0 {\n\t\tif _, _, err := f.Ts.Render(hash, false); err != nil {\n\t\t\treturn nil, errwrap.Wrap(errors.New(\"error rendering tree store\"), err)\n\t\t}\n\t}\n\th, err := types.NewHash(hash)\n\tif err != nil {\n\t\t// should never happen\n\t\tlog.PanicE(\"invalid hash\", err)\n\t}\n\treturn h, nil\n}", "label": 5}
{"code": "function _toCamel(name) {\n    return name.toLowerCase()\n        .replace(/-(.)/g, (match, val) => val.toUpperCase());\n}", "label": 3}
{"code": "def find_attribute_value(tree, path, default)\n      attribute = tree[path.shift]\n      if attribute.is_a?(Hash)\n        find_attribute_value(attribute, path, default)\n      else\n        attribute.nil? ? default : attribute\n      end\n    end", "label": 4}
{"code": "public function run(DebuggerClient $client = null, $asDaemon = true)\n    {\n        $client = $client ?: $this->defaultClient();\n        $extSourceContexts = $this->extSourceContext ? [$this->extSourceContext] : [];\n        $uniquifier = $this->uniquifier ?: $this->defaultUniquifier();\n\n        do {\n            $debuggee = $client->debuggee(null, [\n                'uniquifier' => $uniquifier,\n                'description' => $this->description,\n                'extSourceContexts' => $extSourceContexts,\n                'labels' => $this->labels\n            ]);\n\n            // If registration with backoff fails, then propagate the exception.\n            $backoff = new ExponentialBackoff();\n            $backoff->execute(function () use ($debuggee) {\n                $debuggee->register();\n            });\n\n            try {\n                $options = [];\n                do {\n                    try {\n                        $resp = $debuggee->breakpointsWithWaitToken($options);\n                        $this->setBreakpoints($debuggee, $resp['breakpoints']);\n                        $options['waitToken'] = $resp['nextWaitToken'];\n                    } catch (ConflictException $e) {\n                        // The hanging GET call returns a 409 (Conflict) response\n                        // when the request times out with a status of 'ABORTED'.\n                        // In this case, we'll fetch again with the same waitToken.\n                    }\n                    gc_collect_cycles();\n                } while ($asDaemon);\n            } catch (ServiceException $e) {\n                // For any other ServiceExceptions, re-register and start over.\n            }\n            gc_collect_cycles();\n        } while ($asDaemon);\n    }", "label": 2}
{"code": "def type(self, variant_probe_coverages, variant=None):\n        \"\"\"\n            Takes a list of VariantProbeCoverages and returns a Call for the Variant.\n            Note, in the simplest case the list will be of length one. However, we may be typing the\n            Variant on multiple backgrouds leading to multiple VariantProbes for a single Variant.\n\n        \"\"\"\n        if not isinstance(variant_probe_coverages, list):\n            variant_probe_coverages = [variant_probe_coverages]\n        calls = []\n        for variant_probe_coverage in variant_probe_coverages:\n            calls.append(\n                self._type_variant_probe_coverages(\n                    variant_probe_coverage, variant))\n        hom_alt_calls = [c for c in calls if sum(c[\"genotype\"]) > 1]\n        het_calls = [c for c in calls if sum(c[\"genotype\"]) == 1]\n        if hom_alt_calls:\n            hom_alt_calls.sort(key=lambda x: x[\"info\"][\"conf\"], reverse=True)\n            return hom_alt_calls[0]\n        elif het_calls:\n            het_calls.sort(key=lambda x: x[\"info\"][\"conf\"], reverse=True)\n            return het_calls[0]\n        else:\n            calls.sort(key=lambda x: x[\"info\"][\"conf\"], reverse=True)\n            return calls[0]", "label": 1}
{"code": "public static base_responses update(nitro_service client, filteraction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tfilteraction updateresources[] = new filteraction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new filteraction();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].servicename = resources[i].servicename;\n\t\t\t\tupdateresources[i].value = resources[i].value;\n\t\t\t\tupdateresources[i].respcode = resources[i].respcode;\n\t\t\t\tupdateresources[i].page = resources[i].page;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected void store(Object obj, Identity oid, ClassDescriptor cld,  boolean insert)\n    {\n        store(obj, oid, cld, insert, false);\n    }", "label": 0}
{"code": "public static PropertyResourceBundle getBundle(String baseName, Locale locale) throws UnsupportedEncodingException, IOException{\n\t\tInputStream is = UTF8PropertyResourceBundle.class.getResourceAsStream(\"/\"+baseName + \"_\"+locale.toString()+PROPERTIES_EXT);\n\t\tif(is != null){\n\t\t\treturn new PropertyResourceBundle(new InputStreamReader(is, \"UTF-8\"));\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "function roleOrSelf (role) {\n        if (!_.isNumber(role)) {\n            role = roles[role.toUpperCase()];\n        }\n\n        return function validateRoleOrSelf (kontx, next) {\n            var userPrivLevel = roles[kontx.user.role.toUpperCase()],\n                passedInUserId = kontx.args[0],\n                err = createError(strings.group('codes').forbidden, strings.group('errors').user_privileges_exceeded);\n\n            //If user object passed in instead of a string then parse.\n            if (!_.isUndefined(kontx.args[0]._id)) {\n                passedInUserId = kontx.args[0]._id;\n            }\n\n            //If user has enough priviliges then keep going\n            if (userPrivLevel <= parseInt(role, 10) || kontx.user._id.toString() === passedInUserId.toString()) {\n                next();\n                return;\n            }\n\n            next(err);\n        };\n    }", "label": 3}
{"code": "function reduceProperties(map, callback, initial) {\n        var result = initial;\n        for (var key in map) {\n            result = callback(result, map[key], String(key));\n        }\n        return result;\n    }", "label": 3}
{"code": "function updateValidAndInvalidDataSources(dataSourcesToSplit, currentInvalidDataSources) {\n  logger.debug(\"dataSourcesToSplit\", dataSourcesToSplit);\n  currentInvalidDataSources = currentInvalidDataSources || [];\n  var validInvalid = _.partition(dataSourcesToSplit, function(dataSourceUpdateData) {\n    if (dataSourceUpdateData) {\n      return !dataSourceUpdateData.error;\n    }\n    return true;\n  });\n\n  var validDataSources = validInvalid[0];\n\n  //Updating any data sources that are no longer valid\n  var invalidDataSources = _.union(validInvalid[1], currentInvalidDataSources);\n\n  return {\n    valid: validDataSources,\n    invalid: invalidDataSources\n  };\n}", "label": 3}
{"code": "def update(plugins, specific, **opts)\n      specific ||= []\n      update = opts.merge({gems: specific.empty? ? true : specific})\n      internal_install(plugins, update)\n    end", "label": 4}
{"code": "function(text, settings) {\n            var that = this;\n            settings = settings || {};\n\n            var getTypeId = settings.getTypeId || function(object) { return that.getTypeId(object); };\n            var getConstructor = settings.getConstructor || function(id) { return that.typeMap[id]; };\n            var reviver = settings.reviver || function(key, value) { return that.reviver(key, value, getTypeId, getConstructor); };\n\n            return JSON.parse(text, reviver);\n        }", "label": 3}
{"code": "function createWatchEvent(type, record, event) {\n    const payload = Object.assign({ type, key: record.id, modelName: record.modelName, pluralName: record.pluralName, modelConstructor: record.modelConstructor, dynamicPathProperties: record.dynamicPathComponents, compositeKey: record.compositeKey, dbPath: record.dbPath, localPath: record.localPath || \"\", localPostfix: record.META.localPostfix }, event);\n    return payload;\n}", "label": 3}
{"code": "protected function hydratePivotRelation(string $relationName, EloquentCollection $relationModels): self\n    {\n        $relation = $this->getRelationInstance($relationName);\n\n        if ($relationModels->isNotEmpty() && method_exists($relation, 'hydratePivotRelation')) {\n            $hydrationMethod = new ReflectionMethod(get_class($relation), 'hydratePivotRelation');\n            $hydrationMethod->setAccessible(true);\n            $hydrationMethod->invoke($relation, $relationModels->all());\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "public function setOperationType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Container\\V1\\Operation_Type::class);\n        $this->operation_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def keyword_tokenize(text_string):\n    '''\n    Extracts keywords from text_string using NLTK's list of English stopwords, ignoring words of a\n    length smaller than 3, and returns the new string as type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a non-string argument be passed\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        return \" \".join([word for word in KEYWORD_TOKENIZER.tokenize(text_string) if word not in STOPWORDS and len(word) >= 3])\n    else:\n        raise InputError(\"string not passed as argument for text_string\")", "label": 1}
{"code": "private static function is_optional( $token ) {\n\t\tif ( '[' === substr( $token, 0, 1 ) && ']' === substr( $token, -1 ) ) {\n\t\t\treturn array( true, substr( $token, 1, -1 ) );\n\t\t}\n\n\t\treturn array( false, $token );\n\t}", "label": 2}
{"code": "def may_fire?(obj, to_state=::AASM::NO_VALUE, *args)\n      _fire(obj, {:test_only => true}, to_state, *args) # true indicates test firing\n    end", "label": 4}
{"code": "def get_bin_indices(self, values):\n        \"\"\"Returns index tuple in histogram of bin which contains value\"\"\"\n        return tuple([self.get_axis_bin_index(values[ax_i], ax_i)\n                      for ax_i in range(self.dimensions)])", "label": 1}
{"code": "def members\n      members = member_ids.map do |member_id|\n        Member.find(member_id)\n      end\n      MultiAssociation.new(self, members).proxy\n    end", "label": 4}
{"code": "func (t *TextBar) SetStyle(style tcell.Style) {\n\tt.initialize()\n\tt.style = style\n}", "label": 5}
{"code": "public function setState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Redis\\V1beta1\\Instance_State::class);\n        $this->state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def create_topic(name, num_partitions: 1, replication_factor: 1, timeout: 30, config: {})\n      @cluster.create_topic(\n        name,\n        num_partitions: num_partitions,\n        replication_factor: replication_factor,\n        timeout: timeout,\n        config: config,\n      )\n    end", "label": 4}
{"code": "def delete(reason = nil)\n      if token?\n        API::Webhook.token_delete_webhook(@token, @id, reason)\n      else\n        API::Webhook.delete_webhook(@bot.token, @id, reason)\n      end\n    end", "label": 4}
{"code": "def get_file_from_s3(job, s3_url, encryption_key=None, write_to_jobstore=True):\n    \"\"\"\n    Downloads a supplied URL that points to an unencrypted, unprotected file on Amazon S3. The file\n    is downloaded and a subsequently written to the jobstore and the return value is a the path to\n    the file in the jobstore.\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    filename = '/'.join([work_dir, os.path.basename(s3_url)])\n    # This is common to encrypted and unencrypted downloads\n    download_call = ['curl', '-fs', '--retry', '5']\n    # If an encryption key was provided, use it to create teh headers that need to be injected into\n    # the curl script and append to the call\n    if encryption_key:\n        key = generate_unique_key(encryption_key, s3_url)\n        encoded_key = base64.b64encode(key)\n        encoded_key_md5 = base64.b64encode( hashlib.md5(key).digest() )\n        h1 = 'x-amz-server-side-encryption-customer-algorithm:AES256'\n        h2 = 'x-amz-server-side-encryption-customer-key:{}'.format(encoded_key)\n        h3 = 'x-amz-server-side-encryption-customer-key-md5:{}'.format(encoded_key_md5)\n        download_call.extend(['-H', h1, '-H', h2, '-H', h3])\n    # This is also common to both types of downloads\n    download_call.extend([s3_url, '-o', filename])\n    try:\n        subprocess.check_call(download_call)\n    except subprocess.CalledProcessError:\n        raise RuntimeError('Curl returned a non-zero exit status processing %s. Do you' % s3_url +\n                           'have premssions to access the file?')\n    except OSError:\n        raise RuntimeError('Failed to find \"curl\". Install via \"apt-get install curl\"')\n    assert os.path.exists(filename)\n    if write_to_jobstore:\n        filename = job.fileStore.writeGlobalFile(filename)\n    return filename", "label": 1}
{"code": "public static function create(\n        $selenium_server_url = 'http://localhost:4444/wd/hub',\n        $desired_capabilities = null,\n        $connection_timeout_in_ms = null,\n        $request_timeout_in_ms = null,\n        $http_proxy = null,\n        $http_proxy_port = null,\n        DesiredCapabilities $required_capabilities = null\n    ) {\n        $selenium_server_url = preg_replace('#/+$#', '', $selenium_server_url);\n\n        $desired_capabilities = self::castToDesiredCapabilitiesObject($desired_capabilities);\n\n        $executor = new HttpCommandExecutor($selenium_server_url, $http_proxy, $http_proxy_port);\n        if ($connection_timeout_in_ms !== null) {\n            $executor->setConnectionTimeout($connection_timeout_in_ms);\n        }\n        if ($request_timeout_in_ms !== null) {\n            $executor->setRequestTimeout($request_timeout_in_ms);\n        }\n\n        if ($required_capabilities !== null) {\n            // TODO: Selenium (as of v3.0.1) does accept requiredCapabilities only as a property of desiredCapabilities.\n            // This will probably change in future with the W3C WebDriver spec, but is the only way how to pass these\n            // values now.\n            $desired_capabilities->setCapability('requiredCapabilities', $required_capabilities->toArray());\n        }\n\n        $command = new WebDriverCommand(\n            null,\n            DriverCommand::NEW_SESSION,\n            ['desiredCapabilities' => $desired_capabilities->toArray()]\n        );\n\n        $response = $executor->execute($command);\n        $returnedCapabilities = new DesiredCapabilities($response->getValue());\n\n        $driver = new static($executor, $response->getSessionID(), $returnedCapabilities);\n\n        return $driver;\n    }", "label": 2}
{"code": "def hash(self):\n        \"\"\"The hash value of the current revision\"\"\"\n        if 'digest' not in self._p4dict:\n            self._p4dict = self._connection.run(['fstat', '-m', '1', '-Ol', self.depotFile])[0]\n\n        return self._p4dict['digest']", "label": 1}
{"code": "public static base_response clear(nitro_service client, route6 resource) throws Exception {\n\t\troute6 clearresource = new route6();\n\t\tclearresource.routetype = resource.routetype;\n\t\treturn clearresource.perform_operation(client,\"clear\");\n\t}", "label": 0}
{"code": "def diff_from(time: nil, version: nil)\n      raise ArgumentError, \"Time or version must be specified\" if time.nil? && version.nil?\n\n      from_version = version.nil? ? find_by_time(time) : find_by_version(version)\n      from_version ||= versions.first\n\n      base = changes_to(version: from_version.version)\n      diff = changes_to(version: self.version, data: base, from: from_version.version + 1)\n\n      build_changes(base, diff)\n    end", "label": 4}
{"code": "public function setAllowedValues($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->allowed_values = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def status_codes_chart():\n    \"\"\"Chart for status codes.\"\"\"\n    stats = status_codes_stats()\n\n    chart_options = {\n        'chart': {\n            'type': 'pie'\n        },\n        'title': {\n            'text': ''\n        },\n        'subtitle': {\n            'text': ''\n        },\n        'tooltip': {\n          'formatter': \"return this.y + '/' + this.total + ' (' + \"\n                       \"Highcharts.numberFormat(this.percentage, 1) + '%)';\"\n        },\n        'legend': {\n            'enabled': True,\n        },\n        'plotOptions': {\n            'pie': {\n                'allowPointSelect': True,\n                'cursor': 'pointer',\n                'dataLabels': {\n                    'enabled': True,\n                    'format': '<b>{point.name}</b>: {point.y}/{point.total} '\n                              '({point.percentage:.1f}%)'\n                },\n                'showInLegend': True\n            }\n        },\n        'series': [{\n            'name': _('Status Codes'),\n            'colorByPoint': True,\n            'data': sorted(\n                [{'name': '%s %s' % (k, STATUS_CODES[int(k)]['name']), 'y': v}\n                 for k, v in stats.items()],\n                key=lambda x: x['y'],\n                reverse=True)\n        }]\n    }\n\n    return chart_options", "label": 1}
{"code": "public double distanceSquared(Vector3d v) {\n        double dx = x - v.x;\n        double dy = y - v.y;\n        double dz = z - v.z;\n\n        return dx * dx + dy * dy + dz * dz;\n    }", "label": 0}
{"code": "public static function chain()\n    {\n        $links = func_get_args();\n        if (empty($links)) {\n            throw new \\InvalidArgumentException('No providers in chain');\n        }\n\n        return function () use ($links) {\n            /** @var callable $parent */\n            $parent = array_shift($links);\n            $promise = $parent();\n            while ($next = array_shift($links)) {\n                $promise = $promise->otherwise($next);\n            }\n            return $promise;\n        };\n    }", "label": 2}
{"code": "def relation_primary_key(relation, source: nil, was: false)\n      reflect = relation_reflect(relation)\n      klass = nil\n      if reflect.options.key?(:polymorphic)\n        raise \"can't handle multiple keys with polymorphic associations\" unless (relation.is_a?(Symbol) || relation.length == 1)\n        raise \"must specify source for polymorphic associations...\" unless source\n        return relation_klass(relation, source: source, was: was).try(:primary_key)\n      end\n      reflect.association_primary_key(klass)\n    end", "label": 4}
{"code": "private ColumnDef addColumnFor(FieldDescriptorDef fieldDef, TableDef tableDef)\r\n    {\r\n        String    name      = fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_COLUMN);\r\n        ColumnDef columnDef = tableDef.getColumn(name);\r\n\r\n        if (columnDef == null)\r\n        {\r\n            columnDef = new ColumnDef(name);\r\n            tableDef.addColumn(columnDef);\r\n        }\r\n        if (!fieldDef.isNested())\r\n        {    \r\n            columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_JAVANAME, fieldDef.getName());\r\n        }\r\n        columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_TYPE, fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_JDBC_TYPE));\r\n        columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_ID, fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_ID));\r\n        if (fieldDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_PRIMARYKEY, false))\r\n        {\r\n            columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_PRIMARYKEY, \"true\");\r\n            columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_REQUIRED, \"true\");\r\n        }\r\n        else if (!fieldDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_NULLABLE, true))\r\n        {\r\n            columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_REQUIRED, \"true\");\r\n        }\r\n        if (\"database\".equals(fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_AUTOINCREMENT)))\r\n        {\r\n            columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_AUTOINCREMENT, \"true\");\r\n        }\r\n        columnDef.setProperty(PropertyHelper.TORQUE_PROPERTY_SIZE, fieldDef.getSizeConstraint());\r\n        if (fieldDef.hasProperty(PropertyHelper.OJB_PROPERTY_DOCUMENTATION))\r\n        {\r\n            columnDef.setProperty(PropertyHelper.OJB_PROPERTY_DOCUMENTATION,\r\n                                  fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_DOCUMENTATION));\r\n        }\r\n        if (fieldDef.hasProperty(PropertyHelper.OJB_PROPERTY_COLUMN_DOCUMENTATION))\r\n        {\r\n            columnDef.setProperty(PropertyHelper.OJB_PROPERTY_COLUMN_DOCUMENTATION,\r\n                                  fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_COLUMN_DOCUMENTATION));\r\n        }\r\n        return columnDef;\r\n    }", "label": 0}
{"code": "function getContextuallyTypedParameterType(parameter) {\n            var func = parameter.parent;\n            if (isContextSensitiveFunctionOrObjectLiteralMethod(func)) {\n                var iife = ts.getImmediatelyInvokedFunctionExpression(func);\n                if (iife) {\n                    var indexOfParameter = ts.indexOf(func.parameters, parameter);\n                    if (iife.arguments && indexOfParameter < iife.arguments.length) {\n                        if (parameter.dotDotDotToken) {\n                            var restTypes = [];\n                            for (var i = indexOfParameter; i < iife.arguments.length; i++) {\n                                restTypes.push(getTypeOfExpression(iife.arguments[i]));\n                            }\n                            return createArrayType(getUnionType(restTypes));\n                        }\n                        var links = getNodeLinks(iife);\n                        var cached = links.resolvedSignature;\n                        links.resolvedSignature = anySignature;\n                        var type = checkExpression(iife.arguments[indexOfParameter]);\n                        links.resolvedSignature = cached;\n                        return type;\n                    }\n                }\n                var contextualSignature = getContextualSignature(func);\n                if (contextualSignature) {\n                    var funcHasRestParameters = ts.hasRestParameter(func);\n                    var len = func.parameters.length - (funcHasRestParameters ? 1 : 0);\n                    var indexOfParameter = ts.indexOf(func.parameters, parameter);\n                    if (indexOfParameter < len) {\n                        return getTypeAtPosition(contextualSignature, indexOfParameter);\n                    }\n                    // If last parameter is contextually rest parameter get its type\n                    if (funcHasRestParameters &&\n                        indexOfParameter === (func.parameters.length - 1) &&\n                        isRestParameterIndex(contextualSignature, func.parameters.length - 1)) {\n                        return getTypeOfSymbol(ts.lastOrUndefined(contextualSignature.parameters));\n                    }\n                }\n            }\n            return undefined;\n        }", "label": 3}
{"code": "func ExtractHostID(hostName string, clusterName string) (string, error) {\n\tsuffix := \".\" + clusterName\n\tif !strings.HasSuffix(hostName, suffix) {\n\t\treturn \"\", trace.BadParameter(\"expected suffix %q in %q\", suffix, hostName)\n\t}\n\treturn strings.TrimSuffix(hostName, suffix), nil\n}", "label": 5}
{"code": "func intIf(cnd bool, a, b int) int {\n\tif cnd {\n\t\treturn a\n\t}\n\treturn b\n}", "label": 5}
{"code": "public static <T> OptionalValue<T> ofNullable(T value) {\n        return new GenericOptionalValue<T>(RUNTIME_SOURCE, DEFAULT_KEY, value);\n    }", "label": 0}
{"code": "public function setAddTarget($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1\\Target::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def hook(name, options={}, &block)\n      hooks[name.to_s] << Hook.new(name.to_s, options, &block)\n    end", "label": 4}
{"code": "public ImmutableMap<String, String> getConfigurationTweak(String dbModuleName)\n    {\n        final DbInfo db = cluster.getNextDb();\n        return ImmutableMap.of(\"ness.db.\" + dbModuleName + \".uri\", getJdbcUri(db),\n                               \"ness.db.\" + dbModuleName + \".ds.user\", db.user);\n    }", "label": 0}
{"code": "func (r *reader) piecesUncached() (ret pieceRange) {\n\tra := r.readahead\n\tif ra < 1 {\n\t\t// Needs to be at least 1, because [x, x) means we don't want\n\t\t// anything.\n\t\tra = 1\n\t}\n\tif ra > r.length-r.pos {\n\t\tra = r.length - r.pos\n\t}\n\tret.begin, ret.end = r.t.byteRegionPieces(r.torrentOffset(r.pos), ra)\n\treturn\n}", "label": 5}
{"code": "function() {\n            var self = this;\n            return waterline.catalogs.findOne({\"node\": self.id})\n            .then(function(catalog) {\n                return !_.isEmpty(catalog);\n            });\n        }", "label": 3}
{"code": "public static tmsessionparameter get(nitro_service service) throws Exception{\n\t\ttmsessionparameter obj = new tmsessionparameter();\n\t\ttmsessionparameter[] response = (tmsessionparameter[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "function postForm({ url, payload, useBearer }) {\n  return ajax({\n    url,\n    body: makeFormData( payload ),\n    method: 'post',\n    useBearer\n  })\n}", "label": 3}
{"code": "public void postArtifact(final Artifact artifact, final String user, final String password) throws GrapesCommunicationException, AuthenticationException {\n        final Client client = getClient(user, password);\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.artifactResourcePath());\n        final ClientResponse response = resource.type(MediaType.APPLICATION_JSON).post(ClientResponse.class, artifact);\n\n        client.destroy();\n        if(ClientResponse.Status.CREATED.getStatusCode() != response.getStatus()){\n            final String message = \"Failed to POST artifact\";\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n    }", "label": 0}
{"code": "function updateFormatting(outNode, profile) {\n\tconst node = outNode.node;\n\n\tif (!node.isTextOnly && node.value) {\n\t\t// node with text: put a space before single-line text\n\t\toutNode.beforeText = reNl.test(node.value)\n\t\t\t? outNode.newline + outNode.indent + profile.indent(1)\n\t\t\t: ' ';\n\t}\n\n\treturn outNode;\n}", "label": 3}
{"code": "function AggregateFunction() {\n  var self = this;\n  // function type can be one of\n  // - simple (default)\n  // - ordered - will require window to store elements in arrival and sorted order\n  //\n  self.type = \"simple\";\n  // invoked when a window opens - should 'reset' or 'zero' a windows internal state\n  self.init = function() { throw \"Must subclass\"; };\n  // invoked when an event is enqueued into a window\n  self.accumulate = function(value) { throw \"Must subclass\"; };\n  // invoked to compensate sliding window overwrite\n  self.compensate = function(value) { throw \"Must subclass\"; };\n  // invoked when a window closes\n  self.emit = function() { throw \"Must subclass\"; };\n  // used by window implementations variously to preallocate function instances - makes things 'fast', basically\n  self.make = function(win) { throw \"Must subclass\"; };\n}", "label": 3}
{"code": "protected function detectMnc($lc, $carrierName)\n  {\n      $fp = fopen(__DIR__.DIRECTORY_SEPARATOR.'networkinfo.csv', 'r');\n      $mnc = null;\n\n      while ($data = fgetcsv($fp, 0, ',')) {\n          if ($data[4] === $lc && $data[7] === $carrierName) {\n              $mnc = $data[2];\n              break;\n          }\n      }\n\n      if ($mnc == null) {\n          $mnc = '000';\n      }\n\n      fclose($fp);\n\n      return $mnc;\n  }", "label": 2}
{"code": "function bridgeCommand(command,cb){\n    if(!connected) return setImmediate(function(){\n      cb('killed');\n    });\n\n    if(!connected.pings) connected.pings = {};\n    var id = ++pingid;\n    var timer;\n    connected.pings[id] = function(err,data){\n      clearTimeout(timer);\n      delete connected.pings[id]\n      cb(err,data);\n    };\n    connected.send({command:command,cb:id});\n    // set 5 second time limit for callback.\n    timer = setTimeout(function(){\n      cb(\"timeout\");\n    },5000);\n  }", "label": 3}
{"code": "func getApp(p *pkgPod.Pod) (*schema.RuntimeApp, error) {\n\t_, manifest, err := p.PodManifest()\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"problem getting the pod's manifest\"), err)\n\t}\n\n\tapps := manifest.Apps\n\n\tif flagExportAppName != \"\" {\n\t\texportAppName, err := types.NewACName(flagExportAppName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfor _, ra := range apps {\n\t\t\tif *exportAppName == ra.Name {\n\t\t\t\treturn &ra, nil\n\t\t\t}\n\t\t}\n\t\treturn nil, fmt.Errorf(\"app %s is not present in pod\", flagExportAppName)\n\t}\n\n\tswitch len(apps) {\n\tcase 0:\n\t\treturn nil, fmt.Errorf(\"pod contains zero apps\")\n\tcase 1:\n\t\treturn &apps[0], nil\n\tdefault:\n\t}\n\n\tstderr.Print(\"pod contains multiple apps:\")\n\tfor _, ra := range apps {\n\t\tstderr.Printf(\"\\t%v\", ra.Name)\n\t}\n\n\treturn nil, fmt.Errorf(\"specify app using \\\"rkt export --app= ...\\\"\")\n}", "label": 5}
{"code": "def solve(self):\n        \"\"\" Solves a DC power flow.\n        \"\"\"\n        case = self.case\n        logger.info(\"Starting DC power flow [%s].\" % case.name)\n        t0 = time.time()\n        # Update bus indexes.\n        self.case.index_buses()\n\n        # Find the index of the refence bus.\n        ref_idx = self._get_reference_index(case)\n        if ref_idx < 0:\n            return False\n\n        # Build the susceptance matrices.\n        B, Bsrc, p_businj, p_srcinj = case.Bdc\n        # Get the vector of initial voltage angles.\n        v_angle_guess = self._get_v_angle_guess(case)\n        # Calculate the new voltage phase angles.\n        v_angle, p_ref = self._get_v_angle(case, B, v_angle_guess, p_businj,\n                                           ref_idx)\n        logger.debug(\"Bus voltage phase angles: \\n%s\" % v_angle)\n        self.v_angle = v_angle\n\n        # Push the results to the case.\n        self._update_model(case, B, Bsrc, v_angle, p_srcinj, p_ref, ref_idx)\n\n        logger.info(\"DC power flow completed in %.3fs.\" % (time.time() - t0))\n\n        return True", "label": 1}
{"code": "def timestamp\n      value = self['timestamp']\n      if value.kind_of? Integer\n        value = value / 1000 if value > 9999999999\n        Time.at(value)\n      else\n        value\n      end\n    end", "label": 4}
{"code": "function warning(lines) {\n  lines.unshift('');    // Extra whitespace at the start.\n  lines.push('');       // Extra whitespace at the end.\n\n  lines.forEach(function each(line) {\n    console.error('asset-bundle:warning', line);\n  });\n}", "label": 3}
{"code": "public void close()\t{\n\t\tif (watchdog != null) {\n\t\t\twatchdog.cancel();\n\t\t\twatchdog = null;\n\t\t}\n\t\t\n\t\tdisconnect();\n\t\t\n\t\t// clear nodes collection and send queue\n\t\tfor (Object listener : this.zwaveEventListeners.toArray()) {\n\t\t\tif (!(listener instanceof ZWaveNode))\n\t\t\t\tcontinue;\n\t\t\t\n\t\t\tthis.zwaveEventListeners.remove(listener);\n\t\t}\n\t\t\n\t\tthis.zwaveNodes.clear();\n\t\tthis.sendQueue.clear();\n\t\t\n\t\tlogger.info(\"Stopped Z-Wave controller\");\n\t}", "label": 0}
{"code": "def to(param = :top)\n      args = @object.is_a?(Watir::Element) ? element_scroll(param) : browser_scroll(param)\n      raise ArgumentError, \"Don't know how to scroll #{@object} to: #{param}!\" if args.nil?\n\n      @object.browser.execute_script(*args)\n      self\n    end", "label": 4}
{"code": "func (a *Allocator) DiscoverNew(dType discoverapi.DiscoveryType, data interface{}) error {\n\tif dType != discoverapi.DatastoreConfig {\n\t\treturn nil\n\t}\n\n\tdsc, ok := data.(discoverapi.DatastoreConfigData)\n\tif !ok {\n\t\treturn types.InternalErrorf(\"incorrect data in datastore update notification: %v\", data)\n\t}\n\n\tds, err := datastore.NewDataStoreFromConfig(dsc)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn a.initializeAddressSpace(globalAddressSpace, ds)\n}", "label": 5}
{"code": "private static Constructor retrieveCollectionProxyConstructor(Class proxyClass, Class baseType, String typeDesc)\r\n    {\r\n        if(proxyClass == null)\r\n        {\r\n            throw new MetadataException(\"No \" + typeDesc + \" specified.\");\r\n        }\r\n        if(proxyClass.isInterface() || Modifier.isAbstract(proxyClass.getModifiers()) || !baseType.isAssignableFrom(proxyClass))\r\n        {\r\n            throw new MetadataException(\"Illegal class \"\r\n                    + proxyClass.getName()\r\n                    + \" specified for \"\r\n                    + typeDesc\r\n                    + \". Must be a concrete subclass of \"\r\n                    + baseType.getName());\r\n        }\r\n\r\n        Class[] paramType = {PBKey.class, Class.class, Query.class};\r\n\r\n        try\r\n        {\r\n            return proxyClass.getConstructor(paramType);\r\n        }\r\n        catch(NoSuchMethodException ex)\r\n        {\r\n            throw new MetadataException(\"The class \"\r\n                    + proxyClass.getName()\r\n                    + \" specified for \"\r\n                    + typeDesc\r\n                    + \" is required to have a public constructor with signature (\"\r\n                    + PBKey.class.getName()\r\n                    + \", \"\r\n                    + Class.class.getName()\r\n                    + \", \"\r\n                    + Query.class.getName()\r\n                    + \").\");\r\n        }\r\n    }", "label": 0}
{"code": "func NewWithPortAllocator(allocator *portallocator.PortAllocator, proxyPath string) *PortMapper {\n\treturn &PortMapper{\n\t\tcurrentMappings: make(map[string]*mapping),\n\t\tAllocator:       allocator,\n\t\tproxyPath:       proxyPath,\n\t}\n}", "label": 5}
{"code": "def cancel_all_orders(self) -> List[str]:\n        \"\"\"Cancel all open orders.\"\"\"\n        order_ids = [o.id for o in self.fetch_all_open_orders()]\n        return self.cancel_orders(order_ids)", "label": 1}
{"code": "public function toArray()\n    {\n        return [\n            'uuid' => $this->uuid,\n            'batch_id' => $this->batchId,\n            'type' => $this->type,\n            'content' => $this->content,\n            'created_at' => $this->recordedAt->toDateTimeString(),\n        ];\n    }", "label": 2}
{"code": "def remove_attribute(name)\n      as_writable_attribute!(name) do |access|\n        _assigning do\n          attribute_will_change!(access)\n          delayed_atomic_unsets[atomic_attribute_name(access)] = [] unless new_record?\n          attributes.delete(access)\n        end\n      end\n    end", "label": 4}
{"code": "def read_scalar(buffer = new_buffer, max_size = nil)\n      if !@io.read(4, buffer)\n        return nil\n      end\n      while buffer.size < 4\n        tmp = @io.read(4 - buffer.size)\n        if tmp.empty?\n          return nil\n        else\n          buffer << tmp\n        end\n      end\n\n      size = buffer.unpack(UINT32_PACK_FORMAT)[0]\n      if size == 0\n        buffer.replace('')\n        return buffer\n      else\n        if !max_size.nil? && size > max_size\n          raise SecurityError, \"Scalar message size (#{size}) \" <<\n            \"exceeds maximum allowed size (#{max_size}).\"\n        end\n        if !@io.read(size, buffer)\n          return nil\n        end\n        if buffer.size < size\n          tmp = ''\n          while buffer.size < size\n            if !@io.read(size - buffer.size, tmp)\n              return nil\n            else\n              buffer << tmp\n            end\n          end\n        end\n        return buffer\n      end\n    rescue Errno::ECONNRESET\n      return nil\n    end", "label": 4}
{"code": "func (s *RPCServer) done() {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\n\tif s.DoneCh != nil {\n\t\tclose(s.DoneCh)\n\t\ts.DoneCh = nil\n\t}\n}", "label": 5}
{"code": "private function normalizeResource($resource)\n    {\n        $pieces = explode('/', trim($resource, '/'));\n        array_walk($pieces, function (&$piece) {\n            $piece = rawurlencode($piece);\n        });\n        return '/' . implode('/', $pieces);\n    }", "label": 2}
{"code": "func (c *Client) RotateExternalCertAuthority(ca services.CertAuthority) error {\n\tif err := ca.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdata, err := services.GetCertAuthorityMarshaler().MarshalCertAuthority(ca)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"authorities\", string(ca.GetType()), \"rotate\", \"external\"),\n\t\t&rotateExternalCertAuthorityRawReq{CA: data})\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def check_children_order(sorted_children, children)\n      sorted_children.each_with_index do |sorted_item, index|\n        next if sorted_item == children[index]\n\n        add_lint(sorted_item.first.line,\n                 \"Expected item on line #{sorted_item.first.line} to appear \" \\\n                 \"before line #{children[index].first.line}. #{MESSAGE}\")\n        break\n      end\n    end", "label": 4}
{"code": "public function parse($schema)\n    {\n        $this->schema = $schema;\n        $parsed = [];\n        foreach ($this->getSchemas() as $schemaArray) {\n            $column = $this->getColumn($schemaArray);\n            $attributes = $this->getAttributes($column, $schemaArray);\n            $parsed[$column] = $attributes;\n        }\n\n        return $parsed;\n    }", "label": 2}
{"code": "def csv(options = {}, &block)\n      options[:resource] = config\n\n      config.csv_builder = CSVBuilder.new(options, &block)\n    end", "label": 4}
{"code": "def _var_bounds(self):\n        \"\"\" Returns bounds on the optimisation variables.\n        \"\"\"\n        x0 = array([])\n        xmin = array([])\n        xmax = array([])\n\n        for var in self.om.vars:\n            x0 = r_[x0, var.v0]\n            xmin = r_[xmin, var.vl]\n            xmax = r_[xmax, var.vu]\n\n        return x0, xmin, xmax", "label": 1}
{"code": "def execute_all(event, object)\n      each_subscription_id(event) do |subscription_id|\n        execute(subscription_id, event, object)\n      end\n    end", "label": 4}
{"code": "public static function byteStringToInt($bytes)\n    {\n        if (!self::isSupported()) {\n            throw new \\RuntimeException('This utility is only supported on 64 bit machines with PHP version > 5.5.');\n        }\n        if (self::isSystemLittleEndian()) {\n            $bytes = strrev($bytes);\n        }\n        return unpack(\"q\", $bytes)[1];\n    }", "label": 2}
{"code": "def if_device_path_exists(device_serial, device_path)\n      return if run_adb_command(\"adb -s #{device_serial} shell ls #{device_path}\",\n                                print_all: false,\n                                print_command: false).include?('No such file')\n\n      yield(device_path)\n    rescue\n      # Some versions of ADB will have a non-zero exit status for this, which will cause the executor to raise.\n      # We can safely ignore that and treat it as if it returned 'No such file'\n    end", "label": 4}
{"code": "def disconnect(signal, receiver):\n    \"\"\"Disconnect the receiver `func` from the signal, identified by\n    `signal_id`.\n\n    Args:\n        signal: The signal identifier.\n        receiver: The callable receiver to disconnect.\n\n    Returns:\n        True if the receiver was successfully disconnected. False otherwise.\n    \"\"\"\n    inputkey = __make_id(receiver)\n\n    with __lock:\n        __purge()\n        receivers = __receivers.get(signal)\n\n        for idx in six.moves.range(len(receivers)):\n            connected = receivers[idx]()\n\n            if inputkey != __make_id(connected):\n                continue\n\n            del receivers[idx]\n            return True  # receiver successfully disconnected!\n\n    return False", "label": 1}
{"code": "def pretty_print(io = $stdout, **options)\n      # Handle the special case that Ruby PrettyPrint expects `pretty_print`\n      # to be a customized pretty printing function for a class\n      return io.pp_object(self) if defined?(PP) && io.is_a?(PP)\n\n      io = File.open(options[:to_file], \"w\") if options[:to_file]\n\n      color_output = options.fetch(:color_output) { io.respond_to?(:isatty) && io.isatty }\n      @colorize = color_output ? Polychrome.new : Monochrome.new\n\n      if options[:scale_bytes]\n        total_allocated_output = scale_bytes(total_allocated_memsize)\n        total_retained_output = scale_bytes(total_retained_memsize)\n      else\n        total_allocated_output = \"#{total_allocated_memsize} bytes\"\n        total_retained_output = \"#{total_retained_memsize} bytes\"\n      end\n\n      io.puts \"Total allocated: #{total_allocated_output} (#{total_allocated} objects)\"\n      io.puts \"Total retained:  #{total_retained_output} (#{total_retained} objects)\"\n\n      if options[:detailed_report] != false\n        io.puts\n        TYPES.each do |type|\n          METRICS.each do |metric|\n            NAMES.each do |name|\n              scale_data = metric == \"memory\" && options[:scale_bytes]\n              dump \"#{type} #{metric} by #{name}\", self.send(\"#{type}_#{metric}_by_#{name}\"), io, scale_data\n            end\n          end\n        end\n      end\n\n      io.puts\n      dump_strings(io, \"Allocated\", strings_allocated, limit: options[:allocated_strings])\n      io.puts\n      dump_strings(io, \"Retained\", strings_retained, limit: options[:retained_strings])\n\n      io.close if io.is_a? File\n    end", "label": 4}
{"code": "private boolean hasBidirectionalAssociation(Class clazz)\r\n    {\r\n        ClassDescriptor cdesc;\r\n        Collection refs;\r\n        boolean hasBidirAssc;\r\n\r\n        if (_withoutBidirAssc.contains(clazz))\r\n        {\r\n            return false;\r\n        }\r\n\r\n        if (_withBidirAssc.contains(clazz))\r\n        {\r\n            return true;\r\n        }\r\n\r\n        // first time we meet this class, let's look at metadata\r\n        cdesc = _pb.getClassDescriptor(clazz);\r\n        refs = cdesc.getObjectReferenceDescriptors();\r\n        hasBidirAssc = false;\r\n        REFS_CYCLE:\r\n        for (Iterator it = refs.iterator(); it.hasNext(); )\r\n        {\r\n            ObjectReferenceDescriptor ord;\r\n            ClassDescriptor relCDesc;\r\n            Collection relRefs;\r\n\r\n            ord = (ObjectReferenceDescriptor) it.next();\r\n            relCDesc = _pb.getClassDescriptor(ord.getItemClass());\r\n            relRefs = relCDesc.getObjectReferenceDescriptors();\r\n            for (Iterator relIt = relRefs.iterator(); relIt.hasNext(); )\r\n            {\r\n                ObjectReferenceDescriptor relOrd;\r\n\r\n                relOrd = (ObjectReferenceDescriptor) relIt.next();\r\n                if (relOrd.getItemClass().equals(clazz))\r\n                {\r\n                    hasBidirAssc = true;\r\n                    break REFS_CYCLE;\r\n                }\r\n            }\r\n        }\r\n        if (hasBidirAssc)\r\n        {\r\n            _withBidirAssc.add(clazz);\r\n        }\r\n        else\r\n        {\r\n            _withoutBidirAssc.add(clazz);\r\n        }\r\n\r\n        return hasBidirAssc;\r\n    }", "label": 0}
{"code": "function indent(str, indent) {\n            if (typeof indent === 'number') {\n                var indent_str = '';\n                while (indent_str.length < indent) indent_str += ' ';\n                indent = indent_str;\n            }\n            var lines = str.split(/\\n/);\n            for (var i=0; i<lines.length; i++) {\n                if (lines[i].trim() !== '')\n                    lines[i] = indent + lines[i];\n            }\n            return lines.join(\"\\n\");            \n        }", "label": 3}
{"code": "func (dct *DjangoContentType) Delete(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !dct._exists {\n\t\treturn nil\n\t}\n\n\t// if deleted, bail\n\tif dct._deleted {\n\t\treturn nil\n\t}\n\n\t// sql query\n\tconst sqlstr = `DELETE FROM public.django_content_type WHERE id = $1`\n\n\t// run query\n\tXOLog(sqlstr, dct.ID)\n\t_, err = db.Exec(sqlstr, dct.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// set deleted\n\tdct._deleted = true\n\n\treturn nil\n}", "label": 5}
{"code": "func (m *MockIndex) ForeignTwo(arg0 imp2.Imp2) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"ForeignTwo\", arg0)\n}", "label": 5}
{"code": "func ParsePrivateKeyDER(der []byte) (crypto.Signer, error) {\n\tgeneralKey, err := x509.ParsePKCS8PrivateKey(der)\n\tif err != nil {\n\t\tgeneralKey, err = x509.ParsePKCS1PrivateKey(der)\n\t\tif err != nil {\n\t\t\tgeneralKey, err = x509.ParseECPrivateKey(der)\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"Failed to parse key: %v.\", err)\n\t\t\t\treturn nil, trace.BadParameter(\"failed parsing private key\")\n\t\t\t}\n\t\t}\n\t}\n\n\tswitch generalKey.(type) {\n\tcase *rsa.PrivateKey:\n\t\treturn generalKey.(*rsa.PrivateKey), nil\n\tcase *ecdsa.PrivateKey:\n\t\treturn generalKey.(*ecdsa.PrivateKey), nil\n\t}\n\n\treturn nil, trace.BadParameter(\"unsupported private key type\")\n}", "label": 5}
{"code": "def split_into_chunks_of(chunk_size, suffix_length = 3)\n      if chunk_size.is_a?(Integer) && suffix_length.is_a?(Integer)\n        @splitter = Splitter.new(self, chunk_size, suffix_length)\n      else\n        raise Error, <<-EOS\n          Invalid arguments for #split_into_chunks_of()\n          +chunk_size+ (and optional +suffix_length+) must be Integers.\n        EOS\n      end\n    end", "label": 4}
{"code": "func (m *Manager) ProviderSummary(ctx context.Context, entity types.ManagedObjectReference) (*types.PerfProviderSummary, error) {\n\treq := types.QueryPerfProviderSummary{\n\t\tThis:   m.Reference(),\n\t\tEntity: entity,\n\t}\n\n\tres, err := methods.QueryPerfProviderSummary(ctx, m.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &res.Returnval, nil\n}", "label": 5}
{"code": "public function setFileSet($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CloudStorageOptions_FileSet::class);\n        $this->file_set = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setMessages($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\PubSub\\V1\\PubsubMessage::class);\n        $this->messages = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function(next) {\n            if (options.noModules) return next();\n            var opts = {\n                denyModules: options.denyModules || core.denyModules[core.role] || core.denyModules[\"\"],\n                allowModules: options.allowModules || core.allowModules[core.role] || core.allowModules[\"\"],\n                stopOnError: options.stopOnError || core.stopOnError,\n            };\n            var modules = path.resolve(__dirname, \"../modules\");\n            core.loadModules(modules, opts);\n            core.path.modules.forEach(function(mod) {\n                if (modules == path.resolve(mod)) return;\n                core.loadModules(mod, opts);\n            });\n            next();\n        }", "label": 3}
{"code": "def pixel_intensity(pixel)\n      (306 * (pixel.red & MAX_QUANTUM) + 601 * (pixel.green & MAX_QUANTUM) + 117 * (pixel.blue & MAX_QUANTUM)) / 1024\n    end", "label": 4}
{"code": "public List<Pair<int[][][], int[]>> documentsToDataAndLabelsList(Collection<List<IN>> documents) {\r\n    int numDatums = 0;\r\n\r\n    List<Pair<int[][][], int[]>> docList = new ArrayList<Pair<int[][][], int[]>>();\r\n    for (List<IN> doc : documents) {\r\n      Pair<int[][][], int[]> docPair = documentToDataAndLabels(doc);\r\n      docList.add(docPair);\r\n      numDatums += doc.size();\r\n    }\r\n\r\n    System.err.println(\"numClasses: \" + classIndex.size() + ' ' + classIndex);\r\n    System.err.println(\"numDocuments: \" + docList.size());\r\n    System.err.println(\"numDatums: \" + numDatums);\r\n    System.err.println(\"numFeatures: \" + featureIndex.size());\r\n    return docList;\r\n  }", "label": 0}
{"code": "protected static function collectEntries($batchId)\n    {\n        return collect(static::$entriesQueue)\n            ->each(function ($entry) use ($batchId) {\n                $entry->batchId($batchId);\n\n                if ($entry->isDump()) {\n                    $entry->assignEntryPointFromBatch(static::$entriesQueue);\n                }\n            });\n    }", "label": 2}
{"code": "private function nested($annotation, $nestedContext)\n    {\n        if (property_exists($annotation, '_context') && $annotation->_context === $this->_context) {\n            $annotation->_context = $nestedContext;\n        }\n        return $annotation;\n    }", "label": 2}
{"code": "def unban(user, reason = nil)\n      API::Server.unban_user(@bot.token, @id, user.resolve_id, reason)\n    end", "label": 4}
{"code": "function clearSelectionEvents(array) {\n    while (array.length) {\n      var last = lst(array);\n      if (last.ranges) array.pop();\n      else break;\n    }\n  }", "label": 3}
{"code": "public Object get(int dataSet) throws SerializationException {\r\n\t\tObject result = null;\r\n\t\tfor (Iterator<DataSet> i = dataSets.iterator(); i.hasNext();) {\r\n\t\t\tDataSet ds = i.next();\r\n\t\t\tDataSetInfo info = ds.getInfo();\r\n\t\t\tif (info.getDataSetNumber() == dataSet) {\r\n\t\t\t\tresult = getData(ds);\r\n\t\t\t\tbreak;\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn result;\r\n\t}", "label": 0}
{"code": "func (flag *NetworkFlag) Change(device types.BaseVirtualDevice, update types.BaseVirtualDevice) {\n\tcurrent := device.(types.BaseVirtualEthernetCard).GetVirtualEthernetCard()\n\tchanged := update.(types.BaseVirtualEthernetCard).GetVirtualEthernetCard()\n\n\tcurrent.Backing = changed.Backing\n\n\tif changed.MacAddress != \"\" {\n\t\tcurrent.MacAddress = changed.MacAddress\n\t}\n\n\tif changed.AddressType != \"\" {\n\t\tcurrent.AddressType = changed.AddressType\n\t}\n}", "label": 5}
{"code": "private void handleApplicationUpdateRequest(SerialMessage incomingMessage) {\n\t\tlogger.trace(\"Handle Message Application Update Request\");\n\t\tint nodeId = incomingMessage.getMessagePayloadByte(1);\n\t\t\n\t\tlogger.trace(\"Application Update Request from Node \" + nodeId);\n\t\tUpdateState updateState = UpdateState.getUpdateState(incomingMessage.getMessagePayloadByte(0));\n\t\t\n\t\tswitch (updateState) {\n\t\t\tcase NODE_INFO_RECEIVED:\n\t\t\t\tlogger.debug(\"Application update request, node information received.\");\t\t\t\n\t\t\t\tint length = incomingMessage.getMessagePayloadByte(2);\n\t\t\t\tZWaveNode node = getNode(nodeId);\n\t\t\t\t\n\t\t\t\tnode.resetResendCount();\n\t\t\t\t\n\t\t\t\tfor (int i = 6; i < length + 3; i++) {\n\t\t\t\t\tint data = incomingMessage.getMessagePayloadByte(i);\n\t\t\t\t\tif(data == 0xef )  {\n\t\t\t\t\t\t// TODO: Implement control command classes\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tlogger.debug(String.format(\"Adding command class 0x%02X to the list of supported command classes.\", data));\n\t\t\t\t\tZWaveCommandClass commandClass = ZWaveCommandClass.getInstance(data, node, this);\n\t\t\t\t\tif (commandClass != null)\n\t\t\t\t\t\tnode.addCommandClass(commandClass);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// advance node stage.\n\t\t\t\tnode.advanceNodeStage();\n\t\t\t\t\n\t\t\t\tif (incomingMessage.getMessageClass() == this.lastSentMessage.getExpectedReply() && !incomingMessage.isTransActionCanceled()) {\n\t\t\t\t\tnotifyEventListeners(new ZWaveEvent(ZWaveEventType.TRANSACTION_COMPLETED_EVENT, this.lastSentMessage.getMessageNode(), 1, this.lastSentMessage));\n\t\t\t\t\ttransactionCompleted.release();\n\t\t\t\t\tlogger.trace(\"Released. Transaction completed permit count -> {}\", transactionCompleted.availablePermits());\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase NODE_INFO_REQ_FAILED:\n\t\t\t\tlogger.debug(\"Application update request, Node Info Request Failed, re-request node info.\");\n\t\t\t\t\n\t\t\t\tSerialMessage requestInfoMessage = this.lastSentMessage;\n\t\t\t\t\n\t\t\t\tif (requestInfoMessage.getMessageClass() != SerialMessage.SerialMessageClass.RequestNodeInfo) {\n\t\t\t\t\tlogger.warn(\"Got application update request without node info request, ignoring.\");\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\tif (--requestInfoMessage.attempts >= 0) {\n\t\t\t\t\tlogger.error(\"Got Node Info Request Failed while sending this serial message. Requeueing\");\n\t\t\t\t\tthis.enqueue(requestInfoMessage);\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tlogger.warn(\"Node Info Request Failed 3x. Discarding message: {}\", lastSentMessage.toString());\n\t\t\t\t}\n\t\t\t\ttransactionCompleted.release();\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tlogger.warn(String.format(\"TODO: Implement Application Update Request Handling of %s (0x%02X).\", updateState.getLabel(), updateState.getKey()));\n\t\t}\n\t}", "label": 0}
{"code": "func (c *Manager) GetLibraryItems(ctx context.Context, libraryID string) ([]Item, error) {\n\tids, err := c.ListLibraryItems(ctx, libraryID)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"get library items failed for: %s\", err)\n\t}\n\tvar items []Item\n\tfor _, id := range ids {\n\t\titem, err := c.GetLibraryItem(ctx, id)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"get library item for %s failed for %s\", id, err)\n\t\t}\n\t\titems = append(items, *item)\n\t}\n\treturn items, nil\n}", "label": 5}
{"code": "def from_mongo(cls, doc):\n\t\t\"\"\"Convert data coming in from the MongoDB wire driver into a Document instance.\"\"\"\n\t\t\n\t\tif doc is None:  # To support simplified iterative use, None should return None.\n\t\t\treturn None\n\t\t\n\t\tif isinstance(doc, Document):  # No need to perform processing on existing Document instances.\n\t\t\treturn doc\n\t\t\n\t\tif cls.__type_store__ and cls.__type_store__ in doc:  # Instantiate specific class mentioned in the data.\n\t\t\tcls = load(doc[cls.__type_store__], 'marrow.mongo.document')\n\t\t\n\t\t# Prepare a new instance in such a way that changes to the instance will be reflected in the originating doc.\n\t\tinstance = cls(_prepare_defaults=False)  # Construct an instance, but delay default value processing.\n\t\tinstance.__data__ = doc  # I am Popeye of Borg (pattern); you will be askimilgrated.\n\t\tinstance._prepare_defaults()  # pylint:disable=protected-access -- deferred default value processing.\n\t\t\n\t\treturn instance", "label": 1}
{"code": "public static auditnslogpolicy_aaagroup_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauditnslogpolicy_aaagroup_binding obj = new auditnslogpolicy_aaagroup_binding();\n\t\tobj.set_name(name);\n\t\tauditnslogpolicy_aaagroup_binding response[] = (auditnslogpolicy_aaagroup_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def iterfields(klass):\n    \"\"\"Iterate over the input class members and yield its TypedFields.\n\n    Args:\n        klass: A class (usually an Entity subclass).\n\n    Yields:\n        (class attribute name, TypedField instance) tuples.\n    \"\"\"\n    is_field = lambda x: isinstance(x, TypedField)\n\n    for name, field in inspect.getmembers(klass, predicate=is_field):\n        yield name, field", "label": 1}
{"code": "public function walkSelectStatementWithoutRowNumber(SelectStatement $AST, $addMissingItemsFromOrderByToSelect = true)\n    {\n        // We don't want to call this recursively!\n        if ($AST->orderByClause instanceof OrderByClause && $addMissingItemsFromOrderByToSelect) {\n            // In the case of ordering a query by columns from joined tables, we\n            // must add those columns to the select clause of the query BEFORE\n            // the SQL is generated.\n            $this->addMissingItemsFromOrderByToSelect($AST);\n        }\n\n        // Remove order by clause from the inner query\n        // It will be re-appended in the outer select generated by this method\n        $orderByClause      = $AST->orderByClause;\n        $AST->orderByClause = null;\n\n        $innerSql           = $this->getInnerSQL($AST);\n        $sqlIdentifier      = $this->getSQLIdentifier($AST);\n        $sqlAliasIdentifier = array_map(static function ($info) {\n            return $info['alias'];\n        }, $sqlIdentifier);\n\n        // Build the counter query\n        $sql = sprintf('SELECT DISTINCT %s FROM (%s) dctrn_result', implode(', ', $sqlAliasIdentifier), $innerSql);\n\n        // http://www.doctrine-project.org/jira/browse/DDC-1958\n        $sql = $this->preserveSqlOrdering($sqlAliasIdentifier, $innerSql, $sql, $orderByClause);\n\n        // Apply the limit and offset.\n        $sql = $this->platform->modifyLimitQuery(\n            $sql,\n            $this->maxResults,\n            $this->firstResult ?? 0\n        );\n\n        // Add the columns to the ResultSetMapping. It's not really nice but\n        // it works. Preferably I'd clear the RSM or simply create a new one\n        // but that is not possible from inside the output walker, so we dirty\n        // up the one we have.\n        foreach ($sqlIdentifier as $property => $propertyMapping) {\n            $this->rsm->addScalarResult($propertyMapping['alias'], $property, $propertyMapping['type']);\n        }\n\n        // Restore orderByClause\n        $AST->orderByClause = $orderByClause;\n\n        return $sql;\n    }", "label": 2}
{"code": "def parent(self):\n        \"\"\"Return parent resource\n\n        :rtype: Resource\n        :raises ResourceNotFound: parent resource doesn't exists\n        :raises ResourceMissing: parent resource is not defined\n        \"\"\"\n        try:\n            return Resource(self['parent_type'], uuid=self['parent_uuid'], check=True)\n        except KeyError:\n            raise ResourceMissing('%s has no parent resource' % self)", "label": 1}
{"code": "func (c *Manager) GetTags(ctx context.Context) ([]Tag, error) {\n\tids, err := c.ListTags(ctx)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"get tags failed for: %s\", err)\n\t}\n\n\tvar tags []Tag\n\tfor _, id := range ids {\n\t\ttag, err := c.GetTag(ctx, id)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"get category %s failed for %s\", id, err)\n\t\t}\n\n\t\ttags = append(tags, *tag)\n\n\t}\n\treturn tags, nil\n}", "label": 5}
{"code": "public function setParameters($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->parameters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function getModulePath(filePath, fileName) {\n    if (isJavaScript(fileName)) {\n        fileName = fileName.substring(0, fileName.length - 3);\n    }\n\n    return filePath + '/' + fileName;\n}", "label": 3}
{"code": "public function setSuffixes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->suffixes = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function recordException(MessageLogged $event)\n    {\n        if (! Telescope::isRecording() || $this->shouldIgnore($event)) {\n            return;\n        }\n\n        $exception = $event->context['exception'];\n\n        Telescope::recordException(\n            IncomingExceptionEntry::make($exception, [\n                'class' => get_class($exception),\n                'file' => $exception->getFile(),\n                'line' => $exception->getLine(),\n                'message' => $exception->getMessage(),\n                'trace' => $exception->getTrace(),\n                'line_preview' => ExceptionContext::get($exception),\n            ])->tags($this->tags($event))\n        );\n    }", "label": 2}
{"code": "def flatten(*sequence):\n        \"\"\"Flatten nested sequences into one.\"\"\"\n        result = []\n        for entry in sequence:\n            if isinstance(entry, list):\n                result += Select.flatten(*entry)\n            elif isinstance(entry, tuple):\n                result += Select.flatten(*entry)\n            else:\n                result.append(entry)\n        return result", "label": 1}
{"code": "public function read($path)\n    {\n        $url = self::BASE_URL.$path;\n        return file_get_contents($url, false, $this->context);\n    }", "label": 2}
{"code": "private static String removeLastDot(final String pkgName) {\n\t\treturn pkgName.charAt(pkgName.length() - 1) == Characters.DOT ? pkgName.substring(0, pkgName.length() - 1) : pkgName;\n\t}", "label": 0}
{"code": "public function setBindings(array $bindings = [])\n    {\n        $this->bindings = [];\n        foreach ($bindings as $binding) {\n            $this->addBinding($binding['role'], $binding['members']);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "private function parseCookie($cookie, $host = null, $path = null, $decode = false) {\n        // Explode the cookie string using a series of semicolons\n        $pieces = array_filter(array_map('trim', explode(';', $cookie)));\n\n        // The name of the cookie (first kvp) must include an equal sign.\n        if (empty($pieces) || !strpos($pieces[0], '=')) {\n            return false;\n        }\n\n        // Create the default return array\n        $data = array_merge(array_fill_keys(array_keys(self::$cookieParts), null), array(\n            'cookies'   => array(),\n            'data'      => array(),\n            'path'      => $path ?: '/',\n            'http_only' => false,\n            'discard'   => false,\n            'domain'    => $host\n        ));\n        $foundNonCookies = 0;\n\n        // Add the cookie pieces into the parsed data array\n        foreach ($pieces as $part) {\n\n            $cookieParts = explode('=', $part, 2);\n            $key = trim($cookieParts[0]);\n\n            if (count($cookieParts) == 1) {\n                // Can be a single value (e.g. secure, httpOnly)\n                $value = true;\n            } else {\n                // Be sure to strip wrapping quotes\n                $value = trim($cookieParts[1], \" \\n\\r\\t\\0\\x0B\\\"\");\n                if ($decode) {\n                    $value = urldecode($value);\n                }\n            }\n\n            // Only check for non-cookies when cookies have been found\n            if (!empty($data['cookies'])) {\n                foreach (self::$cookieParts as $mapValue => $search) {\n                    if (!strcasecmp($search, $key)) {\n                        $data[$mapValue] = $mapValue == 'port' ? array_map('trim', explode(',', $value)) : $value;\n                        $foundNonCookies++;\n                        continue 2;\n                    }\n                }\n            }\n\n            // If cookies have not yet been retrieved, or this value was not found in the pieces array, treat it as a\n            // cookie. IF non-cookies have been parsed, then this isn't a cookie, it's cookie data. Cookies then data.\n            $data[$foundNonCookies ? 'data' : 'cookies'][$key] = $value;\n        }\n\n        // Calculate the expires date\n        if (!$data['expires'] && $data['max_age']) {\n            $data['expires'] = time() + (int) $data['max_age'];\n        }\n\n        return $data;\n    }", "label": 2}
{"code": "func (c *Client) Delete(u string) (*roundtrip.Response, error) {\n\treturn httplib.ConvertResponse(c.Client.Delete(context.TODO(), u))\n}", "label": 5}
{"code": "def parse_sam(sam, qual):\n    \"\"\"\n    parse sam file and check mapping quality\n    \"\"\"\n    for line in sam:\n        if line.startswith('@'):\n            continue\n        line = line.strip().split()\n        if int(line[4]) == 0 or int(line[4]) < qual:\n            continue\n        yield line", "label": 1}
{"code": "def parallel(processes, threads):\n    \"\"\"\n    execute jobs in processes using N threads\n    \"\"\"\n    pool = multithread(threads)\n    pool.map(run_process, processes)\n    pool.close()\n    pool.join()", "label": 1}
{"code": "def __get_ws_distance(wstation, latitude, longitude):\n    \"\"\"Get the distance to the weatherstation from wstation section of xml.\n\n    wstation: weerstation section of buienradar xml (dict)\n    latitude: our latitude\n    longitude: our longitude\n    \"\"\"\n    if wstation:\n        try:\n            wslat = float(wstation[__BRLAT])\n            wslon = float(wstation[__BRLON])\n\n            dist = vincenty((latitude, longitude), (wslat, wslon))\n            log.debug(\"calc distance: %s (latitude: %s, longitude: \"\n                      \"%s, wslat: %s, wslon: %s)\", dist, latitude,\n                      longitude, wslat, wslon)\n            return dist\n        except (ValueError, TypeError, KeyError):\n            # value does not exist, or is not a float\n            return None\n    else:\n        return None", "label": 1}
{"code": "public function setSnapshot($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\PubSub\\V1\\Snapshot::class);\n        $this->snapshot = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function cancel($order): Collection\n    {\n        $this->payload['method'] = 'alipay.trade.cancel';\n        $this->payload['biz_content'] = json_encode(is_array($order) ? $order : ['out_trade_no' => $order]);\n        $this->payload['sign'] = Support::generateSign($this->payload);\n\n        Events::dispatch(Events::METHOD_CALLED, new Events\\MethodCalled('Alipay', 'Cancel', $this->gateway, $this->payload));\n\n        return Support::requestApi($this->payload);\n    }", "label": 2}
{"code": "def head(path, options = {}, &block)\n      ensure_method_maintained_across_redirects options\n      perform_request Net::HTTP::Head, path, options, &block\n    end", "label": 4}
{"code": "protected Object getObjectFromResultSet() throws PersistenceBrokerException\r\n    {\r\n\r\n        try\r\n        {\r\n            // if all primitive attributes of the object are contained in the ResultSet\r\n            // the fast direct mapping can be used\r\n            return super.getObjectFromResultSet();\r\n        }\r\n                // if the full loading failed we assume that at least PK attributes are contained\r\n                // in the ResultSet and perform a slower Identity based loading...\r\n                // This may of course also fail and can throw another PersistenceBrokerException\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            Identity oid = getIdentityFromResultSet();\r\n            return getBroker().getObjectByIdentity(oid);\r\n        }\r\n\r\n    }", "label": 0}
{"code": "function(input)\n    {\n      if ( isObject( input ) )\n      {\n        var discriminatedValue = input[ this.discriminator ];\n        var model = this.discriminatorsToModel[ discriminatedValue ];\n\n        if ( model )\n        {\n          return model.Database.keyHandler.buildKeyFromInput( input );\n        }\n      }\n\n      return input;\n    }", "label": 3}
{"code": "public static filterglobal_filterpolicy_binding[] get(nitro_service service) throws Exception{\n\t\tfilterglobal_filterpolicy_binding obj = new filterglobal_filterpolicy_binding();\n\t\tfilterglobal_filterpolicy_binding response[] = (filterglobal_filterpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def exit_statistics(hostname, start_time, count_sent, count_received, min_time, avg_time, max_time, deviation):\n    \"\"\"\n    Print ping exit statistics\n    \"\"\"\n    end_time = datetime.datetime.now()\n    duration = end_time - start_time\n    duration_sec = float(duration.seconds * 1000)\n    duration_ms = float(duration.microseconds / 1000)\n    duration = duration_sec + duration_ms\n    package_loss = 100 - ((float(count_received) / float(count_sent)) * 100)\n    print(f'\\b\\b--- {hostname} ping statistics ---')\n    try:\n        print(f'{count_sent} packages transmitted, {count_received} received, {package_loss}% package loss, time {duration}ms')\n    except ZeroDivisionError:\n        print(f'{count_sent} packets transmitted, {count_received} received, 100% packet loss, time {duration}ms')\n    print(\n        'rtt min/avg/max/dev = %.2f/%.2f/%.2f/%.2f ms' % (\n            min_time.seconds*1000 + float(min_time.microseconds)/1000,\n            float(avg_time) / 1000,\n            max_time.seconds*1000 + float(max_time.microseconds)/1000,\n            float(deviation)\n        )\n    )", "label": 1}
{"code": "def get_etree_root(doc, encoding=None):\n    \"\"\"Returns an instance of lxml.etree._Element for the given `doc` input.\n\n    Args:\n        doc: The input XML document. Can be an instance of\n            ``lxml.etree._Element``, ``lxml.etree._ElementTree``, a file-like\n            object, or a string filename.\n        encoding: The character encoding of `doc`. If ``None``, an attempt\n            will be made to determine the character encoding by the XML\n            parser.\n\n    Returns:\n        An ``lxml.etree._Element`` instance for `doc`.\n\n    Raises:\n        IOError: If `doc` cannot be found.\n        lxml.ParseError: If `doc` is a malformed XML document.\n\n    \"\"\"\n    tree = get_etree(doc, encoding)\n    root = tree.getroot()\n\n    return root", "label": 1}
{"code": "function _addAttribute() {\n  var attributeDictionary = arguments[0];\n\n  var attribute = null;\n  var name = null;\n\n  if (arguments.length === 2) {\n    attribute = arguments[1];\n  } else {\n    attribute = arguments[1];\n    name = arguments[2];\n  }\n\n  expect(attribute).to.be.an(\n    'object',\n    'Invalid argument type when adding an attribute ' + (name ? 'called \"' +\n    name + '\" ' : '') + 'in an AttributeDictionary (it has to be an object)'\n  );\n\n  if (name) {\n    if (attribute.name) {\n      expect(attribute.name).to.equal(\n        name,\n        'Invalid argument \"name\" when adding an attribute called \"' +\n        attribute.name + '\" in an AttributeDictionary (the name given in ' +\n        'argument and the name given in the attribute object should be equal)'\n      );\n    } else {\n      attribute.name = name;\n    }\n  }\n\n  if (!(attribute instanceof Attribute)) {\n    attribute = Attribute.resolve(attribute);\n  }\n\n  expect(attribute.constructor).to.not.equal(\n    Attribute,\n    'Invalid attribute \"' + attribute.name + '\". Attribute is an abstract ' +\n    'class and cannot be directly instantiated and added in an ' +\n    'AttributeDictionary'\n  );\n\n  expect(attributeDictionary).to.not.have.ownProperty(\n    attribute.name,\n    'Duplicated attribute name \"' + attribute.name + '\"'\n  );\n\n  Object.defineProperty(attributeDictionary, attribute.name, {\n    value: attribute,\n    enumerable: true,\n    writable: false,\n    configurable: false\n  });\n}", "label": 3}
{"code": "function(options) {\n            options = options || {};\n\n            //find ids that we don't have in cache and aren't already in the process of being fetched.\n            var idsNotInCache = _.difference(this.getTrackedIds(), _.pluck(parentInstance.models, 'id'));\n            var idsWithPromises = _.pick(parentInstance.idPromises, idsNotInCache);\n\n            // Determine which ids are already being fetched and the associated promises for those ids.\n            options.idsToFetch = _.difference(idsNotInCache, _.uniq(_.flatten(_.keys(idsWithPromises))));\n            var thisFetchPromise = this.fetch(options);\n\n            // Return a promise that resolves when all ids are fetched (including pending ids).\n            var allPromisesToWaitFor = _.flatten(_.values(idsWithPromises));\n            allPromisesToWaitFor.push(thisFetchPromise);\n            var allUniquePromisesToWaitFor = _.uniq(allPromisesToWaitFor);\n            return $.when.apply($, allUniquePromisesToWaitFor)\n              // Make it look like the multiple promises was performed by a single request.\n              .then(function() {\n                // collects the parts of each ajax call into arrays: result = { [data1, data2, ...], [textStatus1, textStatus2, ...], [jqXHR1, jqXHR2, ...] };\n                var result = _.zip(arguments);\n                // Flatten the data so it looks like the result of a single request.\n                var resultData = result[0];\n                var flattenedResultData = _.flatten(resultData);\n                return flattenedResultData;\n              });\n          }", "label": 3}
{"code": "public static base_responses delete(nitro_service client, String trapclass[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (trapclass != null && trapclass.length > 0) {\n\t\t\tsnmptrap deleteresources[] = new snmptrap[trapclass.length];\n\t\t\tfor (int i=0;i<trapclass.length;i++){\n\t\t\t\tdeleteresources[i] = new snmptrap();\n\t\t\t\tdeleteresources[i].trapclass = trapclass[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function getOuterTypeParametersOfClassOrInterface(symbol) {\n            var declaration = symbol.flags & 32 /* Class */ ? symbol.valueDeclaration : ts.getDeclarationOfKind(symbol, 222 /* InterfaceDeclaration */);\n            return appendOuterTypeParameters(undefined, declaration);\n        }", "label": 3}
{"code": "func getIfSocket() (fd int, err error) {\n\tfor _, socket := range []int{\n\t\tsyscall.AF_INET,\n\t\tsyscall.AF_PACKET,\n\t\tsyscall.AF_INET6,\n\t} {\n\t\tif fd, err = syscall.Socket(socket, syscall.SOCK_DGRAM, 0); err == nil {\n\t\t\tbreak\n\t\t}\n\t}\n\tif err == nil {\n\t\treturn fd, nil\n\t}\n\treturn -1, err\n}", "label": 5}
{"code": "function done(err, files) {\n    // On processing errors notify the watcher (if listening) that square is idle.\n    if (err && self.writable) {\n      self.logger.error(err);\n      return fn(err);\n    }\n\n    // Stop our cache, it will be activated again when we need it\n    self.cache.stop();\n\n    // Merge the results array to a key=>value object\n    files = (files || []).reduce(function reduceFiles(memo, collection) {\n      memo[collection.basename] = collection;\n      return memo;\n    }, {});\n\n    // Building is done, call callback if available.\n    self.logger.info('Successfully generated %s', Object.keys(files).join(', ').green);\n    if (err && !args.function) self.critical(err);\n    if (args.function) args.function.call(self, err, files, extensions);\n  }", "label": 3}
{"code": "def filtersBM(dataset,host=biomart_host):\n    \"\"\"\n    Lists BioMart filters for a specific dataset.\n\n    :param dataset: dataset to list filters of.\n    :param host: address of the host server, default='http://www.ensembl.org/biomart'\n\n    :returns: nothing\n\n    \"\"\"\n    stdout_ = sys.stdout #Keep track of the previous value.\n    stream = StringIO()\n    sys.stdout = stream   \n    server = BiomartServer(host)\n    d=server.datasets[dataset]\n    d.show_filters()\n    sys.stdout = stdout_ # restore the previous stdout.\n    variable = stream.getvalue() \n    v=variable.replace(\"{\",\" \") \n    v=v.replace(\"}\",\" \") \n    v=v.replace(\": \",\"\\t\")\n    print(v)", "label": 1}
{"code": "def next(self):\n        \"\"\"\n        Returns a result if availble within \"timeout\" else raises a \n        ``TimeoutError`` exception. See documentation for ``NuMap.next``.\n        \"\"\"\n        return self.iterator.next(task=self.task, timeout=self.timeout,\n                                                    block=self.block)", "label": 1}
{"code": "function inRange (value, min, max) {\n  const int = parseInt(value, 10)\n\n  return (\n    `${int}` === `${value.replace(/^0/, '')}` &&\n    int >= min &&\n    int <= max\n  )\n}", "label": 3}
{"code": "public function subscription()\n    {\n        return $this->info['subscription']\n            ? new Subscription($this->connection, $this->projectId, $this->info['subscription'], null, $this->encode)\n            : null;\n    }", "label": 2}
{"code": "def parse_coord_args(x, y=0)\n      if x.is_a?(String)\n        x, y = *Axlsx::name_to_indices(x)\n      end\n      if x.is_a?(Cell)\n        x, y = *x.pos\n      end\n      if x.is_a?(Array)\n        x, y = *x\n      end\n      [x, y]\n    end", "label": 4}
{"code": "public static void addItemsHandled(String handledItemsType, int handledItemsNumber) {\n    \tJobLogger jobLogger = (JobLogger) getInstance();\n        if (jobLogger == null) {\n            return;\n        }\n\n        jobLogger.addItemsHandledInstance(handledItemsType, handledItemsNumber);\n    }", "label": 0}
{"code": "public function setMembers($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Debugger\\V2\\Variable::class);\n        $this->members = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function(comparator, nullsFirst)\n  {\n    var cmp = comparator ? createComparator( comparator, nullsFirst ) : this.comparator;\n\n    return isSorted( cmp, this );\n  }", "label": 3}
{"code": "public void addColumnIsNull(String column)\r\n    {\r\n\t\t// PAW\r\n\t\t//SelectionCriteria c = ValueCriteria.buildNullCriteria(column, getAlias());\r\n\t\tSelectionCriteria c = ValueCriteria.buildNullCriteria(column, getUserAlias(column));\r\n        c.setTranslateAttribute(false);\r\n        addSelectionCriteria(c);\r\n    }", "label": 0}
{"code": "func (process *TeleportProcess) importListener(listenerType, address string) (net.Listener, error) {\n\tprocess.Lock()\n\tdefer process.Unlock()\n\n\tfor i := range process.importedDescriptors {\n\t\td := process.importedDescriptors[i]\n\t\tif d.Type == listenerType && d.Address == address {\n\t\t\tl, err := d.ToListener()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\tprocess.importedDescriptors = append(process.importedDescriptors[:i], process.importedDescriptors[i+1:]...)\n\t\t\tprocess.registeredListeners = append(process.registeredListeners, RegisteredListener{Type: listenerType, Address: address, Listener: l})\n\t\t\treturn l, nil\n\t\t}\n\t}\n\n\treturn nil, trace.NotFound(\"no file descriptor for type %v and address %v has been imported\", listenerType, address)\n}", "label": 5}
{"code": "def main():\r\n    \"\"\"Entry point for stand-alone execution.\"\"\"\r\n    conf.init(), db.init(conf.DbPath)\r\n    inqueue = LineQueue(sys.stdin).queue\r\n    outqueue = type(\"\", (), {\"put\": lambda self, x: print(\"\\r%s\" % x, end=\" \")})()\r\n    if \"--quiet\" in sys.argv: outqueue = None\r\n    if conf.MouseEnabled:    inqueue.put(\"mouse_start\")\r\n    if conf.KeyboardEnabled: inqueue.put(\"keyboard_start\")\r\n    start(inqueue, outqueue)", "label": 1}
{"code": "def method_missing(method, *args, &block)\n      return benchmark(method, *args) { adapter.send(method, *args, &block) } if adapter.respond_to?(method)\n\n      super\n    end", "label": 4}
{"code": "public void setAlias(UserAlias userAlias)\r\n\t{\r\n\t\tm_alias = userAlias.getName();\r\n\r\n\t\t// propagate to SelectionCriteria,not to Criteria\r\n\t\tfor (int i = 0; i < m_criteria.size(); i++)\r\n\t\t{\r\n\t\t\tif (!(m_criteria.elementAt(i) instanceof Criteria))\r\n\t\t\t{\r\n\t\t\t\t((SelectionCriteria) m_criteria.elementAt(i)).setAlias(userAlias);\r\n\t\t\t}\r\n\t\t}\r\n\t}", "label": 0}
{"code": "public function getOperation($name)\n    {\n        if (!isset($this->operations[$name])) {\n            if (!isset($this->definition['operations'][$name])) {\n                throw new \\InvalidArgumentException(\"Unknown operation: $name\");\n            }\n            $this->operations[$name] = new Operation(\n                $this->definition['operations'][$name],\n                $this->shapeMap\n            );\n        }\n\n        return $this->operations[$name];\n    }", "label": 2}
{"code": "public static base_responses update(nitro_service client, nspbr resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnspbr updateresources[] = new nspbr[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new nspbr();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].action = resources[i].action;\n\t\t\t\tupdateresources[i].srcip = resources[i].srcip;\n\t\t\t\tupdateresources[i].srcipop = resources[i].srcipop;\n\t\t\t\tupdateresources[i].srcipval = resources[i].srcipval;\n\t\t\t\tupdateresources[i].srcport = resources[i].srcport;\n\t\t\t\tupdateresources[i].srcportop = resources[i].srcportop;\n\t\t\t\tupdateresources[i].srcportval = resources[i].srcportval;\n\t\t\t\tupdateresources[i].destip = resources[i].destip;\n\t\t\t\tupdateresources[i].destipop = resources[i].destipop;\n\t\t\t\tupdateresources[i].destipval = resources[i].destipval;\n\t\t\t\tupdateresources[i].destport = resources[i].destport;\n\t\t\t\tupdateresources[i].destportop = resources[i].destportop;\n\t\t\t\tupdateresources[i].destportval = resources[i].destportval;\n\t\t\t\tupdateresources[i].nexthop = resources[i].nexthop;\n\t\t\t\tupdateresources[i].nexthopval = resources[i].nexthopval;\n\t\t\t\tupdateresources[i].iptunnel = resources[i].iptunnel;\n\t\t\t\tupdateresources[i].iptunnelname = resources[i].iptunnelname;\n\t\t\t\tupdateresources[i].srcmac = resources[i].srcmac;\n\t\t\t\tupdateresources[i].protocol = resources[i].protocol;\n\t\t\t\tupdateresources[i].protocolnumber = resources[i].protocolnumber;\n\t\t\t\tupdateresources[i].vlan = resources[i].vlan;\n\t\t\t\tupdateresources[i].Interface = resources[i].Interface;\n\t\t\t\tupdateresources[i].priority = resources[i].priority;\n\t\t\t\tupdateresources[i].msr = resources[i].msr;\n\t\t\t\tupdateresources[i].monitor = resources[i].monitor;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public int getNumWeights() {\r\n    if (weights == null) return 0;\r\n    int numWeights = 0;\r\n    for (double[] wts : weights) {\r\n      numWeights += wts.length;\r\n    }\r\n    return numWeights;\r\n  }", "label": 0}
{"code": "def _magic(header, footer, mime, ext=None):\n    \"\"\" Discover what type of file it is based on the incoming string \"\"\"\n    if not header:\n        raise ValueError(\"Input was empty\")\n    info = _identify_all(header, footer, ext)[0]\n    if mime:\n        return info.mime_type\n    return info.extension if not \\\n        isinstance(info.extension, list) else info[0].extension", "label": 1}
{"code": "def generate_redirect_from(doc)\n      doc.redirect_from.each do |path|\n        page = RedirectPage.redirect_from(doc, path)\n        doc.site.pages << page\n        redirects[page.redirect_from] = page.redirect_to\n      end\n    end", "label": 4}
{"code": "def getSequence(self, level=0):\n        '''Get a sequence of nodes.'''\n\n        seq = []\n        op = ''\n        left_operand = None\n        right_operand = None\n        sequence_closed = False\n        while True:\n            c = self.next()\n            if not c:\n                break\n            if c and c not in self.meta_chars:\n                seq.append(self.getLiteral())\n            elif c and c == u'$' and self.lookahead() == u'{':\n                seq.append(self.getSource())\n            elif c == u'[' and not self.last() == u'\\\\':\n                seq.append(self.getCharacterSet())\n            elif c == u'(' and not self.last() == u'\\\\':\n                seq.append(self.getSequence(level + 1))\n            elif c == u')' and not self.last() == u'\\\\':\n                # end of this sequence\n                if level == 0:\n                    # there should be no parens here\n                    raise StringGenerator.SyntaxError(u\"Extra closing parenthesis\")\n                sequence_closed = True\n                break\n            elif c == u'|' and not self.last() == u'\\\\':\n                op = c\n            elif c == u'&' and not self.last() == u'\\\\':\n                op = c\n            else:\n                if c in self.meta_chars and not self.last() == u\"\\\\\":\n                    raise StringGenerator.SyntaxError(u\"Un-escaped special character: %s\" % c)\n            \n            #print( op,len(seq) )\n            if op and not left_operand:\n                if not seq or len(seq) < 1:\n                    raise StringGenerator.SyntaxError(u\"Operator: %s with no left operand\" % op)\n                left_operand = seq.pop()\n            elif op and len(seq) >= 1 and left_operand:\n                right_operand = seq.pop()\n\n                #print( \"popped: [%s] %s:%s\"%( op, left_operand, right_operand) )\n                if op == u'|':\n                    seq.append(StringGenerator.SequenceOR([left_operand, right_operand]))\n                elif op == u'&':\n                    seq.append(StringGenerator.SequenceAND([left_operand, right_operand]))\n\n                op = u''\n                left_operand = None\n                right_operand = None\n\n        # check for syntax errors\n        if op:\n            raise StringGenerator.SyntaxError(u\"Operator: %s with no right operand\" % op)\n        if level > 0 and not sequence_closed:\n            # it means we are finishing a non-first-level sequence without closing parens\n            raise StringGenerator.SyntaxError(u\"Missing closing parenthesis\")\n\n        return StringGenerator.Sequence(seq)", "label": 1}
{"code": "def updatable(self):\n        \"\"\"bootstrap-py package updatable?.\"\"\"\n        if self.latest_version > self.current_version:\n            updatable_version = self.latest_version\n        else:\n            updatable_version = False\n        return updatable_version", "label": 1}
{"code": "def get(self, recipe=None, plugin=None):\n        \"\"\"\n        Get one or more recipes.\n\n        :param recipe: Name of the recipe\n        :type recipe: str\n        :param plugin: Plugin object, under which the recipe was registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if plugin is not None:\n            if recipe is None:\n                recipes_list = {}\n                for key in self.recipes.keys():\n                    if self.recipes[key].plugin == plugin:\n                        recipes_list[key] = self.recipes[key]\n                return recipes_list\n            else:\n                if recipe in self.recipes.keys():\n                    if self.recipes[recipe].plugin == plugin:\n                        return self.recipes[recipe]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if recipe is None:\n                return self.recipes\n            else:\n                if recipe in self.recipes.keys():\n                    return self.recipes[recipe]\n                else:\n                    return None", "label": 1}
{"code": "function sources(k) {\n      (src[k] || []).forEach(function(s) { deps[s] = k; sources(s); });\n    }", "label": 3}
{"code": "function CheckStatus(token) {\n  if (!token) throw 'Invoice Token must be provided'\n  const config = this.config\n  const hubtelurl = `https://api.hubtel.com/v1/merchantaccount/onlinecheckout/invoice/status/${token}`\n  const auth =\n    'Basic ' +\n     Buffer.from(config.clientid + ':' + config.secretid).toString('base64')\n\n  return request.get(hubtelurl, {\n    headers: {\n      Authorization: auth,\n      'content-type': 'application/json',\n    },\n    json: true,\n  })\n}", "label": 3}
{"code": "public static void createDotStoryFile(String scenarioName,\n            String srcTestRootFolder, String packagePath,\n            String givenDescription, String whenDescription,\n            String thenDescription) throws BeastException {\n        String[] folders = packagePath.split(\".\");\n        for (String folder : folders) {\n            srcTestRootFolder += \"/\" + folder;\n        }\n\n        FileWriter writer = createFileWriter(createDotStoryName(scenarioName),\n                packagePath, srcTestRootFolder);\n        try {\n            writer.write(\"Scenario: \" + scenarioName + \"\\n\");\n            writer.write(\"Given \" + givenDescription + \"\\n\");\n            writer.write(\"When \" + whenDescription + \"\\n\");\n            writer.write(\"Then \" + thenDescription + \"\\n\");\n            writer.close();\n        } catch (Exception e) {\n            String message = \"Unable to write the .story file for the scenario \"\n                    + scenarioName;\n            logger.severe(message);\n            logger.severe(e.getMessage());\n            throw new BeastException(message, e);\n        }\n    }", "label": 0}
{"code": "func (f Filter) MatchObjectContent(objects []types.ObjectContent) []types.ManagedObjectReference {\n\tvar refs []types.ManagedObjectReference\n\n\tfor _, o := range objects {\n\t\tif f.MatchPropertyList(o.PropSet) {\n\t\t\trefs = append(refs, o.Obj)\n\t\t}\n\t}\n\n\treturn refs\n}", "label": 5}
{"code": "def upload_obbs(apk_path, apk_version_code)\n      expansion_paths = find_obbs(apk_path)\n      ['main', 'patch'].each do |type|\n        if expansion_paths[type]\n          upload_obb(expansion_paths[type], type, apk_version_code)\n        end\n      end\n    end", "label": 4}
{"code": "def encoded_group_addresses\n      groups.map { |k,v| v.map { |a| a.encoded } }.flatten\n    end", "label": 4}
{"code": "public String getMessage(Locale locale) {\n\t\tif (getCause() != null) {\n\t\t\tString message = getShortMessage(locale) + \", \" + translate(\"ROOT_CAUSE\", locale) + \" \";\n\t\t\tif (getCause() instanceof GeomajasException) {\n\t\t\t\treturn message + ((GeomajasException) getCause()).getMessage(locale);\n\t\t\t}\n\t\t\treturn message + getCause().getMessage();\n\t\t} else {\n\t\t\treturn getShortMessage(locale);\n\t\t}\n\t}", "label": 0}
{"code": "def benchmark(message = \"Benchmarking\", options = {})\n      if logger\n        options.assert_valid_keys(:level, :silence)\n        options[:level] ||= :info\n\n        result = nil\n        ms = Benchmark.ms { result = options[:silence] ? logger.silence { yield } : yield }\n        logger.send(options[:level], \"%s (%.1fms)\" % [ message, ms ])\n        result\n      else\n        yield\n      end\n    end", "label": 4}
{"code": "func (c *container) inspect(vm *VirtualMachine) error {\n\tif c.id == \"\" {\n\t\treturn nil\n\t}\n\n\tvar objects []struct {\n\t\tNetworkSettings struct {\n\t\t\tGateway     string\n\t\t\tIPAddress   string\n\t\t\tIPPrefixLen int\n\t\t\tMacAddress  string\n\t\t}\n\t}\n\n\tcmd := exec.Command(\"docker\", \"inspect\", c.id)\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = json.NewDecoder(bytes.NewReader(out)).Decode(&objects); err != nil {\n\t\treturn err\n\t}\n\n\tvm.Config.Annotation = strings.Join(cmd.Args, \" \")\n\tvm.logPrintf(\"%s: %s\", vm.Config.Annotation, string(out))\n\n\tfor _, o := range objects {\n\t\ts := o.NetworkSettings\n\t\tif s.IPAddress == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tvm.Guest.IpAddress = s.IPAddress\n\t\tvm.Summary.Guest.IpAddress = s.IPAddress\n\n\t\tif len(vm.Guest.Net) != 0 {\n\t\t\tnet := &vm.Guest.Net[0]\n\t\t\tnet.IpAddress = []string{s.IPAddress}\n\t\t\tnet.MacAddress = s.MacAddress\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function setServiceContext($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\ErrorReporting\\V1beta1\\ServiceContext::class);\n        $this->service_context = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def start(self):\n        \"\"\"\n        Start listening to changes\n        \"\"\"\n        self.running = True\n        self.thread = threading.Thread(target=self._main_loop)\n        self.thread.start()", "label": 1}
{"code": "func (ww *WidgetWatchers) PostEventWidgetMove(w Widget) {\n\tev := &EventWidgetMove{}\n\tev.SetWidget(w)\n\tev.SetEventNow()\n\tww.PostEvent(ev)\n}", "label": 5}
{"code": "def validate_day_lock(time, start_time)\n      days_in_month = TimeUtil.days_in_month(time)\n      date = Date.new(time.year, time.month, time.day)\n\n      if value && value < 0\n        start = TimeUtil.day_of_month(value, date)\n        month_overflow = days_in_month - TimeUtil.days_in_next_month(time)\n      elsif value && value > 0\n        start = value\n        month_overflow = 0\n      else\n        start = TimeUtil.day_of_month(start_time.day, date)\n        month_overflow = 0\n      end\n\n      sleeps = start - date.day\n\n      if value && value > 0\n        until_next_month = days_in_month + sleeps\n      else\n        until_next_month = start < 28 ? days_in_month : TimeUtil.days_to_next_month(date)\n        until_next_month += sleeps - month_overflow\n      end\n\n      sleeps >= 0 ? sleeps : until_next_month\n    end", "label": 4}
{"code": "def filter(self, field_name, field_value):\n        \"\"\"Add permanent filter on the collection\n\n        :param field_name: name of the field to filter on\n        :type field_name: str\n        :param field_value: value to filter on\n\n        :rtype: Collection\n        \"\"\"\n        self.filters.append((field_name, field_value))\n        return self", "label": 1}
{"code": "def track(name, properties = {}, options = {})\n      if exclude?\n        debug \"Event excluded\"\n      elsif missing_params?\n        debug \"Missing required parameters\"\n      else\n        data = {\n          visit_token: visit_token,\n          user_id: user.try(:id),\n          name: name.to_s,\n          properties: properties,\n          time: trusted_time(options[:time]),\n          event_id: options[:id] || generate_id\n        }.select { |_, v| v }\n\n        @store.track_event(data)\n      end\n      true\n    rescue => e\n      report_exception(e)\n    end", "label": 4}
{"code": "def get_file_location(self, volume_id):\n        \"\"\"\n        Get location for the file,\n        WeedFS volume is choosed randomly\n\n        :param integer volume_id: volume_id\n        :rtype: namedtuple `FileLocation` `{\"public_url\":\"\", \"url\":\"\"}`\n        \"\"\"\n        url = (\"http://{master_addr}:{master_port}/\"\n               \"dir/lookup?volumeId={volume_id}\").format(\n            master_addr=self.master_addr,\n            master_port=self.master_port,\n            volume_id=volume_id)\n        data = json.loads(self.conn.get_data(url))\n        _file_location = random.choice(data['locations'])\n        FileLocation = namedtuple('FileLocation', \"public_url url\")\n        return FileLocation(_file_location['publicUrl'], _file_location['url'])", "label": 1}
{"code": "public static authenticationradiuspolicy_vpnvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationradiuspolicy_vpnvserver_binding obj = new authenticationradiuspolicy_vpnvserver_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationradiuspolicy_vpnvserver_binding response[] = (authenticationradiuspolicy_vpnvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function shutdown()\n    {\n        foreach ($this->items as $idNum => $items) {\n            if (count($items) !== 0) {\n                $this->flush($idNum);\n            }\n        }\n    }", "label": 2}
{"code": "public static rnatparam get(nitro_service service) throws Exception{\n\t\trnatparam obj = new rnatparam();\n\t\trnatparam[] response = (rnatparam[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def list_databases(self):\n        \"\"\"\n        Runs the ``\\\\list`` command and returns a list of column values with\n        information about all databases.\n        \"\"\"\n        lines = output_lines(self.exec_psql('\\\\list'))\n        return [line.split('|') for line in lines]", "label": 1}
{"code": "def all_commands\n      commands = @command_class.all_commands.reject do |k,v|\n        v.is_a?(Thor::HiddenCommand)\n      end\n      commands.keys\n    end", "label": 4}
{"code": "function checkIdentifier(str, context) {\n    if (!/^[a-zA-Z_][a-zA-Z_0-9]*$/.test(str)) {\n        throw new ImplementationError(`Invalid identifier \"${str}\"${context.errorContext}`);\n    }\n    return str;\n}", "label": 3}
{"code": "def changes\n      _changes = {}\n      changed.each do |attr|\n        change = attribute_change(attr)\n        _changes[attr] = change if change\n      end\n      _changes.with_indifferent_access\n    end", "label": 4}
{"code": "func (p *PortAllocator) ReleaseAll() error {\n\tp.mutex.Lock()\n\tp.ipMap = ipMapping{}\n\tp.mutex.Unlock()\n\treturn nil\n}", "label": 5}
{"code": "func OptionNetworkControlPlaneMTU(exp int) Option {\n\treturn func(c *Config) {\n\t\tlogrus.Debugf(\"Network Control Plane MTU: %d\", exp)\n\t\tif exp < warningThNetworkControlPlaneMTU {\n\t\t\tlogrus.Warnf(\"Received a MTU of %d, this value is very low, the network control plane can misbehave,\"+\n\t\t\t\t\" defaulting to minimum value (%d)\", exp, minimumNetworkControlPlaneMTU)\n\t\t\tif exp < minimumNetworkControlPlaneMTU {\n\t\t\t\texp = minimumNetworkControlPlaneMTU\n\t\t\t}\n\t\t}\n\t\tc.Daemon.NetworkControlPlaneMTU = exp\n\t}\n}", "label": 5}
{"code": "protected function unionAllRelationQueries(Collection $relations): EloquentBuilder\n    {\n        return $relations\n            ->reduce(\n                function (EloquentBuilder $builder, Relation $relation) {\n                    return $builder->unionAll(\n                        $relation->getQuery()\n                    );\n                },\n                // Use the first query as the initial starting point\n                $relations->shift()->getQuery()\n            );\n    }", "label": 2}
{"code": "def parse_masked(seq, min_len):\n    \"\"\"\n    parse masked sequence into non-masked and masked regions\n    \"\"\"\n    nm, masked = [], [[]]\n    prev = None\n    for base in seq[1]:\n        if base.isupper():\n            nm.append(base)\n            if masked != [[]] and len(masked[-1]) < min_len:\n                nm.extend(masked[-1])\n                del masked[-1]\n            prev = False\n        elif base.islower():\n            if prev is False:\n                masked.append([])\n            masked[-1].append(base)\n            prev = True\n    return nm, masked", "label": 1}
{"code": "public function diffInHoursFiltered(Closure $callback, $date = null, $absolute = true)\n    {\n        return $this->diffFiltered(CarbonInterval::hour(), $callback, $date, $absolute);\n    }", "label": 2}
{"code": "function parseMongoConnectionOptions(req, res, next) {\n  var options = {};\n  options.uri = req.mongoUrl;\n\n  req.connectionOptions = options;\n\n  return next();\n}", "label": 3}
{"code": "public List<DbLicense> getArtifactLicenses(final String gavc, final FiltersHolder filters) {\n        final DbArtifact artifact = getArtifact(gavc);\n        final List<DbLicense> licenses = new ArrayList<>();\n\n        for(final String name: artifact.getLicenses()){\n            final Set<DbLicense> matchingLicenses = licenseMatcher.getMatchingLicenses(name);\n\n            // Here is a license to identify\n            if(matchingLicenses.isEmpty()){\n                final DbLicense notIdentifiedLicense = new DbLicense();\n                notIdentifiedLicense.setName(name);\n                licenses.add(notIdentifiedLicense);\n            } else {\n                matchingLicenses.stream()\n                        .filter(filters::shouldBeInReport)\n                        .forEach(licenses::add);\n            }\n        }\n\n        return licenses;\n    }", "label": 0}
{"code": "def include_required_submodules!\n      class_eval do\n        @sorcery_config.submodules = ::Sorcery::Controller::Config.submodules\n        @sorcery_config.submodules.each do |mod|\n          # TODO: Is there a cleaner way to handle missing submodules?\n          # rubocop:disable Lint/HandleExceptions\n          begin\n            include Submodules.const_get(mod.to_s.split('_').map(&:capitalize).join)\n          rescue NameError\n            # don't stop on a missing submodule. Needed because some submodules are only defined\n            # in the controller side.\n          end\n          # rubocop:enable Lint/HandleExceptions\n        end\n      end\n    end", "label": 4}
{"code": "function appendPropertyOrElementAccessForSymbol(symbol, writer) {\n                var symbolName = getNameOfSymbol(symbol);\n                var firstChar = symbolName.charCodeAt(0);\n                var needsElementAccess = !ts.isIdentifierStart(firstChar, languageVersion);\n                if (needsElementAccess) {\n                    writePunctuation(writer, 19 /* OpenBracketToken */);\n                    if (ts.isSingleOrDoubleQuote(firstChar)) {\n                        writer.writeStringLiteral(symbolName);\n                    }\n                    else {\n                        writer.writeSymbol(symbolName, symbol);\n                    }\n                    writePunctuation(writer, 20 /* CloseBracketToken */);\n                }\n                else {\n                    writePunctuation(writer, 21 /* DotToken */);\n                    writer.writeSymbol(symbolName, symbol);\n                }\n            }", "label": 3}
{"code": "def read\n      @store.transaction(true) do\n        @store.roots.each_with_object({}) do |key, obj|\n          obj[key] = @store[key]\n        end\n      end\n    end", "label": 4}
{"code": "public function setGatewayType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Iot\\V1\\GatewayType::class);\n        $this->gateway_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def removed_or_inserted_action(mapper, connection, target):\n    \"\"\"Remove the action from cache when an item is inserted or deleted.\"\"\"\n    current_access.delete_action_cache(get_action_cache_key(target.action,\n                                                            target.argument))", "label": 1}
{"code": "def add_validator(self, name, validator, *args, **kwargs):\n        \"\"\" Add the validator to the internal configuration dictionary.\n\n        :param name:\n            The field machine name to apply the validator on\n        :param validator:\n            The WTForms validator object\n        The rest are optional arguments and keyword arguments that\n        belong to the validator. We let them simply pass through\n        to be checked and bound later.\n        \"\"\"\n        if name in self._dyn_fields:\n            if 'validators' in self._dyn_fields[name]:\n                self._dyn_fields[name]['validators'].append(validator)\n                self._dyn_fields[name][validator.__name__] = {}\n                if args:\n                    self._dyn_fields[name][validator.__name__]['args'] = args\n                if kwargs:\n                    self._dyn_fields[name][validator.__name__]['kwargs'] = kwargs\n            else:\n                self._dyn_fields[name]['validators'] = []\n                self.add_validator(name, validator, *args, **kwargs)\n        else:\n            raise AttributeError('Field \"{0}\" does not exist. '\n                                 'Did you forget to add it?'.format(name))", "label": 1}
{"code": "public static Comparator getComparator()\r\n    {\r\n        return new Comparator()\r\n        {\r\n            public int compare(Object o1, Object o2)\r\n            {\r\n                FieldDescriptor fmd1 = (FieldDescriptor) o1;\r\n                FieldDescriptor fmd2 = (FieldDescriptor) o2;\r\n                if (fmd1.getColNo() < fmd2.getColNo())\r\n                {\r\n                    return -1;\r\n                }\r\n                else if (fmd1.getColNo() > fmd2.getColNo())\r\n                {\r\n                    return 1;\r\n                }\r\n                else\r\n                {\r\n                    return 0;\r\n                }\r\n            }\r\n        };\r\n    }", "label": 0}
{"code": "function takeWhile(f, xs) {\r\n    const ys = [];\r\n    for (const x of xs) {\r\n        if (f(x)) {\r\n            ys.push(x);\r\n        }\r\n        else {\r\n            break;\r\n        }\r\n    }\r\n    return ys;\r\n}", "label": 3}
{"code": "public static base_response add(nitro_service client, iptunnel resource) throws Exception {\n\t\tiptunnel addresource = new iptunnel();\n\t\taddresource.name = resource.name;\n\t\taddresource.remote = resource.remote;\n\t\taddresource.remotesubnetmask = resource.remotesubnetmask;\n\t\taddresource.local = resource.local;\n\t\taddresource.protocol = resource.protocol;\n\t\taddresource.ipsecprofilename = resource.ipsecprofilename;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function normalizeFgArgs(fgArgs) {\n  var program, args, cb;\n  var processArgsEnd = fgArgs.length;\n  var lastFgArg = fgArgs[fgArgs.length - 1];\n  if (typeof lastFgArg === \"function\") {\n    cb = lastFgArg;\n    processArgsEnd -= 1;\n  } else {\n    cb = function(done) { done(); };\n  }\n\n  if (Array.isArray(fgArgs[0])) {\n    program = fgArgs[0][0];\n    args = fgArgs[0].slice(1);\n  } else {\n    program = fgArgs[0];\n    args = Array.isArray(fgArgs[1]) ? fgArgs[1] : fgArgs.slice(1, processArgsEnd);\n  }\n\n  return {program: program, args: args, cb: cb};\n}", "label": 3}
{"code": "public static base_response change(nitro_service client, nsaptlicense resource) throws Exception {\n\t\tnsaptlicense updateresource = new nsaptlicense();\n\t\tupdateresource.id = resource.id;\n\t\tupdateresource.sessionid = resource.sessionid;\n\t\tupdateresource.bindtype = resource.bindtype;\n\t\tupdateresource.countavailable = resource.countavailable;\n\t\tupdateresource.licensedir = resource.licensedir;\n\t\treturn updateresource.perform_operation(client,\"update\");\n\t}", "label": 0}
{"code": "def to_python(self, value):\n        \"\"\"Normalize data to a list of floats.\"\"\"\n        if not value:\n            return []\n        return map(super(CommaSepFloatField, self).to_python, value.split(','))", "label": 1}
{"code": "def add_charset\n      if !body.empty?\n        # Only give a warning if this isn't an attachment, has non US-ASCII and the user\n        # has not specified an encoding explicitly.\n        if @defaulted_charset && !body.raw_source.ascii_only? && !self.attachment?\n          warning = \"Non US-ASCII detected and no charset defined.\\nDefaulting to UTF-8, set your own if this is incorrect.\\n\"\n          warn(warning)\n        end\n        header[:content_type].parameters['charset'] = @charset\n      end\n    end", "label": 4}
{"code": "def _count_pixels_on_line(self, y, p):\n        \"\"\"Count the number of pixels rendered on this line.\"\"\"\n        h = line(y, self._effective_thickness(p), 0.0)\n        return h.sum()", "label": 1}
{"code": "def correct_spelling(text_string):\n    '''\n    Splits string and converts words not found within a pre-built dictionary to their\n    most likely actual word based on a relative probability dictionary. Returns edited\n    string as type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a string or NoneType not be passed as an argument\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        word_list = text_string.split()\n        spellchecked_word_list = []\n        for word in word_list:\n            spellchecked_word_list.append(spellcheck.correct_word(word))\n        return \" \".join(spellchecked_word_list)\n    else:\n        raise InputError(\"none type or string not passed as an argument\")", "label": 1}
{"code": "public function rows(array $options = [])\n    {\n        $options += $this->queryResultsOptions;\n        $this->waitUntilComplete($options);\n        $schema = $this->info['schema']['fields'];\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $row) use ($schema) {\n                    $mergedRow = [];\n\n                    if ($row === null) {\n                        return $mergedRow;\n                    }\n\n                    if (!array_key_exists('f', $row)) {\n                        throw new GoogleException('Bad response - missing key \"f\" for a row.');\n                    }\n\n                    foreach ($row['f'] as $key => $value) {\n                        $fieldSchema = $schema[$key];\n                        $mergedRow[$fieldSchema['name']] = $this->mapper->fromBigQuery($value, $fieldSchema);\n                    }\n\n                    return $mergedRow;\n                },\n                [$this->connection, 'getQueryResults'],\n                $options + $this->identity,\n                [\n                    'itemsKey' => 'rows',\n                    'firstPage' => $this->info,\n                    'nextResultTokenKey' => 'pageToken'\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "public function user($user)\n    {\n        $this->user = $user;\n\n        $this->content = array_merge($this->content, [\n            'user' => [\n                'id' => $user->getAuthIdentifier(),\n                'name' => $user->name ?? null,\n                'email' => $user->email ?? null,\n            ],\n        ]);\n\n        $this->tags(['Auth:'.$user->getAuthIdentifier()]);\n\n        return $this;\n    }", "label": 2}
{"code": "def contains(self, other):\n        \"\"\"\n        Is the other VariantSequence a subsequence of this one?\n\n        The two sequences must agree on the alt nucleotides, the prefix of the\n        longer must contain the prefix of the shorter, and the suffix of the\n        longer must contain the suffix of the shorter.\n        \"\"\"\n        return (self.alt == other.alt and\n                self.prefix.endswith(other.prefix) and\n                self.suffix.startswith(other.suffix))", "label": 1}
{"code": "function t(time, done) {\n  if (arguments.length === 1) {\n    done = time;\n    time = 2000;\n  }\n  var error = new Error(`Callback took too long (max: ${time})`);\n  var waiting = true;\n\n  var timeout = setTimeout(function () {\n    if (!waiting) return;\n    waiting = false;\n    done(error);\n  }, time);\n\n  function handler() {\n    if (!waiting) return;\n    clearTimeout(timeout);\n    waiting = false;\n    done.apply(this, arguments);\n  }\n\n  return handler;\n}", "label": 3}
{"code": "public function close()\n    {\n        if ($this->session) {\n            if ($this->sessionPool) {\n                $this->sessionPool->release($this->session);\n            } else {\n                $this->session->delete();\n            }\n\n            $this->session = null;\n        }\n    }", "label": 2}
{"code": "public function setProductSearchResults($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\ProductSearchResults::class);\n        $this->product_search_results = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function newWithCreateTerm($term): self\n    {\n        $newTerm = Term::firstOrCreate($term);\n        $this->term_id = $newTerm->id;\n        $this->term()->associate($newTerm);\n        $this->setTaxonomy();\n\n        return $this;\n    }", "label": 2}
{"code": "def in_frame(identifier, frame=nil, &block)\n      frame = frame.nil? ? [] : frame.dup\n      frame << {frame: identifier}\n      block.call(frame)\n    end", "label": 4}
{"code": "public static base_responses delete(nitro_service client, dnsaddrec resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdnsaddrec deleteresources[] = new dnsaddrec[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tdeleteresources[i] = new dnsaddrec();\n\t\t\t\tdeleteresources[i].hostname = resources[i].hostname;\n\t\t\t\tdeleteresources[i].ipaddress = resources[i].ipaddress;\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function (stream, close) {\n                this._stream = stream;\n                if (typeof close === \"function\") {\n                    this._close = close;\n                }\n                stream.on(\"error\", this._onError.bind(this));\n            }", "label": 3}
{"code": "function equalOwnProperties(left, right, equalityComparer) {\n        if (left === right)\n            return true;\n        if (!left || !right)\n            return false;\n        for (var key in left)\n            if (hasOwnProperty.call(left, key)) {\n                if (!hasOwnProperty.call(right, key) === undefined)\n                    return false;\n                if (equalityComparer ? !equalityComparer(left[key], right[key]) : left[key] !== right[key])\n                    return false;\n            }\n        for (var key in right)\n            if (hasOwnProperty.call(right, key)) {\n                if (!hasOwnProperty.call(left, key))\n                    return false;\n            }\n        return true;\n    }", "label": 3}
{"code": "void merge(Archetype flatParent, Archetype specialized) {\n        expandAttributeNodes(specialized.getDefinition());\n\n        flattenCObject(RmPath.ROOT, null, flatParent.getDefinition(), specialized.getDefinition());\n\n\n        mergeOntologies(flatParent.getTerminology(), specialized.getTerminology());\n        if (flatParent.getAnnotations() != null) {\n            if (specialized.getAnnotations() == null) {\n                specialized.setAnnotations(new ResourceAnnotations());\n            }\n            annotationsMerger.merge(flatParent.getAnnotations().getItems(), specialized.getAnnotations().getItems());\n        }\n    }", "label": 0}
{"code": "func (f *file) lintReceiverNames() {\n\ttypeReceiver := map[string]string{}\n\tf.walk(func(n ast.Node) bool {\n\t\tfn, ok := n.(*ast.FuncDecl)\n\t\tif !ok || fn.Recv == nil || len(fn.Recv.List) == 0 {\n\t\t\treturn true\n\t\t}\n\t\tnames := fn.Recv.List[0].Names\n\t\tif len(names) < 1 {\n\t\t\treturn true\n\t\t}\n\t\tname := names[0].Name\n\t\tconst ref = styleGuideBase + \"#receiver-names\"\n\t\tif name == \"_\" {\n\t\t\tf.errorf(n, 1, link(ref), category(\"naming\"), `receiver name should not be an underscore, omit the name if it is unused`)\n\t\t\treturn true\n\t\t}\n\t\tif name == \"this\" || name == \"self\" {\n\t\t\tf.errorf(n, 1, link(ref), category(\"naming\"), `receiver name should be a reflection of its identity; don't use generic names such as \"this\" or \"self\"`)\n\t\t\treturn true\n\t\t}\n\t\trecv := receiverType(fn)\n\t\tif prev, ok := typeReceiver[recv]; ok && prev != name {\n\t\t\tf.errorf(n, 1, link(ref), category(\"naming\"), \"receiver name %s should be consistent with previous receiver name %s for %s\", name, prev, recv)\n\t\t\treturn true\n\t\t}\n\t\ttypeReceiver[recv] = name\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "function _gpfHttpMockRemove (id) {\n    var method = id.substring(_GPF_START, id.indexOf(\".\"));\n    _gpfHttpMockedRequests[method] = _gpfHttpMockGetMockedRequests(method).filter(function (mockedRequest) {\n        return mockedRequest.id !== id;\n    });\n}", "label": 3}
{"code": "func ExpectConnectionProblem(c *check.C, err error) {\n\tc.Assert(trace.IsConnectionProblem(err), check.Equals, true, check.Commentf(\"expected ConnectionProblem, got %T %v at %v\", trace.Unwrap(err), err, string(debug.Stack())))\n}", "label": 5}
{"code": "public function run_command( $args, $assoc_args = array(), $options = array() ) {\n\t\tWP_CLI::do_hook( 'before_run_command' );\n\n\t\tif ( ! empty( $options['back_compat_conversions'] ) ) {\n\t\t\tlist( $args, $assoc_args ) = self::back_compat_conversions( $args, $assoc_args );\n\t\t}\n\t\t$r = $this->find_command_to_run( $args );\n\t\tif ( is_string( $r ) ) {\n\t\t\tWP_CLI::error( $r );\n\t\t}\n\n\t\tlist( $command, $final_args, $cmd_path ) = $r;\n\n\t\t$name = implode( ' ', $cmd_path );\n\n\t\t$extra_args = array();\n\n\t\tif ( isset( $this->extra_config[ $name ] ) ) {\n\t\t\t$extra_args = $this->extra_config[ $name ];\n\t\t}\n\n\t\tWP_CLI::debug( 'Running command: ' . $name, 'bootstrap' );\n\t\ttry {\n\t\t\t$command->invoke( $final_args, $assoc_args, $extra_args );\n\t\t} catch ( WP_CLI\\Iterators\\Exception $e ) {\n\t\t\tWP_CLI::error( $e->getMessage() );\n\t\t}\n\t}", "label": 2}
{"code": "public Authentication getAuthentication(String token) {\n\t\tif (null != token) {\n\t\t\tTokenContainer container = tokens.get(token);\n\t\t\tif (null != container) {\n\t\t\t\tif (container.isValid()) {\n\t\t\t\t\treturn container.getAuthentication();\n\t\t\t\t} else {\n\t\t\t\t\tlogout(token);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "protected function status()\n    {\n        if (! config('telescope.enabled', false)) {\n            return 'disabled';\n        }\n\n        if (cache('telescope:pause-recording', false)) {\n            return 'paused';\n        }\n\n        $watcher = config('telescope.watchers.'.$this->watcher());\n\n        if (! $watcher || (isset($watcher['enabled']) && ! $watcher['enabled'])) {\n            return 'off';\n        }\n\n        return 'enabled';\n    }", "label": 2}
{"code": "def count_lines_in_file(src_file ):\n    \"\"\"\n    test function.\n    \"\"\"\n    tot = 0\n    res = ''\n    try:\n        with open(src_file, 'r') as f:\n            for line in f:\n                tot += 1\n            res = str(tot) + ' recs read'       \n    except:\n        res = 'ERROR -couldnt open file'\n    return res", "label": 1}
{"code": "func (a *Allocator) getAddrSpace(as string) (*addrSpace, error) {\n\ta.Lock()\n\tdefer a.Unlock()\n\taSpace, ok := a.addrSpaces[as]\n\tif !ok {\n\t\treturn nil, types.BadRequestErrorf(\"cannot find address space %s (most likely the backing datastore is not configured)\", as)\n\t}\n\treturn aSpace, nil\n}", "label": 5}
{"code": "private void appendBetweenCriteria(TableAlias alias, PathInfo pathInfo, BetweenCriteria c, StringBuffer buf)\r\n    {\r\n        appendColName(alias, pathInfo, c.isTranslateAttribute(), buf);\r\n        buf.append(c.getClause());\r\n        appendParameter(c.getValue(), buf);\r\n        buf.append(\" AND \");\r\n        appendParameter(c.getValue2(), buf);\r\n    }", "label": 0}
{"code": "func (sm *Manager) SessionIsActive(ctx context.Context) (bool, error) {\n\tif sm.userSession == nil {\n\t\treturn false, nil\n\t}\n\n\treq := types.SessionIsActive{\n\t\tThis:      sm.Reference(),\n\t\tSessionID: sm.userSession.Key,\n\t\tUserName:  sm.userSession.UserName,\n\t}\n\n\tactive, err := methods.SessionIsActive(ctx, sm.client, &req)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn active.Returnval, err\n}", "label": 5}
{"code": "def add_file(values)\n      convert_to_multipart unless self.multipart? || Utilities.blank?(self.body.decoded)\n      add_multipart_mixed_header\n      if values.is_a?(String)\n        basename = File.basename(values)\n        filedata = File.open(values, 'rb') { |f| f.read }\n      else\n        basename = values[:filename]\n        filedata = values\n      end\n      self.attachments[basename] = filedata\n    end", "label": 4}
{"code": "public static Chart getMSDLineWithConfinedModelChart(Trajectory t, int lagMin,\n\t\t\tint lagMax, double timelag, double a, double b, double c, double d) {\n\n\t\tdouble[] xData = new double[lagMax - lagMin + 1];\n\t\tdouble[] yData = new double[lagMax - lagMin + 1];\n\t\tdouble[] modelData = new double[lagMax - lagMin + 1];\n\t\tMeanSquaredDisplacmentFeature msdeval = new MeanSquaredDisplacmentFeature(\n\t\t\t\tt, lagMin);\n\t\tmsdeval.setTrajectory(t);\n\t\tmsdeval.setTimelag(lagMin);\n\t\tfor (int i = lagMin; i < lagMax + 1; i++) {\n\t\t\tmsdeval.setTimelag(i);\n\t\t\tdouble msdhelp = msdeval.evaluate()[0];\n\t\t\txData[i - lagMin] = i;\n\t\t\tyData[i - lagMin] = msdhelp;\n\t\t\tmodelData[i - lagMin] = a\n\t\t\t\t\t* (1 - b * Math.exp((-4 * d) * ((i * timelag) / a) * c));\n\t\t}\n\n\t\t// Create Chart\n\t\tChart chart = QuickChart.getChart(\"MSD Line\", \"LAG\", \"MSD\", \"MSD\",\n\t\t\t\txData, yData);\n\t\tif(Math.abs(1-b)<0.00001 && Math.abs(1-a)<0.00001){\n\t\t\tchart.addSeries(\"y=a*(1-exp(-4*D*t/a))\", xData, modelData);\n\t\t}else{\n\t\t\tchart.addSeries(\"y=a*(1-b*exp(-4*c*D*t/a))\", xData, modelData);\n\t\t}\n\n\t\t// Show it\n\t\t//new SwingWrapper(chart).displayChart();\n\t\treturn chart;\n\t}", "label": 0}
{"code": "public <T> T getSPI(Class<T> spiType)\n   {\n      return getSPI(spiType, SecurityActions.getContextClassLoader());\n   }", "label": 0}
{"code": "public function resolve(array $args, HandlerList $list)\n    {\n        $args['config'] = [];\n        foreach ($this->argDefinitions as $key => $a) {\n            // Add defaults, validate required values, and skip if not set.\n            if (!isset($args[$key])) {\n                if (isset($a['default'])) {\n                    // Merge defaults in when not present.\n                    if (is_callable($a['default'])\n                        && (\n                            is_array($a['default'])\n                            || $a['default'] instanceof \\Closure\n                        )\n                    ) {\n                        $args[$key] = $a['default']($args);\n                    } else {\n                        $args[$key] = $a['default'];\n                    }\n                } elseif (empty($a['required'])) {\n                    continue;\n                } else {\n                    $this->throwRequired($args);\n                }\n            }\n\n            // Validate the types against the provided value.\n            foreach ($a['valid'] as $check) {\n                if (isset(self::$typeMap[$check])) {\n                    $fn = self::$typeMap[$check];\n                    if ($fn($args[$key])) {\n                        goto is_valid;\n                    }\n                } elseif ($args[$key] instanceof $check) {\n                    goto is_valid;\n                }\n            }\n\n            $this->invalidType($key, $args[$key]);\n\n            // Apply the value\n            is_valid:\n            if (isset($a['fn'])) {\n                $a['fn']($args[$key], $args, $list);\n            }\n\n            if ($a['type'] === 'config') {\n                $args['config'][$key] = $args[$key];\n            }\n        }\n\n        return $args;\n    }", "label": 2}
{"code": "def show_gene_expression(self, gene, avg=True, axes=None, **kwargs):\n        \"\"\"Display a gene's expressions.\n\n        Displays a scatter plot using the SAM projection or another input\n        projection with a particular gene's expressions overlaid.\n\n        Parameters\n        ----------\n        gene - string\n            a case-sensitive string indicating the gene expression pattern\n            to display.\n\n        avg - bool, optional, default True\n            If True, the plots use the k-nearest-neighbor-averaged expression\n            values to smooth out noisy expression patterns and improves\n            visualization.\n\n        axes - matplotlib axis, optional, default None\n            Plot output to the specified, existing axes. If None, create new\n            figure window.\n\n        **kwargs - all keyword arguments in 'SAM.scatter' are eligible.\n\n        \"\"\"\n\n        all_gene_names = np.array(list(self.adata.var_names))\n        cell_names = np.array(list(self.adata.obs_names))\n        all_cell_names = np.array(list(self.adata_raw.obs_names))\n\n        idx = np.where(all_gene_names == gene)[0]\n        name = gene\n        if(idx.size == 0):\n            print(\n                \"Gene note found in the filtered dataset. Note that genes \"\n                \"are case sensitive.\")\n            return\n\n        if(avg):\n            a = self.adata.layers['X_knn_avg'][:, idx].toarray().flatten()\n\n            if a.sum() == 0:\n                a = np.log2(self.adata_raw.X[np.in1d(\n                    all_cell_names, cell_names), :][:,\n                                                idx].toarray().flatten() + 1)\n        else:\n            a = np.log2(self.adata_raw.X[np.in1d(\n                all_cell_names, cell_names), :][:,\n                                                idx].toarray().flatten() + 1)\n\n        if axes is None:\n            plt.figure()\n            axes = plt.gca()\n\n        self.scatter(c=a, axes=axes, **kwargs)\n        axes.set_title(name)", "label": 1}
{"code": "public static appfwpolicylabel_policybinding_binding[] get(nitro_service service, String labelname) throws Exception{\n\t\tappfwpolicylabel_policybinding_binding obj = new appfwpolicylabel_policybinding_binding();\n\t\tobj.set_labelname(labelname);\n\t\tappfwpolicylabel_policybinding_binding response[] = (appfwpolicylabel_policybinding_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function deps(s, p) {\n        if (!shards.map[p] || !shards.map[p].ParentShardId) return;\n        shards.deps[s] = lib.toFlags(\"add\", shards.deps[s], shards.map[p].ParentShardId);\n        deps(s, shards.map[p].ParentShardId);\n    }", "label": 3}
{"code": "def process_message(message, notification):\n    \"\"\"\n    Function to process a JSON message delivered from Amazon\n    \"\"\"\n    # Confirm that there are 'notificationType' and 'mail' fields in our\n    # message\n    if not set(VITAL_MESSAGE_FIELDS) <= set(message):\n        # At this point we're sure that it's Amazon sending the message\n        # If we don't return a 200 status code, Amazon will attempt to send us\n        # this same message a few seconds later.\n        logger.info('JSON Message Missing Vital Fields')\n        return HttpResponse('Missing Vital Fields')\n\n    if message['notificationType'] == 'Complaint':\n        return process_complaint(message, notification)\n    if message['notificationType'] == 'Bounce':\n        return process_bounce(message, notification)\n    if message['notificationType'] == 'Delivery':\n        return process_delivery(message, notification)\n    else:\n        return HttpResponse('Unknown Notification Type')", "label": 1}
{"code": "function importTheme(req, res, next) {\n  req.appformsResultPayload = req.appformsResultPayload || {};\n  var themeData = (req.appformsResultPayload.data && req.appformsResultPayload.type === constants.resultTypes.themeTemplate) ? req.appformsResultPayload.data : undefined ;\n\n  var importThemeParams = {\n    theme: themeData,\n    name: req.body.name,\n    description: req.body.description,\n    userEmail: req.user.email\n  };\n\n  forms.cloneTheme(_.extend(req.connectionOptions, importThemeParams), resultHandler(constants.resultTypes.themes, req, next));\n}", "label": 3}
{"code": "def post(self, query_continue=None, upload_file=None, auth=None,\n             continuation=False, **params):\n        \"\"\"Makes an API request with the POST method\n\n        :Parameters:\n            query_continue : `dict`\n                Optionally, the value of a query continuation 'continue' field.\n            upload_file : `bytes`\n                The bytes of a file to upload.\n            auth : mixed\n                Auth tuple or callable to enable Basic/Digest/Custom HTTP Auth.\n            continuation : `bool`\n                If true, a continuation will be attempted and a generator of\n                JSON response documents will be returned.\n            params :\n                Keyword parameters to be sent in the POST message body.\n\n        :Returns:\n            A response JSON documents (or a generator of documents if\n            `continuation == True`)\n\n        :Raises:\n            :class:`mwapi.errors.APIError` : if the API responds with an error\n        \"\"\"\n        if upload_file is not None:\n            files = {'file': upload_file}\n        else:\n            files = None\n\n        return self.request('POST', params=params, auth=auth,\n                            query_continue=query_continue, files=files,\n                            continuation=continuation)", "label": 1}
{"code": "function (name) {\n            var dependencies = this.byName(name).getDependencies(),\n                names = this.getNames(),\n                minIndex = 1; // 0 being boot\n            dependencies.forEach(function (dependencyName) {\n                var index = names.indexOf(dependencyName);\n                ++index;\n                if (index > minIndex) {\n                    minIndex = index;\n                }\n            });\n            return minIndex;\n        }", "label": 3}
{"code": "def process(action, *args)\n      @_action_name = action.to_s\n\n      unless action_name = _find_action_name(@_action_name)\n        raise ActionNotFound, \"The action '#{action}' could not be found for #{self.class.name}\"\n      end\n\n      @_response_body = nil\n\n      process_action(action_name, *args)\n    end", "label": 4}
{"code": "public long removeRangeByScore(final ScoreRange scoreRange) {\n        return doWithJedis(new JedisCallable<Long>() {\n            @Override\n            public Long call(Jedis jedis) {\n                return jedis.zremrangeByScore(getKey(), scoreRange.from(), scoreRange.to());\n            }\n        });\n    }", "label": 0}
{"code": "func (t *TeleportStaticTokensMarshaler) Marshal(c StaticTokens, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch resource := c.(type) {\n\tcase *StaticTokensV2:\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *resource\n\t\t\tcopy.SetResourceID(0)\n\t\t\tresource = &copy\n\t\t}\n\t\treturn utils.FastMarshal(resource)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"unrecognized resource version %T\", c)\n\t}\n}", "label": 5}
{"code": "public static base_responses add(nitro_service client, route resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\troute addresources[] = new route[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new route();\n\t\t\t\taddresources[i].network = resources[i].network;\n\t\t\t\taddresources[i].netmask = resources[i].netmask;\n\t\t\t\taddresources[i].gateway = resources[i].gateway;\n\t\t\t\taddresources[i].cost = resources[i].cost;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t\taddresources[i].distance = resources[i].distance;\n\t\t\t\taddresources[i].cost1 = resources[i].cost1;\n\t\t\t\taddresources[i].weight = resources[i].weight;\n\t\t\t\taddresources[i].advertise = resources[i].advertise;\n\t\t\t\taddresources[i].protocol = resources[i].protocol;\n\t\t\t\taddresources[i].msr = resources[i].msr;\n\t\t\t\taddresources[i].monitor = resources[i].monitor;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (s *Server) SetattrV2(p *Packet) (interface{}, error) {\n\tres := &ReplySetattrV2{}\n\n\treq := new(RequestSetattrV2)\n\terr := UnmarshalBinary(p.Payload, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tname := req.FileName.Path()\n\n\t_, err = os.Stat(name)\n\tif err != nil && os.IsNotExist(err) {\n\t\t// assuming this is a virtual file\n\t\treturn res, nil\n\t}\n\n\tuid := -1\n\tif req.Attr.Mask&AttrValidUserID == AttrValidUserID {\n\t\tuid = int(req.Attr.UserID)\n\t}\n\n\tgid := -1\n\tif req.Attr.Mask&AttrValidGroupID == AttrValidGroupID {\n\t\tgid = int(req.Attr.GroupID)\n\t}\n\n\terr = s.chown(name, uid, gid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar perm os.FileMode\n\n\tif req.Attr.Mask&AttrValidOwnerPerms == AttrValidOwnerPerms {\n\t\tperm |= os.FileMode(req.Attr.OwnerPerms) << 6\n\t}\n\n\tif req.Attr.Mask&AttrValidGroupPerms == AttrValidGroupPerms {\n\t\tperm |= os.FileMode(req.Attr.GroupPerms) << 3\n\t}\n\n\tif req.Attr.Mask&AttrValidOtherPerms == AttrValidOtherPerms {\n\t\tperm |= os.FileMode(req.Attr.OtherPerms)\n\t}\n\n\tif perm != 0 {\n\t\terr = s.chmod(name, perm)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public ResultSetAndStatement executeQuery(Query query, ClassDescriptor cld) throws PersistenceBrokerException\r\n    {\r\n        if (logger.isDebugEnabled())\r\n        {\r\n            logger.debug(\"executeQuery: \" + query);\r\n        }\r\n        /*\r\n\t\t * MBAIRD: we should create a scrollable resultset if the start at\r\n\t\t * index or end at index is set\r\n\t\t */\r\n        boolean scrollable = ((query.getStartAtIndex() > Query.NO_START_AT_INDEX) || (query.getEndAtIndex() > Query.NO_END_AT_INDEX));\r\n        /*\r\n\t\t * OR if the prefetching of relationships is being used.\r\n\t\t */\r\n        if (query != null && query.getPrefetchedRelationships() != null && !query.getPrefetchedRelationships().isEmpty())\r\n        {\r\n            scrollable = true;\r\n        }\r\n        final StatementManagerIF sm = broker.serviceStatementManager();\r\n        final SelectStatement sql = broker.serviceSqlGenerator().getPreparedSelectStatement(query, cld);\r\n        PreparedStatement stmt = null;\r\n        ResultSet rs = null;\r\n        try\r\n        {\r\n            final int queryFetchSize = query.getFetchSize();\r\n            final boolean isStoredProcedure = isStoredProcedure(sql.getStatement());\r\n            stmt = sm.getPreparedStatement(cld, sql.getStatement() ,\r\n                    scrollable, queryFetchSize, isStoredProcedure);\r\n            if (isStoredProcedure)\r\n            {\r\n                // Query implemented as a stored procedure, which must return a result set.\r\n                // Query sytax is: { ?= call PROCEDURE_NAME(?,...,?)}\r\n                getPlatform().registerOutResultSet((CallableStatement) stmt, 1);\r\n                sm.bindStatement(stmt, query, cld, 2);\r\n\r\n                if (logger.isDebugEnabled())\r\n                    logger.debug(\"executeQuery: \" + stmt);\r\n\r\n                stmt.execute();\r\n                rs = (ResultSet) ((CallableStatement) stmt).getObject(1);\r\n            }\r\n            else\r\n            {\r\n                sm.bindStatement(stmt, query, cld, 1);\r\n\r\n                if (logger.isDebugEnabled())\r\n                    logger.debug(\"executeQuery: \" + stmt);\r\n\r\n                rs = stmt.executeQuery();\r\n            }\r\n\r\n            return new ResultSetAndStatement(sm, stmt, rs, sql);\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            // release resources on exception\r\n            sm.closeResources(stmt, rs);\r\n            logger.error(\"PersistenceBrokerException during the execution of the query: \" + e.getMessage(), e);\r\n            throw e;\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            // release resources on exception\r\n            sm.closeResources(stmt, rs);\r\n            throw ExceptionHelper.generateException(e, sql.getStatement(), null, logger, null);\r\n        }\r\n    }", "label": 0}
{"code": "function Connection (options, clientOptions, label) {\n        this.options = options;\n        this.clientOptions = clientOptions;\n        this.label = label;\n        this.initialConnection = false;\n        this.initialConnectionRetries = 0;\n        this.maxConnectionRetries = 60;\n\n        Object.defineProperty(this, 'exchanges', {\n            get: function () {\n                if (this.connection) {\n                    return this.connection.exchanges;\n                }\n            }\n        });\n\n        Object.defineProperty(this, 'connected', {\n            get: function () {\n                return this.connection !== undefined;\n            }\n        });\n    }", "label": 3}
{"code": "private static String wordShapeDan2Bio(String s, Collection<String> knownLCWords) {\r\n    if (containsGreekLetter(s)) {\r\n      return wordShapeDan2(s, knownLCWords) + \"-GREEK\";\r\n    } else {\r\n      return wordShapeDan2(s, knownLCWords);\r\n    }\r\n  }", "label": 0}
{"code": "func (sl *DiskSessionLogger) PostSessionSlice(slice SessionSlice) error {\n\tsl.Lock()\n\tdefer sl.Unlock()\n\n\tfor i := range slice.Chunks {\n\t\t_, err := sl.writeChunk(slice.SessionID, slice.Chunks[i])\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\treturn sl.flush()\n}", "label": 5}
{"code": "function importForms(connections, params, callback) {\n  params = params || {};\n\n  logger.debug(\"Importing Forms \", params);\n\n  //Validating\n  var paramsValidator = validate(params);\n  var failed = paramsValidator.has(ZIP_FILE_PATH, WORKING_DIR);\n\n  if (failed) {\n    return callback(\"Validation Failed \" + (failed[ZIP_FILE_PATH] || failed[WORKING_DIR]));\n  }\n\n  //Random directory name.\n  var newDirectoryName = (new mongoose.Types.ObjectId()).toString();\n  var unzipDirectoryPath = path.join(params.workingDir, \"/\", newDirectoryName);\n\n  async.waterfall([\n    function checkFiles(cb) {\n      async.parallel([\n        async.apply(checkWorkingDir, params.workingDir),\n        async.apply(checkZipFile, params.zipFilePath)\n      ], function(err) {\n        //Not interested in passing any of the results from the aync.parallel to the waterfall callback\n        cb(err);\n      });\n    },\n    function createUniqueDirToUnzipTo(cb) {\n      //Need to create a new directory\n      mkdirp(unzipDirectoryPath, function(err) {\n        return cb(err);\n      });\n    },\n    async.apply(unzipFile, {\n      zipFilePath: params.zipFilePath,\n      workingDir: unzipDirectoryPath,\n      queueConcurrency: 5\n    }),\n    function validateInput(cb) {\n      inputValidator(unzipDirectoryPath, true, cb);\n    },\n    async.apply(importFromDir, connections, unzipDirectoryPath)\n  ], function(err, importedForms) {\n    if (err) {\n      logger.error(\"Error Importing Forms \", err);\n    }\n\n    //we always need to cleanup\n    cleanupFiles(unzipDirectoryPath, params.zipFilePath);\n    return callback(err, importedForms);\n  });\n}", "label": 3}
{"code": "def _oneInteraction(self):\n        \"\"\" Does one interaction between the task and the agent.\n        \"\"\"\n        if self.doOptimization:\n            raise Exception('When using a black-box learning algorithm, only full episodes can be done.')\n        else:\n            self.stepid += 1\n            self.agent.integrateObservation(self.task.getObservation())\n            self.task.performAction(self.agent.getAction())\n\n            # Save the cumulative sum of set-points for each period.\n            for i, g in enumerate(self.task.env.case.online_generators):\n                self.Pg[i, self.stepid - 1] = self.Pg[i, self.stepid - 1] + g.p\n\n            reward = self.task.getReward()\n            self.agent.giveReward(reward)\n            return reward", "label": 1}
{"code": "function getTypeForVariableLikeDeclaration(declaration, includeOptionality) {\n            if (declaration.flags & 134217728 /* JavaScriptFile */) {\n                // If this is a variable in a JavaScript file, then use the JSDoc type (if it has\n                // one as its type), otherwise fallback to the below standard TS codepaths to\n                // try to figure it out.\n                var type = getTypeForVariableLikeDeclarationFromJSDocComment(declaration);\n                if (type && type !== unknownType) {\n                    return type;\n                }\n            }\n            // A variable declared in a for..in statement is always of type string\n            if (declaration.parent.parent.kind === 207 /* ForInStatement */) {\n                return stringType;\n            }\n            if (declaration.parent.parent.kind === 208 /* ForOfStatement */) {\n                // checkRightHandSideOfForOf will return undefined if the for-of expression type was\n                // missing properties/signatures required to get its iteratedType (like\n                // [Symbol.iterator] or next). This may be because we accessed properties from anyType,\n                // or it may have led to an error inside getElementTypeOfIterable.\n                return checkRightHandSideOfForOf(declaration.parent.parent.expression) || anyType;\n            }\n            if (ts.isBindingPattern(declaration.parent)) {\n                return getTypeForBindingElement(declaration);\n            }\n            // Use type from type annotation if one is present\n            if (declaration.type) {\n                return addOptionality(getTypeFromTypeNode(declaration.type), /*optional*/ declaration.questionToken && includeOptionality);\n            }\n            if (declaration.kind === 142 /* Parameter */) {\n                var func = declaration.parent;\n                // For a parameter of a set accessor, use the type of the get accessor if one is present\n                if (func.kind === 150 /* SetAccessor */ && !ts.hasDynamicName(func)) {\n                    var getter = ts.getDeclarationOfKind(declaration.parent.symbol, 149 /* GetAccessor */);\n                    if (getter) {\n                        var getterSignature = getSignatureFromDeclaration(getter);\n                        var thisParameter = getAccessorThisParameter(func);\n                        if (thisParameter && declaration === thisParameter) {\n                            // Use the type from the *getter*\n                            ts.Debug.assert(!thisParameter.type);\n                            return getTypeOfSymbol(getterSignature.thisParameter);\n                        }\n                        return getReturnTypeOfSignature(getterSignature);\n                    }\n                }\n                // Use contextual parameter type if one is available\n                var type = void 0;\n                if (declaration.symbol.name === \"this\") {\n                    var thisParameter = getContextualThisParameter(func);\n                    type = thisParameter ? getTypeOfSymbol(thisParameter) : undefined;\n                }\n                else {\n                    type = getContextuallyTypedParameterType(declaration);\n                }\n                if (type) {\n                    return addOptionality(type, /*optional*/ declaration.questionToken && includeOptionality);\n                }\n            }\n            // Use the type of the initializer expression if one is present\n            if (declaration.initializer) {\n                return addOptionality(checkExpressionCached(declaration.initializer), /*optional*/ declaration.questionToken && includeOptionality);\n            }\n            // If it is a short-hand property assignment, use the type of the identifier\n            if (declaration.kind === 254 /* ShorthandPropertyAssignment */) {\n                return checkIdentifier(declaration.name);\n            }\n            // If the declaration specifies a binding pattern, use the type implied by the binding pattern\n            if (ts.isBindingPattern(declaration.name)) {\n                return getTypeFromBindingPattern(declaration.name, /*includePatternInType*/ false, /*reportErrors*/ true);\n            }\n            // No type specified and nothing can be inferred\n            return undefined;\n        }", "label": 3}
{"code": "public function iam()\n    {\n        if (!$this->iam) {\n            $iamConnection = new IamSubscription($this->connection);\n            $this->iam = new Iam($iamConnection, $this->name);\n        }\n\n        return $this->iam;\n    }", "label": 2}
{"code": "func (fs *FSLocalKeyStore) SaveCerts(proxy string, cas []auth.TrustedCerts) error {\n\tdir, err := fs.dirFor(proxy, true)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tfp, err := os.OpenFile(filepath.Join(dir, fileNameTLSCerts), os.O_CREATE|os.O_RDWR|os.O_TRUNC, 0640)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdefer fp.Sync()\n\tdefer fp.Close()\n\tfor _, ca := range cas {\n\t\tfor _, cert := range ca.TLSCertificates {\n\t\t\t_, err := fp.Write(cert)\n\t\t\tif err != nil {\n\t\t\t\treturn trace.ConvertSystemError(err)\n\t\t\t}\n\t\t\t_, err = fp.WriteString(\"\\n\")\n\t\t\tif err != nil {\n\t\t\t\treturn trace.ConvertSystemError(err)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "protected void addPropertiesStart(String type) {\n    putProperty(PropertyKey.Host.name(), IpUtils.getHostName());\n    putProperty(PropertyKey.Type.name(), type);\n    putProperty(PropertyKey.Status.name(), Status.Start.name());\n  }", "label": 0}
{"code": "function sync(str, options) {\n  var tmpl = this.cache(options) || this.cache(options, this.engine.compile(str, options));\n  return tmpl(options);\n}", "label": 3}
{"code": "function (fn) {\n                fn(this.chart.container, hasPointerEvent ? 'pointerdown' : 'MSPointerDown', this.onContainerPointerDown);\n                fn(this.chart.container, hasPointerEvent ? 'pointermove' : 'MSPointerMove', this.onContainerPointerMove);\n                fn(doc, hasPointerEvent ? 'pointerup' : 'MSPointerUp', this.onDocumentPointerUp);\n            }", "label": 3}
{"code": "def returns(self):\n        \"\"\"The return type for this method in a JSON-compatible format.\n\n        This handles the special case of ``None`` which allows ``type(None)`` also.\n\n        :rtype: str | None\n        \"\"\"\n        return_type = self.signature.return_type\n        none_type = type(None)\n        if return_type is not None and return_type is not none_type:\n            return return_type.__name__", "label": 1}
{"code": "func ParseHTTPFormOptions(r *http.Request) (bool, *JSONOutput) {\n\t_, unsafe := r.Form[\"unsafe\"]\n\tv, json := r.Form[\"json\"]\n\tvar pretty bool\n\tif len(v) > 0 {\n\t\tpretty = v[0] == \"pretty\"\n\t}\n\treturn unsafe, &JSONOutput{enable: json, prettyPrint: pretty}\n}", "label": 5}
{"code": "private void updateMaxMin(IntervalRBTreeNode<T> n, IntervalRBTreeNode<T> c) {\n    if (c != null) {\n      if (n.max < c.max) {\n        n.max = c.max;\n      }\n      if (n.min > c.min) {\n        n.min = c.min;\n      }\n    }\n  }", "label": 0}
{"code": "public function persist($entity)\n    {\n        if (! is_object($entity)) {\n            throw ORMInvalidArgumentException::invalidObject('EntityManager#persist()', $entity);\n        }\n\n        $this->errorIfClosed();\n\n        $this->unitOfWork->persist($entity);\n    }", "label": 2}
{"code": "private static String wordShapeChris4(String s, boolean omitIfInBoundary, Collection<String> knownLCWords) {\r\n    int len = s.length();\r\n    if (len <= BOUNDARY_SIZE * 2) {\r\n      return wordShapeChris4Short(s, len, knownLCWords);\r\n    } else {\r\n      return wordShapeChris4Long(s, omitIfInBoundary, len, knownLCWords);\r\n    }\r\n  }", "label": 0}
{"code": "def find(options = nil, &block)\n      options = validate_options(options)\n      \n      start do |pop3|\n        mails = pop3.mails\n        pop3.reset # Clears all \"deleted\" marks. This prevents non-explicit/accidental deletions due to server settings.\n        mails.sort! { |m1, m2| m2.number <=> m1.number } if options[:what] == :last\n        mails = mails.first(options[:count]) if options[:count].is_a? Integer\n        \n        if options[:what].to_sym == :last && options[:order].to_sym == :desc ||\n           options[:what].to_sym == :first && options[:order].to_sym == :asc ||\n          mails.reverse!\n        end\n        \n        if block_given?\n          mails.each do |mail|\n            new_message = Mail.new(mail.pop)\n            new_message.mark_for_delete = true if options[:delete_after_find]\n            yield new_message\n            mail.delete if options[:delete_after_find] && new_message.is_marked_for_delete? # Delete if still marked for delete\n          end\n        else\n          emails = []\n          mails.each do |mail|\n            emails << Mail.new(mail.pop)\n            mail.delete if options[:delete_after_find]\n          end\n          emails.size == 1 && options[:count] == 1 ? emails.first : emails\n        end\n        \n      end\n    end", "label": 4}
{"code": "def filter_rep_set(inF, otuSet):\n    \"\"\"\n    Parse the rep set file and remove all sequences not associated with unique\n    OTUs.\n\n    :@type inF: file\n    :@param inF: The representative sequence set\n\n    :@rtype: list\n    :@return: The set of sequences associated with unique OTUs\n    \"\"\"\n    seqs = []\n    for record in SeqIO.parse(inF, \"fasta\"):\n        if record.id in otuSet:\n            seqs.append(record)\n    return seqs", "label": 1}
{"code": "public function allocateIds(array $keys, array $options = [])\n    {\n        // Validate the given keys. First check types, then state of each.\n        // The API will throw a 400 if the key is named, but it's an easy\n        // check we can handle before going to the API to save a request.\n        // @todo replace with json schema\n        $this->validateBatch($keys, Key::class, function ($key) {\n            if ($key->state() !== Key::STATE_INCOMPLETE) {\n                throw new \\InvalidArgumentException(sprintf(\n                    'Given $key is in an invalid state. Can only allocate IDs for incomplete keys. ' .\n                    'Given path was %s',\n                    (string) $key\n                ));\n            }\n        });\n\n        $serviceKeys = [];\n        foreach ($keys as $key) {\n            $serviceKeys[] = $key->keyObject();\n        }\n\n        $res = $this->connection->allocateIds([\n            'projectId' => $this->projectId,\n            'keys' => $serviceKeys\n        ] + $options);\n\n        if (isset($res['keys'])) {\n            foreach ($res['keys'] as $index => $key) {\n                if (!isset($keys[$index])) {\n                    continue;\n                }\n\n                $end = end($key['path']);\n                $id = $end['id'];\n                $keys[$index]->setLastElementIdentifier($id);\n            }\n        }\n\n        return $keys;\n    }", "label": 2}
{"code": "public static <E> Set<E> retainNonZeros(Counter<E> counter) {\r\n    Set<E> removed = new HashSet<E>();\r\n    for (E key : counter.keySet()) {\r\n      if (counter.getCount(key) == 0.0) {\r\n        removed.add(key);\r\n      }\r\n    }\r\n    for (E key : removed) {\r\n      counter.remove(key);\r\n    }\r\n    return removed;\r\n  }", "label": 0}
{"code": "protected void printFeatures(IN wi, Collection<String> features) {\r\n    if (flags.printFeatures == null || writtenNum > flags.printFeaturesUpto) {\r\n      return;\r\n    }\r\n    try {\r\n      if (cliqueWriter == null) {\r\n        cliqueWriter = new PrintWriter(new FileOutputStream(\"feats\" + flags.printFeatures + \".txt\"), true);\r\n        writtenNum = 0;\r\n      }\r\n    } catch (Exception ioe) {\r\n      throw new RuntimeException(ioe);\r\n    }\r\n    if (writtenNum >= flags.printFeaturesUpto) {\r\n      return;\r\n    }\r\n    if (wi instanceof CoreLabel) {\r\n      cliqueWriter.print(wi.get(TextAnnotation.class) + ' ' + wi.get(PartOfSpeechAnnotation.class) + ' '\r\n          + wi.get(CoreAnnotations.GoldAnswerAnnotation.class) + '\\t');\r\n    } else {\r\n      cliqueWriter.print(wi.get(CoreAnnotations.TextAnnotation.class)\r\n          + wi.get(CoreAnnotations.GoldAnswerAnnotation.class) + '\\t');\r\n    }\r\n    boolean first = true;\r\n    for (Object feat : features) {\r\n      if (first) {\r\n        first = false;\r\n      } else {\r\n        cliqueWriter.print(\" \");\r\n      }\r\n      cliqueWriter.print(feat);\r\n    }\r\n    cliqueWriter.println();\r\n    writtenNum++;\r\n  }", "label": 0}
{"code": "func (a *AuthServer) GetRemoteCluster(clusterName string) (services.RemoteCluster, error) {\n\t// To make sure remote cluster exists - to protect against random\n\t// clusterName requests (e.g. when clusterName is set to local cluster name)\n\tremoteCluster, err := a.Presence.GetRemoteCluster(clusterName)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif err := a.updateRemoteClusterStatus(remoteCluster); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn remoteCluster, nil\n}", "label": 5}
{"code": "func Run(t *testing.T, suite TestingSuite) {\n\tsuite.SetT(t)\n\tdefer failOnPanic(t)\n\n\tsuiteSetupDone := false\n\t\n\tmethodFinder := reflect.TypeOf(suite)\n\ttests := []testing.InternalTest{}\n\tfor index := 0; index < methodFinder.NumMethod(); index++ {\n\t\tmethod := methodFinder.Method(index)\n\t\tok, err := methodFilter(method.Name)\n\t\tif err != nil {\n\t\t\tfmt.Fprintf(os.Stderr, \"testify: invalid regexp for -m: %s\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\tif !suiteSetupDone {\n\t\t\tif setupAllSuite, ok := suite.(SetupAllSuite); ok {\n\t\t\t\tsetupAllSuite.SetupSuite()\n\t\t\t}\n\t\t\tdefer func() {\n\t\t\t\tif tearDownAllSuite, ok := suite.(TearDownAllSuite); ok {\n\t\t\t\t\ttearDownAllSuite.TearDownSuite()\n\t\t\t\t}\n\t\t\t}()\n\t\t\tsuiteSetupDone = true\n\t\t}\n\t\ttest := testing.InternalTest{\n\t\t\tName: method.Name,\n\t\t\tF: func(t *testing.T) {\n\t\t\t\tparentT := suite.T()\n\t\t\t\tsuite.SetT(t)\n\t\t\t\tdefer failOnPanic(t)\n\n\t\t\t\tif setupTestSuite, ok := suite.(SetupTestSuite); ok {\n\t\t\t\t\tsetupTestSuite.SetupTest()\n\t\t\t\t}\n\t\t\t\tif beforeTestSuite, ok := suite.(BeforeTest); ok {\n\t\t\t\t\tbeforeTestSuite.BeforeTest(methodFinder.Elem().Name(), method.Name)\n\t\t\t\t}\n\t\t\t\tdefer func() {\n\t\t\t\t\tif afterTestSuite, ok := suite.(AfterTest); ok {\n\t\t\t\t\t\tafterTestSuite.AfterTest(methodFinder.Elem().Name(), method.Name)\n\t\t\t\t\t}\n\t\t\t\t\tif tearDownTestSuite, ok := suite.(TearDownTestSuite); ok {\n\t\t\t\t\t\ttearDownTestSuite.TearDownTest()\n\t\t\t\t\t}\n\t\t\t\t\tsuite.SetT(parentT)\n\t\t\t\t}()\n\t\t\t\tmethod.Func.Call([]reflect.Value{reflect.ValueOf(suite)})\n\t\t\t},\n\t\t}\n\t\ttests = append(tests, test)\n\t}\n\trunTests(t, tests)\n}", "label": 5}
{"code": "def relative_abundance(biomf, sampleIDs=None):\n    \"\"\"\n    Calculate the relative abundance of each OTUID in a Sample.\n\n    :type biomf: A BIOM file.\n    :param biomf: OTU table format.\n\n    :type sampleIDs: list\n    :param sampleIDs: A list of sample id's from BIOM format OTU table.\n\n    :rtype: dict\n    :return: Returns a keyed on SampleIDs, and the values are dictionaries keyed on\n             OTUID's and their values represent the relative abundance of that OTUID in\n             that SampleID.\n    \"\"\"\n    if sampleIDs is None:\n        sampleIDs = biomf.ids()\n    else:\n        try:\n            for sid in sampleIDs:\n                assert sid in biomf.ids()\n        except AssertionError:\n            raise ValueError(\n                \"\\nError while calculating relative abundances: The sampleIDs provided do\"\n                \" not match the sampleIDs in biom file. Please double check the sampleIDs\"\n                \" provided.\\n\")\n    otuIDs = biomf.ids(axis=\"observation\")\n    norm_biomf = biomf.norm(inplace=False)\n\n    return {sample: {otuID: norm_biomf.get_value_by_ids(otuID, sample)\n                     for otuID in otuIDs} for sample in sampleIDs}", "label": 1}
{"code": "function _whichTransitionEvent() {\n    const el = document.createElement('meta');\n    const animations = {\n        transition: 'transitionend',\n        OTransition: 'oTransitionEnd',\n        MozTransition: 'transitionend',\n        WebkitTransition: 'webkitTransitionEnd',\n    };\n\n    for (const t in animations) {\n        if (el.style[t] !== undefined) {\n            return animations[t];\n        }\n    }\n}", "label": 3}
{"code": "function(comparator, startingValue)\n  {\n    var cmp = createComparator( comparator || this.comparator, true );\n    var max = startingValue;\n\n    for (var i = 0; i < this.length; i++)\n    {\n      if ( cmp( max, this[i] ) < 0 )\n      {\n        max = this[i];\n      }\n    }\n\n    return max;\n  }", "label": 3}
{"code": "function (value, key, element) {\n                var style = element.style;\n                this[key] = style[key] = value; // style is for #1873\n\n                // Correction for the 1x1 size of the shape container. Used in gauge needles.\n                style.left = -mathRound(mathSin(value * deg2rad) + 1) + PX;\n                style.top = mathRound(mathCos(value * deg2rad)) + PX;\n            }", "label": 3}
{"code": "func (d Duration) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(fmt.Sprintf(\"%v\", d.Duration))\n}", "label": 5}
{"code": "def sync_with_transaction_state\n        if transaction_state = @transaction_state\n          if transaction_state.fully_committed?\n            force_clear_transaction_record_state\n          elsif transaction_state.committed?\n            clear_transaction_record_state\n          elsif transaction_state.rolledback?\n            force_restore_state = transaction_state.fully_rolledback?\n            restore_transaction_record_state(force_restore_state)\n            clear_transaction_record_state\n          end\n        end\n      end", "label": 4}
{"code": "func Run(ctx context.Context, cfg Config, newTeleport NewProcess) error {\n\tif newTeleport == nil {\n\t\tnewTeleport = newTeleportProcess\n\t}\n\tcopyCfg := cfg\n\tsrv, err := newTeleport(&copyCfg)\n\tif err != nil {\n\t\treturn trace.Wrap(err, \"initialization failed\")\n\t}\n\tif srv == nil {\n\t\treturn trace.BadParameter(\"process has returned nil server\")\n\t}\n\tif err := srv.Start(); err != nil {\n\t\treturn trace.Wrap(err, \"startup failed\")\n\t}\n\t// Wait and reload until called exit.\n\tfor {\n\t\tsrv, err = waitAndReload(ctx, cfg, srv, newTeleport)\n\t\tif err != nil {\n\t\t\t// This error means that was a clean shutdown\n\t\t\t// and no reload is necessary.\n\t\t\tif err == ErrTeleportExited {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n}", "label": 5}
{"code": "private function createBucket($path, array $params)\n    {\n        if ($this->getClient()->doesBucketExist($params['Bucket'])) {\n            return $this->triggerError(\"Bucket already exists: {$path}\");\n        }\n\n        return $this->boolCall(function () use ($params, $path) {\n            $this->getClient()->createBucket($params);\n            $this->clearCacheKey($path);\n            return true;\n        });\n    }", "label": 2}
{"code": "def replace_tokens(str, hash) #:nodoc:\n      hash.inject(str) do |string, (key, value)|\n        string.gsub \":#{key}\", value.to_s\n      end\n    end", "label": 4}
{"code": "def pause(expected = nil)\n      paused = listener.paused?\n      states = { paused: true, unpaused: false, toggle: !paused }\n      pause = states[expected || :toggle]\n      fail ArgumentError, \"invalid mode: #{expected.inspect}\" if pause.nil?\n      return if pause == paused\n\n      listener.public_send(pause ? :pause : :start)\n      UI.info \"File event handling has been #{pause ? 'paused' : 'resumed'}\"\n    end", "label": 4}
{"code": "def disk(x, y, height, gaussian_width):\n    \"\"\"\n    Circular disk with Gaussian fall-off after the solid central region.\n    \"\"\"\n    disk_radius = height/2.0\n\n    distance_from_origin = np.sqrt(x**2+y**2)\n    distance_outside_disk = distance_from_origin - disk_radius\n    sigmasq = gaussian_width*gaussian_width\n\n    if sigmasq==0.0:\n        falloff = x*0.0\n    else:\n        with float_error_ignore():\n            falloff = np.exp(np.divide(-distance_outside_disk*distance_outside_disk,\n                                  2*sigmasq))\n\n    return np.where(distance_outside_disk<=0,1.0,falloff)", "label": 1}
{"code": "def main(argv=sys.argv[1:]):\n    \"\"\"Parse argument and start main program.\"\"\"\n    args = docopt(__doc__, argv=argv,\n                  version=pkg_resources.require('buienradar')[0].version)\n\n    level = logging.ERROR\n    if args['-v']:\n        level = logging.INFO\n    if args['-v'] == 2:\n        level = logging.DEBUG\n    logging.basicConfig(level=level)\n\n    log = logging.getLogger(__name__)\n    log.info(\"Start...\")\n\n    latitude = float(args['--latitude'])\n    longitude = float(args['--longitude'])\n    timeframe = int(args['--timeframe'])\n\n    usexml = False\n    if args['--usexml']:\n        usexml = True\n\n    result = get_data(latitude, longitude, usexml)\n    if result[SUCCESS]:\n        log.debug(\"Retrieved data:\\n%s\", result)\n\n        result = parse_data(result[CONTENT], result[RAINCONTENT],\n                            latitude, longitude, timeframe, usexml)\n        log.info(\"result: %s\", result)\n        print(result)\n    else:\n        log.error(\"Retrieving weather data was not successfull (%s)\",\n                  result[MESSAGE])", "label": 1}
{"code": "public function sendPromoteParticipants($gId, $participant)\n    {\n        $msgId = $this->createMsgId();\n        $this->sendGroupsChangeParticipants($gId, $participant, 'promote', $msgId);\n    }", "label": 2}
{"code": "func (info *HostCertificateInfo) FromURL(u *url.URL, config *tls.Config) error {\n\taddr := u.Host\n\tif !(strings.LastIndex(addr, \":\") > strings.LastIndex(addr, \"]\")) {\n\t\taddr += \":443\"\n\t}\n\n\tconn, err := tls.Dial(\"tcp\", addr, config)\n\tif err != nil {\n\t\tswitch err.(type) {\n\t\tcase x509.UnknownAuthorityError:\n\t\tcase x509.HostnameError:\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\n\t\tinfo.Err = err\n\n\t\tconn, err = tls.Dial(\"tcp\", addr, &tls.Config{InsecureSkipVerify: true})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\tinfo.Status = string(types.HostCertificateManagerCertificateInfoCertificateStatusGood)\n\t}\n\n\tstate := conn.ConnectionState()\n\t_ = conn.Close()\n\tinfo.FromCertificate(state.PeerCertificates[0])\n\n\treturn nil\n}", "label": 5}
{"code": "public static cachecontentgroup[] get(nitro_service service) throws Exception{\n\t\tcachecontentgroup obj = new cachecontentgroup();\n\t\tcachecontentgroup[] response = (cachecontentgroup[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function compare (checkDictionary, path, pathContent) {\n        var subPromises = [];\n        pathContent.forEach(function (name) {\n            var JS_EXT = \".js\",\n                JS_EXT_LENGTH = JS_EXT.length,\n                contentFullName = path + name,\n                contentFullNameLength = contentFullName.length;\n            if (contentFullNameLength > JS_EXT_LENGTH\n                && contentFullName.indexOf(JS_EXT) === contentFullNameLength - JS_EXT_LENGTH) {\n                contentFullName = contentFullName.substring(START, contentFullNameLength - JS_EXT_LENGTH);\n                if (checkDictionary[contentFullName] === \"obsolete\") {\n                    checkDictionary[contentFullName] = \"exists\";\n                } else {\n                    checkDictionary[contentFullName] = \"new\";\n                }\n            } else if (name.indexOf(\".\") === NOT_FOUND) {\n                subPromises.push(gpf.http.get(\"/fs/src/\" + contentFullName)\n                    .then(function (response) {\n                        return JSON.parse(response.responseText);\n                    })\n                    .then(function (subPathContent) {\n                        return compare(checkDictionary, contentFullName + \"/\", subPathContent);\n                    }));\n            }\n        });\n        if (!subPromises.length) {\n            return Promise.resolve();\n        }\n        return Promise.all(subPromises);\n    }", "label": 3}
{"code": "def div(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'div_for', &block)\n      define_method(name) do\n        return platform.div_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "def get(self, name=None):\n        \"\"\"\n        Gets a list of all recipes, which are registered by the current plugin.\n        If a name is provided, only the requested recipe is returned or None.\n\n        :param: name: Name of the recipe\n        \"\"\"\n        return self.__app.recipes.get(name, self._plugin)", "label": 1}
{"code": "def +(other)\n      if Duration === other\n        parts = @parts.dup\n        other.parts.each do |(key, value)|\n          parts[key] += value\n        end\n        Duration.new(value + other.value, parts)\n      else\n        seconds = @parts[:seconds] + other\n        Duration.new(value + other, @parts.merge(seconds: seconds))\n      end\n    end", "label": 4}
{"code": "def install_templates(rambafile)\n      # We always clear previously installed templates to avoid conflicts in different versions\n      clear_installed_templates\n\n      templates = rambafile[TEMPLATES_KEY]\n\n      if !templates || templates.count == 0\n        puts 'You must specify at least one template in Rambafile under the key *templates*'.red\n        return\n      end\n\n      # Mapping hashes to model objects\n      templates = rambafile[TEMPLATES_KEY].map { |template_hash|\n        Generamba::TemplateDeclaration.new(template_hash)\n      }\n\n      catalogs = rambafile[CATALOGS_KEY]\n      # If there is at least one template from catalogs, we should update our local copy of the catalog\n      update_catalogs_if_needed(catalogs, templates)\n\n      templates.each do |template_declaration|\n        strategy = @installer_factory.installer_for_type(template_declaration.type)\n        template_declaration.install(strategy)\n      end\n    end", "label": 4}
{"code": "protected Object getProxyFromResultSet() throws PersistenceBrokerException\r\n    {\r\n        // 1. get Identity of current row:\r\n        Identity oid = getIdentityFromResultSet();\r\n\r\n        // 2. return a Proxy instance:\r\n        return getBroker().createProxy(getItemProxyClass(), oid);\r\n    }", "label": 0}
{"code": "def package_existent(name):\n    \"\"\"Search package.\n\n    * :class:`bootstrap_py.exceptions.Conflict` exception occurs\n      when user specified name has already existed.\n\n    * :class:`bootstrap_py.exceptions.BackendFailure` exception occurs\n      when PyPI service is down.\n\n    :param str name: package name\n    \"\"\"\n    try:\n        response = requests.get(PYPI_URL.format(name))\n        if response.ok:\n            msg = ('[error] \"{0}\" is registered already in PyPI.\\n'\n                   '\\tSpecify another package name.').format(name)\n            raise Conflict(msg)\n    except (socket.gaierror,\n            Timeout,\n            ConnectionError,\n            HTTPError) as exc:\n        raise BackendFailure(exc)", "label": 1}
{"code": "function findPartials(source, source_path, options, deps) {\n  var reg = /({>\\s?\")([^\"{}]+)(\"[\\s\\S]*?\\/})/g, // matches dust partial syntax\n    result = null, partial,\n    dep, name, replace;\n\n  // search source & add a dependency for each match\n  while ((result = reg.exec(source)) !== null) {\n    partial = {\n      prefix: result[1],\n      name: result[2],\n      suffix: result[3]\n    };\n\n    // add to dependencies\n    name = addDustDependency(partial.name, source_path, options, deps);\n\n    // retrieve newest dependency\n    dep = deps[deps.length - 1];\n\n    // log\n    log(options, 'found partial dependency \"' + partial.name + '\"');\n\n    // if the partial has been renamed, update the name in the template\n    if (name != partial.name) {\n      log(options, 'renaming partial \"' + partial.name + '\" to \"' + name + '\"')\n\n      // build replacement for partial tag\n      replace = partial.prefix + name + partial.suffix;\n\n      // replace the original partial path with the new \"absolute\" path (relative to root)\n      source = source.substring(0, result.index) + replace + source.substring(result.index + result[0].length);\n\n      // update regex index\n      reg.lastIndex += (replace.length - result[0].length);\n    }\n  }\n\n  return source;\n}", "label": 3}
{"code": "function (soajs, id) {\n        let id1;\n        try {\n            id1 = soajs.mongoDb.ObjectId(id.toString());\n            return id1;\n        }\n        catch (e) {\n            soajs.log.error(e);\n            throw e;\n        }\n    }", "label": 3}
{"code": "public function collection($name)\n    {\n        return $this->getCollectionReference(\n            $this->connection,\n            $this->valueMapper,\n            $this->projectId,\n            $this->database,\n            $name\n        );\n    }", "label": 2}
{"code": "function lintJS (args = []) {\n  if (!Array.isArray(args)) {\n    throw new TypeError('arguments has to be an array')\n  }\n\n  const command = [\n    `node ${resolveBin('eslint')}`,\n    '--format codeframe',\n    '\"src/**/*.js\"',\n    ...args\n  ].join(' ')\n\n  console.log(chalk`\\nCommand:\\n{green ${command}}\\n`)\n\n  try {\n    execSync(command, { stdio: 'inherit' })\n  } catch (error) {\n    return false\n  }\n\n  return true\n}", "label": 3}
{"code": "def _add_get_tracking_url(cls):\n    \"\"\" Add a method to get the tracking url of an object. \"\"\"\n    def get_tracking_url(self):\n        \"\"\" return url to tracking view in admin panel \"\"\"\n        url = reverse('admin:tracking_fields_trackingevent_changelist')\n        object_id = '{0}%3A{1}'.format(\n            ContentType.objects.get_for_model(self).pk,\n            self.pk\n        )\n        return '{0}?object={1}'.format(url, object_id)\n    if not hasattr(cls, 'get_tracking_url'):\n        setattr(cls, 'get_tracking_url', get_tracking_url)", "label": 1}
{"code": "public static base_response delete(nitro_service client, String urlname) throws Exception {\n\t\tvpnurl deleteresource = new vpnurl();\n\t\tdeleteresource.urlname = urlname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "func (c *ClientProfile) Name() string {\n\tif c.ProxyHost != \"\" {\n\t\treturn c.ProxyHost\n\t}\n\n\taddr, _, err := net.SplitHostPort(c.WebProxyAddr)\n\tif err != nil {\n\t\treturn c.WebProxyAddr\n\t}\n\n\treturn addr\n}", "label": 5}
{"code": "def emission_lock(self, name):\n        \"\"\"Holds emission of events and dispatches the last event on release\n\n        The context manager returned will store the last event data called by\n        :meth:`emit` and prevent callbacks until it exits. On exit, it will\n        dispatch the last event captured (if any)::\n\n            class Foo(Dispatcher):\n                _events_ = ['my_event']\n\n            def on_my_event(value):\n                print(value)\n\n            foo = Foo()\n            foo.bind(my_event=on_my_event)\n\n            with foo.emission_lock('my_event'):\n                foo.emit('my_event', 1)\n                foo.emit('my_event', 2)\n\n            >>> 2\n\n        Args:\n            name (str): The name of the :class:`Event` or\n                :class:`~pydispatch.properties.Property`\n\n        Returns:\n            A context manager to be used by the :keyword:`with` statement.\n\n            If available, this will also be an async context manager to be used\n            with the :keyword:`async with` statement (see `PEP 492`_).\n\n        Note:\n            The context manager is re-entrant, meaning that multiple calls to\n            this method within nested context scopes are possible.\n\n        .. _PEP 492: https://www.python.org/dev/peps/pep-0492/#asynchronous-context-managers-and-async-with\n        \"\"\"\n        e = self.__property_events.get(name)\n        if e is None:\n            e = self.__events[name]\n        return e.emission_lock", "label": 1}
{"code": "def normalized_fragment\n      return nil unless self.fragment\n      return @normalized_fragment if defined?(@normalized_fragment)\n      @normalized_fragment ||= begin\n        component = Addressable::URI.normalize_component(\n          self.fragment,\n          Addressable::URI::CharacterClasses::FRAGMENT\n        )\n        component == \"\" ? nil : component\n      end\n      # All normalized values should be UTF-8\n      if @normalized_fragment\n        @normalized_fragment.force_encoding(Encoding::UTF_8)\n      end\n      @normalized_fragment\n    end", "label": 4}
{"code": "func (r *Registry) newReference(item mo.Reference) types.ManagedObjectReference {\n\tref := item.Reference()\n\n\tif ref.Type == \"\" {\n\t\tref.Type = typeName(item)\n\t}\n\n\tif ref.Value == \"\" {\n\t\tn := atomic.AddInt64(&r.counter, 1)\n\t\tref.Value = fmt.Sprintf(\"%s-%d\", valuePrefix(ref.Type), n)\n\t}\n\n\treturn ref\n}", "label": 5}
{"code": "func (d *Decoder) popElement(t *EndElement) bool {\n\ts := d.pop()\n\tname := t.Name\n\tswitch {\n\tcase s == nil || s.kind != stkStart:\n\t\td.err = d.syntaxError(\"unexpected end element </\" + name.Local + \">\")\n\t\treturn false\n\tcase s.name.Local != name.Local:\n\t\tif !d.Strict {\n\t\t\td.needClose = true\n\t\t\td.toClose = t.Name\n\t\t\tt.Name = s.name\n\t\t\treturn true\n\t\t}\n\t\td.err = d.syntaxError(\"element <\" + s.name.Local + \"> closed by </\" + name.Local + \">\")\n\t\treturn false\n\tcase s.name.Space != name.Space:\n\t\td.err = d.syntaxError(\"element <\" + s.name.Local + \"> in space \" + s.name.Space +\n\t\t\t\"closed by </\" + name.Local + \"> in space \" + name.Space)\n\t\treturn false\n\t}\n\n\t// Pop stack until a Start or EOF is on the top, undoing the\n\t// translations that were associated with the element we just closed.\n\tfor d.stk != nil && d.stk.kind != stkStart && d.stk.kind != stkEOF {\n\t\ts := d.pop()\n\t\tif s.ok {\n\t\t\td.ns[s.name.Local] = s.name.Space\n\t\t} else {\n\t\t\tdelete(d.ns, s.name.Local)\n\t\t}\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "public Object selectElement(String predicate) throws org.odmg.QueryInvalidException\r\n    {\r\n        return ((DList) this.query(predicate)).get(0);\r\n    }", "label": 0}
{"code": "public function addCriteria(Criteria $criteria)\n    {\n        $allAliases = $this->getAllAliases();\n        if (! isset($allAliases[0])) {\n            throw new Query\\QueryException('No aliases are set before invoking addCriteria().');\n        }\n\n        $visitor         = new QueryExpressionVisitor($this->getAllAliases());\n        $whereExpression = $criteria->getWhereExpression();\n\n        if ($whereExpression) {\n            $this->andWhere($visitor->dispatch($whereExpression));\n            foreach ($visitor->getParameters() as $parameter) {\n                $this->parameters->add($parameter);\n            }\n        }\n\n        if ($criteria->getOrderings()) {\n            foreach ($criteria->getOrderings() as $sort => $order) {\n                $hasValidAlias = false;\n                foreach ($allAliases as $alias) {\n                    if (strpos($sort . '.', $alias . '.') === 0) {\n                        $hasValidAlias = true;\n                        break;\n                    }\n                }\n\n                if (! $hasValidAlias) {\n                    $sort = $allAliases[0] . '.' . $sort;\n                }\n\n                $this->addOrderBy($sort, $order);\n            }\n        }\n\n        $firstResult = $criteria->getFirstResult();\n        $maxResults  = $criteria->getMaxResults();\n\n        // Overwrite limits only if they was set in criteria\n        if ($firstResult !== null) {\n            $this->setFirstResult($firstResult);\n        }\n        if ($maxResults !== null) {\n            $this->setMaxResults($maxResults);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function filterRepresented(modules, files, options) {\n    return _.filter(modules, function(module) {\n      return !_.some(files, function(file) {\n        // Look for the module name somewhere in the source path\n        return (\n          path\n            .join(sep, options.srcPrefix, file.src.replace(rmain, '$1'), sep)\n            .indexOf(sep + module + sep) > -1\n        )\n      })\n    })\n  }", "label": 3}
{"code": "public ManageableCollection createCollectionProxy(PBKey brokerKey, Query query, Class collectionClass)\r\n    {\r\n        Object args[] = {brokerKey, collectionClass, query};\r\n\r\n        try\r\n        {\r\n            return (ManageableCollection) getCollectionProxyConstructor(collectionClass).newInstance(args);\r\n        }\r\n        catch(InstantiationException ex)\r\n        {\r\n            throw new PersistenceBrokerException(\"Exception while creating a new collection proxy instance\", ex);\r\n        }\r\n        catch(InvocationTargetException ex)\r\n        {\r\n            throw new PersistenceBrokerException(\"Exception while creating a new collection proxy instance\", ex);\r\n        }\r\n        catch(IllegalAccessException ex)\r\n        {\r\n            throw new PersistenceBrokerException(\"Exception while creating a new collection proxy instance\", ex);\r\n        }\r\n    }", "label": 0}
{"code": "private void writeCompressedText(File file, byte[] compressedContent) throws IOException\r\n    {\r\n        ByteArrayInputStream bais   = new ByteArrayInputStream(compressedContent);\r\n        GZIPInputStream      gis    = new GZIPInputStream(bais);\r\n        BufferedReader       input  = new BufferedReader(new InputStreamReader(gis));\r\n        BufferedWriter       output = new BufferedWriter(new FileWriter(file));\r\n        String               line;\r\n\r\n        while ((line = input.readLine()) != null)\r\n        {\r\n            output.write(line);\r\n            output.write('\\n');\r\n        }\r\n        input.close();\r\n        gis.close();\r\n        bais.close();\r\n        output.close();\r\n    }", "label": 0}
{"code": "func (u UUID) MarshalText() (text []byte, err error) {\n\ttext = []byte(u.String())\n\treturn\n}", "label": 5}
{"code": "def parse_parts_to_dc(parts)\n      case parts.length\n      when 1\n        # If there is only one part, it is a reference to an existing data criteria's value\n        @doc.find_criteria_by_lvn(parts.first.strip.split('.')[0])\n      when 2\n        # If there are two parts, there is a computation performed, specifically time difference, on the two criteria\n        children = parts.collect { |p| @doc.find_criteria_by_lvn(p.strip.split('.')[0]).id }\n        id = \"GROUP_TIMEDIFF_#{@id_generator.next_id}\"\n        HQMF2::DataCriteriaWrapper.new(id: id,\n                                       title: id,\n                                       subset_operators: [HQMF::SubsetOperator.new('DATETIMEDIFF', nil)],\n                                       children_criteria: children,\n                                       derivation_operator: HQMF::DataCriteria::XPRODUCT,\n                                       type: 'derived',\n                                       definition: 'derived',\n                                       negation: false,\n                                       source_data_criteria: id\n                                      )\n      else\n        # If there are neither one or 2 parts, the code should fail\n        fail \"No defined extraction method to handle #{parts.length} parts\"\n      end\n    end", "label": 4}
{"code": "function getSymbolsOfParameterPropertyDeclaration(parameter, parameterName) {\n            var constructorDeclaration = parameter.parent;\n            var classDeclaration = parameter.parent.parent;\n            var parameterSymbol = getSymbol(constructorDeclaration.locals, parameterName, 107455 /* Value */);\n            var propertySymbol = getSymbol(classDeclaration.symbol.members, parameterName, 107455 /* Value */);\n            if (parameterSymbol && propertySymbol) {\n                return [parameterSymbol, propertySymbol];\n            }\n            ts.Debug.fail(\"There should exist two symbols, one as property declaration and one as parameter declaration\");\n        }", "label": 3}
{"code": "def value_offset(prop)\n      src_range = prop.name_source_range\n      src_range.start_pos.offset +\n        (src_range.end_pos.offset - src_range.start_pos.offset) +\n        whitespace_after_colon(prop).take_while { |w| w == ' ' }.size\n    end", "label": 4}
{"code": "def delete_queue():\n    \"\"\"Delete indexing queue.\"\"\"\n    def action(queue):\n        queue.delete()\n        click.secho('Indexing queue has been deleted.', fg='green')\n        return queue\n    return action", "label": 1}
{"code": "public function getSettings()\n    {\n        $settings = [];\n        $map = [\n            'localStrictModeEnabled' => 'strictMode',\n            'localMonthsOverflow' => 'monthOverflow',\n            'localYearsOverflow' => 'yearOverflow',\n            'localHumanDiffOptions' => 'humanDiffOptions',\n            'localToStringFormat' => 'toStringFormat',\n            'localSerializer' => 'toJsonFormat',\n            'localMacros' => 'macros',\n            'localGenericMacros' => 'genericMacros',\n            'locale' => 'locale',\n            'tzName' => 'timezone',\n            'localFormatFunction' => 'formatFunction',\n        ];\n        foreach ($map as $property => $key) {\n            $value = $this->$property ?? null;\n            if ($value !== null) {\n                $settings[$key] = $value;\n            }\n        }\n\n        return $settings;\n    }", "label": 2}
{"code": "function onTabLoaded(contentEl) {\n      // Remove theme elements\n      router.removeThemeElements($newTabEl);\n\n      var tabEventTarget = $newTabEl;\n      if (typeof contentEl !== 'string') { tabEventTarget = $(contentEl); }\n\n      tabEventTarget.trigger('tab:init tab:mounted', tabRoute);\n      router.emit('tabInit tabMounted', $newTabEl[0], tabRoute);\n\n      if ($oldTabEl && $oldTabEl.length) {\n        if (animated) {\n          onTabsChanged(function () {\n            router.emit('routeChanged', router.currentRoute, router.previousRoute, router);\n            if (router.params.unloadTabContent) {\n              router.tabRemove($oldTabEl, $newTabEl, tabRoute);\n            }\n          });\n        } else {\n          router.emit('routeChanged', router.currentRoute, router.previousRoute, router);\n          if (router.params.unloadTabContent) {\n            router.tabRemove($oldTabEl, $newTabEl, tabRoute);\n          }\n        }\n      }\n    }", "label": 3}
{"code": "public static <E> Set<E> union(Set<E> s1, Set<E> s2) {\r\n    Set<E> s = new HashSet<E>();\r\n    s.addAll(s1);\r\n    s.addAll(s2);\r\n    return s;\r\n  }", "label": 0}
{"code": "public function setInventors($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->inventors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def rowstack(self, new, mode='nulls'):\n        \"\"\"\n        Vertical stacking for tabarrays.\n\n        Stack tabarray(s) in `new` below `self`.\n\n        **See also**\n\n                :func:`tabular.tabarray.tab_rowstack`, \n                :func:`tabular.spreadsheet.rowstack`\n\n        \"\"\"\n        if isinstance(new,list):\n            return tab_rowstack([self] + new, mode)\n        else:\n            return tab_rowstack([self, new], mode)", "label": 1}
{"code": "def deliver_message(value, key: nil, headers: {}, topic:, partition: nil, partition_key: nil, retries: 1)\n      create_time = Time.now\n\n      message = PendingMessage.new(\n        value: value,\n        key: key,\n        headers: headers,\n        topic: topic,\n        partition: partition,\n        partition_key: partition_key,\n        create_time: create_time\n      )\n\n      if partition.nil?\n        partition_count = @cluster.partitions_for(topic).count\n        partition = Partitioner.partition_for_key(partition_count, message)\n      end\n\n      buffer = MessageBuffer.new\n\n      buffer.write(\n        value: message.value,\n        key: message.key,\n        headers: message.headers,\n        topic: message.topic,\n        partition: partition,\n        create_time: message.create_time,\n      )\n\n      @cluster.add_target_topics([topic])\n\n      compressor = Compressor.new(\n        instrumenter: @instrumenter,\n      )\n\n      transaction_manager = TransactionManager.new(\n        cluster: @cluster,\n        logger: @logger,\n        idempotent: false,\n        transactional: false\n      )\n\n      operation = ProduceOperation.new(\n        cluster: @cluster,\n        transaction_manager: transaction_manager,\n        buffer: buffer,\n        required_acks: 1,\n        ack_timeout: 10,\n        compressor: compressor,\n        logger: @logger,\n        instrumenter: @instrumenter,\n      )\n\n      attempt = 1\n\n      begin\n        operation.execute\n\n        unless buffer.empty?\n          raise DeliveryFailed.new(nil, [message])\n        end\n      rescue Kafka::Error => e\n        @cluster.mark_as_stale!\n\n        if attempt >= (retries + 1)\n          raise\n        else\n          attempt += 1\n          @logger.warn \"Error while delivering message, #{e.class}: #{e.message}; retrying after 1s...\"\n\n          sleep 1\n\n          retry\n        end\n      end\n    end", "label": 4}
{"code": "def find_lints(ruby, source_map)\n      rubocop = ::RuboCop::CLI.new\n\n      filename =\n        if document.file\n          \"#{document.file}.rb\"\n        else\n          'ruby_script.rb'\n        end\n\n      with_ruby_from_stdin(ruby) do\n        extract_lints_from_offenses(lint_file(rubocop, filename), source_map)\n      end\n    end", "label": 4}
{"code": "def authority=(new_authority)\n      if new_authority\n        if !new_authority.respond_to?(:to_str)\n          raise TypeError, \"Can't convert #{new_authority.class} into String.\"\n        end\n        new_authority = new_authority.to_str\n        new_userinfo = new_authority[/^([^\\[\\]]*)@/, 1]\n        if new_userinfo\n          new_user = new_userinfo.strip[/^([^:]*):?/, 1]\n          new_password = new_userinfo.strip[/:(.*)$/, 1]\n        end\n        new_host = new_authority.sub(\n          /^([^\\[\\]]*)@/, EMPTY_STR\n        ).sub(\n          /:([^:@\\[\\]]*?)$/, EMPTY_STR\n        )\n        new_port =\n          new_authority[/:([^:@\\[\\]]*?)$/, 1]\n      end\n\n      # Password assigned first to ensure validity in case of nil\n      self.password = defined?(new_password) ? new_password : nil\n      self.user = defined?(new_user) ? new_user : nil\n      self.host = defined?(new_host) ? new_host : nil\n      self.port = defined?(new_port) ? new_port : nil\n\n      # Reset dependent values\n      remove_instance_variable(:@userinfo) if defined?(@userinfo)\n      remove_instance_variable(:@normalized_userinfo) if defined?(@normalized_userinfo)\n      remove_composite_values\n\n      # Ensure we haven't created an invalid URI\n      validate()\n    end", "label": 4}
{"code": "def notifiers\n      supported = Notifier.supported\n      Notifier.connect(notify: true, silent: true)\n      detected = Notifier.detected\n      Notifier.disconnect\n\n      detected_names = detected.map { |item| item[:name] }\n\n      final_rows = supported.each_with_object([]) do |(name, _), rows|\n        available = detected_names.include?(name) ? \"\u2714\" : \"\u2718\"\n\n        notifier = detected.detect { |n| n[:name] == name }\n        used = notifier ? \"\u2714\" : \"\u2718\"\n\n        options = notifier ? notifier[:options] : {}\n\n        if options.empty?\n          rows << :split\n          _add_row(rows, name, available, used, \"\", \"\")\n        else\n          options.each_with_index do |(option, value), index|\n            if index == 0\n              rows << :split\n              _add_row(rows, name, available, used, option.to_s, value.inspect)\n            else\n              _add_row(rows, \"\", \"\", \"\", option.to_s, value.inspect)\n            end\n          end\n        end\n\n        rows\n      end\n\n      Formatador.display_compact_table(\n        final_rows.drop(1),\n        [:Name, :Available, :Used, :Option, :Value]\n      )\n    end", "label": 4}
{"code": "function(oldViews, newViews, staleViews) {\n      var firstItemViewLeft, injectionSite,\n        view = this,\n        sizeOfOldViews = _.size(oldViews),\n        sizeOfNewViews = _.size(newViews),\n        sizeOfStaleViews = _.size(staleViews);\n      if (view.itemContainer && sizeOfOldViews && sizeOfOldViews == sizeOfStaleViews) {\n        // we removed all the views!\n        injectionSite = $('<span>');\n        _.first(oldViews).$el.before(injectionSite);\n      }\n      view.__removeStaleItemViews(staleViews);\n      _.each(newViews, function(createdViewInfo, indexOfView) {\n        if (createdViewInfo.indexOfModel === 0) {\n          // need to handle this case uniquely.\n          var replaceMethod;\n          if (!view.itemContainer) {\n            replaceMethod = _.bind(view.$el.prepend, view.$el);\n          } else {\n            if (injectionSite) {\n              replaceMethod = _.bind(injectionSite.replaceWith, injectionSite);\n            } else {\n              var staleModelIdMap = _.indexBy(staleViews, 'modelId');\n              var firstModelIdLeft = _.find(view.__orderedModelIdList, function(modelId) {\n                return !staleModelIdMap[modelId];\n              });\n              firstItemViewLeft = view.getTrackedView(view.__modelToViewMap[firstModelIdLeft]);\n              replaceMethod = _.bind(firstItemViewLeft.$el.prepend, firstItemViewLeft.$el);\n            }\n          }\n          view.attachView(null, createdViewInfo.view, {\n            replaceMethod: replaceMethod,\n            discardInjectionSite: true\n          });\n        } else {\n          // There will always the view before this one because we are adding new views in order\n          // and we took care of the initial case.\n          _addItemView.call(view, createdViewInfo.view, createdViewInfo.indexOfModel);\n        }\n      });\n      this.reorder();\n    }", "label": 3}
{"code": "def make_iterable(obj, default=None):\n    \"\"\" Ensure obj is iterable. \"\"\"\n    if obj is None:\n        return default or []\n    if isinstance(obj, (compat.string_types, compat.integer_types)):\n        return [obj]\n    return obj", "label": 1}
{"code": "func (f *Fpdf) SetLineJoinStyle(styleStr string) {\n\tvar joinStyle int\n\tswitch styleStr {\n\tcase \"round\":\n\t\tjoinStyle = 1\n\tcase \"bevel\":\n\t\tjoinStyle = 2\n\tdefault:\n\t\tjoinStyle = 0\n\t}\n\tf.joinStyle = joinStyle\n\tif f.page > 0 {\n\t\tf.outf(\"%d j\", f.joinStyle)\n\t}\n}", "label": 5}
{"code": "def commit(self, commands=\"\", confirmed=None, comment=None,\n               at_time=None, synchronize=False, req_format='text'):\n        \"\"\" Perform a commit operation.\n\n        Purpose: Executes a commit operation. All parameters are optional.\n               | commit confirm and commit at are mutually exclusive. All\n               | the others can be used with each other and commit confirm/at.\n\n        @param commands: A string or list of multiple commands\n                       | that the device will compare with.\n                       | If a string, it can be a single command,\n                       | multiple commands separated by commas, or\n                       | a filepath location of a file with multiple\n                       | commands, each on its own line.\n        @type commands: str or list\n        @param confirmed: integer value of the number of **seconds** to\n                             | confirm the commit for, if requested.\n        @type confirmed: int\n        @param comment: string that the user wants to comment the commit\n                      | with. Will show up in the 'show system commit' log.\n        @type comment: str\n        @param at_time: string designating the time at which the commit\n                      | should happen. Can be in one of two Junos approved\n                      | formats.\n        @type comment: str\n        @param synchronize: boolean set to true if desiring a commit\n                          | synchronize operation.\n        @type synchronize: bool\n        @param req_format: string to specify the response format. Accepts\n                         | either 'text' or 'xml'\n        @type req_format: str\n\n        @returns: The reply from the device.\n        @rtype: str\n        \"\"\"\n        # ncclient doesn't support a truly blank commit, so if nothing is\n        # passed, use 'annotate system' to make a blank commit\n        if not commands:\n            commands = 'annotate system \"\"'\n        clean_cmds = []\n        for cmd in clean_lines(commands):\n            clean_cmds.append(cmd)\n        # try to lock the candidate config so we can make changes.\n        self.lock()\n        self._session.load_configuration(action='set', config=commands)\n        results = \"\"\n        # confirmed and commit at are mutually exclusive. commit confirm\n        # takes precedence.\n        if confirmed:\n            results = self._session.commit(confirmed=True,\n                                           timeout=str(confirmed),\n                                           comment=comment,\n                                           synchronize=synchronize)\n        else:\n            results = self._session.commit(comment=comment, at_time=at_time,\n                                           synchronize=synchronize)\n        self.unlock()\n        if results:\n            if req_format == 'xml':\n                return results\n            # commit() DOES NOT return a parse-able xml tree, so we\n            # convert it to an ElementTree xml tree.\n            results = ET.fromstring(results.tostring)\n            out = ''\n            for i in results.iter():\n                # the success message is just a tag, so we need to get it\n                # specifically.\n                if i.tag == 'commit-check-success':\n                    out += 'configuration check succeeds\\n'\n                elif i.tag == 'commit-success':\n                    out += 'commit complete\\n'\n                elif i.tag == 'ok':\n                    out += 'commit complete\\n'\n                # this is for normal output with a tag and inner text, it will\n                # strip the inner text and add it to the output.\n                elif i.text is not None:\n                    if i.text.strip() + '\\n' != '\\n':\n                        out += i.text.strip() + '\\n'\n                # this is for elements that don't have inner text,\n                # it will add the tag to the output.\n                elif i.text is None:\n                    if i.tag + '\\n' != '\\n':\n                        out += i.tag + '\\n'\n            return out\n        return False", "label": 1}
{"code": "public String processProcedureArgument(Properties attributes) throws XDocletException\r\n    {\r\n        String               id     = attributes.getProperty(ATTRIBUTE_NAME);\r\n        ProcedureArgumentDef argDef = _curClassDef.getProcedureArgument(id);\r\n        String               attrName;\r\n        \r\n        if (argDef == null)\r\n        {    \r\n            argDef = new ProcedureArgumentDef(id);\r\n            _curClassDef.addProcedureArgument(argDef);\r\n        }\r\n\r\n        attributes.remove(ATTRIBUTE_NAME);\r\n        for (Enumeration attrNames = attributes.propertyNames(); attrNames.hasMoreElements(); )\r\n        {\r\n            attrName = (String)attrNames.nextElement();\r\n            argDef.setProperty(attrName, attributes.getProperty(attrName));\r\n        }\r\n        return \"\";\r\n    }", "label": 0}
{"code": "def intercept(obj, methodname, wrapper):\n    \"\"\"\n    Wraps an existing method on an object with the provided generator, which\n    will be \"sent\" the value when it yields control.\n\n    ::\n\n        >>> def ensure_primary_key_is_set():\n        ...     assert model.pk is None\n        ...     saved = yield\n        ...     aasert model is saved\n        ...     assert model.pk is not None\n        ...\n        >>> intercept(model, 'save', ensure_primary_key_is_set)\n        >>> model.save()\n\n    :param obj: the object that has the method to be wrapped\n    :type obj: :class:`object`\n    :param methodname: the name of the method that will be wrapped\n    :type methodname: :class:`str`\n    :param wrapper: the wrapper\n    :type wrapper: generator callable\n    \"\"\"\n    original = getattr(obj, methodname)\n\n    def replacement(*args, **kwargs):\n        wrapfn = wrapper(*args, **kwargs)\n        wrapfn.send(None)\n        result = original(*args, **kwargs)\n        try:\n            wrapfn.send(result)\n        except StopIteration:\n            return result\n        else:\n            raise AssertionError('Generator did not stop')\n\n    def unwrap():\n        \"\"\"\n        Restores the method to it's original (unwrapped) state.\n        \"\"\"\n        setattr(obj, methodname, original)\n\n    replacement.unwrap = unwrap\n\n    setattr(obj, methodname, replacement)", "label": 1}
{"code": "def continue_login(self, login_token, **params):\n        \"\"\"\n        Continues a login that requires an additional step.  This is common\n        for when login requires completing a captcha or supplying a two-factor\n        authentication token.\n\n        :Parameters:\n            login_token : `str`\n                A login token generated by the MediaWiki API (and used in a\n                previous call to login())\n            params : `mixed`\n                A set of parameters to include with the request.  This depends\n                on what \"requests\" for additional information were made by the\n                MediaWiki API.\n        \"\"\"\n\n        login_params = {\n            'action': \"clientlogin\",\n            'logintoken': login_token,\n            'logincontinue': 1\n        }\n        login_params.update(params)\n        login_doc = self.post(**login_params)\n        if login_doc['clientlogin']['status'] != 'PASS':\n            raise LoginError.from_doc(login_doc['clientlogin'])\n        return login_doc['clientlogin']", "label": 1}
{"code": "func SetShell(shell string) ServerOption {\n\treturn func(s *Server) error {\n\t\ts.shell = shell\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public DocumentReaderAndWriter<IN> makePlainTextReaderAndWriter() {\r\n    String readerClassName = flags.plainTextDocumentReaderAndWriter;\r\n    // We set this default here if needed because there may be models\r\n    // which don't have the reader flag set\r\n    if (readerClassName == null) {\r\n      readerClassName = SeqClassifierFlags.DEFAULT_PLAIN_TEXT_READER;\r\n    }\r\n    DocumentReaderAndWriter<IN> readerAndWriter;\r\n    try {\r\n      readerAndWriter = ((DocumentReaderAndWriter<IN>) Class.forName(readerClassName).newInstance());\r\n    } catch (Exception e) {\r\n      throw new RuntimeException(String.format(\"Error loading flags.plainTextDocumentReaderAndWriter: '%s'\", flags.plainTextDocumentReaderAndWriter), e);\r\n    }\r\n    readerAndWriter.init(flags);\r\n    return readerAndWriter;\r\n  }", "label": 0}
{"code": "func GetACIInfosWithKeyPrefix(tx *sql.Tx, prefix string) ([]*ACIInfo, error) {\n\tvar aciinfos []*ACIInfo\n\trows, err := tx.Query(\"SELECT * from aciinfo WHERE hasPrefix(blobkey, $1)\", prefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer rows.Close()\n\tfor rows.Next() {\n\t\taciinfo := &ACIInfo{}\n\t\tif err := aciinfoRowScan(rows, aciinfo); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\taciinfos = append(aciinfos, aciinfo)\n\t}\n\tif err := rows.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn aciinfos, err\n}", "label": 5}
{"code": "def ask(message='Are you sure? [y/N]'):\n    \"\"\"Asks the user his opinion.\"\"\"\n    agree = False\n    answer = raw_input(message).lower()\n    if answer.startswith('y'):\n        agree = True\n    return agree", "label": 1}
{"code": "func (t *Torrent) deleteConnection(c *connection) (ret bool) {\n\tif !c.closed.IsSet() {\n\t\tpanic(\"connection is not closed\")\n\t\t// There are behaviours prevented by the closed state that will fail\n\t\t// if the connection has been deleted.\n\t}\n\t_, ret = t.conns[c]\n\tdelete(t.conns, c)\n\ttorrent.Add(\"deleted connections\", 1)\n\tc.deleteAllRequests()\n\tif len(t.conns) == 0 {\n\t\tt.assertNoPendingRequests()\n\t}\n\treturn\n}", "label": 5}
{"code": "def build(self, output_dir=None, **kwargs):\n        \"\"\"\n        Buildes the recipe and creates needed folder and files.\n        May ask the user for some parameter inputs.\n\n        :param output_dir: Path, where the recipe shall be build. Default is the current working directory\n        :return: location of the installed recipe\n        \"\"\"\n        if output_dir is None:\n            output_dir = os.getcwd()\n\n        target = cookiecutter(self.path, output_dir=output_dir, **kwargs)\n\n        if self.final_words is not None and len(self.final_words) > 0:\n            print(\"\")\n            print(self.final_words)\n        return target", "label": 1}
{"code": "def format_raw_data(self, tpe, raw_data):\n        \"\"\"\n        uses type to format the raw information to a dictionary\n        usable by the mapper\n        \"\"\"\n        \n        if tpe == 'text':\n            formatted_raw_data = self.parse_text_to_dict(raw_data)\n        elif tpe == 'file':\n            formatted_raw_data = self.parse_file_to_dict(raw_data)\n        else:\n            formatted_raw_data = {'ERROR':'unknown data type', 'data':[raw_data]}\n        return formatted_raw_data", "label": 1}
{"code": "def render(scope = Object.new, locals = {}, &block)\n      parent = scope.instance_variable_defined?(:@haml_buffer) ? scope.instance_variable_get(:@haml_buffer) : nil\n      buffer = Haml::Buffer.new(parent, @options.for_buffer)\n\n      if scope.is_a?(Binding)\n        scope_object = eval(\"self\", scope)\n        scope = scope_object.instance_eval{binding} if block_given?\n      else\n        scope_object = scope\n        scope = scope_object.instance_eval{binding}\n      end\n\n      set_locals(locals.merge(:_hamlout => buffer, :_erbout => buffer.buffer), scope, scope_object)\n\n      scope_object.extend(Haml::Helpers)\n      scope_object.instance_variable_set(:@haml_buffer, buffer)\n      begin\n        eval(@temple_engine.precompiled_with_return_value, scope, @options.filename, @options.line)\n      rescue ::SyntaxError => e\n        raise SyntaxError, e.message\n      end\n    ensure\n      # Get rid of the current buffer\n      scope_object.instance_variable_set(:@haml_buffer, buffer.upper) if buffer\n    end", "label": 4}
{"code": "func (info *Info) BuildFromFilePath(root string) (err error) {\n\tinfo.Name = filepath.Base(root)\n\tinfo.Files = nil\n\terr = filepath.Walk(root, func(path string, fi os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif fi.IsDir() {\n\t\t\t// Directories are implicit in torrent files.\n\t\t\treturn nil\n\t\t} else if path == root {\n\t\t\t// The root is a file.\n\t\t\tinfo.Length = fi.Size()\n\t\t\treturn nil\n\t\t}\n\t\trelPath, err := filepath.Rel(root, path)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error getting relative path: %s\", err)\n\t\t}\n\t\tinfo.Files = append(info.Files, FileInfo{\n\t\t\tPath:   strings.Split(relPath, string(filepath.Separator)),\n\t\t\tLength: fi.Size(),\n\t\t})\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn\n\t}\n\tslices.Sort(info.Files, func(l, r FileInfo) bool {\n\t\treturn strings.Join(l.Path, \"/\") < strings.Join(r.Path, \"/\")\n\t})\n\terr = info.GeneratePieces(func(fi FileInfo) (io.ReadCloser, error) {\n\t\treturn os.Open(filepath.Join(root, strings.Join(fi.Path, string(filepath.Separator))))\n\t})\n\tif err != nil {\n\t\terr = fmt.Errorf(\"error generating pieces: %s\", err)\n\t}\n\treturn\n}", "label": 5}
{"code": "func DeepCompare(c *check.C, a, b interface{}) {\n\td := &spew.ConfigState{Indent: \" \", DisableMethods: true, DisablePointerMethods: true, DisablePointerAddresses: true}\n\n\tc.Assert(a, check.DeepEquals, b, check.Commentf(\"%v\\nStack:\\n%v\\n\", diff.Diff(d.Sdump(a), d.Sdump(b)), string(debug.Stack())))\n}", "label": 5}
{"code": "func certificateAuthorityFormat(bytes []byte) (string, error) {\n\t_, _, _, _, err := ssh.ParseAuthorizedKey(bytes)\n\tif err != nil {\n\t\t_, _, _, _, _, err := ssh.ParseKnownHosts(bytes)\n\t\tif err != nil {\n\t\t\treturn \"\", trace.BadParameter(\"unknown ca format\")\n\t\t}\n\t\treturn teleport.KnownHosts, nil\n\t}\n\treturn teleport.AuthorizedKeys, nil\n}", "label": 5}
{"code": "def disabled?(visitor)\n      visitor.is_a?(HamlLint::Linter) &&\n        comment_configuration.disabled?(visitor.name)\n    end", "label": 4}
{"code": "public function sendGetGroupV2Info($groupID)\n    {\n        $msgId = $this->nodeId['get_groupv2_info'] = $this->createIqId();\n\n        $queryNode = new ProtocolNode('query',\n            [\n                'request' => 'interactive',\n            ], null, null);\n\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'w:g2',\n                'type'  => 'get',\n                'to'    => $this->getJID($groupID),\n            ], [$queryNode], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "def set_defaults\n      default_user_agent = Config.user_agent || Typhoeus::USER_AGENT\n\n      options[:headers] = {'User-Agent' => default_user_agent}.merge(options[:headers] || {})\n      options[:headers]['Expect'] ||= ''\n      options[:verbose] = Typhoeus::Config.verbose if options[:verbose].nil? && !Typhoeus::Config.verbose.nil?\n      options[:maxredirs] ||= 50\n      options[:proxy] = Typhoeus::Config.proxy unless options.has_key?(:proxy) || Typhoeus::Config.proxy.nil?\n    end", "label": 4}
{"code": "def get_object(params = {}, options = {}, &block)\n      req = build_request(:get_object, params)\n      req.send_request(options, &block)\n    end", "label": 4}
{"code": "function validateJSonStructure(filePath, cb) {\n  fs.readFile(filePath, function(err, data) {\n    if (err) {\n      return cb(err);\n    }\n\n    try {\n      var jsonObject = JSON.parse(data);\n      cb(null, jsonObject);\n    } catch (e) {\n      cb('Invalid JSON file: ' + path.basename(filePath));\n    }\n  });\n}", "label": 3}
{"code": "func TLSConfig(cipherSuites []uint16) *tls.Config {\n\tconfig := &tls.Config{}\n\n\t// If ciphers suites were passed in, use them. Otherwise use the the\n\t// Go defaults.\n\tif len(cipherSuites) > 0 {\n\t\tconfig.CipherSuites = cipherSuites\n\t}\n\n\t// Pick the servers preferred ciphersuite, not the clients.\n\tconfig.PreferServerCipherSuites = true\n\n\tconfig.MinVersion = tls.VersionTLS12\n\tconfig.SessionTicketsDisabled = false\n\tconfig.ClientSessionCache = tls.NewLRUClientSessionCache(\n\t\tDefaultLRUCapacity)\n\treturn config\n}", "label": 5}
{"code": "func RemoveExistingChain(name string, table Table) error {\n\tc := &ChainInfo{\n\t\tName:  name,\n\t\tTable: table,\n\t}\n\tif string(c.Table) == \"\" {\n\t\tc.Table = Filter\n\t}\n\treturn c.Remove()\n}", "label": 5}
{"code": "public static <E> Counter<E> multiplyInPlace(Counter<E> target, double multiplier) {\r\n    for (Entry<E, Double> entry : target.entrySet()) {\r\n      target.setCount(entry.getKey(), entry.getValue() * multiplier);\r\n    }\r\n    return target;\r\n  }", "label": 0}
{"code": "public synchronized void addListener(MaterializationListener listener)\r\n\t{\r\n\t\tif (_listeners == null)\r\n\t\t{\r\n\t\t\t_listeners = new ArrayList();\r\n\t\t}\r\n\t\t// add listener only once\r\n\t\tif (!_listeners.contains(listener))\r\n\t\t{\r\n\t\t\t_listeners.add(listener);\r\n\t\t}\r\n\t}", "label": 0}
{"code": "public function setProductCategories($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->product_categories = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def ordered_railties #:nodoc:\n      @ordered_railties ||= begin\n        order = config.railties_order.map do |railtie|\n          if railtie == :main_app\n            self\n          elsif railtie.respond_to?(:instance)\n            railtie.instance\n          else\n            railtie\n          end\n        end\n\n        all = (railties - order)\n        all.push(self)   unless (all + order).include?(self)\n        order.push(:all) unless order.include?(:all)\n\n        index = order.index(:all)\n        order[index] = all\n        order\n      end\n    end", "label": 4}
{"code": "def pause(list)\n      unless list.is_a?(TopicPartitionList)\n        raise TypeError.new(\"list has to be a TopicPartitionList\")\n      end\n      tpl = list.to_native_tpl\n      response = Rdkafka::Bindings.rd_kafka_pause_partitions(@native_kafka, tpl)\n\n      if response != 0\n        list = TopicPartitionList.from_native_tpl(tpl)\n        raise Rdkafka::RdkafkaTopicPartitionListError.new(response, list, \"Error pausing '#{list.to_h}'\")\n      end\n    end", "label": 4}
{"code": "public function setBasicCard($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_BasicCard::class);\n        $this->writeOneof(8, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function setReadTimeWindow($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Asset\\V1beta1\\TimeWindow::class);\n        $this->read_time_window = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public void postConstruct(GeoService geoService, DtoConverterService converterService) throws GeomajasException {\n\t\tif (null == layerInfo) {\n\t\t\tlayerInfo = new RasterLayerInfo();\n\t\t}\n\t\tlayerInfo.setCrs(TiledRasterLayerService.MERCATOR);\n\t\tcrs = geoService.getCrs2(TiledRasterLayerService.MERCATOR);\n\t\tlayerInfo.setTileWidth(tileSize);\n\t\tlayerInfo.setTileHeight(tileSize);\n\t\tBbox bbox = new Bbox(-TiledRasterLayerService.HALF_EQUATOR_IN_METERS,\n\t\t\t\t-TiledRasterLayerService.HALF_EQUATOR_IN_METERS, TiledRasterLayerService.EQUATOR_IN_METERS,\n\t\t\t\tTiledRasterLayerService.EQUATOR_IN_METERS);\n\t\tlayerInfo.setMaxExtent(bbox);\n\t\tmaxBounds = converterService.toInternal(bbox);\n\n\t\tresolutions = new double[maxZoomLevel + 1];\n\t\tdouble powerOfTwo = 1;\n\t\tfor (int zoomLevel = 0; zoomLevel <= maxZoomLevel; zoomLevel++) {\n\t\t\tdouble resolution = (TiledRasterLayerService.EQUATOR_IN_METERS) / (tileSize * powerOfTwo);\n\t\t\tresolutions[zoomLevel] = resolution;\n\t\t\tpowerOfTwo *= 2;\n\t\t}\n\t}", "label": 0}
{"code": "def windows(*args)\n      all = @driver.window_handles.map { |handle| Window.new(self, handle: handle) }\n\n      if args.empty?\n        all\n      else\n        filter_windows extract_selector(args), all\n      end\n    end", "label": 4}
{"code": "func renameExpired(preparedExpiration time.Duration) error {\n\tif err := pkgPod.WalkPods(getDataDir(), pkgPod.IncludePreparedDir, func(p *pkgPod.Pod) {\n\t\tst := &syscall.Stat_t{}\n\t\tpp := p.Path()\n\t\tif err := syscall.Lstat(pp, st); err != nil {\n\t\t\tif err != syscall.ENOENT {\n\t\t\t\tstderr.PrintE(fmt.Sprintf(\"unable to stat %q, ignoring\", pp), err)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tif expiration := time.Unix(st.Ctim.Unix()).Add(preparedExpiration); time.Now().After(expiration) {\n\t\t\tstderr.Printf(\"moving expired prepared pod %q to garbage\", p.UUID)\n\t\t\tif err := p.ToGarbage(); err != nil && err != os.ErrNotExist {\n\t\t\t\tstderr.PrintE(\"rename error\", err)\n\t\t\t}\n\t\t}\n\t}); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def create_channel(data)\n      channel = Channel.new(data, self)\n      server = channel.server\n\n      # Handle normal and private channels separately\n      if server\n        server.add_channel(channel)\n        @channels[channel.id] = channel\n      elsif channel.pm?\n        @pm_channels[channel.recipient.id] = channel\n      elsif channel.group?\n        @channels[channel.id] = channel\n      end\n    end", "label": 4}
{"code": "def archive(*args)\n      arguments(args, required: [:user, :repo])\n      params         = arguments.params\n      archive_format = params.delete('archive_format') || 'tarball'\n      ref            = params.delete('ref') || 'master'\n\n      disable_redirects do\n        response = get_request(\"/repos/#{arguments.user}/#{arguments.repo}/#{archive_format}/#{ref}\", params)\n        response.headers.location\n      end\n    end", "label": 4}
{"code": "public void setModificationState(ModificationState newModificationState)\r\n    {\r\n        if(newModificationState != modificationState)\r\n        {\r\n            if(log.isDebugEnabled())\r\n            {\r\n                log.debug(\"object state transition for object \" + this.oid + \" (\"\r\n                        + modificationState + \" --> \" + newModificationState + \")\");\r\n//                try{throw new Exception();}catch(Exception e)\r\n//                {\r\n//                e.printStackTrace();\r\n//                }\r\n            }\r\n            modificationState = newModificationState;\r\n        }\r\n    }", "label": 0}
{"code": "public static base_response delete(nitro_service client, String labelname) throws Exception {\n\t\tdnspolicylabel deleteresource = new dnspolicylabel();\n\t\tdeleteresource.labelname = labelname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def config_option(name, default_value, options = {})\n      compiler      = options.fetch(:compiler_option, nil)\n      valid_values  = options.fetch(:valid_values, [true, false])\n\n      config_options[name] = {\n        default: default_value,\n        compiler: compiler\n      }\n\n      define_singleton_method(name) { config.fetch(name, default_value) }\n      define_singleton_method(\"#{name}=\") do |value|\n        unless valid_values.any? { |valid_value| valid_value === value }\n          raise ArgumentError, \"Not a valid value for option #{self}.#{name}, provided #{value.inspect}. \"\\\n                               \"Must be #{valid_values.inspect} === #{value.inspect}\"\n        end\n\n        config[name] = value\n      end\n    end", "label": 4}
{"code": "public function load()\n    {\n        $shmid = shm_attach($this->sysvKey, $this->shmSize, $this->perm);\n        if ($shmid === false) {\n            throw new \\RuntimeException(\n                'Failed to attach to the shared memory'\n            );\n        }\n        if (! shm_has_var($shmid, self::VAR_KEY)) {\n            $result = new JobConfig();\n        } else {\n            $result = shm_get_var($shmid, self::VAR_KEY);\n        }\n        shm_detach($shmid);\n\n        if ($result === false) {\n            throw new \\RuntimeException(\n                'Failed to deserialize data from shared memory'\n            );\n        }\n        return $result;\n    }", "label": 2}
{"code": "func NewWrapper(writer AccessPoint, cache ReadAccessPoint) AccessPoint {\n\treturn &Wrapper{\n\t\tWrite:           writer,\n\t\tReadAccessPoint: cache,\n\t}\n}", "label": 5}
{"code": "def text_area(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'text_area_for', &block)\n      define_method(name) do\n        return platform.text_area_value_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").value\n      end\n      define_method(\"#{name}=\") do |value|\n        return platform.text_area_value_set(identifier.clone, value) unless block_given?\n        self.send(\"#{name}_element\").value = value\n      end\n    end", "label": 4}
{"code": "def render_done(self, form, **kwargs):\n        \"\"\"\n        This method gets called when all forms passed. The method should also\n        re-validate all steps to prevent manipulation. If any form don't\n        validate, `render_revalidation_failure` should get called.\n        If everything is fine call `done`.\n        \"\"\"\n        final_form_list = []\n        # walk through the form list and try to validate the data again.\n        for form_key in self.get_form_list():\n            form_obj = self.get_form(step=form_key,\n                data=self.storage.get_step_data(form_key),\n                files=self.storage.get_step_files(form_key))\n            if not form_obj.is_valid():\n                return self.render_revalidation_failure(form_key, form_obj, **kwargs)\n            final_form_list.append(form_obj)\n\n        # render the done view and reset the wizard before returning the\n        # response. This is needed to prevent from rendering done with the\n        # same data twice.\n        done_response = self.done(final_form_list, **kwargs)\n        self.storage.reset()\n        return done_response", "label": 1}
{"code": "function(req, data, name, snippet, field, callback) {\n      var manager = self._pages.getManager(field.withType);\n      if (!manager) {\n        return callback(new Error('join with type ' + field.withType + ' unrecognized'));\n      }\n      var titleOrId = self._apos.sanitizeString(data[name]);\n      var criteria = { $or: [ { sortTitle: self._apos.sortify(titleOrId) }, { _id: titleOrId } ] };\n      return manager.get(req, criteria, { fields: { _id: 1 } }, function(err, results) {\n        if (err) {\n          return callback(err);\n        }\n        results = results.pages || results.snippets;\n        if (!results.length) {\n          return callback(null);\n        }\n        snippet[field.idField] = results[0]._id;\n        return callback(null);\n      });\n    }", "label": 3}
{"code": "function (clt_name, op, err, onFail, is_exception) {\n\n\tvar msg = 'DB ' + op + ' error for [' + clt_name + ']';\n\tLOG.error(msg, 'SR.DB');\n\tLOG.error(err, 'SR.DB');\n\tif (typeof err.stack !== 'undefined') {\n\t\tLOG.error(err.stack, 'SR.DB');\n\t\tmsg += ('\\n\\n' + err.stack);\n\t}\n\tUTIL.safeCall(onFail, err);\n\n\tif (is_exception) {\n\t\treturn;\n\t}\n\n\t// notify project admin if it's not code exception\n\t// NOTE: only project admins are notified\n\tUTIL.notifyAdmin(\n\t\t'[SR DB error: ' + clt_name + ']',\n\t\tmsg\n\t);\n}", "label": 3}
{"code": "def execute_command(name, event, arguments, chained = false, check_permissions = true)\n      debug(\"Executing command #{name} with arguments #{arguments}\")\n      return unless @commands\n\n      command = @commands[name]\n      command = command.aliased_command if command.is_a?(CommandAlias)\n      return unless !check_permissions || channels?(event.channel, @attributes[:channels]) ||\n                    (command && !command.attributes[:channels].nil?)\n\n      unless command\n        event.respond @attributes[:command_doesnt_exist_message].gsub('%command%', name.to_s) if @attributes[:command_doesnt_exist_message]\n        return\n      end\n      return unless !check_permissions || channels?(event.channel, command.attributes[:channels])\n\n      arguments = arg_check(arguments, command.attributes[:arg_types], event.server) if check_permissions\n      if (check_permissions &&\n         permission?(event.author, command.attributes[:permission_level], event.server) &&\n         required_permissions?(event.author, command.attributes[:required_permissions], event.channel) &&\n         required_roles?(event.author, command.attributes[:required_roles]) &&\n         allowed_roles?(event.author, command.attributes[:allowed_roles])) ||\n         !check_permissions\n        event.command = command\n        result = command.call(event, arguments, chained, check_permissions)\n        stringify(result)\n      else\n        event.respond command.attributes[:permission_message].gsub('%name%', name.to_s) if command.attributes[:permission_message]\n        nil\n      end\n    rescue Discordrb::Errors::NoPermission\n      event.respond @attributes[:no_permission_message] unless @attributes[:no_permission_message].nil?\n      raise\n    end", "label": 4}
{"code": "def detect_nexson_version(blob):\n    \"\"\"Returns the nexml2json attribute or the default code for badgerfish\"\"\"\n    n = get_nexml_el(blob)\n    assert isinstance(n, dict)\n    return n.get('@nexml2json', BADGER_FISH_NEXSON_VERSION)", "label": 1}
{"code": "def create_script_staging_table(self, output_table, col_list):\n        \"\"\"\n        appends the CREATE TABLE, index etc to another table\n        \"\"\"\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += '-- CREATE Staging Table - ' + output_table + '\\n'\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += 'DROP TABLE ' + output_table + ' CASCADE CONSTRAINTS;\\n'\n        self.ddl_text += 'CREATE TABLE ' + output_table + ' (\\n  '\n        self.ddl_text += '  '.join([col + ' VARCHAR2(200), \\n' for col in col_list])\n        self.ddl_text += '  ' + self.date_updated_col + ' DATE \\n' # + src_table + '; \\n'\n        self.ddl_text += ');\\n'", "label": 1}
{"code": "func (s *PresenceService) UpsertReverseTunnel(tunnel services.ReverseTunnel) error {\n\tif err := tunnel.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tvalue, err := services.GetReverseTunnelMarshaler().MarshalReverseTunnel(tunnel)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = s.Put(context.TODO(), backend.Item{\n\t\tKey:     backend.Key(reverseTunnelsPrefix, tunnel.GetName()),\n\t\tValue:   value,\n\t\tExpires: tunnel.Expiry(),\n\t\tID:      tunnel.GetResourceID(),\n\t})\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "function _setClass(el, className) {\n    el instanceof SVGElement ?\n        el.setAttribute('class', className) :\n        el.className = className;\n}", "label": 3}
{"code": "function convertAllObjectIdsToString(form) {\n  form._id = form._id ? form._id.toString() : form._id;\n  form.pages = _.map(form.pages, function(page) {\n    page._id = page._id ? page._id.toString() : page._id;\n\n    page.fields = _.map(page.fields, function(field) {\n      field._id = field._id ? field._id.toString() : field._id;\n      return field;\n    });\n\n    return page;\n  });\n  return form;\n}", "label": 3}
{"code": "public function setConditionAbsent($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\AlertPolicy_Condition_MetricAbsence::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function formatJsonTrace(level, context, message, args, err) {\n  return formatJsonTrace.stringify(formatJsonTrace.toObject(level, context, message, args, err));\n}", "label": 3}
{"code": "func NewAuthPreference(spec AuthPreferenceSpecV2) (AuthPreference, error) {\n\treturn &AuthPreferenceV2{\n\t\tKind:    KindClusterAuthPreference,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName:      MetaNameClusterAuthPreference,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: spec,\n\t}, nil\n}", "label": 5}
{"code": "public static function init(PsrLogger $psrLogger = null)\n    {\n        self::$psrLogger = $psrLogger ?: (new LoggingClient())\n            ->psrLogger(self::DEFAULT_LOGNAME, [\n                'batchEnabled' => true,\n                'debugOutput' => true,\n                'batchOptions' => [\n                    'numWorkers' => 2\n                ]\n            ]);\n        register_shutdown_function([self::class, 'shutdownHandler']);\n        set_exception_handler([self::class, 'exceptionHandler']);\n        set_error_handler([self::class, 'errorHandler']);\n    }", "label": 2}
{"code": "function(context, parentPkg, childPkg, isRoot){\n\t\tvar pkg = parentPkg;\n\t\tvar isFlat = context.isFlatFileStructure;\n\n\t\t// if a peer dependency, and not isRoot\n\t\tif(childPkg._isPeerDependency && !isRoot ) {\n\t\t\t// check one node_module level higher\n\t\t\tchildPkg.origFileUrl = nodeModuleAddress(pkg.fileUrl)+\"/\"+childPkg.name+\"/package.json\";\n\t\t} else if(isRoot) {\n\t\t\tchildPkg.origFileUrl = utils.path.depPackage(pkg.fileUrl, childPkg.name);\n\t\t} else {\n\t\t\t// npm 2\n\t\t\tchildPkg.origFileUrl = childPkg.nestedFileUrl =\n\t\t\t\tutils.path.depPackage(pkg.fileUrl, childPkg.name);\n\n\t\t\tif(isFlat) {\n\t\t\t\t// npm 3\n\t\t\t\tchildPkg.origFileUrl = crawl.parentMostAddress(context,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   childPkg);\n\t\t\t}\n\t\t}\n\n\t\t// check if childPkg matches a parent's version ... if it\n\t\t// does ... do nothing\n\t\tif(crawl.hasParentPackageThatMatches(context, childPkg)) {\n\t\t\treturn;\n\t\t}\n\n\t\tif(crawl.isSameRequestedVersionFound(context, childPkg)) {\n\t\t\treturn;\n\t\t}\n\n\t\tvar requestedVersion = childPkg.version;\n\t\treturn npmLoad(context, childPkg, requestedVersion)\n\t\t.then(function(pkg){\n\t\t\tcrawl.setVersionsConfig(context, pkg, requestedVersion);\n\t\t\treturn pkg;\n\t\t});\n\t}", "label": 3}
{"code": "public function validate_assoc( $assoc_args ) {\n\t\t$assoc_spec = $this->query_spec(\n\t\t\tarray(\n\t\t\t\t'type' => 'assoc',\n\t\t\t)\n\t\t);\n\n\t\t$errors = array(\n\t\t\t'fatal'   => array(),\n\t\t\t'warning' => array(),\n\t\t);\n\n\t\t$to_unset = array();\n\n\t\tforeach ( $assoc_spec as $param ) {\n\t\t\t$key = $param['name'];\n\n\t\t\tif ( ! isset( $assoc_args[ $key ] ) ) {\n\t\t\t\tif ( ! $param['optional'] ) {\n\t\t\t\t\t$errors['fatal'][ $key ] = \"missing --$key parameter\";\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif ( true === $assoc_args[ $key ] && ! $param['value']['optional'] ) {\n\t\t\t\t\t$error_type                    = ( ! $param['optional'] ) ? 'fatal' : 'warning';\n\t\t\t\t\t$errors[ $error_type ][ $key ] = \"--$key parameter needs a value\";\n\n\t\t\t\t\t$to_unset[] = $key;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn array( $errors, $to_unset );\n\t}", "label": 2}
{"code": "function emitFiles(resolver, host, targetSourceFile, emitOnlyDtsFiles) {\n        // emit output for the __extends helper function\n        var extendsHelper = \"\\nvar __extends = (this && this.__extends) || function (d, b) {\\n    for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\\n    function __() { this.constructor = d; }\\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\\n};\";\n        var assignHelper = \"\\nvar __assign = (this && this.__assign) || Object.assign || function(t) {\\n    for (var s, i = 1, n = arguments.length; i < n; i++) {\\n        s = arguments[i];\\n        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\\n            t[p] = s[p];\\n    }\\n    return t;\\n};\";\n        // emit output for the __decorate helper function\n        var decorateHelper = \"\\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\\n    if (typeof Reflect === \\\"object\\\" && typeof Reflect.decorate === \\\"function\\\") r = Reflect.decorate(decorators, target, key, desc);\\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\\n};\";\n        // emit output for the __metadata helper function\n        var metadataHelper = \"\\nvar __metadata = (this && this.__metadata) || function (k, v) {\\n    if (typeof Reflect === \\\"object\\\" && typeof Reflect.metadata === \\\"function\\\") return Reflect.metadata(k, v);\\n};\";\n        // emit output for the __param helper function\n        var paramHelper = \"\\nvar __param = (this && this.__param) || function (paramIndex, decorator) {\\n    return function (target, key) { decorator(target, key, paramIndex); }\\n};\";\n        var awaiterHelper = \"\\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\\n    return new (P || (P = Promise))(function (resolve, reject) {\\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\\n        function rejected(value) { try { step(generator.throw(value)); } catch (e) { reject(e); } }\\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\\n        step((generator = generator.apply(thisArg, _arguments)).next());\\n    });\\n};\";\n        var compilerOptions = host.getCompilerOptions();\n        var languageVersion = ts.getEmitScriptTarget(compilerOptions);\n        var modulekind = ts.getEmitModuleKind(compilerOptions);\n        var sourceMapDataList = compilerOptions.sourceMap || compilerOptions.inlineSourceMap ? [] : undefined;\n        var emittedFilesList = compilerOptions.listEmittedFiles ? [] : undefined;\n        var emitterDiagnostics = ts.createDiagnosticCollection();\n        var emitSkipped = false;\n        var newLine = host.getNewLine();\n        var emitJavaScript = createFileEmitter();\n        ts.forEachExpectedEmitFile(host, emitFile, targetSourceFile, emitOnlyDtsFiles);\n        return {\n            emitSkipped: emitSkipped,\n            diagnostics: emitterDiagnostics.getDiagnostics(),\n            emittedFiles: emittedFilesList,\n            sourceMaps: sourceMapDataList\n        };\n        function isUniqueLocalName(name, container) {\n            for (var node = container; ts.isNodeDescendentOf(node, container); node = node.nextContainer) {\n                if (node.locals && name in node.locals) {\n                    // We conservatively include alias symbols to cover cases where they're emitted as locals\n                    if (node.locals[name].flags & (107455 /* Value */ | 1048576 /* ExportValue */ | 8388608 /* Alias */)) {\n                        return false;\n                    }\n                }\n            }\n            return true;\n        }\n        function setLabeledJump(state, isBreak, labelText, labelMarker) {\n            if (isBreak) {\n                if (!state.labeledNonLocalBreaks) {\n                    state.labeledNonLocalBreaks = ts.createMap();\n                }\n                state.labeledNonLocalBreaks[labelText] = labelMarker;\n            }\n            else {\n                if (!state.labeledNonLocalContinues) {\n                    state.labeledNonLocalContinues = ts.createMap();\n                }\n                state.labeledNonLocalContinues[labelText] = labelMarker;\n            }\n        }\n        function hoistVariableDeclarationFromLoop(state, declaration) {\n            if (!state.hoistedLocalVariables) {\n                state.hoistedLocalVariables = [];\n            }\n            visit(declaration.name);\n            function visit(node) {\n                if (node.kind === 69 /* Identifier */) {\n                    state.hoistedLocalVariables.push(node);\n                }\n                else {\n                    for (var _a = 0, _b = node.elements; _a < _b.length; _a++) {\n                        var element = _b[_a];\n                        visit(element.name);\n                    }\n                }\n            }\n        }\n        function createFileEmitter() {\n            var writer = ts.createTextWriter(newLine);\n            var write = writer.write, writeTextOfNode = writer.writeTextOfNode, writeLine = writer.writeLine, increaseIndent = writer.increaseIndent, decreaseIndent = writer.decreaseIndent;\n            var sourceMap = compilerOptions.sourceMap || compilerOptions.inlineSourceMap ? ts.createSourceMapWriter(host, writer) : ts.getNullSourceMapWriter();\n            var setSourceFile = sourceMap.setSourceFile, emitStart = sourceMap.emitStart, emitEnd = sourceMap.emitEnd, emitPos = sourceMap.emitPos;\n            var currentSourceFile;\n            var currentText;\n            var currentLineMap;\n            var currentFileIdentifiers;\n            var renamedDependencies;\n            var isEs6Module;\n            var isCurrentFileExternalModule;\n            // name of an exporter function if file is a System external module\n            // System.register([...], function (<exporter>) {...})\n            // exporting in System modules looks like:\n            // export var x; ... x = 1\n            // =>\n            // var x;... exporter(\"x\", x = 1)\n            var exportFunctionForFile;\n            var contextObjectForFile;\n            var generatedNameSet;\n            var nodeToGeneratedName;\n            var computedPropertyNamesToGeneratedNames;\n            var decoratedClassAliases;\n            var convertedLoopState;\n            var extendsEmitted;\n            var assignEmitted;\n            var decorateEmitted;\n            var paramEmitted;\n            var awaiterEmitted;\n            var tempFlags = 0;\n            var tempVariables;\n            var tempParameters;\n            var externalImports;\n            var exportSpecifiers;\n            var exportEquals;\n            var hasExportStarsToExportValues;\n            var detachedCommentsInfo;\n            /** Sourcemap data that will get encoded */\n            var sourceMapData;\n            /** Is the file being emitted into its own file */\n            var isOwnFileEmit;\n            /** If removeComments is true, no leading-comments needed to be emitted **/\n            var emitLeadingCommentsOfPosition = compilerOptions.removeComments ? function (pos) { } : emitLeadingCommentsOfPositionWorker;\n            var setSourceMapWriterEmit = compilerOptions.sourceMap || compilerOptions.inlineSourceMap ? changeSourceMapEmit : function (writer) { };\n            var moduleEmitDelegates = ts.createMap((_a = {},\n                _a[ts.ModuleKind.ES6] = emitES6Module,\n                _a[ts.ModuleKind.AMD] = emitAMDModule,\n                _a[ts.ModuleKind.System] = emitSystemModule,\n                _a[ts.ModuleKind.UMD] = emitUMDModule,\n                _a[ts.ModuleKind.CommonJS] = emitCommonJSModule,\n                _a\n            ));\n            var bundleEmitDelegates = ts.createMap((_b = {},\n                _b[ts.ModuleKind.ES6] = function () { },\n                _b[ts.ModuleKind.AMD] = emitAMDModule,\n                _b[ts.ModuleKind.System] = emitSystemModule,\n                _b[ts.ModuleKind.UMD] = function () { },\n                _b[ts.ModuleKind.CommonJS] = function () { },\n                _b\n            ));\n            return doEmit;\n            function doEmit(jsFilePath, sourceMapFilePath, sourceFiles, isBundledEmit) {\n                sourceMap.initialize(jsFilePath, sourceMapFilePath, sourceFiles, isBundledEmit);\n                generatedNameSet = ts.createMap();\n                nodeToGeneratedName = [];\n                decoratedClassAliases = [];\n                isOwnFileEmit = !isBundledEmit;\n                // Emit helpers from all the files\n                if (isBundledEmit && modulekind) {\n                    ts.forEach(sourceFiles, emitEmitHelpers);\n                }\n                // Do not call emit directly. It does not set the currentSourceFile.\n                ts.forEach(sourceFiles, emitSourceFile);\n                writeLine();\n                var sourceMappingURL = sourceMap.getSourceMappingURL();\n                if (sourceMappingURL) {\n                    write(\"//# \" + \"sourceMappingURL\" + \"=\" + sourceMappingURL); // Sometimes tools can sometimes see this line as a source mapping url comment\n                }\n                writeEmittedFiles(writer.getText(), jsFilePath, sourceMapFilePath, /*writeByteOrderMark*/ compilerOptions.emitBOM, sourceFiles);\n                // reset the state\n                sourceMap.reset();\n                writer.reset();\n                currentSourceFile = undefined;\n                currentText = undefined;\n                currentLineMap = undefined;\n                exportFunctionForFile = undefined;\n                contextObjectForFile = undefined;\n                generatedNameSet = undefined;\n                nodeToGeneratedName = undefined;\n                decoratedClassAliases = undefined;\n                computedPropertyNamesToGeneratedNames = undefined;\n                convertedLoopState = undefined;\n                extendsEmitted = false;\n                decorateEmitted = false;\n                paramEmitted = false;\n                awaiterEmitted = false;\n                assignEmitted = false;\n                tempFlags = 0;\n                tempVariables = undefined;\n                tempParameters = undefined;\n                externalImports = undefined;\n                exportSpecifiers = undefined;\n                exportEquals = undefined;\n                hasExportStarsToExportValues = undefined;\n                detachedCommentsInfo = undefined;\n                sourceMapData = undefined;\n                isEs6Module = false;\n                renamedDependencies = undefined;\n                isCurrentFileExternalModule = false;\n            }\n            function emitSourceFile(sourceFile) {\n                currentSourceFile = sourceFile;\n                currentText = sourceFile.text;\n                currentLineMap = ts.getLineStarts(sourceFile);\n                exportFunctionForFile = undefined;\n                contextObjectForFile = undefined;\n                isEs6Module = sourceFile.symbol && sourceFile.symbol.exports && !!sourceFile.symbol.exports[\"___esModule\"];\n                renamedDependencies = sourceFile.renamedDependencies;\n                currentFileIdentifiers = sourceFile.identifiers;\n                isCurrentFileExternalModule = ts.isExternalModule(sourceFile);\n                setSourceFile(sourceFile);\n                emitNodeWithCommentsAndWithoutSourcemap(sourceFile);\n            }\n            function isUniqueName(name) {\n                return !resolver.hasGlobalName(name) &&\n                    !(name in currentFileIdentifiers) &&\n                    !(name in generatedNameSet);\n            }\n            // Return the next available name in the pattern _a ... _z, _0, _1, ...\n            // TempFlags._i or TempFlags._n may be used to express a preference for that dedicated name.\n            // Note that names generated by makeTempVariableName and makeUniqueName will never conflict.\n            function makeTempVariableName(flags) {\n                if (flags && !(tempFlags & flags)) {\n                    var name_24 = flags === 268435456 /* _i */ ? \"_i\" : \"_n\";\n                    if (isUniqueName(name_24)) {\n                        tempFlags |= flags;\n                        return name_24;\n                    }\n                }\n                while (true) {\n                    var count = tempFlags & 268435455 /* CountMask */;\n                    tempFlags++;\n                    // Skip over 'i' and 'n'\n                    if (count !== 8 && count !== 13) {\n                        var name_25 = count < 26 ? \"_\" + String.fromCharCode(97 /* a */ + count) : \"_\" + (count - 26);\n                        if (isUniqueName(name_25)) {\n                            return name_25;\n                        }\n                    }\n                }\n            }\n            // Generate a name that is unique within the current file and doesn't conflict with any names\n            // in global scope. The name is formed by adding an '_n' suffix to the specified base name,\n            // where n is a positive integer. Note that names generated by makeTempVariableName and\n            // makeUniqueName are guaranteed to never conflict.\n            function makeUniqueName(baseName) {\n                // Find the first unique 'name_n', where n is a positive number\n                if (baseName.charCodeAt(baseName.length - 1) !== 95 /* _ */) {\n                    baseName += \"_\";\n                }\n                var i = 1;\n                while (true) {\n                    var generatedName = baseName + i;\n                    if (isUniqueName(generatedName)) {\n                        return generatedNameSet[generatedName] = generatedName;\n                    }\n                    i++;\n                }\n            }\n            function generateNameForModuleOrEnum(node) {\n                var name = node.name.text;\n                // Use module/enum name itself if it is unique, otherwise make a unique variation\n                return isUniqueLocalName(name, node) ? name : makeUniqueName(name);\n            }\n            function generateNameForImportOrExportDeclaration(node) {\n                var expr = ts.getExternalModuleName(node);\n                var baseName = expr.kind === 9 /* StringLiteral */ ?\n                    ts.escapeIdentifier(ts.makeIdentifierFromModuleName(expr.text)) : \"module\";\n                return makeUniqueName(baseName);\n            }\n            function generateNameForExportDefault() {\n                return makeUniqueName(\"default\");\n            }\n            function generateNameForClassExpression() {\n                return makeUniqueName(\"class\");\n            }\n            function generateNameForNode(node) {\n                switch (node.kind) {\n                    case 69 /* Identifier */:\n                        return makeUniqueName(node.text);\n                    case 225 /* ModuleDeclaration */:\n                    case 224 /* EnumDeclaration */:\n                        return generateNameForModuleOrEnum(node);\n                    case 230 /* ImportDeclaration */:\n                    case 236 /* ExportDeclaration */:\n                        return generateNameForImportOrExportDeclaration(node);\n                    case 220 /* FunctionDeclaration */:\n                    case 221 /* ClassDeclaration */:\n                    case 235 /* ExportAssignment */:\n                        return generateNameForExportDefault();\n                    case 192 /* ClassExpression */:\n                        return generateNameForClassExpression();\n                    default:\n                        ts.Debug.fail();\n                }\n            }\n            function getGeneratedNameForNode(node) {\n                var id = ts.getNodeId(node);\n                return nodeToGeneratedName[id] || (nodeToGeneratedName[id] = ts.unescapeIdentifier(generateNameForNode(node)));\n            }\n            /** Write emitted output to disk */\n            function writeEmittedFiles(emitOutput, jsFilePath, sourceMapFilePath, writeByteOrderMark, sourceFiles) {\n                if (compilerOptions.sourceMap && !compilerOptions.inlineSourceMap) {\n                    ts.writeFile(host, emitterDiagnostics, sourceMapFilePath, sourceMap.getText(), /*writeByteOrderMark*/ false, sourceFiles);\n                }\n                if (sourceMapDataList) {\n                    sourceMapDataList.push(sourceMap.getSourceMapData());\n                }\n                ts.writeFile(host, emitterDiagnostics, jsFilePath, emitOutput, writeByteOrderMark, sourceFiles);\n            }\n            // Create a temporary variable with a unique unused name.\n            function createTempVariable(flags) {\n                var result = ts.createSynthesizedNode(69 /* Identifier */);\n                result.text = makeTempVariableName(flags);\n                return result;\n            }\n            function recordTempDeclaration(name) {\n                if (!tempVariables) {\n                    tempVariables = [];\n                }\n                tempVariables.push(name);\n            }\n            function createAndRecordTempVariable(flags) {\n                var temp = createTempVariable(flags);\n                recordTempDeclaration(temp);\n                return temp;\n            }\n            function emitTempDeclarations(newLine) {\n                if (tempVariables) {\n                    if (newLine) {\n                        writeLine();\n                    }\n                    else {\n                        write(\" \");\n                    }\n                    write(\"var \");\n                    emitCommaList(tempVariables);\n                    write(\";\");\n                }\n            }\n            /** Emit the text for the given token that comes after startPos\n              * This by default writes the text provided with the given tokenKind\n              * but if optional emitFn callback is provided the text is emitted using the callback instead of default text\n              * @param tokenKind the kind of the token to search and emit\n              * @param startPos the position in the source to start searching for the token\n              * @param emitFn if given will be invoked to emit the text instead of actual token emit */\n            function emitToken(tokenKind, startPos, emitFn) {\n                var tokenStartPos = ts.skipTrivia(currentText, startPos);\n                emitPos(tokenStartPos);\n                var tokenString = ts.tokenToString(tokenKind);\n                if (emitFn) {\n                    emitFn();\n                }\n                else {\n                    write(tokenString);\n                }\n                var tokenEndPos = tokenStartPos + tokenString.length;\n                emitPos(tokenEndPos);\n                return tokenEndPos;\n            }\n            function emitOptional(prefix, node) {\n                if (node) {\n                    write(prefix);\n                    emit(node);\n                }\n            }\n            function emitParenthesizedIf(node, parenthesized) {\n                if (parenthesized) {\n                    write(\"(\");\n                }\n                emit(node);\n                if (parenthesized) {\n                    write(\")\");\n                }\n            }\n            function emitLinePreservingList(parent, nodes, allowTrailingComma, spacesBetweenBraces) {\n                ts.Debug.assert(nodes.length > 0);\n                increaseIndent();\n                if (nodeStartPositionsAreOnSameLine(parent, nodes[0])) {\n                    if (spacesBetweenBraces) {\n                        write(\" \");\n                    }\n                }\n                else {\n                    writeLine();\n                }\n                for (var i = 0, n = nodes.length; i < n; i++) {\n                    if (i) {\n                        if (nodeEndIsOnSameLineAsNodeStart(nodes[i - 1], nodes[i])) {\n                            write(\", \");\n                        }\n                        else {\n                            write(\",\");\n                            writeLine();\n                        }\n                    }\n                    emit(nodes[i]);\n                }\n                if (nodes.hasTrailingComma && allowTrailingComma) {\n                    write(\",\");\n                }\n                decreaseIndent();\n                if (nodeEndPositionsAreOnSameLine(parent, ts.lastOrUndefined(nodes))) {\n                    if (spacesBetweenBraces) {\n                        write(\" \");\n                    }\n                }\n                else {\n                    writeLine();\n                }\n            }\n            function emitList(nodes, start, count, multiLine, trailingComma, leadingComma, noTrailingNewLine, emitNode) {\n                if (!emitNode) {\n                    emitNode = emit;\n                }\n                for (var i = 0; i < count; i++) {\n                    if (multiLine) {\n                        if (i || leadingComma) {\n                            write(\",\");\n                        }\n                        writeLine();\n                    }\n                    else {\n                        if (i || leadingComma) {\n                            write(\", \");\n                        }\n                    }\n                    var node = nodes[start + i];\n                    // This emitting is to make sure we emit following comment properly\n                    //   ...(x, /*comment1*/ y)...\n                    //         ^ => node.pos\n                    // \"comment1\" is not considered leading comment for \"y\" but rather\n                    // considered as trailing comment of the previous node.\n                    emitTrailingCommentsOfPosition(node.pos);\n                    emitNode(node);\n                    leadingComma = true;\n                }\n                if (trailingComma) {\n                    write(\",\");\n                }\n                if (multiLine && !noTrailingNewLine) {\n                    writeLine();\n                }\n                return count;\n            }\n            function emitCommaList(nodes) {\n                if (nodes) {\n                    emitList(nodes, 0, nodes.length, /*multiLine*/ false, /*trailingComma*/ false);\n                }\n            }\n            function emitLines(nodes) {\n                emitLinesStartingAt(nodes, /*startIndex*/ 0);\n            }\n            function emitLinesStartingAt(nodes, startIndex) {\n                for (var i = startIndex; i < nodes.length; i++) {\n                    writeLine();\n                    emit(nodes[i]);\n                }\n            }\n            function isBinaryOrOctalIntegerLiteral(node, text) {\n                if (node.kind === 8 /* NumericLiteral */ && text.length > 1) {\n                    switch (text.charCodeAt(1)) {\n                        case 98 /* b */:\n                        case 66 /* B */:\n                        case 111 /* o */:\n                        case 79 /* O */:\n                            return true;\n                    }\n                }\n                return false;\n            }\n            function emitLiteral(node) {\n                var text = getLiteralText(node);\n                if ((compilerOptions.sourceMap || compilerOptions.inlineSourceMap) && (node.kind === 9 /* StringLiteral */ || ts.isTemplateLiteralKind(node.kind))) {\n                    writer.writeLiteral(text);\n                }\n                else if (languageVersion < 2 /* ES6 */ && isBinaryOrOctalIntegerLiteral(node, text)) {\n                    write(node.text);\n                }\n                else {\n                    write(text);\n                }\n            }\n            function getLiteralText(node) {\n                // Any template literal or string literal with an extended escape\n                // (e.g. \"\\u{0067}\") will need to be downleveled as a escaped string literal.\n                if (languageVersion < 2 /* ES6 */ && (ts.isTemplateLiteralKind(node.kind) || node.hasExtendedUnicodeEscape)) {\n                    return getQuotedEscapedLiteralText('\"', node.text, '\"');\n                }\n                // If we don't need to downlevel and we can reach the original source text using\n                // the node's parent reference, then simply get the text as it was originally written.\n                if (node.parent) {\n                    return ts.getTextOfNodeFromSourceText(currentText, node);\n                }\n                // If we can't reach the original source text, use the canonical form if it's a number,\n                // or an escaped quoted form of the original text if it's string-like.\n                switch (node.kind) {\n                    case 9 /* StringLiteral */:\n                        return getQuotedEscapedLiteralText('\"', node.text, '\"');\n                    case 11 /* NoSubstitutionTemplateLiteral */:\n                        return getQuotedEscapedLiteralText(\"`\", node.text, \"`\");\n                    case 12 /* TemplateHead */:\n                        return getQuotedEscapedLiteralText(\"`\", node.text, \"${\");\n                    case 13 /* TemplateMiddle */:\n                        return getQuotedEscapedLiteralText(\"}\", node.text, \"${\");\n                    case 14 /* TemplateTail */:\n                        return getQuotedEscapedLiteralText(\"}\", node.text, \"`\");\n                    case 8 /* NumericLiteral */:\n                        return node.text;\n                }\n                ts.Debug.fail(\"Literal kind '\" + node.kind + \"' not accounted for.\");\n            }\n            function getQuotedEscapedLiteralText(leftQuote, text, rightQuote) {\n                return leftQuote + ts.escapeNonAsciiCharacters(ts.escapeString(text)) + rightQuote;\n            }\n            function emitDownlevelRawTemplateLiteral(node) {\n                // Find original source text, since we need to emit the raw strings of the tagged template.\n                // The raw strings contain the (escaped) strings of what the user wrote.\n                // Examples: `\\n` is converted to \"\\\\n\", a template string with a newline to \"\\n\".\n                var text = ts.getTextOfNodeFromSourceText(currentText, node);\n                // text contains the original source, it will also contain quotes (\"`\"), dollar signs and braces (\"${\" and \"}\"),\n                // thus we need to remove those characters.\n                // First template piece starts with \"`\", others with \"}\"\n                // Last template piece ends with \"`\", others with \"${\"\n                var isLast = node.kind === 11 /* NoSubstitutionTemplateLiteral */ || node.kind === 14 /* TemplateTail */;\n                text = text.substring(1, text.length - (isLast ? 1 : 2));\n                // Newline normalization:\n                // ES6 Spec 11.8.6.1 - Static Semantics of TV's and TRV's\n                // <CR><LF> and <CR> LineTerminatorSequences are normalized to <LF> for both TV and TRV.\n                text = text.replace(/\\r\\n?/g, \"\\n\");\n                text = ts.escapeString(text);\n                write(\"\\\"\" + text + \"\\\"\");\n            }\n            function emitDownlevelTaggedTemplateArray(node, literalEmitter) {\n                write(\"[\");\n                if (node.template.kind === 11 /* NoSubstitutionTemplateLiteral */) {\n                    literalEmitter(node.template);\n                }\n                else {\n                    literalEmitter(node.template.head);\n                    ts.forEach(node.template.templateSpans, function (child) {\n                        write(\", \");\n                        literalEmitter(child.literal);\n                    });\n                }\n                write(\"]\");\n            }\n            function emitDownlevelTaggedTemplate(node) {\n                var tempVariable = createAndRecordTempVariable(0 /* Auto */);\n                write(\"(\");\n                emit(tempVariable);\n                write(\" = \");\n                emitDownlevelTaggedTemplateArray(node, emit);\n                write(\", \");\n                emit(tempVariable);\n                write(\".raw = \");\n                emitDownlevelTaggedTemplateArray(node, emitDownlevelRawTemplateLiteral);\n                write(\", \");\n                emitParenthesizedIf(node.tag, needsParenthesisForPropertyAccessOrInvocation(node.tag));\n                write(\"(\");\n                emit(tempVariable);\n                // Now we emit the expressions\n                if (node.template.kind === 189 /* TemplateExpression */) {\n                    ts.forEach(node.template.templateSpans, function (templateSpan) {\n                        write(\", \");\n                        var needsParens = templateSpan.expression.kind === 187 /* BinaryExpression */\n                            && templateSpan.expression.operatorToken.kind === 24 /* CommaToken */;\n                        emitParenthesizedIf(templateSpan.expression, needsParens);\n                    });\n                }\n                write(\"))\");\n            }\n            function emitTemplateExpression(node) {\n                // In ES6 mode and above, we can simply emit each portion of a template in order, but in\n                // ES3 & ES5 we must convert the template expression into a series of string concatenations.\n                if (languageVersion >= 2 /* ES6 */) {\n                    ts.forEachChild(node, emit);\n                    return;\n                }\n                var emitOuterParens = ts.isExpression(node.parent)\n                    && templateNeedsParens(node, node.parent);\n                if (emitOuterParens) {\n                    write(\"(\");\n                }\n                var headEmitted = false;\n                if (shouldEmitTemplateHead()) {\n                    emitLiteral(node.head);\n                    headEmitted = true;\n                }\n                for (var i = 0, n = node.templateSpans.length; i < n; i++) {\n                    var templateSpan = node.templateSpans[i];\n                    // Check if the expression has operands and binds its operands less closely than binary '+'.\n                    // If it does, we need to wrap the expression in parentheses. Otherwise, something like\n                    //    `abc${ 1 << 2 }`\n                    // becomes\n                    //    \"abc\" + 1 << 2 + \"\"\n                    // which is really\n                    //    (\"abc\" + 1) << (2 + \"\")\n                    // rather than\n                    //    \"abc\" + (1 << 2) + \"\"\n                    var needsParens = templateSpan.expression.kind !== 178 /* ParenthesizedExpression */\n                        && comparePrecedenceToBinaryPlus(templateSpan.expression) !== 1 /* GreaterThan */;\n                    if (i > 0 || headEmitted) {\n                        // If this is the first span and the head was not emitted, then this templateSpan's\n                        // expression will be the first to be emitted. Don't emit the preceding ' + ' in that\n                        // case.\n                        write(\" + \");\n                    }\n                    emitParenthesizedIf(templateSpan.expression, needsParens);\n                    // Only emit if the literal is non-empty.\n                    // The binary '+' operator is left-associative, so the first string concatenation\n                    // with the head will force the result up to this point to be a string.\n                    // Emitting a '+ \"\"' has no semantic effect for middles and tails.\n                    if (templateSpan.literal.text.length !== 0) {\n                        write(\" + \");\n                        emitLiteral(templateSpan.literal);\n                    }\n                }\n                if (emitOuterParens) {\n                    write(\")\");\n                }\n                function shouldEmitTemplateHead() {\n                    // If this expression has an empty head literal and the first template span has a non-empty\n                    // literal, then emitting the empty head literal is not necessary.\n                    //     `${ foo } and ${ bar }`\n                    // can be emitted as\n                    //     foo + \" and \" + bar\n                    // This is because it is only required that one of the first two operands in the emit\n                    // output must be a string literal, so that the other operand and all following operands\n                    // are forced into strings.\n                    //\n                    // If the first template span has an empty literal, then the head must still be emitted.\n                    //     `${ foo }${ bar }`\n                    // must still be emitted as\n                    //     \"\" + foo + bar\n                    // There is always atleast one templateSpan in this code path, since\n                    // NoSubstitutionTemplateLiterals are directly emitted via emitLiteral()\n                    ts.Debug.assert(node.templateSpans.length !== 0);\n                    return node.head.text.length !== 0 || node.templateSpans[0].literal.text.length === 0;\n                }\n                function templateNeedsParens(template, parent) {\n                    switch (parent.kind) {\n                        case 174 /* CallExpression */:\n                        case 175 /* NewExpression */:\n                            return parent.expression === template;\n                        case 176 /* TaggedTemplateExpression */:\n                        case 178 /* ParenthesizedExpression */:\n                            return false;\n                        default:\n                            return comparePrecedenceToBinaryPlus(parent) !== -1 /* LessThan */;\n                    }\n                }\n                /**\n                 * Returns whether the expression has lesser, greater,\n                 * or equal precedence to the binary '+' operator\n                 */\n                function comparePrecedenceToBinaryPlus(expression) {\n                    // All binary expressions have lower precedence than '+' apart from '*', '/', and '%'\n                    // which have greater precedence and '-' which has equal precedence.\n                    // All unary operators have a higher precedence apart from yield.\n                    // Arrow functions and conditionals have a lower precedence,\n                    // although we convert the former into regular function expressions in ES5 mode,\n                    // and in ES6 mode this function won't get called anyway.\n                    //\n                    // TODO (drosen): Note that we need to account for the upcoming 'yield' and\n                    //                spread ('...') unary operators that are anticipated for ES6.\n                    switch (expression.kind) {\n                        case 187 /* BinaryExpression */:\n                            switch (expression.operatorToken.kind) {\n                                case 37 /* AsteriskToken */:\n                                case 39 /* SlashToken */:\n                                case 40 /* PercentToken */:\n                                    return 1 /* GreaterThan */;\n                                case 35 /* PlusToken */:\n                                case 36 /* MinusToken */:\n                                    return 0 /* EqualTo */;\n                                default:\n                                    return -1 /* LessThan */;\n                            }\n                        case 190 /* YieldExpression */:\n                        case 188 /* ConditionalExpression */:\n                            return -1 /* LessThan */;\n                        default:\n                            return 1 /* GreaterThan */;\n                    }\n                }\n            }\n            function emitTemplateSpan(span) {\n                emit(span.expression);\n                emit(span.literal);\n            }\n            function jsxEmitReact(node) {\n                /// Emit a tag name, which is either '\"div\"' for lower-cased names, or\n                /// 'Div' for upper-cased or dotted names\n                function emitTagName(name) {\n                    if (name.kind === 69 /* Identifier */ && ts.isIntrinsicJsxName(name.text)) {\n                        write('\"');\n                        emit(name);\n                        write('\"');\n                    }\n                    else {\n                        emit(name);\n                    }\n                }\n                /// Emit an attribute name, which is quoted if it needs to be quoted. Because\n                /// these emit into an object literal property name, we don't need to be worried\n                /// about keywords, just non-identifier characters\n                function emitAttributeName(name) {\n                    if (/^[A-Za-z_]\\w*$/.test(name.text)) {\n                        emit(name);\n                    }\n                    else {\n                        write('\"');\n                        emit(name);\n                        write('\"');\n                    }\n                }\n                /// Emit an name/value pair for an attribute (e.g. \"x: 3\")\n                function emitJsxAttribute(node) {\n                    emitAttributeName(node.name);\n                    write(\": \");\n                    if (node.initializer) {\n                        emit(node.initializer);\n                    }\n                    else {\n                        write(\"true\");\n                    }\n                }\n                function emitJsxElement(openingNode, children) {\n                    var syntheticReactRef = ts.createSynthesizedNode(69 /* Identifier */);\n                    syntheticReactRef.text = compilerOptions.reactNamespace ? compilerOptions.reactNamespace : \"React\";\n                    syntheticReactRef.parent = openingNode;\n                    // Call React.createElement(tag, ...\n                    emitLeadingComments(openingNode);\n                    emitExpressionIdentifier(syntheticReactRef);\n                    write(\".createElement(\");\n                    emitTagName(openingNode.tagName);\n                    write(\", \");\n                    // Attribute list\n                    if (openingNode.attributes.length === 0) {\n                        // When there are no attributes, React wants \"null\"\n                        write(\"null\");\n                    }\n                    else {\n                        // Either emit one big object literal (no spread attribs), or\n                        // a call to the __assign helper\n                        var attrs = openingNode.attributes;\n                        if (ts.forEach(attrs, function (attr) { return attr.kind === 247 /* JsxSpreadAttribute */; })) {\n                            write(\"__assign(\");\n                            var haveOpenedObjectLiteral = false;\n                            for (var i = 0; i < attrs.length; i++) {\n                                if (attrs[i].kind === 247 /* JsxSpreadAttribute */) {\n                                    // If this is the first argument, we need to emit a {} as the first argument\n                                    if (i === 0) {\n                                        write(\"{}, \");\n                                    }\n                                    if (haveOpenedObjectLiteral) {\n                                        write(\"}\");\n                                        haveOpenedObjectLiteral = false;\n                                    }\n                                    if (i > 0) {\n                                        write(\", \");\n                                    }\n                                    emit(attrs[i].expression);\n                                }\n                                else {\n                                    ts.Debug.assert(attrs[i].kind === 246 /* JsxAttribute */);\n                                    if (haveOpenedObjectLiteral) {\n                                        write(\", \");\n                                    }\n                                    else {\n                                        haveOpenedObjectLiteral = true;\n                                        if (i > 0) {\n                                            write(\", \");\n                                        }\n                                        write(\"{\");\n                                    }\n                                    emitJsxAttribute(attrs[i]);\n                                }\n                            }\n                            if (haveOpenedObjectLiteral)\n                                write(\"}\");\n                            write(\")\"); // closing paren to React.__spread(\n                        }\n                        else {\n                            // One object literal with all the attributes in them\n                            write(\"{\");\n                            for (var i = 0, n = attrs.length; i < n; i++) {\n                                if (i > 0) {\n                                    write(\", \");\n                                }\n                                emitJsxAttribute(attrs[i]);\n                            }\n                            write(\"}\");\n                        }\n                    }\n                    // Children\n                    if (children) {\n                        var firstChild = void 0;\n                        var multipleEmittableChildren = false;\n                        for (var i = 0, n = children.length; i < n; i++) {\n                            var jsxChild = children[i];\n                            if (isJsxChildEmittable(jsxChild)) {\n                                // we need to decide whether to emit in single line or multiple lines as indented list\n                                // store firstChild reference, if we see another emittable child, then emit accordingly\n                                if (!firstChild) {\n                                    write(\", \");\n                                    firstChild = jsxChild;\n                                }\n                                else {\n                                    // more than one emittable child, emit indented list\n                                    if (!multipleEmittableChildren) {\n                                        multipleEmittableChildren = true;\n                                        increaseIndent();\n                                        writeLine();\n                                        emit(firstChild);\n                                    }\n                                    write(\", \");\n                                    writeLine();\n                                    emit(jsxChild);\n                                }\n                            }\n                        }\n                        if (multipleEmittableChildren) {\n                            decreaseIndent();\n                        }\n                        else if (firstChild) {\n                            if (firstChild.kind !== 241 /* JsxElement */ && firstChild.kind !== 242 /* JsxSelfClosingElement */) {\n                                emit(firstChild);\n                            }\n                            else {\n                                // If the only child is jsx element, put it on a new indented line\n                                increaseIndent();\n                                writeLine();\n                                emit(firstChild);\n                                writeLine();\n                                decreaseIndent();\n                            }\n                        }\n                    }\n                    // Closing paren\n                    write(\")\"); // closes \"React.createElement(\"\n                    emitTrailingComments(openingNode);\n                }\n                if (node.kind === 241 /* JsxElement */) {\n                    emitJsxElement(node.openingElement, node.children);\n                }\n                else {\n                    ts.Debug.assert(node.kind === 242 /* JsxSelfClosingElement */);\n                    emitJsxElement(node);\n                }\n            }\n            function jsxEmitPreserve(node) {\n                function emitJsxAttribute(node) {\n                    emit(node.name);\n                    if (node.initializer) {\n                        write(\"=\");\n                        emit(node.initializer);\n                    }\n                }\n                function emitJsxSpreadAttribute(node) {\n                    write(\"{...\");\n                    emit(node.expression);\n                    write(\"}\");\n                }\n                function emitAttributes(attribs) {\n                    for (var i = 0, n = attribs.length; i < n; i++) {\n                        if (i > 0) {\n                            write(\" \");\n                        }\n                        if (attribs[i].kind === 247 /* JsxSpreadAttribute */) {\n                            emitJsxSpreadAttribute(attribs[i]);\n                        }\n                        else {\n                            ts.Debug.assert(attribs[i].kind === 246 /* JsxAttribute */);\n                            emitJsxAttribute(attribs[i]);\n                        }\n                    }\n                }\n                function emitJsxOpeningOrSelfClosingElement(node) {\n                    write(\"<\");\n                    emit(node.tagName);\n                    if (node.attributes.length > 0 || (node.kind === 242 /* JsxSelfClosingElement */)) {\n                        write(\" \");\n                    }\n                    emitAttributes(node.attributes);\n                    if (node.kind === 242 /* JsxSelfClosingElement */) {\n                        write(\"/>\");\n                    }\n                    else {\n                        write(\">\");\n                    }\n                }\n                function emitJsxClosingElement(node) {\n                    write(\"</\");\n                    emit(node.tagName);\n                    write(\">\");\n                }\n                function emitJsxElement(node) {\n                    emitJsxOpeningOrSelfClosingElement(node.openingElement);\n                    for (var i = 0, n = node.children.length; i < n; i++) {\n                        emit(node.children[i]);\n                    }\n                    emitJsxClosingElement(node.closingElement);\n                }\n                if (node.kind === 241 /* JsxElement */) {\n                    emitJsxElement(node);\n                }\n                else {\n                    ts.Debug.assert(node.kind === 242 /* JsxSelfClosingElement */);\n                    emitJsxOpeningOrSelfClosingElement(node);\n                }\n            }\n            // This function specifically handles numeric/string literals for enum and accessor 'identifiers'.\n            // In a sense, it does not actually emit identifiers as much as it declares a name for a specific property.\n            // For example, this is utilized when feeding in a result to Object.defineProperty.\n            function emitExpressionForPropertyName(node) {\n                ts.Debug.assert(node.kind !== 169 /* BindingElement */);\n                if (node.kind === 9 /* StringLiteral */) {\n                    emitLiteral(node);\n                }\n                else if (node.kind === 140 /* ComputedPropertyName */) {\n                    // if this is a decorated computed property, we will need to capture the result\n                    // of the property expression so that we can apply decorators later. This is to ensure\n                    // we don't introduce unintended side effects:\n                    //\n                    //   class C {\n                    //     [_a = x]() { }\n                    //   }\n                    //\n                    // The emit for the decorated computed property decorator is:\n                    //\n                    //   __decorate([dec], C.prototype, _a, Object.getOwnPropertyDescriptor(C.prototype, _a));\n                    //\n                    if (ts.nodeIsDecorated(node.parent)) {\n                        if (!computedPropertyNamesToGeneratedNames) {\n                            computedPropertyNamesToGeneratedNames = [];\n                        }\n                        var generatedName = computedPropertyNamesToGeneratedNames[ts.getNodeId(node)];\n                        if (generatedName) {\n                            // we have already generated a variable for this node, write that value instead.\n                            write(generatedName);\n                            return;\n                        }\n                        generatedName = createAndRecordTempVariable(0 /* Auto */).text;\n                        computedPropertyNamesToGeneratedNames[ts.getNodeId(node)] = generatedName;\n                        write(generatedName);\n                        write(\" = \");\n                    }\n                    emit(node.expression);\n                }\n                else {\n                    write('\"');\n                    if (node.kind === 8 /* NumericLiteral */) {\n                        write(node.text);\n                    }\n                    else {\n                        writeTextOfNode(currentText, node);\n                    }\n                    write('\"');\n                }\n            }\n            function isExpressionIdentifier(node) {\n                var parent = node.parent;\n                switch (parent.kind) {\n                    case 170 /* ArrayLiteralExpression */:\n                    case 195 /* AsExpression */:\n                    case 184 /* AwaitExpression */:\n                    case 187 /* BinaryExpression */:\n                    case 174 /* CallExpression */:\n                    case 249 /* CaseClause */:\n                    case 140 /* ComputedPropertyName */:\n                    case 188 /* ConditionalExpression */:\n                    case 143 /* Decorator */:\n                    case 181 /* DeleteExpression */:\n                    case 204 /* DoStatement */:\n                    case 173 /* ElementAccessExpression */:\n                    case 235 /* ExportAssignment */:\n                    case 202 /* ExpressionStatement */:\n                    case 194 /* ExpressionWithTypeArguments */:\n                    case 206 /* ForStatement */:\n                    case 207 /* ForInStatement */:\n                    case 208 /* ForOfStatement */:\n                    case 203 /* IfStatement */:\n                    case 245 /* JsxClosingElement */:\n                    case 242 /* JsxSelfClosingElement */:\n                    case 243 /* JsxOpeningElement */:\n                    case 247 /* JsxSpreadAttribute */:\n                    case 248 /* JsxExpression */:\n                    case 175 /* NewExpression */:\n                    case 196 /* NonNullExpression */:\n                    case 178 /* ParenthesizedExpression */:\n                    case 186 /* PostfixUnaryExpression */:\n                    case 185 /* PrefixUnaryExpression */:\n                    case 211 /* ReturnStatement */:\n                    case 254 /* ShorthandPropertyAssignment */:\n                    case 191 /* SpreadElementExpression */:\n                    case 213 /* SwitchStatement */:\n                    case 176 /* TaggedTemplateExpression */:\n                    case 197 /* TemplateSpan */:\n                    case 215 /* ThrowStatement */:\n                    case 177 /* TypeAssertionExpression */:\n                    case 182 /* TypeOfExpression */:\n                    case 183 /* VoidExpression */:\n                    case 205 /* WhileStatement */:\n                    case 212 /* WithStatement */:\n                    case 190 /* YieldExpression */:\n                        return true;\n                    case 169 /* BindingElement */:\n                    case 255 /* EnumMember */:\n                    case 142 /* Parameter */:\n                    case 253 /* PropertyAssignment */:\n                    case 145 /* PropertyDeclaration */:\n                    case 218 /* VariableDeclaration */:\n                        return parent.initializer === node;\n                    case 172 /* PropertyAccessExpression */:\n                        return parent.expression === node;\n                    case 180 /* ArrowFunction */:\n                    case 179 /* FunctionExpression */:\n                        return parent.body === node;\n                    case 229 /* ImportEqualsDeclaration */:\n                        return parent.moduleReference === node;\n                    case 139 /* QualifiedName */:\n                        return parent.left === node;\n                }\n                return false;\n            }\n            function emitExpressionIdentifier(node) {\n                var container = resolver.getReferencedExportContainer(node);\n                if (container) {\n                    if (container.kind === 256 /* SourceFile */) {\n                        // Identifier references module export\n                        if (modulekind !== ts.ModuleKind.ES6 && modulekind !== ts.ModuleKind.System) {\n                            write(\"exports.\");\n                        }\n                    }\n                    else {\n                        // Identifier references namespace export\n                        write(getGeneratedNameForNode(container));\n                        write(\".\");\n                    }\n                }\n                else {\n                    if (modulekind !== ts.ModuleKind.ES6) {\n                        var declaration = resolver.getReferencedImportDeclaration(node);\n                        if (declaration) {\n                            if (declaration.kind === 231 /* ImportClause */) {\n                                // Identifier references default import\n                                write(getGeneratedNameForNode(declaration.parent));\n                                write(languageVersion === 0 /* ES3 */ ? '[\"default\"]' : \".default\");\n                                return;\n                            }\n                            else if (declaration.kind === 234 /* ImportSpecifier */) {\n                                // Identifier references named import\n                                write(getGeneratedNameForNode(declaration.parent.parent.parent));\n                                var name_26 = declaration.propertyName || declaration.name;\n                                var identifier = ts.getTextOfNodeFromSourceText(currentText, name_26);\n                                if (languageVersion === 0 /* ES3 */ && identifier === \"default\") {\n                                    write('[\"default\"]');\n                                }\n                                else {\n                                    write(\".\");\n                                    write(identifier);\n                                }\n                                return;\n                            }\n                        }\n                    }\n                    if (languageVersion < 2 /* ES6 */) {\n                        var declaration = resolver.getReferencedDeclarationWithCollidingName(node);\n                        if (declaration) {\n                            write(getGeneratedNameForNode(declaration.name));\n                            return;\n                        }\n                    }\n                    else if (resolver.getNodeCheckFlags(node) & 1048576 /* BodyScopedClassBinding */) {\n                        // Due to the emit for class decorators, any reference to the class from inside of the class body\n                        // must instead be rewritten to point to a temporary variable to avoid issues with the double-bind\n                        // behavior of class names in ES6.\n                        var declaration = resolver.getReferencedValueDeclaration(node);\n                        if (declaration) {\n                            var classAlias = decoratedClassAliases[ts.getNodeId(declaration)];\n                            if (classAlias !== undefined) {\n                                write(classAlias);\n                                return;\n                            }\n                        }\n                    }\n                }\n                if (ts.nodeIsSynthesized(node)) {\n                    write(node.text);\n                }\n                else {\n                    writeTextOfNode(currentText, node);\n                }\n            }\n            function isNameOfNestedBlockScopedRedeclarationOrCapturedBinding(node) {\n                if (languageVersion < 2 /* ES6 */) {\n                    var parent_13 = node.parent;\n                    switch (parent_13.kind) {\n                        case 169 /* BindingElement */:\n                        case 221 /* ClassDeclaration */:\n                        case 224 /* EnumDeclaration */:\n                        case 218 /* VariableDeclaration */:\n                            return parent_13.name === node && resolver.isDeclarationWithCollidingName(parent_13);\n                    }\n                }\n                return false;\n            }\n            function getClassExpressionInPropertyAccessInStaticPropertyDeclaration(node) {\n                if (languageVersion >= 2 /* ES6 */) {\n                    var parent_14 = node.parent;\n                    if (parent_14.kind === 172 /* PropertyAccessExpression */ && parent_14.expression === node) {\n                        parent_14 = parent_14.parent;\n                        while (parent_14 && parent_14.kind !== 145 /* PropertyDeclaration */) {\n                            parent_14 = parent_14.parent;\n                        }\n                        return parent_14 && parent_14.kind === 145 /* PropertyDeclaration */ && (parent_14.flags & 32 /* Static */) !== 0 &&\n                            parent_14.parent.kind === 192 /* ClassExpression */ ? parent_14.parent : undefined;\n                    }\n                }\n                return undefined;\n            }\n            function emitIdentifier(node) {\n                if (convertedLoopState) {\n                    if (node.text == \"arguments\" && resolver.isArgumentsLocalBinding(node)) {\n                        // in converted loop body arguments cannot be used directly.\n                        var name_27 = convertedLoopState.argumentsName || (convertedLoopState.argumentsName = makeUniqueName(\"arguments\"));\n                        write(name_27);\n                        return;\n                    }\n                }\n                if (!node.parent) {\n                    write(node.text);\n                }\n                else if (isExpressionIdentifier(node)) {\n                    var classExpression = getClassExpressionInPropertyAccessInStaticPropertyDeclaration(node);\n                    if (classExpression) {\n                        var declaration = resolver.getReferencedValueDeclaration(node);\n                        if (declaration === classExpression) {\n                            write(getGeneratedNameForNode(declaration.name));\n                            return;\n                        }\n                    }\n                    emitExpressionIdentifier(node);\n                }\n                else if (isNameOfNestedBlockScopedRedeclarationOrCapturedBinding(node)) {\n                    write(getGeneratedNameForNode(node));\n                }\n                else if (ts.nodeIsSynthesized(node)) {\n                    write(node.text);\n                }\n                else {\n                    writeTextOfNode(currentText, node);\n                }\n            }\n            function emitThis(node) {\n                if (resolver.getNodeCheckFlags(node) & 2 /* LexicalThis */) {\n                    write(\"_this\");\n                }\n                else if (convertedLoopState) {\n                    write(convertedLoopState.thisName || (convertedLoopState.thisName = makeUniqueName(\"this\")));\n                }\n                else {\n                    write(\"this\");\n                }\n            }\n            function emitSuper(node) {\n                if (languageVersion >= 2 /* ES6 */) {\n                    write(\"super\");\n                }\n                else {\n                    var flags = resolver.getNodeCheckFlags(node);\n                    if (flags & 256 /* SuperInstance */) {\n                        write(\"_super.prototype\");\n                    }\n                    else {\n                        write(\"_super\");\n                    }\n                }\n            }\n            function emitObjectBindingPattern(node) {\n                write(\"{ \");\n                var elements = node.elements;\n                emitList(elements, 0, elements.length, /*multiLine*/ false, /*trailingComma*/ elements.hasTrailingComma);\n                write(\" }\");\n            }\n            function emitArrayBindingPattern(node) {\n                write(\"[\");\n                var elements = node.elements;\n                emitList(elements, 0, elements.length, /*multiLine*/ false, /*trailingComma*/ elements.hasTrailingComma);\n                write(\"]\");\n            }\n            function emitBindingElement(node) {\n                if (node.propertyName) {\n                    emit(node.propertyName);\n                    write(\": \");\n                }\n                if (node.dotDotDotToken) {\n                    write(\"...\");\n                }\n                if (ts.isBindingPattern(node.name)) {\n                    emit(node.name);\n                }\n                else {\n                    emitModuleMemberName(node);\n                }\n                emitOptional(\" = \", node.initializer);\n            }\n            function emitSpreadElementExpression(node) {\n                write(\"...\");\n                emit(node.expression);\n            }\n            function emitYieldExpression(node) {\n                write(ts.tokenToString(114 /* YieldKeyword */));\n                if (node.asteriskToken) {\n                    write(\"*\");\n                }\n                if (node.expression) {\n                    write(\" \");\n                    emit(node.expression);\n                }\n            }\n            function emitAwaitExpression(node) {\n                var needsParenthesis = needsParenthesisForAwaitExpressionAsYield(node);\n                if (needsParenthesis) {\n                    write(\"(\");\n                }\n                write(ts.tokenToString(114 /* YieldKeyword */));\n                write(\" \");\n                emit(node.expression);\n                if (needsParenthesis) {\n                    write(\")\");\n                }\n            }\n            function needsParenthesisForAwaitExpressionAsYield(node) {\n                if (node.parent.kind === 187 /* BinaryExpression */ && !ts.isAssignmentOperator(node.parent.operatorToken.kind)) {\n                    return true;\n                }\n                else if (node.parent.kind === 188 /* ConditionalExpression */ && node.parent.condition === node) {\n                    return true;\n                }\n                else if (node.parent.kind === 185 /* PrefixUnaryExpression */ || node.parent.kind === 181 /* DeleteExpression */ ||\n                    node.parent.kind === 182 /* TypeOfExpression */ || node.parent.kind === 183 /* VoidExpression */) {\n                    return true;\n                }\n                return false;\n            }\n            function needsParenthesisForPropertyAccessOrInvocation(node) {\n                switch (node.kind) {\n                    case 69 /* Identifier */:\n                    case 170 /* ArrayLiteralExpression */:\n                    case 172 /* PropertyAccessExpression */:\n                    case 173 /* ElementAccessExpression */:\n                    case 174 /* CallExpression */:\n                    case 178 /* ParenthesizedExpression */:\n                        // This list is not exhaustive and only includes those cases that are relevant\n                        // to the check in emitArrayLiteral. More cases can be added as needed.\n                        return false;\n                }\n                return true;\n            }\n            function emitListWithSpread(elements, needsUniqueCopy, multiLine, trailingComma, useConcat) {\n                var pos = 0;\n                var group = 0;\n                var length = elements.length;\n                while (pos < length) {\n                    // Emit using the pattern <group0>.concat(<group1>, <group2>, ...)\n                    if (group === 1 && useConcat) {\n                        write(\".concat(\");\n                    }\n                    else if (group > 0) {\n                        write(\", \");\n                    }\n                    var e = elements[pos];\n                    if (e.kind === 191 /* SpreadElementExpression */) {\n                        e = e.expression;\n                        emitParenthesizedIf(e, /*parenthesized*/ group === 0 && needsParenthesisForPropertyAccessOrInvocation(e));\n                        pos++;\n                        if (pos === length && group === 0 && needsUniqueCopy && e.kind !== 170 /* ArrayLiteralExpression */) {\n                            write(\".slice()\");\n                        }\n                    }\n                    else {\n                        var i = pos;\n                        while (i < length && elements[i].kind !== 191 /* SpreadElementExpression */) {\n                            i++;\n                        }\n                        write(\"[\");\n                        if (multiLine) {\n                            increaseIndent();\n                        }\n                        emitList(elements, pos, i - pos, multiLine, trailingComma && i === length);\n                        if (multiLine) {\n                            decreaseIndent();\n                        }\n                        write(\"]\");\n                        pos = i;\n                    }\n                    group++;\n                }\n                if (group > 1) {\n                    if (useConcat) {\n                        write(\")\");\n                    }\n                }\n            }\n            function isSpreadElementExpression(node) {\n                return node.kind === 191 /* SpreadElementExpression */;\n            }\n            function emitArrayLiteral(node) {\n                var elements = node.elements;\n                if (elements.length === 0) {\n                    write(\"[]\");\n                }\n                else if (languageVersion >= 2 /* ES6 */ || !ts.forEach(elements, isSpreadElementExpression)) {\n                    write(\"[\");\n                    emitLinePreservingList(node, node.elements, elements.hasTrailingComma, /*spacesBetweenBraces*/ false);\n                    write(\"]\");\n                }\n                else {\n                    emitListWithSpread(elements, /*needsUniqueCopy*/ true, /*multiLine*/ node.multiLine, \n                    /*trailingComma*/ elements.hasTrailingComma, /*useConcat*/ true);\n                }\n            }\n            function emitObjectLiteralBody(node, numElements) {\n                if (numElements === 0) {\n                    write(\"{}\");\n                    return;\n                }\n                write(\"{\");\n                if (numElements > 0) {\n                    var properties = node.properties;\n                    // If we are not doing a downlevel transformation for object literals,\n                    // then try to preserve the original shape of the object literal.\n                    // Otherwise just try to preserve the formatting.\n                    if (numElements === properties.length) {\n                        emitLinePreservingList(node, properties, /*allowTrailingComma*/ languageVersion >= 1 /* ES5 */, /*spacesBetweenBraces*/ true);\n                    }\n                    else {\n                        var multiLine = node.multiLine;\n                        if (!multiLine) {\n                            write(\" \");\n                        }\n                        else {\n                            increaseIndent();\n                        }\n                        emitList(properties, 0, numElements, /*multiLine*/ multiLine, /*trailingComma*/ false);\n                        if (!multiLine) {\n                            write(\" \");\n                        }\n                        else {\n                            decreaseIndent();\n                        }\n                    }\n                }\n                write(\"}\");\n            }\n            function emitDownlevelObjectLiteralWithComputedProperties(node, firstComputedPropertyIndex) {\n                var multiLine = node.multiLine;\n                var properties = node.properties;\n                write(\"(\");\n                if (multiLine) {\n                    increaseIndent();\n                }\n                // For computed properties, we need to create a unique handle to the object\n                // literal so we can modify it without risking internal assignments tainting the object.\n                var tempVar = createAndRecordTempVariable(0 /* Auto */);\n                // Write out the first non-computed properties\n                // (or all properties if none of them are computed),\n                // then emit the rest through indexing on the temp variable.\n                emit(tempVar);\n                write(\" = \");\n                emitObjectLiteralBody(node, firstComputedPropertyIndex);\n                for (var i = firstComputedPropertyIndex, n = properties.length; i < n; i++) {\n                    var property = properties[i];\n                    if (property.kind === 149 /* GetAccessor */ || property.kind === 150 /* SetAccessor */) {\n                        // TODO (drosen): Reconcile with 'emitMemberFunctions'.\n                        var accessors = ts.getAllAccessorDeclarations(node.properties, property);\n                        if (property !== accessors.firstAccessor) {\n                            continue;\n                        }\n                        writeComma();\n                        emitStart(property);\n                        write(\"Object.defineProperty(\");\n                        emit(tempVar);\n                        write(\", \");\n                        emitStart(property.name);\n                        emitExpressionForPropertyName(property.name);\n                        emitEnd(property.name);\n                        write(\", {\");\n                        increaseIndent();\n                        if (accessors.getAccessor) {\n                            writeLine();\n                            emitLeadingComments(accessors.getAccessor);\n                            write(\"get: \");\n                            emitStart(accessors.getAccessor);\n                            write(\"function \");\n                            emitSignatureAndBody(accessors.getAccessor);\n                            emitEnd(accessors.getAccessor);\n                            emitTrailingComments(accessors.getAccessor);\n                            write(\",\");\n                        }\n                        if (accessors.setAccessor) {\n                            writeLine();\n                            emitLeadingComments(accessors.setAccessor);\n                            write(\"set: \");\n                            emitStart(accessors.setAccessor);\n                            write(\"function \");\n                            emitSignatureAndBody(accessors.setAccessor);\n                            emitEnd(accessors.setAccessor);\n                            emitTrailingComments(accessors.setAccessor);\n                            write(\",\");\n                        }\n                        writeLine();\n                        write(\"enumerable: true,\");\n                        writeLine();\n                        write(\"configurable: true\");\n                        decreaseIndent();\n                        writeLine();\n                        write(\"})\");\n                        emitEnd(property);\n                    }\n                    else {\n                        writeComma();\n                        emitStart(property);\n                        emitLeadingComments(property);\n                        emitStart(property.name);\n                        emit(tempVar);\n                        emitMemberAccessForPropertyName(property.name);\n                        emitEnd(property.name);\n                        write(\" = \");\n                        if (property.kind === 253 /* PropertyAssignment */) {\n                            emit(property.initializer);\n                        }\n                        else if (property.kind === 254 /* ShorthandPropertyAssignment */) {\n                            emitExpressionIdentifier(property.name);\n                        }\n                        else if (property.kind === 147 /* MethodDeclaration */) {\n                            emitFunctionDeclaration(property);\n                        }\n                        else {\n                            ts.Debug.fail(\"ObjectLiteralElement type not accounted for: \" + property.kind);\n                        }\n                        emitEnd(property);\n                    }\n                }\n                writeComma();\n                emit(tempVar);\n                if (multiLine) {\n                    decreaseIndent();\n                    writeLine();\n                }\n                write(\")\");\n                function writeComma() {\n                    if (multiLine) {\n                        write(\",\");\n                        writeLine();\n                    }\n                    else {\n                        write(\", \");\n                    }\n                }\n            }\n            function emitObjectLiteral(node) {\n                var properties = node.properties;\n                if (languageVersion < 2 /* ES6 */) {\n                    var numProperties = properties.length;\n                    // Find the first computed property.\n                    // Everything until that point can be emitted as part of the initial object literal.\n                    var numInitialNonComputedProperties = numProperties;\n                    for (var i = 0, n = properties.length; i < n; i++) {\n                        if (properties[i].name.kind === 140 /* ComputedPropertyName */) {\n                            numInitialNonComputedProperties = i;\n                            break;\n                        }\n                    }\n                    var hasComputedProperty = numInitialNonComputedProperties !== properties.length;\n                    if (hasComputedProperty) {\n                        emitDownlevelObjectLiteralWithComputedProperties(node, numInitialNonComputedProperties);\n                        return;\n                    }\n                }\n                // Ordinary case: either the object has no computed properties\n                // or we're compiling with an ES6+ target.\n                emitObjectLiteralBody(node, properties.length);\n            }\n            function createBinaryExpression(left, operator, right, startsOnNewLine) {\n                var result = ts.createSynthesizedNode(187 /* BinaryExpression */, startsOnNewLine);\n                result.operatorToken = ts.createSynthesizedNode(operator);\n                result.left = left;\n                result.right = right;\n                return result;\n            }\n            function createPropertyAccessExpression(expression, name) {\n                var result = ts.createSynthesizedNode(172 /* PropertyAccessExpression */);\n                result.expression = parenthesizeForAccess(expression);\n                result.name = name;\n                return result;\n            }\n            function createElementAccessExpression(expression, argumentExpression) {\n                var result = ts.createSynthesizedNode(173 /* ElementAccessExpression */);\n                result.expression = parenthesizeForAccess(expression);\n                result.argumentExpression = argumentExpression;\n                return result;\n            }\n            function parenthesizeForAccess(expr) {\n                // When diagnosing whether the expression needs parentheses, the decision should be based\n                // on the innermost expression in a chain of nested type assertions.\n                while (expr.kind === 177 /* TypeAssertionExpression */ ||\n                    expr.kind === 195 /* AsExpression */ ||\n                    expr.kind === 196 /* NonNullExpression */) {\n                    expr = expr.expression;\n                }\n                // isLeftHandSideExpression is almost the correct criterion for when it is not necessary\n                // to parenthesize the expression before a dot. The known exceptions are:\n                //\n                //    NewExpression:\n                //       new C.x        -> not the same as (new C).x\n                //    NumberLiteral\n                //       1.x            -> not the same as (1).x\n                //\n                if (ts.isLeftHandSideExpression(expr) &&\n                    expr.kind !== 175 /* NewExpression */ &&\n                    expr.kind !== 8 /* NumericLiteral */) {\n                    return expr;\n                }\n                var node = ts.createSynthesizedNode(178 /* ParenthesizedExpression */);\n                node.expression = expr;\n                return node;\n            }\n            function emitComputedPropertyName(node) {\n                write(\"[\");\n                emitExpressionForPropertyName(node);\n                write(\"]\");\n            }\n            function emitMethod(node) {\n                if (languageVersion >= 2 /* ES6 */ && node.asteriskToken) {\n                    write(\"*\");\n                }\n                emit(node.name);\n                if (languageVersion < 2 /* ES6 */) {\n                    write(\": function \");\n                }\n                emitSignatureAndBody(node);\n            }\n            function emitPropertyAssignment(node) {\n                emit(node.name);\n                write(\": \");\n                // This is to ensure that we emit comment in the following case:\n                //      For example:\n                //          obj = {\n                //              id: /*comment1*/ ()=>void\n                //          }\n                // \"comment1\" is not considered to be leading comment for node.initializer\n                // but rather a trailing comment on the previous node.\n                emitTrailingCommentsOfPosition(node.initializer.pos);\n                emit(node.initializer);\n            }\n            // Return true if identifier resolves to an exported member of a namespace\n            function isExportReference(node) {\n                var container = resolver.getReferencedExportContainer(node);\n                return !!container;\n            }\n            // Return true if identifier resolves to an imported identifier\n            function isImportedReference(node) {\n                var declaration = resolver.getReferencedImportDeclaration(node);\n                return declaration && (declaration.kind === 231 /* ImportClause */ || declaration.kind === 234 /* ImportSpecifier */);\n            }\n            function emitShorthandPropertyAssignment(node) {\n                // The name property of a short-hand property assignment is considered an expression position, so here\n                // we manually emit the identifier to avoid rewriting.\n                writeTextOfNode(currentText, node.name);\n                // If emitting pre-ES6 code, or if the name requires rewriting when resolved as an expression identifier,\n                // we emit a normal property assignment. For example:\n                //   module m {\n                //       export let y;\n                //   }\n                //   module m {\n                //       let obj = { y };\n                //   }\n                // Here we need to emit obj = { y : m.y } regardless of the output target.\n                // The same rules apply for imported identifiers when targeting module formats with indirect access to\n                // the imported identifiers. For example, when targeting CommonJS:\n                //\n                //   import {foo} from './foo';\n                //   export const baz = { foo };\n                //\n                // Must be transformed into:\n                //\n                //   const foo_1 = require('./foo');\n                //   exports.baz = { foo: foo_1.foo };\n                //\n                if (languageVersion < 2 /* ES6 */ || (modulekind !== ts.ModuleKind.ES6 && isImportedReference(node.name)) || isExportReference(node.name)) {\n                    // Emit identifier as an identifier\n                    write(\": \");\n                    emitExpressionIdentifier(node.name);\n                }\n                if (languageVersion >= 2 /* ES6 */ && node.objectAssignmentInitializer) {\n                    write(\" = \");\n                    emit(node.objectAssignmentInitializer);\n                }\n            }\n            function tryEmitConstantValue(node) {\n                var constantValue = tryGetConstEnumValue(node);\n                if (constantValue !== undefined) {\n                    write(constantValue.toString());\n                    if (!compilerOptions.removeComments) {\n                        var propertyName = node.kind === 172 /* PropertyAccessExpression */ ? ts.declarationNameToString(node.name) : ts.getTextOfNode(node.argumentExpression);\n                        write(\" /* \" + propertyName + \" */\");\n                    }\n                    return true;\n                }\n                return false;\n            }\n            function tryGetConstEnumValue(node) {\n                if (compilerOptions.isolatedModules) {\n                    return undefined;\n                }\n                return node.kind === 172 /* PropertyAccessExpression */ || node.kind === 173 /* ElementAccessExpression */\n                    ? resolver.getConstantValue(node)\n                    : undefined;\n            }\n            // Returns 'true' if the code was actually indented, false otherwise.\n            // If the code is not indented, an optional valueToWriteWhenNotIndenting will be\n            // emitted instead.\n            function indentIfOnDifferentLines(parent, node1, node2, valueToWriteWhenNotIndenting) {\n                var realNodesAreOnDifferentLines = !ts.nodeIsSynthesized(parent) && !nodeEndIsOnSameLineAsNodeStart(node1, node2);\n                // Always use a newline for synthesized code if the synthesizer desires it.\n                var synthesizedNodeIsOnDifferentLine = synthesizedNodeStartsOnNewLine(node2);\n                if (realNodesAreOnDifferentLines || synthesizedNodeIsOnDifferentLine) {\n                    increaseIndent();\n                    writeLine();\n                    return true;\n                }\n                else {\n                    if (valueToWriteWhenNotIndenting) {\n                        write(valueToWriteWhenNotIndenting);\n                    }\n                    return false;\n                }\n            }\n            function emitPropertyAccess(node) {\n                if (tryEmitConstantValue(node)) {\n                    return;\n                }\n                if (languageVersion === 2 /* ES6 */ &&\n                    node.expression.kind === 95 /* SuperKeyword */ &&\n                    isInAsyncMethodWithSuperInES6(node)) {\n                    var name_28 = ts.createSynthesizedNode(9 /* StringLiteral */);\n                    name_28.text = node.name.text;\n                    emitSuperAccessInAsyncMethod(node.expression, name_28);\n                    return;\n                }\n                emit(node.expression);\n                var dotRangeStart = ts.nodeIsSynthesized(node.expression) ? -1 : node.expression.end;\n                var dotRangeEnd = ts.nodeIsSynthesized(node.expression) ? -1 : ts.skipTrivia(currentText, node.expression.end) + 1;\n                var dotToken = { pos: dotRangeStart, end: dotRangeEnd };\n                var indentedBeforeDot = indentIfOnDifferentLines(node, node.expression, dotToken);\n                // 1 .toString is a valid property access, emit a space after the literal\n                // Also emit a space if expression is a integer const enum value - it will appear in generated code as numeric literal\n                var shouldEmitSpace = false;\n                if (!indentedBeforeDot) {\n                    if (node.expression.kind === 8 /* NumericLiteral */) {\n                        // check if numeric literal was originally written with a dot\n                        var text = ts.getTextOfNodeFromSourceText(currentText, node.expression);\n                        shouldEmitSpace = text.indexOf(ts.tokenToString(21 /* DotToken */)) < 0;\n                    }\n                    else {\n                        // check if constant enum value is integer\n                        var constantValue = tryGetConstEnumValue(node.expression);\n                        // isFinite handles cases when constantValue is undefined\n                        shouldEmitSpace = isFinite(constantValue) && Math.floor(constantValue) === constantValue;\n                    }\n                }\n                if (shouldEmitSpace) {\n                    write(\" .\");\n                }\n                else {\n                    write(\".\");\n                }\n                var indentedAfterDot = indentIfOnDifferentLines(node, dotToken, node.name);\n                emit(node.name);\n                decreaseIndentIf(indentedBeforeDot, indentedAfterDot);\n            }\n            function emitQualifiedName(node) {\n                emit(node.left);\n                write(\".\");\n                emit(node.right);\n            }\n            function emitQualifiedNameAsExpression(node, useFallback) {\n                if (node.left.kind === 69 /* Identifier */) {\n                    emitEntityNameAsExpression(node.left, useFallback);\n                }\n                else if (useFallback) {\n                    var temp = createAndRecordTempVariable(0 /* Auto */);\n                    write(\"(\");\n                    emitNodeWithoutSourceMap(temp);\n                    write(\" = \");\n                    emitEntityNameAsExpression(node.left, /*useFallback*/ true);\n                    write(\") && \");\n                    emitNodeWithoutSourceMap(temp);\n                }\n                else {\n                    emitEntityNameAsExpression(node.left, /*useFallback*/ false);\n                }\n                write(\".\");\n                emit(node.right);\n            }\n            function emitEntityNameAsExpression(node, useFallback) {\n                switch (node.kind) {\n                    case 69 /* Identifier */:\n                        if (useFallback) {\n                            write(\"typeof \");\n                            emitExpressionIdentifier(node);\n                            write(\" !== 'undefined' && \");\n                        }\n                        emitExpressionIdentifier(node);\n                        break;\n                    case 139 /* QualifiedName */:\n                        emitQualifiedNameAsExpression(node, useFallback);\n                        break;\n                    default:\n                        emitNodeWithoutSourceMap(node);\n                        break;\n                }\n            }\n            function emitIndexedAccess(node) {\n                if (tryEmitConstantValue(node)) {\n                    return;\n                }\n                if (languageVersion === 2 /* ES6 */ &&\n                    node.expression.kind === 95 /* SuperKeyword */ &&\n                    isInAsyncMethodWithSuperInES6(node)) {\n                    emitSuperAccessInAsyncMethod(node.expression, node.argumentExpression);\n                    return;\n                }\n                emit(node.expression);\n                write(\"[\");\n                emit(node.argumentExpression);\n                write(\"]\");\n            }\n            function hasSpreadElement(elements) {\n                return ts.forEach(elements, function (e) { return e.kind === 191 /* SpreadElementExpression */; });\n            }\n            function skipParentheses(node) {\n                while (node.kind === 178 /* ParenthesizedExpression */ ||\n                    node.kind === 177 /* TypeAssertionExpression */ ||\n                    node.kind === 195 /* AsExpression */ ||\n                    node.kind === 196 /* NonNullExpression */) {\n                    node = node.expression;\n                }\n                return node;\n            }\n            function emitCallTarget(node) {\n                if (node.kind === 69 /* Identifier */ || node.kind === 97 /* ThisKeyword */ || node.kind === 95 /* SuperKeyword */) {\n                    emit(node);\n                    return node;\n                }\n                var temp = createAndRecordTempVariable(0 /* Auto */);\n                write(\"(\");\n                emit(temp);\n                write(\" = \");\n                emit(node);\n                write(\")\");\n                return temp;\n            }\n            function emitCallWithSpread(node) {\n                var target;\n                var expr = skipParentheses(node.expression);\n                if (expr.kind === 172 /* PropertyAccessExpression */) {\n                    // Target will be emitted as \"this\" argument\n                    target = emitCallTarget(expr.expression);\n                    write(\".\");\n                    emit(expr.name);\n                }\n                else if (expr.kind === 173 /* ElementAccessExpression */) {\n                    // Target will be emitted as \"this\" argument\n                    target = emitCallTarget(expr.expression);\n                    write(\"[\");\n                    emit(expr.argumentExpression);\n                    write(\"]\");\n                }\n                else if (expr.kind === 95 /* SuperKeyword */) {\n                    target = expr;\n                    write(\"_super\");\n                }\n                else {\n                    emit(node.expression);\n                }\n                write(\".apply(\");\n                if (target) {\n                    if (target.kind === 95 /* SuperKeyword */) {\n                        // Calls of form super(...) and super.foo(...)\n                        emitThis(target);\n                    }\n                    else {\n                        // Calls of form obj.foo(...)\n                        emit(target);\n                    }\n                }\n                else {\n                    // Calls of form foo(...)\n                    write(\"void 0\");\n                }\n                write(\", \");\n                emitListWithSpread(node.arguments, /*needsUniqueCopy*/ false, /*multiLine*/ false, /*trailingComma*/ false, /*useConcat*/ true);\n                write(\")\");\n            }\n            function isInAsyncMethodWithSuperInES6(node) {\n                if (languageVersion === 2 /* ES6 */) {\n                    var container = ts.getSuperContainer(node, /*includeFunctions*/ false);\n                    if (container && resolver.getNodeCheckFlags(container) & (2048 /* AsyncMethodWithSuper */ | 4096 /* AsyncMethodWithSuperBinding */)) {\n                        return true;\n                    }\n                }\n                return false;\n            }\n            function emitSuperAccessInAsyncMethod(superNode, argumentExpression) {\n                var container = ts.getSuperContainer(superNode, /*includeFunctions*/ false);\n                var isSuperBinding = resolver.getNodeCheckFlags(container) & 4096 /* AsyncMethodWithSuperBinding */;\n                write(\"_super(\");\n                emit(argumentExpression);\n                write(isSuperBinding ? \").value\" : \")\");\n            }\n            function emitCallExpression(node) {\n                if (languageVersion < 2 /* ES6 */ && hasSpreadElement(node.arguments)) {\n                    emitCallWithSpread(node);\n                    return;\n                }\n                var expression = node.expression;\n                var superCall = false;\n                var isAsyncMethodWithSuper = false;\n                if (expression.kind === 95 /* SuperKeyword */) {\n                    emitSuper(expression);\n                    superCall = true;\n                }\n                else {\n                    superCall = ts.isSuperPropertyOrElementAccess(expression);\n                    isAsyncMethodWithSuper = superCall && isInAsyncMethodWithSuperInES6(node);\n                    emit(expression);\n                }\n                if (superCall && (languageVersion < 2 /* ES6 */ || isAsyncMethodWithSuper)) {\n                    write(\".call(\");\n                    emitThis(expression);\n                    if (node.arguments.length) {\n                        write(\", \");\n                        emitCommaList(node.arguments);\n                    }\n                    write(\")\");\n                }\n                else {\n                    write(\"(\");\n                    emitCommaList(node.arguments);\n                    write(\")\");\n                }\n            }\n            function emitNewExpression(node) {\n                write(\"new \");\n                // Spread operator logic is supported in new expressions in ES5 using a combination\n                // of Function.prototype.bind() and Function.prototype.apply().\n                //\n                //     Example:\n                //\n                //         var args = [1, 2, 3, 4, 5];\n                //         new Array(...args);\n                //\n                //     is compiled into the following ES5:\n                //\n                //         var args = [1, 2, 3, 4, 5];\n                //         new (Array.bind.apply(Array, [void 0].concat(args)));\n                //\n                // The 'thisArg' to 'bind' is ignored when invoking the result of 'bind' with 'new',\n                // Thus, we set it to undefined ('void 0').\n                if (languageVersion === 1 /* ES5 */ &&\n                    node.arguments &&\n                    hasSpreadElement(node.arguments)) {\n                    write(\"(\");\n                    var target = emitCallTarget(node.expression);\n                    write(\".bind.apply(\");\n                    emit(target);\n                    write(\", [void 0].concat(\");\n                    emitListWithSpread(node.arguments, /*needsUniqueCopy*/ false, /*multiLine*/ false, /*trailingComma*/ false, /*useConcat*/ false);\n                    write(\")))\");\n                    write(\"()\");\n                }\n                else {\n                    emit(node.expression);\n                    if (node.arguments) {\n                        write(\"(\");\n                        emitCommaList(node.arguments);\n                        write(\")\");\n                    }\n                }\n            }\n            function emitTaggedTemplateExpression(node) {\n                if (languageVersion >= 2 /* ES6 */) {\n                    emit(node.tag);\n                    write(\" \");\n                    emit(node.template);\n                }\n                else {\n                    emitDownlevelTaggedTemplate(node);\n                }\n            }\n            function emitParenExpression(node) {\n                // If the node is synthesized, it means the emitter put the parentheses there,\n                // not the user. If we didn't want them, the emitter would not have put them\n                // there.\n                if (!ts.nodeIsSynthesized(node) && node.parent.kind !== 180 /* ArrowFunction */) {\n                    if (node.expression.kind === 177 /* TypeAssertionExpression */ ||\n                        node.expression.kind === 195 /* AsExpression */ ||\n                        node.expression.kind === 196 /* NonNullExpression */) {\n                        var operand = node.expression.expression;\n                        // Make sure we consider all nested cast expressions, e.g.:\n                        // (<any><number><any>-A).x;\n                        while (operand.kind === 177 /* TypeAssertionExpression */ ||\n                            operand.kind === 195 /* AsExpression */ ||\n                            operand.kind === 196 /* NonNullExpression */) {\n                            operand = operand.expression;\n                        }\n                        // We have an expression of the form: (<Type>SubExpr) or (SubExpr as Type)\n                        // Emitting this as (SubExpr) is really not desirable. We would like to emit the subexpr as is.\n                        // Omitting the parentheses, however, could cause change in the semantics of the generated\n                        // code if the casted expression has a lower precedence than the rest of the expression, e.g.:\n                        //      (<any>new A).foo should be emitted as (new A).foo and not new A.foo\n                        //      (<any>typeof A).toString() should be emitted as (typeof A).toString() and not typeof A.toString()\n                        //      new (<any>A()) should be emitted as new (A()) and not new A()\n                        //      (<any>function foo() { })() should be emitted as an IIF (function foo(){})() and not declaration function foo(){} ()\n                        if (operand.kind !== 185 /* PrefixUnaryExpression */ &&\n                            operand.kind !== 183 /* VoidExpression */ &&\n                            operand.kind !== 182 /* TypeOfExpression */ &&\n                            operand.kind !== 181 /* DeleteExpression */ &&\n                            operand.kind !== 186 /* PostfixUnaryExpression */ &&\n                            operand.kind !== 175 /* NewExpression */ &&\n                            !(operand.kind === 187 /* BinaryExpression */ && node.expression.kind === 195 /* AsExpression */) &&\n                            !(operand.kind === 174 /* CallExpression */ && node.parent.kind === 175 /* NewExpression */) &&\n                            !(operand.kind === 179 /* FunctionExpression */ && node.parent.kind === 174 /* CallExpression */) &&\n                            !(operand.kind === 8 /* NumericLiteral */ && node.parent.kind === 172 /* PropertyAccessExpression */)) {\n                            emit(operand);\n                            return;\n                        }\n                    }\n                }\n                write(\"(\");\n                emit(node.expression);\n                write(\")\");\n            }\n            function emitDeleteExpression(node) {\n                write(ts.tokenToString(78 /* DeleteKeyword */));\n                write(\" \");\n                emit(node.expression);\n            }\n            function emitVoidExpression(node) {\n                write(ts.tokenToString(103 /* VoidKeyword */));\n                write(\" \");\n                emit(node.expression);\n            }\n            function emitTypeOfExpression(node) {\n                write(ts.tokenToString(101 /* TypeOfKeyword */));\n                write(\" \");\n                emit(node.expression);\n            }\n            function isNameOfExportedSourceLevelDeclarationInSystemExternalModule(node) {\n                if (!isCurrentFileSystemExternalModule() || node.kind !== 69 /* Identifier */ || ts.nodeIsSynthesized(node)) {\n                    return false;\n                }\n                var isVariableDeclarationOrBindingElement = node.parent && (node.parent.kind === 218 /* VariableDeclaration */ || node.parent.kind === 169 /* BindingElement */);\n                var targetDeclaration = isVariableDeclarationOrBindingElement\n                    ? node.parent\n                    : resolver.getReferencedValueDeclaration(node);\n                return isSourceFileLevelDeclarationInSystemJsModule(targetDeclaration, /*isExported*/ true);\n            }\n            function isNameOfExportedDeclarationInNonES6Module(node) {\n                if (modulekind === ts.ModuleKind.System || node.kind !== 69 /* Identifier */ || ts.nodeIsSynthesized(node)) {\n                    return false;\n                }\n                if (exportEquals || !exportSpecifiers || !(node.text in exportSpecifiers)) {\n                    return false;\n                }\n                // check that referenced declaration is declared on source file level\n                var declaration = resolver.getReferencedValueDeclaration(node);\n                return declaration && ts.getEnclosingBlockScopeContainer(declaration).kind === 256 /* SourceFile */;\n            }\n            function emitPrefixUnaryExpression(node) {\n                var isPlusPlusOrMinusMinus = (node.operator === 41 /* PlusPlusToken */\n                    || node.operator === 42 /* MinusMinusToken */);\n                var externalExportChanged = isPlusPlusOrMinusMinus &&\n                    isNameOfExportedSourceLevelDeclarationInSystemExternalModule(node.operand);\n                if (externalExportChanged) {\n                    // emit\n                    // ++x\n                    // as\n                    // exports('x', ++x)\n                    write(exportFunctionForFile + \"(\\\"\");\n                    emitNodeWithoutSourceMap(node.operand);\n                    write(\"\\\", \");\n                }\n                var internalExportChanged = isPlusPlusOrMinusMinus &&\n                    isNameOfExportedDeclarationInNonES6Module(node.operand);\n                if (internalExportChanged) {\n                    emitAliasEqual(node.operand);\n                }\n                write(ts.tokenToString(node.operator));\n                // In some cases, we need to emit a space between the operator and the operand. One obvious case\n                // is when the operator is an identifier, like delete or typeof. We also need to do this for plus\n                // and minus expressions in certain cases. Specifically, consider the following two cases (parens\n                // are just for clarity of exposition, and not part of the source code):\n                //\n                //  (+(+1))\n                //  (+(++1))\n                //\n                // We need to emit a space in both cases. In the first case, the absence of a space will make\n                // the resulting expression a prefix increment operation. And in the second, it will make the resulting\n                // expression a prefix increment whose operand is a plus expression - (++(+x))\n                // The same is true of minus of course.\n                if (node.operand.kind === 185 /* PrefixUnaryExpression */) {\n                    var operand = node.operand;\n                    if (node.operator === 35 /* PlusToken */ && (operand.operator === 35 /* PlusToken */ || operand.operator === 41 /* PlusPlusToken */)) {\n                        write(\" \");\n                    }\n                    else if (node.operator === 36 /* MinusToken */ && (operand.operator === 36 /* MinusToken */ || operand.operator === 42 /* MinusMinusToken */)) {\n                        write(\" \");\n                    }\n                }\n                emit(node.operand);\n                if (externalExportChanged) {\n                    write(\")\");\n                }\n            }\n            function emitPostfixUnaryExpression(node) {\n                var externalExportChanged = isNameOfExportedSourceLevelDeclarationInSystemExternalModule(node.operand);\n                var internalExportChanged = isNameOfExportedDeclarationInNonES6Module(node.operand);\n                if (externalExportChanged) {\n                    // export function returns the value that was passes as the second argument\n                    // however for postfix unary expressions result value should be the value before modification.\n                    // emit 'x++' as '(export('x', ++x) - 1)' and 'x--' as '(export('x', --x) + 1)'\n                    write(\"(\" + exportFunctionForFile + \"(\\\"\");\n                    emitNodeWithoutSourceMap(node.operand);\n                    write(\"\\\", \");\n                    write(ts.tokenToString(node.operator));\n                    emit(node.operand);\n                    if (node.operator === 41 /* PlusPlusToken */) {\n                        write(\") - 1)\");\n                    }\n                    else {\n                        write(\") + 1)\");\n                    }\n                }\n                else if (internalExportChanged) {\n                    emitAliasEqual(node.operand);\n                    emit(node.operand);\n                    if (node.operator === 41 /* PlusPlusToken */) {\n                        write(\" += 1\");\n                    }\n                    else {\n                        write(\" -= 1\");\n                    }\n                }\n                else {\n                    emit(node.operand);\n                    write(ts.tokenToString(node.operator));\n                }\n            }\n            function shouldHoistDeclarationInSystemJsModule(node) {\n                return isSourceFileLevelDeclarationInSystemJsModule(node, /*isExported*/ false);\n            }\n            /*\n             * Checks if given node is a source file level declaration (not nested in module/function).\n             * If 'isExported' is true - then declaration must also be exported.\n             * This function is used in two cases:\n             * - check if node is a exported source file level value to determine\n             *   if we should also export the value after its it changed\n             * - check if node is a source level declaration to emit it differently,\n             *   i.e non-exported variable statement 'var x = 1' is hoisted so\n             *   when we emit variable statement 'var' should be dropped.\n             */\n            function isSourceFileLevelDeclarationInSystemJsModule(node, isExported) {\n                if (!node || !isCurrentFileSystemExternalModule()) {\n                    return false;\n                }\n                var current = ts.getRootDeclaration(node).parent;\n                while (current) {\n                    if (current.kind === 256 /* SourceFile */) {\n                        return !isExported || ((ts.getCombinedNodeFlags(node) & 1 /* Export */) !== 0);\n                    }\n                    else if (ts.isDeclaration(current)) {\n                        return false;\n                    }\n                    else {\n                        current = current.parent;\n                    }\n                }\n            }\n            /**\n             * Emit ES7 exponentiation operator downlevel using Math.pow\n             * @param node a binary expression node containing exponentiationOperator (**, **=)\n             */\n            function emitExponentiationOperator(node) {\n                var leftHandSideExpression = node.left;\n                if (node.operatorToken.kind === 60 /* AsteriskAsteriskEqualsToken */) {\n                    var synthesizedLHS = void 0;\n                    var shouldEmitParentheses = false;\n                    if (ts.isElementAccessExpression(leftHandSideExpression)) {\n                        shouldEmitParentheses = true;\n                        write(\"(\");\n                        synthesizedLHS = ts.createSynthesizedNode(173 /* ElementAccessExpression */, /*startsOnNewLine*/ false);\n                        var identifier = emitTempVariableAssignment(leftHandSideExpression.expression, /*canDefineTempVariablesInPlace*/ false, /*shouldEmitCommaBeforeAssignment*/ false);\n                        synthesizedLHS.expression = identifier;\n                        if (leftHandSideExpression.argumentExpression.kind !== 8 /* NumericLiteral */ &&\n                            leftHandSideExpression.argumentExpression.kind !== 9 /* StringLiteral */) {\n                            var tempArgumentExpression = createAndRecordTempVariable(268435456 /* _i */);\n                            synthesizedLHS.argumentExpression = tempArgumentExpression;\n                            emitAssignment(tempArgumentExpression, leftHandSideExpression.argumentExpression, /*shouldEmitCommaBeforeAssignment*/ true, leftHandSideExpression.expression);\n                        }\n                        else {\n                            synthesizedLHS.argumentExpression = leftHandSideExpression.argumentExpression;\n                        }\n                        write(\", \");\n                    }\n                    else if (ts.isPropertyAccessExpression(leftHandSideExpression)) {\n                        shouldEmitParentheses = true;\n                        write(\"(\");\n                        synthesizedLHS = ts.createSynthesizedNode(172 /* PropertyAccessExpression */, /*startsOnNewLine*/ false);\n                        var identifier = emitTempVariableAssignment(leftHandSideExpression.expression, /*canDefineTempVariablesInPlace*/ false, /*shouldEmitCommaBeforeAssignment*/ false);\n                        synthesizedLHS.expression = identifier;\n                        synthesizedLHS.name = leftHandSideExpression.name;\n                        write(\", \");\n                    }\n                    emit(synthesizedLHS || leftHandSideExpression);\n                    write(\" = \");\n                    write(\"Math.pow(\");\n                    emit(synthesizedLHS || leftHandSideExpression);\n                    write(\", \");\n                    emit(node.right);\n                    write(\")\");\n                    if (shouldEmitParentheses) {\n                        write(\")\");\n                    }\n                }\n                else {\n                    write(\"Math.pow(\");\n                    emit(leftHandSideExpression);\n                    write(\", \");\n                    emit(node.right);\n                    write(\")\");\n                }\n            }\n            function emitAliasEqual(name) {\n                for (var _a = 0, _b = exportSpecifiers[name.text]; _a < _b.length; _a++) {\n                    var specifier = _b[_a];\n                    emitStart(specifier.name);\n                    emitContainingModuleName(specifier);\n                    if (languageVersion === 0 /* ES3 */ && name.text === \"default\") {\n                        write('[\"default\"]');\n                    }\n                    else {\n                        write(\".\");\n                        emitNodeWithCommentsAndWithoutSourcemap(specifier.name);\n                    }\n                    emitEnd(specifier.name);\n                    write(\" = \");\n                }\n                return true;\n            }\n            function emitBinaryExpression(node) {\n                if (languageVersion < 2 /* ES6 */ && node.operatorToken.kind === 56 /* EqualsToken */ &&\n                    (node.left.kind === 171 /* ObjectLiteralExpression */ || node.left.kind === 170 /* ArrayLiteralExpression */)) {\n                    emitDestructuring(node, node.parent.kind === 202 /* ExpressionStatement */);\n                }\n                else {\n                    var isAssignment = ts.isAssignmentOperator(node.operatorToken.kind);\n                    var externalExportChanged = isAssignment &&\n                        isNameOfExportedSourceLevelDeclarationInSystemExternalModule(node.left);\n                    if (externalExportChanged) {\n                        // emit assignment 'x <op> y' as 'exports(\"x\", x <op> y)'\n                        write(exportFunctionForFile + \"(\\\"\");\n                        emitNodeWithoutSourceMap(node.left);\n                        write(\"\\\", \");\n                    }\n                    var internalExportChanged = isAssignment &&\n                        isNameOfExportedDeclarationInNonES6Module(node.left);\n                    if (internalExportChanged) {\n                        // export { foo }\n                        // emit foo = 2 as exports.foo = foo = 2\n                        emitAliasEqual(node.left);\n                    }\n                    if (node.operatorToken.kind === 38 /* AsteriskAsteriskToken */ || node.operatorToken.kind === 60 /* AsteriskAsteriskEqualsToken */) {\n                        // Downleveled emit exponentiation operator using Math.pow\n                        emitExponentiationOperator(node);\n                    }\n                    else {\n                        emit(node.left);\n                        // Add indentation before emit the operator if the operator is on different line\n                        // For example:\n                        //      3\n                        //      + 2;\n                        //   emitted as\n                        //      3\n                        //          + 2;\n                        var indentedBeforeOperator = indentIfOnDifferentLines(node, node.left, node.operatorToken, node.operatorToken.kind !== 24 /* CommaToken */ ? \" \" : undefined);\n                        write(ts.tokenToString(node.operatorToken.kind));\n                        var indentedAfterOperator = indentIfOnDifferentLines(node, node.operatorToken, node.right, \" \");\n                        emit(node.right);\n                        decreaseIndentIf(indentedBeforeOperator, indentedAfterOperator);\n                    }\n                    if (externalExportChanged) {\n                        write(\")\");\n                    }\n                }\n            }\n            function synthesizedNodeStartsOnNewLine(node) {\n                return ts.nodeIsSynthesized(node) && node.startsOnNewLine;\n            }\n            function emitConditionalExpression(node) {\n                emit(node.condition);\n                var indentedBeforeQuestion = indentIfOnDifferentLines(node, node.condition, node.questionToken, \" \");\n                write(\"?\");\n                var indentedAfterQuestion = indentIfOnDifferentLines(node, node.questionToken, node.whenTrue, \" \");\n                emit(node.whenTrue);\n                decreaseIndentIf(indentedBeforeQuestion, indentedAfterQuestion);\n                var indentedBeforeColon = indentIfOnDifferentLines(node, node.whenTrue, node.colonToken, \" \");\n                write(\":\");\n                var indentedAfterColon = indentIfOnDifferentLines(node, node.colonToken, node.whenFalse, \" \");\n                emit(node.whenFalse);\n                decreaseIndentIf(indentedBeforeColon, indentedAfterColon);\n            }\n            // Helper function to decrease the indent if we previously indented.  Allows multiple\n            // previous indent values to be considered at a time.  This also allows caller to just\n            // call this once, passing in all their appropriate indent values, instead of needing\n            // to call this helper function multiple times.\n            function decreaseIndentIf(value1, value2) {\n                if (value1) {\n                    decreaseIndent();\n                }\n                if (value2) {\n                    decreaseIndent();\n                }\n            }\n            function isSingleLineEmptyBlock(node) {\n                if (node && node.kind === 199 /* Block */) {\n                    var block = node;\n                    return block.statements.length === 0 && nodeEndIsOnSameLineAsNodeStart(block, block);\n                }\n            }\n            function emitBlock(node) {\n                if (isSingleLineEmptyBlock(node)) {\n                    emitToken(15 /* OpenBraceToken */, node.pos);\n                    write(\" \");\n                    emitToken(16 /* CloseBraceToken */, node.statements.end);\n                    return;\n                }\n                emitToken(15 /* OpenBraceToken */, node.pos);\n                increaseIndent();\n                if (node.kind === 226 /* ModuleBlock */) {\n                    ts.Debug.assert(node.parent.kind === 225 /* ModuleDeclaration */);\n                    emitCaptureThisForNodeIfNecessary(node.parent);\n                }\n                emitLines(node.statements);\n                if (node.kind === 226 /* ModuleBlock */) {\n                    emitTempDeclarations(/*newLine*/ true);\n                }\n                decreaseIndent();\n                writeLine();\n                emitToken(16 /* CloseBraceToken */, node.statements.end);\n            }\n            function emitEmbeddedStatement(node) {\n                if (node.kind === 199 /* Block */) {\n                    write(\" \");\n                    emit(node);\n                }\n                else {\n                    increaseIndent();\n                    writeLine();\n                    emit(node);\n                    decreaseIndent();\n                }\n            }\n            function emitExpressionStatement(node) {\n                emitParenthesizedIf(node.expression, /*parenthesized*/ node.expression.kind === 180 /* ArrowFunction */);\n                write(\";\");\n            }\n            function emitIfStatement(node) {\n                var endPos = emitToken(88 /* IfKeyword */, node.pos);\n                write(\" \");\n                endPos = emitToken(17 /* OpenParenToken */, endPos);\n                emit(node.expression);\n                emitToken(18 /* CloseParenToken */, node.expression.end);\n                emitEmbeddedStatement(node.thenStatement);\n                if (node.elseStatement) {\n                    writeLine();\n                    emitToken(80 /* ElseKeyword */, node.thenStatement.end);\n                    if (node.elseStatement.kind === 203 /* IfStatement */) {\n                        write(\" \");\n                        emit(node.elseStatement);\n                    }\n                    else {\n                        emitEmbeddedStatement(node.elseStatement);\n                    }\n                }\n            }\n            function emitDoStatement(node) {\n                emitLoop(node, emitDoStatementWorker);\n            }\n            function emitDoStatementWorker(node, loop) {\n                write(\"do\");\n                if (loop) {\n                    emitConvertedLoopCall(loop, /*emitAsBlock*/ true);\n                }\n                else {\n                    emitNormalLoopBody(node, /*emitAsEmbeddedStatement*/ true);\n                }\n                if (node.statement.kind === 199 /* Block */) {\n                    write(\" \");\n                }\n                else {\n                    writeLine();\n                }\n                write(\"while (\");\n                emit(node.expression);\n                write(\");\");\n            }\n            function emitWhileStatement(node) {\n                emitLoop(node, emitWhileStatementWorker);\n            }\n            function emitWhileStatementWorker(node, loop) {\n                write(\"while (\");\n                emit(node.expression);\n                write(\")\");\n                if (loop) {\n                    emitConvertedLoopCall(loop, /*emitAsBlock*/ true);\n                }\n                else {\n                    emitNormalLoopBody(node, /*emitAsEmbeddedStatement*/ true);\n                }\n            }\n            /**\n             * Returns true if start of variable declaration list was emitted.\n             * Returns false if nothing was written - this can happen for source file level variable declarations\n             *     in system modules where such variable declarations are hoisted.\n             */\n            function tryEmitStartOfVariableDeclarationList(decl) {\n                if (shouldHoistVariable(decl, /*checkIfSourceFileLevelDecl*/ true)) {\n                    // variables in variable declaration list were already hoisted\n                    return false;\n                }\n                if (convertedLoopState && (ts.getCombinedNodeFlags(decl) & 3072 /* BlockScoped */) === 0) {\n                    // we are inside a converted loop - this can only happen in downlevel scenarios\n                    // record names for all variable declarations\n                    for (var _a = 0, _b = decl.declarations; _a < _b.length; _a++) {\n                        var varDecl = _b[_a];\n                        hoistVariableDeclarationFromLoop(convertedLoopState, varDecl);\n                    }\n                    return false;\n                }\n                emitStart(decl);\n                if (decl && languageVersion >= 2 /* ES6 */) {\n                    if (ts.isLet(decl)) {\n                        write(\"let \");\n                    }\n                    else if (ts.isConst(decl)) {\n                        write(\"const \");\n                    }\n                    else {\n                        write(\"var \");\n                    }\n                }\n                else {\n                    write(\"var \");\n                }\n                // Note here we specifically dont emit end so that if we are going to emit binding pattern\n                // we can alter the source map correctly\n                return true;\n            }\n            function emitVariableDeclarationListSkippingUninitializedEntries(list) {\n                var started = false;\n                for (var _a = 0, _b = list.declarations; _a < _b.length; _a++) {\n                    var decl = _b[_a];\n                    if (!decl.initializer) {\n                        continue;\n                    }\n                    if (!started) {\n                        started = true;\n                    }\n                    else {\n                        write(\", \");\n                    }\n                    emit(decl);\n                }\n                return started;\n            }\n            function shouldConvertLoopBody(node) {\n                return languageVersion < 2 /* ES6 */ &&\n                    (resolver.getNodeCheckFlags(node) & 65536 /* LoopWithCapturedBlockScopedBinding */) !== 0;\n            }\n            function emitLoop(node, loopEmitter) {\n                var shouldConvert = shouldConvertLoopBody(node);\n                if (!shouldConvert) {\n                    loopEmitter(node, /* convertedLoop*/ undefined);\n                }\n                else {\n                    var loop = convertLoopBody(node);\n                    if (node.parent.kind === 214 /* LabeledStatement */) {\n                        // if parent of the loop was labeled statement - attach the label to loop skipping converted loop body\n                        emitLabelAndColon(node.parent);\n                    }\n                    loopEmitter(node, loop);\n                }\n            }\n            function convertLoopBody(node) {\n                var functionName = makeUniqueName(\"_loop\");\n                var loopInitializer;\n                switch (node.kind) {\n                    case 206 /* ForStatement */:\n                    case 207 /* ForInStatement */:\n                    case 208 /* ForOfStatement */:\n                        var initializer = node.initializer;\n                        if (initializer && initializer.kind === 219 /* VariableDeclarationList */) {\n                            loopInitializer = node.initializer;\n                        }\n                        break;\n                }\n                var loopParameters;\n                var loopOutParameters;\n                if (loopInitializer && (ts.getCombinedNodeFlags(loopInitializer) & 3072 /* BlockScoped */)) {\n                    // if loop initializer contains block scoped variables - they should be passed to converted loop body as parameters\n                    loopParameters = [];\n                    for (var _a = 0, _b = loopInitializer.declarations; _a < _b.length; _a++) {\n                        var varDeclaration = _b[_a];\n                        processVariableDeclaration(varDeclaration.name);\n                    }\n                }\n                var bodyIsBlock = node.statement.kind === 199 /* Block */;\n                var paramList = loopParameters ? loopParameters.join(\", \") : \"\";\n                writeLine();\n                write(\"var \" + functionName + \" = function(\" + paramList + \")\");\n                var convertedOuterLoopState = convertedLoopState;\n                convertedLoopState = { loopOutParameters: loopOutParameters };\n                if (convertedOuterLoopState) {\n                    // convertedOuterLoopState !== undefined means that this converted loop is nested in another converted loop.\n                    // if outer converted loop has already accumulated some state - pass it through\n                    if (convertedOuterLoopState.argumentsName) {\n                        // outer loop has already used 'arguments' so we've already have some name to alias it\n                        // use the same name in all nested loops\n                        convertedLoopState.argumentsName = convertedOuterLoopState.argumentsName;\n                    }\n                    if (convertedOuterLoopState.thisName) {\n                        // outer loop has already used 'this' so we've already have some name to alias it\n                        // use the same name in all nested loops\n                        convertedLoopState.thisName = convertedOuterLoopState.thisName;\n                    }\n                    if (convertedOuterLoopState.hoistedLocalVariables) {\n                        // we've already collected some non-block scoped variable declarations in enclosing loop\n                        // use the same storage in nested loop\n                        convertedLoopState.hoistedLocalVariables = convertedOuterLoopState.hoistedLocalVariables;\n                    }\n                }\n                write(\" {\");\n                writeLine();\n                increaseIndent();\n                if (bodyIsBlock) {\n                    emitLines(node.statement.statements);\n                }\n                else {\n                    emit(node.statement);\n                }\n                writeLine();\n                // end of loop body -> copy out parameter\n                copyLoopOutParameters(convertedLoopState, 1 /* ToOutParameter */, /*emitAsStatements*/ true);\n                decreaseIndent();\n                writeLine();\n                write(\"};\");\n                writeLine();\n                if (loopOutParameters) {\n                    // declare variables to hold out params for loop body\n                    write(\"var \");\n                    for (var i = 0; i < loopOutParameters.length; i++) {\n                        if (i !== 0) {\n                            write(\", \");\n                        }\n                        write(loopOutParameters[i].outParamName);\n                    }\n                    write(\";\");\n                    writeLine();\n                }\n                if (convertedLoopState.argumentsName) {\n                    // if alias for arguments is set\n                    if (convertedOuterLoopState) {\n                        // pass it to outer converted loop\n                        convertedOuterLoopState.argumentsName = convertedLoopState.argumentsName;\n                    }\n                    else {\n                        // this is top level converted loop and we need to create an alias for 'arguments' object\n                        write(\"var \" + convertedLoopState.argumentsName + \" = arguments;\");\n                        writeLine();\n                    }\n                }\n                if (convertedLoopState.thisName) {\n                    // if alias for this is set\n                    if (convertedOuterLoopState) {\n                        // pass it to outer converted loop\n                        convertedOuterLoopState.thisName = convertedLoopState.thisName;\n                    }\n                    else {\n                        // this is top level converted loop so we need to create an alias for 'this' here\n                        // NOTE:\n                        // if converted loops were all nested in arrow function then we'll always emit '_this' so convertedLoopState.thisName will not be set.\n                        // If it is set this means that all nested loops are not nested in arrow function and it is safe to capture 'this'.\n                        write(\"var \" + convertedLoopState.thisName + \" = this;\");\n                        writeLine();\n                    }\n                }\n                if (convertedLoopState.hoistedLocalVariables) {\n                    // if hoistedLocalVariables !== undefined this means that we've possibly collected some variable declarations to be hoisted later\n                    if (convertedOuterLoopState) {\n                        // pass them to outer converted loop\n                        convertedOuterLoopState.hoistedLocalVariables = convertedLoopState.hoistedLocalVariables;\n                    }\n                    else {\n                        // deduplicate and hoist collected variable declarations\n                        write(\"var \");\n                        var seen = void 0;\n                        for (var _c = 0, _d = convertedLoopState.hoistedLocalVariables; _c < _d.length; _c++) {\n                            var id = _d[_c];\n                            // Don't initialize seen unless we have at least one element.\n                            // Emit a comma to separate for all but the first element.\n                            if (!seen) {\n                                seen = ts.createMap();\n                            }\n                            else {\n                                write(\", \");\n                            }\n                            if (!(id.text in seen)) {\n                                emit(id);\n                                seen[id.text] = id.text;\n                            }\n                        }\n                        write(\";\");\n                        writeLine();\n                    }\n                }\n                var currentLoopState = convertedLoopState;\n                convertedLoopState = convertedOuterLoopState;\n                return { functionName: functionName, paramList: paramList, state: currentLoopState };\n                function processVariableDeclaration(name) {\n                    if (name.kind === 69 /* Identifier */) {\n                        var nameText = isNameOfNestedBlockScopedRedeclarationOrCapturedBinding(name)\n                            ? getGeneratedNameForNode(name)\n                            : name.text;\n                        loopParameters.push(nameText);\n                        if (resolver.getNodeCheckFlags(name.parent) & 2097152 /* NeedsLoopOutParameter */) {\n                            var reassignedVariable = { originalName: name, outParamName: makeUniqueName(\"out_\" + nameText) };\n                            (loopOutParameters || (loopOutParameters = [])).push(reassignedVariable);\n                        }\n                    }\n                    else {\n                        for (var _a = 0, _b = name.elements; _a < _b.length; _a++) {\n                            var element = _b[_a];\n                            processVariableDeclaration(element.name);\n                        }\n                    }\n                }\n            }\n            function emitNormalLoopBody(node, emitAsEmbeddedStatement) {\n                var saveAllowedNonLabeledJumps;\n                if (convertedLoopState) {\n                    // we get here if we are trying to emit normal loop loop inside converted loop\n                    // set allowedNonLabeledJumps to Break | Continue to mark that break\\continue inside the loop should be emitted as is\n                    saveAllowedNonLabeledJumps = convertedLoopState.allowedNonLabeledJumps;\n                    convertedLoopState.allowedNonLabeledJumps = 2 /* Break */ | 4 /* Continue */;\n                }\n                if (emitAsEmbeddedStatement) {\n                    emitEmbeddedStatement(node.statement);\n                }\n                else if (node.statement.kind === 199 /* Block */) {\n                    emitLines(node.statement.statements);\n                }\n                else {\n                    writeLine();\n                    emit(node.statement);\n                }\n                if (convertedLoopState) {\n                    convertedLoopState.allowedNonLabeledJumps = saveAllowedNonLabeledJumps;\n                }\n            }\n            function copyLoopOutParameters(state, copyDirection, emitAsStatements) {\n                if (state.loopOutParameters) {\n                    for (var _a = 0, _b = state.loopOutParameters; _a < _b.length; _a++) {\n                        var outParam = _b[_a];\n                        if (copyDirection === 0 /* ToOriginal */) {\n                            emitIdentifier(outParam.originalName);\n                            write(\" = \" + outParam.outParamName);\n                        }\n                        else {\n                            write(outParam.outParamName + \" = \");\n                            emitIdentifier(outParam.originalName);\n                        }\n                        if (emitAsStatements) {\n                            write(\";\");\n                            writeLine();\n                        }\n                        else {\n                            write(\", \");\n                        }\n                    }\n                }\n            }\n            function emitConvertedLoopCall(loop, emitAsBlock) {\n                if (emitAsBlock) {\n                    write(\" {\");\n                    writeLine();\n                    increaseIndent();\n                }\n                // loop is considered simple if it does not have any return statements or break\\continue that transfer control outside of the loop\n                // simple loops are emitted as just 'loop()';\n                // NOTE: if loop uses only 'continue' it still will be emitted as simple loop\n                var isSimpleLoop = !(loop.state.nonLocalJumps & ~4 /* Continue */) &&\n                    !loop.state.labeledNonLocalBreaks &&\n                    !loop.state.labeledNonLocalContinues;\n                var loopResult = makeUniqueName(\"state\");\n                if (!isSimpleLoop) {\n                    write(\"var \" + loopResult + \" = \");\n                }\n                write(loop.functionName + \"(\" + loop.paramList + \");\");\n                writeLine();\n                copyLoopOutParameters(loop.state, 0 /* ToOriginal */, /*emitAsStatements*/ true);\n                if (!isSimpleLoop) {\n                    // for non simple loops we need to store result returned from converted loop function and use it to do dispatching\n                    // converted loop function can return:\n                    // - object - used when body of the converted loop contains return statement. Property \"value\" of this object stores retuned value\n                    // - string - used to dispatch jumps. \"break\" and \"continue\" are used to non-labeled jumps, other values are used to transfer control to\n                    //   different labels\n                    writeLine();\n                    if (loop.state.nonLocalJumps & 8 /* Return */) {\n                        write(\"if (typeof \" + loopResult + \" === \\\"object\\\") \");\n                        if (convertedLoopState) {\n                            // we are currently nested in another converted loop - return unwrapped result\n                            write(\"return \" + loopResult + \";\");\n                            // propagate 'hasReturn' flag to outer loop\n                            convertedLoopState.nonLocalJumps |= 8 /* Return */;\n                        }\n                        else {\n                            // top level converted loop - return unwrapped value\n                            write(\"return \" + loopResult + \".value;\");\n                        }\n                        writeLine();\n                    }\n                    if (loop.state.nonLocalJumps & 2 /* Break */) {\n                        write(\"if (\" + loopResult + \" === \\\"break\\\") break;\");\n                        writeLine();\n                    }\n                    // in case of labeled breaks emit code that either breaks to some known label inside outer loop or delegates jump decision to outer loop\n                    emitDispatchTableForLabeledJumps(loopResult, loop.state, convertedLoopState);\n                }\n                if (emitAsBlock) {\n                    writeLine();\n                    decreaseIndent();\n                    write(\"}\");\n                }\n                function emitDispatchTableForLabeledJumps(loopResultVariable, currentLoop, outerLoop) {\n                    if (!currentLoop.labeledNonLocalBreaks && !currentLoop.labeledNonLocalContinues) {\n                        return;\n                    }\n                    write(\"switch(\" + loopResultVariable + \") {\");\n                    increaseIndent();\n                    emitDispatchEntriesForLabeledJumps(currentLoop.labeledNonLocalBreaks, /*isBreak*/ true, loopResultVariable, outerLoop);\n                    emitDispatchEntriesForLabeledJumps(currentLoop.labeledNonLocalContinues, /*isBreak*/ false, loopResultVariable, outerLoop);\n                    decreaseIndent();\n                    writeLine();\n                    write(\"}\");\n                }\n                function emitDispatchEntriesForLabeledJumps(table, isBreak, loopResultVariable, outerLoop) {\n                    if (!table) {\n                        return;\n                    }\n                    for (var labelText in table) {\n                        var labelMarker = table[labelText];\n                        writeLine();\n                        write(\"case \\\"\" + labelMarker + \"\\\": \");\n                        // if there are no outer converted loop or outer label in question is located inside outer converted loop\n                        // then emit labeled break\\continue\n                        // otherwise propagate pair 'label -> marker' to outer converted loop and emit 'return labelMarker' so outer loop can later decide what to do\n                        if (!outerLoop || (outerLoop.labels && outerLoop.labels[labelText])) {\n                            if (isBreak) {\n                                write(\"break \");\n                            }\n                            else {\n                                write(\"continue \");\n                            }\n                            write(labelText + \";\");\n                        }\n                        else {\n                            setLabeledJump(outerLoop, isBreak, labelText, labelMarker);\n                            write(\"return \" + loopResultVariable + \";\");\n                        }\n                    }\n                }\n            }\n            function emitForStatement(node) {\n                emitLoop(node, emitForStatementWorker);\n            }\n            function emitForStatementWorker(node, loop) {\n                var endPos = emitToken(86 /* ForKeyword */, node.pos);\n                write(\" \");\n                endPos = emitToken(17 /* OpenParenToken */, endPos);\n                if (node.initializer && node.initializer.kind === 219 /* VariableDeclarationList */) {\n                    var variableDeclarationList = node.initializer;\n                    var startIsEmitted = tryEmitStartOfVariableDeclarationList(variableDeclarationList);\n                    if (startIsEmitted) {\n                        emitCommaList(variableDeclarationList.declarations);\n                    }\n                    else {\n                        emitVariableDeclarationListSkippingUninitializedEntries(variableDeclarationList);\n                    }\n                }\n                else if (node.initializer) {\n                    emit(node.initializer);\n                }\n                write(\";\");\n                emitOptional(\" \", node.condition);\n                write(\";\");\n                emitOptional(\" \", node.incrementor);\n                write(\")\");\n                if (loop) {\n                    emitConvertedLoopCall(loop, /*emitAsBlock*/ true);\n                }\n                else {\n                    emitNormalLoopBody(node, /*emitAsEmbeddedStatement*/ true);\n                }\n            }\n            function emitForInOrForOfStatement(node) {\n                if (languageVersion < 2 /* ES6 */ && node.kind === 208 /* ForOfStatement */) {\n                    emitLoop(node, emitDownLevelForOfStatementWorker);\n                }\n                else {\n                    emitLoop(node, emitForInOrForOfStatementWorker);\n                }\n            }\n            function emitForInOrForOfStatementWorker(node, loop) {\n                var endPos = emitToken(86 /* ForKeyword */, node.pos);\n                write(\" \");\n                endPos = emitToken(17 /* OpenParenToken */, endPos);\n                if (node.initializer.kind === 219 /* VariableDeclarationList */) {\n                    var variableDeclarationList = node.initializer;\n                    if (variableDeclarationList.declarations.length >= 1) {\n                        tryEmitStartOfVariableDeclarationList(variableDeclarationList);\n                        emit(variableDeclarationList.declarations[0]);\n                    }\n                }\n                else {\n                    emit(node.initializer);\n                }\n                if (node.kind === 207 /* ForInStatement */) {\n                    write(\" in \");\n                }\n                else {\n                    write(\" of \");\n                }\n                emit(node.expression);\n                emitToken(18 /* CloseParenToken */, node.expression.end);\n                if (loop) {\n                    emitConvertedLoopCall(loop, /*emitAsBlock*/ true);\n                }\n                else {\n                    emitNormalLoopBody(node, /*emitAsEmbeddedStatement*/ true);\n                }\n            }\n            function emitDownLevelForOfStatementWorker(node, loop) {\n                // The following ES6 code:\n                //\n                //    for (let v of expr) { }\n                //\n                // should be emitted as\n                //\n                //    for (let _i = 0, _a = expr; _i < _a.length; _i++) {\n                //        let v = _a[_i];\n                //    }\n                //\n                // where _a and _i are temps emitted to capture the RHS and the counter,\n                // respectively.\n                // When the left hand side is an expression instead of a let declaration,\n                // the \"let v\" is not emitted.\n                // When the left hand side is a let/const, the v is renamed if there is\n                // another v in scope.\n                // Note that all assignments to the LHS are emitted in the body, including\n                // all destructuring.\n                // Note also that because an extra statement is needed to assign to the LHS,\n                // for-of bodies are always emitted as blocks.\n                var endPos = emitToken(86 /* ForKeyword */, node.pos);\n                write(\" \");\n                endPos = emitToken(17 /* OpenParenToken */, endPos);\n                // Do not emit the LHS let declaration yet, because it might contain destructuring.\n                // Do not call recordTempDeclaration because we are declaring the temps\n                // right here. Recording means they will be declared later.\n                // In the case where the user wrote an identifier as the RHS, like this:\n                //\n                //     for (let v of arr) { }\n                //\n                // we can't reuse 'arr' because it might be modified within the body of the loop.\n                var counter = createTempVariable(268435456 /* _i */);\n                var rhsReference = ts.createSynthesizedNode(69 /* Identifier */);\n                rhsReference.text = node.expression.kind === 69 /* Identifier */ ?\n                    makeUniqueName(node.expression.text) :\n                    makeTempVariableName(0 /* Auto */);\n                // This is the let keyword for the counter and rhsReference. The let keyword for\n                // the LHS will be emitted inside the body.\n                emitStart(node.expression);\n                write(\"var \");\n                // _i = 0\n                emitNodeWithoutSourceMap(counter);\n                write(\" = 0\");\n                emitEnd(node.expression);\n                // , _a = expr\n                write(\", \");\n                emitStart(node.expression);\n                emitNodeWithoutSourceMap(rhsReference);\n                write(\" = \");\n                emitNodeWithoutSourceMap(node.expression);\n                emitEnd(node.expression);\n                write(\"; \");\n                // _i < _a.length;\n                emitStart(node.expression);\n                emitNodeWithoutSourceMap(counter);\n                write(\" < \");\n                emitNodeWithCommentsAndWithoutSourcemap(rhsReference);\n                write(\".length\");\n                emitEnd(node.expression);\n                write(\"; \");\n                // _i++)\n                emitStart(node.expression);\n                emitNodeWithoutSourceMap(counter);\n                write(\"++\");\n                emitEnd(node.expression);\n                emitToken(18 /* CloseParenToken */, node.expression.end);\n                // Body\n                write(\" {\");\n                writeLine();\n                increaseIndent();\n                // Initialize LHS\n                // let v = _a[_i];\n                var rhsIterationValue = createElementAccessExpression(rhsReference, counter);\n                emitStart(node.initializer);\n                if (node.initializer.kind === 219 /* VariableDeclarationList */) {\n                    write(\"var \");\n                    var variableDeclarationList = node.initializer;\n                    if (variableDeclarationList.declarations.length > 0) {\n                        var declaration = variableDeclarationList.declarations[0];\n                        if (ts.isBindingPattern(declaration.name)) {\n                            // This works whether the declaration is a var, let, or const.\n                            // It will use rhsIterationValue _a[_i] as the initializer.\n                            emitDestructuring(declaration, /*isAssignmentExpressionStatement*/ false, rhsIterationValue);\n                        }\n                        else {\n                            // The following call does not include the initializer, so we have\n                            // to emit it separately.\n                            emitNodeWithCommentsAndWithoutSourcemap(declaration);\n                            write(\" = \");\n                            emitNodeWithoutSourceMap(rhsIterationValue);\n                        }\n                    }\n                    else {\n                        // It's an empty declaration list. This can only happen in an error case, if the user wrote\n                        //     for (let of []) {}\n                        emitNodeWithoutSourceMap(createTempVariable(0 /* Auto */));\n                        write(\" = \");\n                        emitNodeWithoutSourceMap(rhsIterationValue);\n                    }\n                }\n                else {\n                    // Initializer is an expression. Emit the expression in the body, so that it's\n                    // evaluated on every iteration.\n                    var assignmentExpression = createBinaryExpression(node.initializer, 56 /* EqualsToken */, rhsIterationValue, /*startsOnNewLine*/ false);\n                    if (node.initializer.kind === 170 /* ArrayLiteralExpression */ || node.initializer.kind === 171 /* ObjectLiteralExpression */) {\n                        // This is a destructuring pattern, so call emitDestructuring instead of emit. Calling emit will not work, because it will cause\n                        // the BinaryExpression to be passed in instead of the expression statement, which will cause emitDestructuring to crash.\n                        emitDestructuring(assignmentExpression, /*isAssignmentExpressionStatement*/ true, /*value*/ undefined);\n                    }\n                    else {\n                        emitNodeWithCommentsAndWithoutSourcemap(assignmentExpression);\n                    }\n                }\n                emitEnd(node.initializer);\n                write(\";\");\n                if (loop) {\n                    writeLine();\n                    emitConvertedLoopCall(loop, /*emitAsBlock*/ false);\n                }\n                else {\n                    emitNormalLoopBody(node, /*emitAsEmbeddedStatement*/ false);\n                }\n                writeLine();\n                decreaseIndent();\n                write(\"}\");\n            }\n            function emitBreakOrContinueStatement(node) {\n                if (convertedLoopState) {\n                    // check if we can emit break\\continue as is\n                    // it is possible if either\n                    //   - break\\continue is statement labeled and label is located inside the converted loop\n                    //   - break\\continue is non-labeled and located in non-converted loop\\switch statement\n                    var jump = node.kind === 210 /* BreakStatement */ ? 2 /* Break */ : 4 /* Continue */;\n                    var canUseBreakOrContinue = (node.label && convertedLoopState.labels && convertedLoopState.labels[node.label.text]) ||\n                        (!node.label && (convertedLoopState.allowedNonLabeledJumps & jump));\n                    if (!canUseBreakOrContinue) {\n                        write(\"return \");\n                        // explicit exit from loop -> copy out parameters\n                        copyLoopOutParameters(convertedLoopState, 1 /* ToOutParameter */, /*emitAsStatements*/ false);\n                        if (!node.label) {\n                            if (node.kind === 210 /* BreakStatement */) {\n                                convertedLoopState.nonLocalJumps |= 2 /* Break */;\n                                write(\"\\\"break\\\";\");\n                            }\n                            else {\n                                convertedLoopState.nonLocalJumps |= 4 /* Continue */;\n                                // note: return value is emitted only to simplify debugging, call to converted loop body does not do any dispatching on it.\n                                write(\"\\\"continue\\\";\");\n                            }\n                        }\n                        else {\n                            var labelMarker = void 0;\n                            if (node.kind === 210 /* BreakStatement */) {\n                                labelMarker = \"break-\" + node.label.text;\n                                setLabeledJump(convertedLoopState, /*isBreak*/ true, node.label.text, labelMarker);\n                            }\n                            else {\n                                labelMarker = \"continue-\" + node.label.text;\n                                setLabeledJump(convertedLoopState, /*isBreak*/ false, node.label.text, labelMarker);\n                            }\n                            write(\"\\\"\" + labelMarker + \"\\\";\");\n                        }\n                        return;\n                    }\n                }\n                emitToken(node.kind === 210 /* BreakStatement */ ? 70 /* BreakKeyword */ : 75 /* ContinueKeyword */, node.pos);\n                emitOptional(\" \", node.label);\n                write(\";\");\n            }\n            function emitReturnStatement(node) {\n                if (convertedLoopState) {\n                    convertedLoopState.nonLocalJumps |= 8 /* Return */;\n                    write(\"return { value: \");\n                    if (node.expression) {\n                        emit(node.expression);\n                    }\n                    else {\n                        write(\"void 0\");\n                    }\n                    write(\" };\");\n                    return;\n                }\n                emitToken(94 /* ReturnKeyword */, node.pos);\n                emitOptional(\" \", node.expression);\n                write(\";\");\n            }\n            function emitWithStatement(node) {\n                write(\"with (\");\n                emit(node.expression);\n                write(\")\");\n                emitEmbeddedStatement(node.statement);\n            }\n            function emitSwitchStatement(node) {\n                var endPos = emitToken(96 /* SwitchKeyword */, node.pos);\n                write(\" \");\n                emitToken(17 /* OpenParenToken */, endPos);\n                emit(node.expression);\n                endPos = emitToken(18 /* CloseParenToken */, node.expression.end);\n                write(\" \");\n                var saveAllowedNonLabeledJumps;\n                if (convertedLoopState) {\n                    saveAllowedNonLabeledJumps = convertedLoopState.allowedNonLabeledJumps;\n                    // for switch statement allow only non-labeled break\n                    convertedLoopState.allowedNonLabeledJumps |= 2 /* Break */;\n                }\n                emitCaseBlock(node.caseBlock, endPos);\n                if (convertedLoopState) {\n                    convertedLoopState.allowedNonLabeledJumps = saveAllowedNonLabeledJumps;\n                }\n            }\n            function emitCaseBlock(node, startPos) {\n                emitToken(15 /* OpenBraceToken */, startPos);\n                increaseIndent();\n                emitLines(node.clauses);\n                decreaseIndent();\n                writeLine();\n                emitToken(16 /* CloseBraceToken */, node.clauses.end);\n            }\n            function nodeStartPositionsAreOnSameLine(node1, node2) {\n                return ts.getLineOfLocalPositionFromLineMap(currentLineMap, ts.skipTrivia(currentText, node1.pos)) ===\n                    ts.getLineOfLocalPositionFromLineMap(currentLineMap, ts.skipTrivia(currentText, node2.pos));\n            }\n            function nodeEndPositionsAreOnSameLine(node1, node2) {\n                return ts.getLineOfLocalPositionFromLineMap(currentLineMap, node1.end) ===\n                    ts.getLineOfLocalPositionFromLineMap(currentLineMap, node2.end);\n            }\n            function nodeEndIsOnSameLineAsNodeStart(node1, node2) {\n                return ts.getLineOfLocalPositionFromLineMap(currentLineMap, node1.end) ===\n                    ts.getLineOfLocalPositionFromLineMap(currentLineMap, ts.skipTrivia(currentText, node2.pos));\n            }\n            function emitCaseOrDefaultClause(node) {\n                if (node.kind === 249 /* CaseClause */) {\n                    write(\"case \");\n                    emit(node.expression);\n                    write(\":\");\n                }\n                else {\n                    write(\"default:\");\n                }\n                if (node.statements.length === 1 && nodeStartPositionsAreOnSameLine(node, node.statements[0])) {\n                    write(\" \");\n                    emit(node.statements[0]);\n                }\n                else {\n                    increaseIndent();\n                    emitLines(node.statements);\n                    decreaseIndent();\n                }\n            }\n            function emitThrowStatement(node) {\n                write(\"throw \");\n                emit(node.expression);\n                write(\";\");\n            }\n            function emitTryStatement(node) {\n                write(\"try \");\n                emit(node.tryBlock);\n                emit(node.catchClause);\n                if (node.finallyBlock) {\n                    writeLine();\n                    write(\"finally \");\n                    emit(node.finallyBlock);\n                }\n            }\n            function emitCatchClause(node) {\n                writeLine();\n                var endPos = emitToken(72 /* CatchKeyword */, node.pos);\n                write(\" \");\n                emitToken(17 /* OpenParenToken */, endPos);\n                emit(node.variableDeclaration);\n                emitToken(18 /* CloseParenToken */, node.variableDeclaration ? node.variableDeclaration.end : endPos);\n                write(\" \");\n                emitBlock(node.block);\n            }\n            function emitDebuggerStatement(node) {\n                emitToken(76 /* DebuggerKeyword */, node.pos);\n                write(\";\");\n            }\n            function emitLabelAndColon(node) {\n                emit(node.label);\n                write(\": \");\n            }\n            function emitLabeledStatement(node) {\n                if (!ts.isIterationStatement(node.statement, /* lookInLabeledStatements */ false) || !shouldConvertLoopBody(node.statement)) {\n                    emitLabelAndColon(node);\n                }\n                if (convertedLoopState) {\n                    if (!convertedLoopState.labels) {\n                        convertedLoopState.labels = ts.createMap();\n                    }\n                    convertedLoopState.labels[node.label.text] = node.label.text;\n                }\n                emit(node.statement);\n                if (convertedLoopState) {\n                    convertedLoopState.labels[node.label.text] = undefined;\n                }\n            }\n            function getContainingModule(node) {\n                do {\n                    node = node.parent;\n                } while (node && node.kind !== 225 /* ModuleDeclaration */);\n                return node;\n            }\n            function emitContainingModuleName(node) {\n                var container = getContainingModule(node);\n                write(container ? getGeneratedNameForNode(container) : \"exports\");\n            }\n            function emitModuleMemberName(node) {\n                emitStart(node.name);\n                if (ts.getCombinedNodeFlags(node) & 1 /* Export */) {\n                    var container = getContainingModule(node);\n                    if (container) {\n                        write(getGeneratedNameForNode(container));\n                        write(\".\");\n                    }\n                    else if (modulekind !== ts.ModuleKind.ES6 && modulekind !== ts.ModuleKind.System) {\n                        write(\"exports.\");\n                    }\n                }\n                emitNodeWithCommentsAndWithoutSourcemap(node.name);\n                emitEnd(node.name);\n            }\n            function createVoidZero() {\n                var zero = ts.createSynthesizedNode(8 /* NumericLiteral */);\n                zero.text = \"0\";\n                var result = ts.createSynthesizedNode(183 /* VoidExpression */);\n                result.expression = zero;\n                return result;\n            }\n            function emitEs6ExportDefaultCompat(node) {\n                if (node.parent.kind === 256 /* SourceFile */) {\n                    ts.Debug.assert(!!(node.flags & 512 /* Default */) || node.kind === 235 /* ExportAssignment */);\n                    // only allow export default at a source file level\n                    if (modulekind === ts.ModuleKind.CommonJS || modulekind === ts.ModuleKind.AMD || modulekind === ts.ModuleKind.UMD) {\n                        if (!isEs6Module) {\n                            if (languageVersion !== 0 /* ES3 */) {\n                                // default value of configurable, enumerable, writable are `false`.\n                                write('Object.defineProperty(exports, \"__esModule\", { value: true });');\n                                writeLine();\n                            }\n                            else {\n                                write(\"exports.__esModule = true;\");\n                                writeLine();\n                            }\n                        }\n                    }\n                }\n            }\n            function emitExportMemberAssignment(node) {\n                if (node.flags & 1 /* Export */) {\n                    writeLine();\n                    emitStart(node);\n                    // emit call to exporter only for top level nodes\n                    if (modulekind === ts.ModuleKind.System && node.parent === currentSourceFile) {\n                        // emit export default <smth> as\n                        // export(\"default\", <smth>)\n                        write(exportFunctionForFile + \"(\\\"\");\n                        if (node.flags & 512 /* Default */) {\n                            write(\"default\");\n                        }\n                        else {\n                            emitNodeWithCommentsAndWithoutSourcemap(node.name);\n                        }\n                        write(\"\\\", \");\n                        emitDeclarationName(node);\n                        write(\")\");\n                    }\n                    else {\n                        if (node.flags & 512 /* Default */) {\n                            emitEs6ExportDefaultCompat(node);\n                            if (languageVersion === 0 /* ES3 */) {\n                                write('exports[\"default\"]');\n                            }\n                            else {\n                                write(\"exports.default\");\n                            }\n                        }\n                        else {\n                            emitModuleMemberName(node);\n                        }\n                        write(\" = \");\n                        emitDeclarationName(node);\n                    }\n                    emitEnd(node);\n                    write(\";\");\n                }\n            }\n            function emitExportMemberAssignments(name) {\n                if (modulekind === ts.ModuleKind.System) {\n                    return;\n                }\n                if (!exportEquals && exportSpecifiers && name.text in exportSpecifiers) {\n                    for (var _a = 0, _b = exportSpecifiers[name.text]; _a < _b.length; _a++) {\n                        var specifier = _b[_a];\n                        writeLine();\n                        emitStart(specifier.name);\n                        emitContainingModuleName(specifier);\n                        write(\".\");\n                        emitNodeWithCommentsAndWithoutSourcemap(specifier.name);\n                        emitEnd(specifier.name);\n                        write(\" = \");\n                        emitExpressionIdentifier(name);\n                        write(\";\");\n                    }\n                }\n            }\n            function emitExportSpecifierInSystemModule(specifier) {\n                ts.Debug.assert(modulekind === ts.ModuleKind.System);\n                if (!resolver.getReferencedValueDeclaration(specifier.propertyName || specifier.name) && !resolver.isValueAliasDeclaration(specifier)) {\n                    return;\n                }\n                writeLine();\n                emitStart(specifier.name);\n                write(exportFunctionForFile + \"(\\\"\");\n                emitNodeWithCommentsAndWithoutSourcemap(specifier.name);\n                write(\"\\\", \");\n                emitExpressionIdentifier(specifier.propertyName || specifier.name);\n                write(\")\");\n                emitEnd(specifier.name);\n                write(\";\");\n            }\n            /**\n             * Emit an assignment to a given identifier, 'name', with a given expression, 'value'.\n             * @param name an identifier as a left-hand-side operand of the assignment\n             * @param value an expression as a right-hand-side operand of the assignment\n             * @param shouldEmitCommaBeforeAssignment a boolean indicating whether to prefix an assignment with comma\n             */\n            function emitAssignment(name, value, shouldEmitCommaBeforeAssignment, nodeForSourceMap) {\n                if (shouldEmitCommaBeforeAssignment) {\n                    write(\", \");\n                }\n                var exportChanged = isNameOfExportedSourceLevelDeclarationInSystemExternalModule(name);\n                if (exportChanged) {\n                    write(exportFunctionForFile + \"(\\\"\");\n                    emitNodeWithCommentsAndWithoutSourcemap(name);\n                    write(\"\\\", \");\n                }\n                var isVariableDeclarationOrBindingElement = name.parent && (name.parent.kind === 218 /* VariableDeclaration */ || name.parent.kind === 169 /* BindingElement */);\n                // If this is first var declaration, we need to start at var/let/const keyword instead\n                // otherwise use nodeForSourceMap as the start position\n                emitStart(isFirstVariableDeclaration(nodeForSourceMap) ? nodeForSourceMap.parent : nodeForSourceMap);\n                withTemporaryNoSourceMap(function () {\n                    if (isVariableDeclarationOrBindingElement) {\n                        emitModuleMemberName(name.parent);\n                    }\n                    else {\n                        emit(name);\n                    }\n                    write(\" = \");\n                    emit(value);\n                });\n                emitEnd(nodeForSourceMap, /*stopOverridingSpan*/ true);\n                if (exportChanged) {\n                    write(\")\");\n                }\n            }\n            /**\n             * Create temporary variable, emit an assignment of the variable the given expression\n             * @param expression an expression to assign to the newly created temporary variable\n             * @param canDefineTempVariablesInPlace a boolean indicating whether you can define the temporary variable at an assignment location\n             * @param shouldEmitCommaBeforeAssignment a boolean indicating whether an assignment should prefix with comma\n             */\n            function emitTempVariableAssignment(expression, canDefineTempVariablesInPlace, shouldEmitCommaBeforeAssignment, sourceMapNode) {\n                var identifier = createTempVariable(0 /* Auto */);\n                if (!canDefineTempVariablesInPlace) {\n                    recordTempDeclaration(identifier);\n                }\n                emitAssignment(identifier, expression, shouldEmitCommaBeforeAssignment, sourceMapNode || expression.parent);\n                return identifier;\n            }\n            function isFirstVariableDeclaration(root) {\n                return root.kind === 218 /* VariableDeclaration */ &&\n                    root.parent.kind === 219 /* VariableDeclarationList */ &&\n                    root.parent.declarations[0] === root;\n            }\n            function emitDestructuring(root, isAssignmentExpressionStatement, value) {\n                var emitCount = 0;\n                // An exported declaration is actually emitted as an assignment (to a property on the module object), so\n                // temporary variables in an exported declaration need to have real declarations elsewhere\n                // Also temporary variables should be explicitly allocated for source level declarations when module target is system\n                // because actual variable declarations are hoisted\n                var canDefineTempVariablesInPlace = false;\n                if (root.kind === 218 /* VariableDeclaration */) {\n                    var isExported = ts.getCombinedNodeFlags(root) & 1 /* Export */;\n                    var isSourceLevelForSystemModuleKind = shouldHoistDeclarationInSystemJsModule(root);\n                    canDefineTempVariablesInPlace = !isExported && !isSourceLevelForSystemModuleKind;\n                }\n                else if (root.kind === 142 /* Parameter */) {\n                    canDefineTempVariablesInPlace = true;\n                }\n                if (root.kind === 187 /* BinaryExpression */) {\n                    emitAssignmentExpression(root);\n                }\n                else {\n                    ts.Debug.assert(!isAssignmentExpressionStatement);\n                    // If first variable declaration of variable statement correct the start location\n                    if (isFirstVariableDeclaration(root)) {\n                        // Use emit location of \"var \" as next emit start entry\n                        sourceMap.changeEmitSourcePos();\n                    }\n                    emitBindingElement(root, value);\n                }\n                /**\n                 * Ensures that there exists a declared identifier whose value holds the given expression.\n                 * This function is useful to ensure that the expression's value can be read from in subsequent expressions.\n                 * Unless 'reuseIdentifierExpressions' is false, 'expr' will be returned if it is just an identifier.\n                 *\n                 * @param expr the expression whose value needs to be bound.\n                 * @param reuseIdentifierExpressions true if identifier expressions can simply be returned;\n                 *                                   false if it is necessary to always emit an identifier.\n                 */\n                function ensureIdentifier(expr, reuseIdentifierExpressions, sourceMapNode) {\n                    if (expr.kind === 69 /* Identifier */ && reuseIdentifierExpressions) {\n                        return expr;\n                    }\n                    var identifier = emitTempVariableAssignment(expr, canDefineTempVariablesInPlace, emitCount > 0, sourceMapNode);\n                    emitCount++;\n                    return identifier;\n                }\n                function createDefaultValueCheck(value, defaultValue, sourceMapNode) {\n                    // The value expression will be evaluated twice, so for anything but a simple identifier\n                    // we need to generate a temporary variable\n                    // If the temporary variable needs to be emitted use the source Map node for assignment of that statement\n                    value = ensureIdentifier(value, /*reuseIdentifierExpressions*/ true, sourceMapNode);\n                    // Return the expression 'value === void 0 ? defaultValue : value'\n                    var equals = ts.createSynthesizedNode(187 /* BinaryExpression */);\n                    equals.left = value;\n                    equals.operatorToken = ts.createSynthesizedNode(32 /* EqualsEqualsEqualsToken */);\n                    equals.right = createVoidZero();\n                    return createConditionalExpression(equals, defaultValue, value);\n                }\n                function createConditionalExpression(condition, whenTrue, whenFalse) {\n                    var cond = ts.createSynthesizedNode(188 /* ConditionalExpression */);\n                    cond.condition = condition;\n                    cond.questionToken = ts.createSynthesizedNode(53 /* QuestionToken */);\n                    cond.whenTrue = whenTrue;\n                    cond.colonToken = ts.createSynthesizedNode(54 /* ColonToken */);\n                    cond.whenFalse = whenFalse;\n                    return cond;\n                }\n                function createNumericLiteral(value) {\n                    var node = ts.createSynthesizedNode(8 /* NumericLiteral */);\n                    node.text = \"\" + value;\n                    return node;\n                }\n                function createPropertyAccessForDestructuringProperty(object, propName) {\n                    var index;\n                    var nameIsComputed = propName.kind === 140 /* ComputedPropertyName */;\n                    if (nameIsComputed) {\n                        // TODO to handle when we look into sourcemaps for computed properties, for now use propName\n                        index = ensureIdentifier(propName.expression, /*reuseIdentifierExpressions*/ false, propName);\n                    }\n                    else {\n                        // We create a synthetic copy of the identifier in order to avoid the rewriting that might\n                        // otherwise occur when the identifier is emitted.\n                        index = ts.createSynthesizedNode(propName.kind);\n                        // We need to unescape identifier here because when parsing an identifier prefixing with \"__\"\n                        // the parser need to append \"_\" in order to escape colliding with magic identifiers such as \"__proto__\"\n                        // Therefore, in order to correctly emit identifiers that are written in original TypeScript file,\n                        // we will unescapeIdentifier to remove additional underscore (if no underscore is added, the function will return original input string)\n                        index.text = ts.unescapeIdentifier(propName.text);\n                    }\n                    return !nameIsComputed && index.kind === 69 /* Identifier */\n                        ? createPropertyAccessExpression(object, index)\n                        : createElementAccessExpression(object, index);\n                }\n                function createSliceCall(value, sliceIndex) {\n                    var call = ts.createSynthesizedNode(174 /* CallExpression */);\n                    var sliceIdentifier = ts.createSynthesizedNode(69 /* Identifier */);\n                    sliceIdentifier.text = \"slice\";\n                    call.expression = createPropertyAccessExpression(value, sliceIdentifier);\n                    call.arguments = ts.createSynthesizedNodeArray();\n                    call.arguments[0] = createNumericLiteral(sliceIndex);\n                    return call;\n                }\n                function emitObjectLiteralAssignment(target, value, sourceMapNode) {\n                    var properties = target.properties;\n                    if (properties.length !== 1) {\n                        // For anything but a single element destructuring we need to generate a temporary\n                        // to ensure value is evaluated exactly once.\n                        // When doing so we want to highlight the passed in source map node since thats the one needing this temp assignment\n                        value = ensureIdentifier(value, /*reuseIdentifierExpressions*/ true, sourceMapNode);\n                    }\n                    for (var _a = 0, properties_5 = properties; _a < properties_5.length; _a++) {\n                        var p = properties_5[_a];\n                        if (p.kind === 253 /* PropertyAssignment */ || p.kind === 254 /* ShorthandPropertyAssignment */) {\n                            var propName = p.name;\n                            var target_1 = p.kind === 254 /* ShorthandPropertyAssignment */ ? p : p.initializer || propName;\n                            // Assignment for target = value.propName should highlight whole property, hence use p as source map node\n                            emitDestructuringAssignment(target_1, createPropertyAccessForDestructuringProperty(value, propName), p);\n                        }\n                    }\n                }\n                function emitArrayLiteralAssignment(target, value, sourceMapNode) {\n                    var elements = target.elements;\n                    if (elements.length !== 1) {\n                        // For anything but a single element destructuring we need to generate a temporary\n                        // to ensure value is evaluated exactly once.\n                        // When doing so we want to highlight the passed in source map node since thats the one needing this temp assignment\n                        value = ensureIdentifier(value, /*reuseIdentifierExpressions*/ true, sourceMapNode);\n                    }\n                    for (var i = 0; i < elements.length; i++) {\n                        var e = elements[i];\n                        if (e.kind !== 193 /* OmittedExpression */) {\n                            // Assignment for target = value.propName should highlight whole property, hence use e as source map node\n                            if (e.kind !== 191 /* SpreadElementExpression */) {\n                                emitDestructuringAssignment(e, createElementAccessExpression(value, createNumericLiteral(i)), e);\n                            }\n                            else if (i === elements.length - 1) {\n                                emitDestructuringAssignment(e.expression, createSliceCall(value, i), e);\n                            }\n                        }\n                    }\n                }\n                function emitDestructuringAssignment(target, value, sourceMapNode) {\n                    // When emitting target = value use source map node to highlight, including any temporary assignments needed for this\n                    if (target.kind === 254 /* ShorthandPropertyAssignment */) {\n                        if (target.objectAssignmentInitializer) {\n                            value = createDefaultValueCheck(value, target.objectAssignmentInitializer, sourceMapNode);\n                        }\n                        target = target.name;\n                    }\n                    else if (target.kind === 187 /* BinaryExpression */ && target.operatorToken.kind === 56 /* EqualsToken */) {\n                        value = createDefaultValueCheck(value, target.right, sourceMapNode);\n                        target = target.left;\n                    }\n                    if (target.kind === 171 /* ObjectLiteralExpression */) {\n                        emitObjectLiteralAssignment(target, value, sourceMapNode);\n                    }\n                    else if (target.kind === 170 /* ArrayLiteralExpression */) {\n                        emitArrayLiteralAssignment(target, value, sourceMapNode);\n                    }\n                    else {\n                        emitAssignment(target, value, /*shouldEmitCommaBeforeAssignment*/ emitCount > 0, sourceMapNode);\n                        emitCount++;\n                    }\n                }\n                function emitAssignmentExpression(root) {\n                    var target = root.left;\n                    var value = root.right;\n                    if (ts.isEmptyObjectLiteralOrArrayLiteral(target)) {\n                        emit(value);\n                    }\n                    else if (isAssignmentExpressionStatement) {\n                        // Source map node for root.left = root.right is root\n                        // but if root is synthetic, which could be in below case, use the target which is { a }\n                        // for ({a} of {a: string}) {\n                        // }\n                        emitDestructuringAssignment(target, value, ts.nodeIsSynthesized(root) ? target : root);\n                    }\n                    else {\n                        if (root.parent.kind !== 178 /* ParenthesizedExpression */) {\n                            write(\"(\");\n                        }\n                        // Temporary assignment needed to emit root should highlight whole binary expression\n                        value = ensureIdentifier(value, /*reuseIdentifierExpressions*/ true, root);\n                        // Source map node for root.left = root.right is root\n                        emitDestructuringAssignment(target, value, root);\n                        write(\", \");\n                        emit(value);\n                        if (root.parent.kind !== 178 /* ParenthesizedExpression */) {\n                            write(\")\");\n                        }\n                    }\n                }\n                function emitBindingElement(target, value) {\n                    // Any temporary assignments needed to emit target = value should point to target\n                    if (target.initializer) {\n                        // Combine value and initializer\n                        value = value ? createDefaultValueCheck(value, target.initializer, target) : target.initializer;\n                    }\n                    else if (!value) {\n                        // Use 'void 0' in absence of value and initializer\n                        value = createVoidZero();\n                    }\n                    if (ts.isBindingPattern(target.name)) {\n                        var pattern = target.name;\n                        var elements = pattern.elements;\n                        var numElements = elements.length;\n                        if (numElements !== 1) {\n                            // For anything other than a single-element destructuring we need to generate a temporary\n                            // to ensure value is evaluated exactly once. Additionally, if we have zero elements\n                            // we need to emit *something* to ensure that in case a 'var' keyword was already emitted,\n                            // so in that case, we'll intentionally create that temporary.\n                            value = ensureIdentifier(value, /*reuseIdentifierExpressions*/ numElements !== 0, target);\n                        }\n                        for (var i = 0; i < numElements; i++) {\n                            var element = elements[i];\n                            if (pattern.kind === 167 /* ObjectBindingPattern */) {\n                                // Rewrite element to a declaration with an initializer that fetches property\n                                var propName = element.propertyName || element.name;\n                                emitBindingElement(element, createPropertyAccessForDestructuringProperty(value, propName));\n                            }\n                            else if (element.kind !== 193 /* OmittedExpression */) {\n                                if (!element.dotDotDotToken) {\n                                    // Rewrite element to a declaration that accesses array element at index i\n                                    emitBindingElement(element, createElementAccessExpression(value, createNumericLiteral(i)));\n                                }\n                                else if (i === numElements - 1) {\n                                    emitBindingElement(element, createSliceCall(value, i));\n                                }\n                            }\n                        }\n                    }\n                    else {\n                        emitAssignment(target.name, value, /*shouldEmitCommaBeforeAssignment*/ emitCount > 0, target);\n                        emitCount++;\n                    }\n                }\n            }\n            function emitVariableDeclaration(node) {\n                if (ts.isBindingPattern(node.name)) {\n                    var isExported = ts.getCombinedNodeFlags(node) & 1 /* Export */;\n                    if (languageVersion >= 2 /* ES6 */ && (!isExported || modulekind === ts.ModuleKind.ES6)) {\n                        // emit ES6 destructuring only if target module is ES6 or variable is not exported\n                        // exported variables in CJS/AMD are prefixed with 'exports.' so result javascript { exports.toString } = 1; is illegal\n                        var isTopLevelDeclarationInSystemModule = modulekind === ts.ModuleKind.System &&\n                            shouldHoistVariable(node, /*checkIfSourceFileLevelDecl*/ true);\n                        if (isTopLevelDeclarationInSystemModule) {\n                            // In System modules top level variables are hoisted\n                            // so variable declarations with destructuring are turned into destructuring assignments.\n                            // As a result, they will need parentheses to disambiguate object binding assignments from blocks.\n                            write(\"(\");\n                        }\n                        emit(node.name);\n                        emitOptional(\" = \", node.initializer);\n                        if (isTopLevelDeclarationInSystemModule) {\n                            write(\")\");\n                        }\n                    }\n                    else {\n                        emitDestructuring(node, /*isAssignmentExpressionStatement*/ false);\n                    }\n                }\n                else {\n                    var initializer = node.initializer;\n                    if (!initializer &&\n                        languageVersion < 2 /* ES6 */ &&\n                        // for names - binding patterns that lack initializer there is no point to emit explicit initializer\n                        // since downlevel codegen for destructuring will fail in the absence of initializer so all binding elements will say uninitialized\n                        node.name.kind === 69 /* Identifier */) {\n                        var container = ts.getEnclosingBlockScopeContainer(node);\n                        var flags = resolver.getNodeCheckFlags(node);\n                        // nested let bindings might need to be initialized explicitly to preserve ES6 semantic\n                        // { let x = 1; }\n                        // { let x; } // x here should be undefined. not 1\n                        // NOTES:\n                        // Top level bindings never collide with anything and thus don't require explicit initialization.\n                        // As for nested let bindings there are two cases:\n                        // - nested let bindings that were not renamed definitely should be initialized explicitly\n                        //   { let x = 1; }\n                        //   { let x; if (some-condition) { x = 1}; if (x) { /*1*/ } }\n                        //   Without explicit initialization code in /*1*/ can be executed even if some-condition is evaluated to false\n                        // - renaming introduces fresh name that should not collide with any existing names, however renamed bindings sometimes also should be\n                        //   explicitly initialized. One particular case: non-captured binding declared inside loop body (but not in loop initializer)\n                        //   let x;\n                        //   for (;;) {\n                        //       let x;\n                        //   }\n                        //   in downlevel codegen inner 'x' will be renamed so it won't collide with outer 'x' however it will should be reset on every iteration\n                        //   as if it was declared anew.\n                        //   * Why non-captured binding - because if loop contains block scoped binding captured in some function then loop body will be rewritten\n                        //   to have a fresh scope on every iteration so everything will just work.\n                        //   * Why loop initializer is excluded - since we've introduced a fresh name it already will be undefined.\n                        var isCapturedInFunction = flags & 131072 /* CapturedBlockScopedBinding */;\n                        var isDeclaredInLoop = flags & 262144 /* BlockScopedBindingInLoop */;\n                        var emittedAsTopLevel = ts.isBlockScopedContainerTopLevel(container) ||\n                            (isCapturedInFunction && isDeclaredInLoop && container.kind === 199 /* Block */ && ts.isIterationStatement(container.parent, /*lookInLabeledStatements*/ false));\n                        var emittedAsNestedLetDeclaration = ts.getCombinedNodeFlags(node) & 1024 /* Let */ &&\n                            !emittedAsTopLevel;\n                        var emitExplicitInitializer = emittedAsNestedLetDeclaration &&\n                            container.kind !== 207 /* ForInStatement */ &&\n                            container.kind !== 208 /* ForOfStatement */ &&\n                            (!resolver.isDeclarationWithCollidingName(node) ||\n                                (isDeclaredInLoop && !isCapturedInFunction && !ts.isIterationStatement(container, /*lookInLabeledStatements*/ false)));\n                        if (emitExplicitInitializer) {\n                            initializer = createVoidZero();\n                        }\n                    }\n                    var exportChanged = isNameOfExportedSourceLevelDeclarationInSystemExternalModule(node.name);\n                    if (exportChanged) {\n                        write(exportFunctionForFile + \"(\\\"\");\n                        emitNodeWithCommentsAndWithoutSourcemap(node.name);\n                        write(\"\\\", \");\n                    }\n                    emitModuleMemberName(node);\n                    emitOptional(\" = \", initializer);\n                    if (exportChanged) {\n                        write(\")\");\n                    }\n                }\n            }\n            function emitExportVariableAssignments(node) {\n                if (node.kind === 193 /* OmittedExpression */) {\n                    return;\n                }\n                var name = node.name;\n                if (name.kind === 69 /* Identifier */) {\n                    emitExportMemberAssignments(name);\n                }\n                else if (ts.isBindingPattern(name)) {\n                    ts.forEach(name.elements, emitExportVariableAssignments);\n                }\n            }\n            function isES6ExportedDeclaration(node) {\n                return !!(node.flags & 1 /* Export */) &&\n                    modulekind === ts.ModuleKind.ES6 &&\n                    node.parent.kind === 256 /* SourceFile */;\n            }\n            function emitVariableStatement(node) {\n                var startIsEmitted = false;\n                if (node.flags & 1 /* Export */) {\n                    if (isES6ExportedDeclaration(node)) {\n                        // Exported ES6 module member\n                        write(\"export \");\n                        startIsEmitted = tryEmitStartOfVariableDeclarationList(node.declarationList);\n                    }\n                }\n                else {\n                    startIsEmitted = tryEmitStartOfVariableDeclarationList(node.declarationList);\n                }\n                if (startIsEmitted) {\n                    emitCommaList(node.declarationList.declarations);\n                    write(\";\");\n                }\n                else {\n                    var atLeastOneItem = emitVariableDeclarationListSkippingUninitializedEntries(node.declarationList);\n                    if (atLeastOneItem) {\n                        write(\";\");\n                    }\n                }\n                if (modulekind !== ts.ModuleKind.ES6 && node.parent === currentSourceFile) {\n                    ts.forEach(node.declarationList.declarations, emitExportVariableAssignments);\n                }\n            }\n            function shouldEmitLeadingAndTrailingCommentsForVariableStatement(node) {\n                // If we're not exporting the variables, there's nothing special here.\n                // Always emit comments for these nodes.\n                if (!(node.flags & 1 /* Export */)) {\n                    return true;\n                }\n                // If we are exporting, but it's a top-level ES6 module exports,\n                // we'll emit the declaration list verbatim, so emit comments too.\n                if (isES6ExportedDeclaration(node)) {\n                    return true;\n                }\n                // Otherwise, only emit if we have at least one initializer present.\n                for (var _a = 0, _b = node.declarationList.declarations; _a < _b.length; _a++) {\n                    var declaration = _b[_a];\n                    if (declaration.initializer) {\n                        return true;\n                    }\n                }\n                return false;\n            }\n            function emitParameter(node) {\n                if (languageVersion < 2 /* ES6 */) {\n                    if (ts.isBindingPattern(node.name)) {\n                        var name_29 = createTempVariable(0 /* Auto */);\n                        if (!tempParameters) {\n                            tempParameters = [];\n                        }\n                        tempParameters.push(name_29);\n                        emit(name_29);\n                    }\n                    else {\n                        emit(node.name);\n                    }\n                }\n                else {\n                    if (node.dotDotDotToken) {\n                        write(\"...\");\n                    }\n                    emit(node.name);\n                    emitOptional(\" = \", node.initializer);\n                }\n            }\n            function emitDefaultValueAssignments(node) {\n                if (languageVersion < 2 /* ES6 */) {\n                    var tempIndex_1 = 0;\n                    ts.forEach(node.parameters, function (parameter) {\n                        // A rest parameter cannot have a binding pattern or an initializer,\n                        // so let's just ignore it.\n                        if (parameter.dotDotDotToken) {\n                            return;\n                        }\n                        var paramName = parameter.name, initializer = parameter.initializer;\n                        if (ts.isBindingPattern(paramName)) {\n                            // In cases where a binding pattern is simply '[]' or '{}',\n                            // we usually don't want to emit a var declaration; however, in the presence\n                            // of an initializer, we must emit that expression to preserve side effects.\n                            var hasBindingElements = paramName.elements.length > 0;\n                            if (hasBindingElements || initializer) {\n                                writeLine();\n                                write(\"var \");\n                                if (hasBindingElements) {\n                                    emitDestructuring(parameter, /*isAssignmentExpressionStatement*/ false, tempParameters[tempIndex_1]);\n                                }\n                                else {\n                                    emit(tempParameters[tempIndex_1]);\n                                    write(\" = \");\n                                    emit(initializer);\n                                }\n                                write(\";\");\n                            }\n                            // Regardless of whether we will emit a var declaration for the binding pattern, we generate the temporary\n                            // variable for the parameter (see: emitParameter)\n                            tempIndex_1++;\n                        }\n                        else if (initializer) {\n                            writeLine();\n                            emitStart(parameter);\n                            write(\"if (\");\n                            emitNodeWithoutSourceMap(paramName);\n                            write(\" === void 0)\");\n                            emitEnd(parameter);\n                            write(\" { \");\n                            emitStart(parameter);\n                            emitNodeWithCommentsAndWithoutSourcemap(paramName);\n                            write(\" = \");\n                            emitNodeWithCommentsAndWithoutSourcemap(initializer);\n                            emitEnd(parameter);\n                            write(\"; }\");\n                        }\n                    });\n                }\n            }\n            function emitRestParameter(node) {\n                if (languageVersion < 2 /* ES6 */ && ts.hasDeclaredRestParameter(node)) {\n                    var restParam = node.parameters[node.parameters.length - 1];\n                    // A rest parameter cannot have a binding pattern, so let's just ignore it if it does.\n                    if (ts.isBindingPattern(restParam.name)) {\n                        return;\n                    }\n                    var skipThisCount = node.parameters.length && node.parameters[0].name.originalKeywordKind === 97 /* ThisKeyword */ ? 1 : 0;\n                    var restIndex = node.parameters.length - 1 - skipThisCount;\n                    var tempName = createTempVariable(268435456 /* _i */).text;\n                    writeLine();\n                    emitLeadingComments(restParam);\n                    emitStart(restParam);\n                    write(\"var \");\n                    emitNodeWithCommentsAndWithoutSourcemap(restParam.name);\n                    write(\" = [];\");\n                    emitEnd(restParam);\n                    emitTrailingComments(restParam);\n                    writeLine();\n                    write(\"for (\");\n                    emitStart(restParam);\n                    write(\"var \" + tempName + \" = \" + restIndex + \";\");\n                    emitEnd(restParam);\n                    write(\" \");\n                    emitStart(restParam);\n                    write(tempName + \" < arguments.length;\");\n                    emitEnd(restParam);\n                    write(\" \");\n                    emitStart(restParam);\n                    write(tempName + \"++\");\n                    emitEnd(restParam);\n                    write(\") {\");\n                    increaseIndent();\n                    writeLine();\n                    emitStart(restParam);\n                    emitNodeWithCommentsAndWithoutSourcemap(restParam.name);\n                    write(\"[\" + tempName + \" - \" + restIndex + \"] = arguments[\" + tempName + \"];\");\n                    emitEnd(restParam);\n                    decreaseIndent();\n                    writeLine();\n                    write(\"}\");\n                }\n            }\n            function emitAccessor(node) {\n                write(node.kind === 149 /* GetAccessor */ ? \"get \" : \"set \");\n                emit(node.name);\n                emitSignatureAndBody(node);\n            }\n            function shouldEmitAsArrowFunction(node) {\n                return node.kind === 180 /* ArrowFunction */ && languageVersion >= 2 /* ES6 */;\n            }\n            function emitDeclarationName(node) {\n                if (node.name) {\n                    emitNodeWithCommentsAndWithoutSourcemap(node.name);\n                }\n                else {\n                    write(getGeneratedNameForNode(node));\n                }\n            }\n            function shouldEmitFunctionName(node) {\n                if (node.kind === 179 /* FunctionExpression */) {\n                    // Emit name if one is present\n                    return !!node.name;\n                }\n                if (node.kind === 220 /* FunctionDeclaration */) {\n                    // Emit name if one is present, or emit generated name in down-level case (for export default case)\n                    return !!node.name || modulekind !== ts.ModuleKind.ES6;\n                }\n            }\n            function emitFunctionDeclaration(node) {\n                if (ts.nodeIsMissing(node.body)) {\n                    return emitCommentsOnNotEmittedNode(node);\n                }\n                // TODO (yuisu) : we should not have special cases to condition emitting comments\n                // but have one place to fix check for these conditions.\n                var kind = node.kind, parent = node.parent;\n                if (kind !== 147 /* MethodDeclaration */ &&\n                    kind !== 146 /* MethodSignature */ &&\n                    parent &&\n                    parent.kind !== 253 /* PropertyAssignment */ &&\n                    parent.kind !== 174 /* CallExpression */ &&\n                    parent.kind !== 170 /* ArrayLiteralExpression */) {\n                    // 1. Methods will emit comments at their assignment declaration sites.\n                    //\n                    // 2. If the function is a property of object literal, emitting leading-comments\n                    //    is done by emitNodeWithoutSourceMap which then call this function.\n                    //    In particular, we would like to avoid emit comments twice in following case:\n                    //\n                    //          var obj = {\n                    //              id:\n                    //                  /*comment*/ () => void\n                    //          }\n                    //\n                    // 3. If the function is an argument in call expression, emitting of comments will be\n                    //    taken care of in emit list of arguments inside of 'emitCallExpression'.\n                    //\n                    // 4. If the function is in an array literal, 'emitLinePreservingList' will take care\n                    //    of leading comments.\n                    emitLeadingComments(node);\n                }\n                emitStart(node);\n                // For targeting below es6, emit functions-like declaration including arrow function using function keyword.\n                // When targeting ES6, emit arrow function natively in ES6 by omitting function keyword and using fat arrow instead\n                if (!shouldEmitAsArrowFunction(node)) {\n                    if (isES6ExportedDeclaration(node)) {\n                        write(\"export \");\n                        if (node.flags & 512 /* Default */) {\n                            write(\"default \");\n                        }\n                    }\n                    write(\"function\");\n                    if (languageVersion >= 2 /* ES6 */ && node.asteriskToken) {\n                        write(\"*\");\n                    }\n                    write(\" \");\n                }\n                if (shouldEmitFunctionName(node)) {\n                    emitDeclarationName(node);\n                }\n                emitSignatureAndBody(node);\n                if (modulekind !== ts.ModuleKind.ES6 && kind === 220 /* FunctionDeclaration */ && parent === currentSourceFile && node.name) {\n                    emitExportMemberAssignments(node.name);\n                }\n                emitEnd(node);\n                if (kind !== 147 /* MethodDeclaration */ &&\n                    kind !== 146 /* MethodSignature */ &&\n                    kind !== 180 /* ArrowFunction */) {\n                    emitTrailingComments(node);\n                }\n            }\n            function emitCaptureThisForNodeIfNecessary(node) {\n                if (resolver.getNodeCheckFlags(node) & 4 /* CaptureThis */) {\n                    writeLine();\n                    emitStart(node);\n                    write(\"var _this = this;\");\n                    emitEnd(node);\n                }\n            }\n            function emitSignatureParameters(node) {\n                increaseIndent();\n                write(\"(\");\n                if (node) {\n                    var parameters = node.parameters;\n                    var skipCount = node.parameters.length && node.parameters[0].name.originalKeywordKind === 97 /* ThisKeyword */ ? 1 : 0;\n                    var omitCount = languageVersion < 2 /* ES6 */ && ts.hasDeclaredRestParameter(node) ? 1 : 0;\n                    emitList(parameters, skipCount, parameters.length - omitCount - skipCount, /*multiLine*/ false, /*trailingComma*/ false);\n                }\n                write(\")\");\n                decreaseIndent();\n            }\n            function emitSignatureParametersForArrow(node) {\n                // Check whether the parameter list needs parentheses and preserve no-parenthesis\n                if (node.parameters.length === 1 && node.pos === node.parameters[0].pos) {\n                    emit(node.parameters[0]);\n                    return;\n                }\n                emitSignatureParameters(node);\n            }\n            function emitAsyncFunctionBodyForES6(node) {\n                var promiseConstructor = ts.getEntityNameFromTypeNode(node.type);\n                var isArrowFunction = node.kind === 180 /* ArrowFunction */;\n                var hasLexicalArguments = (resolver.getNodeCheckFlags(node) & 8192 /* CaptureArguments */) !== 0;\n                // An async function is emit as an outer function that calls an inner\n                // generator function. To preserve lexical bindings, we pass the current\n                // `this` and `arguments` objects to `__awaiter`. The generator function\n                // passed to `__awaiter` is executed inside of the callback to the\n                // promise constructor.\n                //\n                // The emit for an async arrow without a lexical `arguments` binding might be:\n                //\n                //  // input\n                //  let a = async (b) => { await b; }\n                //\n                //  // output\n                //  let a = (b) => __awaiter(this, void 0, void 0, function* () {\n                //      yield b;\n                //  });\n                //\n                // The emit for an async arrow with a lexical `arguments` binding might be:\n                //\n                //  // input\n                //  let a = async (b) => { await arguments[0]; }\n                //\n                //  // output\n                //  let a = (b) => __awaiter(this, arguments, void 0, function* (arguments) {\n                //      yield arguments[0];\n                //  });\n                //\n                // The emit for an async function expression without a lexical `arguments` binding\n                // might be:\n                //\n                //  // input\n                //  let a = async function (b) {\n                //      await b;\n                //  }\n                //\n                //  // output\n                //  let a = function (b) {\n                //      return __awaiter(this, void 0, void 0, function* () {\n                //          yield b;\n                //      });\n                //  }\n                //\n                // The emit for an async function expression with a lexical `arguments` binding\n                // might be:\n                //\n                //  // input\n                //  let a = async function (b) {\n                //      await arguments[0];\n                //  }\n                //\n                //  // output\n                //  let a = function (b) {\n                //      return __awaiter(this, arguments, void 0, function* (_arguments) {\n                //          yield _arguments[0];\n                //      });\n                //  }\n                //\n                // The emit for an async function expression with a lexical `arguments` binding\n                // and a return type annotation might be:\n                //\n                //  // input\n                //  let a = async function (b): MyPromise<any> {\n                //      await arguments[0];\n                //  }\n                //\n                //  // output\n                //  let a = function (b) {\n                //      return __awaiter(this, arguments, MyPromise, function* (_arguments) {\n                //          yield _arguments[0];\n                //      });\n                //  }\n                //\n                // If this is not an async arrow, emit the opening brace of the function body\n                // and the start of the return statement.\n                if (!isArrowFunction) {\n                    write(\" {\");\n                    increaseIndent();\n                    writeLine();\n                    if (resolver.getNodeCheckFlags(node) & 4096 /* AsyncMethodWithSuperBinding */) {\n                        writeLines(\"\\nconst _super = (function (geti, seti) {\\n    const cache = Object.create(null);\\n    return name => cache[name] || (cache[name] = { get value() { return geti(name); }, set value(v) { seti(name, v); } });\\n})(name => super[name], (name, value) => super[name] = value);\");\n                        writeLine();\n                    }\n                    else if (resolver.getNodeCheckFlags(node) & 2048 /* AsyncMethodWithSuper */) {\n                        write(\"const _super = name => super[name];\");\n                        writeLine();\n                    }\n                    write(\"return\");\n                }\n                write(\" __awaiter(this\");\n                if (hasLexicalArguments) {\n                    write(\", arguments, \");\n                }\n                else {\n                    write(\", void 0, \");\n                }\n                if (languageVersion >= 2 /* ES6 */ || !promiseConstructor) {\n                    write(\"void 0\");\n                }\n                else {\n                    emitEntityNameAsExpression(promiseConstructor, /*useFallback*/ false);\n                }\n                // Emit the call to __awaiter.\n                write(\", function* ()\");\n                // Emit the signature and body for the inner generator function.\n                emitFunctionBody(node);\n                write(\")\");\n                // If this is not an async arrow, emit the closing brace of the outer function body.\n                if (!isArrowFunction) {\n                    write(\";\");\n                    decreaseIndent();\n                    writeLine();\n                    write(\"}\");\n                }\n            }\n            function emitFunctionBody(node) {\n                if (!node.body) {\n                    // There can be no body when there are parse errors.  Just emit an empty block\n                    // in that case.\n                    write(\" { }\");\n                }\n                else {\n                    if (node.body.kind === 199 /* Block */) {\n                        emitBlockFunctionBody(node, node.body);\n                    }\n                    else {\n                        emitExpressionFunctionBody(node, node.body);\n                    }\n                }\n            }\n            function emitSignatureAndBody(node) {\n                var saveConvertedLoopState = convertedLoopState;\n                var saveTempFlags = tempFlags;\n                var saveTempVariables = tempVariables;\n                var saveTempParameters = tempParameters;\n                convertedLoopState = undefined;\n                tempFlags = 0;\n                tempVariables = undefined;\n                tempParameters = undefined;\n                // When targeting ES6, emit arrow function natively in ES6\n                if (shouldEmitAsArrowFunction(node)) {\n                    emitSignatureParametersForArrow(node);\n                    write(\" =>\");\n                }\n                else {\n                    emitSignatureParameters(node);\n                }\n                var isAsync = ts.isAsyncFunctionLike(node);\n                if (isAsync) {\n                    emitAsyncFunctionBodyForES6(node);\n                }\n                else {\n                    emitFunctionBody(node);\n                }\n                if (!isES6ExportedDeclaration(node)) {\n                    emitExportMemberAssignment(node);\n                }\n                ts.Debug.assert(convertedLoopState === undefined);\n                convertedLoopState = saveConvertedLoopState;\n                tempFlags = saveTempFlags;\n                tempVariables = saveTempVariables;\n                tempParameters = saveTempParameters;\n            }\n            // Returns true if any preamble code was emitted.\n            function emitFunctionBodyPreamble(node) {\n                emitCaptureThisForNodeIfNecessary(node);\n                emitDefaultValueAssignments(node);\n                emitRestParameter(node);\n            }\n            function emitExpressionFunctionBody(node, body) {\n                if (languageVersion < 2 /* ES6 */ || node.flags & 256 /* Async */) {\n                    emitDownLevelExpressionFunctionBody(node, body);\n                    return;\n                }\n                // For es6 and higher we can emit the expression as is.  However, in the case\n                // where the expression might end up looking like a block when emitted, we'll\n                // also wrap it in parentheses first.  For example if you have: a => <foo>{}\n                // then we need to generate: a => ({})\n                write(\" \");\n                // Unwrap all type assertions.\n                var current = body;\n                while (current.kind === 177 /* TypeAssertionExpression */) {\n                    current = current.expression;\n                }\n                emitParenthesizedIf(body, current.kind === 171 /* ObjectLiteralExpression */);\n            }\n            function emitDownLevelExpressionFunctionBody(node, body) {\n                write(\" {\");\n                increaseIndent();\n                var outPos = writer.getTextPos();\n                emitDetachedCommentsAndUpdateCommentsInfo(node.body);\n                emitFunctionBodyPreamble(node);\n                var preambleEmitted = writer.getTextPos() !== outPos;\n                decreaseIndent();\n                // If we didn't have to emit any preamble code, then attempt to keep the arrow\n                // function on one line.\n                if (!preambleEmitted && nodeStartPositionsAreOnSameLine(node, body)) {\n                    write(\" \");\n                    emitStart(body);\n                    write(\"return \");\n                    emit(body);\n                    emitEnd(body);\n                    write(\";\");\n                    emitTempDeclarations(/*newLine*/ false);\n                    write(\" \");\n                }\n                else {\n                    increaseIndent();\n                    writeLine();\n                    emitLeadingComments(node.body);\n                    emitStart(body);\n                    write(\"return \");\n                    emit(body);\n                    emitEnd(body);\n                    write(\";\");\n                    emitTrailingComments(node.body);\n                    emitTempDeclarations(/*newLine*/ true);\n                    decreaseIndent();\n                    writeLine();\n                }\n                emitStart(node.body);\n                write(\"}\");\n                emitEnd(node.body);\n            }\n            function emitBlockFunctionBody(node, body) {\n                write(\" {\");\n                var initialTextPos = writer.getTextPos();\n                increaseIndent();\n                emitDetachedCommentsAndUpdateCommentsInfo(body.statements);\n                // Emit all the directive prologues (like \"use strict\").  These have to come before\n                // any other preamble code we write (like parameter initializers).\n                var startIndex = emitDirectivePrologues(body.statements, /*startWithNewLine*/ true);\n                emitFunctionBodyPreamble(node);\n                decreaseIndent();\n                var preambleEmitted = writer.getTextPos() !== initialTextPos;\n                if (!preambleEmitted && nodeEndIsOnSameLineAsNodeStart(body, body)) {\n                    for (var _a = 0, _b = body.statements; _a < _b.length; _a++) {\n                        var statement = _b[_a];\n                        write(\" \");\n                        emit(statement);\n                    }\n                    emitTempDeclarations(/*newLine*/ false);\n                    write(\" \");\n                    emitLeadingCommentsOfPosition(body.statements.end);\n                }\n                else {\n                    increaseIndent();\n                    emitLinesStartingAt(body.statements, startIndex);\n                    emitTempDeclarations(/*newLine*/ true);\n                    writeLine();\n                    emitLeadingCommentsOfPosition(body.statements.end);\n                    decreaseIndent();\n                }\n                emitToken(16 /* CloseBraceToken */, body.statements.end);\n            }\n            /**\n             * Return the statement at a given index if it is a super-call statement\n             * @param ctor a constructor declaration\n             * @param index an index to constructor's body to check\n             */\n            function getSuperCallAtGivenIndex(ctor, index) {\n                if (!ctor.body) {\n                    return undefined;\n                }\n                var statements = ctor.body.statements;\n                if (!statements || index >= statements.length) {\n                    return undefined;\n                }\n                var statement = statements[index];\n                if (statement.kind === 202 /* ExpressionStatement */) {\n                    return ts.isSuperCallExpression(statement.expression) ? statement : undefined;\n                }\n            }\n            function emitParameterPropertyAssignments(node) {\n                ts.forEach(node.parameters, function (param) {\n                    if (param.flags & 92 /* ParameterPropertyModifier */) {\n                        writeLine();\n                        emitStart(param);\n                        emitStart(param.name);\n                        write(\"this.\");\n                        emitNodeWithoutSourceMap(param.name);\n                        emitEnd(param.name);\n                        write(\" = \");\n                        emit(param.name);\n                        write(\";\");\n                        emitEnd(param);\n                    }\n                });\n            }\n            function emitMemberAccessForPropertyName(memberName) {\n                // This does not emit source map because it is emitted by caller as caller\n                // is aware how the property name changes to the property access\n                // eg. public x = 10; becomes this.x and static x = 10 becomes className.x\n                if (memberName.kind === 9 /* StringLiteral */ || memberName.kind === 8 /* NumericLiteral */) {\n                    write(\"[\");\n                    emitNodeWithCommentsAndWithoutSourcemap(memberName);\n                    write(\"]\");\n                }\n                else if (memberName.kind === 140 /* ComputedPropertyName */) {\n                    emitComputedPropertyName(memberName);\n                }\n                else {\n                    write(\".\");\n                    emitNodeWithCommentsAndWithoutSourcemap(memberName);\n                }\n            }\n            function getInitializedProperties(node, isStatic) {\n                var properties = [];\n                for (var _a = 0, _b = node.members; _a < _b.length; _a++) {\n                    var member = _b[_a];\n                    if (member.kind === 145 /* PropertyDeclaration */ && isStatic === ((member.flags & 32 /* Static */) !== 0) && member.initializer) {\n                        properties.push(member);\n                    }\n                }\n                return properties;\n            }\n            function emitPropertyDeclarations(node, properties) {\n                for (var _a = 0, properties_6 = properties; _a < properties_6.length; _a++) {\n                    var property = properties_6[_a];\n                    emitPropertyDeclaration(node, property);\n                }\n            }\n            function emitPropertyDeclaration(node, property, receiver, isExpression) {\n                writeLine();\n                emitLeadingComments(property);\n                emitStart(property);\n                emitStart(property.name);\n                if (receiver) {\n                    write(receiver);\n                }\n                else {\n                    if (property.flags & 32 /* Static */) {\n                        emitDeclarationName(node);\n                    }\n                    else {\n                        write(\"this\");\n                    }\n                }\n                emitMemberAccessForPropertyName(property.name);\n                emitEnd(property.name);\n                write(\" = \");\n                emit(property.initializer);\n                if (!isExpression) {\n                    write(\";\");\n                }\n                emitEnd(property);\n                emitTrailingComments(property);\n            }\n            function emitMemberFunctionsForES5AndLower(node) {\n                ts.forEach(node.members, function (member) {\n                    if (member.kind === 198 /* SemicolonClassElement */) {\n                        writeLine();\n                        write(\";\");\n                    }\n                    else if (member.kind === 147 /* MethodDeclaration */ || node.kind === 146 /* MethodSignature */) {\n                        if (!member.body) {\n                            return emitCommentsOnNotEmittedNode(member);\n                        }\n                        writeLine();\n                        emitLeadingComments(member);\n                        emitStart(member);\n                        emitStart(member.name);\n                        emitClassMemberPrefix(node, member);\n                        emitMemberAccessForPropertyName(member.name);\n                        emitEnd(member.name);\n                        write(\" = \");\n                        emitFunctionDeclaration(member);\n                        emitEnd(member);\n                        write(\";\");\n                        emitTrailingComments(member);\n                    }\n                    else if (member.kind === 149 /* GetAccessor */ || member.kind === 150 /* SetAccessor */) {\n                        var accessors = ts.getAllAccessorDeclarations(node.members, member);\n                        if (member === accessors.firstAccessor) {\n                            writeLine();\n                            emitStart(member);\n                            write(\"Object.defineProperty(\");\n                            emitStart(member.name);\n                            emitClassMemberPrefix(node, member);\n                            write(\", \");\n                            emitExpressionForPropertyName(member.name);\n                            emitEnd(member.name);\n                            write(\", {\");\n                            increaseIndent();\n                            if (accessors.getAccessor) {\n                                writeLine();\n                                emitLeadingComments(accessors.getAccessor);\n                                write(\"get: \");\n                                emitStart(accessors.getAccessor);\n                                write(\"function \");\n                                emitSignatureAndBody(accessors.getAccessor);\n                                emitEnd(accessors.getAccessor);\n                                emitTrailingComments(accessors.getAccessor);\n                                write(\",\");\n                            }\n                            if (accessors.setAccessor) {\n                                writeLine();\n                                emitLeadingComments(accessors.setAccessor);\n                                write(\"set: \");\n                                emitStart(accessors.setAccessor);\n                                write(\"function \");\n                                emitSignatureAndBody(accessors.setAccessor);\n                                emitEnd(accessors.setAccessor);\n                                emitTrailingComments(accessors.setAccessor);\n                                write(\",\");\n                            }\n                            writeLine();\n                            write(\"enumerable: true,\");\n                            writeLine();\n                            write(\"configurable: true\");\n                            decreaseIndent();\n                            writeLine();\n                            write(\"});\");\n                            emitEnd(member);\n                        }\n                    }\n                });\n            }\n            function emitMemberFunctionsForES6AndHigher(node) {\n                for (var _a = 0, _b = node.members; _a < _b.length; _a++) {\n                    var member = _b[_a];\n                    if ((member.kind === 147 /* MethodDeclaration */ || node.kind === 146 /* MethodSignature */) && !member.body) {\n                        emitCommentsOnNotEmittedNode(member);\n                    }\n                    else if (member.kind === 147 /* MethodDeclaration */ ||\n                        member.kind === 149 /* GetAccessor */ ||\n                        member.kind === 150 /* SetAccessor */) {\n                        writeLine();\n                        emitLeadingComments(member);\n                        emitStart(member);\n                        if (member.flags & 32 /* Static */) {\n                            write(\"static \");\n                        }\n                        if (member.kind === 149 /* GetAccessor */) {\n                            write(\"get \");\n                        }\n                        else if (member.kind === 150 /* SetAccessor */) {\n                            write(\"set \");\n                        }\n                        if (member.asteriskToken) {\n                            write(\"*\");\n                        }\n                        emit(member.name);\n                        emitSignatureAndBody(member);\n                        emitEnd(member);\n                        emitTrailingComments(member);\n                    }\n                    else if (member.kind === 198 /* SemicolonClassElement */) {\n                        writeLine();\n                        write(\";\");\n                    }\n                }\n            }\n            function emitConstructor(node, baseTypeElement) {\n                var saveConvertedLoopState = convertedLoopState;\n                var saveTempFlags = tempFlags;\n                var saveTempVariables = tempVariables;\n                var saveTempParameters = tempParameters;\n                convertedLoopState = undefined;\n                tempFlags = 0;\n                tempVariables = undefined;\n                tempParameters = undefined;\n                emitConstructorWorker(node, baseTypeElement);\n                ts.Debug.assert(convertedLoopState === undefined);\n                convertedLoopState = saveConvertedLoopState;\n                tempFlags = saveTempFlags;\n                tempVariables = saveTempVariables;\n                tempParameters = saveTempParameters;\n            }\n            function emitConstructorWorker(node, baseTypeElement) {\n                // Check if we have property assignment inside class declaration.\n                // If there is property assignment, we need to emit constructor whether users define it or not\n                // If there is no property assignment, we can omit constructor if users do not define it\n                var hasInstancePropertyWithInitializer = false;\n                // Emit the constructor overload pinned comments\n                ts.forEach(node.members, function (member) {\n                    if (member.kind === 148 /* Constructor */ && !member.body) {\n                        emitCommentsOnNotEmittedNode(member);\n                    }\n                    // Check if there is any non-static property assignment\n                    if (member.kind === 145 /* PropertyDeclaration */ && member.initializer && (member.flags & 32 /* Static */) === 0) {\n                        hasInstancePropertyWithInitializer = true;\n                    }\n                });\n                var ctor = ts.getFirstConstructorWithBody(node);\n                // For target ES6 and above, if there is no user-defined constructor and there is no property assignment\n                // do not emit constructor in class declaration.\n                if (languageVersion >= 2 /* ES6 */ && !ctor && !hasInstancePropertyWithInitializer) {\n                    return;\n                }\n                if (ctor) {\n                    emitLeadingComments(ctor);\n                }\n                emitStart(ctor || node);\n                if (languageVersion < 2 /* ES6 */) {\n                    write(\"function \");\n                    emitDeclarationName(node);\n                    emitSignatureParameters(ctor);\n                }\n                else {\n                    write(\"constructor\");\n                    if (ctor) {\n                        emitSignatureParameters(ctor);\n                    }\n                    else {\n                        // The ES2015 spec specifies in 14.5.14. Runtime Semantics: ClassDefinitionEvaluation:\n                        // If constructor is empty, then\n                        //     If ClassHeritag_eopt is present and protoParent is not null, then\n                        //          Let constructor be the result of parsing the source text\n                        //              constructor(...args) { super (...args);}\n                        //          using the syntactic grammar with the goal symbol MethodDefinition[~Yield].\n                        //      Else,\n                        //           Let constructor be the result of parsing the source text\n                        //               constructor( ){ }\n                        //           using the syntactic grammar with the goal symbol MethodDefinition[~Yield].\n                        //\n                        // While we could emit the '...args' rest parameter, certain later tools in the pipeline might\n                        // downlevel the '...args' portion less efficiently by naively copying the contents of 'arguments' to an array.\n                        // Instead, we'll avoid using a rest parameter and spread into the super call as\n                        // 'super(...arguments)' instead of 'super(...args)', as you can see below.\n                        write(\"()\");\n                    }\n                }\n                var startIndex = 0;\n                write(\" {\");\n                increaseIndent();\n                if (ctor) {\n                    // Emit all the directive prologues (like \"use strict\").  These have to come before\n                    // any other preamble code we write (like parameter initializers).\n                    startIndex = emitDirectivePrologues(ctor.body.statements, /*startWithNewLine*/ true);\n                    emitDetachedCommentsAndUpdateCommentsInfo(ctor.body.statements);\n                }\n                emitCaptureThisForNodeIfNecessary(node);\n                var superCall;\n                if (ctor) {\n                    emitDefaultValueAssignments(ctor);\n                    emitRestParameter(ctor);\n                    if (baseTypeElement) {\n                        superCall = getSuperCallAtGivenIndex(ctor, startIndex);\n                        if (superCall) {\n                            writeLine();\n                            emit(superCall);\n                        }\n                    }\n                    emitParameterPropertyAssignments(ctor);\n                }\n                else {\n                    if (baseTypeElement) {\n                        writeLine();\n                        emitStart(baseTypeElement);\n                        if (languageVersion < 2 /* ES6 */) {\n                            write(\"_super.apply(this, arguments);\");\n                        }\n                        else {\n                            // See comment above on using '...arguments' instead of '...args'.\n                            write(\"super(...arguments);\");\n                        }\n                        emitEnd(baseTypeElement);\n                    }\n                }\n                emitPropertyDeclarations(node, getInitializedProperties(node, /*isStatic*/ false));\n                if (ctor) {\n                    var statements = ctor.body.statements;\n                    if (superCall) {\n                        statements = statements.slice(1);\n                    }\n                    emitLinesStartingAt(statements, startIndex);\n                }\n                emitTempDeclarations(/*newLine*/ true);\n                writeLine();\n                if (ctor) {\n                    emitLeadingCommentsOfPosition(ctor.body.statements.end);\n                }\n                decreaseIndent();\n                emitToken(16 /* CloseBraceToken */, ctor ? ctor.body.statements.end : node.members.end);\n                emitEnd(ctor || node);\n                if (ctor) {\n                    emitTrailingComments(ctor);\n                }\n            }\n            function emitClassExpression(node) {\n                return emitClassLikeDeclaration(node);\n            }\n            function emitClassDeclaration(node) {\n                return emitClassLikeDeclaration(node);\n            }\n            function emitClassLikeDeclaration(node) {\n                if (languageVersion < 2 /* ES6 */) {\n                    emitClassLikeDeclarationBelowES6(node);\n                }\n                else {\n                    emitClassLikeDeclarationForES6AndHigher(node);\n                }\n                if (modulekind !== ts.ModuleKind.ES6 && node.parent === currentSourceFile && node.name) {\n                    emitExportMemberAssignments(node.name);\n                }\n            }\n            function emitClassLikeDeclarationForES6AndHigher(node) {\n                var decoratedClassAlias;\n                var isHoistedDeclarationInSystemModule = shouldHoistDeclarationInSystemJsModule(node);\n                var isDecorated = ts.nodeIsDecorated(node);\n                var rewriteAsClassExpression = isDecorated || isHoistedDeclarationInSystemModule;\n                if (node.kind === 221 /* ClassDeclaration */) {\n                    if (rewriteAsClassExpression) {\n                        // When we emit an ES6 class that has a class decorator, we must tailor the\n                        // emit to certain specific cases.\n                        //\n                        // In the simplest case, we emit the class declaration as a let declaration, and\n                        // evaluate decorators after the close of the class body:\n                        //\n                        //  TypeScript                      | Javascript\n                        //  --------------------------------|------------------------------------\n                        //  @dec                            | let C = class C {\n                        //  class C {                       | }\n                        //  }                               | C = __decorate([dec], C);\n                        //  --------------------------------|------------------------------------\n                        //  @dec                            | export let C = class C {\n                        //  export class C {                | }\n                        //  }                               | C = __decorate([dec], C);\n                        //  ---------------------------------------------------------------------\n                        //  [Example 1]\n                        //\n                        // If a class declaration contains a reference to itself *inside* of the class body,\n                        // this introduces two bindings to the class: One outside of the class body, and one\n                        // inside of the class body. If we apply decorators as in [Example 1] above, there\n                        // is the possibility that the decorator `dec` will return a new value for the\n                        // constructor, which would result in the binding inside of the class no longer\n                        // pointing to the same reference as the binding outside of the class.\n                        //\n                        // As a result, we must instead rewrite all references to the class *inside* of the\n                        // class body to instead point to a local temporary alias for the class:\n                        //\n                        //  TypeScript                      | Javascript\n                        //  --------------------------------|------------------------------------\n                        //  @dec                            | let C_1 = class C {\n                        //  class C {                       |   static x() { return C_1.y; }\n                        //    static x() { return C.y; }    | }\n                        //    static y = 1;                 | let C = C_1;\n                        //  }                               | C.y = 1;\n                        //                                  | C = C_1 = __decorate([dec], C);\n                        //  --------------------------------|------------------------------------\n                        //  @dec                            | let C_1 = class C {\n                        //  export class C {                |   static x() { return C_1.y; }\n                        //    static x() { return C.y; }    | }\n                        //    static y = 1;                 | export let C = C_1;\n                        //  }                               | C.y = 1;\n                        //                                  | C = C_1 = __decorate([dec], C);\n                        //  ---------------------------------------------------------------------\n                        //  [Example 2]\n                        //\n                        // If a class declaration is the default export of a module, we instead emit\n                        // the export after the decorated declaration:\n                        //\n                        //  TypeScript                      | Javascript\n                        //  --------------------------------|------------------------------------\n                        //  @dec                            | let default_1 = class {\n                        //  export default class {          | }\n                        //  }                               | default_1 = __decorate([dec], default_1);\n                        //                                  | export default default_1;\n                        //  --------------------------------|------------------------------------\n                        //  @dec                            | let C = class C {\n                        //  export default class {          | }\n                        //  }                               | C = __decorate([dec], C);\n                        //                                  | export default C;\n                        //  ---------------------------------------------------------------------\n                        //  [Example 3]\n                        //\n                        // If the class declaration is the default export and a reference to itself\n                        // inside of the class body, we must emit both an alias for the class *and*\n                        // move the export after the declaration:\n                        //\n                        //  TypeScript                      | Javascript\n                        //  --------------------------------|------------------------------------\n                        //  @dec                            | let C_1 = class C {\n                        //  export default class C {        |   static x() { return C_1.y; }\n                        //    static x() { return C.y; }    | };\n                        //    static y = 1;                 | let C = C_1;\n                        //  }                               | C.y = 1;\n                        //                                  | C = C_1 = __decorate([dec], C);\n                        //                                  | export default C;\n                        //  ---------------------------------------------------------------------\n                        //  [Example 4]\n                        //\n                        // NOTE: we reuse the same rewriting logic for cases when targeting ES6 and module kind is System.\n                        // Because of hoisting top level class declaration need to be emitted as class expressions.\n                        // Double bind case is only required if node is decorated.\n                        if (isDecorated && resolver.getNodeCheckFlags(node) & 524288 /* ClassWithBodyScopedClassBinding */) {\n                            decoratedClassAlias = ts.unescapeIdentifier(makeUniqueName(node.name ? node.name.text : \"default\"));\n                            decoratedClassAliases[ts.getNodeId(node)] = decoratedClassAlias;\n                        }\n                        if (isES6ExportedDeclaration(node) && !(node.flags & 512 /* Default */) && decoratedClassAlias === undefined) {\n                            write(\"export \");\n                        }\n                        if (decoratedClassAlias !== undefined) {\n                            write(\"let \" + decoratedClassAlias);\n                        }\n                        else {\n                            if (!isHoistedDeclarationInSystemModule) {\n                                write(\"let \");\n                            }\n                            emitDeclarationName(node);\n                        }\n                        write(\" = \");\n                    }\n                    else if (isES6ExportedDeclaration(node)) {\n                        write(\"export \");\n                        if (node.flags & 512 /* Default */) {\n                            write(\"default \");\n                        }\n                    }\n                }\n                // If the class has static properties, and it's a class expression, then we'll need\n                // to specialize the emit a bit.  for a class expression of the form:\n                //\n                //      (class C { static a = 1; static b = 2; ... })\n                //\n                // We'll emit:\n                //\n                //    ((C_1 = class C {\n                //            // Normal class body\n                //        },\n                //        C_1.a = 1,\n                //        C_1.b = 2,\n                //        C_1));\n                //    var C_1;\n                //\n                // This keeps the expression as an expression, while ensuring that the static parts\n                // of it have been initialized by the time it is used.\n                var staticProperties = getInitializedProperties(node, /*isStatic*/ true);\n                var isClassExpressionWithStaticProperties = staticProperties.length > 0 && node.kind === 192 /* ClassExpression */;\n                var generatedName;\n                if (isClassExpressionWithStaticProperties) {\n                    generatedName = node.name ? getGeneratedNameForNode(node.name) : makeUniqueName(\"classExpression\");\n                    var synthesizedNode = ts.createSynthesizedNode(69 /* Identifier */);\n                    synthesizedNode.text = generatedName;\n                    recordTempDeclaration(synthesizedNode);\n                    write(\"(\");\n                    increaseIndent();\n                    emit(synthesizedNode);\n                    write(\" = \");\n                }\n                write(\"class\");\n                // emit name if\n                // - node has a name\n                // - this is default export with static initializers\n                if (node.name || (node.flags & 512 /* Default */ && (staticProperties.length > 0 || modulekind !== ts.ModuleKind.ES6) && !rewriteAsClassExpression)) {\n                    write(\" \");\n                    emitDeclarationName(node);\n                }\n                var baseTypeNode = ts.getClassExtendsHeritageClauseElement(node);\n                if (baseTypeNode) {\n                    write(\" extends \");\n                    emit(baseTypeNode.expression);\n                }\n                write(\" {\");\n                increaseIndent();\n                writeLine();\n                emitConstructor(node, baseTypeNode);\n                emitMemberFunctionsForES6AndHigher(node);\n                decreaseIndent();\n                writeLine();\n                emitToken(16 /* CloseBraceToken */, node.members.end);\n                if (rewriteAsClassExpression) {\n                    if (decoratedClassAlias !== undefined) {\n                        write(\";\");\n                        writeLine();\n                        if (isES6ExportedDeclaration(node) && !(node.flags & 512 /* Default */)) {\n                            write(\"export \");\n                        }\n                        write(\"let \");\n                        emitDeclarationName(node);\n                        write(\" = \" + decoratedClassAlias);\n                    }\n                    decoratedClassAliases[ts.getNodeId(node)] = undefined;\n                    write(\";\");\n                }\n                // Emit static property assignment. Because classDeclaration is lexically evaluated,\n                // it is safe to emit static property assignment after classDeclaration\n                // From ES6 specification:\n                //      HasLexicalDeclaration (N) : Determines if the argument identifier has a binding in this environment record that was created using\n                //                                  a lexical declaration such as a LexicalDeclaration or a ClassDeclaration.\n                if (isClassExpressionWithStaticProperties) {\n                    for (var _a = 0, staticProperties_1 = staticProperties; _a < staticProperties_1.length; _a++) {\n                        var property = staticProperties_1[_a];\n                        write(\",\");\n                        writeLine();\n                        emitPropertyDeclaration(node, property, /*receiver*/ generatedName, /*isExpression*/ true);\n                    }\n                    write(\",\");\n                    writeLine();\n                    write(generatedName);\n                    decreaseIndent();\n                    write(\")\");\n                }\n                else {\n                    writeLine();\n                    emitPropertyDeclarations(node, staticProperties);\n                    emitDecoratorsOfClass(node, decoratedClassAlias);\n                }\n                if (!(node.flags & 1 /* Export */)) {\n                    return;\n                }\n                if (modulekind !== ts.ModuleKind.ES6) {\n                    emitExportMemberAssignment(node);\n                }\n                else {\n                    // If this is an exported class, but not on the top level (i.e. on an internal\n                    // module), export it\n                    if (node.flags & 512 /* Default */) {\n                        // if this is a top level default export of decorated class, write the export after the declaration.\n                        if (isDecorated) {\n                            writeLine();\n                            write(\"export default \");\n                            emitDeclarationName(node);\n                            write(\";\");\n                        }\n                    }\n                    else if (node.parent.kind !== 256 /* SourceFile */) {\n                        writeLine();\n                        emitStart(node);\n                        emitModuleMemberName(node);\n                        write(\" = \");\n                        emitDeclarationName(node);\n                        emitEnd(node);\n                        write(\";\");\n                    }\n                }\n            }\n            function emitClassLikeDeclarationBelowES6(node) {\n                var isES6ExportedClass = isES6ExportedDeclaration(node);\n                if (node.kind === 221 /* ClassDeclaration */) {\n                    if (isES6ExportedClass && !(node.flags & 512 /* Default */)) {\n                        write(\"export \");\n                    }\n                    // source file level classes in system modules are hoisted so 'var's for them are already defined\n                    if (!shouldHoistDeclarationInSystemJsModule(node)) {\n                        write(\"var \");\n                    }\n                    emitDeclarationName(node);\n                    write(\" = \");\n                }\n                write(\"(function (\");\n                var baseTypeNode = ts.getClassExtendsHeritageClauseElement(node);\n                if (baseTypeNode) {\n                    write(\"_super\");\n                }\n                write(\") {\");\n                var saveTempFlags = tempFlags;\n                var saveTempVariables = tempVariables;\n                var saveTempParameters = tempParameters;\n                var saveComputedPropertyNamesToGeneratedNames = computedPropertyNamesToGeneratedNames;\n                var saveConvertedLoopState = convertedLoopState;\n                convertedLoopState = undefined;\n                tempFlags = 0;\n                tempVariables = undefined;\n                tempParameters = undefined;\n                computedPropertyNamesToGeneratedNames = undefined;\n                increaseIndent();\n                if (baseTypeNode) {\n                    writeLine();\n                    emitStart(baseTypeNode);\n                    write(\"__extends(\");\n                    emitDeclarationName(node);\n                    write(\", _super);\");\n                    emitEnd(baseTypeNode);\n                }\n                writeLine();\n                emitConstructor(node, baseTypeNode);\n                emitMemberFunctionsForES5AndLower(node);\n                emitPropertyDeclarations(node, getInitializedProperties(node, /*isStatic*/ true));\n                writeLine();\n                emitDecoratorsOfClass(node, /*decoratedClassAlias*/ undefined);\n                writeLine();\n                emitToken(16 /* CloseBraceToken */, node.members.end, function () {\n                    write(\"return \");\n                    emitDeclarationName(node);\n                });\n                write(\";\");\n                emitTempDeclarations(/*newLine*/ true);\n                ts.Debug.assert(convertedLoopState === undefined);\n                convertedLoopState = saveConvertedLoopState;\n                tempFlags = saveTempFlags;\n                tempVariables = saveTempVariables;\n                tempParameters = saveTempParameters;\n                computedPropertyNamesToGeneratedNames = saveComputedPropertyNamesToGeneratedNames;\n                decreaseIndent();\n                writeLine();\n                emitToken(16 /* CloseBraceToken */, node.members.end);\n                emitStart(node);\n                write(\"(\");\n                if (baseTypeNode) {\n                    emit(baseTypeNode.expression);\n                }\n                write(\"))\");\n                if (node.kind === 221 /* ClassDeclaration */) {\n                    write(\";\");\n                }\n                emitEnd(node);\n                if (node.kind === 221 /* ClassDeclaration */ && !isES6ExportedClass) {\n                    emitExportMemberAssignment(node);\n                }\n                else if (isES6ExportedClass && (node.flags & 512 /* Default */)) {\n                    writeLine();\n                    write(\"export default \");\n                    emitDeclarationName(node);\n                    write(\";\");\n                }\n            }\n            function emitClassMemberPrefix(node, member) {\n                emitDeclarationName(node);\n                if (!(member.flags & 32 /* Static */)) {\n                    write(\".prototype\");\n                }\n            }\n            function emitDecoratorsOfClass(node, decoratedClassAlias) {\n                emitDecoratorsOfMembers(node, /*staticFlag*/ 0);\n                emitDecoratorsOfMembers(node, 32 /* Static */);\n                emitDecoratorsOfConstructor(node, decoratedClassAlias);\n            }\n            function emitDecoratorsOfConstructor(node, decoratedClassAlias) {\n                var decorators = node.decorators;\n                var constructor = ts.getFirstConstructorWithBody(node);\n                var firstParameterDecorator = constructor && ts.forEach(constructor.parameters, function (parameter) { return parameter.decorators; });\n                // skip decoration of the constructor if neither it nor its parameters are decorated\n                if (!decorators && !firstParameterDecorator) {\n                    return;\n                }\n                // Emit the call to __decorate. Given the class:\n                //\n                //   @dec\n                //   class C {\n                //   }\n                //\n                // The emit for the class is:\n                //\n                //   C = __decorate([dec], C);\n                //\n                writeLine();\n                emitStart(node.decorators || firstParameterDecorator);\n                emitDeclarationName(node);\n                if (decoratedClassAlias !== undefined) {\n                    write(\" = \" + decoratedClassAlias);\n                }\n                write(\" = __decorate([\");\n                increaseIndent();\n                writeLine();\n                var decoratorCount = decorators ? decorators.length : 0;\n                var argumentsWritten = emitList(decorators, 0, decoratorCount, /*multiLine*/ true, /*trailingComma*/ false, /*leadingComma*/ false, /*noTrailingNewLine*/ true, function (decorator) { return emit(decorator.expression); });\n                if (firstParameterDecorator) {\n                    argumentsWritten += emitDecoratorsOfParameters(constructor, /*leadingComma*/ argumentsWritten > 0);\n                }\n                emitSerializedTypeMetadata(node, /*leadingComma*/ argumentsWritten >= 0);\n                decreaseIndent();\n                writeLine();\n                write(\"], \");\n                emitDeclarationName(node);\n                write(\")\");\n                emitEnd(node.decorators || firstParameterDecorator);\n                write(\";\");\n                writeLine();\n            }\n            function emitDecoratorsOfMembers(node, staticFlag) {\n                for (var _a = 0, _b = node.members; _a < _b.length; _a++) {\n                    var member = _b[_a];\n                    // only emit members in the correct group\n                    if ((member.flags & 32 /* Static */) !== staticFlag) {\n                        continue;\n                    }\n                    // skip members that cannot be decorated (such as the constructor)\n                    if (!ts.nodeCanBeDecorated(member)) {\n                        continue;\n                    }\n                    // skip an accessor declaration if it is not the first accessor\n                    var decorators = void 0;\n                    var functionLikeMember = void 0;\n                    if (ts.isAccessor(member)) {\n                        var accessors = ts.getAllAccessorDeclarations(node.members, member);\n                        if (member !== accessors.firstAccessor) {\n                            continue;\n                        }\n                        // get the decorators from the first accessor with decorators\n                        decorators = accessors.firstAccessor.decorators;\n                        if (!decorators && accessors.secondAccessor) {\n                            decorators = accessors.secondAccessor.decorators;\n                        }\n                        // we only decorate parameters of the set accessor\n                        functionLikeMember = accessors.setAccessor;\n                    }\n                    else {\n                        decorators = member.decorators;\n                        // we only decorate the parameters here if this is a method\n                        if (member.kind === 147 /* MethodDeclaration */) {\n                            functionLikeMember = member;\n                        }\n                    }\n                    var firstParameterDecorator = functionLikeMember && ts.forEach(functionLikeMember.parameters, function (parameter) { return parameter.decorators; });\n                    // skip a member if it or any of its parameters are not decorated\n                    if (!decorators && !firstParameterDecorator) {\n                        continue;\n                    }\n                    // Emit the call to __decorate. Given the following:\n                    //\n                    //   class C {\n                    //     @dec method(@dec2 x) {}\n                    //     @dec get accessor() {}\n                    //     @dec prop;\n                    //   }\n                    //\n                    // The emit for a method is:\n                    //\n                    //   __decorate([\n                    //       dec,\n                    //       __param(0, dec2),\n                    //       __metadata(\"design:type\", Function),\n                    //       __metadata(\"design:paramtypes\", [Object]),\n                    //       __metadata(\"design:returntype\", void 0)\n                    //   ], C.prototype, \"method\", undefined);\n                    //\n                    // The emit for an accessor is:\n                    //\n                    //   __decorate([\n                    //       dec\n                    //   ], C.prototype, \"accessor\", undefined);\n                    //\n                    // The emit for a property is:\n                    //\n                    //   __decorate([\n                    //       dec\n                    //   ], C.prototype, \"prop\");\n                    //\n                    writeLine();\n                    emitStart(decorators || firstParameterDecorator);\n                    write(\"__decorate([\");\n                    increaseIndent();\n                    writeLine();\n                    var decoratorCount = decorators ? decorators.length : 0;\n                    var argumentsWritten = emitList(decorators, 0, decoratorCount, /*multiLine*/ true, /*trailingComma*/ false, /*leadingComma*/ false, /*noTrailingNewLine*/ true, function (decorator) { return emit(decorator.expression); });\n                    if (firstParameterDecorator) {\n                        argumentsWritten += emitDecoratorsOfParameters(functionLikeMember, argumentsWritten > 0);\n                    }\n                    emitSerializedTypeMetadata(member, argumentsWritten > 0);\n                    decreaseIndent();\n                    writeLine();\n                    write(\"], \");\n                    emitClassMemberPrefix(node, member);\n                    write(\", \");\n                    emitExpressionForPropertyName(member.name);\n                    if (languageVersion > 0 /* ES3 */) {\n                        if (member.kind !== 145 /* PropertyDeclaration */) {\n                            // We emit `null` here to indicate to `__decorate` that it can invoke `Object.getOwnPropertyDescriptor` directly.\n                            // We have this extra argument here so that we can inject an explicit property descriptor at a later date.\n                            write(\", null\");\n                        }\n                        else {\n                            // We emit `void 0` here to indicate to `__decorate` that it can invoke `Object.defineProperty` directly, but that it\n                            // should not invoke `Object.getOwnPropertyDescriptor`.\n                            write(\", void 0\");\n                        }\n                    }\n                    write(\")\");\n                    emitEnd(decorators || firstParameterDecorator);\n                    write(\";\");\n                    writeLine();\n                }\n            }\n            function emitDecoratorsOfParameters(node, leadingComma) {\n                var argumentsWritten = 0;\n                if (node) {\n                    var parameterIndex_1 = 0;\n                    for (var _a = 0, _b = node.parameters; _a < _b.length; _a++) {\n                        var parameter = _b[_a];\n                        if (ts.nodeIsDecorated(parameter)) {\n                            var decorators = parameter.decorators;\n                            argumentsWritten += emitList(decorators, 0, decorators.length, /*multiLine*/ true, /*trailingComma*/ false, /*leadingComma*/ leadingComma, /*noTrailingNewLine*/ true, function (decorator) {\n                                write(\"__param(\" + parameterIndex_1 + \", \");\n                                emit(decorator.expression);\n                                write(\")\");\n                            });\n                            leadingComma = true;\n                        }\n                        parameterIndex_1++;\n                    }\n                }\n                return argumentsWritten;\n            }\n            function shouldEmitTypeMetadata(node) {\n                // This method determines whether to emit the \"design:type\" metadata based on the node's kind.\n                // The caller should have already tested whether the node has decorators and whether the emitDecoratorMetadata\n                // compiler option is set.\n                switch (node.kind) {\n                    case 147 /* MethodDeclaration */:\n                    case 149 /* GetAccessor */:\n                    case 150 /* SetAccessor */:\n                    case 145 /* PropertyDeclaration */:\n                        return true;\n                }\n                return false;\n            }\n            function shouldEmitReturnTypeMetadata(node) {\n                // This method determines whether to emit the \"design:returntype\" metadata based on the node's kind.\n                // The caller should have already tested whether the node has decorators and whether the emitDecoratorMetadata\n                // compiler option is set.\n                switch (node.kind) {\n                    case 147 /* MethodDeclaration */:\n                        return true;\n                }\n                return false;\n            }\n            function shouldEmitParamTypesMetadata(node) {\n                // This method determines whether to emit the \"design:paramtypes\" metadata based on the node's kind.\n                // The caller should have already tested whether the node has decorators and whether the emitDecoratorMetadata\n                // compiler option is set.\n                switch (node.kind) {\n                    case 221 /* ClassDeclaration */:\n                    case 147 /* MethodDeclaration */:\n                    case 150 /* SetAccessor */:\n                        return true;\n                }\n                return false;\n            }\n            /** Serializes the type of a declaration to an appropriate JS constructor value. Used by the __metadata decorator for a class member. */\n            function emitSerializedTypeOfNode(node) {\n                // serialization of the type of a declaration uses the following rules:\n                //\n                // * The serialized type of a ClassDeclaration is \"Function\"\n                // * The serialized type of a ParameterDeclaration is the serialized type of its type annotation.\n                // * The serialized type of a PropertyDeclaration is the serialized type of its type annotation.\n                // * The serialized type of an AccessorDeclaration is the serialized type of the return type annotation of its getter or parameter type annotation of its setter.\n                // * The serialized type of any other FunctionLikeDeclaration is \"Function\".\n                // * The serialized type of any other node is \"void 0\".\n                //\n                // For rules on serializing type annotations, see `serializeTypeNode`.\n                switch (node.kind) {\n                    case 221 /* ClassDeclaration */:\n                        write(\"Function\");\n                        return;\n                    case 145 /* PropertyDeclaration */:\n                        emitSerializedTypeNode(node.type);\n                        return;\n                    case 142 /* Parameter */:\n                        emitSerializedTypeNode(node.type);\n                        return;\n                    case 149 /* GetAccessor */:\n                        emitSerializedTypeNode(node.type);\n                        return;\n                    case 150 /* SetAccessor */:\n                        emitSerializedTypeNode(ts.getSetAccessorTypeAnnotationNode(node));\n                        return;\n                }\n                if (ts.isFunctionLike(node)) {\n                    write(\"Function\");\n                    return;\n                }\n                write(\"void 0\");\n            }\n            function emitSerializedTypeNode(node) {\n                if (node) {\n                    switch (node.kind) {\n                        case 103 /* VoidKeyword */:\n                            write(\"void 0\");\n                            return;\n                        case 164 /* ParenthesizedType */:\n                            emitSerializedTypeNode(node.type);\n                            return;\n                        case 156 /* FunctionType */:\n                        case 157 /* ConstructorType */:\n                            write(\"Function\");\n                            return;\n                        case 160 /* ArrayType */:\n                        case 161 /* TupleType */:\n                            write(\"Array\");\n                            return;\n                        case 154 /* TypePredicate */:\n                        case 120 /* BooleanKeyword */:\n                            write(\"Boolean\");\n                            return;\n                        case 132 /* StringKeyword */:\n                        case 166 /* LiteralType */:\n                            write(\"String\");\n                            return;\n                        case 130 /* NumberKeyword */:\n                            write(\"Number\");\n                            return;\n                        case 133 /* SymbolKeyword */:\n                            write(\"Symbol\");\n                            return;\n                        case 155 /* TypeReference */:\n                            emitSerializedTypeReferenceNode(node);\n                            return;\n                        case 158 /* TypeQuery */:\n                        case 159 /* TypeLiteral */:\n                        case 162 /* UnionType */:\n                        case 163 /* IntersectionType */:\n                        case 117 /* AnyKeyword */:\n                        case 165 /* ThisType */:\n                            break;\n                        default:\n                            ts.Debug.fail(\"Cannot serialize unexpected type node.\");\n                            break;\n                    }\n                }\n                write(\"Object\");\n            }\n            /** Serializes a TypeReferenceNode to an appropriate JS constructor value. Used by the __metadata decorator. */\n            function emitSerializedTypeReferenceNode(node) {\n                var location = node.parent;\n                while (ts.isDeclaration(location) || ts.isTypeNode(location)) {\n                    location = location.parent;\n                }\n                // Clone the type name and parent it to a location outside of the current declaration.\n                var typeName = ts.cloneEntityName(node.typeName, location);\n                var result = resolver.getTypeReferenceSerializationKind(typeName);\n                switch (result) {\n                    case ts.TypeReferenceSerializationKind.Unknown:\n                        var temp = createAndRecordTempVariable(0 /* Auto */);\n                        write(\"(typeof (\");\n                        emitNodeWithoutSourceMap(temp);\n                        write(\" = \");\n                        emitEntityNameAsExpression(typeName, /*useFallback*/ true);\n                        write(\") === 'function' && \");\n                        emitNodeWithoutSourceMap(temp);\n                        write(\") || Object\");\n                        break;\n                    case ts.TypeReferenceSerializationKind.TypeWithConstructSignatureAndValue:\n                        emitEntityNameAsExpression(typeName, /*useFallback*/ false);\n                        break;\n                    case ts.TypeReferenceSerializationKind.VoidType:\n                        write(\"void 0\");\n                        break;\n                    case ts.TypeReferenceSerializationKind.BooleanType:\n                        write(\"Boolean\");\n                        break;\n                    case ts.TypeReferenceSerializationKind.NumberLikeType:\n                        write(\"Number\");\n                        break;\n                    case ts.TypeReferenceSerializationKind.StringLikeType:\n                        write(\"String\");\n                        break;\n                    case ts.TypeReferenceSerializationKind.ArrayLikeType:\n                        write(\"Array\");\n                        break;\n                    case ts.TypeReferenceSerializationKind.ESSymbolType:\n                        if (languageVersion < 2 /* ES6 */) {\n                            write(\"typeof Symbol === 'function' ? Symbol : Object\");\n                        }\n                        else {\n                            write(\"Symbol\");\n                        }\n                        break;\n                    case ts.TypeReferenceSerializationKind.TypeWithCallSignature:\n                        write(\"Function\");\n                        break;\n                    case ts.TypeReferenceSerializationKind.ObjectType:\n                        write(\"Object\");\n                        break;\n                }\n            }\n            /** Serializes the parameter types of a function or the constructor of a class. Used by the __metadata decorator for a method or set accessor. */\n            function emitSerializedParameterTypesOfNode(node) {\n                // serialization of parameter types uses the following rules:\n                //\n                // * If the declaration is a class, the parameters of the first constructor with a body are used.\n                // * If the declaration is function-like and has a body, the parameters of the function are used.\n                //\n                // For the rules on serializing the type of each parameter declaration, see `serializeTypeOfDeclaration`.\n                if (node) {\n                    var valueDeclaration = void 0;\n                    if (node.kind === 221 /* ClassDeclaration */) {\n                        valueDeclaration = ts.getFirstConstructorWithBody(node);\n                    }\n                    else if (ts.isFunctionLike(node) && ts.nodeIsPresent(node.body)) {\n                        valueDeclaration = node;\n                    }\n                    if (valueDeclaration) {\n                        var parameters = valueDeclaration.parameters;\n                        var skipThisCount = parameters.length && parameters[0].name.originalKeywordKind === 97 /* ThisKeyword */ ? 1 : 0;\n                        var parameterCount = parameters.length;\n                        if (parameterCount > skipThisCount) {\n                            for (var i = skipThisCount; i < parameterCount; i++) {\n                                if (i > skipThisCount) {\n                                    write(\", \");\n                                }\n                                if (parameters[i].dotDotDotToken) {\n                                    var parameterType = parameters[i].type;\n                                    if (parameterType && parameterType.kind === 160 /* ArrayType */) {\n                                        parameterType = parameterType.elementType;\n                                    }\n                                    else if (parameterType && parameterType.kind === 155 /* TypeReference */ && parameterType.typeArguments && parameterType.typeArguments.length === 1) {\n                                        parameterType = parameterType.typeArguments[0];\n                                    }\n                                    else {\n                                        parameterType = undefined;\n                                    }\n                                    emitSerializedTypeNode(parameterType);\n                                }\n                                else {\n                                    emitSerializedTypeOfNode(parameters[i]);\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            /** Serializes the return type of function. Used by the __metadata decorator for a method. */\n            function emitSerializedReturnTypeOfNode(node) {\n                if (node && ts.isFunctionLike(node)) {\n                    if (node.type) {\n                        emitSerializedTypeNode(node.type);\n                        return;\n                    }\n                    else if (ts.isAsyncFunctionLike(node)) {\n                        write(\"Promise\");\n                        return;\n                    }\n                }\n                write(\"void 0\");\n            }\n            function emitSerializedTypeMetadata(node, writeComma) {\n                // This method emits the serialized type metadata for a decorator target.\n                // The caller should have already tested whether the node has decorators.\n                var argumentsWritten = 0;\n                if (compilerOptions.emitDecoratorMetadata) {\n                    if (shouldEmitTypeMetadata(node)) {\n                        if (writeComma) {\n                            write(\", \");\n                        }\n                        writeLine();\n                        write(\"__metadata('design:type', \");\n                        emitSerializedTypeOfNode(node);\n                        write(\")\");\n                        argumentsWritten++;\n                    }\n                    if (shouldEmitParamTypesMetadata(node)) {\n                        if (writeComma || argumentsWritten) {\n                            write(\", \");\n                        }\n                        writeLine();\n                        write(\"__metadata('design:paramtypes', [\");\n                        emitSerializedParameterTypesOfNode(node);\n                        write(\"])\");\n                        argumentsWritten++;\n                    }\n                    if (shouldEmitReturnTypeMetadata(node)) {\n                        if (writeComma || argumentsWritten) {\n                            write(\", \");\n                        }\n                        writeLine();\n                        write(\"__metadata('design:returntype', \");\n                        emitSerializedReturnTypeOfNode(node);\n                        write(\")\");\n                        argumentsWritten++;\n                    }\n                }\n                return argumentsWritten;\n            }\n            function emitInterfaceDeclaration(node) {\n                emitCommentsOnNotEmittedNode(node);\n            }\n            function shouldEmitEnumDeclaration(node) {\n                var isConstEnum = ts.isConst(node);\n                return !isConstEnum || compilerOptions.preserveConstEnums || compilerOptions.isolatedModules;\n            }\n            function emitEnumDeclaration(node) {\n                // const enums are completely erased during compilation.\n                if (!shouldEmitEnumDeclaration(node)) {\n                    return;\n                }\n                if (!shouldHoistDeclarationInSystemJsModule(node)) {\n                    // do not emit var if variable was already hoisted\n                    var isES6ExportedEnum = isES6ExportedDeclaration(node);\n                    if (!(node.flags & 1 /* Export */) || (isES6ExportedEnum && isFirstDeclarationOfKind(node, node.symbol && node.symbol.declarations, 224 /* EnumDeclaration */))) {\n                        emitStart(node);\n                        if (isES6ExportedEnum) {\n                            write(\"export \");\n                        }\n                        write(\"var \");\n                        emit(node.name);\n                        emitEnd(node);\n                        write(\";\");\n                    }\n                }\n                writeLine();\n                emitStart(node);\n                write(\"(function (\");\n                emitStart(node.name);\n                write(getGeneratedNameForNode(node));\n                emitEnd(node.name);\n                write(\") {\");\n                increaseIndent();\n                emitLines(node.members);\n                decreaseIndent();\n                writeLine();\n                emitToken(16 /* CloseBraceToken */, node.members.end);\n                write(\")(\");\n                emitModuleMemberName(node);\n                write(\" || (\");\n                emitModuleMemberName(node);\n                write(\" = {}));\");\n                emitEnd(node);\n                if (!isES6ExportedDeclaration(node) && node.flags & 1 /* Export */ && !shouldHoistDeclarationInSystemJsModule(node)) {\n                    // do not emit var if variable was already hoisted\n                    writeLine();\n                    emitStart(node);\n                    write(\"var \");\n                    emit(node.name);\n                    write(\" = \");\n                    emitModuleMemberName(node);\n                    emitEnd(node);\n                    write(\";\");\n                }\n                if (modulekind !== ts.ModuleKind.ES6 && node.parent === currentSourceFile) {\n                    if (modulekind === ts.ModuleKind.System && (node.flags & 1 /* Export */)) {\n                        // write the call to exporter for enum\n                        writeLine();\n                        write(exportFunctionForFile + \"(\\\"\");\n                        emitDeclarationName(node);\n                        write(\"\\\", \");\n                        emitDeclarationName(node);\n                        write(\");\");\n                    }\n                    emitExportMemberAssignments(node.name);\n                }\n            }\n            function emitEnumMember(node) {\n                var enumParent = node.parent;\n                emitStart(node);\n                write(getGeneratedNameForNode(enumParent));\n                write(\"[\");\n                write(getGeneratedNameForNode(enumParent));\n                write(\"[\");\n                emitExpressionForPropertyName(node.name);\n                write(\"] = \");\n                writeEnumMemberDeclarationValue(node);\n                write(\"] = \");\n                emitExpressionForPropertyName(node.name);\n                emitEnd(node);\n                write(\";\");\n            }\n            function writeEnumMemberDeclarationValue(member) {\n                var value = resolver.getConstantValue(member);\n                if (value !== undefined) {\n                    write(value.toString());\n                    return;\n                }\n                else if (member.initializer) {\n                    emit(member.initializer);\n                }\n                else {\n                    write(\"undefined\");\n                }\n            }\n            function getInnerMostModuleDeclarationFromDottedModule(moduleDeclaration) {\n                if (moduleDeclaration.body && moduleDeclaration.body.kind === 225 /* ModuleDeclaration */) {\n                    var recursiveInnerModule = getInnerMostModuleDeclarationFromDottedModule(moduleDeclaration.body);\n                    return recursiveInnerModule || moduleDeclaration.body;\n                }\n            }\n            function shouldEmitModuleDeclaration(node) {\n                return ts.isInstantiatedModule(node, compilerOptions.preserveConstEnums || compilerOptions.isolatedModules);\n            }\n            function isModuleMergedWithES6Class(node) {\n                return languageVersion === 2 /* ES6 */ && !!(resolver.getNodeCheckFlags(node) & 32768 /* LexicalModuleMergesWithClass */);\n            }\n            function isFirstDeclarationOfKind(node, declarations, kind) {\n                return !ts.forEach(declarations, function (declaration) { return declaration.kind === kind && declaration.pos < node.pos; });\n            }\n            function emitModuleDeclaration(node) {\n                // Emit only if this module is non-ambient.\n                var shouldEmit = shouldEmitModuleDeclaration(node);\n                if (!shouldEmit) {\n                    return emitCommentsOnNotEmittedNode(node);\n                }\n                var hoistedInDeclarationScope = shouldHoistDeclarationInSystemJsModule(node);\n                var emitVarForModule = !hoistedInDeclarationScope && !isModuleMergedWithES6Class(node);\n                if (emitVarForModule) {\n                    var isES6ExportedNamespace = isES6ExportedDeclaration(node);\n                    if (!isES6ExportedNamespace || isFirstDeclarationOfKind(node, node.symbol && node.symbol.declarations, 225 /* ModuleDeclaration */)) {\n                        emitStart(node);\n                        if (isES6ExportedNamespace) {\n                            write(\"export \");\n                        }\n                        write(\"var \");\n                        emit(node.name);\n                        write(\";\");\n                        emitEnd(node);\n                        writeLine();\n                    }\n                }\n                emitStart(node);\n                write(\"(function (\");\n                emitStart(node.name);\n                write(getGeneratedNameForNode(node));\n                emitEnd(node.name);\n                write(\") \");\n                ts.Debug.assert(node.body !== undefined); // node.body must exist, as this is a non-ambient module\n                if (node.body.kind === 226 /* ModuleBlock */) {\n                    var saveConvertedLoopState = convertedLoopState;\n                    var saveTempFlags = tempFlags;\n                    var saveTempVariables = tempVariables;\n                    convertedLoopState = undefined;\n                    tempFlags = 0;\n                    tempVariables = undefined;\n                    emit(node.body);\n                    ts.Debug.assert(convertedLoopState === undefined);\n                    convertedLoopState = saveConvertedLoopState;\n                    tempFlags = saveTempFlags;\n                    tempVariables = saveTempVariables;\n                }\n                else {\n                    write(\"{\");\n                    increaseIndent();\n                    emitCaptureThisForNodeIfNecessary(node);\n                    writeLine();\n                    emit(node.body);\n                    decreaseIndent();\n                    writeLine();\n                    var moduleBlock = getInnerMostModuleDeclarationFromDottedModule(node).body;\n                    emitToken(16 /* CloseBraceToken */, moduleBlock.statements.end);\n                }\n                write(\")(\");\n                // write moduleDecl = containingModule.m only if it is not exported es6 module member\n                if ((node.flags & 1 /* Export */) && !isES6ExportedDeclaration(node)) {\n                    emit(node.name);\n                    write(\" = \");\n                }\n                emitModuleMemberName(node);\n                write(\" || (\");\n                emitModuleMemberName(node);\n                write(\" = {}));\");\n                emitEnd(node);\n                if (!isES6ExportedDeclaration(node) && node.name.kind === 69 /* Identifier */ && node.parent === currentSourceFile) {\n                    if (modulekind === ts.ModuleKind.System && (node.flags & 1 /* Export */)) {\n                        writeLine();\n                        write(exportFunctionForFile + \"(\\\"\");\n                        emitDeclarationName(node);\n                        write(\"\\\", \");\n                        emitDeclarationName(node);\n                        write(\");\");\n                    }\n                    emitExportMemberAssignments(node.name);\n                }\n            }\n            /*\n             * Some bundlers (SystemJS builder) sometimes want to rename dependencies.\n             * Here we check if alternative name was provided for a given moduleName and return it if possible.\n             */\n            function tryRenameExternalModule(moduleName) {\n                if (renamedDependencies && moduleName.text in renamedDependencies) {\n                    return \"\\\"\" + renamedDependencies[moduleName.text] + \"\\\"\";\n                }\n                return undefined;\n            }\n            function emitRequire(moduleName) {\n                if (moduleName.kind === 9 /* StringLiteral */) {\n                    write(\"require(\");\n                    var text = tryRenameExternalModule(moduleName);\n                    if (text) {\n                        write(text);\n                    }\n                    else {\n                        emitStart(moduleName);\n                        emitLiteral(moduleName);\n                        emitEnd(moduleName);\n                    }\n                    emitToken(18 /* CloseParenToken */, moduleName.end);\n                }\n                else {\n                    write(\"require()\");\n                }\n            }\n            function getNamespaceDeclarationNode(node) {\n                if (node.kind === 229 /* ImportEqualsDeclaration */) {\n                    return node;\n                }\n                var importClause = node.importClause;\n                if (importClause && importClause.namedBindings && importClause.namedBindings.kind === 232 /* NamespaceImport */) {\n                    return importClause.namedBindings;\n                }\n            }\n            function isDefaultImport(node) {\n                return node.kind === 230 /* ImportDeclaration */ && node.importClause && !!node.importClause.name;\n            }\n            function emitExportImportAssignments(node) {\n                if (ts.isAliasSymbolDeclaration(node) && resolver.isValueAliasDeclaration(node)) {\n                    emitExportMemberAssignments(node.name);\n                }\n                ts.forEachChild(node, emitExportImportAssignments);\n            }\n            function emitImportDeclaration(node) {\n                if (modulekind !== ts.ModuleKind.ES6) {\n                    return emitExternalImportDeclaration(node);\n                }\n                // ES6 import\n                if (node.importClause) {\n                    var shouldEmitDefaultBindings = resolver.isReferencedAliasDeclaration(node.importClause);\n                    var shouldEmitNamedBindings = node.importClause.namedBindings && resolver.isReferencedAliasDeclaration(node.importClause.namedBindings, /* checkChildren */ true);\n                    if (shouldEmitDefaultBindings || shouldEmitNamedBindings) {\n                        write(\"import \");\n                        emitStart(node.importClause);\n                        if (shouldEmitDefaultBindings) {\n                            emit(node.importClause.name);\n                            if (shouldEmitNamedBindings) {\n                                write(\", \");\n                            }\n                        }\n                        if (shouldEmitNamedBindings) {\n                            emitLeadingComments(node.importClause.namedBindings);\n                            emitStart(node.importClause.namedBindings);\n                            if (node.importClause.namedBindings.kind === 232 /* NamespaceImport */) {\n                                write(\"* as \");\n                                emit(node.importClause.namedBindings.name);\n                            }\n                            else {\n                                write(\"{ \");\n                                emitExportOrImportSpecifierList(node.importClause.namedBindings.elements, resolver.isReferencedAliasDeclaration);\n                                write(\" }\");\n                            }\n                            emitEnd(node.importClause.namedBindings);\n                            emitTrailingComments(node.importClause.namedBindings);\n                        }\n                        emitEnd(node.importClause);\n                        write(\" from \");\n                        emit(node.moduleSpecifier);\n                        write(\";\");\n                    }\n                }\n                else {\n                    write(\"import \");\n                    emit(node.moduleSpecifier);\n                    write(\";\");\n                }\n            }\n            function emitExternalImportDeclaration(node) {\n                if (ts.contains(externalImports, node)) {\n                    var isExportedImport = node.kind === 229 /* ImportEqualsDeclaration */ && (node.flags & 1 /* Export */) !== 0;\n                    var namespaceDeclaration = getNamespaceDeclarationNode(node);\n                    var varOrConst = (languageVersion <= 1 /* ES5 */) ? \"var \" : \"const \";\n                    if (modulekind !== ts.ModuleKind.AMD) {\n                        emitLeadingComments(node);\n                        emitStart(node);\n                        if (namespaceDeclaration && !isDefaultImport(node)) {\n                            // import x = require(\"foo\")\n                            // import * as x from \"foo\"\n                            if (!isExportedImport) {\n                                write(varOrConst);\n                            }\n                            ;\n                            emitModuleMemberName(namespaceDeclaration);\n                            write(\" = \");\n                        }\n                        else {\n                            // import \"foo\"\n                            // import x from \"foo\"\n                            // import { x, y } from \"foo\"\n                            // import d, * as x from \"foo\"\n                            // import d, { x, y } from \"foo\"\n                            var isNakedImport = node.kind === 230 /* ImportDeclaration */ && !node.importClause;\n                            if (!isNakedImport) {\n                                write(varOrConst);\n                                write(getGeneratedNameForNode(node));\n                                write(\" = \");\n                            }\n                        }\n                        emitRequire(ts.getExternalModuleName(node));\n                        if (namespaceDeclaration && isDefaultImport(node)) {\n                            // import d, * as x from \"foo\"\n                            write(\", \");\n                            emitModuleMemberName(namespaceDeclaration);\n                            write(\" = \");\n                            write(getGeneratedNameForNode(node));\n                        }\n                        write(\";\");\n                        emitEnd(node);\n                        emitExportImportAssignments(node);\n                        emitTrailingComments(node);\n                    }\n                    else {\n                        if (isExportedImport) {\n                            emitModuleMemberName(namespaceDeclaration);\n                            write(\" = \");\n                            emit(namespaceDeclaration.name);\n                            write(\";\");\n                        }\n                        else if (namespaceDeclaration && isDefaultImport(node)) {\n                            // import d, * as x from \"foo\"\n                            write(varOrConst);\n                            emitModuleMemberName(namespaceDeclaration);\n                            write(\" = \");\n                            write(getGeneratedNameForNode(node));\n                            write(\";\");\n                        }\n                        emitExportImportAssignments(node);\n                    }\n                }\n            }\n            function emitImportEqualsDeclaration(node) {\n                if (ts.isExternalModuleImportEqualsDeclaration(node)) {\n                    emitExternalImportDeclaration(node);\n                    return;\n                }\n                // preserve old compiler's behavior: emit 'var' for import declaration (even if we do not consider them referenced) when\n                // - current file is not external module\n                // - import declaration is top level and target is value imported by entity name\n                if (resolver.isReferencedAliasDeclaration(node) ||\n                    (!isCurrentFileExternalModule && resolver.isTopLevelValueImportEqualsWithEntityName(node))) {\n                    emitLeadingComments(node);\n                    emitStart(node);\n                    // variable declaration for import-equals declaration can be hoisted in system modules\n                    // in this case 'var' should be omitted and emit should contain only initialization\n                    var variableDeclarationIsHoisted = shouldHoistVariable(node, /*checkIfSourceFileLevelDecl*/ true);\n                    // is it top level export import v = a.b.c in system module?\n                    // if yes - it needs to be rewritten as exporter('v', v = a.b.c)\n                    var isExported = isSourceFileLevelDeclarationInSystemJsModule(node, /*isExported*/ true);\n                    if (!variableDeclarationIsHoisted) {\n                        ts.Debug.assert(!isExported);\n                        if (isES6ExportedDeclaration(node)) {\n                            write(\"export \");\n                            write(\"var \");\n                        }\n                        else if (!(node.flags & 1 /* Export */)) {\n                            write(\"var \");\n                        }\n                    }\n                    if (isExported) {\n                        write(exportFunctionForFile + \"(\\\"\");\n                        emitNodeWithoutSourceMap(node.name);\n                        write(\"\\\", \");\n                    }\n                    emitModuleMemberName(node);\n                    write(\" = \");\n                    emit(node.moduleReference);\n                    if (isExported) {\n                        write(\")\");\n                    }\n                    write(\";\");\n                    emitEnd(node);\n                    emitExportImportAssignments(node);\n                    emitTrailingComments(node);\n                }\n            }\n            function emitExportDeclaration(node) {\n                ts.Debug.assert(modulekind !== ts.ModuleKind.System);\n                if (modulekind !== ts.ModuleKind.ES6) {\n                    if (node.moduleSpecifier && (!node.exportClause || resolver.isValueAliasDeclaration(node))) {\n                        emitStart(node);\n                        var generatedName = getGeneratedNameForNode(node);\n                        if (node.exportClause) {\n                            // export { x, y, ... } from \"foo\"\n                            if (modulekind !== ts.ModuleKind.AMD) {\n                                write(\"var \");\n                                write(generatedName);\n                                write(\" = \");\n                                emitRequire(ts.getExternalModuleName(node));\n                                write(\";\");\n                            }\n                            for (var _a = 0, _b = node.exportClause.elements; _a < _b.length; _a++) {\n                                var specifier = _b[_a];\n                                if (resolver.isValueAliasDeclaration(specifier)) {\n                                    writeLine();\n                                    emitStart(specifier);\n                                    emitContainingModuleName(specifier);\n                                    write(\".\");\n                                    emitNodeWithCommentsAndWithoutSourcemap(specifier.name);\n                                    write(\" = \");\n                                    write(generatedName);\n                                    write(\".\");\n                                    emitNodeWithCommentsAndWithoutSourcemap(specifier.propertyName || specifier.name);\n                                    write(\";\");\n                                    emitEnd(specifier);\n                                }\n                            }\n                        }\n                        else {\n                            // export * from \"foo\"\n                            if (hasExportStarsToExportValues && resolver.moduleExportsSomeValue(node.moduleSpecifier)) {\n                                writeLine();\n                                write(\"__export(\");\n                                if (modulekind !== ts.ModuleKind.AMD) {\n                                    emitRequire(ts.getExternalModuleName(node));\n                                }\n                                else {\n                                    write(generatedName);\n                                }\n                                write(\");\");\n                            }\n                        }\n                        emitEnd(node);\n                    }\n                }\n                else {\n                    if (!node.exportClause || resolver.isValueAliasDeclaration(node)) {\n                        write(\"export \");\n                        if (node.exportClause) {\n                            // export { x, y, ... }\n                            write(\"{ \");\n                            emitExportOrImportSpecifierList(node.exportClause.elements, resolver.isValueAliasDeclaration);\n                            write(\" }\");\n                        }\n                        else {\n                            write(\"*\");\n                        }\n                        if (node.moduleSpecifier) {\n                            write(\" from \");\n                            emit(node.moduleSpecifier);\n                        }\n                        write(\";\");\n                    }\n                }\n            }\n            function emitExportOrImportSpecifierList(specifiers, shouldEmit) {\n                ts.Debug.assert(modulekind === ts.ModuleKind.ES6);\n                var needsComma = false;\n                for (var _a = 0, specifiers_1 = specifiers; _a < specifiers_1.length; _a++) {\n                    var specifier = specifiers_1[_a];\n                    if (shouldEmit(specifier)) {\n                        if (needsComma) {\n                            write(\", \");\n                        }\n                        if (specifier.propertyName) {\n                            emit(specifier.propertyName);\n                            write(\" as \");\n                        }\n                        emit(specifier.name);\n                        needsComma = true;\n                    }\n                }\n            }\n            function emitExportAssignment(node) {\n                if (!node.isExportEquals && resolver.isValueAliasDeclaration(node)) {\n                    if (modulekind === ts.ModuleKind.ES6) {\n                        writeLine();\n                        emitStart(node);\n                        write(\"export default \");\n                        var expression = node.expression;\n                        emit(expression);\n                        if (expression.kind !== 220 /* FunctionDeclaration */ &&\n                            expression.kind !== 221 /* ClassDeclaration */) {\n                            write(\";\");\n                        }\n                        emitEnd(node);\n                    }\n                    else {\n                        writeLine();\n                        emitStart(node);\n                        if (modulekind === ts.ModuleKind.System) {\n                            write(exportFunctionForFile + \"(\\\"default\\\",\");\n                            emit(node.expression);\n                            write(\")\");\n                        }\n                        else {\n                            emitEs6ExportDefaultCompat(node);\n                            emitContainingModuleName(node);\n                            if (languageVersion === 0 /* ES3 */) {\n                                write('[\"default\"] = ');\n                            }\n                            else {\n                                write(\".default = \");\n                            }\n                            emit(node.expression);\n                        }\n                        write(\";\");\n                        emitEnd(node);\n                    }\n                }\n            }\n            function collectExternalModuleInfo(sourceFile) {\n                externalImports = [];\n                exportSpecifiers = ts.createMap();\n                exportEquals = undefined;\n                hasExportStarsToExportValues = false;\n                for (var _a = 0, _b = sourceFile.statements; _a < _b.length; _a++) {\n                    var node = _b[_a];\n                    switch (node.kind) {\n                        case 230 /* ImportDeclaration */:\n                            if (!node.importClause ||\n                                resolver.isReferencedAliasDeclaration(node.importClause, /*checkChildren*/ true)) {\n                                // import \"mod\"\n                                // import x from \"mod\" where x is referenced\n                                // import * as x from \"mod\" where x is referenced\n                                // import { x, y } from \"mod\" where at least one import is referenced\n                                externalImports.push(node);\n                            }\n                            break;\n                        case 229 /* ImportEqualsDeclaration */:\n                            if (node.moduleReference.kind === 240 /* ExternalModuleReference */ && resolver.isReferencedAliasDeclaration(node)) {\n                                // import x = require(\"mod\") where x is referenced\n                                externalImports.push(node);\n                            }\n                            break;\n                        case 236 /* ExportDeclaration */:\n                            if (node.moduleSpecifier) {\n                                if (!node.exportClause) {\n                                    // export * from \"mod\"\n                                    if (resolver.moduleExportsSomeValue(node.moduleSpecifier)) {\n                                        externalImports.push(node);\n                                        hasExportStarsToExportValues = true;\n                                    }\n                                }\n                                else if (resolver.isValueAliasDeclaration(node)) {\n                                    // export { x, y } from \"mod\" where at least one export is a value symbol\n                                    externalImports.push(node);\n                                }\n                            }\n                            else {\n                                // export { x, y }\n                                for (var _c = 0, _d = node.exportClause.elements; _c < _d.length; _c++) {\n                                    var specifier = _d[_c];\n                                    var name_30 = (specifier.propertyName || specifier.name).text;\n                                    (exportSpecifiers[name_30] || (exportSpecifiers[name_30] = [])).push(specifier);\n                                }\n                            }\n                            break;\n                        case 235 /* ExportAssignment */:\n                            if (node.isExportEquals && !exportEquals) {\n                                // export = x\n                                exportEquals = node;\n                            }\n                            break;\n                    }\n                }\n            }\n            function emitExportStarHelper() {\n                if (hasExportStarsToExportValues) {\n                    writeLine();\n                    write(\"function __export(m) {\");\n                    increaseIndent();\n                    writeLine();\n                    write(\"for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\");\n                    decreaseIndent();\n                    writeLine();\n                    write(\"}\");\n                }\n            }\n            function getLocalNameForExternalImport(node) {\n                var namespaceDeclaration = getNamespaceDeclarationNode(node);\n                if (namespaceDeclaration && !isDefaultImport(node)) {\n                    return ts.getTextOfNodeFromSourceText(currentText, namespaceDeclaration.name);\n                }\n                if (node.kind === 230 /* ImportDeclaration */ && node.importClause) {\n                    return getGeneratedNameForNode(node);\n                }\n                if (node.kind === 236 /* ExportDeclaration */ && node.moduleSpecifier) {\n                    return getGeneratedNameForNode(node);\n                }\n            }\n            function getExternalModuleNameText(importNode, emitRelativePathAsModuleName) {\n                if (emitRelativePathAsModuleName) {\n                    var name_31 = getExternalModuleNameFromDeclaration(host, resolver, importNode);\n                    if (name_31) {\n                        return \"\\\"\" + name_31 + \"\\\"\";\n                    }\n                }\n                var moduleName = ts.getExternalModuleName(importNode);\n                if (moduleName.kind === 9 /* StringLiteral */) {\n                    return tryRenameExternalModule(moduleName) || getLiteralText(moduleName);\n                }\n                return undefined;\n            }\n            function emitVariableDeclarationsForImports() {\n                if (externalImports.length === 0) {\n                    return;\n                }\n                writeLine();\n                var started = false;\n                for (var _a = 0, externalImports_1 = externalImports; _a < externalImports_1.length; _a++) {\n                    var importNode = externalImports_1[_a];\n                    // do not create variable declaration for exports and imports that lack import clause\n                    var skipNode = importNode.kind === 236 /* ExportDeclaration */ ||\n                        (importNode.kind === 230 /* ImportDeclaration */ && !importNode.importClause);\n                    if (skipNode) {\n                        continue;\n                    }\n                    if (!started) {\n                        write(\"var \");\n                        started = true;\n                    }\n                    else {\n                        write(\", \");\n                    }\n                    write(getLocalNameForExternalImport(importNode));\n                }\n                if (started) {\n                    write(\";\");\n                }\n            }\n            function emitLocalStorageForExportedNamesIfNecessary(exportedDeclarations) {\n                // when resolving exports local exported entries/indirect exported entries in the module\n                // should always win over entries with similar names that were added via star exports\n                // to support this we store names of local/indirect exported entries in a set.\n                // this set is used to filter names brought by star exports.\n                if (!hasExportStarsToExportValues) {\n                    // local names set is needed only in presence of star exports\n                    return undefined;\n                }\n                // local names set should only be added if we have anything exported\n                if (!exportedDeclarations && !ts.someProperties(exportSpecifiers)) {\n                    // no exported declarations (export var ...) or export specifiers (export {x})\n                    // check if we have any non star export declarations.\n                    var hasExportDeclarationWithExportClause = false;\n                    for (var _a = 0, externalImports_2 = externalImports; _a < externalImports_2.length; _a++) {\n                        var externalImport = externalImports_2[_a];\n                        if (externalImport.kind === 236 /* ExportDeclaration */ && externalImport.exportClause) {\n                            hasExportDeclarationWithExportClause = true;\n                            break;\n                        }\n                    }\n                    if (!hasExportDeclarationWithExportClause) {\n                        // we still need to emit exportStar helper\n                        return emitExportStarFunction(/*localNames*/ undefined);\n                    }\n                }\n                var exportedNamesStorageRef = makeUniqueName(\"exportedNames\");\n                writeLine();\n                write(\"var \" + exportedNamesStorageRef + \" = {\");\n                increaseIndent();\n                var started = false;\n                if (exportedDeclarations) {\n                    for (var i = 0; i < exportedDeclarations.length; i++) {\n                        // write name of exported declaration, i.e 'export var x...'\n                        writeExportedName(exportedDeclarations[i]);\n                    }\n                }\n                if (exportSpecifiers) {\n                    for (var n in exportSpecifiers) {\n                        for (var _b = 0, _c = exportSpecifiers[n]; _b < _c.length; _b++) {\n                            var specifier = _c[_b];\n                            // write name of export specified, i.e. 'export {x}'\n                            writeExportedName(specifier.name);\n                        }\n                    }\n                }\n                for (var _d = 0, externalImports_3 = externalImports; _d < externalImports_3.length; _d++) {\n                    var externalImport = externalImports_3[_d];\n                    if (externalImport.kind !== 236 /* ExportDeclaration */) {\n                        continue;\n                    }\n                    var exportDecl = externalImport;\n                    if (!exportDecl.exportClause) {\n                        // export * from ...\n                        continue;\n                    }\n                    for (var _e = 0, _f = exportDecl.exportClause.elements; _e < _f.length; _e++) {\n                        var element = _f[_e];\n                        // write name of indirectly exported entry, i.e. 'export {x} from ...'\n                        writeExportedName(element.name || element.propertyName);\n                    }\n                }\n                decreaseIndent();\n                writeLine();\n                write(\"};\");\n                return emitExportStarFunction(exportedNamesStorageRef);\n                function emitExportStarFunction(localNames) {\n                    var exportStarFunction = makeUniqueName(\"exportStar\");\n                    writeLine();\n                    // define an export star helper function\n                    write(\"function \" + exportStarFunction + \"(m) {\");\n                    increaseIndent();\n                    writeLine();\n                    write(\"var exports = {};\");\n                    writeLine();\n                    write(\"for(var n in m) {\");\n                    increaseIndent();\n                    writeLine();\n                    write(\"if (n !== \\\"default\\\"\");\n                    if (localNames) {\n                        write(\"&& !\" + localNames + \".hasOwnProperty(n)\");\n                    }\n                    write(\") exports[n] = m[n];\");\n                    decreaseIndent();\n                    writeLine();\n                    write(\"}\");\n                    writeLine();\n                    write(exportFunctionForFile + \"(exports);\");\n                    decreaseIndent();\n                    writeLine();\n                    write(\"}\");\n                    return exportStarFunction;\n                }\n                function writeExportedName(node) {\n                    // do not record default exports\n                    // they are local to module and never overwritten (explicitly skipped) by star export\n                    if (node.kind !== 69 /* Identifier */ && node.flags & 512 /* Default */) {\n                        return;\n                    }\n                    if (started) {\n                        write(\",\");\n                    }\n                    else {\n                        started = true;\n                    }\n                    writeLine();\n                    write(\"'\");\n                    if (node.kind === 69 /* Identifier */) {\n                        emitNodeWithCommentsAndWithoutSourcemap(node);\n                    }\n                    else {\n                        emitDeclarationName(node);\n                    }\n                    write(\"': true\");\n                }\n            }\n            function processTopLevelVariableAndFunctionDeclarations(node) {\n                // per ES6 spec:\n                // 15.2.1.16.4 ModuleDeclarationInstantiation() Concrete Method\n                // - var declarations are initialized to undefined - 14.a.ii\n                // - function/generator declarations are instantiated - 16.a.iv\n                // this means that after module is instantiated but before its evaluation\n                // exported functions are already accessible at import sites\n                // in theory we should hoist only exported functions and its dependencies\n                // in practice to simplify things we'll hoist all source level functions and variable declaration\n                // including variables declarations for module and class declarations\n                var hoistedVars;\n                var hoistedFunctionDeclarations;\n                var exportedDeclarations;\n                visit(node);\n                if (hoistedVars) {\n                    writeLine();\n                    write(\"var \");\n                    var seen = ts.createMap();\n                    for (var i = 0; i < hoistedVars.length; i++) {\n                        var local = hoistedVars[i];\n                        var name_32 = local.kind === 69 /* Identifier */\n                            ? local\n                            : local.name;\n                        if (name_32) {\n                            // do not emit duplicate entries (in case of declaration merging) in the list of hoisted variables\n                            var text = ts.unescapeIdentifier(name_32.text);\n                            if (text in seen) {\n                                continue;\n                            }\n                            else {\n                                seen[text] = text;\n                            }\n                        }\n                        if (i !== 0) {\n                            write(\", \");\n                        }\n                        if (local.kind === 221 /* ClassDeclaration */ || local.kind === 225 /* ModuleDeclaration */ || local.kind === 224 /* EnumDeclaration */) {\n                            emitDeclarationName(local);\n                        }\n                        else {\n                            emit(local);\n                        }\n                        var flags = ts.getCombinedNodeFlags(local.kind === 69 /* Identifier */ ? local.parent : local);\n                        if (flags & 1 /* Export */) {\n                            if (!exportedDeclarations) {\n                                exportedDeclarations = [];\n                            }\n                            exportedDeclarations.push(local);\n                        }\n                    }\n                    write(\";\");\n                }\n                if (hoistedFunctionDeclarations) {\n                    for (var _a = 0, hoistedFunctionDeclarations_1 = hoistedFunctionDeclarations; _a < hoistedFunctionDeclarations_1.length; _a++) {\n                        var f = hoistedFunctionDeclarations_1[_a];\n                        writeLine();\n                        emit(f);\n                        if (f.flags & 1 /* Export */) {\n                            if (!exportedDeclarations) {\n                                exportedDeclarations = [];\n                            }\n                            exportedDeclarations.push(f);\n                        }\n                    }\n                }\n                return exportedDeclarations;\n                function visit(node) {\n                    if (node.flags & 2 /* Ambient */) {\n                        return;\n                    }\n                    if (node.kind === 220 /* FunctionDeclaration */) {\n                        if (!hoistedFunctionDeclarations) {\n                            hoistedFunctionDeclarations = [];\n                        }\n                        hoistedFunctionDeclarations.push(node);\n                        return;\n                    }\n                    if (node.kind === 221 /* ClassDeclaration */) {\n                        if (!hoistedVars) {\n                            hoistedVars = [];\n                        }\n                        hoistedVars.push(node);\n                        return;\n                    }\n                    if (node.kind === 224 /* EnumDeclaration */) {\n                        if (shouldEmitEnumDeclaration(node)) {\n                            if (!hoistedVars) {\n                                hoistedVars = [];\n                            }\n                            hoistedVars.push(node);\n                        }\n                        return;\n                    }\n                    if (node.kind === 225 /* ModuleDeclaration */) {\n                        if (shouldEmitModuleDeclaration(node)) {\n                            if (!hoistedVars) {\n                                hoistedVars = [];\n                            }\n                            hoistedVars.push(node);\n                        }\n                        return;\n                    }\n                    if (node.kind === 218 /* VariableDeclaration */ || node.kind === 169 /* BindingElement */) {\n                        if (shouldHoistVariable(node, /*checkIfSourceFileLevelDecl*/ false)) {\n                            var name_33 = node.name;\n                            if (name_33.kind === 69 /* Identifier */) {\n                                if (!hoistedVars) {\n                                    hoistedVars = [];\n                                }\n                                hoistedVars.push(name_33);\n                            }\n                            else {\n                                ts.forEachChild(name_33, visit);\n                            }\n                        }\n                        return;\n                    }\n                    if (ts.isInternalModuleImportEqualsDeclaration(node) && resolver.isValueAliasDeclaration(node)) {\n                        if (!hoistedVars) {\n                            hoistedVars = [];\n                        }\n                        hoistedVars.push(node.name);\n                        return;\n                    }\n                    if (ts.isBindingPattern(node)) {\n                        ts.forEach(node.elements, visit);\n                        return;\n                    }\n                    if (!ts.isDeclaration(node)) {\n                        ts.forEachChild(node, visit);\n                    }\n                }\n            }\n            function shouldHoistVariable(node, checkIfSourceFileLevelDecl) {\n                if (checkIfSourceFileLevelDecl && !shouldHoistDeclarationInSystemJsModule(node)) {\n                    return false;\n                }\n                // hoist variable if\n                // - it is not block scoped\n                // - it is top level block scoped\n                // if block scoped variables are nested in some another block then\n                // no other functions can use them except ones that are defined at least in the same block\n                return (ts.getCombinedNodeFlags(node) & 3072 /* BlockScoped */) === 0 ||\n                    ts.getEnclosingBlockScopeContainer(node).kind === 256 /* SourceFile */;\n            }\n            function isCurrentFileSystemExternalModule() {\n                return modulekind === ts.ModuleKind.System && isCurrentFileExternalModule;\n            }\n            function emitSystemModuleBody(node, dependencyGroups, startIndex) {\n                // shape of the body in system modules:\n                // function (exports) {\n                //     <list of local aliases for imports>\n                //     <hoisted function declarations>\n                //     <hoisted variable declarations>\n                //     return {\n                //         setters: [\n                //             <list of setter function for imports>\n                //         ],\n                //         execute: function() {\n                //             <module statements>\n                //         }\n                //     }\n                //     <temp declarations>\n                // }\n                // I.e:\n                // import {x} from 'file1'\n                // var y = 1;\n                // export function foo() { return y + x(); }\n                // console.log(y);\n                // will be transformed to\n                // function(exports) {\n                //     var file1; // local alias\n                //     var y;\n                //     function foo() { return y + file1.x(); }\n                //     exports(\"foo\", foo);\n                //     return {\n                //         setters: [\n                //             function(v) { file1 = v }\n                //         ],\n                //         execute(): function() {\n                //             y = 1;\n                //             console.log(y);\n                //         }\n                //     };\n                // }\n                emitVariableDeclarationsForImports();\n                writeLine();\n                var exportedDeclarations = processTopLevelVariableAndFunctionDeclarations(node);\n                var exportStarFunction = emitLocalStorageForExportedNamesIfNecessary(exportedDeclarations);\n                writeLine();\n                write(\"return {\");\n                increaseIndent();\n                writeLine();\n                emitSetters(exportStarFunction, dependencyGroups);\n                writeLine();\n                emitExecute(node, startIndex);\n                decreaseIndent();\n                writeLine();\n                write(\"}\"); // return\n                emitTempDeclarations(/*newLine*/ true);\n            }\n            function emitSetters(exportStarFunction, dependencyGroups) {\n                write(\"setters:[\");\n                for (var i = 0; i < dependencyGroups.length; i++) {\n                    if (i !== 0) {\n                        write(\",\");\n                    }\n                    writeLine();\n                    increaseIndent();\n                    var group = dependencyGroups[i];\n                    // derive a unique name for parameter from the first named entry in the group\n                    var parameterName = makeUniqueName(ts.forEach(group, getLocalNameForExternalImport) || \"\");\n                    write(\"function (\" + parameterName + \") {\");\n                    increaseIndent();\n                    for (var _a = 0, group_1 = group; _a < group_1.length; _a++) {\n                        var entry = group_1[_a];\n                        var importVariableName = getLocalNameForExternalImport(entry) || \"\";\n                        switch (entry.kind) {\n                            case 230 /* ImportDeclaration */:\n                                if (!entry.importClause) {\n                                    // 'import \"...\"' case\n                                    // module is imported only for side-effects, no emit required\n                                    break;\n                                }\n                            // fall-through\n                            case 229 /* ImportEqualsDeclaration */:\n                                ts.Debug.assert(importVariableName !== \"\");\n                                writeLine();\n                                // save import into the local\n                                write(importVariableName + \" = \" + parameterName + \";\");\n                                writeLine();\n                                break;\n                            case 236 /* ExportDeclaration */:\n                                ts.Debug.assert(importVariableName !== \"\");\n                                if (entry.exportClause) {\n                                    // export {a, b as c} from 'foo'\n                                    // emit as:\n                                    // exports_({\n                                    //    \"a\": _[\"a\"],\n                                    //    \"c\": _[\"b\"]\n                                    // });\n                                    writeLine();\n                                    write(exportFunctionForFile + \"({\");\n                                    writeLine();\n                                    increaseIndent();\n                                    for (var i_1 = 0, len = entry.exportClause.elements.length; i_1 < len; i_1++) {\n                                        if (i_1 !== 0) {\n                                            write(\",\");\n                                            writeLine();\n                                        }\n                                        var e = entry.exportClause.elements[i_1];\n                                        write(\"\\\"\");\n                                        emitNodeWithCommentsAndWithoutSourcemap(e.name);\n                                        write(\"\\\": \" + parameterName + \"[\\\"\");\n                                        emitNodeWithCommentsAndWithoutSourcemap(e.propertyName || e.name);\n                                        write(\"\\\"]\");\n                                    }\n                                    decreaseIndent();\n                                    writeLine();\n                                    write(\"});\");\n                                }\n                                else {\n                                    // collectExternalModuleInfo prefilters star exports to keep only ones that export values\n                                    // this means that check 'resolver.moduleExportsSomeValue' is redundant and can be omitted here\n                                    writeLine();\n                                    // export * from 'foo'\n                                    // emit as:\n                                    // exportStar(_foo);\n                                    write(exportStarFunction + \"(\" + parameterName + \");\");\n                                }\n                                writeLine();\n                                break;\n                        }\n                    }\n                    decreaseIndent();\n                    write(\"}\");\n                    decreaseIndent();\n                }\n                write(\"],\");\n            }\n            function emitExecute(node, startIndex) {\n                write(\"execute: function() {\");\n                increaseIndent();\n                writeLine();\n                for (var i = startIndex; i < node.statements.length; i++) {\n                    var statement = node.statements[i];\n                    switch (statement.kind) {\n                        // - function declarations are not emitted because they were already hoisted\n                        // - import declarations are not emitted since they are already handled in setters\n                        // - export declarations with module specifiers are not emitted since they were already written in setters\n                        // - export declarations without module specifiers are emitted preserving the order\n                        case 220 /* FunctionDeclaration */:\n                        case 230 /* ImportDeclaration */:\n                            continue;\n                        case 236 /* ExportDeclaration */:\n                            if (!statement.moduleSpecifier) {\n                                for (var _a = 0, _b = statement.exportClause.elements; _a < _b.length; _a++) {\n                                    var element = _b[_a];\n                                    // write call to exporter function for every export specifier in exports list\n                                    emitExportSpecifierInSystemModule(element);\n                                }\n                            }\n                            continue;\n                        case 229 /* ImportEqualsDeclaration */:\n                            if (!ts.isInternalModuleImportEqualsDeclaration(statement)) {\n                                // - import equals declarations that import external modules are not emitted\n                                continue;\n                            }\n                        // fall-though for import declarations that import internal modules\n                        default:\n                            writeLine();\n                            emit(statement);\n                    }\n                }\n                decreaseIndent();\n                writeLine();\n                write(\"}\"); // execute\n            }\n            function writeModuleName(node, emitRelativePathAsModuleName) {\n                var moduleName = node.moduleName;\n                if (moduleName || (emitRelativePathAsModuleName && (moduleName = getResolvedExternalModuleName(host, node)))) {\n                    write(\"\\\"\" + moduleName + \"\\\", \");\n                }\n            }\n            function emitSystemModule(node, emitRelativePathAsModuleName) {\n                collectExternalModuleInfo(node);\n                // System modules has the following shape\n                // System.register(['dep-1', ... 'dep-n'], function(exports) {/* module body function */})\n                // 'exports' here is a function 'exports<T>(name: string, value: T): T' that is used to publish exported values.\n                // 'exports' returns its 'value' argument so in most cases expressions\n                // that mutate exported values can be rewritten as:\n                // expr -> exports('name', expr).\n                // The only exception in this rule is postfix unary operators,\n                // see comment to 'emitPostfixUnaryExpression' for more details\n                ts.Debug.assert(!exportFunctionForFile);\n                // make sure that  name of 'exports' function does not conflict with existing identifiers\n                exportFunctionForFile = makeUniqueName(\"exports\");\n                contextObjectForFile = makeUniqueName(\"context\");\n                writeLine();\n                write(\"System.register(\");\n                writeModuleName(node, emitRelativePathAsModuleName);\n                write(\"[\");\n                var groupIndices = ts.createMap();\n                var dependencyGroups = [];\n                for (var i = 0; i < externalImports.length; i++) {\n                    var text = getExternalModuleNameText(externalImports[i], emitRelativePathAsModuleName);\n                    if (text === undefined) {\n                        continue;\n                    }\n                    // text should be quoted string\n                    // for deduplication purposes in key remove leading and trailing quotes so 'a' and \"a\" will be considered the same\n                    var key = text.substr(1, text.length - 2);\n                    if (key in groupIndices) {\n                        // deduplicate/group entries in dependency list by the dependency name\n                        var groupIndex = groupIndices[key];\n                        dependencyGroups[groupIndex].push(externalImports[i]);\n                        continue;\n                    }\n                    else {\n                        groupIndices[key] = dependencyGroups.length;\n                        dependencyGroups.push([externalImports[i]]);\n                    }\n                    if (i !== 0) {\n                        write(\", \");\n                    }\n                    write(text);\n                }\n                write(\"], function(\" + exportFunctionForFile + \", \" + contextObjectForFile + \") {\");\n                writeLine();\n                increaseIndent();\n                var startIndex = emitDirectivePrologues(node.statements, /*startWithNewLine*/ true, /*ensureUseStrict*/ !compilerOptions.noImplicitUseStrict);\n                writeLine();\n                write(\"var __moduleName = \" + contextObjectForFile + \" && \" + contextObjectForFile + \".id;\");\n                writeLine();\n                emitEmitHelpers(node);\n                emitCaptureThisForNodeIfNecessary(node);\n                emitSystemModuleBody(node, dependencyGroups, startIndex);\n                decreaseIndent();\n                writeLine();\n                write(\"});\");\n            }\n            function getAMDDependencyNames(node, includeNonAmdDependencies, emitRelativePathAsModuleName) {\n                // names of modules with corresponding parameter in the factory function\n                var aliasedModuleNames = [];\n                // names of modules with no corresponding parameters in factory function\n                var unaliasedModuleNames = [];\n                var importAliasNames = []; // names of the parameters in the factory function; these\n                // parameters need to match the indexes of the corresponding\n                // module names in aliasedModuleNames.\n                // Fill in amd-dependency tags\n                for (var _a = 0, _b = node.amdDependencies; _a < _b.length; _a++) {\n                    var amdDependency = _b[_a];\n                    if (amdDependency.name) {\n                        aliasedModuleNames.push('\"' + amdDependency.path + '\"');\n                        importAliasNames.push(amdDependency.name);\n                    }\n                    else {\n                        unaliasedModuleNames.push('\"' + amdDependency.path + '\"');\n                    }\n                }\n                for (var _c = 0, externalImports_4 = externalImports; _c < externalImports_4.length; _c++) {\n                    var importNode = externalImports_4[_c];\n                    // Find the name of the external module\n                    var externalModuleName = getExternalModuleNameText(importNode, emitRelativePathAsModuleName);\n                    // Find the name of the module alias, if there is one\n                    var importAliasName = getLocalNameForExternalImport(importNode);\n                    if (includeNonAmdDependencies && importAliasName) {\n                        aliasedModuleNames.push(externalModuleName);\n                        importAliasNames.push(importAliasName);\n                    }\n                    else {\n                        unaliasedModuleNames.push(externalModuleName);\n                    }\n                }\n                return { aliasedModuleNames: aliasedModuleNames, unaliasedModuleNames: unaliasedModuleNames, importAliasNames: importAliasNames };\n            }\n            function emitAMDDependencies(node, includeNonAmdDependencies, emitRelativePathAsModuleName) {\n                // An AMD define function has the following shape:\n                //     define(id?, dependencies?, factory);\n                //\n                // This has the shape of\n                //     define(name, [\"module1\", \"module2\"], function (module1Alias) {\n                // The location of the alias in the parameter list in the factory function needs to\n                // match the position of the module name in the dependency list.\n                //\n                // To ensure this is true in cases of modules with no aliases, e.g.:\n                // `import \"module\"` or `<amd-dependency path= \"a.css\" />`\n                // we need to add modules without alias names to the end of the dependencies list\n                var dependencyNames = getAMDDependencyNames(node, includeNonAmdDependencies, emitRelativePathAsModuleName);\n                emitAMDDependencyList(dependencyNames);\n                write(\", \");\n                emitAMDFactoryHeader(dependencyNames);\n            }\n            function emitAMDDependencyList(_a) {\n                var aliasedModuleNames = _a.aliasedModuleNames, unaliasedModuleNames = _a.unaliasedModuleNames;\n                write('[\"require\", \"exports\"');\n                if (aliasedModuleNames.length) {\n                    write(\", \");\n                    write(aliasedModuleNames.join(\", \"));\n                }\n                if (unaliasedModuleNames.length) {\n                    write(\", \");\n                    write(unaliasedModuleNames.join(\", \"));\n                }\n                write(\"]\");\n            }\n            function emitAMDFactoryHeader(_a) {\n                var importAliasNames = _a.importAliasNames;\n                write(\"function (require, exports\");\n                if (importAliasNames.length) {\n                    write(\", \");\n                    write(importAliasNames.join(\", \"));\n                }\n                write(\") {\");\n            }\n            function emitAMDModule(node, emitRelativePathAsModuleName) {\n                emitEmitHelpers(node);\n                collectExternalModuleInfo(node);\n                writeLine();\n                write(\"define(\");\n                writeModuleName(node, emitRelativePathAsModuleName);\n                emitAMDDependencies(node, /*includeNonAmdDependencies*/ true, emitRelativePathAsModuleName);\n                increaseIndent();\n                var startIndex = emitDirectivePrologues(node.statements, /*startWithNewLine*/ true, /*ensureUseStrict*/ !compilerOptions.noImplicitUseStrict);\n                emitExportStarHelper();\n                emitCaptureThisForNodeIfNecessary(node);\n                emitLinesStartingAt(node.statements, startIndex);\n                emitExportEquals(/*emitAsReturn*/ true);\n                emitTempDeclarations(/*newLine*/ true);\n                decreaseIndent();\n                writeLine();\n                write(\"});\");\n            }\n            function emitCommonJSModule(node) {\n                var startIndex = emitDirectivePrologues(node.statements, /*startWithNewLine*/ false, /*ensureUseStrict*/ !compilerOptions.noImplicitUseStrict);\n                emitEmitHelpers(node);\n                collectExternalModuleInfo(node);\n                emitExportStarHelper();\n                emitCaptureThisForNodeIfNecessary(node);\n                emitLinesStartingAt(node.statements, startIndex);\n                emitExportEquals(/*emitAsReturn*/ false);\n                emitTempDeclarations(/*newLine*/ true);\n            }\n            function emitUMDModule(node) {\n                emitEmitHelpers(node);\n                collectExternalModuleInfo(node);\n                var dependencyNames = getAMDDependencyNames(node, /*includeNonAmdDependencies*/ false);\n                // Module is detected first to support Browserify users that load into a browser with an AMD loader\n                writeLines(\"(function (factory) {\\n    if (typeof module === 'object' && typeof module.exports === 'object') {\\n        var v = factory(require, exports); if (v !== undefined) module.exports = v;\\n    }\\n    else if (typeof define === 'function' && define.amd) {\\n        define(\");\n                emitAMDDependencyList(dependencyNames);\n                write(\", factory);\");\n                writeLines(\"    }\\n})(\");\n                emitAMDFactoryHeader(dependencyNames);\n                increaseIndent();\n                var startIndex = emitDirectivePrologues(node.statements, /*startWithNewLine*/ true, /*ensureUseStrict*/ !compilerOptions.noImplicitUseStrict);\n                emitExportStarHelper();\n                emitCaptureThisForNodeIfNecessary(node);\n                emitLinesStartingAt(node.statements, startIndex);\n                emitExportEquals(/*emitAsReturn*/ true);\n                emitTempDeclarations(/*newLine*/ true);\n                decreaseIndent();\n                writeLine();\n                write(\"});\");\n            }\n            function emitES6Module(node) {\n                externalImports = undefined;\n                exportSpecifiers = undefined;\n                exportEquals = undefined;\n                hasExportStarsToExportValues = false;\n                var startIndex = emitDirectivePrologues(node.statements, /*startWithNewLine*/ false);\n                emitEmitHelpers(node);\n                emitCaptureThisForNodeIfNecessary(node);\n                emitLinesStartingAt(node.statements, startIndex);\n                emitTempDeclarations(/*newLine*/ true);\n                // Emit exportDefault if it exists will happen as part\n                // or normal statement emit.\n            }\n            function emitExportEquals(emitAsReturn) {\n                if (exportEquals && resolver.isValueAliasDeclaration(exportEquals)) {\n                    writeLine();\n                    emitStart(exportEquals);\n                    write(emitAsReturn ? \"return \" : \"module.exports = \");\n                    emit(exportEquals.expression);\n                    write(\";\");\n                    emitEnd(exportEquals);\n                }\n            }\n            function emitJsxElement(node) {\n                switch (compilerOptions.jsx) {\n                    case 2 /* React */:\n                        jsxEmitReact(node);\n                        break;\n                    case 1 /* Preserve */:\n                    // Fall back to preserve if None was specified (we'll error earlier)\n                    default:\n                        jsxEmitPreserve(node);\n                        break;\n                }\n            }\n            function trimReactWhitespaceAndApplyEntities(node) {\n                var result = undefined;\n                var text = ts.getTextOfNode(node, /*includeTrivia*/ true);\n                var firstNonWhitespace = 0;\n                var lastNonWhitespace = -1;\n                // JSX trims whitespace at the end and beginning of lines, except that the\n                // start/end of a tag is considered a start/end of a line only if that line is\n                // on the same line as the closing tag. See examples in tests/cases/conformance/jsx/tsxReactEmitWhitespace.tsx\n                for (var i = 0; i < text.length; i++) {\n                    var c = text.charCodeAt(i);\n                    if (ts.isLineBreak(c)) {\n                        if (firstNonWhitespace !== -1 && (lastNonWhitespace - firstNonWhitespace + 1 > 0)) {\n                            var part = text.substr(firstNonWhitespace, lastNonWhitespace - firstNonWhitespace + 1);\n                            result = (result ? result + \"\\\" + ' ' + \\\"\" : \"\") + ts.escapeString(part);\n                        }\n                        firstNonWhitespace = -1;\n                    }\n                    else if (!ts.isWhiteSpaceSingleLine(c)) {\n                        lastNonWhitespace = i;\n                        if (firstNonWhitespace === -1) {\n                            firstNonWhitespace = i;\n                        }\n                    }\n                }\n                if (firstNonWhitespace !== -1) {\n                    var part = text.substr(firstNonWhitespace);\n                    result = (result ? result + \"\\\" + ' ' + \\\"\" : \"\") + ts.escapeString(part);\n                }\n                if (result) {\n                    // Replace entities like &nbsp;\n                    result = result.replace(/&(\\w+);/g, function (s, m) {\n                        if (entities[m] !== undefined) {\n                            var ch = String.fromCharCode(entities[m]);\n                            // &quot; needs to be escaped\n                            return ch === '\"' ? \"\\\\\\\"\" : ch;\n                        }\n                        else {\n                            return s;\n                        }\n                    });\n                }\n                return result;\n            }\n            function isJsxChildEmittable(child) {\n                if (child.kind === 248 /* JsxExpression */) {\n                    // Don't emit empty expressions\n                    return !!child.expression;\n                }\n                else if (child.kind === 244 /* JsxText */) {\n                    // Don't emit empty strings\n                    return !!getTextToEmit(child);\n                }\n                return true;\n            }\n            ;\n            function getTextToEmit(node) {\n                switch (compilerOptions.jsx) {\n                    case 2 /* React */:\n                        var text = trimReactWhitespaceAndApplyEntities(node);\n                        if (text === undefined || text.length === 0) {\n                            return undefined;\n                        }\n                        else {\n                            return text;\n                        }\n                    case 1 /* Preserve */:\n                    default:\n                        return ts.getTextOfNode(node, /*includeTrivia*/ true);\n                }\n            }\n            function emitJsxText(node) {\n                switch (compilerOptions.jsx) {\n                    case 2 /* React */:\n                        write('\"');\n                        write(trimReactWhitespaceAndApplyEntities(node));\n                        write('\"');\n                        break;\n                    case 1 /* Preserve */:\n                    default:\n                        writer.writeLiteral(ts.getTextOfNode(node, /*includeTrivia*/ true));\n                        break;\n                }\n            }\n            function emitJsxExpression(node) {\n                if (node.expression) {\n                    switch (compilerOptions.jsx) {\n                        case 1 /* Preserve */:\n                        default:\n                            write(\"{\");\n                            emit(node.expression);\n                            write(\"}\");\n                            break;\n                        case 2 /* React */:\n                            emit(node.expression);\n                            break;\n                    }\n                }\n            }\n            function isUseStrictPrologue(node) {\n                return node.expression.text === \"use strict\";\n            }\n            function ensureUseStrictPrologue(startWithNewLine, writeUseStrict) {\n                if (writeUseStrict) {\n                    if (startWithNewLine) {\n                        writeLine();\n                    }\n                    write(\"\\\"use strict\\\";\");\n                }\n            }\n            function emitDirectivePrologues(statements, startWithNewLine, ensureUseStrict) {\n                var foundUseStrict = false;\n                for (var i = 0; i < statements.length; i++) {\n                    if (ts.isPrologueDirective(statements[i])) {\n                        if (isUseStrictPrologue(statements[i])) {\n                            foundUseStrict = true;\n                        }\n                        if (startWithNewLine || i > 0) {\n                            writeLine();\n                        }\n                        emit(statements[i]);\n                    }\n                    else {\n                        ensureUseStrictPrologue(startWithNewLine || i > 0, !foundUseStrict && ensureUseStrict);\n                        // return index of the first non prologue directive\n                        return i;\n                    }\n                }\n                ensureUseStrictPrologue(startWithNewLine, !foundUseStrict && ensureUseStrict);\n                return statements.length;\n            }\n            function writeLines(text) {\n                var lines = text.split(/\\r\\n|\\r|\\n/g);\n                for (var i = 0; i < lines.length; i++) {\n                    var line = lines[i];\n                    if (line.length) {\n                        writeLine();\n                        write(line);\n                    }\n                }\n            }\n            function emitEmitHelpers(node) {\n                // Only emit helpers if the user did not say otherwise.\n                if (!compilerOptions.noEmitHelpers) {\n                    // Only Emit __extends function when target ES5.\n                    // For target ES6 and above, we can emit classDeclaration as is.\n                    if (languageVersion < 2 /* ES6 */ && !extendsEmitted && node.flags & 262144 /* HasClassExtends */) {\n                        writeLines(extendsHelper);\n                        extendsEmitted = true;\n                    }\n                    if (compilerOptions.jsx !== 1 /* Preserve */ && !assignEmitted && (node.flags & 1073741824 /* HasJsxSpreadAttribute */)) {\n                        writeLines(assignHelper);\n                        assignEmitted = true;\n                    }\n                    if (!decorateEmitted && node.flags & 524288 /* HasDecorators */) {\n                        writeLines(decorateHelper);\n                        if (compilerOptions.emitDecoratorMetadata) {\n                            writeLines(metadataHelper);\n                        }\n                        decorateEmitted = true;\n                    }\n                    if (!paramEmitted && node.flags & 1048576 /* HasParamDecorators */) {\n                        writeLines(paramHelper);\n                        paramEmitted = true;\n                    }\n                    if (!awaiterEmitted && node.flags & 2097152 /* HasAsyncFunctions */) {\n                        writeLines(awaiterHelper);\n                        awaiterEmitted = true;\n                    }\n                }\n            }\n            function emitSourceFileNode(node) {\n                // Start new file on new line\n                writeLine();\n                emitShebang();\n                emitDetachedCommentsAndUpdateCommentsInfo(node);\n                if (ts.isExternalModule(node) || compilerOptions.isolatedModules) {\n                    if (isOwnFileEmit || (!ts.isExternalModule(node) && compilerOptions.isolatedModules)) {\n                        var emitModule = moduleEmitDelegates[modulekind] || moduleEmitDelegates[ts.ModuleKind.CommonJS];\n                        emitModule(node);\n                    }\n                    else {\n                        bundleEmitDelegates[modulekind](node, /*emitRelativePathAsModuleName*/ true);\n                    }\n                }\n                else {\n                    // emit prologue directives prior to __extends\n                    var startIndex = emitDirectivePrologues(node.statements, /*startWithNewLine*/ false);\n                    externalImports = undefined;\n                    exportSpecifiers = undefined;\n                    exportEquals = undefined;\n                    hasExportStarsToExportValues = false;\n                    emitEmitHelpers(node);\n                    emitCaptureThisForNodeIfNecessary(node);\n                    emitLinesStartingAt(node.statements, startIndex);\n                    emitTempDeclarations(/*newLine*/ true);\n                }\n                emitLeadingComments(node.endOfFileToken);\n            }\n            function emit(node) {\n                emitNodeConsideringCommentsOption(node, emitNodeWithSourceMap);\n            }\n            function emitNodeWithCommentsAndWithoutSourcemap(node) {\n                emitNodeConsideringCommentsOption(node, emitNodeWithoutSourceMap);\n            }\n            function emitNodeConsideringCommentsOption(node, emitNodeConsideringSourcemap) {\n                if (node) {\n                    if (node.flags & 2 /* Ambient */) {\n                        return emitCommentsOnNotEmittedNode(node);\n                    }\n                    if (isSpecializedCommentHandling(node)) {\n                        // This is the node that will handle its own comments and sourcemap\n                        return emitNodeWithoutSourceMap(node);\n                    }\n                    var emitComments_1 = shouldEmitLeadingAndTrailingComments(node);\n                    if (emitComments_1) {\n                        emitLeadingComments(node);\n                    }\n                    emitNodeConsideringSourcemap(node);\n                    if (emitComments_1) {\n                        emitTrailingComments(node);\n                    }\n                }\n            }\n            function emitNodeWithSourceMap(node) {\n                if (node) {\n                    emitStart(node);\n                    emitNodeWithoutSourceMap(node);\n                    emitEnd(node);\n                }\n            }\n            function emitNodeWithoutSourceMap(node) {\n                if (node) {\n                    emitJavaScriptWorker(node);\n                }\n            }\n            function changeSourceMapEmit(writer) {\n                sourceMap = writer;\n                emitStart = writer.emitStart;\n                emitEnd = writer.emitEnd;\n                emitPos = writer.emitPos;\n                setSourceFile = writer.setSourceFile;\n            }\n            function withTemporaryNoSourceMap(callback) {\n                var prevSourceMap = sourceMap;\n                setSourceMapWriterEmit(ts.getNullSourceMapWriter());\n                callback();\n                setSourceMapWriterEmit(prevSourceMap);\n            }\n            function isSpecializedCommentHandling(node) {\n                switch (node.kind) {\n                    // All of these entities are emitted in a specialized fashion.  As such, we allow\n                    // the specialized methods for each to handle the comments on the nodes.\n                    case 222 /* InterfaceDeclaration */:\n                    case 220 /* FunctionDeclaration */:\n                    case 230 /* ImportDeclaration */:\n                    case 229 /* ImportEqualsDeclaration */:\n                    case 223 /* TypeAliasDeclaration */:\n                    case 235 /* ExportAssignment */:\n                        return true;\n                }\n            }\n            function shouldEmitLeadingAndTrailingComments(node) {\n                switch (node.kind) {\n                    case 200 /* VariableStatement */:\n                        return shouldEmitLeadingAndTrailingCommentsForVariableStatement(node);\n                    case 225 /* ModuleDeclaration */:\n                        // Only emit the leading/trailing comments for a module if we're actually\n                        // emitting the module as well.\n                        return shouldEmitModuleDeclaration(node);\n                    case 224 /* EnumDeclaration */:\n                        // Only emit the leading/trailing comments for an enum if we're actually\n                        // emitting the module as well.\n                        return shouldEmitEnumDeclaration(node);\n                }\n                // If the node is emitted in specialized fashion, dont emit comments as this node will handle\n                // emitting comments when emitting itself\n                ts.Debug.assert(!isSpecializedCommentHandling(node));\n                // If this is the expression body of an arrow function that we're down-leveling,\n                // then we don't want to emit comments when we emit the body.  It will have already\n                // been taken care of when we emitted the 'return' statement for the function\n                // expression body.\n                if (node.kind !== 199 /* Block */ &&\n                    node.parent &&\n                    node.parent.kind === 180 /* ArrowFunction */ &&\n                    node.parent.body === node &&\n                    languageVersion <= 1 /* ES5 */) {\n                    return false;\n                }\n                // Emit comments for everything else.\n                return true;\n            }\n            function emitJavaScriptWorker(node) {\n                // Check if the node can be emitted regardless of the ScriptTarget\n                switch (node.kind) {\n                    case 69 /* Identifier */:\n                        return emitIdentifier(node);\n                    case 142 /* Parameter */:\n                        return emitParameter(node);\n                    case 147 /* MethodDeclaration */:\n                    case 146 /* MethodSignature */:\n                        return emitMethod(node);\n                    case 149 /* GetAccessor */:\n                    case 150 /* SetAccessor */:\n                        return emitAccessor(node);\n                    case 97 /* ThisKeyword */:\n                        return emitThis(node);\n                    case 95 /* SuperKeyword */:\n                        return emitSuper(node);\n                    case 93 /* NullKeyword */:\n                        return write(\"null\");\n                    case 99 /* TrueKeyword */:\n                        return write(\"true\");\n                    case 84 /* FalseKeyword */:\n                        return write(\"false\");\n                    case 8 /* NumericLiteral */:\n                    case 9 /* StringLiteral */:\n                    case 10 /* RegularExpressionLiteral */:\n                    case 11 /* NoSubstitutionTemplateLiteral */:\n                    case 12 /* TemplateHead */:\n                    case 13 /* TemplateMiddle */:\n                    case 14 /* TemplateTail */:\n                        return emitLiteral(node);\n                    case 189 /* TemplateExpression */:\n                        return emitTemplateExpression(node);\n                    case 197 /* TemplateSpan */:\n                        return emitTemplateSpan(node);\n                    case 241 /* JsxElement */:\n                    case 242 /* JsxSelfClosingElement */:\n                        return emitJsxElement(node);\n                    case 244 /* JsxText */:\n                        return emitJsxText(node);\n                    case 248 /* JsxExpression */:\n                        return emitJsxExpression(node);\n                    case 139 /* QualifiedName */:\n                        return emitQualifiedName(node);\n                    case 167 /* ObjectBindingPattern */:\n                        return emitObjectBindingPattern(node);\n                    case 168 /* ArrayBindingPattern */:\n                        return emitArrayBindingPattern(node);\n                    case 169 /* BindingElement */:\n                        return emitBindingElement(node);\n                    case 170 /* ArrayLiteralExpression */:\n                        return emitArrayLiteral(node);\n                    case 171 /* ObjectLiteralExpression */:\n                        return emitObjectLiteral(node);\n                    case 253 /* PropertyAssignment */:\n                        return emitPropertyAssignment(node);\n                    case 254 /* ShorthandPropertyAssignment */:\n                        return emitShorthandPropertyAssignment(node);\n                    case 140 /* ComputedPropertyName */:\n                        return emitComputedPropertyName(node);\n                    case 172 /* PropertyAccessExpression */:\n                        return emitPropertyAccess(node);\n                    case 173 /* ElementAccessExpression */:\n                        return emitIndexedAccess(node);\n                    case 174 /* CallExpression */:\n                        return emitCallExpression(node);\n                    case 175 /* NewExpression */:\n                        return emitNewExpression(node);\n                    case 176 /* TaggedTemplateExpression */:\n                        return emitTaggedTemplateExpression(node);\n                    case 177 /* TypeAssertionExpression */:\n                    case 195 /* AsExpression */:\n                    case 196 /* NonNullExpression */:\n                        return emit(node.expression);\n                    case 178 /* ParenthesizedExpression */:\n                        return emitParenExpression(node);\n                    case 220 /* FunctionDeclaration */:\n                    case 179 /* FunctionExpression */:\n                    case 180 /* ArrowFunction */:\n                        return emitFunctionDeclaration(node);\n                    case 181 /* DeleteExpression */:\n                        return emitDeleteExpression(node);\n                    case 182 /* TypeOfExpression */:\n                        return emitTypeOfExpression(node);\n                    case 183 /* VoidExpression */:\n                        return emitVoidExpression(node);\n                    case 184 /* AwaitExpression */:\n                        return emitAwaitExpression(node);\n                    case 185 /* PrefixUnaryExpression */:\n                        return emitPrefixUnaryExpression(node);\n                    case 186 /* PostfixUnaryExpression */:\n                        return emitPostfixUnaryExpression(node);\n                    case 187 /* BinaryExpression */:\n                        return emitBinaryExpression(node);\n                    case 188 /* ConditionalExpression */:\n                        return emitConditionalExpression(node);\n                    case 191 /* SpreadElementExpression */:\n                        return emitSpreadElementExpression(node);\n                    case 190 /* YieldExpression */:\n                        return emitYieldExpression(node);\n                    case 193 /* OmittedExpression */:\n                        return;\n                    case 199 /* Block */:\n                    case 226 /* ModuleBlock */:\n                        return emitBlock(node);\n                    case 200 /* VariableStatement */:\n                        return emitVariableStatement(node);\n                    case 201 /* EmptyStatement */:\n                        return write(\";\");\n                    case 202 /* ExpressionStatement */:\n                        return emitExpressionStatement(node);\n                    case 203 /* IfStatement */:\n                        return emitIfStatement(node);\n                    case 204 /* DoStatement */:\n                        return emitDoStatement(node);\n                    case 205 /* WhileStatement */:\n                        return emitWhileStatement(node);\n                    case 206 /* ForStatement */:\n                        return emitForStatement(node);\n                    case 208 /* ForOfStatement */:\n                    case 207 /* ForInStatement */:\n                        return emitForInOrForOfStatement(node);\n                    case 209 /* ContinueStatement */:\n                    case 210 /* BreakStatement */:\n                        return emitBreakOrContinueStatement(node);\n                    case 211 /* ReturnStatement */:\n                        return emitReturnStatement(node);\n                    case 212 /* WithStatement */:\n                        return emitWithStatement(node);\n                    case 213 /* SwitchStatement */:\n                        return emitSwitchStatement(node);\n                    case 249 /* CaseClause */:\n                    case 250 /* DefaultClause */:\n                        return emitCaseOrDefaultClause(node);\n                    case 214 /* LabeledStatement */:\n                        return emitLabeledStatement(node);\n                    case 215 /* ThrowStatement */:\n                        return emitThrowStatement(node);\n                    case 216 /* TryStatement */:\n                        return emitTryStatement(node);\n                    case 252 /* CatchClause */:\n                        return emitCatchClause(node);\n                    case 217 /* DebuggerStatement */:\n                        return emitDebuggerStatement(node);\n                    case 218 /* VariableDeclaration */:\n                        return emitVariableDeclaration(node);\n                    case 192 /* ClassExpression */:\n                        return emitClassExpression(node);\n                    case 221 /* ClassDeclaration */:\n                        return emitClassDeclaration(node);\n                    case 222 /* InterfaceDeclaration */:\n                        return emitInterfaceDeclaration(node);\n                    case 224 /* EnumDeclaration */:\n                        return emitEnumDeclaration(node);\n                    case 255 /* EnumMember */:\n                        return emitEnumMember(node);\n                    case 225 /* ModuleDeclaration */:\n                        return emitModuleDeclaration(node);\n                    case 230 /* ImportDeclaration */:\n                        return emitImportDeclaration(node);\n                    case 229 /* ImportEqualsDeclaration */:\n                        return emitImportEqualsDeclaration(node);\n                    case 236 /* ExportDeclaration */:\n                        return emitExportDeclaration(node);\n                    case 235 /* ExportAssignment */:\n                        return emitExportAssignment(node);\n                    case 256 /* SourceFile */:\n                        return emitSourceFileNode(node);\n                }\n            }\n            function hasDetachedComments(pos) {\n                return detachedCommentsInfo !== undefined && ts.lastOrUndefined(detachedCommentsInfo).nodePos === pos;\n            }\n            function getLeadingCommentsWithoutDetachedComments() {\n                // get the leading comments from detachedPos\n                var leadingComments = ts.getLeadingCommentRanges(currentText, ts.lastOrUndefined(detachedCommentsInfo).detachedCommentEndPos);\n                if (detachedCommentsInfo.length - 1) {\n                    detachedCommentsInfo.pop();\n                }\n                else {\n                    detachedCommentsInfo = undefined;\n                }\n                return leadingComments;\n            }\n            /**\n             * Determine if the given comment is a triple-slash\n             *\n             * @return true if the comment is a triple-slash comment else false\n             **/\n            function isTripleSlashComment(comment) {\n                // Verify this is /// comment, but do the regexp match only when we first can find /// in the comment text\n                // so that we don't end up computing comment string and doing match for all // comments\n                if (currentText.charCodeAt(comment.pos + 1) === 47 /* slash */ &&\n                    comment.pos + 2 < comment.end &&\n                    currentText.charCodeAt(comment.pos + 2) === 47 /* slash */) {\n                    var textSubStr = currentText.substring(comment.pos, comment.end);\n                    return textSubStr.match(ts.fullTripleSlashReferencePathRegEx) ||\n                        textSubStr.match(ts.fullTripleSlashAMDReferencePathRegEx) ?\n                        true : false;\n                }\n                return false;\n            }\n            function getLeadingCommentsToEmit(node) {\n                // Emit the leading comments only if the parent's pos doesn't match because parent should take care of emitting these comments\n                if (node.parent) {\n                    if (node.parent.kind === 256 /* SourceFile */ || node.pos !== node.parent.pos) {\n                        if (hasDetachedComments(node.pos)) {\n                            // get comments without detached comments\n                            return getLeadingCommentsWithoutDetachedComments();\n                        }\n                        else {\n                            // get the leading comments from the node\n                            return ts.getLeadingCommentRangesOfNodeFromText(node, currentText);\n                        }\n                    }\n                }\n            }\n            function getTrailingCommentsToEmit(node) {\n                // Emit the trailing comments only if the parent's pos doesn't match because parent should take care of emitting these comments\n                if (node.parent) {\n                    if (node.parent.kind === 256 /* SourceFile */ || node.end !== node.parent.end) {\n                        return ts.getTrailingCommentRanges(currentText, node.end);\n                    }\n                }\n            }\n            /**\n             * Emit comments associated with node that will not be emitted into JS file\n             */\n            function emitCommentsOnNotEmittedNode(node) {\n                emitLeadingCommentsWorker(node, /*isEmittedNode*/ false);\n            }\n            function emitLeadingComments(node) {\n                return emitLeadingCommentsWorker(node, /*isEmittedNode*/ true);\n            }\n            function emitLeadingCommentsWorker(node, isEmittedNode) {\n                if (compilerOptions.removeComments) {\n                    return;\n                }\n                var leadingComments;\n                if (isEmittedNode) {\n                    leadingComments = getLeadingCommentsToEmit(node);\n                }\n                else {\n                    // If the node will not be emitted in JS, remove all the comments(normal, pinned and ///) associated with the node,\n                    // unless it is a triple slash comment at the top of the file.\n                    // For Example:\n                    //      /// <reference-path ...>\n                    //      declare var x;\n                    //      /// <reference-path ...>\n                    //      interface F {}\n                    //  The first /// will NOT be removed while the second one will be removed even though both node will not be emitted\n                    if (node.pos === 0) {\n                        leadingComments = ts.filter(getLeadingCommentsToEmit(node), isTripleSlashComment);\n                    }\n                }\n                ts.emitNewLineBeforeLeadingComments(currentLineMap, writer, node, leadingComments);\n                // Leading comments are emitted at /*leading comment1 */space/*leading comment*/space\n                ts.emitComments(currentText, currentLineMap, writer, leadingComments, /*trailingSeparator*/ true, newLine, writeComment);\n            }\n            function emitTrailingComments(node) {\n                if (compilerOptions.removeComments) {\n                    return;\n                }\n                // Emit the trailing comments only if the parent's end doesn't match\n                var trailingComments = getTrailingCommentsToEmit(node);\n                // trailing comments are emitted at space/*trailing comment1 */space/*trailing comment*/\n                ts.emitComments(currentText, currentLineMap, writer, trailingComments, /*trailingSeparator*/ false, newLine, writeComment);\n            }\n            /**\n             * Emit trailing comments at the position. The term trailing comment is used here to describe following comment:\n             *      x, /comment1/ y\n             *        ^ => pos; the function will emit \"comment1\" in the emitJS\n             */\n            function emitTrailingCommentsOfPosition(pos) {\n                if (compilerOptions.removeComments) {\n                    return;\n                }\n                var trailingComments = ts.getTrailingCommentRanges(currentText, pos);\n                // trailing comments are emitted at space/*trailing comment1 */space/*trailing comment*/\n                ts.emitComments(currentText, currentLineMap, writer, trailingComments, /*trailingSeparator*/ true, newLine, writeComment);\n            }\n            function emitLeadingCommentsOfPositionWorker(pos) {\n                if (compilerOptions.removeComments) {\n                    return;\n                }\n                var leadingComments;\n                if (hasDetachedComments(pos)) {\n                    // get comments without detached comments\n                    leadingComments = getLeadingCommentsWithoutDetachedComments();\n                }\n                else {\n                    // get the leading comments from the node\n                    leadingComments = ts.getLeadingCommentRanges(currentText, pos);\n                }\n                ts.emitNewLineBeforeLeadingComments(currentLineMap, writer, { pos: pos, end: pos }, leadingComments);\n                // Leading comments are emitted at /*leading comment1 */space/*leading comment*/space\n                ts.emitComments(currentText, currentLineMap, writer, leadingComments, /*trailingSeparator*/ true, newLine, writeComment);\n            }\n            function emitDetachedCommentsAndUpdateCommentsInfo(node) {\n                var currentDetachedCommentInfo = ts.emitDetachedComments(currentText, currentLineMap, writer, writeComment, node, newLine, compilerOptions.removeComments);\n                if (currentDetachedCommentInfo) {\n                    if (detachedCommentsInfo) {\n                        detachedCommentsInfo.push(currentDetachedCommentInfo);\n                    }\n                    else {\n                        detachedCommentsInfo = [currentDetachedCommentInfo];\n                    }\n                }\n            }\n            function writeComment(text, lineMap, writer, comment, newLine) {\n                emitPos(comment.pos);\n                ts.writeCommentRange(text, lineMap, writer, comment, newLine);\n                emitPos(comment.end);\n            }\n            function emitShebang() {\n                var shebang = ts.getShebang(currentText);\n                if (shebang) {\n                    write(shebang);\n                    writeLine();\n                }\n            }\n            var _a, _b;\n        }\n        function emitFile(_a, sourceFiles, isBundledEmit, emitOnlyDtsFiles) {\n            var jsFilePath = _a.jsFilePath, sourceMapFilePath = _a.sourceMapFilePath, declarationFilePath = _a.declarationFilePath;\n            if (!emitOnlyDtsFiles) {\n                // Make sure not to write js File and source map file if any of them cannot be written\n                if (!host.isEmitBlocked(jsFilePath) && !compilerOptions.noEmit) {\n                    emitJavaScript(jsFilePath, sourceMapFilePath, sourceFiles, isBundledEmit);\n                }\n                else {\n                    emitSkipped = true;\n                }\n            }\n            if (declarationFilePath) {\n                emitSkipped = ts.writeDeclarationFile(declarationFilePath, sourceFiles, isBundledEmit, host, resolver, emitterDiagnostics, emitOnlyDtsFiles) || emitSkipped;\n            }\n            if (!emitSkipped && emittedFilesList) {\n                if (!emitOnlyDtsFiles) {\n                    emittedFilesList.push(jsFilePath);\n                    if (sourceMapFilePath) {\n                        emittedFilesList.push(sourceMapFilePath);\n                    }\n                }\n                if (declarationFilePath) {\n                    emittedFilesList.push(declarationFilePath);\n                }\n            }\n        }\n    }", "label": 3}
{"code": "def _print_drift_report(self):\n        \"\"\"\n        Report the drift of the stack.\n\n        Args:\n            None\n\n        Returns:\n            Good or Bad; True or False\n\n        Note: not yet implemented\n        \"\"\"\n        try:\n            response = self._cloud_formation.describe_stack_resources(StackName=self._stack_name)\n            rows = []\n            for resource in response.get('StackResources', []):\n                row = []\n                row.append(resource.get('LogicalResourceId', 'unknown'))\n                row.append(resource.get('PhysicalResourceId', 'unknown'))\n                row.append(resource.get('ResourceStatus', 'unknown'))\n                row.append(resource.get('DriftInformation', {}).get('StackResourceDriftStatus', 'unknown'))\n                rows.append(row)\n\n            print('Drift Report:')\n            print(tabulate(rows, headers=[\n                'Logical ID',\n                'Physical ID',\n                'Resource Status',\n                'Drift Info'\n            ]))\n        except Exception as wtf:\n            logging.error(wtf, exc_info=True)\n            return False\n\n        return True", "label": 1}
{"code": "public Object getTransferData(DataFlavor flavor) throws UnsupportedFlavorException, java.io.IOException\r\n    {\r\n        if (flavor.isMimeTypeEqual(OJBMETADATA_FLAVOR))\r\n            return selectedDescriptors;\r\n        else\r\n            throw new UnsupportedFlavorException(flavor);\r\n    }", "label": 0}
{"code": "function resolveKey(key, attrNode, options, context) {\n    const resolvedKey = {};\n\n    key.forEach(keyAttrPath => {\n        const keyAttrNode = getLocalAttribute(keyAttrPath, attrNode, context);\n\n        if (keyAttrNode.multiValued) {\n            if (!options.allowMultiValued) {\n                throw new ImplementationError(\n                    `Key attribute \"${keyAttrPath.join('.')}\" ` + `must not be multiValued${context.errorContext}`\n                );\n            }\n            if (key.length > 1) {\n                throw new ImplementationError(\n                    `Composite key attribute \"${keyAttrPath.join('.')}\" ` +\n                        `must not be multiValued${context.errorContext}`\n                );\n            }\n        }\n\n        if (keyAttrNode.map) {\n            Object.keys(keyAttrNode.map.default).forEach(dataSourceName => {\n                if (!resolvedKey[dataSourceName]) resolvedKey[dataSourceName] = [];\n                resolvedKey[dataSourceName].push(keyAttrNode.map.default[dataSourceName]);\n            });\n        }\n\n        if (options.neededDataSources) {\n            options.neededDataSources.forEach(neededDataSource => {\n                if (!keyAttrNode.map || !keyAttrNode.map.default[neededDataSource]) {\n                    throw new ImplementationError(\n                        `Key attribute \"${keyAttrPath.join('.')}\" ` +\n                            `is not mapped to \"${neededDataSource}\" DataSource${context.errorContext}`\n                    );\n                }\n            });\n        }\n    });\n\n    // remove DataSources with incomplete keys:\n    Object.keys(resolvedKey).forEach(dataSourceName => {\n        if (resolvedKey[dataSourceName].length !== key.length) {\n            delete resolvedKey[dataSourceName];\n        }\n    });\n\n    if (Object.keys(resolvedKey).length < 1) {\n        throw new ImplementationError('Key is not mappable to a single DataSource' + context.errorContext);\n    }\n\n    return resolvedKey;\n}", "label": 3}
{"code": "def monthdayscalendar(cls, year, month):\n        \"\"\"Return a list of the weeks in the month month of the year as full weeks.\n        Weeks are lists of seven day numbers.\"\"\"\n        weeks = []\n        week = []\n        for day in NepCal.itermonthdays(year, month):\n            week.append(day)\n            if len(week) == 7:\n                weeks.append(week)\n                week = []\n        if len(week) > 0:\n            weeks.append(week)\n        return weeks", "label": 1}
{"code": "def valid_authenticity_token?(session, encoded_masked_token) # :doc:\n        if encoded_masked_token.nil? || encoded_masked_token.empty? || !encoded_masked_token.is_a?(String)\n          return false\n        end\n\n        begin\n          masked_token = Base64.strict_decode64(encoded_masked_token)\n        rescue ArgumentError # encoded_masked_token is invalid Base64\n          return false\n        end\n\n        # See if it's actually a masked token or not. In order to\n        # deploy this code, we should be able to handle any unmasked\n        # tokens that we've issued without error.\n\n        if masked_token.length == AUTHENTICITY_TOKEN_LENGTH\n          # This is actually an unmasked token. This is expected if\n          # you have just upgraded to masked tokens, but should stop\n          # happening shortly after installing this gem.\n          compare_with_real_token masked_token, session\n\n        elsif masked_token.length == AUTHENTICITY_TOKEN_LENGTH * 2\n          csrf_token = unmask_token(masked_token)\n\n          compare_with_real_token(csrf_token, session) ||\n            valid_per_form_csrf_token?(csrf_token, session)\n        else\n          false # Token is malformed.\n        end\n      end", "label": 4}
{"code": "def _search(self, trie, strings, limit=None):\n        \"\"\"Search in cache\n\n        :param strings: list of strings to get from the cache\n        :type strings: str list\n        :param limit: limit search results\n        :type limit: int\n\n        :rtype: [Resource | Collection]\n        \"\"\"\n        results = [trie.has_keys_with_prefix(s) for s in strings]\n        if not any(results):\n            return []\n        for result, s in zip(results, strings):\n            if result is True:\n                return trie.values(s)[:limit]", "label": 1}
{"code": "function (msgtype, event) {\n\t\n\t\t// we only forward for non-SR user-defined events at lobby\n\t\tif (SR.Settings.SERVER_INFO.type !== 'lobby' || msgtype.startsWith('SR'))\n\t\t\treturn false;\n\t\t\n\t\t// check if we're lobby and same-name app servers are available\n\t\tvar list = SR.AppConn.queryAppServers();\n\t\tLOG.sys('check forward for: ' + msgtype + ' app server size: ' + Object.keys(list).length, l_name);\n\t\n\t\tvar minload_id = undefined;\n\t\tvar minload = 10000;\n\t\t\n\t\tfor (var id in list) {\n\t\t\tvar info = list[id];\n\t\t\tif (info.type === 'app' && info.name === SR.Settings.SERVER_INFO.name) {\n\t\t\t\tLOG.warn('found forward target [' + id + '] loading: ' + info.usercount, l_name);\n\t\t\t\tif (info.usercount < minload) {\n\t\t\t\t\tminload_id = id;\n\t\t\t\t\tminload = info.usercount;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\t\n\t\t// an app server with minimal loading is available, relay the event\n\t\tif (minload_id) {\n\t\t\tSR.RPC.relayEvent(minload_id, msgtype, event);\t\n\t\t\treturn true;\n\t\t}\n\t\t\n\t\t// no need to forward, local execution\n\t\treturn false;\n\t}", "label": 3}
{"code": "function createWrappedComponent() {\n\n        // Create a picker wrapper holder\n        return PickerConstructor._.node( 'div',\n\n            // Create a picker wrapper node\n            PickerConstructor._.node( 'div',\n\n                // Create a picker frame\n                PickerConstructor._.node( 'div',\n\n                    // Create a picker box node\n                    PickerConstructor._.node( 'div',\n\n                        // Create the components nodes.\n                        P.component.nodes( STATE.open ),\n\n                        // The picker box class\n                        CLASSES.box\n                    ),\n\n                    // Picker wrap class\n                    CLASSES.wrap\n                ),\n\n                // Picker frame class\n                CLASSES.frame\n            ),\n\n            // Picker holder class\n            CLASSES.holder\n        ) //endreturn\n    }", "label": 3}
{"code": "public static String changeFirstLetterToLowerCase(String word) {\n        char[] letras = word.toCharArray();\n        char a = letras[0];\n        letras[0] = Character.toLowerCase(a);\n        return new String(letras);\n    }", "label": 0}
{"code": "func (s *ClusterConfigurationService) DeleteClusterConfig() error {\n\terr := s.Delete(context.TODO(), backend.Key(clusterConfigPrefix, generalPrefix))\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn trace.NotFound(\"cluster configuration not found\")\n\t\t}\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static void showOnlyChannels(Object... channels){\r\n    for(LogRecordHandler handler : handlers){\r\n      if(handler instanceof VisibilityHandler){\r\n        VisibilityHandler visHandler = (VisibilityHandler) handler;\r\n        visHandler.hideAll();\r\n        for (Object channel : channels) {\r\n          visHandler.alsoShow(channel);\r\n        }\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "public function addTags(array $tags)\n    {\n        $this->tagsChanges['added'] = array_unique(\n            array_merge($this->tagsChanges['added'], $tags)\n        );\n\n        return $this;\n    }", "label": 2}
{"code": "public void addColumn(ColumnDef columnDef)\r\n    {\r\n        columnDef.setOwner(this);\r\n        _columns.put(columnDef.getName(), columnDef);\r\n    }", "label": 0}
{"code": "func (f *DatastoreFile) Follow(interval time.Duration) io.ReadCloser {\n\treturn &followDatastoreFile{\n\t\tr: f,\n\t\tc: make(chan struct{}),\n\t\ti: interval,\n\t}\n}", "label": 5}
{"code": "public void add(Vector3d v1) {\n        x += v1.x;\n        y += v1.y;\n        z += v1.z;\n    }", "label": 0}
{"code": "def check_hash_in_2xx_response(href, effective_url, response, filenames)\n      return false if @options[:only_4xx]\n      return false unless @options[:check_external_hash]\n      return false unless (hash = hash?(href))\n\n      body_doc = create_nokogiri(response.body)\n\n      unencoded_hash = Addressable::URI.unescape(hash)\n      xpath = %(//*[@name=\"#{hash}\"]|/*[@name=\"#{unencoded_hash}\"]|//*[@id=\"#{hash}\"]|//*[@id=\"#{unencoded_hash}\"])\n      # user-content is a special addition by GitHub.\n      if URI.parse(href).host =~ /github\\.com/i\n        xpath << %(|//*[@name=\"user-content-#{hash}\"]|//*[@id=\"user-content-#{hash}\"])\n        # when linking to a file on GitHub, like #L12-L34, only the first \"L\" portion\n        # will be identified as a linkable portion\n        if hash =~ /\\A(L\\d)+/\n          xpath << %(|//td[@id=\"#{Regexp.last_match[1]}\"])\n        end\n      end\n\n      return unless body_doc.xpath(xpath).empty?\n\n      msg = \"External link #{href} failed: #{effective_url} exists, but the hash '#{hash}' does not\"\n      add_external_issue(filenames, msg, response.code)\n      @cache.add(href, filenames, response.code, msg)\n      true\n    end", "label": 4}
{"code": "public static <T> JacksonParser<T> json(Class<T> contentType) {\n        return new JacksonParser<>(null, contentType);\n    }", "label": 0}
{"code": "function markDiastereotopicAtoms(molecule) {\n  // changed from markDiastereo(); TLS 9.Nov.2015\n  let ids = getAtomIDs(molecule);\n  let analyzed = {};\n  let group = 0;\n  for (let id of ids) {\n    console.log(`${id} - ${group}`);\n    if (!analyzed.contains(id)) {\n      analyzed[id] = true;\n      for (let iAtom = 0; iAtom < ids.length; iAtom++) {\n        if (id.equals(ids[iAtom])) {\n          molecule.setAtomCustomLabel(iAtom, group);\n        }\n      }\n      group++;\n    }\n  }\n}", "label": 3}
{"code": "func (a *ArgType) TemplateSet() *TemplateSet {\n\tif a.templateSet == nil {\n\t\ta.templateSet = &TemplateSet{\n\t\t\tfuncs: a.NewTemplateFuncs(),\n\t\t\tl:     a.TemplateLoader,\n\t\t\ttpls:  map[string]*template.Template{},\n\t\t}\n\t}\n\n\treturn a.templateSet\n}", "label": 5}
{"code": "func (p *printer) writeStart(start *StartElement) error {\n\tif start.Name.Local == \"\" {\n\t\treturn fmt.Errorf(\"xml: start tag with no name\")\n\t}\n\n\tp.tags = append(p.tags, start.Name)\n\tp.markPrefix()\n\n\tp.writeIndent(1)\n\tp.WriteByte('<')\n\tp.WriteString(start.Name.Local)\n\n\tif start.Name.Space != \"\" {\n\t\tp.WriteString(` xmlns=\"`)\n\t\tp.EscapeString(start.Name.Space)\n\t\tp.WriteByte('\"')\n\t}\n\n\t// Attributes\n\tfor _, attr := range start.Attr {\n\t\tname := attr.Name\n\t\tif name.Local == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tp.WriteByte(' ')\n\t\tif name.Space != \"\" {\n\t\t\tp.WriteString(p.createAttrPrefix(name.Space))\n\t\t\tp.WriteByte(':')\n\t\t}\n\t\tp.WriteString(name.Local)\n\t\tp.WriteString(`=\"`)\n\t\tp.EscapeString(attr.Value)\n\t\tp.WriteByte('\"')\n\t}\n\tp.WriteByte('>')\n\treturn nil\n}", "label": 5}
{"code": "def to_xml_string(str = '')\n      validate_attributes_for_chart_type\n      str << '<c:dLbls>'\n      %w(d_lbl_pos show_legend_key show_val show_cat_name show_ser_name show_percent show_bubble_size show_leader_lines).each do |key|\n        next unless instance_values.keys.include?(key) && instance_values[key] != nil\n        str <<  \"<c:#{Axlsx::camel(key, false)} val='#{instance_values[key]}' />\" \n      end\n      str << '</c:dLbls>'\n    end", "label": 4}
{"code": "public function setMax($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Value::class);\n        $this->max = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "protected function registerConfig()\n    {\n        $this->publishes([\n            realpath(PLATFORM_PATH.'/config/press.php') => config_path('press.php'),\n        ], 'config');\n\n        $this->mergeConfigFrom(\n            realpath(PLATFORM_PATH.'/config/press.php'), 'press'\n        );\n\n        return $this;\n    }", "label": 2}
{"code": "protected String getDBManipulationUrl()\r\n    {\r\n        JdbcConnectionDescriptor jcd = getConnection();\r\n\r\n        return jcd.getProtocol()+\":\"+jcd.getSubProtocol()+\":\"+jcd.getDbAlias();\r\n    }", "label": 0}
{"code": "def pattern(self, platform, key, compiled=True):\n        \"\"\"Return the pattern defined by the key string specific to the platform.\n\n        :param platform:\n        :param key:\n        :param compiled:\n        :return: Pattern string or RE object.\n        \"\"\"\n        patterns = self._platform_patterns(platform, compiled=compiled)\n        pattern = patterns.get(key, self._platform_patterns(compiled=compiled).get(key, None))\n\n        if pattern is None:\n            raise KeyError(\"Patterns database corrupted. Platform: {}, Key: {}\".format(platform, key))\n\n        return pattern", "label": 1}
{"code": "function (args) {\n                var shardKey = this.prototype.shardKey;\n                var query = !_.isUndefined(args[0]) ? args[0] : {};\n                var options = !_.isUndefined(args[1]) ? args[1] : {};\n                var ignoreShardKey = MemberHelpers.getPathPropertyValue(options, 'ignoreShardKey') ? true : false;\n                var missingFields = [];\n\n                if (!_.isUndefined(shardKey) && !_.isUndefined(query) && !ignoreShardKey) {\n\n                    for (let shardKeyField in shardKey) {\n                        if (!query.hasOwnProperty(shardKeyField)) {\n                            missingFields.push(shardKeyField);\n                        }\n                    }\n                }\n\n                return new Q.Promise(function (resolve, reject) {\n                    if (!_.isEmpty(missingFields)) {\n                        return reject(\"Query doesn't contain the shard key or parts of it. Missing fields: \" + missingFields.join(', '));\n                    }\n                    return resolve();\n                });\n            }", "label": 3}
{"code": "def get(cls):\n        \"\"\"Get values gathered from the previously set hierarchy.\n\n        Respects the order in which sources are set, the first source set\n        has the highest priority, overrides values with the same key that\n        exist in sources with lower priority.\n\n        Returns:\n            dict: The dictionary containing values gathered from all set sources.\n        \"\"\"\n        results = {}\n\n        hierarchy = cls.__hierarchy\n        hierarchy.reverse()\n\n        for storeMethod in hierarchy:\n            cls.merger.merge(results, storeMethod.get())\n\n        return results", "label": 1}
{"code": "def records():\n    \"\"\"Load records.\"\"\"\n    import pkg_resources\n    import uuid\n    from dojson.contrib.marc21 import marc21\n    from dojson.contrib.marc21.utils import create_record, split_blob\n    from invenio_pidstore import current_pidstore\n    from invenio_records.api import Record\n\n    # pkg resources the demodata\n    data_path = pkg_resources.resource_filename(\n        'invenio_records', 'data/marc21/bibliographic.xml'\n    )\n    with open(data_path) as source:\n        indexer = RecordIndexer()\n        with db.session.begin_nested():\n            for index, data in enumerate(split_blob(source.read()), start=1):\n                # create uuid\n                rec_uuid = uuid.uuid4()\n                # do translate\n                record = marc21.do(create_record(data))\n                # create PID\n                current_pidstore.minters['recid'](\n                    rec_uuid, record\n                )\n                # create record\n                indexer.index(Record.create(record, id_=rec_uuid))\n        db.session.commit()", "label": 1}
{"code": "public static base_response create(nitro_service client, sslfipskey resource) throws Exception {\n\t\tsslfipskey createresource = new sslfipskey();\n\t\tcreateresource.fipskeyname = resource.fipskeyname;\n\t\tcreateresource.modulus = resource.modulus;\n\t\tcreateresource.exponent = resource.exponent;\n\t\treturn createresource.perform_operation(client,\"create\");\n\t}", "label": 0}
{"code": "def execute(self):\n        \"\"\"\n        executes all automatic tasks in order of task id\n        \"\"\"\n        func_params = []\n        exec_str = self.func.__name__ + '(' \n        for p in self.params:\n            if p[0][0:2] != '__':   # ignore custom param names\n                exec_str += p[0] + '=\"' + self._force_str(p[1]) + '\", '\n                func_params.append(p[1])\n        exec_str = exec_str[:-2]\n        exec_str += ')  # task' + str(self.task_id) + ': ' + self.name\n        \n        \n        self.result = self.func(*func_params)\n        print(exec_str + ' loaded ', self.result)", "label": 1}
{"code": "function resolveDataSourceAttributes(resourceTree, dataSources, primaryName) {\n    Object.keys(dataSources).forEach(dataSourceName => {\n        const dataSource = dataSources[dataSourceName];\n        dataSource.attributes = [];\n        dataSource.attributeOptions = {};\n    });\n\n    resourceTree.attributes.forEach(function resolveAttribute(attrInfo) {\n        let selectedDataSources;\n\n        if (attrInfo.fromDataSource === '#same-group') {\n            return attrInfo.attributes.forEach(resolveAttribute); // handle key-groups as flat\n        }\n\n        if (attrInfo.fromDataSource === '#all-selected') {\n            attrInfo.attrNode.selectedDataSource = primaryName;\n            selectedDataSources = [];\n            Object.keys(dataSources).forEach(dataSourceName => {\n                if (dataSources[dataSourceName].joinParentKey) return;\n                selectedDataSources.push(dataSourceName);\n            });\n        } else if (attrInfo.fromDataSource === '#current-primary') {\n            attrInfo.attrNode.selectedDataSource = primaryName;\n            selectedDataSources = [attrInfo.attrNode.selectedDataSource];\n        } else if (attrInfo.fromDataSource) {\n            attrInfo.attrNode.selectedDataSource = attrInfo.fromDataSource;\n            selectedDataSources = [attrInfo.attrNode.selectedDataSource];\n        } else {\n            attrInfo.attrNode.selectedDataSource = Object.keys(attrInfo.dataSourceMap).find(\n                dataSourceName => dataSources[dataSourceName]\n            );\n\n            if (!attrInfo.attrNode.selectedDataSource) {\n                throw new ImplementationError(\n                    'No proper DataSource selected for attribute ' +\n                        '(this should not happen - bug in request-resolver in Flora core)'\n                );\n            }\n            selectedDataSources = [attrInfo.attrNode.selectedDataSource];\n        }\n\n        selectedDataSources.forEach(selectedDataSourceName => {\n            const attribute = attrInfo.dataSourceMap[selectedDataSourceName];\n            dataSources[selectedDataSourceName].attributes.push(attribute);\n            dataSources[selectedDataSourceName].attributeOptions[attribute] = _.pick(attrInfo.attrNode, [\n                'type',\n                'storedType',\n                'multiValued',\n                'delimiter'\n            ]);\n        });\n\n        return null;\n    });\n\n    Object.keys(dataSources).forEach(dataSourceName => {\n        dataSources[dataSourceName].attributes = _.uniq(dataSources[dataSourceName].attributes);\n    });\n}", "label": 3}
{"code": "function getNestedProperty(rootObject, propertyString) {\n    propertyString = propertyString.replace(/\\[(\\w+)\\]/g, '.$1'); // convert indexes to properties\n    propertyString = propertyString.replace(/^\\./, '');           // strip a leading dot\n    var propertyStringParts = propertyString.split(PROPERTY_SEPARATOR);\n    return _.reduce(propertyStringParts, function(currentBaseObject, currentPropertyName) {\n      return _.isUndefined(currentBaseObject) ? undefined : currentBaseObject[currentPropertyName];\n    }, rootObject);\n  }", "label": 3}
{"code": "def compile_attribute_values(values)\n      if values.map(&:key).uniq.size == 1\n        compile_attribute(values.first.key, values)\n      else\n        runtime_build(values)\n      end\n    end", "label": 4}
{"code": "public function setManipulations($manipulations) : self\n    {\n        if ($manipulations instanceof Manipulations) {\n            $this->manipulations = $this->manipulations->mergeManipulations($manipulations);\n        }\n\n        if (is_callable($manipulations)) {\n            $manipulations($this->manipulations);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def ele_index(class_name, index)\n      raise 'Index must be >= 1' unless index == 'last()' || (index.is_a?(Integer) && index >= 1)\n\n      elements = tags(class_name)\n\n      if index == 'last()'\n        result = elements.last\n      else\n        # elements array is 0 indexed\n        index -= 1\n        result = elements[index]\n      end\n\n      raise _no_such_element if result.nil?\n\n      result\n    end", "label": 4}
{"code": "def definitions_at filename, line, column\n      position = Position.new(line, column)\n      cursor = Source::Cursor.new(checkout(filename), position)\n      api_map.clip(cursor).define\n    end", "label": 4}
{"code": "function loadChild(node, cb){\n        db.nodes.getByParent(node._id.toString()).then(\n            function(data){\n                payload = payload.concat(data);\n                async.each(data, loadChild, cb);\n            }).done();\n    }", "label": 3}
{"code": "def serialisasi(self):\n        \"\"\"Mengembalikan hasil serialisasi objek Makna ini.\n\n        :returns: Dictionary hasil serialisasi\n        :rtype: dict\n        \"\"\"\n\n        return {\n            \"kelas\": self.kelas,\n            \"submakna\": self.submakna,\n            \"info\": self.info,\n            \"contoh\": self.contoh\n        }", "label": 1}
{"code": "func (d *discardSessionServer) GetSession(namespace string, id ID) (*Session, error) {\n\treturn &Session{}, nil\n}", "label": 5}
{"code": "def autoload_all(prefix, options)\n      if prefix =~ %r{^faraday(/|$)}i\n        prefix = File.join(Faraday.root_path, prefix)\n      end\n\n      options.each do |const_name, path|\n        autoload const_name, File.join(prefix, path)\n      end\n    end", "label": 4}
{"code": "def search_exoplanet(exoplanet):\n    '''\n    It is also possible to query the exoplanets by label, here is an example of querying for the exoplanet labeled as 11 Com\n\n    http://star-api.herokuapp.com/api/v1/exo_planets/11 Com\n    '''\n\n    base_url = \"http://star-api.herokuapp.com/api/v1/exo_planets/\"\n\n    if not isinstance(exoplanet, str):\n        raise ValueError(\n            \"The exoplanet arg you provided is not the type of str\")\n    else:\n        base_url += exoplanet\n\n    return dispatch_http_get(base_url)", "label": 1}
{"code": "public function restore(BlueprintInterface $blueprint)\n    {\n        Notification::where($this->getAttributes($blueprint))->update(['is_deleted' => false]);\n    }", "label": 2}
{"code": "func (c *Client) NewServiceClient(path string, namespace string) *Client {\n\tvc := c.URL()\n\tu, err := url.Parse(path)\n\tif err != nil {\n\t\tlog.Panicf(\"url.Parse(%q): %s\", path, err)\n\t}\n\tif u.Host == \"\" {\n\t\tu.Scheme = vc.Scheme\n\t\tu.Host = vc.Host\n\t}\n\n\tclient := NewClient(u, c.k)\n\tclient.Namespace = \"urn:\" + namespace\n\tif cert := c.Certificate(); cert != nil {\n\t\tclient.SetCertificate(*cert)\n\t}\n\n\t// Copy the trusted thumbprints\n\tc.hostsMu.Lock()\n\tfor k, v := range c.hosts {\n\t\tclient.hosts[k] = v\n\t}\n\tc.hostsMu.Unlock()\n\n\t// Copy the cookies\n\tclient.Client.Jar.SetCookies(u, c.Client.Jar.Cookies(u))\n\n\t// Set SOAP Header cookie\n\tfor _, cookie := range client.Jar.Cookies(u) {\n\t\tif cookie.Name == SessionCookieName {\n\t\t\tclient.cookie = cookie.Value\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Copy any query params (e.g. GOVMOMI_TUNNEL_PROXY_PORT used in testing)\n\tclient.u.RawQuery = vc.RawQuery\n\n\tclient.UserAgent = c.UserAgent\n\n\treturn client\n}", "label": 5}
{"code": "def render_hash(tags, key, **opts)\n      data = meta_tags.meta_tags[key]\n      return unless data.kind_of?(Hash)\n\n      process_hash(tags, key, data, **opts)\n      meta_tags.extract(key)\n    end", "label": 4}
{"code": "public static dnstxtrec[] get(nitro_service service) throws Exception{\n\t\tdnstxtrec obj = new dnstxtrec();\n\t\tdnstxtrec[] response = (dnstxtrec[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setTasks($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Tasks\\V2beta2\\Task::class);\n        $this->tasks = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function configureSites($projectName, $projectDirectory)\n    {\n        $sites = [\n            [\n                'map' => \"{$projectName}.test\",\n                'to' => \"/home/vagrant/{$projectDirectory}/public\",\n            ],\n        ];\n\n        if (isset($this->attributes['sites']) && ! empty($this->attributes['sites'])) {\n            foreach ($this->attributes['sites'] as $index => $user_site) {\n                if (isset($user_site['map'])) {\n                    $sites[$index]['map'] = $user_site['map'];\n                }\n\n                if (isset($user_site['to'])) {\n                    $sites[$index]['to'] = $user_site['to'];\n                }\n\n                if (isset($user_site['type'])) {\n                    $sites[$index]['type'] = $user_site['type'];\n                }\n\n                if (isset($user_site['schedule'])) {\n                    $sites[$index]['schedule'] = $user_site['schedule'];\n                }\n\n                if (isset($user_site['php'])) {\n                    $sites[$index]['php'] = $user_site['php'];\n                }\n\n                if (isset($user_site['xhgui'])) {\n                    $sites[$index]['xhgui'] = $user_site['xhgui'];\n                }\n            }\n        }\n\n        $this->update(['sites' => $sites]);\n\n        return $this;\n    }", "label": 2}
{"code": "func parseJSON(input []byte) (*logEntry, error) {\n\tvar raw map[string]interface{}\n\tentry := &logEntry{}\n\n\terr := json.Unmarshal(input, &raw)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Parse hclog-specific objects\n\tif v, ok := raw[\"@message\"]; ok {\n\t\tentry.Message = v.(string)\n\t\tdelete(raw, \"@message\")\n\t}\n\n\tif v, ok := raw[\"@level\"]; ok {\n\t\tentry.Level = v.(string)\n\t\tdelete(raw, \"@level\")\n\t}\n\n\tif v, ok := raw[\"@timestamp\"]; ok {\n\t\tt, err := time.Parse(\"2006-01-02T15:04:05.000000Z07:00\", v.(string))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tentry.Timestamp = t\n\t\tdelete(raw, \"@timestamp\")\n\t}\n\n\t// Parse dynamic KV args from the hclog payload.\n\tfor k, v := range raw {\n\t\tentry.KVPairs = append(entry.KVPairs, &logEntryKV{\n\t\t\tKey:   k,\n\t\t\tValue: v,\n\t\t})\n\t}\n\n\treturn entry, nil\n}", "label": 5}
{"code": "def add_axis(name, axis_class)\n      axis = axis_class.new\n      set_cross_axis(axis)\n      axes << [name, axis]\n    end", "label": 4}
{"code": "@Deprecated\n\t@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n\tpublic Map<String, PrimitiveAttribute<?>> getAttributes() {\n\t\tif (!isPrimitiveOnly()) {\n\t\t\tthrow new UnsupportedOperationException(\"Primitive API not supported for nested association values\");\n\t\t}\n\t\treturn (Map) attributes;\n\t}", "label": 0}
{"code": "public function setTimeSeries($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Monitoring\\V3\\TimeSeries::class);\n        $this->time_series = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function applyCustomColors(config) {\n  const { colors } = getAppSettings();\n\n  if (!config.hasOwnProperty('colors')) {\n    return {\n      ...config,\n      colors,\n    };\n  }\n\n  return {\n    ...config,\n    colors: {\n      ...config.colors,\n      ...colors,\n    },\n  };\n}", "label": 3}
{"code": "def send_file(file, caption: nil, tts: false, filename: nil, spoiler: nil)\n      @bot.send_file(@id, file, caption: caption, tts: tts, filename: filename, spoiler: spoiler)\n    end", "label": 4}
{"code": "function detect_class_members_from_object(cls, ast) {\n  cls[\"members\"] = []\n  return each_pair_in_object_expression(ast, function(key, value, pair) {\n    detect_method_or_property(cls, key, value, pair);\n  });\n}", "label": 3}
{"code": "def version\n      values = {}\n      ring.servers.each do |server|\n        values[\"#{server.name}\"] = server.alive? ? server.request(:version) : nil\n      end\n      values\n    end", "label": 4}
{"code": "def gets(sep_string, length = nil)\n      return read(length) if sep_string.nil?\n\n      # Read more data until we get the sep_string\n      while (index = @read_buffer.index(sep_string)).nil? && !@ios.eof?\n        break if length && @read_buffer.length >= length\n\n        read_block\n      end\n      index ||= -1\n      data    = @read_buffer.slice!(0..index)\n      @pos   += data.length\n      return nil if data.empty? && eof?\n\n      data\n    end", "label": 4}
{"code": "def get_all_keys(reactor, key_type, value_type, etcd_address):\n    \"\"\"Returns all keys from etcd.\n\n    :param reactor: reference to Twisted' reactor.\n    :param etcd_address: Address with port number where etcd is\n        running.\n    :return: An instance of txaioetcd.Range containing all keys and\n        their values.\n    \"\"\"\n    etcd = Client(reactor, etcd_address)\n    result = yield etcd.get(b'\\x00', range_end=b'\\x00')\n\n    res = {}\n    for item in result.kvs:\n        if key_type == u'utf8':\n            key = item.key.decode('utf8')\n        elif key_type == u'binary':\n            key = binascii.b2a_base64(item.key).decode().strip()\n        else:\n            raise Exception('logic error')\n\n        if value_type == u'json':\n            value = json.loads(item.value.decode('utf8'))\n        elif value_type == u'binary':\n            value = binascii.b2a_base64(item.value).decode().strip()\n        elif value_type == u'utf8':\n            value = item.value.decode('utf8')\n        else:\n            raise Exception('logic error')\n\n        res[key] = value\n\n    returnValue(res)", "label": 1}
{"code": "def recover(self, key, value):\n        \"\"\"Get the deserialized value for a given key, and the serialized version.\"\"\"\n        if key not in self._dtypes:\n            self.read_types()\n        if key not in self._dtypes:\n            raise ValueError(\"Unknown datatype for {} and {}\".format(key, value))\n        return self._dtypes[key][2](value)", "label": 1}
{"code": "func (cl *Client) Close() {\n\tcl.lock()\n\tdefer cl.unlock()\n\tcl.closed.Set()\n\tcl.eachDhtServer(func(s *dht.Server) { s.Close() })\n\tcl.closeSockets()\n\tfor _, t := range cl.torrents {\n\t\tt.close()\n\t}\n\tfor _, f := range cl.onClose {\n\t\tf()\n\t}\n\tcl.event.Broadcast()\n}", "label": 5}
{"code": "def find_type_elements(type, nested=true, elements=@elements)\n      results = []\n      if type.class == Symbol\n        type = [type]\n      end\n      elements.each do |e|\n        results.push(e) if type.include?(e.type)\n        if nested and not e.children.empty?\n          results.concat(find_type_elements(type, nested, e.children))\n        end\n      end\n      results\n    end", "label": 4}
{"code": "def search_path_by_state_link(state)\n      path = search_path_by(resource_type: params.dig(:filter, :resource_type), space_state: state)\n      is_active = params.dig(:filter, :space_state).to_s == state.to_s\n\n      link_to path, class: \"order-by__tab#{\" is-active\" if is_active}\" do\n        content_tag(:strong, t(state || :all, scope: \"decidim.searches.filters.state\"))\n      end\n    end", "label": 4}
{"code": "protected function addLookups(Route $route)\n    {\n        $action = $route->getAction();\n\n        if (isset($action['as'])) {\n            $this->names[$action['as']] = $route;\n        }\n\n        if (isset($action['controller'])) {\n            $this->actions[$action['controller']] = $route;\n        }\n    }", "label": 2}
{"code": "protected function validateArgs(): void\n    {\n        if (! $this->rules) {\n            return;\n        }\n\n        $validator = validator(\n            $this->args,\n            $this->rules,\n            $this->messages,\n            [\n                'root' => $this->root,\n                'context' => $this->context,\n                // This makes it so that we get an instance of our own Validator class\n                'resolveInfo' => $this->resolveInfo,\n            ]\n        );\n\n        if ($validator->fails()) {\n            foreach ($validator->errors()->getMessages() as $key => $errorMessages) {\n                foreach ($errorMessages as $errorMessage) {\n                    $this->validationErrorBuffer->push($errorMessage, $key);\n                }\n            }\n        }\n\n        $path = implode(\n            '.',\n            $this->resolveInfo()->path\n        );\n        $this->validationErrorBuffer->flush(\n            \"Validation failed for the field [$path].\"\n        );\n\n        // reset rules and messages\n        $this->rules = [];\n        $this->messages = [];\n    }", "label": 2}
{"code": "private void setMax(MtasRBTreeNode n) {\n    n.max = n.right;\n    if (n.leftChild != null) {\n      n.max = Math.max(n.max, n.leftChild.max);\n    }\n    if (n.rightChild != null) {\n      n.max = Math.max(n.max, n.rightChild.max);\n    }\n  }", "label": 0}
{"code": "def append_index_id(id, ids):\n    \"\"\"\n    add index to id to make it unique wrt ids\n    \"\"\"\n    index = 1\n    mod = '%s_%s' % (id, index)\n    while mod in ids:\n        index += 1\n        mod = '%s_%s' % (id, index)\n    ids.append(mod)\n    return mod, ids", "label": 1}
{"code": "function handleClientLoad() {\n\t(async ()=> {\n\t\tawait config.load()\n\t\tawait config.api.google.load()\n\t\tgapi.load('client:auth2', initClient)\t\n\t})().catch(console.error)\n}", "label": 3}
{"code": "function removeTrailingDirectorySeparator(path) {\n        if (path.charAt(path.length - 1) === ts.directorySeparator) {\n            return path.substr(0, path.length - 1);\n        }\n        return path;\n    }", "label": 3}
{"code": "func (t *TeleportClusterNameMarshaler) Marshal(c ClusterName, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch resource := c.(type) {\n\tcase *ClusterNameV2:\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *resource\n\t\t\tcopy.SetResourceID(0)\n\t\t\tresource = &copy\n\t\t}\n\t\treturn utils.FastMarshal(resource)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"unrecognized resource version %T\", c)\n\t}\n}", "label": 5}
{"code": "func (f FileManager) MakeDirectory(ctx context.Context, name string, dc *Datacenter, createParentDirectories bool) error {\n\treq := types.MakeDirectory{\n\t\tThis:                    f.Reference(),\n\t\tName:                    name,\n\t\tCreateParentDirectories: types.NewBool(createParentDirectories),\n\t}\n\n\tif dc != nil {\n\t\tref := dc.Reference()\n\t\treq.Datacenter = &ref\n\t}\n\n\t_, err := methods.MakeDirectory(ctx, f.c, &req)\n\treturn err\n}", "label": 5}
{"code": "def init(options = {})\n      json = client.put(\"/v1/sys/init\", JSON.fast_generate(\n        root_token_pgp_key: options.fetch(:root_token_pgp_key, nil),\n        secret_shares:      options.fetch(:secret_shares, options.fetch(:shares, 5)),\n        secret_threshold:   options.fetch(:secret_threshold, options.fetch(:threshold, 3)),\n        pgp_keys:           options.fetch(:pgp_keys, nil),\n        stored_shares:      options.fetch(:stored_shares, nil),\n        recovery_shares:    options.fetch(:recovery_shares, nil),\n        recovery_threshold: options.fetch(:recovery_threshold, nil),\n        recovery_pgp_keys:  options.fetch(:recovery_pgp_keys, nil),\n      ))\n      return InitResponse.decode(json)\n    end", "label": 4}
{"code": "function loggerFactory(\n    events,\n    Constants,\n    assert,\n    _,\n    util,\n    stack,\n    nconf\n) {\n    var levels = _.keys(Constants.Logging.Levels);\n\n    function getCaller (depth) {\n        var current = stack.get()[depth];\n\n        var file = current.getFileName().replace(\n            Constants.WorkingDirectory,\n            ''\n        ) + ':' + current.getLineNumber();\n\n        return file.replace(/^node_modules/, '');\n    }\n\n    function Logger (module) {\n        var provides = util.provides(module);\n\n        if (provides !== undefined) {\n            this.module = provides;\n        } else {\n            if (_.isFunction(module)) {\n                this.module = module.name;\n            } else {\n                this.module = module || 'No Module';\n            }\n        }\n    }\n\n    Logger.prototype.log = function (level, message, context) {\n        assert.isIn(level, levels);\n        assert.string(message, 'message');\n\n        // Exit if the log level of this message is less than the minimum log level.\n        var minLogLevel = nconf.get('minLogLevel');\n        if ((minLogLevel === undefined) || (typeof minLogLevel !== 'number')) {\n            minLogLevel = 0;\n        }\n        if (Constants.Logging.Levels[level] < minLogLevel) {\n            return;\n        }\n\n        events.log({\n            name: Constants.Name,\n            host: Constants.Host,\n            module: this.module,\n            level: level,\n            message: message,\n            context: context,\n            timestamp: new Date().toISOString(),\n            caller: getCaller(3),\n            subject: 'Server'\n        });\n    };\n\n    _.forEach(levels, function(level) {\n        Logger.prototype[level] = function (message, context) {\n            this.log(level, message, context);\n        };\n    });\n\n    Logger.prototype.deprecate = function (message, frames) {\n        console.error([\n            'DEPRECATION:',\n            this.module,\n            '-',\n            message,\n            getCaller(frames || 2)\n        ].join(' '));\n    };\n\n    Logger.initialize = function (module) {\n        return new Logger(module);\n    };\n\n    return Logger;\n}", "label": 3}
{"code": "func (c *Client) UpsertReverseTunnel(tunnel services.ReverseTunnel) error {\n\tdata, err := services.GetReverseTunnelMarshaler().MarshalReverseTunnel(tunnel)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\targs := &upsertReverseTunnelRawReq{\n\t\tReverseTunnel: data,\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"reversetunnels\"), args)\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "func NewClient(ctx context.Context, rt soap.RoundTripper) (*Client, error) {\n\tc := Client{\n\t\tRoundTripper: rt,\n\t}\n\n\t// Set client if it happens to be a soap.Client\n\tif sc, ok := rt.(*soap.Client); ok {\n\t\tc.Client = sc\n\n\t\tif c.Namespace == \"\" {\n\t\t\tc.Namespace = \"urn:\" + Namespace\n\t\t} else if !strings.Contains(c.Namespace, \":\") {\n\t\t\tc.Namespace = \"urn:\" + c.Namespace // ensure valid URI format\n\t\t}\n\t\tif c.Version == \"\" {\n\t\t\tc.Version = Version\n\t\t}\n\t}\n\n\tvar err error\n\tc.ServiceContent, err = methods.GetServiceContent(ctx, rt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &c, nil\n}", "label": 5}
{"code": "function findGroup(group, options) {\n  options = _.opts(options, {refresh: true, throwIfNotFound: true});\n  if (_.isString(group) && group.match(/^[0-9]+$/)) {\n    group = parseInt(group, 10);\n  }\n  return _findGroup(group, options);\n}", "label": 3}
{"code": "private boolean checkForVariables(List<Map<String, String>> values) {\n    if (values == null || values.isEmpty()) {\n      return false;\n    } else {\n      for (Map<String, String> list : values) {\n        if (list.containsKey(\"type\") && list.get(\"type\")\n            .equals(MtasParserMapping.PARSER_TYPE_VARIABLE)) {\n          return true;\n        }\n      }\n    }\n    return false;\n  }", "label": 0}
{"code": "private function resolveConfig(array $config)\n    {\n        if (!isset($config['httpHandler'])) {\n            $config['httpHandler'] = HttpHandlerFactory::build();\n        }\n\n        if (!isset($config['asyncHttpHandler'])) {\n            $isGuzzleHandler = $config['httpHandler'] instanceof Guzzle6HttpHandler\n                || $config['httpHandler'] instanceof Guzzle5HttpHandler;\n            $config['asyncHttpHandler'] = $isGuzzleHandler\n                ? [$config['httpHandler'], 'async']\n                : [HttpHandlerFactory::build(), 'async'];\n        }\n\n        return array_merge($this->config, $config);\n    }", "label": 2}
{"code": "func (t *TeleportStaticTokensMarshaler) Unmarshal(bytes []byte, opts ...MarshalOption) (StaticTokens, error) {\n\tvar staticTokens StaticTokensV2\n\n\tif len(bytes) == 0 {\n\t\treturn nil, trace.BadParameter(\"missing resource data\")\n\t}\n\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tif cfg.SkipValidation {\n\t\tif err := utils.FastUnmarshal(bytes, &staticTokens); err != nil {\n\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t}\n\t} else {\n\t\terr = utils.UnmarshalWithSchema(GetStaticTokensSchema(\"\"), &staticTokens, bytes)\n\t\tif err != nil {\n\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t}\n\t}\n\n\terr = staticTokens.CheckAndSetDefaults()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tif cfg.ID != 0 {\n\t\tstaticTokens.SetResourceID(cfg.ID)\n\t}\n\tif !cfg.Expires.IsZero() {\n\t\tstaticTokens.SetExpiry(cfg.Expires)\n\t}\n\treturn &staticTokens, nil\n}", "label": 5}
{"code": "function writeFormsToZip(forms, callback) {\n  var zip = archiver('zip')\n    , metadata = {};\n\n  metadata.exportCreated = new Date();\n  metadata.files = {};\n\n  function processForms() {\n    // Process all forms\n    _.each(forms, function(form) {\n      // Update metadata on the fly\n      updateMetadata(metadata, form);\n      zip.append(JSON.stringify(form), {\n        name: path.join(ZIP_SUBFOLDER_NAME, form.id + '.json')\n      });\n    });\n\n    // Last step: write the metadata file in the root folder\n    zip.append(JSON.stringify(metadata), {\n      name: METADATA_FILE_NAME\n    });\n\n    zip.finalize();\n  }\n\n  process.nextTick(processForms);\n  callback(null, zip);\n}", "label": 3}
{"code": "def stack_register?(reg)\n      %w[esp ebp rsp rbp sp x29].include?(reg)\n    end", "label": 4}
{"code": "def is_remote_branch?(branch)\n      branch_names = self.branches.remote.map {|b| b.name}\n      branch_names.include?(branch)\n    end", "label": 4}
{"code": "public static statobjects get(nitro_service service) throws Exception{\n\t\tstatobjects obj = new statobjects();\n\t\tstatobjects[] response = (statobjects[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public void actionPerformed(java.awt.event.ActionEvent e)\r\n    {\r\n        System.out.println(\"Action Command: \" + e.getActionCommand());\r\n        System.out.println(\"Action Params : \" + e.paramString());\r\n        System.out.println(\"Action Source : \" + e.getSource());\r\n        System.out.println(\"Action SrcCls : \" + e.getSource().getClass().getName());\r\n        org.apache.ojb.broker.metadata.ClassDescriptor cld =\r\n            new org.apache.ojb.broker.metadata.ClassDescriptor(rootNode.getRepository());\r\n        // cld.setClassNameOfObject(\"New Class\");\r\n        cld.setTableName(\"New Table\");\r\n        rootNode.addClassDescriptor(cld);\r\n    }", "label": 0}
{"code": "public function unblockAddress($ip) {\n        if (isset($this->_blacklist[$this->filterAddress($ip)])) {\n            unset($this->_blacklist[$this->filterAddress($ip)]);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "public function has($name)\n    {\n        return isset($this->properties[$name]) || isset($this->delivery_info[$name]);\n    }", "label": 2}
{"code": "def append_to_solr_doc(solr_doc, solr_field_key, field_info, val)\n      return super unless object.controlled_properties.include?(solr_field_key.to_sym)\n      case val\n      when ActiveTriples::Resource\n        append_label_and_uri(solr_doc, solr_field_key, field_info, val)\n      when String\n        append_label(solr_doc, solr_field_key, field_info, val)\n      else\n        raise ArgumentError, \"Can't handle #{val.class}\"\n      end\n    end", "label": 4}
{"code": "func (c *AuthPreferenceV2) String() string {\n\treturn fmt.Sprintf(\"AuthPreference(Type=%q,SecondFactor=%q)\", c.Spec.Type, c.Spec.SecondFactor)\n}", "label": 5}
{"code": "function generateMakefile(testFiles, targetPath, callback) {\n  var template = new templates.Template('Makefile.magic');\n  var fullPath = path.join(targetPath, 'Makefile');\n  var context = {\n    test_files: testFiles.join(' \\\\\\n ')\n  };\n\n  if (path.existsSync(fullPath)) {\n    callback(new Error(sprintf('File \"%s\" already exists', fullPath)));\n    return;\n  }\n\n  async.waterfall([\n    template.load.bind(template),\n\n    function render(template, callback) {\n      template.render(context, callback);\n    },\n\n    function save(output, callback) {\n      fs.writeFile(fullPath, output.join(''), callback);\n    }\n  ], callback);\n}", "label": 3}
{"code": "func (f *Fpdf) UseTemplateScaled(t Template, corner PointType, size SizeType) {\n\tif t == nil {\n\t\tf.SetErrorf(\"template is nil\")\n\t\treturn\n\t}\n\n\t// You have to add at least a page first\n\tif f.page <= 0 {\n\t\tf.SetErrorf(\"cannot use a template without first adding a page\")\n\t\treturn\n\t}\n\n\t// make a note of the fact that we actually use this template, as well as any other templates,\n\t// images or fonts it uses\n\tf.templates[t.ID()] = t\n\tfor _, tt := range t.Templates() {\n\t\tf.templates[tt.ID()] = tt\n\t}\n\tfor name, ti := range t.Images() {\n\t\tname = sprintf(\"t%s-%s\", t.ID(), name)\n\t\tf.images[name] = ti\n\t}\n\n\t// template data\n\t_, templateSize := t.Size()\n\tscaleX := size.Wd / templateSize.Wd\n\tscaleY := size.Ht / templateSize.Ht\n\ttx := corner.X * f.k\n\tty := (f.curPageSize.Ht - corner.Y - size.Ht) * f.k\n\n\tf.outf(\"q %.4f 0 0 %.4f %.4f %.4f cm\", scaleX, scaleY, tx, ty) // Translate\n\tf.outf(\"/TPL%s Do Q\", t.ID())\n}", "label": 5}
{"code": "public static void main(String[] args) {\r\n\r\n    String[] s = {\"there once was a man\", \"this one is a manic\", \"hey there\", \"there once was a mane\", \"once in a manger.\", \"where is one match?\", \"Jo3seph Smarr!\", \"Joseph R Smarr\"};\r\n    for (int i = 0; i < 8; i++) {\r\n      for (int j = 0; j < 8; j++) {\r\n        System.out.println(\"s1: \" + s[i]);\r\n        System.out.println(\"s2: \" + s[j]);\r\n        System.out.println(\"edit distance: \" + editDistance(s[i], s[j]));\r\n        System.out.println(\"LCS:           \" + longestCommonSubstring(s[i], s[j]));\r\n        System.out.println(\"LCCS:          \" + longestCommonContiguousSubstring(s[i], s[j]));\r\n        System.out.println();\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "func hasMultiByteCharacter(fl FieldLevel) bool {\n\n\tfield := fl.Field()\n\n\tif field.Len() == 0 {\n\t\treturn true\n\t}\n\n\treturn multibyteRegex.MatchString(field.String())\n}", "label": 5}
{"code": "def _wait_for_macaroon(wait_url):\n    ''' Returns a macaroon from a legacy wait endpoint.\n    '''\n    headers = {\n        BAKERY_PROTOCOL_HEADER: str(bakery.LATEST_VERSION)\n    }\n    resp = requests.get(url=wait_url, headers=headers)\n    if resp.status_code != 200:\n        raise InteractionError('cannot get {}'.format(wait_url))\n\n    return bakery.Macaroon.from_dict(resp.json().get('Macaroon'))", "label": 1}
{"code": "def get_or_create_from_ip(ip):\n        \"\"\"\n        Get or create an entry using obtained information from an IP.\n\n        Args:\n            ip (str): IP address xxx.xxx.xxx.xxx.\n\n        Returns:\n            ip_info: an instance of IPInfo.\n        \"\"\"\n        data = ip_api_handler.get(ip)\n        if data and any(v for v in data.values()):\n            if data.get('ip_address', None) is None or not data['ip_address']:\n                data['ip_address'] = ip\n            return IPInfo.objects.get_or_create(**data)\n        return None, False", "label": 1}
{"code": "public function diffInWeekdays($date = null, $absolute = true)\n    {\n        return $this->diffInDaysFiltered(function (CarbonInterface $date) {\n            return $date->isWeekday();\n        }, $date, $absolute);\n    }", "label": 2}
{"code": "public static appfwpolicy_csvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappfwpolicy_csvserver_binding obj = new appfwpolicy_csvserver_binding();\n\t\tobj.set_name(name);\n\t\tappfwpolicy_csvserver_binding response[] = (appfwpolicy_csvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void postBuildInfo(final String moduleName, final String moduleVersion, final Map<String, String> buildInfo, final String user, final String password) throws GrapesCommunicationException, AuthenticationException {\n        final Client client = getClient(user, password);\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.getBuildInfoPath(moduleName, moduleVersion));\n        final ClientResponse response = resource.type(MediaType.APPLICATION_JSON).post(ClientResponse.class, buildInfo);\n\n        client.destroy();\n        if(ClientResponse.Status.CREATED.getStatusCode() != response.getStatus()){\n            final String message = \"Failed to POST buildInfo\";\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n    }", "label": 0}
{"code": "def item(ctx, appid, title):\n    \"\"\"Market-related commands.\"\"\"\n    ctx.obj['appid'] = appid\n    ctx.obj['title'] = title", "label": 1}
{"code": "public static spilloverpolicy_stats[] get(nitro_service service) throws Exception{\n\t\tspilloverpolicy_stats obj = new spilloverpolicy_stats();\n\t\tspilloverpolicy_stats[] response = (spilloverpolicy_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def all_axis_bin_centers(self, axis):\n        \"\"\"Return ndarray of same shape as histogram containing bin center value along axis at each point\"\"\"\n        # Arcane hack that seems to work, at least in 3d... hope\n        axis = self.get_axis_number(axis)\n        return np.meshgrid(*self.bin_centers(), indexing='ij')[axis]", "label": 1}
{"code": "def site_bar_switch_link\n      link_to_if(admin?, t('.switch_to_your_website', site_bar_translate_locale_args),\n                         refinery.root_path(site_bar_translate_locale_args),\n                         'data-turbolinks' => false) do\n        link_to t('.switch_to_your_website_editor', site_bar_translate_locale_args),\n                Refinery::Core.backend_path, 'data-turbolinks' => false\n      end\n    end", "label": 4}
{"code": "public void create(final DbProduct dbProduct) {\n        if(repositoryHandler.getProduct(dbProduct.getName()) != null){\n            throw new WebApplicationException(Response.status(Response.Status.CONFLICT).entity(\"Product already exist!\").build());\n        }\n\n        repositoryHandler.store(dbProduct);\n    }", "label": 0}
{"code": "def _extract_email(gh):\n    \"\"\"Get user email from github.\"\"\"\n    return next(\n        (x.email for x in gh.emails() if x.verified and x.primary), None)", "label": 1}
{"code": "function mapColumns(children, callback) {\n  var newChildren = [];\n  React.Children.forEach(children, function(originalChild)  {\n    var newChild = originalChild;\n\n    // The child is either a column group or a column. If it is a column group\n    // we need to iterate over its columns and then potentially generate a\n    // new column group\n    if (originalChild.type === FixedDataTableColumnGroup.type) {\n      var haveColumnsChanged = false;\n      var newColumns = [];\n\n      forEachColumn(originalChild.props.children, function(originalcolumn)  {\n        var newColumn = callback(originalcolumn);\n        if (newColumn !== originalcolumn) {\n          haveColumnsChanged = true;\n        }\n        newColumns.push(newColumn);\n      });\n\n      // If the column groups columns have changed clone the group and supply\n      // new children\n      if (haveColumnsChanged) {\n        newChild = cloneWithProps(originalChild, {children: newColumns});\n      }\n    } else if (originalChild.type === FixedDataTableColumn.type) {\n      newChild = callback(originalChild);\n    }\n\n    newChildren.push(newChild);\n  });\n\n  return newChildren;\n}", "label": 3}
{"code": "public void takeNoteOfGradient(IntDoubleVector gradient) {\n        gradient.iterate(new FnIntDoubleToVoid() {            \n            @Override\n            public void call(int index, double value) {\n                gradSumSquares[index] += value * value;\n                assert !Double.isNaN(gradSumSquares[index]);\n            }\n        });\n    }", "label": 0}
{"code": "async def load_field(obj, elem_type, params=None, elem=None):\n    \"\"\"\n    Loads a field from the reader, based on the field type specification. Demultiplexer.\n\n    :param obj:\n    :param elem_type:\n    :param params:\n    :param elem:\n    :return:\n    \"\"\"\n    if issubclass(elem_type, x.UVarintType) or issubclass(elem_type, x.IntType) or isinstance(obj, (int, bool)):\n        return set_elem(elem, obj)\n\n    elif issubclass(elem_type, x.BlobType):\n        fvalue = await load_blob(obj, elem_type)\n        return set_elem(elem, fvalue)\n\n    elif issubclass(elem_type, x.UnicodeType) or isinstance(elem, str):\n        return set_elem(elem, obj)\n\n    elif issubclass(elem_type, x.VariantType):\n        fvalue = await load_variant(obj, elem=get_elem(elem), elem_type=elem_type, params=params)\n        return set_elem(elem, fvalue)\n\n    elif issubclass(elem_type, x.ContainerType):  # container ~ simple list\n        fvalue = await load_container(obj, elem_type, params=params, container=get_elem(elem))\n        return set_elem(elem, fvalue)\n\n    elif issubclass(elem_type, x.MessageType):\n        fvalue = await load_message(obj, msg_type=elem_type, msg=get_elem(elem))\n        return set_elem(elem, fvalue)\n\n    else:\n        raise TypeError", "label": 1}
{"code": "public function updateBatch($table, array $dataSet)\n    {\n        $this->enqueue(Operation::OP_UPDATE, $table, $dataSet);\n\n        return $this;\n    }", "label": 2}
{"code": "def log(self):\n        \"\"\"\n            Return recent log entries as a string.\n        \"\"\"\n        logserv = self.system.request_service('LogStoreService')\n        return logserv.lastlog(html=False)", "label": 1}
{"code": "def producer\n      # Create opaque\n      opaque = Opaque.new\n      # Create Kafka config\n      config = native_config(opaque)\n      # Set callback to receive delivery reports on config\n      Rdkafka::Bindings.rd_kafka_conf_set_dr_msg_cb(config, Rdkafka::Bindings::DeliveryCallback)\n      # Return producer with Kafka client\n      Rdkafka::Producer.new(native_kafka(config, :rd_kafka_producer)).tap do |producer|\n        opaque.producer = producer\n      end\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, filterhtmlinjectionparameter resource) throws Exception {\n\t\tfilterhtmlinjectionparameter updateresource = new filterhtmlinjectionparameter();\n\t\tupdateresource.rate = resource.rate;\n\t\tupdateresource.frequency = resource.frequency;\n\t\tupdateresource.strict = resource.strict;\n\t\tupdateresource.htmlsearchlen = resource.htmlsearchlen;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def list_keys(self, pattern='*', db=0):\n        \"\"\"\n        Run the ``KEYS`` command and return the list of matching keys.\n\n        :param pattern: the pattern to filter keys by (default ``*``)\n        :param db: the db number to query (default ``0``)\n        \"\"\"\n        lines = output_lines(self.exec_redis_cli('KEYS', [pattern], db=db))\n        return [] if lines == [''] else lines", "label": 1}
{"code": "def present?\n      displayed = display_check\n      if displayed.nil? && display_check\n        Watir.logger.deprecate 'Checking `#present? == false` to determine a stale element',\n                               '`#stale? == true`',\n                               reference: 'http://watir.com/staleness-changes',\n                               ids: [:stale_present]\n      end\n      displayed\n    rescue UnknownObjectException, UnknownFrameException\n      false\n    end", "label": 4}
{"code": "def last(n = nil)\n      require_terminating_rules\n      occurrences = enumerate_occurrences(start_time).to_a\n      n.nil? ? occurrences.last : occurrences[-n..-1]\n    end", "label": 4}
{"code": "func (nDB *NetworkDB) JoinNetwork(nid string) error {\n\tltime := nDB.networkClock.Increment()\n\n\tnDB.Lock()\n\tnodeNetworks, ok := nDB.networks[nDB.config.NodeID]\n\tif !ok {\n\t\tnodeNetworks = make(map[string]*network)\n\t\tnDB.networks[nDB.config.NodeID] = nodeNetworks\n\t}\n\tn, ok := nodeNetworks[nid]\n\tvar entries int\n\tif ok {\n\t\tentries = n.entriesNumber\n\t}\n\tnodeNetworks[nid] = &network{id: nid, ltime: ltime, entriesNumber: entries}\n\tnodeNetworks[nid].tableBroadcasts = &memberlist.TransmitLimitedQueue{\n\t\tNumNodes: func() int {\n\t\t\t//TODO fcrisciani this can be optimized maybe avoiding the lock?\n\t\t\t// this call is done each GetBroadcasts call to evaluate the number of\n\t\t\t// replicas for the message\n\t\t\tnDB.RLock()\n\t\t\tdefer nDB.RUnlock()\n\t\t\treturn len(nDB.networkNodes[nid])\n\t\t},\n\t\tRetransmitMult: 4,\n\t}\n\tnDB.addNetworkNode(nid, nDB.config.NodeID)\n\tnetworkNodes := nDB.networkNodes[nid]\n\tn = nodeNetworks[nid]\n\tnDB.Unlock()\n\n\tif err := nDB.sendNetworkEvent(nid, NetworkEventTypeJoin, ltime); err != nil {\n\t\treturn fmt.Errorf(\"failed to send leave network event for %s: %v\", nid, err)\n\t}\n\n\tlogrus.Debugf(\"%v(%v): joined network %s\", nDB.config.Hostname, nDB.config.NodeID, nid)\n\tif _, err := nDB.bulkSync(networkNodes, true); err != nil {\n\t\tlogrus.Errorf(\"Error bulk syncing while joining network %s: %v\", nid, err)\n\t}\n\n\t// Mark the network as being synced\n\t// note this is a best effort, we are not checking the result of the bulk sync\n\tnDB.Lock()\n\tn.inSync = true\n\tnDB.Unlock()\n\n\treturn nil\n}", "label": 5}
{"code": "protected function checkInitializer($initializer)\n    {\n        if (is_callable($initializer)) {\n            return $initializer;\n        }\n\n        $class = new \\ReflectionClass($initializer);\n\n        if (!$class->isSubclassOf('Predis\\Connection\\NodeConnectionInterface')) {\n            throw new \\InvalidArgumentException(\n                'A connection initializer must be a valid connection class or a callable object.'\n            );\n        }\n\n        return $initializer;\n    }", "label": 2}
{"code": "func (r *ChainResponse) AddChain(chain bees.Chain) {\n\tr.chains[chain.Name] = &chain\n}", "label": 5}
{"code": "public static function pluralize( $word ) {\n\t\tif ( isset( self::$cache['pluralize'][ $word ] ) ) {\n\t\t\treturn self::$cache['pluralize'][ $word ];\n\t\t}\n\n\t\tif ( ! isset( self::$plural['merged']['irregular'] ) ) {\n\t\t\tself::$plural['merged']['irregular'] = self::$plural['irregular'];\n\t\t}\n\n\t\tif ( ! isset( self::$plural['merged']['uninflected'] ) ) {\n\t\t\tself::$plural['merged']['uninflected'] = array_merge( self::$plural['uninflected'], self::$uninflected );\n\t\t}\n\n\t\tif ( ! isset( self::$plural['cacheUninflected'] ) || ! isset( self::$plural['cacheIrregular'] ) ) {\n\t\t\tself::$plural['cacheUninflected'] = '(?:' . implode( '|', self::$plural['merged']['uninflected'] ) . ')';\n\t\t\tself::$plural['cacheIrregular']   = '(?:' . implode( '|', array_keys( self::$plural['merged']['irregular'] ) ) . ')';\n\t\t}\n\n\t\tif ( preg_match( '/(.*)\\\\b(' . self::$plural['cacheIrregular'] . ')$/i', $word, $regs ) ) {\n\t\t\tself::$cache['pluralize'][ $word ] = $regs[1] . substr( $word, 0, 1 ) . substr( self::$plural['merged']['irregular'][ strtolower( $regs[2] ) ], 1 );\n\n\t\t\treturn self::$cache['pluralize'][ $word ];\n\t\t}\n\n\t\tif ( preg_match( '/^(' . self::$plural['cacheUninflected'] . ')$/i', $word, $regs ) ) {\n\t\t\tself::$cache['pluralize'][ $word ] = $word;\n\n\t\t\treturn $word;\n\t\t}\n\n\t\tforeach ( self::$plural['rules'] as $rule => $replacement ) {\n\t\t\tif ( preg_match( $rule, $word ) ) {\n\t\t\t\tself::$cache['pluralize'][ $word ] = preg_replace( $rule, $replacement, $word );\n\n\t\t\t\treturn self::$cache['pluralize'][ $word ];\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "def transform_comments(separator, &block)\n      if @comments.empty?\n        nil\n      else\n        block ||= lambda { |c| c }\n        @comments.map(&block).join(separator)\n      end\n    end", "label": 4}
{"code": "def parse_miss_cann(node, m, c):\n    \"\"\"\n    extracts names from the node to get \n    counts of miss + cann on both sides\n    \"\"\"\n    if node[2]:\n        m1 = node[0]\n        m2 = m-node[0]\n        c1 = node[1]\n        c2 = c-node[1]\n    else:\n        m1=m-node[0]\n        m2=node[0]\n        c1=c-node[1]\n        c2=node[1]\n    \n    return m1, c1, m2, c2", "label": 1}
{"code": "public function setTransferConfigs($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferConfig::class);\n        $this->transfer_configs = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def fetch_withdrawals_since(self, since: int) -> List[Withdrawal]:\n        \"\"\"Fetch all withdrawals since the given timestamp.\"\"\"\n        return self._transactions_since(self._withdrawals_since, 'withdrawals', since)", "label": 1}
{"code": "private function buildToCreateList($number)\n    {\n        $toCreate = [];\n        $time = $this->time();\n\n        for ($i = 0; $i < $number; $i++) {\n            $toCreate[uniqid($time . '_', true)] = $time;\n        }\n\n        return $toCreate;\n    }", "label": 2}
{"code": "public function setPropertyOverride(Property $property) : void\n    {\n        $fieldName = $property->getName();\n\n        if (! isset($this->declaredProperties[$fieldName])) {\n            throw MappingException::invalidOverrideFieldName($this->className, $fieldName);\n        }\n\n        $originalProperty          = $this->getProperty($fieldName);\n        $originalPropertyClassName = get_class($originalProperty);\n\n        // If moving from transient to persistent, assume it's a new property\n        if ($originalPropertyClassName === TransientMetadata::class) {\n            unset($this->declaredProperties[$fieldName]);\n\n            $this->addProperty($property);\n\n            return;\n        }\n\n        // Do not allow to change property type\n        if ($originalPropertyClassName !== get_class($property)) {\n            throw MappingException::invalidOverridePropertyType($this->className, $fieldName);\n        }\n\n        // Do not allow to change version property\n        if ($originalProperty instanceof VersionFieldMetadata) {\n            throw MappingException::invalidOverrideVersionField($this->className, $fieldName);\n        }\n\n        unset($this->declaredProperties[$fieldName]);\n\n        if ($property instanceof FieldMetadata) {\n            // Unset defined fieldName prior to override\n            unset($this->fieldNames[$originalProperty->getColumnName()]);\n\n            // Revert what should not be allowed to change\n            $property->setDeclaringClass($originalProperty->getDeclaringClass());\n            $property->setPrimaryKey($originalProperty->isPrimaryKey());\n        } elseif ($property instanceof AssociationMetadata) {\n            // Unset all defined fieldNames prior to override\n            if ($originalProperty instanceof ToOneAssociationMetadata && $originalProperty->isOwningSide()) {\n                foreach ($originalProperty->getJoinColumns() as $joinColumn) {\n                    unset($this->fieldNames[$joinColumn->getColumnName()]);\n                }\n            }\n\n            // Override what it should be allowed to change\n            if ($property->getInversedBy()) {\n                $originalProperty->setInversedBy($property->getInversedBy());\n            }\n\n            if ($property->getFetchMode() !== $originalProperty->getFetchMode()) {\n                $originalProperty->setFetchMode($property->getFetchMode());\n            }\n\n            if ($originalProperty instanceof ToOneAssociationMetadata && $property->getJoinColumns()) {\n                $originalProperty->setJoinColumns($property->getJoinColumns());\n            } elseif ($originalProperty instanceof ManyToManyAssociationMetadata && $property->getJoinTable()) {\n                $originalProperty->setJoinTable($property->getJoinTable());\n            }\n\n            $property = $originalProperty;\n        }\n\n        $this->addProperty($property);\n    }", "label": 2}
{"code": "def validate(string_or_document, rules: nil, context: nil)\n      doc = if string_or_document.is_a?(String)\n        GraphQL.parse(string_or_document)\n      else\n        string_or_document\n      end\n      query = GraphQL::Query.new(self, document: doc, context: context)\n      validator_opts = { schema: self }\n      rules && (validator_opts[:rules] = rules)\n      validator = GraphQL::StaticValidation::Validator.new(validator_opts)\n      res = validator.validate(query)\n      res[:errors]\n    end", "label": 4}
{"code": "def idsKEGG(organism):\n    \"\"\"\n    Uses KEGG to retrieve all ids for a given KEGG organism\n\n    :param organism: an organism as listed in organismsKEGG()\n\n    :returns: a Pandas dataframe of with 'gene_name' and 'KEGGid'.\n\n    \"\"\"\n    ORG=urlopen(\"http://rest.kegg.jp/list/\"+organism).read()\n    ORG=ORG.split(\"\\n\")\n    final=[]\n    for k in ORG:\n        final.append(k.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n    df.columns=['KEGGid','description']\n    field = pd.DataFrame(df['description'].str.split(';',1).tolist())[0]\n    field = pd.DataFrame(field)\n    df = pd.concat([df[['KEGGid']],field],axis=1)\n    df.columns=['KEGGid','gene_name']\n    df=df[['gene_name','KEGGid']]\n    return df", "label": 1}
{"code": "function() {\n      var staleItemViews = [];\n      var modelsWithViews = _.clone(this.__modelToViewMap);\n      _.each(this.modelsToRender(), function(model) {\n        var itemView = this.getItemViewFromModel(model);\n        if (itemView) {\n          delete modelsWithViews[model[this.__modelId]];\n        }\n      }, this);\n      _.each(modelsWithViews, function(viewId, modelId) {\n        var itemView = this.getTrackedView(viewId);\n        if (itemView) {\n          staleItemViews.push({ view: itemView, modelId: modelId });\n        }\n      }, this);\n      return staleItemViews;\n    }", "label": 3}
{"code": "def plausible? number, hints = {}\n      normalized = clean number\n\n      # False if it fails the basic check.\n      #\n      return false unless (4..16) === normalized.size\n\n      country, cc, rest = partial_split normalized\n\n      # Country code plausible?\n      #\n      cc_needed = hints[:cc]\n      return false if cc_needed && !(cc_needed === cc)\n\n      # Country specific tests.\n      #\n      country.plausible? rest, hints\n    rescue StandardError\n      return false\n    end", "label": 4}
{"code": "private StyleFilter findStyleFilter(Object feature, List<StyleFilter> styles) {\n\t\tfor (StyleFilter styleFilter : styles) {\n\t\t\tif (styleFilter.getFilter().evaluate(feature)) {\n\t\t\t\treturn styleFilter;\n\t\t\t}\n\t\t}\n\t\treturn new StyleFilterImpl();\n\t}", "label": 0}
{"code": "func (aSpace *addrSpace) updatePoolDBOnAdd(k SubnetKey, nw *net.IPNet, ipr *AddressRange, pdf bool) (func() error, error) {\n\taSpace.Lock()\n\tdefer aSpace.Unlock()\n\n\t// Check if already allocated\n\tif _, ok := aSpace.subnets[k]; ok {\n\t\tif pdf {\n\t\t\treturn nil, types.InternalMaskableErrorf(\"predefined pool %s is already reserved\", nw)\n\t\t}\n\t\t// This means the same pool is already allocated. updatePoolDBOnAdd is called when there\n\t\t// is request for a pool/subpool. It should ensure there is no overlap with existing pools\n\t\treturn nil, ipamapi.ErrPoolOverlap\n\t}\n\n\t// If master pool, check for overlap\n\tif ipr == nil {\n\t\tif aSpace.contains(k.AddressSpace, nw) {\n\t\t\treturn nil, ipamapi.ErrPoolOverlap\n\t\t}\n\t\t// This is a new master pool, add it along with corresponding bitmask\n\t\taSpace.subnets[k] = &PoolData{Pool: nw, RefCount: 1}\n\t\treturn func() error { return aSpace.alloc.insertBitMask(k, nw) }, nil\n\t}\n\n\t// This is a new non-master pool (subPool)\n\tp := &PoolData{\n\t\tParentKey: SubnetKey{AddressSpace: k.AddressSpace, Subnet: k.Subnet},\n\t\tPool:      nw,\n\t\tRange:     ipr,\n\t\tRefCount:  1,\n\t}\n\taSpace.subnets[k] = p\n\n\t// Look for parent pool\n\tpp, ok := aSpace.subnets[p.ParentKey]\n\tif ok {\n\t\taSpace.incRefCount(pp, 1)\n\t\treturn func() error { return nil }, nil\n\t}\n\n\t// Parent pool does not exist, add it along with corresponding bitmask\n\taSpace.subnets[p.ParentKey] = &PoolData{Pool: nw, RefCount: 1}\n\treturn func() error { return aSpace.alloc.insertBitMask(p.ParentKey, nw) }, nil\n}", "label": 5}
{"code": "def unregister(self, thread):\n        \"\"\"\n        Unregisters an existing thread, so that this thread is no longer available.\n\n        This function is mainly used during plugin deactivation.\n\n        :param thread: Name of the thread\n        \"\"\"\n        if thread not in self.threads.keys():\n            self.log.warning(\"Can not unregister thread %s\" % thread)\n        else:\n            del (self.threads[thread])\n            self.__log.debug(\"Thread %s got unregistered\" % thread)", "label": 1}
{"code": "function(callback, dest)\n  {\n    var out = dest || new Map();\n    var n = this.size();\n    var values = this.values;\n    var keys = this.keys;\n\n    for (var i = 0; i < n; i++)\n    {\n      var v = values[ i ];\n      var k = keys[ i ];\n\n      if ( callback( v, k ) )\n      {\n        out.put( k, v );\n      }\n    }\n\n    return out;\n  }", "label": 3}
{"code": "function refreshSyncers(keys) {\n\tif (typeof keys === 'string') {\n\t\tkeys = [keys]\n\t}\n\tif (!keys) {\n\t\tkeys = Object.keys(this._syncers)\n\t}\n\treturn Promise.all(keys.map(key => {\n\t\treturn this._syncers[key].refresh()\n\t}))\n}", "label": 3}
{"code": "public static function generate($email, $userId)\n    {\n        $token = new static;\n\n        $token->token = str_random(40);\n        $token->user_id = $userId;\n        $token->email = $email;\n        $token->created_at = Carbon::now();\n\n        return $token;\n    }", "label": 2}
{"code": "public function setStatus($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Tasks\\V2beta2\\TaskStatus::class);\n        $this->status = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo]) do\n        permit VALID_LABEL_INPUTS\n        assert_required VALID_LABEL_INPUTS\n      end\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/labels\", arguments.params)\n    end", "label": 4}
{"code": "public function write_octet($n)\n    {\n        if ($n < 0 || $n > 255) {\n            throw new AMQPInvalidArgumentException('Octet out of range: ' . $n);\n        }\n\n        $this->out .= chr($n);\n\n        return $this;\n    }", "label": 2}
{"code": "protected function channel_alert($reader)\n    {\n        $reply_code = $reader->read_short();\n        $reply_text = $reader->read_shortstr();\n        $details = $reader->read_table();\n        array_push($this->alerts, array($reply_code, $reply_text, $details));\n    }", "label": 2}
{"code": "func (h HeartbeatMode) String() string {\n\tswitch h {\n\tcase HeartbeatModeNode:\n\t\treturn \"Node\"\n\tcase HeartbeatModeProxy:\n\t\treturn \"Proxy\"\n\tcase HeartbeatModeAuth:\n\t\treturn \"Auth\"\n\tdefault:\n\t\treturn fmt.Sprintf(\"<unknown: %v>\", int(h))\n\t}\n}", "label": 5}
{"code": "public static base_responses unset(nitro_service client, String urlname[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (urlname != null && urlname.length > 0) {\n\t\t\tvpnurl unsetresources[] = new vpnurl[urlname.length];\n\t\t\tfor (int i=0;i<urlname.length;i++){\n\t\t\t\tunsetresources[i] = new vpnurl();\n\t\t\t\tunsetresources[i].urlname = urlname[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def use_webpacker(middleware)\n      return unless Jets.webpacker? # checks for local development if webpacker installed\n      # Different check for middleware because we need webpacker helpers for url helpers.\n      # But we dont want to actually serve via webpacker middleware when running on AWS.\n      # By this time the url helpers are serving assets out of s3.\n      return if File.exist?(\"#{Jets.root}/config/disable-webpacker-middleware.txt\") # created as part of `jets deploy`\n      require \"jets/controller/middleware/webpacker_setup\"\n      middleware.use Webpacker::DevServerProxy\n    end", "label": 4}
{"code": "public function setLogicalOperator($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dlp\\V2\\RecordCondition_Expressions_LogicalOperator::class);\n        $this->logical_operator = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function compareTimeZones(a, b) {\n    if (typeof a !== 'string' || typeof b !== 'string') {\n      return NaN;\n    }\n\n    return normalizeIso8601TimeZone(a) - normalizeIso8601TimeZone(b);\n  }", "label": 3}
{"code": "def wait_while_present(depr_timeout = nil, timeout: nil, interval: nil, message: nil)\n      timeout = depr_timeout if depr_timeout\n      Watir.logger.deprecate \"#{self.class}#wait_while_present\",\n                             \"#{self.class}#wait_while(&:present?)\",\n                             ids: [:wait_while_present]\n\n      message ||= proc { |obj| \"waiting for #{obj.inspect} not to be present\" }\n      wait_while(timeout: timeout, interval: interval, message: message, element_reset: true, &:present?)\n    end", "label": 4}
{"code": "function setAttrs(file, attrs) {\n  if (isLink(file)) return;\n  if (_.every([attrs.atime, attrs.mtime], _.identity)) {\n    fs.utimesSync(file, new Date(attrs.atime), new Date(attrs.mtime));\n  }\n  if (attrs.mode) {\n    chmod(file, attrs.mode);\n  }\n}", "label": 3}
{"code": "def set_launch_target(build_target)\n      launch_runnable = BuildableProductRunnable.new(build_target, 0)\n      launch_action.buildable_product_runnable = launch_runnable\n\n      profile_runnable = BuildableProductRunnable.new(build_target)\n      profile_action.buildable_product_runnable = profile_runnable\n\n      macro_exp = MacroExpansion.new(build_target)\n      test_action.add_macro_expansion(macro_exp)\n    end", "label": 4}
{"code": "def address(self):\n\t\t\"The address in big-endian\"\n\t\t_ = struct.pack('L', self.address_num)\n\t\treturn struct.unpack('!L', _)[0]", "label": 1}
{"code": "func NewCIMDString(typ Type, version uint32, data string) string {\n\treturn fmt.Sprintf(\"%s:%s:v=%d:%s\", Scheme, typ, version, data)\n}", "label": 5}
{"code": "func (s Style) Bold(on bool) Style {\n\treturn s.setAttrs(Style(AttrBold), on)\n}", "label": 5}
{"code": "def files_to_lint(task_args)\n      # Note: we're abusing Rake's argument handling a bit here. We call the\n      # first argument `files` but it's actually only the first file--we pull\n      # the rest out of the `extras` from the task arguments. This is so we\n      # can specify an arbitrary list of files separated by commas on the\n      # command line or in a custom task definition.\n      explicit_files = Array(task_args[:files]) + Array(task_args.extras)\n\n      explicit_files.any? ? explicit_files : files\n    end", "label": 4}
{"code": "func (s *PresenceService) GetTunnelConnection(clusterName, connectionName string, opts ...services.MarshalOption) (services.TunnelConnection, error) {\n\titem, err := s.Get(context.TODO(), backend.Key(tunnelConnectionsPrefix, clusterName, connectionName))\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn nil, trace.NotFound(\"trusted cluster connection %q is not found\", connectionName)\n\t\t}\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tconn, err := services.UnmarshalTunnelConnection(item.Value,\n\t\tservices.AddOptions(opts, services.WithResourceID(item.ID), services.WithExpires(item.Expires))...)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn conn, nil\n}", "label": 5}
{"code": "public function setRating($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\Rating::class);\n        $this->rating = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response reset(nitro_service client) throws Exception {\n\t\tappfwlearningdata resetresource = new appfwlearningdata();\n\t\treturn resetresource.perform_operation(client,\"reset\");\n\t}", "label": 0}
{"code": "def _swaplch(LCH):\n    \"Reverse the order of an LCH numpy dstack or tuple for analysis.\"\n    try: # Numpy array\n        L,C,H = np.dsplit(LCH,3)\n        return np.dstack((H,C,L))\n    except: # Tuple\n        L,C,H = LCH\n        return H,C,L", "label": 1}
{"code": "def write_json_double(num)\n      @context.write(trans)\n      # Normalize output of thrift::to_string for NaNs and Infinities\n      special = false;\n      if (num.nan?)\n        special = true;\n        val = @@kThriftNan;\n      elsif (num.infinite?)\n        special = true;\n        val = @@kThriftInfinity;\n        if (num < 0.0)\n          val = @@kThriftNegativeInfinity;\n        end\n      else\n        val = num.to_s\n      end\n\n      escapeNum = special || @context.escapeNum\n      if (escapeNum)\n        trans.write(@@kJSONStringDelimiter)\n      end\n      trans.write(val)\n      if (escapeNum)\n        trans.write(@@kJSONStringDelimiter)\n      end\n    end", "label": 4}
{"code": "public function setTemplate($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\WorkflowTemplate::class);\n        $this->template = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func buildAci(root, manifestPath, target string, uidRange *user.UidRange) (e error) {\n\tmode := os.O_CREATE | os.O_WRONLY\n\tif flagOverwriteACI {\n\t\tmode |= os.O_TRUNC\n\t} else {\n\t\tmode |= os.O_EXCL\n\t}\n\taciFile, err := os.OpenFile(target, mode, 0644)\n\tif err != nil {\n\t\tif os.IsExist(err) {\n\t\t\treturn errors.New(\"target file exists (try --overwrite)\")\n\t\t} else {\n\t\t\treturn errwrap.Wrap(fmt.Errorf(\"unable to open target %s\", target), err)\n\t\t}\n\t}\n\n\tgw := gzip.NewWriter(aciFile)\n\ttr := tar.NewWriter(gw)\n\n\tdefer func() {\n\t\ttr.Close()\n\t\tgw.Close()\n\t\taciFile.Close()\n\t\t// e is implicitly assigned by the return statement. As defer runs\n\t\t// after return, but before actually returning, this works.\n\t\tif e != nil {\n\t\t\tos.Remove(target)\n\t\t}\n\t}()\n\n\tb, err := ioutil.ReadFile(manifestPath)\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"unable to read Image Manifest\"), err)\n\t}\n\tvar im schema.ImageManifest\n\tif err := im.UnmarshalJSON(b); err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"unable to load Image Manifest\"), err)\n\t}\n\tiw := aci.NewImageWriter(im, tr)\n\n\t// Unshift uid and gid when pod was started with --private-user (user namespace)\n\tvar walkerCb aci.TarHeaderWalkFunc = func(hdr *tar.Header) bool {\n\t\tif uidRange != nil {\n\t\t\tuid, gid, err := uidRange.UnshiftRange(uint32(hdr.Uid), uint32(hdr.Gid))\n\t\t\tif err != nil {\n\t\t\t\tstderr.PrintE(\"error unshifting gid and uid\", err)\n\t\t\t\treturn false\n\t\t\t}\n\t\t\thdr.Uid, hdr.Gid = int(uid), int(gid)\n\t\t}\n\t\treturn true\n\t}\n\n\tif err := filepath.Walk(root, aci.BuildWalker(root, iw, walkerCb)); err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"error walking rootfs\"), err)\n\t}\n\n\tif err = iw.Close(); err != nil {\n\t\treturn errwrap.Wrap(fmt.Errorf(\"unable to close image %s\", target), err)\n\t}\n\n\treturn\n}", "label": 5}
{"code": "public Iterator getReportQueryIteratorByQuery(Query query) throws PersistenceBrokerException\n    {\n        ClassDescriptor cld = getClassDescriptor(query.getSearchClass());\n        return getReportQueryIteratorFromQuery(query, cld);\n    }", "label": 0}
{"code": "public String getScopes() {\n        final StringBuilder sb = new StringBuilder();\n        for (final Scope scope : Scope.values()) {\n            sb.append(scope);\n            sb.append(\", \");\n        }\n        final String scopes = sb.toString().trim();\n        return scopes.substring(0, scopes.length() - 1);\n    }", "label": 0}
{"code": "def get(*args)\n      params = arguments(args).params\n\n      if user_name = params.delete('user')\n        get_request(\"/users/#{user_name}\", params)\n      else\n        get_request(\"/user\", params)\n      end\n    end", "label": 4}
{"code": "public static ntpserver[] get(nitro_service service) throws Exception{\n\t\tntpserver obj = new ntpserver();\n\t\tntpserver[] response = (ntpserver[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function subscriberByRequest(array $input, array $headers): ?Subscriber\n    {\n        $channel = Arr::get($input, 'channel_name');\n\n        return $channel\n            ? $this->subscriberByChannel($channel)\n            : null;\n    }", "label": 2}
{"code": "func exportedType(typ types.Type) bool {\n\tswitch T := typ.(type) {\n\tcase *types.Named:\n\t\t// Builtin types have no package.\n\t\treturn T.Obj().Pkg() == nil || T.Obj().Exported()\n\tcase *types.Map:\n\t\treturn exportedType(T.Key()) && exportedType(T.Elem())\n\tcase interface {\n\t\tElem() types.Type\n\t}: // array, slice, pointer, chan\n\t\treturn exportedType(T.Elem())\n\t}\n\t// Be conservative about other types, such as struct, interface, etc.\n\treturn true\n}", "label": 5}
{"code": "public void setProxyClass(Class newProxyClass)\r\n    {\r\n        proxyClass = newProxyClass;\r\n        if (proxyClass == null)\r\n        {\r\n            setProxyClassName(null);\r\n        }\r\n        else\r\n        {\r\n            proxyClassName = proxyClass.getName();\r\n        }\r\n    }", "label": 0}
{"code": "protected function connection_start($args)\n    {\n        $this->version_major = $args->read_octet();\n        $this->version_minor = $args->read_octet();\n        $this->server_properties = $args->read_table();\n        $this->mechanisms = explode(' ', $args->read_longstr());\n        $this->locales = explode(' ', $args->read_longstr());\n\n        $this->debug->debug_connection_start(\n            $this->version_major,\n            $this->version_minor,\n            $this->server_properties,\n            $this->mechanisms,\n            $this->locales\n        );\n    }", "label": 2}
{"code": "public function productSearch($image, ProductSearchParams $productSearchParams, $optionalArgs = [])\n    {\n        if (isset($optionalArgs['imageContext']) && $optionalArgs['imageContext'] instanceof ImageContext) {\n            $optionalArgs['imageContext']->setProductSearchParams($productSearchParams);\n        } else {\n            $optionalArgs['imageContext'] = (new ImageContext)\n                ->setProductSearchParams($productSearchParams);\n        }\n\n        return $this->annotateSingleFeature(\n            $image,\n            Type::PRODUCT_SEARCH,\n            $optionalArgs\n        );\n    }", "label": 2}
{"code": "function(value, fn) {\n        if(value.constructor === Function ) {\n            this.default_handler = value;\n        } else if(value.constructor === Number) {\n            this.on_args[value] = fn;\n        } else {\n            this.on_switches[value] = fn;\n        }\n    }", "label": 3}
{"code": "@Override\n    public Object[] getAgentPlans(String agent_name, Connector connector) {\n        // Not supported in JADE\n        connector.getLogger().warning(\"Non suported method for Jade Platform. There is no plans in Jade platform.\");\n        throw new java.lang.UnsupportedOperationException(\"Non suported method for Jade Platform. There is no extra properties.\");\n    }", "label": 0}
{"code": "func (f *Fpdf) loadfont(r io.Reader) (def fontDefType) {\n\tif f.err != nil {\n\t\treturn\n\t}\n\t// dbg(\"Loading font [%s]\", fontStr)\n\tvar buf bytes.Buffer\n\t_, err := buf.ReadFrom(r)\n\tif err != nil {\n\t\tf.err = err\n\t\treturn\n\t}\n\terr = json.Unmarshal(buf.Bytes(), &def)\n\tif err != nil {\n\t\tf.err = err\n\t\treturn\n\t}\n\n\tif def.i, err = generateFontID(def); err != nil {\n\t\tf.err = err\n\t}\n\t// dump(def)\n\treturn\n}", "label": 5}
{"code": "function updateForms(params, validDataSources, invalidDataSources, cb) {\n  //Only interested In Data Sources Where Data Was Actually Updated. If the data set is still the same, then no need to mark the form as updated the form.\n  var dataSoucesUpdated = _.filter(validDataSources, function(dataSourceData) {\n    return dataSourceData.dataChanged === true;\n  });\n\n  //Updating Any Forms That Reference Updated Data Sources\n  var updatedDataSourceIds = _.map(dataSoucesUpdated, function(validDataSourceData) {\n    return validDataSourceData._id;\n  });\n\n  //Need to find and update any forms associated with the data sources.\n  var Form = models.get(params.connections.mongooseConnection, models.MODELNAMES.FORM);\n\n  //Flagging Any Forms That Are Using The Updated Data Sources As Being Updated. This is useful for client/cloud apps that need to determine if they need to load the entire form again.\n  Form.update({\n    \"dataSources.formDataSources\": {\"$in\": updatedDataSourceIds}\n  }, {\n    \"$set\": {\n      \"dataSources.lastRefresh\": params.currentTime\n    }\n  }, { multi: true }, function(err) {\n    if (err) {\n      return cb(buildErrorResponse({\n        error: new Error(\"Error Updating Forms Refresh Fields\"),\n        code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n      }));\n    }\n\n    //No error, forms updated, moving on\n    cb(undefined, validDataSources, invalidDataSources);\n  });\n}", "label": 3}
{"code": "function listFiles() {\n\tgapi.client.drive.files.list({\n\t\t'pageSize': 10,\n\t\t'fields': \"nextPageToken, files(id, name)\"\n\t}).then(function(response) {\n\t\tappendPre('Files:');\n\t\tvar files = response.result.files;\n\t\tif (files && files.length > 0) {\n\t\t\tfor (var i = 0; i < files.length; i++) {\n\t\t\t\tvar file = files[i];\n\t\t\t\tappendPre(file.name + ' (' + file.id + ')');\n\t\t\t}\n\t\t} else {\n\t\t\tappendPre('No files found.');\n\t\t}\n\t});\n}", "label": 3}
{"code": "public function resolveTransformer()\n    {\n        if (is_string($this->resolver)) {\n            return $this->container->make($this->resolver);\n        } elseif (is_callable($this->resolver)) {\n            return call_user_func($this->resolver, $this->container);\n        } elseif (is_object($this->resolver)) {\n            return $this->resolver;\n        }\n\n        throw new RuntimeException('Unable to resolve transformer binding.');\n    }", "label": 2}
{"code": "def update_variation(location_id, item_id, variation_id, body, opts = {})\n      data, _status_code, _headers = update_variation_with_http_info(location_id, item_id, variation_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "def text_fields(field_name)\n      if text_fields = text_fields_hash[field_name.to_sym]\n        text_fields.to_a\n      else\n        raise(\n          UnrecognizedFieldError,\n          \"No text field configured for #{@types * ', '} with name '#{field_name}'\"\n        )\n      end\n    end", "label": 4}
{"code": "function getObjectByKey(data, prop) {\n    if (!prop || !~prop.indexOf('.')) return data[prop];\n\n    var result = prop\n      , structure = data;\n\n    for (var paths = prop.split('.'), i = 0, length = paths.length; i < length; i++) {\n      result = structure[+paths[i] || paths[i]];\n      structure = result;\n    }\n\n    return result || data[prop];\n  }", "label": 3}
{"code": "func RawCombinedOutputNative(args ...string) error {\n\tif output, err := raw(args...); err != nil || len(output) != 0 {\n\t\treturn fmt.Errorf(\"%s (%v)\", string(output), err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func AuthUsersByUsername(db XODB, username string) ([]*AuthUser, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, password, last_login, is_superuser, username, first_name, last_name, email, is_staff, is_active, date_joined ` +\n\t\t`FROM public.auth_user ` +\n\t\t`WHERE username = $1`\n\n\t// run query\n\tXOLog(sqlstr, username)\n\tq, err := db.Query(sqlstr, username)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*AuthUser{}\n\tfor q.Next() {\n\t\tau := AuthUser{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&au.ID, &au.Password, &au.LastLogin, &au.IsSuperuser, &au.Username, &au.FirstName, &au.LastName, &au.Email, &au.IsStaff, &au.IsActive, &au.DateJoined)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &au)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public static void validate(final Organization organization) {\n        if(organization.getName() == null ||\n                organization.getName().isEmpty()){\n            throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                    .entity(\"Organization name cannot be null or empty!\")\n                    .build());\n        }\n    }", "label": 0}
{"code": "public function sendGroupsChatCreate($subject, $participants)\n    {\n        if (!is_array($participants)) {\n            $participants = [$participants];\n        }\n\n        $participantNode = [];\n        foreach ($participants as $participant) {\n            $participantNode[] = new ProtocolNode('participant', [\n                'jid' => $this->getJID($participant),\n            ], null, null);\n        }\n\n        $id = $this->nodeId['groupcreate'] = $this->createIqId();\n\n        $createNode = new ProtocolNode('create',\n            [\n                'subject' => $subject,\n            ], $participantNode, null);\n\n        $iqNode = new ProtocolNode('iq',\n            [\n                'xmlns' => 'w:g2',\n                'id'    => $id,\n                'type'  => 'set',\n                'to'    => Constants::WHATSAPP_GROUP_SERVER,\n            ], [$createNode], null);\n\n        $this->sendNode($iqNode);\n        $this->waitForServer($id);\n        $groupId = $this->groupId;\n\n        $this->eventManager()->fire('onGroupCreate',\n            [\n                $this->phoneNumber,\n                $groupId,\n            ]);\n\n        return $groupId;\n    }", "label": 2}
{"code": "public function startJob(JobConfigurationInterface $config, array $options = [])\n    {\n        $response = null;\n        $config = $config->toArray() + $options;\n\n        if (isset($config['data'])) {\n            $response = $this->connection->insertJobUpload($config)->upload();\n        } else {\n            $response = $this->connection->insertJob($config);\n        }\n\n        return new Job(\n            $this->connection,\n            $config['jobReference']['jobId'],\n            $this->identity['projectId'],\n            $this->mapper,\n            $response\n        );\n    }", "label": 2}
{"code": "def _fix_value(self, value):\n        \"\"\"Attempt to coerce value into the correct type.\n\n        Subclasses can override this function.\n        \"\"\"\n        try:\n            return self._castfunc(value)\n        except:\n            error = \"Can't put '{0}' ({1}) into a {2}. Expected a {3} object.\"\n            error = error.format(\n                value,                  # Input value\n                type(value),            # Type of input value\n                type(self),             # Type of collection\n                self._type              # Expected type of input value\n            )\n            six.reraise(TypeError, TypeError(error), sys.exc_info()[-1])", "label": 1}
{"code": "public function setConfidenceMetricsEntry($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\AutoMl\\V1beta1\\ClassificationEvaluationMetrics\\ConfidenceMetricsEntry::class);\n        $this->confidence_metrics_entry = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (fs *FlagSet) IsSet(name string) bool {\n\treturn fs.actual[name] != nil\n}", "label": 5}
{"code": "def colorized?\n      scan_for_colors.inject([]) do |colors, match|\n        colors << match.tap(&:pop)\n      end.flatten.compact.any?\n    end", "label": 4}
{"code": "def _process_options(options)\n        super\n        if options[:stream]\n          if request.version == \"HTTP/1.0\"\n            options.delete(:stream)\n          else\n            headers[\"Cache-Control\"] ||= \"no-cache\"\n            headers[\"Transfer-Encoding\"] = \"chunked\"\n            headers.delete(\"Content-Length\")\n          end\n        end\n      end", "label": 4}
{"code": "func MustAbs(dir string) string {\n\tabsDir, err := filepath.Abs(dir)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Failed to get absolute path of a directory %q: %v\\n\", dir, err))\n\t}\n\treturn filepath.Clean(absDir)\n}", "label": 5}
{"code": "public function addMediaFromUrl(string $url, ...$allowedMimeTypes)\n    {\n        if (! $stream = @fopen($url, 'r')) {\n            throw UnreachableUrl::create($url);\n        }\n\n        $temporaryFile = tempnam(sys_get_temp_dir(), 'media-library');\n        file_put_contents($temporaryFile, $stream);\n\n        $this->guardAgainstInvalidMimeType($temporaryFile, $allowedMimeTypes);\n\n        $filename = basename(parse_url($url, PHP_URL_PATH));\n        $filename = str_replace('%20', ' ', $filename);\n\n        if ($filename === '') {\n            $filename = 'file';\n        }\n\n        $mediaExtension = explode('/', mime_content_type($temporaryFile));\n\n        if (! str_contains($filename, '.')) {\n            $filename = \"{$filename}.{$mediaExtension[1]}\";\n        }\n\n        return app(FileAdderFactory::class)\n            ->create($this, $temporaryFile)\n            ->usingName(pathinfo($filename, PATHINFO_FILENAME))\n            ->usingFileName($filename);\n    }", "label": 2}
{"code": "public void localBegin()\r\n    {\r\n        if (this.isInLocalTransaction)\r\n        {\r\n            throw new TransactionInProgressException(\"Connection is already in transaction\");\r\n        }\r\n        Connection connection = null;\r\n        try\r\n        {\r\n            connection = this.getConnection();\r\n        }\r\n        catch (LookupException e)\r\n        {\r\n            /**\r\n             * must throw to notify user that we couldn't start a connection\r\n             */\r\n            throw new PersistenceBrokerException(\"Can't lookup a connection\", e);\r\n        }\r\n        if (log.isDebugEnabled()) log.debug(\"localBegin was called for con \" + connection);\r\n        // change autoCommit state only if we are not in a managed environment\r\n        // and it is enabled by user\r\n        if(!broker.isManaged())\r\n        {\r\n            if (jcd.getUseAutoCommit() == JdbcConnectionDescriptor.AUTO_COMMIT_SET_TRUE_AND_TEMPORARY_FALSE)\r\n            {\r\n                if (log.isDebugEnabled()) log.debug(\"Try to change autoCommit state to 'false'\");\r\n                platform.changeAutoCommitState(jcd, connection, false);\r\n            }\r\n        }\r\n        else\r\n        {\r\n            if(log.isDebugEnabled()) log.debug(\r\n                        \"Found managed environment setting in PB, will skip Platform.changeAutoCommitState(...) call\");\r\n        }\r\n        this.isInLocalTransaction = true;\r\n    }", "label": 0}
{"code": "function compare(var1, var2, operator) {\n    switch (operator) {\n        case Workflo.Comparator.equalTo || Workflo.Comparator.eq:\n            return var1 === var2;\n        case Workflo.Comparator.notEqualTo || Workflo.Comparator.ne:\n            return var1 !== var2;\n        case Workflo.Comparator.greaterThan || Workflo.Comparator.gt:\n            return var1 > var2;\n        case Workflo.Comparator.lessThan || Workflo.Comparator.lt:\n            return var1 < var2;\n    }\n}", "label": 3}
{"code": "def main():\n    \"\"\"\n    Example to show AIKIF logging of results.\n    Generates a sequence of random grids and runs the\n    Game of Life, saving results\n    \"\"\"\n    iterations  = 9     # how many simulations to run\n    years       = 3    # how many times to run each simulation\n    width       = 22     # grid height\n    height      = 78     # grid width\n    time_delay  = 0.03   # delay when printing on screen\n    lg = mod_log.Log('test')\n    lg.record_process('Game of Life', 'game_of_life_console.py')\n    for _ in range(iterations):\n        s,e = run_game_of_life(years, width, height, time_delay, 'N') \n        lg.record_result(\"Started with \" +  str(s) + \" cells and ended with \" + str(e) + \" cells\")", "label": 1}
{"code": "function ClearFloats($clear, $blklvl = 0)\n\t{\n\t\tlist($l_exists, $r_exists, $l_max, $r_max, $l_width, $r_width) = $this->GetFloatDivInfo($blklvl, true);\n\t\t$end = $currpos = ($this->page * 1000 + $this->y);\n\t\tif ($clear == 'BOTH' && ($l_exists || $r_exists)) {\n\t\t\t$this->pageoutput[$this->page] = [];\n\t\t\t$end = max($l_max, $r_max, $currpos);\n\t\t} elseif ($clear == 'RIGHT' && $r_exists) {\n\t\t\t$this->pageoutput[$this->page] = [];\n\t\t\t$end = max($r_max, $currpos);\n\t\t} elseif ($clear == 'LEFT' && $l_exists) {\n\t\t\t$this->pageoutput[$this->page] = [];\n\t\t\t$end = max($l_max, $currpos);\n\t\t} else {\n\t\t\treturn;\n\t\t}\n\t\t$old_page = $this->page;\n\t\t$new_page = intval($end / 1000);\n\t\tif ($old_page != $new_page) {\n\t\t\t$s = $this->PrintPageBackgrounds();\n\t\t\t// Writes after the marker so not overwritten later by page background etc.\n\t\t\t$this->pages[$this->page] = preg_replace('/(___BACKGROUND___PATTERNS' . $this->uniqstr . ')/', '\\\\1' . \"\\n\" . $s . \"\\n\", $this->pages[$this->page]);\n\t\t\t$this->pageBackgrounds = [];\n\t\t\t$this->page = $new_page;\n\t\t}\n\t\t$this->ResetMargins();\n\t\t$this->pageoutput[$this->page] = [];\n\t\t$this->y = (($end * 1000) % 1000000) / 1000; // mod changes operands to integers before processing\n\t}", "label": 2}
{"code": "def format_item(item, template, name='item'):\n    \"\"\"Render a template to a string with the provided item in context.\"\"\"\n    ctx = {name: item}\n    return render_template_to_string(template, **ctx)", "label": 1}
{"code": "def _get_default_language(self):\n        \"\"\"\n        If a default language has been set, and is still available in\n        `self.available_languages`, return it and remove it from the list.\n\n        If not, simply pop the first available language.\n        \"\"\"\n\n        assert hasattr(self, 'available_languages'), \\\n            'No available languages have been generated.'\n        assert len(self.available_languages) > 0, \\\n            'No available languages to select from.'\n\n        if (\n            settings.DEFAULT_LANGUAGE and\n            settings.DEFAULT_LANGUAGE in self.available_languages\n        ) or (\n            'language_code' not in self.form.base_fields\n        ):\n            # Default language still available\n\n            self.available_languages.remove(settings.DEFAULT_LANGUAGE)\n            return settings.DEFAULT_LANGUAGE\n\n        else:\n            # Select the first item and return it\n            return self.available_languages.pop(0)", "label": 1}
{"code": "protected Query buildMtoNImplementorQuery(Collection ids)\r\n    {\r\n        String[] indFkCols = getFksToThisClass();\r\n        String[] indItemFkCols = getFksToItemClass();\r\n        FieldDescriptor[] pkFields = getOwnerClassDescriptor().getPkFields();\r\n        FieldDescriptor[] itemPkFields = getItemClassDescriptor().getPkFields();\r\n        String[] cols = new String[indFkCols.length + indItemFkCols.length];\r\n        int[] jdbcTypes = new int[indFkCols.length + indItemFkCols.length];\r\n\r\n        // concatenate the columns[]\r\n        System.arraycopy(indFkCols, 0, cols, 0, indFkCols.length);\r\n        System.arraycopy(indItemFkCols, 0, cols, indFkCols.length, indItemFkCols.length);\r\n\r\n        Criteria crit = buildPrefetchCriteria(ids, indFkCols, indItemFkCols, itemPkFields);\r\n\r\n        // determine the jdbcTypes of the pks\r\n        for (int i = 0; i < pkFields.length; i++)\r\n        {\r\n            jdbcTypes[i] = pkFields[i].getJdbcType().getType();\r\n        }\r\n        for (int i = 0; i < itemPkFields.length; i++)\r\n        {\r\n            jdbcTypes[pkFields.length + i] = itemPkFields[i].getJdbcType().getType();\r\n        }\r\n\r\n        ReportQueryByMtoNCriteria q = new ReportQueryByMtoNCriteria(getItemClassDescriptor().getClassOfObject(), cols,\r\n                crit, false);\r\n        q.setIndirectionTable(getCollectionDescriptor().getIndirectionTable());\r\n        q.setJdbcTypes(jdbcTypes);\r\n\r\n        CollectionDescriptor cds = getCollectionDescriptor();\r\n        //check if collection must be ordered\r\n        if (!cds.getOrderBy().isEmpty())\r\n        {\r\n            Iterator iter = cds.getOrderBy().iterator();\r\n            while (iter.hasNext())\r\n            {\r\n                q.addOrderBy((FieldHelper) iter.next());\r\n            }\r\n        }\r\n        \r\n        return q;\r\n    }", "label": 0}
{"code": "def join(details)\n      joinchar = self.joiner\n\n      fields.collect { |field|\n        # If the field is marked absent, use the appropriate replacement\n        if details[field] == :absent or details[field] == [:absent] or details[field].nil?\n          if self.optional.include?(field)\n            self.absent\n          else\n            raise ArgumentError, _(\"Field '%{field}' is required\") % { field: field }\n          end\n        else\n          details[field].to_s\n        end\n      }.reject { |c| c.nil?}.join(joinchar)\n    end", "label": 4}
{"code": "def greedy_merge(\n        variant_sequences,\n        min_overlap_size=MIN_VARIANT_SEQUENCE_ASSEMBLY_OVERLAP_SIZE):\n    \"\"\"\n    Greedily merge overlapping sequences into longer sequences.\n\n    Accepts a collection of VariantSequence objects and returns another\n    collection of elongated variant sequences. The reads field of the\n    returned VariantSequence object will contain reads which\n    only partially overlap the full sequence.\n    \"\"\"\n    merged_any = True\n    while merged_any:\n        variant_sequences, merged_any = greedy_merge_helper(\n            variant_sequences,\n            min_overlap_size=min_overlap_size)\n    return variant_sequences", "label": 1}
{"code": "def run_game_of_life(years, width, height, time_delay, silent=\"N\"):\n    \"\"\"\n    run a single game of life for 'years' and log start and \n    end living cells to aikif\n    \"\"\"\n    lfe = mod_grid.GameOfLife(width, height, ['.', 'x'], 1)\n    set_random_starting_grid(lfe)\n    lg.record_source(lfe, 'game_of_life_console.py')\n    print(lfe)\n    start_cells = lfe.count_filled_positions()\n    for ndx, dummy_idx in enumerate(range(years)):\n        lfe.update_gol()\n        if silent == \"N\":\n            print_there(1,1, \"Game of Life - Iteration # \" + str(ndx))\n            print_there(1, 2, lfe)\n            time.sleep(time_delay)\n    end_cells = lfe.count_filled_positions()\n    return start_cells, end_cells", "label": 1}
{"code": "func NewOVAFile(filename string) (*OVAFile, error) {\n\tf, err := os.Open(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttarFile := tar.NewReader(f)\n\treturn &OVAFile{filename: filename, file: f, tarFile: tarFile}, nil\n}", "label": 5}
{"code": "def check_for_infinite_loop(processed_source, offenses)\n      checksum = processed_source.checksum\n\n      if @processed_sources.include?(checksum)\n        raise InfiniteCorrectionLoop.new(processed_source.path, offenses)\n      end\n\n      @processed_sources << checksum\n    end", "label": 4}
{"code": "def read_auth_info(agent_file_content):\n    '''Loads agent authentication information from the\n    specified content string, as read from an agents file.\n    The returned information is suitable for passing as an argument\n    to the AgentInteractor constructor.\n    @param agent_file_content The agent file content (str)\n    @return AuthInfo The authentication information\n    @raises AgentFileFormatError when the file format is bad.\n    '''\n    try:\n        data = json.loads(agent_file_content)\n        return AuthInfo(\n            key=bakery.PrivateKey.deserialize(data['key']['private']),\n            agents=list(\n                Agent(url=a['url'], username=a['username'])\n                for a in data.get('agents', [])\n            ),\n        )\n    except (\n        KeyError,\n        ValueError,\n        TypeError,\n    ) as e:\n        raise AgentFileFormatError('invalid agent file', e)", "label": 1}
{"code": "public function setExclusionType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dlp\\V2\\CustomInfoType_ExclusionType::class);\n        $this->exclusion_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def cache_key\n      if new_record?\n        \"#{model_name.cache_key}/new\"\n      else\n        if cache_version\n          \"#{model_name.cache_key}/#{id}\"\n        else\n          timestamp = max_updated_column_timestamp\n\n          if timestamp\n            timestamp = timestamp.utc.to_s(cache_timestamp_format)\n            \"#{model_name.cache_key}/#{id}-#{timestamp}\"\n          else\n            \"#{model_name.cache_key}/#{id}\"\n          end\n        end\n      end\n    end", "label": 4}
{"code": "def register(self, settings_class=NoSwitcher, *simple_checks,\n                 **conditions):\n        \"\"\"\n        Register a settings class with the switcher. Can be passed the settings\n        class to register or be used as a decorator.\n\n        :param settings_class: The class to register with the provided\n                conditions.\n        :param *simple_checks: A list of conditions for using the settings\n                class. If any of the values are falsy, the class will not be\n                used. If any of the values are callable, they will be called\n                before evaluating.\n        :param **conditions: Values to check. The key specifies which of the\n                check functions (registered with ``add_check``) to use; the\n                value is passed to the check function.\n        \"\"\"\n        if settings_class is NoSwitcher:\n            def decorator(cls):\n                self.register(cls, *simple_checks, **conditions)\n                return cls\n            return decorator\n\n        available_checks = self.checks.keys()\n        for condition in conditions.keys():\n            if condition not in available_checks:\n                raise InvalidCondition(\n                    'There is no check for the condition \"%s\"' % condition)\n\n        self._registry.append((settings_class, simple_checks, conditions))", "label": 1}
{"code": "function refreshSourceRow (target, source) {\n        var row = upToSourceRow(target),\n            newRow = rowFactory(source, source.getIndex());\n        sourceRows.replaceChild(newRow, row);\n        updateSourceRow(source);\n    }", "label": 3}
{"code": "func OptionIngress() SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.ingress = true\n\t\tsb.oslTypes = append(sb.oslTypes, osl.SandboxTypeIngress)\n\t}\n}", "label": 5}
{"code": "protected function encrypt($unencryptedData)\n    {\n        try {\n            if ($this->encryptionKey instanceof Key) {\n                return Crypto::encrypt($unencryptedData, $this->encryptionKey);\n            }\n\n            return Crypto::encryptWithPassword($unencryptedData, $this->encryptionKey);\n        } catch (Exception $e) {\n            throw new LogicException($e->getMessage(), null, $e);\n        }\n    }", "label": 2}
{"code": "public static base_responses create(nitro_service client, sslfipskey resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslfipskey createresources[] = new sslfipskey[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tcreateresources[i] = new sslfipskey();\n\t\t\t\tcreateresources[i].fipskeyname = resources[i].fipskeyname;\n\t\t\t\tcreateresources[i].modulus = resources[i].modulus;\n\t\t\t\tcreateresources[i].exponent = resources[i].exponent;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, createresources,\"create\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def unlocked_release(id)\n      lock_file = @machine_locks[id]\n      if lock_file\n        lock_file.close\n        begin\n          File.delete(lock_file.path)\n        rescue Errno::EACCES\n          # Another process is probably opened it, no problem.\n        end\n\n        @machine_locks.delete(id)\n      end\n    end", "label": 4}
{"code": "func newClient(scope string, kv string, addr string, config *store.Config, cached bool) (DataStore, error) {\n\n\tif cached && scope != LocalScope {\n\t\treturn nil, fmt.Errorf(\"caching supported only for scope %s\", LocalScope)\n\t}\n\tsequential := false\n\tif scope == LocalScope {\n\t\tsequential = true\n\t}\n\n\tif config == nil {\n\t\tconfig = &store.Config{}\n\t}\n\n\tvar addrs []string\n\n\tif kv == string(store.BOLTDB) {\n\t\t// Parse file path\n\t\taddrs = strings.Split(addr, \",\")\n\t} else {\n\t\t// Parse URI\n\t\tparts := strings.SplitN(addr, \"/\", 2)\n\t\taddrs = strings.Split(parts[0], \",\")\n\n\t\t// Add the custom prefix to the root chain\n\t\tif len(parts) == 2 {\n\t\t\trootChain = append([]string{parts[1]}, defaultRootChain...)\n\t\t}\n\t}\n\n\tstore, err := libkv.NewStore(store.Backend(kv), addrs, config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tds := &datastore{scope: scope, store: store, active: true, watchCh: make(chan struct{}), sequential: sequential}\n\tif cached {\n\t\tds.cache = newCache(ds)\n\t}\n\n\treturn ds, nil\n}", "label": 5}
{"code": "function (node, selText, cssText) {\n    if(!cssText) return\n    // get parent to add\n    var parent = getParent(node);\n    var parentRule = node.parentRule;\n    if (validParent(node))\n      return node.omRule = addCSSRule(parent, selText, cssText, node)\n    else if (parentRule) {\n      // for old IE not support @media, check mediaEnabled, add child nodes\n      if (parentRule.mediaEnabled) {\n        [].concat(node.omRule).forEach(removeOneRule);\n        return node.omRule = addCSSRule(parent, selText, cssText, node)\n      } else if (node.omRule) {\n        node.omRule.forEach(removeOneRule);\n        delete node.omRule;\n      }\n    }\n  }", "label": 3}
{"code": "func (v VirtualMachine) RevertToCurrentSnapshot(ctx context.Context, suppressPowerOn bool) (*Task, error) {\n\treq := types.RevertToCurrentSnapshot_Task{\n\t\tThis:            v.Reference(),\n\t\tSuppressPowerOn: types.NewBool(suppressPowerOn),\n\t}\n\n\tres, err := methods.RevertToCurrentSnapshot_Task(ctx, v.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewTask(v.c, res.Returnval), nil\n}", "label": 5}
{"code": "function drawSelectionCursor(cm, range, output) {\n    var pos = cursorCoords(cm, range.head, \"div\", null, null, !cm.options.singleCursorHeightPerLine);\n\n    var cursor = output.appendChild(elt(\"div\", \"\\u00a0\", \"CodeMirror-cursor\"));\n    cursor.style.left = pos.left + \"px\";\n    cursor.style.top = pos.top + \"px\";\n    cursor.style.height = Math.max(0, pos.bottom - pos.top) * cm.options.cursorHeight + \"px\";\n\n    if (pos.other) {\n      // Secondary cursor, shown when on a 'jump' in bi-directional text\n      var otherCursor = output.appendChild(elt(\"div\", \"\\u00a0\", \"CodeMirror-cursor CodeMirror-secondarycursor\"));\n      otherCursor.style.display = \"\";\n      otherCursor.style.left = pos.other.left + \"px\";\n      otherCursor.style.top = pos.other.top + \"px\";\n      otherCursor.style.height = (pos.other.bottom - pos.other.top) * .85 + \"px\";\n    }\n  }", "label": 3}
{"code": "public function setWebhookState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_WebhookState::class);\n        $this->webhook_state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function isIso8601DateString(value) {\n    var regex = /^([+-]\\d{6}|\\d{4})(-(0[1-9]|1[0-2])(-(0[1-9]|[12]\\d|3[01]))?)?$/;\n\n    // Verify that it's in ISO 8601 format (via the regex) and that it represents a valid day (via Date.parse)\n    return regex.test(value) && !isNaN(Date.parse(value));\n  }", "label": 3}
{"code": "func (opts BeeOptions) Value(name string) interface{} {\n\tfor _, opt := range opts {\n\t\tif opt.Name == name {\n\t\t\treturn opt.Value\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func HTMLBasicTokenize(htmlStr string) (list []HTMLBasicSegmentType) {\n\t// This routine is adapted from http://www.fpdf.org/\n\tlist = make([]HTMLBasicSegmentType, 0, 16)\n\thtmlStr = strings.Replace(htmlStr, \"\\n\", \" \", -1)\n\thtmlStr = strings.Replace(htmlStr, \"\\r\", \"\", -1)\n\ttagRe, _ := regexp.Compile(`(?U)<.*>`)\n\tattrRe, _ := regexp.Compile(`([^=]+)=[\"']?([^\"']+)`)\n\tcapList := tagRe.FindAllStringIndex(htmlStr, -1)\n\tif capList != nil {\n\t\tvar seg HTMLBasicSegmentType\n\t\tvar parts []string\n\t\tpos := 0\n\t\tfor _, cap := range capList {\n\t\t\tif pos < cap[0] {\n\t\t\t\tseg.Cat = 'T'\n\t\t\t\tseg.Str = htmlStr[pos:cap[0]]\n\t\t\t\tseg.Attr = nil\n\t\t\t\tlist = append(list, seg)\n\t\t\t}\n\t\t\tif htmlStr[cap[0]+1] == '/' {\n\t\t\t\tseg.Cat = 'C'\n\t\t\t\tseg.Str = strings.ToLower(htmlStr[cap[0]+2 : cap[1]-1])\n\t\t\t\tseg.Attr = nil\n\t\t\t\tlist = append(list, seg)\n\t\t\t} else {\n\t\t\t\t// Extract attributes\n\t\t\t\tparts = strings.Split(htmlStr[cap[0]+1:cap[1]-1], \" \")\n\t\t\t\tif len(parts) > 0 {\n\t\t\t\t\tfor j, part := range parts {\n\t\t\t\t\t\tif j == 0 {\n\t\t\t\t\t\t\tseg.Cat = 'O'\n\t\t\t\t\t\t\tseg.Str = strings.ToLower(parts[0])\n\t\t\t\t\t\t\tseg.Attr = make(map[string]string)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tattrList := attrRe.FindAllStringSubmatch(part, -1)\n\t\t\t\t\t\t\tif attrList != nil {\n\t\t\t\t\t\t\t\tfor _, attr := range attrList {\n\t\t\t\t\t\t\t\t\tseg.Attr[strings.ToLower(attr[1])] = attr[2]\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tlist = append(list, seg)\n\t\t\t\t}\n\t\t\t}\n\t\t\tpos = cap[1]\n\t\t}\n\t\tif len(htmlStr) > pos {\n\t\t\tseg.Cat = 'T'\n\t\t\tseg.Str = htmlStr[pos:]\n\t\t\tseg.Attr = nil\n\t\t\tlist = append(list, seg)\n\t\t}\n\t} else {\n\t\tlist = append(list, HTMLBasicSegmentType{Cat: 'T', Str: htmlStr, Attr: nil})\n\t}\n\treturn\n}", "label": 5}
{"code": "public void addPropertyChangeListener (String propertyName, java.beans.PropertyChangeListener listener)\r\n    {\r\n        this.propertyChangeDelegate.addPropertyChangeListener(propertyName, listener);\r\n    }", "label": 0}
{"code": "func (c *controller) agentStopComplete() {\n\tc.Lock()\n\tif c.agentStopDone != nil {\n\t\tclose(c.agentStopDone)\n\t\tc.agentStopDone = nil\n\t}\n\tc.Unlock()\n}", "label": 5}
{"code": "public function cache_prune() {\n\t\t$cache = WP_CLI::get_cache();\n\n\t\tif ( ! $cache->is_enabled() ) {\n\t\t\tWP_CLI::error( 'Cache directory does not exist.' );\n\t\t}\n\n\t\t$cache->prune();\n\n\t\tWP_CLI::success( 'Cache pruned.' );\n\t}", "label": 2}
{"code": "function chainsFor(obj) {\n  var m = metaFor(obj), ret = m.chains;\n  if (!ret) {\n    ret = m.chains = new ChainNode(null, null, obj);\n  } else if (ret.value() !== obj) {\n    ret = m.chains = ret.copy(obj);\n  }\n  return ret;\n}", "label": 3}
{"code": "def get_metadata_as_csv(fname):\n    \"\"\" Gets all metadata and puts into CSV format \"\"\"\n    q = chr(34)\n    d = \",\"\n    res = q + fname + q + d\n    res = res + q + os.path.basename(fname) + q + d\n    res = res + q + os.path.dirname(fname) + q + d\n    try:\n        res = res + q + str(os.path.getsize(fname)) + q + d\n        img = Image.open(fname)\n        # get the image's width and height in pixels\n        width, height = img.size\n        res = res + q + str(width) + q + d\n        res = res + q + str(height) + q + d\n        res = res + q + str(img.format) + q + d\n        res = res + q + str(img.palette) + q + d\n        stat = ImageStat.Stat(img)\n        #print(fname, width, height) \n        #res = res + q + str(stat.extrema) + q + d\n        res = res + q + List2String(stat.count, \",\") + q + d\n        res = res + q + List2String(stat.sum, \",\") + q + d\n        res = res + q + List2String(stat.sum2, \",\") + q + d\n        res = res + q + List2String(stat.mean, \",\") + q + d\n        res = res + q + List2String(stat.median, \",\") + q + d\n        res = res + q + List2String(stat.rms, \",\") + q + d\n        res = res + q + List2String(stat.var, \",\") + q + d\n        res = res + q + List2String(stat.stddev, \",\") + q + d\n\n        exif_data = get_exif_data(img)\n        (lat, lon) = get_lat_lon(exif_data)\n        res = res + q + str(lat) + q + d\n        res = res + q + str(lon) + q + d\n    except Exception as ex:\n        print('problem reading image file metadata in ', fname, str(ex))\n    return res", "label": 1}
{"code": "function process(advertiserData) {\n  var altBeacon = {};\n  var data = advertiserData.manufacturerSpecificData.data;\n\n  altBeacon.id = data.substr(4,40);\n  altBeacon.refRSSI = pdu.convertTxPower(data.substr(44,2));\n  altBeacon.mfgReserved = data.substr(46,2);\n\n  advertiserData.manufacturerSpecificData.altBeacon = altBeacon;\n}", "label": 3}
{"code": "public function has_command( $_, $assoc_args ) {\n\n\t\t// If command is input as a string, then explode it into array.\n\t\t$command = explode( ' ', implode( ' ', $_ ) );\n\n\t\tWP_CLI::halt( is_array( WP_CLI::get_runner()->find_command_to_run( $command ) ) ? 0 : 1 );\n\t}", "label": 2}
{"code": "function encryptAndHash (state, ciphertext, plaintext) {\n  assert(state.byteLength === STATELEN)\n  assert(ciphertext.byteLength != null)\n  assert(plaintext.byteLength != null)\n\n  var cstate = state.subarray(CIPHER_BEGIN, CIPHER_END)\n  var h = state.subarray(HASH_BEGIN, HASH_END)\n\n  cipherState.encryptWithAd(cstate, ciphertext, h, plaintext)\n  encryptAndHash.bytesRead = cipherState.encryptWithAd.bytesRead\n  encryptAndHash.bytesWritten = cipherState.encryptWithAd.bytesWritten\n  mixHash(state, ciphertext.subarray(0, encryptAndHash.bytesWritten))\n}", "label": 3}
{"code": "private void increaseBeliefCount(String bName) {\n        Object belief = this.getBelief(bName);\n        int count = 0;\n        if (belief!=null) {\n            count = (Integer) belief;\n        }\n        this.setBelief(bName, count + 1);\n    }", "label": 0}
{"code": "function(value, attr, fn, model, computed, indices) {\n        return fn.call(this, value, attr, model, computed, indices);\n      }", "label": 3}
{"code": "func (f *file) lintUnexportedReturn() {\n\tf.walk(func(n ast.Node) bool {\n\t\tfn, ok := n.(*ast.FuncDecl)\n\t\tif !ok {\n\t\t\treturn true\n\t\t}\n\t\tif fn.Type.Results == nil {\n\t\t\treturn false\n\t\t}\n\t\tif !fn.Name.IsExported() {\n\t\t\treturn false\n\t\t}\n\t\tthing := \"func\"\n\t\tif fn.Recv != nil && len(fn.Recv.List) > 0 {\n\t\t\tthing = \"method\"\n\t\t\tif !ast.IsExported(receiverType(fn)) {\n\t\t\t\t// Don't report exported methods of unexported types,\n\t\t\t\t// such as private implementations of sort.Interface.\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tfor _, ret := range fn.Type.Results.List {\n\t\t\ttyp := f.pkg.typeOf(ret.Type)\n\t\t\tif exportedType(typ) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tf.errorf(ret.Type, 0.8, category(\"unexported-type-in-api\"),\n\t\t\t\t\"exported %s %s returns unexported type %s, which can be annoying to use\",\n\t\t\t\tthing, fn.Name.Name, typ)\n\t\t\tbreak // only flag one\n\t\t}\n\t\treturn false\n\t})\n}", "label": 5}
{"code": "function publishCachedMessages() {\n    if (_cachedPublishMessages.length > 0) {\n      async.each(_cachedPublishMessages, function(message, callback) {\n        debug('republish message', message);\n        self.publishTopic(message.exchange, message.topic, message.message, message.options, function(err) {\n          if (err) {\n            debug('Failed to republish message', message);\n          } else {\n            var idx = _cachedPublishMessages.indexOf(message);\n            _cachedPublishMessages.splice(idx, 1);\n            debug('cached publish message re-published, now there are ' + _cachedPublishMessages.length + ' messages left');\n          }\n          return callback();\n        });\n      }, function() {\n        debug('cached publish messages processed');\n      });\n    }\n  }", "label": 3}
{"code": "public function getDropDatabaseSQL()\n    {\n        $sm     = $this->em->getConnection()->getSchemaManager();\n        $schema = $sm->createSchema();\n\n        $visitor = new DropSchemaSqlCollector($this->platform);\n        $schema->visit($visitor);\n\n        return $visitor->getQueries();\n    }", "label": 2}
{"code": "def delete_data(self, url, *args, **kwargs):\n        \"\"\"Deletes data under provided url\n\n        Returns status as boolean.\n\n        Args:\n            **url**: address of file to be deleted\n\n            .. versionadded:: 0.3.2\n                **additional_headers**: (optional) Additional headers\n                to be used with request\n\n        Returns:\n            Boolean. True if request was successful. False if not.\n        \"\"\"\n        res = self._conn.delete(url, headers=self._prepare_headers(**kwargs))\n        if res.status_code == 200 or res.status_code == 202:\n            return True\n        else:\n            return False", "label": 1}
{"code": "public boolean checkWrite(TransactionImpl tx, Object obj)\r\n    {\r\n        LockEntry writer = getWriter(obj);\r\n        if (writer == null)\r\n            return false;\r\n        else if (writer.isOwnedBy(tx))\r\n            return true;\r\n        else\r\n            return false;\r\n    }", "label": 0}
{"code": "def lock(timeout = nil, &block)\n      Scripts.call(:lock, redis_pool,\n                   keys: [exists_key, grabbed_key, available_key, UNIQUE_SET, unique_digest],\n                   argv: [jid, ttl, lock_type])\n\n      grab_token(timeout) do |token|\n        touch_grabbed_token(token)\n        return_token_or_block_value(token, &block)\n      end\n    end", "label": 4}
{"code": "private static function extract_zip( $zipfile, $dest ) {\n\t\tif ( ! class_exists( 'ZipArchive' ) ) {\n\t\t\tthrow new \\Exception( 'Extracting a zip file requires ZipArchive.' );\n\t\t}\n\t\t$zip = new ZipArchive();\n\t\t$res = $zip->open( $zipfile );\n\t\tif ( true === $res ) {\n\t\t\t$tempdir = implode(\n\t\t\t\tDIRECTORY_SEPARATOR,\n\t\t\t\tarray(\n\t\t\t\t\tdirname( $zipfile ),\n\t\t\t\t\tUtils\\basename( $zipfile, '.zip' ),\n\t\t\t\t\t$zip->getNameIndex( 0 ),\n\t\t\t\t)\n\t\t\t);\n\n\t\t\t$zip->extractTo( dirname( $tempdir ) );\n\t\t\t$zip->close();\n\n\t\t\tself::copy_overwrite_files( $tempdir, $dest );\n\t\t\tself::rmdir( dirname( $tempdir ) );\n\t\t} else {\n\t\t\tthrow new \\Exception( sprintf( \"ZipArchive failed to unzip '%s': %s.\", $zipfile, self::zip_error_msg( $res ) ) );\n\t\t}\n\t}", "label": 2}
{"code": "func NewTLSClient(cfg ClientConfig, params ...roundtrip.ClientParam) (*Client, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttransport := &http.Transport{\n\t\t// notice that below roundtrip.Client is passed\n\t\t// teleport.APIEndpoint as an address for the API server, this is\n\t\t// to make sure client verifies the DNS name of the API server\n\t\t// custom DialContext overrides this DNS name to the real address\n\t\t// in addition this dialer tries multiple adresses if provided\n\t\tDialContext:           cfg.DialContext,\n\t\tResponseHeaderTimeout: defaults.DefaultDialTimeout,\n\t\tTLSClientConfig:       cfg.TLS,\n\n\t\t// Increase the size of the connection pool. This substantially improves the\n\t\t// performance of Teleport under load as it reduces the number of TLS\n\t\t// handshakes performed.\n\t\tMaxIdleConns:        defaults.HTTPMaxIdleConns,\n\t\tMaxIdleConnsPerHost: defaults.HTTPMaxIdleConnsPerHost,\n\n\t\t// IdleConnTimeout defines the maximum amount of time before idle connections\n\t\t// are closed. Leaving this unset will lead to connections open forever and\n\t\t// will cause memory leaks in a long running process.\n\t\tIdleConnTimeout: defaults.HTTPIdleTimeout,\n\t}\n\n\tclientParams := append(\n\t\t[]roundtrip.ClientParam{\n\t\t\troundtrip.HTTPClient(&http.Client{Transport: transport}),\n\t\t\troundtrip.SanitizerEnabled(true),\n\t\t},\n\t\tparams...,\n\t)\n\troundtripClient, err := roundtrip.NewClient(\"https://\"+teleport.APIDomain, CurrentVersion, clientParams...)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &Client{\n\t\tClientConfig: cfg,\n\t\tClient:       *roundtripClient,\n\t\ttransport:    transport,\n\t}, nil\n}", "label": 5}
{"code": "public function assignEntryPointFromBatch(array $batch)\n    {\n        $entryPoint = collect($batch)->first(function ($entry) {\n            return in_array($entry->type, [EntryType::REQUEST, EntryType::JOB, EntryType::COMMAND]);\n        });\n\n        if (! $entryPoint) {\n            return;\n        }\n\n        $this->content = array_merge($this->content, [\n            'entry_point_type' => $entryPoint->type,\n            'entry_point_uuid' => $entryPoint->uuid,\n            'entry_point_description' => $this->entryPointDescription($entryPoint),\n        ]);\n    }", "label": 2}
{"code": "func (r *BeeResponse) AddBee(bee *bees.BeeInterface) {\n\tr.bees[(*bee).Name()] = bee\n\n\thive := bees.GetFactory((*bee).Namespace())\n\tif hive == nil {\n\t\tpanic(\"Hive for Bee not found\")\n\t}\n\n\tr.hives[(*hive).Name()] = hive\n\tr.Hives = append(r.Hives, hives.PrepareHiveResponse(r.Context, hive))\n}", "label": 5}
{"code": "function getFileDetails(db, fileSelectionCriteria, fileOptions, cb) {\n\n  defaultLogger.debug(\"In getFileDetails \");\n  var selectionQuery = undefined;\n  if (fileSelectionCriteria.groupId) {\n\n    selectionQuery= {\"metadata.groupId\": fileSelectionCriteria.groupId};\n\n\n  } else if (fileSelectionCriteria.hash) {\n    selectionQuery= {\"md5\": fileSelectionCriteria.hash};\n  }\n\n  var gridStore = new GridStore(db, null, \"r\", {\"root\": constants.ROOT_COLLECTION});\n  var fileOfInterest = undefined;\n\n  gridStore.collection(function(err, collection) {\n    collection.find(selectionQuery, { \"sort\": {\"metadata.version\":-1}}, function(err, files) {\n      if (err) {\n        defaultLogger.error(err); return cb(err);\n      }\n\n      files.toArray(function(err, filesArray) {\n        if (err) {\n          defaultLogger.error(err); return cb(err);\n        }\n        if (!(filesArray && Array.isArray(filesArray) && filesArray.length > 0)) {\n          return cb(new Error(\"No files exist for groupId \" + fileSelectionCriteria.groupId));\n        }\n\n        //If the file details are needed for all files in the groupId, then an array containing all of the file details is returned.\n        if (fileOptions.allMatchingFiles == true) { // eslint-disable-line eqeqeq\n          fileOfInterest = filesArray;\n        } else {// Just want the details of a single file.\n          //If there is no version, get the latest version\n\n          //If no version is found or we have a hash query, just want the first entry of the array.\n          if (!fileSelectionCriteria.version || fileSelectionCriteria.hash) {\n            fileOfInterest = filesArray[0];\n          } else {\n            fileOfInterest = filesArray.filter(function(file) {\n              return file.metadata.version === fileSelectionCriteria.version;\n            });\n\n            if (fileOfInterest.length === 1) {\n              fileOfInterest = fileOfInterest[0];\n            } else {\n              return cb(new Error(\"Unexpected number of files returned for groupId \" + fileSelectionCriteria.groupId, fileOfInterest.length));\n            }\n          }\n        }\n\n        if (!Array.isArray(fileOfInterest)) {\n          //Actually want the thumbnail for the file, return the details for that file instead.\n          if (fileOptions.thumbnail) {\n            if (fileOfInterest.metadata.thumbnail) {\n              getThumbnailFileDetails(db, fileOfInterest.metadata.thumbnail, function(err, thumbFileDetails) {\n                if (err) {\n                  defaultLogger.error(err); return cb(err);\n                }\n\n                fileOfInterest = thumbFileDetails;\n\n                gridStore.close(function(err) {\n                  return cb(err, fileOfInterest);\n                });\n              });\n            } else {\n              return cb(new Error(\"Thumbnail for file \" + JSON.stringify(fileSelectionCriteria) + \" does not exist.\"));\n            }\n          } else {\n            gridStore.close(function(err) {\n              return cb(err, fileOfInterest);\n            });\n          }\n        } else {\n          gridStore.close(function(err) {\n            return cb(err, fileOfInterest);\n          });\n        }\n      });\n    });\n  });\n}", "label": 3}
{"code": "function(next) {\n            if (options.noConfigure || core.noConfigure) return next();\n            core.runMethods(\"configureModule\", options, next);\n        }", "label": 3}
{"code": "def render_relative_path(export_path, path)\n      export_path = Pathname.new(export_path)\n      path = Pathname.new(path).relative_path_from(export_path)\n      return path.to_path\n    end", "label": 4}
{"code": "public static int cudnnCTCLoss(\n        cudnnHandle handle, \n        cudnnTensorDescriptor probsDesc, /** Tensor descriptor for probabilities, the dimensions are T,N,A (T is the timing steps, N is the\n                          mini batch size, A is the alphabet size)  */\n        Pointer probs, /** probabilities after softmax, in GPU memory */\n        int[] labels, /** labels, in CPU memory */\n        int[] labelLengths, /** the length of each label, in CPU memory */\n        int[] inputLengths, /** the lengths of timing steps in each batch, in CPU memory */\n        Pointer costs, /** the returned costs of CTC, in GPU memory */\n        cudnnTensorDescriptor gradientsDesc, /** Tensor descriptor for gradients, the dimensions are T,N,A */\n        Pointer gradients, /** the returned CTC gradients, in GPU memory, to compute costs only, set it to NULL */\n        int algo, /** algorithm selected, supported now 0 and 1 */\n        cudnnCTCLossDescriptor ctcLossDesc, \n        Pointer workspace, /** pointer to the workspace, in GPU memory */\n        long workSpaceSizeInBytes)/** the workspace size needed */\n    {\n        return checkResult(cudnnCTCLossNative(handle, probsDesc, probs, labels, labelLengths, inputLengths, costs, gradientsDesc, gradients, algo, ctcLossDesc, workspace, workSpaceSizeInBytes));\n    }", "label": 0}
{"code": "public static snmpcommunity[] get(nitro_service service) throws Exception{\n\t\tsnmpcommunity obj = new snmpcommunity();\n\t\tsnmpcommunity[] response = (snmpcommunity[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getError(errno, app) {\n\tlet errObj = {\n\t\terrno: errno,\n\t\tmessage: errors[errno].replace('$app', app)\n\t};\n\treturn errObj.message;\n}", "label": 3}
{"code": "function viewBox(details) {\n    svg.viewBox = `${details.x || 0} ${details.y || 0} ${details.width} ${details.height}`;\n\n    fn(null, svg);\n  }", "label": 3}
{"code": "function detect(eventData) {\n    if(!this.current || this.stopped) {\n      return;\n    }\n\n    // extend event data with calculations about scale, distance etc\n    eventData = this.extendEventData(eventData);\n\n    // instance options\n    var inst_options = this.current.inst.options;\n\n    // call Hammer.gesture handlers\n    Hammer.utils.each(this.gestures, function(gesture) {\n      // only when the instance options have enabled this gesture\n      if(!this.stopped && inst_options[gesture.name] !== false) {\n        // if a handler returns false, we stop with the detection\n        if(gesture.handler.call(gesture, eventData, this.current.inst) === false) {\n          this.stopDetect();\n          return false;\n        }\n      }\n    }, this);\n\n    // store as previous event event\n    if(this.current) {\n      this.current.lastEvent = eventData;\n    }\n\n    // endevent, but not the last touch, so dont stop\n    if(eventData.eventType == Hammer.EVENT_END && !eventData.touches.length - 1) {\n      this.stopDetect();\n    }\n\n    return eventData;\n  }", "label": 3}
{"code": "func PgShdependsByRefclassidRefobjid(db XODB, refclassid pgtypes.Oid, refobjid pgtypes.Oid) ([]*PgShdepend, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, dbid, classid, objid, objsubid, refclassid, refobjid, deptype ` +\n\t\t`FROM pg_catalog.pg_shdepend ` +\n\t\t`WHERE refclassid = $1 AND refobjid = $2`\n\n\t// run query\n\tXOLog(sqlstr, refclassid, refobjid)\n\tq, err := db.Query(sqlstr, refclassid, refobjid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*PgShdepend{}\n\tfor q.Next() {\n\t\tps := PgShdepend{}\n\n\t\t// scan\n\t\terr = q.Scan(&ps.Tableoid, &ps.Cmax, &ps.Xmax, &ps.Cmin, &ps.Xmin, &ps.Ctid, &ps.Dbid, &ps.Classid, &ps.Objid, &ps.Objsubid, &ps.Refclassid, &ps.Refobjid, &ps.Deptype)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ps)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public void setT(int t) {\r\n        this.t = Math.min((radius * 2 + 1) * (radius * 2 + 1) / 2, Math.max(0, t));\r\n    }", "label": 0}
{"code": "function gotoIFrame(src) {\n    var iframe = document.createElement(\"iframe\");\n    iframe.style.display = \"none\";\n    iframe.src = src;\n    document.body.appendChild(iframe);\n    return iframe;\n  }", "label": 3}
{"code": "public function setLoggingConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\LoggingConfig::class);\n        $this->logging_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(lines) {\n        var idx = 0;\n        jsonCaptions = [];\n        for (idx = 0; idx < lines.length; idx++) {\n            if (!module.exports.verify(lines[idx])) {\n                module.exports.translateLine(lines[idx].toLowerCase());\n            }\n        }\n        if (paintBuffer.length > 0) {\n            rollUp(true);\n        }\n        if (jsonCaptions[jsonCaptions.length - 1].endTimeMicro === undefined) {\n            jsonCaptions[jsonCaptions.length - 1].endTimeMicro = jsonCaptions[jsonCaptions.length - 1].startTimeMicro;\n        }\n        return jsonCaptions;\n    }", "label": 3}
{"code": "public function setGcsSource($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\GcsSource::class);\n        $this->gcs_source = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function isInCommentHelper(sourceFile, position, predicate) {\n        var token = getTokenAtPosition(sourceFile, position);\n        if (token && position <= token.getStart(sourceFile)) {\n            var commentRanges = ts.getLeadingCommentRanges(sourceFile.text, token.pos);\n            // The end marker of a single-line comment does not include the newline character.\n            // In the following case, we are inside a comment (^ denotes the cursor position):\n            //\n            //    // asdf   ^\\n\n            //\n            // But for multi-line comments, we don't want to be inside the comment in the following case:\n            //\n            //    /* asdf */^\n            //\n            // Internally, we represent the end of the comment at the newline and closing '/', respectively.\n            return predicate ?\n                ts.forEach(commentRanges, function (c) { return c.pos < position &&\n                    (c.kind == 2 /* SingleLineCommentTrivia */ ? position <= c.end : position < c.end) &&\n                    predicate(c); }) :\n                ts.forEach(commentRanges, function (c) { return c.pos < position &&\n                    (c.kind == 2 /* SingleLineCommentTrivia */ ? position <= c.end : position < c.end); });\n        }\n        return false;\n    }", "label": 3}
{"code": "function getAngle(originX, originY, projectionX, projectionY) {\n  const angle = Math.atan2(projectionY - originY, projectionX - originX) * ((180) / Math.PI);\n  return 360 - ((angle < 0) ? (360 + angle) : angle);\n}", "label": 3}
{"code": "protected void appendWhereClause(StringBuffer stmt, Object[] columns)\r\n    {\r\n        stmt.append(\" WHERE \");\r\n\r\n        for (int i = 0; i < columns.length; i++)\r\n        {\r\n            if (i > 0)\r\n            {\r\n                stmt.append(\" AND \");\r\n            }\r\n            stmt.append(columns[i]);\r\n            stmt.append(\"=?\");\r\n        }\r\n    }", "label": 0}
{"code": "public function setTargetChangeType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Firestore\\V1\\TargetChange_TargetChangeType::class);\n        $this->target_change_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function recordCommand(CommandFinished $event)\n    {\n        if (! Telescope::isRecording() || $this->shouldIgnore($event)) {\n            return;\n        }\n\n        Telescope::recordCommand(IncomingEntry::make([\n            'command' => $event->command ?? $event->input->getArguments()['command'] ?? 'default',\n            'exit_code' => $event->exitCode,\n            'arguments' => $event->input->getArguments(),\n            'options' => $event->input->getOptions(),\n        ]));\n    }", "label": 2}
{"code": "public function setFollowupEventInput($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\EventInput::class);\n        $this->followup_event_input = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def date_group_items=(options)\n      options.each do |date_group|\n        raise ArgumentError, \"date_group_items should be an array of hashes specifying the options for each date_group_item\" unless date_group.is_a?(Hash)\n        date_group_items << DateGroupItem.new(date_group)\n      end\n    end", "label": 4}
{"code": "public function recordAction($event, $data)\n    {\n        if (! Telescope::isRecording() || ! $this->shouldRecord($event)) {\n            return;\n        }\n\n        $model = FormatModel::given($data[0]);\n\n        $changes = $data[0]->getChanges();\n\n        Telescope::recordModelEvent(IncomingEntry::make(array_filter([\n            'action' => $this->action($event),\n            'model' => $model,\n            'changes' => empty($changes) ? null : $changes,\n        ]))->tags([$model]));\n    }", "label": 2}
{"code": "func AuditConfigFromObject(in interface{}) (*AuditConfig, error) {\n\tvar cfg AuditConfig\n\tif in == nil {\n\t\treturn &cfg, nil\n\t}\n\tif err := utils.ObjectToStruct(in, &cfg); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &cfg, nil\n}", "label": 5}
{"code": "def index_workflow_fields(solr_document)\n      return unless object.persisted?\n      entity = PowerConverter.convert_to_sipity_entity(object)\n      return if entity.nil?\n      solr_document[workflow_role_field] = workflow_roles(entity).map { |role| \"#{entity.workflow.permission_template.source_id}-#{entity.workflow.name}-#{role}\" }\n      solr_document[workflow_state_name_field] = entity.workflow_state.name if entity.workflow_state\n    end", "label": 4}
{"code": "public Query getCountQuery(Query aQuery)\r\n    {\r\n        if(aQuery instanceof QueryBySQL)\r\n        {\r\n            return getQueryBySqlCount((QueryBySQL) aQuery);\r\n        }\r\n        else if(aQuery instanceof ReportQueryByCriteria)\r\n        {\r\n            return getReportQueryByCriteriaCount((ReportQueryByCriteria) aQuery);\r\n        }\r\n        else\r\n        {\r\n            return getQueryByCriteriaCount((QueryByCriteria) aQuery);\r\n        }\r\n    }", "label": 0}
{"code": "public static base_response unset(nitro_service client, sslfips resource, String[] args) throws Exception{\n\t\tsslfips unsetresource = new sslfips();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "func parseLinuxSeccompSet(p *stage1commontypes.Pod, s types.LinuxSeccompSet) (syscallFilter []string, flag string, err error) {\n\tfor _, item := range s.Set() {\n\t\tif item[0] == '@' {\n\t\t\t// Wildcards\n\t\t\twildcard := strings.SplitN(string(item), \"/\", 2)\n\t\t\tif len(wildcard) != 2 {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tscope := wildcard[0]\n\t\t\tname := wildcard[1]\n\t\t\tswitch scope {\n\t\t\tcase \"@appc.io\":\n\t\t\t\t// appc-reserved wildcards\n\t\t\t\tswitch name {\n\t\t\t\tcase \"all\":\n\t\t\t\t\treturn nil, \"all\", nil\n\t\t\t\tcase \"empty\":\n\t\t\t\t\treturn nil, \"empty\", nil\n\t\t\t\t}\n\t\t\tcase \"@docker\":\n\t\t\t\t// Docker-originated wildcards\n\t\t\t\tswitch name {\n\t\t\t\tcase \"default-blacklist\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, DockerDefaultSeccompBlacklist...)\n\t\t\t\tcase \"default-whitelist\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, DockerDefaultSeccompWhitelist...)\n\t\t\t\t}\n\t\t\tcase \"@rkt\":\n\t\t\t\t// Custom rkt wildcards\n\t\t\t\tswitch name {\n\t\t\t\tcase \"default-blacklist\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, RktDefaultSeccompBlacklist...)\n\t\t\t\tcase \"default-whitelist\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, RktDefaultSeccompWhitelist...)\n\t\t\t\t}\n\t\t\tcase \"@systemd\":\n\t\t\t\t// Custom systemd wildcards (systemd >= 231)\n\t\t\t\t_, systemdVersion, err := GetFlavor(p)\n\t\t\t\tif err != nil || systemdVersion < 231 {\n\t\t\t\t\treturn nil, \"\", errors.New(\"Unsupported or unknown systemd version, seccomp groups need systemd >= v231\")\n\t\t\t\t}\n\t\t\t\tswitch name {\n\t\t\t\tcase \"clock\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@clock\")\n\t\t\t\tcase \"default-whitelist\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@default\")\n\t\t\t\tcase \"mount\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@mount\")\n\t\t\t\tcase \"network-io\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@network-io\")\n\t\t\t\tcase \"obsolete\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@obsolete\")\n\t\t\t\tcase \"privileged\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@privileged\")\n\t\t\t\tcase \"process\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@process\")\n\t\t\t\tcase \"raw-io\":\n\t\t\t\t\tsyscallFilter = append(syscallFilter, \"@raw-io\")\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// Plain syscall name\n\t\t\tsyscallFilter = append(syscallFilter, string(item))\n\t\t}\n\t}\n\treturn syscallFilter, \"\", nil\n}", "label": 5}
{"code": "public static void main(String[] args) throws Exception {\r\n    System.err.println(\"CRFBiasedClassifier invoked at \" + new Date()\r\n            + \" with arguments:\");\r\n    for (String arg : args) {\r\n      System.err.print(\" \" + arg);\r\n    }\r\n    System.err.println();\r\n\r\n    Properties props = StringUtils.argsToProperties(args);\r\n    CRFBiasedClassifier crf = new CRFBiasedClassifier(props);\r\n    String testFile = crf.flags.testFile;\r\n    String loadPath = crf.flags.loadClassifier;\r\n\r\n    if (loadPath != null) {\r\n      crf.loadClassifierNoExceptions(loadPath, props);\r\n    } else if (crf.flags.loadJarClassifier != null) {\r\n      crf.loadJarClassifier(crf.flags.loadJarClassifier, props);\r\n    } else {\r\n      crf.loadDefaultClassifier();\r\n    }\r\n    if(crf.flags.classBias != null) {\r\n      StringTokenizer biases = new java.util.StringTokenizer(crf.flags.classBias,\",\");\r\n      while (biases.hasMoreTokens()) {\r\n        StringTokenizer bias = new java.util.StringTokenizer(biases.nextToken(),\":\");\r\n        String cname = bias.nextToken();\r\n        double w = Double.parseDouble(bias.nextToken());\r\n        crf.setBiasWeight(cname,w);\r\n        System.err.println(\"Setting bias for class \"+cname+\" to \"+w);\r\n      }\r\n    }\r\n\r\n    if (testFile != null) {\r\n      DocumentReaderAndWriter readerAndWriter = crf.makeReaderAndWriter();\r\n      if (crf.flags.printFirstOrderProbs) {\r\n        crf.printFirstOrderProbs(testFile, readerAndWriter);\r\n      } else if (crf.flags.printProbs) {\r\n        crf.printProbs(testFile, readerAndWriter);\r\n      } else if (crf.flags.useKBest) {\r\n        int k = crf.flags.kBest;\r\n        crf.classifyAndWriteAnswersKBest(testFile, k, readerAndWriter);\r\n      } else {\r\n        crf.classifyAndWriteAnswers(testFile, readerAndWriter);\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "def add_type_converter(type, r2c, c2r)\n      warn \"WAR\\NING: overridding #{type} on #{caller[0]}\" if @@type_map.has_key? type\n      @@type_map[type] = [r2c, c2r]\n    end", "label": 4}
{"code": "def initialize_default_cfvos(user_cfvos)\n      defaults = self.class.default_cfvos\n      user_cfvos.each_with_index do |cfvo, index|\n        if index < defaults.size\n          cfvo = defaults[index].merge(cfvo)\n        end\n        add cfvo\n      end\n      while colors.size < defaults.size\n        add defaults[colors.size - 1]\n      end\n    end", "label": 4}
{"code": "def hook(name, opts=nil)\n      @logger.info(\"Running hook: #{name}\")\n      opts ||= {}\n      opts[:callable] ||= Action::Builder.new\n      opts[:runner] ||= action_runner\n      opts[:action_name] = name\n      opts[:env] = self\n      opts.delete(:runner).run(opts.delete(:callable), opts)\n    end", "label": 4}
{"code": "def ip_geoloc(ip, hit_api=True):\n    \"\"\"\n    Get IP geolocation.\n\n    Args:\n        ip (str): IP address to use if no data provided.\n        hit_api (bool): whether to hit api if info not found.\n\n    Returns:\n        str: latitude and longitude, comma-separated.\n    \"\"\"\n    from ..logs.models import IPInfoCheck\n    try:\n        obj = IPInfoCheck.objects.get(ip_address=ip).ip_info\n    except IPInfoCheck.DoesNotExist:\n        if hit_api:\n            try:\n                obj = IPInfoCheck.check_ip(ip)\n            except RateExceededError:\n                return None\n        else:\n            return None\n    return obj.latitude, obj.longitude", "label": 1}
{"code": "func (m *ProcessManager) Start(r *vix.StartProgramRequest, p *Process) (int64, error) {\n\tp.Name = r.ProgramPath\n\tp.Args = r.Arguments\n\n\t// Owner is cosmetic, but useful for example with: govc guest.ps -U $uid\n\tif p.Owner == \"\" {\n\t\tp.Owner = defaultOwner\n\t}\n\n\tp.StartTime = time.Now().Unix()\n\n\tp.ctx, p.Kill = context.WithCancel(context.Background())\n\n\tpid, err := p.Start(p, r)\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\n\tif pid == 0 {\n\t\tp.Pid = m.pids.Get().(int64) // pseudo pid for funcs\n\t} else {\n\t\tp.Pid = pid\n\t}\n\n\tm.mu.Lock()\n\tm.entries[p.Pid] = p\n\tm.mu.Unlock()\n\n\tm.wg.Add(1)\n\tgo func() {\n\t\twerr := p.Wait()\n\n\t\tatomic.StoreInt64(&p.EndTime, time.Now().Unix())\n\n\t\tif werr != nil {\n\t\t\trc := int32(1)\n\t\t\tif xerr, ok := werr.(*ProcessError); ok {\n\t\t\t\trc = xerr.ExitCode\n\t\t\t}\n\n\t\t\tatomic.StoreInt32(&p.ExitCode, rc)\n\t\t}\n\n\t\tm.wg.Done()\n\t\tp.Kill() // cancel context for those waiting on p.ctx.Done()\n\n\t\t// See: http://pubs.vmware.com/vsphere-65/topic/com.vmware.wssdk.apiref.doc/vim.vm.guest.ProcessManager.ProcessInfo.html\n\t\t// \"If the process was started using StartProgramInGuest then the process completion time\n\t\t//  will be available if queried within 5 minutes after it completes.\"\n\t\t<-time.After(m.expire)\n\n\t\tm.mu.Lock()\n\t\tdelete(m.entries, p.Pid)\n\t\tm.mu.Unlock()\n\n\t\tif pid == 0 {\n\t\t\tm.pids.Put(p.Pid) // pseudo pid can be reused now\n\t\t}\n\t}()\n\n\treturn p.Pid, nil\n}", "label": 5}
{"code": "def update_timecard(timecard_id, body, opts = {})\n      data, _status_code, _headers = update_timecard_with_http_info(timecard_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "func writeTypes(args *internal.ArgType) error {\n\tvar err error\n\n\tout := internal.TBufSlice(args.Generated)\n\n\t// sort segments\n\tsort.Sort(out)\n\n\t// loop, writing in order\n\tfor _, t := range out {\n\t\tvar f *os.File\n\n\t\t// skip when in append and type is XO\n\t\tif args.Append && t.TemplateType == internal.XOTemplate {\n\t\t\tcontinue\n\t\t}\n\n\t\t// check if generated template is only whitespace/empty\n\t\tbufStr := strings.TrimSpace(t.Buf.String())\n\t\tif len(bufStr) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\t// get file and filename\n\t\tf, err = getFile(args, &t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// should only be nil when type == xo\n\t\tif f == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// write segment\n\t\tif !args.Append || (t.TemplateType != internal.TypeTemplate && t.TemplateType != internal.QueryTypeTemplate) {\n\t\t\t_, err = t.Buf.WriteTo(f)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// build goimports parameters, closing files\n\tparams := []string{\"-w\"}\n\tfor k, f := range files {\n\t\tparams = append(params, k)\n\n\t\t// close\n\t\terr = f.Close()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// process written files with goimports\n\toutput, err := exec.Command(\"goimports\", params...).CombinedOutput()\n\tif err != nil {\n\t\treturn errors.New(string(output))\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def object_to_items(data_structure):\n    \"\"\"Converts a object to a items list respecting also slots.\n\n    Use dict(object_to_items(obj)) to get a dictionary.\"\"\"\n    items = []\n    # Get all items from dict\n    try:\n        items = list(data_structure.__dict__.items())\n    except:\n        pass\n    # Get all slots\n    hierarchy = [data_structure]\n    try:\n        hierarchy += inspect.getmro(data_structure)\n    except:\n        pass\n    slots = []\n    try:\n        for b in hierarchy:\n            try:\n                slots += b.__slots__\n            except:  # pragma: no cover\n                pass\n    except:  # pragma: no cover\n        pass\n    # Get attrs from slots\n    for x in slots:\n        items.append((x, getattr(data_structure, x)))\n    return items", "label": 1}
{"code": "def run(self):\n        \"\"\"\n        loops until exit command given\n        \"\"\"\n        while self.status != 'EXIT':\n            print(self.process_input(self.get_input()))\n        \n        print('Bye')", "label": 1}
{"code": "func StopBees() {\n\tfor _, bee := range bees {\n\t\tlog.Println(\"Stopping bee:\", (*bee).Name())\n\t\t(*bee).Stop()\n\t}\n\n\tclose(eventsIn)\n\tbees = make(map[string]*BeeInterface)\n}", "label": 5}
{"code": "def changelist_view(self, request, extra_context=None):\n        \"\"\" Get object currently tracked and add a button to get back to it \"\"\"\n        extra_context = extra_context or {}\n        if 'object' in request.GET.keys():\n            value = request.GET['object'].split(':')\n            content_type = get_object_or_404(\n                ContentType,\n                id=value[0],\n            )\n            tracked_object = get_object_or_404(\n                content_type.model_class(),\n                id=value[1],\n            )\n            extra_context['tracked_object'] = tracked_object\n            extra_context['tracked_object_opts'] = tracked_object._meta\n        return super(TrackingEventAdmin, self).changelist_view(\n            request, extra_context)", "label": 1}
{"code": "public function attribute($key)\n    {\n        return (isset($this->message['attributes'][$key]))\n            ? $this->message['attributes'][$key]\n            : null;\n    }", "label": 2}
{"code": "def __is_bound_method(method):\n    \"\"\"Return ``True`` if the `method` is a bound method (attached to an class\n    instance.\n\n    Args:\n        method: A method or function type object.\n    \"\"\"\n    if not(hasattr(method, \"__func__\") and hasattr(method, \"__self__\")):\n        return False\n\n    # Bound methods have a __self__ attribute pointing to the owner instance\n    return six.get_method_self(method) is not None", "label": 1}
{"code": "def decode_caveat(key, caveat):\n    '''Decode caveat by decrypting the encrypted part using key.\n\n    @param key the nacl private key to decode.\n    @param caveat bytes.\n    @return ThirdPartyCaveatInfo\n    '''\n    if len(caveat) == 0:\n        raise VerificationError('empty third party caveat')\n\n    first = caveat[:1]\n    if first == b'e':\n        # 'e' will be the first byte if the caveatid is a base64\n        # encoded JSON object.\n        return _decode_caveat_v1(key, caveat)\n    first_as_int = six.byte2int(first)\n    if (first_as_int == VERSION_2 or\n            first_as_int == VERSION_3):\n        if (len(caveat) < _VERSION3_CAVEAT_MIN_LEN\n                and first_as_int == VERSION_3):\n            # If it has the version 3 caveat tag and it's too short, it's\n            # almost certainly an id, not an encrypted payload.\n            raise VerificationError(\n                'caveat id payload not provided for caveat id {}'.format(\n                    caveat))\n        return _decode_caveat_v2_v3(first_as_int, key, caveat)\n    raise VerificationError('unknown version for caveat')", "label": 1}
{"code": "def verify_integrity(self):\n        \"\"\"Verifies that all required functions been injected.\"\"\"\n        if not self.__integrity_check:\n            if not self.__appid:\n                raise Exception('U2F_APPID was not defined! Please define it in configuration file.')\n\n            if self.__facets_enabled and not len(self.__facets_list):\n                raise Exception(\"\"\"U2F facets been enabled, but U2F facet list is empty.\n                                   Please either disable facets by setting U2F_FACETS_ENABLED to False.\n                                   Or add facets list using, by assigning it to U2F_FACETS_LIST.\n                                \"\"\")\n\n            # Injection\n            \n            undefined_message = 'U2F {name} handler is not defined! Please import {name} through {method}!'\n\n            if not self.__get_u2f_devices:\n                raise Exception(undefined_message.format(name='Read', method='@u2f.read'))\n\n            if not self.__save_u2f_devices:\n                raise Exception(undefined_message.format(name='Save', method='@u2f.save'))\n\n\n            if not self.__call_success_enroll:\n                raise Exception(undefined_message.format(name='enroll onSuccess', method='@u2f.enroll_on_success'))\n\n            if not self.__call_success_sign:\n                raise Exception(undefined_message.format(name='sign onSuccess', method='@u2f.sign_on_success'))\n\n            self.__integrity_check = True\n\n        return True", "label": 1}
{"code": "public Set<String> rangeByLexReverse(final LexRange lexRange) {\n        return doWithJedis(new JedisCallable<Set<String>>() {\n            @Override\n            public Set<String> call(Jedis jedis) {\n                if (lexRange.hasLimit()) {\n                    return jedis.zrevrangeByLex(getKey(), lexRange.fromReverse(), lexRange.toReverse(), lexRange.offset(), lexRange.count());\n                } else {\n                    return jedis.zrevrangeByLex(getKey(), lexRange.fromReverse(), lexRange.toReverse());\n                }\n            }\n        });\n    }", "label": 0}
{"code": "public function setInspectDetails($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\InspectDataSourceDetails::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def raise_insufficient_permission_error!(additional_error_string: nil, caller_location: 2)\n      # get the method name of the request that failed\n      # `block in` is used very often for requests when surrounded for paging or retrying blocks\n      # The ! is part of some methods when they modify or delete a resource, so we don't want to show it\n      # Using `sub` instead of `delete` as we don't want to allow multiple matches\n      calling_method_name = caller_locations(caller_location, 2).first.label.sub(\"block in\", \"\").delete(\"!\").strip\n\n      # calling the computed property self.team_id can get us into an exception handling loop\n      team_id = @current_team_id ? \"(Team ID #{@current_team_id}) \" : \"\"\n\n      error_message = \"User #{self.user} #{team_id}doesn't have enough permission for the following action: #{calling_method_name}\"\n      error_message += \" (#{additional_error_string})\" if additional_error_string.to_s.length > 0\n      raise InsufficientPermissions, error_message\n    end", "label": 4}
{"code": "function reload () {\n        sourceRows.innerHTML = \"\"; // Clear content\n        sources.forEach(function (source, index) {\n            if (flavor && !flavor[index]) {\n                return;\n            }\n            sourceRows.appendChild(rowFactory(source, index));\n            updateSourceRow(source);\n        });\n    }", "label": 3}
{"code": "public static base_response delete(nitro_service client, ntpserver resource) throws Exception {\n\t\tntpserver deleteresource = new ntpserver();\n\t\tdeleteresource.serverip = resource.serverip;\n\t\tdeleteresource.servername = resource.servername;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def find_best_rsquared(list_of_fits):\n        \"\"\"Return the best fit, based on rsquared\"\"\"\n        res = sorted(list_of_fits, key=lambda x: x.rsquared)\n        return res[-1]", "label": 1}
{"code": "func StartKeepAliveLoop(p KeepAliveParams) {\n\tvar missedCount int64\n\n\tlog := logrus.WithFields(logrus.Fields{\n\t\ttrace.Component: teleport.ComponentKeepAlive,\n\t})\n\tlog.Debugf(\"Starting keep-alive loop with with interval %v and max count %v.\", p.Interval, p.MaxCount)\n\n\ttickerCh := time.NewTicker(p.Interval)\n\tdefer tickerCh.Stop()\n\n\tfor {\n\t\tselect {\n\t\tcase <-tickerCh.C:\n\t\t\tvar sentCount int\n\n\t\t\t// Send a keep alive message on all connections and make sure a response\n\t\t\t// was received on all.\n\t\t\tfor _, conn := range p.Conns {\n\t\t\t\tok := sendKeepAliveWithTimeout(conn, defaults.ReadHeadersTimeout, p.CloseContext)\n\t\t\t\tif ok {\n\t\t\t\t\tsentCount += 1\n\t\t\t\t}\n\t\t\t}\n\t\t\tif sentCount == len(p.Conns) {\n\t\t\t\tmissedCount = 0\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// If enough keep-alives are missed, the connection is dead, call cancel\n\t\t\t// and notify the server to disconnect and cleanup.\n\t\t\tmissedCount = missedCount + 1\n\t\t\tif missedCount > p.MaxCount {\n\t\t\t\tlog.Infof(\"Missed %v keep-alive messages, closing connection.\", missedCount)\n\t\t\t\tp.CloseCancel()\n\t\t\t\treturn\n\t\t\t}\n\t\t// If an external caller closed the context (connection is done) then no\n\t\t// more need to wait around for keep-alives.\n\t\tcase <-p.CloseContext.Done():\n\t\t\treturn\n\t\t}\n\t}\n}", "label": 5}
{"code": "function pushDeviceFilterByUsers() {\n    var users = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        users[_i - 0] = arguments[_i];\n    }\n    if (users.length <= 0) {\n        return {\n            type: 'null',\n            fieldName: 'user',\n            isNull: true\n        };\n    }\n    else if (users.length === 1) {\n        return {\n            type: 'string',\n            fieldName: 'user',\n            value: domain.uuidOf(users[0])\n        };\n    }\n    else {\n        var uuids = users.map(function (user) { return domain.uuidOf(user); });\n        return {\n            type: 'stringEnum',\n            fieldName: 'user',\n            values: uuids\n        };\n    }\n}", "label": 3}
{"code": "public static cachepolicylabel_binding get(nitro_service service, String labelname) throws Exception{\n\t\tcachepolicylabel_binding obj = new cachepolicylabel_binding();\n\t\tobj.set_labelname(labelname);\n\t\tcachepolicylabel_binding response = (cachepolicylabel_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (m VirtualDiskManager) QueryVirtualDiskUuid(ctx context.Context, name string, dc *Datacenter) (string, error) {\n\treq := types.QueryVirtualDiskUuid{\n\t\tThis: m.Reference(),\n\t\tName: name,\n\t}\n\n\tif dc != nil {\n\t\tref := dc.Reference()\n\t\treq.Datacenter = &ref\n\t}\n\n\tres, err := methods.QueryVirtualDiskUuid(ctx, m.c, &req)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif res == nil {\n\t\treturn \"\", nil\n\t}\n\n\treturn res.Returnval, nil\n}", "label": 5}
{"code": "def respond_to?(method_name, _include_all = false)\n      if attrs.key?(method_name.to_s)\n        true\n      else\n        super(method_name)\n      end\n    end", "label": 4}
{"code": "func CheckNameserverOverlaps(nameservers []string, toCheck *net.IPNet) error {\n\tif len(nameservers) > 0 {\n\t\tfor _, ns := range nameservers {\n\t\t\t_, nsNetwork, err := net.ParseCIDR(ns)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif NetworkOverlaps(toCheck, nsNetwork) {\n\t\t\t\treturn ErrNetworkOverlapsWithNameservers\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func PgConstraintByOid(db XODB, oid pgtypes.Oid) (*PgConstraint, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, conname, connamespace, contype, condeferrable, condeferred, convalidated, conrelid, contypid, conindid, confrelid, confupdtype, confdeltype, confmatchtype, conislocal, coninhcount, connoinherit, conkey, confkey, conpfeqop, conppeqop, conffeqop, conexclop, conbin, consrc ` +\n\t\t`FROM pg_catalog.pg_constraint ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpc := PgConstraint{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pc.Tableoid, &pc.Cmax, &pc.Xmax, &pc.Cmin, &pc.Xmin, &pc.Oid, &pc.Ctid, &pc.Conname, &pc.Connamespace, &pc.Contype, &pc.Condeferrable, &pc.Condeferred, &pc.Convalidated, &pc.Conrelid, &pc.Contypid, &pc.Conindid, &pc.Confrelid, &pc.Confupdtype, &pc.Confdeltype, &pc.Confmatchtype, &pc.Conislocal, &pc.Coninhcount, &pc.Connoinherit, &pc.Conkey, &pc.Confkey, &pc.Conpfeqop, &pc.Conppeqop, &pc.Conffeqop, &pc.Conexclop, &pc.Conbin, &pc.Consrc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pc, nil\n}", "label": 5}
{"code": "func (c *Manager) GetTag(ctx context.Context, id string) (*Tag, error) {\n\tif isName(id) {\n\t\ttags, err := c.GetTags(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor i := range tags {\n\t\t\tif tags[i].Name == id {\n\t\t\t\treturn &tags[i], nil\n\t\t\t}\n\t\t}\n\t}\n\n\turl := internal.URL(c, internal.TagPath).WithID(id)\n\tvar res Tag\n\treturn &res, c.Do(ctx, url.Request(http.MethodGet), &res)\n\n}", "label": 5}
{"code": "def update(*args)\n      arguments(args, required: [:id]) do\n        permit VALID_KEY_PARAM_NAMES\n      end\n      patch_request(\"/user/keys/#{arguments.id}\", arguments.params)\n    end", "label": 4}
{"code": "function shouldBeIncluded(file) {\n\n  if (!showAllFiles && file[0] === '.') {\n    return false\n  }\n  if (hasExcludePattern) {\n    return !excludePattern.test(file)\n  }\n  if (hasIncludePattern) {\n    return includePattern.test(file)\n  }\n  return true\n}", "label": 3}
{"code": "func (sink *influxdbSink) labelsToPredicate(labels map[string]string) string {\n\tif len(labels) == 0 {\n\t\treturn \"\"\n\t}\n\n\tparts := make([]string, 0, len(labels))\n\tfor k, v := range labels {\n\t\tparts = append(parts, fmt.Sprintf(\"%q = '%s'\", k, v))\n\t}\n\n\treturn strings.Join(parts, \" AND \")\n}", "label": 5}
{"code": "def type(self, sequence_coverage_collection,\n             min_gene_percent_covg_threshold=99):\n        \"\"\"Types a collection of genes returning the most likely gene version\n            in the collection with it's genotype\"\"\"\n        best_versions = self.get_best_version(\n            sequence_coverage_collection.values(),\n            min_gene_percent_covg_threshold)\n        return [self.presence_typer.type(best_version)\n                for best_version in best_versions]", "label": 1}
{"code": "def cookie(\n        url,\n        name,\n        value,\n        expires=None):\n    '''Return a new Cookie using a slightly more\n    friendly API than that provided by six.moves.http_cookiejar\n\n    @param name The cookie name {str}\n    @param value The cookie value {str}\n    @param url The URL path of the cookie {str}\n    @param expires The expiry time of the cookie {datetime}. If provided,\n        it must be a naive timestamp in UTC.\n    '''\n    u = urlparse(url)\n    domain = u.hostname\n    if '.' not in domain and not _is_ip_addr(domain):\n        domain += \".local\"\n    port = str(u.port) if u.port is not None else None\n    secure = u.scheme == 'https'\n    if expires is not None:\n        if expires.tzinfo is not None:\n            raise ValueError('Cookie expiration must be a naive datetime')\n        expires = (expires - datetime(1970, 1, 1)).total_seconds()\n    return http_cookiejar.Cookie(\n        version=0,\n        name=name,\n        value=value,\n        port=port,\n        port_specified=port is not None,\n        domain=domain,\n        domain_specified=True,\n        domain_initial_dot=False,\n        path=u.path,\n        path_specified=True,\n        secure=secure,\n        expires=expires,\n        discard=False,\n        comment=None,\n        comment_url=None,\n        rest=None,\n        rfc2109=False,\n    )", "label": 1}
{"code": "function (exec_path, onExec) {\n\n\t\tvar onFound = function () {\n\t\t\t\n\t\t\t// if file found, execute directly\n\t\t\t// store starting path\n\t\t\targs.exec_path = exec_path;\n\t\t\t\n\t\t\tLOG.warn('starting ' + size + ' [' + server_type + '] servers', l_name);\n\t\t\t\n\t\t\t// store an entry for the callback when all servers are started as requested\n\t\t\t// TODO: if it takes too long to start all app servers, then force return in some interval\n\t\t\tl_pendingStart.push({\n\t\t\t\tonDone: onDone,\n\t\t\t\ttotal: size,\n\t\t\t\tcurr: 0,\n\t\t\t\tserver_type: server_type,\n\t\t\t\tservers: []\n\t\t\t});\n\t\t\t\n\t\t\tstart_server();\n\t\t}\n\t\t\n\t\tvar file_path = SR.path.join(exec_path, args.name, 'frontier.js');\n\t\tLOG.warn('validate file_path: ' + file_path, l_name);\n\t\t\n\t\t// verify frontier file exists, if not then we try package.json\n\t\tSR.fs.stat(file_path, function (err, stats) {\n\n\t\t\t// file not found\n\t\t\tif (err) {\n\t\t\t\tfile_path = SR.path.join(exec_path, 'package.json');\n\t\t\t\t\n\t\t\t\t// remove server name from parameter \n\t\t\t\targs.name = '';\n\t\t\t\t\n\t\t\t\tSR.fs.stat(file_path, function (err, stats) {\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\treturn onExec('cannot find entry file');\n\t\t\t\t\t}\n\t\t\t\t\tonFound();\n\t\t\t\t});\n\t\t\t}\n\t\t\tonFound();\n\t\t});\n\t}", "label": 3}
{"code": "function die(reason = \"\", error = null, exitCode = 0){\n\treason = (reason || \"\").trim();\n\t\n\t// ANSI escape sequences (disabled if output is redirected)\n\tconst [reset,, underline,, noUnderline, red] = process.stderr.isTTY\n\t\t? [0, 1, 4, 22, 24, [31, 9, 38]].map(s => `\\x1B[${ Array.isArray(s) ? s.join(\";\") : s}m`)\n\t\t: Array.of(\"\", 40);\n\t\n\tif(error){\n\t\tconst {inspect} = require(\"util\");\n\t\tprocess.stderr.write(red + inspect(error) + reset + \"\\n\\n\");\n\t}\n\t\n\t// Underline all occurrences of target-file's name\n\tconst target = underline + file + noUnderline;\n\t\n\t// \"Not found\" -> \"package.json not found\"\n\tif(reason && !reason.match(file))\n\t\treason = (file + \" \")\n\t\t\t+ reason[0].toLowerCase()\n\t\t\t+ reason.substr(1);\n\t\n\t// Pedantic polishes\n\treason = reason\n\t\t.replace(/(?:\\r\\n|\\s)+/g,  \" \")\n\t\t.replace(/^\\s+|[.!]*\\s*$/g, \"\")\n\t\t.replace(/^(?!\\.$)/, \": \")\n\t\t.replace(file, target);\n\t\n\tconst output = `${red}Unable to finish installing Atom-Mocha${reason}${reset}\n\t\n\tThe following field must be added to your project's ${target} file:\n\t\n\t\t\"${key}\": \"${value}\"\n\t\n\tSee ${underline}README.md${reset} for setup instructions.\n\t\n\t`.replace(/^\\t/gm, \"\");\n\tprocess.stderr.write(output);\n\tprocess.exit(exitCode);\n}", "label": 3}
{"code": "function parallax(progress) {\n  var range = this.options.range || 0;\n  var offset = progress * range;        // TODO add provision for speed as well\n\n  this.transforms.position[1] = offset;   // just vertical for now\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, sslcipher resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslcipher addresources[] = new sslcipher[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new sslcipher();\n\t\t\t\taddresources[i].ciphergroupname = resources[i].ciphergroupname;\n\t\t\t\taddresources[i].ciphgrpalias = resources[i].ciphgrpalias;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function _getDurationsFromProperties(dimensions, coefficients, speedOfSound) {\n  let durations = new Float32Array(Utils.NUMBER_REVERB_FREQUENCY_BANDS);\n\n  // Sanitize inputs.\n  dimensions = _sanitizeDimensions(dimensions);\n  coefficients = _sanitizeCoefficients(coefficients);\n  if (speedOfSound == undefined) {\n    speedOfSound = Utils.DEFAULT_SPEED_OF_SOUND;\n  }\n\n  // Acoustic constant.\n  let k = Utils.TWENTY_FOUR_LOG10 / speedOfSound;\n\n  // Compute volume, skip if room is not present.\n  let volume = dimensions.width * dimensions.height * dimensions.depth;\n  if (volume < Utils.ROOM_MIN_VOLUME) {\n    return durations;\n  }\n\n  // Room surface area.\n  let leftRightArea = dimensions.width * dimensions.height;\n  let floorCeilingArea = dimensions.width * dimensions.depth;\n  let frontBackArea = dimensions.depth * dimensions.height;\n  let totalArea = 2 * (leftRightArea + floorCeilingArea + frontBackArea);\n  for (let i = 0; i < Utils.NUMBER_REVERB_FREQUENCY_BANDS; i++) {\n    // Effective absorptive area.\n    let absorbtionArea =\n      (coefficients.left[i] + coefficients.right[i]) * leftRightArea +\n      (coefficients.down[i] + coefficients.up[i]) * floorCeilingArea +\n      (coefficients.front[i] + coefficients.back[i]) * frontBackArea;\n    let meanAbsorbtionArea = absorbtionArea / totalArea;\n\n    // Compute reverberation using Eyring equation [1].\n    // [1] Beranek, Leo L. \"Analysis of Sabine and Eyring equations and their\n    //     application to concert hall audience and chair absorption.\" The\n    //     Journal of the Acoustical Society of America, Vol. 120, No. 3.\n    //     (2006), pp. 1399-1399.\n    durations[i] = Utils.ROOM_EYRING_CORRECTION_COEFFICIENT * k * volume /\n      (-totalArea * Math.log(1 - meanAbsorbtionArea) + 4 *\n      Utils.ROOM_AIR_ABSORPTION_COEFFICIENTS[i] * volume);\n  }\n  return durations;\n}", "label": 3}
{"code": "func (r *DrvRegistry) AddDriver(ntype string, fn InitFunc, config map[string]interface{}) error {\n\treturn fn(r, config)\n}", "label": 5}
{"code": "func (r *router) URLFor(name string, params ...interface{}) string {\n\troute := r.findRoute(name)\n\n\tif route == nil {\n\t\tpanic(\"route not found\")\n\t}\n\n\tvar args []string\n\tfor _, param := range params {\n\t\tswitch v := param.(type) {\n\t\tcase int:\n\t\t\targs = append(args, strconv.FormatInt(int64(v), 10))\n\t\tcase string:\n\t\t\targs = append(args, v)\n\t\tdefault:\n\t\t\tif v != nil {\n\t\t\t\tpanic(\"Arguments passed to URLFor must be integers or strings\")\n\t\t\t}\n\t\t}\n\t}\n\n\treturn route.URLWith(args)\n}", "label": 5}
{"code": "def update_voice_state(data)\n      user_id = data['user_id'].to_i\n\n      if data['channel_id']\n        unless @voice_states[user_id]\n          # Create a new voice state for the user\n          @voice_states[user_id] = VoiceState.new(user_id)\n        end\n\n        # Update the existing voice state (or the one we just created)\n        channel = @channels_by_id[data['channel_id'].to_i]\n        @voice_states[user_id].update(\n          channel,\n          data['mute'],\n          data['deaf'],\n          data['self_mute'],\n          data['self_deaf']\n        )\n      else\n        # The user is not in a voice channel anymore, so delete its voice state\n        @voice_states.delete(user_id)\n      end\n    end", "label": 4}
{"code": "func (r *StaticRoute) GetCopy() *StaticRoute {\n\td := GetIPNetCopy(r.Destination)\n\tnh := GetIPCopy(r.NextHop)\n\treturn &StaticRoute{Destination: d,\n\t\tRouteType: r.RouteType,\n\t\tNextHop:   nh,\n\t}\n}", "label": 5}
{"code": "func NewBee(name, factoryName, description string, options []BeeOption) Bee {\n\tc := BeeConfig{\n\t\tName:        name,\n\t\tClass:       factoryName,\n\t\tDescription: description,\n\t\tOptions:     options,\n\t}\n\tb := Bee{\n\t\tconfig:    c,\n\t\tSigChan:   make(chan bool),\n\t\twaitGroup: &sync.WaitGroup{},\n\t}\n\n\treturn b\n}", "label": 5}
{"code": "public static function createFromIso($iso, $options = null)\n    {\n        $params = static::parseIso8601($iso);\n\n        $instance = static::createFromArray($params);\n\n        if ($options !== null) {\n            $instance->setOptions($options);\n        }\n\n        return $instance;\n    }", "label": 2}
{"code": "def column_for_attribute(name)\n      filter = self.class.filters[name]\n      FilterColumn.intern(filter.database_column_type) if filter\n    end", "label": 4}
{"code": "public function listDocuments(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        $options += [\n            'parent' => $this->parentPath($this->name),\n            'collectionId' => $this->pathId($this->name),\n            'mask' => []\n        ];\n\n        return new ItemIterator(\n            new PageIterator(\n                function ($document) {\n                    return $this->documentFactory($document['name']);\n                },\n                [$this->connection, 'listDocuments'],\n                $options,\n                [\n                    'itemsKey' => 'documents',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "public static long count_filtered(nitro_service service, String servicename, filtervalue[] filter) throws Exception{\n\t\tgslbservice_dnsview_binding obj = new gslbservice_dnsview_binding();\n\t\tobj.set_servicename(servicename);\n\t\toptions option = new options();\n\t\toption.set_count(true);\n\t\toption.set_filter(filter);\n\t\tgslbservice_dnsview_binding[] response = (gslbservice_dnsview_binding[]) obj.getfiltered(service, option);\n\t\tif (response != null) {\n\t\t\treturn response[0].__count;\n\t\t}\n\t\treturn 0;\n\t}", "label": 0}
{"code": "public function frame($frame)\n    {\n        if ($frame instanceof WebDriverElement) {\n            $id = ['ELEMENT' => $frame->getID()];\n        } else {\n            $id = (string) $frame;\n        }\n\n        $params = ['id' => $id];\n        $this->executor->execute(DriverCommand::SWITCH_TO_FRAME, $params);\n\n        return $this->driver;\n    }", "label": 2}
{"code": "def get_as_datadict(self):\n        \"\"\"\n            Get data of this object as a data dictionary. Used by websocket service.\n        \"\"\"\n        d = super().get_as_datadict()\n        d.update(dict(status=self.status, data_type=self.data_type, editable=self.editable))\n        return d", "label": 1}
{"code": "function _gpfPow2 (n) {\n    var result = _gpfPow2[n];\n    if (result) {\n        return result;\n    }\n    result = _gpfComputePow2(n);\n    _gpfPow2[n] = result;\n    return result;\n}", "label": 3}
{"code": "def ban(user, message_days = 0, reason: nil)\n      API::Server.ban_user(@bot.token, @id, user.resolve_id, message_days, reason)\n    end", "label": 4}
{"code": "def sequence(name, *args, &block)\n      sequence = Sequence.new(name, *args, &block)\n      FactoryBot::Internal.register_inline_sequence(sequence)\n      add_attribute(name) { increment_sequence(sequence) }\n    end", "label": 4}
{"code": "public static base_response add(nitro_service client, dnsnsrec resource) throws Exception {\n\t\tdnsnsrec addresource = new dnsnsrec();\n\t\taddresource.domain = resource.domain;\n\t\taddresource.nameserver = resource.nameserver;\n\t\taddresource.ttl = resource.ttl;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def name_to_system_object(self, value):\n        \"\"\"\n        Return object for given name registered in System namespace.\n        \"\"\"\n        if not self.system:\n            raise SystemNotReady\n\n        if isinstance(value, (str, Object)):\n            rv = self.system.name_to_system_object(value)\n            return rv if rv else value\n        else:\n            return value", "label": 1}
{"code": "func HTTPBody(handler http.HandlerFunc, method, url string, values url.Values) string {\n\tw := httptest.NewRecorder()\n\treq, err := http.NewRequest(method, url+\"?\"+values.Encode(), nil)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\thandler(w, req)\n\treturn w.Body.String()\n}", "label": 5}
{"code": "def MAPGenoToTrans(parsedGTF,feature):\n    \"\"\"\n    Gets all positions of all bases in an exon\n\n    :param df: a Pandas dataframe with 'start','end', and 'strand' information for each entry.\n                df must contain 'seqname','feature','start','end','strand','frame','gene_id',\n                'transcript_id','exon_id','exon_number']\n    :param feature: feature upon wich to generate the map, eg. 'exon' or 'transcript'\n\n    :returns: a string with the comma separated positions of all bases in the exon\n    \"\"\"\n    GenTransMap=parsedGTF[parsedGTF[\"feature\"]==feature]\n    def getExonsPositions(df):\n        start=int(df[\"start\"])\n        stop=int(df[\"end\"])\n        strand=df[\"strand\"]\n        r=range(start,stop+1)\n        if strand==\"-\":\n            r.sort(reverse=True)\n        r=[ str(s) for s in r]\n        return \",\".join(r)\n\n    GenTransMap[\"feature_bases\"]=GenTransMap.apply(getExonsPositions, axis=1)\n    GenTransMap=GenTransMap.sort_values(by=[\"transcript_id\",\"exon_number\"],ascending=True)\n    def CombineExons(df):\n        return pd.Series(dict( feature_bases = ','.join(df['feature_bases']) ) )\n    GenTransMap=GenTransMap.groupby(\"transcript_id\").apply(CombineExons)\n    GenTransMap=GenTransMap.to_dict().get(\"feature_bases\")\n\n    return GenTransMap", "label": 1}
{"code": "def can(self, action, subject, **conditions):\n        \"\"\"\n        Check if the user has permission to perform a given action on an object\n        \"\"\"\n        for rule in self.relevant_rules_for_match(action, subject):\n            if rule.matches_conditions(action, subject, **conditions):\n                return rule.base_behavior\n        return False", "label": 1}
{"code": "public static aaauser_auditnslogpolicy_binding[] get(nitro_service service, String username) throws Exception{\n\t\taaauser_auditnslogpolicy_binding obj = new aaauser_auditnslogpolicy_binding();\n\t\tobj.set_username(username);\n\t\taaauser_auditnslogpolicy_binding response[] = (aaauser_auditnslogpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def setup_webserver():\n    '''Run setup tasks to set up a nicely configured webserver.\n\n    Features:\n     * owncloud service\n     * fdroid repository\n     * certificates via letsencrypt\n     * and more\n\n    The task is defined in file fabsetup_custom/fabfile_addtitions/__init__.py\n    and could be customized by Your own needs.  More info: README.md\n    '''\n    run('sudo apt-get update')\n    install_packages(packages_webserver)\n    execute(custom.latex)\n    execute(setup.solarized)\n    execute(setup.vim)\n    execute(setup.tmux)\n    checkup_git_repo_legacy(url='git@github.com:letsencrypt/letsencrypt.git')\n    execute(setup.service.fdroid)\n    execute(setup.service.owncloud)\n    # circumvent circular import, cf. http://stackoverflow.com/a/18486863\n    from fabfile import dfh, check_reboot\n    dfh()\n    check_reboot()", "label": 1}
{"code": "def add_recurrence_time(time)\n      return if time.nil?\n      rule = SingleOccurrenceRule.new(time)\n      add_recurrence_rule rule\n      time\n    end", "label": 4}
{"code": "public void bindSelect(PreparedStatement stmt, Identity oid, ClassDescriptor cld, boolean callableStmt) throws SQLException\r\n    {\r\n        ValueContainer[] values = null;\r\n        int i = 0;\r\n        int j = 0;\r\n\r\n        if (cld == null)\r\n        {\r\n            cld = m_broker.getClassDescriptor(oid.getObjectsRealClass());\r\n        }\r\n        try\r\n        {\r\n            if(callableStmt)\r\n            {\r\n                // First argument is the result set\r\n                m_platform.registerOutResultSet((CallableStatement) stmt, 1);\r\n                j++;\r\n            }\r\n\r\n            values = getKeyValues(m_broker, cld, oid);\r\n            for (/*void*/; i < values.length; i++, j++)\r\n            {\r\n                setObjectForStatement(stmt, j + 1, values[i].getValue(), values[i].getJdbcType().getType());\r\n            }\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            m_log.error(\"bindSelect failed for: \" + oid.toString() + \", PK: \" + i + \", value: \" + values[i]);\r\n            throw e;\r\n        }\r\n    }", "label": 0}
{"code": "def fetch_ticker(self) -> Ticker:\n        \"\"\"Fetch the market ticker.\"\"\"\n        return self._fetch('ticker', self.market.code)(self._ticker)()", "label": 1}
{"code": "function getTransformer(name, clientPlugin, pluginOptions) {\n\n    // if in cache, just return it\n    if (cache[name]) { return cache[name]; }\n\n    var transformers = clientPlugin.transformers;\n    var templateDir = clientPlugin.templateDir;\n\n    // if no transformer, throw error\n    if (!transformers[name]) { throw new Error('No transformer called ' + name); }\n\n    // generate all the transformers\n    _.each(transformers, function (transformer, transformerName) {\n        cache[transformerName] = generateTransformer(transformerName, transformer, templateDir, pluginOptions);\n    });\n\n    // return the specific one that was requested\n    return cache[name];\n}", "label": 3}
{"code": "def reserve\n      queues.each do |queue|\n        log_with_severity :debug, \"Checking #{queue}\"\n        if job = Resque.reserve(queue)\n          log_with_severity :debug, \"Found job on #{queue}\"\n          return job\n        end\n      end\n\n      nil\n    rescue Exception => e\n      log_with_severity :error, \"Error reserving job: #{e.inspect}\"\n      log_with_severity :error, e.backtrace.join(\"\\n\")\n      raise e\n    end", "label": 4}
{"code": "def id\n      id_attr = resource[:id]\n      return id_attr.to_s if id_attr.present? && id_attr.is_a?(::Valkyrie::ID) && !id_attr.blank?\n      return \"\" unless resource.respond_to?(:alternate_ids)\n      resource.alternate_ids.first.to_s\n    end", "label": 4}
{"code": "private void lockAndRegisterReferences(ClassDescriptor cld, Object sourceObject, int lockMode, List registeredObjects) throws LockNotGrantedException\r\n    {\r\n        if (implicitLocking)\r\n        {\r\n            Iterator i = cld.getObjectReferenceDescriptors(true).iterator();\r\n            while (i.hasNext())\r\n            {\r\n                ObjectReferenceDescriptor rds = (ObjectReferenceDescriptor) i.next();\r\n                Object refObj = rds.getPersistentField().get(sourceObject);\r\n                if (refObj != null)\r\n                {\r\n                    boolean isProxy = ProxyHelper.isProxy(refObj);\r\n                    RuntimeObject rt = isProxy ? new RuntimeObject(refObj, this, false) : new RuntimeObject(refObj, this);\r\n                    if (!registrationList.contains(rt.getIdentity()))\r\n                    {\r\n                        lockAndRegister(rt, lockMode, registeredObjects);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public function setSession($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\V1\\Session::class);\n        $this->session = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func ipToUint64(ip []byte) (value uint64) {\n\tcip := types.GetMinimalIP(ip)\n\tfor i := 0; i < len(cip); i++ {\n\t\tj := len(cip) - 1 - i\n\t\tvalue += uint64(cip[i]) << uint(j*8)\n\t}\n\treturn value\n}", "label": 5}
{"code": "def _handle_windows(self, event):\r\n        \"\"\"Windows key event handler.\"\"\"\r\n        vkey = self._keyname(event.GetKey())\r\n        if event.Message in self.KEYS_UP + self.KEYS_DOWN:\r\n            if vkey in self.MODIFIERNAMES:\r\n                self._realmodifiers[vkey] = event.Message in self.KEYS_DOWN\r\n                self._modifiers[self.MODIFIERNAMES[vkey]] = self._realmodifiers[vkey]\r\n        if event.Message not in self.KEYS_DOWN:\r\n            return True\r\n\r\n        is_altgr = False\r\n        if (vkey, event.IsExtended()) in self.NUMPAD_SPECIALS:\r\n            key = vkey = \"Numpad-\" + vkey\r\n        elif not event.Ascii or vkey.startswith(\"Numpad\"):\r\n            key = vkey\r\n        else:\r\n            is_altgr = event.Ascii in self.ALT_GRS\r\n            key = self._keyname(unichr(event.Ascii))\r\n\r\n        if DEBUG: print(\"Adding key %s (real %s)\" % (key.encode(\"utf-8\"), vkey.encode(\"utf-8\")))\r\n        self._output(type=\"keys\", key=key, realkey=vkey)\r\n\r\n        if vkey not in self.MODIFIERNAMES and not is_altgr:\r\n            modifier = \"-\".join(k for k in [\"Ctrl\", \"Alt\", \"Shift\", \"Win\"]\r\n                                if self._modifiers[k])\r\n            if modifier and modifier != \"Shift\": # Shift-X is not a combo\r\n                if self._modifiers[\"Ctrl\"] and event.Ascii:\r\n                    key = self._keyname(unichr(event.KeyID))\r\n                realmodifier = \"-\".join(k for k, v in self._realmodifiers.items() if v)\r\n                realkey = \"%s-%s\" % (realmodifier, key)\r\n                key = \"%s-%s\" % (modifier, key)\r\n                if DEBUG: print(\"Adding combo %s (real %s)\" % (key.encode(\"utf-8\"), realkey.encode(\"utf-8\")))\r\n                self._output(type=\"combos\", key=key, realkey=realkey)\r\n\r\n        if DEBUG:\r\n            print(\"CHARACTER: %r\" % key)\r\n            print('GetKey: {0}'.format(event.GetKey()))  # Name of the virtual keycode, str\r\n            print('IsAlt: {0}'.format(event.IsAlt()))  # Was the alt key depressed?, bool\r\n            print('IsExtended: {0}'.format(event.IsExtended()))  # Is this an extended key?, bool\r\n            print('IsInjected: {0}'.format(event.IsInjected()))  # Was this event generated programmatically?, bool\r\n            print('IsTransition: {0}'.format(event.IsTransition()))  #Is this a transition from up to down or vice versa?, bool\r\n            print('ASCII: {0}'.format(event.Ascii))  # ASCII value, if one exists, str\r\n            print('KeyID: {0}'.format(event.KeyID))  # Virtual key code, int\r\n            print('ScanCode: {0}'.format(event.ScanCode))  # Scan code, int\r\n            print('Message: {0}'.format(event.Message))  # Name of the virtual keycode, str\r\n            print()\r\n        return True", "label": 1}
{"code": "func (sink *RiemannSink) ExportData(dataBatch *core.DataBatch) {\n\tsink.Lock()\n\tdefer sink.Unlock()\n\n\tif sink.client == nil {\n\t\t// the client could be nil here, so we reconnect\n\t\tclient, err := riemannCommon.GetRiemannClient(sink.config)\n\t\tif err != nil {\n\t\t\tglog.Warningf(\"Riemann sink not connected: %v\", err)\n\t\t\treturn\n\t\t}\n\t\tsink.client = client\n\t}\n\n\tvar events []riemanngo.Event\n\n\tfor _, metricSet := range dataBatch.MetricSets {\n\t\thost := metricSet.Labels[core.LabelHostname.Key]\n\t\tfor metricName, metricValue := range metricSet.MetricValues {\n\t\t\tif value := metricValue.GetValue(); value != nil {\n\t\t\t\ttimestamp := dataBatch.Timestamp.Unix()\n\t\t\t\t// creates an event and add it to dataEvent\n\t\t\t\tevents = appendEvent(events, sink, host, metricName, value, metricSet.Labels, timestamp)\n\t\t\t}\n\t\t}\n\t\tfor _, metric := range metricSet.LabeledMetrics {\n\t\t\tif value := metric.GetValue(); value != nil {\n\t\t\t\tlabels := make(map[string]string)\n\t\t\t\tfor k, v := range metricSet.Labels {\n\t\t\t\t\tlabels[k] = v\n\t\t\t\t}\n\t\t\t\tfor k, v := range metric.Labels {\n\t\t\t\t\tlabels[k] = v\n\t\t\t\t}\n\t\t\t\ttimestamp := dataBatch.Timestamp.Unix()\n\t\t\t\t// creates an event and add it to dataEvent\n\t\t\t\tevents = appendEvent(events, sink, host, metric.Name, value, labels, timestamp)\n\t\t\t}\n\t\t}\n\t}\n\t// Send events to Riemann if events is not empty\n\tif len(events) > 0 {\n\t\terr := riemannCommon.SendData(sink.client, events)\n\t\tif err != nil {\n\t\t\tglog.Warningf(\"Error sending events to Riemann: %v\", err)\n\t\t\t// client will reconnect later\n\t\t\tsink.client = nil\n\t\t}\n\t}\n}", "label": 5}
{"code": "public static base_response update(nitro_service client, nsxmlnamespace resource) throws Exception {\n\t\tnsxmlnamespace updateresource = new nsxmlnamespace();\n\t\tupdateresource.prefix = resource.prefix;\n\t\tupdateresource.Namespace = resource.Namespace;\n\t\tupdateresource.description = resource.description;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public static function tap(callable $fn)\n    {\n        return function (callable $handler) use ($fn) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler, $fn) {\n                $fn($command, $request);\n                return $handler($command, $request);\n            };\n        };\n    }", "label": 2}
{"code": "function() {\n      this.listenTo(this.view, 'initialize:complete', this.__augmentViewPrepare);\n      this.listenTo(this.view, 'before-dispose-callback', this.__dispose);\n      _.each(eventMap, function(callback, event) {\n        this.listenTo(this.view, event, this[callback]);\n      }, this);\n    }", "label": 3}
{"code": "func (f *Fpdf) SetProtection(actionFlag byte, userPassStr, ownerPassStr string) {\n\tif f.err != nil {\n\t\treturn\n\t}\n\tf.protect.setProtection(actionFlag, userPassStr, ownerPassStr)\n}", "label": 5}
{"code": "public function deleteFromFamily($family)\n    {\n        $this->mutations[] = (new Mutation)\n            ->setDeleteFromFamily(\n                (new DeleteFromFamily)->setFamilyName($family)\n            );\n        return $this;\n    }", "label": 2}
{"code": "func SetRotationGetter(getter RotationGetter) ServerOption {\n\treturn func(s *Server) error {\n\t\ts.getRotation = getter\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "def render(*args)\n      arguments(args) do\n        assert_required ['text']\n      end\n      params = arguments.params\n      params['raw'] = true\n\n      post_request(\"markdown\", arguments.params)\n    end", "label": 4}
{"code": "def logger=(logger)\n      case logger\n      when false, nil then @logger = NullLogger.new\n      when true then @logger = default_logger\n      else\n        @logger = logger if logger.respond_to?(:info)\n      end\n    end", "label": 4}
{"code": "def tweak_css(repo_dir):\n    '''Comment out some css settings.'''\n    print_msg(\"* don't capitalize titles (no uppercase headings)\")\n    files = [\n        'beige.css', 'black.css', 'blood.css', 'league.css', 'moon.css',\n        'night.css', 'serif.css', 'simple.css', 'sky.css', 'solarized.css',\n        'white.css',\n    ]\n    line = '  text-transform: uppercase;'\n    for file_ in files:\n        update_or_append_line(filename=flo('{repo_dir}/css/theme/{file_}'),\n                              prefix=line, new_line=flo('/*{line}*/'))\n\n    print_msg('* images without border')\n    data = [\n        {'file': 'beige.css',     'line': '  border: 4px solid #333;'},\n        {'file': 'black.css',     'line': '  border: 4px solid #fff;'},\n        {'file': 'blood.css',     'line': '  border: 4px solid #eee;'},\n        {'file': 'league.css',    'line': '  border: 4px solid #eee;'},\n        {'file': 'moon.css',      'line': '  border: 4px solid #93a1a1;'},\n        {'file': 'night.css',     'line': '  border: 4px solid #eee;'},\n        {'file': 'serif.css',     'line': '  border: 4px solid #000;'},\n        {'file': 'simple.css',    'line': '  border: 4px solid #000;'},\n        {'file': 'sky.css',       'line': '  border: 4px solid #333;'},\n        {'file': 'solarized.css', 'line': '  border: 4px solid #657b83;'},\n        {'file': 'white.css',     'line': '  border: 4px solid #222;'},\n    ]\n    for item in data:\n        file_ = item['file']\n        lines = [item['line'], ]\n        lines.extend(['  box-shadow: 0 0 10px rgba(0, 0, 0, 0.15); }',\n                      '  box-shadow: 0 0 20px rgba(0, 0, 0, 0.55); }'])\n        for line in lines:\n            update_or_append_line(filename=flo('{repo_dir}/css/theme/{file_}'),\n                                  prefix=line, new_line=flo('/*{line}*/'))", "label": 1}
{"code": "func (f *file) lintContextArgs() {\n\tf.walk(func(n ast.Node) bool {\n\t\tfn, ok := n.(*ast.FuncDecl)\n\t\tif !ok || len(fn.Type.Params.List) <= 1 {\n\t\t\treturn true\n\t\t}\n\t\t// A context.Context should be the first parameter of a function.\n\t\t// Flag any that show up after the first.\n\t\tfor _, arg := range fn.Type.Params.List[1:] {\n\t\t\tif isPkgDot(arg.Type, \"context\", \"Context\") {\n\t\t\t\tf.errorf(fn, 0.9, link(\"https://golang.org/pkg/context/\"), category(\"arg-order\"), \"context.Context should be the first parameter of a function\")\n\t\t\t\tbreak // only flag one\n\t\t\t}\n\t\t}\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "func (roles Roles) Include(role Role) bool {\n\tfor _, r := range roles {\n\t\tif r == role {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "public void drawImage(Image img, Rectangle rect, Rectangle clipRect) {\n\t\tdrawImage(img, rect, clipRect, 1);\n\t}", "label": 0}
{"code": "function addAuthHeaders ({ \n  auth,\n  bearerToken, \n  headers, \n  overrideHeaders=false, \n}) {\n  if (overrideHeaders) return\n  if (bearerToken) return { \n    headers: { ...headers, Authorization: `Bearer ${ bearerToken }` } \n  }\n  if (auth) {\n    const username = auth.username || ''\n    const password = auth.password || ''\n    const encodedToken = Base64.btoa(`${ username }:${ password }`)\n    return {\n      headers: { ...headers, Authorization: `Basic ${ encodedToken }` }\n    }\n  }\n}", "label": 3}
{"code": "def geo_field(queryset):\n    \"\"\"Returns the GeometryField for a django or spillway GeoQuerySet.\"\"\"\n    for field in queryset.model._meta.fields:\n        if isinstance(field, models.GeometryField):\n            return field\n    raise exceptions.FieldDoesNotExist('No GeometryField found')", "label": 1}
{"code": "def to_bson(buffer = BSON::ByteBuffer.new, validating_keys = BSON::Config.validating_keys?)\n      as_json.to_bson(buffer)\n    end", "label": 4}
{"code": "def filtered_args(args)\n      return args if args.empty?\n\n      json_args = Normalizer.jsonify(args)\n\n      case unique_args_method\n      when Proc\n        filter_by_proc(json_args)\n      when Symbol\n        filter_by_symbol(json_args)\n      else\n        log_debug(\"#{__method__} arguments not filtered (using all arguments for uniqueness)\")\n        json_args\n      end\n    end", "label": 4}
{"code": "def legacy_interact(self, client, location, visit_url):\n        '''Implement LegacyInteractor.legacy_interact by obtaining\n        the discharge macaroon using the client's private key\n        '''\n        agent = self._find_agent(location)\n        # Shallow-copy the client so that we don't unexpectedly side-effect\n        # it by changing the key. Another possibility might be to\n        # set up agent authentication differently, in such a way that\n        # we're sure that client.key is the same as self._auth_info.key.\n        client = copy.copy(client)\n        client.key = self._auth_info.key\n        resp = client.request(\n            method='POST',\n            url=visit_url,\n            json={\n                'username': agent.username,\n                'public_key': str(self._auth_info.key.public_key),\n            },\n        )\n        if resp.status_code != 200:\n            raise httpbakery.InteractionError(\n                'cannot acquire agent macaroon from {}: {} (response body: {!r})'.format(visit_url, resp.status_code, resp.text))\n        if not resp.json().get('agent_login', False):\n            raise httpbakery.InteractionError('agent login failed')", "label": 1}
{"code": "function (item) {\n        item.value.sort(function (a, b) {\n            if (a.key < b.key) {\n                return -1;\n            }\n            /* istanbul ignore next */\n            // Below line exists only for the sake of completeness. Generally the array will\n            // always be sorted, and therefore it is impossible to get to this state in a test.\n            return a.key > b.key ? 1 : 0;\n        });\n        return item;\n    }", "label": 3}
{"code": "public SerialMessage getSupportedMessage() {\r\n\t\tlogger.debug(\"Creating new message for application command SENSOR_ALARM_SUPPORTED_GET for node {}\", this.getNode().getNodeId());\r\n\t\t\r\n\t\tif (this.getNode().getManufacturer() == 0x010F && this.getNode().getDeviceType() == 0x0501) {\r\n\t\t\tlogger.warn(\"Detected Fibaro FGBS001 Universal Sensor - this device fails to respond to SENSOR_ALARM_GET and SENSOR_ALARM_SUPPORTED_GET.\");\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\t\r\n\t\tSerialMessage result = new SerialMessage(this.getNode().getNodeId(), SerialMessage.SerialMessageClass.SendData, SerialMessage.SerialMessageType.Request, SerialMessage.SerialMessageClass.ApplicationCommandHandler, SerialMessage.SerialMessagePriority.Get);\r\n    \tbyte[] newPayload = { \t(byte) this.getNode().getNodeId(), \r\n    \t\t\t\t\t\t\t2, \r\n\t\t\t\t\t\t\t\t(byte) getCommandClass().getKey(), \r\n\t\t\t\t\t\t\t\t(byte) SENSOR_ALARM_SUPPORTED_GET };\r\n    \tresult.setMessagePayload(newPayload);\r\n    \treturn result;\t\t\r\n\t}", "label": 0}
{"code": "function getComments(id) {\n    $.ajax({\n     type: 'GET',\n     url: opts.getCommentsURL,\n     data: {node: id},\n     success: function(data, textStatus, request) {\n       var ul = $('#cl' + id);\n       var speed = 100;\n       $('#cf' + id)\n         .find('textarea[name=\"proposal\"]')\n         .data('source', data.source);\n\n       if (data.comments.length === 0) {\n         ul.html('<li>No comments yet.</li>');\n         ul.data('empty', true);\n       } else {\n         // If there are comments, sort them and put them in the list.\n         var comments = sortComments(data.comments);\n         speed = data.comments.length * 100;\n         appendComments(comments, ul);\n         ul.data('empty', false);\n       }\n       $('#cn' + id).slideUp(speed + 200);\n       ul.slideDown(speed);\n     },\n     error: function(request, textStatus, error) {\n       showError('Oops, there was a problem retrieving the comments.');\n     },\n     dataType: 'json'\n    });\n  }", "label": 3}
{"code": "protected function getDefaultHandlers()\n    {\n        return array(\n            '+' => new Handler\\StatusResponse(),\n            '-' => new Handler\\ErrorResponse(),\n            ':' => new Handler\\IntegerResponse(),\n            '$' => new Handler\\BulkResponse(),\n            '*' => new Handler\\MultiBulkResponse(),\n        );\n    }", "label": 2}
{"code": "func HasChrootCapability() bool {\n\t// Checking the capabilities should be enough, but in case there're\n\t// problem retrieving them, fallback checking for the effective uid\n\t// (hoping it hasn't dropped its CAP_SYS_CHROOT).\n\tcaps, err := capability.NewPid(0)\n\tif err == nil {\n\t\treturn caps.Get(capability.EFFECTIVE, capability.CAP_SYS_CHROOT)\n\t} else {\n\t\treturn os.Geteuid() == 0\n\t}\n}", "label": 5}
{"code": "def add_method(self, loop, callback):\n        \"\"\"Add a coroutine function\n\n        Args:\n            loop: The :class:`event loop <asyncio.BaseEventLoop>` instance\n                on which to schedule callbacks\n            callback: The :term:`coroutine function` to add\n        \"\"\"\n        f, obj = get_method_vars(callback)\n        wrkey = (f, id(obj))\n        self[wrkey] = obj\n        self.event_loop_map[wrkey] = loop", "label": 1}
{"code": "def add_var(self, var):\n        \"\"\" Adds a variable to the model.\n        \"\"\"\n        if var.name in [v.name for v in self.vars]:\n            logger.error(\"Variable set named '%s' already exists.\" % var.name)\n            return\n\n        var.i1 = self.var_N\n        var.iN = self.var_N + var.N - 1\n        self.vars.append(var)", "label": 1}
{"code": "func PgForeignTableByFtrelid(db XODB, ftrelid pgtypes.Oid) (*PgForeignTable, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, ftrelid, ftserver, ftoptions ` +\n\t\t`FROM pg_catalog.pg_foreign_table ` +\n\t\t`WHERE ftrelid = $1`\n\n\t// run query\n\tXOLog(sqlstr, ftrelid)\n\tpft := PgForeignTable{}\n\n\terr = db.QueryRow(sqlstr, ftrelid).Scan(&pft.Tableoid, &pft.Cmax, &pft.Xmax, &pft.Cmin, &pft.Xmin, &pft.Ctid, &pft.Ftrelid, &pft.Ftserver, &pft.Ftoptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pft, nil\n}", "label": 5}
{"code": "public function setFieldTransforms($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Firestore\\V1beta1\\DocumentTransform\\FieldTransform::class);\n        $this->field_transforms = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function calculateClockOffset() {\n  const start = Date.now();\n  let cur = start;\n  // Limit the iterations, just in case we're running in an environment where Date.now() has been mocked and is\n  // constant.\n  for (let i = 0; i < 1e6 && cur === start; i++) {\n    cur = Date.now();\n  }\n\n  // At this point |cur| \"just\" became equal to the next millisecond -- the unseen digits after |cur| are approximately\n  // all 0, and |cur| is the closest to the actual value of the UNIX time. Now, get the current global monotonic clock\n  // value and do the remaining calculations.\n\n  return cur - getGlobalMonotonicClockMS();\n}", "label": 3}
{"code": "function loadReactors() {\n        var reactors = {};\n        var reactorsDir = path.join(this.injector.rootDir, this.injector.servicesDir + '/reactors');\n\n        if (!fs.existsSync(reactorsDir)) {\n            return reactors;\n        }\n\n        var me = this;\n        var reactorNames = fs.readdirSync(reactorsDir);\n\n        _.each(reactorNames, function (reactorName) {\n            reactorName = reactorName.substring(0, reactorName.length - 3);\n            reactors[reactorName] = me.injector.loadModule(utils.getCamelCase(reactorName));\n        });\n\n        // add the reactors that come from plugins to the list\n        _.extend(reactors, this.injector.reactors);\n\n        return reactors;\n    }", "label": 3}
{"code": "function configurator (location) {\n  return !(location && fs.existsSync(location))\n    ? {}\n    : JSON.parse(\n        fs.readFileSync(location, 'UTF-8')\n          .replace(/\\/\\*[\\s\\S]*(?:\\*\\/)/g, '') // removes /* comments */\n          .replace(/\\/\\/[^\\n\\r]*/g, '') // removes // comments\n      );\n}", "label": 3}
{"code": "public void createInsertionSql(Database model, Platform platform, Writer writer) throws IOException\r\n    {\r\n        for (Iterator it = _beans.iterator(); it.hasNext();)\r\n        {\r\n            writer.write(platform.getInsertSql(model, (DynaBean)it.next()));\r\n            if (it.hasNext())\r\n            {\r\n                writer.write(\"\\n\");\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public static callhome get(nitro_service service) throws Exception{\n\t\tcallhome obj = new callhome();\n\t\tcallhome[] response = (callhome[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "function idGen(channel, info) {\n        var cid = channel.registry.generateClientId();\n        var cookies;\n        var ids;\n\n\n        // Return the id only if token was validated.\n        // More checks could be done here to ensure that token is unique in ids.\n        ids = channel.registry.getIds();\n        cookies = info.cookies;\n        if (cookies.player) {\n\n            if (!ids[cookies.player] || ids[cookies.player].disconnected) {\n                return cookies.player;\n            }\n            else {\n                console.log(\"already in ids\", cookies.player);\n                return false;\n            }\n        }\n    }", "label": 3}
{"code": "def launch(self, offer_id, tasks, filters=Filters()):\n        \"\"\"Launches the given set of tasks.\n\n        Any resources remaining (i.e., not used by the tasks or their executors)\n        will be considered declined.\n        The specified filters are applied on all unused resources (see\n        mesos.proto for a description of Filters). Available resources are\n        aggregated when multiple offers are provided. Note that all offers must\n        belong to the same slave. Invoking this function with an empty\n        collection of tasks declines the offers in entirety (see\n        Scheduler.decline).\n\n        Note that passing a single offer is also supported.\n        \"\"\"\n        logging.info('Launches tasks {}'.format(tasks))\n        return self.driver.launchTasks(encode(offer_id),\n                                       map(encode, tasks),\n                                       encode(filters))", "label": 1}
{"code": "public static base_response update(nitro_service client, vlan resource) throws Exception {\n\t\tvlan updateresource = new vlan();\n\t\tupdateresource.id = resource.id;\n\t\tupdateresource.aliasname = resource.aliasname;\n\t\tupdateresource.ipv6dynamicrouting = resource.ipv6dynamicrouting;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def CELERY_RESULT_BACKEND(self):\n        \"\"\"Redis result backend config\"\"\"\n\n        # allow specify directly\n        configured = get('CELERY_RESULT_BACKEND', None)\n        if configured:\n            return configured\n\n        if not self._redis_available():\n            return None\n\n        host, port = self.REDIS_HOST, self.REDIS_PORT\n\n        if host and port:\n            default = \"redis://{host}:{port}/{db}\".format(\n                    host=host, port=port,\n                    db=self.CELERY_REDIS_RESULT_DB)\n\n        return default", "label": 1}
{"code": "function (state, action) {\n    return _.defaults({\n      isValidating: action.isValidating,\n      lastAction: IS_VALIDATING\n    }, state)\n  }", "label": 3}
{"code": "public static base_response change(nitro_service client, sslcertkey resource) throws Exception {\n\t\tsslcertkey updateresource = new sslcertkey();\n\t\tupdateresource.certkey = resource.certkey;\n\t\tupdateresource.cert = resource.cert;\n\t\tupdateresource.key = resource.key;\n\t\tupdateresource.password = resource.password;\n\t\tupdateresource.fipskey = resource.fipskey;\n\t\tupdateresource.inform = resource.inform;\n\t\tupdateresource.passplain = resource.passplain;\n\t\tupdateresource.nodomaincheck = resource.nodomaincheck;\n\t\treturn updateresource.perform_operation(client,\"update\");\n\t}", "label": 0}
{"code": "public function build(Shape $shape, array $args)\n    {\n        $result = json_encode($this->format($shape, $args));\n\n        return $result == '[]' ? '{}' : $result;\n    }", "label": 2}
{"code": "def getFTPs(accessions, ftp, search, exclude, convert = False, threads = 1, attempt = 1,\n            max_attempts = 2):\n    \"\"\"\n    download genome info from NCBI\n    \"\"\"\n    info = wget(ftp)[0]\n    allMatches = []\n    for genome in open(info, encoding = 'utf8'):\n        genome = str(genome)\n        matches, genomeInfo = check(genome, accessions)\n        if genomeInfo is not False:\n            f = genomeInfo[0] + search\n            Gftp = genomeInfo[19]\n            Gftp = Gftp + '/' + search\n            allMatches.extend(matches)\n            yield (Gftp, f, exclude, matches)\n    # print accessions that could not be matched\n    # and whether or not they could be converted (optional)\n    newAccs = []\n    missing = accessions.difference(set(allMatches))\n    if convert is True:\n        pool = Pool(threads)\n        pool = pool.imap_unordered(searchAccession, missing)\n        for newAcc in tqdm(pool, total = len(missing)):\n            status, accession, newAcc = newAcc\n            if status is True:\n                newAccs.append(newAcc)\n            print('not found:', accession, '->', newAcc)\n    else:\n        for accession in missing:\n            print('not found:', accession)\n    # re-try after converting accessions (optional)\n    if len(newAccs) > 0 and attempt <= max_attempts:\n        print('convert accession attempt', attempt)\n        attempt += 1\n        for hit in getFTPs(set(newAccs), ftp, search, exclude, convert,\n                threads = 1, attempt = attempt):\n            yield hit", "label": 1}
{"code": "public function deleteSubscriber(string $channel): ?Subscriber\n    {\n        $key = self::SUBSCRIBER_KEY.\".{$channel}\";\n        $hasSubscriber = $this->cache->has($key);\n\n        $subscriber = $this->cache->get($key);\n\n        if ($hasSubscriber) {\n            $this->cache->forget($key);\n        }\n\n        return $subscriber;\n    }", "label": 2}
{"code": "function StdevFunction(win) {\n  var self = this, m, m2, d, n;\n  self.name = \"stdevs\";\n  self.type = \"simple\";\n  self.init = function() { m = 0, m2 = 0, d = 0, n = 0; };\n  self.accumulate = function(v) {\n    n+=1; \n    d = v - m;\n    m = m + d/n;\n    m2 = m2 + d*(v-m);\n  };\n  self.compensate = function(v) {\n    n-=1;\n    d = m - v;\n    m = d/n + m;\n    m2 = d*(v-m) + m2;\n  };\n  self.emit = function()  { return Math.sqrt(m2/(n-1)); };\n  self.make = function(win) { return new StdevFunction(win); };\n}", "label": 3}
{"code": "func SetChains(cs []Chain) {\n\tnewcs := []Chain{}\n\t// migrate old chain style\n\tfor _, c := range cs {\n\t\tfor _, el := range c.Elements {\n\t\t\tif el.Action.Name != \"\" {\n\t\t\t\tel.Action.ID = UUID()\n\t\t\t\tc.Actions = append(c.Actions, el.Action.ID)\n\t\t\t\tactions = append(actions, el.Action)\n\t\t\t}\n\t\t\tif el.Filter.Name != \"\" {\n\t\t\t\t//FIXME: migrate old style filters\n\t\t\t\tc.Filters = append(c.Filters, el.Filter.Options.Value.(string))\n\t\t\t}\n\t\t}\n\t\tc.Elements = []ChainElement{}\n\n\t\tnewcs = append(newcs, c)\n\t}\n\n\tchains = newcs\n}", "label": 5}
{"code": "func (cli *NetworkCli) CmdServicePublish(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"publish\", \"SERVICE[.NETWORK]\", \"Publish a new service on a network\", false)\n\tflAlias := opts.NewListOpts(netutils.ValidateAlias)\n\tcmd.Var(&flAlias, []string{\"-alias\"}, \"Add alias to self\")\n\tcmd.Require(flag.Exact, 1)\n\terr := cmd.ParseFlags(args, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsn, nn := parseServiceName(cmd.Arg(0))\n\tsc := serviceCreate{Name: sn, Network: nn, MyAliases: flAlias.GetAll()}\n\tobj, _, err := readBody(cli.call(\"POST\", \"/services\", sc, nil))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar replyID string\n\terr = json.Unmarshal(obj, &replyID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfmt.Fprintf(cli.out, \"%s\\n\", replyID)\n\treturn nil\n}", "label": 5}
{"code": "func OptionDefaultDriver(dd string) Option {\n\treturn func(c *Config) {\n\t\tlogrus.Debugf(\"Option DefaultDriver: %s\", dd)\n\t\tc.Daemon.DefaultDriver = strings.TrimSpace(dd)\n\t}\n}", "label": 5}
{"code": "def query_by_action(cls, action, argument=None):\n        \"\"\"Prepare query object with filtered action.\n\n        :param action: The action to deny.\n        :param argument: The action argument. If it's ``None`` then, if exists,\n            the ``action.argument`` will be taken. In the worst case will be\n            set as ``None``. (Default: ``None``)\n        :returns: A query object.\n        \"\"\"\n        query = cls.query.filter_by(action=action.value)\n        argument = argument or getattr(action, 'argument', None)\n        if argument is not None:\n            query = query.filter(db.or_(\n                cls.argument == str(argument),\n                cls.argument.is_(None),\n            ))\n        else:\n            query = query.filter(cls.argument.is_(None))\n        return query", "label": 1}
{"code": "func (l *localFileSystem) CreateFile(filePath string, length uint64) (io.WriteCloser, error) {\n\tf, err := os.Create(filePath)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn f, nil\n}", "label": 5}
{"code": "def remove(*models)\n      @connection.delete_by_id(\n        models.map { |model| Adapters::InstanceAdapter.adapt(model).index_id }\n      )\n    end", "label": 4}
{"code": "func (cn *connection) writer(keepAliveTimeout time.Duration) {\n\tvar (\n\t\tlastWrite      time.Time = time.Now()\n\t\tkeepAliveTimer *time.Timer\n\t)\n\tkeepAliveTimer = time.AfterFunc(keepAliveTimeout, func() {\n\t\tcn.mu().Lock()\n\t\tdefer cn.mu().Unlock()\n\t\tif time.Since(lastWrite) >= keepAliveTimeout {\n\t\t\tcn.tickleWriter()\n\t\t}\n\t\tkeepAliveTimer.Reset(keepAliveTimeout)\n\t})\n\tcn.mu().Lock()\n\tdefer cn.mu().Unlock()\n\tdefer cn.Close()\n\tdefer keepAliveTimer.Stop()\n\tfrontBuf := new(bytes.Buffer)\n\tfor {\n\t\tif cn.closed.IsSet() {\n\t\t\treturn\n\t\t}\n\t\tif cn.writeBuffer.Len() == 0 {\n\t\t\tcn.fillWriteBuffer(func(msg pp.Message) bool {\n\t\t\t\tcn.wroteMsg(&msg)\n\t\t\t\tcn.writeBuffer.Write(msg.MustMarshalBinary())\n\t\t\t\ttorrent.Add(fmt.Sprintf(\"messages filled of type %s\", msg.Type.String()), 1)\n\t\t\t\treturn cn.writeBuffer.Len() < 1<<16 // 64KiB\n\t\t\t})\n\t\t}\n\t\tif cn.writeBuffer.Len() == 0 && time.Since(lastWrite) >= keepAliveTimeout {\n\t\t\tcn.writeBuffer.Write(pp.Message{Keepalive: true}.MustMarshalBinary())\n\t\t\tpostedKeepalives.Add(1)\n\t\t}\n\t\tif cn.writeBuffer.Len() == 0 {\n\t\t\t// TODO: Minimize wakeups....\n\t\t\tcn.writerCond.Wait()\n\t\t\tcontinue\n\t\t}\n\t\t// Flip the buffers.\n\t\tfrontBuf, cn.writeBuffer = cn.writeBuffer, frontBuf\n\t\tcn.mu().Unlock()\n\t\tn, err := cn.w.Write(frontBuf.Bytes())\n\t\tcn.mu().Lock()\n\t\tif n != 0 {\n\t\t\tlastWrite = time.Now()\n\t\t\tkeepAliveTimer.Reset(keepAliveTimeout)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tif n != frontBuf.Len() {\n\t\t\tpanic(\"short write\")\n\t\t}\n\t\tfrontBuf.Reset()\n\t}\n}", "label": 5}
{"code": "function (member, memberValue, visibility) {\n        if (_GPF_VISIBILITY_STATIC === visibility) {\n            _gpfAssert(undefined === this._Constructor[member], \"Static members can't be overridden\");\n            this._Constructor[member] = memberValue;\n        } else if (\"constructor\" === member) {\n            this._addConstructor(memberValue, visibility);\n        } else {\n            this._addNonStaticMember(member, memberValue, visibility);\n        }\n    }", "label": 3}
{"code": "public static appfwprofile_xmlvalidationurl_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappfwprofile_xmlvalidationurl_binding obj = new appfwprofile_xmlvalidationurl_binding();\n\t\tobj.set_name(name);\n\t\tappfwprofile_xmlvalidationurl_binding response[] = (appfwprofile_xmlvalidationurl_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setJobLocation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\Location::class);\n        $this->job_location = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def pricing_tiers\n      @pricing_tiers ||= begin\n        r = request(:get, 'ra/apps/pricing/matrix')\n        data = parse_response(r, 'data')['pricingTiers']\n        data.map { |tier| Spaceship::Tunes::PricingTier.factory(tier) }\n      end\n    end", "label": 4}
{"code": "public boolean unlink(Object source, String attributeName, Object target)\r\n    {\r\n        return linkOrUnlink(false, source, attributeName, false);\r\n    }", "label": 0}
{"code": "function triggerEvent(el, type, options) {\n  if (isString(el)) {\n    options = type;\n    type = el;\n    el = document;\n  }\n\n  var e = createEvent(type, options);\n\n  el.dispatchEvent\n    ? el.dispatchEvent(e)\n    : el.fireEvent('on' + type, e);\n}", "label": 3}
{"code": "func (c *Manager) ListLibraryItemUpdateSession(ctx context.Context) (*[]string, error) {\n\turl := internal.URL(c, internal.LibraryItemUpdateSession)\n\tvar res []string\n\treturn &res, c.Do(ctx, url.Request(http.MethodGet), &res)\n}", "label": 5}
{"code": "public static gslbservice[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tgslbservice obj = new gslbservice();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tgslbservice[] response = (gslbservice[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def parse_time string\n      klass = class_loader.load 'Time'\n\n      date, time = *(string.split(/[ tT]/, 2))\n      (yy, m, dd) = date.match(/^(-?\\d{4})-(\\d{1,2})-(\\d{1,2})/).captures.map { |x| x.to_i }\n      md = time.match(/(\\d+:\\d+:\\d+)(?:\\.(\\d*))?\\s*(Z|[-+]\\d+(:\\d\\d)?)?/)\n\n      (hh, mm, ss) = md[1].split(':').map { |x| x.to_i }\n      us = (md[2] ? Rational(\"0.#{md[2]}\") : 0) * 1000000\n\n      time = klass.utc(yy, m, dd, hh, mm, ss, us)\n\n      return time if 'Z' == md[3]\n      return klass.at(time.to_i, us) unless md[3]\n\n      tz = md[3].match(/^([+\\-]?\\d{1,2})\\:?(\\d{1,2})?$/)[1..-1].compact.map { |digit| Integer(digit, 10) }\n      offset = tz.first * 3600\n\n      if offset < 0\n        offset -= ((tz[1] || 0) * 60)\n      else\n        offset += ((tz[1] || 0) * 60)\n      end\n\n      klass.new(yy, m, dd, hh, mm, ss+us/(1_000_000r), offset)\n    end", "label": 4}
{"code": "func (m *Manager) ValidateHost(ctx context.Context, ovfDescriptor string, host mo.Reference, vhp types.OvfValidateHostParams) (*types.OvfValidateHostResult, error) {\n\treq := types.ValidateHost{\n\t\tThis:          m.Reference(),\n\t\tOvfDescriptor: ovfDescriptor,\n\t\tHost:          host.Reference(),\n\t\tVhp:           vhp,\n\t}\n\n\tres, err := methods.ValidateHost(ctx, m.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &res.Returnval, nil\n}", "label": 5}
{"code": "function detectExtension() {\n  var mimeType = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var favoredExtension = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n\n  mimeType = mimeType.toString().toLowerCase().replace(/\\s/g, '');\n  if (!(mimeType in _listTypes.types)) {\n    return 'bin';\n  }\n\n  if (typeof _listTypes.types[mimeType] === 'string') {\n    return _listTypes.types[mimeType];\n  }\n\n  favoredExtension = favoredExtension.toString().toLowerCase().replace(/\\s/g, '');\n  if (favoredExtension && _listTypes.types[mimeType].includes(favoredExtension)) {\n    return favoredExtension;\n  }\n\n  // search for name match\n  var mimePart = mimeType.split('/')[1];\n  for (var i = 0, len = _listTypes.types[mimeType].length; i < len; i++) {\n    if (mimePart === _listTypes.types[mimeType][i]) {\n      return _listTypes.types[mimeType][i];\n    }\n  }\n\n  // use the first one\n  return _listTypes.types[mimeType][0];\n}", "label": 3}
{"code": "public function addAsFirstManipulations(Manipulations $manipulations) : self\n    {\n        $manipulationSequence = $manipulations->getManipulationSequence()->toArray();\n\n        $this->manipulations\n            ->getManipulationSequence()\n            ->mergeArray($manipulationSequence);\n\n        return $this;\n    }", "label": 2}
{"code": "def _structlog_default_keys_processor(logger_class, log_method, event):\n    ''' Add unique id, type and hostname '''\n    global HOSTNAME\n\n    if 'id' not in event:\n        event['id'] = '%s_%s' % (\n            datetime.utcnow().strftime('%Y%m%dT%H%M%S'),\n            uuid.uuid1().hex\n        )\n\n    if 'type' not in event:\n        event['type'] = 'log'\n\n    event['host'] = HOSTNAME\n\n    return event", "label": 1}
{"code": "def list_actions():\n    \"\"\"List all registered actions.\"\"\"\n    for name, action in _current_actions.items():\n        click.echo('{0}:{1}'.format(\n            name, '*' if hasattr(action, 'argument') else ''\n        ))", "label": 1}
{"code": "public function getConfig($key = null, $default = null)\n    {\n        if (is_null($key)) {\n            return $this->config->all();\n        }\n\n        if ($this->config->has($key)) {\n            return $this->config[$key];\n        }\n\n        return $default;\n    }", "label": 2}
{"code": "public function notifications(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $notification) {\n                    return new Notification(\n                        $this->connection,\n                        $notification['id'],\n                        $this->identity['bucket'],\n                        $notification + [\n                            'requesterProjectId' => $this->identity['userProject']\n                        ]\n                    );\n                },\n                [$this->connection, 'listNotifications'],\n                $options + $this->identity,\n                ['resultLimit' => $resultLimit]\n            )\n        );\n    }", "label": 2}
{"code": "private int bindStatementValue(PreparedStatement stmt, int index, Object attributeOrQuery, Object value, ClassDescriptor cld)\r\n            throws SQLException\r\n    {\r\n        FieldDescriptor fld = null;\r\n        // if value is a subQuery bind it\r\n        if (value instanceof Query)\r\n        {\r\n            Query subQuery = (Query) value;\r\n            return bindStatement(stmt, subQuery, cld.getRepository().getDescriptorFor(subQuery.getSearchClass()), index);\r\n        }\r\n\r\n        // if attribute is a subQuery bind it\r\n        if (attributeOrQuery instanceof Query)\r\n        {\r\n            Query subQuery = (Query) attributeOrQuery;\r\n            bindStatement(stmt, subQuery, cld.getRepository().getDescriptorFor(subQuery.getSearchClass()), index);\r\n        }\r\n        else\r\n        {\r\n            fld = cld.getFieldDescriptorForPath((String) attributeOrQuery);\r\n        }\r\n\r\n        if (fld != null)\r\n        {\r\n            // BRJ: use field conversions and platform\r\n            if (value != null)\r\n            {\r\n                m_platform.setObjectForStatement(stmt, index, fld.getFieldConversion().javaToSql(value), fld.getJdbcType().getType());\r\n            }\r\n            else\r\n            {\r\n                m_platform.setNullForStatement(stmt, index, fld.getJdbcType().getType());\r\n            }\r\n        }\r\n        else\r\n        {\r\n            if (value != null)\r\n            {\r\n                stmt.setObject(index, value);\r\n            }\r\n            else\r\n            {\r\n                stmt.setNull(index, Types.NULL);\r\n            }\r\n        }\r\n\r\n        return ++index; // increment before return\r\n    }", "label": 0}
{"code": "func (m *MockMath) Sum(arg0, arg1 int) int {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"Sum\", arg0, arg1)\n\tret0, _ := ret[0].(int)\n\treturn ret0\n}", "label": 5}
{"code": "def add_caveat(self, cav, key=None, loc=None):\n        '''Add a caveat to the macaroon.\n\n        It encrypts it using the given key pair\n        and by looking up the location using the given locator.\n        As a special case, if the caveat's Location field has the prefix\n        \"local \" the caveat is added as a client self-discharge caveat using\n        the public key base64-encoded in the rest of the location. In this\n        case, the Condition field must be empty. The resulting third-party\n        caveat will encode the condition \"true\" encrypted with that public\n        key.\n\n        @param cav the checkers.Caveat to be added.\n        @param key the public key to encrypt third party caveat.\n        @param loc locator to find information on third parties when adding\n        third party caveats. It is expected to have a third_party_info method\n        that will be called with a location string and should return a\n        ThirdPartyInfo instance holding the requested information.\n        '''\n        if cav.location is None:\n            self._macaroon.add_first_party_caveat(\n                self.namespace.resolve_caveat(cav).condition)\n            return\n        if key is None:\n            raise ValueError(\n                'no private key to encrypt third party caveat')\n        local_info = _parse_local_location(cav.location)\n        if local_info is not None:\n            info = local_info\n            if cav.condition is not '':\n                raise ValueError(\n                    'cannot specify caveat condition in '\n                    'local third-party caveat')\n            cav = checkers.Caveat(location='local', condition='true')\n        else:\n            if loc is None:\n                raise ValueError(\n                    'no locator when adding third party caveat')\n            info = loc.third_party_info(cav.location)\n\n        root_key = os.urandom(24)\n\n        # Use the least supported version to encode the caveat.\n        if self._version < info.version:\n            info = ThirdPartyInfo(\n                version=self._version,\n                public_key=info.public_key,\n            )\n\n        caveat_info = encode_caveat(\n            cav.condition, root_key, info, key, self._namespace)\n        if info.version < VERSION_3:\n            # We're encoding for an earlier client or third party which does\n            # not understand bundled caveat info, so use the encoded\n            # caveat information as the caveat id.\n            id = caveat_info\n        else:\n            id = self._new_caveat_id(self._caveat_id_prefix)\n            self._caveat_data[id] = caveat_info\n\n        self._macaroon.add_third_party_caveat(cav.location, root_key, id)", "label": 1}
{"code": "public function setEntityTypeNames($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->entity_type_names = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func MarshalNamespace(resource Namespace, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif !cfg.PreserveResourceID {\n\t\t// avoid modifying the original object\n\t\t// to prevent unexpected data races\n\t\tcopy := resource\n\t\tcopy.SetResourceID(0)\n\t\tresource = copy\n\t}\n\treturn utils.FastMarshal(resource)\n}", "label": 5}
{"code": "func (a *hmacAnonymizer) Anonymize(data []byte) string {\n\th := hmac.New(sha256.New, []byte(a.key))\n\th.Write(data)\n\treturn base64.StdEncoding.EncodeToString(h.Sum(nil))\n}", "label": 5}
{"code": "function checkStrictModeIdentifier(node) {\n            if (inStrictMode &&\n                node.originalKeywordKind >= 106 /* FirstFutureReservedWord */ &&\n                node.originalKeywordKind <= 114 /* LastFutureReservedWord */ &&\n                !ts.isIdentifierName(node) &&\n                !ts.isInAmbientContext(node)) {\n                // Report error only if there are no parse errors in file\n                if (!file.parseDiagnostics.length) {\n                    file.bindDiagnostics.push(ts.createDiagnosticForNode(node, getStrictModeIdentifierMessage(node), ts.declarationNameToString(node)));\n                }\n            }\n        }", "label": 3}
{"code": "func AuthUserUserPermissionByID(db XODB, id int) (*AuthUserUserPermission, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, user_id, permission_id ` +\n\t\t`FROM public.auth_user_user_permissions ` +\n\t\t`WHERE id = $1`\n\n\t// run query\n\tXOLog(sqlstr, id)\n\tauup := AuthUserUserPermission{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, id).Scan(&auup.ID, &auup.UserID, &auup.PermissionID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &auup, nil\n}", "label": 5}
{"code": "async def load_string(reader):\n    \"\"\"\n    Loads string from binary stream\n\n    :param reader:\n    :return:\n    \"\"\"\n    ivalue = await load_varint(reader)\n    fvalue = bytearray(ivalue)\n    await reader.areadinto(fvalue)\n    return bytes(fvalue)", "label": 1}
{"code": "public function unknown_positionals( $args ) {\n\t\t$positional_repeating = $this->query_spec(\n\t\t\tarray(\n\t\t\t\t'type'      => 'positional',\n\t\t\t\t'repeating' => true,\n\t\t\t)\n\t\t);\n\n\t\t// At least one positional supports as many as possible.\n\t\tif ( ! empty( $positional_repeating ) ) {\n\t\t\treturn array();\n\t\t}\n\n\t\t$positional = $this->query_spec(\n\t\t\tarray(\n\t\t\t\t'type'      => 'positional',\n\t\t\t\t'repeating' => false,\n\t\t\t)\n\t\t);\n\n\t\treturn array_slice( $args, count( $positional ) );\n\t}", "label": 2}
{"code": "func (a *TestAuthServer) NewCertificate(identity TestIdentity) (*tls.Certificate, error) {\n\tcert, key, err := GenerateCertificate(a.AuthServer, identity)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttlsCert, err := tls.X509KeyPair(cert, key)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &tlsCert, nil\n}", "label": 5}
{"code": "def _register_template(cls, template_bytes):\n    '''Registers the template for the widget and hooks init_template'''\n\n    # This implementation won't work if there are nested templates, but\n    # we can't do that anyways due to PyGObject limitations so it's ok\n\n    if not hasattr(cls, 'set_template'):\n        raise TypeError(\"Requires PyGObject 3.13.2 or greater\")\n\n    cls.set_template(template_bytes)\n\n    bound_methods = set()\n    bound_widgets = set()\n\n    # Walk the class, find marked callbacks and child attributes\n    for name in dir(cls):\n        o = getattr(cls, name, None)\n\n        if inspect.ismethod(o):\n            if hasattr(o, '_gtk_callback'):\n                bound_methods.add(name)\n                # Don't need to call this, as connect_func always gets called\n                #cls.bind_template_callback_full(name, o)\n        elif isinstance(o, _Child):\n            cls.bind_template_child_full(name, True, 0)\n            bound_widgets.add(name)\n\n    # Have to setup a special connect function to connect at template init\n    # because the methods are not bound yet\n    cls.set_connect_func(_connect_func, cls)\n\n    cls.__gtemplate_methods__ = bound_methods\n    cls.__gtemplate_widgets__ = bound_widgets\n\n    base_init_template = cls.init_template\n    cls.init_template = lambda s: _init_template(s, cls, base_init_template)", "label": 1}
{"code": "function isRekord(x)\n{\n  return !!(x && x.Database && isFunction( x ) && x.prototype instanceof Model);\n}", "label": 3}
{"code": "function collectUniqNodes(list, func) {\n    var result = [];\n    var nodeIds = {};\n    var currentNodeId;\n\n    flexiEach(list, function(value) {\n      flexiEach(func(value), function(node) {\n        if (!nodeIds[currentNodeId = getNodeId(node)]) {\n          result.push(node);\n          nodeIds[currentNodeId] = true;\n        }\n      });\n    });\n    return result;\n  }", "label": 3}
{"code": "func (r *Rotation) LastRotatedDescription() string {\n\tif r.LastRotated.IsZero() {\n\t\treturn \"never updated\"\n\t}\n\treturn fmt.Sprintf(\"last rotated %v\", r.LastRotated.Format(teleport.HumanDateFormatSeconds))\n}", "label": 5}
{"code": "function run_callbacks (object, key) {\n  var callbacks = object[key];\n  var callback;\n  // Mark the module is ready\n  // `delete module.c` is not safe\n  // #135\n  // Android 2.2 might treat `null` as [object Global] and equal it to true,\n  // So, never confuse `null` and `false`\n  object[key] = FALSE;\n  while(callback = callbacks.pop()){\n    callback();\n  }\n}", "label": 3}
{"code": "function cssobj$1 (obj, config, state) {\n  config = config || {};\n\n  var local = config.local;\n  config.local = !local\n    ? {space: ''}\n  : local && typeof local === 'object' ? local : {};\n\n  config.plugins = [].concat(\n    config.plugins || [],\n    cssobj_plugin_selector_localize(config.local),\n    cssobj_plugin_post_cssom(config.cssom)\n  );\n\n  return cssobj(config)(obj, state)\n}", "label": 3}
{"code": "function getValue(fromObject, fromKey) {\n  var regDot = /\\./g\n    , regFinishArray = /.+(\\[\\])/g\n    , keys\n    , key\n    , result\n    , lastValue\n    ;\n\n  keys = fromKey.split(regDot);\n  key = keys.splice(0, 1);\n\n  result = _getValue(fromObject, key[0], keys);\n\n  return handleArrayOfUndefined_(result);\n}", "label": 3}
{"code": "protected void addTagging(boolean seen, IntTaggedWord itw, double count) {\r\n    if (seen) {\r\n      seenCounter.incrementCount(itw, count);\r\n      if (itw.tag() == nullTag) {\r\n        words.add(itw);\r\n      } else if (itw.word() == nullWord) {\r\n        tags.add(itw);\r\n      } else {\r\n        // rules.add(itw);\r\n      }\r\n    } else {\r\n      uwModel.addTagging(seen, itw, count);\r\n      // if (itw.tag() == nullTag) {\r\n      // sigs.add(itw);\r\n      // }\r\n    }\r\n  }", "label": 0}
{"code": "private Object[] convert(FieldConversion[] fcs, Object[] values)\r\n    {\r\n        Object[] convertedValues = new Object[values.length];\r\n        \r\n        for (int i= 0; i < values.length; i++)\r\n        {\r\n            convertedValues[i] = fcs[i].sqlToJava(values[i]);\r\n        }\r\n\r\n        return convertedValues;\r\n    }", "label": 0}
{"code": "public function run()\n    {\n        $this->setupSignalHandlers();\n\n        $procs = [];\n        while (true) {\n            $jobs = $this->runner->getJobs();\n            foreach ($jobs as $job) {\n                if (! array_key_exists($job->identifier(), $procs)) {\n                    $procs[$job->identifier()] = [];\n                }\n                while (count($procs[$job->identifier()]) > $job->numWorkers()) {\n                    // Stopping an excessive child.\n                    echo 'Stopping an excessive child.' . PHP_EOL;\n                    $proc = array_pop($procs[$job->identifier()]);\n                    $status = proc_get_status($proc);\n                    // Keep sending SIGTERM until the child exits.\n                    while ($status['running'] === true) {\n                        @proc_terminate($proc);\n                        usleep(50000);\n                        $status = proc_get_status($proc);\n                    }\n                    @proc_close($proc);\n                }\n                for ($i = 0; $i < $job->numWorkers(); $i++) {\n                    $needStart = false;\n                    if (array_key_exists($i, $procs[$job->identifier()])) {\n                        $status = proc_get_status($procs[$job->identifier()][$i]);\n                        if ($status['running'] !== true) {\n                            $needStart = true;\n                        }\n                    } else {\n                        $needStart = true;\n                    }\n                    if ($needStart) {\n                        echo 'Starting a child.' . PHP_EOL;\n                        $procs[$job->identifier()][$i] = proc_open(\n                            sprintf('%s %d', $this->command, $job->id()),\n                            $this->descriptorSpec,\n                            $pipes\n                        );\n                    }\n                }\n            }\n            usleep(1000000); // Reload the config after 1 second\n            pcntl_signal_dispatch();\n            if ($this->shutdown) {\n                echo 'Shutting down, waiting for the children' . PHP_EOL;\n                foreach ($procs as $k => $v) {\n                    foreach ($v as $proc) {\n                        $status = proc_get_status($proc);\n                        // Keep sending SIGTERM until the child exits.\n                        while ($status['running'] === true) {\n                            @proc_terminate($proc);\n                            usleep(50000);\n                            $status = proc_get_status($proc);\n                        }\n                        @proc_close($proc);\n                    }\n                }\n                echo 'BatchDaemon exiting' . PHP_EOL;\n                exit;\n            }\n            // Reload the config\n            $this->runner->loadConfig();\n        }\n    }", "label": 2}
{"code": "public function setHotwordRule($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CustomInfoType_DetectionRule_HotwordRule::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def save\n      return update! if id\n\n      from_response(client.post(\"/checklists\", {\n        name: name,\n        idCard: card_id\n      }))\n    end", "label": 4}
{"code": "function OpenEventObserver(clientPort, serverPort) {\n    events.EventEmitter.call(this);\n\n    this.isClientPortOpen = false;\n    this.isServerPortOpen = false;\n\n    clientPort.on('open', this._clientPortOpenHandler(this));\n    serverPort.on('open', this._serverPortOpenHandler(this));\n}", "label": 3}
{"code": "private function updatePrefixes()\n    {\n        foreach ($this->page['prefixes'] as $prefix) {\n            if (!in_array($prefix, $this->prefixes)) {\n                $this->prefixes[] = $prefix;\n            }\n        }\n    }", "label": 2}
{"code": "func (c *remoteConn) findAndSend() error {\n\t// Find all proxies that don't have a connection to a remote agent. If all\n\t// proxies have connections, return right away.\n\tdisconnectedProxies, err := c.findDisconnectedProxies()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif len(disconnectedProxies) == 0 {\n\t\treturn nil\n\t}\n\n\tc.log.Debugf(\"Proxy %v sending %v discovery request with tunnel ID: %v and disconnected proxies: %v.\",\n\t\tc.proxyName, string(c.tunnelType), c.tunnelID, Proxies(disconnectedProxies))\n\n\treq := discoveryRequest{\n\t\tTunnelID: c.tunnelID,\n\t\tType:     string(c.tunnelType),\n\t\tProxies:  disconnectedProxies,\n\t}\n\n\terr = c.sendDiscoveryRequests(req)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function pathString()\n    {\n        $out = [];\n        foreach ($this->fieldNames as $part) {\n            $out[] = $this->escapePathPart($part);\n        }\n\n        $fieldPath = implode('.', $out);\n\n        return $fieldPath;\n    }", "label": 2}
{"code": "public static base_response flush(nitro_service client, nssimpleacl resource) throws Exception {\n\t\tnssimpleacl flushresource = new nssimpleacl();\n\t\tflushresource.estsessions = resource.estsessions;\n\t\treturn flushresource.perform_operation(client,\"flush\");\n\t}", "label": 0}
{"code": "def extract_key(ctx)\n      parts = []\n      # fetching from cred provider directly gives warnings\n      parts << ctx.config.credentials.credentials.access_key_id\n      if _endpoint_operation_identifier(ctx)\n        parts << ctx.operation_name\n        ctx.operation.input.shape.members.inject(parts) do |p, (name, ref)|\n          p << ctx.params[name] if ref[\"endpointdiscoveryid\"]\n          p\n        end\n      end\n      parts.join('_')\n    end", "label": 4}
{"code": "def get_pipeline_inputs(job, input_flag, input_file, encryption_key=None, per_file_encryption=False,\n                        gdc_download_token=None):\n    \"\"\"\n    Get the input file from s3 or disk and write to file store.\n\n    :param str input_flag: The name of the flag\n    :param str input_file: The value passed in the config file\n    :param str encryption_key: Path to the encryption key if encrypted with sse-c\n    :param bool per_file_encryption: If encrypted, was the file encrypted using the per-file method?\n    :param str gdc_download_token: The download token to obtain files from the GDC\n    :return: fsID for the file\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    job.fileStore.logToMaster('Obtaining file (%s) to the file job store' % input_flag)\n    if input_file.startswith(('http', 'https', 'ftp')):\n        input_file = get_file_from_url(job, input_file, encryption_key=encryption_key,\n                                       per_file_encryption=per_file_encryption,\n                                       write_to_jobstore=True)\n    elif input_file.startswith(('S3', 's3')):\n        input_file = get_file_from_s3(job, input_file, encryption_key=encryption_key,\n                                      per_file_encryption=per_file_encryption,\n                                      write_to_jobstore=True)\n    elif input_file.startswith(('GDC', 'gdc')):\n        input_file = get_file_from_gdc(job, input_file, gdc_download_token=gdc_download_token,\n                                       write_to_jobstore=True)\n    else:\n        assert os.path.exists(input_file), 'Bogus Input : ' + input_file\n        input_file = job.fileStore.writeGlobalFile(input_file)\n    return input_file", "label": 1}
{"code": "protected function shouldEagerLoad($response)\n    {\n        if ($response instanceof IlluminatePaginator) {\n            $response = $response->getCollection();\n        }\n\n        return $response instanceof EloquentCollection && $this->eagerLoading;\n    }", "label": 2}
{"code": "public function setPrompts($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->prompts = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *PresenceService) GetNamespace(name string) (*services.Namespace, error) {\n\tif name == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing namespace name\")\n\t}\n\titem, err := s.Get(context.TODO(), backend.Key(namespacesPrefix, name, paramsPrefix))\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn nil, trace.NotFound(\"namespace %q is not found\", name)\n\t\t}\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.UnmarshalNamespace(\n\t\titem.Value, services.WithResourceID(item.ID), services.WithExpires(item.Expires))\n}", "label": 5}
{"code": "def connect(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Open proxy connection to a device's management interface.\n\n        :param id: Device ID as an int.\n        :return: :class:`devices.Connection <devices.Connection>` object\n        :rtype: devices.Connection\n        \"\"\"\n        schema = ConnectionSchema()\n        resp = self.service.post(self.base+str(id)+'/connect/')\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public function write($entry, array $options = [])\n    {\n        $entryOptions = $this->pluckArray($this->entryOptions, $options);\n        $this->writeBatch(\n            [$this->handleEntry($entry, $entryOptions)],\n            $options\n        );\n    }", "label": 2}
{"code": "public function setCertifications($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\Certification::class);\n        $this->certifications = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *Manager) AddLibraryItemFileFromURI(\n\tctx context.Context,\n\tsessionID, fileName, uri string) (*UpdateFileInfo, error) {\n\n\tn, fingerprint, err := GetContentLengthAndFingerprint(ctx, uri)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tinfo, err := c.AddLibraryItemFile(ctx, sessionID, UpdateFile{\n\t\tName:       fileName,\n\t\tSourceType: \"PULL\",\n\t\tSize:       &n,\n\t\tSourceEndpoint: &SourceEndpoint{\n\t\t\tURI:                      uri,\n\t\t\tSSLCertificateThumbprint: fingerprint,\n\t\t},\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn info, c.CompleteLibraryItemUpdateSession(ctx, sessionID)\n}", "label": 5}
{"code": "private static <E> void loadIntoCounter(String filename, Class<E> c, Counter<E> counter) throws RuntimeException {\r\n    try {\r\n      Constructor<E> m = c.getConstructor(String.class);\r\n      BufferedReader in = IOUtils.getBufferedFileReader(filename);// new\r\n                                                                  // BufferedReader(new\r\n                                                                  // FileReader(filename));\r\n      String line = in.readLine();\r\n      while (line != null && line.length() > 0) {\r\n        int endPos = Math.max(line.lastIndexOf(' '), line.lastIndexOf('\\t'));\r\n\r\n        counter.setCount(m.newInstance(line.substring(0, endPos).trim()), Double.parseDouble(line.substring(endPos, line.length()).trim()));\r\n\r\n        line = in.readLine();\r\n      }\r\n      in.close();\r\n    } catch (Exception e) {\r\n      throw new RuntimeException(e);\r\n    }\r\n  }", "label": 0}
{"code": "def url_request(url)\n      uri = URI.parse(url)\n      http = Net::HTTP.new(uri.host, uri.port)\n      http.use_ssl = true\n      http.verify_mode = ::OpenSSL::SSL::VERIFY_NONE\n\n      request = Net::HTTP::Get.new(uri.request_uri)\n\n      response = http.request(request)\n      raise ArgumentError, \"Fail to get response of #{url}\" unless %w[200 302].include?(response.code)\n\n      response.code == '302' ? response['location'] : response.body\n    rescue NoMethodError, SocketError, ArgumentError => e\n      OneGadget::Logger.error(e.message)\n      nil\n    end", "label": 4}
{"code": "function providePromise(obj, providePromiseName) {\n    if(!isString(providePromiseName)) {\n      throw new Error('Must provide string as name of promised module');\n    }\n    di.annotate(obj, new di.ProvidePromise(providePromiseName));\n  }", "label": 3}
{"code": "func (ca *CertAuthorityV2) SetCheckingKeys(keys [][]byte) error {\n\tca.Spec.CheckingKeys = keys\n\treturn nil\n}", "label": 5}
{"code": "def _create_payload(self, symbols):\n        \"\"\" Creates a payload with no none values.\n\n        :param symbols: currency symbols to request specific exchange rates.\n        :type symbols: list or tuple\n        :return: a payload.\n        :rtype: dict\n        \"\"\"\n        payload = {'access_key': self.access_key}\n        if symbols is not None:\n            payload['symbols'] = ','.join(symbols)\n\n        return payload", "label": 1}
{"code": "function _bigintcmp(a, b) {\n        // The following code is a bit tricky to avoid code branching\n        var c, abs_r, mask;\n        var r = 0;\n        for (c = 15; c >= 0; c--) {\n            var x = a[c];\n            var y = b[c];\n            r = r + (x - y) * (1 - r * r);\n            // http://graphics.stanford.edu/~seander/bithacks.html#IntegerAbs\n            // correct for [-294967295, 294967295]\n            mask = r >> 31;\n            abs_r = (r + mask) ^ mask;\n            // http://stackoverflow.com/questions/596467/how-do-i-convert-a-number-to-an-integer-in-javascript\n            // this rounds towards zero\n            r = ~~((r << 1) / (abs_r + 1));\n        }\n        return r;\n    }", "label": 3}
{"code": "def fetch_program_license_agreement_messages\n      all_messages = []\n\n      messages_request = request(:get, \"https://appstoreconnect.apple.com/olympus/v1/contractMessages\")\n      body = messages_request.body\n      if body\n        body = JSON.parse(body) if body.kind_of?(String)\n        body.map do |messages|\n          all_messages.push(messages[\"message\"])\n        end\n      end\n\n      return all_messages\n    end", "label": 4}
{"code": "async function renderSass (opts = {}) {\n  const tpl = await fs.readFile(path.resolve(__dirname, 'sass.ejs'), 'utf8');\n  return ejs.render(tpl, opts);\n}", "label": 3}
{"code": "public static base_responses unset(nitro_service client, String name[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (name != null && name.length > 0) {\n\t\t\tclusternodegroup unsetresources[] = new clusternodegroup[name.length];\n\t\t\tfor (int i=0;i<name.length;i++){\n\t\t\t\tunsetresources[i] = new clusternodegroup();\n\t\t\t\tunsetresources[i].name = name[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "private WmsLayer getLayer(String layerId) {\n\t\tRasterLayer layer = configurationService.getRasterLayer(layerId);\n\t\tif (layer instanceof WmsLayer) {\n\t\t\treturn (WmsLayer) layer;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "func (c *TopCommand) Top(client *roundtrip.Client) error {\n\tif err := ui.Init(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdefer ui.Close()\n\n\tctx, cancel := context.WithCancel(context.TODO())\n\tdefer cancel()\n\n\tuiEvents := ui.PollEvents()\n\tticker := time.NewTicker(*c.refreshPeriod)\n\tdefer ticker.Stop()\n\n\t// fetch and render first time\n\tvar prev *Report\n\tre, err := c.fetchAndGenerateReport(ctx, client, nil)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tlastTab := \"\"\n\tif err := c.render(ctx, *re, lastTab); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tfor {\n\t\tselect {\n\t\tcase e := <-uiEvents:\n\t\t\tswitch e.ID { // event string/identifier\n\t\t\tcase \"q\", \"<C-c>\": // press 'q' or 'C-c' to quit\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif e.ID == \"1\" || e.ID == \"2\" || e.ID == \"3\" {\n\t\t\t\tlastTab = e.ID\n\t\t\t}\n\t\t\t// render previously fetched data on the resize event\n\t\t\tif re != nil {\n\t\t\t\tif err := c.render(ctx, *re, lastTab); err != nil {\n\t\t\t\t\treturn trace.Wrap(err)\n\t\t\t\t}\n\t\t\t}\n\t\tcase <-ticker.C:\n\t\t\t// fetch data and re-render on ticker\n\t\t\tprev = re\n\t\t\tre, err = c.fetchAndGenerateReport(ctx, client, prev)\n\t\t\tif err != nil {\n\t\t\t\treturn trace.Wrap(err)\n\t\t\t}\n\t\t\tif err := c.render(ctx, *re, lastTab); err != nil {\n\t\t\t\treturn trace.Wrap(err)\n\t\t\t}\n\t\t}\n\t}\n}", "label": 5}
{"code": "func PgAmopByAmopoprAmoppurposeAmopfamily(db XODB, amopopr pgtypes.Oid, amoppurpose uint8, amopfamily pgtypes.Oid) (*PgAmop, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, amopfamily, amoplefttype, amoprighttype, amopstrategy, amoppurpose, amopopr, amopmethod, amopsortfamily ` +\n\t\t`FROM pg_catalog.pg_amop ` +\n\t\t`WHERE amopopr = $1 AND amoppurpose = $2 AND amopfamily = $3`\n\n\t// run query\n\tXOLog(sqlstr, amopopr, amoppurpose, amopfamily)\n\tpa := PgAmop{}\n\n\terr = db.QueryRow(sqlstr, amopopr, amoppurpose, amopfamily).Scan(&pa.Tableoid, &pa.Cmax, &pa.Xmax, &pa.Cmin, &pa.Xmin, &pa.Oid, &pa.Ctid, &pa.Amopfamily, &pa.Amoplefttype, &pa.Amoprighttype, &pa.Amopstrategy, &pa.Amoppurpose, &pa.Amopopr, &pa.Amopmethod, &pa.Amopsortfamily)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "func (ep *endpoint) isServiceEnabled() bool {\n\tep.Lock()\n\tdefer ep.Unlock()\n\treturn ep.serviceEnabled\n}", "label": 5}
{"code": "func SqQueryColumns(args *internal.ArgType, inspect []string) ([]*models.Column, error) {\n\tvar err error\n\n\t// create temporary view xoid\n\txoid := \"_xo_\" + internal.GenRandomID()\n\tviewq := `CREATE TEMPORARY VIEW ` + xoid + ` AS ` + strings.Join(inspect, \"\\n\")\n\tmodels.XOLog(viewq)\n\t_, err = args.DB.Exec(viewq)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// load column information\n\treturn SqTableColumns(args.DB, \"\", xoid)\n}", "label": 5}
{"code": "def dict_to_htmlrow(d):\n    \"\"\"\n    converts a dictionary to a HTML table row\n    \"\"\"\n    res = \"<TR>\\n\"\n    for k, v in d.items():\n        if type(v) == str:\n            res = res + '<TD><p>' + k + ':</p></TD><TD><p>' + v + '</p></TD>'\n        else:\n            res = res + '<TD><p>' + k + ':</p></TD><TD><p>' + str(v) + '</p></TD>'\n    res += '</TR>\\n'\n    return res", "label": 1}
{"code": "function append(file, text, options) {\n  options = _.sanitize(options, {atNewLine: false, encoding: 'utf-8'});\n\n  if (!exists(file)) {\n    write(file, text, {encoding: options.encoding});\n  } else {\n    if (options.atNewLine && !text.match(/^\\n/) && exists(file)) text = `\\n${text}`;\n    fs.appendFileSync(file, text, {encoding: options.encoding});\n  }\n}", "label": 3}
{"code": "def force_to_string(unknown):\n    \"\"\"\n    converts and unknown type to string for display purposes.\n    \n    \"\"\"\n    result = ''\n    if type(unknown) is str:\n        result = unknown\n    if type(unknown) is int:\n        result = str(unknown)\n    if type(unknown) is float:\n        result = str(unknown)\n    if type(unknown) is dict:\n        result = Dict2String(unknown)\n    if type(unknown) is list:\n        result = List2String(unknown)\n    return result", "label": 1}
{"code": "def apply_inflections(word, rules, locale = :en)\n        result = word.to_s.dup\n\n        if word.empty? || inflections(locale).uncountables.uncountable?(result)\n          result\n        else\n          rules.each { |(rule, replacement)| break if result.sub!(rule, replacement) }\n          result\n        end\n      end", "label": 4}
{"code": "public Set<ConstraintViolation> validate() {\r\n\t\tSet<ConstraintViolation> errors = new LinkedHashSet<ConstraintViolation>();\r\n\t\tfor (int record = 1; record <= 3; ++record) {\r\n\t\t\terrors.addAll(validate(record));\r\n\t\t}\r\n\t\treturn errors;\r\n\t}", "label": 0}
{"code": "func (c *Config) KubeProxyHostPort() (string, int) {\n\tif c.KubeProxyAddr != \"\" {\n\t\taddr, err := utils.ParseAddr(c.KubeProxyAddr)\n\t\tif err == nil {\n\t\t\treturn addr.Host(), addr.Port(defaults.KubeProxyListenPort)\n\t\t}\n\t}\n\n\twebProxyHost, _ := c.WebProxyHostPort()\n\treturn webProxyHost, defaults.KubeProxyListenPort\n}", "label": 5}
{"code": "def single_stats(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Compute stats for a result.\n\n        :param id: Result ID as an int.\n        :return: :class:`results.SingleStats <results.SingleStats>` object\n        :rtype: results.SingleStats\n        \"\"\"\n        schema = SingleStatsSchema()\n        resp = self.service.get(self.base+str(id)+'/', params={'stats': 'all'})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public static base_responses update(nitro_service client, tmtrafficaction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\ttmtrafficaction updateresources[] = new tmtrafficaction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new tmtrafficaction();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].apptimeout = resources[i].apptimeout;\n\t\t\t\tupdateresources[i].sso = resources[i].sso;\n\t\t\t\tupdateresources[i].formssoaction = resources[i].formssoaction;\n\t\t\t\tupdateresources[i].persistentcookie = resources[i].persistentcookie;\n\t\t\t\tupdateresources[i].initiatelogout = resources[i].initiatelogout;\n\t\t\t\tupdateresources[i].kcdaccount = resources[i].kcdaccount;\n\t\t\t\tupdateresources[i].samlssoprofile = resources[i].samlssoprofile;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func isUrnRFC2141(fl FieldLevel) bool {\n\tfield := fl.Field()\n\n\tswitch field.Kind() {\n\n\tcase reflect.String:\n\n\t\tstr := field.String()\n\n\t\t_, match := urn.Parse([]byte(str))\n\n\t\treturn match\n\t}\n\n\tpanic(fmt.Sprintf(\"Bad field type %T\", field.Interface()))\n}", "label": 5}
{"code": "def show_time_as_short_string(self, seconds):\n        \"\"\" \n        converts seconds to a string in terms of \n        seconds -> years to show complexity of algorithm\n        \"\"\"\n        if seconds < 60:\n            return str(seconds) + ' seconds'\n        elif seconds < 3600:\n            return str(round(seconds/60, 1)) + ' minutes'\n        elif seconds < 3600*24:\n            return str(round(seconds/(60*24), 1)) + ' hours'\n        elif seconds < 3600*24*365:\n            return str(round(seconds/(3600*24), 1)) + ' days'\n        else:\n            print('WARNING - this will take ' + str(seconds/(60*24*365)) + ' YEARS to run' )\n            return str(round(seconds/(60*24*365), 1)) + ' years'", "label": 1}
{"code": "func (o HostNetworkSystem) UpdateNetworkConfig(ctx context.Context, config types.HostNetworkConfig, changeMode string) (*types.HostNetworkConfigResult, error) {\n\treq := types.UpdateNetworkConfig{\n\t\tThis:       o.Reference(),\n\t\tConfig:     config,\n\t\tChangeMode: changeMode,\n\t}\n\n\tres, err := methods.UpdateNetworkConfig(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &res.Returnval, nil\n}", "label": 5}
{"code": "public static base_responses add(nitro_service client, nd6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnd6 addresources[] = new nd6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new nd6();\n\t\t\t\taddresources[i].neighbor = resources[i].neighbor;\n\t\t\t\taddresources[i].mac = resources[i].mac;\n\t\t\t\taddresources[i].ifnum = resources[i].ifnum;\n\t\t\t\taddresources[i].vlan = resources[i].vlan;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def services_by_name(self):\n        \"\"\"\n            A property that gives a dictionary that contains services as values and their names as keys.\n        \"\"\"\n        srvs = defaultdict(list)\n        for i in self.services:\n            srvs[i.__class__.__name__].append(i)\n        return srvs", "label": 1}
{"code": "func (g *generator) mockName(typeName string) string {\n\tif mockName, ok := g.mockNames[typeName]; ok {\n\t\treturn mockName\n\t}\n\n\treturn \"Mock\" + typeName\n}", "label": 5}
{"code": "public static base_responses add(nitro_service client, snmpgroup resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmpgroup addresources[] = new snmpgroup[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new snmpgroup();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].securitylevel = resources[i].securitylevel;\n\t\t\t\taddresources[i].readviewname = resources[i].readviewname;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setPagesWithMatchingImages($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\WebDetection\\WebPage::class);\n        $this->pages_with_matching_images = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function documentToObject(document, adapterName) {\n  expect(arguments).to.have.length(\n    2,\n    'Invalid arguments length when converting a MongoDB document into ' +\n    'an entity object (it has to be passed 2 arguments)'\n  );\n\n  var obj = {};\n\n  // replace `_id` with `id`\n  if (document.hasOwnProperty('_id')) {\n    obj.id = document._id;\n  }\n\n  // get document class\n  var EntityClass = Entity.getSpecialization(document.Entity);\n\n  // loop through entity's attributes and replace with parsed values\n  var attributes = EntityClass.attributes;\n  for (var attrName in attributes) {\n    if (attributes.hasOwnProperty(attrName)) {\n      // get attribute name in database\n      var attr = attributes[attrName];\n      var dataName = attr.getDataName(adapterName);\n      // check if name is present on document and replace with parsed value\n      if (document.hasOwnProperty(dataName)) {\n        obj[attrName] = attr.parseDataValue(document[dataName]);\n      }\n    }\n  }\n\n  return new EntityClass(obj);\n}", "label": 3}
{"code": "def get_file_url(self, fid, public=None):\n        \"\"\"\n        Get url for the file\n\n        :param string fid: File ID\n        :param boolean public: public or internal url\n        :rtype: string\n        \"\"\"\n        try:\n            volume_id, rest = fid.strip().split(\",\")\n        except ValueError:\n            raise BadFidFormat(\n                \"fid must be in format: <volume_id>,<file_name_hash>\")\n        file_location = self.get_file_location(volume_id)\n        if public is None:\n            public = self.use_public_url\n        volume_url = file_location.public_url if public else file_location.url\n        url = \"http://{volume_url}/{fid}\".format(\n            volume_url=volume_url, fid=fid)\n        return url", "label": 1}
{"code": "def _calculate_degree_days(temperature_equivalent, base_temperature, cooling=False):\n    \"\"\"\n    Calculates degree days, starting with a series of temperature equivalent values\n\n    Parameters\n    ----------\n    temperature_equivalent : Pandas Series\n    base_temperature : float\n    cooling : bool\n        Set True if you want cooling degree days instead of heating degree days\n\n    Returns\n    -------\n    Pandas Series called HDD_base_temperature for heating degree days or\n    CDD_base_temperature for cooling degree days.\n    \"\"\"\n\n    if cooling:\n        ret = temperature_equivalent - base_temperature\n    else:\n        ret = base_temperature - temperature_equivalent\n\n    # degree days cannot be negative\n    ret[ret < 0] = 0\n\n    prefix = 'CDD' if cooling else 'HDD'\n    ret.name = '{}_{}'.format(prefix, base_temperature)\n\n    return ret", "label": 1}
{"code": "public void linkOneToMany(Object obj, CollectionDescriptor cod, boolean insert)\n    {\n        Object referencedObjects = cod.getPersistentField().get(obj);\n        storeAndLinkOneToMany(true, obj, cod,referencedObjects, insert);\n    }", "label": 0}
{"code": "func (a *CellView) Init() {\n\ta.once.Do(func() {\n\t\ta.port = NewViewPort(nil, 0, 0, 0, 0)\n\t\ta.style = tcell.StyleDefault\n\t})\n}", "label": 5}
{"code": "public static base_responses unset(nitro_service client, String prefix[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (prefix != null && prefix.length > 0) {\n\t\t\tnsxmlnamespace unsetresources[] = new nsxmlnamespace[prefix.length];\n\t\t\tfor (int i=0;i<prefix.length;i++){\n\t\t\t\tunsetresources[i] = new nsxmlnamespace();\n\t\t\t\tunsetresources[i].prefix = prefix[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def module_to_dict(module, omittable=lambda k: k.startswith('_')):\n    \"\"\"\n    Converts a module namespace to a Python dictionary. Used by get_settings_diff.\n    \"\"\"\n    return dict([(k, repr(v)) for k, v in module.__dict__.items() if not omittable(k)])", "label": 1}
{"code": "def update_modifier_option(location_id, modifier_list_id, modifier_option_id, body, opts = {})\n      data, _status_code, _headers = update_modifier_option_with_http_info(location_id, modifier_list_id, modifier_option_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "func queryTime(query url.Values, name string, def time.Time) (time.Time, error) {\n\tstr := query.Get(name)\n\tif str == \"\" {\n\t\treturn def, nil\n\t}\n\tparsed, err := time.Parse(time.RFC3339, str)\n\tif err != nil {\n\t\treturn time.Time{}, trace.BadParameter(\"failed to parse %v as RFC3339 time: %v\", name, str)\n\t}\n\treturn parsed, nil\n}", "label": 5}
{"code": "def ensure_channel(data, server = nil)\n      if @channels.include?(data['id'].to_i)\n        @channels[data['id'].to_i]\n      else\n        @channels[data['id'].to_i] = Channel.new(data, self, server)\n      end\n    end", "label": 4}
{"code": "public static scpolicy_stats get(nitro_service service, String name) throws Exception{\n\t\tscpolicy_stats obj = new scpolicy_stats();\n\t\tobj.set_name(name);\n\t\tscpolicy_stats response = (scpolicy_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function addColorScale(name, colors, positions) {\n  if (colors.length !== positions.length) {\n    throw new Error('Invalid color scale.');\n  }\n  colorscales[name] = { colors, positions };\n}", "label": 3}
{"code": "function getAuth (auth, url) {\n  if (auth && auth.user && auth.pass) {\n    return auth.user + ':' + auth.pass\n  }\n  return url.auth\n}", "label": 3}
{"code": "func (a *AuthCommand) RotateCertAuthority(client auth.ClientI) error {\n\treq := auth.RotateRequest{\n\t\tType:        services.CertAuthType(a.rotateType),\n\t\tGracePeriod: &a.rotateGracePeriod,\n\t\tTargetPhase: a.rotateTargetPhase,\n\t}\n\tif a.rotateManualMode {\n\t\treq.Mode = services.RotationModeManual\n\t} else {\n\t\treq.Mode = services.RotationModeAuto\n\t}\n\tif err := client.RotateCertAuthority(req); err != nil {\n\t\treturn err\n\t}\n\tif a.rotateTargetPhase != \"\" {\n\t\tfmt.Printf(\"Updated rotation phase to %q. To check status use 'tctl status'\\n\", a.rotateTargetPhase)\n\t} else {\n\t\tfmt.Printf(\"Initiated certificate authority rotation. To check status use 'tctl status'\\n\")\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function setResourceLabels($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->resource_labels = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setDateClass(string $dateClass)\n    {\n        if (!is_a($dateClass, CarbonInterface::class, true)) {\n            throw new InvalidArgumentException(sprintf(\n                'Given class does not implement %s: %s', CarbonInterface::class, $dateClass\n            ));\n        }\n\n        $this->dateClass = $dateClass;\n\n        if (is_a($dateClass, Carbon::class, true)) {\n            $this->toggleOptions(static::IMMUTABLE, false);\n        } elseif (is_a($dateClass, CarbonImmutable::class, true)) {\n            $this->toggleOptions(static::IMMUTABLE, true);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function(field) {\n  var converted = field.fieldId;\n  converted.values = field.fieldValues;\n  converted.sectionIndex = field.sectionIndex;\n  return converted;\n}", "label": 3}
{"code": "@Nullable\n\tpublic Import find(@Nonnull final String typeName) {\n\t\tCheck.notEmpty(typeName, \"typeName\");\n\t\tImport ret = null;\n\t\tfinal Type type = new Type(typeName);\n\t\tfor (final Import imp : imports) {\n\t\t\tif (imp.getType().getName().equals(type.getName())) {\n\t\t\t\tret = imp;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (ret == null) {\n\t\t\tfinal Type javaLangType = Type.evaluateJavaLangType(typeName);\n\t\t\tif (javaLangType != null) {\n\t\t\t\tret = Import.of(javaLangType);\n\t\t\t}\n\t\t}\n\t\treturn ret;\n\t}", "label": 0}
{"code": "def bind_name(self, name):\n        \"\"\"Bind field to its name in model class.\"\"\"\n        if self.name:\n            raise errors.Error('Already bound \"{0}\" with name \"{1}\" could not '\n                               'be rebound'.format(self, self.name))\n        self.name = name\n        self.storage_name = ''.join(('_', self.name))\n        return self", "label": 1}
{"code": "public static reporting get(nitro_service service) throws Exception{\n\t\treporting obj = new reporting();\n\t\treporting[] response = (reporting[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "function extractDependencyIds(options) {\n  const dependencies = [];\n\n  function extract(items) {\n    // Invalid if not Array\n    if (Array.isArray(items)) {\n      items.reduce((dependencies, item) => {\n        // Items can be Array with depedency as first param\n        const dep = Array.isArray(item) ? item[0] : item;\n\n        // Only gather string references, not functions/modules\n        if ('string' == typeof dep) dependencies.push(dep);\n        return dependencies;\n      }, dependencies);\n    }\n  }\n\n  if (options.plugins) extract(options.plugins);\n  if (options.presets) extract(options.presets);\n\n  return dependencies;\n}", "label": 3}
{"code": "function(key, file, options) {\n      options = opts(this, options);\n      if (!key) key = this.keygen();\n      if (!options.filename) options.filename = key;\n\n      // Warning: may not necessarily use ajax to perform upload.\n      var apicall = new APICall({\n        action: 'binary/' + key,\n        type: 'post',\n        later: true,\n        encoding: 'binary',\n        options: options,\n        processResponse: APICall.basicResponse\n      });\n\n      function upload(data, type) {\n        if (!options.contentType) options.contentType = type || defaultType;\n        APICall.binaryUpload(apicall, data, options.filename, options.contentType).done();\n      }\n\n      if (isString(file) || (Buffer && file instanceof Buffer)) {\n        // Upload by filename\n\n        if (isNode) {\n          if (isString(file)) file = fs.readFileSync(file);\n          upload(file);\n        }\n        else NotSupported();\n      } else if (file.toDataURL) {\n        // Canvas will have a toDataURL function.\n        upload(file, 'image/png');\n      } else if (CanvasRenderingContext2D && file instanceof CanvasRenderingContext2D) {\n        upload(file.canvas, 'image/png');\n      } else if (isBinary(file)) {\n        // Binary files are base64 encoded from a buffer.\n        var reader = new FileReader();\n\n        /** @private */\n        reader.onabort = function() {\n          apicall.setData(\"FileReader aborted\").abort();\n        }\n\n        /** @private */\n        reader.onerror = function(e) {\n          apicall.setData(e.target.error).abort();\n        }\n\n        /** @private */\n        reader.onload = function(e) {\n          upload(e.target.result);\n        }\n\n        // Don't need to transform Files to Blobs.\n        if (File && file instanceof File) {\n          if (!options.contentType && file.type != \"\") options.contentType = file.type;\n        } else {\n          file = new Blob([ new Uint8Array(file) ], {type: options.contentType || defaultType});\n        }\n\n        reader.readAsDataURL(file);\n      } else NotSupported();\n\n      return apicall;\n    }", "label": 3}
{"code": "function(width, height) {\n\t\t\t\t\t\t\t\t\tvar newImage = svgCanvas.addSvgElementFromJson({\n\t\t\t\t\t\t\t\t\t\telement: 'image',\n\t\t\t\t\t\t\t\t\t\tattr: {\n\t\t\t\t\t\t\t\t\t\t\tx: 0,\n\t\t\t\t\t\t\t\t\t\t\ty: 0,\n\t\t\t\t\t\t\t\t\t\t\twidth: width,\n\t\t\t\t\t\t\t\t\t\t\theight: height,\n\t\t\t\t\t\t\t\t\t\t\tid: svgCanvas.getNextId(),\n\t\t\t\t\t\t\t\t\t\t\tstyle: 'pointer-events:inherit'\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\tsvgCanvas.setHref(newImage, e.target.result);\n\t\t\t\t\t\t\t\t\tsvgCanvas.selectOnly([newImage]);\n\t\t\t\t\t\t\t\t\tsvgCanvas.alignSelectedElements('m', 'page');\n\t\t\t\t\t\t\t\t\tsvgCanvas.alignSelectedElements('c', 'page');\n\t\t\t\t\t\t\t\t\tupdateContextPanel();\n\t\t\t\t\t\t\t\t}", "label": 3}
{"code": "public String getVertexString() {\n        if (tail() != null) {\n            return \"\" + tail().index + \"-\" + head().index;\n        } else {\n            return \"?-\" + head().index;\n        }\n    }", "label": 0}
{"code": "public void sub(Vector3d v1, Vector3d v2) {\n        x = v1.x - v2.x;\n        y = v1.y - v2.y;\n        z = v1.z - v2.z;\n    }", "label": 0}
{"code": "def convert(self, inp):\n        \"\"\"Converts a string representation of some quantity of units into a\n        quantities object.\n\n        Args:\n            inp (str): A textual representation of some quantity of units,\n                e.g., \"fifty kilograms\".\n\n        Returns:\n            A quantities object representing the described quantity and its\n            units.\n        \"\"\"\n        inp = self._preprocess(inp)\n\n        n = NumberService().longestNumber(inp)\n        units = self.extractUnits(inp)\n\n        # Convert to quantity object, attempt conversion\n        quantity = pq.Quantity(float(n), units[0])\n        quantity.units = units[1]\n\n        return quantity", "label": 1}
{"code": "public static Class getClass(String name) throws ClassNotFoundException\r\n    {\r\n        try\r\n        {\r\n            return Class.forName(name);\r\n        }\r\n        catch (ClassNotFoundException ex)\r\n        {\r\n            throw new ClassNotFoundException(name);\r\n        }\r\n    }", "label": 0}
{"code": "def get_from_postcode(postcode, distance):\n    \"\"\"\n    Request all postcode data within `distance` miles of `postcode`.\n\n    :param postcode: the postcode to search for. The postcode may \n                     contain spaces (they will be removed).\n\n    :param distance: distance in miles to `postcode`.\n\n    :returns: a list of dicts containing postcode data within the \n              specified distance or `None` if `postcode` is not valid.\n    \"\"\"\n    postcode = quote(postcode.replace(' ', ''))\n    return _get_from(distance, 'postcode=%s' % postcode)", "label": 1}
{"code": "func NewDataStore(scope string, cfg *ScopeCfg) (DataStore, error) {\n\tif cfg == nil || cfg.Client.Provider == \"\" || cfg.Client.Address == \"\" {\n\t\tc, ok := defaultScopes[scope]\n\t\tif !ok || c.Client.Provider == \"\" || c.Client.Address == \"\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected scope %s without configuration passed\", scope)\n\t\t}\n\n\t\tcfg = c\n\t}\n\n\tvar cached bool\n\tif scope == LocalScope {\n\t\tcached = true\n\t}\n\n\treturn newClient(scope, cfg.Client.Provider, cfg.Client.Address, cfg.Client.Config, cached)\n}", "label": 5}
{"code": "function getUid(username, options) {\n  const uid = _.tryOnce(findUser(username, options), 'id');\n  return _.isUndefined(uid) ? null : uid;\n}", "label": 3}
{"code": "def fetch_related_resource_id_tree(relationship)\n      relationship_name = relationship.name.to_sym\n      @related_resource_id_trees[relationship_name] ||= RelatedResourceIdTree.new(relationship, self)\n    end", "label": 4}
{"code": "def generate_html(store):\n    \"\"\"\n    Generating HTML report.\n\n    Args:\n        store (Store): report data.\n\n    Returns:\n        str: rendered HTML template.\n    \"\"\"\n    spline = {\n        'version': VERSION,\n        'url': 'https://github.com/Nachtfeuer/pipeline',\n        'generated': datetime.now().strftime(\"%A, %d. %B %Y - %I:%M:%S %p\")\n    }\n\n    html_template_file = os.path.join(os.path.dirname(__file__), 'templates/report.html.j2')\n    with open(html_template_file) as handle:\n        html_template = handle.read()\n        return render(html_template, spline=spline, store=store)", "label": 1}
{"code": "private static void freeTempLOB(ClobWrapper clob, BlobWrapper blob)\r\n\t{\r\n\t\ttry\r\n\t\t{\r\n\t\t\tif (clob != null)\r\n\t\t\t{\r\n\t\t\t\t// If the CLOB is open, close it\r\n\t\t\t\tif (clob.isOpen())\r\n\t\t\t\t{\r\n\t\t\t\t\tclob.close();\r\n\t\t\t\t}\r\n\r\n\t\t\t\t// Free the memory used by this CLOB\r\n\t\t\t\tclob.freeTemporary();\r\n\t\t\t}\r\n\r\n\t\t\tif (blob != null)\r\n\t\t\t{\r\n\t\t\t\t// If the BLOB is open, close it\r\n\t\t\t\tif (blob.isOpen())\r\n\t\t\t\t{\r\n\t\t\t\t\tblob.close();\r\n\t\t\t\t}\r\n\r\n\t\t\t\t// Free the memory used by this BLOB\r\n\t\t\t\tblob.freeTemporary();\r\n\t\t\t}\r\n\t\t}\r\n\t\tcatch (Exception e)\r\n\t\t{\r\n            logger.error(\"Error during temporary LOB release\", e);\r\n\t\t}\r\n\t}", "label": 0}
{"code": "def end_hook(hook, status, output)\n      # Want to print the header for quiet hooks only if the result wasn't good\n      # so that the user knows what failed\n      print_header(hook) if (!hook.quiet? && !@config['quiet']) || status != :pass\n\n      print_result(hook, status, output)\n    end", "label": 4}
{"code": "async function setPreferredMcpSettings(accessToken, languageCode, languageTag, timezone) {\n    let preferredLanguage = getValidLanguageOrThrow(languageCode);\n    let preferredRegionalSettings = getValidLanguageTagOrThrow(languageTag);\n    let preferredTimezone = getValidTimezoneOrThrow(timezone);\n\n    const mcpSettings = await getMcpSettings(accessToken);\n\n    return await mcpCustomizr.putSettings(accessToken, {\n        language: updatePreferredLanguage(preferredLanguage, mcpSettings.language),\n        regionalSettings: preferredRegionalSettings,\n        timezone: preferredTimezone,\n    });\n}", "label": 3}
{"code": "public function setSubscriptions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->subscriptions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public Collection values()\r\n    {\r\n        if (values != null) return values;\r\n        values = new AbstractCollection()\r\n        {\r\n            public int size()\r\n            {\r\n                return size;\r\n            }\r\n\r\n            public void clear()\r\n            {\r\n                ReferenceMap.this.clear();\r\n            }\r\n\r\n            public Iterator iterator()\r\n            {\r\n                return new ValueIterator();\r\n            }\r\n        };\r\n        return values;\r\n    }", "label": 0}
{"code": "def renamecol(self, old, new):\n        \"\"\"\n        Rename column or color in-place.\n\n        Method wraps::\n\n                tabular.spreadsheet.renamecol(self, old, new)\n\n        \"\"\"\n        spreadsheet.renamecol(self,old,new)\n        for x in self.coloring.keys():\n            if old in self.coloring[x]:\n                ind = self.coloring[x].index(old)\n                self.coloring[x][ind] = new", "label": 1}
{"code": "public static base_response add(nitro_service client, sslaction resource) throws Exception {\n\t\tsslaction addresource = new sslaction();\n\t\taddresource.name = resource.name;\n\t\taddresource.clientauth = resource.clientauth;\n\t\taddresource.clientcert = resource.clientcert;\n\t\taddresource.certheader = resource.certheader;\n\t\taddresource.clientcertserialnumber = resource.clientcertserialnumber;\n\t\taddresource.certserialheader = resource.certserialheader;\n\t\taddresource.clientcertsubject = resource.clientcertsubject;\n\t\taddresource.certsubjectheader = resource.certsubjectheader;\n\t\taddresource.clientcerthash = resource.clientcerthash;\n\t\taddresource.certhashheader = resource.certhashheader;\n\t\taddresource.clientcertissuer = resource.clientcertissuer;\n\t\taddresource.certissuerheader = resource.certissuerheader;\n\t\taddresource.sessionid = resource.sessionid;\n\t\taddresource.sessionidheader = resource.sessionidheader;\n\t\taddresource.cipher = resource.cipher;\n\t\taddresource.cipherheader = resource.cipherheader;\n\t\taddresource.clientcertnotbefore = resource.clientcertnotbefore;\n\t\taddresource.certnotbeforeheader = resource.certnotbeforeheader;\n\t\taddresource.clientcertnotafter = resource.clientcertnotafter;\n\t\taddresource.certnotafterheader = resource.certnotafterheader;\n\t\taddresource.owasupport = resource.owasupport;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def crossvalidate(self, foldsfile):\n        \"\"\"Train & Test using cross validation, testfile is a file that contains the filenames of all the folds!\"\"\"\n        options = \"-F \" + self.format + \" \" +  self.timbloptions + \" -t cross_validate\"\n        print(\"Instantiating Timbl API : \" + options,file=stderr)\n        if sys.version < '3':\n            self.api = timblapi.TimblAPI(b(options), b\"\")\n        else:\n            self.api = timblapi.TimblAPI(options, \"\")\n        if self.debug:\n            print(\"Enabling debug for timblapi\",file=stderr)\n            self.api.enableDebug()\n        print(\"Calling Timbl Test : \" + options,file=stderr)\n        if sys.version < '3':\n            self.api.test(b(foldsfile),b'',b'')\n        else:\n            self.api.test(u(foldsfile),'','')\n        a = self.api.getAccuracy()\n        del self.api\n        return a", "label": 1}
{"code": "public function submit(RequestParameters $params)\n    {\n        $handle = $this->curl->init($this->siteVerifyUrl);\n\n        $options = array(\n            CURLOPT_POST => true,\n            CURLOPT_POSTFIELDS => $params->toQueryString(),\n            CURLOPT_HTTPHEADER => array(\n                'Content-Type: application/x-www-form-urlencoded'\n            ),\n            CURLINFO_HEADER_OUT => false,\n            CURLOPT_HEADER => false,\n            CURLOPT_RETURNTRANSFER => true,\n            CURLOPT_SSL_VERIFYPEER => true\n        );\n        $this->curl->setoptArray($handle, $options);\n\n        $response = $this->curl->exec($handle);\n        $this->curl->close($handle);\n\n        if ($response !== false) {\n            return $response;\n        }\n\n        return '{\"success\": false, \"error-codes\": [\"'.ReCaptcha::E_CONNECTION_FAILED.'\"]}';\n    }", "label": 2}
{"code": "def update_view(name, version: nil, sql_definition: nil, revert_to_version: nil, materialized: false)\n      if version.blank? && sql_definition.blank?\n        raise(\n          ArgumentError,\n          \"sql_definition or version must be specified\",\n        )\n      end\n\n      if version.present? && sql_definition.present?\n        raise(\n          ArgumentError,\n          \"sql_definition and version cannot both be set\",\n        )\n      end\n\n      sql_definition ||= definition(name, version)\n\n      if materialized\n        Scenic.database.update_materialized_view(\n          name,\n          sql_definition,\n          no_data: no_data(materialized),\n        )\n      else\n        Scenic.database.update_view(name, sql_definition)\n      end\n    end", "label": 4}
{"code": "public static function do_hook( $when ) {\n\n\t\t$args = func_num_args() > 1\n\t\t\t? array_slice( func_get_args(), 1 )\n\t\t\t: array();\n\n\t\tself::$hooks_passed[ $when ] = $args;\n\n\t\tif ( ! isset( self::$hooks[ $when ] ) ) {\n\t\t\treturn;\n\t\t}\n\n\t\tself::debug(\n\t\t\tsprintf(\n\t\t\t\t'Processing hook \"%s\" with %d callbacks',\n\t\t\t\t$when,\n\t\t\t\tcount( self::$hooks[ $when ] )\n\t\t\t),\n\t\t\t'hooks'\n\t\t);\n\n\t\tforeach ( self::$hooks[ $when ] as $callback ) {\n\t\t\tself::debug(\n\t\t\t\tsprintf(\n\t\t\t\t\t'On hook \"%s\": %s',\n\t\t\t\t\t$when,\n\t\t\t\t\tUtils\\describe_callable( $callback )\n\t\t\t\t),\n\t\t\t\t'hooks'\n\t\t\t);\n\t\t\tcall_user_func_array( $callback, $args );\n\t\t}\n\t}", "label": 2}
{"code": "public function submit($item, $idNum)\n    {\n        if (!array_key_exists($idNum, $this->sysvQs)) {\n            $this->sysvQs[$idNum] =\n                msg_get_queue($this->getSysvKey($idNum));\n        }\n        $result = @msg_send(\n            $this->sysvQs[$idNum],\n            self::$typeDirect,\n            $item\n        );\n        if ($result === false) {\n            // Try to put the content in a temp file and send the filename.\n            $tempFile = tempnam(sys_get_temp_dir(), 'Item');\n            $result = file_put_contents($tempFile, serialize($item));\n            if ($result === false) {\n                throw new \\RuntimeException(\n                    \"Failed to write to $tempFile while submiting the item\"\n                );\n            }\n            $result = @msg_send(\n                $this->sysvQs[$idNum],\n                self::$typeFile,\n                $tempFile\n            );\n            if ($result === false) {\n                @unlink($tempFile);\n                throw new \\RuntimeException(\n                    \"Failed to submit the filename: $tempFile\"\n                );\n            }\n        }\n    }", "label": 2}
{"code": "def to_definition(only: nil, except: nil, context: {})\n      GraphQL::Schema::Printer.print_schema(self, only: only, except: except, context: context)\n    end", "label": 4}
{"code": "private static JsonRtn appendErrorHumanMsg(JsonRtn jsonRtn) {\n        if (bundle == null || jsonRtn == null || StringUtils.isEmpty(jsonRtn.getErrCode())) {\n            return null;\n        }\n\n        try {\n            jsonRtn.setErrHumanMsg(bundle.getString(jsonRtn.getErrCode()));\n            return jsonRtn;\n        } catch (Exception e) {\n            return null;\n        }\n    }", "label": 0}
{"code": "def add(cells)\n      self << if cells.is_a?(String)\n                 cells\n               elsif cells.is_a?(Array)\n                 Axlsx::cell_range(cells, false)\n               elsif cells.is_a?(Row)\n                 Axlsx::cell_range(cells, false)\n               end\n    end", "label": 4}
{"code": "public function setManagement($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\NodeManagement::class);\n        $this->management = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def file_field(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'file_field_for', &block)\n      define_method(\"#{name}=\") do |value|\n        return platform.file_field_value_set(identifier.clone, value) unless block_given?\n        self.send(\"#{name}_element\").value = value\n      end\n    end", "label": 4}
{"code": "def doEpisodes(self, number=1):\n        \"\"\" Do the given numer of episodes, and return the rewards of each\n            step as a list.\n        \"\"\"\n        for episode in range(number):\n            print \"Starting episode %d.\" % episode\n\n            # Initialise the profile cycle.\n            if len(self.profile.shape) == 1: # 1D array\n                self._pcycle = cycle(self.profile)\n            else:\n                assert self.profile.shape[0] >= number\n                self._pcycle = cycle(self.profile[episode, :])\n\n            # Scale the initial load.\n            c = self._pcycle.next()\n            for bus in self.market.case.buses:\n                bus.p_demand = self.pdemand[bus] * c\n\n            # Initialise agents and their tasks.\n            for task, agent in zip(self.tasks, self.agents):\n                agent.newEpisode()\n                task.reset()\n\n            while False in [task.isFinished() for task in self.tasks]:\n                if True in [task.isFinished() for task in self.tasks]:\n                    raise ValueError\n                self._oneInteraction()\n\n        self.reset_case()", "label": 1}
{"code": "public static sslcipher_individualcipher_binding[] get_filtered(nitro_service service, String ciphergroupname, filtervalue[] filter) throws Exception{\n\t\tsslcipher_individualcipher_binding obj = new sslcipher_individualcipher_binding();\n\t\tobj.set_ciphergroupname(ciphergroupname);\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tsslcipher_individualcipher_binding[] response = (sslcipher_individualcipher_binding[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static int compare(double a, double b, double delta) {\n        if (equals(a, b, delta)) {\n            return 0;\n        }\n        return Double.compare(a, b);\n    }", "label": 0}
{"code": "function extractFileHeader(path, opts) {\n  opts = opts || {};\n\n  var decode = opts.decode === undefined ? true : !!opts.decode;\n  var size = Math.max(opts.size || 4096, 4);\n  var fd = fs.openSync(path, 'r');\n  var buf = new Buffer(size);\n  var pos = 0;\n  var tap = new utils.Tap(buf);\n  var header = null;\n\n  while (pos < 4) {\n    // Make sure we have enough to check the magic bytes.\n    pos += fs.readSync(fd, buf, pos, size - pos);\n  }\n  if (containers.MAGIC_BYTES.equals(buf.slice(0, 4))) {\n    do {\n      header = containers.HEADER_TYPE._read(tap);\n    } while (!isValid());\n    if (decode !== false) {\n      var meta = header.meta;\n      meta['avro.schema'] = JSON.parse(meta['avro.schema'].toString());\n      if (meta['avro.codec'] !== undefined) {\n        meta['avro.codec'] = meta['avro.codec'].toString();\n      }\n    }\n  }\n  fs.closeSync(fd);\n  return header;\n\n  function isValid() {\n    if (tap.isValid()) {\n      return true;\n    }\n    var len = 2 * tap.buf.length;\n    var buf = new Buffer(len);\n    len = fs.readSync(fd, buf, 0, len);\n    tap.buf = Buffer.concat([tap.buf, buf]);\n    tap.pos = 0;\n    return false;\n  }\n}", "label": 3}
{"code": "func (c *Call) After(preReq *Call) *Call {\n\tc.t.Helper()\n\n\tif c == preReq {\n\t\tc.t.Fatalf(\"A call isn't allowed to be its own prerequisite\")\n\t}\n\tif preReq.isPreReq(c) {\n\t\tc.t.Fatalf(\"Loop in call order: %v is a prerequisite to %v (possibly indirectly).\", c, preReq)\n\t}\n\n\tc.preReqs = append(c.preReqs, preReq)\n\treturn c\n}", "label": 5}
{"code": "public void modified(ServiceReference<S> declarationBinderRef) throws InvalidFilterException {\n        declarationBinders.get(declarationBinderRef).update(declarationBinderRef);\n    }", "label": 0}
{"code": "func (ni *NetInfo) MergeCNIResult(result types.Result) {\n\tni.IP = result.IP4.IP.IP\n\tni.Mask = net.IP(result.IP4.IP.Mask)\n\tni.HostIP = result.IP4.Gateway\n\tni.IP4 = result.IP4\n\tni.DNS = result.DNS\n}", "label": 5}
{"code": "public static filterhtmlinjectionparameter get(nitro_service service,  options option) throws Exception{\n\t\tfilterhtmlinjectionparameter obj = new filterhtmlinjectionparameter();\n\t\tfilterhtmlinjectionparameter[] response = (filterhtmlinjectionparameter[])obj.get_resources(service,option);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "func SqAutoIncrements(db XODB) ([]*SqAutoIncrement, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`name as table_name, sql ` +\n\t\t`FROM sqlite_master ` +\n\t\t`WHERE type='table' ` +\n\t\t`ORDER BY name`\n\n\t// run query\n\tXOLog(sqlstr)\n\tq, err := db.Query(sqlstr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*SqAutoIncrement{}\n\tfor q.Next() {\n\t\tsai := SqAutoIncrement{}\n\n\t\t// scan\n\t\terr = q.Scan(&sai.TableName, &sai.SQL)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &sai)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def error(self, msg):\n        '''Raise a ConfigParseError at the current input position'''\n        if self.finished():\n            raise ConfigParseError(\"Unexpected end of input; %s\" % (msg,))\n        else:\n            t = self.peek()\n            raise ConfigParseError(\"Unexpected token %s; %s\" % (t, msg))", "label": 1}
{"code": "function checkForInlineMixins(mixin, rtn) {\n            if (mixin.mixins) {\n                get(mixin.mixins, index, initiatedOnce, rtn);\n            }\n        }", "label": 3}
{"code": "def catalog\n      @catalog_mutex.synchronize do\n        break if synchronized?\n        logger.info \"Cataloging #{workspace.directory.empty? ? 'generic workspace' : workspace.directory}\"\n        api_map.catalog bundle\n        @synchronized = true\n        logger.info \"Catalog complete (#{api_map.pins.length} pins)\"\n      end\n    end", "label": 4}
{"code": "def run_strelka_with_merge(job, tumor_bam, normal_bam, univ_options, strelka_options):\n    \"\"\"\n    A wrapper for the the entire strelka sub-graph.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict strelka_options: Options specific to strelka\n    :return: fsID to the merged strelka calls\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    spawn = job.wrapJobFn(run_strelka, tumor_bam, normal_bam, univ_options,\n                          strelka_options, split=False).encapsulate()\n    job.addChild(spawn)\n    return spawn.rv()", "label": 1}
{"code": "function(values, delaySort)\n  {\n    if ( isArray( values ) && values.length )\n    {\n      var i = this.length;\n\n      AP.push.apply( this, values );\n\n      this.trigger( Collection.Events.Adds, [this, values, i] );\n\n      if ( !delaySort )\n      {\n        this.sort( undefined, undefined, true );\n      }\n    }\n\n    return this;\n  }", "label": 3}
{"code": "def allow_capability(self, ctx, ops):\n        '''Checks that the user is allowed to perform all the\n        given operations. If not, a discharge error will be raised.\n        If allow_capability succeeds, it returns a list of first party caveat\n        conditions that must be applied to any macaroon granting capability\n        to execute the operations. Those caveat conditions will not\n        include any declarations contained in login macaroons - the\n        caller must be careful not to mint a macaroon associated\n        with the LOGIN_OP operation unless they add the expected\n        declaration caveat too - in general, clients should not create\n        capabilities that grant LOGIN_OP rights.\n\n        The operations must include at least one non-LOGIN_OP operation.\n        '''\n        nops = 0\n        for op in ops:\n            if op != LOGIN_OP:\n                nops += 1\n        if nops == 0:\n            raise ValueError('no non-login operations required in capability')\n\n        _, used = self._allow_any(ctx, ops)\n        squasher = _CaveatSquasher()\n        for i, is_used in enumerate(used):\n            if not is_used:\n                continue\n            for cond in self._conditions[i]:\n                squasher.add(cond)\n        return squasher.final()", "label": 1}
{"code": "public static String getShortClassName(Object o) {\r\n    String name = o.getClass().getName();\r\n    int index = name.lastIndexOf('.');\r\n    if (index >= 0) {\r\n      name = name.substring(index + 1);\r\n    }\r\n    return name;\r\n  }", "label": 0}
{"code": "def super_and_sub?(sup, sub)\n      fqsup = qualify(sup)\n      cls = qualify(store.get_superclass(sub), sub)\n      until cls.nil?\n        return true if cls == fqsup\n        cls = qualify(store.get_superclass(cls), cls)\n      end\n      false\n    end", "label": 4}
{"code": "def get_employee_wage(id, opts = {})\n      data, _status_code, _headers = get_employee_wage_with_http_info(id, opts)\n      return data\n    end", "label": 4}
{"code": "function scrapTitle(window){\n   var $ = window.$;\n   var url = window.location.href;\n\n   // Tags or attributes whom can contain a nice title for the page\n   var titleTag =  $('title').text().trim();\n   var metaTitleTag = $('meta[name=\"title\"]').attr('content');\n   var openGraphTitle = $('meta[property=\"og:title\"]').attr('content');\n   var h1Tag = $('h1').eq(0).text().trim();\n   var itempropNameTag = $('[itemprop=\"name\"]').text().trim();\n   var titles = [titleTag, metaTitleTag, openGraphTitle, h1Tag, itempropNameTag];\n\n   // Regex of the web site name\n   var nameWebsite = utils.getWebsiteName(url);\n   var regex = new RegExp(nameWebsite,'i');\n   // Sort to find the best title\n   var titlesNotEmpty = titles.filter(function(value){\n      return !!value;\n   });\n   var titlesBest = titlesNotEmpty.filter(function(value){\n      return !regex.test(value);\n   });\n   var bestTitle = (titlesBest && titlesBest[0]) || (titlesNotEmpty && titlesNotEmpty[0]) || '';\n   return utils.inline(bestTitle);\n}", "label": 3}
{"code": "public static <T> List<List<T>> getNGrams(List<T> items, int minSize, int maxSize) {\r\n    List<List<T>> ngrams = new ArrayList<List<T>>();\r\n    int listSize = items.size();\r\n    for (int i = 0; i < listSize; ++i) {\r\n      for (int ngramSize = minSize; ngramSize <= maxSize; ++ngramSize) {\r\n        if (i + ngramSize <= listSize) {\r\n          List<T> ngram = new ArrayList<T>();\r\n          for (int j = i; j < i + ngramSize; ++j) {\r\n            ngram.add(items.get(j));\r\n          }\r\n          ngrams.add(ngram);\r\n        }\r\n      }\r\n    }\r\n    return ngrams;\r\n  }", "label": 0}
{"code": "public function getJobFromIdNum($idNum)\n    {\n        return array_key_exists($idNum, $this->idToIdentifier)\n            ? $this->jobs[$this->idToIdentifier[$idNum]]\n            : null;\n    }", "label": 2}
{"code": "public function createMetric($name, $filter, array $options = [])\n    {\n        $response =  $this->connection->createMetric($options + [\n            'parent' => $this->formattedProjectName,\n            'name' => $name,\n            'filter' => $filter\n        ]);\n\n        return new Metric($this->connection, $name, $this->projectId, $response);\n    }", "label": 2}
{"code": "func (t *Terminfo) TColor(fi, bi int) string {\n\trv := \"\"\n\t// As a special case, we map bright colors to lower versions if the\n\t// color table only holds 8.  For the remaining 240 colors, the user\n\t// is out of luck.  Someday we could create a mapping table, but its\n\t// not worth it.\n\tif t.Colors == 8 {\n\t\tif fi > 7 && fi < 16 {\n\t\t\tfi -= 8\n\t\t}\n\t\tif bi > 7 && bi < 16 {\n\t\t\tbi -= 8\n\t\t}\n\t}\n\tif t.Colors > fi && fi >= 0 {\n\t\trv += t.TParm(t.SetFg, fi)\n\t}\n\tif t.Colors > bi && bi >= 0 {\n\t\trv += t.TParm(t.SetBg, bi)\n\t}\n\treturn rv\n}", "label": 5}
{"code": "def render(options, screenshots, export_path = nil)\n      @screenshots = screenshots || []\n      @options = options\n      @export_path = export_path\n\n      @app_name = (options[:name]['en-US'] || options[:name].values.first) if options[:name]\n      @app_name ||= options[:app].name\n\n      @languages = options[:description].keys if options[:description]\n      @languages ||= options[:app].latest_version.description.languages\n\n      html_path = File.join(Deliver::ROOT, \"lib/assets/summary.html.erb\")\n      html = ERB.new(File.read(html_path)).result(binding) # https://web.archive.org/web/20160430190141/www.rrn.dk/rubys-erb-templating-system\n\n      export_path = File.join(export_path, \"Preview.html\")\n      File.write(export_path, html)\n\n      return export_path\n    end", "label": 4}
{"code": "def each(&block)\n      if block.arity == 1\n        @errors.each(&block)\n      else\n        ActiveSupport::Deprecation.warn(<<~MSG)\n          Enumerating ActiveModel::Errors as a hash has been deprecated.\n          In Rails 6.1, `errors` is an array of Error objects,\n          therefore it should be accessed by a block with a single block\n          parameter like this:\n\n          person.errors.each do |error|\n            error.full_message\n          end\n\n          You are passing a block expecting two parameters,\n          so the old hash behavior is simulated. As this is deprecated,\n          this will result in an ArgumentError in Rails 6.2.\n        MSG\n        @errors.\n          sort { |a, b| a.attribute <=> b.attribute }.\n          each { |error| yield error.attribute, error.message }\n      end\n    end", "label": 4}
{"code": "public static sslcertkey_crldistribution_binding[] get(nitro_service service, String certkey) throws Exception{\n\t\tsslcertkey_crldistribution_binding obj = new sslcertkey_crldistribution_binding();\n\t\tobj.set_certkey(certkey);\n\t\tsslcertkey_crldistribution_binding response[] = (sslcertkey_crldistribution_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _locate_day(year, cutoff):\n\t\t\"\"\"\n\t\tTakes a SYSTEMTIME object, such as retrieved from a TIME_ZONE_INFORMATION\n\t\tstructure or call to GetTimeZoneInformation and interprets\n\t\tit based on the given\n\t\tyear to identify the actual day.\n\n\t\tThis method is necessary because the SYSTEMTIME structure\n\t\trefers to a day by its\n\t\tday of the week and week of the month (e.g. 4th saturday in March).\n\n\t\t>>> SATURDAY = 6\n\t\t>>> MARCH = 3\n\t\t>>> st = SYSTEMTIME(2000, MARCH, SATURDAY, 4, 0, 0, 0, 0)\n\n\t\t# according to my calendar, the 4th Saturday in March in 2009 was the 28th\n\t\t>>> expected_date = datetime.datetime(2009, 3, 28)\n\t\t>>> Info._locate_day(2009, st) == expected_date\n\t\tTrue\n\t\t\"\"\"\n\t\t# MS stores Sunday as 0, Python datetime stores Monday as zero\n\t\ttarget_weekday = (cutoff.day_of_week + 6) % 7\n\t\t# For SYSTEMTIMEs relating to time zone inforamtion, cutoff.day\n\t\t#  is the week of the month\n\t\tweek_of_month = cutoff.day\n\t\t# so the following is the first day of that week\n\t\tday = (week_of_month - 1) * 7 + 1\n\t\tresult = datetime.datetime(\n\t\t\tyear, cutoff.month, day,\n\t\t\tcutoff.hour, cutoff.minute, cutoff.second, cutoff.millisecond)\n\t\t# now the result is the correct week, but not necessarily\n\t\t# the correct day of the week\n\t\tdays_to_go = (target_weekday - result.weekday()) % 7\n\t\tresult += datetime.timedelta(days_to_go)\n\t\t# if we selected a day in the month following the target month,\n\t\t#  move back a week or two.\n\t\t# This is necessary because Microsoft defines the fifth week in a month\n\t\t#  to be the last week in a month and adding the time delta might have\n\t\t#  pushed the result into the next month.\n\t\twhile result.month == cutoff.month + 1:\n\t\t\tresult -= datetime.timedelta(weeks=1)\n\t\treturn result", "label": 1}
{"code": "@Override\r\n  public <VALUEBASE, VALUE extends VALUEBASE, KEY extends Key<CoreMap, VALUEBASE>>\r\n    VALUE set(Class<KEY> key, VALUE value) {\r\n    \r\n    if (immutableKeys.contains(key)) {\r\n      throw new HashableCoreMapException(\"Attempt to change value \" +\r\n      \t\t\"of immutable field \"+key.getSimpleName());\r\n    }\r\n    \r\n    return super.set(key, value);\r\n  }", "label": 0}
{"code": "func (s *handler) AttachTag(ref vim.ManagedObjectReference, tag vim.VslmTagEntry) vim.BaseMethodFault {\n\tt := s.findTag(tag)\n\tif t == nil {\n\t\treturn new(vim.NotFound)\n\t}\n\ts.Association[t.ID][internal.AssociatedObject(ref)] = true\n\treturn nil\n}", "label": 5}
{"code": "def switch_to!(version, append: Logidze.append_on_undo)\n      return false unless at_version(version)\n\n      if append && version < log_version\n        update!(log_data.changes_to(version: version))\n      else\n        at_version!(version)\n        self.class.without_logging { save! }\n      end\n    end", "label": 4}
{"code": "def log(level, *args)\n      return 'disabled' unless enabled?\n\n      message, exception, extra, context = extract_arguments(args)\n      use_exception_level_filters = use_exception_level_filters?(extra)\n\n      return 'ignored' if ignored?(exception, use_exception_level_filters)\n\n      begin\n        status = call_before_process(:level => level,\n                                     :exception => exception,\n                                     :message => message,\n                                     :extra => extra)\n        return 'ignored' if status == 'ignored'\n      rescue Rollbar::Ignore\n        return 'ignored'\n      end\n\n      level = lookup_exception_level(level, exception,\n                                     use_exception_level_filters)\n\n      begin\n        report(level, message, exception, extra, context)\n      rescue StandardError, SystemStackError => e\n        report_internal_error(e)\n\n        'error'\n      end\n    end", "label": 4}
{"code": "function Plugin(square, collection) {\n  if (!(this instanceof Plugin)) return new Plugin(square, collection);\n  if (!square) throw new Error('Missing square instance');\n  if (!collection) throw new Error('Missing collection');\n\n  var self = this;\n\n  this.square = square;           // Reference to the current square instance.\n  this.async = async;             // Handle async operation.\n  this._ = _;                     // Utilities.\n  this.logger = {};               // Our logging utility.\n  this.collection = collection;   // Reference to the original collection.\n\n  // Provide a default namespace to the logging method, we are going to prefix\n  // it with the plugin's name which will help with the debug ability of this\n  // module.\n  Object.keys(square.logger.levels).forEach(function generate(level) {\n    self.logger[level] = square.logger[level].bind(\n        square.logger\n      , '[plugin::'+ self.id +']'\n    );\n  });\n\n  // Merge the given collection with the plugin, but don't override the default\n  // values.\n  Object.keys(collection).forEach(function each(key) {\n    self[key] = collection[key];\n  });\n\n  // Force an async nature of the plugin interface, this also allows us to\n  // attach or listen to methods after we have constructed the plugin.\n  process.nextTick(this.configure.bind(this));\n}", "label": 3}
{"code": "def set_implicit_wait(wait)\n      @driver.manage.timeouts.implicit_wait = wait\n    rescue Selenium::WebDriver::Error::UnknownError => e\n      unless e.message.include?('The operation requested is not yet implemented by Espresso driver')\n        raise ::Appium::Core::Error::ServerError\n      end\n\n      {}\n    end", "label": 4}
{"code": "def process(job = nil, &block)\n      return unless job ||= reserve\n\n      job.worker = self\n      working_on job\n      perform(job, &block)\n    ensure\n      done_working\n    end", "label": 4}
{"code": "private void setTableAliasForPath(String aPath, List hintClasses, TableAlias anAlias)\r\n    {\r\n        m_pathToAlias.put(buildAliasKey(aPath, hintClasses), anAlias);\r\n    }", "label": 0}
{"code": "def perform_action!(action, resource, author, extra_log_info = {})\n      PaperTrail.request(whodunnit: gid(author)) do\n        Decidim::ApplicationRecord.transaction do\n          result = block_given? ? yield : nil\n          loggable_resource = resource.is_a?(Class) ? result : resource\n          log(action, author, loggable_resource, extra_log_info)\n          return result\n        end\n      end\n    end", "label": 4}
{"code": "def daterange(start_date, end_date):\n    \"\"\"\n    Yield one date per day from starting date to ending date.\n\n    Args:\n        start_date (date): starting date.\n        end_date (date): ending date.\n\n    Yields:\n        date: a date for each day within the range.\n    \"\"\"\n    for n in range(int((end_date - start_date).days)):\n        yield start_date + timedelta(n)", "label": 1}
{"code": "func (c *SessionContext) ClientTLSConfig(clusterName ...string) (*tls.Config, error) {\n\tvar certPool *x509.CertPool\n\tif len(clusterName) == 0 {\n\t\tcertAuthorities, err := c.parent.proxyClient.GetCertAuthorities(services.HostCA, false)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tcertPool, err = services.CertPoolFromCertAuthorities(certAuthorities)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t} else {\n\t\tcertAuthority, err := c.parent.proxyClient.GetCertAuthority(services.CertAuthID{\n\t\t\tType:       services.HostCA,\n\t\t\tDomainName: clusterName[0],\n\t\t}, false)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tcertPool, err = services.CertPool(certAuthority)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\n\ttlsConfig := utils.TLSConfig(c.parent.cipherSuites)\n\ttlsCert, err := tls.X509KeyPair(c.sess.GetTLSCert(), c.sess.GetPriv())\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to parse TLS cert and key\")\n\t}\n\ttlsConfig.Certificates = []tls.Certificate{tlsCert}\n\ttlsConfig.RootCAs = certPool\n\ttlsConfig.ServerName = auth.EncodeClusterName(c.parent.clusterName)\n\treturn tlsConfig, nil\n}", "label": 5}
{"code": "def obtain_socket(uri)\n      socket = TCPSocket.new(uri.host, uri.port || socket_port(uri))\n\n      if secure_uri?(uri)\n        ctx = OpenSSL::SSL::SSLContext.new\n\n        if ENV['DISCORDRB_SSL_VERIFY_NONE']\n          ctx.ssl_version = 'SSLv23'\n          ctx.verify_mode = OpenSSL::SSL::VERIFY_NONE # use VERIFY_PEER for verification\n\n          cert_store = OpenSSL::X509::Store.new\n          cert_store.set_default_paths\n          ctx.cert_store = cert_store\n        else\n          ctx.set_params ssl_version: :TLSv1_2\n        end\n\n        socket = OpenSSL::SSL::SSLSocket.new(socket, ctx)\n        socket.connect\n      end\n\n      socket\n    end", "label": 4}
{"code": "def process_if(exp, _parent)\n      children = exp.children\n      increase_statement_count_by(children[1])\n      increase_statement_count_by(children[2])\n      decrease_statement_count\n      process(exp)\n    end", "label": 4}
{"code": "def get_cards(ctx):\n    \"\"\"Prints out cards available for application.\"\"\"\n\n    appid = ctx.obj['appid']\n    app = Application(appid)\n\n    click.secho('Cards for `%s` [appid: %s]' % (app.title, appid), fg='green')\n\n    if not app.has_cards:\n        click.secho('This app has no cards.', fg='red', err=True)\n        return\n\n    cards, booster = app.get_cards()\n\n    def get_line(card):\n        return '%s [market hash: `%s`]' % (card.title, card.market_hash)\n\n    for card in cards.values():\n        click.echo(get_line(card))\n\n    if booster:\n        click.secho('* Booster pack: `%s`' % get_line(booster), fg='yellow')\n\n    click.secho('* Total cards: %d' % len(cards), fg='green')", "label": 1}
{"code": "function (scrollOffset) {\n            var alignAttr = this.group.alignAttr,\n              translateY,\n              clipHeight = this.clipHeight || this.legendHeight;\n\n            if (alignAttr) {\n                translateY = alignAttr.translateY;\n                each(this.allItems, function (item) {\n                    var checkbox = item.checkbox,\n                      top;\n\n                    if (checkbox) {\n                        top = (translateY + checkbox.y + (scrollOffset || 0) + 3);\n                        css(checkbox, {\n                            left: (alignAttr.translateX + item.checkboxOffset + checkbox.x - 20) + PX,\n                            top: top + PX,\n                            display: top > translateY - 6 && top < translateY + clipHeight - 6 ? '' : NONE\n                        });\n                    }\n                });\n            }\n        }", "label": 3}
{"code": "public static base_responses delete(nitro_service client, String xmlcontenttypevalue[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (xmlcontenttypevalue != null && xmlcontenttypevalue.length > 0) {\n\t\t\tappfwxmlcontenttype deleteresources[] = new appfwxmlcontenttype[xmlcontenttypevalue.length];\n\t\t\tfor (int i=0;i<xmlcontenttypevalue.length;i++){\n\t\t\t\tdeleteresources[i] = new appfwxmlcontenttype();\n\t\t\t\tdeleteresources[i].xmlcontenttypevalue = xmlcontenttypevalue[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def create(*args)\n      arguments(args, required: [:org_name]) do\n        assert_required %w[ name ]\n      end\n      params = arguments.params\n\n      params[\"accept\"] ||= PREVIEW_MEDIA\n\n      post_request(\"/orgs/#{arguments.org_name}/projects\", params)\n    end", "label": 4}
{"code": "def content_fields\n      output = {}\n\n      # Include file content-related fields\n      if is_a?(Jekyll::StaticFile)\n        output[\"encoded_content\"] = encoded_content\n      elsif is_a?(JekyllAdmin::DataFile)\n        output[\"content\"] = content\n        output[\"raw_content\"] = raw_content\n      else\n        output[\"raw_content\"] = raw_content\n        output[\"front_matter\"] = front_matter\n      end\n\n      # Include next and previous documents non-recursively\n      if is_a?(Jekyll::Document)\n        %w(next previous).each do |direction|\n          method = \"#{direction}_doc\".to_sym\n          doc = public_send(method)\n          output[direction] = doc.to_api if doc\n        end\n      end\n\n      output\n    end", "label": 4}
{"code": "function (x, y, w, h, options) {\n                var arrowLength = 6,\n                  halfDistance = 6,\n                  r = mathMin((options && options.r) || 0, w, h),\n                  safeDistance = r + halfDistance,\n                  anchorX = options && options.anchorX,\n                  anchorY = options && options.anchorY,\n                  path,\n                  normalizer = mathRound(options.strokeWidth || 0) % 2 / 2; // mathRound because strokeWidth can sometimes have roundoff errors;\n\n                x += normalizer;\n                y += normalizer;\n                path = [\n                    'M', x + r, y,\n                    'L', x + w - r, y, // top side\n                    'C', x + w, y, x + w, y, x + w, y + r, // top-right corner\n                    'L', x + w, y + h - r, // right side\n                    'C', x + w, y + h, x + w, y + h, x + w - r, y + h, // bottom-right corner\n                    'L', x + r, y + h, // bottom side\n                    'C', x, y + h, x, y + h, x, y + h - r, // bottom-left corner\n                    'L', x, y + r, // left side\n                    'C', x, y, x, y, x + r, y // top-right corner\n                ];\n\n                if (anchorX && anchorX > w && anchorY > y + safeDistance && anchorY < y + h - safeDistance) { // replace right side\n                    path.splice(13, 3,\n                      'L', x + w, anchorY - halfDistance,\n                      x + w + arrowLength, anchorY,\n                      x + w, anchorY + halfDistance,\n                      x + w, y + h - r\n                    );\n                } else if (anchorX && anchorX < 0 && anchorY > y + safeDistance && anchorY < y + h - safeDistance) { // replace left side\n                    path.splice(33, 3,\n                      'L', x, anchorY + halfDistance,\n                      x - arrowLength, anchorY,\n                      x, anchorY - halfDistance,\n                      x, y + r\n                    );\n                } else if (anchorY && anchorY > h && anchorX > x + safeDistance && anchorX < x + w - safeDistance) { // replace bottom\n                    path.splice(23, 3,\n                      'L', anchorX + halfDistance, y + h,\n                      anchorX, y + h + arrowLength,\n                      anchorX - halfDistance, y + h,\n                      x + r, y + h\n                    );\n                } else if (anchorY && anchorY < 0 && anchorX > x + safeDistance && anchorX < x + w - safeDistance) { // replace top\n                    path.splice(3, 3,\n                      'L', anchorX - halfDistance, y,\n                      anchorX, y - arrowLength,\n                      anchorX + halfDistance, y,\n                      w - r, y\n                    );\n                }\n                return path;\n            }", "label": 3}
{"code": "def h2(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'h2_for', &block)\n      define_method(name) do\n        return platform.h2_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "function isWhiteSpaceSingleLine(ch) {\n        // Note: nextLine is in the Zs space, and should be considered to be a whitespace.\n        // It is explicitly not a line-break as it isn't in the exact set specified by EcmaScript.\n        return ch === 32 /* space */ ||\n            ch === 9 /* tab */ ||\n            ch === 11 /* verticalTab */ ||\n            ch === 12 /* formFeed */ ||\n            ch === 160 /* nonBreakingSpace */ ||\n            ch === 133 /* nextLine */ ||\n            ch === 5760 /* ogham */ ||\n            ch >= 8192 /* enQuad */ && ch <= 8203 /* zeroWidthSpace */ ||\n            ch === 8239 /* narrowNoBreakSpace */ ||\n            ch === 8287 /* mathematicalSpace */ ||\n            ch === 12288 /* ideographicSpace */ ||\n            ch === 65279 /* byteOrderMark */;\n    }", "label": 3}
{"code": "func NetworkOptionIpam(ipamDriver string, addrSpace string, ipV4 []*IpamConf, ipV6 []*IpamConf, opts map[string]string) NetworkOption {\n\treturn func(n *network) {\n\t\tif ipamDriver != \"\" {\n\t\t\tn.ipamType = ipamDriver\n\t\t\tif ipamDriver == ipamapi.DefaultIPAM {\n\t\t\t\tn.ipamType = defaultIpamForNetworkType(n.Type())\n\t\t\t}\n\t\t}\n\t\tn.ipamOptions = opts\n\t\tn.addrSpace = addrSpace\n\t\tn.ipamV4Config = ipV4\n\t\tn.ipamV6Config = ipV6\n\t}\n}", "label": 5}
{"code": "func renameAborted() error {\n\tif err := pkgPod.WalkPods(getDataDir(), pkgPod.IncludePrepareDir, func(p *pkgPod.Pod) {\n\t\tif p.State() == pkgPod.AbortedPrepare {\n\t\t\tstderr.Printf(\"moving failed prepare %q to garbage\", p.UUID)\n\t\t\tif err := p.ToGarbage(); err != nil && err != os.ErrNotExist {\n\t\t\t\tstderr.PrintE(\"rename error\", err)\n\t\t\t}\n\t\t}\n\t}); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def docker_call(tool, tool_parameters, work_dir, java_opts=None, outfile=None,\n                dockerhub='aarjunrao', interactive=False):\n    \"\"\"\n    Makes subprocess call of a command to a docker container. work_dir MUST BE AN ABSOLUTE PATH or\n    the call will fail.  outfile is an open file descriptor to a writeable file.\n    \"\"\"\n    # If an outifle has been provided, then ensure that it is of type file, it is writeable, and\n    # that it is open.\n    if outfile:\n        assert isinstance(outfile, file), 'outfile was not passsed a file'\n        assert outfile.mode in ['w', 'a', 'wb', 'ab'], 'outfile not writeable'\n        assert not outfile.closed, 'outfile is closed'\n    # If the call is interactive, set intereactive to -i\n    if interactive:\n        interactive = '-i'\n    else:\n        interactive = ''\n    # If a tag is passed along with the image, use it.\n    if ':' in tool:\n        docker_tool = '/'.join([dockerhub, tool])\n    # Else use 'latest'\n    else:\n        docker_tool = ''.join([dockerhub, '/', tool, ':latest'])\n    # Get the docker image on the worker if needed\n    call = ['docker', 'images']\n    dimg_rv = subprocess.check_output(call)\n    existing_images = [':'.join(x.split()[0:2]) for x in dimg_rv.splitlines()\n                       if x.startswith(dockerhub)]\n    if docker_tool not in existing_images:\n        try:\n            call = ' '.join(['docker', 'pull', docker_tool]).split()\n            subprocess.check_call(call)\n        except subprocess.CalledProcessError as err:\n            raise RuntimeError('docker command returned a non-zero exit status ' +\n                               '(%s)' % err.returncode + 'for command \\\"%s\\\"' % ' '.join(call),)\n        except OSError:\n            raise RuntimeError('docker not found on system. Install on all' +\n                               ' nodes.')\n    # If java options have been provided, it needs to be in the docker call\n    if java_opts:\n        base_docker_call = ' docker run -e JAVA_OPTS=-Xmx{} '.format(java_opts) + '--rm=true ' + \\\n            '-v {}:/data --log-driver=none '.format(work_dir) + interactive\n    else:\n        base_docker_call = ' docker run --rm=true -v {}:/data '.format(work_dir) + \\\n            '--log-driver=none ' + interactive\n    call = base_docker_call.split() + [docker_tool] + tool_parameters\n    try:\n        subprocess.check_call(call, stdout=outfile)\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError('docker command returned a non-zero exit status (%s)' % err.returncode +\n                           'for command \\\"%s\\\"' % ' '.join(call),)\n    except OSError:\n        raise RuntimeError('docker not found on system. Install on all nodes.')", "label": 1}
{"code": "public static ipset[] get(nitro_service service) throws Exception{\n\t\tipset obj = new ipset();\n\t\tipset[] response = (ipset[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function errMessageFormat (showDiff, pos, title, msg, stack) {\n  if (showDiff) {\n    return format.red('  ' + pos + ') ' + title + ':\\n' + msg) + format.gray('\\n' + stack + '\\n')\n  }\n  return format.red('  ' + pos + ') ' + title + ':\\n') +\n    format.white('     ' + msg) +\n    format.white('\\n' + stack + '\\n')\n}", "label": 3}
{"code": "def main(**kwargs):\n    \"\"\"The Pipeline tool.\"\"\"\n    options = ApplicationOptions(**kwargs)\n    Event.configure(is_logging_enabled=options.event_logging)\n    application = Application(options)\n    application.run(options.definition)", "label": 1}
{"code": "public static base_response delete(nitro_service client, route6 resource) throws Exception {\n\t\troute6 deleteresource = new route6();\n\t\tdeleteresource.network = resource.network;\n\t\tdeleteresource.gateway = resource.gateway;\n\t\tdeleteresource.vlan = resource.vlan;\n\t\tdeleteresource.td = resource.td;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "public function subscribe($name, array $options = [])\n    {\n        $subscription = $this->subscriptionFactory($name);\n\n        $subscription->create($options);\n\n        return $subscription;\n    }", "label": 2}
{"code": "def calc_thresholds(rbh, file_name, thresholds = [False, False, False, False], stdevs = 2):\n    \"\"\"\n    if thresholds are not specififed, calculate based on the distribution of normalized bit scores\n    \"\"\"\n    calc_threshold = thresholds[-1]\n    norm_threshold = {}\n    for pair in itertools.permutations([i for i in rbh], 2):\n        if pair[0] not in norm_threshold:\n            norm_threshold[pair[0]] = {}\n        norm_threshold[pair[0]][pair[1]] = {}\n    out = open(file_name, 'w')\n    print('#### summary of rbh comparisons\\n', file=out)\n    comparisons = []\n    for genome in rbh:\n        for compare in rbh[genome]:\n            pair = ''.join(sorted([genome, compare]))\n            if pair in comparisons:\n                continue\n            comparisons.append(pair)\n            scores = {'percent identity': [], 'e-value': [], 'bit score': [], 'normalized bit score': [], 'alignment length fraction': []}\n            print('### blast between %s and %s\\n' % (genome, compare), file=out)\n            for id in rbh[genome][compare]:\n                pident, length_fraction, e, bit, norm_bit = rbh[genome][compare][id][3:]\n                scores['percent identity'].append(pident)\n                scores['alignment length fraction'].append(length_fraction)\n                scores['e-value'].append(e)\n                scores['bit score'].append(bit)\n                scores['normalized bit score'].append(norm_bit)\n            if calc_threshold is True:\n                norms = scores['normalized bit score']\n                average = numpy.average(norms) \n                std = numpy.std(norms)\n                normal_thresh = average - (std * stdevs)\n                print('## average normalized bit score: %s' % average, file=out)\n                print('## standard deviation of normalized bit scores: %s' % std, file=out)\n                print('## normalized bit score threshold set to: %s\\n' % (normal_thresh), file=out)\n                norm_threshold[genome][compare], norm_threshold[compare][genome] = normal_thresh, normal_thresh\n            for score in scores:\n                print('## %s' % (score), file=out)\n                if len(scores[score]) > 0:\n                    print('## average: %s' % numpy.average(scores[score]), file=out)\n#                    hist = histogram(scores[score], [])\n#                    for line in hist:\n#                        print >> out, line\n                print('', file=out)\n    out.close()\n    if calc_threshold is True:\n        return thresholds[0:-1] + [norm_threshold]\n    else:\n        return thresholds", "label": 1}
{"code": "def remove_recipient(recipient)\n      raise 'Tried to remove recipient from a non-group channel' unless group?\n      raise ArgumentError, 'Tried to remove a non-recipient from a group' unless recipient.is_a?(Recipient)\n\n      @recipients.delete(recipient)\n    end", "label": 4}
{"code": "func (f *FileName) FromString(name string) {\n\tname = strings.TrimPrefix(name, \"/\")\n\n\tcp := strings.Split(name, \"/\")\n\n\tcp = append([]string{serverPolicyRootShareName}, cp...)\n\n\tf.Name = strings.Join(cp, \"\\x00\")\n\tf.Length = uint32(len(f.Name))\n}", "label": 5}
{"code": "def get_elem(elem_ref, default=None):\n    \"\"\"\n    Gets the element referenced by elem_ref or returns the elem_ref directly if its not a reference.\n\n    :param elem_ref:\n    :param default:\n    :return:\n    \"\"\"\n    if not is_elem_ref(elem_ref):\n        return elem_ref\n    elif elem_ref[0] == ElemRefObj:\n        return getattr(elem_ref[1], elem_ref[2], default)\n    elif elem_ref[0] == ElemRefArr:\n        return elem_ref[1][elem_ref[2]]", "label": 1}
{"code": "function get(req, res, next) {\n\n  //Admin Fields And Data Sources Should Not Be Shown For App Requests\n  var showAdminAndDataSources = !req.params.projectid;\n\n  var getParams = {\n    \"_id\": req.params.id,\n    \"showAdminFields\": showAdminAndDataSources,\n    includeDataSources: showAdminAndDataSources,\n    //Data Source Caches are required for app requests\n    expectDataSourceCache: !showAdminAndDataSources\n  };\n\n  logger.debug(\"Middleware: Get form: \", {getParams: getParams});\n\n  forms.getForm(_.extend(req.connectionOptions, getParams), formsResultHandlers(constants.resultTypes.forms, req, next));\n}", "label": 3}
{"code": "public function activeElement()\n    {\n        $response = $this->driver->execute(DriverCommand::GET_ACTIVE_ELEMENT, []);\n        $method = new RemoteExecuteMethod($this->driver);\n\n        return new RemoteWebElement($method, $response['ELEMENT']);\n    }", "label": 2}
{"code": "public static base_response clear(nitro_service client, Interface resource) throws Exception {\n\t\tInterface clearresource = new Interface();\n\t\tclearresource.id = resource.id;\n\t\treturn clearresource.perform_operation(client,\"clear\");\n\t}", "label": 0}
{"code": "def stop(self, timeout=5):\n        \"\"\"\n        Stop the container. The container must have been created.\n\n        :param timeout:\n            Timeout in seconds to wait for the container to stop before sending\n            a ``SIGKILL``. Default: 5 (half the Docker default)\n        \"\"\"\n        self.inner().stop(timeout=timeout)\n        self.inner().reload()", "label": 1}
{"code": "public static Object unmarshal(String message, Class<?> childClass) {\n        try {\n            Class<?>[] reverseAndToArray = Iterables.toArray(Lists.reverse(getAllSuperTypes(childClass)), Class.class);\n            JAXBContext jaxbCtx = JAXBContext.newInstance(reverseAndToArray);\n            Unmarshaller unmarshaller = jaxbCtx.createUnmarshaller();\n\n            return unmarshaller.unmarshal(new StringReader(message));\n        } catch (Exception e) {\n        }\n\n        return null;\n    }", "label": 0}
{"code": "def defaults(values={}):\r\n    \"\"\"Returns a once-assembled dict of this module's storable attributes.\"\"\"\r\n    if values: return values\r\n    save_types = basestring, int, float, tuple, list, dict, type(None)\r\n    for k, v in globals().items():\r\n        if isinstance(v, save_types) and not k.startswith(\"_\"): values[k] = v\r\n    return values", "label": 1}
{"code": "def dispersion_ranking_NN(self, nnm, num_norm_avg=50):\n        \"\"\"Computes the spatial dispersion factors for each gene.\n\n        Parameters\n        ----------\n        nnm - scipy.sparse, float\n            Square cell-to-cell nearest-neighbor matrix.\n\n        num_norm_avg - int, optional, default 50\n            The top 'num_norm_avg' dispersions are averaged to determine the\n            normalization factor when calculating the weights. This ensures\n            that outlier genes do not significantly skew the weight\n            distribution.\n\n        Returns:\n        -------\n        indices - ndarray, int\n            The indices corresponding to the gene weights sorted in decreasing\n            order.\n\n        weights - ndarray, float\n            The vector of gene weights.\n        \"\"\"\n\n        self.knn_avg(nnm)\n        D_avg = self.adata.layers['X_knn_avg']\n\n        mu, var = sf.mean_variance_axis(D_avg, axis=0)\n\n        dispersions = np.zeros(var.size)\n        dispersions[mu > 0] = var[mu > 0] / mu[mu > 0]\n\n        self.adata.var['spatial_dispersions'] = dispersions.copy()\n\n        ma = np.sort(dispersions)[-num_norm_avg:].mean()\n        dispersions[dispersions >= ma] = ma\n\n        weights = ((dispersions / dispersions.max())**0.5).flatten()\n\n        self.adata.var['weights'] = weights\n\n        return weights", "label": 1}
{"code": "public function setJarFileUris($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->jar_file_uris = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def load_main_manifest\n    parser = Parser::EvaluatingParser.singleton\n    parsed_code = Puppet[:code]\n    program = if parsed_code != \"\"\n      parser.parse_string(parsed_code, 'unknown-source-location')\n    else\n      file = @environment.manifest\n\n      # if the manifest file is a reference to a directory, parse and combine\n      # all .pp files in that directory\n      if file == Puppet::Node::Environment::NO_MANIFEST\n        nil\n      elsif File.directory?(file)\n        raise Puppet::Error, \"manifest of environment '#{@environment.name}' appoints directory '#{file}'. It must be a file\"\n      elsif File.exists?(file)\n        parser.parse_file(file)\n      else\n        raise Puppet::Error, \"manifest of environment '#{@environment.name}' appoints '#{file}'. It does not exist\"\n      end\n    end\n    instantiate_definitions(program, public_environment_loader) unless program.nil?\n    program\n  rescue Puppet::ParseErrorWithIssue => detail\n    detail.environment = @environment.name\n    raise\n  rescue => detail\n    msg = _('Could not parse for environment %{env}: %{detail}') % { env: @environment, detail: detail }\n    error = Puppet::Error.new(msg)\n    error.set_backtrace(detail.backtrace)\n    raise error\n  end", "label": 4}
{"code": "def group_reads_by_allele(allele_reads):\n    \"\"\"\n    Returns dictionary mapping each allele's nucleotide sequence to a list of\n    supporting AlleleRead objects.\n    \"\"\"\n    allele_to_reads_dict = defaultdict(list)\n    for allele_read in allele_reads:\n        allele_to_reads_dict[allele_read.allele].append(allele_read)\n    return allele_to_reads_dict", "label": 1}
{"code": "def handle_program_options():\n    \"\"\"\n    Uses the built-in argparse module to handle command-line options for the\n    program.\n\n    :return: The gathered command-line options specified by the user\n    :rtype: argparse.ArgumentParser\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Convert Sanger-sequencing \\\n                                     derived data files for use with the \\\n                                     metagenomics analysis program QIIME, by \\\n                                     extracting Sample ID information, adding\\\n                                     barcodes and primers to the sequence \\\n                                     data, and outputting a mapping file and\\\n                                     single FASTA-formatted sequence file \\\n                                     formed by concatenating all input data.\")\n    parser.add_argument('-i', '--input_dir', required=True,\n                        help=\"The directory containing sequence data files. \\\n                              Assumes all data files are placed in this \\\n                              directory. For files organized within folders by\\\n                              sample, use -s in addition.\")\n    parser.add_argument('-m', '--map_file', default='map.txt',\n                        help=\"QIIME-formatted mapping file linking Sample IDs \\\n                              with barcodes and primers.\")\n    parser.add_argument('-o', '--output', default='output.fasta',\n                        metavar='OUTPUT_FILE',\n                        help=\"Single file containing all sequence data found \\\n                              in input_dir, FASTA-formatted with barcode and \\\n                              primer preprended to sequence. If the -q option \\\n                              is passed, any quality data will also be output \\\n                              to a single file of the same name with a .qual \\\n                              extension.\")\n    parser.add_argument('-b', '--barcode_length', type=int, default=12,\n                        help=\"Length of the generated barcode sequences. \\\n                              Default is 12 (QIIME default), minimum is 8.\")\n\n    parser.add_argument('-q', '--qual', action='store_true', default=False,\n                        help=\"Instruct the program to look for quality \\\n                              input files\")\n    parser.add_argument('-u', '--utf16', action='store_true', default=False,\n                        help=\"UTF-16 encoded input files\")\n\n    parser.add_argument('-t', '--treatment',\n                        help=\"Inserts an additional column into the mapping \\\n                              file specifying some treatment or other variable\\\n                              that separates the current set of sequences \\\n                              from any other set of seqeunces. For example:\\\n                              -t DiseaseState=healthy\")\n\n    # data input options\n    sidGroup = parser.add_mutually_exclusive_group(required=True)\n    sidGroup.add_argument('-d', '--identifier_pattern',\n                          action=ValidateIDPattern,\n                          nargs=2, metavar=('SEPARATOR', 'FIELD_NUMBER'),\n                          help=\"Indicates how to extract the Sample ID from \\\n                               the description line. Specify two things: \\\n                               1. Field separator, 2. Field number of Sample \\\n                               ID (1 or greater). If the separator is a space \\\n                               or tab, use \\s or \\\\t respectively. \\\n                               Example: >ka-SampleID-2091, use -i - 2, \\\n                               indicating - is the separator and the Sample ID\\\n                               is field #2.\")\n    sidGroup.add_argument('-f', '--filename_sample_id', action='store_true',\n                          default=False, help='Specify that the program should\\\n                          the name of each fasta file as the Sample ID for use\\\n                          in the mapping file. This is meant to be used when \\\n                          all sequence data for a sample is stored in a single\\\n                          file.')\n\n    return parser.parse_args()", "label": 1}
{"code": "public static base_responses update(nitro_service client, gslbsite resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tgslbsite updateresources[] = new gslbsite[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new gslbsite();\n\t\t\t\tupdateresources[i].sitename = resources[i].sitename;\n\t\t\t\tupdateresources[i].metricexchange = resources[i].metricexchange;\n\t\t\t\tupdateresources[i].nwmetricexchange = resources[i].nwmetricexchange;\n\t\t\t\tupdateresources[i].sessionexchange = resources[i].sessionexchange;\n\t\t\t\tupdateresources[i].triggermonitor = resources[i].triggermonitor;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def isinstance_(x, A_tuple):\n    \"\"\" native isinstance_ with the test for typing.Union overridden \"\"\"\n    if is_union(A_tuple):\n        return any(isinstance_(x, t) for t in A_tuple.__args__)\n    elif getattr(A_tuple, '__origin__', None) is not None:\n        return isinstance(x, A_tuple.__origin__)\n    else:\n        return isinstance(x, A_tuple)", "label": 1}
{"code": "def vacuum(self, threshold=0.3):\n        '''\n        Force garbage collection\n\n        :param float threshold (optional): The threshold is optional, and\n        will not change the default threshold.\n        :rtype: boolean\n\n        '''\n        url = (\"http://{master_addr}:{master_port}/\"\n               \"vol/vacuum?garbageThreshold={threshold}\").format(\n            master_addr=self.master_addr,\n            master_port=self.master_port,\n            threshold=threshold)\n        res = self.conn.get_data(url)\n        if res is not None:\n            return True\n        return False", "label": 1}
{"code": "def schema():\n        \"\"\"Provide schema for shell configuration.\"\"\"\n        return Schema({\n            'script': And(Or(type(' '), type(u' ')), len),\n            Optional('title', default=''): str,\n            Optional('model', default={}): {Optional(And(str, len)): object},\n            Optional('env', default={}): {Optional(And(str, len)): And(str, len)},\n            Optional('item', default=None): object,\n            Optional('dry_run', default=False): bool,\n            Optional('debug', default=False): bool,\n            Optional('strict', default=False): bool,\n            Optional('variables', default={}): {\n                Optional(And(Or(type(' '), type(u' ')), len, Regex(r'([a-zA-Z][_a-zA-Z]*)'))):\n                    Or(type(' '), type(u' '))\n            },\n            Optional('temporary_scripts_path', default=''): Or(type(''), type(u'')),\n            Optional('internal', default=False): bool\n        })", "label": 1}
{"code": "function detect_list(type, doc_map) {\n    if (doc_map[type])\n      return _.flatten(_.map(doc_map[type], function(d) { d[type] }));\n    else\n      return null;\n}", "label": 3}
{"code": "public function ceilWeek($weekStartsAt = null)\n    {\n        if ($this->isMutable()) {\n            $startOfWeek = $this->copy()->startOfWeek($weekStartsAt);\n\n            return $startOfWeek != $this ?\n                $this->startOfWeek($weekStartsAt)->addWeek() :\n                $this;\n        }\n\n        $startOfWeek = $this->startOfWeek($weekStartsAt);\n\n        return $startOfWeek != $this ?\n            $startOfWeek->addWeek() :\n            $this->copy();\n    }", "label": 2}
{"code": "def list_receivers(self):\n        \"\"\"\n        Prints a list of all registered receivers. Including signal, plugin name and description.\n        \"\"\"\n        print(\"Receiver list\")\n        print(\"*************\\n\")\n        for key, receiver in self.app.signals.receivers.items():\n            print(\"%s <-- %s (%s):\\n  %s\\n\" % (receiver.name,\n                                               receiver.signal,\n                                               receiver.plugin.name,\n                                               receiver.description))", "label": 1}
{"code": "public static base_response Import(nitro_service client, responderhtmlpage resource) throws Exception {\n\t\tresponderhtmlpage Importresource = new responderhtmlpage();\n\t\tImportresource.src = resource.src;\n\t\tImportresource.name = resource.name;\n\t\tImportresource.comment = resource.comment;\n\t\tImportresource.overwrite = resource.overwrite;\n\t\treturn Importresource.perform_operation(client,\"Import\");\n\t}", "label": 0}
{"code": "public static function jobName($project, $location, $job)\n    {\n        return self::getJobNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'job' => $job,\n        ]);\n    }", "label": 2}
{"code": "public String propertyValue(Properties attributes) throws XDocletException\r\n    {\r\n        String value = getPropertyValue(attributes.getProperty(ATTRIBUTE_LEVEL), attributes.getProperty(ATTRIBUTE_NAME));\r\n\r\n        if (value == null)\r\n        {\r\n            value = attributes.getProperty(ATTRIBUTE_DEFAULT);\r\n        }\r\n        return value;\r\n    }", "label": 0}
{"code": "public ExecutorLoadBalancingConfig<GROUP> useLoadBalancedEnumOrdinalPrioritizer(Class<GROUP> groupClass) {\n        if(!groupClass.isEnum()) {\n            throw new IllegalArgumentException(\"The group class \"+groupClass+\" is not an enum\");\n        }\n        groupPrioritizer = new LoadBalancedPriorityPrioritizer<GROUP>(new EnumOrdinalPrioritizer<GROUP>());\n        return this;\n    }", "label": 0}
{"code": "def serve\n      # Note, looks like stopping jets server with Ctrl-C sends the TERM signal\n      # down to the sub bin/rackup command cleans up the child process fine.\n      Bundler.with_clean_env do\n        args = ''\n        # only forward the host option, port is always 9292 for simplicity\n        if @options[:host]\n          args << \" --host #{@options[:host]}\"\n        else\n          args << \" --host 127.0.0.1\" # using the default localhost is not starting up https://stackoverflow.com/questions/4356646/address-family-not-supported-by-protocol-family\n        end\n\n\n        command = \"cd #{rack_project} && bin/rackup#{args}\" # leads to the same wrapper rack scripts\n        puts \"=> #{command}\".color(:green)\n        system(command)\n      end\n    end", "label": 4}
{"code": "private function auto_check_update() {\n\n\t\t// `wp cli update` only works with Phars at this time.\n\t\tif ( ! Utils\\inside_phar() ) {\n\t\t\treturn;\n\t\t}\n\n\t\t$existing_phar = realpath( $_SERVER['argv'][0] );\n\t\t// Phar needs to be writable to be easily updateable.\n\t\tif ( ! is_writable( $existing_phar ) || ! is_writable( dirname( $existing_phar ) ) ) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Only check for update when a human is operating.\n\t\tif ( ! function_exists( 'posix_isatty' ) || ! posix_isatty( STDOUT ) ) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Allow hosts and other providers to disable automatic check update.\n\t\tif ( getenv( 'WP_CLI_DISABLE_AUTO_CHECK_UPDATE' ) ) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Permit configuration of number of days between checks.\n\t\t$days_between_checks = getenv( 'WP_CLI_AUTO_CHECK_UPDATE_DAYS' );\n\t\tif ( false === $days_between_checks ) {\n\t\t\t$days_between_checks = 1;\n\t\t}\n\n\t\t$cache     = WP_CLI::get_cache();\n\t\t$cache_key = 'wp-cli-update-check';\n\t\t// Bail early on the first check, so we don't always check on an unwritable cache.\n\t\tif ( ! $cache->has( $cache_key ) ) {\n\t\t\t$cache->write( $cache_key, time() );\n\t\t\treturn;\n\t\t}\n\n\t\t// Bail if last check is still within our update check time period.\n\t\t$last_check = (int) $cache->read( $cache_key );\n\t\tif ( ( time() - ( 24 * 60 * 60 * $days_between_checks ) ) < $last_check ) {\n\t\t\treturn;\n\t\t}\n\n\t\t// In case the operation fails, ensure the timestamp has been updated.\n\t\t$cache->write( $cache_key, time() );\n\n\t\t// Check whether any updates are available.\n\t\tob_start();\n\t\tWP_CLI::run_command(\n\t\t\tarray( 'cli', 'check-update' ),\n\t\t\tarray(\n\t\t\t\t'format' => 'count',\n\t\t\t)\n\t\t);\n\t\t$count = ob_get_clean();\n\t\tif ( ! $count ) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Looks like an update is available, so let's prompt to update.\n\t\tWP_CLI::run_command( array( 'cli', 'update' ) );\n\t\t// If the Phar was replaced, we can't proceed with the original process.\n\t\texit;\n\t}", "label": 2}
{"code": "public static base_response update(nitro_service client, vpnsessionaction resource) throws Exception {\n\t\tvpnsessionaction updateresource = new vpnsessionaction();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.httpport = resource.httpport;\n\t\tupdateresource.winsip = resource.winsip;\n\t\tupdateresource.dnsvservername = resource.dnsvservername;\n\t\tupdateresource.splitdns = resource.splitdns;\n\t\tupdateresource.sesstimeout = resource.sesstimeout;\n\t\tupdateresource.clientsecurity = resource.clientsecurity;\n\t\tupdateresource.clientsecuritygroup = resource.clientsecuritygroup;\n\t\tupdateresource.clientsecuritymessage = resource.clientsecuritymessage;\n\t\tupdateresource.clientsecuritylog = resource.clientsecuritylog;\n\t\tupdateresource.splittunnel = resource.splittunnel;\n\t\tupdateresource.locallanaccess = resource.locallanaccess;\n\t\tupdateresource.rfc1918 = resource.rfc1918;\n\t\tupdateresource.spoofiip = resource.spoofiip;\n\t\tupdateresource.killconnections = resource.killconnections;\n\t\tupdateresource.transparentinterception = resource.transparentinterception;\n\t\tupdateresource.windowsclienttype = resource.windowsclienttype;\n\t\tupdateresource.defaultauthorizationaction = resource.defaultauthorizationaction;\n\t\tupdateresource.authorizationgroup = resource.authorizationgroup;\n\t\tupdateresource.clientidletimeout = resource.clientidletimeout;\n\t\tupdateresource.proxy = resource.proxy;\n\t\tupdateresource.allprotocolproxy = resource.allprotocolproxy;\n\t\tupdateresource.httpproxy = resource.httpproxy;\n\t\tupdateresource.ftpproxy = resource.ftpproxy;\n\t\tupdateresource.socksproxy = resource.socksproxy;\n\t\tupdateresource.gopherproxy = resource.gopherproxy;\n\t\tupdateresource.sslproxy = resource.sslproxy;\n\t\tupdateresource.proxyexception = resource.proxyexception;\n\t\tupdateresource.proxylocalbypass = resource.proxylocalbypass;\n\t\tupdateresource.clientcleanupprompt = resource.clientcleanupprompt;\n\t\tupdateresource.forcecleanup = resource.forcecleanup;\n\t\tupdateresource.clientoptions = resource.clientoptions;\n\t\tupdateresource.clientconfiguration = resource.clientconfiguration;\n\t\tupdateresource.sso = resource.sso;\n\t\tupdateresource.ssocredential = resource.ssocredential;\n\t\tupdateresource.windowsautologon = resource.windowsautologon;\n\t\tupdateresource.usemip = resource.usemip;\n\t\tupdateresource.useiip = resource.useiip;\n\t\tupdateresource.clientdebug = resource.clientdebug;\n\t\tupdateresource.loginscript = resource.loginscript;\n\t\tupdateresource.logoutscript = resource.logoutscript;\n\t\tupdateresource.homepage = resource.homepage;\n\t\tupdateresource.icaproxy = resource.icaproxy;\n\t\tupdateresource.wihome = resource.wihome;\n\t\tupdateresource.citrixreceiverhome = resource.citrixreceiverhome;\n\t\tupdateresource.wiportalmode = resource.wiportalmode;\n\t\tupdateresource.clientchoices = resource.clientchoices;\n\t\tupdateresource.epaclienttype = resource.epaclienttype;\n\t\tupdateresource.iipdnssuffix = resource.iipdnssuffix;\n\t\tupdateresource.forcedtimeout = resource.forcedtimeout;\n\t\tupdateresource.forcedtimeoutwarning = resource.forcedtimeoutwarning;\n\t\tupdateresource.ntdomain = resource.ntdomain;\n\t\tupdateresource.clientlessvpnmode = resource.clientlessvpnmode;\n\t\tupdateresource.emailhome = resource.emailhome;\n\t\tupdateresource.clientlessmodeurlencoding = resource.clientlessmodeurlencoding;\n\t\tupdateresource.clientlesspersistentcookie = resource.clientlesspersistentcookie;\n\t\tupdateresource.allowedlogingroups = resource.allowedlogingroups;\n\t\tupdateresource.securebrowse = resource.securebrowse;\n\t\tupdateresource.storefronturl = resource.storefronturl;\n\t\tupdateresource.kcdaccount = resource.kcdaccount;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func WrongCommand(message, usage string) *HTTPResult {\n\treturn &HTTPResult{\n\t\tMessage: message,\n\t\tDetails: &UsageCmd{Usage: usage},\n\t}\n}", "label": 5}
{"code": "func (tl TypeLoader) LoadSchema(args *ArgType) error {\n\tvar err error\n\n\t// load enums\n\t_, err = tl.LoadEnums(args)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// load procs\n\t_, err = tl.LoadProcs(args)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// load tables\n\ttableMap, err := tl.LoadRelkind(args, Table)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// load views\n\tviewMap, err := tl.LoadRelkind(args, View)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// merge views with the tableMap\n\tfor k, v := range viewMap {\n\t\ttableMap[k] = v\n\t}\n\n\t// load foreign keys\n\t_, err = tl.LoadForeignKeys(args, tableMap)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// load indexes\n\t_, err = tl.LoadIndexes(args, tableMap)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static base_response unset(nitro_service client, nshttpparam resource, String[] args) throws Exception{\n\t\tnshttpparam unsetresource = new nshttpparam();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def write_doc_from_tmpfile(self,\n                               doc_id,\n                               tmpfi,\n                               parent_sha,\n                               auth_info,\n                               commit_msg='',\n                               doctype_display_name=\"document\"):\n        \"\"\"Given a doc_id, temporary filename of content, branch and auth_info\n        \"\"\"\n        gh_user, author = get_user_author(auth_info)\n        doc_filepath = self.path_for_doc(doc_id)\n        doc_dir = os.path.split(doc_filepath)[0]\n        if parent_sha is None:\n            self.checkout_master()\n            parent_sha = self.get_master_sha()\n        branch = self.create_or_checkout_branch(gh_user, doc_id, parent_sha)\n\n        # build complete (probably type-specific) commit message\n        default_commit_msg = \"Update %s '%s' via OpenTree API\" % (doctype_display_name, doc_id)\n        if commit_msg:\n            commit_msg = \"%s\\n\\n(%s)\" % (commit_msg, default_commit_msg)\n        else:\n            commit_msg = default_commit_msg\n\n        # create a doc directory if this is a new document  EJM- what if it isn't?\n        if not os.path.isdir(doc_dir):\n            os.makedirs(doc_dir)\n\n        if os.path.exists(doc_filepath):\n            prev_file_sha = self.get_blob_sha_for_file(doc_filepath)\n        else:\n            prev_file_sha = None\n        shutil.copy(tmpfi.name, doc_filepath)\n        self._add_and_commit(doc_filepath, author, commit_msg)\n        new_sha = git(self.gitdir, self.gitwd, \"rev-parse\", \"HEAD\")\n        _LOG.debug('Committed document \"{i}\" to branch \"{b}\" commit SHA: \"{s}\"'.format(i=doc_id,\n                                                                                       b=branch,\n                                                                                       s=new_sha.strip()))\n        return {'commit_sha': new_sha.strip(),\n                'branch': branch,\n                'prev_file_sha': prev_file_sha,\n                }", "label": 1}
{"code": "def parse(self, words):\n        \"\"\"A general method for parsing word-representations of numbers.\n        Supports floats and integers.\n\n        Args:\n            words (str): Description of an arbitrary number.\n\n        Returns:\n            A double representation of the words.\n        \"\"\"\n        def exact(words):\n            \"\"\"If already represented as float or int, convert.\"\"\"\n            try:\n                return float(words)\n            except:\n                return None\n\n        guess = exact(words)\n        if guess is not None:\n            return guess\n\n        split = words.split(' ')\n\n        # Replace final ordinal/fraction with number\n        if split[-1] in self.__fractions__:\n            split[-1] = self.__fractions__[split[-1]]\n        elif split[-1] in self.__ordinals__:\n            split[-1] = self.__ordinals__[split[-1]]\n\n        parsed_ordinals = ' '.join(split)\n\n        return self.parseFloat(parsed_ordinals)", "label": 1}
{"code": "def exponential(x, y, xscale, yscale):\n    \"\"\"\n    Two-dimensional oriented exponential decay pattern.\n    \"\"\"\n    if xscale==0.0 or yscale==0.0:\n        return x*0.0\n\n    with float_error_ignore():\n        x_w = np.divide(x,xscale)\n        y_h = np.divide(y,yscale)\n        return np.exp(-np.sqrt(x_w*x_w+y_h*y_h))", "label": 1}
{"code": "def plot_correlated_genes(\n            self,\n            name,\n            n_genes=5,\n            number_of_features=1000,\n            **kwargs):\n        \"\"\"Plots gene expression patterns correlated with the input gene.\n\n        Parameters\n        ----------\n        name - string\n            The name of the gene with respect to which correlated gene\n            expression patterns will be displayed.\n\n        n_genes - int, optional, default 5\n            The number of top ranked correlated genes to display.\n\n        **kwargs -\n            All keyword arguments in 'show_gene_expression' and 'scatter'\n            are eligible.\n        \"\"\"\n        all_gene_names = np.array(list(self.adata.var_names))\n        if((all_gene_names == name).sum() == 0):\n            print(\n                \"Gene not found in the filtered dataset. Note that genes \"\n                \"are case sensitive.\")\n            return\n        sds = self.corr_bin_genes(\n            input_gene=name,\n            number_of_features=number_of_features)\n        if (n_genes + 1 > sds.size):\n            x = sds.size\n        else:\n            x = n_genes + 1\n\n        for i in range(1, x):\n            self.show_gene_expression(sds[i], **kwargs)\n        return sds[1:]", "label": 1}
{"code": "public static base_responses update(nitro_service client, responderaction resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tresponderaction updateresources[] = new responderaction[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new responderaction();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].target = resources[i].target;\n\t\t\t\tupdateresources[i].bypasssafetycheck = resources[i].bypasssafetycheck;\n\t\t\t\tupdateresources[i].htmlpage = resources[i].htmlpage;\n\t\t\t\tupdateresources[i].comment = resources[i].comment;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public void setDateAttribute(String name, Date value) {\n\t\tensureAttributes();\n\t\tAttribute attribute = new DateAttribute(value);\n\t\tattribute.setEditable(isEditable(name));\n\t\tgetAllAttributes().put(name, attribute);\n\t}", "label": 0}
{"code": "def find(patterns, excluded_patterns)\n      excluded_patterns = excluded_patterns.map { |pattern| normalize_path(pattern) }\n\n      extract_files_from(patterns).reject do |file|\n        excluded_patterns.any? do |exclusion_glob|\n          HamlLint::Utils.any_glob_matches?(exclusion_glob, file)\n        end\n      end\n    end", "label": 4}
{"code": "def decision_function(self, X):\n        \"\"\"\n        Generate an inlier score for each test data example.\n\n        Parameters\n        ----------\n        X : array\n            Test data, of dimension N times d (rows are examples, columns\n            are data dimensions)\n\n        Returns:\n        -------\n        scores : array\n            A vector of length N, where each element contains an inlier\n            score in the range 0-1 (outliers have values close to zero,\n            inliers have values close to one).\n        \"\"\"\n        predictions = self.predict_proba(X)\n        out = np.zeros((predictions.shape[0], 1))\n        out[:, 0] = 1 - predictions[:, -1]\n        return out", "label": 1}
{"code": "public function addCookie($cookie)\n    {\n        if (is_array($cookie)) {\n            $cookie = Cookie::createFromArray($cookie);\n        }\n        if (!$cookie instanceof Cookie) {\n            throw new InvalidArgumentException('Cookie must be set from instance of Cookie class or from array.');\n        }\n\n        $this->executor->execute(\n            DriverCommand::ADD_COOKIE,\n            ['cookie' => $cookie->toArray()]\n        );\n\n        return $this;\n    }", "label": 2}
{"code": "function ensureLineWrapped(lineView) {\n    if (lineView.node == lineView.text) {\n      lineView.node = elt(\"div\", null, null, \"position: relative\");\n      if (lineView.text.parentNode)\n        lineView.text.parentNode.replaceChild(lineView.node, lineView.text);\n      lineView.node.appendChild(lineView.text);\n      if (ie && ie_version < 8) lineView.node.style.zIndex = 2;\n    }\n    return lineView.node;\n  }", "label": 3}
{"code": "public <L extends Listener> void popEvent(Event<?, L> expected) {\n        synchronized (this.stack) {\n            final Event<?, ?> actual = this.stack.pop();\n            if (actual != expected) {\n                throw new IllegalStateException(String.format(\n                        \"Unbalanced pop: expected '%s' but encountered '%s'\",\n                        expected.getListenerClass(), actual));\n            }\n        }\n    }", "label": 0}
{"code": "func NewDataStoreFromConfig(dsc discoverapi.DatastoreConfigData) (DataStore, error) {\n\tvar (\n\t\tok    bool\n\t\tsCfgP *store.Config\n\t)\n\n\tsCfgP, ok = dsc.Config.(*store.Config)\n\tif !ok && dsc.Config != nil {\n\t\treturn nil, fmt.Errorf(\"cannot parse store configuration: %v\", dsc.Config)\n\t}\n\n\tscopeCfg := &ScopeCfg{\n\t\tClient: ScopeClientCfg{\n\t\t\tAddress:  dsc.Address,\n\t\t\tProvider: dsc.Provider,\n\t\t\tConfig:   sCfgP,\n\t\t},\n\t}\n\n\tds, err := NewDataStore(dsc.Scope, scopeCfg)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to construct datastore client from datastore configuration %v: %v\", dsc, err)\n\t}\n\n\treturn ds, err\n}", "label": 5}
{"code": "def load_graph_from_rdf(fname):\n    \"\"\" reads an RDF file into a graph \"\"\"\n    print(\"reading RDF from \" + fname + \"....\")\n    store = Graph()\n    store.parse(fname, format=\"n3\")\n    print(\"Loaded \" + str(len(store)) + \" tuples\")\n    return store", "label": 1}
{"code": "def all(query)\n      return to_enum(:all, query) unless block_given?\n\n      if @hash.include? query\n        yield @hash[query]\n        return\n      end\n\n      case query\n      when String\n        optimize_if_necessary!\n\n        # see if any of the regexps match the string\n        @regexes.each do |regex|\n          match = regex.match(query)\n          next unless match\n          @regex_counts[regex] += 1\n          value = @hash[regex]\n          if value.respond_to? :call\n            yield value.call(match)\n          else\n            yield value\n          end\n        end\n\n      when Numeric\n        # see if any of the ranges match the integer\n        @ranges.each do |range|\n          yield @hash[range] if range.cover? query\n        end\n\n      when Regexp\n        # Reverse operation: `rash[/regexp/]` returns all the hash's string keys which match the regexp\n        @hash.each do |key, val|\n          yield val if key.is_a?(String) && query =~ key\n        end\n      end\n    end", "label": 4}
{"code": "function getPromisedType(promise) {\n            //\n            //  { // promise\n            //      then( // thenFunction\n            //          onfulfilled: ( // onfulfilledParameterType\n            //              value: T // valueParameterType\n            //          ) => any\n            //      ): any;\n            //  }\n            //\n            if (isTypeAny(promise)) {\n                return undefined;\n            }\n            if (promise.flags & 131072 /* Reference */) {\n                if (promise.target === tryGetGlobalPromiseType()\n                    || promise.target === getGlobalPromiseLikeType()) {\n                    return promise.typeArguments[0];\n                }\n            }\n            var globalPromiseLikeType = getInstantiatedGlobalPromiseLikeType();\n            if (globalPromiseLikeType === emptyObjectType || !isTypeAssignableTo(promise, globalPromiseLikeType)) {\n                return undefined;\n            }\n            var thenFunction = getTypeOfPropertyOfType(promise, \"then\");\n            if (!thenFunction || isTypeAny(thenFunction)) {\n                return undefined;\n            }\n            var thenSignatures = getSignaturesOfType(thenFunction, 0 /* Call */);\n            if (thenSignatures.length === 0) {\n                return undefined;\n            }\n            var onfulfilledParameterType = getTypeWithFacts(getUnionType(ts.map(thenSignatures, getTypeOfFirstParameterOfSignature)), 131072 /* NEUndefined */);\n            if (isTypeAny(onfulfilledParameterType)) {\n                return undefined;\n            }\n            var onfulfilledParameterSignatures = getSignaturesOfType(onfulfilledParameterType, 0 /* Call */);\n            if (onfulfilledParameterSignatures.length === 0) {\n                return undefined;\n            }\n            return getUnionType(ts.map(onfulfilledParameterSignatures, getTypeOfFirstParameterOfSignature), /*subtypeReduction*/ true);\n        }", "label": 3}
{"code": "def verify_connection!(uri)\n      if default_options.persistent? && uri.origin != default_options.persistent\n        raise StateError, \"Persistence is enabled for #{default_options.persistent}, but we got #{uri.origin}\"\n      # We re-create the connection object because we want to let prior requests\n      # lazily load the body as long as possible, and this mimics prior functionality.\n      elsif @connection && (!@connection.keep_alive? || @connection.expired?)\n        close\n      # If we get into a bad state (eg, Timeout.timeout ensure being killed)\n      # close the connection to prevent potential for mixed responses.\n      elsif @state == :dirty\n        close\n      end\n    end", "label": 4}
{"code": "func (c *Client) UpsertOIDCConnector(connector services.OIDCConnector) error {\n\tdata, err := services.GetOIDCConnectorMarshaler().MarshalOIDCConnector(connector)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = c.PostJSON(c.Endpoint(\"oidc\", \"connectors\"), &upsertOIDCConnectorRawReq{\n\t\tConnector: data,\n\t})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def upload_binary\n      UI.message(\"Uploading binary to App Store Connect\")\n      if options[:ipa]\n        package_path = FastlaneCore::IpaUploadPackageBuilder.new.generate(\n          app_id: options[:app].apple_id,\n          ipa_path: options[:ipa],\n          package_path: \"/tmp\",\n          platform: options[:platform]\n        )\n      elsif options[:pkg]\n        package_path = FastlaneCore::PkgUploadPackageBuilder.new.generate(\n          app_id: options[:app].apple_id,\n          pkg_path: options[:pkg],\n          package_path: \"/tmp\",\n          platform: options[:platform]\n        )\n      end\n\n      transporter = transporter_for_selected_team\n      result = transporter.upload(options[:app].apple_id, package_path)\n      UI.user_error!(\"Could not upload binary to App Store Connect. Check out the error above\", show_github_issues: true) unless result\n    end", "label": 4}
{"code": "function resolveBin (moduleName) {\n  // Get the directory from the module's package.json path\n  const directory = path.dirname(require.resolve(`${moduleName}/package.json`))\n\n  // Get the relative bin path from the module's package.json bin key\n  let bin = require(`${moduleName}/package.json`).bin\n\n  // Sometimes the bin file isn't a string but an object\n  // This extracts the first bin from that object\n  if (typeof bin !== 'string') {\n    bin = Object.values(bin)[0]\n  }\n\n  return path.join(directory, bin)\n}", "label": 3}
{"code": "public static base_response Import(nitro_service client, sslfipskey resource) throws Exception {\n\t\tsslfipskey Importresource = new sslfipskey();\n\t\tImportresource.fipskeyname = resource.fipskeyname;\n\t\tImportresource.key = resource.key;\n\t\tImportresource.inform = resource.inform;\n\t\tImportresource.wrapkeyname = resource.wrapkeyname;\n\t\tImportresource.iv = resource.iv;\n\t\tImportresource.exponent = resource.exponent;\n\t\treturn Importresource.perform_operation(client,\"Import\");\n\t}", "label": 0}
{"code": "func InDeltaMapValues(t TestingT, expected, actual interface{}, delta float64, msgAndArgs ...interface{}) bool {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif expected == nil || actual == nil ||\n\t\treflect.TypeOf(actual).Kind() != reflect.Map ||\n\t\treflect.TypeOf(expected).Kind() != reflect.Map {\n\t\treturn Fail(t, \"Arguments must be maps\", msgAndArgs...)\n\t}\n\n\texpectedMap := reflect.ValueOf(expected)\n\tactualMap := reflect.ValueOf(actual)\n\n\tif expectedMap.Len() != actualMap.Len() {\n\t\treturn Fail(t, \"Arguments must have the same number of keys\", msgAndArgs...)\n\t}\n\n\tfor _, k := range expectedMap.MapKeys() {\n\t\tev := expectedMap.MapIndex(k)\n\t\tav := actualMap.MapIndex(k)\n\n\t\tif !ev.IsValid() {\n\t\t\treturn Fail(t, fmt.Sprintf(\"missing key %q in expected map\", k), msgAndArgs...)\n\t\t}\n\n\t\tif !av.IsValid() {\n\t\t\treturn Fail(t, fmt.Sprintf(\"missing key %q in actual map\", k), msgAndArgs...)\n\t\t}\n\n\t\tif !InDelta(\n\t\t\tt,\n\t\t\tev.Interface(),\n\t\t\tav.Interface(),\n\t\t\tdelta,\n\t\t\tmsgAndArgs...,\n\t\t) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "function formatDevTrace(level, context, message, args, err) {\n  var str,\n      mainMessage = util.format.apply(global, [message].concat(args)),\n      printStack = API.stacktracesWith.indexOf(level) > -1,\n      errCommomMessage = err && (err.name + ': ' + err.message),\n      isErrorLoggingWithoutMessage = mainMessage === errCommomMessage;\n\n  switch (level) {\n    case 'DEBUG':\n      str = colors.grey(level);\n      break;\n    case 'INFO':\n      str = colors.blue(level) + ' '; // Pad to 5 chars\n      break;\n    case 'WARN':\n      str = colors.yellow(level) + ' '; // Pad to 5 chars\n      break;\n    case 'ERROR':\n      str = colors.red(level);\n      break;\n    case 'FATAL':\n      str = colors.red.bold(level);\n      break;\n  }\n  str += ' ' + mainMessage;\n\n  if (isErrorLoggingWithoutMessage) {\n    str += colorize(colors.gray, serializeErr(err).toString(printStack).substr(mainMessage.length));\n  } else if (err) {\n    str += '\\n' + colorize(colors.gray, serializeErr(err).toString(printStack));\n  }\n\n  var localContext = _.omit(context, formatDevTrace.omit);\n  str += Object.keys(localContext).length ?\n      ' ' + colorize(colors.gray, util.inspect(localContext)) :\n      '';\n\n  // pad all subsequent lines with as much spaces as \"DEBUG \" or \"INFO  \" have\n  return str.replace(new RegExp('\\r?\\n','g'), '\\n      ');\n}", "label": 3}
{"code": "func (i *Idm) GetID(serial bool) (uint64, error) {\n\tif i.handle == nil {\n\t\treturn 0, errors.New(\"ID set is not initialized\")\n\t}\n\tordinal, err := i.handle.SetAny(serial)\n\treturn i.start + ordinal, err\n}", "label": 5}
{"code": "def unordered_list(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'unordered_list_for', &block)\n      define_method(name) do\n        return platform.unordered_list_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "public function changeEmail($email)\n    {\n        if ($email !== $this->email) {\n            $this->email = $email;\n\n            $this->raise(new EmailChanged($this));\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function keyboardCapsLockLayout(layout, caps) {\n    return layout.map(function (row) {\n        return row.map(function (key) {\n            return isSpecial(key) ? key : (caps ? key.toUpperCase() : key.toLowerCase());\n        });\n    });\n}", "label": 3}
{"code": "public double[][] Kernel2D(int size) {\n        if (((size % 2) == 0) || (size < 3) || (size > 101)) {\n            try {\n                throw new Exception(\"Wrong size\");\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n\n        int r = size / 2;\n        double[][] kernel = new double[size][size];\n\n        // compute kernel\n        double sum = 0;\n        for (int y = -r, i = 0; i < size; y++, i++) {\n            for (int x = -r, j = 0; j < size; x++, j++) {\n                kernel[i][j] = Function2D(x, y);\n                sum += kernel[i][j];\n            }\n        }\n\n        for (int i = 0; i < kernel.length; i++) {\n            for (int j = 0; j < kernel[0].length; j++) {\n                kernel[i][j] /= sum;\n            }\n        }\n\n        return kernel;\n    }", "label": 0}
{"code": "func (r *AddressRange) UnmarshalJSON(data []byte) error {\n\tm := map[string]interface{}{}\n\terr := json.Unmarshal(data, &m)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif r.Sub, err = types.ParseCIDR(m[\"Sub\"].(string)); err != nil {\n\t\treturn err\n\t}\n\tr.Start = uint64(m[\"Start\"].(float64))\n\tr.End = uint64(m[\"End\"].(float64))\n\treturn nil\n}", "label": 5}
{"code": "public static base_responses save(nitro_service client, cachecontentgroup resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcachecontentgroup saveresources[] = new cachecontentgroup[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tsaveresources[i] = new cachecontentgroup();\n\t\t\t\tsaveresources[i].name = resources[i].name;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, saveresources,\"save\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setProjectRepoId($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\DevTools\\Source\\V1\\ProjectRepoId::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static final void setBounds(UIObject o, Rect bounds) {\n        setPosition(o, bounds);\n        setSize(o, bounds);\n    }", "label": 0}
{"code": "func (c *controller) cleanupServiceDiscovery(cleanupNID string) {\n\tc.Lock()\n\tdefer c.Unlock()\n\tif cleanupNID == \"\" {\n\t\tlogrus.Debugf(\"cleanupServiceDiscovery for all networks\")\n\t\tc.svcRecords = make(map[string]svcInfo)\n\t\treturn\n\t}\n\tlogrus.Debugf(\"cleanupServiceDiscovery for network:%s\", cleanupNID)\n\tdelete(c.svcRecords, cleanupNID)\n}", "label": 5}
{"code": "function _advanceFloatMargins()\n\t{\n\t\t// Update floatmargins - L\n\t\tif (isset($this->floatmargins['L']) && $this->floatmargins['L']['skipline'] && $this->floatmargins['L']['y0'] != $this->y) {\n\t\t\t$yadj = $this->y - $this->floatmargins['L']['y0'];\n\t\t\t$this->floatmargins['L']['y0'] = $this->y;\n\t\t\t$this->floatmargins['L']['y1'] += $yadj;\n\n\t\t\t// Update objattr in floatbuffer\n\t\t\tif ($this->floatbuffer[$this->floatmargins['L']['id']]['border_left']['w']) {\n\t\t\t\t$this->floatbuffer[$this->floatmargins['L']['id']]['BORDER-Y'] += $yadj;\n\t\t\t}\n\t\t\t$this->floatbuffer[$this->floatmargins['L']['id']]['INNER-Y'] += $yadj;\n\t\t\t$this->floatbuffer[$this->floatmargins['L']['id']]['OUTER-Y'] += $yadj;\n\n\t\t\t// Unset values\n\t\t\t$this->floatbuffer[$this->floatmargins['L']['id']]['skipline'] = false;\n\t\t\t$this->floatmargins['L']['skipline'] = false;\n\t\t\t$this->floatmargins['L']['id'] = '';\n\t\t}\n\t\t// Update floatmargins - R\n\t\tif (isset($this->floatmargins['R']) && $this->floatmargins['R']['skipline'] && $this->floatmargins['R']['y0'] != $this->y) {\n\t\t\t$yadj = $this->y - $this->floatmargins['R']['y0'];\n\t\t\t$this->floatmargins['R']['y0'] = $this->y;\n\t\t\t$this->floatmargins['R']['y1'] += $yadj;\n\n\t\t\t// Update objattr in floatbuffer\n\t\t\tif ($this->floatbuffer[$this->floatmargins['R']['id']]['border_left']['w']) {\n\t\t\t\t$this->floatbuffer[$this->floatmargins['R']['id']]['BORDER-Y'] += $yadj;\n\t\t\t}\n\t\t\t$this->floatbuffer[$this->floatmargins['R']['id']]['INNER-Y'] += $yadj;\n\t\t\t$this->floatbuffer[$this->floatmargins['R']['id']]['OUTER-Y'] += $yadj;\n\n\t\t\t// Unset values\n\t\t\t$this->floatbuffer[$this->floatmargins['R']['id']]['skipline'] = false;\n\t\t\t$this->floatmargins['R']['skipline'] = false;\n\t\t\t$this->floatmargins['R']['id'] = '';\n\t\t}\n\t}", "label": 2}
{"code": "def process_is_alive?(pid)\n      begin\n        Process.kill(0, pid)\n        return true\n      rescue Errno::ESRCH\n        return false\n      rescue SystemCallError => e\n        return true\n      end\n    end", "label": 4}
{"code": "func renameExited() error {\n\tif err := pkgPod.WalkPods(getDataDir(), pkgPod.IncludeRunDir, func(p *pkgPod.Pod) {\n\t\tif p.State() == pkgPod.Exited {\n\t\t\tstderr.Printf(\"moving pod %q to garbage\", p.UUID)\n\t\t\tif err := p.ToExitedGarbage(); err != nil && err != os.ErrNotExist {\n\t\t\t\tstderr.PrintE(\"rename error\", err)\n\t\t\t}\n\t\t}\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function defaultPushCallback(error, pushMessage) {\n    if (error) {\n        diag.debug.error('push failure', error);\n    }\n    else if (pushMessage && pushMessage.message) {\n        diag.debug.info('push received', pushMessage.message);\n    }\n    return pushMessage;\n}", "label": 3}
{"code": "def _encode_secret_part_v2_v3(version, condition, root_key, ns):\n    '''Creates a version 2 or version 3 secret part of the third party\n    caveat. The returned data is not encrypted.\n\n    The format has the following packed binary fields:\n    version 2 or 3 [1 byte]\n    root key length [n: uvarint]\n    root key [n bytes]\n    namespace length [n: uvarint] (v3 only)\n    namespace [n bytes] (v3 only)\n    predicate [rest of message]\n    '''\n    data = bytearray()\n    data.append(version)\n    encode_uvarint(len(root_key), data)\n    data.extend(root_key)\n    if version >= VERSION_3:\n        encode_uvarint(len(ns), data)\n        data.extend(ns)\n    data.extend(condition.encode('utf-8'))\n    return bytes(data)", "label": 1}
{"code": "def load(s, **kwargs):\n    \"\"\"Load yaml file\"\"\"\n    try:\n        return loads(s, **kwargs)\n    except TypeError:\n        return loads(s.read(), **kwargs)", "label": 1}
{"code": "public static String getModuleVersion(final String moduleId) {\n        final int splitter = moduleId.lastIndexOf(':');\n        if(splitter == -1){\n            return moduleId;\n        }\n        return moduleId.substring(splitter+1);\n    }", "label": 0}
{"code": "func (ts *Store) Render(key string, rebuild bool) (id string, hash string, err error) {\n\tid, err = ts.GetID(key)\n\tif err != nil {\n\t\treturn \"\", \"\", errwrap.Wrap(errors.New(\"cannot calculate treestore id\"), err)\n\t}\n\n\t// this lock references the treestore dir for the specified id.\n\ttreeStoreKeyLock, err := lock.ExclusiveKeyLock(ts.lockDir, id)\n\tif err != nil {\n\t\treturn \"\", \"\", errwrap.Wrap(errors.New(\"error locking tree store\"), err)\n\t}\n\tdefer treeStoreKeyLock.Close()\n\n\tif !rebuild {\n\t\trendered, err := ts.IsRendered(id)\n\t\tif err != nil {\n\t\t\treturn \"\", \"\", errwrap.Wrap(errors.New(\"cannot determine if tree is already rendered\"), err)\n\t\t}\n\t\tif rendered {\n\t\t\treturn id, \"\", nil\n\t\t}\n\t}\n\t// Firstly remove a possible partial treestore if existing.\n\t// This is needed as a previous ACI removal operation could have failed\n\t// cleaning the tree store leaving some stale files.\n\tif err := ts.remove(id); err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\tif hash, err = ts.render(id, key); err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\n\treturn id, hash, nil\n}", "label": 5}
{"code": "def walk_graph(bitmap, graph)\n      index    = Array.new(graph.size, nil)\n      traversed = Set.new\n\n      graph.nodes do |node|\n        next if traversed.include?(node)\n        traverse(node, traversed, index, [], bitmap, graph)\n      end\n    end", "label": 4}
{"code": "public static base_responses create(nitro_service client, systembackup resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsystembackup createresources[] = new systembackup[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tcreateresources[i] = new systembackup();\n\t\t\t\tcreateresources[i].filename = resources[i].filename;\n\t\t\t\tcreateresources[i].level = resources[i].level;\n\t\t\t\tcreateresources[i].comment = resources[i].comment;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, createresources,\"create\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static authorizationpolicy_aaauser_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthorizationpolicy_aaauser_binding obj = new authorizationpolicy_aaauser_binding();\n\t\tobj.set_name(name);\n\t\tauthorizationpolicy_aaauser_binding response[] = (authorizationpolicy_aaauser_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def log(self, level, message, *args, **kwargs):\n        \"\"\"\n        Provide current user as extra context to the logger\n        \"\"\"\n        extra = kwargs.pop('extra', {})\n        extra.update({\n            'user': self.user\n        })\n\n        kwargs['extra'] = extra\n        super(ServiceLogger, self).log(level, message, *args, **kwargs)", "label": 1}
{"code": "public function database($name, array $options = [])\n    {\n        return new Database(\n            $this->connection,\n            $this,\n            $this->lroConnection,\n            $this->lroCallables,\n            $this->projectId,\n            $name,\n            isset($options['sessionPool']) ? $options['sessionPool'] : null,\n            $this->returnInt64AsObject\n        );\n    }", "label": 2}
{"code": "function tryEmitStartOfVariableDeclarationList(decl) {\n                if (shouldHoistVariable(decl, /*checkIfSourceFileLevelDecl*/ true)) {\n                    // variables in variable declaration list were already hoisted\n                    return false;\n                }\n                if (convertedLoopState && (ts.getCombinedNodeFlags(decl) & 3072 /* BlockScoped */) === 0) {\n                    // we are inside a converted loop - this can only happen in downlevel scenarios\n                    // record names for all variable declarations\n                    for (var _a = 0, _b = decl.declarations; _a < _b.length; _a++) {\n                        var varDecl = _b[_a];\n                        hoistVariableDeclarationFromLoop(convertedLoopState, varDecl);\n                    }\n                    return false;\n                }\n                emitStart(decl);\n                if (decl && languageVersion >= 2 /* ES6 */) {\n                    if (ts.isLet(decl)) {\n                        write(\"let \");\n                    }\n                    else if (ts.isConst(decl)) {\n                        write(\"const \");\n                    }\n                    else {\n                        write(\"var \");\n                    }\n                }\n                else {\n                    write(\"var \");\n                }\n                // Note here we specifically dont emit end so that if we are going to emit binding pattern\n                // we can alter the source map correctly\n                return true;\n            }", "label": 3}
{"code": "public function getAttributes($column, $schema)\n    {\n        $fields = str_replace($column . ':', '', $schema);\n\n        return $this->hasCustomAttribute($column) ? $this->getCustomAttribute($column) : explode(':', $fields);\n    }", "label": 2}
{"code": "function(cloneModels, cloneProperties)\n  {\n    var source = this;\n\n    if ( cloneModels )\n    {\n      source = [];\n\n      for (var i = 0; i < this.length; i++)\n      {\n        source[ i ] = this[ i ].$clone( cloneProperties );\n      }\n    }\n\n    return ModelCollection.create( this.database, source, true );\n  }", "label": 3}
{"code": "func (m ObjectManager) PlaceDisk(ctx context.Context, spec *types.VslmCreateSpec, pool types.ManagedObjectReference) error {\n\tbacking := spec.BackingSpec.GetVslmCreateSpecBackingSpec()\n\tif backing.Datastore.Type != \"StoragePod\" {\n\t\treturn nil\n\t}\n\n\tdevice := &types.VirtualDisk{\n\t\tVirtualDevice: types.VirtualDevice{\n\t\t\tKey: 0,\n\t\t\tBacking: &types.VirtualDiskFlatVer2BackingInfo{\n\t\t\t\tDiskMode:        string(types.VirtualDiskModePersistent),\n\t\t\t\tThinProvisioned: types.NewBool(true),\n\t\t\t},\n\t\t\tUnitNumber: types.NewInt32(0),\n\t\t},\n\t\tCapacityInKB: spec.CapacityInMB * 1024,\n\t}\n\n\tstorage := types.StoragePlacementSpec{\n\t\tType:         string(types.StoragePlacementSpecPlacementTypeCreate),\n\t\tResourcePool: &pool,\n\t\tPodSelectionSpec: types.StorageDrsPodSelectionSpec{\n\t\t\tStoragePod: &backing.Datastore,\n\t\t\tInitialVmConfig: []types.VmPodConfigForPlacement{\n\t\t\t\t{\n\t\t\t\t\tStoragePod: backing.Datastore,\n\t\t\t\t\tDisk: []types.PodDiskLocator{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tDiskId:          device.Key,\n\t\t\t\t\t\t\tDiskBackingInfo: device.Backing,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tConfigSpec: &types.VirtualMachineConfigSpec{\n\t\t\tName: spec.Name,\n\t\t\tDeviceChange: []types.BaseVirtualDeviceConfigSpec{\n\t\t\t\t&types.VirtualDeviceConfigSpec{\n\t\t\t\t\tOperation:     types.VirtualDeviceConfigSpecOperationAdd,\n\t\t\t\t\tFileOperation: types.VirtualDeviceConfigSpecFileOperationCreate,\n\t\t\t\t\tDevice:        device,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\treq := types.RecommendDatastores{\n\t\tThis:        *m.c.ServiceContent.StorageResourceManager,\n\t\tStorageSpec: storage,\n\t}\n\n\tres, err := methods.RecommendDatastores(ctx, m.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tr := res.Returnval.Recommendations\n\tif len(r) == 0 {\n\t\treturn errors.New(\"no storage placement recommendations\")\n\t}\n\n\tbacking.Datastore = r[0].Action[0].(*types.StoragePlacementAction).Destination\n\n\treturn nil\n}", "label": 5}
{"code": "func (r *TunnelConnectionV2) SetLastHeartbeat(tm time.Time) {\n\tr.Spec.LastHeartbeat = tm\n}", "label": 5}
{"code": "private function checkPrefixes(array $paths)\n    {\n        sort($paths);\n\n        for ($i = 1; $i < count($paths); $i++) {\n            $prefix = $paths[$i-1];\n            $suffix = $paths[$i];\n\n            $prefix = explode('.', $prefix);\n            $suffix = explode('.', $suffix);\n\n            $isPrefix = count($prefix) < count($suffix)\n                && $prefix === array_slice($suffix, 0, count($prefix));\n\n            if ($isPrefix) {\n                throw new \\InvalidArgumentException(sprintf(\n                    'Field path conflict detected for field path `%s`. ' .\n                    'Conflicts occur when a field path descends from another ' .\n                    'path. For instance `a.b` is not allowed when `a` is also ' .\n                    'provided.',\n                    $prefix\n                ));\n            }\n        }\n    }", "label": 2}
{"code": "func (t *tScreen) buildAcsMap() {\n\tacsstr := t.ti.AltChars\n\tt.acs = make(map[rune]string)\n\tfor len(acsstr) > 2 {\n\t\tsrcv := acsstr[0]\n\t\tdstv := string(acsstr[1])\n\t\tif r, ok := vtACSNames[srcv]; ok {\n\t\t\tt.acs[r] = t.ti.EnterAcs + dstv + t.ti.ExitAcs\n\t\t}\n\t\tacsstr = acsstr[2:]\n\t}\n}", "label": 5}
{"code": "protected function parseRow($row)\n    {\n        list($k, $v) = explode(':', $row, 2);\n\n        if (preg_match('/^db\\d+$/', $k)) {\n            $v = $this->parseDatabaseStats($v);\n        }\n\n        return array($k, $v);\n    }", "label": 2}
{"code": "function configFromRFC2822(config) {\n    var string, match, dayFormat,\n        dateFormat, timeFormat, tzFormat;\n    var timezones = {\n        ' GMT': ' +0000',\n        ' EDT': ' -0400',\n        ' EST': ' -0500',\n        ' CDT': ' -0500',\n        ' CST': ' -0600',\n        ' MDT': ' -0600',\n        ' MST': ' -0700',\n        ' PDT': ' -0700',\n        ' PST': ' -0800'\n    };\n    var military = 'YXWVUTSRQPONZABCDEFGHIKLM';\n    var timezone, timezoneIndex;\n\n    string = config._i\n        .replace(/\\([^\\)]*\\)|[\\n\\t]/g, ' ') // Remove comments and folding whitespace\n        .replace(/(\\s\\s+)/g, ' ') // Replace multiple-spaces with a single space\n        .replace(/^\\s|\\s$/g, ''); // Remove leading and trailing spaces\n    match = basicRfcRegex.exec(string);\n\n    if (match) {\n        dayFormat = match[1] ? 'ddd' + ((match[1].length === 5) ? ', ' : ' ') : '';\n        dateFormat = 'D MMM ' + ((match[2].length > 10) ? 'YYYY ' : 'YY ');\n        timeFormat = 'HH:mm' + (match[4] ? ':ss' : '');\n\n        // TODO: Replace the vanilla JS Date object with an indepentent day-of-week check.\n        if (match[1]) { // day of week given\n            var momentDate = new Date(match[2]);\n            var momentDay = ['Sun','Mon','Tue','Wed','Thu','Fri','Sat'][momentDate.getDay()];\n\n            if (match[1].substr(0,3) !== momentDay) {\n                getParsingFlags(config).weekdayMismatch = true;\n                config._isValid = false;\n                return;\n            }\n        }\n\n        switch (match[5].length) {\n            case 2: // military\n                if (timezoneIndex === 0) {\n                    timezone = ' +0000';\n                } else {\n                    timezoneIndex = military.indexOf(match[5][1].toUpperCase()) - 12;\n                    timezone = ((timezoneIndex < 0) ? ' -' : ' +') +\n                        (('' + timezoneIndex).replace(/^-?/, '0')).match(/..$/)[0] + '00';\n                }\n                break;\n            case 4: // Zone\n                timezone = timezones[match[5]];\n                break;\n            default: // UT or +/-9999\n                timezone = timezones[' GMT'];\n        }\n        match[5] = timezone;\n        config._i = match.splice(1).join('');\n        tzFormat = ' ZZ';\n        config._f = dayFormat + dateFormat + timeFormat + tzFormat;\n        configFromStringAndFormat(config);\n        getParsingFlags(config).rfc2822 = true;\n    } else {\n        config._isValid = false;\n    }\n}", "label": 3}
{"code": "public static rewritepolicylabel_rewritepolicy_binding[] get(nitro_service service, String labelname) throws Exception{\n\t\trewritepolicylabel_rewritepolicy_binding obj = new rewritepolicylabel_rewritepolicy_binding();\n\t\tobj.set_labelname(labelname);\n\t\trewritepolicylabel_rewritepolicy_binding response[] = (rewritepolicylabel_rewritepolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (h *portForwardProxy) run() {\n\th.Debugf(\"Waiting for port forward streams.\")\n\tfor {\n\t\tselect {\n\t\tcase <-h.context.Done():\n\t\t\th.Debugf(\"Context is closing, returning.\")\n\t\t\treturn\n\t\tcase <-h.sourceConn.CloseChan():\n\t\t\th.Debugf(\"Upgraded connection closed.\")\n\t\t\treturn\n\t\tcase stream := <-h.streamChan:\n\t\t\trequestID, err := h.requestID(stream)\n\t\t\tif err != nil {\n\t\t\t\th.Warningf(\"Failed to parse request id: %v.\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tstreamType := stream.Headers().Get(StreamType)\n\t\t\th.Debugf(\"Received new stream %v of type %v.\", requestID, streamType)\n\n\t\t\tp, created := h.getStreamPair(requestID)\n\t\t\tif created {\n\t\t\t\tgo h.monitorStreamPair(p, time.After(h.streamCreationTimeout))\n\t\t\t}\n\t\t\tif complete, err := p.add(stream); err != nil {\n\t\t\t\tmsg := fmt.Sprintf(\"error processing stream for request %s: %v\", requestID, err)\n\t\t\t\tp.printError(msg)\n\t\t\t} else if complete {\n\t\t\t\tgo h.portForward(p)\n\t\t\t}\n\t\t}\n\t}\n}", "label": 5}
{"code": "function FixedDataTableRowBuffer(\nrowsCount,\n    /*number*/  defaultRowHeight,\n    /*number*/ viewportHeight,\n    /*?function*/ rowHeightGetter)\n   {\n    invariant(\n      defaultRowHeight !== 0,\n      \"defaultRowHeight musn't be equal 0 in FixedDataTableRowBuffer\"\n    );\n\n    this.$FixedDataTableRowBuffer_bufferSet = new IntegerBufferSet();\n    this.$FixedDataTableRowBuffer_defaultRowHeight = defaultRowHeight;\n    this.$FixedDataTableRowBuffer_viewportRowsBegin = 0;\n    this.$FixedDataTableRowBuffer_viewportRowsEnd = 0;\n    this.$FixedDataTableRowBuffer_maxVisibleRowCount = Math.ceil(viewportHeight / defaultRowHeight) + 1;\n    this.$FixedDataTableRowBuffer_bufferRowsCount = clamp(\n      MIN_BUFFER_ROWS,\n      Math.floor(this.$FixedDataTableRowBuffer_maxVisibleRowCount/2),\n      MAX_BUFFER_ROWS\n    );\n    this.$FixedDataTableRowBuffer_rowsCount = rowsCount;\n    this.$FixedDataTableRowBuffer_rowHeightGetter = rowHeightGetter;\n    this.$FixedDataTableRowBuffer_rows = [];\n    this.$FixedDataTableRowBuffer_viewportHeight = viewportHeight;\n\n    this.getRows = this.getRows.bind(this);\n    this.getRowsWithUpdatedBuffer = this.getRowsWithUpdatedBuffer.bind(this);\n  }", "label": 3}
{"code": "function (CurrentEntity) {\n  return function (attributeValues) {\n    expect(arguments).to.have.length.below(\n      2,\n      'Invalid arguments length when creating a new \"' +\n      CurrentEntity.specification.name +\n      '\" instance (it has to be passed less than 2 arguments)');\n\n    return new Promise(function (resolve, reject) {\n      var newEntity = new CurrentEntity(attributeValues);\n\n      newEntity\n        .save({\n          forceCreate: true\n        })\n        .then(function () {\n          resolve(newEntity);\n        })\n        .catch(reject);\n    });\n  };\n}", "label": 3}
{"code": "def summary_stats(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Compute summary stats for a result.\n\n        :param id: Result ID as an int.\n        :return: :class:`results.SummaryStats <results.SummaryStats>` object\n        :rtype: results.SummaryStats\n        \"\"\"\n        schema = SummaryStatsSchema()\n        resp = self.service.get(self.base+str(id)+'/', params={'stats': 'summary'})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public function setSecondaryWorkerConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\InstanceGroupConfig::class);\n        $this->secondary_worker_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def worker(data):\n    \"\"\"Running on shell via multiprocessing.\"\"\"\n    creator = get_creator_by_name(data['creator'])\n    shell = creator(data['entry'],\n                    ShellConfig(script=data['entry']['script'],\n                                title=data['entry']['title'] if 'title' in data['entry'] else '',\n                                model=data['model'], env=data['env'], item=data['item'],\n                                dry_run=data['dry_run'], debug=data['debug'], strict=data['strict'],\n                                variables=data['variables'],\n                                temporary_scripts_path=data['temporary_scripts_path']))\n    output = []\n    for line in shell.process():\n        output.append(line)\n        Logger.get_logger(__name__ + '.worker').info(\" | %s\", line)\n    return {'id': data['id'], 'success': shell.success, 'output': output}", "label": 1}
{"code": "func (cli *NetworkCli) Subcmd(chain, name, signature, description string, exitOnError bool) *flag.FlagSet {\n\tvar errorHandling flag.ErrorHandling\n\tif exitOnError {\n\t\terrorHandling = flag.ExitOnError\n\t} else {\n\t\terrorHandling = flag.ContinueOnError\n\t}\n\tflags := flag.NewFlagSet(name, errorHandling)\n\tflags.Usage = func() {\n\t\tflags.ShortUsage()\n\t\tflags.PrintDefaults()\n\t}\n\tflags.ShortUsage = func() {\n\t\toptions := \"\"\n\t\tif signature != \"\" {\n\t\t\tsignature = \" \" + signature\n\t\t}\n\t\tif flags.FlagCountUndeprecated() > 0 {\n\t\t\toptions = \" [OPTIONS]\"\n\t\t}\n\t\tfmt.Fprintf(cli.out, \"\\nUsage: %s %s%s%s\\n\\n%s\\n\\n\", chain, name, options, signature, description)\n\t\tflags.SetOutput(cli.out)\n\t}\n\treturn flags\n}", "label": 5}
{"code": "public static authenticationvserver_authenticationcertpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationvserver_authenticationcertpolicy_binding obj = new authenticationvserver_authenticationcertpolicy_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationvserver_authenticationcertpolicy_binding response[] = (authenticationvserver_authenticationcertpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setEntityResultType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Datastore\\V1\\EntityResult_ResultType::class);\n        $this->entity_result_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def _clear_interrupt(self, intbit):\n        \"\"\"Clear the specified interrupt bit in the interrupt status register.\n        \"\"\"\n        int_status = self._device.readU8(VCNL4010_INTSTAT);\n        int_status &= ~intbit;\n        self._device.write8(VCNL4010_INTSTAT, int_status);", "label": 1}
{"code": "func (p *Collector) Destroy(ctx context.Context) error {\n\treq := types.DestroyPropertyCollector{\n\t\tThis: p.Reference(),\n\t}\n\n\t_, err := methods.DestroyPropertyCollector(ctx, p.roundTripper, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tp.reference = types.ManagedObjectReference{}\n\treturn nil\n}", "label": 5}
{"code": "private function get_parameters( $spec = array() ) {\n\t\t$local_parameters  = array_column( $spec, 'name' );\n\t\t$global_parameters = array_column(\n\t\t\tWP_CLI\\SynopsisParser::parse( $this->get_global_params() ),\n\t\t\t'name'\n\t\t);\n\n\t\treturn array_unique( array_merge( $local_parameters, $global_parameters ) );\n\t}", "label": 2}
{"code": "private void createCodeMappings(MtasTokenIdFactory mtasTokenIdFactory,\n      Level level, String stringValue, int offsetStart, int offsetEnd,\n      int realOffsetStart, int realOffsetEnd, List<Integer> codePositions)\n      throws IOException {\n    String[] stringValues = MtasPennTreebankReader.createStrings(stringValue,\n        Pattern.quote(STRING_SPLITTER));\n    MtasToken token = new MtasTokenString(mtasTokenIdFactory.createTokenId(),\n        level.node, filterString(stringValues[0].trim()));\n    token.setOffset(offsetStart, offsetEnd);\n    token.setRealOffset(realOffsetStart, realOffsetEnd);\n    token.addPositions(codePositions.stream().mapToInt(i -> i).toArray());\n    tokenCollection.add(token);\n    level.tokens.add(token);\n  }", "label": 0}
{"code": "def log_notices(notices=[], level=:warn)\n      notices.each do |concern|\n        message = concern.delete(:message)\n        @logger.send(level, message, redact_sensitive(concern))\n      end\n    end", "label": 4}
{"code": "public function read_array($returnObject = false)\n    {\n        $this->bitcount = $this->bits = 0;\n\n        // Determine array length and its end position\n        $arrayLength = $this->read_php_int();\n        $endOffset = $this->offset + $arrayLength;\n\n        $result = $returnObject ? new AMQPArray() : array();\n\n        // Read values until we reach the end of the array\n        while ($this->offset < $endOffset) {\n            $fieldType = AMQPAbstractCollection::getDataTypeForSymbol($this->rawread(1));\n            $fieldValue = $this->read_value($fieldType, $returnObject);\n            $returnObject ? $result->push($fieldValue, $fieldType) : $result[] = $fieldValue;\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "def create_activity!(*args)\n      return unless self.public_activity_enabled?\n      options = prepare_settings(*args)\n\n      if call_hook_safe(options[:key].split('.').last)\n        reset_activity_instance_options\n        return PublicActivity::Adapter.create_activity!(self, options)\n      end\n    end", "label": 4}
{"code": "private void ensureReferencedFKs(ModelDef modelDef, CollectionDescriptorDef collDef) throws ConstraintException\r\n    {\r\n        String             elementClassName = collDef.getProperty(PropertyHelper.OJB_PROPERTY_ELEMENT_CLASS_REF);\r\n        ClassDescriptorDef elementClassDef  = modelDef.getClass(elementClassName);\r\n        String             fkFieldNames     = collDef.getProperty(PropertyHelper.OJB_PROPERTY_FOREIGNKEY);\r\n        ArrayList          missingFields    = new ArrayList();\r\n        SequencedHashMap   fkFields         = new SequencedHashMap();\r\n\r\n        // first we gather all field names\r\n        for (CommaListIterator it = new CommaListIterator(fkFieldNames); it.hasNext();)\r\n        {\r\n            String             fieldName = (String)it.next();\r\n            FieldDescriptorDef fieldDef  = elementClassDef.getField(fieldName);\r\n\r\n            if (fieldDef == null)\r\n            {\r\n                missingFields.add(fieldName);\r\n            }\r\n            fkFields.put(fieldName, fieldDef);\r\n        }\r\n\r\n        // next we traverse all sub types and gather fields as we go\r\n        for (Iterator it = elementClassDef.getAllExtentClasses(); it.hasNext() && !missingFields.isEmpty();)\r\n        {\r\n            ClassDescriptorDef subTypeDef = (ClassDescriptorDef)it.next();\r\n\r\n            for (int idx = 0; idx < missingFields.size();)\r\n            {\r\n                FieldDescriptorDef fieldDef = subTypeDef.getField((String)missingFields.get(idx));\r\n\r\n                if (fieldDef != null)\r\n                {\r\n                    fkFields.put(fieldDef.getName(), fieldDef);\r\n                    missingFields.remove(idx);\r\n                }\r\n                else\r\n                {\r\n                    idx++;\r\n                }\r\n            }\r\n        }\r\n        if (!missingFields.isEmpty())\r\n        {\r\n            throw new ConstraintException(\"Cannot find field \"+missingFields.get(0).toString()+\" in the hierarchy with root type \"+\r\n                                          elementClassDef.getName()+\" which is used as foreignkey in collection \"+\r\n                                          collDef.getName()+\" in \"+collDef.getOwner().getName());\r\n        }\r\n\r\n        // copy the found fields into the element class\r\n        ensureFields(elementClassDef, fkFields.values());\r\n    }", "label": 0}
{"code": "public function getErrors()\n    {\n        $arr_errors = [];\n\n        if (! extension_loaded('gd') && ! extension_loaded('imagick')) {\n            array_push($arr_errors, trans('laravel-filemanager::lfm.message-extension_not_found'));\n        }\n\n        if (! extension_loaded('exif')) {\n            array_push($arr_errors, 'EXIF extension not found.');\n        }\n\n        if (! extension_loaded('fileinfo')) {\n            array_push($arr_errors, 'Fileinfo extension not found.');\n        }\n\n        $mine_config_key = 'lfm.folder_categories.'\n            . $this->helper->currentLfmType()\n            . '.valid_mime';\n\n        if (! is_array(config($mine_config_key))) {\n            array_push($arr_errors, 'Config : ' . $mine_config_key . ' is not a valid array.');\n        }\n\n        return $arr_errors;\n    }", "label": 2}
{"code": "function(view, options) {\n      options = options || {};\n      this.unregisterTrackedView(view);\n      if (options.child || !options.shared) {\n        this.__childViews[view.cid] = view;\n      } else {\n        this.__sharedViews[view.cid] = view;\n      }\n      return view;\n    }", "label": 3}
{"code": "def color=(color)\n      each_with_index do | cell, index |\n        cell.color = color.is_a?(Array) ? color[index] : color\n      end\n    end", "label": 4}
{"code": "func (p *Pod) WaitReady(ctx context.Context) error {\n\tf := func() bool {\n\t\tif err := p.refreshState(); err != nil {\n\t\t\treturn false\n\t\t}\n\n\t\treturn p.IsSupervisorReady()\n\t}\n\n\treturn retry(ctx, f, 100*time.Millisecond)\n}", "label": 5}
{"code": "func (g GridType) YRange() (min, max float64) {\n\tmin = g.yTicks[0]\n\tmax = g.yTicks[len(g.yTicks)-1]\n\treturn\n}", "label": 5}
{"code": "final void roll(final long timeForSuffix) {\n\n    final File backupFile = this.prepareBackupFile(timeForSuffix);\n\n    // close filename\n    this.getAppender().closeFile();\n\n    // rename filename on disk to filename+suffix(+number)\n    this.doFileRoll(this.getAppender().getIoFile(), backupFile);\n\n    // setup new file 'filename'\n    this.getAppender().openFile();\n\n    this.fireFileRollEvent(new FileRollEvent(this, backupFile));\n  }", "label": 0}
{"code": "def _ensure_value_is_valid(self, value):\n        \"\"\"Ensure that value is a valid collection's value.\"\"\"\n        if not isinstance(value, self.__class__.value_type):\n            raise TypeError('{0} is not valid collection value, instance '\n                            'of {1} required'.format(\n                                value, self.__class__.value_type))\n        return value", "label": 1}
{"code": "def name(gender = :any)\n      case gender\n      when :any then rand(0..1) == 0 ? name(:male) : name(:female)\n      when :male then fetch_sample(MALE_FIRST_NAMES)\n      when :female then fetch_sample(FEMALE_FIRST_NAMES)\n      else raise ArgumentError, 'Invalid gender, must be one of :any, :male, :female'\n      end\n    end", "label": 4}
{"code": "func formatUnequalValues(expected, actual interface{}) (e string, a string) {\n\tif reflect.TypeOf(expected) != reflect.TypeOf(actual) {\n\t\treturn fmt.Sprintf(\"%T(%#v)\", expected, expected),\n\t\t\tfmt.Sprintf(\"%T(%#v)\", actual, actual)\n\t}\n\n\treturn fmt.Sprintf(\"%#v\", expected),\n\t\tfmt.Sprintf(\"%#v\", actual)\n}", "label": 5}
{"code": "public function getSize()\n    {\n        $size = $this->executor->execute(\n            DriverCommand::GET_WINDOW_SIZE,\n            [':windowHandle' => 'current']\n        );\n\n        return new WebDriverDimension(\n            $size['width'],\n            $size['height']\n        );\n    }", "label": 2}
{"code": "function getTypingNamesFromNodeModuleFolder(nodeModulesPath) {\n                // Todo: add support for ModuleResolutionHost too\n                if (!host.directoryExists(nodeModulesPath)) {\n                    return;\n                }\n                var typingNames = [];\n                var fileNames = host.readDirectory(nodeModulesPath, [\".json\"], /*excludes*/ undefined, /*includes*/ undefined, /*depth*/ 2);\n                for (var _i = 0, fileNames_2 = fileNames; _i < fileNames_2.length; _i++) {\n                    var fileName = fileNames_2[_i];\n                    var normalizedFileName = ts.normalizePath(fileName);\n                    if (ts.getBaseFileName(normalizedFileName) !== \"package.json\") {\n                        continue;\n                    }\n                    var result = ts.readConfigFile(normalizedFileName, function (path) { return host.readFile(path); });\n                    if (!result.config) {\n                        continue;\n                    }\n                    var packageJson = result.config;\n                    // npm 3's package.json contains a \"_requiredBy\" field\n                    // we should include all the top level module names for npm 2, and only module names whose\n                    // \"_requiredBy\" field starts with \"#\" or equals \"/\" for npm 3.\n                    if (packageJson._requiredBy &&\n                        ts.filter(packageJson._requiredBy, function (r) { return r[0] === \"#\" || r === \"/\"; }).length === 0) {\n                        continue;\n                    }\n                    // If the package has its own d.ts typings, those will take precedence. Otherwise the package name will be used\n                    // to download d.ts files from DefinitelyTyped\n                    if (!packageJson.name) {\n                        continue;\n                    }\n                    if (packageJson.typings) {\n                        var absolutePath = ts.getNormalizedAbsolutePath(packageJson.typings, ts.getDirectoryPath(normalizedFileName));\n                        inferredTypings[packageJson.name] = absolutePath;\n                    }\n                    else {\n                        typingNames.push(packageJson.name);\n                    }\n                }\n                mergeTypings(typingNames);\n            }", "label": 3}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo]) do\n        assert_required %w[ tree ]\n        permit VALID_TREE_PARAM_NAMES, 'tree', { recursive: true }\n        assert_values VALID_TREE_PARAM_VALUES, 'tree'\n      end\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/git/trees\", arguments.params)\n    end", "label": 4}
{"code": "public function recordKeyWritten(KeyWritten $event)\n    {\n        if (! Telescope::isRecording() || $this->shouldIgnore($event)) {\n            return;\n        }\n\n        Telescope::recordCache(IncomingEntry::make([\n            'type' => 'set',\n            'key' => $event->key,\n            'value' => $event->value,\n            'expiration' => $this->formatExpiration($event),\n        ]));\n    }", "label": 2}
{"code": "def find_type_elements_except(type, nested_except=[], elements=@elements)\n      results = []\n      if type.class == Symbol\n        type = [type]\n      end\n      if nested_except.class == Symbol\n        nested_except = [nested_except]\n      end\n      elements.each do |e|\n        results.push(e) if type.include?(e.type)\n        unless nested_except.include?(e.type) or e.children.empty?\n          results.concat(find_type_elements_except(type, nested_except, e.children))\n        end\n      end\n      results\n    end", "label": 4}
{"code": "def get_privilege_information():\n\t\"\"\"\n\tGet all privileges associated with the current process.\n\t\"\"\"\n\t# first call with zero length to determine what size buffer we need\n\n\treturn_length = wintypes.DWORD()\n\tparams = [\n\t\tget_process_token(),\n\t\tprivilege.TOKEN_INFORMATION_CLASS.TokenPrivileges,\n\t\tNone,\n\t\t0,\n\t\treturn_length,\n\t]\n\n\tres = privilege.GetTokenInformation(*params)\n\n\t# assume we now have the necessary length in return_length\n\n\tbuffer = ctypes.create_string_buffer(return_length.value)\n\tparams[2] = buffer\n\tparams[3] = return_length.value\n\n\tres = privilege.GetTokenInformation(*params)\n\tassert res > 0, \"Error in second GetTokenInformation (%d)\" % res\n\n\tprivileges = ctypes.cast(\n\t\tbuffer, ctypes.POINTER(privilege.TOKEN_PRIVILEGES)).contents\n\treturn privileges", "label": 1}
{"code": "def validate(data):\n        \"\"\"\n        Validate data against the schema.\n\n        Args:\n            data(dict): data structure to validate.\n\n        Returns:\n            dict: data as provided and defaults where defined in schema.\n        \"\"\"\n        try:\n            return Schema(Validator.SCHEMA).validate(data)\n        except SchemaError as exception:\n            logging.getLogger(__name__).error(exception)\n            return None", "label": 1}
{"code": "def query(query, args = {})\n        args[:q] = query\n        args[:qt] = 'standard'\n        conn = ActiveFedora::SolrService.instance.conn\n        result = conn.post('select', data: args)\n        result.fetch('response').fetch('docs')\n      end", "label": 4}
{"code": "public static <T> Set<T> toSet(Iterable<T> items) {\r\n    Set<T> set = new HashSet<T>();\r\n    addAll(set, items);\r\n    return set;\r\n  }", "label": 0}
{"code": "public void notifySubscriberCallback(ContentNotification cn) {\n        String content = fetchContentFromPublisher(cn);\n\n        distributeContentToSubscribers(content, cn.getUrl());\n    }", "label": 0}
{"code": "func fmtIndexName(ixName string, tableName string) string {\n\t// chop off _ix, _idx, _index, _pkey, or _key\n\tm := IndexChopSuffixRE.FindStringIndex(ixName)\n\tif m != nil {\n\t\tixName = ixName[:m[0]]\n\t}\n\n\t// check tableName\n\tif ixName == tableName {\n\t\treturn \"\"\n\t}\n\n\t// chop off tablename_\n\tif strings.HasPrefix(ixName, tableName+\"_\") {\n\t\tixName = ixName[len(tableName)+1:]\n\t}\n\n\t// camel case name\n\treturn snaker.SnakeToCamelIdentifier(ixName)\n}", "label": 5}
{"code": "function isIElementNode(node) {\n    return typeof node['getText'] === 'function' &&\n        typeof node.currently['hasText'] === 'function' &&\n        typeof node.currently['hasAnyText'] === 'function' &&\n        typeof node.currently['containsText'] === 'function' &&\n        typeof node.wait['hasText'] === 'function' &&\n        typeof node.wait['hasAnyText'] === 'function' &&\n        typeof node.wait['containsText'] === 'function' &&\n        typeof node.eventually['hasText'] === 'function' &&\n        typeof node.eventually['hasAnyText'] === 'function' &&\n        typeof node.eventually['containsText'] === 'function' &&\n        typeof node['getDirectText'] === 'function' &&\n        typeof node.currently['hasDirectText'] === 'function' &&\n        typeof node.currently['hasAnyDirectText'] === 'function' &&\n        typeof node.currently['containsDirectText'] === 'function' &&\n        typeof node.wait['hasDirectText'] === 'function' &&\n        typeof node.wait['hasAnyDirectText'] === 'function' &&\n        typeof node.wait['containsDirectText'] === 'function' &&\n        typeof node.eventually['hasDirectText'] === 'function' &&\n        typeof node.eventually['hasAnyDirectText'] === 'function' &&\n        typeof node.eventually['containsDirectText'] === 'function';\n}", "label": 3}
{"code": "func (pc *PropertyCollector) RetrieveProperties(ctx *Context, r *types.RetrieveProperties) soap.HasFault {\n\tbody := &methods.RetrievePropertiesBody{}\n\n\tres := pc.RetrievePropertiesEx(ctx, &types.RetrievePropertiesEx{\n\t\tThis:    r.This,\n\t\tSpecSet: r.SpecSet,\n\t})\n\n\tif res.Fault() != nil {\n\t\tbody.Fault_ = res.Fault()\n\t} else {\n\t\tbody.Res = &types.RetrievePropertiesResponse{\n\t\t\tReturnval: res.(*methods.RetrievePropertiesExBody).Res.Returnval.Objects,\n\t\t}\n\t}\n\n\treturn body\n}", "label": 5}
{"code": "func OptionParentUpdate(cid string, name, ip string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.parentUpdates = append(sb.config.parentUpdates, parentUpdate{cid: cid, name: name, ip: ip})\n\t}\n}", "label": 5}
{"code": "def addReward(self, r=None):\n        \"\"\" A filtered mapping towards performAction of the underlying\n            environment.\n        \"\"\"\n        r = self.getReward() if r is None else r\n\n        # by default, the cumulative reward is just the sum over the episode\n        if self.discount:\n            self.cumulativeReward += power(self.discount, self.samples) * r\n        else:\n            self.cumulativeReward += r", "label": 1}
{"code": "def default(context = nil)\n      raise NoDefaultError, name unless default?\n\n      value = raw_default(context)\n      raise InvalidValueError if value.is_a?(GroupedInput)\n\n      cast(value, context)\n    rescue InvalidNestedValueError => error\n      raise InvalidDefaultError, \"#{name}: #{value.inspect} (#{error})\"\n    rescue InvalidValueError, MissingValueError\n      raise InvalidDefaultError, \"#{name}: #{value.inspect}\"\n    end", "label": 4}
{"code": "public function setCustomNumericFunctions(array $functions) : void\n    {\n        foreach ($functions as $name => $className) {\n            $this->addCustomNumericFunction($name, $className);\n        }\n    }", "label": 2}
{"code": "public Set<String> rangeByScoreReverse(final ScoreRange scoreRange) {\n        return doWithJedis(new JedisCallable<Set<String>>() {\n            @Override\n            public Set<String> call(Jedis jedis) {\n                if (scoreRange.hasLimit()) {\n                    return jedis.zrevrangeByScore(getKey(), scoreRange.fromReverse(), scoreRange.toReverse(), scoreRange.offset(), scoreRange.count());\n                } else {\n                    return jedis.zrevrangeByScore(getKey(), scoreRange.fromReverse(), scoreRange.toReverse());\n                }\n            }\n        });\n    }", "label": 0}
{"code": "function updateExistingFile(db, fileName, fileReadStream, options, cb) {\n  defaultLogger.debug(\"In updateExistingFile\");\n\n  getFileDetails(db, {\"groupId\": options.groupId}, {}, function(err, fileInfo) {\n    if (err) {\n      defaultLogger.error(err); return cb(err);\n    }\n    var latestFileVersion = fileInfo.metadata.version;\n    incrementFileVersion(latestFileVersion, function(newFileVersion) {\n      if (!newFileVersion) {\n        return cb(new Error(\"File version was not incremented for file \" + fileName));\n      }\n      defaultLogger.debug(\"New File Version \", newFileVersion);\n      createFileWithVersion(db, fileName, fileReadStream, newFileVersion, options, cb);\n    });\n  });\n}", "label": 3}
{"code": "function JugglingStore(schema, options) {\n\t\toptions = options || {};\n\t\tStore.call(this, options);\n\t\tthis.maxAge = options.maxAge || defaults.maxAge;\n\t\tvar coll = this.collection = schema.define('Session', {\n\t\t\tsid: {\n\t\t\t\ttype: String,\n\t\t\t\tindex: true\n\t\t\t},\n\t\t\texpires: {\n\t\t\t\ttype: Date,\n\t\t\t\tindex: true\n\t\t\t},\n\t\t\tsession: schema.constructor.JSON\n\t\t}, {\n\t\t\ttable: options.table || defaults.table\n\t\t});\n\n\t\tcoll.validatesUniquenessOf('sid');\n\n\t\t// destroy all expired sessions after each create/update\n\t\tcoll.afterSave = function(next) {\n\t\t\tcoll.iterate({where: {\n\t\t\t\texpires: {lte: new Date()}\n\t\t\t}}, function(obj, nexti, i) {\n\t\t\t\tobj.destroy(nexti);\n\t\t\t}, next);\n\t\t};\n\t}", "label": 3}
{"code": "public static base_response add(nitro_service client, dnstxtrec resource) throws Exception {\n\t\tdnstxtrec addresource = new dnstxtrec();\n\t\taddresource.domain = resource.domain;\n\t\taddresource.String = resource.String;\n\t\taddresource.ttl = resource.ttl;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public function getNativeDescription()\n    {\n        $region = $this->getRegionName();\n        $variant = $this->getVariantName();\n\n        return $this->getNativeName().($region ? ' ('.$region.')' : '').($variant ? ' ('.$variant.')' : '');\n    }", "label": 2}
{"code": "func (s *CA) DeleteAllCertAuthorities(caType services.CertAuthType) error {\n\tstartKey := backend.Key(authoritiesPrefix, string(caType))\n\treturn s.DeleteRange(context.TODO(), startKey, backend.RangeEnd(startKey))\n}", "label": 5}
{"code": "func (s *Server) Start() {\n\tif s.URL != \"\" {\n\t\tpanic(\"Server already started\")\n\t}\n\tif s.client == nil {\n\t\ts.client = &http.Client{Transport: &http.Transport{}}\n\t}\n\ts.URL = \"http://\" + s.Listener.Addr().String()\n\ts.wrap()\n\ts.goServe()\n}", "label": 5}
{"code": "def find_or_create_by_path(path, attributes = {})\n      subpath = _ct.build_ancestry_attr_path(path, attributes)\n      return self if subpath.empty?\n\n      found = find_by_path(subpath, attributes)\n      return found if found\n\n      attrs = subpath.shift\n      _ct.with_advisory_lock do\n        # shenanigans because children.create is bound to the superclass\n        # (in the case of polymorphism):\n        child = self.children.where(attrs).first || begin\n          # Support STI creation by using base_class:\n          _ct.create(self.class, attrs).tap do |ea|\n            # We know that there isn't a cycle, because we just created it, and\n            # cycle detection is expensive when the node is deep.\n            ea._ct_skip_cycle_detection!\n            self.children << ea\n          end\n        end\n        child.find_or_create_by_path(subpath, attributes)\n      end\n    end", "label": 4}
{"code": "function(delaySort)\n  {\n    var removed = this[ 0 ];\n\n    this.map.removeAt( 0 );\n    this.trigger( Collection.Events.Remove, [this, removed, 0] );\n\n    if ( !delaySort )\n    {\n      this.sort();\n    }\n\n    return removed;\n  }", "label": 3}
{"code": "func MarshalProvisionToken(t ProvisionToken, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttype token1 interface {\n\t\tV1() *ProvisionTokenV1\n\t}\n\ttype token2 interface {\n\t\tV2() *ProvisionTokenV2\n\t}\n\tversion := cfg.GetVersion()\n\tswitch version {\n\tcase V1:\n\t\tv, ok := t.(token1)\n\t\tif !ok {\n\t\t\treturn nil, trace.BadParameter(\"don't know how to marshal %v\", V1)\n\t\t}\n\t\treturn utils.FastMarshal(v.V1())\n\tcase V2:\n\t\tv, ok := t.(token2)\n\t\tif !ok {\n\t\t\treturn nil, trace.BadParameter(\"don't know how to marshal %v\", V2)\n\t\t}\n\t\treturn utils.FastMarshal(v.V2())\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"version %v is not supported\", version)\n\t}\n}", "label": 5}
{"code": "def index_branches(self, branches=None, start=0):\n        \"\"\" Updates the indices of all branches.\n\n        @param start: Starting index, typically 0 or 1.\n        @type start: int\n        \"\"\"\n        ln = self.online_branches if branches is None else branches\n        for i, l in enumerate(ln):\n            l._i = start + i", "label": 1}
{"code": "private Optional<? extends SoyMsgBundle> mergeMsgBundles(final Locale locale, final List<SoyMsgBundle> soyMsgBundles) {\n        if (soyMsgBundles.isEmpty()) {\n            return Optional.absent();\n        }\n\n        final List<SoyMsg> msgs = Lists.newArrayList();\n        for (final SoyMsgBundle smb : soyMsgBundles) {\n            for (final Iterator<SoyMsg> it = smb.iterator(); it.hasNext();) {\n                msgs.add(it.next());\n            }\n        }\n\n        return Optional.of(new SoyMsgBundleImpl(locale.toString(), msgs));\n    }", "label": 0}
{"code": "function (x, y, w, h, options) {\n                    return SVGRenderer.prototype.symbols[\n                      !defined(options) || !options.r ? 'square' : 'callout'\n                      ].call(0, x, y, w, h, options);\n                }", "label": 3}
{"code": "public static lbgroup_lbvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbgroup_lbvserver_binding obj = new lbgroup_lbvserver_binding();\n\t\tobj.set_name(name);\n\t\tlbgroup_lbvserver_binding response[] = (lbgroup_lbvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def route!(base = settings, pass_block=nil)\n      if routes = base.routes[@request.request_method]\n        routes.each do |pattern, keys, conditions, block|\n          pass_block = process_route(pattern, keys, conditions) do |*args|\n            route_eval { block[*args] }\n          end\n        end\n      end\n\n      # Run routes defined in superclass.\n      if base.superclass.respond_to?(:routes)\n        return route!(base.superclass, pass_block)\n      end\n\n      route_eval(&pass_block) if pass_block\n      route_missing\n    end", "label": 4}
{"code": "function create_new() {\n        var id\n\n        // Check if we already have an id or if\n        // we need to generate a new one.\n        if (undefined !== ent.id$) {\n          // Take a copy of the existing id and\n          // delete it from the ent object. Do\n          // save will handle the id for us.\n          id = ent.id$\n          delete ent.id$\n\n          // Save with the existing id\n          return do_save(id, true)\n        }\n\n        // Generate a new id\n        id = options.generate_id ? options.generate_id(ent) : void 0\n\n        if (undefined !== id) {\n          return do_save(id, true)\n        } else {\n          var gen_id = {\n            role: 'basic',\n            cmd: 'generate_id',\n            name: name,\n            base: base,\n            zone: zone\n          }\n\n          // When we get a respones we will use the id param\n          // as our entity id, if this fails we just fail and\n          // call reply() as we have no way to save without an id\n          seneca.act(gen_id, function(err, id) {\n            if (err) return reply(err)\n            do_save(id, true)\n          })\n        }\n      }", "label": 3}
{"code": "def calculate(account, args = {})\n      options = Options.new(account, args)\n      relations = RelationBuilder.new(options)\n      lines = relations.build\n\n      if options.between? || options.code?\n        # from and to or code lookups have to be done via sum\n        Money.new(lines.sum(:amount), account.currency)\n      else\n        # all other lookups can be performed with running balances\n        result = lines.\n                 from(lines_table_name(options)).\n                 order('id DESC').\n                 limit(1).\n                 pluck(:balance)\n        result.empty? ? Money.zero(account.currency) : Money.new(result.first, account.currency)\n      end\n    end", "label": 4}
{"code": "func (self *realKubeFramework) CreateRBAC(rbac *rbacv1.ClusterRoleBinding) error {\n\t_, err := self.kubeClient.RbacV1().ClusterRoleBindings().Create(rbac)\n\treturn err\n}", "label": 5}
{"code": "def q_limited(self):\n        \"\"\" Is the machine at it's limit of reactive power?\n        \"\"\"\n        if (self.q >= self.q_max) or (self.q <= self.q_min):\n            return True\n        else:\n            return False", "label": 1}
{"code": "public static Chart getMSDLineWithFreeModelChart(Trajectory t, int lagMin,\n\t\t\tint lagMax, double timelag, double diffusionCoefficient, double intercept) {\n\n\t\tdouble[] xData = new double[lagMax - lagMin + 1];\n\t\tdouble[] yData = new double[lagMax - lagMin + 1];\n\t\tdouble[] modelData = new double[lagMax - lagMin + 1];\n\t\tMeanSquaredDisplacmentFeature msdeval = new MeanSquaredDisplacmentFeature(\n\t\t\t\tt, lagMin);\n\t\tmsdeval.setTrajectory(t);\n\t\tmsdeval.setTimelag(lagMin);\n\t\tfor (int i = lagMin; i < lagMax + 1; i++) {\n\t\t\tmsdeval.setTimelag(i);\n\t\t\tdouble msdhelp = msdeval.evaluate()[0];\n\t\t\txData[i - lagMin] = i;\n\t\t\tyData[i - lagMin] = msdhelp;\n\t\t\tmodelData[i - lagMin] = intercept + 4*diffusionCoefficient*(i*timelag);//4 * D * Math.pow(i * timelag, a);\n\t\t}\n\n\t\t// Create Chart\n\t\tChart chart = QuickChart.getChart(\"MSD Line\", \"LAG\", \"MSD\", \"MSD\",\n\t\t\t\txData, yData);\n\t\tchart.addSeries(\"y=4*D*t + a\", xData, modelData);\n\n\t\t// Show it\n\t\t//new SwingWrapper(chart).displayChart();\n\t\treturn chart;\n\t}", "label": 0}
{"code": "def show_status(self):\n        \"\"\"\n        dumps the status of the agent\n        \"\"\"\n        txt = 'Agent Status:\\n'\n        print(txt)\n        txt += \"start_x  = \" + str(self.start_x) + \"\\n\"\n        txt += \"start_y  = \" + str(self.start_y) + \"\\n\"\n        txt += \"target_x = \" + str(self.target_x) + \"\\n\"\n        txt += \"target_y = \" + str(self.target_y) + \"\\n\"\n        txt += \"current_x = \" + str(self.current_x) + \"\\n\"\n        txt += \"current_y = \" + str(self.current_y) + \"\\n\"\n       \n        \n        print(self.grd)\n        return txt", "label": 1}
{"code": "def start(self, message):\n        \"\"\"\n        Manually starts timer with the message.\n\n        :param message:  The display message.\n        \"\"\"\n        self._start = time.clock()\n        VSGLogger.info(\"{0:<20} - Started\".format(message))", "label": 1}
{"code": "def run_muse_with_merge(job, tumor_bam, normal_bam, univ_options, muse_options):\n    \"\"\"\n    A wrapper for the the entire MuSE sub-graph.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict muse_options: Options specific to MuSE\n    :return: fsID to the merged MuSE calls\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    spawn = job.wrapJobFn(run_muse, tumor_bam, normal_bam, univ_options, muse_options,\n                          disk='100M').encapsulate()\n    merge = job.wrapJobFn(merge_perchrom_vcfs, spawn.rv(), disk='100M')\n    job.addChild(spawn)\n    spawn.addChild(merge)\n    return merge.rv()", "label": 1}
{"code": "public RgbaColor adjustHue(float degrees) {\n        float[] HSL = convertToHsl();\n        HSL[0] = hueCheck(HSL[0] + degrees); // ensure [0-360)\n        return RgbaColor.fromHsl(HSL);\n    }", "label": 0}
{"code": "function role(value) {\n  if (typeof value === 'boolean')\n    return value;\n\n  if (value !== 'sender' && value !== 'receiver')\n    throw new errors.EncodingError(value, 'invalid role');\n  return (value === 'sender') ? false : true;\n}", "label": 3}
{"code": "public static Organization unserializeOrganization(final String organization) throws IOException {\n        final ObjectMapper mapper = new ObjectMapper();\n        mapper.disable(MapperFeature.USE_GETTERS_AS_SETTERS);\n        return mapper.readValue(organization, Organization.class);\n    }", "label": 0}
{"code": "def _set_frequency_spacing(self, min_freq, max_freq):\n        \"\"\"\n        Frequency spacing to use, i.e. how to map the available\n        frequency range to the discrete sheet rows.\n\n        NOTE: We're calculating the spacing of a range between the\n        highest and lowest frequencies, the actual segmentation and\n        averaging of the frequencies to fit this spacing occurs in\n        _getAmplitudes().\n\n        This method is here solely to provide a minimal overload if\n        custom spacing is required.\n        \"\"\"\n\n        self.frequency_spacing = np.linspace(min_freq, max_freq, num=self._sheet_dimensions[0]+1, endpoint=True)", "label": 1}
{"code": "def local_third_party_caveat(key, version):\n    ''' Returns a third-party caveat that, when added to a macaroon with\n    add_caveat, results in a caveat with the location \"local\", encrypted with\n    the given PublicKey.\n    This can be automatically discharged by discharge_all passing a local key.\n    '''\n    if version >= VERSION_2:\n        loc = 'local {} {}'.format(version, key)\n    else:\n        loc = 'local {}'.format(key)\n    return checkers.Caveat(location=loc, condition='')", "label": 1}
{"code": "public function findOrFail($id, User $user = null)\n    {\n        $query = Discussion::where('id', $id);\n\n        return $this->scopeVisibleTo($query, $user)->firstOrFail();\n    }", "label": 2}
{"code": "public static base_responses Import(nitro_service client, sslfipskey resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslfipskey Importresources[] = new sslfipskey[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tImportresources[i] = new sslfipskey();\n\t\t\t\tImportresources[i].fipskeyname = resources[i].fipskeyname;\n\t\t\t\tImportresources[i].key = resources[i].key;\n\t\t\t\tImportresources[i].inform = resources[i].inform;\n\t\t\t\tImportresources[i].wrapkeyname = resources[i].wrapkeyname;\n\t\t\t\tImportresources[i].iv = resources[i].iv;\n\t\t\t\tImportresources[i].exponent = resources[i].exponent;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, Importresources,\"Import\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def clear_offsets_excluding(excluded)\n      # Clear all offsets that aren't in `excluded`.\n      @processed_offsets.each do |topic, partitions|\n        partitions.keep_if do |partition, _|\n          excluded.fetch(topic, []).include?(partition)\n        end\n      end\n\n      # Clear the cached commits from the brokers.\n      @committed_offsets = nil\n      @resolved_offsets.clear\n    end", "label": 4}
{"code": "function extract(npmignore) {\n  if (npmignore == null) {\n    throw new Error('npmignore expects a string.');\n  }\n\n  var lines = split(npmignore);\n  var len = lines.length;\n  var npmignored = false;\n  var git = [];\n  var npm = [];\n  var i = 0;\n\n  while (i < len) {\n    var line = lines[i++];\n    if (re.test(line)) {\n      npmignored = true;\n    }\n\n    if (npmignored) {\n      npm.push(line);\n    } else {\n      git.push(line);\n    }\n  }\n\n  return npm;\n}", "label": 3}
{"code": "def add(class_, name, value, sep=';'):\n\t\t\"\"\"\n\t\tAdd a value to a delimited variable, but only when the value isn't\n\t\talready present.\n\t\t\"\"\"\n\t\tvalues = class_.get_values_list(name, sep)\n\t\tif value in values:\n\t\t\treturn\n\t\tnew_value = sep.join(values + [value])\n\t\twinreg.SetValueEx(\n\t\t\tclass_.key, name, 0, winreg.REG_EXPAND_SZ, new_value)\n\t\tclass_.notify()", "label": 1}
{"code": "public String processNested(Properties attributes) throws XDocletException\r\n    {\r\n        String    name      = OjbMemberTagsHandler.getMemberName();\r\n        XClass    type      = OjbMemberTagsHandler.getMemberType();\r\n        int       dim       = OjbMemberTagsHandler.getMemberDimension();\r\n        NestedDef nestedDef = _curClassDef.getNested(name);\r\n\r\n        if (type == null)\r\n        {\r\n            throw new XDocletException(Translator.getString(XDocletModulesOjbMessages.class,\r\n                                          XDocletModulesOjbMessages.COULD_NOT_DETERMINE_TYPE_OF_MEMBER,\r\n                                          new String[]{name}));\r\n        }\r\n        if (dim > 0)\r\n        {\r\n            throw new XDocletException(Translator.getString(XDocletModulesOjbMessages.class,\r\n                                          XDocletModulesOjbMessages.MEMBER_CANNOT_BE_NESTED,\r\n                                          new String[]{name, _curClassDef.getName()}));\r\n        }\r\n\r\n        ClassDescriptorDef nestedTypeDef = _model.getClass(type.getQualifiedName());\r\n\r\n        if (nestedTypeDef == null)\r\n        {\r\n            throw new XDocletException(Translator.getString(XDocletModulesOjbMessages.class,\r\n                                          XDocletModulesOjbMessages.COULD_NOT_DETERMINE_TYPE_OF_MEMBER,\r\n                                          new String[]{name}));\r\n        }\r\n        if (nestedDef == null)\r\n        {\r\n            nestedDef = new NestedDef(name, nestedTypeDef);\r\n            _curClassDef.addNested(nestedDef);\r\n        }\r\n        LogHelper.debug(false, OjbTagsHandler.class, \"processNested\", \"  Processing nested object \"+nestedDef.getName()+\" of type \"+nestedTypeDef.getName());\r\n\r\n        String attrName;\r\n        \r\n        for (Enumeration attrNames = attributes.propertyNames(); attrNames.hasMoreElements(); )\r\n        {\r\n            attrName = (String)attrNames.nextElement();\r\n            nestedDef.setProperty(attrName, attributes.getProperty(attrName));\r\n        }\r\n        return \"\";\r\n    }", "label": 0}
{"code": "func PgTablespaceByOid(db XODB, oid pgtypes.Oid) (*PgTablespace, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, spcname, spcowner, spcacl, spcoptions ` +\n\t\t`FROM pg_catalog.pg_tablespace ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpt := PgTablespace{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pt.Tableoid, &pt.Cmax, &pt.Xmax, &pt.Cmin, &pt.Xmin, &pt.Oid, &pt.Ctid, &pt.Spcname, &pt.Spcowner, &pt.Spcacl, &pt.Spcoptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pt, nil\n}", "label": 5}
{"code": "func findResources(isolators types.Isolators) (mem, cpus int64) {\n\tfor _, i := range isolators {\n\t\tswitch v := i.Value().(type) {\n\t\tcase *types.ResourceMemory:\n\t\t\tmem = v.Limit().Value()\n\t\t\t// Convert bytes into megabytes\n\t\t\tmem /= 1024 * 1024\n\t\tcase *types.ResourceCPU:\n\t\t\tcpus = v.Limit().Value()\n\t\t}\n\t}\n\treturn mem, cpus\n}", "label": 5}
{"code": "public static void downloadUrl(String stringUrl, Map<String, String> parameters, File fileToSave)\n      throws IOException {\n    URL url = new URL(stringUrl);\n    HttpURLConnection conn = (HttpURLConnection) url.openConnection();\n    conn.setFollowRedirects(true);\n    \n    if (parameters != null) {\n      for (Entry<String, String> entry : parameters.entrySet()) {\n        conn.addRequestProperty(entry.getKey(), entry.getValue());\n      }\n    }\n\n\n    boolean redirect = false;\n\n    // normally, 3xx is redirect\n    int status = conn.getResponseCode();\n    if (status != HttpURLConnection.HTTP_OK) {\n        if (status == HttpURLConnection.HTTP_MOVED_TEMP\n            || status == HttpURLConnection.HTTP_MOVED_PERM\n                || status == HttpURLConnection.HTTP_SEE_OTHER)\n        redirect = true;\n    }\n\n    if (redirect) {\n\n        // get redirect url from \"location\" header field\n        String newUrl = conn.getHeaderField(\"Location\");\n\n        // get the cookie if need, for login\n        String cookies = conn.getHeaderField(\"Set-Cookie\");\n\n        // open the new connnection again\n        conn = (HttpURLConnection) new URL(newUrl).openConnection();\n        conn.setRequestProperty(\"Cookie\", cookies);\n\n    }\n    \n    byte[] data = MyStreamUtils.readContentBytes(conn.getInputStream());\n    FileOutputStream fos = new FileOutputStream(fileToSave);\n    fos.write(data);\n    fos.close();\n  }", "label": 0}
{"code": "func srcLine(src []byte, p token.Position) string {\n\t// Run to end of line in both directions if not at line start/end.\n\tlo, hi := p.Offset, p.Offset+1\n\tfor lo > 0 && src[lo-1] != '\\n' {\n\t\tlo--\n\t}\n\tfor hi < len(src) && src[hi-1] != '\\n' {\n\t\thi++\n\t}\n\treturn string(src[lo:hi])\n}", "label": 5}
{"code": "function (patternFolder, patterns, cb) {\n    getSourceFile(function generatePatterns(content) {\n      patterns.forEach(function (file) {\n        content += '<hr/>';\n        content += '<div class=\"pattern\"><div class=\"display\">';\n        content += file.content;\n        content += '</div><div class=\"source\"><textarea rows=\"6\" cols=\"30\">';\n        content += simpleEscaper(file.content);\n        content += '</textarea>';\n        content += '<p><a href=\"/'+ patternFolder + '/' + file.filename +'\">' + file.filename + '</a></p>';\n        content += '</div></div>';\n      });\n      content += '</body></html>';\n      cb(content);\n    });\n  }", "label": 3}
{"code": "func parseCIMD(u *url.URL) (*cimd, error) {\n\tif u.Scheme != Scheme {\n\t\treturn nil, fmt.Errorf(\"unsupported scheme: %q\", u.Scheme)\n\t}\n\tparts := strings.SplitN(u.Opaque, \":\", 3)\n\tif len(parts) < 3 {\n\t\treturn nil, fmt.Errorf(\"malformed distribution uri: %q\", u.String())\n\t}\n\tversion, err := strconv.ParseUint(strings.TrimPrefix(parts[1], \"v=\"), 10, 32)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"malformed distribution version: %s\", parts[1])\n\t}\n\treturn &cimd{\n\t\tType:    Type(parts[0]),\n\t\tVersion: uint32(version),\n\t\tData:    parts[2],\n\t}, nil\n}", "label": 5}
{"code": "public function bufferWrite(string $data): Promise\n    {\n        if ($this->append_after) {\n            $this->append_after -= strlen($data);\n            if ($this->append_after === 0) {\n                $data .= $this->append;\n                $this->append = '';\n            } elseif ($this->append_after < 0) {\n                $this->append_after = 0;\n                $this->append = '';\n\n                throw new Exception('Tried to send too much out of frame data, cannot append');\n            }\n        }\n\n        return $this->write($data);\n    }", "label": 2}
{"code": "def run(args)\n      options = SCSSLint::Options.new.parse(args)\n      act_on_options(options)\n    rescue StandardError => e\n      handle_runtime_exception(e, options)\n    end", "label": 4}
{"code": "public function valid()\n    {\n        $isValid = $this->isFlagSet(self::STATUS_VALID);\n        $subscriptionFlags = self::STATUS_SUBSCRIBED | self::STATUS_PSUBSCRIBED;\n        $hasSubscriptions = ($this->statusFlags & $subscriptionFlags) > 0;\n\n        return $isValid && $hasSubscriptions;\n    }", "label": 2}
{"code": "function(xs, ys, matrix){\n  var lcs = [];\n  for(var i = xs.size, j = ys.size; i !== 0 && j !== 0;){\n    if (matrix[i][j] === matrix[i-1][j]){ i--; }\n    else if (matrix[i][j] === matrix[i][j-1]){ j--; }\n    else{\n      if(Immutable.is(xs.get(i-1), ys.get(j-1))){\n        lcs.push(xs.get(i-1));\n        i--;\n        j--;\n      }\n    }\n  }\n  return lcs.reverse();\n}", "label": 3}
{"code": "func (a *ArgType) colcount(fields []*Field, ignoreNames ...string) int {\n\tignore := map[string]bool{}\n\tfor _, n := range ignoreNames {\n\t\tignore[n] = true\n\t}\n\n\ti := 1\n\tfor _, f := range fields {\n\t\tif ignore[f.Name] {\n\t\t\tcontinue\n\t\t}\n\n\t\ti++\n\t}\n\treturn i\n}", "label": 5}
{"code": "public function queue_purge($queue = '', $nowait = false, $ticket = null)\n    {\n        $ticket = $this->getTicket($ticket);\n        list($class_id, $method_id, $args) = $this->protocolWriter->queuePurge($ticket, $queue, $nowait);\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        if ($nowait) {\n            return null;\n        }\n\n        return $this->wait(array(\n            $this->waitHelper->get_wait('queue.purge_ok')\n        ), false, $this->channel_rpc_timeout);\n    }", "label": 2}
{"code": "def rgb_to_hsv(self,RGB):\n        \"linear rgb to hsv\"\n        gammaRGB = self._gamma_rgb(RGB)\n        return self._ABC_to_DEF_by_fn(gammaRGB,rgb_to_hsv)", "label": 1}
{"code": "def percentile(self, percentile):\n        \"\"\"Return bin center nearest to percentile\"\"\"\n        return self.bin_centers[np.argmin(np.abs(self.cumulative_density * 100 - percentile))]", "label": 1}
{"code": "def register(self, signal, plugin, description=\"\"):\n        \"\"\"\n        Registers a new signal.\n\n        :param signal: Unique name of the signal\n        :param plugin: Plugin, which registers the new signal\n        :param description: Description of the reason or use case, why this signal is needed.\n                            Used for documentation.\n        \"\"\"\n        if signal in self.signals.keys():\n            raise Exception(\"Signal %s was already registered by %s\" % (signal, self.signals[signal].plugin.name))\n\n        self.signals[signal] = Signal(signal, plugin, self._namespace, description)\n        self.__log.debug(\"Signal %s registered by %s\" % (signal, plugin.name))\n        return self.signals[signal]", "label": 1}
{"code": "def BROKER_TYPE(self):\n        \"\"\"Custom setting allowing switch between rabbitmq, redis\"\"\"\n\n        broker_type = get('BROKER_TYPE', DEFAULT_BROKER_TYPE)\n        if broker_type not in SUPPORTED_BROKER_TYPES:\n            log.warn(\"Specified BROKER_TYPE {} not supported. Backing to default {}\".format(\n                broker_type, DEFAULT_BROKER_TYPE))\n            return DEFAULT_BROKER_TYPE\n        else:\n            return broker_type", "label": 1}
{"code": "def page_entries_info(collection, options = {})\n      entry_name = options[:entry_name] || \"entry\"\n      entry_name = entry_name.pluralize unless collection.total_count == 1\n\n      if collection.total_pages < 2\n        t('trestle.helpers.page_entries_info.one_page.display_entries', entry_name: entry_name, count: collection.total_count, default: \"Displaying <strong>all %{count}</strong> %{entry_name}\")\n      else\n        first = number_with_delimiter(collection.offset_value + 1)\n        last  = number_with_delimiter((sum = collection.offset_value + collection.limit_value) > collection.total_count ? collection.total_count : sum)\n        total = number_with_delimiter(collection.total_count)\n\n        t('trestle.helpers.page_entries_info.more_pages.display_entries', entry_name: entry_name, first: first, last: last, total: total, default: \"Displaying %{entry_name} <strong>%{first}&nbsp;-&nbsp;%{last}</strong> of <b>%{total}</b>\")\n      end.html_safe\n    end", "label": 4}
{"code": "public function callResult($id, $data = array()) {\n        return $this->send(json_encode(array(WAMP::MSG_CALL_RESULT, $id, $data)));\n    }", "label": 2}
{"code": "public static double Sinc(double x) {\r\n        return Math.sin(Math.PI * x) / (Math.PI * x);\r\n    }", "label": 0}
{"code": "def summary(self, id, seq, intf, filter=None, inline=False): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a capture's summary.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param intf: Interface name as string.\n        :param filter: (optional) PCAP filter to apply as string.\n        :param inline: (optional) Use inline version of capture file.\n        :return: :class:`captures.Summary <captures.Summary>` object\n        :rtype: captures.Summary\n        \"\"\"\n        schema = SummarySchema()\n        resp = self.service.get(self._base(id, seq)+str(intf)+'/summary/',\n                                params={'filter': filter, 'inline': inline})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public static base_responses delete(nitro_service client, String mappolicyname[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (mappolicyname != null && mappolicyname.length > 0) {\n\t\t\tpolicymap deleteresources[] = new policymap[mappolicyname.length];\n\t\t\tfor (int i=0;i<mappolicyname.length;i++){\n\t\t\t\tdeleteresources[i] = new policymap();\n\t\t\t\tdeleteresources[i].mappolicyname = mappolicyname[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (c *IpamConf) CopyTo(dstC *IpamConf) error {\n\tdstC.PreferredPool = c.PreferredPool\n\tdstC.SubPool = c.SubPool\n\tdstC.Gateway = c.Gateway\n\tif c.AuxAddresses != nil {\n\t\tdstC.AuxAddresses = make(map[string]string, len(c.AuxAddresses))\n\t\tfor k, v := range c.AuxAddresses {\n\t\t\tdstC.AuxAddresses[k] = v\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def part(params = {})\n      new_part = Part.new(params)\n      yield new_part if block_given?\n      add_part(new_part)\n    end", "label": 4}
{"code": "def process(self, data, type, history):\n        \"\"\" process the specified type then process its children \"\"\"\n        if type in history:\n            return\n        if type.enum():\n            return\n        history.append(type)\n        resolved = type.resolve()\n        value = None\n        if type.multi_occurrence():\n            value = []\n        else:\n            if len(resolved) > 0:\n                if resolved.mixed():\n                    value = Factory.property(resolved.name)\n                    md = value.__metadata__\n                    md.sxtype = resolved\n                else:\n                    value = Factory.object(resolved.name)\n                    md = value.__metadata__\n                    md.sxtype = resolved\n                    md.ordering = self.ordering(resolved)\n        setattr(data, type.name, value)\n        if value is not None:\n            data = value\n        if not isinstance(data, list):\n            self.add_attributes(data, resolved)\n            for child, ancestry in resolved.children():\n                if self.skip_child(child, ancestry):\n                    continue\n                self.process(data, child, history[:])", "label": 1}
{"code": "public function jobConfigurationProperties(\n        $projectId,\n        array $config,\n        $location\n    ) {\n        $this->config = array_replace_recursive([\n            'projectId' => $projectId,\n            'jobReference' => ['projectId' => $projectId]\n        ], $config);\n\n        if ($location && !isset($this->config['jobReference']['location'])) {\n            $this->config['jobReference']['location'] = $location;\n        }\n\n        if (!isset($this->config['jobReference']['jobId'])) {\n            $this->config['jobReference']['jobId'] = $this->generateJobId();\n        }\n    }", "label": 2}
{"code": "def extractTimes(self, inp):\n        \"\"\"Extracts time-related information from an input string.\n        Ignores any information related to the specific date, focusing\n        on the time-of-day.\n\n        Args:\n            inp (str): Input string to be parsed.\n\n        Returns:\n            A list of datetime objects containing the extracted times from the\n            input snippet, or an empty list if none found.\n        \"\"\"\n        def handleMatch(time):\n            relative = False\n\n            if not time:\n                return None\n\n            # Default times: 8am, 12pm, 7pm\n            elif time.group(1) == 'morning':\n                h = 8\n                m = 0\n            elif time.group(1) == 'afternoon':\n                h = 12\n                m = 0\n            elif time.group(1) == 'evening':\n                h = 19\n                m = 0\n            elif time.group(4) and time.group(5):\n                h, m = 0, 0\n\n                # Extract hours difference\n                converter = NumberService()\n                try:\n                    diff = converter.parse(time.group(4))\n                except:\n                    return None\n\n                if time.group(5) == 'hours':\n                    h += diff\n                else:\n                    m += diff\n\n                # Extract minutes difference\n                if time.group(6):\n                    converter = NumberService()\n                    try:\n                        diff = converter.parse(time.group(7))\n                    except:\n                        return None\n\n                    if time.group(8) == 'hours':\n                        h += diff\n                    else:\n                        m += diff\n\n                relative = True\n            else:\n                # Convert from \"HH:MM pm\" format\n                t = time.group(2)\n                h, m = int(t.split(':')[0]) % 12, int(t.split(':')[1])\n\n                try:\n                    if time.group(3) == 'pm':\n                        h += 12\n                except IndexError:\n                    pass\n\n            if relative:\n                return self.now + datetime.timedelta(hours=h, minutes=m)\n            else:\n                return datetime.datetime(\n                    self.now.year, self.now.month, self.now.day, h, m\n                )\n\n        inp = self._preprocess(inp)\n        return [handleMatch(time) for time in self._timeRegex.finditer(inp)]", "label": 1}
{"code": "function(fetchMethod, options) {\n        var object = this;\n        this.loadingCount++;\n        this.loading = true;\n        this.trigger('load-begin');\n        return $.when(fetchMethod.call(object, options)).always(function() {\n          if (!object.loadedOnce) {\n            object.loadedOnce = true;\n            object.loadedOnceDeferred.resolve();\n          }\n          object.loadingCount--;\n          if (object.loadingCount <= 0) {\n            object.loadingCount = 0; // prevent going negative.\n            object.loading = false;\n          }\n        }).done(function(data, textStatus, jqXHR) {\n          object.trigger('load-complete', {success: true, data: data, textStatus: textStatus, jqXHR: jqXHR});\n        }).fail(function(jqXHR, textStatus, errorThrown) {\n          object.trigger('load-complete', {success: false, jqXHR: jqXHR, textStatus: textStatus, errorThrown: errorThrown});\n        });\n      }", "label": 3}
{"code": "def reset_persisted_children\n      _children.each do |child|\n        child.move_changes\n        child.new_record = false\n      end\n      _reset_memoized_children!\n    end", "label": 4}
{"code": "func RemoveCASecrets(ca CertAuthority) {\n\tca.SetSigningKeys(nil)\n\tkeyPairs := ca.GetTLSKeyPairs()\n\tfor i := range keyPairs {\n\t\tkeyPairs[i].Key = nil\n\t}\n\tca.SetTLSKeyPairs(keyPairs)\n}", "label": 5}
{"code": "def solve(self):\n        \"\"\" Runs a power flow\n\n        @rtype: dict\n        @return: Solution dictionary with the following keys:\n                   - C{V} - final complex voltages\n                   - C{converged} - boolean value indicating if the solver\n                     converged or not\n                   - C{iterations} - the number of iterations performed\n        \"\"\"\n        # Zero result attributes.\n        self.case.reset()\n\n        # Retrieve the contents of the case.\n        b, l, g, _, _, _, _ = self._unpack_case(self.case)\n\n        # Update bus indexes.\n        self.case.index_buses(b)\n\n        # Index buses accoding to type.\n#        try:\n#            _, pq, pv, pvpq = self._index_buses(b)\n#        except SlackBusError:\n#            logger.error(\"Swing bus required for DCPF.\")\n#            return {\"converged\": False}\n\n        refs, pq, pv, pvpq = self._index_buses(b)\n        if len(refs) != 1:\n            logger.error(\"Swing bus required for DCPF.\")\n            return {\"converged\": False}\n\n        # Start the clock.\n        t0 = time()\n\n        # Build the vector of initial complex bus voltages.\n        V0 = self._initial_voltage(b, g)\n\n        # Save index and angle of original reference bus.\n#        if self.qlimit:\n#            ref0 = ref\n#            Varef0 = b[ref0].Va\n#            # List of buses at Q limits.\n#            limits = []\n#            # Qg of generators at Q limits.\n#            fixedQg = matrix(0.0, (g.size[0], 1))\n\n        repeat = True\n        while repeat:\n            # Build admittance matrices.\n            Ybus, Yf, Yt = self.case.getYbus(b, l)\n\n            # Compute complex bus power injections (generation - load).\n            Sbus = self.case.getSbus(b)\n\n            # Run the power flow.\n            V, converged, i = self._run_power_flow(Ybus, Sbus, V0, pv, pq, pvpq)\n\n            # Update case with solution.\n            self.case.pf_solution(Ybus, Yf, Yt, V)\n\n            # Enforce generator Q limits.\n            if self.qlimit:\n                raise NotImplementedError\n            else:\n                repeat = False\n\n        elapsed = time() - t0\n\n        if converged and self.verbose:\n            logger.info(\"AC power flow converged in %.3fs\" % elapsed)\n\n        return {\"converged\": converged, \"elapsed\": elapsed, \"iterations\": i,\n                \"V\":V}", "label": 1}
{"code": "public static cachepolicy_cacheglobal_binding[] get(nitro_service service, String policyname) throws Exception{\n\t\tcachepolicy_cacheglobal_binding obj = new cachepolicy_cacheglobal_binding();\n\t\tobj.set_policyname(policyname);\n\t\tcachepolicy_cacheglobal_binding response[] = (cachepolicy_cacheglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setIntentView($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\IntentView::class);\n        $this->intent_view = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def run_mutect_with_merge(job, tumor_bam, normal_bam, univ_options, mutect_options):\n    \"\"\"\n    A wrapper for the the entire MuTect sub-graph.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict mutect_options: Options specific to MuTect\n    :return: fsID to the merged MuTect calls\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    spawn = job.wrapJobFn(run_mutect, tumor_bam, normal_bam, univ_options,\n                          mutect_options).encapsulate()\n    merge = job.wrapJobFn(merge_perchrom_vcfs, spawn.rv())\n    job.addChild(spawn)\n    spawn.addChild(merge)\n    return merge.rv()", "label": 1}
{"code": "public static sslservice get(nitro_service service, String servicename) throws Exception{\n\t\tsslservice obj = new sslservice();\n\t\tobj.set_servicename(servicename);\n\t\tsslservice response = (sslservice) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def render_template(view, template, layout_name = nil, locals = {}) #:nodoc:\n      return [super.body] unless layout_name && template.supports_streaming?\n\n      locals ||= {}\n      layout   = layout_name && find_layout(layout_name, locals.keys, [formats.first])\n\n      Body.new do |buffer|\n        delayed_render(buffer, template, layout, view, locals)\n      end\n    end", "label": 4}
{"code": "public static base_responses unset(nitro_service client, String acl6name[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (acl6name != null && acl6name.length > 0) {\n\t\t\tnsacl6 unsetresources[] = new nsacl6[acl6name.length];\n\t\t\tfor (int i=0;i<acl6name.length;i++){\n\t\t\t\tunsetresources[i] = new nsacl6();\n\t\t\t\tunsetresources[i].acl6name = acl6name[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func CreateOptionIpam(ipV4, ipV6 net.IP, llIPs []net.IP, ipamOptions map[string]string) EndpointOption {\n\treturn func(ep *endpoint) {\n\t\tep.prefAddress = ipV4\n\t\tep.prefAddressV6 = ipV6\n\t\tif len(llIPs) != 0 {\n\t\t\tfor _, ip := range llIPs {\n\t\t\t\tnw := &net.IPNet{IP: ip, Mask: linkLocalMask}\n\t\t\t\tif ip.To4() == nil {\n\t\t\t\t\tnw.Mask = linkLocalMaskIPv6\n\t\t\t\t}\n\t\t\t\tep.iface.llAddrs = append(ep.iface.llAddrs, nw)\n\t\t\t}\n\t\t}\n\t\tep.ipamOptions = ipamOptions\n\t}\n}", "label": 5}
{"code": "func MarshalLicense(license License, opts ...MarshalOption) ([]byte, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch resource := license.(type) {\n\tcase *LicenseV3:\n\t\tif !cfg.PreserveResourceID {\n\t\t\t// avoid modifying the original object\n\t\t\t// to prevent unexpected data races\n\t\t\tcopy := *resource\n\t\t\tcopy.SetResourceID(0)\n\t\t\tresource = &copy\n\t\t}\n\t\treturn utils.FastMarshal(resource)\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"unrecognized resource version %T\", license)\n\t}\n}", "label": 5}
{"code": "func (l *LoadBalancer) untrackConnection(backend NetAddr, id int64) {\n\tl.Lock()\n\tdefer l.Unlock()\n\ttracker, ok := l.connections[backend]\n\tif !ok {\n\t\treturn\n\t}\n\tdelete(tracker, id)\n}", "label": 5}
{"code": "function getChildren(ul, recursive) {\n    var children = [];\n    ul.children().children(\"[id^='cd']\")\n      .each(function() {\n        var comment = $(this).data('comment');\n        if (recursive)\n          comment.children = getChildren($(this).find('#cl' + comment.id), true);\n        children.push(comment);\n      });\n    return children;\n  }", "label": 3}
{"code": "def _pruaf(self):\n        \"\"\"\n        Return percentage runoff urban adjustment factor.\n\n        Methodology source: eqn. 6, Kjeldsen 2010\n        \"\"\"\n        return 1 + 0.47 * self.catchment.descriptors.urbext(self.year) \\\n                   * self.catchment.descriptors.bfihost / (1 - self.catchment.descriptors.bfihost)", "label": 1}
{"code": "def all_classes\n      klass = @app_class.constantize\n      all_classes = []\n      while klass != Object\n        all_classes << klass\n        klass = klass.superclass\n      end\n      all_classes.reverse\n    end", "label": 4}
{"code": "func (di *info) ovf() (string, error) {\n\tvar buf bytes.Buffer\n\n\ttmpl, err := template.New(\"ovf\").Parse(ovfenv)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\terr = tmpl.Execute(&buf, di)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn buf.String(), nil\n}", "label": 5}
{"code": "public static Face createTriangle(Vertex v0, Vertex v1, Vertex v2, double minArea) {\n        Face face = new Face();\n        HalfEdge he0 = new HalfEdge(v0, face);\n        HalfEdge he1 = new HalfEdge(v1, face);\n        HalfEdge he2 = new HalfEdge(v2, face);\n\n        he0.prev = he2;\n        he0.next = he1;\n        he1.prev = he0;\n        he1.next = he2;\n        he2.prev = he1;\n        he2.next = he0;\n\n        face.he0 = he0;\n\n        // compute the normal and offset\n        face.computeNormalAndCentroid(minArea);\n        return face;\n    }", "label": 0}
{"code": "func clusterDialer(remoteCluster reversetunnel.RemoteSite) auth.DialContext {\n\treturn func(in context.Context, network, _ string) (net.Conn, error) {\n\t\treturn remoteCluster.DialAuthServer()\n\t}\n}", "label": 5}
{"code": "function getResource(serviceInfo, moduleStack) {\n        var resourceName = serviceInfo.resourceName;\n        var resourcePath = '/resources/' + resourceName + '/' + resourceName + '.resource';\n        return this.loadIfExists(resourcePath, moduleStack, 'Could not find resource file');\n    }", "label": 3}
{"code": "public static function hasRelativeKeywords($time)\n    {\n        if (strtotime($time) === false) {\n            return false;\n        }\n\n        $date1 = new DateTime('2000-01-01T00:00:00Z');\n        $date1->modify($time);\n        $date2 = new DateTime('2001-12-25T00:00:00Z');\n        $date2->modify($time);\n\n        return $date1 != $date2;\n    }", "label": 2}
{"code": "func NewACI(dir string, manifest string, entries []*ACIEntry) (*os.File, error) {\n\tvar im schema.ImageManifest\n\tif err := im.UnmarshalJSON([]byte(manifest)); err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"invalid image manifest\"), err)\n\t}\n\n\ttf, err := ioutil.TempFile(dir, \"\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer os.Remove(tf.Name())\n\n\ttw := tar.NewWriter(tf)\n\taw := NewImageWriter(im, tw)\n\n\tfor _, entry := range entries {\n\t\t// Add default mode\n\t\tif entry.Header.Mode == 0 {\n\t\t\tif entry.Header.Typeflag == tar.TypeDir {\n\t\t\t\tentry.Header.Mode = 0755\n\t\t\t} else {\n\t\t\t\tentry.Header.Mode = 0644\n\t\t\t}\n\t\t}\n\t\t// Add calling user uid and gid or tests will fail\n\t\tentry.Header.Uid = os.Getuid()\n\t\tentry.Header.Gid = os.Getgid()\n\t\tsr := strings.NewReader(entry.Contents)\n\t\tif err := aw.AddFile(entry.Header, sr); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif err := aw.Close(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn tf, nil\n}", "label": 5}
{"code": "def bulk_delete(ids, strict = false)\n      min_snowflake = IDObject.synthesise(Time.now - TWO_WEEKS)\n\n      ids.reject! do |e|\n        next unless e < min_snowflake\n\n        message = \"Attempted to bulk_delete message #{e} which is too old (min = #{min_snowflake})\"\n        raise ArgumentError, message if strict\n\n        Discordrb::LOGGER.warn(message)\n        true\n      end\n\n      API::Channel.bulk_delete_messages(@bot.token, @id, ids)\n      ids.size\n    end", "label": 4}
{"code": "func fieldExcludes(fl FieldLevel) bool {\n\tfield := fl.Field()\n\n\tcurrentField, _, ok := fl.GetStructFieldOK()\n\tif !ok {\n\t\treturn true\n\t}\n\n\treturn !strings.Contains(field.String(), currentField.String())\n}", "label": 5}
{"code": "public FinishRequest toFinishRequest(boolean includeHeaders) {\n        if (includeHeaders) {\n            return new FinishRequest(body, copyHeaders(headers), statusCode);\n        } else {\n            String mime = null;\n            if (body!=null) {\n                mime = \"text/plain\";\n                if (headers!=null && (headers.containsKey(\"Content-Type\") || headers.containsKey(\"content-type\"))) {\n                    mime = headers.get(\"Content-Type\");\n                    if (mime==null) {\n                        mime = headers.get(\"content-type\");\n                    }\n                }\n            }\n\n            return new FinishRequest(body, mime, statusCode);\n        }\n    }", "label": 0}
{"code": "def _do_get(self, url, **kwargs):\n        \"\"\"\n        Convenient method for GET requests\n        Returns http request status value from a POST request\n        \"\"\"\n        #TODO:\n        # Add error handling. Check for HTTP status here would be much more conveinent than in each calling method\n        scaleioapi_post_headers = {'Content-type':'application/json','Version':'1.0'}\n        try:\n            #response = self._session.get(\"{}/{}\".format(self._api_url, uri)).json()\n            response = self._session.get(url)\n            if response.status_code == requests.codes.ok:\n                self.conn.logger.debug('_do_get() - HTTP response OK, data: %s', response.text)                \n                return response\n            else:\n                self.conn.logger.error('_do_get() - HTTP response error: %s', response.status_code)\n                self.conn.logger.error('_do_get() - HTTP response error, data: %s', response.text)                \n                raise RuntimeError(\"_do_get() - HTTP response error\" + response.status_code)\n        except Exception as e:\n            self.conn.logger.error(\"_do_get() - Unhandled Error Occurred: %s\" % str(e)) \n            raise RuntimeError(\"_do_get() - Communication error with ScaleIO gateway\")\n        return response", "label": 1}
{"code": "public static function env()\n    {\n        return function () {\n            // Use credentials from environment variables, if available\n            $key = getenv(self::ENV_KEY);\n            $secret = getenv(self::ENV_SECRET);\n            if ($key && $secret) {\n                return Promise\\promise_for(\n                    new Credentials($key, $secret, getenv(self::ENV_SESSION) ?: NULL)\n                );\n            }\n\n            return self::reject('Could not find environment variable '\n                . 'credentials in ' . self::ENV_KEY . '/' . self::ENV_SECRET);\n        };\n    }", "label": 2}
{"code": "function getMongooseConnection(mongoDbUrl, logger, cb) {\n  logger.debug(\"creating mongoose connection for data_source_update job\", {mongoDbUrl: mongoDbUrl});\n  var mongooseConnection = mongoose.createConnection(mongoDbUrl);\n  return cb(undefined, mongooseConnection);\n}", "label": 3}
{"code": "def revert(self, unchanged_only=False):\n        \"\"\"Revert all files in this changelist\n\n        :param unchanged_only: Only revert unchanged files\n        :type unchanged_only: bool\n        :raises: :class:`.ChangelistError`\n        \"\"\"\n        if self._reverted:\n            raise errors.ChangelistError('This changelist has been reverted')\n\n        change = self._change\n        if self._change == 0:\n            change = 'default'\n\n        cmd = ['revert', '-c', str(change)]\n\n        if unchanged_only:\n            cmd.append('-a')\n\n        files = [f.depotFile for f in self._files]\n        if files:\n            cmd += files\n            self._connection.run(cmd)\n\n        self._files = []\n        self._reverted = True", "label": 1}
{"code": "public Double score(final String member) {\n        return doWithJedis(new JedisCallable<Double>() {\n            @Override\n            public Double call(Jedis jedis) {\n                return jedis.zscore(getKey(), member);\n            }\n        });\n    }", "label": 0}
{"code": "def container\n      @opf_path = opf_path\n      tmplfile = File.expand_path('./xml/container.xml.erb', ReVIEW::Template::TEMPLATE_DIR)\n      tmpl = ReVIEW::Template.load(tmplfile)\n      tmpl.result(binding)\n    end", "label": 4}
{"code": "public static base_responses delete(nitro_service client, String ipv6address[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (ipv6address != null && ipv6address.length > 0) {\n\t\t\tnsip6 deleteresources[] = new nsip6[ipv6address.length];\n\t\t\tfor (int i=0;i<ipv6address.length;i++){\n\t\t\t\tdeleteresources[i] = new nsip6();\n\t\t\t\tdeleteresources[i].ipv6address = ipv6address[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def _get_voltage_angle_var(self, refs, buses):\n        \"\"\" Returns the voltage angle variable set.\n        \"\"\"\n        Va = array([b.v_angle * (pi / 180.0) for b in buses])\n\n        Vau = Inf * ones(len(buses))\n        Val = -Vau\n        Vau[refs] = Va[refs]\n        Val[refs] = Va[refs]\n\n        return Variable(\"Va\", len(buses), Va, Val, Vau)", "label": 1}
{"code": "function sleep(seconds) {\n  const time = parseFloat(seconds, 10);\n  if (!_.isFinite(time)) { throw new Error(`invalid time interval '${seconds}'`); }\n  runProgram('sleep', [time], {logCommand: false});\n}", "label": 3}
{"code": "public static double SymmetricKullbackLeibler(double[] p, double[] q) {\n        double dist = 0;\n        for (int i = 0; i < p.length; i++) {\n            dist += (p[i] - q[i]) * (Math.log(p[i]) - Math.log(q[i]));\n        }\n\n        return dist;\n    }", "label": 0}
{"code": "private function isLastEnabledEntity($result, $entity): bool\n    {\n        return !$result || 0 === count($result)\n        || (1 === count($result) && $entity === ($result instanceof \\Iterator ? $result->current() : current($result)));\n    }", "label": 2}
{"code": "public void setClasspathRef(Reference r)\r\n    {\r\n        createClasspath().setRefid(r);\r\n        log(\"Verification classpath is \"+ _classpath,\r\n            Project.MSG_VERBOSE);\r\n    }", "label": 0}
{"code": "function getTypeFromArrayBindingPattern(pattern, includePatternInType, reportErrors) {\n            var elements = pattern.elements;\n            if (elements.length === 0 || elements[elements.length - 1].dotDotDotToken) {\n                return languageVersion >= 2 /* ES6 */ ? createIterableType(anyType) : anyArrayType;\n            }\n            // If the pattern has at least one element, and no rest element, then it should imply a tuple type.\n            var elementTypes = ts.map(elements, function (e) { return e.kind === 193 /* OmittedExpression */ ? anyType : getTypeFromBindingElement(e, includePatternInType, reportErrors); });\n            var result = createTupleType(elementTypes);\n            if (includePatternInType) {\n                result = cloneTypeReference(result);\n                result.pattern = pattern;\n            }\n            return result;\n        }", "label": 3}
{"code": "def execute_tasks(self):\n        \"\"\"\n        run execute on all tasks IFF prior task is successful\n        \"\"\"\n        for t in self.tasks:\n            print('RUNNING ' + str(t.task_id) + ' = ' + t.name)\n            t.execute()\n            if t.success != '__IGNORE__RESULT__':\n                print(t)\n                print('TASK RESULT :', t.result, ' but success = ' , t.success )\n                if t.result != t.success:\n                    #raise Exception('Project execution failed at task ' + str(t.task_id) + ' = ' + t.name)\n                    print('ABORTING TASK EXECUTION SEQUENCE'  + str(t.task_id) + ' = ' + t.name)\n                    break", "label": 1}
{"code": "function()\n  {\n    if ( AP.reverse )\n    {\n      AP.reverse.apply( this );\n    }\n    else\n    {\n      reverse( this );\n    }\n\n    this.trigger( Collection.Events.Updates, [this] );\n\n    return this;\n  }", "label": 3}
{"code": "function sma(arr, range, format) {\n  if (!Array.isArray(arr)) {\n    throw TypeError('expected first argument to be an array');\n  }\n\n  var fn = typeof format === 'function' ? format : toFixed;\n  var num = range || arr.length;\n  var res = [];\n  var len = arr.length + 1;\n  var idx = num - 1;\n  while (++idx < len) {\n    res.push(fn(avg(arr, idx, num)));\n  }\n  return res;\n}", "label": 3}
{"code": "def define_log_renderer(fmt, fpath, quiet):\n    \"\"\"\n    the final log processor that structlog requires to render.\n    \"\"\"\n    # it must accept a logger, method_name and event_dict (just like processors)\n    # but must return the rendered string, not a dictionary.\n    # TODO tty logic\n\n    if fmt:\n        return structlog.processors.JSONRenderer()\n\n    if fpath is not None:\n        return structlog.processors.JSONRenderer()\n\n    if sys.stderr.isatty() and not quiet:\n        return structlog.dev.ConsoleRenderer()\n\n    return structlog.processors.JSONRenderer()", "label": 1}
{"code": "private static function _validate($fields, $parents, $skip, $baseRef)\n    {\n        $valid = true;\n        $blacklist = [];\n        if (is_object($fields)) {\n            if (in_array($fields, $skip, true)) {\n                return true;\n            }\n            $skip[] = $fields;\n            $blacklist = property_exists($fields, '_blacklist') ? $fields::$_blacklist : [];\n        }\n\n        foreach ($fields as $field => $value) {\n            if ($value === null || is_scalar($value) || in_array($field, $blacklist)) {\n                continue;\n            }\n            $ref = $baseRef !== '' ? $baseRef.'/'.urlencode((string)$field) : urlencode((string)$field);\n            if (is_object($value)) {\n                if (method_exists($value, 'validate')) {\n                    if (!$value->validate($parents, $skip, $ref)) {\n                        $valid = false;\n                    }\n                } elseif (!self::_validate($value, $parents, $skip, $ref)) {\n                    $valid = false;\n                }\n            } elseif (is_array($value) && !self::_validate($value, $parents, $skip, $ref)) {\n                $valid = false;\n            }\n        }\n        return $valid;\n    }", "label": 2}
{"code": "def userpass(username, password, options = {})\n      payload = { password: password }.merge(options)\n      json = client.post(\"/v1/auth/userpass/login/#{encode_path(username)}\", JSON.fast_generate(payload))\n      secret = Secret.decode(json)\n      client.token = secret.auth.client_token\n      return secret\n    end", "label": 4}
{"code": "def apply_modifier_list(location_id, modifier_list_id, item_id, opts = {})\n      data, _status_code, _headers = apply_modifier_list_with_http_info(location_id, modifier_list_id, item_id, opts)\n      return data\n    end", "label": 4}
{"code": "def variants_to_reference_contexts_dataframe(\n        variants,\n        context_size,\n        transcript_id_whitelist=None):\n    \"\"\"\n    Given a collection of variants, find all reference sequence contexts\n    around each variant.\n\n    Parameters\n    ----------\n    variants : varcode.VariantCollection\n\n    context_size : int\n        Max of nucleotides to include to the left and right of the variant\n        in the context sequence.\n\n    transcript_id_whitelist : set, optional\n        If given, then only consider transcripts whose IDs are in this set.\n\n    Returns a DataFrame with {\"chr\", \"pos\", \"ref\", \"alt\"} columns for variants,\n    as well as all the fields of ReferenceContext.\n    \"\"\"\n\n    df_builder = DataFrameBuilder(\n        ReferenceContext,\n        exclude=[\"variant\"],\n        converters=dict(transcripts=lambda ts: \";\".join(t.name for t in ts)),\n        extra_column_fns={\n            \"gene\": lambda variant, _: \";\".join(variant.gene_names),\n        })\n    for variant, reference_contexts in reference_contexts_for_variants(\n            variants=variants,\n            context_size=context_size,\n            transcript_id_whitelist=transcript_id_whitelist).items():\n        df_builder.add_many(variant, reference_contexts)\n    return df_builder.to_dataframe()", "label": 1}
{"code": "public function setItem($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\ContentItem::class);\n        $this->item = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def __put_key(self, local_file, target_file, acl='public-read', del_after_upload=False, overwrite=True, source=\"filename\"):\n        \"\"\"Copy a file to s3.\"\"\"\n        action_word = \"moving\" if del_after_upload else \"copying\"\n\n        try:\n            self.k.key = target_file  # setting the path (key) of file in the container\n\n            if source == \"filename\":\n                # grabs the contents from local_file address. Note that it loads the whole file into memory\n                self.k.set_contents_from_filename(local_file, self.AWS_HEADERS)\n            elif source == \"fileobj\":\n                self.k.set_contents_from_file(local_file, self.AWS_HEADERS)\n            elif source == \"string\":\n                self.k.set_contents_from_string(local_file, self.AWS_HEADERS)\n            else:\n                raise Exception(\"%s is not implemented as a source.\" % source)\n            self.k.set_acl(acl)  # setting the file permissions\n            self.k.close()  # not sure if it is needed. Somewhere I read it is recommended.\n\n            self.printv(\"%s %s to %s\" % (action_word, local_file, target_file))\n            # if it is supposed to delete the local file after uploading\n            if del_after_upload and source == \"filename\":\n                try:\n                    os.remove(local_file)\n                except:\n                    logger.error(\"Unable to delete the file: \", local_file, exc_info=True)\n\n            return True\n\n        except:\n            logger.error(\"Error in writing to %s\", target_file, exc_info=True)\n            return False", "label": 1}
{"code": "def new_request(sender, request=None, notify=True, **kwargs):\n    \"\"\"New request for inclusion.\"\"\"\n    if current_app.config['COMMUNITIES_MAIL_ENABLED'] and notify:\n        send_community_request_email(request)", "label": 1}
{"code": "public static nsacl6[] get(nitro_service service) throws Exception{\n\t\tnsacl6 obj = new nsacl6();\n\t\tnsacl6[] response = (nsacl6[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function verifyDataSources(formDataSourceIds, cb) {\n    findMatchingDocuments(models.MODELNAMES.DATA_SOURCE, formDataSourceIds, dataSourceModel, cb);\n  }", "label": 3}
{"code": "def get_random(self, size=10):\n        \"\"\"Returns random variates from the histogram.\n        Note this assumes the histogram is an 'events per bin', not a pdf.\n        Inside the bins, a uniform distribution is assumed.\n        \"\"\"\n        bin_i = np.random.choice(np.arange(len(self.bin_centers)), size=size, p=self.normalized_histogram)\n        return self.bin_centers[bin_i] + np.random.uniform(-0.5, 0.5, size=size) * self.bin_volumes()[bin_i]", "label": 1}
{"code": "def valid_for_country?(country)\n      country = country.to_s.upcase\n      tdata = analyze(sanitized, passed_country(country))\n      tdata.find do |iso2, data|\n        country == iso2 && data[:valid].any?\n      end.is_a? Array\n    end", "label": 4}
{"code": "func (g *GRPCServer) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\t// magic combo match signifying GRPC request\n\t// https://grpc.io/blog/coreos\n\tif r.ProtoMajor == 2 && strings.Contains(r.Header.Get(\"Content-Type\"), \"application/grpc\") {\n\t\tg.grpcHandler.ServeHTTP(w, r)\n\t} else {\n\t\tg.httpHandler.ServeHTTP(w, r)\n\t}\n}", "label": 5}
{"code": "def describe(committish=nil, opts={})\n      arr_opts = []\n\n      arr_opts << '--all' if opts[:all]\n      arr_opts << '--tags' if opts[:tags]\n      arr_opts << '--contains' if opts[:contains]\n      arr_opts << '--debug' if opts[:debug]\n      arr_opts << '--long' if opts[:long]\n      arr_opts << '--always' if opts[:always]\n      arr_opts << '--exact-match' if opts[:exact_match] || opts[:\"exact-match\"]\n\n      arr_opts << '--dirty' if opts['dirty'] == true\n      arr_opts << \"--dirty=#{opts['dirty']}\" if opts['dirty'].is_a?(String)\n\n      arr_opts << \"--abbrev=#{opts['abbrev']}\" if opts[:abbrev]\n      arr_opts << \"--candidates=#{opts['candidates']}\" if opts[:candidates]\n      arr_opts << \"--match=#{opts['match']}\" if opts[:match]\n\n      arr_opts << committish if committish\n\n      return command('describe', arr_opts)\n    end", "label": 4}
{"code": "public function toArray()\n    {\n        return [\n            'year' => $this->year,\n            'month' => $this->month,\n            'day' => $this->day,\n            'dayOfWeek' => $this->dayOfWeek,\n            'dayOfYear' => $this->dayOfYear,\n            'hour' => $this->hour,\n            'minute' => $this->minute,\n            'second' => $this->second,\n            'micro' => $this->micro,\n            'timestamp' => $this->timestamp,\n            'formatted' => $this->rawFormat(defined('static::DEFAULT_TO_STRING_FORMAT') ? static::DEFAULT_TO_STRING_FORMAT : CarbonInterface::DEFAULT_TO_STRING_FORMAT),\n            'timezone' => $this->timezone,\n        ];\n    }", "label": 2}
{"code": "public function setResourceProperties($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Protobuf\\Value::class);\n        $this->resource_properties = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private boolean setNextIterator()\r\n    {\r\n        boolean retval = false;\r\n        // first, check if the activeIterator is null, and set it.\r\n        if (m_activeIterator == null)\r\n        {\r\n            if (m_rsIterators.size() > 0)\r\n            {\r\n                m_activeIteratorIndex = 0;\r\n                m_currentCursorPosition = 0;\r\n                m_activeIterator = (OJBIterator) m_rsIterators.get(m_activeIteratorIndex);\r\n            }\r\n        }\r\n        else if (!m_activeIterator.hasNext())\r\n        {\r\n            if (m_rsIterators.size() > (m_activeIteratorIndex + 1))\r\n            {\r\n                // we still have iterators in the collection, move to the\r\n                // next one, increment the counter, and set the active\r\n                // iterator.\r\n                m_activeIteratorIndex++;\r\n                m_currentCursorPosition = 0;\r\n                m_activeIterator = (OJBIterator) m_rsIterators.get(m_activeIteratorIndex);\r\n                retval = true;\r\n            }\r\n        }\r\n\r\n        return retval;\r\n    }", "label": 0}
{"code": "public static crvserver_policymap_binding[] get(nitro_service service, String name) throws Exception{\n\t\tcrvserver_policymap_binding obj = new crvserver_policymap_binding();\n\t\tobj.set_name(name);\n\t\tcrvserver_policymap_binding response[] = (crvserver_policymap_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def match(uri, processor=nil)\n      uri = Addressable::URI.parse(uri)\n      mapping = {}\n\n      # First, we need to process the pattern, and extract the values.\n      expansions, expansion_regexp =\n        parse_template_pattern(pattern, processor)\n\n      return nil unless uri.to_str.match(expansion_regexp)\n      unparsed_values = uri.to_str.scan(expansion_regexp).flatten\n\n      if uri.to_str == pattern\n        return Addressable::Template::MatchData.new(uri, self, mapping)\n      elsif expansions.size > 0\n        index = 0\n        expansions.each do |expansion|\n          _, operator, varlist = *expansion.match(EXPRESSION)\n          varlist.split(',').each do |varspec|\n            _, name, modifier = *varspec.match(VARSPEC)\n            mapping[name] ||= nil\n            case operator\n            when nil, '+', '#', '/', '.'\n              unparsed_value = unparsed_values[index]\n              name = varspec[VARSPEC, 1]\n              value = unparsed_value\n              value = value.split(JOINERS[operator]) if value && modifier == '*'\n            when ';', '?', '&'\n              if modifier == '*'\n                if unparsed_values[index]\n                  value = unparsed_values[index].split(JOINERS[operator])\n                  value = value.inject({}) do |acc, v|\n                    key, val = v.split('=')\n                    val = \"\" if val.nil?\n                    acc[key] = val\n                    acc\n                  end\n                end\n              else\n                if (unparsed_values[index])\n                  name, value = unparsed_values[index].split('=')\n                  value = \"\" if value.nil?\n                end\n              end\n            end\n            if processor != nil && processor.respond_to?(:restore)\n              value = processor.restore(name, value)\n            end\n            if processor == nil\n              if value.is_a?(Hash)\n                value = value.inject({}){|acc, (k, v)|\n                  acc[Addressable::URI.unencode_component(k)] =\n                    Addressable::URI.unencode_component(v)\n                  acc\n                }\n              elsif value.is_a?(Array)\n                value = value.map{|v| Addressable::URI.unencode_component(v) }\n              else\n                value = Addressable::URI.unencode_component(value)\n              end\n            end\n            if !mapping.has_key?(name) || mapping[name].nil?\n              # Doesn't exist, set to value (even if value is nil)\n              mapping[name] = value\n            end\n            index = index + 1\n          end\n        end\n        return Addressable::Template::MatchData.new(uri, self, mapping)\n      else\n        return nil\n      end\n    end", "label": 4}
{"code": "protected function execute(InputInterface $input, OutputInterface $output)\n    {\n        if (PHP_VERSION_ID < 50600) {\n            throw new \\RuntimeException('This command is only available in PHP 5.6 and later.');\n        }\n\n        $execDir = $this->rootPath . '/' . self::EXEC_DIR;\n        $token = $this->githubToken($input->getOption('token'));\n\n        $shell = new RunShell;\n        $guzzle = $this->guzzleClient();\n        $github = $this->githubClient($output, $shell, $guzzle, $token);\n        $split = $this->splitWrapper($output, $shell);\n\n        @mkdir($execDir);\n\n        $splitBinaryPath = $this->splitshInstall($output, $shell, $execDir, $input->getOption('splitsh'));\n\n        $componentId = $input->getOption('component');\n        $components = $this->componentManager->componentsExtra($componentId);\n\n        // remove umbrella component.\n        $components = array_filter($components, function ($component, $key) {\n            return $key !== 'google-cloud';\n        }, ARRAY_FILTER_USE_BOTH);\n\n        $manifestPath = $this->rootPath . '/docs/manifest.json';\n\n        $parentTagSource = sprintf(self::PARENT_TAG_NAME, $input->getArgument('parent'));\n\n        $errors = [];\n        foreach ($components as $component) {\n            $res = $this->processComponent($output, $github, $split, $component, $splitBinaryPath, $parentTagSource);\n            if (!$res) {\n                $errors[] = $component['id'];\n            }\n\n            $output->writeln('');\n            $output->writeln('');\n        }\n\n        if ($errors) {\n            $output->writeln('<error>[ERROR]</error>: One or more components reported an error.');\n            $output->writeln('Please correct errors and try again.');\n            $output->writeln('Error component(s): ' . implode(', ', $errors));\n\n            return 1;\n        }\n\n        return 0;\n    }", "label": 2}
{"code": "def download_data():\n    \"\"\"\n    Downloads complete station dataset including catchment descriptors and amax records. And saves it into a cache\n    folder.\n    \"\"\"\n    with urlopen(_retrieve_download_url()) as f:\n        with open(os.path.join(CACHE_FOLDER, CACHE_ZIP), \"wb\") as local_file:\n            local_file.write(f.read())", "label": 1}
{"code": "def make_argparser():\n    \"\"\"\n    Setup argparse arguments.\n\n    :return: The parser which :class:`MypolrCli` expects parsed arguments from.\n    :rtype: argparse.ArgumentParser\n    \"\"\"\n    parser = argparse.ArgumentParser(prog='mypolr',\n                                     description=\"Interacts with the Polr Project's API.\\n\\n\"\n                                                 \"User Guide and documentation: https://mypolr.readthedocs.io\",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n                                     epilog=\"NOTE: if configurations are saved, they are stored as plain text on disk, \"\n                                            \"and can be read by anyone with access to the file.\")\n    parser.add_argument(\"-v\", \"--version\", action=\"store_true\", help=\"Print version and exit.\")\n\n    parser.add_argument(\"url\", nargs='?', default=None, help=\"The url to process.\")\n\n    api_group = parser.add_argument_group('API server arguments',\n                                          'Use these for configure the API. Can be stored locally with --save.')\n\n    api_group.add_argument(\"-s\", \"--server\", default=None, help=\"Server hosting the API.\")\n    api_group.add_argument(\"-k\", \"--key\", default=None, help=\"API_KEY to authenticate against server.\")\n    api_group.add_argument(\"--api-root\", default=DEFAULT_API_ROOT,\n                           help=\"API endpoint root.\")\n\n    option_group = parser.add_argument_group('Action options',\n                                             'Configure the API action to use.')\n\n    option_group.add_argument(\"-c\", \"--custom\", default=None,\n                              help=\"Custom short url ending.\")\n    option_group.add_argument(\"--secret\", action=\"store_true\",\n                              help=\"Set option if using secret url.\")\n    option_group.add_argument(\"-l\", \"--lookup\", action=\"store_true\",\n                              help=\"Perform lookup action instead of shorten action.\")\n\n    manage_group = parser.add_argument_group('Manage credentials',\n                                             'Use these to save, delete or update SERVER, KEY and/or '\n                                             'API_ROOT locally in ~/.mypolr/config.ini.')\n\n    manage_group.add_argument(\"--save\", action=\"store_true\",\n                              help=\"Save configuration (including credentials) in plaintext(!).\")\n    manage_group.add_argument(\"--clear\", action=\"store_true\",\n                              help=\"Clear configuration.\")\n    return parser", "label": 1}
{"code": "def json_dumps(inbox):\n    \"\"\"\n    Serializes the first element of the input using the JSON protocol as \n    implemented by the ``json`` Python 2.6 library.\n    \n    \"\"\"\n    gc.disable()\n    str_ = json.dumps(inbox[0])\n    gc.enable()\n    return str_", "label": 1}
{"code": "def as_python(self, name: str) -> str:\n        \"\"\" Return the python representation \"\"\"\n        if self._ruleTokens:\n            pattern = \"jsg.JSGPattern(r'{}'.format({}))\".\\\n                format(self._rulePattern, ', '.join(['{v}={v}.pattern'.format(v=v) for v in sorted(self._ruleTokens)]))\n        else:\n            pattern = \"jsg.JSGPattern(r'{}')\".format(self._rulePattern)\n        base_type = self._jsontype.signature_type() if self._jsontype else \"jsg.JSGString\"\n        return python_template.format(name=name, base_type=base_type, pattern=pattern)", "label": 1}
{"code": "def random_score(seed = Time.now, options = {})\n      scoring = options.merge(random_score: {seed: seed.to_i})\n      chain { criteria.update_scores scoring }\n    end", "label": 4}
{"code": "public function setImage($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_Image::class);\n        $this->image = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def handle_od_rm(tokens, options)\n      day = tokens[0].get_tag(OrdinalDay).type\n      month = tokens[2].get_tag(RepeaterMonth)\n      handle_m_d(month, day, tokens[3..tokens.size], options)\n    end", "label": 4}
{"code": "func SetPermitUserEnvironment(permitUserEnvironment bool) ServerOption {\n\treturn func(s *Server) error {\n\t\ts.permitUserEnvironment = permitUserEnvironment\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public int executeUpdateSQL(\r\n        String sqlStatement,\r\n        ClassDescriptor cld,\r\n        ValueContainer[] values1,\r\n        ValueContainer[] values2)\r\n        throws PersistenceBrokerException\r\n    {\r\n        if (logger.isDebugEnabled())\r\n            logger.debug(\"executeUpdateSQL: \" + sqlStatement);\r\n\r\n        int result;\r\n        int index;\r\n        PreparedStatement stmt = null;\r\n        final StatementManagerIF sm = broker.serviceStatementManager();\r\n        try\r\n        {\r\n            stmt = sm.getPreparedStatement(cld, sqlStatement,\r\n                    Query.NOT_SCROLLABLE, StatementManagerIF.FETCH_SIZE_NOT_APPLICABLE, isStoredProcedure(sqlStatement));\r\n            index = sm.bindValues(stmt, values1, 1);\r\n            sm.bindValues(stmt, values2, index);\r\n            result = stmt.executeUpdate();\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            logger.error(\"PersistenceBrokerException during the execution of the Update SQL query: \" + e.getMessage(), e);\r\n            throw e;\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            ValueContainer[] tmp = addValues(values1, values2);\r\n            throw ExceptionHelper.generateException(e, sqlStatement, cld, tmp, logger, null);\r\n        }\r\n        finally\r\n        {\r\n            sm.closeResources(stmt, null);\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "public function process(Request $request, Handler $handler): Response\n    {\n        $method = $request->getMethod();\n        $uri = $request->getUri()->getPath() ?: '/';\n\n        $routeInfo = $this->getDispatcher()->dispatch($method, $uri);\n\n        switch ($routeInfo[0]) {\n            case Dispatcher::NOT_FOUND:\n                throw new RouteNotFoundException($uri);\n            case Dispatcher::METHOD_NOT_ALLOWED:\n                throw new MethodNotAllowedException($method);\n            case Dispatcher::FOUND:\n                $handler = $routeInfo[1];\n                $parameters = $routeInfo[2];\n\n                return $handler($request, $parameters);\n        }\n    }", "label": 2}
{"code": "func (f *removeOnClose) Close() error {\n\tif f == nil || f.File == nil {\n\t\treturn nil\n\t}\n\tname := f.File.Name()\n\tif err := f.File.Close(); err != nil {\n\t\treturn err\n\t}\n\tif err := os.Remove(name); err != nil && !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\treturn nil\n}", "label": 5}
{"code": "private function arrayMergeRecursive(array $array1, array $array2)\n    {\n        foreach ($array2 as $key => $value) {\n            if (array_key_exists($key, $array1) && is_array($array1[$key]) && is_array($value)) {\n                $array1[$key] = ($this->isAssoc($array1[$key]) && $this->isAssoc($value))\n                    ? $this->arrayMergeRecursive($array1[$key], $value)\n                    : array_merge($array1[$key], $value);\n            } else {\n                $array1[$key] = $value;\n            }\n        }\n\n        return $array1;\n    }", "label": 2}
{"code": "def to_xml_string(str = \"\")\n      return if empty?\n      str << \"<dataValidations count='#{size}'>\"\n      each { |item| item.to_xml_string(str) }\n      str << '</dataValidations>'\n    end", "label": 4}
{"code": "def h5(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'h5_for', &block)\n      define_method(name) do\n        return platform.h5_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "def all_loaded_constants\n      constants\n        .map { |c| const_get(c) }\n        .select { |a| a.respond_to?(:loaded?) && a.loaded? }\n    end", "label": 4}
{"code": "func (c *Client) Protocol() Protocol {\n\t_, err := c.Start()\n\tif err != nil {\n\t\treturn ProtocolInvalid\n\t}\n\n\treturn c.protocol\n}", "label": 5}
{"code": "def pickle_matpower_cases(case_paths, case_format=2):\n    \"\"\" Parses the MATPOWER case files at the given paths and pickles the\n        resulting Case objects to the same directory.\n    \"\"\"\n    import pylon.io\n\n    if isinstance(case_paths, basestring):\n        case_paths = [case_paths]\n\n    for case_path in case_paths:\n        # Read the MATPOWER case file.\n        case = pylon.io.MATPOWERReader(case_format).read(case_path)\n\n        # Give the new file the same name, but with a different extension.\n        dir_path = os.path.dirname(case_path)\n        case_basename = os.path.basename(case_path)\n        root, _ = os.path.splitext(case_basename)\n        pickled_case_path = os.path.join(dir_path, root + '.pkl')\n\n        # Pickle the resulting Pylon Case object.\n        pylon.io.PickleWriter(case).write(pickled_case_path)", "label": 1}
{"code": "def run(self):\n        \"\"\"Reads data from CNPJ list and write results to output directory.\"\"\"\n        self._assure_output_dir(self.output)\n        companies = self.read()\n        print '%s CNPJs found' % len(companies)\n\n        pbar = ProgressBar(\n            widgets=[Counter(), ' ', Percentage(), ' ', Bar(), ' ', Timer()],\n            maxval=len(companies)).start()\n\n        resolved = 0\n        runner = Runner(companies, self.days, self.token)\n\n        try:\n            for data in runner:\n                self.write(data)\n                resolved = resolved + 1\n                pbar.update(resolved)\n        except KeyboardInterrupt:\n            print '\\naborted: waiting current requests to finish.'\n            runner.stop()\n            return\n\n        pbar.finish()", "label": 1}
{"code": "def create_iap!(app_id: nil, type: nil, versions: nil, reference_name: nil, product_id: nil, cleared_for_sale: true, review_notes: nil, review_screenshot: nil, pricing_intervals: nil, family_id: nil, subscription_duration: nil, subscription_free_trial: nil)\n      # Load IAP Template based on Type\n      type ||= \"consumable\"\n      r = request(:get, \"ra/apps/#{app_id}/iaps/#{type}/template\")\n      data = parse_response(r, 'data')\n\n      # Now fill in the values we have\n      # some values are nil, that's why there is a hash\n      data['familyId'] = family_id.to_s if family_id\n      data['productId'] = { value: product_id }\n      data['referenceName'] = { value: reference_name }\n      data['clearedForSale'] = { value: cleared_for_sale }\n\n      data['pricingDurationType'] = { value: subscription_duration } if subscription_duration\n      data['freeTrialDurationType'] = { value: subscription_free_trial } if subscription_free_trial\n\n      # pricing tier\n      if pricing_intervals\n        data['pricingIntervals'] = []\n        pricing_intervals.each do |interval|\n          data['pricingIntervals'] << {\n              value: {\n                  country: interval[:country] || \"WW\",\n                  tierStem: interval[:tier].to_s,\n                  priceTierEndDate: interval[:end_date],\n                  priceTierEffectiveDate: interval[:begin_date]\n                }\n          }\n        end\n      end\n\n      versions_array = []\n      versions.each do |k, v|\n        versions_array << {\n                  value: {\n                    description: { value: v[:description] },\n                    name: { value: v[:name] },\n                    localeCode: k.to_s\n                  }\n        }\n      end\n      data[\"versions\"][0][\"details\"][\"value\"] = versions_array\n      data['versions'][0][\"reviewNotes\"] = { value: review_notes }\n\n      if review_screenshot\n        # Upload Screenshot:\n        upload_file = UploadFile.from_path(review_screenshot)\n        screenshot_data = upload_purchase_review_screenshot(app_id, upload_file)\n        data[\"versions\"][0][\"reviewScreenshot\"] = screenshot_data\n      end\n\n      # Now send back the modified hash\n      r = request(:post) do |req|\n        req.url(\"ra/apps/#{app_id}/iaps\")\n        req.body = data.to_json\n        req.headers['Content-Type'] = 'application/json'\n      end\n      handle_itc_response(r.body)\n    end", "label": 4}
{"code": "def override_secure(env, config = {})\n      if scheme(env) != \"https\" && config != OPT_OUT\n        config[:secure] = OPT_OUT\n      end\n\n      config\n    end", "label": 4}
{"code": "func (h *Heartbeat) Run() error {\n\tdefer func() {\n\t\th.reset(HeartbeatStateInit)\n\t\th.checkTicker.Stop()\n\t}()\n\tfor {\n\t\tif err := h.fetchAndAnnounce(); err != nil {\n\t\t\th.Warningf(\"Heartbeat failed %v.\", err)\n\t\t}\n\t\tselect {\n\t\tcase <-h.checkTicker.C:\n\t\tcase <-h.sendC:\n\t\t\th.Debugf(\"Asked check out of cycle\")\n\t\tcase <-h.cancelCtx.Done():\n\t\t\th.Debugf(\"Heartbeat exited.\")\n\t\t\treturn nil\n\t\t}\n\t}\n}", "label": 5}
{"code": "public static nspbr6 get(nitro_service service, String name) throws Exception{\n\t\tnspbr6 obj = new nspbr6();\n\t\tobj.set_name(name);\n\t\tnspbr6 response = (nspbr6) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "protected function validateRedirectUri(\n        string $redirectUri,\n        ClientEntityInterface $client,\n        ServerRequestInterface $request\n    ) {\n        if (\\is_string($client->getRedirectUri())\n            && (strcmp($client->getRedirectUri(), $redirectUri) !== 0)\n        ) {\n            $this->getEmitter()->emit(new RequestEvent(RequestEvent::CLIENT_AUTHENTICATION_FAILED, $request));\n            throw OAuthServerException::invalidClient();\n        } elseif (\\is_array($client->getRedirectUri())\n            && \\in_array($redirectUri, $client->getRedirectUri(), true) === false\n        ) {\n            $this->getEmitter()->emit(new RequestEvent(RequestEvent::CLIENT_AUTHENTICATION_FAILED, $request));\n            throw OAuthServerException::invalidClient();\n        }\n    }", "label": 2}
{"code": "func (t *Torrent) Metainfo() metainfo.MetaInfo {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\treturn t.newMetaInfo()\n}", "label": 5}
{"code": "function parseChildInputpaths(build) {\n  function parse(build) {\n    let inputpaths = [];\n\n    build.forEach(build => {\n      inputpaths = inputpaths.concat(build.inputpaths, build.builds ? parse(build.builds) : []);\n    });\n\n    return inputpaths;\n  }\n\n  build.childInputpaths = parse(build.builds);\n}", "label": 3}
{"code": "public static dnsview_binding get(nitro_service service, String viewname) throws Exception{\n\t\tdnsview_binding obj = new dnsview_binding();\n\t\tobj.set_viewname(viewname);\n\t\tdnsview_binding response = (dnsview_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func tryParseMetricValue(aggName string, rawVal []interface{}, targetValue *core.MetricValue, fieldIndex int, wasInt map[string]bool) error {\n\t// the Influx client decodes numeric fields to json.Number (a string), so we have to deal with that --\n\t// assume, starting off, that values may be either float or int.  Try int until we fail once, and always\n\t// try float.  At the end, figure out which is which.\n\n\tvar rv string\n\tif rvN, ok := rawVal[fieldIndex].(json.Number); !ok {\n\t\treturn fmt.Errorf(\"Value %q of metric %q was not a json.Number\", rawVal[fieldIndex], aggName)\n\t} else {\n\t\trv = rvN.String()\n\t}\n\n\ttryInt := false\n\tisInt, triedBefore := wasInt[aggName]\n\ttryInt = isInt || !triedBefore\n\n\tif tryInt {\n\t\tif err := json.Unmarshal([]byte(rv), &targetValue.IntValue); err != nil {\n\t\t\twasInt[aggName] = false\n\t\t} else {\n\t\t\twasInt[aggName] = true\n\t\t}\n\t}\n\n\tif err := json.Unmarshal([]byte(rv), &targetValue.FloatValue); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def init_contents\n      self[:Contents] = self[:Contents][:referenced_object][:indirect_without_dictionary] if self[:Contents].is_a?(Hash) && self[:Contents][:referenced_object] && self[:Contents][:referenced_object].is_a?(Hash) && self[:Contents][:referenced_object][:indirect_without_dictionary]\n      self[:Contents] = [self[:Contents]] unless self[:Contents].is_a?(Array)\n      self[:Contents].delete(is_reference_only: true, referenced_object: { indirect_reference_id: 0, raw_stream_content: '' })\n      # un-nest any referenced arrays\n      self[:Contents].map! { |s| actual_value(s).is_a?(Array) ? actual_value(s) : s }\n      self[:Contents].flatten!\n      self[:Contents].compact!\n      # wrap content streams\n      insert_content 'q', 0\n      insert_content 'Q'\n\n      # Prep content\n      @contents = ''\n      insert_content @contents\n      @contents\n    end", "label": 4}
{"code": "def connect_inputs(self, datas):\n        \"\"\"\n        Connects input ``Pipers`` to \"datas\" input data  in the correct order \n        determined, by the ``Piper.ornament`` attribute and the ``Dagger._cmp`` \n        function.\n\n        It is assumed that the input data is in the form of an iterator and\n        that all inputs have the same number of input items. A pipeline will\n        **deadlock** otherwise. \n        \n        Arguments:\n        \n          - datas (sequence of sequences) An ordered sequence of inputs for \n            all input ``Pipers``.\n        \n        \"\"\"\n        start_pipers = self.get_inputs()\n        self.log.debug('%s trying to connect inputs in the order %s' % \\\n                      (repr(self), repr(start_pipers)))\n        for piper, data in izip(start_pipers, datas):\n            piper.connect([data])\n        self.log.debug('%s succesfuly connected inputs' % repr(self))", "label": 1}
{"code": "function (driver, response, remote, options, deferred) {\n      // log response data\n      this.events.emit('driver:webdriver:response', {\n        statusCode: response.statusCode,\n        method: response.req.method,\n        path: response.req.path,\n        data: this.data\n      });\n      \n      if (remote.onResponse) {\n        remote.onResponse.call(this, response, remote, options, deferred, this.data);\n      } else {\n        deferred.resolve(this.data);\n      }\n      return this;\n    }", "label": 3}
{"code": "public static iptunnelparam get(nitro_service service) throws Exception{\n\t\tiptunnelparam obj = new iptunnelparam();\n\t\tiptunnelparam[] response = (iptunnelparam[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public function add_deferred_commands() {\n\t\t$deferred_additions = \\WP_CLI::get_deferred_additions();\n\n\t\tforeach ( $deferred_additions as $name => $addition ) {\n\t\t\t\\WP_CLI::debug(\n\t\t\t\tsprintf(\n\t\t\t\t\t'Adding deferred command: %s => %s',\n\t\t\t\t\t$name,\n\t\t\t\t\tjson_encode( $addition )\n\t\t\t\t),\n\t\t\t\t'bootstrap'\n\t\t\t);\n\n\t\t\t\\WP_CLI::add_command(\n\t\t\t\t$name,\n\t\t\t\t$addition['callable'],\n\t\t\t\t$addition['args']\n\t\t\t);\n\t\t}\n\t}", "label": 2}
{"code": "func (s *Server) RegisterHandler(ctx interface{}, hdlrs map[string]HTTPHandlerFunc) {\n\ts.Lock()\n\tdefer s.Unlock()\n\tfor path, fun := range hdlrs {\n\t\tif _, ok := s.registeredHanders[path]; ok {\n\t\t\tcontinue\n\t\t}\n\t\ts.mux.Handle(path, httpHandlerCustom{ctx, fun})\n\t\ts.registeredHanders[path] = true\n\t}\n}", "label": 5}
{"code": "def email_report(job, univ_options):\n    \"\"\"\n    Send an email to the user when the run finishes.\n\n    :param dict univ_options: Dict of universal options used by almost all tools\n    \"\"\"\n    fromadd = \"results@protect.cgl.genomics.ucsc.edu\"\n    msg = MIMEMultipart()\n    msg['From'] = fromadd\n    if  univ_options['mail_to'] is None:\n        return\n    else:\n        msg['To'] = univ_options['mail_to']\n    msg['Subject'] = \"Protect run for sample %s completed successfully.\" % univ_options['patient']\n    body = \"Protect run for sample %s completed successfully.\" % univ_options['patient']\n    msg.attach(MIMEText(body, 'plain'))\n    text = msg.as_string()\n\n    try:\n        server = smtplib.SMTP('localhost')\n    except socket.error as e:\n        if e.errno == 111:\n            print('No mail utils on this maachine')\n        else:\n            print('Unexpected error while attempting to send an email.')\n        print('Could not send email report')\n    except:\n        print('Could not send email report')\n    else:\n        server.sendmail(fromadd, msg['To'], text)\n        server.quit()", "label": 1}
{"code": "def following?(*args)\n      arguments(args, required: [:username])\n      params = arguments.params\n      if target_user = params.delete('target_user')\n        get_request(\"/users/#{arguments.username}/following/#{target_user}\", params)\n      else\n        get_request(\"/user/following/#{arguments.username}\", params)\n      end\n      true\n    rescue Github::Error::NotFound\n      false\n    end", "label": 4}
{"code": "func (s *AuthServer) ChangePassword(req services.ChangePasswordReq) error {\n\t// validate new password\n\terr := services.VerifyPassword(req.NewPassword)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tauthPreference, err := s.GetAuthPreference()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tuserID := req.User\n\tfn := func() error {\n\t\tsecondFactor := authPreference.GetSecondFactor()\n\t\tswitch secondFactor {\n\t\tcase teleport.OFF:\n\t\t\treturn s.CheckPasswordWOToken(userID, req.OldPassword)\n\t\tcase teleport.OTP:\n\t\t\treturn s.CheckPassword(userID, req.OldPassword, req.SecondFactorToken)\n\t\tcase teleport.U2F:\n\t\t\tif req.U2FSignResponse == nil {\n\t\t\t\treturn trace.BadParameter(\"missing U2F sign response\")\n\t\t\t}\n\n\t\t\treturn s.CheckU2FSignResponse(userID, req.U2FSignResponse)\n\t\t}\n\n\t\treturn trace.BadParameter(\"unsupported second factor method: %q\", secondFactor)\n\t}\n\n\terr = s.WithUserLock(userID, fn)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn trace.Wrap(s.UpsertPassword(userID, req.NewPassword))\n}", "label": 5}
{"code": "public static vrid_nsip6_binding[] get(nitro_service service, Long id) throws Exception{\n\t\tvrid_nsip6_binding obj = new vrid_nsip6_binding();\n\t\tobj.set_id(id);\n\t\tvrid_nsip6_binding response[] = (vrid_nsip6_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def delete_entity(resource_name, name, namespace = nil, delete_options: {})\n      delete_options_hash = delete_options.to_hash\n      ns_prefix = build_namespace_prefix(namespace)\n      payload = delete_options_hash.to_json unless delete_options_hash.empty?\n      response = handle_exception do\n        rs = rest_client[ns_prefix + resource_name + \"/#{name}\"]\n        RestClient::Request.execute(\n          rs.options.merge(\n            method: :delete,\n            url: rs.url,\n            headers: { 'Content-Type' => 'application/json' }.merge(@headers),\n            payload: payload\n          )\n        )\n      end\n      format_response(@as, response.body)\n    end", "label": 4}
{"code": "def id_nameDAVID(df,GTF=None,name_id=None):\n    \"\"\"\n    Given a DAVIDenrich output it converts ensembl gene ids to genes names and adds this column to the output\n\n    :param df: a dataframe output from DAVIDenrich\n    :param GTF: a GTF dataframe from readGTF()\n    :param name_id: instead of a gtf dataframe a dataframe with the columns 'gene_name' and 'gene_id' can be given as input\n\n    :returns: a pandas dataframe with a gene name column added to it.\n    \"\"\"\n    if name_id is None:\n        gene_name=retrieve_GTF_field('gene_name',GTF)\n        gene_id=retrieve_GTF_field('gene_id', GTF)\n        GTF=pd.concat([gene_name,gene_id],axis=1)\n    else:\n        GTF=name_id.copy()\n    df['Gene_names']=\"genes\"\n    terms=df['termName'].tolist()\n    enrichN=pd.DataFrame()\n    for term in terms:\n        tmp=df[df['termName']==term]\n        tmp=tmp.reset_index(drop=True)\n        ids=tmp.xs(0)['geneIds']\n        ids=pd.DataFrame(data=ids.split(\", \"))\n        ids.columns=['geneIds']\n        ids['geneIds']=ids['geneIds'].map(str.lower)\n        GTF['gene_id']=GTF['gene_id'].astype(str)\n        GTF['gene_id']=GTF['gene_id'].map(str.lower)\n        ids=pd.merge(ids, GTF, how='left', left_on='geneIds', right_on='gene_id')\n        names=ids['gene_name'].tolist()\n        names= ', '.join(names)\n        tmp[\"Gene_names\"]=names\n        #tmp=tmp.replace(to_replace=tmp.xs(0)['Gene_names'], value=names)\n        enrichN=pd.concat([enrichN, tmp])\n    enrichN=enrichN.reset_index(drop=True)\n\n    gene_names=enrichN[['Gene_names']]\n    gpos=enrichN.columns.get_loc(\"geneIds\")\n    enrichN=enrichN.drop(['Gene_names'],axis=1)\n    cols=enrichN.columns.tolist()\n    enrichN=pd.concat([enrichN[cols[:gpos+1]],gene_names,enrichN[cols[gpos+1:]]],axis=1)\n\n    return enrichN", "label": 1}
{"code": "def fetch(self, recursive=1, fields=None, detail=None,\n              filters=None, parent_uuid=None, back_refs_uuid=None):\n        \"\"\"\n        Fetch collection from API server\n\n        :param recursive: level of recursion\n        :type recursive: int\n        :param fields: fetch only listed fields.\n                       contrail 3.0 required\n        :type fields: [str]\n        :param detail: fetch all fields\n        :type detail: bool\n        :param filters: list of filters\n        :type filters: [(name, value), ...]\n        :param parent_uuid: filter by parent_uuid\n        :type parent_uuid: v4UUID str or list of v4UUID str\n        :param back_refs_uuid: filter by back_refs_uuid\n        :type back_refs_uuid: v4UUID str or list of v4UUID str\n\n        :rtype: Collection\n        \"\"\"\n\n        params = self._format_fetch_params(fields=fields, detail=detail, filters=filters,\n                                           parent_uuid=parent_uuid, back_refs_uuid=back_refs_uuid)\n        data = self.session.get_json(self.href, **params)\n\n        if not self.type:\n            self.data = [Collection(col[\"link\"][\"name\"],\n                                    fetch=recursive - 1 > 0,\n                                    recursive=recursive - 1,\n                                    fields=self._fetch_fields(fields),\n                                    detail=detail or self.detail,\n                                    filters=self._fetch_filters(filters),\n                                    parent_uuid=self._fetch_parent_uuid(parent_uuid),\n                                    back_refs_uuid=self._fetch_back_refs_uuid(back_refs_uuid))\n                         for col in data['links']\n                         if col[\"link\"][\"rel\"] == \"collection\"]\n        else:\n            # when detail=False, res == {resource_attrs}\n            # when detail=True, res == {'type': {resource_attrs}}\n            self.data = [Resource(self.type,\n                                  fetch=recursive - 1 > 0,\n                                  recursive=recursive - 1,\n                                  **res.get(self.type, res))\n                         for res_type, res_list in data.items()\n                         for res in res_list]\n\n        return self", "label": 1}
{"code": "function(e, s)\n                {\n                    var parens = [];\n                    e.tree.push(parens);\n                    parens.parent = e.tree;\n                    e.tree = parens;\n                }", "label": 3}
{"code": "def options\n      hash = {}\n      hash[:p] = ENV[\"FASTLANE_PATH\"] if ENV[\"FASTLANE_PATH\"]\n      hash[:P] = ENV[\"FASTLANE_PORT\"] if ENV[\"FASTLANE_PORT\"]\n      hash[:r] = ENV[\"FASTLANE_PROTOCOL\"] if ENV[\"FASTLANE_PROTOCOL\"]\n      hash.empty? ? nil : hash\n    end", "label": 4}
{"code": "func (this *summaryMetricsSource) decodeSummary(summary *stats.Summary) map[string]*MetricSet {\n\tglog.V(9).Infof(\"Begin summary decode\")\n\tresult := map[string]*MetricSet{}\n\n\tlabels := map[string]string{\n\t\tLabelNodename.Key: this.node.NodeName,\n\t\tLabelHostname.Key: this.node.HostName,\n\t\tLabelHostID.Key:   this.node.HostID,\n\t}\n\n\tthis.decodeNodeStats(result, labels, &summary.Node)\n\tfor _, pod := range summary.Pods {\n\t\tthis.decodePodStats(result, labels, &pod)\n\t}\n\n\tglog.V(9).Infof(\"End summary decode\")\n\treturn result\n}", "label": 5}
{"code": "private function set($field, $args)\n    {\n        $this->initializeDoctrine();\n\n        $property = $this->cm->getProperty($field);\n\n        if (! $property) {\n            throw new BadMethodCallException(\"no field with name '\" . $field . \"' exists on '\" . $this->cm->getClassName() . \"'\");\n        }\n\n        switch (true) {\n            case $property instanceof FieldMetadata && ! $property->isPrimaryKey():\n                $this->{$field} = $args[0];\n                break;\n\n            case $property instanceof ToOneAssociationMetadata:\n                $targetClassName = $property->getTargetEntity();\n\n                if ($args[0] !== null && ! ($args[0] instanceof $targetClassName)) {\n                    throw new InvalidArgumentException(\"Expected persistent object of type '\" . $targetClassName . \"'\");\n                }\n\n                $this->{$field} = $args[0];\n                $this->completeOwningSide($property, $args[0]);\n                break;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "public function createNotification($topic, array $options = [])\n    {\n        $res = $this->connection->insertNotification($options + $this->identity + [\n            'topic' => $this->getFormattedTopic($topic),\n            'payload_format' => 'JSON_API_V1'\n        ]);\n\n        return new Notification(\n            $this->connection,\n            $res['id'],\n            $this->identity['bucket'],\n            $res + [\n                'requesterProjectId' => $this->identity['userProject']\n            ]\n        );\n    }", "label": 2}
{"code": "private double Noise(int x, int y) {\n        int n = x + y * 57;\n        n = (n << 13) ^ n;\n\n        return (1.0 - ((n * (n * n * 15731 + 789221) + 1376312589) & 0x7fffffff) / 1073741824.0);\n    }", "label": 0}
{"code": "func RemoveEmptyLines(str string) []string {\n\tlines := make([]string, 0)\n\n\tfor _, v := range strings.Split(str, \"\\n\") {\n\t\tif len(v) > 0 {\n\t\t\tlines = append(lines, v)\n\t\t}\n\t}\n\n\treturn lines\n}", "label": 5}
{"code": "function (memberValue, visibility) {\n        _gpfAsserts({\n            \"Constructor must be a function\": \"function\" === typeof memberValue,\n            \"Own constructor can't be overridden\": null === this._definitionConstructor\n        });\n        if (_gpfUsesSuper(memberValue)) {\n            memberValue = _gpfGenSuperMember(this._Super, memberValue);\n        }\n        _gpfIgnore(visibility); // TODO Handle constructor visibility\n        this._definitionConstructor = memberValue;\n    }", "label": 3}
{"code": "def _rest(url, req, data=None):\n    \"\"\"Send a rest rest request to the server.\"\"\"\n    if url.upper().startswith(\"HTTPS\"):\n        print(\"Secure connection required: Please use HTTPS or https\")\n        return \"\"\n\n    req = req.upper()\n    if req != \"GET\" and req != \"PUT\" and req != \"POST\" and req != \"DELETE\":\n        return \"\"\n\n    status, body = _api_action(url, req, data)\n    if (int(status) >= 200 and int(status) <= 226):\n        return body\n    else:\n        return body", "label": 1}
{"code": "public static base_response update(nitro_service client, protocolhttpband resource) throws Exception {\n\t\tprotocolhttpband updateresource = new protocolhttpband();\n\t\tupdateresource.reqbandsize = resource.reqbandsize;\n\t\tupdateresource.respbandsize = resource.respbandsize;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public void resetResendCount() {\n\t\tthis.resendCount = 0;\n\t\tif (this.initializationComplete)\n\t\t\tthis.nodeStage = NodeStage.NODEBUILDINFO_DONE;\n\t\tthis.lastUpdated = Calendar.getInstance().getTime();\n\t}", "label": 0}
{"code": "func Value(label string) (value string) {\n\tif kv := strings.SplitN(label, \"=\", 2); len(kv) > 1 {\n\t\tvalue = kv[1]\n\t}\n\treturn\n}", "label": 5}
{"code": "public static vpnvserver_cachepolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_cachepolicy_binding obj = new vpnvserver_cachepolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_cachepolicy_binding response[] = (vpnvserver_cachepolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public NamedStyleInfo getNamedStyleInfo(String name) {\n\t\tfor (NamedStyleInfo info : namedStyleInfos) {\n\t\t\tif (info.getName().equals(name)) {\n\t\t\t\treturn info;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def get(*args)\n      arguments(args, required: [:id])\n\n      if (sha = arguments.params.delete('sha'))\n        get_request(\"/gists/#{arguments.id}/#{sha}\")\n      else\n        get_request(\"/gists/#{arguments.id}\", arguments.params)\n      end\n    end", "label": 4}
{"code": "def _runOPF(self):\n        \"\"\" Computes dispatch points and LMPs using OPF.\n        \"\"\"\n        if self.decommit:\n            solver = UDOPF(self.case, dc=(self.locationalAdjustment == \"dc\"))\n        elif self.locationalAdjustment == \"dc\":\n            solver = OPF(self.case, dc=True)\n        else:\n            solver = OPF(self.case, dc=False, opt={\"verbose\": True})\n\n        self._solution = solver.solve()\n\n#        for ob in self.offers + self.bids:\n#            ob.f = solution[\"f\"]\n\n        return self._solution[\"converged\"]", "label": 1}
{"code": "def execute(query_str = nil, **kwargs)\n      if query_str\n        kwargs[:query] = query_str\n      end\n      # Some of the query context _should_ be passed to the multiplex, too\n      multiplex_context = if (ctx = kwargs[:context])\n        {\n          backtrace: ctx[:backtrace],\n          tracers: ctx[:tracers],\n        }\n      else\n        {}\n      end\n      # Since we're running one query, don't run a multiplex-level complexity analyzer\n      all_results = multiplex([kwargs], max_complexity: nil, context: multiplex_context)\n      all_results[0]\n    end", "label": 4}
{"code": "function _gpfHttpGenSend (methodName) {\n    return function (httpObj, data) {\n        if (data) {\n            httpObj[methodName](data);\n        } else {\n            httpObj[methodName]();\n        }\n    };\n}", "label": 3}
{"code": "def dfTObedtool(df):\n    \"\"\"\n    Transforms a pandas dataframe into a bedtool\n\n    :param df: Pandas dataframe\n\n    :returns: a bedtool\n    \"\"\"\n\n    df=df.astype(str)\n    df=df.drop_duplicates()\n    df=df.values.tolist()\n    df=[\"\\t\".join(s) for s in df ]\n    df=\"\\n\".join(df)\n    df=BedTool(df, from_string=True)\n    return df", "label": 1}
{"code": "private function validatePrecondition(array &$options)\n    {\n        $precondition = isset($options['precondition'])\n            ? $options['precondition']\n            : null;\n\n        if (!$precondition) {\n            return;\n        }\n\n        if (isset($precondition['exists'])) {\n            return $precondition;\n        }\n\n        if (isset($precondition['updateTime'])) {\n            if (!($precondition['updateTime'] instanceof Timestamp)) {\n                throw new \\InvalidArgumentException(\n                    'Precondition Update Time must be an instance of `Google\\\\Cloud\\\\Core\\\\Timestamp`'\n                );\n            }\n\n            return [\n                'updateTime' => $precondition['updateTime']->formatForApi()\n            ];\n        }\n\n        throw new \\InvalidArgumentException('Preconditions must provide either `exists` or `updateTime`.');\n    }", "label": 2}
{"code": "def remote_exception(exc, tb):\n    \"\"\" Metaclass that wraps exception type in RemoteException \"\"\"\n    if type(exc) in exceptions:\n        typ = exceptions[type(exc)]\n        return typ(exc, tb)\n    else:\n        try:\n            typ = type(exc.__class__.__name__,\n                       (RemoteException, type(exc)),\n                       {'exception_type': type(exc)})\n            exceptions[type(exc)] = typ\n            return typ(exc, tb)\n        except TypeError:\n            return exc", "label": 1}
{"code": "func (c *Client) GetToken(token string) (services.ProvisionToken, error) {\n\tout, err := c.Get(c.Endpoint(\"tokens\", token), url.Values{})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.UnmarshalProvisionToken(out.Bytes(), services.SkipValidation())\n}", "label": 5}
{"code": "function (parameters, argumentsToParse) {\n                var\n                    result = {},\n                    len,\n                    idx,\n                    argument,\n                    parameter,\n                    name,\n                    lastNonPrefixIdx = 0;\n                parameters = gpf.Parameter.create(parameters);\n                len = argumentsToParse.length;\n                for (idx = 0; idx < len; ++idx) {\n                    // Check if a prefix was used and find parameter\n                    argument = this.getPrefixValuePair(argumentsToParse[idx]);\n                    if (argument instanceof Array) {\n                        parameter = this.getOnPrefix(parameters, argument[0]);\n                        argument = argument[1];\n                    } else {\n                        parameter = this.getOnPrefix(parameters,\n                            lastNonPrefixIdx);\n                        lastNonPrefixIdx = parameters.indexOf(parameter) + 1;\n                    }\n                    // If no parameter corresponds, ignore\n                    if (!parameter) {\n                        // TODO maybe an error might be more appropriate\n                        continue;\n                    }\n                    // Sometimes, the prefix might be used without value\n                    if (undefined === argument) {\n                        if (\"boolean\" === parameter._type) {\n                            argument = !parameter._defaultValue;\n                        } else {\n                            // Nothing to do with it\n                            // TODO maybe an error might be more appropriate\n                            continue;\n                        }\n                    }\n                    // Convert the value to match the type\n                    // TODO change when type will be an object\n                    argument = gpf.value(argument, parameter._defaultValue,\n                        parameter._type);\n                    // Assign the corresponding member of the result object\n                    name = parameter._name;\n                    if (parameter._multiple) {\n                        if (undefined === result[name]) {\n                            result[name] = [];\n                        }\n                        result[name].push(argument);\n                        if (parameter._prefix === \"\") {\n                            --lastNonPrefixIdx;\n                        }\n\n                    } else {\n                        // The last one wins\n                        result[name] = argument;\n                    }\n                }\n                this._finalizeParse(parameters, result);\n                return result;\n            }", "label": 3}
{"code": "public function GetInstance(\\Google\\Cloud\\Spanner\\Admin\\Instance\\V1\\GetInstanceRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.spanner.admin.instance.v1.InstanceAdmin/GetInstance',\n        $argument,\n        ['\\Google\\Cloud\\Spanner\\Admin\\Instance\\V1\\Instance', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "def init!(plugins, repair=false)\n      if !@initial_specifications\n        @initial_specifications = Gem::Specification.find_all{true}\n      else\n        Gem::Specification.all = @initial_specifications\n        Gem::Specification.reset\n      end\n\n      # Add HashiCorp RubyGems source\n      if !Gem.sources.include?(HASHICORP_GEMSTORE)\n        current_sources = Gem.sources.sources.dup\n        Gem.sources.clear\n        Gem.sources << HASHICORP_GEMSTORE\n        current_sources.each do |src|\n          Gem.sources << src\n        end\n      end\n\n      # Generate dependencies for all registered plugins\n      plugin_deps = plugins.map do |name, info|\n        Gem::Dependency.new(name, info['installed_gem_version'].to_s.empty? ? '> 0' : info['installed_gem_version'])\n      end\n\n      @logger.debug(\"Current generated plugin dependency list: #{plugin_deps}\")\n\n      # Load dependencies into a request set for resolution\n      request_set = Gem::RequestSet.new(*plugin_deps)\n      # Never allow dependencies to be remotely satisfied during init\n      request_set.remote = false\n\n      repair_result = nil\n      begin\n        # Compose set for resolution\n        composed_set = generate_vagrant_set\n        # Resolve the request set to ensure proper activation order\n        solution = request_set.resolve(composed_set)\n      rescue Gem::UnsatisfiableDependencyError => failure\n        if repair\n          raise failure if @init_retried\n          @logger.debug(\"Resolution failed but attempting to repair. Failure: #{failure}\")\n          install(plugins)\n          @init_retried = true\n          retry\n        else\n          raise\n        end\n      end\n\n      # Activate the gems\n      activate_solution(solution)\n\n      full_vagrant_spec_list = @initial_specifications +\n        solution.map(&:full_spec)\n\n      if(defined?(::Bundler))\n        @logger.debug(\"Updating Bundler with full specification list\")\n        ::Bundler.rubygems.replace_entrypoints(full_vagrant_spec_list)\n      end\n\n      Gem.post_reset do\n        Gem::Specification.all = full_vagrant_spec_list\n      end\n\n      Gem::Specification.reset\n      nil\n    end", "label": 4}
{"code": "@Api\n\tpublic void setFeatureModel(FeatureModel featureModel) throws LayerException {\n\t\tthis.featureModel = featureModel;\n\t\tif (null != getLayerInfo()) {\n\t\t\tfeatureModel.setLayerInfo(getLayerInfo());\n\t\t}\n\t\tfilterService.registerFeatureModel(featureModel);\n\t}", "label": 0}
{"code": "public List<Module> getModules(final Map<String, String> filters) throws GrapesCommunicationException {\n        final Client client = getClient();\n        WebResource resource = client.resource(serverURL).path(RequestUtils.getAllModulesPath());\n        for(final Map.Entry<String,String> queryParam: filters.entrySet()){\n            resource = resource.queryParam(queryParam.getKey(), queryParam.getValue());\n        }\n\n        final ClientResponse response = resource.accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);\n\n        client.destroy();\n        if(ClientResponse.Status.OK.getStatusCode() != response.getStatus()){\n            final String message = \"Failed to get filtered modules.\";\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n\n        return response.getEntity(new GenericType<List<Module>>(){});\n    }", "label": 0}
{"code": "public function read($id)\n    {\n        try {\n            $key = $this->datastore->key(\n                $this->kind,\n                $id,\n                ['namespaceId' => $this->namespaceId]\n            );\n            $entity = $this->transaction->lookup($key);\n            if ($entity !== null && isset($entity['data'])) {\n                return $entity['data'];\n            }\n        } catch (Exception $e) {\n            trigger_error(\n                sprintf('Datastore lookup failed: %s', $e->getMessage()),\n                E_USER_WARNING\n            );\n        }\n        return '';\n    }", "label": 2}
{"code": "protected function applyFilterColumn($query, $columnName, $keyword, $boolean = 'and')\n    {\n        $query    = $this->getBaseQueryBuilder($query);\n        $callback = $this->columnDef['filter'][$columnName]['method'];\n\n        if ($this->query instanceof EloquentBuilder) {\n            $builder = $this->query->newModelInstance()->newQuery();\n        } else {\n            $builder = $this->query->newQuery();\n        }\n\n        $callback($builder, $keyword);\n\n        $query->addNestedWhereQuery($this->getBaseQueryBuilder($builder), $boolean);\n    }", "label": 2}
{"code": "protected function prepareCacheStore()\n    {\n        if ($this->retrieve('expires') != $this->throttle->getExpires()) {\n            $this->forget('requests');\n            $this->forget('expires');\n            $this->forget('reset');\n        }\n    }", "label": 2}
{"code": "public function setApplicationOutcomeNotesFilters($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\ApplicationOutcomeNotesFilter::class);\n        $this->application_outcome_notes_filters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def kms_encrypt(value, key, aws_config=None):\n    \"\"\"Encrypt and value with KMS key.\n\n    Args:\n        value (str): value to encrypt\n        key (str): key id or alias\n        aws_config (optional[dict]): aws credentials\n            dict of arguments passed into boto3 session\n            example:\n                aws_creds = {'aws_access_key_id': aws_access_key_id,\n                             'aws_secret_access_key': aws_secret_access_key,\n                             'region_name': 'us-east-1'}\n\n    Returns:\n        str: encrypted cipher text\n    \"\"\"\n    aws_config = aws_config or {}\n    aws = boto3.session.Session(**aws_config)\n    client = aws.client('kms')\n    enc_res = client.encrypt(KeyId=key,\n                             Plaintext=value)\n    return n(b64encode(enc_res['CiphertextBlob']))", "label": 1}
{"code": "func (h *Handle) FromByteArray(ba []byte) error {\n\tif ba == nil {\n\t\treturn errors.New(\"nil byte array\")\n\t}\n\n\tnh := &sequence{}\n\terr := nh.fromByteArray(ba[16:])\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to deserialize head: %s\", err.Error())\n\t}\n\n\th.Lock()\n\th.head = nh\n\th.bits = binary.BigEndian.Uint64(ba[0:8])\n\th.unselected = binary.BigEndian.Uint64(ba[8:16])\n\th.Unlock()\n\n\treturn nil\n}", "label": 5}
{"code": "public void pauseUpload() throws LocalOperationException {\n        if (state == State.UPLOADING) {\n            setState(State.PAUSED);\n            executor.hardStop();\n        } else {\n            throw new LocalOperationException(\"Attempt to pause upload while assembly is not uploading\");\n        }\n    }", "label": 0}
{"code": "public void clear() {\n\t\tfor (Bean bean : beans.values()) {\n\t\t\tif (null != bean.destructionCallback) {\n\t\t\t\tbean.destructionCallback.run();\n\t\t\t}\n\t\t}\n\t\tbeans.clear();\n\t}", "label": 0}
{"code": "public void translateRectangle(Rectangle rect, float dx, float dy) {\n\t\tfloat width = rect.getWidth();\n\t\tfloat height = rect.getHeight();\n\t\trect.setLeft(rect.getLeft() + dx);\n\t\trect.setBottom(rect.getBottom() + dy);\n\t\trect.setRight(rect.getLeft() + dx + width);\n\t\trect.setTop(rect.getBottom() + dy + height);\n\t}", "label": 0}
{"code": "public static nstimer_binding get(nitro_service service, String name) throws Exception{\n\t\tnstimer_binding obj = new nstimer_binding();\n\t\tobj.set_name(name);\n\t\tnstimer_binding response = (nstimer_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private void computeCosts() {\n    cost = Long.MAX_VALUE;\n    for (QueueItem item : queueSpans) {\n      cost = Math.min(cost, item.sequenceSpans.spans.cost());\n    }\n  }", "label": 0}
{"code": "def algolia_reindex(batch_size = AlgoliaSearch::IndexSettings::DEFAULT_BATCH_SIZE, synchronous = false)\n      return if algolia_without_auto_index_scope\n      algolia_configurations.each do |options, settings|\n        next if algolia_indexing_disabled?(options)\n        next if options[:slave] || options[:replica]\n\n        # fetch the master settings\n        master_index = algolia_ensure_init(options, settings)\n        master_settings = master_index.get_settings rescue {} # if master doesn't exist yet\n        master_settings.merge!(JSON.parse(settings.to_settings.to_json)) # convert symbols to strings\n\n        # remove the replicas of the temporary index\n        master_settings.delete :slaves\n        master_settings.delete 'slaves'\n        master_settings.delete :replicas\n        master_settings.delete 'replicas'\n\n        # init temporary index\n        index_name = algolia_index_name(options)\n        tmp_options = options.merge({ :index_name => \"#{index_name}.tmp\" })\n        tmp_options.delete(:per_environment) # already included in the temporary index_name\n        tmp_settings = settings.dup\n        tmp_index = algolia_ensure_init(tmp_options, tmp_settings, master_settings)\n\n        algolia_find_in_batches(batch_size) do |group|\n          if algolia_conditional_index?(tmp_options)\n            # select only indexable objects\n            group = group.select { |o| algolia_indexable?(o, tmp_options) }\n          end\n          objects = group.map { |o| tmp_settings.get_attributes(o).merge 'objectID' => algolia_object_id_of(o, tmp_options) }\n          tmp_index.save_objects(objects)\n        end\n\n        move_task = SafeIndex.move_index(tmp_index.name, index_name)\n        master_index.wait_task(move_task[\"taskID\"]) if synchronous || options[:synchronous]\n      end\n      nil\n    end", "label": 4}
{"code": "def print_file_details_as_csv(self, fname, col_headers):\r\n        \"\"\" saves as csv format \"\"\"\r\n        line = ''\r\n        qu = '\"'\r\n        d = ','\r\n        for fld in col_headers:\r\n            if fld == \"fullfilename\":\r\n                line = line + qu + fname + qu + d\r\n            if fld == \"name\":\r\n                line = line + qu + os.path.basename(fname) + qu + d\r\n            if fld == \"date\":\r\n                line = line + qu + self.GetDateAsString(fname) + qu + d\r\n            if fld == \"size\":\r\n                line = line + qu + self.get_size_as_string(fname) + qu + d\r\n            if fld == \"path\":\r\n                try:\r\n                    line = line + qu + os.path.dirname(fname) + qu + d\r\n                except IOError:\r\n                    line = line + qu + 'ERROR_PATH' + qu + d\r\n\r\n        return line", "label": 1}
{"code": "def buildIndex(ipFile, ndxFile, append='Y', silent='N', useShortFileName='Y'):\n    \"\"\"\n    this creates an index of a text file specifically for use in AIKIF\n    separates the ontology descriptions highest followed by values and lastly\n    a final pass to get all delimited word parts.\n    \"\"\"\n    if silent == 'N':\n        pass\n    if append == 'N':\n        try:\n            os.remove(ndxFile)\n        except Exception as ex:\n            print('file already deleted - ignore' + str(ex))\n            \n    delims = [',', chr(31), '\u001f', '$', '&', '\"', '%', '/', '\\\\', '.', ';', ':', '!', '?', '-', '_', ' ', '\\n', '*', '\\'', '(', ')', '[', ']', '{', '}']\n    # 1st pass - index the ontologies, including 2 depths up (later - TODO)\n    #buildIndex(ipFile, ndxFile, ' ', 1, 'Y')\n\n    # 2nd pass - use ALL delims to catch each word as part of hyphenated - eg AI Build py\n    totWords, totLines, uniqueWords = getWordList(ipFile, delims)\n    \n    AppendIndexDictionaryToFile(uniqueWords, ndxFile, ipFile, useShortFileName)\n    if silent == 'N':\n        print(format_op_row(ipFile, totLines, totWords, uniqueWords))\n   \n        show('uniqueWords', uniqueWords, 5)\n    DisplayIndexAsDictionary(uniqueWords)", "label": 1}
{"code": "def project_name(new_name = nil)\n      return @project_name if defined?(@project_name) && @project_name && new_name.nil?\n      @project_name = new_name if new_name.is_a?(String)\n      @project_name ||= File.basename(root.split(\"/\").last).capitalize.tr(\"_\", \" \")\n    end", "label": 4}
{"code": "def SAS_NG(self):\n    \"\"\"\n    Set-up for the ungridded superposition of analytical solutions \n    method for solving flexure\n    \"\"\"\n    if self.filename:\n      # Define the (scalar) elastic thickness\n      self.Te = self.configGet(\"float\", \"input\", \"ElasticThickness\")\n      # See if it wants to be run in lat/lon\n      # Could put under in 2D if-statement, but could imagine an eventual desire\n      # to change this and have 1D lat/lon profiles as well.\n      # So while the options will be under \"numerical2D\", this place here will \n      # remain held for an eventual future.\n      self.latlon = self.configGet(\"string\", \"numerical2D\", \"latlon\", optional=True)\n      self.PlanetaryRadius = self.configGet(\"float\", \"numerical2D\", \"PlanetaryRadius\", optional=True)\n      if self.dimension == 2:\n        from scipy.special import kei\n    # Parse out input q0 into variables of imoprtance for solution\n    if self.dimension == 1:\n      try:\n        # If these have already been set, e.g., by getters/setters, great!\n        self.x\n        self.q\n      except:\n        # Using [x, y, w] configuration file\n        if self.q0.shape[1] == 2:\n          self.x = self.q0[:,0]\n          self.q = self.q0[:,1]\n        else:\n          sys.exit(\"For 1D (ungridded) SAS_NG configuration file, need [x,w] array. Your dimensions are: \"+str(self.q0.shape))\n    else:\n      try:\n        # If these have already been set, e.g., by getters/setters, great!\n        self.x\n        self.u\n        self.q\n      except:\n        # Using [x, y, w] configuration file\n        if self.q0.shape[1] == 3:\n          self.x = self.q0[:,0]\n          self.y = self.q0[:,1]\n          self.q = self.q0[:,2]\n        else:\n          sys.exit(\"For 2D (ungridded) SAS_NG configuration file, need [x,y,w] array. Your dimensions are: \"+str(self.q0.shape))\n    # x, y are in absolute coordinates. Create a local grid reference to \n    # these. This local grid, which starts at (0,0), is defined just so that \n    # we have a way of running the model without defined real-world \n    # coordinates\n    self.x = self.x\n    if self.dimension == 2:\n      self.y = self.y\n    # Remove self.q0 to avoid issues with multiply-defined inputs\n    # q0 is the parsable input to either a qs grid or contains (x,(y),q)\n    del self.q0\n    \n    # Check if a seperate output set of x,y points has been defined\n    # otherwise, set those values to None\n    # First, try to load the arrays\n    try:\n      self.xw\n    except:\n      try:\n        self.xw = self.configGet('string', \"input\", \"xw\", optional=True)\n        if self.xw == '':\n          self.xw = None\n      except:\n        self.xw = None\n    # If strings, load arrays\n    if type(self.xw) == str:\n      self.xw = self.loadFile(self.xw)\n    if self.dimension == 2:\n      try:\n        # already set by setter?\n        self.yw\n      except:\n        try:\n          self.yw = self.configGet('string', \"input\", \"yw\", optional=True )\n          if self.yw == '':\n            self.yw = None\n        except:\n          self.yw = None\n      # At this point, can check if we have both None or both defined\n      if (self.xw is not None and self.yw is None) \\\n        or (self.xw is None and self.yw is not None):\n        sys.exit(\"SAS_NG output at specified points requires both xw and yw to be defined\")\n      # All right, now just finish defining\n      if type(self.yw) == str:\n        self.yw = self.loadFile(self.yw)\n      elif self.yw is None:\n        self.yw = self.y.copy()\n    if self.xw is None:\n      self.xw = self.x.copy()", "label": 1}
{"code": "public static <E> Collection<E> sampleWithReplacement(Collection<E> c, int n) {\r\n    return sampleWithReplacement(c, n, new Random());\r\n  }", "label": 0}
{"code": "public static int cudnnSoftmaxForward(\n        cudnnHandle handle, \n        int algo, \n        int mode, \n        Pointer alpha, \n        cudnnTensorDescriptor xDesc, \n        Pointer x, \n        Pointer beta, \n        cudnnTensorDescriptor yDesc, \n        Pointer y)\n    {\n        return checkResult(cudnnSoftmaxForwardNative(handle, algo, mode, alpha, xDesc, x, beta, yDesc, y));\n    }", "label": 0}
{"code": "def load_entry_point_system_roles(self, entry_point_group):\n        \"\"\"Load system roles from an entry point group.\n\n        :param entry_point_group: The entrypoint for extensions.\n        \"\"\"\n        for ep in pkg_resources.iter_entry_points(group=entry_point_group):\n            self.register_system_role(ep.load())", "label": 1}
{"code": "public function match($token)\n    {\n        $lookaheadType = $this->lexer->lookahead['type'];\n\n        // Short-circuit on first condition, usually types match\n        if ($lookaheadType === $token) {\n            $this->lexer->moveNext();\n\n            return;\n        }\n\n        // If parameter is not identifier (1-99) must be exact match\n        if ($token < Lexer::T_IDENTIFIER) {\n            $this->syntaxError($this->lexer->getLiteral($token));\n        }\n\n        // If parameter is keyword (200+) must be exact match\n        if ($token > Lexer::T_IDENTIFIER) {\n            $this->syntaxError($this->lexer->getLiteral($token));\n        }\n\n        // If parameter is T_IDENTIFIER, then matches T_IDENTIFIER (100) and keywords (200+)\n        if ($token === Lexer::T_IDENTIFIER && $lookaheadType < Lexer::T_IDENTIFIER) {\n            $this->syntaxError($this->lexer->getLiteral($token));\n        }\n\n        $this->lexer->moveNext();\n    }", "label": 2}
{"code": "function () {\n                var me = this, lines = me._consolidateLines();\n                me._buffer.length = 0;\n                me._pushBackLastLineIfNotEmpty(lines);\n                _gpfArrayForEach(lines, function (line) {\n                    me._appendToReadBuffer(line);\n                });\n            }", "label": 3}
{"code": "def c_raw_singleton src, options = {}\n      options = {\n        :singleton => true,\n      }.merge options\n      self.generate src, options\n    end", "label": 4}
{"code": "func NetworkOptionLBEndpoint(ip net.IP) NetworkOption {\n\treturn func(n *network) {\n\t\tn.loadBalancerIP = ip\n\t}\n}", "label": 5}
{"code": "public function runTransaction(callable $callable, array $options = [])\n    {\n        $options += [\n            'maxRetries' => self::MAX_RETRIES,\n            'begin' => [],\n            'commit' => [],\n            'rollback' => []\n        ];\n\n        $retryableErrors = [\n            AbortedException::class\n        ];\n\n        $delayFn = function () {\n            return [\n                'seconds' => 0,\n                'nanos' => 0\n            ];\n        };\n\n        $retryFn = function (\\Exception $e) use ($retryableErrors) {\n            return in_array(get_class($e), $retryableErrors);\n        };\n\n        // Track the Transaction ID outside the retry function.\n        // If the transaction is retried after an abort, the previous transaction\n        // must be provided to the subsequent `beginTransaction` rpc.\n        // It also provides a convenient indication to the user whether the\n        // transaction is retried or not.\n        $transactionId = null;\n\n        $retry = new Retry($options['maxRetries'], $delayFn, $retryFn);\n\n        return $retry->execute(function (\n            callable $callable,\n            array $options\n        ) use (&$transactionId) {\n            $database = $this->databaseName($this->projectId, $this->database);\n\n            $beginTransaction = $this->connection->beginTransaction(array_filter([\n                'database' => $database,\n                'retryTransaction' => $transactionId\n            ]) + $options['begin']);\n\n            $transactionId = $beginTransaction['transaction'];\n\n            $transaction = new Transaction(\n                $this->connection,\n                $this->valueMapper,\n                $database,\n                $transactionId\n            );\n\n            try {\n                $res = $callable($transaction);\n\n                if (!$transaction->writer()->isEmpty()) {\n                    $transaction->writer()->commit([\n                        'transaction' => $transactionId\n                    ] + $options['commit']);\n                } else {\n                    // trigger rollback if no writes exist.\n                    $transaction->writer()->rollback($options['rollback']);\n                }\n\n                return $res;\n            } catch (\\Exception $e) {\n                $transaction->writer()->rollback($options['rollback']);\n\n                throw $e;\n            }\n        }, [\n            $callable,\n            $options\n        ]);\n    }", "label": 2}
{"code": "def replace_all(text, replace_dict):\n    \"\"\"\n    Replace multiple strings in a text.\n\n\n    .. note::\n\n        Replacements are made successively, without any warranty on the order \\\n        in which they are made.\n\n    :param text: Text to replace in.\n    :param replace_dict: Dictionary mapping strings to replace with their \\\n            substitution.\n    :returns: Text after replacements.\n\n    >>> replace_all(\"foo bar foo thing\", {\"foo\": \"oof\", \"bar\": \"rab\"})\n    'oof rab oof thing'\n    \"\"\"\n    for i, j in replace_dict.items():\n        text = text.replace(i, j)\n    return text", "label": 1}
{"code": "function code_after(range, parent) {\n  // Look through all child nodes of parent...\n  var children = child_nodes(parent);\n  for (var i = 0; i < children.length; i++) {\n    if (less(range, children[i][\"range\"])) {\n      // If node is after our range, then that's it.  There could\n      // be comments in our way, but that's taken care of in\n      // #stuff_after method.\n      return children[i];\n    }\n    else if (within(range, children[i][\"range\"])) {\n      // Our range is within the node --> recurse\n      return code_after(range, children[i])\n    }\n  }\n  return;\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, nspbr resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnspbr addresources[] = new nspbr[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new nspbr();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].action = resources[i].action;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t\taddresources[i].srcip = resources[i].srcip;\n\t\t\t\taddresources[i].srcipop = resources[i].srcipop;\n\t\t\t\taddresources[i].srcipval = resources[i].srcipval;\n\t\t\t\taddresources[i].srcport = resources[i].srcport;\n\t\t\t\taddresources[i].srcportop = resources[i].srcportop;\n\t\t\t\taddresources[i].srcportval = resources[i].srcportval;\n\t\t\t\taddresources[i].destip = resources[i].destip;\n\t\t\t\taddresources[i].destipop = resources[i].destipop;\n\t\t\t\taddresources[i].destipval = resources[i].destipval;\n\t\t\t\taddresources[i].destport = resources[i].destport;\n\t\t\t\taddresources[i].destportop = resources[i].destportop;\n\t\t\t\taddresources[i].destportval = resources[i].destportval;\n\t\t\t\taddresources[i].nexthop = resources[i].nexthop;\n\t\t\t\taddresources[i].nexthopval = resources[i].nexthopval;\n\t\t\t\taddresources[i].iptunnel = resources[i].iptunnel;\n\t\t\t\taddresources[i].iptunnelname = resources[i].iptunnelname;\n\t\t\t\taddresources[i].srcmac = resources[i].srcmac;\n\t\t\t\taddresources[i].protocol = resources[i].protocol;\n\t\t\t\taddresources[i].protocolnumber = resources[i].protocolnumber;\n\t\t\t\taddresources[i].vlan = resources[i].vlan;\n\t\t\t\taddresources[i].Interface = resources[i].Interface;\n\t\t\t\taddresources[i].priority = resources[i].priority;\n\t\t\t\taddresources[i].msr = resources[i].msr;\n\t\t\t\taddresources[i].monitor = resources[i].monitor;\n\t\t\t\taddresources[i].state = resources[i].state;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func GetTokenFromHOTPMockFile(path string) (token string, e error) {\n\totp, err := LoadHOTPMockFromFile(path)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\n\ttoken = otp.OTP()\n\n\terr = otp.SaveToFile(path)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\n\treturn token, nil\n}", "label": 5}
{"code": "public boolean classifySentenceStdin(DocumentReaderAndWriter<IN> readerWriter)\r\n    throws IOException\r\n  {\r\n    BufferedReader is = new BufferedReader(new InputStreamReader(System.in, flags.inputEncoding));\r\n    String line;\r\n    String text = \"\";\r\n    String eol = \"\\n\";\r\n    String sentence = \"<s>\";\r\n    while ((line = is.readLine()) != null) {\r\n    \t\r\n      if (line.trim().equals(\"\")) {\r\n    \t  text += sentence + eol;\r\n    \t  ObjectBank<List<IN>> documents = makeObjectBankFromString(text, readerWriter);\r\n          classifyAndWriteAnswers(documents, readerWriter);\r\n          text = \"\";\r\n      } else {\r\n    \t  text += line + eol;\r\n      }\r\n    }\r\n    if (text.trim().equals(\"\")) {\r\n    \treturn false;\r\n    }\r\n    return true;\r\n  }", "label": 0}
{"code": "func MarshalIndent(v interface{}, prefix, indent string) ([]byte, error) {\n\tvar b bytes.Buffer\n\tenc := NewEncoder(&b)\n\tenc.Indent(prefix, indent)\n\tif err := enc.Encode(v); err != nil {\n\t\treturn nil, err\n\t}\n\treturn b.Bytes(), nil\n}", "label": 5}
{"code": "func (c *Context) mapSession() {\n\tif cookie, err := c.req.Cookie(soap.SessionCookieName); err == nil {\n\t\tif val, ok := c.svc.sm.sessions[cookie.Value]; ok {\n\t\t\tc.SetSession(val, false)\n\t\t}\n\t}\n}", "label": 5}
{"code": "def variant_combinations\n      combinations = []\n      0.upto(2 ** FIELD_VARIANTS.length - 1) do |b|\n        combinations << combination = []\n        FIELD_VARIANTS.each_with_index do |variant, i|\n          combination << variant if b & 1<<i > 0\n        end\n      end\n      combinations\n    end", "label": 4}
{"code": "func (c *CredentialsClient) HostCredentials(ctx context.Context, req auth.RegisterUsingTokenRequest) (*auth.PackedKeys, error) {\n\tresp, err := c.clt.PostJSON(ctx, c.clt.Endpoint(\"webapi\", \"host\", \"credentials\"), req)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tvar packedKeys *auth.PackedKeys\n\terr = json.Unmarshal(resp.Bytes(), &packedKeys)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn packedKeys, nil\n}", "label": 5}
{"code": "def get_col_data_by_name(self, col_name, WHERE_Clause=''):\n        \"\"\" returns the values of col_name according to where \"\"\"\n        #print('get_col_data_by_name: col_name = ', col_name, ' WHERE = ', WHERE_Clause)\n        col_key = self.get_col_by_name(col_name)\n        if col_key is None:\n            print('get_col_data_by_name: col_name = ', col_name, ' NOT FOUND')\n            return []\n        #print('get_col_data_by_name: col_key =', col_key)\n        res = []\n        for row in self.arr:\n            #print('col_key=',col_key, ' len(row)=', len(row), ' row=', row)\n            res.append(row[col_key])  # need to convert to int for calcs but leave as string for lookups\n        return res", "label": 1}
{"code": "public function setMaintenancePolicy($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\MaintenancePolicy::class);\n        $this->maintenance_policy = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def accept(self, offer_ids, operations, filters=Filters()):\n        \"\"\"Accepts the given offers and performs a sequence of operations\n           on those accepted offers.\n\n        See Offer.Operation in mesos.proto for the set of available operations.\n        Available resources are aggregated when multiple offers are provided.\n\n        Note that all offers must belong to the same slave. Any unused resources\n        will be considered declined. The specified filters are applied on all\n        unused resources (see mesos.proto for a description of Filters).\n        \"\"\"\n        logging.info('Accepts offers {}'.format(offer_ids))\n        return self.driver.acceptOffers(map(encode, offer_ids),\n                                        map(encode, operations),\n                                        encode(filters))", "label": 1}
{"code": "public function sendGetNormalizedJid($countryCode, $number)\n    {\n        $msgId = $this->createIqId();\n        $ccNode = new ProtocolNode('cc', null, null, $countryCode);\n        $inNode = new ProtocolNode('in', null, null, $number);\n        $normalizeNode = new ProtocolNode('normalize', null, [$ccNode, $inNode], null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'urn:xmpp:whatsapp:account',\n                'type'  => 'get',\n                'to'    => Constants::WHATSAPP_SERVER,\n            ], [$normalizeNode], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "func (s *Server) Init() {\n\ts.mux = http.NewServeMux()\n\n\t// Register local handlers\n\ts.RegisterHandler(s, diagPaths2Func)\n}", "label": 5}
{"code": "public void check(ReferenceDescriptorDef refDef, String checkLevel) throws ConstraintException\r\n    {\r\n        ensureClassRef(refDef, checkLevel);\r\n        checkProxyPrefetchingLimit(refDef, checkLevel);\r\n    }", "label": 0}
{"code": "public function setStoredType($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\StoredType::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def attach_plugins_to_gemfile!(path_to_gemfile)\n      content = gemfile_content || (AUTOGENERATED_LINE + GEMFILE_SOURCE_LINE)\n\n      # We have to make sure fastlane is also added to the Gemfile, since we now use\n      # bundler to run fastlane\n      content += \"\\ngem 'fastlane'\\n\" unless available_gems.include?('fastlane')\n      content += \"\\n#{self.class.code_to_attach}\\n\"\n\n      File.write(path_to_gemfile, content)\n    end", "label": 4}
{"code": "func (c *Client) Upload(ctx context.Context, f io.Reader, u *url.URL, param *Upload) error {\n\tvar err error\n\n\tif param.Progress != nil {\n\t\tpr := progress.NewReader(ctx, param.Progress, f, param.ContentLength)\n\t\tf = pr\n\n\t\t// Mark progress reader as done when returning from this function.\n\t\tdefer func() {\n\t\t\tpr.Done(err)\n\t\t}()\n\t}\n\n\treq, err := http.NewRequest(param.Method, u.String(), f)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq = req.WithContext(ctx)\n\n\treq.ContentLength = param.ContentLength\n\treq.Header.Set(\"Content-Type\", param.Type)\n\n\tfor k, v := range param.Headers {\n\t\treq.Header.Add(k, v)\n\t}\n\n\tif param.Ticket != nil {\n\t\treq.AddCookie(param.Ticket)\n\t}\n\n\tres, err := c.Client.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer res.Body.Close()\n\n\tswitch res.StatusCode {\n\tcase http.StatusOK:\n\tcase http.StatusCreated:\n\tdefault:\n\t\terr = errors.New(res.Status)\n\t}\n\n\treturn err\n}", "label": 5}
{"code": "public CollectionDescriptorDef getCollection(String name)\r\n    {\r\n        CollectionDescriptorDef collDef = null;\r\n\r\n        for (Iterator it = _collections.iterator(); it.hasNext(); )\r\n        {\r\n            collDef = (CollectionDescriptorDef)it.next();\r\n            if (collDef.getName().equals(name))\r\n            {\r\n                return collDef;\r\n            }\r\n        }\r\n        return null;\r\n    }", "label": 0}
{"code": "def drop_view(name, revert_to_version: nil, materialized: false)\n      if materialized\n        Scenic.database.drop_materialized_view(name)\n      else\n        Scenic.database.drop_view(name)\n      end\n    end", "label": 4}
{"code": "function flipImageData (data, width, height) {\n  const numComponents = data.length / (width * height)\n  for (let y = 0; y < height / 2; y++) {\n    for (let x = 0; x < width; x++) {\n      for (let c = 0; c < numComponents; c++) {\n        const i = (y * width + x) * numComponents + c\n        const flippedI = ((height - y - 1) * width + x) * numComponents + c\n        const tmp = data[i]\n        data[i] = data[flippedI]\n        data[flippedI] = tmp\n      }\n    }\n  }\n}", "label": 3}
{"code": "function array_merge_recursive_unique($array1, $array2)\n\t{\n\t\t$arrays = func_get_args();\n\t\t$narrays = count($arrays);\n\t\t$ret = $arrays[0];\n\t\tfor ($i = 1; $i < $narrays; $i ++) {\n\t\t\tforeach ($arrays[$i] as $key => $value) {\n\t\t\t\tif (((string) $key) === ((string)((int) $key))) { // integer or string as integer key - append\n\t\t\t\t\t$ret[] = $value;\n\t\t\t\t} else { // string key - merge\n\t\t\t\t\tif (is_array($value) && isset($ret[$key])) {\n\t\t\t\t\t\t$ret[$key] = $this->array_merge_recursive_unique($ret[$key], $value);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t$ret[$key] = $value;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn $ret;\n\t}", "label": 2}
{"code": "def run\n      par = false\n\n      if @allow_parallel\n        par = true\n        @logger.info(\"Enabling parallelization by default.\")\n      end\n\n      if par\n        @actions.each do |machine, _, _|\n          if !machine.provider_options[:parallel]\n            @logger.info(\"Disabling parallelization because provider doesn't support it: #{machine.provider_name}\")\n            par = false\n            break\n          end\n        end\n      end\n\n      if par && @actions.length <= 1\n        @logger.info(\"Disabling parallelization because only executing one action\")\n        par = false\n      end\n\n      @logger.info(\"Batch action will parallelize: #{par.inspect}\")\n\n      threads = []\n      @actions.each do |machine, action, options|\n        @logger.info(\"Starting action: #{machine} #{action} #{options}\")\n\n        # Create the new thread to run our action. This is basically just\n        # calling the action but also contains some error handling in it\n        # as well.\n        thread = Thread.new do\n          Thread.current[:error] = nil\n\n          # Record our pid when we started in order to figure out if\n          # we've forked...\n          start_pid = Process.pid\n\n          begin\n            if action.is_a?(Proc)\n              action.call(machine)\n            else\n              machine.send(:action, action, options)\n            end\n          rescue Exception => e\n            # If we're not parallelizing, then raise the error. We also\n            # don't raise the error if we've forked, because it'll hang\n            # the process.\n            raise if !par && Process.pid == start_pid\n\n            # Store the exception that will be processed later\n            Thread.current[:error] = e\n\n            # We can only do the things below if we do not fork, otherwise\n            # it'll hang the process.\n            if Process.pid == start_pid\n              # Let the user know that this process had an error early\n              # so that they see it while other things are happening.\n              machine.ui.error(I18n.t(\"vagrant.general.batch_notify_error\"))\n            end\n          end\n\n          # If we forked during the process run, we need to do a hard\n          # exit here. Ruby's fork only copies the running process (which\n          # would be us), so if we return from this thread, it results\n          # in a zombie Ruby process.\n          if Process.pid != start_pid\n            # We forked.\n\n            exit_status = true\n            if Thread.current[:error]\n              # We had an error, print the stack trace and exit immediately.\n              exit_status = false\n              error = Thread.current[:error]\n              @logger.error(error.inspect)\n              @logger.error(error.message)\n              @logger.error(error.backtrace.join(\"\\n\"))\n            end\n\n            Process.exit!(exit_status)\n          end\n        end\n\n        # Set some attributes on the thread for later\n        thread[:machine] = machine\n\n        if !par\n          thread.join(THREAD_MAX_JOIN_TIMEOUT) while thread.alive?\n        end\n        threads << thread\n      end\n\n      errors = []\n\n      threads.each do |thread|\n        # Wait for the thread to complete\n        thread.join(THREAD_MAX_JOIN_TIMEOUT) while thread.alive?\n\n        # If the thread had an error, then store the error to show later\n        if thread[:error]\n          e = thread[:error]\n          # If the error isn't a Vagrant error, then store the backtrace\n          # as well.\n          if !thread[:error].is_a?(Errors::VagrantError)\n            e       = thread[:error]\n            message = e.message\n            message += \"\\n\"\n            message += \"\\n#{e.backtrace.join(\"\\n\")}\"\n\n            errors << I18n.t(\"vagrant.general.batch_unexpected_error\",\n                             machine: thread[:machine].name,\n                             message: message)\n          else\n            errors << I18n.t(\"vagrant.general.batch_vagrant_error\",\n                             machine: thread[:machine].name,\n                             message: thread[:error].message)\n          end\n        end\n      end\n\n      if !errors.empty?\n        raise Errors::BatchMultiError, message: errors.join(\"\\n\\n\")\n      end\n    end", "label": 4}
{"code": "func FailNowf(t TestingT, failureMessage string, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.FailNowf(t, failureMessage, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "label": 5}
{"code": "def register_pipeline(name, proc = nil, &block)\n      proc ||= block\n\n      self.config = hash_reassoc(config, :pipeline_exts) do |pipeline_exts|\n        pipeline_exts.merge(\".#{name}\".freeze => name.to_sym)\n      end\n\n      self.config = hash_reassoc(config, :pipelines) do |pipelines|\n        pipelines.merge(name.to_sym => proc)\n      end\n    end", "label": 4}
{"code": "def encapsulate_string(string)\n      string = string.gsub('\\\\', '\\\\\\\\')\n\n      ENCAPSULATED_CHARACTERS.each do |char|\n        string = string.gsub(char, \"\\\\#{char}\")\n      end\n\n      string\n    end", "label": 4}
{"code": "@Modified(id = \"importerServices\")\n    void modifiedImporterService(ServiceReference<ImporterService> serviceReference) {\n        try {\n            importersManager.modified(serviceReference);\n        } catch (InvalidFilterException invalidFilterException) {\n            LOG.error(\"The ServiceProperty \\\"\" + TARGET_FILTER_PROPERTY + \"\\\" of the ImporterService \"\n                            + bundleContext.getService(serviceReference) + \" doesn't provides a valid Filter.\"\n                            + \" To be used, it must provides a correct \\\"\" + TARGET_FILTER_PROPERTY + \"\\\" ServiceProperty.\",\n                    invalidFilterException\n            );\n            importersManager.removeLinks(serviceReference);\n            return;\n        }\n        if (importersManager.matched(serviceReference)) {\n            importersManager.updateLinks(serviceReference);\n        } else {\n            importersManager.removeLinks(serviceReference);\n        }\n    }", "label": 0}
{"code": "def validate_value(value)\n      v = value.to_s\n      return v unless v.include?(\"\\n\")\n      raise HeaderError, \"Invalid HTTP header field value: #{v.inspect}\"\n    end", "label": 4}
{"code": "func DefaultScopes(dataDir string) map[string]*ScopeCfg {\n\tif dataDir != \"\" {\n\t\tdefaultScopes[LocalScope].Client.Address = dataDir + \"/network/files/local-kv.db\"\n\t\treturn defaultScopes\n\t}\n\n\tdefaultScopes[LocalScope].Client.Address = defaultPrefix + \"/local-kv.db\"\n\treturn defaultScopes\n}", "label": 5}
{"code": "func (h *Handle) Set(ordinal uint64) error {\n\tif err := h.validateOrdinal(ordinal); err != nil {\n\t\treturn err\n\t}\n\t_, err := h.set(ordinal, 0, 0, false, false, false)\n\treturn err\n}", "label": 5}
{"code": "function () {\n\t\tif (item.done === false) {\n\t\t\tLOG.error('job timeout! please check if the job calls onDone eventually. ' + (item.name ? '[' + item.name + ']' : ''), l_name);\n\t\t\t\n\t\t\t// force this job be done\n\t\t\tonJobDone(false);\n\t\t}\n\t}", "label": 3}
{"code": "function indent(string, column) {\n  const spaces = new Array(++column).join(COLUMN);\n\n  return string.replace(RE_LINE_BEGIN, spaces);\n}", "label": 3}
{"code": "public function validateLifecycleCallbacks(ReflectionService $reflectionService) : void\n    {\n        foreach ($this->lifecycleCallbacks as $callbacks) {\n            /** @var array $callbacks */\n            foreach ($callbacks as $callbackFuncName) {\n                if (! $reflectionService->hasPublicMethod($this->className, $callbackFuncName)) {\n                    throw MappingException::lifecycleCallbackMethodNotFound($this->className, $callbackFuncName);\n                }\n            }\n        }\n    }", "label": 2}
{"code": "function(){\n\t\tvar viewWidth=$(\"#svgroot\").attr(\"width\");\n\t\tvar viewHeight=$(\"#svgroot\").attr(\"height\");\n\t\tvar viewX=640;\n\t\tvar viewY=480;\n\t\t\n\t\tif(svgedit.browser.isIE())\n\t\t{\n\t\t\t//This has only been tested with Firefox 10 and IE 9 (without chrome frame).\n\t\t\t//I am not sure if if is Firefox or IE that is being non compliant here.\n\t\t\t//Either way the one that is noncompliant may become more compliant later.\n\t\t\t//TAG:HACK  \n\t\t\t//TAG:VERSION_DEPENDENT\n\t\t\t//TAG:BROWSER_SNIFFING\n\t\t\tviewX=0;\n\t\t\tviewY=0;\n\t\t}\n\t\t\n\t\tvar svgWidth_old=$(\"#overviewMiniView\").attr(\"width\");\n\t\tvar svgHeight_new=viewHeight/viewWidth*svgWidth_old;\n\t\t$(\"#overviewMiniView\").attr(\"viewBox\",viewX+\" \"+viewY+\" \"+viewWidth+\" \"+viewHeight);\n\t\t$(\"#overviewMiniView\").attr(\"height\",svgHeight_new);\n\t\tupdateViewBox();\n\t}", "label": 3}
{"code": "func sendKeepAliveWithTimeout(conn RequestSender, timeout time.Duration, closeContext context.Context) bool {\n\terrorCh := make(chan error, 1)\n\n\tgo func() {\n\t\t// SendRequest will unblock when connection or channel is closed.\n\t\t_, _, err := conn.SendRequest(teleport.KeepAliveReqType, true, nil)\n\t\terrorCh <- err\n\t}()\n\n\tselect {\n\tcase err := <-errorCh:\n\t\tif err != nil {\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\tcase <-time.After(timeout):\n\t\treturn false\n\tcase <-closeContext.Done():\n\t\treturn false\n\t}\n}", "label": 5}
{"code": "func PodContainerKey(namespace, podName, containerName string) string {\n\treturn fmt.Sprintf(\"namespace:%s/pod:%s/container:%s\", namespace, podName, containerName)\n}", "label": 5}
{"code": "func (m *MockIndex) ForeignOne(arg0 imp1.Imp1) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"ForeignOne\", arg0)\n}", "label": 5}
{"code": "public function setCrossSeriesReducer($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Monitoring\\V3\\Aggregation_Reducer::class);\n        $this->cross_series_reducer = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function globify (args) {\n  let parsed = new ParsedArgs(args);\n  let expandGlob = parsed.args[parsed.globIndex];\n  let renameOutfile = parsed.args[parsed.outfileIndex];\n  let files = expandGlob && expandGlob(parsed.globOptions);\n\n  if (!expandGlob) {\n    // No glob patterns were found, so just run browserify as-is\n    if (renameOutfile) {\n      parsed.args[parsed.outfileIndex] = renameOutfile();\n    }\n    browserify(parsed.cmd, parsed.args);\n  }\n  else if (!renameOutfile) {\n    // Run browserify with the expanded list of file names\n    Array.prototype.splice.apply(parsed.args, [parsed.globIndex, 1].concat(files));\n    browserify(parsed.cmd, parsed.args);\n  }\n  else {\n    // Run browserify separately for each file\n    files.forEach((file) => {\n      let fileArgs = parsed.args.slice();\n      fileArgs[parsed.globIndex] = file;\n      fileArgs[parsed.outfileIndex] = renameOutfile(file, parsed.baseDir);\n      browserify(parsed.cmd, fileArgs);\n    });\n  }\n}", "label": 3}
{"code": "func (nDB *NetworkDB) GetTableByNetwork(tname, nid string) map[string]*TableElem {\n\tentries := make(map[string]*TableElem)\n\tnDB.indexes[byTable].WalkPrefix(fmt.Sprintf(\"/%s/%s\", tname, nid), func(k string, v interface{}) bool {\n\t\tentry := v.(*entry)\n\t\tif entry.deleting {\n\t\t\treturn false\n\t\t}\n\t\tkey := k[strings.LastIndex(k, \"/\")+1:]\n\t\tentries[key] = &TableElem{Value: entry.value, owner: entry.node}\n\t\treturn false\n\t})\n\treturn entries\n}", "label": 5}
{"code": "func (cn *connection) rw() io.ReadWriter {\n\treturn struct {\n\t\tio.Reader\n\t\tio.Writer\n\t}{cn.r, cn.w}\n}", "label": 5}
{"code": "def validate_currency(*currencies):\n\t\"\"\" some validation checks before doing anything \"\"\"\n\tvalidated_currency = []\n\tif not currencies:\n\t\traise CurrencyException('My function need something to run, duh')\n\tfor currency in currencies:\n\t\tcurrency = currency.upper()\n\t\tif not isinstance(currency, str):\n\t\t\traise TypeError('Currency code should be a string: ' + repr(currency))\n\t\tif currency not in _currencies:\n\t\t\traise CurrencyException('Currency code not found: ' + repr(currency))\n\t\tvalidated_currency.append(currency)\n\treturn validated_currency[0] if len(validated_currency) == 1 else validated_currency", "label": 1}
{"code": "def print_line(l):\n    \"\"\"\n    print line if starts with ...\n    \"\"\"\n    print_lines = ['# STOCKHOLM', '#=GF', '#=GS', ' ']\n    if len(l.split()) == 0:\n        return True\n    for start in print_lines:\n        if l.startswith(start):\n            return True\n    return False", "label": 1}
{"code": "func (s *SimpleStyledTextBar) SetCenter(m string) {\n\ts.initialize()\n\ts.center.SetMarkup(m)\n}", "label": 5}
{"code": "function getSymbolOfPartOfRightHandSideOfImportEquals(entityName, importDeclaration, dontResolveAlias) {\n            // There are three things we might try to look for. In the following examples,\n            // the search term is enclosed in |...|:\n            //\n            //     import a = |b|; // Namespace\n            //     import a = |b.c|; // Value, type, namespace\n            //     import a = |b.c|.d; // Namespace\n            if (entityName.kind === 69 /* Identifier */ && ts.isRightSideOfQualifiedNameOrPropertyAccess(entityName)) {\n                entityName = entityName.parent;\n            }\n            // Check for case 1 and 3 in the above example\n            if (entityName.kind === 69 /* Identifier */ || entityName.parent.kind === 139 /* QualifiedName */) {\n                return resolveEntityName(entityName, 1920 /* Namespace */, /*ignoreErrors*/ false, dontResolveAlias);\n            }\n            else {\n                // Case 2 in above example\n                // entityName.kind could be a QualifiedName or a Missing identifier\n                ts.Debug.assert(entityName.parent.kind === 229 /* ImportEqualsDeclaration */);\n                return resolveEntityName(entityName, 107455 /* Value */ | 793064 /* Type */ | 1920 /* Namespace */, /*ignoreErrors*/ false, dontResolveAlias);\n            }\n        }", "label": 3}
{"code": "public function changeAvatarPath($path)\n    {\n        $this->avatar_url = $path;\n\n        $this->raise(new AvatarChanged($this));\n\n        return $this;\n    }", "label": 2}
{"code": "def attributes_for_code(code, code_system)\n      @attributes.find_all { |e| e.send(:code) == code && e.send(:code_obj).send(:system) == code_system }\n    end", "label": 4}
{"code": "def validate_resource(self, value):\n        \"\"\"Validate the network resource with exponential backoff\"\"\"\n\n        def do_backoff(*args, **kwargs):\n            \"\"\"Call self._test_connection with exponential backoff, for self._max_tries attempts\"\"\"\n            attempts = 0\n            while True:\n                try:\n                    self._test_connection(*args, **kwargs)\n                    break\n                except ValidationError:\n                    wait_secs = min(self._max_wait, 2 ** attempts)\n                    attempts += 1\n                    if attempts < self._max_tries:\n                        time.sleep(wait_secs)\n                    else:\n                        raise\n\n        do_backoff(value)", "label": 1}
{"code": "def reload(self):\n        \"\"\"Reread secrets from the vault path\"\"\"\n        self._source = self._fetch_secrets(self._vault_url, self._path, self._token)", "label": 1}
{"code": "def offset(value = nil, &block)\n      chain { criteria.update_request_options from: block || Integer(value) }\n    end", "label": 4}
{"code": "def to_xml_string(str = '')\n      update_properties\n      str << \"<sheetPr #{serialized_attributes}>\"\n      tab_color.to_xml_string(str, 'tabColor') if tab_color\n      outline_pr.to_xml_string(str) if @outline_pr\n      page_setup_pr.to_xml_string(str)\n      str << \"</sheetPr>\"\n    end", "label": 4}
{"code": "public void addProcedure(ProcedureDef procDef)\r\n    {\r\n        procDef.setOwner(this);\r\n        _procedures.put(procDef.getName(), procDef);\r\n    }", "label": 0}
{"code": "public RedwoodConfiguration stderr(){\r\n    LogRecordHandler visibility = new VisibilityHandler();\r\n    LogRecordHandler console = Redwood.ConsoleHandler.err();\r\n    return this\r\n        .rootHandler(visibility)\r\n        .handler(visibility, console);\r\n  }", "label": 0}
{"code": "function parseUnaryExpressionOrHigher() {\n            /**\n             * ES7 UpdateExpression:\n             *      1) LeftHandSideExpression[?Yield]\n             *      2) LeftHandSideExpression[?Yield][no LineTerminator here]++\n             *      3) LeftHandSideExpression[?Yield][no LineTerminator here]--\n             *      4) ++UnaryExpression[?Yield]\n             *      5) --UnaryExpression[?Yield]\n             */\n            if (isUpdateExpression()) {\n                var incrementExpression = parseIncrementExpression();\n                return token() === 38 /* AsteriskAsteriskToken */ ?\n                    parseBinaryExpressionRest(getBinaryOperatorPrecedence(), incrementExpression) :\n                    incrementExpression;\n            }\n            /**\n             * ES7 UnaryExpression:\n             *      1) UpdateExpression[?yield]\n             *      2) delete UpdateExpression[?yield]\n             *      3) void UpdateExpression[?yield]\n             *      4) typeof UpdateExpression[?yield]\n             *      5) + UpdateExpression[?yield]\n             *      6) - UpdateExpression[?yield]\n             *      7) ~ UpdateExpression[?yield]\n             *      8) ! UpdateExpression[?yield]\n             */\n            var unaryOperator = token();\n            var simpleUnaryExpression = parseSimpleUnaryExpression();\n            if (token() === 38 /* AsteriskAsteriskToken */) {\n                var start = ts.skipTrivia(sourceText, simpleUnaryExpression.pos);\n                if (simpleUnaryExpression.kind === 177 /* TypeAssertionExpression */) {\n                    parseErrorAtPosition(start, simpleUnaryExpression.end - start, ts.Diagnostics.A_type_assertion_expression_is_not_allowed_in_the_left_hand_side_of_an_exponentiation_expression_Consider_enclosing_the_expression_in_parentheses);\n                }\n                else {\n                    parseErrorAtPosition(start, simpleUnaryExpression.end - start, ts.Diagnostics.An_unary_expression_with_the_0_operator_is_not_allowed_in_the_left_hand_side_of_an_exponentiation_expression_Consider_enclosing_the_expression_in_parentheses, ts.tokenToString(unaryOperator));\n                }\n            }\n            return simpleUnaryExpression;\n        }", "label": 3}
{"code": "def persist_or_delay_atomic_operation(operation)\n      if executing_atomically?\n        operation.each do |(name, hash)|\n          @atomic_context[name] ||= {}\n          @atomic_context[name].merge!(hash)\n        end\n      else\n        persist_atomic_operations(operation)\n      end\n    end", "label": 4}
{"code": "func (g *GLogger) Errorln(args ...interface{}) {\n\tg.Entry.Error(fmt.Sprintln(args...))\n}", "label": 5}
{"code": "def wrap_rankboost(job, rsem_files, merged_mhc_calls, transgene_out, univ_options,\n                   rankboost_options):\n    \"\"\"\n    A wrapper for boost_ranks.\n\n    :param dict rsem_files: Dict of results from rsem\n    :param dict merged_mhc_calls: Dict of results from merging mhc peptide binding predictions\n    :param dict transgene_out: Dict of results from running Transgene\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict rankboost_options: Options specific to rankboost\n    :return: Dict of concise and detailed results for mhci and mhcii\n             output_files:\n                |- 'mhcii_rankboost_concise_results.tsv': fsID\n                |- 'mhcii_rankboost_detailed_results.txt': fsID\n                |- 'mhci_rankboost_concise_results.tsv': fsID\n                +- 'mhci_rankboost_detailed_results.txt': fsID\n    :rtype: dict\n    \"\"\"\n    rankboost = job.addChildJobFn(boost_ranks, rsem_files['rsem.isoforms.results'],\n                                  merged_mhc_calls, transgene_out, univ_options, rankboost_options)\n\n    return rankboost.rv()", "label": 1}
{"code": "def print_available_linters\n      log.info 'Available linters:'\n\n      linter_names = HamlLint::LinterRegistry.linters.map do |linter|\n        linter.name.split('::').last\n      end\n\n      linter_names.sort.each do |linter_name|\n        log.log \" - #{linter_name}\"\n      end\n    end", "label": 4}
{"code": "function writeEmittedFiles(emitOutput, jsFilePath, sourceMapFilePath, writeByteOrderMark, sourceFiles) {\n                if (compilerOptions.sourceMap && !compilerOptions.inlineSourceMap) {\n                    ts.writeFile(host, emitterDiagnostics, sourceMapFilePath, sourceMap.getText(), /*writeByteOrderMark*/ false, sourceFiles);\n                }\n                if (sourceMapDataList) {\n                    sourceMapDataList.push(sourceMap.getSourceMapData());\n                }\n                ts.writeFile(host, emitterDiagnostics, jsFilePath, emitOutput, writeByteOrderMark, sourceFiles);\n            }", "label": 3}
{"code": "def get_store(logger: Logger=None) -> 'Store':\n    \"\"\"Get and configure the storage backend\"\"\"\n    from trading_bots.conf import settings\n    store_settings = settings.storage\n    store = store_settings.get('name', 'json')\n    if store == 'json':\n        store = 'trading_bots.core.storage.JSONStore'\n    elif store == 'redis':\n        store = 'trading_bots.core.storage.RedisStore'\n    store_cls = load_class_by_name(store)\n    kwargs = store_cls.configure(store_settings)\n    return store_cls(logger=logger, **kwargs)", "label": 1}
{"code": "func PgRangeByRngtypid(db XODB, rngtypid pgtypes.Oid) (*PgRange, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, rngtypid, rngsubtype, rngcollation, rngsubopc, rngcanonical, rngsubdiff ` +\n\t\t`FROM pg_catalog.pg_range ` +\n\t\t`WHERE rngtypid = $1`\n\n\t// run query\n\tXOLog(sqlstr, rngtypid)\n\tpr := PgRange{}\n\n\terr = db.QueryRow(sqlstr, rngtypid).Scan(&pr.Tableoid, &pr.Cmax, &pr.Xmax, &pr.Cmin, &pr.Xmin, &pr.Ctid, &pr.Rngtypid, &pr.Rngsubtype, &pr.Rngcollation, &pr.Rngsubopc, &pr.Rngcanonical, &pr.Rngsubdiff)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pr, nil\n}", "label": 5}
{"code": "public static void Forward(double[][] data) {\n        double[][] result = new double[data.length][data[0].length];\n\n        for (int m = 0; m < data.length; m++) {\n            for (int n = 0; n < data[0].length; n++) {\n                double sum = 0;\n                for (int i = 0; i < result.length; i++) {\n                    for (int k = 0; k < data.length; k++) {\n                        sum += data[i][k] * cas(((2.0 * Math.PI) / data.length) * (i * m + k * n));\n                    }\n                    result[m][n] = (1.0 / data.length) * sum;\n                }\n            }\n        }\n\n        for (int i = 0; i < data.length; i++) {\n            for (int j = 0; j < data[0].length; j++) {\n                data[i][j] = result[i][j];\n            }\n        }\n    }", "label": 0}
{"code": "function ReadableSerial(list, iterator, callback)\n{\n  if (!(this instanceof ReadableSerial))\n  {\n    return new ReadableSerial(list, iterator, callback);\n  }\n\n  // turn on object mode\n  ReadableSerial.super_.call(this, {objectMode: true});\n\n  this._start(serial, list, iterator, callback);\n}", "label": 3}
{"code": "def run_linter(linter, engine, file_path)\n      return if @config.excluded_file_for_linter?(file_path, linter)\n      @lints += linter.run(engine, @config.linter_options(linter))\n    end", "label": 4}
{"code": "def find_type(type, nested=true)\n      find_type_elements(type, nested).map { |e| e.options }\n    end", "label": 4}
{"code": "func (ww *WidgetWatchers) PostEventWidgetContent(w Widget) {\n\tev := &EventWidgetContent{}\n\tev.SetWidget(w)\n\tev.SetEventNow()\n\tww.PostEvent(ev)\n}", "label": 5}
{"code": "func (s *PresenceService) DeleteReverseTunnel(clusterName string) error {\n\terr := s.Delete(context.TODO(), backend.Key(reverseTunnelsPrefix, clusterName))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "public function subUnitNoOverflow($valueUnit, $value, $overflowUnit)\n    {\n        return $this->setUnitNoOverflow($valueUnit, $this->$valueUnit - $value, $overflowUnit);\n    }", "label": 2}
{"code": "public ReferenceDescriptorDef getReference(String name)\r\n    {\r\n        ReferenceDescriptorDef refDef;\r\n\r\n        for (Iterator it = _references.iterator(); it.hasNext(); )\r\n        {\r\n            refDef = (ReferenceDescriptorDef)it.next();\r\n            if (refDef.getName().equals(name))\r\n            {\r\n                return refDef;\r\n            }\r\n        }\r\n        return null;\r\n    }", "label": 0}
{"code": "def element(name, tag=:element, identifier={ :index => 0 }, &block)\n      #\n      # sets tag as element if not defined\n      #\n      if tag.is_a?(Hash)\n        identifier = tag\n        tag        = :element\n      end\n\n      standard_methods(name, identifier, 'element_for', &block)\n\n      define_method(\"#{name}\") do\n        element = self.send(\"#{name}_element\")\n\n        %w(Button TextField Radio Hidden CheckBox FileField).each do |klass|\n          next unless element.element.class.to_s  == \"Watir::#{klass}\"\n          self.class.send(klass.gsub(/(.)([A-Z])/,'\\1_\\2').downcase, name, identifier, &block)\n          return self.send name\n        end\n        element.text\n      end\n      define_method(\"#{name}_element\") do\n        return call_block(&block) if block_given?\n        platform.element_for(tag, identifier.clone)\n      end\n      define_method(\"#{name}?\") do\n        self.send(\"#{name}_element\").exists?\n      end\n      define_method(\"#{name}=\") do |value|\n        element = self.send(\"#{name}_element\")\n\n        klass = case element.element\n                when Watir::TextField\n                  'text_field'\n                when Watir::TextArea\n                  'text_area'\n                when Watir::Select\n                  'select_list'\n                when Watir::FileField\n                  'file_field'\n                else\n                  raise \"Can not set a #{element.element} element with #=\"\n                end\n        self.class.send(klass, name, identifier, &block)\n        self.send(\"#{name}=\", value)\n      end\n    end", "label": 4}
{"code": "def merge_perchrom_mutations(job, chrom, mutations, univ_options):\n    \"\"\"\n    Merge the mutation calls for a single chromosome.\n\n    :param str chrom: Chromosome to process\n    :param dict mutations: dict of dicts of the various mutation caller names as keys, and a dict of\n           per chromosome job store ids for vcfs as value\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :returns fsID for vcf contaning merged calls for the given chromosome\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    from protect.mutation_calling.muse import process_muse_vcf\n    from protect.mutation_calling.mutect import process_mutect_vcf\n    from protect.mutation_calling.radia import process_radia_vcf\n    from protect.mutation_calling.somaticsniper import process_somaticsniper_vcf\n    from protect.mutation_calling.strelka import process_strelka_vcf\n    mutations.pop('indels')\n    mutations['strelka_indels'] = mutations['strelka']['indels']\n    mutations['strelka_snvs'] = mutations['strelka']['snvs']\n    vcf_processor = {'snvs': {'mutect': process_mutect_vcf,\n                              'muse': process_muse_vcf,\n                              'radia': process_radia_vcf,\n                              'somaticsniper': process_somaticsniper_vcf,\n                              'strelka_snvs': process_strelka_vcf\n                              },\n                     'indels': {'strelka_indels': process_strelka_vcf\n                                }\n                     }\n    #                 'fusions': lambda x: None,\n    #                 'indels': lambda x: None}\n    # For now, let's just say 2 out of n need to call it.\n    # num_preds = len(mutations)\n    # majority = int((num_preds + 0.5) / 2)\n    majority = {'snvs': 2,\n                'indels': 1}\n\n    accepted_hits = defaultdict(dict)\n\n    for mut_type in vcf_processor.keys():\n        # Get input files\n        perchrom_mutations = {caller: vcf_processor[mut_type][caller](job, mutations[caller][chrom],\n                                                                      work_dir, univ_options)\n                              for caller in vcf_processor[mut_type]}\n        # Process the strelka key\n        perchrom_mutations['strelka'] = perchrom_mutations['strelka_' + mut_type]\n        perchrom_mutations.pop('strelka_' + mut_type)\n        # Read in each file to a dict\n        vcf_lists = {caller: read_vcf(vcf_file) for caller, vcf_file in perchrom_mutations.items()}\n        all_positions = list(set(itertools.chain(*vcf_lists.values())))\n        for position in sorted(all_positions):\n            hits = {caller: position in vcf_lists[caller] for caller in perchrom_mutations.keys()}\n            if sum(hits.values()) >= majority[mut_type]:\n                callers = ','.join([caller for caller, hit in hits.items() if hit])\n                assert position[1] not in accepted_hits[position[0]]\n                accepted_hits[position[0]][position[1]] = (position[2], position[3], callers)\n\n    with open(''.join([work_dir, '/', chrom, '.vcf']), 'w') as outfile:\n        print('##fileformat=VCFv4.0', file=outfile)\n        print('##INFO=<ID=callers,Number=.,Type=String,Description=List of supporting callers.',\n              file=outfile)\n        print('#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO', file=outfile)\n        for chrom in chrom_sorted(accepted_hits.keys()):\n            for position in sorted(accepted_hits[chrom]):\n                    print(chrom, position, '.', accepted_hits[chrom][position][0],\n                          accepted_hits[chrom][position][1], '.', 'PASS',\n                          'callers=' + accepted_hits[chrom][position][2], sep='\\t', file=outfile)\n    fsid = job.fileStore.writeGlobalFile(outfile.name)\n    export_results(job, fsid, outfile.name, univ_options, subfolder='mutations/merged')\n    return fsid", "label": 1}
{"code": "def reduce_node(irep_node, reducer_states)\n      visit_analyzers(:enter, irep_node, reducer_states)\n\n      irep_node.typed_children.each do |type_defn, children|\n        children.each do |name, child_irep_node|\n          reduce_node(child_irep_node, reducer_states)\n        end\n      end\n\n      visit_analyzers(:leave, irep_node, reducer_states)\n    end", "label": 4}
{"code": "def _enable_thread_pool(func):\n    \"\"\"\n    Use thread pool for executing a task if self.enable_thread_pool is True.\n\n    Return an instance of future when flag is_async is True otherwise will to\n    block waiting for the result until timeout then returns the result.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        self = args[0]\n        if self.enable_thread_pool and hasattr(self, 'thread_pool'):\n            future = self.thread_pool.submit(func, *args, **kwargs)\n            is_async = kwargs.get('is_async')\n            if is_async is None or not is_async:\n                timeout = kwargs.get('timeout')\n                if timeout is None:\n                    timeout = 2\n                try:\n                    result = future.result(timeout=timeout)\n                except TimeoutError as e:\n                    self.logger.exception(e)\n                    result = None\n                return result\n            return future\n        else:\n            return func(*args, **kwargs)\n\n    return wrapper", "label": 1}
{"code": "func MsIdentities(db XODB, schema string) ([]*MsIdentity, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT o.name as table_name ` +\n\t\t`FROM sys.objects o inner join sys.columns c on o.object_id = c.object_id ` +\n\t\t`WHERE c.is_identity = 1 ` +\n\t\t`AND schema_name(o.schema_id) = $1 AND o.type = 'U'`\n\n\t// run query\n\tXOLog(sqlstr, schema)\n\tq, err := db.Query(sqlstr, schema)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*MsIdentity{}\n\tfor q.Next() {\n\t\tmi := MsIdentity{}\n\n\t\t// scan\n\t\terr = q.Scan(&mi.TableName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &mi)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def can(self):\n        \"\"\"Grant permission if owner or admin.\"\"\"\n        return str(current_user.get_id()) == str(self.community.id_user) or \\\n            DynamicPermission(ActionNeed('admin-access')).can()", "label": 1}
{"code": "def title(title = nil, headline = '')\n      set_meta_tags(title: title) unless title.nil?\n      headline.presence || meta_tags[:title]\n    end", "label": 4}
{"code": "public static cacheselector[] get(nitro_service service, options option) throws Exception{\n\t\tcacheselector obj = new cacheselector();\n\t\tcacheselector[] response = (cacheselector[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def required_repeated_param(type, name)\n      internal_param(type, name, true)\n      raise ArgumentError, _('A required repeated parameter cannot be added after an optional parameter') if @min != @max\n      @min += 1\n      @max = :default\n    end", "label": 4}
{"code": "def search_path_by(resource_type: nil, space_state: nil)\n      new_params = {\n        utf8: params[:utf8],\n        filter: {\n          decidim_scope_id: params.dig(:filter, :decidim_scope_id),\n          term: params[:term] || params.dig(:filter, :term)\n        }\n      }\n      new_params[:filter][:resource_type] = resource_type if resource_type.present?\n      new_params[:filter][:space_state] = space_state if space_state.present?\n      decidim.search_path(new_params)\n    end", "label": 4}
{"code": "func NewEventsService(b backend.Backend) *EventsService {\n\treturn &EventsService{\n\t\tEntry:   logrus.WithFields(logrus.Fields{trace.Component: \"Events\"}),\n\t\tbackend: b,\n\t}\n}", "label": 5}
{"code": "public function setValue($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\Value::class);\n        $this->value = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static void stopService() {\n        DaemonStarter.currentPhase.set(LifecyclePhase.STOPPING);\n        final CountDownLatch cdl = new CountDownLatch(1);\n        Executors.newSingleThreadExecutor().execute(() -> {\n            DaemonStarter.getLifecycleListener().stopping();\n            DaemonStarter.daemon.stop();\n            cdl.countDown();\n        });\n\n        try {\n            int timeout = DaemonStarter.lifecycleListener.get().getShutdownTimeoutSeconds();\n            if (!cdl.await(timeout, TimeUnit.SECONDS)) {\n                DaemonStarter.rlog.error(\"Failed to stop gracefully\");\n                DaemonStarter.abortSystem();\n            }\n        } catch (InterruptedException e) {\n            DaemonStarter.rlog.error(\"Failure awaiting stop\", e);\n            Thread.currentThread().interrupt();\n        }\n\n    }", "label": 0}
{"code": "func (f *Fpdf) Cellf(w, h float64, fmtStr string, args ...interface{}) {\n\tf.CellFormat(w, h, sprintf(fmtStr, args...), \"\", 0, \"L\", false, 0, \"\")\n}", "label": 5}
{"code": "func (a *AuthServer) SetClock(clock clockwork.Clock) {\n\ta.lock.Lock()\n\tdefer a.lock.Unlock()\n\ta.clock = clock\n}", "label": 5}
{"code": "def handle_known_template_id(template_id)\n      case template_id\n      when VARIABLE_TEMPLATE\n        @derivation_operator = HQMF::DataCriteria::INTERSECT if @derivation_operator == HQMF::DataCriteria::XPRODUCT\n        @definition ||= 'derived'\n        @variable = true\n        @negation = false\n      when SATISFIES_ANY_TEMPLATE\n        @definition = HQMF::DataCriteria::SATISFIES_ANY\n        @negation = false\n      when SATISFIES_ALL_TEMPLATE\n        @definition = HQMF::DataCriteria::SATISFIES_ALL\n        @derivation_operator = HQMF::DataCriteria::INTERSECT\n        @negation = false\n      else\n        return false\n      end\n      true\n    end", "label": 4}
{"code": "def waitForResponse(self, timeOut=None):\n        \"\"\"blocks until the response arrived or timeout is reached.\"\"\"\n        self.__evt.wait(timeOut)\n        if self.waiting():\n            raise Timeout()\n        else:\n            if self.response[\"error\"]:\n                raise Exception(self.response[\"error\"])\n            else:\n                return self.response[\"result\"]", "label": 1}
{"code": "function SetStylesArray($arr)\n\t{\n\t\t$style = '';\n\t\tforeach (['B', 'I'] as $s) {\n\t\t\tif (isset($arr[$s])) {\n\t\t\t\tif ($arr[$s]) {\n\t\t\t\t\t$this->$s = true;\n\t\t\t\t\t$style .= $s;\n\t\t\t\t} else {\n\t\t\t\t\t$this->$s = false;\n\t\t\t\t}\n\t\t\t} elseif ($this->$s) {\n\t\t\t\t$style .= $s;\n\t\t\t}\n\t\t}\n\t\t$this->currentfontstyle = $style;\n\t\t$this->SetFont('', $style, 0, false);\n\t}", "label": 2}
{"code": "public static Dimension getDimension(File videoFile) throws IOException {\n    try (FileInputStream fis = new FileInputStream(videoFile)) {\n      return getDimension(fis, new AtomicReference<ByteBuffer>());\n    }\n  }", "label": 0}
{"code": "def accept_invite(invite)\n      resolved = invite(invite).code\n      API::Invite.accept(token, resolved)\n    end", "label": 4}
{"code": "public void addFkToItemClass(String column)\r\n    {\r\n        if (fksToItemClass == null)\r\n        {\r\n            fksToItemClass = new Vector();\r\n        }\r\n        fksToItemClass.add(column);\r\n        fksToItemClassAry = null;\r\n    }", "label": 0}
{"code": "def initialize_capabilities!(host, hosts, capabilities, *args)\n      @cap_logger = Log4r::Logger.new(\n        \"vagrant::capability_host::#{self.class.to_s.downcase}\")\n\n      if host && !hosts[host]\n        raise Errors::CapabilityHostExplicitNotDetected, value: host.to_s\n      end\n\n      if !host\n        host = autodetect_capability_host(hosts, *args) if !host\n        raise Errors::CapabilityHostNotDetected if !host\n      end\n\n      if !hosts[host]\n        # This should never happen because the autodetect above uses the\n        # hosts hash to look up hosts. And if an explicit host is specified,\n        # we do another check higher up.\n        raise \"Internal error. Host not found: #{host}\"\n      end\n\n      name      = host\n      host_info = hosts[name]\n      host      = host_info[0].new\n      chain     = []\n      chain << [name, host]\n\n      # Build the proper chain of parents if there are any.\n      # This allows us to do \"inheritance\" of capabilities later\n      if host_info[1]\n        parent_name = host_info[1]\n        parent_info = hosts[parent_name]\n        while parent_info\n          chain << [parent_name, parent_info[0].new]\n          parent_name = parent_info[1]\n          parent_info = hosts[parent_name]\n        end\n      end\n\n      @cap_host_chain = chain\n      @cap_args       = args\n      @cap_caps       = capabilities\n      true\n    end", "label": 4}
{"code": "public static nsmode get(nitro_service service) throws Exception{\n\t\tnsmode obj = new nsmode();\n\t\tnsmode[] response = (nsmode[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def _combine_costs(self, Npwl, Hpwl, Cpwl, fparm_pwl, any_pwl,\n                       Npol, Hpol, Cpol, fparm_pol, npol, nw):\n        \"\"\" Combines pwl, polynomial and user-defined costs.\n        \"\"\"\n        NN = vstack([n for n in [Npwl, Npol] if n is not None], \"csr\")\n\n        if (Hpwl is not None) and (Hpol is not None):\n            Hpwl = hstack([Hpwl, csr_matrix((any_pwl, npol))])\n            Hpol = hstack([csr_matrix((npol, any_pwl)), Hpol])\n#        if H is not None:\n#            H = hstack([csr_matrix((nw, any_pwl+npol)), H])\n\n        HHw = vstack([h for h in [Hpwl, Hpol] if h is not None], \"csr\")\n\n        CCw = r_[Cpwl, Cpol]\n\n        ffparm = r_[fparm_pwl, fparm_pol]\n\n        return NN, HHw, CCw, ffparm", "label": 1}
{"code": "def get_loco_name(self):\n        \"\"\"\n        Returns the Provider, Product and Engine name.\n\n        :return list\n        \"\"\"\n        ret_str = self.dll.GetLocoName().decode()\n        if not ret_str:\n            return\n        return ret_str.split('.:.')", "label": 1}
{"code": "def blt(f: List[SYM], x: List[SYM]) -> Dict[str, Any]:\n    \"\"\"\n    Sort equations by dependence\n    \"\"\"\n    J = ca.jacobian(f, x)\n    nblock, rowperm, colperm, rowblock, colblock, coarserow, coarsecol = J.sparsity().btf()\n    return {\n        'J': J,\n        'nblock': nblock,\n        'rowperm': rowperm,\n        'colperm': colperm,\n        'rowblock': rowblock,\n        'colblock': colblock,\n        'coarserow': coarserow,\n        'coarsecol': coarsecol\n    }", "label": 1}
{"code": "public Criteria copy(boolean includeGroupBy, boolean includeOrderBy, boolean includePrefetchedRelationships)\r\n    {\r\n        Criteria copy = new Criteria();\r\n\r\n        copy.m_criteria = new Vector(this.m_criteria);\r\n        copy.m_negative = this.m_negative;\r\n\r\n        if (includeGroupBy)\r\n        {\r\n            copy.groupby = this.groupby;\r\n        }\r\n        if (includeOrderBy)\r\n        {\r\n            copy.orderby = this.orderby;\r\n        }\r\n        if (includePrefetchedRelationships)\r\n        {\r\n            copy.prefetchedRelationships = this.prefetchedRelationships;\r\n        }\r\n\r\n        return copy;\r\n    }", "label": 0}
{"code": "func (r *SpecRunner) combineCoverprofiles(runners []*testrunner.TestRunner) error {\n\n\tpath, _ := filepath.Abs(r.getOutputDir())\n\tif !fileExists(path) {\n\t\treturn fmt.Errorf(\"Unable to create combined profile, outputdir does not exist: %s\", r.getOutputDir())\n\t}\n\n\tfmt.Println(\"path is \" + path)\n\n\tcombined, err := os.OpenFile(filepath.Join(path, r.getCoverprofile()),\n\t\tos.O_APPEND|os.O_WRONLY|os.O_CREATE, 0666)\n\n\tif err != nil {\n\t\tfmt.Printf(\"Unable to create combined profile, %v\\n\", err)\n\t\treturn nil // non-fatal error\n\t}\n\n\tfor _, runner := range runners {\n\t\tcontents, err := ioutil.ReadFile(runner.CoverageFile)\n\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Unable to read coverage file %s to combine, %v\\n\", runner.CoverageFile, err)\n\t\t\treturn nil // non-fatal error\n\t\t}\n\n\t\t_, err = combined.Write(contents)\n\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Unable to append to coverprofile, %v\\n\", err)\n\t\t\treturn nil // non-fatal error\n\t\t}\n\t}\n\n\tfmt.Println(\"All profiles combined\")\n\treturn nil\n}", "label": 5}
{"code": "function evaluate(conf, parent) {\n  if (!conf || conf.constructor.name !== 'Object') return conf;\n  var val;\n  for (var key in conf) {\n    val = conf[key];\n    if (typeof val === 'function') val = reduceVal(parent, val);\n    conf[key] = evaluate(val, parent);\n  }\n  return conf;\n}", "label": 3}
{"code": "public base_response enable_features(String[] features) throws Exception\n\t{\n\t\tbase_response result = null;\n\t\tnsfeature resource = new nsfeature();\n\t\tresource.set_feature(features);\n\t\toptions option = new options();\n\t\toption.set_action(\"enable\");\n\t\tresult = resource.perform_operation(this, option);\n\t\treturn result;\n\t}", "label": 0}
{"code": "private function newRow(CellChunk $chunk)\n    {\n        $this->validateNewRow($chunk);\n        $this->rowKey = $chunk->getRowKey();\n        $familyName = $chunk->getFamilyName()->getValue();\n        $qualifierName = $chunk->getQualifier()->getValue();\n        $labels = ($chunk->getLabels()->getIterator()->valid())\n            ? implode(iterator_to_array($chunk->getLabels()->getIterator()))\n            : '';\n        $this->row[$familyName] = [];\n        $this->family = &$this->row[$familyName];\n        $this->family[$qualifierName] = [];\n        $this->qualifiers = &$this->family[$qualifierName];\n        $qualifier = [\n            'value' => $chunk->getValue(),\n            'labels' => $labels,\n            'timeStamp' => $chunk->getTimestampMicros()\n        ];\n        $this->qualifierValue = &$qualifier['value'];\n        $this->qualifiers[] = &$qualifier;\n        $this->moveToNextState($chunk);\n    }", "label": 2}
{"code": "def send_proxy_connect_request(req)\n      return unless req.uri.https? && req.using_proxy?\n\n      @pending_request = true\n\n      req.connect_using_proxy @socket\n\n      @pending_request  = false\n      @pending_response = true\n\n      read_headers!\n      @proxy_response_headers = @parser.headers\n\n      if @parser.status_code != 200\n        @failed_proxy_connect = true\n        return\n      end\n\n      @parser.reset\n      @pending_response = false\n    end", "label": 4}
{"code": "public DocumentReaderAndWriter<IN> makeReaderAndWriter() {\r\n    DocumentReaderAndWriter<IN> readerAndWriter;\r\n    try {\r\n      readerAndWriter = ((DocumentReaderAndWriter<IN>)\r\n                         Class.forName(flags.readerAndWriter).newInstance());\r\n    } catch (Exception e) {\r\n      throw new RuntimeException(String.format(\"Error loading flags.readerAndWriter: '%s'\", flags.readerAndWriter), e);\r\n    }\r\n    readerAndWriter.init(flags);\r\n    return readerAndWriter;\r\n  }", "label": 0}
{"code": "func (s *AuthServer) initializeTOTP(accountName string) (key string, qr []byte, err error) {\n\t// create totp key\n\totpKey, err := totp.Generate(totp.GenerateOpts{\n\t\tIssuer:      \"Teleport\",\n\t\tAccountName: accountName,\n\t})\n\tif err != nil {\n\t\treturn \"\", nil, trace.Wrap(err)\n\t}\n\n\t// create QR code\n\tvar otpQRBuf bytes.Buffer\n\totpImage, err := otpKey.Image(456, 456)\n\tif err != nil {\n\t\treturn \"\", nil, trace.Wrap(err)\n\t}\n\tpng.Encode(&otpQRBuf, otpImage)\n\n\treturn otpKey.Secret(), otpQRBuf.Bytes(), nil\n}", "label": 5}
{"code": "def get_entries(dir, subfolder)\n      base = site.in_source_dir(dir, subfolder)\n      return [] unless File.exist?(base)\n\n      entries = Dir.chdir(base) { filter_entries(Dir[\"**/*\"], base) }\n      entries.delete_if { |e| File.directory?(site.in_source_dir(base, e)) }\n    end", "label": 4}
{"code": "def read_vcf(vcf_file):\n    \"\"\"\n    Read a vcf file to a dict of lists.\n\n    :param str vcf_file: Path to a vcf file.\n    :return: dict of lists of vcf records\n    :rtype: dict\n    \"\"\"\n    vcf_dict = []\n    with open(vcf_file, 'r') as invcf:\n        for line in invcf:\n            if line.startswith('#'):\n                continue\n            line = line.strip().split()\n            vcf_dict.append((line[0], line[1], line[3], line[4]))\n    return vcf_dict", "label": 1}
{"code": "function (file, errors, options) {\n      var reports = []\n        , content = file.content.split('\\n');\n\n      errors.forEach(function error (err) {\n        // some linters don't return the location -_-\n        if (!err.line) return reports.push(err.message.grey, '');\n\n        var start = err.line > 3 ? err.line - 3 : 0\n          , stop = err.line + 2\n          , range = content.slice(start, stop)\n          , numbers = _.range(start + 1, stop + 1)\n          , len = stop.toString().length;\n\n        reports.push('Lint error: ' + err.line + ' col ' + err.column);\n        range.map(function reformat (line) {\n          var lineno = numbers.shift()\n            , offender = lineno === err.line\n            , inline = /\\'[^\\']+?\\'/\n            , slice;\n\n          // this is the actual line with the error, so we should start finding\n          // what the error is and how we could highlight it in the output\n          if (offender) {\n            if (line.length < err.column) {\n              // we are missing something at the end of the line.. so add a red\n              // square\n              line += ' '.inverse.red;\n            } else {\n              // we have a direct match on a statement\n              if (inline.test(err.message)) {\n                slice = err.message.match(inline)[0].replace(/\\'/g, '');\n              } else {\n                // it's happening in the center of things, so we can start\n                // coloring inside the shizzle\n                slice = line.slice(err.column - 1);\n              }\n\n              line = line.replace(slice, slice.inverse.red);\n            }\n          }\n\n          reports.push('  ' + pad(lineno, len) + ' | ' + line);\n        });\n\n        reports.push('');\n        reports.push(err.message.grey);\n        reports.push('');\n\n      });\n\n      // output the shizzle\n      reports.forEach(function output (line) {\n        this.logger.error(line);\n      }.bind(this));\n    }", "label": 3}
{"code": "def upsert_agent(instance)\n      @logger.info(\"Adding agent #{instance.agent_id} (#{instance.job}/#{instance.id}) to #{name}...\")\n\n      agent_id = instance.agent_id\n\n      if agent_id.nil?\n        @logger.warn(\"No agent id for instance #{instance.job}/#{instance.id} in deployment #{name}\")\n        #count agents for instances with deleted vm, which expect to have vm\n        if instance.expects_vm? && !instance.has_vm?\n          agent = Agent.new(\"agent_with_no_vm\", deployment: name)\n          @instance_id_to_agent[instance.id] = agent\n          agent.update_instance(instance)\n        end\n        return false\n      end\n\n      # Idle VMs, we don't care about them, but we still want to track them\n      if instance.job.nil?\n        @logger.debug(\"VM with no job found: #{agent_id}\")\n      end\n\n      agent = @agent_id_to_agent[agent_id]\n\n      if agent.nil?\n        @logger.debug(\"Discovered agent #{agent_id}\")\n        agent = Agent.new(agent_id, deployment: name)\n        @agent_id_to_agent[agent_id] = agent\n        @instance_id_to_agent.delete(instance.id) if @instance_id_to_agent[instance.id]\n      end\n\n      agent.update_instance(instance)\n\n      true\n    end", "label": 4}
{"code": "def _locked_refresh_doc_ids(self):\n        \"\"\"Assumes that the caller has the _index_lock !\n        \"\"\"\n        d = {}\n        for s in self._shards:\n            for k in s.doc_index.keys():\n                if k in d:\n                    raise KeyError('doc \"{i}\" found in multiple repos'.format(i=k))\n                d[k] = s\n        self._doc2shard_map = d", "label": 1}
{"code": "def validate_format_percentage(name, value)\n      DataTypeValidator.validate name, Float, value, lambda { |arg| arg >= 0.0 && arg <= 1.0}\n    end", "label": 4}
{"code": "function generateFileLoaderOptions (dir) {\n  const name = `assets/${dir}/[name]${store.state.config.fileNameHash ? '.[hash:8]' : ''}.[ext]`\n  const publicPath = process.env.NODE_ENV === 'production' ? '..' : undefined\n\n  return { name, publicPath }\n}", "label": 3}
{"code": "def clear_messages(topic:, partition:)\n      return unless @buffer.key?(topic) && @buffer[topic].key?(partition)\n\n      @size -= @buffer[topic][partition].count\n      @bytesize -= @buffer[topic][partition].map(&:bytesize).reduce(0, :+)\n\n      @buffer[topic].delete(partition)\n      @buffer.delete(topic) if @buffer[topic].empty?\n    end", "label": 4}
{"code": "public synchronized boolean checkWrite(TransactionImpl tx, Object obj)\r\n    {\r\n        if (log.isDebugEnabled()) log.debug(\"LM.checkWrite(tx-\" + tx.getGUID() + \", \" + new Identity(obj, tx.getBroker()).toString() + \")\");\r\n        LockStrategy lockStrategy = LockStrategyFactory.getStrategyFor(obj);\r\n        return lockStrategy.checkWrite(tx, obj);\r\n    }", "label": 0}
{"code": "def widgets(self):\n        \"\"\"Get the items.\"\"\"\n        widgets = []\n        for i, chart in enumerate(most_visited_pages_charts()):\n            widgets.append(Widget(html_id='most_visited_chart_%d' % i,\n                                  content=json.dumps(chart),\n                                  template='meerkat/widgets/highcharts.html',\n                                  js_code=['plotOptions.tooltip.pointFormatter']))\n\n        return widgets", "label": 1}
{"code": "function makeLoginHandler(provider, providerAccounts) {\n  return function (accessToken, refreshToken, profile, done) {\n    log.debug('Authentiated for ' + provider);\n    log.debug(profile);\n\n    profile.provider = provider;\n    profile.idWithProvider = profile.id;\n    exports.getUserFromProfile(providerAccounts, profile)\n      .then(function (userRecord) {\n\n        // Save the user if they are new.\n        var fieldsToCopy = ['provider', 'displayName', 'emails'];\n        if (userRecord && userRecord.data) {\n\n          return userRecord;\n        } else {\n          userRecord = {\n            isAuthenticated: true\n          };\n          userRecord.meta = {\n            isRegistered: false\n          };\n          userRecord.data = {\n            idWithProvider: profile.id,\n          };\n          fieldsToCopy.forEach(function (key) {\n            userRecord.data[key] = profile[key];\n          });\n\n          return providerAccounts.create(userRecord.data)\n            .then(function () {\n              return userRecord;\n            });\n        }\n      })\n      .then(function (userRecord) {\n        done(null, userRecord);\n      })\n      .then(null, function (error) {\n        log.error(error);\n        done(error);\n      })\n      .then(null, log.error);\n  };\n}", "label": 3}
{"code": "def serialized_attributes(str = '', additional_attributes = {})\n      attributes = declared_attributes.merge! additional_attributes\n      attributes.each do |key, value|\n        str << \"#{Axlsx.camel(key, false)}=\\\"#{Axlsx.camel(Axlsx.booleanize(value), false)}\\\" \"\n      end\n      str\n    end", "label": 4}
{"code": "public static int cudnnReduceTensor(\n        cudnnHandle handle, \n        cudnnReduceTensorDescriptor reduceTensorDesc, \n        Pointer indices, \n        long indicesSizeInBytes, \n        Pointer workspace, \n        long workspaceSizeInBytes, \n        Pointer alpha, \n        cudnnTensorDescriptor aDesc, \n        Pointer A, \n        Pointer beta, \n        cudnnTensorDescriptor cDesc, \n        Pointer C)\n    {\n        return checkResult(cudnnReduceTensorNative(handle, reduceTensorDesc, indices, indicesSizeInBytes, workspace, workspaceSizeInBytes, alpha, aDesc, A, beta, cDesc, C));\n    }", "label": 0}
{"code": "def renamecol(X, old, new):\n    \"\"\"\n    Rename column of a numpy ndarray with structured dtype, in-place.\n\n    Implemented by the tabarray method \n    :func:`tabular.tab.tabarray.renamecol`.\n\n    **Parameters**\n\n            **X** :  numpy ndarray with structured dtype\n\n                    The numpy array for which a column is to be renamed.\n\n            **old** :  string\n\n                    Old column name, e.g. a name in `X.dtype.names`.\n\n            **new** :  string\n\n                    New column name to replace `old`.\n\n    \"\"\"\n    NewNames = tuple([n if n != old else new for n in X.dtype.names])\n    X.dtype.names = NewNames", "label": 1}
{"code": "public static boolean isSinglePositionPrefix(FieldInfo fieldInfo,\n      String prefix) throws IOException {\n    if (fieldInfo == null) {\n      throw new IOException(\"no fieldInfo\");\n    } else {\n      String info = fieldInfo.getAttribute(\n          MtasCodecPostingsFormat.MTAS_FIELDINFO_ATTRIBUTE_PREFIX_SINGLE_POSITION);\n      if (info == null) {\n        throw new IOException(\"no \"\n            + MtasCodecPostingsFormat.MTAS_FIELDINFO_ATTRIBUTE_PREFIX_SINGLE_POSITION);\n      } else {\n        return Arrays.asList(info.split(Pattern.quote(MtasToken.DELIMITER)))\n            .contains(prefix);\n      }\n    }\n  }", "label": 0}
{"code": "def create(*args)\n      arguments(args) do\n        assert_required %w[ name ]\n      end\n      params = arguments.params\n\n      # Requires authenticated user\n      if (org = params.delete('org') || org)\n        post_request(\"/orgs/#{org}/repos\", params)\n      else\n        post_request(\"/user/repos\", params)\n      end\n    end", "label": 4}
{"code": "public static base_response delete(nitro_service client, String communityname) throws Exception {\n\t\tsnmpcommunity deleteresource = new snmpcommunity();\n\t\tdeleteresource.communityname = communityname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "function _gpfGenSuperMember (superMethod, method) {\n    return function GpfSuperableMethod () {\n        var previousSuper = this._super,\n            result;\n        // Add a new ._super() method pointing to the base class member\n        this._super = superMethod;\n        try {\n            // Execute the method\n            result = method.apply(this, arguments);\n        } finally {\n            // Remove it after execution\n            if (undefined === previousSuper) {\n                delete this._super;\n            } else {\n                this._super = previousSuper;\n            }\n        }\n        return result;\n    };\n}", "label": 3}
{"code": "public function broadcast(GraphQLSubscription $subscription, string $fieldName, $root): void\n    {\n        $topic = $subscription->decodeTopic($fieldName, $root);\n\n        $subscribers = $this->storage\n            ->subscribersByTopic($topic)\n            ->filter(function (Subscriber $subscriber) use ($subscription, $root): bool {\n                return $subscription->filter($subscriber, $root);\n            });\n\n        $this->iterator->process(\n            $subscribers,\n            function (Subscriber $subscriber) use ($root): void {\n                $data = $this->graphQL->executeQuery(\n                    $subscriber->query,\n                    $subscriber->context,\n                    $subscriber->args,\n                    $subscriber->setRoot($root),\n                    $subscriber->operationName\n                );\n\n                $this->broadcastManager->broadcast(\n                    $subscriber,\n                    $data->jsonSerialize()\n                );\n            }\n        );\n    }", "label": 2}
{"code": "public static function get(Throwable $exception)\n    {\n        return collect(explode(\"\\n\", file_get_contents($exception->getFile())))\n            ->slice($exception->getLine() - 10, 20)\n            ->mapWithKeys(function ($value, $key) {\n                return [$key + 1 => $value];\n            })->all();\n    }", "label": 2}
{"code": "public boolean link(D declaration, ServiceReference<S> declarationBinderRef) {\n        S declarationBinder = bindersManager.getDeclarationBinder(declarationBinderRef);\n        LOG.debug(declaration + \" match the filter of \" + declarationBinder + \" : bind them together\");\n        declaration.bind(declarationBinderRef);\n        try {\n            declarationBinder.addDeclaration(declaration);\n        } catch (Exception e) {\n            declaration.unbind(declarationBinderRef);\n            LOG.debug(declarationBinder + \" throw an exception when giving to it the Declaration \"\n                    + declaration, e);\n            return false;\n        }\n        return true;\n    }", "label": 0}
{"code": "def estimate_complexity(self, x,y,z,n):\n        \"\"\" \n        calculates a rough guess of runtime based on product of parameters \n        \"\"\"\n        num_calculations = x * y * z * n\n        run_time = num_calculations / 100000  # a 2014 PC does about 100k calcs in a second (guess based on prior logs)\n        return self.show_time_as_short_string(run_time)", "label": 1}
{"code": "public static cmpglobal_cmppolicy_binding[] get(nitro_service service) throws Exception{\n\t\tcmpglobal_cmppolicy_binding obj = new cmpglobal_cmppolicy_binding();\n\t\tcmpglobal_cmppolicy_binding response[] = (cmpglobal_cmppolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function clearRegionStats($regionName)\n    {\n        $this->cachePutCountMap[$regionName]  = 0;\n        $this->cacheHitCountMap[$regionName]  = 0;\n        $this->cacheMissCountMap[$regionName] = 0;\n    }", "label": 2}
{"code": "public static vpnglobal_vpntrafficpolicy_binding[] get(nitro_service service) throws Exception{\n\t\tvpnglobal_vpntrafficpolicy_binding obj = new vpnglobal_vpntrafficpolicy_binding();\n\t\tvpnglobal_vpntrafficpolicy_binding response[] = (vpnglobal_vpntrafficpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function splitToObj(str, delim) {\n    if (!(_.isString(str))) {\n        throw new Error(`Input must be a string: ${str}`);\n    }\n    else {\n        return util_1.convertToObject(str.split(delim), () => true);\n    }\n}", "label": 3}
{"code": "private void printKeySet() {\r\n    Set<?> keys = keySet();\r\n    System.out.println(\"printing keyset:\");\r\n    for (Object o: keys) {\r\n      //System.out.println(Arrays.asList((Object[]) i.next()));\r\n      System.out.println(o);\r\n    }\r\n  }", "label": 0}
{"code": "def becomes(klass)\n      unless klass.include?(Mongoid::Document)\n        raise ArgumentError, \"A class which includes Mongoid::Document is expected\"\n      end\n\n      became = klass.new(clone_document)\n      became._id = _id\n      became.instance_variable_set(:@changed_attributes, changed_attributes)\n      became.instance_variable_set(:@errors, ActiveModel::Errors.new(became))\n      became.errors.instance_variable_set(:@messages, errors.instance_variable_get(:@messages))\n      became.instance_variable_set(:@new_record, new_record?)\n      became.instance_variable_set(:@destroyed, destroyed?)\n      became.changed_attributes[\"_type\"] = self.class.to_s\n      became._type = klass.to_s\n\n      # mark embedded docs as persisted\n      embedded_relations.each_pair do |name, meta|\n        without_autobuild do\n          relation = became.__send__(name)\n          Array.wrap(relation).each do |r|\n            r.instance_variable_set(:@new_record, new_record?)\n          end\n        end\n      end\n\n      became\n    end", "label": 4}
{"code": "def is_valid(hal_id):\n    \"\"\"\n    Check that a given HAL id is a valid one.\n\n    :param hal_id: The HAL id to be checked.\n    :returns: Boolean indicating whether the HAL id is valid or not.\n\n    >>> is_valid(\"hal-01258754, version 1\")\n    True\n\n    >>> is_valid(\"hal-01258754\")\n    True\n\n    >>> is_valid(\"hal-01258754v2\")\n    True\n\n    >>> is_valid(\"foobar\")\n    False\n    \"\"\"\n    match = REGEX.match(hal_id)\n    return (match is not None) and (match.group(0) == hal_id)", "label": 1}
{"code": "public static dnsnsecrec get(nitro_service service, String hostname) throws Exception{\n\t\tdnsnsecrec obj = new dnsnsecrec();\n\t\tobj.set_hostname(hostname);\n\t\tdnsnsecrec response = (dnsnsecrec) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function () {\n            var header = this._header;\n            this._separator = _gpfArrayForEachFalsy(_gpfCsvSeparators, function (separator) {\n                if (header.includes(separator)) {\n                    return separator;\n                }\n            }) || _gpfCsvSeparators[_GPF_START];\n        }", "label": 3}
{"code": "def add_lint(node_or_line_or_location, message)\n      @lints << Lint.new(self,\n                         engine.filename,\n                         extract_location(node_or_line_or_location),\n                         message,\n                         @config.fetch('severity', :warning).to_sym)\n    end", "label": 4}
{"code": "func (r SSOLoginConsoleReq) Check() error {\n\tif r.RedirectURL == \"\" {\n\t\treturn trace.BadParameter(\"missing RedirectURL\")\n\t}\n\tif len(r.PublicKey) == 0 {\n\t\treturn trace.BadParameter(\"missing PublicKey\")\n\t}\n\tif r.ConnectorID == \"\" {\n\t\treturn trace.BadParameter(\"missing ConnectorID\")\n\t}\n\treturn nil\n}", "label": 5}
{"code": "private void handleFailedSendDataRequest(SerialMessage originalMessage) {\n\t\tZWaveNode node = this.getNode(originalMessage.getMessageNode());\n\t\t\n\t\tif (node.getNodeStage() == NodeStage.NODEBUILDINFO_DEAD)\n\t\t\treturn;\n\t\t\n\t\tif (!node.isListening() && originalMessage.getPriority() != SerialMessage.SerialMessagePriority.Low) {\n\t\t\tZWaveWakeUpCommandClass wakeUpCommandClass = (ZWaveWakeUpCommandClass)node.getCommandClass(ZWaveCommandClass.CommandClass.WAKE_UP);\n\t\t\t\n\t\t\tif (wakeUpCommandClass != null) {\n\t\t\t\twakeUpCommandClass.setAwake(false);\n\t\t\t\twakeUpCommandClass.putInWakeUpQueue(originalMessage); //it's a battery operated device, place in wake-up queue.\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else if (!node.isListening() && originalMessage.getPriority() == SerialMessage.SerialMessagePriority.Low)\n\t\t\treturn;\n\t\t\n\t\tnode.incrementResendCount();\n\t\t\n\t\tlogger.error(\"Got an error while sending data to node {}. Resending message.\", node.getNodeId());\n\t\tthis.sendData(originalMessage);\n\t}", "label": 0}
{"code": "function(eventType, callback, context) {\n      if (eventType == null && callback == null && context == null) {\n        this._events = {};\n      } else if (eventType == null) {\n        each(this._events, function(value, key, collection) {\n          collection._events[key] = removeCallbacks(value, callback, context);\n        });\n      } else {\n        this._events[eventType] = removeCallbacks(this._events[eventType], callback, context);\n      }\n      return this;\n    }", "label": 3}
{"code": "function writeHTMLHeaders()\n\t{\n\n\t\tif ($this->mirrorMargins && ($this->page) % 2 == 0) {\n\t\t\t$OE = 'E';\n\t\t} else {\n\t\t\t$OE = 'O';\n\t\t}\n\n\t\tif ($OE === 'E') {\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['html'] = $this->HTMLHeaderE['html'];\n\t\t} else {\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['html'] = $this->HTMLHeader['html'];\n\t\t}\n\n\t\tif ($this->forcePortraitHeaders && $this->CurOrientation == 'L' && $this->CurOrientation != $this->DefOrientation) {\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['rotate'] = true;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['ml'] = $this->tMargin;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['mr'] = $this->bMargin;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['mh'] = $this->margin_header;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['mf'] = $this->margin_footer;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['pw'] = $this->h;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['ph'] = $this->w;\n\t\t} else {\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['ml'] = $this->lMargin;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['mr'] = $this->rMargin;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['mh'] = $this->margin_header;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['mf'] = $this->margin_footer;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['pw'] = $this->w;\n\t\t\t$this->saveHTMLHeader[$this->page][$OE]['ph'] = $this->h;\n\t\t}\n\t}", "label": 2}
{"code": "function useBasicAuth() {\n  return new Promise((resolve, reject) => {\n    if (!defaults.userToken || !defaults.masterToken) {\n      reject(__generateFakeResponse__(0, '', {}, 'userToken or masterToken are missing for basic authentication'))\n    }\n    else {\n      let details = {\n        \"token_type\": \"Basic\",\n        \"expires_in\": 0,\n        \"appName\": defaults.appName,\n        \"username\": \"\",\n        \"role\": \"\",\n        \"firstName\": \"\",\n        \"lastName\": \"\",\n        \"fullName\": \"\",\n        \"regId\": 0,\n        \"userId\": null\n      };\n      let basicToken = 'Basic ' + createBasicToken(defaults.masterToken, defaults.userToken);\n      utils.storage.set('user', {\n        token: {\n          Authorization:  basicToken\n        },\n        details: details\n      });\n      resolve(__generateFakeResponse__(200, 'OK', {}, details, {}));\n    }\n  });\n\n}", "label": 3}
{"code": "private void createNodeMappings(MtasTokenIdFactory mtasTokenIdFactory,\n      Level level, Level parentLevel) {\n    MtasToken nodeToken;\n    if (level.node != null && level.positionStart != null\n        && level.positionEnd != null) {\n      nodeToken = new MtasTokenString(mtasTokenIdFactory.createTokenId(),\n          level.node, \"\");\n      nodeToken.setOffset(level.offsetStart, level.offsetEnd);\n      nodeToken.setRealOffset(level.realOffsetStart, level.realOffsetEnd);\n      nodeToken.addPositionRange(level.positionStart, level.positionEnd);\n      tokenCollection.add(nodeToken);\n      if (parentLevel != null) {\n        parentLevel.tokens.add(nodeToken);\n      }\n      // only for first mapping(?)\n      for (MtasToken token : level.tokens) {\n        token.setParentId(nodeToken.getId());\n      }\n    }\n  }", "label": 0}
{"code": "public static appflowpolicylabel get(nitro_service service, String labelname) throws Exception{\n\t\tappflowpolicylabel obj = new appflowpolicylabel();\n\t\tobj.set_labelname(labelname);\n\t\tappflowpolicylabel response = (appflowpolicylabel) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def icon=(icon)\n      if icon.respond_to? :read\n        icon_string = 'data:image/jpg;base64,'\n        icon_string += Base64.strict_encode64(icon.read)\n        update_server_data(icon_id: icon_string)\n      else\n        update_server_data(icon_id: icon)\n      end\n    end", "label": 4}
{"code": "public static <T> OptionalValue<T> ofNullable(ResourceKey key, T value) {\n        return new GenericOptionalValue<T>(RUNTIME_SOURCE, key, value);\n    }", "label": 0}
{"code": "public boolean shouldBeInReport(final DbDependency dependency) {\n        if(dependency == null){\n            return false;\n        }\n        if(dependency.getTarget() == null){\n            return false;\n        }\n        if(corporateFilter != null){\n            if(!decorator.getShowThirdparty() && !corporateFilter.filter(dependency)){\n                return false;\n            }\n            if(!decorator.getShowCorporate() && corporateFilter.filter(dependency)){\n                return false;\n            }\n        }\n\n        if(!scopeHandler.filter(dependency)){\n            return false;\n        }\n\n        return true;\n    }", "label": 0}
{"code": "function toRepoUrl(url) {\n  if (url.startsWith('git@')) {\n    if (argv.useSSH) {\n      return url;\n    }\n    // have an ssh url need an http url\n    const m = url.match(/(https?:\\/\\/([^/]+)\\/|git@(.+):)([\\w\\d-_/]+)(.git)?/);\n    return `https://${m[3]}/${m[4]}.git`;\n  }\n  if (url.startsWith('http')) {\n    if (!argv.useSSH) {\n      return url;\n    }\n    // have a http url need an ssh url\n    const m = url.match(/(https?:\\/\\/([^/]+)\\/|git@(.+):)([\\w\\d-_/]+)(.git)?/);\n    return `git@${m[2]}:${m[4]}.git`;\n  }\n  if (!url.includes('/')) {\n    url = `Caleydo/${url}`;\n  }\n  if (argv.useSSH) {\n    return `git@github.com:${url}.git`;\n  }\n  return `https://github.com/${url}.git`;\n}", "label": 3}
{"code": "def module_root\n      metadata_path = find_upwards('metadata.json')\n      if metadata_path\n        File.dirname(metadata_path)\n      elsif in_module_root?\n        Dir.pwd\n      else\n        nil\n      end\n    end", "label": 4}
{"code": "function () {\n        if (!window.ove.context.isInitialized) {\n            log.debug('Requesting an update of state configuration from server');\n            window.ove.socket.send({ action: Constants.Action.READ });\n        }\n    }", "label": 3}
{"code": "def method_missing(method, *args, &block)\n      return super unless strategy.allowed? method\n\n      object.send(method, *args, &block).decorate\n    end", "label": 4}
{"code": "def relevant_configuration_file(options)\n      if options[:config_file]\n        options[:config_file]\n      elsif File.exist?(Config::FILE_NAME)\n        Config::FILE_NAME\n      elsif File.exist?(Config.user_file)\n        Config.user_file\n      end\n    end", "label": 4}
{"code": "def forcibly_stop_workers\n      return unless @workers.size > 0\n      GRPC.logger.info(\"forcibly terminating #{@workers.size} worker(s)\")\n      @workers.each do |t|\n        next unless t.alive?\n        begin\n          t.exit\n        rescue StandardError => e\n          GRPC.logger.warn('error while terminating a worker')\n          GRPC.logger.warn(e)\n        end\n      end\n    end", "label": 4}
{"code": "function (options, iterationInfo) {\n        // Use the identity for the key name\n        var identity;\n        if (options.mode === 'list') {\n            identity = iterationInfo.relativeFullPath;\n            //identity = identity.toLowerCase();\n            //find and replace all containments of '/', ':' and '\\' within the string\n            identity = identity.replace(/\\/|\\\\|:/g, '');\n        }\n        else if (options.mode === 'tree') {\n            identity = iterationInfo.fileName;\n            //identity = identity.toLowerCase();\n        }\n        else\n            throw new Error('Unknown mode');\n\n        //remove extention\n        identity = identity.substr(0, identity.lastIndexOf('.')) || identity;\n\n        return identity;\n    }", "label": 3}
{"code": "func NetworkOptionEnableIPv6(enableIPv6 bool) NetworkOption {\n\treturn func(n *network) {\n\t\tif n.generic == nil {\n\t\t\tn.generic = make(map[string]interface{})\n\t\t}\n\t\tn.enableIPv6 = enableIPv6\n\t\tn.generic[netlabel.EnableIPv6] = enableIPv6\n\t}\n}", "label": 5}
{"code": "private ClassDescriptorDef ensureClassDef(XClass original)\r\n    {\r\n        String             name     = original.getQualifiedName();\r\n        ClassDescriptorDef classDef = _model.getClass(name);\r\n\r\n        if (classDef == null)\r\n        {\r\n            classDef = new ClassDescriptorDef(original);\r\n            _model.addClass(classDef);\r\n        }\r\n        return classDef;\r\n    }", "label": 0}
{"code": "func (pm *PortMapper) SetIptablesChain(c *iptables.ChainInfo, bridgeName string) {\n\tpm.chain = c\n\tpm.bridgeName = bridgeName\n}", "label": 5}
{"code": "function() {\n      var templateContext = View.prototype.prepare.apply(this);\n      templateContext.formErrors = (_.size(this._errors) !== 0) ? this._errors : null;\n      templateContext.formSuccess = this._success;\n      return templateContext;\n    }", "label": 3}
{"code": "def tinymce_javascript(config=:default, options={})\n      options, config = config, :default if config.is_a?(Hash)\n      options = Configuration.new(options)\n\n      \"TinyMCERails.initialize('#{config}', #{options.to_javascript});\".html_safe\n    end", "label": 4}
{"code": "func (a *allocator) RequestAddress(poolID string, address net.IP, options map[string]string) (*net.IPNet, map[string]string, error) {\n\tvar (\n\t\tprefAddress string\n\t\tretAddress  *net.IPNet\n\t\terr         error\n\t)\n\tif address != nil {\n\t\tprefAddress = address.String()\n\t}\n\treq := &api.RequestAddressRequest{PoolID: poolID, Address: prefAddress, Options: options}\n\tres := &api.RequestAddressResponse{}\n\tif err := a.call(\"RequestAddress\", req, res); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif res.Address != \"\" {\n\t\tretAddress, err = types.ParseCIDR(res.Address)\n\t} else {\n\t\treturn nil, nil, ipamapi.ErrNoIPReturned\n\t}\n\treturn retAddress, res.Data, err\n}", "label": 5}
{"code": "def log(self, *args, **kwargs):\n        \"\"\"Convenience function for printing indenting debug output.\"\"\"\n        if self.verbose:\n            print('   ' * self.depth, *args, **kwargs)", "label": 1}
{"code": "public static String read(final File file) throws IOException {\n        final StringBuilder sb = new StringBuilder();\n\n        try (\n                final FileReader fr = new FileReader(file);\n                final BufferedReader br = new BufferedReader(fr);\n        ) {\n\n            String sCurrentLine;\n\n            while ((sCurrentLine = br.readLine()) != null) {\n                sb.append(sCurrentLine);\n            }\n        }\n\n        return sb.toString();\n    }", "label": 0}
{"code": "func (f *Fpdf) Cell(w, h float64, txtStr string) {\n\tf.CellFormat(w, h, txtStr, \"\", 0, \"L\", false, 0, \"\")\n}", "label": 5}
{"code": "public function load(array $args)\n    {\n        $envelope = new MetadataEnvelope();\n        $constantValues = MetadataEnvelope::getConstantValues();\n\n        foreach ($constantValues as $constant) {\n            if (!empty($args['Metadata'][$constant])) {\n                $envelope[$constant] = $args['Metadata'][$constant];\n            }\n        }\n\n        return $envelope;\n    }", "label": 2}
{"code": "func MarshalCertRoles(roles []string) (string, error) {\n\tout, err := json.Marshal(CertRoles{Version: V1, Roles: roles})\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\treturn string(out), err\n}", "label": 5}
{"code": "def load_plugin(plugin_path)\n      plugin_class = load_plugin_class(plugin_path)\n      return nil unless plugin_class.kind_of?(Class)\n      if plugin_class < Ohai::DSL::Plugin::VersionVII\n        load_v7_plugin(plugin_class)\n      else\n        raise Exceptions::IllegalPluginDefinition, \"cannot create plugin of type #{plugin_class}\"\n      end\n    end", "label": 4}
{"code": "public E extractMin() {\r\n    if (isEmpty()) {\r\n      throw new NoSuchElementException();\r\n    }\r\n    HeapEntry<E> minEntry = indexToEntry.get(0);\r\n    int lastIndex = size() - 1;\r\n    if (lastIndex > 0) {\r\n      HeapEntry<E> lastEntry =  indexToEntry.get(lastIndex);\r\n      swap(lastEntry, minEntry);\r\n      removeLast(minEntry);\r\n      heapifyDown(lastEntry);\r\n    } else {\r\n      removeLast(minEntry);\r\n    }\r\n    return minEntry.object;\r\n  }", "label": 0}
{"code": "def gpu_c2r_ifft(in1, is_gpuarray=False, store_on_gpu=False):\n    \"\"\"\n    This function makes use of the scikits implementation of the FFT for GPUs to take the complex to real IFFT.\n\n    INPUTS:\n    in1             (no default):       The array on which the IFFT is to be performed.\n    is_gpuarray     (default=True):     Boolean specifier for whether or not input is on the gpu.\n    store_on_gpu    (default=False):    Boolean specifier for whether the result is to be left on the gpu or not.\n\n    OUTPUTS:\n    gpu_out1                            The gpu array containing the result.\n    OR\n    gpu_out1.get()                      The result from the gpu array.\n    \"\"\"\n\n    if is_gpuarray:\n        gpu_in1 = in1\n    else:\n        gpu_in1 = gpuarray.to_gpu_async(in1.astype(np.complex64))\n\n    output_size = np.array(in1.shape)\n    output_size[1] = 2*(output_size[1]-1)\n\n    gpu_out1 = gpuarray.empty([output_size[0],output_size[1]], np.float32)\n    gpu_plan = Plan(output_size, np.complex64, np.float32)\n    ifft(gpu_in1, gpu_out1, gpu_plan)\n    scale_fft(gpu_out1)\n\n    if store_on_gpu:\n        return gpu_out1\n    else:\n        return gpu_out1.get()", "label": 1}
{"code": "public static snmpmanager[] get(nitro_service service) throws Exception{\n\t\tsnmpmanager obj = new snmpmanager();\n\t\tsnmpmanager[] response = (snmpmanager[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def rm(self, path):\n        \"\"\"\n        Delete the path and anything under the path.\n\n        Example\n        -------\n            >>> s3utils.rm(\"path/to/file_or_folder\")\n        \"\"\"\n\n        list_of_files = list(self.ls(path))\n\n        if list_of_files:\n            if len(list_of_files) == 1:\n                self.bucket.delete_key(list_of_files[0])\n            else:\n                self.bucket.delete_keys(list_of_files)\n            self.printv(\"Deleted: %s\" % list_of_files)\n        else:\n            logger.error(\"There was nothing to remove under %s\", path)", "label": 1}
{"code": "private String getSubQuerySQL(Query subQuery)\r\n    {\r\n        ClassDescriptor cld = getRoot().cld.getRepository().getDescriptorFor(subQuery.getSearchClass());\r\n        String sql;\r\n\r\n        if (subQuery instanceof QueryBySQL)\r\n        {\r\n            sql = ((QueryBySQL) subQuery).getSql();\r\n        }\r\n        else\r\n        {\r\n            sql = new SqlSelectStatement(this, m_platform, cld, subQuery, m_logger).getStatement();\r\n        }\r\n\r\n        return sql;\r\n    }", "label": 0}
{"code": "def trim_variant_fields(location, ref, alt):\n    \"\"\"\n    Trims common prefixes from the ref and alt sequences\n\n    Parameters\n    ----------\n    location : int\n        Position (starting from 1) on some chromosome\n\n    ref : str\n        Reference nucleotides\n\n    alt : str\n        Alternate (mutant) nucleotide\n\n    Returns adjusted triplet (location, ref, alt)\n    \"\"\"\n    if len(alt) > 0 and ref.startswith(alt):\n        # if alt is a prefix of the ref sequence then we actually have a\n        # deletion like:\n        #   g.10 GTT > GT\n        # which can be trimmed to\n        #   g.12 'T'>''\n        ref = ref[len(alt):]\n        location += len(alt)\n        alt = \"\"\n    if len(ref) > 0 and alt.startswith(ref):\n        # if ref sequence is a prefix of the alt sequence then we actually have\n        # an insertion like:\n        #   g.10 GT>GTT\n        # which can be trimmed to\n        #   g.11 ''>'T'\n        # Note that we are selecting the position *before* the insertion\n        # (as an arbitrary convention)\n        alt = alt[len(ref):]\n        location += len(ref) - 1\n        ref = \"\"\n    return location, ref, alt", "label": 1}
{"code": "func (h *ArchiveHandler) newArchiveFromGuest(u *url.URL) (File, error) {\n\tr, w := io.Pipe()\n\n\ta := &archive{\n\t\tname:   u.Path,\n\t\tdone:   r.Close,\n\t\tReader: r,\n\t\tWriter: w,\n\t}\n\n\tvar z io.Writer = w\n\tvar c io.Closer = ioutil.NopCloser(nil)\n\n\tswitch u.Query().Get(\"format\") {\n\tcase \"tgz\":\n\t\tgz := gzip.NewWriter(w)\n\t\tz = gz\n\t\tc = gz\n\t}\n\n\ttw := tar.NewWriter(z)\n\n\tgo func() {\n\t\terr := h.Write(u, tw)\n\n\t\t_ = tw.Close()\n\t\t_ = c.Close()\n\t\tif gzipTrailer {\n\t\t\t_, _ = w.Write(gzipHeader)\n\t\t}\n\t\t_ = w.CloseWithError(err)\n\t}()\n\n\treturn a, nil\n}", "label": 5}
{"code": "def main_url\n      main_page = @options.main_page\n      ref = nil\n      if main_page\n        ref = AllReferences[main_page]\n        if ref\n          ref = ref.path\n        else\n          $stderr.puts \"Could not find main page #{main_page}\"\n        end\n      end\n\n      unless ref\n        for file in @files\n          if file.document_self and file.context.global\n            ref = CGI.escapeHTML(\"#{CLASS_DIR}/#{file.context.module_name}.html\")\n            break\n          end\n        end\n      end\n\n      unless ref\n        for file in @files\n          if file.document_self and !file.context.global\n            ref = CGI.escapeHTML(\"#{CLASS_DIR}/#{file.context.module_name}.html\")\n            break\n          end\n        end\n      end\n\n      unless ref\n        $stderr.puts \"Couldn't find anything to document\"\n        $stderr.puts \"Perhaps you've used :stopdoc: in all classes\"\n        exit(1)\n      end\n\n      ref\n    end", "label": 4}
{"code": "function baseParseLine(line, strict) {\n  const fields = String(line).replace(/(?:\\r?\\n)+$/, '').split('\\t');\n  const record = {};\n\n  for (let i = 0, len = fields.length; i < len; ++i) {\n    const _splitField = splitField(fields[i], strict),\n          label = _splitField.label,\n          value = _splitField.value;\n\n    record[label] = value;\n  }\n\n  return record;\n}", "label": 3}
{"code": "func Remember(index Index, keys []string, values []interface{}) {\n\tfor i, k := range keys {\n\t\tindex.Put(k, values[i])\n\t}\n\terr := index.NillableRet()\n\tif err != nil {\n\t\tlog.Fatalf(\"Woah! %v\", err)\n\t}\n\tif len(keys) > 0 && keys[0] == \"a\" {\n\t\tindex.Ellip(\"%d\", 0, 1, 1, 2, 3)\n\t\tindex.Ellip(\"%d\", 1, 3, 6, 10, 15)\n\t\tindex.EllipOnly(\"arg\")\n\t}\n}", "label": 5}
{"code": "public Object remove(String name) {\n\t\tThreadScopeContext context = ThreadScopeContextHolder.getContext();\n\t\treturn context.remove(name);\n\t}", "label": 0}
{"code": "def make_dbsource(**kwargs):\n    \"\"\"Returns a mapnik PostGIS or SQLite Datasource.\"\"\"\n    if 'spatialite' in connection.settings_dict.get('ENGINE'):\n        kwargs.setdefault('file', connection.settings_dict['NAME'])\n        return mapnik.SQLite(wkb_format='spatialite', **kwargs)\n    names = (('dbname', 'NAME'), ('user', 'USER'),\n             ('password', 'PASSWORD'), ('host', 'HOST'), ('port', 'PORT'))\n    for mopt, dopt in names:\n        val = connection.settings_dict.get(dopt)\n        if val:\n            kwargs.setdefault(mopt, val)\n    return mapnik.PostGIS(**kwargs)", "label": 1}
{"code": "def list(self):\n        \"\"\"\n        List the existing stacks in the indicated region\n\n        Args:\n            None\n\n        Returns:\n            True if True\n\n        Todo:\n            Figure out what could go wrong and take steps\n            to hanlde problems.\n        \"\"\"\n        self._initialize_list()\n        interested = True\n\n        response = self._cloudFormation.list_stacks()\n        print('Stack(s):')\n        while interested:\n            if 'StackSummaries' in response:\n                for stack in response['StackSummaries']:\n                    stack_status = stack['StackStatus']\n                    if stack_status != 'DELETE_COMPLETE':\n                        print('    [{}] - {}'.format(stack['StackStatus'], stack['StackName']))\n\n            next_token = response.get('NextToken', None)\n            if next_token:\n                response = self._cloudFormation.list_stacks(NextToken=next_token)\n            else:\n                interested = False\n\n        return True", "label": 1}
{"code": "def start_recv(sockfile=None):\n    '''Open a server on Unix Domain Socket'''\n\n    if sockfile is not None:\n        SOCKFILE = sockfile\n    else:\n        # default sockfile\n        SOCKFILE = \"/tmp/snort_alert\"\n\n    if os.path.exists(SOCKFILE):\n        os.unlink(SOCKFILE)\n    unsock = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)\n    unsock.bind(SOCKFILE)\n    logging.warning('Unix socket start listening...')\n    while True:\n        data = unsock.recv(BUFSIZE)\n        parsed_msg = alert.AlertPkt.parser(data)\n        if parsed_msg:\n            yield parsed_msg", "label": 1}
{"code": "protected function resolveCarbon($date = null)\n    {\n        if (!$date) {\n            return $this->nowWithSameTz();\n        }\n\n        if (is_string($date)) {\n            return static::parse($date, $this->getTimezone());\n        }\n\n        static::expectDateTime($date, ['null', 'string']);\n\n        return $date instanceof self ? $date : static::instance($date);\n    }", "label": 2}
{"code": "protected FieldDescriptor resolvePayloadField(Message message) {\n        for (FieldDescriptor field : message.getDescriptorForType().getFields()) {\n            if (message.hasField(field)) {\n                return field;\n            }\n        }\n\n        throw new RuntimeException(\"No payload found in message \" + message);\n    }", "label": 0}
{"code": "function html(req, res) {\n  fs.readFile(path.join(__dirname, 'index.html'), function read(err, file) {\n    if (err) throw err;\n\n    res.setHeader('Content-Length', file.length);\n    res.writeHead(200, { 'Content-Type': 'text/html' });\n\n    res.end(file);\n  });\n}", "label": 3}
{"code": "private void checkId(FieldDescriptorDef fieldDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        String id = fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_ID);\r\n\r\n        if ((id != null) && (id.length() > 0))\r\n        {\r\n            try\r\n            {\r\n                Integer.parseInt(id);\r\n            }\r\n            catch (NumberFormatException ex)\r\n            {\r\n                throw new ConstraintException(\"The id attribute of field \"+fieldDef.getName()+\" in class \"+fieldDef.getOwner().getName()+\" is not a valid number\");\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def detect_actual_closed_dates(issues)\n      print \"Fetching closed dates for issues...\\r\" if options[:verbose]\n\n      i = 0\n      issues.each do |issue|\n        find_closed_date_by_commit(issue)\n        i += 1\n      end\n      puts \"Fetching closed dates for issues: #{i}/#{issues.count}\" if options[:verbose]\n    end", "label": 4}
{"code": "def _get_load_ramping_construct(self):\n        \"\"\" Returns a construct for an array of load ramping data.\n        \"\"\"\n        bus_no = integer.setResultsName(\"bus_no\")\n        s_rating = real.setResultsName(\"s_rating\") # MVA\n        up_rate = real.setResultsName(\"up_rate\") # p.u./h\n        down_rate = real.setResultsName(\"down_rate\") # p.u./h\n        min_up_time = real.setResultsName(\"min_up_time\") # min\n        min_down_time = real.setResultsName(\"min_down_time\") # min\n        n_period_up = integer.setResultsName(\"n_period_up\")\n        n_period_down = integer.setResultsName(\"n_period_down\")\n        status = boolean.setResultsName(\"status\")\n\n        l_ramp_data = bus_no + s_rating + up_rate + down_rate + \\\n            min_up_time + min_down_time + n_period_up + \\\n            n_period_down + status + scolon\n\n        l_ramp_array = Literal(\"Rmpl.con\") + \"=\" + \"[\" + \\\n            ZeroOrMore(l_ramp_data + Optional(\"]\" + scolon))\n\n        return l_ramp_array", "label": 1}
{"code": "public Conditionals ifModifiedSince(LocalDateTime time) {\n        Preconditions.checkArgument(match.isEmpty(), String.format(ERROR_MESSAGE, HeaderConstants.IF_MODIFIED_SINCE, HeaderConstants.IF_MATCH));\n        Preconditions.checkArgument(!unModifiedSince.isPresent(), String.format(ERROR_MESSAGE, HeaderConstants.IF_MODIFIED_SINCE, HeaderConstants.IF_UNMODIFIED_SINCE));\n        time = time.withNano(0);\n        return new Conditionals(empty(), noneMatch, Optional.of(time), Optional.empty());\n    }", "label": 0}
{"code": "func (s *PresenceService) UpsertProxy(server services.Server) error {\n\treturn s.upsertServer(proxiesPrefix, server)\n}", "label": 5}
{"code": "def work\n      stat :attempting_lock_on, item_id: object_id\n      if @mutex.try_lock\n        stat :has_lock_on, item_id: object_id\n        chore\n        stat :releasing_lock_on, item_id: object_id\n        @mutex.unlock\n      else\n        stat :bailed_on, item_id: object_id\n      end\n    end", "label": 4}
{"code": "def pickle_dumps(inbox):\n    \"\"\"\n    Serializes the first element of the input using the pickle protocol using\n    the fastes binary protocol.\n    \n    \"\"\"\n    # http://bugs.python.org/issue4074\n    gc.disable()\n    str_ = cPickle.dumps(inbox[0], cPickle.HIGHEST_PROTOCOL)\n    gc.enable()\n    return str_", "label": 1}
{"code": "def save_as(path)\n      FileUtils.mkdir_p(path)\n      File.open(File.join(path, 'contents.xcworkspacedata'), 'w') do |out|\n        out << to_s\n      end\n    end", "label": 4}
{"code": "public function promise()\n    {\n        // If the promise has been created, just return it.\n        if (!$this->promise) {\n            // Create an upload/download promise for the transfer.\n            $this->promise = $this->sourceMetadata['scheme'] === 'file'\n                ? $this->createUploadPromise()\n                : $this->createDownloadPromise();\n        }\n\n        return $this->promise;\n    }", "label": 2}
{"code": "def check_cwd\n      desired_encoding = @env.root_path.to_s.encoding\n      vagrant_cwd_filepath = @data_dir.join('vagrant_cwd')\n      vagrant_cwd = if File.exist?(vagrant_cwd_filepath)\n                      File.read(vagrant_cwd_filepath,\n                        external_encoding: desired_encoding\n                      ).chomp\n                    end\n\n      if !File.identical?(vagrant_cwd.to_s, @env.root_path.to_s)\n        if vagrant_cwd\n          ui.warn(I18n.t(\n            'vagrant.moved_cwd',\n            old_wd:     \"#{vagrant_cwd}\",\n            current_wd: \"#{@env.root_path.to_s}\"))\n        end\n        File.write(vagrant_cwd_filepath, @env.root_path.to_s,\n          external_encoding: desired_encoding\n        )\n      end\n    end", "label": 4}
{"code": "public static void validate(final Module module) {\n        if (null == module) {\n            throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                .entity(\"Module cannot be null!\")\n                .build());\n        }\n        if(module.getName() == null ||\n                module.getName().isEmpty()){\n            throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                    .entity(\"Module name cannot be null or empty!\")\n                    .build());\n        }\n        if(module.getVersion()== null ||\n                module.getVersion().isEmpty()){\n            throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                    .entity(\"Module version cannot be null or empty!\")\n                    .build());\n        }\n\n        // Check artifacts\n        for(final Artifact artifact: DataUtils.getAllArtifacts(module)){\n            validate(artifact);\n        }\n\n        // Check dependencies\n        for(final Dependency dependency: DataUtils.getAllDependencies(module)){\n            validate(dependency.getTarget());\n        }\n    }", "label": 0}
{"code": "func (s *APIServer) deleteProxy(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tname := p.ByName(\"name\")\n\tif name == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing proxy name\")\n\t}\n\terr := auth.DeleteProxy(name)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn message(\"ok\"), nil\n}", "label": 5}
{"code": "def doOutages(self):\n        \"\"\" Applies branch outtages.\n        \"\"\"\n        assert len(self.branchOutages) == len(self.market.case.branches)\n\n        weights = [[(False, r), (True, 1 - (r))] for r in self.branchOutages]\n\n        for i, ln in enumerate(self.market.case.branches):\n            ln.online = weighted_choice(weights[i])\n            if ln.online == False:\n                print \"Branch outage [%s] in period %d.\" %(ln.name,self.stepid)", "label": 1}
{"code": "function ZDuplex(options) {\n\tif(options) {\n\t\tif(options.objectMode) {\n\t\t\toptions.readableObjectMode = true;\n\t\t\toptions.writableObjectMode = true;\n\t\t}\n\t\tif(options.readableObjectMode && options.writableObjectMode) {\n\t\t\toptions.objectMode = true;\n\t\t}\n\t\t//Add support for iojs simplified stream constructor\n\t\tif(typeof options.read === 'function') {\n\t\t\tthis._read = options.read;\n\t\t}\n\t\tif(typeof options.write === 'function') {\n\t\t\tthis._write = options.write;\n\t\t}\n\t\tif(typeof options.flush === 'function') {\n\t\t\tthis._flush = options.flush;\n\t\t}\n\t}\n\tDuplex.call(this, options);\n\n\t// Register listeners for finish (v0.10) and prefinish (v0.12) to run _duplexPrefinish\n\tthis._duplexFinished = false;\n\tthis.once('finish', this._duplexPrefinish.bind(this));\n\tthis.once('prefinish', this._duplexPrefinish.bind(this));\n\n\t// note: exclamation marks are used to convert to booleans\n\tif(options && !options.objectMode && (!options.readableObjectMode) !== (!options.writableObjectMode)) {\n\t\tthis._writableState.objectMode = !!options.writableObjectMode;\n\t\tthis._readableState.objectMode = !!options.readableObjectMode;\n\t}\n\tif(options && options.readableObjectMode) {\n\t\tthis._readableState.highWaterMark = 16;\n\t}\n\tif(options && options.writableObjectMode) {\n\t\tthis._writableState.highWaterMark = 16;\n\t}\n\tstreamMixins.call(this, Duplex.prototype, options);\n\treadableMixins.call(this, options);\n\twritableMixins.call(this, options);\n}", "label": 3}
{"code": "func (a *ArgType) ForeignKeyName(fkMap map[string]*ForeignKey, fk *ForeignKey) string {\n\treturn fkName(*a.ForeignKeyMode, fkMap, fk)\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, sslocspresponder resource) throws Exception {\n\t\tsslocspresponder addresource = new sslocspresponder();\n\t\taddresource.name = resource.name;\n\t\taddresource.url = resource.url;\n\t\taddresource.cache = resource.cache;\n\t\taddresource.cachetimeout = resource.cachetimeout;\n\t\taddresource.batchingdepth = resource.batchingdepth;\n\t\taddresource.batchingdelay = resource.batchingdelay;\n\t\taddresource.resptimeout = resource.resptimeout;\n\t\taddresource.respondercert = resource.respondercert;\n\t\taddresource.trustresponder = resource.trustresponder;\n\t\taddresource.producedattimeskew = resource.producedattimeskew;\n\t\taddresource.signingcert = resource.signingcert;\n\t\taddresource.usenonce = resource.usenonce;\n\t\taddresource.insertclientcert = resource.insertclientcert;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function normalize(obj) {\n  if (obj === null || typeof obj !== 'object') {\n    return JSON.stringify(obj);\n  }\n  if (obj instanceof Array) {\n    return '[' + obj.map(normalize).join(', ') + ']';\n  }\n  var answer = '{';\n  for (var key of Object.keys(obj).sort()) {\n    answer += key + ': ';\n    answer += normalize(obj[key]);\n    answer += ', ';\n  }\n  answer += '}';\n  return answer;\n}", "label": 3}
{"code": "def notice_contents\n      Dir.glob(dir_path.join(\"*\"))\n         .grep(LEGAL_FILES_PATTERN)\n         .select { |path| File.file?(path) }\n         .sort # sorted by the path\n         .map { |path| { \"sources\" => normalize_source_path(path), \"text\" => File.read(path).rstrip } }\n         .select { |notice| notice[\"text\"].length > 0 } # files with content only\n    end", "label": 4}
{"code": "public static <E> Set<E> retainBelow(Counter<E> counter, double countMaxThreshold) {\r\n    Set<E> removed = new HashSet<E>();\r\n    for (E key : counter.keySet()) {\r\n      if (counter.getCount(key) > countMaxThreshold) {\r\n        removed.add(key);\r\n      }\r\n    }\r\n    for (E key : removed) {\r\n      counter.remove(key);\r\n    }\r\n    return removed;\r\n  }", "label": 0}
{"code": "func ReadOrMakeHostUUID(dataDir string) (string, error) {\n\tid, err := ReadHostUUID(dataDir)\n\tif err == nil {\n\t\treturn id, nil\n\t}\n\tif !trace.IsNotFound(err) {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\tid = uuid.New()\n\tif err = WriteHostUUID(dataDir, id); err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\treturn id, nil\n}", "label": 5}
{"code": "def get_enroll(self):\n        \"\"\"Returns new enroll seed\"\"\"\n\n        devices = [DeviceRegistration.wrap(device) for device in self.__get_u2f_devices()]\n        enroll  = start_register(self.__appid, devices)\n        enroll['status'] = 'ok'\n\n        session['_u2f_enroll_'] = enroll.json\n        return enroll", "label": 1}
{"code": "public static String serialize(final Object obj) throws IOException {\n\t\tfinal ObjectMapper mapper = new ObjectMapper();\n        mapper.disable(MapperFeature.USE_GETTERS_AS_SETTERS);\n\t\treturn mapper.writeValueAsString(obj);\n\t\t\n\t}", "label": 0}
{"code": "public static systemeventhistory[] get(nitro_service service, systemeventhistory_args args) throws Exception{\n\t\tsystemeventhistory obj = new systemeventhistory();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tsystemeventhistory[] response = (systemeventhistory[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func ParseCertificatePEM(bytes []byte) (*x509.Certificate, error) {\n\tblock, _ := pem.Decode(bytes)\n\tif block == nil {\n\t\treturn nil, trace.BadParameter(\"expected PEM-encoded block\")\n\t}\n\tcert, err := x509.ParseCertificate(block.Bytes)\n\tif err != nil {\n\t\treturn nil, trace.BadParameter(err.Error())\n\t}\n\treturn cert, nil\n}", "label": 5}
{"code": "def histogram(fg = 'white', bg = 'black')\n      red   = Array.new(HISTOGRAM_COLS, 0)\n      green = Array.new(HISTOGRAM_COLS, 0)\n      blue  = Array.new(HISTOGRAM_COLS, 0)\n      alpha = Array.new(HISTOGRAM_COLS, 0)\n      int   = Array.new(HISTOGRAM_COLS, 0)\n\n      rows.times do |row|\n        pixels = get_pixels(0, row, columns, 1)\n        pixels.each do |pixel|\n          red[pixel.red & MAX_QUANTUM] += 1\n          green[pixel.green & MAX_QUANTUM] += 1\n          blue[pixel.blue & MAX_QUANTUM] += 1\n\n          # Only count opacity channel if some pixels are not opaque.\n          alpha[pixel.opacity & MAX_QUANTUM] += 1 unless opaque?\n          v = pixel_intensity(pixel)\n          int[v] += 1\n        end\n      end\n\n      # Scale to chart size. When computing the scale, add some \"air\" between\n      # the max frequency and the top of the histogram. This makes a prettier chart.\n      # The RGBA and intensity histograms are all drawn to the same scale.\n\n      max = [red.max, green.max, blue.max, alpha.max, int.max].max\n      scale = HISTOGRAM_ROWS / (max * AIR_FACTOR)\n\n      charts = ImageList.new\n\n      # Add the thumbnail.\n      thumb = copy\n      thumb['Label'] = File.basename(filename)\n      charts << thumb\n\n      # Compute the channel and intensity histograms.\n      channel_hists = channel_histograms(red, green, blue, int, scale, fg, bg)\n\n      # Add the red, green, and blue histograms to the list\n      charts << channel_hists.shift\n      charts << channel_hists.shift\n      charts << channel_hists.shift\n\n      # Add Alpha channel or image stats\n      charts << if !opaque?\n                  alpha_hist(alpha, scale, fg, bg)\n                else\n                  info_text(fg, bg)\n                end\n\n      # Add the RGB histogram\n      charts << channel_hists.shift\n\n      # Add the intensity histogram.\n      charts << intensity_hist(channel_hists.shift)\n\n      # Add the color frequency histogram.\n      charts << color_hist(fg, bg)\n\n      # Make a montage.\n      histogram = charts.montage do\n        self.background_color = bg\n        self.stroke = 'transparent'\n        self.fill = fg\n        self.border_width = 1\n        self.tile         = '4x2'\n        self.geometry     = \"#{HISTOGRAM_COLS}x#{HISTOGRAM_ROWS}+10+10\"\n      end\n\n      histogram\n    end", "label": 4}
{"code": "private function getOrgAndRepo(array $composer)\n    {\n        $target = $composer['target'];\n\n        $matches = [];\n        preg_match(self::TARGET_REGEX, $target, $matches);\n\n        $org = $matches[1];\n        $repo = $matches[2];\n\n        return [$org, $repo];\n    }", "label": 2}
{"code": "def unlock(self, store=True):\n        \"\"\"Unlocks the achievement.\n\n\n        :param bool store: Whether to send data to server immediately (as to get overlay notification).\n        :rtype: bool\n\n        \"\"\"\n        result = self._iface.ach_unlock(self.name)\n        result and store and self._store()\n        return result", "label": 1}
{"code": "def with_cardinality(cls, cardinality, converter, pattern=None,\n                         listsep=','):\n        \"\"\"Creates a type converter for the specified cardinality\n        by using the type converter for T.\n\n        :param cardinality: Cardinality to use (0..1, 0..*, 1..*).\n        :param converter: Type converter (function) for data type T.\n        :param pattern:  Regexp pattern for an item (=converter.pattern).\n        :return: type-converter for optional<T> (T or None).\n        \"\"\"\n        if cardinality is Cardinality.one:\n            return converter\n        # -- NORMAL-CASE\n        builder_func = getattr(cls, \"with_%s\" % cardinality.name)\n        if cardinality is Cardinality.zero_or_one:\n            return builder_func(converter, pattern)\n        else:\n            # -- MANY CASE: 0..*, 1..*\n            return builder_func(converter, pattern, listsep=listsep)", "label": 1}
{"code": "function(eventHash) {\n      // coped from Backbone\n      var delegateEventSplitter = /^(\\S+)\\s*(.*)$/;\n      var namespacedEvents = {};\n      var behaviorId = this.cid;\n      _.each(eventHash, function(value, key) {\n        var splitEventKey = key.match(delegateEventSplitter);\n        var eventName = splitEventKey[1];\n        var selector = splitEventKey[2];\n        var namespacedEventName = eventName + '.behavior.' + behaviorId;\n        namespacedEvents[[namespacedEventName, selector].join(' ')] = value;\n      });\n      return namespacedEvents;\n    }", "label": 3}
{"code": "function exists(cmd) {\n  return run(`which ${cmd}`).then(stdout => {\n    if (stdout.trim().length === 0) {\n      // maybe an empty command was supplied?\n      // are we running on Windows??\n      return Promise.reject(new Error(\"No output\"));\n    }\n\n    const rNotFound = /^[\\w\\-]+ not found/g;\n\n    if (rNotFound.test(cmd)) {\n      return Promise.resolve(false);\n    }\n\n    return Promise.resolve(true);\n  });\n}", "label": 3}
{"code": "function update(req, res, next) {\n  var options = req.connectionOptions;\n  req.appformsResultPayload = req.appformsResultPayload || {};\n\n  var params = {\n    userEmail: req.user.email\n  };\n\n  options = _.extend(options, params);\n\n  var form = req.body;\n\n  if (_.isObject(req.appformsResultPayload.data) && !req.body._id) {\n    form = req.appformsResultPayload.data;\n  }\n\n  logger.debug(\"Middleware: Update form: \", {options: options, form: form});\n\n  forms.updateForm(options, form, formsResultHandlers(constants.resultTypes.forms, req, next));\n}", "label": 3}
{"code": "public List<String> getModuleVersions(final String name, final FiltersHolder filters) {\n        final List<String> versions = repositoryHandler.getModuleVersions(name, filters);\n\n        if (versions.isEmpty()) {\n            throw new WebApplicationException(Response.status(Response.Status.NOT_FOUND)\n                    .entity(\"Module \" + name + \" does not exist.\").build());\n        }\n\n        return versions;\n    }", "label": 0}
{"code": "function(computedAlias) {\n      var hasAllModels = true,\n        config = this.getMapping(computedAlias),\n        modelConfigs = [];\n      _.each(this.__getModelAliases(computedAlias), function(modelAlias) {\n        var modelConfig = this.__createModelConfig(modelAlias, config.mapping[modelAlias]);\n        if (modelConfig) {\n          modelConfigs.push(modelConfig);\n        } else {\n          hasAllModels = false;\n        }\n      }, this);\n      return hasAllModels ? modelConfigs : undefined;\n    }", "label": 3}
{"code": "public static nspbr6_stats get(nitro_service service, String name) throws Exception{\n\t\tnspbr6_stats obj = new nspbr6_stats();\n\t\tobj.set_name(name);\n\t\tnspbr6_stats response = (nspbr6_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (t *Torrent) addConnection(c *connection) (err error) {\n\tdefer func() {\n\t\tif err == nil {\n\t\t\ttorrent.Add(\"added connections\", 1)\n\t\t}\n\t}()\n\tif t.closed.IsSet() {\n\t\treturn errors.New(\"torrent closed\")\n\t}\n\tfor c0 := range t.conns {\n\t\tif c.PeerID != c0.PeerID {\n\t\t\tcontinue\n\t\t}\n\t\tif !t.cl.config.dropDuplicatePeerIds {\n\t\t\tcontinue\n\t\t}\n\t\tif left, ok := c.hasPreferredNetworkOver(c0); ok && left {\n\t\t\tc0.Close()\n\t\t\tt.deleteConnection(c0)\n\t\t} else {\n\t\t\treturn errors.New(\"existing connection preferred\")\n\t\t}\n\t}\n\tif len(t.conns) >= t.maxEstablishedConns {\n\t\tc := t.worstBadConn()\n\t\tif c == nil {\n\t\t\treturn errors.New(\"don't want conns\")\n\t\t}\n\t\tc.Close()\n\t\tt.deleteConnection(c)\n\t}\n\tif len(t.conns) >= t.maxEstablishedConns {\n\t\tpanic(len(t.conns))\n\t}\n\tt.conns[c] = struct{}{}\n\treturn nil\n}", "label": 5}
{"code": "def fix_tree(tree, a_id_lookup, out):\n    \"\"\"\n    get the names for sequences in the raxml tree\n    \"\"\"\n    if check(out) is False and check(tree) is True:\n        tree = open(tree).read()\n        for line in open(a_id_lookup):\n            id, name, header = line.strip().split('\\t')\n            tree = tree.replace(id+':', name+':')\n        out_f = open(out, 'w')\n        print(tree.strip(), file=out_f)\n    return out", "label": 1}
{"code": "function removeRolePrivilege (access, role, privilege) {\n  if (role === true) {\n    access[privilege] = {\n      role: []\n    }\n    return\n  }\n\n  if (access[privilege].role === true) {\n    access[privilege].role = true\n  }\n\n  _.pullAll(access[privilege].role, _.concat(role))\n}", "label": 3}
{"code": "function reduceVal(conf, val) {\n  val = val.call(conf);\n  return typeof val === 'function' ? reduceVal(conf, val) : val;\n}", "label": 3}
{"code": "def run(self):\n        \"\"\" Find and load step definitions, and them find and load\n        features under `base_path` specified on constructor\n        \"\"\"\n        try:\n            self.loader.find_and_load_step_definitions()\n        except StepLoadingError, e:\n            print \"Error loading step definitions:\\n\", e\n            return\n\n        results = []\n        if self.explicit_features:\n            features_files = self.explicit_features\n        else:\n            features_files = self.loader.find_feature_files()\n        if self.random:\n            random.shuffle(features_files)\n\n        if not features_files:\n            self.output.print_no_features_found(self.loader.base_dir)\n            return\n\n        processes = Pool(processes=self.parallelization)\n        test_results_it = processes.imap_unordered(\n            worker_process, [(self, filename) for filename in features_files]\n        )\n        \n        all_total = ParallelTotalResult()\n        for result in test_results_it:\n            all_total += result['total']\n            sys.stdout.write(result['stdout'])\n            sys.stderr.write(result['stderr'])\n\n        return all_total", "label": 1}
{"code": "final public void setRealOffset(Integer start, Integer end) {\n    if ((start == null) || (end == null)) {\n      // do nothing\n    } else if (start > end) {\n      throw new IllegalArgumentException(\n          \"Start real offset after end real offset\");\n    } else {\n      tokenRealOffset = new MtasOffset(start, end);\n    }\n  }", "label": 0}
{"code": "function defaultHandler(command) {\n        debug(`executing default handler for unrecognized command ${command.commandText}`);\n        if (!command.mention) {\n            command.reply(`Command \\`${command.command}\\` is not recognized`);\n        }\n        return Promise.resolve();\n    }", "label": 3}
{"code": "function process(advertiserData) {\n  var snfBeacon = {};\n  var data = advertiserData.manufacturerSpecificData.data;\n\n  snfBeacon.type = 'V2 Single Payload';\n  snfBeacon.id = pdu.reverseBytes(data.substr(2,16));\n  snfBeacon.time = parseInt(pdu.reverseBytes(data.substr(18,8)),16);\n  snfBeacon.scanCount = parseInt(data.substr(26,2),16) / 4;\n  snfBeacon.batteryVoltage = data.substr(28,2);\n  snfBeacon.temperature = parseInt(data.substr(30,2),16);\n  if(snfBeacon.temperature > 127) {\n    snfBeacon.temperature = 127 - snfBeacon.temperature;\n  }\n  snfBeacon.temperature += (parseInt(data.substr(26,2),16) % 4) / 4;\n  snfBeacon.calibration = data.substr(32,2);\n  snfBeacon.checksum = data.substr(34,6);\n\n  advertiserData.manufacturerSpecificData.snfBeacon = snfBeacon;\n}", "label": 3}
{"code": "def rubocop_checksum\n      ResultCache.source_checksum ||=\n        begin\n          lib_root = File.join(File.dirname(__FILE__), '..')\n          exe_root = File.join(lib_root, '..', 'exe')\n\n          # These are all the files we have `require`d plus everything in the\n          # exe directory. A change to any of them could affect the cop output\n          # so we include them in the cache hash.\n          source_files = $LOADED_FEATURES + Find.find(exe_root).to_a\n          sources = source_files\n                    .select { |path| File.file?(path) }\n                    .sort\n                    .map { |path| IO.read(path, encoding: Encoding::UTF_8) }\n          Digest::SHA1.hexdigest(sources.join)\n        end\n    end", "label": 4}
{"code": "func (c *Client) CreateUserWithU2FToken(token string, password string, u2fRegisterResponse u2f.RegisterResponse) (services.WebSession, error) {\n\tout, err := c.PostJSON(c.Endpoint(\"u2f\", \"users\"), createUserWithU2FTokenReq{\n\t\tToken:               token,\n\t\tPassword:            password,\n\t\tU2FRegisterResponse: u2fRegisterResponse,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.GetWebSessionMarshaler().UnmarshalWebSession(out.Bytes())\n}", "label": 5}
{"code": "def normalize_posts_meta(hash)\n      hash[\"posts\"] ||= {}\n      hash[\"posts\"][\"path\"] ||= config[\"path\"]\n      hash[\"posts\"][\"categories\"] ||= config[\"categories\"]\n      config[\"path\"] ||= hash[\"posts\"][\"path\"]\n      hash\n    end", "label": 4}
{"code": "def trim_sequences(variant_sequence, reference_context):\n    \"\"\"\n    A VariantSequence and ReferenceContext may contain a different number of\n    nucleotides before the variant locus. Furthermore, the VariantSequence is\n    always expressed in terms of the positive strand against which it aligned,\n    but reference transcripts may have sequences from the negative strand of the\n    genome. Take the reverse complement of the VariantSequence if the\n    ReferenceContext is from negative strand transcripts and trim either\n    sequence to ensure that the prefixes are of the same length.\n\n    Parameters\n    ----------\n    variant_sequence : VariantSequence\n\n    reference_context : ReferenceContext\n\n    Returns a tuple with the following fields:\n        1) cDNA prefix of variant sequence, trimmed to be same length as the\n           reference prefix. If the reference context was on the negative\n           strand then this is the trimmed sequence *after* the variant from\n           the genomic DNA sequence.\n        2) cDNA sequence of the variant nucleotides, in reverse complement if\n           the reference context is on the negative strand.\n        3) cDNA sequence of the nucleotides after the variant nucleotides. If\n           the reference context is on the negative strand then this sequence\n           is the reverse complement of the original prefix sequence.\n        4) Reference sequence before the variant locus, trimmed to be the\n           same length as the variant prefix.\n        5) Reference sequence after the variant locus, untrimmed.\n        6) Number of nucleotides trimmed from the reference sequence, used\n           later for adjustint offset to first complete codon.\n    \"\"\"\n    cdna_prefix = variant_sequence.prefix\n    cdna_alt = variant_sequence.alt\n    cdna_suffix = variant_sequence.suffix\n\n    # if the transcript is on the reverse strand then we have to\n    # take the sequence PREFIX|VARIANT|SUFFIX\n    # and take the complement of XIFFUS|TNAIRAV|XIFERP\n    if reference_context.strand == \"-\":\n        # notice that we are setting the *prefix* to be reverse complement\n        # of the *suffix* and vice versa\n        cdna_prefix, cdna_alt, cdna_suffix = (\n            reverse_complement_dna(cdna_suffix),\n            reverse_complement_dna(cdna_alt),\n            reverse_complement_dna(cdna_prefix)\n        )\n\n    reference_sequence_before_variant = reference_context.sequence_before_variant_locus\n    reference_sequence_after_variant = reference_context.sequence_after_variant_locus\n\n    # trim the reference prefix and the RNA-derived prefix sequences to the same length\n    if len(reference_sequence_before_variant) > len(cdna_prefix):\n        n_trimmed_from_reference = len(reference_sequence_before_variant) - len(cdna_prefix)\n        n_trimmed_from_variant = 0\n    elif len(reference_sequence_before_variant) < len(cdna_prefix):\n        n_trimmed_from_variant = len(cdna_prefix) - len(reference_sequence_before_variant)\n        n_trimmed_from_reference = 0\n    else:\n        n_trimmed_from_variant = 0\n        n_trimmed_from_reference = 0\n\n    reference_sequence_before_variant = reference_sequence_before_variant[\n        n_trimmed_from_reference:]\n    cdna_prefix = cdna_prefix[n_trimmed_from_variant:]\n\n    return (\n        cdna_prefix,\n        cdna_alt,\n        cdna_suffix,\n        reference_sequence_before_variant,\n        reference_sequence_after_variant,\n        n_trimmed_from_reference\n    )", "label": 1}
{"code": "func (cl *Client) forSkeys(f func([]byte) bool) {\n\tcl.lock()\n\tdefer cl.unlock()\n\tfor ih := range cl.torrents {\n\t\tif !f(ih[:]) {\n\t\t\tbreak\n\t\t}\n\t}\n}", "label": 5}
{"code": "def namespace_for_prefix(self, prefix):\n        \"\"\"Get the namespace the given prefix maps to.\n\n        Args:\n            prefix (str): The prefix\n\n        Returns:\n            str: The namespace, or None if the prefix isn't mapped to\n                anything in this set.\n        \"\"\"\n        try:\n            ni = self.__lookup_prefix(prefix)\n        except PrefixNotFoundError:\n            return None\n        else:\n            return ni.uri", "label": 1}
{"code": "public static base_response add(nitro_service client, autoscaleaction resource) throws Exception {\n\t\tautoscaleaction addresource = new autoscaleaction();\n\t\taddresource.name = resource.name;\n\t\taddresource.type = resource.type;\n\t\taddresource.profilename = resource.profilename;\n\t\taddresource.parameters = resource.parameters;\n\t\taddresource.vmdestroygraceperiod = resource.vmdestroygraceperiod;\n\t\taddresource.quiettime = resource.quiettime;\n\t\taddresource.vserver = resource.vserver;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public void fillRectangle(Rectangle rect, Color color) {\n\t\ttemplate.saveState();\n\t\tsetFill(color);\n\t\ttemplate.rectangle(origX + rect.getLeft(), origY + rect.getBottom(), rect.getWidth(), rect.getHeight());\n\t\ttemplate.fill();\n\t\ttemplate.restoreState();\n\t}", "label": 0}
{"code": "public static int[] Unique(int[] values) {\r\n        HashSet<Integer> lst = new HashSet<Integer>();\r\n        for (int i = 0; i < values.length; i++) {\r\n            lst.add(values[i]);\r\n        }\r\n\r\n        int[] v = new int[lst.size()];\r\n        Iterator<Integer> it = lst.iterator();\r\n        for (int i = 0; i < v.length; i++) {\r\n            v[i] = it.next();\r\n        }\r\n\r\n        return v;\r\n    }", "label": 0}
{"code": "func PgTriggerByOid(db XODB, oid pgtypes.Oid) (*PgTrigger, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, tgrelid, tgname, tgfoid, tgtype, tgenabled, tgisinternal, tgconstrrelid, tgconstrindid, tgconstraint, tgdeferrable, tginitdeferred, tgnargs, tgattr, tgargs, tgqual ` +\n\t\t`FROM pg_catalog.pg_trigger ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpt := PgTrigger{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pt.Tableoid, &pt.Cmax, &pt.Xmax, &pt.Cmin, &pt.Xmin, &pt.Oid, &pt.Ctid, &pt.Tgrelid, &pt.Tgname, &pt.Tgfoid, &pt.Tgtype, &pt.Tgenabled, &pt.Tgisinternal, &pt.Tgconstrrelid, &pt.Tgconstrindid, &pt.Tgconstraint, &pt.Tgdeferrable, &pt.Tginitdeferred, &pt.Tgnargs, &pt.Tgattr, &pt.Tgargs, &pt.Tgqual)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pt, nil\n}", "label": 5}
{"code": "function errorSerializer (err) {\n  if (!err || !err.stack) return err\n  const obj = {\n    message: err.message,\n    name: err.name,\n    code: err.code,\n    stack: getErrorStack(err)\n  }\n  return obj\n}", "label": 3}
{"code": "func (c *Manager) DeleteTag(ctx context.Context, tag *Tag) error {\n\turl := internal.URL(c, internal.TagPath).WithID(tag.ID)\n\treturn c.Do(ctx, url.Request(http.MethodDelete), nil)\n}", "label": 5}
{"code": "def clean_time(time_string):\n    \"\"\"Return a datetime from the Amazon-provided datetime string\"\"\"\n    # Get a timezone-aware datetime object from the string\n    time = dateutil.parser.parse(time_string)\n    if not settings.USE_TZ:\n        # If timezone support is not active, convert the time to UTC and\n        # remove the timezone field\n        time = time.astimezone(timezone.utc).replace(tzinfo=None)\n    return time", "label": 1}
{"code": "func appStateInImmutablePod(app *v1.App, pod *pkgPod.Pod) error {\n\tapp.State = appStateFromPod(pod)\n\n\tt, err := pod.CreationTime()\n\tif err != nil {\n\t\treturn err\n\t}\n\tcreatedAt := t.UnixNano()\n\tapp.CreatedAt = &createdAt\n\n\tcode, err := pod.AppExitCode(app.Name)\n\tif err == nil {\n\t\t// there is an exit code, it is definitely Exited\n\t\tapp.State = v1.AppStateExited\n\t\texitCode := int32(code)\n\t\tapp.ExitCode = &exitCode\n\t}\n\n\tstart, err := pod.StartTime()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !start.IsZero() {\n\t\tstartedAt := start.UnixNano()\n\t\tapp.StartedAt = &startedAt\n\t}\n\t// the best we can guess for immutable pods\n\tfinish, err := pod.GCMarkedTime()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !finish.IsZero() {\n\t\tfinishedAt := finish.UnixNano()\n\t\tapp.FinishedAt = &finishedAt\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function checkSourceFileWorker(node) {\n            var links = getNodeLinks(node);\n            if (!(links.flags & 1 /* TypeChecked */)) {\n                // If skipLibCheck is enabled, skip type checking if file is a declaration file.\n                // If skipDefaultLibCheck is enabled, skip type checking if file contains a\n                // '/// <reference no-default-lib=\"true\"/>' directive.\n                if (compilerOptions.skipLibCheck && node.isDeclarationFile || compilerOptions.skipDefaultLibCheck && node.hasNoDefaultLib) {\n                    return;\n                }\n                // Grammar checking\n                checkGrammarSourceFile(node);\n                potentialThisCollisions.length = 0;\n                deferredNodes = [];\n                deferredUnusedIdentifierNodes = produceDiagnostics && noUnusedIdentifiers ? [] : undefined;\n                ts.forEach(node.statements, checkSourceElement);\n                checkDeferredNodes();\n                if (ts.isExternalModule(node)) {\n                    registerForUnusedIdentifiersCheck(node);\n                }\n                if (!node.isDeclarationFile) {\n                    checkUnusedIdentifiers();\n                }\n                deferredNodes = undefined;\n                deferredUnusedIdentifierNodes = undefined;\n                if (ts.isExternalOrCommonJsModule(node)) {\n                    checkExternalModuleExports(node);\n                }\n                if (potentialThisCollisions.length) {\n                    ts.forEach(potentialThisCollisions, checkIfThisIsCapturedInEnclosingScope);\n                    potentialThisCollisions.length = 0;\n                }\n                links.flags |= 1 /* TypeChecked */;\n            }\n        }", "label": 3}
{"code": "public function get_longdesc() {\n\t\t$shortdesc = $this->get_shortdesc();\n\t\tif ( ! $shortdesc ) {\n\t\t\treturn '';\n\t\t}\n\n\t\t$longdesc = substr( $this->doc_comment, strlen( $shortdesc ) );\n\n\t\t$lines = array();\n\t\tforeach ( explode( \"\\n\", $longdesc ) as $line ) {\n\t\t\tif ( 0 === strpos( $line, '@' ) ) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t$lines[] = $line;\n\t\t}\n\t\t$longdesc = trim( implode( $lines, \"\\n\" ) );\n\n\t\treturn $longdesc;\n\t}", "label": 2}
{"code": "func UnmarshalBody(typeFunc func(string) (reflect.Type, bool), data []byte) (*Method, error) {\n\tbody := &Element{typeFunc: typeFunc}\n\treq := soap.Envelope{\n\t\tHeader: &soap.Header{\n\t\t\tSecurity: new(Element),\n\t\t},\n\t\tBody: body,\n\t}\n\n\terr := xml.Unmarshal(data, &req)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"xml.Unmarshal: %s\", err)\n\t}\n\n\tvar start xml.StartElement\n\tvar ok bool\n\tdecoder := body.decoder()\n\n\tfor {\n\t\ttok, derr := decoder.Token()\n\t\tif derr != nil {\n\t\t\treturn nil, fmt.Errorf(\"decoding: %s\", derr)\n\t\t}\n\t\tif start, ok = tok.(xml.StartElement); ok {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"decoding: method token not found\")\n\t}\n\n\tkind := start.Name.Local\n\trtype, ok := typeFunc(kind)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"no vmomi type defined for '%s'\", kind)\n\t}\n\n\tval := reflect.New(rtype).Interface()\n\n\terr = decoder.DecodeElement(val, &start)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"decoding %s: %s\", kind, err)\n\t}\n\n\tmethod := &Method{Name: kind, Header: *req.Header, Body: val}\n\n\tfield := reflect.ValueOf(val).Elem().FieldByName(\"This\")\n\n\tmethod.This = field.Interface().(types.ManagedObjectReference)\n\n\treturn method, nil\n}", "label": 5}
{"code": "public function getSentinelConnection()\n    {\n        if (!$this->sentinelConnection) {\n            if (!$this->sentinels) {\n                throw new \\Predis\\ClientException('No sentinel server available for autodiscovery.');\n            }\n\n            $sentinel = array_shift($this->sentinels);\n            $this->sentinelConnection = $this->createSentinelConnection($sentinel);\n        }\n\n        return $this->sentinelConnection;\n    }", "label": 2}
{"code": "func UnmarshalProvisionToken(data []byte, opts ...MarshalOption) (ProvisionToken, error) {\n\tif len(data) == 0 {\n\t\treturn nil, trace.BadParameter(\"missing provision token data\")\n\t}\n\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tvar h ResourceHeader\n\terr = utils.FastUnmarshal(data, &h)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tswitch h.Version {\n\tcase \"\":\n\t\tvar p ProvisionTokenV1\n\t\terr := utils.FastUnmarshal(data, &p)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tv2 := p.V2()\n\t\tif cfg.ID != 0 {\n\t\t\tv2.SetResourceID(cfg.ID)\n\t\t}\n\t\treturn v2, nil\n\tcase V2:\n\t\tvar p ProvisionTokenV2\n\t\tif cfg.SkipValidation {\n\t\t\tif err := utils.FastUnmarshal(data, &p); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t} else {\n\t\t\tif err := utils.UnmarshalWithSchema(GetProvisionTokenSchema(), &p, data); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t}\n\t\tif err := p.CheckAndSetDefaults(); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tif cfg.ID != 0 {\n\t\t\tp.SetResourceID(cfg.ID)\n\t\t}\n\t\treturn &p, nil\n\t}\n\treturn nil, trace.BadParameter(\"server resource version %v is not supported\", h.Version)\n}", "label": 5}
{"code": "func MkdirAll(targetDirectory string, mode os.FileMode) error {\n\terr := os.MkdirAll(targetDirectory, mode)\n\tif err != nil {\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def write(self, data):\n        \"\"\"Writes json data to the output directory.\"\"\"\n        cnpj, data = data\n\n        path = os.path.join(self.output, '%s.json' % cnpj)\n        with open(path, 'w') as f:\n            json.dump(data, f, encoding='utf-8')", "label": 1}
{"code": "public static base_response delete(nitro_service client, dnsaddrec resource) throws Exception {\n\t\tdnsaddrec deleteresource = new dnsaddrec();\n\t\tdeleteresource.hostname = resource.hostname;\n\t\tdeleteresource.ipaddress = resource.ipaddress;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "public void abortExternalTx(TransactionImpl odmgTrans)\r\n    {\r\n        if (log.isDebugEnabled()) log.debug(\"abortExternTransaction was called\");\r\n        if (odmgTrans == null) return;\r\n        TxBuffer buf = (TxBuffer) txRepository.get();\r\n        Transaction extTx = buf != null ? buf.getExternTx() : null;\r\n        try\r\n        {\r\n            if (extTx != null && extTx.getStatus() == Status.STATUS_ACTIVE)\r\n            {\r\n                if(log.isDebugEnabled())\r\n                {\r\n                    log.debug(\"Set extern transaction to rollback\");\r\n                }\r\n                extTx.setRollbackOnly();\r\n            }\r\n        }\r\n        catch (Exception ignore)\r\n        {\r\n        }\r\n        txRepository.set(null);\r\n    }", "label": 0}
{"code": "def save(filename=ConfigPath):\r\n    \"\"\"Saves this module's changed attributes to INI configuration.\"\"\"\r\n    default_values = defaults()\r\n    parser = configparser.RawConfigParser()\r\n    parser.optionxform = str # Force case-sensitivity on names\r\n    try:\r\n        save_types = basestring, int, float, tuple, list, dict, type(None)\r\n        for k, v in sorted(globals().items()):\r\n            if not isinstance(v, save_types) or k.startswith(\"_\") \\\r\n            or default_values.get(k, parser) == v: continue # for k, v\r\n            try: parser.set(\"DEFAULT\", k, json.dumps(v))\r\n            except Exception: pass\r\n        if parser.defaults():\r\n            with open(filename, \"wb\") as f:\r\n                f.write(\"# %s %s configuration written on %s.\\n\" % (Title, Version,\r\n                        datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\r\n                parser.write(f)\r\n        else: # Nothing to write: delete configuration file\r\n            try: os.unlink(filename)\r\n            except Exception: pass\r\n    except Exception:\r\n        logging.warn(\"Error writing config to %s.\", filename, exc_info=True)", "label": 1}
{"code": "func (ts *Store) Hash(id string) (string, error) {\n\ttreepath := ts.GetPath(id)\n\n\thash := sha512.New()\n\tiw := newHashWriter(hash)\n\terr := filepath.Walk(treepath, buildWalker(treepath, iw))\n\tif err != nil {\n\t\treturn \"\", errwrap.Wrap(errors.New(\"error walking rootfs\"), err)\n\t}\n\n\thashstring := hashToKey(hash)\n\n\treturn hashstring, nil\n}", "label": 5}
{"code": "private function normalizeExpiration($expires)\n    {\n        if ($expires instanceof Timestamp) {\n            $seconds = $expires->get()->format('U');\n        } elseif ($expires instanceof \\DateTimeInterface) {\n            $seconds = $expires->format('U');\n        } elseif (is_numeric($expires)) {\n            $seconds = (int) $expires;\n        } else {\n            throw new \\InvalidArgumentException('Invalid expiration.');\n        }\n\n        return $seconds;\n    }", "label": 2}
{"code": "def der(self, x: Sym):\n        \"\"\"Get the derivative of the variable, create it if it doesn't exist.\"\"\"\n        name = 'der({:s})'.format(x.name())\n        if name not in self.scope['dvar'].keys():\n            self.scope['dvar'][name] = self.sym.sym(name, *x.shape)\n            self.scope['states'].append(x.name())\n        return self.scope['dvar'][name]", "label": 1}
{"code": "private void removeTimedOutLocks(long timeout)\r\n    {\r\n        int count = 0;\r\n        long maxAge = System.currentTimeMillis() - timeout;\r\n        boolean breakFromLoop = false;\r\n        ObjectLocks temp = null;\r\n    \tsynchronized (locktable)\r\n    \t{\r\n\t        Iterator it = locktable.values().iterator();\r\n\t        /**\r\n\t         * run this loop while:\r\n\t         * - we have more in the iterator\r\n\t         * - the breakFromLoop flag hasn't been set\r\n\t         * - we haven't removed more than the limit for this cleaning iteration.\r\n\t         */\r\n\t        while (it.hasNext() && !breakFromLoop && (count <= MAX_LOCKS_TO_CLEAN))\r\n\t        {\r\n\t        \ttemp = (ObjectLocks) it.next();\r\n\t        \tif (temp.getWriter() != null)\r\n\t        \t{\r\n\t\t        \tif (temp.getWriter().getTimestamp() < maxAge)\r\n\t\t        \t{\r\n\t\t        \t\t// writer has timed out, set it to null\r\n\t\t        \t\ttemp.setWriter(null);\r\n\t\t        \t}\r\n\t        \t}\r\n\t        \tif (temp.getYoungestReader() < maxAge)\r\n\t        \t{\r\n\t        \t\t// all readers are older than timeout.\r\n\t        \t\ttemp.getReaders().clear();\r\n\t        \t\tif (temp.getWriter() == null)\r\n\t        \t\t{\r\n\t        \t\t\t// all readers and writer are older than timeout,\r\n\t        \t\t\t// remove the objectLock from the iterator (which\r\n\t        \t\t\t// is backed by the map, so it will be removed.\r\n\t        \t\t\tit.remove();\r\n\t        \t\t}\r\n\t        \t}\r\n\t        \telse\r\n\t        \t{\r\n\t        \t\t// we need to walk each reader.\r\n\t        \t\tIterator readerIt = temp.getReaders().values().iterator();\r\n\t        \t\tLockEntry readerLock = null;\r\n\t        \t\twhile (readerIt.hasNext())\r\n\t        \t\t{\r\n\t        \t\t\treaderLock = (LockEntry) readerIt.next();\r\n\t        \t\t\tif (readerLock.getTimestamp() < maxAge)\r\n\t        \t\t\t{\r\n\t        \t\t\t\t// this read lock is old, remove it.\r\n\t        \t\t\t\treaderIt.remove();\r\n\t        \t\t\t}\r\n\t        \t\t}\r\n\t        \t}\r\n\t        \tcount++;\r\n\t        }\r\n    \t}\r\n    }", "label": 0}
{"code": "function abstractDegreeCentrality(assign, method, graph, options) {\n  var name = method + 'Centrality';\n\n  if (!isGraph(graph))\n    throw new Error('graphology-centrality/' + name + ': the given graph is not a valid graphology instance.');\n\n  if (method !== 'degree' && graph.type === 'undirected')\n    throw new Error('graphology-centrality/' + name + ': cannot compute ' + method + ' centrality on an undirected graph.');\n\n  // Solving options\n  options = options || {};\n\n  var attributes = options.attributes || {};\n\n  var centralityAttribute = attributes.centrality || name;\n\n  // Variables\n  var order = graph.order,\n      nodes = graph.nodes(),\n      getDegree = graph[method].bind(graph),\n      centralities = {};\n\n  if (order === 0)\n    return assign ? undefined : centralities;\n\n  var s = 1 / (order - 1);\n\n  // Iteration variables\n  var node,\n      centrality,\n      i;\n\n  for (i = 0; i < order; i++) {\n    node = nodes[i];\n    centrality = getDegree(node) * s;\n\n    if (assign)\n      graph.setNodeAttribute(node, centralityAttribute, centrality);\n    else\n      centralities[node] = centrality;\n  }\n\n  return assign ? undefined : centralities;\n}", "label": 3}
{"code": "func PgConversionByConnamespaceConforencodingContoencodingOid(db XODB, connamespace pgtypes.Oid, conforencoding int, contoencoding int, oid pgtypes.Oid) (*PgConversion, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, conname, connamespace, conowner, conforencoding, contoencoding, conproc, condefault ` +\n\t\t`FROM pg_catalog.pg_conversion ` +\n\t\t`WHERE connamespace = $1 AND conforencoding = $2 AND contoencoding = $3 AND oid = $4`\n\n\t// run query\n\tXOLog(sqlstr, connamespace, conforencoding, contoencoding, oid)\n\tpc := PgConversion{}\n\n\terr = db.QueryRow(sqlstr, connamespace, conforencoding, contoencoding, oid).Scan(&pc.Tableoid, &pc.Cmax, &pc.Xmax, &pc.Cmin, &pc.Xmin, &pc.Oid, &pc.Ctid, &pc.Conname, &pc.Connamespace, &pc.Conowner, &pc.Conforencoding, &pc.Contoencoding, &pc.Conproc, &pc.Condefault)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pc, nil\n}", "label": 5}
{"code": "public static boolean isPunct(String s){\r\n    Pattern p = Pattern.compile(\"^[\\\\p{Punct}]+$\");\r\n    Matcher m = p.matcher(s);\r\n    return m.matches();\r\n  }", "label": 0}
{"code": "function sink(modulename, level, message, obj) {\n  term.puts(sprintf('[green]%s[/green]: %s', modulename, message));\n}", "label": 3}
{"code": "protected function extractDataFromView($view)\n    {\n        return collect($view->getData())->map(function ($value) {\n            if ($value instanceof Model) {\n                return FormatModel::given($value);\n            } elseif (is_object($value)) {\n                return [\n                    'class' => get_class($value),\n                    'properties' => json_decode(json_encode($value), true),\n                ];\n            } else {\n                return json_decode(json_encode($value), true);\n            }\n        })->toArray();\n    }", "label": 2}
{"code": "function emitToken(tokenKind, startPos, emitFn) {\n                var tokenStartPos = ts.skipTrivia(currentText, startPos);\n                emitPos(tokenStartPos);\n                var tokenString = ts.tokenToString(tokenKind);\n                if (emitFn) {\n                    emitFn();\n                }\n                else {\n                    write(tokenString);\n                }\n                var tokenEndPos = tokenStartPos + tokenString.length;\n                emitPos(tokenEndPos);\n                return tokenEndPos;\n            }", "label": 3}
{"code": "public static base_response add(nitro_service client, inat resource) throws Exception {\n\t\tinat addresource = new inat();\n\t\taddresource.name = resource.name;\n\t\taddresource.publicip = resource.publicip;\n\t\taddresource.privateip = resource.privateip;\n\t\taddresource.tcpproxy = resource.tcpproxy;\n\t\taddresource.ftp = resource.ftp;\n\t\taddresource.tftp = resource.tftp;\n\t\taddresource.usip = resource.usip;\n\t\taddresource.usnip = resource.usnip;\n\t\taddresource.proxyip = resource.proxyip;\n\t\taddresource.mode = resource.mode;\n\t\taddresource.td = resource.td;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function getPythonCode(options) {\n    var pythonCode = [],\n        internalPylint = !options.externalPylint,\n        pylintPath = path.join(__dirname, 'lib'),\n        initHook = options.initHook;\n    delete options.initHook;\n\n    if (initHook) {\n      pythonCode.push(initHook);\n    }\n\n    if (internalPylint) {\n      pythonCode.push('import sys', 'sys.path.insert(0, r\"' + pylintPath + '\")');\n    }\n\n    pythonCode.push('import pylint', 'pylint.run_pylint()');\n    delete options.externalPylint;\n    return pythonCode.join('; ');\n  }", "label": 3}
{"code": "public function setModifyDeadlineAckIds($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->modify_deadline_ack_ids = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def userinfo=(new_userinfo)\n      if new_userinfo && !new_userinfo.respond_to?(:to_str)\n        raise TypeError, \"Can't convert #{new_userinfo.class} into String.\"\n      end\n      new_user, new_password = if new_userinfo\n        [\n          new_userinfo.to_str.strip[/^(.*):/, 1],\n          new_userinfo.to_str.strip[/:(.*)$/, 1]\n        ]\n      else\n        [nil, nil]\n      end\n\n      # Password assigned first to ensure validity in case of nil\n      self.password = new_password\n      self.user = new_user\n\n      # Reset dependent values\n      remove_instance_variable(:@authority) if defined?(@authority)\n      remove_composite_values\n\n      # Ensure we haven't created an invalid URI\n      validate()\n    end", "label": 4}
{"code": "public function sub($unit, $value = 1)\n    {\n        if (is_numeric($unit)) {\n            $_unit = $value;\n            $value = $unit;\n            $unit = $_unit;\n            unset($_unit);\n        }\n\n        return $this->add($unit, -floatval($value));\n    }", "label": 2}
{"code": "def parse_file(path)\n      {}.tap do |hash|\n        File.readlines(path).each do |line|\n          key, value = line.split(SEPARATOR)\n          hash[key] = value.strip\n        end\n      end\n    end", "label": 4}
{"code": "func (h *hawkularSink) cache(md *metrics.MetricDefinition) {\n\th.pushToCache(md.ID, hashDefinition(md))\n}", "label": 5}
{"code": "protected function prepareKeyword($keyword)\n    {\n        if ($this->config->isCaseInsensitive()) {\n            $keyword = Str::lower($keyword);\n        }\n\n        if ($this->config->isWildcard()) {\n            $keyword = Helper::wildcardLikeString($keyword);\n        }\n\n        if ($this->config->isSmartSearch()) {\n            $keyword = \"%$keyword%\";\n        }\n\n        return $keyword;\n    }", "label": 2}
{"code": "func (hv *KvmHypervisor) InitKernelParams(isDebug bool) {\n\thv.KernelParams = append(hv.KernelParams, []string{\n\t\t\"console=hvc0\",\n\t\t\"init=/usr/lib/systemd/systemd\",\n\t\t\"no_timer_check\",\n\t\t\"noreplace-smp\",\n\t\t\"tsc=reliable\"}...)\n\n\tif isDebug {\n\t\thv.KernelParams = append(hv.KernelParams, []string{\n\t\t\t\"debug\",\n\t\t\t\"systemd.log_level=debug\",\n\t\t\t\"systemd.show_status=true\",\n\t\t}...)\n\t} else {\n\t\thv.KernelParams = append(hv.KernelParams, []string{\n\t\t\t\"systemd.show_status=false\",\n\t\t\t\"systemd.log_target=null\",\n\t\t\t\"rd.udev.log-priority=3\",\n\t\t\t\"quiet=vga\",\n\t\t\t\"quiet systemd.log_level=emerg\",\n\t\t}...)\n\t}\n\n\tcustomKernelParams := os.Getenv(\"RKT_HYPERVISOR_EXTRA_KERNEL_PARAMS\")\n\tif customKernelParams != \"\" {\n\t\thv.KernelParams = append(hv.KernelParams, customKernelParams)\n\t}\n}", "label": 5}
{"code": "function _onResize () {\n        _width = window.innerWidth;\n        _height = window.innerHeight;\n        var\n            orientation,\n            orientationChanged = false,\n            toRemove = [],\n            toAdd = [];\n        if (_width > _height) {\n            orientation = \"gpf-landscape\";\n        } else {\n            orientation = \"gpf-portrait\";\n        }\n        if (_orientation !== orientation) {\n            toRemove.push(_orientation);\n            _orientation = orientation;\n            toAdd.push(orientation);\n            orientationChanged = true;\n        }\n        gpf.html.alterClass(document.body, toAdd, toRemove);\n        _broadcaster.broadcastEvent(\"resize\", {\n            width: _width,\n            height: _height\n        });\n        if (orientationChanged) {\n            _broadcaster.broadcastEvent(\"rotate\", {\n                orientation: orientation\n            });\n        }\n    }", "label": 3}
{"code": "private static boolean isConjWithNoPrep(TreeGraphNode node, Collection<TypedDependency> list) {\r\n    for (TypedDependency td : list) {\r\n      if (td.gov() == node && td.reln() == CONJUNCT) {\r\n        // we have a conjunct\r\n        // check the POS of the dependent\r\n        String tdDepPOS = td.dep().parent().value();\r\n        if (!(tdDepPOS.equals(\"IN\") || tdDepPOS.equals(\"TO\"))) {\r\n          return true;\r\n        }\r\n      }\r\n    }\r\n    return false;\r\n  }", "label": 0}
{"code": "def gcp(role, jwt, path = 'gcp')\n      payload = { role: role, jwt: jwt }\n      json = client.post(\"/v1/auth/#{CGI.escape(path)}/login\", JSON.fast_generate(payload))\n      secret = Secret.decode(json)\n      client.token = secret.auth.client_token\n      return secret\n    end", "label": 4}
{"code": "async def get_creds(self, proof_req_json: str, filt: dict = None, filt_dflt_incl: bool = False) -> (Set[str], str):\n        \"\"\"\n        Get credentials from HolderProver wallet corresponding to proof request and\n        filter criteria; return credential identifiers from wallet and credentials json.\n        Return empty set and empty production for no such credentials.\n\n        :param proof_req_json: proof request json as Verifier creates; has entries for proof request's\n            nonce, name, and version; plus credential's requested attributes, requested predicates. I.e.,\n\n        ::\n\n            {\n                'nonce': string,  # indy-sdk makes no semantic specification on this value\n                'name': string,  # indy-sdk makes no semantic specification on this value\n                'version': numeric-string,  # indy-sdk makes no semantic specification on this value\n                'requested_attributes': {\n                    '<attr_uuid>': {  # aka attr_referent, a proof-request local identifier\n                        'name': string,  # attribute name (matches case- and space-insensitively)\n                        'restrictions' [  # optional\n                            {\n                                \"schema_id\": string,  # optional\n                                \"schema_issuer_did\": string,  # optional\n                                \"schema_name\": string,  # optional\n                                \"schema_version\": string,  # optional\n                                \"issuer_did\": string,  # optional\n                                \"cred_def_id\": string  # optional\n                            },\n                            {\n                                ...  # if more than one restriction given, combined disjunctively (i.e., via OR)\n                            }\n                        ],\n                        'non_revoked': {  # optional - indy-sdk ignores when getting creds from wallet\n                            'from': int,  # optional, epoch seconds\n                            'to': int  # optional, epoch seconds\n                        }\n                    },\n                    ...\n                },\n                'requested_predicates': {\n                    '<pred_uuid>': {  # aka predicate_referent, a proof-request local predicate identifier\n                        'name': string,  # attribute name (matches case- and space-insensitively)\n                        'p_type': '>=',\n                        'p_value': int,  # predicate value\n                        'restrictions': [  # optional\n                            {\n                                \"schema_id\": string,  # optional\n                                \"schema_issuer_did\": string,  # optional\n                                \"schema_name\": string,  # optional\n                                \"schema_version\": string,  # optional\n                                \"issuer_did\": string,  # optional\n                                \"cred_def_id\": string  # optional\n                            },\n                            {\n                                ...  # if more than one restriction given, combined disjunctively (i.e., via OR)\n                            }\n                        ],\n                        'non_revoked': {  # optional - indy-sdk ignores when getting creds from wallet\n                            'from': int,  # optional, epoch seconds\n                            'to': int  # optional, epoch seconds\n                        }\n                    },\n                    ...\n                },\n                'non_revoked': {  # optional - indy-sdk ignores when getting creds from wallet\n                    'from': Optional<int>,\n                    'to': Optional<int>\n                }\n            }\n\n        :param filt: filter for matching attribute-value pairs and predicates; dict mapping each\n            cred def id to dict (specify empty dict or none for no filter, matching all)\n            mapping attributes to values to match or compare. E.g.,\n\n        ::\n\n            {\n                'Vx4E82R17q...:3:CL:16:0': {\n                    'attr-match': {\n                        'name': 'Alex',\n                        'sex': 'M',\n                        'favouriteDrink': None\n                    },\n                    'minima': {  # if both attr-match and minima present, combined conjunctively (i.e., via AND)\n                        'favouriteNumber' : 10,\n                        'score': '100'  # nicety: implementation converts to int for caller\n                    },\n                },\n                'R17v42T4pk...:3:CL:19:0': {\n                    'attr-match': {\n                        'height': 175,\n                        'birthdate': '1975-11-15'  # combined conjunctively (i.e., via AND)\n                    }\n                },\n                'Z9ccax812j...:3:CL:27:0': {\n                    'attr-match': {}  # match all attributes on this cred def\n                }\n                ...\n            }\n\n        :param filt_dflt_incl: whether to include (True) all credentials from wallet that filter does not\n            identify by cred def, or to exclude (False) all such credentials\n        :return: tuple with (set of referents, creds json for input proof request);\n            empty set and empty production for no such credential\n        \"\"\"\n\n        LOGGER.debug('HolderProver.get_creds >>> proof_req_json: %s, filt: %s', proof_req_json, filt)\n\n        if filt is None:\n            filt = {}\n        rv = None\n        creds_json = await anoncreds.prover_get_credentials_for_proof_req(self.wallet.handle, proof_req_json)\n        creds = json.loads(creds_json)\n        cred_ids = set()\n\n        if filt:\n            for cd_id in filt:\n                try:\n                    json.loads(await self.get_cred_def(cd_id))\n                except AbsentCredDef:\n                    LOGGER.warning('HolderProver.get_creds: ignoring filter criterion, no cred def on %s', cd_id)\n                    filt.pop(cd_id)\n\n        for inner_creds in {**creds['attrs'], **creds['predicates']}.values():\n            for cred in inner_creds:  # cred is a dict in a list of dicts\n                cred_info = cred['cred_info']\n                if filt:\n                    cred_cd_id = cred_info['cred_def_id']\n                    if cred_cd_id not in filt:\n                        if filt_dflt_incl:\n                            cred_ids.add(cred_info['referent'])\n                        continue\n                    if 'attr-match' in (filt[cred_cd_id] or {}):  # maybe filt[cred_cd_id]: None\n                        if not {k: str(filt[cred_cd_id].get('attr-match', {})[k])\n                                for k in filt[cred_cd_id].get('attr-match', {})}.items() <= cred_info['attrs'].items():\n                            continue\n                    if 'minima' in (filt[cred_cd_id] or {}):  # maybe filt[cred_cd_id]: None\n                        minima = filt[cred_cd_id].get('minima', {})\n                        try:\n                            if any((attr not in cred_info['attrs'])\n                                or (int(cred_info['attrs'][attr]) < int(minima[attr]))\n                                    for attr in minima):\n                                continue\n                        except ValueError:\n                            continue  # int conversion failed - reject candidate\n                    cred_ids.add(cred_info['referent'])\n                else:\n                    cred_ids.add(cred_info['referent'])\n\n        if filt:\n            creds = json.loads(prune_creds_json(creds, cred_ids))\n\n        rv = (cred_ids, json.dumps(creds))\n        LOGGER.debug('HolderProver.get_creds <<< %s', rv)\n        return rv", "label": 1}
{"code": "public function setPysparkJob($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\PySparkJob::class);\n        $this->writeOneof(4, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def send_file(channel, file, caption: nil, tts: false, filename: nil, spoiler: nil)\n      if file.respond_to?(:read)\n        if spoiler\n          filename ||= File.basename(file.path)\n          filename = 'SPOILER_' + filename unless filename.start_with? 'SPOILER_'\n        end\n        # https://github.com/rest-client/rest-client/blob/v2.0.2/lib/restclient/payload.rb#L160\n        file.define_singleton_method(:original_filename) { filename } if filename\n      end\n\n      channel = channel.resolve_id\n      response = API::Channel.upload_file(token, channel, file, caption: caption, tts: tts)\n      Message.new(JSON.parse(response), self)\n    end", "label": 4}
{"code": "public function basic_consume(\n        $queue = '',\n        $consumer_tag = '',\n        $no_local = false,\n        $no_ack = false,\n        $exclusive = false,\n        $nowait = false,\n        $callback = null,\n        $ticket = null,\n        $arguments = array()\n    ) {\n        $ticket = $this->getTicket($ticket);\n        list($class_id, $method_id, $args) = $this->protocolWriter->basicConsume(\n            $ticket,\n            $queue,\n            $consumer_tag,\n            $no_local,\n            $no_ack,\n            $exclusive,\n            $nowait,\n            $this->protocolVersion == '0.9.1' ? $arguments : null\n        );\n\n        $this->send_method_frame(array($class_id, $method_id), $args);\n\n        if (false === $nowait) {\n            $consumer_tag = $this->wait(array(\n                $this->waitHelper->get_wait('basic.consume_ok')\n            ), false, $this->channel_rpc_timeout);\n        }\n\n        $this->callbacks[$consumer_tag] = $callback;\n\n        return $consumer_tag;\n    }", "label": 2}
{"code": "function getCollection() {\n\n    var config = {\n        properties: {\n            collection: {\n                description: 'Collection name and number of rows, 5 if omitted (ex: posts 10): '.magenta,\n                type: 'string',\n                required: true\n            }\n        }\n    };\n\n    prompt.start();\n    prompt.message = ' > ';\n    prompt.delimiter = '';\n\n    return new Promise(function(resolve, reject) {\n        prompt.get(config, function(err, result) {\n            if (err) return reject(err);\n            return resolve(result.collection);\n        });\n    });\n}", "label": 3}
{"code": "def qualify namespace, context = ''\n      # @todo The return for self might work better elsewhere\n      return nil if namespace.nil?\n      return qualify(context) if namespace == 'self'\n      cached = cache.get_qualified_namespace(namespace, context)\n      return cached.clone unless cached.nil?\n      result = if namespace.start_with?('::')\n                 inner_qualify(namespace[2..-1], '', [])\n               else\n                 inner_qualify(namespace, context, [])\n               end\n      cache.set_qualified_namespace(namespace, context, result)\n      result\n    end", "label": 4}
{"code": "def create_registrationform(*args, **kwargs):\n    \"\"\"Make a registration form.\"\"\"\n    class RegistrationForm(_security.confirm_register_form):\n        password = None\n        recaptcha = None\n    return RegistrationForm(*args, **kwargs)", "label": 1}
{"code": "def get(user)\n      mechanism = user.mechanism\n      raise InvalidMechanism.new(mechanism) if !SOURCES.has_key?(mechanism)\n      SOURCES[mechanism].new(user)\n    end", "label": 4}
{"code": "function _computeReflectionCoefficients(absorptionCoefficients) {\n  let reflectionCoefficients = [];\n  for (let property in Utils.DEFAULT_REFLECTION_COEFFICIENTS) {\n    if (Utils.DEFAULT_REFLECTION_COEFFICIENTS\n        .hasOwnProperty(property)) {\n      // Compute average absorption coefficient (per wall).\n      reflectionCoefficients[property] = 0;\n      for (let j = 0; j < Utils.NUMBER_REFLECTION_AVERAGING_BANDS; j++) {\n        let bandIndex = j + Utils.ROOM_STARTING_AVERAGING_BAND;\n        reflectionCoefficients[property] +=\n          absorptionCoefficients[property][bandIndex];\n      }\n      reflectionCoefficients[property] /=\n        Utils.NUMBER_REFLECTION_AVERAGING_BANDS;\n\n      // Convert absorption coefficient to reflection coefficient.\n      reflectionCoefficients[property] =\n        Math.sqrt(1 - reflectionCoefficients[property]);\n    }\n  }\n  return reflectionCoefficients;\n}", "label": 3}
{"code": "public function setDataSourceIds($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->data_source_ids = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (s *PresenceService) DeleteAllRemoteClusters() error {\n\tstartKey := backend.Key(remoteClustersPrefix)\n\terr := s.DeleteRange(context.TODO(), startKey, backend.RangeEnd(startKey))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "func (t *FpdfTpl) GobEncode() ([]byte, error) {\n\tw := new(bytes.Buffer)\n\tencoder := gob.NewEncoder(w)\n\n\tchildrensTemplates := t.childrensTemplates()\n\tfirstClassTemplates := make([]Template, 0)\n\nfound_continue:\n\tfor x := 0; x < len(t.templates); x++ {\n\t\tfor y := 0; y < len(childrensTemplates); y++ {\n\t\t\tif childrensTemplates[y].ID() == t.templates[x].ID() {\n\t\t\t\tcontinue found_continue\n\t\t\t}\n\t\t}\n\n\t\tfirstClassTemplates = append(firstClassTemplates, t.templates[x])\n\t}\n\terr := encoder.Encode(firstClassTemplates)\n\n\tchildrenImgs := t.childrenImages()\n\tfirstClassImgs := make(map[string]*ImageInfoType)\n\n\tfor key, img := range t.images {\n\t\tif _, ok := childrenImgs[key]; !ok {\n\t\t\tfirstClassImgs[key] = img\n\t\t}\n\t}\n\n\tif err == nil {\n\t\terr = encoder.Encode(firstClassImgs)\n\t}\n\tif err == nil {\n\t\terr = encoder.Encode(t.corner)\n\t}\n\tif err == nil {\n\t\terr = encoder.Encode(t.size)\n\t}\n\tif err == nil {\n\t\terr = encoder.Encode(t.bytes)\n\t}\n\tif err == nil {\n\t\terr = encoder.Encode(t.page)\n\t}\n\n\treturn w.Bytes(), err\n}", "label": 5}
{"code": "def shortcut_app_id(shortcut):\n  \"\"\"\n  Generates the app id for a given shortcut. Steam uses app ids as a unique\n  identifier for games, but since shortcuts dont have a canonical serverside\n  representation they need to be generated on the fly. The important part\n  about this function is that it will generate the same app id as Steam does\n  for a given shortcut\n  \"\"\"\n  algorithm = Crc(width = 32, poly = 0x04C11DB7, reflect_in = True, xor_in = 0xffffffff, reflect_out = True, xor_out = 0xffffffff)\n  crc_input = ''.join([shortcut.exe,shortcut.name])\n  high_32 = algorithm.bit_by_bit(crc_input) | 0x80000000\n  full_64 = (high_32 << 32) | 0x02000000\n  return str(full_64)", "label": 1}
{"code": "public static function createFromDateString($time)\n    {\n        $interval = parent::createFromDateString($time);\n        if ($interval instanceof DateInterval && !($interval instanceof static)) {\n            $interval = static::instance($interval);\n        }\n\n        return static::instance($interval);\n    }", "label": 2}
{"code": "function createIndex() {\n  var directory = 'src/views'\n  var directories = fs.readdirSync(directory)\n\n  try {\n    var lines = ['// This is a generated file, do not edit, or disable \"prebuild\" command in package.json if you want to take control']\n    for (var i = 0; i < directories.length; i++) {\n      var path = directory + '/' + directories[i];\n      if (fs.existsSync(path) && fs.lstatSync(path).isDirectory()) {\n        var file = directories[i] + '.js'\n        if (fs.existsSync(directory + '/' + directories[i] + '/' + file)) {\n          lines.push('export { default as ' + directories[i] + ' } from \\'./' + directories[i] + '/' + directories[i] + '\\'')\n        }\n      }\n    }\n\n    fs.writeFileSync(directory + '/index.js', lines.join('\\n') + '\\n');\n  } catch (err) {\n    console.log(err)\n  }\n}", "label": 3}
{"code": "public function walkNullIfExpression($nullIfExpression)\n    {\n        $firstExpression = is_string($nullIfExpression->firstExpression)\n            ? $this->conn->quote($nullIfExpression->firstExpression)\n            : $this->walkSimpleArithmeticExpression($nullIfExpression->firstExpression);\n\n        $secondExpression = is_string($nullIfExpression->secondExpression)\n            ? $this->conn->quote($nullIfExpression->secondExpression)\n            : $this->walkSimpleArithmeticExpression($nullIfExpression->secondExpression);\n\n        return 'NULLIF(' . $firstExpression . ', ' . $secondExpression . ')';\n    }", "label": 2}
{"code": "public function entries(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n        $resourceNames = ['projects/' . $this->projectId];\n        if (isset($options['projectIds'])) {\n            foreach ($options['projectIds'] as $projectId) {\n                  $resourceNames[] = 'projects/' . $projectId;\n            }\n            unset($options['projectIds']);\n        }\n        if (isset($options['resourceNames'])) {\n            $options['resourceNames'] = array_merge($resourceNames, $options['projectIds']);\n        } else {\n            $options['resourceNames'] = $resourceNames;\n        }\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $entry) {\n                    return new Entry($entry);\n                },\n                [$this->connection, 'listEntries'],\n                $options,\n                [\n                    'itemsKey' => 'entries',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "public static final void setSize(UIObject o, Rect size) {\n        o.setPixelSize(size.w, size.h);\n\n    }", "label": 0}
{"code": "public function ActivateJobTrigger(\\Google\\Cloud\\Dlp\\V2\\ActivateJobTriggerRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.privacy.dlp.v2.DlpService/ActivateJobTrigger',\n        $argument,\n        ['\\Google\\Cloud\\Dlp\\V2\\DlpJob', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "def select_each(conn, query: str, parameter_groups, name=None):\n    \"\"\"Run select query for each parameter set in single transaction.\"\"\"\n\n    with conn:\n        with conn.cursor(name=name) as cursor:\n            for parameters in parameter_groups:\n                cursor.execute(query, parameters)\n                yield cursor.fetchone()", "label": 1}
{"code": "public function sendGetServicePricing($lg, $lc)\n    {\n        $msgId = $this->createIqId();\n        $pricingNode = new ProtocolNode('pricing',\n            [\n                'lg' => $lg,\n                'lc' => $lc,\n            ], null, null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'xmlns' => 'urn:xmpp:whatsapp:account',\n                'type'  => 'get',\n                'to'    => Constants::WHATSAPP_SERVER,\n            ], [$pricingNode], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "def split national_number\n      _, trunk, ndc, *rest = internal_split national_number\n      [trunk, ndc, *rest]\n    end", "label": 4}
{"code": "function remove(connections, params, cb) {\n  var failed = validate(params).has(CONSTANTS.DATA_SOURCE_ID);\n\n  if (failed) {\n    return cb(buildErrorResponse({error: new Error(\"An ID Parameter Is Required To Remove A Data Source\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n  }\n\n  if (!misc.checkId(params[CONSTANTS.DATA_SOURCE_ID])) {\n    return cb(buildErrorResponse({error: new Error(\"Invalid ID Parameter\"), code: ERROR_CODES.FH_FORMS_INVALID_PARAMETERS}));\n  }\n  var DataSource = models.get(connections.mongooseConnection, models.MODELNAMES.DATA_SOURCE);\n\n  async.waterfall([\n    function findAssociatedForms(cb) {\n      checkFormsUsingDataSource(connections, params, cb);\n    },\n    function verifyNoFormsAssociated(updatedDataSource, cb) {\n      //If there are any forms using this data source, then do not delete it.\n      logger.debug(\"Remove Data Source \", {updatedDataSource: updatedDataSource});\n\n      if (updatedDataSource.forms.length > 0) {\n        return cb(buildErrorResponse({\n          error: new Error(\"Forms Are Associated With This Data Source. Please Disassociate Forms From This Data Source Before Deleting.\"),\n          code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n        }));\n      }\n\n      return cb(undefined, updatedDataSource);\n    },\n    function processResponse(updatedDataSource, cb) {\n      //Removing The Data Source\n\n      DataSource.remove({_id: updatedDataSource._id}, function(err) {\n        if (err) {\n          return cb(buildErrorResponse({\n            error: err,\n            userDetail: \"Unexpected Error When Removing A Data Source\",\n            code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n          }));\n        }\n\n        //Data Source Removed Successfully\n        return cb(undefined, updatedDataSource);\n      });\n    },\n    function removeAduditLogs(updatedDataSource, cb) {\n      DataSource.clearAuditLogs(updatedDataSource._id, cb);\n    }\n  ], cb);\n}", "label": 3}
{"code": "public static function define($alias, $class)\n    {\n        $reflection = new \\ReflectionClass($class);\n\n        if (!$reflection->isSubclassOf('Predis\\Profile\\ProfileInterface')) {\n            throw new \\InvalidArgumentException(\"The class '$class' is not a valid profile class.\");\n        }\n\n        self::$profiles[$alias] = $class;\n    }", "label": 2}
{"code": "func TTL(clock clockwork.Clock, t time.Time) time.Duration {\n\tif t.IsZero() {\n\t\treturn Forever\n\t}\n\tdiff := t.UTC().Sub(clock.Now().UTC())\n\tif diff < 0 {\n\t\treturn Forever\n\t}\n\treturn diff\n}", "label": 5}
{"code": "func (f *Fetcher) FetchImages(al *apps.Apps) error {\n\treturn al.Walk(func(app *apps.App) error {\n\t\td, err := DistFromImageString(app.Image)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\th, err := f.FetchImage(d, app.Image, app.Asc)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tapp.ImageID = *h\n\t\treturn nil\n\t})\n}", "label": 5}
{"code": "function split(p) {\n  const components = p.replace(/\\/+/g, '/').replace(/\\/+$/, '').split(path.sep);\n  if (path.isAbsolute(p) && components[0] === '') {\n    components[0] = '/';\n  }\n  return components;\n}", "label": 3}
{"code": "public Object doGetObjectByIdentity(Identity id) throws PersistenceBrokerException\n    {\n        if (logger.isDebugEnabled()) logger.debug(\"getObjectByIdentity \" + id);\n\n        // check if object is present in ObjectCache:\n        Object obj = objectCache.lookup(id);\n        // only perform a db lookup if necessary (object not cached yet)\n        if (obj == null)\n        {\n            obj = getDBObject(id);\n        }\n        else\n        {\n            ClassDescriptor cld = getClassDescriptor(obj.getClass());\n            // if specified in the ClassDescriptor the instance must be refreshed\n            if (cld.isAlwaysRefresh())\n            {\n                refreshInstance(obj, id, cld);\n            }\n            // now refresh all references\n            checkRefreshRelationships(obj, id, cld);\n        }\n\n        // Invoke events on PersistenceBrokerAware instances and listeners\n        AFTER_LOOKUP_EVENT.setTarget(obj);\n        fireBrokerEvent(AFTER_LOOKUP_EVENT);\n        AFTER_LOOKUP_EVENT.setTarget(null);\n\n        //logger.info(\"RETRIEVING object \" + obj);\n        return obj;\n    }", "label": 0}
{"code": "public static base_responses update(nitro_service client, ntpserver resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tntpserver updateresources[] = new ntpserver[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new ntpserver();\n\t\t\t\tupdateresources[i].serverip = resources[i].serverip;\n\t\t\t\tupdateresources[i].servername = resources[i].servername;\n\t\t\t\tupdateresources[i].minpoll = resources[i].minpoll;\n\t\t\t\tupdateresources[i].maxpoll = resources[i].maxpoll;\n\t\t\t\tupdateresources[i].preferredntpserver = resources[i].preferredntpserver;\n\t\t\t\tupdateresources[i].autokey = resources[i].autokey;\n\t\t\t\tupdateresources[i].key = resources[i].key;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setMessageTypes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::ENUM, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferMessage\\MessageSeverity::class);\n        $this->message_types = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def chmod(self, target_file, acl='public-read'):\n        \"\"\"\n        sets permissions for a file on S3\n\n        Parameters\n        ----------\n\n        target_file : string\n            Path to file on S3\n\n        acl : string, optional\n            File permissions on S3. Default is public-read\n\n            options:\n                - private: Owner gets FULL_CONTROL. No one else has any access rights.\n                - public-read: Owners gets FULL_CONTROL and the anonymous principal is granted READ access.\n                - public-read-write: Owner gets FULL_CONTROL and the anonymous principal is granted READ and WRITE access.\n                - authenticated-read: Owner gets FULL_CONTROL and any principal authenticated as a registered Amazon S3 user is granted READ access\n\n\n        Examples\n        --------\n            >>> s3utils.chmod(\"path/to/file\",\"private\")\n\n\n        \"\"\"\n        self.k.key = target_file  # setting the path (key) of file in the container\n        self.k.set_acl(acl)  # setting the file permissions\n        self.k.close()", "label": 1}
{"code": "def load(fp: Union[TextIO, str], load_module: types.ModuleType, **kwargs):\n    \"\"\" Convert a file name or file-like object containing stringified JSON into a JSGObject\n\n    :param fp: file-like object to deserialize\n    :param load_module: module that contains declarations for types\n    :param kwargs: arguments see: json.load for details\n    :return: JSGObject representing the json string\n    \"\"\"\n    if isinstance(fp, str):\n        with open(fp) as f:\n            return loads(f.read(), load_module, **kwargs)\n    else:\n        return loads(fp.read(), load_module, **kwargs)", "label": 1}
{"code": "def marshal_load(serialised)\n      self.method  = serialised[:method]\n      self.body    = serialised[:body]\n      self.headers = serialised[:headers]\n      self.path    = serialised[:path]\n      self.params  = serialised[:params]\n      self.options = serialised[:options]\n    end", "label": 4}
{"code": "function createRemoveNodeHandler(el, fn) {\n  return function (mutations, observer) {\n    mutations.forEach(function (mutation) {\n      if (_includes(mutation.removedNodes, el)) {\n        fn();\n        observer.disconnect();\n      }\n    });\n  };\n}", "label": 3}
{"code": "public function saveAs($filename, $format = 'auto')\n    {\n\n        if ($format === 'auto') {\n            $format =   strtolower(substr($filename, -5)) === '.json' ? 'json' : 'yaml';\n        }\n        if (strtolower($format) === 'json') {\n            $content = $this->toJson();\n        } else {\n            $content = $this->toYaml();\n        }\n        if (file_put_contents($filename, $content) === false) {\n            throw new Exception('Failed to saveAs(\"' . $filename . '\", \"'.$format.'\")');\n        }\n    }", "label": 2}
{"code": "def start\n      # Start IRB with current context:\n      # http://stackoverflow.com/questions/4189818/how-to-run-irb-start-in-context-of-current-class\n      ARGV.clear\n      IRB.setup nil\n\n      IRB.conf[:IRB_NAME] = 'aruba'\n\n      IRB.conf[:PROMPT] = {}\n      IRB.conf[:PROMPT][:ARUBA] = {\n        PROMPT_I: '%N:%03n:%i> ',\n        PROMPT_S: '%N:%03n:%i%l ',\n        PROMPT_C: '%N:%03n:%i* ',\n        RETURN: \"# => %s\\n\"\n      }\n      IRB.conf[:PROMPT_MODE] = :ARUBA\n\n      IRB.conf[:RC] = false\n\n      require 'irb/completion'\n      require 'irb/ext/save-history'\n      IRB.conf[:READLINE] = true\n      IRB.conf[:SAVE_HISTORY] = 1000\n      IRB.conf[:HISTORY_FILE] = Aruba.config.console_history_file\n\n      context = Class.new do\n        include Aruba::Api\n        include Aruba::Console::Help\n\n        def initialize\n          setup_aruba\n        end\n\n        def inspect\n          'nil'\n        end\n      end\n\n      irb = IRB::Irb.new(IRB::WorkSpace.new(context.new))\n      IRB.conf[:MAIN_CONTEXT] = irb.context\n\n      trap(\"SIGINT\") do\n        irb.signal_handle\n      end\n\n      begin\n        catch(:IRB_EXIT) do\n          irb.eval_input\n        end\n      ensure\n        IRB.irb_at_exit\n      end\n    end", "label": 4}
{"code": "def quote_xml(text):\n    \"\"\"Format a value for display as an XML text node.\n\n    Returns:\n        Unicode string (str on Python 3, unicode on Python 2)\n    \"\"\"\n    text = _coerce_unicode(text)\n\n    # If it's a CDATA block, return the text as is.\n    if text.startswith(CDATA_START):\n        return text\n\n    # If it's not a CDATA block, escape the XML and return the character\n    # encoded string.\n    return saxutils.escape(text)", "label": 1}
{"code": "public function merge_yml( $path, $current_alias = null ) {\n\t\t$yaml = self::load_yml( $path );\n\t\tif ( ! empty( $yaml['_']['inherit'] ) ) {\n\t\t\t$this->merge_yml( $yaml['_']['inherit'], $current_alias );\n\t\t}\n\t\t// Prepare the base path for absolutized alias paths\n\t\t$yml_file_dir = $path ? dirname( $path ) : false;\n\t\tforeach ( $yaml as $key => $value ) {\n\t\t\tif ( preg_match( '#' . self::ALIAS_REGEX . '#', $key ) ) {\n\t\t\t\t$this->aliases[ $key ] = array();\n\t\t\t\t$is_alias              = false;\n\t\t\t\tforeach ( self::$alias_spec as $i ) {\n\t\t\t\t\tif ( isset( $value[ $i ] ) ) {\n\t\t\t\t\t\tif ( 'path' === $i && ! isset( $value['ssh'] ) ) {\n\t\t\t\t\t\t\tself::absolutize( $value[ $i ], $yml_file_dir );\n\t\t\t\t\t\t}\n\t\t\t\t\t\t$this->aliases[ $key ][ $i ] = $value[ $i ];\n\t\t\t\t\t\t$is_alias                    = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// If it's not an alias, it might be a group of aliases\n\t\t\t\tif ( ! $is_alias && is_array( $value ) ) {\n\t\t\t\t\t$alias_group = array();\n\t\t\t\t\tforeach ( $value as $i => $k ) {\n\t\t\t\t\t\tif ( preg_match( '#' . self::ALIAS_REGEX . '#', $k ) ) {\n\t\t\t\t\t\t\t$alias_group[] = $k;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t$this->aliases[ $key ] = $alias_group;\n\t\t\t\t}\n\t\t\t} elseif ( ! isset( $this->spec[ $key ] ) || false === $this->spec[ $key ]['file'] ) {\n\t\t\t\tif ( isset( $this->extra_config[ $key ] )\n\t\t\t\t\t&& ! empty( $yaml['_']['merge'] )\n\t\t\t\t\t&& is_array( $this->extra_config[ $key ] )\n\t\t\t\t\t&& is_array( $value ) ) {\n\t\t\t\t\t$this->extra_config[ $key ] = array_merge( $this->extra_config[ $key ], $value );\n\t\t\t\t} else {\n\t\t\t\t\t$this->extra_config[ $key ] = $value;\n\t\t\t\t}\n\t\t\t} elseif ( $this->spec[ $key ]['multiple'] ) {\n\t\t\t\tself::arrayify( $value );\n\t\t\t\t$this->config[ $key ] = array_merge( $this->config[ $key ], $value );\n\t\t\t} else {\n\t\t\t\tif ( $current_alias && in_array( $key, self::$alias_spec, true ) ) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t$this->config[ $key ] = $value;\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "func DebugHTTPForm(r *http.Request) {\n\tfor k, v := range r.Form {\n\t\tlogrus.Debugf(\"Form[%q] = %q\\n\", k, v)\n\t}\n}", "label": 5}
{"code": "public function toBigQuery($value)\n    {\n        if ($value instanceof ValueInterface || $value instanceof Int64) {\n            return (string) $value;\n        }\n\n        if ($value instanceof \\DateTime) {\n            return $value->format(self::DATETIME_FORMAT_INSERT);\n        }\n\n        if (is_array($value)) {\n            foreach ($value as $key => $item) {\n                $value[$key] = $this->toBigQuery($item);\n            }\n\n            return $value;\n        }\n\n        return $value;\n    }", "label": 2}
{"code": "function getTypeFromBindingElement(element, includePatternInType, reportErrors) {\n            if (element.initializer) {\n                return checkExpressionCached(element.initializer);\n            }\n            if (ts.isBindingPattern(element.name)) {\n                return getTypeFromBindingPattern(element.name, includePatternInType, reportErrors);\n            }\n            if (reportErrors && compilerOptions.noImplicitAny && !declarationBelongsToPrivateAmbientMember(element)) {\n                reportImplicitAnyError(element, anyType);\n            }\n            return anyType;\n        }", "label": 3}
{"code": "function failFirstRequest(server) {\n    var listeners = server.listeners(\"request\"),\n        existingListeners = [];\n    for (var i = 0, l = listeners.length; i < l; i++) {\n        existingListeners[i] = listeners[i];\n    }\n    server.removeAllListeners(\"request\");\n    server.on(\"request\", function (req, res) {\n        var fireExisting = true;\n        if (/^\\/transport\\/server\\//.test(req.url)) {\n            fireExisting = onTransportRequest(req, res);\n        }\n        if (fireExisting) {\n            for (var i = 0, l = existingListeners.length; i < l; i++) {\n                existingListeners[i].call(server, req, res);\n            }\n        }\n    });\n\n    var count = 0;\n    function onTransportRequest(req, res) {\n        count += 1;\n        console.log(\"REQUEST\", req.url, count);\n        if (count === 1) {\n            console.log(\"  Fail request\");\n            res.end(\"<An unparsable response>\");\n            return false;\n        }\n        return true;\n    }\n}", "label": 3}
{"code": "def member(server_or_id, user_id)\n      server_id = server_or_id.resolve_id\n      user_id = user_id.resolve_id\n\n      server = server_or_id.is_a?(Server) ? server_or_id : self.server(server_id)\n\n      return server.member(user_id) if server.member_cached?(user_id)\n\n      LOGGER.out(\"Resolving member #{server_id} on server #{user_id}\")\n      begin\n        response = API::Server.resolve_member(token, server_id, user_id)\n      rescue RestClient::ResourceNotFound\n        return nil\n      end\n      member = Member.new(JSON.parse(response), server, self)\n      server.cache_member(member)\n    end", "label": 4}
{"code": "def oauth_error_handler(f):\n    \"\"\"Decorator to handle exceptions.\"\"\"\n    @wraps(f)\n    def inner(*args, **kwargs):\n        # OAuthErrors should not happen, so they are not caught here. Hence\n        # they will result in a 500 Internal Server Error which is what we\n        # are interested in.\n        try:\n            return f(*args, **kwargs)\n        except OAuthClientError as e:\n            current_app.logger.warning(e.message, exc_info=True)\n            return oauth2_handle_error(\n                e.remote, e.response, e.code, e.uri, e.description\n            )\n        except OAuthCERNRejectedAccountError as e:\n            current_app.logger.warning(e.message, exc_info=True)\n            flash(_('CERN account not allowed.'),\n                  category='danger')\n            return redirect('/')\n        except OAuthRejectedRequestError:\n            flash(_('You rejected the authentication request.'),\n                  category='info')\n            return redirect('/')\n        except AlreadyLinkedError:\n            flash(_('External service is already linked to another account.'),\n                  category='danger')\n            return redirect(url_for('invenio_oauthclient_settings.index'))\n    return inner", "label": 1}
{"code": "func (d *driver) initStore(option map[string]interface{}) error {\n\tif data, ok := option[netlabel.LocalKVClient]; ok {\n\t\tvar err error\n\t\tdsc, ok := data.(discoverapi.DatastoreConfigData)\n\t\tif !ok {\n\t\t\treturn types.InternalErrorf(\"incorrect data in datastore configuration: %v\", data)\n\t\t}\n\t\td.store, err = datastore.NewDataStoreFromConfig(dsc)\n\t\tif err != nil {\n\t\t\treturn types.InternalErrorf(\"macvlan driver failed to initialize data store: %v\", err)\n\t\t}\n\n\t\treturn d.populateNetworks()\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func (s *ID) Check() error {\n\t_, err := ParseID(string(*s))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "function ConsoleLogger(options) {\n\tEventEmitter.call(this);\n\tthis.options = options || {};\n\t// allow use to customize if they want the label or not\n\tthis.prefix = this.options.prefix === undefined ? true : this.options.prefix;\n\tthis.showcr = this.options.showcr === undefined ? true : this.options.showcr;\n\tthis.showtab = this.options.showtab === undefined ? true : this.options.showtab;\n\tthis.colorize = this.options.colorize === undefined ? checkColorize() : this.options.colorize;\n\tthis.logPrepend = this.options.logPrepend;\n\tchalk.enabled = !!this.colorize;\n\n\t// if we are logging from a cluster worker, prepend the process PID\n\t// istanbul ignore if\n\tif (cluster.isWorker) {\n\t\tif (chalk.enabled) {\n\t\t\tthis.logPrepend = chalk.black.inverse(String(process.pid)) + grey(' |');\n\t\t} else {\n\t\t\tthis.logPrepend = process.pid + ' |';\n\t\t}\n\t}\n\tthis.remapLevels();\n}", "label": 3}
{"code": "function ZReadable(options) {\n\tif(options) {\n\t\tif(options.readableObjectMode) {\n\t\t\toptions.objectMode = true;\n\t\t}\n\t\t//Add support for iojs simplified stream constructor\n\t\tif(typeof options.read === 'function') {\n\t\t\tthis._read = options.read;\n\t\t}\n\t}\n\tReadable.call(this, options);\n\tstreamMixins.call(this, Readable.prototype, options);\n\treadableMixins.call(this, options);\n}", "label": 3}
{"code": "public function setApplicationLastStageFilters($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\ApplicationLastStageFilter::class);\n        $this->application_last_stage_filters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def write_field(*args)\n      if args.size == 3\n        # handles the documented method signature - write_field(field_info, fid, value)\n        field_info = args[0]\n        fid = args[1]\n        value = args[2]\n      elsif args.size == 4\n        # handles the deprecated method signature - write_field(name, type, fid, value)\n        field_info = {:name => args[0], :type => args[1]}\n        fid = args[2]\n        value = args[3]\n      else\n        raise ArgumentError, \"wrong number of arguments (#{args.size} for 3)\"\n      end\n\n      write_field_begin(field_info[:name], field_info[:type], fid)\n      write_type(field_info, value)\n      write_field_end\n    end", "label": 4}
{"code": "def find_upwards(target, start_dir = nil)\n      previous = nil\n      current  = File.expand_path(start_dir || Dir.pwd)\n\n      until !File.directory?(current) || current == previous\n        filename = File.join(current, target)\n        return filename if File.file?(filename)\n        previous = current\n        current = File.expand_path('..', current)\n      end\n    end", "label": 4}
{"code": "public static servicegroup_lbmonitor_binding[] get(nitro_service service, String servicegroupname) throws Exception{\n\t\tservicegroup_lbmonitor_binding obj = new servicegroup_lbmonitor_binding();\n\t\tobj.set_servicegroupname(servicegroupname);\n\t\tservicegroup_lbmonitor_binding response[] = (servicegroup_lbmonitor_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def valid(self, cnpj):\n        \"\"\"Check if a CNPJ is valid.\n\n        We should avoid sending invalid CNPJ to the web service as we know\n        it is going to be a waste of bandwidth. Assumes CNPJ is a string.\n        \"\"\"\n        if len(cnpj) != 14:\n            return False\n\n        tam = 12\n        nums = cnpj[:tam]\n        digs = cnpj[tam:]\n\n        tot = 0\n        pos = tam-7\n        for i in range(tam, 0, -1):\n            tot = tot + int(nums[tam-i])*pos\n            pos = pos - 1\n            if pos < 2:\n                pos = 9\n        res = 0 if tot % 11 < 2 else 11 - (tot % 11)\n        if res != int(digs[0]):\n            return False\n\n        tam = tam + 1\n        nums = cnpj[:tam]\n        tot = 0\n        pos = tam-7\n        for i in range(tam, 0, -1):\n            tot = tot + int(nums[tam-i])*pos\n            pos = pos - 1\n            if pos < 2:\n                pos = 9\n        res = 0 if tot % 11 < 2 else 11 - (tot % 11)\n        if res != int(digs[1]):\n            return False\n\n        return True", "label": 1}
{"code": "def browse(package, homepage):\n    \"\"\"Browse to a package's PyPI or project homepage.\"\"\"\n    p = Package(package)\n    try:\n        if homepage:\n            secho(u'Opening homepage for \"{0}\"...'.format(package), bold=True)\n            url = p.home_page\n        else:\n            secho(u'Opening PyPI page for \"{0}\"...'.format(package), bold=True)\n            url = p.package_url\n    except NotFoundError:\n        abort_not_found(package)\n    click.launch(url)", "label": 1}
{"code": "def canAdd(self, filename):\n        \"\"\"Determines if a filename can be added to the depot under the current client\n\n        :param filename: File path to add\n        :type filename: str\n        \"\"\"\n        try:\n            result = self.run(['add', '-n', '-t', 'text', filename])[0]\n        except errors.CommandError as err:\n            LOGGER.debug(err)\n            return False\n\n        if result.get('code') not in ('error', 'info'):\n            return True\n\n        LOGGER.warn('Unable to add {}: {}'.format(filename, result['data']))\n\n        return False", "label": 1}
{"code": "def iterative_overlap_assembly(\n        variant_sequences,\n        min_overlap_size=MIN_VARIANT_SEQUENCE_ASSEMBLY_OVERLAP_SIZE):\n    \"\"\"\n    Assembles longer sequences from reads centered on a variant by\n    between merging all pairs of overlapping sequences and collapsing\n    shorter sequences onto every longer sequence which contains them.\n\n    Returns a list of variant sequences, sorted by decreasing read support.\n    \"\"\"\n    if len(variant_sequences) <= 1:\n        # if we don't have at least two sequences to start with then\n        # skip the whole mess below\n        return variant_sequences\n\n    # reduce the number of inputs to the merge algorithm by first collapsing\n    # shorter sequences onto the longer sequences which contain them\n    n_before_collapse = len(variant_sequences)\n    variant_sequences = collapse_substrings(variant_sequences)\n    n_after_collapse = len(variant_sequences)\n    logger.info(\n        \"Collapsed %d -> %d sequences\",\n        n_before_collapse,\n        n_after_collapse)\n\n    merged_variant_sequences = greedy_merge(variant_sequences, min_overlap_size)\n    return list(sorted(\n        merged_variant_sequences,\n        key=lambda seq: -len(seq.reads)))", "label": 1}
{"code": "function getProp(propName) {\n      var bindGetters = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n      var bindTo = arguments.length > 2 ? arguments[2] : undefined;\n      // $FlowFixMe\n      var proto = Object.getPrototypeOf(this);\n      var descriptor = Object.getOwnPropertyDescriptor(proto, propName);\n      var result;\n\n      if (!descriptor) {\n        return null;\n      }\n\n      if (descriptor) {\n        if (descriptor.initializer || descriptor.get) {\n          var what = descriptor.initializer || descriptor.get;\n\n          if (bindGetters) {\n            result = what.bind(bindTo || this);\n          } else {\n            result = what;\n          }\n        } else if (descriptor.value) {\n          result = descriptor.value;\n        }\n      }\n\n      return result;\n    }", "label": 3}
{"code": "func (t *terminal) GetWinSize() (*term.Winsize, error) {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif t.pty == nil {\n\t\treturn nil, trace.NotFound(\"no pty\")\n\t}\n\tws, err := term.GetWinsize(t.pty.Fd())\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn ws, nil\n}", "label": 5}
{"code": "private function genericSubscribeInit($subscribeAction)\n    {\n        if (isset($this->options[$subscribeAction])) {\n            $this->$subscribeAction($this->options[$subscribeAction]);\n        }\n    }", "label": 2}
{"code": "func (t *terminal) Close() error {\n\tvar err error\n\t// note, pty is closed in the copying goroutine,\n\t// not here to avoid data races\n\tif t.tty != nil {\n\t\tif e := t.tty.Close(); e != nil {\n\t\t\terr = e\n\t\t}\n\t}\n\tgo t.closePTY()\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def get_method_docstring(cls, method_name):\n    \"\"\"\n    return method  docstring\n    if method docstring is empty we get docstring from parent\n\n    :param method:\n    :type method:\n    :return:\n    :rtype:\n    \"\"\"\n    method = getattr(cls, method_name, None)\n    if method is None:\n        return\n    docstrign = inspect.getdoc(method)\n    if docstrign is None:\n        for base in cls.__bases__:\n            docstrign = get_method_docstring(base, method_name)\n            if docstrign:\n                return docstrign\n        else:\n            return None\n\n    return docstrign", "label": 1}
{"code": "function addPlugin(plugin) {\n  if (!plugin) {\n    return;\n  }\n  if (!needFilterPlugin) {\n    console.warn('You are adding a plugin after getPlugins is called.');\n  }\n  needFilterPlugin = true;\n  if (!plugin.name) {\n    console.log('plugin: ', plugin);\n    throw new Error('Each plugin should have a name.');\n  }\n  if (_.find(allPlugins, { name: plugin.name })) {\n    console.warn('You should not add a plugin with same name: ' + plugin.name);\n    return;\n  }\n  allPlugins.push(plugin);\n}", "label": 3}
{"code": "def select(str_or_rx)\n      %i[value label].each do |key|\n        radio = radio(key => str_or_rx)\n        next unless radio.exist?\n\n        radio.click unless radio.selected?\n        return key == :value ? radio.value : radio.text\n      end\n      raise UnknownObjectException, \"Unable to locate radio matching #{str_or_rx.inspect}\"\n    end", "label": 4}
{"code": "function getService(name) {\n    if (name.indexOf('.') >= 0) {\n        name = utils.getCamelCase(name);\n    }\n\n    if (!name.match(/^.*Service$/)) {\n        name += 'Service';\n    }\n\n    return cook(name);\n}", "label": 3}
{"code": "def render_layout(output, layout, info)\n      payload[\"content\"] = output\n      payload[\"layout\"]  = Utils.deep_merge_hashes(layout.data, payload[\"layout\"] || {})\n\n      render_liquid(\n        layout.content,\n        payload,\n        info,\n        layout.relative_path\n      )\n    end", "label": 4}
{"code": "def gauge(stat, value, opts=EMPTY_OPTIONS)\n      opts = {:sample_rate => opts} if opts.is_a? Numeric\n      send_stats stat, value, GAUGE_TYPE, opts\n    end", "label": 4}
{"code": "def _init_kata_dasar(self, dasar):\n        \"\"\"Memproses kata dasar yang ada dalam nama entri.\n\n        :param dasar: ResultSet untuk label HTML dengan class=\"rootword\"\n        :type dasar: ResultSet\n        \"\"\"\n\n        for tiap in dasar:\n            kata = tiap.find('a')\n            dasar_no = kata.find('sup')\n            kata = ambil_teks_dalam_label(kata)\n            self.kata_dasar.append(\n                kata + ' [{}]'.format(dasar_no.text.strip()) if dasar_no else kata\n            )", "label": 1}
{"code": "protected function error($message)\n    {\n        if ($this->output instanceof ConsoleOutputInterface) {\n            $this->output->getErrorOutput()->writeln(\"<error>$message</error>\");\n        } else {\n            $this->output->writeln(\"<error>$message</error>\");\n        }\n    }", "label": 2}
{"code": "func setupMacVTapDevice(podID types.UUID, config MacVTapNetConf, interfaceNumber int) (netlink.Link, error) {\n\tmaster, err := netlink.LinkByName(config.Master)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(fmt.Errorf(\"cannot find master device '%v'\", config.Master), err)\n\t}\n\tvar mode netlink.MacvlanMode\n\tswitch config.Mode {\n\t// if not set - defaults to bridge mode as in:\n\t// https://github.com/rkt/rkt/blob/master/Documentation/networking.md#macvlan\n\tcase \"\", \"bridge\":\n\t\tmode = netlink.MACVLAN_MODE_BRIDGE\n\tcase \"private\":\n\t\tmode = netlink.MACVLAN_MODE_PRIVATE\n\tcase \"vepa\":\n\t\tmode = netlink.MACVLAN_MODE_VEPA\n\tcase \"passthru\":\n\t\tmode = netlink.MACVLAN_MODE_PASSTHRU\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported macvtap mode: %v\", config.Mode)\n\t}\n\tmtu := master.Attrs().MTU\n\tif config.MTU != 0 {\n\t\tmtu = config.MTU\n\t}\n\tinterfaceName := fmt.Sprintf(\"rkt-%s-vtap%d\", podID.String()[0:4], interfaceNumber)\n\tlink := &netlink.Macvtap{\n\t\tMacvlan: netlink.Macvlan{\n\t\t\tLinkAttrs: netlink.LinkAttrs{\n\t\t\t\tName:        interfaceName,\n\t\t\t\tMTU:         mtu,\n\t\t\t\tParentIndex: master.Attrs().Index,\n\t\t\t},\n\t\t\tMode: mode,\n\t\t},\n\t}\n\n\tif err := netlink.LinkAdd(link); err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"cannot create macvtap interface\"), err)\n\t}\n\n\t// TODO: duplicate following lines for ipv6 support, when it will be added in other places\n\tipv4SysctlValueName := fmt.Sprintf(IPv4InterfaceArpProxySysctlTemplate, interfaceName)\n\tif _, err := cnisysctl.Sysctl(ipv4SysctlValueName, \"1\"); err != nil {\n\t\t// remove the newly added link and ignore errors, because we already are in a failed state\n\t\t_ = netlink.LinkDel(link)\n\t\treturn nil, errwrap.Wrap(fmt.Errorf(\"failed to set proxy_arp on newly added interface %q\", interfaceName), err)\n\t}\n\n\tif err := netlink.LinkSetUp(link); err != nil {\n\t\t// remove the newly added link and ignore errors, because we already are in a failed state\n\t\t_ = netlink.LinkDel(link)\n\t\treturn nil, errwrap.Wrap(errors.New(\"cannot set up macvtap interface\"), err)\n\t}\n\treturn link, nil\n}", "label": 5}
{"code": "def click(*modifiers)\n      # TODO: Should wait_for_enabled be default, or `Button` specific behavior?\n      element_call(:wait_for_enabled) do\n        if modifiers.any?\n          action = driver.action\n          modifiers.each { |mod| action.key_down mod }\n          action.click @element\n          modifiers.each { |mod| action.key_up mod }\n\n          action.perform\n        else\n          @element.click\n        end\n      end\n\n      browser.after_hooks.run\n    end", "label": 4}
{"code": "public function acknowledgeBatch(array $messages, array $options = [])\n    {\n        $this->validateBatch($messages, Message::class);\n\n        $this->connection->acknowledge($options + [\n            'subscription' => $this->name,\n            'ackIds' => $this->getMessageAckIds($messages)\n        ]);\n    }", "label": 2}
{"code": "def get_transcripts(transcript_file):\n    \"\"\"\n    Parses FusionInspector transcript file and returns dictionary of sequences\n\n    :param str transcript_file: path to transcript FASTA\n    :return: de novo assembled transcripts\n    :rtype: dict\n    \"\"\"\n    with open(transcript_file, 'r') as fa:\n        transcripts = {}\n        regex_s = r\"(?P<ID>TRINITY.*)\\s(?P<fusion>.*--.*):(?P<left_start>\\d+)-(?P<right_start>\\d+)\"\n        regex = re.compile(regex_s)\n        while True:\n            # Usually the transcript is on one line\n            try:\n                info = fa.next()\n                seq = fa.next()\n\n                assert info.startswith('>')\n\n                m = regex.search(info)\n                if m:\n                    transcripts[m.group('ID')] = seq.strip()\n\n            except StopIteration:\n                break\n\n            except AssertionError:\n                print(\"WARNING: Malformed fusion transcript file\")\n    return transcripts", "label": 1}
{"code": "def format_op_row(ipFile, totLines, totWords, uniqueWords):\n    \"\"\"\n    Format the output row with stats\n    \"\"\"\n    txt = os.path.basename(ipFile).ljust(36) + ' '\n    txt += str(totLines).rjust(7) + ' '\n    txt += str(totWords).rjust(7) + ' '\n    txt += str(len(uniqueWords)).rjust(7) + ' '\n    return txt", "label": 1}
{"code": "def head(self, path=None, url_kwargs=None, **kwargs):\n        \"\"\"\n        Sends a HEAD request.\n\n        :param path:\n            The HTTP path (either absolute or relative).\n        :param url_kwargs:\n            Parameters to override in the generated URL. See `~hyperlink.URL`.\n        :param **kwargs:\n            Optional arguments that ``request`` takes.\n        :return: response object\n        \"\"\"\n        return self._session.head(self._url(path, url_kwargs), **kwargs)", "label": 1}
{"code": "public static java.sql.Time getTime(Object value) {\n        try {\n            return toTime(value);\n        } catch (ParseException pe) {\n            pe.printStackTrace();\n            return null;\n        }\n    }", "label": 0}
{"code": "def run_callbacks(kind, *args, &block)\n      cascadable_children(kind).each do |child|\n        if child.run_callbacks(child_callback_type(kind, child), *args) == false\n          return false\n        end\n      end\n      callback_executable?(kind) ? super(kind, *args, &block) : true\n    end", "label": 4}
{"code": "def most_similar_catchments(self, subject_catchment, similarity_dist_function, records_limit=500,\n                                include_subject_catchment='auto'):\n        \"\"\"\n        Return a list of catchments sorted by hydrological similarity defined by `similarity_distance_function`\n\n        :param subject_catchment: subject catchment to find similar catchments for\n        :type subject_catchment: :class:`floodestimation.entities.Catchment`\n        :param similarity_dist_function: a method returning a similarity distance measure with 2 arguments, both\n                                         :class:`floodestimation.entities.Catchment` objects\n        :param include_subject_catchment: - `auto`: include subject catchment if suitable for pooling and if urbext < 0.03\n                                          - `force`: always include subject catchment having at least 10 years of data\n                                          - `exclude`: do not include the subject catchment\n        :type include_subject_catchment: str\n        :return: list of catchments sorted by similarity\n        :type: list of :class:`floodestimation.entities.Catchment`\n        \"\"\"\n        if include_subject_catchment not in ['auto', 'force', 'exclude']:\n            raise ValueError(\"Parameter `include_subject_catchment={}` invalid.\".format(include_subject_catchment) +\n                             \"Must be one of `auto`, `force` or `exclude`.\")\n\n        query = (self.db_session.query(Catchment).\n                 join(Catchment.descriptors).\n                 join(Catchment.amax_records).\n                 filter(Catchment.id != subject_catchment.id,\n                        Catchment.is_suitable_for_pooling,\n                        or_(Descriptors.urbext2000 < 0.03, Descriptors.urbext2000 == None),\n                        AmaxRecord.flag == 0).\n                 group_by(Catchment).\n                 having(func.count(AmaxRecord.catchment_id) >= 10))  # At least 10 AMAX records\n        catchments = query.all()\n\n        # Add subject catchment if required (may not exist in database, so add after querying db\n        if include_subject_catchment == 'force':\n            if len(subject_catchment.amax_records) >= 10:  # Never include short-record catchments\n                catchments.append(subject_catchment)\n        elif include_subject_catchment == 'auto':\n            if len(subject_catchment.amax_records) >= 10 and subject_catchment.is_suitable_for_pooling and \\\n               (subject_catchment.descriptors.urbext2000 < 0.03 or subject_catchment.descriptors.urbext2000 is None):\n                catchments.append(subject_catchment)\n\n        # Store the similarity distance as an additional attribute for each catchment\n        for catchment in catchments:\n            catchment.similarity_dist = similarity_dist_function(subject_catchment, catchment)\n        # Then simply sort by this attribute\n        catchments.sort(key=attrgetter('similarity_dist'))\n\n        # Limit catchments until total amax_records counts is at least `records_limit`, default 500\n        amax_records_count = 0\n        catchments_limited = []\n        for catchment in catchments:\n            catchments_limited.append(catchment)\n            amax_records_count += catchment.record_length\n            if amax_records_count >= records_limit:\n                break\n\n        return catchments_limited", "label": 1}
{"code": "def custom_url_for_mail_root(organization, newsletter_id = nil)\n      if newsletter_id.present?\n        decidim.root_url(host: organization.host) + utm_codes(organization.host, newsletter_id.to_s)\n      else\n        decidim.root_url(host: organization.host)\n      end\n    end", "label": 4}
{"code": "def genome_coverage(covs, s2b):\n    \"\"\"\n    calculate genome coverage from scaffold coverage\n    \"\"\"\n    COV = []\n    for cov in covs:\n        COV.append(parse_cov(cov, s2b))\n    return pd.concat(COV)", "label": 1}
{"code": "function mergeLists(list, _filters) {\n        if (list.specFiles) {\n            list.specFiles.forEach(value => _filters.specFiles[value] = true);\n        }\n        if (list.testcaseFiles) {\n            list.testcaseFiles.forEach(value => _filters.testcaseFiles[value] = true);\n        }\n        if (list.features) {\n            list.features.forEach(value => _filters.features[value] = true);\n        }\n        if (list.specs) {\n            list.specs.forEach(value => _filters.specs[value] = true);\n        }\n        if (list.testcases) {\n            list.testcases.forEach(value => _filters.testcases[value] = true);\n        }\n        if (list.listFiles) {\n            for (const listFile of list.listFiles) {\n                // complete cli listFiles paths\n                const listFilePath = path.join(listsDir, `${listFile}.list.ts`);\n                if (!fs.existsSync(listFilePath)) {\n                    throw new Error(`List file could not be found: ${listFilePath}`);\n                }\n                else {\n                    const sublist = require(listFilePath).default;\n                    // recursively traverse sub list files\n                    mergeLists(sublist, _filters);\n                }\n            }\n        }\n    }", "label": 3}
{"code": "func main() {\n\n\tencoding.Register()\n\n\ts, e := tcell.NewScreen()\n\tif e != nil {\n\t\tfmt.Fprintf(os.Stderr, \"%v\\n\", e)\n\t\tos.Exit(1)\n\t}\n\tif e := s.Init(); e != nil {\n\t\tfmt.Fprintf(os.Stderr, \"%v\\n\", e)\n\t\tos.Exit(1)\n\t}\n\tdefStyle = tcell.StyleDefault.\n\t\tBackground(tcell.ColorBlack).\n\t\tForeground(tcell.ColorWhite)\n\ts.SetStyle(defStyle)\n\ts.EnableMouse()\n\ts.Clear()\n\n\tposfmt := \"Mouse: %d, %d  \"\n\tbtnfmt := \"Buttons: %s\"\n\tkeyfmt := \"Keys: %s\"\n\twhite := tcell.StyleDefault.\n\t\tForeground(tcell.ColorWhite).Background(tcell.ColorRed)\n\n\tmx, my := -1, -1\n\tox, oy := -1, -1\n\tbx, by := -1, -1\n\tw, h := s.Size()\n\tlchar := '*'\n\tbstr := \"\"\n\tlks := \"\"\n\tecnt := 0\n\n\tfor {\n\t\tdrawBox(s, 1, 1, 42, 6, white, ' ')\n\t\temitStr(s, 2, 2, white, \"Press ESC twice to exit, C to clear.\")\n\t\temitStr(s, 2, 3, white, fmt.Sprintf(posfmt, mx, my))\n\t\temitStr(s, 2, 4, white, fmt.Sprintf(btnfmt, bstr))\n\t\temitStr(s, 2, 5, white, fmt.Sprintf(keyfmt, lks))\n\n\t\ts.Show()\n\t\tbstr = \"\"\n\t\tev := s.PollEvent()\n\t\tst := tcell.StyleDefault.Background(tcell.ColorRed)\n\t\tup := tcell.StyleDefault.\n\t\t\tBackground(tcell.ColorBlue).\n\t\t\tForeground(tcell.ColorBlack)\n\t\tw, h = s.Size()\n\n\t\t// always clear any old selection box\n\t\tif ox >= 0 && oy >= 0 && bx >= 0 {\n\t\t\tdrawSelect(s, ox, oy, bx, by, false)\n\t\t}\n\n\t\tswitch ev := ev.(type) {\n\t\tcase *tcell.EventResize:\n\t\t\ts.Sync()\n\t\t\ts.SetContent(w-1, h-1, 'R', nil, st)\n\t\tcase *tcell.EventKey:\n\t\t\ts.SetContent(w-2, h-2, ev.Rune(), nil, st)\n\t\t\ts.SetContent(w-1, h-1, 'K', nil, st)\n\t\t\tif ev.Key() == tcell.KeyEscape {\n\t\t\t\tecnt++\n\t\t\t\tif ecnt > 1 {\n\t\t\t\t\ts.Fini()\n\t\t\t\t\tos.Exit(0)\n\t\t\t\t}\n\t\t\t} else if ev.Key() == tcell.KeyCtrlL {\n\t\t\t\ts.Sync()\n\t\t\t} else {\n\t\t\t\tecnt = 0\n\t\t\t\tif ev.Rune() == 'C' || ev.Rune() == 'c' {\n\t\t\t\t\ts.Clear()\n\t\t\t\t}\n\t\t\t}\n\t\t\tlks = ev.Name()\n\t\tcase *tcell.EventMouse:\n\t\t\tx, y := ev.Position()\n\t\t\tbutton := ev.Buttons()\n\t\t\tfor i := uint(0); i < 8; i++ {\n\t\t\t\tif int(button)&(1<<i) != 0 {\n\t\t\t\t\tbstr += fmt.Sprintf(\" Button%d\", i+1)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif button&tcell.WheelUp != 0 {\n\t\t\t\tbstr += \" WheelUp\"\n\t\t\t}\n\t\t\tif button&tcell.WheelDown != 0 {\n\t\t\t\tbstr += \" WheelDown\"\n\t\t\t}\n\t\t\tif button&tcell.WheelLeft != 0 {\n\t\t\t\tbstr += \" WheelLeft\"\n\t\t\t}\n\t\t\tif button&tcell.WheelRight != 0 {\n\t\t\t\tbstr += \" WheelRight\"\n\t\t\t}\n\t\t\t// Only buttons, not wheel events\n\t\t\tbutton &= tcell.ButtonMask(0xff)\n\t\t\tch := '*'\n\n\t\t\tif button != tcell.ButtonNone && ox < 0 {\n\t\t\t\tox, oy = x, y\n\t\t\t}\n\t\t\tswitch ev.Buttons() {\n\t\t\tcase tcell.ButtonNone:\n\t\t\t\tif ox >= 0 {\n\t\t\t\t\tbg := tcell.Color((lchar - '0') * 2)\n\t\t\t\t\tdrawBox(s, ox, oy, x, y,\n\t\t\t\t\t\tup.Background(bg),\n\t\t\t\t\t\tlchar)\n\t\t\t\t\tox, oy = -1, -1\n\t\t\t\t\tbx, by = -1, -1\n\t\t\t\t}\n\t\t\tcase tcell.Button1:\n\t\t\t\tch = '1'\n\t\t\tcase tcell.Button2:\n\t\t\t\tch = '2'\n\t\t\tcase tcell.Button3:\n\t\t\t\tch = '3'\n\t\t\tcase tcell.Button4:\n\t\t\t\tch = '4'\n\t\t\tcase tcell.Button5:\n\t\t\t\tch = '5'\n\t\t\tcase tcell.Button6:\n\t\t\t\tch = '6'\n\t\t\tcase tcell.Button7:\n\t\t\t\tch = '7'\n\t\t\tcase tcell.Button8:\n\t\t\t\tch = '8'\n\t\t\tdefault:\n\t\t\t\tch = '*'\n\n\t\t\t}\n\t\t\tif button != tcell.ButtonNone {\n\t\t\t\tbx, by = x, y\n\t\t\t}\n\t\t\tlchar = ch\n\t\t\ts.SetContent(w-1, h-1, 'M', nil, st)\n\t\t\tmx, my = x, y\n\t\tdefault:\n\t\t\ts.SetContent(w-1, h-1, 'X', nil, st)\n\t\t}\n\n\t\tif ox >= 0 && bx >= 0 {\n\t\t\tdrawSelect(s, ox, oy, bx, by, true)\n\t\t}\n\t}\n}", "label": 5}
{"code": "func (m *MockIndex) StructChan(arg0 chan struct{}) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"StructChan\", arg0)\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, appfwjsoncontenttype resource) throws Exception {\n\t\tappfwjsoncontenttype addresource = new appfwjsoncontenttype();\n\t\taddresource.jsoncontenttypevalue = resource.jsoncontenttypevalue;\n\t\taddresource.isregex = resource.isregex;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def generate_builtin_set(system_plugins=[])\n      builtin_set = BuiltinSet.new\n      @logger.debug(\"Generating new builtin set instance.\")\n      vagrant_internal_specs.each do |spec|\n        if !system_plugins.include?(spec.name)\n          builtin_set.add_builtin_spec(spec)\n        end\n      end\n      builtin_set\n    end", "label": 4}
{"code": "function getTplPath(tpl) {\n  const tplFile = path.join(__dirname, './templates', tpl);\n  const customTplDir =\n    _.get(config.getRekitConfig(), 'rekitReact.templateDir') ||\n    path.join(paths.map('.rekit-react/templates'));\n  const customTplFile = path.join(customTplDir, tpl);\n  return fs.existsSync(customTplFile) ? customTplFile : tplFile;\n}", "label": 3}
{"code": "def pairwise_compare(afa, leven, threads, print_list, ignore_gaps):\n    \"\"\"\n    make pairwise sequence comparisons between aligned sequences\n    \"\"\"\n    # load sequences into dictionary\n    seqs = {seq[0]: seq for seq in nr_fasta([afa], append_index = True)}\n    num_seqs = len(seqs)\n    # define all pairs\n    pairs = ((i[0], i[1], ignore_gaps) for i in itertools.combinations(list(seqs.values()), 2))\n    pool = multithread(threads)\n    # calc percent identity between all pairs - parallelize\n    if leven is True:\n        pident = pool.map(compare_seqs_leven, pairs)\n    else:\n        compare = pool.imap_unordered(compare_seqs, pairs)\n        pident = [i for i in tqdm(compare, total = (num_seqs*num_seqs)/2)]\n    pool.close()\n    pool.terminate()\n    pool.join()\n    return to_dictionary(pident, print_list)", "label": 1}
{"code": "final void waitForSizeQueue(final int queueSize) {\n    synchronized (this.queue) {\n      while (this.queue.size() > queueSize) {\n        try {\n          this.queue.wait(250L);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n        }\n      }\n      try {\n        Thread.sleep(500L);\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n      }\n      this.queue.notifyAll();\n    }\n  }", "label": 0}
{"code": "private static int getSqlInLimit()\r\n    {\r\n        try\r\n        {\r\n            PersistenceBrokerConfiguration config = (PersistenceBrokerConfiguration) PersistenceBrokerFactory\r\n                    .getConfigurator().getConfigurationFor(null);\r\n            return config.getSqlInLimit();\r\n        }\r\n        catch (ConfigurationException e)\r\n        {\r\n            return 200;\r\n        }\r\n    }", "label": 0}
{"code": "public static sslpolicy_lbvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tsslpolicy_lbvserver_binding obj = new sslpolicy_lbvserver_binding();\n\t\tobj.set_name(name);\n\t\tsslpolicy_lbvserver_binding response[] = (sslpolicy_lbvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (a *AuthenticateSSHRequest) CheckAndSetDefaults() error {\n\tif err := a.AuthenticateUserRequest.CheckAndSetDefaults(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif len(a.PublicKey) == 0 {\n\t\treturn trace.BadParameter(\"missing parameter 'public_key'\")\n\t}\n\tcertificateFormat, err := utils.CheckCertificateFormatFlag(a.CompatibilityMode)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\ta.CompatibilityMode = certificateFormat\n\treturn nil\n}", "label": 5}
{"code": "def total_cost(self, p=None, p_cost=None, pcost_model=None):\n        \"\"\" Computes total cost for the generator at the given output level.\n        \"\"\"\n        p = self.p if p is None else p\n        p_cost = self.p_cost if p_cost is None else p_cost\n        pcost_model = self.pcost_model if pcost_model is None else pcost_model\n\n        p = 0.0 if not self.online else p\n\n        if pcost_model == PW_LINEAR:\n            n_segments = len(p_cost) - 1\n            # Iterate over the piece-wise linear segments.\n            for i in range(n_segments):\n                x1, y1 = p_cost[i]\n                x2, y2 = p_cost[i + 1]\n                m = (y2 - y1) / (x2 - x1)\n                c = y1 - m * x1\n                if x1 <= p <= x2:\n                    result = m*p + c\n                    break\n            else:\n#                print \"TOTC:\", self.name, p, self.p_max, p_cost\n\n#                raise ValueError, \"Value [%f] outwith pwl cost curve.\" % p\n\n                # Use the last segment for values outwith the cost curve.\n                logger.error(\"Value [%f] outside pwl cost curve [%s].\" %\n                             (p, p_cost[-1][0]))\n                result = m*p + c\n        elif pcost_model == POLYNOMIAL:\n#            result = p_cost[-1]\n#            for i in range(1, len(p_cost)):\n#                result += p_cost[-(i + 1)] * p**i\n            result = polyval(p_cost, p)\n        else:\n            raise ValueError\n\n        if self.is_load:\n            return -result\n        else:\n            return result", "label": 1}
{"code": "public static dnspolicy64 get(nitro_service service, String name) throws Exception{\n\t\tdnspolicy64 obj = new dnspolicy64();\n\t\tobj.set_name(name);\n\t\tdnspolicy64 response = (dnspolicy64) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def change_return_type(f):\n    \"\"\"\n    Converts the returned value of wrapped function to the type of the\n    first arg or to the type specified by a kwarg key return_type's value.\n    \"\"\"\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        if kwargs.has_key('return_type'):\n            return_type = kwargs['return_type']\n            kwargs.pop('return_type')\n            return return_type(f(*args, **kwargs))\n        elif len(args) > 0:\n            return_type = type(args[0])\n            return return_type(f(*args, **kwargs))\n        else:\n            return f(*args, **kwargs)\n    return wrapper", "label": 1}
{"code": "function (driver, response, remote, options, deferred) {\n      // Provide a default error handler to prevent hangs.\n      if (!remote.onError) {\n        remote.onError = function (request, remote, options, deferred, data) {\n          data = JSON.parse(data);\n          var value = -1;\n          if (typeof data.value.message === 'string') {\n            var msg = JSON.parse(data.value.message);\n            value = msg.errorMessage;\n          }\n          deferred.resolve(JSON.stringify({'sessionId': data.sessionId, value: value}));\n        };\n      }\n      remote.onError.call(this, response, remote, options, deferred, this.data);\n      return this;\n    }", "label": 3}
{"code": "def signature\n      hook_config = @config.for_hook(@hook_name, @context.hook_class_name).\n                            dup.\n                            tap { |config| IGNORED_CONFIG_KEYS.each { |k| config.delete(k) } }\n\n      content_to_sign =\n        if signable_file?(hook_path) && Overcommit::GitRepo.tracked?(hook_path)\n          hook_contents\n        end\n\n      Digest::SHA256.hexdigest(content_to_sign.to_s + hook_config.to_s)\n    end", "label": 4}
{"code": "def add_javascripts(self, *js_files):\n        \"\"\"add javascripts files in HTML body\"\"\"\n        # create the script tag if don't exists\n        if self.main_soup.script is None:\n            script_tag = self.main_soup.new_tag('script')\n            self.main_soup.body.append(script_tag)\n\n        for js_file in js_files:\n            self.main_soup.script.append(self._text_file(js_file))", "label": 1}
{"code": "func (mr *MockIndexMockRecorder) Ellip(arg0 interface{}, arg1 ...interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\tvarargs := append([]interface{}{arg0}, arg1...)\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Ellip\", reflect.TypeOf((*MockIndex)(nil).Ellip), varargs...)\n}", "label": 5}
{"code": "def batch(parallel=true)\n      parallel = false if ENV[\"VAGRANT_NO_PARALLEL\"]\n\n      @batch_lock.synchronize do\n        BatchAction.new(parallel).tap do |b|\n          # Yield it so that the caller can setup actions\n          yield b\n\n          # And run it!\n          b.run\n        end\n      end\n    end", "label": 4}
{"code": "function validateMetadata(metadataPath, cb) {\n  validateJSonStructure(metadataPath, function(err, metadataObject) {\n    if (err) {\n      cb(err, null);\n    } else {\n      cb(null, metadataObject.files);\n    }\n  });\n}", "label": 3}
{"code": "private void init()\r\n    {\r\n        jdbcProperties = new Properties();\r\n        dbcpProperties = new Properties();\r\n        setFetchSize(0);\r\n        this.setTestOnBorrow(true);\r\n        this.setTestOnReturn(false);\r\n        this.setTestWhileIdle(false);\r\n        this.setLogAbandoned(false);\r\n        this.setRemoveAbandoned(false);\r\n    }", "label": 0}
{"code": "function () {\n            var result = {\n                name: this._name\n            };\n            if (!this._test) {\n                result.test = false;\n            }\n            if (this._tags.length) {\n                result.tags = this._tags.join(\" \");\n            }\n            return result;\n        }", "label": 3}
{"code": "protected DataSource wrapAsDataSource(JdbcConnectionDescriptor jcd,\r\n                                          ObjectPool connectionPool)\r\n    {\r\n        final boolean allowConnectionUnwrap;\r\n        if (jcd == null)\r\n        {\r\n            allowConnectionUnwrap = false;\r\n        }\r\n        else\r\n        {\r\n            final Properties properties = jcd.getConnectionPoolDescriptor().getDbcpProperties();\r\n            final String allowConnectionUnwrapParam;\r\n            allowConnectionUnwrapParam = properties.getProperty(PARAM_NAME_UNWRAP_ALLOWED);\r\n            allowConnectionUnwrap = allowConnectionUnwrapParam != null &&\r\n                    Boolean.valueOf(allowConnectionUnwrapParam).booleanValue();\r\n        }\r\n        final PoolingDataSource dataSource;\r\n        dataSource = new PoolingDataSource(connectionPool);\r\n        dataSource.setAccessToUnderlyingConnectionAllowed(allowConnectionUnwrap);\r\n\r\n        if(jcd != null)\r\n        {\r\n            final AbandonedConfig ac = jcd.getConnectionPoolDescriptor().getAbandonedConfig();\r\n            if (ac.getRemoveAbandoned() && ac.getLogAbandoned()) {\r\n                final LoggerWrapperPrintWriter loggerPiggyBack;\r\n                loggerPiggyBack = new LoggerWrapperPrintWriter(log, Logger.ERROR);\r\n                dataSource.setLogWriter(loggerPiggyBack);\r\n            }\r\n        }\r\n        return dataSource;\r\n    }", "label": 0}
{"code": "def collection_dir(*files)\n      return directory if files.empty?\n\n      site.in_source_dir(container, relative_directory, *files)\n    end", "label": 4}
{"code": "func (ww *WidgetWatchers) PostEvent(wev EventWidget) {\n\tfor watcher := range ww.watchers {\n\t\t// Deliver events to all listeners, ignoring return value.\n\t\twatcher.HandleEvent(wev)\n\t}\n}", "label": 5}
{"code": "public void store(Object obj, ObjectModification mod) throws PersistenceBrokerException\n    {\n        obj = extractObjectToStore(obj);\n        // null for unmaterialized Proxy\n        if (obj == null)\n        {\n            return;\n        }\n\n        ClassDescriptor cld = getClassDescriptor(obj.getClass());\n        // this call ensures that all autoincremented primary key attributes are filled\n        Identity oid = serviceIdentity().buildIdentity(cld, obj);\n        // select flag for insert / update selection by checking the ObjectModification\n        if (mod.needsInsert())\n        {\n            store(obj, oid, cld, true);\n        }\n        else if (mod.needsUpdate())\n        {\n            store(obj, oid, cld, false);\n        }\n        /*\n        arminw\n        TODO: Why we need this behaviour? What about 1:1 relations?\n        */\n        else\n        {\n            // just store 1:n and m:n associations\n            storeCollections(obj, cld, mod.needsInsert());\n        }\n    }", "label": 0}
{"code": "public double[][] getU() {\n        double[][] X = new double[n][n];\n        double[][] U = X;\n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j++) {\n                if (i <= j) {\n                    U[i][j] = LU[i][j];\n                } else {\n                    U[i][j] = 0.0;\n                }\n            }\n        }\n        return X;\n    }", "label": 0}
{"code": "def write_parts(zip)\n      p = parts\n      p.each do |part|\n        unless part[:doc].nil?\n          zip.put_next_entry(zip_entry_for_part(part))\n          part[:doc].to_xml_string(zip)\n        end\n        unless part[:path].nil?\n          zip.put_next_entry(zip_entry_for_part(part))\n          zip.write IO.read(part[:path])\n        end\n      end\n      zip\n    end", "label": 4}
{"code": "func (app *Application) Quit() {\n\tev := &eventAppQuit{}\n\tev.SetEventNow()\n\tif scr := app.screen; scr != nil {\n\t\tgo func() { scr.PostEventWait(ev) }()\n\t}\n}", "label": 5}
{"code": "public static audit_stats get(nitro_service service,  options option) throws Exception{\n\t\taudit_stats obj = new audit_stats();\n\t\taudit_stats[] response = (audit_stats[])obj.stat_resources(service,option);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def managed?\n    # Once an object is managed, it always stays managed; but an object\n    # that is listed as unmanaged might become managed later in the process,\n    # so we have to check that every time\n    if @managed\n      return @managed\n    else\n      @managed = false\n      properties.each { |property|\n        s = property.should\n        if s and ! property.class.unmanaged\n          @managed = true\n          break\n        end\n      }\n      return @managed\n    end\n  end", "label": 4}
{"code": "def fetch(key, ttl=nil, options=nil)\n      options = options.nil? ? CACHE_NILS : options.merge(CACHE_NILS) if @options[:cache_nils]\n      val = get(key, options)\n      not_found = @options[:cache_nils] ?\n        val == Dalli::Server::NOT_FOUND :\n        val.nil?\n      if not_found && block_given?\n        val = yield\n        add(key, val, ttl_or_default(ttl), options)\n      end\n      val\n    end", "label": 4}
{"code": "func PgCollationByOid(db XODB, oid pgtypes.Oid) (*PgCollation, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, collname, collnamespace, collowner, collencoding, collcollate, collctype ` +\n\t\t`FROM pg_catalog.pg_collation ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpc := PgCollation{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pc.Tableoid, &pc.Cmax, &pc.Xmax, &pc.Cmin, &pc.Xmin, &pc.Oid, &pc.Ctid, &pc.Collname, &pc.Collnamespace, &pc.Collowner, &pc.Collencoding, &pc.Collcollate, &pc.Collctype)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pc, nil\n}", "label": 5}
{"code": "def replace_col(self, line, ndx):\n        \"\"\" \n        replace a grids column at index 'ndx' with 'line' \n        \"\"\"\n        for row in range(len(line)):\n            self.set_tile(row, ndx, line[row])", "label": 1}
{"code": "func OptionDiscoveryWatcher(watcher discovery.Watcher) Option {\n\treturn func(c *Config) {\n\t\tc.Cluster.Watcher = watcher\n\t}\n}", "label": 5}
{"code": "def load_plugins(group='metrics.plugin.10'):\n    \"\"\"Load and installed metrics plugins.\n    \"\"\"\n    # on using entrypoints:\n    # http://stackoverflow.com/questions/774824/explain-python-entry-points\n    file_processors = []\n    build_processors = []\n    for ep in pkg_resources.iter_entry_points(group, name=None):\n        log.debug('loading \\'%s\\'', ep)\n        plugin = ep.load()  # load the plugin\n        if hasattr(plugin, 'get_file_processors'):\n            file_processors.extend(plugin.get_file_processors())\n        if hasattr(plugin, 'get_build_processors'):\n            build_processors.extend(plugin.get_build_processors())\n    return file_processors, build_processors", "label": 1}
{"code": "public static function isContainedByInPhp(\n        Type\\Union $input_type = null,\n        Type\\Union $container_type\n    ) {\n        if (!$input_type) {\n            return false;\n        }\n\n        if ($input_type->getId() === $container_type->getId()) {\n            return true;\n        }\n\n        if ($input_type->isNullable() && !$container_type->isNullable()) {\n            return false;\n        }\n\n        $input_type_not_null = clone $input_type;\n        $input_type_not_null->removeType('null');\n\n        $container_type_not_null = clone $container_type;\n        $container_type_not_null->removeType('null');\n\n        if ($input_type_not_null->getId() === $container_type_not_null->getId()) {\n            return true;\n        }\n\n        if ($input_type_not_null->hasArray() && $container_type_not_null->hasType('iterable')) {\n            return true;\n        }\n\n        return false;\n    }", "label": 2}
{"code": "function transform(flapjack, pluginOptions, runtimeOptions) {\n    var name = runtimeOptions.transformer;\n    var transformer = transformerFactory.getTransformer(name, clientPlugin, pluginOptions);\n    var options = _.extend({}, pluginOptions, runtimeOptions);\n    return transformer.transform(flapjack, options);\n}", "label": 3}
{"code": "func (c *crontime) nextValidSecond(baseTime time.Time) {\n\tfor _, sec := range c.second {\n\t\tif !c.minuteHasPassed(baseTime) {\n\t\t\t// check if sec is in the past. <= prevents triggering the same event twice\n\t\t\tif sec > c.calculatedTime.Second() {\n\t\t\t\tc.calculatedTime = setSecond(c.calculatedTime, sec)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else {\n\t\t\tc.calculatedTime = setSecond(c.calculatedTime, sec)\n\t\t\treturn\n\t\t}\n\t}\n\tc.calculatedTime = c.calculatedTime.Add(1 * time.Minute)\n\tc.calculatedTime = setSecond(c.calculatedTime, 0)\n\t//log.Println(\"Cronbee: Second\", c.calculatedTime, baseTime)\n\tc.nextValidMinute(baseTime)\n\tc.nextValidSecond(baseTime)\n}", "label": 5}
{"code": "def delete!\n      Scripts.call(\n        :delete,\n        redis_pool,\n        keys: [exists_key, grabbed_key, available_key, version_key, UNIQUE_SET, unique_digest],\n      )\n    end", "label": 4}
{"code": "func LookupGidFromFile(groupName, groupFile string) (gid int, err error) {\n\tgroups, err := parseGroupFile(groupFile)\n\tif err != nil {\n\t\treturn -1, errwrap.Wrap(fmt.Errorf(\"error parsing %q file\", groupFile), err)\n\t}\n\n\tgroup, ok := groups[groupName]\n\tif !ok {\n\t\treturn -1, fmt.Errorf(\"%q group not found\", groupName)\n\t}\n\n\treturn group.Gid, nil\n}", "label": 5}
{"code": "function bufferloader (url, limit = 0, limitJustByBody = false, redirCount = 3) {\n    return new Promise((resolve, reject) => {\n\n        if (redirCount <= 0) {\n            reject(new Error('Too many redirects'));\n        }\n\n        let totalLength = 0;\n        let buf = Buffer.alloc(0);\n\n        const req = https.get(url, (res) => {\n\n            if (res.statusCode === 301 && res.headers && res.headers.location) {\n                // redirect\n                req.removeAllListeners();\n                resolve(bufferloader(res.headers.location, limit, limitJustByBody, redirCount - 1));\n                return;\n            }\n\n            if (res.statusCode !== 200) {\n                req.removeAllListeners();\n                reject(new Error(res.statusMessage || 'Cant load'));\n                return;\n            }\n\n            if (!limitJustByBody && limit > 0 && res.headers && res.headers['content-length']) {\n                const len = parseInt(res.headers['content-length'], 10);\n                if (!Number.isNaN(len) && len > limit) {\n                    req.removeAllListeners();\n                    reject(sizeLimitExceeded(limit, len));\n                    return;\n                }\n            }\n\n            const cleanup = () => {\n                res.removeAllListeners();\n                req.removeAllListeners();\n            };\n\n            res.on('data', (data) => {\n                totalLength += data.length;\n                if (limit > 0 && totalLength > limit) {\n                    cleanup();\n                    res.destroy();\n                    reject(sizeLimitExceeded(limit, totalLength));\n                    return;\n                }\n\n                buf = Buffer.concat([\n                    buf,\n                    data\n                ]);\n            });\n\n            res.on('end', () => {\n                cleanup();\n                resolve(buf);\n            });\n\n        });\n\n        req.on('error', (err) => {\n            req.removeAllListeners();\n            reject(err);\n        });\n    });\n}", "label": 3}
{"code": "def _macaroon_id_ops(ops):\n    '''Return operations suitable for serializing as part of a MacaroonId.\n\n    It assumes that ops has been canonicalized and that there's at least\n    one operation.\n    '''\n    id_ops = []\n    for entity, entity_ops in itertools.groupby(ops, lambda x: x.entity):\n        actions = map(lambda x: x.action, entity_ops)\n        id_ops.append(id_pb2.Op(entity=entity, actions=actions))\n    return id_ops", "label": 1}
{"code": "func (p *fileParser) parseFile(importPath string, file *ast.File) (*model.Package, error) {\n\tallImports, dotImports := importsOfFile(file)\n\t// Don't stomp imports provided by -imports. Those should take precedence.\n\tfor pkg, path := range allImports {\n\t\tif _, ok := p.imports[pkg]; !ok {\n\t\t\tp.imports[pkg] = path\n\t\t}\n\t}\n\t// Add imports from auxiliary files, which might be needed for embedded interfaces.\n\t// Don't stomp any other imports.\n\tfor _, f := range p.auxFiles {\n\t\tauxImports, _ := importsOfFile(f)\n\t\tfor pkg, path := range auxImports {\n\t\t\tif _, ok := p.imports[pkg]; !ok {\n\t\t\t\tp.imports[pkg] = path\n\t\t\t}\n\t\t}\n\t}\n\n\tvar is []*model.Interface\n\tfor ni := range iterInterfaces(file) {\n\t\ti, err := p.parseInterface(ni.name.String(), importPath, ni.it)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tis = append(is, i)\n\t}\n\treturn &model.Package{\n\t\tName:       file.Name.String(),\n\t\tInterfaces: is,\n\t\tDotImports: dotImports,\n\t}, nil\n}", "label": 5}
{"code": "public function invoke(string $functionName, $event = null): InvocationResult\n    {\n        $rawResult = $this->lambda->invoke([\n            'FunctionName' => $functionName,\n            'LogType' => 'Tail',\n            'Payload' => $event ?? '',\n        ]);\n\n        /** @var StreamInterface $resultPayload */\n        $resultPayload = $rawResult->get('Payload');\n        $resultPayload = json_decode($resultPayload->getContents(), true);\n\n        $invocationResult = new InvocationResult($rawResult, $resultPayload);\n\n        $error = $rawResult->get('FunctionError');\n        if ($error) {\n            throw new InvocationFailed($invocationResult);\n        }\n\n        return $invocationResult;\n    }", "label": 2}
{"code": "def read_into_buffer(buffer, size)\n      i = 0\n      while i < size\n        # If the read buffer is exhausted, try to read up to DEFAULT_BUFFER more bytes into it.\n        if @index >= @rbuf.size\n          @rbuf = @transport.read(DEFAULT_BUFFER)\n          @index = 0\n        end\n\n        # The read buffer has some data now, so copy bytes over to the output buffer.\n        byte = Bytes.get_string_byte(@rbuf, @index)\n        Bytes.set_string_byte(buffer, i, byte)\n        @index += 1\n        i += 1\n      end\n      i\n    end", "label": 4}
{"code": "def read_struct\n      klass_name = read(cache: false)\n      klass = safe_const_get(klass_name)\n      attributes = read_hash(cache: false)\n      args = attributes.values_at(*klass.members)\n      result = klass.new(*args)\n      @object_cache << result\n      result\n    end", "label": 4}
{"code": "public static Field getField(Class clazz, String fieldName)\r\n    {\r\n        try\r\n        {\r\n            return clazz.getField(fieldName);\r\n        }\r\n        catch (Exception ignored)\r\n        {}\r\n        return null;\r\n    }", "label": 0}
{"code": "public function getPreferencesAttribute($value)\n    {\n        $defaults = array_map(function ($value) {\n            return $value['default'];\n        }, static::$preferences);\n\n        $user = array_only((array) json_decode($value, true), array_keys(static::$preferences));\n\n        return array_merge($defaults, $user);\n    }", "label": 2}
{"code": "public void check(FieldDescriptorDef fieldDef, String checkLevel) throws ConstraintException\r\n    {\r\n        ensureColumn(fieldDef, checkLevel);\r\n        ensureJdbcType(fieldDef, checkLevel);\r\n        ensureConversion(fieldDef, checkLevel);\r\n        ensureLength(fieldDef, checkLevel);\r\n        ensurePrecisionAndScale(fieldDef, checkLevel);\r\n        checkLocking(fieldDef, checkLevel);\r\n        checkSequenceName(fieldDef, checkLevel);\r\n        checkId(fieldDef, checkLevel);\r\n        if (fieldDef.isAnonymous())\r\n        {\r\n            checkAnonymous(fieldDef, checkLevel);\r\n        }\r\n        else\r\n        {\r\n            checkReadonlyAccessForNativePKs(fieldDef, checkLevel);\r\n        }\r\n    }", "label": 0}
{"code": "function( error ) {\n\t\tif( error instanceof Buffer && error.toString().match( app.options.errorMessage ) ) {\n\t\t\tinitialized( 'Development server has error.' );\n\t\t}\n\t}", "label": 3}
{"code": "func funcArgsFromType(t reflect.Type) (in []*Parameter, variadic *Parameter, out []*Parameter, err error) {\n\tnin := t.NumIn()\n\tif t.IsVariadic() {\n\t\tnin--\n\t}\n\tvar p *Parameter\n\tfor i := 0; i < nin; i++ {\n\t\tp, err = parameterFromType(t.In(i))\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tin = append(in, p)\n\t}\n\tif t.IsVariadic() {\n\t\tp, err = parameterFromType(t.In(nin).Elem())\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tvariadic = p\n\t}\n\tfor i := 0; i < t.NumOut(); i++ {\n\t\tp, err = parameterFromType(t.Out(i))\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tout = append(out, p)\n\t}\n\treturn\n}", "label": 5}
{"code": "public void setDoubleAttribute(String name, Double value) {\n\t\tensureAttributes();\n\t\tAttribute attribute = new DoubleAttribute(value);\n\t\tattribute.setEditable(isEditable(name));\n\t\tgetAllAttributes().put(name, attribute);\n\n\t}", "label": 0}
{"code": "def addnot(self, action=None, subject=None, **conditions):\n        \"\"\"\n        Defines an ability which cannot be done.\n        \"\"\"\n        self.add_rule(Rule(False, action, subject, **conditions))", "label": 1}
{"code": "def set_content_type_and_size_in_model\n      model.content_type = file.content_type if file.content_type\n      model.file_size = file.size\n    end", "label": 4}
{"code": "def render_ruby(engine, template, options={}, locals={}, &block)\n      options, template = template, nil if template.is_a?(Hash)\n      template = Proc.new { block } if template.nil?\n      render engine, template, options, locals\n    end", "label": 4}
{"code": "def get_string_for_issue(issue)\n      encapsulated_title = encapsulate_string issue[\"title\"]\n\n      title_with_number = \"#{encapsulated_title} [\\\\##{issue['number']}](#{issue['html_url']})\"\n      title_with_number = \"#{title_with_number}#{line_labels_for(issue)}\" if @options[:issue_line_labels].present?\n      line = issue_line_with_user(title_with_number, issue)\n      issue_line_with_body(line, issue)\n    end", "label": 4}
{"code": "function parseIncrementExpression() {\n            if (token() === 41 /* PlusPlusToken */ || token() === 42 /* MinusMinusToken */) {\n                var node = createNode(185 /* PrefixUnaryExpression */);\n                node.operator = token();\n                nextToken();\n                node.operand = parseLeftHandSideExpressionOrHigher();\n                return finishNode(node);\n            }\n            else if (sourceFile.languageVariant === 1 /* JSX */ && token() === 25 /* LessThanToken */ && lookAhead(nextTokenIsIdentifierOrKeyword)) {\n                // JSXElement is part of primaryExpression\n                return parseJsxElementOrSelfClosingElement(/*inExpressionContext*/ true);\n            }\n            var expression = parseLeftHandSideExpressionOrHigher();\n            ts.Debug.assert(ts.isLeftHandSideExpression(expression));\n            if ((token() === 41 /* PlusPlusToken */ || token() === 42 /* MinusMinusToken */) && !scanner.hasPrecedingLineBreak()) {\n                var node = createNode(186 /* PostfixUnaryExpression */, expression.pos);\n                node.operand = expression;\n                node.operator = token();\n                nextToken();\n                return finishNode(node);\n            }\n            return expression;\n        }", "label": 3}
{"code": "private Object getLiteralValue(Expression expression) {\n\t\tif (!(expression instanceof Literal)) {\n\t\t\tthrow new IllegalArgumentException(\"Expression \" + expression + \" is not a Literal.\");\n\t\t}\n\t\treturn ((Literal) expression).getValue();\n\t}", "label": 0}
{"code": "def paragraph(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'paragraph_for', &block)\n      define_method(name) do\n        return platform.paragraph_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "public static function getAvailableLocalesInfo()\n    {\n        $languages = [];\n        foreach (static::getAvailableLocales() as $id) {\n            $languages[$id] = new Language($id);\n        }\n\n        return $languages;\n    }", "label": 2}
{"code": "def send_message(channel, content, tts = false, embed = nil)\n      channel = channel.resolve_id\n      debug(\"Sending message to #{channel} with content '#{content}'\")\n\n      response = API::Channel.create_message(token, channel, content, tts, embed ? embed.to_hash : nil)\n      Message.new(JSON.parse(response), self)\n    end", "label": 4}
{"code": "func (a *AuthWithRoles) DeleteClusterName() error {\n\tif err := a.action(defaults.Namespace, services.KindClusterName, services.VerbDelete); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.DeleteClusterName()\n}", "label": 5}
{"code": "def write(self, text):\n        \"\"\"Override the standard write method to filter the content.\"\"\"\n        index = text.find('\\n')\n        if index == -1:\n            self._buffer = self._buffer + text\n        else:\n            self._buffer = self._buffer + text[:index + 1]\n            if self._pattern:\n                # pattern already compiled no need to check\n                result = re.search(self._pattern, self._buffer)\n                if result:\n                    for group in result.groups():\n                        if group:\n                            self._buffer = self._buffer.replace(group, \"***\")\n            self._file.write(self._buffer)\n            self._file.flush()\n            self._buffer = text[index + 1:]", "label": 1}
{"code": "function getSourceRepeatingSections(rule) {\n    return _.chain(rule.ruleConditionalStatements)\n      .map(function(ruleConditionalStatement) {\n        var sourceId = ruleConditionalStatement.sourceField.toString();\n        return fieldSectionMapping[sourceId];\n      })\n      .filter(function(section) {\n        return section && section.repeating;\n      })\n      .map(function(repeatingSection) {\n        return repeatingSection._id.toString();\n      })\n      .uniq()\n      .value();\n  }", "label": 3}
{"code": "def do_your_job(self):\n        \"\"\"\n        the goal of the explore agent is to move to the \n        target while avoiding blockages on the grid.\n        This function is messy and needs to be looked at.\n        It currently has a bug in that the backtrack oscillates\n        so need a new method of doing this - probably checking if\n        previously backtracked in that direction for those coords, ie\n        keep track of cells visited and number of times visited?\n        \"\"\"\n        y,x = self.get_intended_direction()  # first find out where we should go\n        if self.target_x == self.current_x and self.target_y == self.current_y:\n            #print(self.name + \" : TARGET ACQUIRED\")\n            if len(self.results) == 0:\n                self.results.append(\"TARGET ACQUIRED\")\n                self.lg_mv(2, self.name + \": TARGET ACQUIRED\" )\n            \n            return\n        \n        self.num_steps += 1   \n        # first try is to move on the x axis in a simple greedy search\n        accessible = ['\\\\', '-', '|', '/', '.']\n        \n        # randomly move in Y direction instead of X if all paths clear\n        if y != 0 and x != 0 and self.backtrack == [0,0]:\n            if random.randint(1,10) > 6:\n                if self.grd.get_tile(self.current_y + y, self.current_x) in accessible:\n                    self.current_y += y\n                    self.lg_mv(3, self.name + \": randomly moving Y axis \" + str(self.num_steps)  )\n                    return\n        if x == 1:\n            if self.grd.get_tile(self.current_y, self.current_x + 1) in accessible:\n                self.current_x += 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving West\" )\n                return\n        elif x == -1:\n            if self.grd.get_tile(self.current_y, self.current_x - 1) in accessible:\n                self.current_x -= 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving East\" )\n                return\n        elif y == 1:\n            if self.grd.get_tile(self.current_y + 1, self.current_x) in accessible:\n                self.current_y += 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving South\" )\n                return\n        elif y == -1:\n            if self.grd.get_tile(self.current_y - 1, self.current_x) in accessible:\n                self.current_y -= 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving North\")\n                return\n        \n        self.grd.set_tile(self.start_y, self.start_x, 'A')\n        self.grd.save(os.path.join(os.getcwd(), 'agent.txt'))", "label": 1}
{"code": "public function setTransformation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\PrimitiveTransformation::class);\n        $this->transformation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function refract(value) {\n  if (value instanceof Element) {\n    return value;\n  }\n\n  if (typeof value === 'string') {\n    return new StringElement(value);\n  }\n\n  if (typeof value === 'number') {\n    return new NumberElement(value);\n  }\n\n  if (typeof value === 'boolean') {\n    return new BooleanElement(value);\n  }\n\n  if (value === null) {\n    return new NullElement();\n  }\n\n  if (Array.isArray(value)) {\n    return new ArrayElement(value.map(refract));\n  }\n\n  if (typeof value === 'object') {\n    const element = new ObjectElement(value);\n    return element;\n  }\n\n  return value;\n}", "label": 3}
{"code": "public void deleteModule(final String moduleId) {\n        final DbModule module = getModule(moduleId);\n        repositoryHandler.deleteModule(module.getId());\n\n        for (final String gavc : DataUtils.getAllArtifacts(module)) {\n            repositoryHandler.deleteArtifact(gavc);\n        }\n    }", "label": 0}
{"code": "func (f *Fpdf) RegisterImageReader(imgName, tp string, r io.Reader) (info *ImageInfoType) {\n\toptions := ImageOptions{\n\t\tReadDpi:   false,\n\t\tImageType: tp,\n\t}\n\treturn f.RegisterImageOptionsReader(imgName, options, r)\n}", "label": 5}
{"code": "def _c3_mro(cls, abcs=None):\n    \"\"\"Computes the method resolution order using extended C3 linearization.\n\n    If no *abcs* are given, the algorithm works exactly like the built-in C3\n    linearization used for method resolution.\n\n    If given, *abcs* is a list of abstract base classes that should be inserted\n    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the\n    result. The algorithm inserts ABCs where their functionality is introduced,\n    i.e. issubclass(cls, abc) returns True for the class itself but returns\n    False for all its direct base classes. Implicit ABCs for a given class\n    (either registered or inferred from the presence of a special method like\n    __len__) are inserted directly after the last ABC explicitly listed in the\n    MRO of said class. If two implicit ABCs end up next to each other in the\n    resulting MRO, their ordering depends on the order of types in *abcs*.\n\n    \"\"\"\n    for i, base in enumerate(reversed(cls.__bases__)):\n        if hasattr(base, '__abstractmethods__'):\n            boundary = len(cls.__bases__) - i\n            break  # Bases up to the last explicit ABC are considered first.\n    else:\n        boundary = 0\n    abcs = list(abcs) if abcs else []\n    explicit_bases = list(cls.__bases__[:boundary])\n    abstract_bases = []\n    other_bases = list(cls.__bases__[boundary:])\n    for base in abcs:\n        if issubclass(cls, base) and not any(issubclass(b, base) for b in cls.__bases__):\n            # If *cls* is the class that introduces behaviour described by\n            # an ABC *base*, insert said ABC to its MRO.\n            abstract_bases.append(base)\n    for base in abstract_bases:\n        abcs.remove(base)\n    explicit_c3_mros = [_c3_mro(base, abcs=abcs) for base in explicit_bases]\n    abstract_c3_mros = [_c3_mro(base, abcs=abcs) for base in abstract_bases]\n    other_c3_mros = [_c3_mro(base, abcs=abcs) for base in other_bases]\n    return _c3_merge(\n        [[cls]] + explicit_c3_mros + abstract_c3_mros + other_c3_mros + [explicit_bases] + [abstract_bases] + [\n            other_bases])", "label": 1}
{"code": "async function compileProgram (dirPath, command) {\n  await validateDirPathForCLI(dirPath);\n  const params = pick(command, [\n    'fontName',\n    'sassPlaceholder',\n    'cssClass',\n    'fontTypes',\n    'styleFormats',\n    'styleDest',\n    'styleName',\n    'fontDest',\n    'authorName',\n    'authorUrl',\n    'className',\n    'previewDest',\n    'preview',\n    'catalogDest',\n\n    'experimentalFontOnCatalog',\n    'experimentalDisableStyles'\n  ]);\n\n  try {\n    return collecticonsCompile({\n      dirPath,\n      ...params\n    });\n  } catch (error) {\n    if (!error.userError) throw error;\n    // Capture some errors and convert to their command line alternative.\n    const code = error.code;\n    if (code === 'PLC_CLASS_EXC') {\n      error.details = ['Error: --no-sass-placeholder and --no-css-class are mutually exclusive'];\n    } else if (code === 'FONT_TYPE') {\n      error.details = ['Error: invalid font type value passed to --font-types'];\n    } else if (code === 'CLASS_CSS_FORMAT') {\n      error.details = ['Error: \"--no-css-class\" and \"--style-formats css\" are not compatible'];\n    } else if (code === 'STYLE_TYPE') {\n      error.details = ['Error: invalid style format value passed to --style-format'];\n    }\n\n    throw error;\n  }\n}", "label": 3}
{"code": "async function setPreferredMcpRegionalSettings(accessToken, languageTag) {\n    let regionalSettings = getValidLanguageTagOrThrow(languageTag);\n\n    return mcpCustomizr.putSettings(accessToken, {\n        regionalSettings: regionalSettings,\n    });\n}", "label": 3}
{"code": "func NewClient(ctx context.Context, c *vim25.Client) (*Client, error) {\n\tfilter := &types.LookupServiceRegistrationFilter{\n\t\tServiceType: &types.LookupServiceRegistrationServiceType{\n\t\t\tProduct: \"com.vmware.cis\",\n\t\t\tType:    \"sso:sts\",\n\t\t},\n\t\tEndpointType: &types.LookupServiceRegistrationEndpointType{\n\t\t\tProtocol: \"wsTrust\",\n\t\t\tType:     \"com.vmware.cis.cs.identity.sso\",\n\t\t},\n\t}\n\n\turl := lookup.EndpointURL(ctx, c, Path, filter)\n\tsc := c.Client.NewServiceClient(url, Namespace)\n\n\treturn &Client{sc}, nil\n}", "label": 5}
{"code": "func (a *AuthServer) RotateExternalCertAuthority(ca services.CertAuthority) error {\n\tif ca == nil {\n\t\treturn trace.BadParameter(\"missing certificate authority\")\n\t}\n\tclusterName, err := a.GetClusterName()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// this is just an extra precaution against local admins,\n\t// because this is additionally enforced by RBAC as well\n\tif ca.GetClusterName() == clusterName.GetClusterName() {\n\t\treturn trace.BadParameter(\"can not rotate local certificate authority\")\n\t}\n\n\texisting, err := a.Trust.GetCertAuthority(services.CertAuthID{\n\t\tType:       ca.GetType(),\n\t\tDomainName: ca.GetClusterName(),\n\t}, false)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tupdated := existing.Clone()\n\tupdated.SetCheckingKeys(ca.GetCheckingKeys())\n\tupdated.SetTLSKeyPairs(ca.GetTLSKeyPairs())\n\tupdated.SetRotation(ca.GetRotation())\n\n\t// use compare and swap to protect from concurrent updates\n\t// by trusted cluster API\n\tif err := a.CompareAndSwapCertAuthority(updated, existing); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function lessThan(xs, ys) {\r\n    for (let i = 0; i < Math.min(xs.length, ys.length); i++) {\r\n        if (xs[i] < ys[i])\r\n            return true;\r\n        if (xs[i] > ys[i])\r\n            return false;\r\n    }\r\n    return xs.length < ys.length;\r\n}", "label": 3}
{"code": "@Override\n    public void setValue(String value, boolean fireEvents) {\n\tboolean added = setSelectedValue(this, value, addMissingValue);\n\tif (added && fireEvents) {\n\t    ValueChangeEvent.fire(this, getValue());\n\t}\n    }", "label": 0}
{"code": "public static function mapRequest(callable $f)\n    {\n        return function (callable $handler) use ($f) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler, $f) {\n                return $handler($command, $f($request));\n            };\n        };\n    }", "label": 2}
{"code": "def program(key, *args, &block)\n      if key == :help && !args.empty?\n        @program[:help] ||= {}\n        @program[:help][args.first] = args.at(1)\n      elsif key == :help_formatter && !args.empty?\n        @program[key] = (@help_formatter_aliases[args.first] || args.first)\n      elsif block\n        @program[key] = block\n      else\n        unless args.empty?\n          @program[key] = args.count == 1 ? args[0] : args\n        end\n        @program[key]\n      end\n    end", "label": 4}
{"code": "public function item($item, $transformer, $parameters = [], Closure $after = null)\n    {\n        $class = get_class($item);\n\n        if ($parameters instanceof \\Closure) {\n            $after = $parameters;\n            $parameters = [];\n        }\n\n        $binding = $this->transformer->register($class, $transformer, $parameters, $after);\n\n        return new Response($item, 200, [], $binding);\n    }", "label": 2}
{"code": "private void sortFileList() {\n    if (this.size() > 1) {\n      Collections.sort(this.fileList, new Comparator() {\n\n        public final int compare(final Object o1, final Object o2) {\n          final File f1 = (File) o1;\n          final File f2 = (File) o2;\n          final Object[] f1TimeAndCount = backupSuffixHelper\n              .backupTimeAndCount(f1.getName(), baseFile);\n          final Object[] f2TimeAndCount = backupSuffixHelper\n              .backupTimeAndCount(f2.getName(), baseFile);\n          final long f1TimeSuffix = ((Long) f1TimeAndCount[0]).longValue();\n          final long f2TimeSuffix = ((Long) f2TimeAndCount[0]).longValue();\n          if ((0L == f1TimeSuffix) && (0L == f2TimeSuffix)) {\n            final long f1Time = f1.lastModified();\n            final long f2Time = f2.lastModified();\n            if (f1Time < f2Time) {\n              return -1;\n            }\n            if (f1Time > f2Time) {\n              return 1;\n            }\n            return 0;\n          }\n          if (f1TimeSuffix < f2TimeSuffix) {\n            return -1;\n          }\n          if (f1TimeSuffix > f2TimeSuffix) {\n            return 1;\n          }\n          final int f1Count = ((Integer) f1TimeAndCount[1]).intValue();\n          final int f2Count = ((Integer) f2TimeAndCount[1]).intValue();\n          if (f1Count < f2Count) {\n            return -1;\n          }\n          if (f1Count > f2Count) {\n            return 1;\n          }\n          if (f1Count == f2Count) {\n            if (fileHelper.isCompressed(f1)) {\n              return -1;\n            }\n            if (fileHelper.isCompressed(f2)) {\n              return 1;\n            }\n          }\n          return 0;\n        }\n      });\n    }\n  }", "label": 0}
{"code": "func (tl TypeLoader) LoadIndexColumns(args *ArgType, ixTpl *Index) error {\n\tvar err error\n\n\t// load index columns\n\tindexCols, err := tl.IndexColumnList(args.DB, args.Schema, ixTpl.Type.Table.TableName, ixTpl.Index.IndexName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// process index columns\n\tfor _, ic := range indexCols {\n\t\tvar field *Field\n\n\tfieldLoop:\n\t\t// find field\n\t\tfor _, f := range ixTpl.Type.Fields {\n\t\t\tif f.Col.ColumnName == ic.ColumnName {\n\t\t\t\tfield = f\n\t\t\t\tbreak fieldLoop\n\t\t\t}\n\t\t}\n\n\t\tif field == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tixTpl.Fields = append(ixTpl.Fields, field)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "async def load_message_field(obj, msg, field, field_archiver=None):\n    \"\"\"\n    Loads message field from the object. Field is defined by the message field specification.\n    Returns loaded value, supports field reference.\n\n    :param reader:\n    :param msg:\n    :param field:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    fname, ftype, params = field[0], field[1], field[2:]\n    field_archiver = field_archiver if field_archiver else load_field\n    await field_archiver(obj[fname], ftype, params, eref(msg, fname))", "label": 1}
{"code": "function addModelCell (propertyName, model, cellDefinitions) {\n  const cell = {}\n\n  var defName = propertyName\n  var counter = 1\n\n  while (defName in cellDefinitions) {\n    defName = `${propertyName}${counter}`\n    counter++\n  }\n\n  cellDefinitions[defName] = cell\n\n  const props = getPropertyOrder(model.properties)\n  const children = props.map((propName) => {\n    // we have a circular dependency\n    /* eslint-disable no-use-before-define */\n    return addModel(propName, model.properties[propName], cellDefinitions)\n    /* eslint-enable no-use-before-define */\n  })\n\n  if (model.dependencies) {\n    _.forIn(model.dependencies, (dep, depName) => {\n      const depProps = getPropertyOrder(dep.properties)\n      const depChildren = depProps.map((propName) => {\n        // we have a circular dependency\n        /* eslint-disable no-use-before-define */\n        return addDependentModel(propName, depName, dep.properties[propName], cellDefinitions)\n        /* eslint-enable no-use-before-define */\n      })\n      children.push.apply(children, depChildren)\n    })\n  }\n  cell.children = children\n  return defName\n}", "label": 3}
{"code": "public function setParameters($parameters)\n    {\n        // BC compatibility with 2.3-\n        if (is_array($parameters)) {\n            $parameterCollection = new ArrayCollection();\n\n            foreach ($parameters as $key => $value) {\n                $parameterCollection->add(new Parameter($key, $value));\n            }\n\n            $parameters = $parameterCollection;\n        }\n\n        $this->parameters = $parameters;\n\n        return $this;\n    }", "label": 2}
{"code": "private void handleSendDataResponse(SerialMessage incomingMessage) {\n\t\tlogger.trace(\"Handle Message Send Data Response\");\n\t\tif(incomingMessage.getMessageBuffer()[2] != 0x00)\n\t\t\tlogger.debug(\"Sent Data successfully placed on stack.\");\n\t\telse\n\t\t\tlogger.error(\"Sent Data was not placed on stack due to error.\");\n\t}", "label": 0}
{"code": "protected final void sendObjectToSocket(Object objectToSend, WriteCallback cb) {\n        Session sess = this.getSession();\n        if (sess != null) {\n            String json;\n            try {\n                json = this.mapper.writeValueAsString(objectToSend);\n            } catch (JsonProcessingException e) {\n                throw new RuntimeException(\"Failed to serialize object\", e);\n            }\n            sess.getRemote().sendString(json, cb);\n        }\n    }", "label": 0}
{"code": "def token_setter(remote, token, secret='', token_type='', extra_data=None,\n                 user=None):\n    \"\"\"Set token for user.\n\n    :param remote: The remote application.\n    :param token: The token to set.\n    :param token_type: The token type. (Default: ``''``)\n    :param extra_data: Extra information. (Default: ``None``)\n    :param user: The user owner of the remote token. If it's not defined,\n        the current user is used automatically. (Default: ``None``)\n    :returns: A :class:`invenio_oauthclient.models.RemoteToken` instance or\n        ``None``.\n    \"\"\"\n    session[token_session_key(remote.name)] = (token, secret)\n    user = user or current_user\n\n    # Save token if user is not anonymous (user exists but can be not active at\n    # this moment)\n    if not user.is_anonymous:\n        uid = user.id\n        cid = remote.consumer_key\n\n        # Check for already existing token\n        t = RemoteToken.get(uid, cid, token_type=token_type)\n\n        if t:\n            t.update_token(token, secret)\n        else:\n            t = RemoteToken.create(\n                uid, cid, token, secret,\n                token_type=token_type, extra_data=extra_data\n            )\n        return t\n    return None", "label": 1}
{"code": "public static base_response update(nitro_service client, nsconfig resource) throws Exception {\n\t\tnsconfig updateresource = new nsconfig();\n\t\tupdateresource.ipaddress = resource.ipaddress;\n\t\tupdateresource.netmask = resource.netmask;\n\t\tupdateresource.nsvlan = resource.nsvlan;\n\t\tupdateresource.ifnum = resource.ifnum;\n\t\tupdateresource.tagged = resource.tagged;\n\t\tupdateresource.httpport = resource.httpport;\n\t\tupdateresource.maxconn = resource.maxconn;\n\t\tupdateresource.maxreq = resource.maxreq;\n\t\tupdateresource.cip = resource.cip;\n\t\tupdateresource.cipheader = resource.cipheader;\n\t\tupdateresource.cookieversion = resource.cookieversion;\n\t\tupdateresource.securecookie = resource.securecookie;\n\t\tupdateresource.pmtumin = resource.pmtumin;\n\t\tupdateresource.pmtutimeout = resource.pmtutimeout;\n\t\tupdateresource.ftpportrange = resource.ftpportrange;\n\t\tupdateresource.crportrange = resource.crportrange;\n\t\tupdateresource.timezone = resource.timezone;\n\t\tupdateresource.grantquotamaxclient = resource.grantquotamaxclient;\n\t\tupdateresource.exclusivequotamaxclient = resource.exclusivequotamaxclient;\n\t\tupdateresource.grantquotaspillover = resource.grantquotaspillover;\n\t\tupdateresource.exclusivequotaspillover = resource.exclusivequotaspillover;\n\t\tupdateresource.nwfwmode = resource.nwfwmode;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def inclusive_temporal_ref?\n      # FIXME: NINF is used instead of 0 sometimes...? (not in the IG)\n      # FIXME: Given nullFlavor, but IG uses it and nullValue everywhere...\n      less_than_equal_tr = attr_val('../@highClosed') == 'true' &&\n                           (attr_val('../cda:low/@value') == '0' || attr_val('../cda:low/@nullFlavor') == 'NINF')\n      greater_than_equal_tr = attr_val('../cda:high/@nullFlavor') == 'PINF' &&\n                              attr_val('../cda:low/@value')\n      # Both less and greater require lowClosed to be set to true\n      (less_than_equal_tr || greater_than_equal_tr) && attr_val('../@lowClosed') == 'true'\n    end", "label": 4}
{"code": "public static File writeObjectToTempFile(Object o, String filename)\r\n  throws IOException {\r\n    File file = File.createTempFile(filename, \".tmp\");\r\n    file.deleteOnExit();\r\n    ObjectOutputStream oos = new ObjectOutputStream(new BufferedOutputStream(\r\n        new GZIPOutputStream(new FileOutputStream(file))));\r\n    oos.writeObject(o);\r\n    oos.close();\r\n    return file;\r\n  }", "label": 0}
{"code": "public static base_response unset(nitro_service client, iptunnelparam resource, String[] args) throws Exception{\n\t\tiptunnelparam unsetresource = new iptunnelparam();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public ClassDescriptor getDescriptorFor(String strClassName) throws ClassNotPersistenceCapableException\r\n    {\r\n        ClassDescriptor result = discoverDescriptor(strClassName);\r\n        if (result == null)\r\n        {\r\n            throw new ClassNotPersistenceCapableException(strClassName + \" not found in OJB Repository\");\r\n        }\r\n        else\r\n        {\r\n            return result;\r\n        }\r\n    }", "label": 0}
{"code": "public Integer getEnd() {\n    if (mtasPositionType.equals(POSITION_RANGE)\n        || mtasPositionType.equals(POSITION_SET)) {\n      return mtasPositionEnd;\n    } else if (mtasPositionType.equals(POSITION_SINGLE)) {\n      return mtasPositionStart;\n    } else {\n      return null;\n    }\n  }", "label": 0}
{"code": "def parse_insertion(insertion, gff):\n    \"\"\"\n    parse insertion to gff format\n    \"\"\"\n    offset = insertion['offset']\n    for ins in parse_fasta(insertion['insertion sequence'].split('|')):\n        strand = insertion['strand']\n        ID = ins[0].split('>')[1].split()[0]\n        Start, End = [int(i) for i in ins[0].split('gene-pos=', 1)[1].split()[0].split('-')]\n        Start, End = abs(Start + offset), abs(End + offset)\n        if strand == '-':\n            Start, End = End, Start\n        gff['#seqname'].append(insertion['ID'])\n        gff['source'].append(insertion['source'])\n        gff['feature'].append('IVS')\n        gff['start'].append(Start)\n        gff['end'].append(End)\n        gff['score'].append('.')\n        gff['strand'].append(strand) # same as rRNA\n        gff['frame'].append('.')\n        gff['attribute'].append('ID=%s' % (ID))\n    return gff", "label": 1}
{"code": "function(){\n\t\t// If a task is currently loading this fileUrl,\n\t\t// wait for it to complete\n\t\tvar loadingTask = this.context.loadingPaths[this.fileUrl];\n\t\tif (!loadingTask) return;\n\n\t\tvar task = this;\n\t\treturn loadingTask.promise.then(function() {\n\t\t\ttask._fetchedPackage = loadingTask.getPackage();\n\n\t\t\tvar firstTaskFailed = loadingTask.hadErrorLoading();\n\t\t\tvar currentTaskIsCompatible = task.isCompatibleVersion();\n\t\t\tvar firstTaskIsNotCompatible = !loadingTask.isCompatibleVersion();\n\n\t\t\t// Do not flag the current task as failed if:\n\t\t\t//\n\t\t\t//\t- Current task fetches a version in rage and\n\t\t\t//\t- First task had no error loading at all or\n\t\t\t//\t- First task fetched an incompatible version\n\t\t\t//\n\t\t\t// otherwise, assume current task will fail for the same reason as\n\t\t\t// the first did\n\t\t\tif (currentTaskIsCompatible && (!firstTaskFailed || firstTaskIsNotCompatible)) {\n\t\t\t\ttask.failed = false;\n\t\t\t\ttask.error = null;\n\t\t\t}\n\t\t\telse if (!currentTaskIsCompatible) {\n\t\t\t\ttask.failed = true;\n\t\t\t\ttask.error = new Error(\"Incompatible package version requested\");\n\t\t\t}\n\t\t\telse if (firstTaskFailed) {\n\t\t\t\ttask.failed = true;\n\t\t\t\ttask.error = loadingTask.error;\n\t\t\t}\n\t\t});\n\t}", "label": 3}
{"code": "func containsAny(fl FieldLevel) bool {\n\treturn strings.ContainsAny(fl.Field().String(), fl.Param())\n}", "label": 5}
{"code": "def progress(arr, options = {})\n      bar = ProgressBar.new arr.length, options\n      bar.show\n      arr.each { |v| bar.increment yield(v) }\n    end", "label": 4}
{"code": "def logout():\n    \"\"\"CERN logout view.\"\"\"\n    logout_url = REMOTE_APP['logout_url']\n\n    apps = current_app.config.get('OAUTHCLIENT_REMOTE_APPS')\n    if apps:\n        cern_app = apps.get('cern', REMOTE_APP)\n        logout_url = cern_app['logout_url']\n\n    return redirect(logout_url, code=302)", "label": 1}
{"code": "def warning(cls, name, message, *args):\n        \"\"\"\n        Convenience function to log a message at the WARNING level.\n\n        :param name:    The name of the logger instance in the VSG namespace (VSG.<name>)\n        :param message: A message format string.\n        :param args:    The arguments that are are merged into msg using the string formatting operator.\n        :..note:        The native logger's `kwargs` are not used in this function.\n        \"\"\"\n        cls.getLogger(name).warning(message, *args)", "label": 1}
{"code": "function search(query, options = {}) {\n  const {\n    format = 'idCode',\n    mode = 'substructure',\n    flattenResult = true,\n    keepMolecule = false,\n    limit = Number.MAX_SAFE_INTEGER\n  } = options;\n\n  if (typeof query === 'string') {\n    const getMoleculeCreators = require('./moleculeCreators');\n    const moleculeCreators = getMoleculeCreators(this.OCL.Molecule);\n    query = moleculeCreators.get(format.toLowerCase())(query);\n  } else if (!(query instanceof this.OCL.Molecule)) {\n    throw new TypeError('toSearch must be a Molecule or string');\n  }\n\n  let result;\n  switch (mode.toLowerCase()) {\n    case 'exact':\n      result = exactSearch(this.moleculeDB.db, query, limit);\n      break;\n    case 'substructure':\n      result = subStructureSearch(this.moleculeDB, query, limit);\n      break;\n    case 'similarity':\n      result = similaritySearch(this.moleculeDB, this.OCL, query, limit);\n      break;\n    default:\n      throw new Error(`unknown search mode: ${options.mode}`);\n  }\n  return processResult(result, { flattenResult, keepMolecule, limit });\n}", "label": 3}
{"code": "def summarize_taxa(biom):\n    \"\"\"\n    Given an abundance table, group the counts by every\n    taxonomic level.\n    \"\"\"\n    tamtcounts = defaultdict(int)\n    tot_seqs = 0.0\n\n    for row, col, amt in biom['data']:\n        tot_seqs += amt\n        rtax = biom['rows'][row]['metadata']['taxonomy']\n        for i, t in enumerate(rtax):\n            t = t.strip()\n            if i == len(rtax)-1 and len(t) > 3 and len(rtax[-1]) > 3:\n                t = 's__'+rtax[i-1].strip().split('_')[-1]+'_'+t.split('_')[-1]\n            tamtcounts[t] += amt\n\n    lvlData = {lvl: levelData(tamtcounts, tot_seqs, lvl) for lvl in ['k', 'p', 'c', 'o', 'f', 'g', 's']}\n\n    return tot_seqs, lvlData", "label": 1}
{"code": "function inputTypeForCommand (cmd) {\n  switch (String(cmd)) {\n    case obciChannelCmdADCNormal:\n      return obciStringADCNormal;\n    case obciChannelCmdADCShorted:\n      return obciStringADCShorted;\n    case obciChannelCmdADCBiasMethod:\n      return obciStringADCBiasMethod;\n    case obciChannelCmdADCMVDD:\n      return obciStringADCMvdd;\n    case obciChannelCmdADCTemp:\n      return obciStringADCTemp;\n    case obciChannelCmdADCTestSig:\n      return obciStringADCTestSig;\n    case obciChannelCmdADCBiasDRP:\n      return obciStringADCBiasDrp;\n    case obciChannelCmdADCBiasDRN:\n      return obciStringADCBiasDrn;\n    default:\n      throw new Error('Invalid input type, must be less than 8');\n  }\n}", "label": 3}
{"code": "private void handleGetVersionResponse(SerialMessage incomingMessage) {\n\t\tthis.ZWaveLibraryType = incomingMessage.getMessagePayloadByte(12);\n\t\tthis.zWaveVersion = new String(ArrayUtils.subarray(incomingMessage.getMessagePayload(), 0, 11));\n\t\tlogger.debug(String.format(\"Got MessageGetVersion response. Version = %s, Library Type = 0x%02X\", zWaveVersion, ZWaveLibraryType));\n\t}", "label": 0}
{"code": "def pause(self):\n        \"\"\"\n        Pauses a running pipeline. This will stop retrieving results from the \n        pipeline. Parallel parts of the pipeline will stop after the ``NuMap`` \n        buffer is has been filled. A paused pipeline can be run or stopped. \n        \n        \"\"\"\n        # 1. stop the plumbing thread by raising a StopIteration on a stride \n        #    boundary\n        if self._started.isSet() and \\\n           self._running.isSet() and \\\n           not self._pausing.isSet():\n            self._pausing.set()\n            self._plunger.join()\n            del self._plunger\n            self._pausing.clear()\n            self._running.clear()\n        else:\n            raise PlumberError", "label": 1}
{"code": "def from_json(cls, json_doc):\n        \"\"\"Parse a JSON string and build an entity.\"\"\"\n        try:\n            d = json.load(json_doc)\n        except AttributeError:  # catch the read() error\n            d = json.loads(json_doc)\n\n        return cls.from_dict(d)", "label": 1}
{"code": "public static base_response delete(nitro_service client, String ipv6prefix) throws Exception {\n\t\tonlinkipv6prefix deleteresource = new onlinkipv6prefix();\n\t\tdeleteresource.ipv6prefix = ipv6prefix;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def adjust_volume(buf, mult)\n      # We don't need to adjust anything if the buf is nil so just return in that case\n      return unless buf\n\n      # buf is s16le so use 's<' for signed, 16 bit, LE\n      result = buf.unpack('s<*').map do |sample|\n        sample *= mult\n\n        # clamp to s16 range\n        [32_767, [-32_768, sample].max].min\n      end\n\n      # After modification, make it s16le again\n      result.pack('s<*')\n    end", "label": 4}
{"code": "function (scrollBy, animation) {\n            var pages = this.pages,\n              pageCount = pages.length,\n              currentPage = this.currentPage + scrollBy,\n              clipHeight = this.clipHeight,\n              navOptions = this.options.navigation,\n              activeColor = navOptions.activeColor,\n              inactiveColor = navOptions.inactiveColor,\n              pager = this.pager,\n              padding = this.padding,\n              scrollOffset;\n\n            // When resizing while looking at the last page\n            if (currentPage > pageCount) {\n                currentPage = pageCount;\n            }\n\n            if (currentPage > 0) {\n\n                if (animation !== UNDEFINED) {\n                    setAnimation(animation, this.chart);\n                }\n\n                this.nav.attr({\n                    translateX: padding,\n                    translateY: clipHeight + this.padding + 7 + this.titleHeight,\n                    visibility: VISIBLE\n                });\n                this.up.attr({\n                      fill: currentPage === 1 ? inactiveColor : activeColor\n                  })\n                  .css({\n                      cursor: currentPage === 1 ? 'default' : 'pointer'\n                  });\n                pager.attr({\n                    text: currentPage + '/' + pageCount\n                });\n                this.down.attr({\n                      x: 18 + this.pager.getBBox().width, // adjust to text width\n                      fill: currentPage === pageCount ? inactiveColor : activeColor\n                  })\n                  .css({\n                      cursor: currentPage === pageCount ? 'default' : 'pointer'\n                  });\n\n                scrollOffset = -pages[currentPage - 1] + this.initialItemY;\n\n                this.scrollGroup.animate({\n                    translateY: scrollOffset\n                });\n\n                this.currentPage = currentPage;\n                this.positionCheckboxes(scrollOffset);\n            }\n\n        }", "label": 3}
{"code": "function(models, delaySort, remoteData)\n  {\n    if ( isArray( models ) )\n    {\n      var indices = [];\n\n      for (var i = 0; i < models.length; i++)\n      {\n        var model = this.parseModel( models[ i ], remoteData );\n        var key = model.$key();\n\n        this.map.put( key, model );\n        indices.push( this.map.indices[ key ] );\n      }\n\n      this.trigger( Collection.Events.Adds, [this, models, indices] );\n\n      if ( !delaySort )\n      {\n        this.sort();\n      }\n    }\n  }", "label": 3}
{"code": "private function getClientRedirectUri(AuthorizationRequest $authorizationRequest)\n    {\n        return \\is_array($authorizationRequest->getClient()->getRedirectUri())\n                ? $authorizationRequest->getClient()->getRedirectUri()[0]\n                : $authorizationRequest->getClient()->getRedirectUri();\n    }", "label": 2}
{"code": "public function setDeviceRegistry($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Iot\\V1\\DeviceRegistry::class);\n        $this->device_registry = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def country_can_dp?(country)\n      Phonelib.phone_data[country] &&\n        Phonelib.phone_data[country][Core::DOUBLE_COUNTRY_PREFIX_FLAG] &&\n        !original_starts_with_plus?\n    end", "label": 4}
{"code": "def parsetypes(dtype):\n    \"\"\"\n    Parse the types from a structured numpy dtype object.\n\n    Return list of string representations of types from a structured numpy \n    dtype object, e.g. ['int', 'float', 'str'].\n\n    Used by :func:`tabular.io.saveSV` to write out type information in the \n    header.\n\n    **Parameters**\n\n        **dtype** :  numpy dtype object\n\n            Structured numpy dtype object to parse.\n\n    **Returns**\n\n        **out** :  list of strings\n\n            List of strings corresponding to numpy types::\n\n                [dtype[i].name.strip('1234567890').rstrip('ing') \\ \n                 for i in range(len(dtype))]\n\n    \"\"\"\n    return [dtype[i].name.strip('1234567890').rstrip('ing') \n            for i in range(len(dtype))]", "label": 1}
{"code": "def clean(count = 2, age = 3600)\n      asset_versions = files.group_by { |_, attrs| attrs['logical_path'] }\n\n      asset_versions.each do |logical_path, versions|\n        current = assets[logical_path]\n\n        versions.reject { |path, _|\n          path == current\n        }.sort_by { |_, attrs|\n          # Sort by timestamp\n          Time.parse(attrs['mtime'])\n        }.reverse.each_with_index.drop_while { |(_, attrs), index|\n          _age = [0, Time.now - Time.parse(attrs['mtime'])].max\n          # Keep if under age or within the count limit\n          _age < age || index < count\n        }.each { |(path, _), _|\n           # Remove old assets\n          remove(path)\n        }\n      end\n    end", "label": 4}
{"code": "protected function getJoinSQLForAssociation(AssociationMetadata $association)\n    {\n        if (! $association->isOwningSide()) {\n            return 'LEFT JOIN';\n        }\n\n        // if one of the join columns is nullable, return left join\n        foreach ($association->getJoinColumns() as $joinColumn) {\n            if (! $joinColumn->isNullable()) {\n                continue;\n            }\n\n            return 'LEFT JOIN';\n        }\n\n        return 'INNER JOIN';\n    }", "label": 2}
{"code": "private ArrayTypeSignature getArrayTypeSignature(\r\n\t\t\tGenericArrayType genericArrayType) {\r\n\t\tFullTypeSignature componentTypeSignature = getFullTypeSignature(genericArrayType\r\n\t\t\t\t.getGenericComponentType());\r\n\t\tArrayTypeSignature arrayTypeSignature = new ArrayTypeSignature(\r\n\t\t\t\tcomponentTypeSignature);\r\n\t\treturn arrayTypeSignature;\r\n\t}", "label": 0}
{"code": "function aggregateCoverage(files) {\n  var i, len, file, content, results;\n  var resultsObj = getEmptyResultObject();\n\n  for (i = 0, len = files.length; i < len; i++) {\n    file = files[i];\n    content = JSON.parse(fs.readFileSync(file).toString());\n    resultsObj = populateCoverage(resultsObj, content);\n  }\n\n  return resultsObj;\n}", "label": 3}
{"code": "func ParseAdvertiseAddr(advertiseIP string) (string, string, error) {\n\tadvertiseIP = strings.TrimSpace(advertiseIP)\n\thost := advertiseIP\n\tport := \"\"\n\tif len(net.ParseIP(host)) == 0 && strings.Contains(advertiseIP, \":\") {\n\t\tvar err error\n\t\thost, port, err = net.SplitHostPort(advertiseIP)\n\t\tif err != nil {\n\t\t\treturn \"\", \"\", trace.BadParameter(\"failed to parse address %q\", advertiseIP)\n\t\t}\n\t\tif _, err := strconv.Atoi(port); err != nil {\n\t\t\treturn \"\", \"\", trace.BadParameter(\"bad port %q, expected integer\", port)\n\t\t}\n\t\tif host == \"\" {\n\t\t\treturn \"\", \"\", trace.BadParameter(\"missing host parameter\")\n\t\t}\n\t}\n\tip := net.ParseIP(host)\n\tif len(ip) != 0 {\n\t\tif ip.IsUnspecified() || ip.IsMulticast() {\n\t\t\treturn \"\", \"\", trace.BadParameter(\"unreachable advertise IP: %v\", advertiseIP)\n\t\t}\n\t}\n\treturn host, port, nil\n}", "label": 5}
{"code": "def align_rna(job, fastqs, univ_options, star_options):\n    \"\"\"\n    A wrapper for the entire rna alignment subgraph.\n\n    :param list fastqs: The input fastqs for alignment\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict star_options: Options specific to star\n    :return: Dict containing input bam and the generated index (.bam.bai)\n    :rtype: dict\n    \"\"\"\n    star = job.wrapJobFn(run_star, fastqs, univ_options, star_options,\n                         cores=star_options['n'],\n                         memory=PromisedRequirement(lambda x: int(1.85 * x.size),\n                                                    star_options['index']),\n                         disk=PromisedRequirement(star_disk, fastqs, star_options['index']))\n    s_and_i = job.wrapJobFn(sort_and_index_star, star.rv(), univ_options,\n                            star_options).encapsulate()\n    job.addChild(star)\n    star.addChild(s_and_i)\n    return s_and_i.rv()", "label": 1}
{"code": "function(userIds) {\n    return new Promise((resolve, reject) => {\n      this._start()\n          .uri('/api/user/bulk')\n          .urlParameter('userId', userIds)\n          .delete()\n          .go(this._responseHandler(resolve, reject));\n    });\n  }", "label": 3}
{"code": "func PgProcs(db XODB, schema string) ([]*Proc, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`p.proname, ` + // ::varchar AS proc_name\n\t\t`pg_get_function_result(p.oid) ` + // ::varchar AS return_type\n\t\t`FROM pg_proc p ` +\n\t\t`JOIN ONLY pg_namespace n ON p.pronamespace = n.oid ` +\n\t\t`WHERE n.nspname = $1`\n\n\t// run query\n\tXOLog(sqlstr, schema)\n\tq, err := db.Query(sqlstr, schema)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*Proc{}\n\tfor q.Next() {\n\t\tp := Proc{}\n\n\t\t// scan\n\t\terr = q.Scan(&p.ProcName, &p.ReturnType)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &p)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "function assertUniTypeObject(attr, data, type) {\n  data = assertObject(attr, data);\n\n  if (data === null) {\n    return null;\n  }\n\n  Object.keys(data).forEach(key => {\n    if (type === undefined) {\n      type = typeof data[key];\n    }\n    type = type.toLowerCase();\n\n    let msg = `Attribute ${attr} must be of type \"object\" and have all its properties of type ${type}.`\n      + `\\nExpected \"${attr}.${key}\" to be of type \"${type}\", but go \"${typeof data[key]}\".`;\n\n    switch (type) {\n      case 'array':\n        if (!Array.isArray(data[key])) {\n          throw new ParseError(msg);\n        }\n        break;\n      default:\n        if (typeof data[key] !== type) {\n          throw new ParseError(msg);\n        }\n        break;\n    }\n\n  });\n\n  return data;\n}", "label": 3}
{"code": "protected static function getAddress(ParametersInterface $parameters)\n    {\n        if (filter_var($host = $parameters->host, FILTER_VALIDATE_IP)) {\n            return $host;\n        }\n\n        if ($host === $address = gethostbyname($host)) {\n            return false;\n        }\n\n        return $address;\n    }", "label": 2}
{"code": "def qmed_all_methods(self):\n        \"\"\"\n        Returns a dict of QMED methods using all available methods.\n\n        Available methods are defined in :attr:`qmed_methods`. The returned dict keys contain the method name, e.g.\n        `amax_record` with value representing the corresponding QMED estimate in m\u00b3/s.\n\n        :return: dict of QMED estimates\n        :rtype: dict\n        \"\"\"\n        result = {}\n        for method in self.methods:\n            try:\n                result[method] = getattr(self, '_qmed_from_' + method)()\n            except:\n                result[method] = None\n        return result", "label": 1}
{"code": "func (process *TeleportProcess) getConnectors() []*Connector {\n\tprocess.Lock()\n\tdefer process.Unlock()\n\n\tout := make([]*Connector, 0, len(process.connectors))\n\tfor role := range process.connectors {\n\t\tout = append(out, process.connectors[role])\n\t}\n\treturn out\n}", "label": 5}
{"code": "function (letter1, letter2) {\n  var index1 = scale.indexOf(letter1);\n  var index2 = scale.indexOf(letter2);\n  var distance = mod(index2 - index1, scale.length) + 1;\n\n  assert(index1 > -1);\n  assert(index2 > -1);\n  assert(distance > 0 && distance <= scale.length);\n\n  return distance;\n}", "label": 3}
{"code": "function onScroll() {\n\t\t// unique tick id\n\t\t++ticks;\n\n\t\t// viewport rectangle\n\t\tvar top = jWindow.scrollTop(),\n\t\t\tleft = jWindow.scrollLeft(),\n\t\t\tright = left + jWindow.width(),\n\t\t\tbottom = top + jWindow.height();\n\n\t\t// determine which elements are in view\n//        + 60 accounts for fixed nav\n\t\tvar intersections = findElements(top+offset.top + 200, right+offset.right, bottom+offset.bottom, left+offset.left);\n\t\t$.each(intersections, function(i, element) {\n\n\t\t\tvar lastTick = element.data('scrollSpy:ticks');\n\t\t\tif (typeof lastTick != 'number') {\n\t\t\t\t// entered into view\n\t\t\t\telement.triggerHandler('scrollSpy:enter');\n\t\t\t}\n\n\t\t\t// update tick id\n\t\t\telement.data('scrollSpy:ticks', ticks);\n\t\t});\n\n\t\t// determine which elements are no longer in view\n\t\t$.each(elementsInView, function(i, element) {\n\t\t\tvar lastTick = element.data('scrollSpy:ticks');\n\t\t\tif (typeof lastTick == 'number' && lastTick !== ticks) {\n\t\t\t\t// exited from view\n\t\t\t\telement.triggerHandler('scrollSpy:exit');\n\t\t\t\telement.data('scrollSpy:ticks', null);\n\t\t\t}\n\t\t});\n\n\t\t// remember elements in view for next tick\n\t\telementsInView = intersections;\n\t}", "label": 3}
{"code": "def abort_current_edit\n      ensure_active_edit!\n\n      call_google_api { client.delete_edit(current_package_name, current_edit.id) }\n\n      self.current_edit = nil\n      self.current_package_name = nil\n    end", "label": 4}
{"code": "def excelx_format(row, col, sheet = nil)\n      key = normalize(row, col)\n      sheet_for(sheet).excelx_format(key)\n    end", "label": 4}
{"code": "def refresh(params = {}, access_token_opts = {}, access_token_class = self.class)\n      raise('A refresh_token is not available') unless refresh_token\n      params[:grant_type] = 'refresh_token'\n      params[:refresh_token] = refresh_token\n      new_token = @client.get_token(params, access_token_opts, access_token_class)\n      new_token.options = options\n      new_token.refresh_token = refresh_token unless new_token.refresh_token\n      new_token\n    end", "label": 4}
{"code": "def apply(params)\n      case mode.to_sym\n      when :basic_auth\n        apply_basic_auth(params)\n      when :request_body\n        apply_params_auth(params)\n      else\n        raise NotImplementedError\n      end\n    end", "label": 4}
{"code": "func (ctx *Context) GetIdentifier(fields []string) (interface{}, error) {\n\tswitch fields[0] {\n\tcase UserIdentifier:\n\t\tvar user User\n\t\tif ctx.User == nil {\n\t\t\tuser = emptyUser\n\t\t} else {\n\t\t\tuser = ctx.User\n\t\t}\n\t\treturn predicate.GetFieldByTag(user, teleport.JSON, fields[1:])\n\tcase ResourceIdentifier:\n\t\tvar resource Resource\n\t\tif ctx.Resource == nil {\n\t\t\tresource = emptyResource\n\t\t} else {\n\t\t\tresource = ctx.Resource\n\t\t}\n\t\treturn predicate.GetFieldByTag(resource, \"json\", fields[1:])\n\tdefault:\n\t\treturn nil, trace.NotFound(\"%v is not defined\", strings.Join(fields, \".\"))\n\t}\n}", "label": 5}
{"code": "public static base_responses update(nitro_service client, systemuser resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsystemuser updateresources[] = new systemuser[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new systemuser();\n\t\t\t\tupdateresources[i].username = resources[i].username;\n\t\t\t\tupdateresources[i].password = resources[i].password;\n\t\t\t\tupdateresources[i].externalauth = resources[i].externalauth;\n\t\t\t\tupdateresources[i].promptstring = resources[i].promptstring;\n\t\t\t\tupdateresources[i].timeout = resources[i].timeout;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def reporter_from_options(options)\n      if options[:auto_gen_config]\n        HamlLint::Reporter::DisabledConfigReporter.new(log, limit: options[:auto_gen_exclude_limit] || 15) # rubocop:disable Metrics/LineLength\n      else\n        options.fetch(:reporter, HamlLint::Reporter::DefaultReporter).new(log)\n      end\n    end", "label": 4}
{"code": "func defaultPathMaker(baseDir string, info *metainfo.Info, infoHash metainfo.Hash) string {\n\treturn baseDir\n}", "label": 5}
{"code": "public function canTypeBeContainedByType(\n        Type\\Union $input_type,\n        Type\\Union $container_type\n    ): bool {\n        return TypeAnalyzer::canBeContainedBy($this, $input_type, $container_type);\n    }", "label": 2}
{"code": "def _read_file(self):\n        \"\"\"\n        reads the file and cleans into standard text ready for parsing\n        \"\"\"\n        self.raw = []\n        with open(self.fname, 'r') as f:\n            for line in f:\n                #print(line)\n                if line.startswith('#'):    \n                    pass # comment\n                elif line.strip('\\n') == '':\n                    pass # space\n                else:\n                    self.raw.append(line.strip('\\n'))", "label": 1}
{"code": "def generate(value, expires_at: nil, expires_in: nil, purpose: nil)\n      data = encode(Messages::Metadata.wrap(@serializer.dump(value), expires_at: expires_at, expires_in: expires_in, purpose: purpose))\n      \"#{data}--#{generate_digest(data)}\"\n    end", "label": 4}
{"code": "func (t *Torrent) Seeding() bool {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\treturn t.seeding()\n}", "label": 5}
{"code": "def wait_true(opts = {})\n      opts = opts.is_a?(Numeric) ? { timeout: opts } : opts\n\n      if opts.is_a? Hash\n        opts.empty? ? @core.wait_true { yield } : @core.wait_true(opts) { yield }\n      else\n        ::Appium::Logger.warn('Arguments should be Hash like {timeout: 100}')\n      end\n    end", "label": 4}
{"code": "public static base_response unset(nitro_service client, nsip6 resource, String[] args) throws Exception{\n\t\tnsip6 unsetresource = new nsip6();\n\t\tunsetresource.ipv6address = resource.ipv6address;\n\t\tunsetresource.td = resource.td;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public static vpnvserver_intranetip_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_intranetip_binding obj = new vpnvserver_intranetip_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_intranetip_binding response[] = (vpnvserver_intranetip_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def check_down_connections(self):\n        \"\"\"\n        Iterates through all connections which were previously listed as unavailable\n        and marks any that have expired their retry_timeout as being up.\n        \"\"\"\n        now = time.time()\n\n        for db_num, marked_down_at in self._down_connections.items():\n            if marked_down_at + self.retry_timeout <= now:\n                self.mark_connection_up(db_num)", "label": 1}
{"code": "function min(compare, iterable, dflt = undefined) {\n\n  let iterator = (0, _iter.iter)(iterable);\n\n  let first = iterator.next();\n\n  if (first.done) return dflt;\n\n  let smallest = first.value;\n\n  for (let candidate of iterator) {\n\n    if (compare(candidate, smallest) < 0) {\n\n      smallest = candidate;\n    }\n  }\n\n  return smallest;\n}", "label": 3}
{"code": "function save(template, distpath) {\n  var data = generate(template);\n  var dir = path.dirname(distpath);\n\n  mkdirp(dir, function(err) {\n    if(err) {\n      console.log(err.message);\n      return;\n    }\n\n    fs.writeFile(distpath, JSON.stringify(data, null, 2), function(err) {\n      if(err) {\n        console.log(err.message);\n        return;\n      }\n    });\n\n  });\n\n}", "label": 3}
{"code": "protected function parseAllocationStats($str)\n    {\n        $stats = array();\n\n        foreach (explode(',', $str) as $kv) {\n            @list($size, $objects, $extra) = explode('=', $kv);\n\n            // hack to prevent incorrect values when parsing the >=256 key\n            if (isset($extra)) {\n                $size = \">=$objects\";\n                $objects = $extra;\n            }\n\n            $stats[$size] = $objects;\n        }\n\n        return $stats;\n    }", "label": 2}
{"code": "def dist_single(self, g_num, at_1, at_2):\n        \"\"\" Distance between two atoms.\n\n        Parameters\n        ----------\n        g_num\n            |int| -- Index of the desired geometry\n\n        at_1\n            |int| -- Index of the first atom\n\n        at_2\n            |int| -- Index of the second atom\n\n        Returns\n        -------\n        dist\n            |npfloat_| --\n            Distance in Bohrs between `at_1` and `at_2` from\n            geometry `g_num`\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an invalid (out-of-range) `g_num` or `at_#` is provided\n\n        \"\"\"\n\n        # Import used math library function(s)\n        import numpy as np\n        from scipy import linalg as spla\n        from .utils import safe_cast as scast\n\n        # The below errors are explicitly thrown since values are multiplied by\n        #  three when they are used as an index and thus give non-intuitive\n        #  errors in subsequent code.\n        # Complain if at_1 is invalid\n        if not (-self.num_atoms <= at_1 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_1' ({0})\".format(at_1))\n\n        # Complain if at_2 is invalid\n        if not (-self.num_atoms <= at_2 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_2' ({0})\".format(at_2))\n\n        # Should never be necessary (save for badly erroneous calling code),\n        #  but coerce at_1 and at_2 to their floor() values.  This is again\n        #  needed since they are multiplied by three in the index expresssions\n        #  below, and can cause funny behavior when truncated by the indexing\n        at_1 = scast(np.floor(at_1), np.int_)\n        at_2 = scast(np.floor(at_2), np.int_)\n\n        # Calculate the interatomic distance and return. Return identically\n        #  zero if the indices are equal\n        if at_1 == at_2:\n            dist = 0.0\n        else:\n            dist = scast(\n                    spla.norm(self.displ_single(g_num, at_1, at_2)),\n                            np.float_)\n        ## end if\n\n        return dist", "label": 1}
{"code": "def host_targets_for_embedded_target(embedded_target)\n      native_targets.select do |native_target|\n        ((embedded_target.uuid != native_target.uuid) &&\n         (native_target.dependencies.map(&:native_target_uuid).include? embedded_target.uuid))\n      end\n    end", "label": 4}
{"code": "function makeRandomId(digits) {\n    digits = digits || 16;\n    var id = \"\";\n    for (var ii = 0; ii < digits; ++ii) {\n      id = id + ((Math.random() * 16 | 0)).toString(16);\n    }\n    return id;\n  }", "label": 3}
{"code": "def parent(self, resource):\n        \"\"\"Set parent resource\n\n        :param resource: parent resource\n        :type resource: Resource\n\n        :raises ResourceNotFound: resource not found on the API\n        \"\"\"\n        resource.check()\n        self['parent_type'] = resource.type\n        self['parent_uuid'] = resource.uuid", "label": 1}
{"code": "protected function store(CacheManager $cache, string $key, $value, ?Carbon $expiration, array $tags): void\n    {\n        $supportsTags = $this->useTags($cache);\n\n        if ($expiration) {\n            $supportsTags\n                ? $cache->tags($tags)->put($key, $value, $expiration)\n                : $cache->put($key, $value, $expiration);\n\n            return;\n        }\n\n        $supportsTags\n            ? $cache->tags($tags)->forever($key, $value)\n            : $cache->forever($key, $value);\n    }", "label": 2}
{"code": "def push(remote_or_url, *args)\n      unless remote_or_url.kind_of? Remote\n        remote_or_url = remotes[remote_or_url] || remotes.create_anonymous(remote_or_url)\n      end\n\n      remote_or_url.push(*args)\n    end", "label": 4}
{"code": "def _identify_all(header, footer, ext=None):\n    \"\"\" Attempt to identify 'data' by its magic numbers\"\"\"\n\n    # Capture the length of the data\n    # That way we do not try to identify bytes that don't exist\n    matches = list()\n    for magic_row in magic_header_array:\n        start = magic_row.offset\n        end = magic_row.offset + len(magic_row.byte_match)\n        if end > len(header):\n            continue\n        if header[start:end] == magic_row.byte_match:\n            matches.append(magic_row)\n\n    for magic_row in magic_footer_array:\n        start = magic_row.offset\n        if footer[start:] == magic_row.byte_match:\n            matches.append(magic_row)\n    if not matches:\n        raise PureError(\"Could not identify file\")\n\n    return _confidence(matches, ext)", "label": 1}
{"code": "def rules(self, word):\n        \"\"\"\n        Function to tokenize input string and return output of str with ortho rules\n        applied.\n\n        Parameters\n        ----------\n        word : str\n            The input string to be tokenized.\n\n        Returns\n        -------\n        result : str\n            Result of the orthography rules applied to the input str.\n\n        \"\"\"\n        return self._rules.apply(word) if self._rules else word", "label": 1}
{"code": "public function isVisibleTo(User $user)\n    {\n        return (bool) $this->newQuery()->whereVisibleTo($user)->find($this->id);\n    }", "label": 2}
{"code": "async function action_handler(req, h) {\n    const data = req.payload\n    const json = 'string' === typeof data ? tu.parseJSON(data) : data\n    if (json instanceof Error) {\n      throw json\n    }\n\n    const seneca = prepare_seneca(req, json)\n    const msg = tu.internalize_msg(seneca, json)\n\n    return await new Promise(resolve => {\n      var out = null\n      for (var i = 0; i < modify_action.length; i++) {\n        out = modify_action[i].call(seneca, msg, req)\n        if (out) {\n          return resolve(out)\n        }\n      }\n\n      seneca.act(msg, function(err, out, meta) {\n        if (err && !options.debug) {\n          err.stack = null\n        }\n\n        resolve(tu.externalize_reply(this, err, out, meta))\n      })\n    })\n  }", "label": 3}
{"code": "def get_job_output(params = {}, options = {}, &block)\n      req = build_request(:get_job_output, params)\n      req.send_request(options, &block)\n    end", "label": 4}
{"code": "def sh(*command, log: true, error_callback: nil, &b)\n      FastFile.sh(*command, log: log, error_callback: error_callback, &b)\n    end", "label": 4}
{"code": "public void checkConstraints(String checkLevel) throws ConstraintException\r\n    {\r\n        // now checking constraints\r\n        FieldDescriptorConstraints      fieldConstraints = new FieldDescriptorConstraints();\r\n        ReferenceDescriptorConstraints  refConstraints   = new ReferenceDescriptorConstraints();\r\n        CollectionDescriptorConstraints collConstraints  = new CollectionDescriptorConstraints();\r\n\r\n        for (Iterator it = getFields(); it.hasNext();)\r\n        {\r\n            fieldConstraints.check((FieldDescriptorDef)it.next(), checkLevel);\r\n        }\r\n        for (Iterator it = getReferences(); it.hasNext();)\r\n        {\r\n            refConstraints.check((ReferenceDescriptorDef)it.next(), checkLevel);\r\n        }\r\n        for (Iterator it = getCollections(); it.hasNext();)\r\n        {\r\n            collConstraints.check((CollectionDescriptorDef)it.next(), checkLevel);\r\n        }\r\n        new ClassDescriptorConstraints().check(this, checkLevel);\r\n    }", "label": 0}
{"code": "def login(self, username, password, login_token=None):\n        \"\"\"\n        Authenticate with the given credentials.  If authentication is\n        successful, all further requests sent will be signed the authenticated\n        user.\n\n        Note that passwords are sent as plaintext. This is a limitation of the\n        Mediawiki API.  Use a https host if you want your password to be secure\n\n        :Parameters:\n            username : str\n                The username of the user to be authenticated\n            password : str\n                The password of the user to be authenticated\n\n        :Raises:\n            :class:`mwapi.errors.LoginError` : if authentication fails\n            :class:`mwapi.errors.ClientInteractionRequest` : if authentication requires a continue_login() call\n            :class:`mwapi.errors.APIError` : if the API responds with an error\n        \"\"\"\n        if login_token is None:\n            token_doc = self.post(action='query', meta='tokens', type='login')\n            login_token = token_doc['query']['tokens']['logintoken']\n\n        login_doc = self.post(\n            action=\"clientlogin\", username=username, password=password,\n            logintoken=login_token, loginreturnurl=\"http://example.org/\")\n\n        if login_doc['clientlogin']['status'] == \"UI\":\n            raise ClientInteractionRequest.from_doc(\n                login_token, login_doc['clientlogin'])\n        elif login_doc['clientlogin']['status'] != 'PASS':\n            raise LoginError.from_doc(login_doc['clientlogin'])\n        return login_doc['clientlogin']", "label": 1}
{"code": "def get_host_usage(self):\n        \"\"\" \n        get details of CPU, RAM usage of this PC \n        \"\"\"\n        import psutil\n        process_names = [proc.name for proc in psutil.process_iter()]\n        cpu_pct = psutil.cpu_percent(interval=1)\n        mem = psutil.virtual_memory()\n        return str(cpu_pct), str(len(process_names)), str(mem.available), str(mem.total)", "label": 1}
{"code": "function appendPre(message) {\n\tvar pre = document.getElementById('content');\n\tvar textContent = document.createTextNode(message + '\\n');\n\tpre.appendChild(textContent);\n}", "label": 3}
{"code": "function(userName, firstName, lastName, password) {\n    var _this = this;\n\n\n\n\n\n\n\n    _this['userName'] = userName;\n    _this['firstName'] = firstName;\n    _this['lastName'] = lastName;\n\n    _this['password'] = password;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  }", "label": 3}
{"code": "def send_audio(buf, sequence, time)\n      # Header of the audio packet\n      header = [0x80, 0x78, sequence, time, @ssrc].pack('CCnNN')\n\n      # Encrypt data, if necessary\n      buf = encrypt_audio(header, buf) if encrypted?\n\n      send_packet(header + buf)\n    end", "label": 4}
{"code": "def as_indexed_json(options={})\n      self.as_json(\n        include: { categories: { only: :title},\n                   authors:    { methods: [:full_name, :department], only: [:full_name, :department] },\n                   comments:   { only: :text }\n                 })\n    end", "label": 4}
{"code": "function(key, model, delaySort)\n  {\n    this.map.put( key, model );\n    this.trigger( Collection.Events.Add, [this, model, this.map.indices[ key ]] );\n\n    if ( !delaySort )\n    {\n      this.sort();\n    }\n  }", "label": 3}
{"code": "func (h *AuthHandlers) CheckPortForward(addr string, ctx *ServerContext) error {\n\tif ok := ctx.Identity.RoleSet.CanPortForward(); !ok {\n\t\tsystemErrorMessage := fmt.Sprintf(\"port forwarding not allowed by role set: %v\", ctx.Identity.RoleSet)\n\t\tuserErrorMessage := \"port forwarding not allowed\"\n\n\t\t// emit port forward failure event\n\t\th.AuditLog.EmitAuditEvent(events.PortForwardFailure, events.EventFields{\n\t\t\tevents.PortForwardAddr:    addr,\n\t\t\tevents.PortForwardSuccess: false,\n\t\t\tevents.PortForwardErr:     systemErrorMessage,\n\t\t\tevents.EventLogin:         ctx.Identity.Login,\n\t\t\tevents.EventUser:          ctx.Identity.TeleportUser,\n\t\t\tevents.LocalAddr:          ctx.Conn.LocalAddr().String(),\n\t\t\tevents.RemoteAddr:         ctx.Conn.RemoteAddr().String(),\n\t\t})\n\t\th.Warnf(\"Port forwarding request denied: %v.\", systemErrorMessage)\n\n\t\treturn trace.AccessDenied(userErrorMessage)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def unmerge(job, input_vcf, tool_name, chromosomes, tool_options, univ_options):\n    \"\"\"\n    Un-merge a vcf file into per-chromosome vcfs.\n\n    :param str input_vcf: Input vcf\n    :param str tool_name: The name of the mutation caller\n    :param list chromosomes: List of chromosomes to retain\n    :param dict tool_options: Options specific to the mutation caller\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :return: dict of fsIDs, one for each chromosomal vcf\n    :rtype: dict\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'input.vcf': input_vcf,\n        'genome.fa.fai.tar.gz': tool_options['genome_fai']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n\n    input_files['genome.fa.fai'] = untargz(input_files['genome.fa.fai.tar.gz'], work_dir)\n\n    read_chromosomes = defaultdict()\n    with open(input_files['input.vcf'], 'r') as in_vcf:\n        header = []\n        for line in in_vcf:\n            if line.startswith('#'):\n                header.append(line)\n                continue\n            line = line.strip()\n            chrom = line.split()[0]\n            if chrom in read_chromosomes:\n                print(line, file=read_chromosomes[chrom])\n            else:\n                read_chromosomes[chrom] = open(os.path.join(os.getcwd(), chrom + '.vcf'), 'w')\n                print(''.join(header), file=read_chromosomes[chrom], end='')\n                print(line, file=read_chromosomes[chrom])\n    # Process chromosomes that had no mutations\n    for chrom in set(chromosomes).difference(set(read_chromosomes.keys())):\n        read_chromosomes[chrom] = open(os.path.join(os.getcwd(), chrom + '.vcf'), 'w')\n        print(''.join(header), file=read_chromosomes[chrom], end='')\n    outdict = {}\n    chroms = set(chromosomes).intersection(set(read_chromosomes.keys()))\n    for chrom, chromvcf in read_chromosomes.items():\n        chromvcf.close()\n        if chrom not in chroms:\n            continue\n        outdict[chrom] = job.fileStore.writeGlobalFile(chromvcf.name)\n        export_results(job, outdict[chrom], chromvcf.name, univ_options,\n                       subfolder='mutations/' + tool_name)\n    return outdict", "label": 1}
{"code": "function(user_id, password, options) {\n      options = opts(this, options);\n\n      var payload = JSON.stringify({\n        password: password\n      });\n\n      return new APICall({\n        action: 'account/' + user_id + '/password/change',\n        type: 'POST',\n        options: options,\n        processResponse: APICall.basicResponse,\n        data: payload\n      });\n    }", "label": 3}
{"code": "def each_pixel\n      get_pixels(0, 0, columns, rows).each_with_index do |p, n|\n        yield(p, n % columns, n / columns)\n      end\n      self\n    end", "label": 4}
{"code": "function (cb) {\n\t\t\tif (!o1.options.useCDN)\n\t\t\t\treturn cb();\n\n\t\t\to1._log('CDN enabling the container');\n\n\t\t\tcontainer.enableCdn(function (err, _container) {\n\t\t\t\tif (err)\n\t\t\t\t\treturn cb(err);\n\n\t\t\t\t// check that a parallel operation didn't just CDN enable the same container\n\t\t\t\tvar index = _.findIndex(o1.aContainers, { name : sName });\n\n\t\t\t\tcontainer = o1.aContainers[index] = _container;\n\n\t\t\t\tcb();\n\t\t\t});\n\t\t}", "label": 3}
{"code": "def set_attrs_from_response(response)\n      unless response.body.nil? || (response.body.length < 2)\n        json = self.class.parse_json(response.body)\n        set_attrs(json)\n      end\n    end", "label": 4}
{"code": "func (s *SpdyRoundTripper) dial(req *http.Request) (net.Conn, error) {\n\treturn s.dialWithoutProxy(req.URL)\n}", "label": 5}
{"code": "function loadFactories(opts) {\n        this.flapjackFactory = new FlapjackFactory(this);\n\n        return [\n            new InternalObjFactory(this),\n            new AdapterFactory(this),\n            new ServiceFactory(this),\n            new ModelFactory(this),\n            new UipartFactory(this),\n            this.flapjackFactory,\n            new ModulePluginFactory(this, opts.modulePlugins),\n            new DefaultFactory(this)\n        ];\n    }", "label": 3}
{"code": "public function setReadWrite($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\TransactionOptions_ReadWrite::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def create(*args)\n      arguments(args, required: [:org_name]) do\n        assert_required REQUIRED_PARAMS\n      end\n\n      post_request(\"/orgs/#{arguments.org_name}/hooks\", arguments.params)\n    end", "label": 4}
{"code": "def teardown(self):\n        \"\"\"\n        Clean up all resources when we're done with them.\n        \"\"\"\n        self.containers._teardown()\n        self.networks._teardown()\n        self.volumes._teardown()\n\n        # We need to close the underlying APIClient explicitly to avoid\n        # ResourceWarnings from unclosed HTTP connections.\n        self._client.api.close()", "label": 1}
{"code": "public function write($id, $data)\n    {\n        $changed = $id !== $this->openSessionId\n            || $data !== $this->dataRead;\n        $this->openSessionId = $id;\n\n        // Write the session data using the selected locking strategy\n        $this->sessionWritten = $this->connection\n            ->write($this->formatId($id), $data, $changed);\n\n        return $this->sessionWritten;\n    }", "label": 2}
{"code": "def get_content_type(obj, field_name=False):\n    \"\"\"\n    Returns the content type of an object.\n\n    :param obj: A model instance.\n    :param field_name: Field of the object to return.\n\n    \"\"\"\n    content_type = ContentType.objects.get_for_model(obj)\n    if field_name:\n        return getattr(content_type, field_name, '')\n    return content_type", "label": 1}
{"code": "function getSuperCallAtGivenIndex(ctor, index) {\n                if (!ctor.body) {\n                    return undefined;\n                }\n                var statements = ctor.body.statements;\n                if (!statements || index >= statements.length) {\n                    return undefined;\n                }\n                var statement = statements[index];\n                if (statement.kind === 202 /* ExpressionStatement */) {\n                    return ts.isSuperCallExpression(statement.expression) ? statement : undefined;\n                }\n            }", "label": 3}
{"code": "func (c *ClusterConfigV3) SetKeepAliveInterval(t time.Duration) {\n\tc.Spec.KeepAliveInterval = Duration(t)\n}", "label": 5}
{"code": "func (h *Heartbeat) reset(state KeepAliveState) {\n\th.setState(state)\n\th.nextAnnounce = time.Time{}\n\th.nextKeepAlive = time.Time{}\n\th.keepAlive = nil\n\tif h.keepAliver != nil {\n\t\tif err := h.keepAliver.Close(); err != nil {\n\t\t\th.Warningf(\"Failed to close keep aliver: %v\", err)\n\t\t}\n\t\th.keepAliver = nil\n\t}\n}", "label": 5}
{"code": "func (r *Registry) CustomFieldsManager() *CustomFieldsManager {\n\treturn r.Get(r.content().CustomFieldsManager.Reference()).(*CustomFieldsManager)\n}", "label": 5}
{"code": "function openPopup(params) {\n  var container = getContainer();\n  var popup = getPopup();\n\n  if (params.onBeforeOpen !== null && typeof params.onBeforeOpen === 'function') {\n    params.onBeforeOpen(popup);\n  }\n\n  if (params.animation) {\n    addClass(popup, swalClasses.show);\n    addClass(container, swalClasses.fade);\n    removeClass(popup, swalClasses.hide);\n  } else {\n    removeClass(popup, swalClasses.fade);\n  }\n\n  show(popup); // scrolling is 'hidden' until animation is done, after that 'auto'\n\n  container.style.overflowY = 'hidden';\n\n  if (animationEndEvent && !hasClass(popup, swalClasses.noanimation)) {\n    popup.addEventListener(animationEndEvent, function swalCloseEventFinished() {\n      popup.removeEventListener(animationEndEvent, swalCloseEventFinished);\n      container.style.overflowY = 'auto';\n    });\n  } else {\n    container.style.overflowY = 'auto';\n  }\n\n  addClass([document.documentElement, document.body, container], swalClasses.shown);\n\n  if (params.heightAuto && params.backdrop && !params.toast) {\n    addClass([document.documentElement, document.body], swalClasses['height-auto']);\n  }\n\n  if (isModal()) {\n    fixScrollbar();\n    iOSfix();\n    IEfix();\n    setAriaHidden(); // sweetalert2/issues/1247\n\n    setTimeout(function () {\n      container.scrollTop = 0;\n    });\n  }\n\n  if (!isToast() && !globalState.previousActiveElement) {\n    globalState.previousActiveElement = document.activeElement;\n  }\n\n  if (params.onOpen !== null && typeof params.onOpen === 'function') {\n    setTimeout(function () {\n      params.onOpen(popup);\n    });\n  }\n}", "label": 3}
{"code": "func NewAllocator(lcDs, glDs datastore.DataStore) (*Allocator, error) {\n\ta := &Allocator{}\n\n\t// Load predefined subnet pools\n\n\ta.predefined = map[string][]*net.IPNet{\n\t\tlocalAddressSpace:  ipamutils.GetLocalScopeDefaultNetworks(),\n\t\tglobalAddressSpace: ipamutils.GetGlobalScopeDefaultNetworks(),\n\t}\n\n\t// Initialize asIndices map\n\ta.predefinedStartIndices = make(map[string]int)\n\n\t// Initialize bitseq map\n\ta.addresses = make(map[SubnetKey]*bitseq.Handle)\n\n\t// Initialize address spaces\n\ta.addrSpaces = make(map[string]*addrSpace)\n\tfor _, aspc := range []struct {\n\t\tas string\n\t\tds datastore.DataStore\n\t}{\n\t\t{localAddressSpace, lcDs},\n\t\t{globalAddressSpace, glDs},\n\t} {\n\t\ta.initializeAddressSpace(aspc.as, aspc.ds)\n\t}\n\n\treturn a, nil\n}", "label": 5}
{"code": "public static String regexFindFirst(String pattern, String str) {\n    return regexFindFirst(Pattern.compile(pattern), str, 1);\n  }", "label": 0}
{"code": "function prefixProp (name, inCSS) {\n  // $prop will skip\n  if(name[0]=='$') return ''\n  // find name and cache the name for next time use\n  var retName = cssProps[ name ] ||\n      ( cssProps[ name ] = vendorPropName( name ) || name);\n  return inCSS   // if hasPrefix in prop\n    ? dashify(cssPrefixesReg.test(retName) ? capitalize(retName) : name=='float' && name || retName)  // fix float in CSS, avoid return cssFloat\n  : retName\n}", "label": 3}
{"code": "def log(self, level, message, *args, **kwargs):\n        \"\"\"\n        This is the primary method to override to ensure logging with extra\n        options gets correctly specified.\n        \"\"\"\n        extra = self.extras.copy()\n        extra.update(kwargs.pop('extra', {}))\n\n        kwargs['extra'] = extra\n        self.logger.log(level, message, *args, **kwargs)", "label": 1}
{"code": "private Long fetchServiceId(ServiceReference serviceReference) {\n        return (Long) serviceReference.getProperty(org.osgi.framework.Constants.SERVICE_ID);\n    }", "label": 0}
{"code": "def add_logout_button_to_menu(menu, priority = 20, html_options = {})\n      if logout_link_path\n        html_options = html_options.reverse_merge(method: logout_link_method || :get)\n        menu.add id: 'logout', priority: priority, html_options: html_options,\n          label: -> { I18n.t 'active_admin.logout' },\n          url:   -> { render_or_call_method_or_proc_on self, active_admin_namespace.logout_link_path },\n          if:    :current_active_admin_user?\n      end\n    end", "label": 4}
{"code": "func saveConfig(c Config) {\n\tj, err := json.MarshalIndent(c, \"\", \"  \")\n\tif err == nil {\n\t\terr = ioutil.WriteFile(configFile, j, 0644)\n\t}\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}", "label": 5}
{"code": "function compactBuffers(context, node) {\n  var out = [node[0]], memo;\n  for (var i=1, len=node.length; i<len; i++) {\n    var res = dust.filterNode(context, node[i]);\n    if (res) {\n      if (res[0] === 'buffer') {\n        if (memo) {\n          memo[1] += res[1];\n        } else {\n          memo = res;\n          out.push(res);\n        }\n      } else {\n        memo = null;\n        out.push(res);\n      }\n    }\n  }\n  return out;\n}", "label": 3}
{"code": "function File(retries, cdn, options) {\n  options = options || {};\n\n  this.backoff = new Backoff({ min: 100, max: 20000 });\n  this.mime = options.mime || {};\n  this.retries = retries || 5;\n  this.client = cdn.client;\n  this.cdn = cdn;\n}", "label": 3}
{"code": "def FD(self):\n    \"\"\"\n    Set-up for the finite difference solution method\n    \"\"\"\n    if self.Verbose:\n      print(\"Finite Difference Solution Technique\")\n    # Used to check for coeff_matrix here, but now doing so in self.bc_check()\n    # called by f1d and f2d at the start\n    # \n    # Define a stress-based qs = q0\n    # But only if the latter has not already been defined\n    # (e.g., by the getters and setters)\n    try:\n      self.qs\n    except:\n      self.qs = self.q0.copy()\n      # Remove self.q0 to avoid issues with multiply-defined inputs\n      # q0 is the parsable input to either a qs grid or contains (x,(y),q)\n      del self.q0\n    # Give it x and y dimensions for help with plotting tools\n    # (not implemented internally, but a help with external methods)\n    self.x = np.arange(self.dx/2., self.dx * self.qs.shape[0], self.dx)\n    if self.dimension == 2:\n      self.y = np.arange(self.dy/2., self.dy * self.qs.shape[1], self.dy)\n    # Is there a solver defined\n    try:\n      self.Solver # See if it exists already\n    except:\n      # Well, will fail if it doesn't see this, maybe not the most reasonable\n      # error message.\n      if self.filename:\n        self.Solver = self.configGet(\"string\", \"numerical\", \"Solver\")\n      else:\n        sys.exit(\"No solver defined!\")\n    # Check consistency of size if coeff array was loaded\n    if self.filename:\n      # In the case that it is iterative, find the convergence criterion\n      self.iterative_ConvergenceTolerance = self.configGet(\"float\", \"numerical\", \"ConvergenceTolerance\")    \n      # Try to import Te grid or scalar for the finite difference solution\n      try:\n        self.Te = self.configGet(\"float\", \"input\", \"ElasticThickness\", optional=False)\n        if self.Te is None:\n          Tepath = self.configGet(\"string\", \"input\", \"ElasticThickness\", optional=False)\n          self.Te = Tepath\n        else:\n          Tepath = None\n      except:\n        Tepath = self.configGet(\"string\", \"input\", \"ElasticThickness\", optional=False)\n        self.Te = Tepath\n      if self.Te is None:\n        if self.coeff_matrix is not None:\n          pass\n        else:\n          # Have to bring this out here in case it was discovered in the \n          # try statement that there is no value given\n          sys.exit(\"No input elastic thickness or coefficient matrix supplied.\")\n    # or if getter/setter\n    if type(self.Te) == str: \n      # Try to import Te grid or scalar for the finite difference solution\n      Tepath = self.Te\n    else:\n      Tepath = None # in case no self.filename present (like for GRASS GIS)\n    # If there is a Tepath, import Te\n    # Assume that even if a coeff_matrix is defined\n    # That the user wants Te if they gave the path\n    if Tepath:\n      self.Te = self.loadFile(self.Te, close_on_fail = False)\n      if self.Te is None:\n        print(\"Requested Te file is provided but cannot be located.\")\n        print(\"No scalar elastic thickness is provided in configuration file\")\n        print(\"(Typo in path to input Te grid?)\")\n        if self.coeff_matrix is not None:\n          print(\"But a coefficient matrix has been found.\")\n          print(\"Calculations will be carried forward using it.\")\n        else:\n          print(\"Exiting.\")\n          sys.exit()\n\n      # Check that Te is the proper size if it was loaded\n      # Will be array if it was loaded\n      if self.Te.any():\n        self.TeArraySizeCheck()", "label": 1}
{"code": "function mergeTypings(typingNames) {\n                if (!typingNames) {\n                    return;\n                }\n                for (var _i = 0, typingNames_1 = typingNames; _i < typingNames_1.length; _i++) {\n                    var typing = typingNames_1[_i];\n                    if (!(typing in inferredTypings)) {\n                        inferredTypings[typing] = undefined;\n                    }\n                }\n            }", "label": 3}
{"code": "def wrap(lower, upper, x):\n    \"\"\"\n    Circularly alias the numeric value x into the range [lower,upper).\n\n    Valid for cyclic quantities like orientations or hues.\n    \"\"\"\n    #I have no idea how I came up with this algorithm; it should be simplified.\n    #\n    # Note that Python's % operator works on floats and arrays;\n    # usually one can simply use that instead.  E.g. to wrap array or\n    # scalar x into 0,2*pi, just use \"x % (2*pi)\".\n    range_=upper-lower\n    return lower + np.fmod(x-lower + 2*range_*(1-np.floor(x/(2*range_))), range_)", "label": 1}
{"code": "function getCommandHelps() {\n        const cmds = {},\n            topics = {},\n            result = ['Registered commands:'];\n        let keys = {};\n        Object.keys(handlers).map((key) => {\n            keys[key] = 1;\n        });\n        Object.keys(helpTopics).map((key) => {\n            keys[key] = 1;\n        });\n        Object.keys(keys).map((key) => {\n            if (handlers[key]) {\n                cmds[key] = handlers[key].help;\n                if (helpTopics[key]) {\n                    cmds[key] += ' *';\n                }\n            } else {\n                topics[key] = 'Extended help topic';\n            }\n        });\n        keys = Object.keys(cmds);\n        keys.sort();\n        keys.forEach((cmd) => result.push(`${cmd}: ${cmds[cmd]}`));\n        keys = Object.keys(topics);\n        if (keys.length) {\n            result.push('');\n            result.push('Help Topics:');\n            keys.sort();\n            keys.forEach((topic) => result.push(`${topic}: ${topics[topic]}`));\n        }\n        return result.join('\\n');\n    }", "label": 3}
{"code": "func (c *GithubConnectorV3) MapClaims(claims GithubClaims) ([]string, []string) {\n\tvar logins, kubeGroups []string\n\tfor _, mapping := range c.GetTeamsToLogins() {\n\t\tteams, ok := claims.OrganizationToTeams[mapping.Organization]\n\t\tif !ok {\n\t\t\t// the user does not belong to this organization\n\t\t\tcontinue\n\t\t}\n\t\tfor _, team := range teams {\n\t\t\t// see if the user belongs to this team\n\t\t\tif team == mapping.Team {\n\t\t\t\tlogins = append(logins, mapping.Logins...)\n\t\t\t\tkubeGroups = append(kubeGroups, mapping.KubeGroups...)\n\t\t\t}\n\t\t}\n\t}\n\treturn utils.Deduplicate(logins), utils.Deduplicate(kubeGroups)\n}", "label": 5}
{"code": "function (i) {\n                    if (i >= columns.length) {\n                        insertIntoDB();\n                        return;\n                    }\n\n                    var dbField = columns[i];\n                    var field = dbField.Field;\n\n                    //Check required fields\n                    if (dbField.Null === 'NO' && \n                        dbField.Default === '' && \n                        dbField.Extra !== 'auto_increment' && \n                        dbField.Extra.search('on update')===-1) {\n\n                        //Check if field not set\n                        if (undefOrEmpty(req.body[field])) {\n                            return sendError(res,\"Field \" + field + \" is NOT NULL but not specified in this request\");\n                        } else {\n                            //Check if the set values are roughly okay\n                            value = checkIfSentvaluesAreSufficient(req,dbField);\n                            console.log(value);\n                            if(value !== false) {\n                                //Value seems okay, go to the next field\n                                insertJson[field] = value;\n                                iterator(i + 1);\n                            } else {\n                                return sendError(res,'Value for field ' + field + ' is not sufficient. Expecting ' + dbField.Type + ' but got ' + typeof req.body[field] );\n                            }\n                        }\n                    }  else {\n                        //Check for not required fields\n                        //Skip auto_incremented fields\n                        if(dbField.Extra === 'auto_increment') {\n                            iterator(i + 1);\n                        } else {\n                            //Check if the field was provided by the client\n                            var defined = false;\n                            if(dbField.Default == \"FILE\") {\n                                if(req.files.hasOwnProperty(dbField.Field)) {\n                                    defined = true;\n                                }\n                            } else {\n                                if(typeof req.body[field] !== \"undefined\") {\n                                    defined = true;\n                                }\n                            }\n\n                            //If it was provided, check if the values are okay\n                            if(defined) {\n                                value = checkIfSentvaluesAreSufficient(req,dbField);\n                                if(value !== false) {\n                                    insertJson[field] = value;\n                                    iterator(i + 1);\n                                } else {\n                                    if(dbField.Default == \"FILE\") {\n                                        return sendError(res, 'Value for field ' + field + ' is not sufficient. Either the file is to large or an other error occured');\n                                    } else {\n                                        return sendError(res, 'Value for field ' + field + ' is not sufficient. Expecting ' + dbField.Type + ' but got ' + typeof req.body[field]);\n                                    }\n                                }\n                            } else {\n                                //If not, don't mind\n                                iterator(i + 1);\n                            }\n\n                        }\n                    }\n\n                }", "label": 3}
{"code": "public static String termPrefix(String term) {\n    int i = term.indexOf(MtasToken.DELIMITER);\n    String prefix = term;\n    if (i >= 0) {\n      prefix = term.substring(0, i);\n    }\n    return prefix.replace(\"\\u0000\", \"\");\n  }", "label": 0}
{"code": "function TransactionTask(readOnly, txnCallback, errorCallback, successCallback) {\n  this.readOnly = readOnly;\n  this.txnCallback = txnCallback;\n  this.errorCallback = errorCallback;\n  this.successCallback = successCallback;\n}", "label": 3}
{"code": "public function toParameter($value)\n    {\n        $pValue = ['value' => $value];\n        $type = gettype($value);\n\n        switch ($type) {\n            case 'boolean':\n                $pType['type'] = self::TYPE_BOOL;\n\n                break;\n            case 'integer':\n                $pType['type'] = self::TYPE_INT64;\n\n                break;\n            case 'double':\n                $pType['type'] = self::TYPE_FLOAT64;\n\n                break;\n            case 'string':\n                $pType['type'] = self::TYPE_STRING;\n\n                break;\n            case 'resource':\n                $pType['type'] = self::TYPE_BYTES;\n                $pValue['value'] = base64_encode(stream_get_contents($value));\n\n                break;\n            case 'object':\n                list($pType, $pValue) = $this->objectToParameter($value);\n\n                break;\n            case 'array':\n                list($pType, $pValue) = $this->isAssoc($value)\n                    ? $this->assocArrayToParameter($value)\n                    : $this->arrayToParameter($value);\n\n                break;\n            default:\n                throw new \\InvalidArgumentException(sprintf(\n                    'Unrecognized value type %s. Please ensure you are using the latest version of google/cloud.',\n                    $type\n                ));\n\n                break;\n        }\n\n        return [\n            'parameterType' => $pType,\n            'parameterValue' => $pValue\n        ];\n    }", "label": 2}
{"code": "function write(drizzleData) {\n  return Promise.all([\n    writePages(drizzleData),\n    writeCollections(drizzleData)\n  ]).then(\n    () => drizzleData,\n    error => DrizzleError.error(error, drizzleData.options)\n  );\n}", "label": 3}
{"code": "public function byteSize()\n    {\n        return mb_strlen($this->name) +\n                mb_strlen($this->type) +\n                mb_strlen($this->value);\n    }", "label": 2}
{"code": "protected function createAuthNode()\n  {\n      $data = $this->createAuthBlob();\n      $attributes = [\n          'user'      => $this->phoneNumber,\n          'mechanism' => 'WAUTH-2',\n\n      ];\n      $node = new ProtocolNode('auth', $attributes, null, $data);\n\n      return $node;\n  }", "label": 2}
{"code": "def to_s(format = nil, options = nil)\n      case format\n      when nil\n        super()\n      when Integer, String\n        super(format)\n      when :phone\n        ActiveSupport::NumberHelper.number_to_phone(self, options || {})\n      when :currency\n        ActiveSupport::NumberHelper.number_to_currency(self, options || {})\n      when :percentage\n        ActiveSupport::NumberHelper.number_to_percentage(self, options || {})\n      when :delimited\n        ActiveSupport::NumberHelper.number_to_delimited(self, options || {})\n      when :rounded\n        ActiveSupport::NumberHelper.number_to_rounded(self, options || {})\n      when :human\n        ActiveSupport::NumberHelper.number_to_human(self, options || {})\n      when :human_size\n        ActiveSupport::NumberHelper.number_to_human_size(self, options || {})\n      when Symbol\n        super()\n      else\n        super(format)\n      end\n    end", "label": 4}
{"code": "def set_ref(self, ref, attr=None):\n        \"\"\"Set reference to resource\n\n        Can be used to set references on a resource\n        that is not already created.\n\n        :param ref: reference to add\n        :type ref: Resource\n\n        :rtype: Resource\n        \"\"\"\n        ref_attr = '%s_refs' % ref.type.replace('-', '_')\n        ref = {\n            'to': ref.fq_name,\n            'uuid': ref.uuid,\n        }\n        if ref_attr in self:\n            self[ref_attr].append(ref)\n        else:\n            self[ref_attr] = [ref]\n        return self", "label": 1}
{"code": "function getPointDistance(x0, x1, y0, y1) {\n  return (Math.sqrt(((x1 - x0) * (x1 - x0)) + ((y1 - y0) * (y1 - y0))));\n}", "label": 3}
{"code": "private function addMissingItemsFromOrderByToSelect(SelectStatement $AST)\n    {\n        $this->orderByPathExpressions = [];\n\n        // We need to do this in another walker because otherwise we'll end up\n        // polluting the state of this one.\n        $walker = clone $this;\n\n        // This will populate $orderByPathExpressions via\n        // LimitSubqueryOutputWalker::walkPathExpression, which will be called\n        // as the select statement is walked. We'll end up with an array of all\n        // path expressions referenced in the query.\n        $walker->walkSelectStatementWithoutRowNumber($AST, false);\n        $orderByPathExpressions = $walker->getOrderByPathExpressions();\n\n        // Get a map of referenced identifiers to field names.\n        $selects = [];\n\n        foreach ($orderByPathExpressions as $pathExpression) {\n            $idVar = $pathExpression->identificationVariable;\n            $field = $pathExpression->field;\n\n            if (! isset($selects[$idVar])) {\n                $selects[$idVar] = [];\n            }\n\n            $selects[$idVar][$field] = true;\n        }\n\n        // Loop the select clause of the AST and exclude items from $select\n        // that are already being selected in the query.\n        foreach ($AST->selectClause->selectExpressions as $selectExpression) {\n            if ($selectExpression instanceof SelectExpression) {\n                $idVar = $selectExpression->expression;\n\n                if (! is_string($idVar)) {\n                    continue;\n                }\n\n                $field = $selectExpression->fieldIdentificationVariable;\n\n                if ($field === null) {\n                    // No need to add this select, as we're already fetching the whole object.\n                    unset($selects[$idVar]);\n                } else {\n                    unset($selects[$idVar][$field]);\n                }\n            }\n        }\n\n        // Add select items which were not excluded to the AST's select clause.\n        foreach ($selects as $idVar => $fields) {\n            $selectExpression = new SelectExpression(new PartialObjectExpression($idVar, array_keys($fields)), null, true);\n\n            $AST->selectClause->selectExpressions[] = $selectExpression;\n        }\n    }", "label": 2}
{"code": "public static base_responses update(nitro_service client, clusterinstance resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tclusterinstance updateresources[] = new clusterinstance[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new clusterinstance();\n\t\t\t\tupdateresources[i].clid = resources[i].clid;\n\t\t\t\tupdateresources[i].deadinterval = resources[i].deadinterval;\n\t\t\t\tupdateresources[i].hellointerval = resources[i].hellointerval;\n\t\t\t\tupdateresources[i].preemption = resources[i].preemption;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected function getSelectConditionCriteriaSQL(Criteria $criteria)\n    {\n        $expression = $criteria->getWhereExpression();\n\n        if ($expression === null) {\n            return '';\n        }\n\n        $visitor = new SqlExpressionVisitor($this, $this->class);\n\n        return $visitor->dispatch($expression);\n    }", "label": 2}
{"code": "func (tl TypeLoader) LoadProcParams(args *ArgType, procTpl *Proc) error {\n\tvar err error\n\n\t// load proc params\n\tparamList, err := tl.ProcParamList(args.DB, args.Schema, procTpl.Proc.ProcName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// process params\n\tfor i, p := range paramList {\n\t\t// TODO: some databases support named parameters in procs (MySQL)\n\t\tparamTpl := &Field{\n\t\t\tName: fmt.Sprintf(\"v%d\", i),\n\t\t}\n\n\t\t// TODO: fix this so that nullable types can be used as parameters\n\t\t_, _, paramTpl.Type = tl.ParseType(args, strings.TrimSpace(p.ParamType), false)\n\n\t\t// add to proc params\n\t\tif procTpl.ProcParams != \"\" {\n\t\t\tprocTpl.ProcParams = procTpl.ProcParams + \", \"\n\t\t}\n\t\tprocTpl.ProcParams = procTpl.ProcParams + p.ParamType\n\n\t\tprocTpl.Params = append(procTpl.Params, paramTpl)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "private void deleteByQuery(Query query, ClassDescriptor cld) throws PersistenceBrokerException\n    {\n        if (logger.isDebugEnabled())\n        {\n            logger.debug(\"deleteByQuery \" + cld.getClassNameOfObject() + \", \" + query);\n        }\n\n        if (query instanceof QueryBySQL)\n        {\n            String sql = ((QueryBySQL) query).getSql();\n            this.dbAccess.executeUpdateSQL(sql, cld);\n        }\n        else\n        {\n            // if query is Identity based transform it to a criteria based query first\n            if (query instanceof QueryByIdentity)\n            {\n                QueryByIdentity qbi = (QueryByIdentity) query;\n                Object oid = qbi.getExampleObject();\n                // make sure it's an Identity\n                if (!(oid instanceof Identity))\n                {\n                    oid = serviceIdentity().buildIdentity(oid);\n                }\n                query = referencesBroker.getPKQuery((Identity) oid);\n            }\n\n            if (!cld.isInterface())\n            {\n                this.dbAccess.executeDelete(query, cld);\n            }\n\n            // if class is an extent, we have to delete all extent classes too\n            String lastUsedTable = cld.getFullTableName();\n            if (cld.isExtent())\n            {\n                Iterator extents = getDescriptorRepository().getAllConcreteSubclassDescriptors(cld).iterator();\n\n                while (extents.hasNext())\n                {\n                    ClassDescriptor extCld = (ClassDescriptor) extents.next();\n\n                    // read same table only once\n                    if (!extCld.getFullTableName().equals(lastUsedTable))\n                    {\n                        lastUsedTable = extCld.getFullTableName();\n                        this.dbAccess.executeDelete(query, extCld);\n                    }\n                }\n            }\n\n        }\n    }", "label": 0}
{"code": "function cleanResultsStatus() {\n        // remove criterias and spec if no criteria in spec\n        for (const spec in mergedResults.specs) {\n            if (!(spec in parseResults.specs.specTable) || Object.keys(parseResults.specs.specTable[spec].criteria).length === 0) {\n                delete mergedResults.specs[spec];\n            }\n            else {\n                const parsedCriteria = parseResults.specs.specTable[spec].criteria;\n                const resultsCriteria = mergedResults.specs[spec];\n                for (const criteria in resultsCriteria) {\n                    if (!(criteria in parsedCriteria)) {\n                        delete mergedResults.specs[spec][criteria];\n                    }\n                }\n            }\n        }\n        for (const testcase in mergedResults.testcases) {\n            if (!(testcase in parseResults.testcases.testcaseTable)) {\n                delete mergedResults.testcases[testcase];\n            }\n        }\n        // add criteria\n        for (const spec in parseResults.specs.specTable) {\n            if (!(spec in mergedResults.specs)) {\n                mergedResults.specs[spec] = {};\n            }\n            const parsedCriteria = parseResults.specs.specTable[spec].criteria;\n            const resultsCriteria = mergedResults.specs[spec];\n            for (const criteria in parsedCriteria) {\n                if (!(criteria in resultsCriteria)) {\n                    mergedResults.specs[spec][criteria] = {\n                        dateTime,\n                        status: 'unknown',\n                        resultsFolder: undefined,\n                    };\n                    if (criteria in criteriaAnalysis.specs[spec].manual) {\n                        mergedResults.specs[spec][criteria].manual = true;\n                    }\n                }\n            }\n        }\n        for (const testcase in parseResults.testcases.testcaseTable) {\n            if (!(testcase in mergedResults.testcases)) {\n                mergedResults.testcases[testcase] = {\n                    dateTime,\n                    status: 'unknown',\n                    resultsFolder: undefined,\n                };\n            }\n        }\n        fs.writeFileSync(mergedResultsPath, JSON.stringify(mergedResults), { encoding: 'utf8' });\n    }", "label": 3}
{"code": "protected function bootSchemas()\n    {\n        $configSchemas = config('graphql.schemas');\n        foreach ($configSchemas as $name => $schema) {\n            $this->app['graphql']->addSchema($name, $schema);\n        }\n    }", "label": 2}
{"code": "def render_revalidation_failure(self, failed_step, form, **kwargs):\n        \"\"\"\n        When a step fails, we have to redirect the user to the first failing\n        step.\n        \"\"\"\n        self.storage.current_step = failed_step\n        return redirect(self.url_name, step=failed_step)", "label": 1}
{"code": "def untargz(input_targz_file, untar_to_dir):\n    \"\"\"\n    This module accepts a tar.gz archive and untars it.\n\n    RETURN VALUE: path to the untar-ed directory/file\n\n    NOTE: this module expects the multiple files to be in a directory before\n          being tar-ed.\n    \"\"\"\n    assert tarfile.is_tarfile(input_targz_file), 'Not a tar file.'\n    tarball = tarfile.open(input_targz_file)\n    return_value = os.path.join(untar_to_dir, tarball.getmembers()[0].name)\n    tarball.extractall(path=untar_to_dir)\n    tarball.close()\n    return return_value", "label": 1}
{"code": "def service_start_type(service_name)\n      start_type = nil\n      open_service(service_name, SC_MANAGER_CONNECT, SERVICE_QUERY_CONFIG) do |service|\n        query_config(service) do |config|\n          start_type = SERVICE_START_TYPES[config[:dwStartType]]\n        end\n      end\n      if start_type.nil?\n        raise Puppet::Error.new(_(\"Unknown start type '%{start_type}' for '%{service_name}'\") % { start_type: start_type.to_s, service_name: service_name})\n      end\n      start_type\n    end", "label": 4}
{"code": "public boolean shouldNotCache(String requestUri) {\n\t\tString uri = requestUri.toLowerCase();\n\t\treturn checkContains(uri, noCacheIdentifiers) || checkSuffixes(uri, noCacheSuffixes);\n\t}", "label": 0}
{"code": "public static base_responses update(nitro_service client, policyexpression resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tpolicyexpression updateresources[] = new policyexpression[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new policyexpression();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].value = resources[i].value;\n\t\t\t\tupdateresources[i].description = resources[i].description;\n\t\t\t\tupdateresources[i].comment = resources[i].comment;\n\t\t\t\tupdateresources[i].clientsecuritymessage = resources[i].clientsecuritymessage;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func SetAuditLog(alog events.IAuditLog) ServerOption {\n\treturn func(s *Server) error {\n\t\ts.alog = alog\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "protected function executeCommand()\n    {\n        return $this->client->lrange($this->key, $this->position + 1, $this->position + $this->count);\n    }", "label": 2}
{"code": "def collect(options = {}, &block)\n      collector = AnswersCollector.new(self, options)\n      collector.call(&block)\n    end", "label": 4}
{"code": "def restore_merge_state\n      if @merge_head\n        FileUtils.touch(File.expand_path('MERGE_MODE', Overcommit::Utils.git_dir))\n\n        File.open(File.expand_path('MERGE_HEAD', Overcommit::Utils.git_dir), 'w') do |f|\n          f.write(@merge_head)\n        end\n        @merge_head = nil\n      end\n\n      if @merge_msg\n        File.open(File.expand_path('MERGE_MSG', Overcommit::Utils.git_dir), 'w') do |f|\n          f.write(\"#{@merge_msg}\\n\")\n        end\n        @merge_msg = nil\n      end\n    end", "label": 4}
{"code": "def encode(self, o):\n        \"\"\"\n        Return a JSON string representation of a Python data structure.\n\n        >>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n        '{\"foo\":[\"bar\", \"baz\"]}'\n        \"\"\"\n        # This doesn't pass the iterator directly to ''.join() because it\n        # sucks at reporting exceptions.  It's going to do this internally\n        # anyway because it uses PySequence_Fast or similar.\n        chunks = list(self.iterencode(o))\n        return ''.join(chunks)", "label": 1}
{"code": "private static function removePrefix($str, $prefix)\n    {\n        if (substr($str, 0, strlen($prefix)) == $prefix) {\n            return substr($str, strlen($prefix));\n        }\n        return null;\n    }", "label": 2}
{"code": "public function setUnit($unit, $value = null)\n    {\n        $unit = static::singularUnit($unit);\n        $dateUnits = ['year', 'month', 'day'];\n        if (in_array($unit, $dateUnits)) {\n            return $this->setDate(...array_map(function ($name) use ($unit, $value) {\n                return $name === $unit ? $value : $this->$name;\n            }, $dateUnits));\n        }\n\n        $units = ['hour', 'minute', 'second', 'micro'];\n        if ($unit === 'millisecond' || $unit === 'milli') {\n            $value *= 1000;\n            $unit = 'micro';\n        } elseif ($unit === 'microsecond') {\n            $unit = 'micro';\n        }\n\n        return $this->setTime(...array_map(function ($name) use ($unit, $value) {\n            return $name === $unit ? $value : $this->$name;\n        }, $units));\n    }", "label": 2}
{"code": "function plugin(options) {\n    if (!options || typeof options !== 'object') {\n        throw new Error('AjvMoment#plugin requires options');\n    }\n    if (!options.ajv) {\n        throw new Error(`AjvMoment#plugin options requries an 'ajv' attribute (ajv instance)`);\n    }\n    if (!options.moment) {\n        throw new Error(`AjvMoment#plugin options requries a 'moment' attribute (moment.js)`);\n    }\n    const { ajv, moment } = options;\n    ajv.moment = moment;\n    const keywordSettings = {\n        type: 'string',\n        statements: true,\n        errors: true,\n        inline\n    };\n    if (ajv) {\n        ajv.addKeyword('moment', keywordSettings);\n    }\n    return keywordSettings;\n}", "label": 3}
{"code": "async def _sync_revoc(self, rr_id: str, rr_size: int = None) -> None:\n        \"\"\"\n        Create revoc registry if need be for input revocation registry identifier;\n        open and cache tails file reader.\n\n        :param rr_id: revocation registry identifier\n        :param rr_size: if new revocation registry necessary, its size (default as per _create_rev_reg())\n        \"\"\"\n\n        LOGGER.debug('Issuer._sync_revoc >>> rr_id: %s, rr_size: %s', rr_id, rr_size)\n\n        (cd_id, tag) = rev_reg_id2cred_def_id__tag(rr_id)\n\n        try:\n            await self.get_cred_def(cd_id)\n        except AbsentCredDef:\n            LOGGER.debug(\n                'Issuer._sync_revoc: <!< tails tree %s may be for another ledger; no cred def found on %s',\n                self._dir_tails,\n                cd_id)\n            raise AbsentCredDef('Tails tree {} may be for another ledger; no cred def found on {}'.format(\n                self._dir_tails,\n                cd_id))\n\n        with REVO_CACHE.lock:\n            revo_cache_entry = REVO_CACHE.get(rr_id, None)\n            tails = None if revo_cache_entry is None else revo_cache_entry.tails\n            if tails is None:  #  it's a new revocation registry, or not yet set in cache\n                try:\n                    tails = await Tails(self._dir_tails, cd_id, tag).open()\n                except AbsentTails:\n                    await self._create_rev_reg(rr_id, rr_size)   # it's a new revocation registry\n                    tails = await Tails(self._dir_tails, cd_id, tag).open()  # symlink should exist now\n\n                if revo_cache_entry is None:\n                    REVO_CACHE[rr_id] = RevoCacheEntry(None, tails)\n                else:\n                    REVO_CACHE[rr_id].tails = tails\n\n        LOGGER.debug('Issuer._sync_revoc <<<')", "label": 1}
{"code": "protected void getBatch(int batchSize){\r\n\r\n//      if (numCalls == 0) {\r\n//        for (int i = 0; i < 1538*\\15; i++) {\r\n//          randGenerator.nextInt(this.dataDimension());\r\n//        }\r\n//      }\r\n//      numCalls++;\r\n\r\n    if (thisBatch == null || thisBatch.length != batchSize){\r\n      thisBatch = new int[batchSize];\r\n    }\r\n\r\n    //-----------------------------\r\n    //RANDOM WITH REPLACEMENT\r\n    //-----------------------------\r\n    if (sampleMethod.equals(SamplingMethod.RandomWithReplacement)){\r\n      for(int i = 0; i<batchSize;i++){\r\n        thisBatch[i] = randGenerator.nextInt(this.dataDimension());        //Just generate a random index\r\n//        System.err.println(\"numCalls = \"+(numCalls++));\r\n      }\r\n      //-----------------------------\r\n      //ORDERED\r\n      //-----------------------------\r\n    }else if(sampleMethod.equals(SamplingMethod.Ordered)){\r\n      for(int i = 0; i<batchSize;i++){\r\n        thisBatch[i] = (curElement + i) % this.dataDimension() ;          //Take the next batchSize points in order\r\n      }\r\n      curElement = (curElement + batchSize) % this.dataDimension();       //watch out for overflow\r\n\r\n      //-----------------------------\r\n      //RANDOM WITHOUT REPLACEMENT\r\n      //-----------------------------\r\n    }else if(sampleMethod.equals(SamplingMethod.RandomWithoutReplacement)){\r\n      //Declare the indices array if needed.\r\n      if (allIndices == null || allIndices.size()!= this.dataDimension()){\r\n\r\n        allIndices = new ArrayList<Integer>();\r\n        for(int i=0;i<this.dataDimension();i++){\r\n          allIndices.add(i);\r\n        }\r\n        Collections.shuffle(allIndices,randGenerator);\r\n      }\r\n\r\n      for(int i = 0; i<batchSize;i++){\r\n        thisBatch[i] = allIndices.get((curElement + i) % allIndices.size());  //Grab the next batchSize indices\r\n      }\r\n\r\n      if (curElement + batchSize > this.dataDimension()){\r\n        Collections.shuffle(Arrays.asList(allIndices),randGenerator);                   //Shuffle if we got to the end of the list\r\n      }\r\n\r\n      //watch out for overflow\r\n      curElement = (curElement + batchSize) % allIndices.size();          //Rollover\r\n\r\n\r\n    }else{\r\n      System.err.println(\"NO SAMPLING METHOD SELECTED\");\r\n      System.exit(1);\r\n    }\r\n\r\n\r\n  }", "label": 0}
{"code": "def get_gems(ctx):\n    \"\"\"Prints out total gems count for a Steam user.\"\"\"\n\n    username = ctx.obj['username']\n    click.secho(\n        'Total gems owned by `%s`: %d' % (username, User(username).gems_total),\n        fg='green')", "label": 1}
{"code": "def configurations\n      @configurations ||= if workspace?\n                            workspace\n                              .file_references\n                              .map(&:path)\n                              .reject { |p| p.include?(\"Pods/Pods.xcodeproj\") }\n                              .map do |p|\n                                # To maintain backwards compatibility, we\n                                # silently ignore non-existent projects from\n                                # workspaces.\n                                begin\n                                  Xcodeproj::Project.open(p).build_configurations\n                                rescue\n                                  []\n                                end\n                              end\n                              .flatten\n                              .compact\n                              .map(&:name)\n                          else\n                            project.build_configurations.map(&:name)\n                          end\n    end", "label": 4}
{"code": "def _add_base_info(self, event_dict):\n        \"\"\"\n        Instead of using a processor, adding basic information like caller, filename etc\n        here.\n        \"\"\"\n        f = sys._getframe()\n        level_method_frame = f.f_back\n        caller_frame = level_method_frame.f_back\n        return event_dict", "label": 1}
{"code": "def filter_callbacks(kind, action_name)\n      self.class.send(\"#{kind}_callbacks\").select do |callback|\n        callback[:only].nil? || callback[:only].include?(action_name)\n      end\n    end", "label": 4}
{"code": "function sortComments(comments) {\n    comments.sort(comp);\n    $.each(comments, function() {\n      this.children = sortComments(this.children);\n    });\n    return comments;\n  }", "label": 3}
{"code": "public SerialMessage setValueMessage(int level) {\r\n\t\tlogger.debug(\"Creating new message for application command BASIC_SET for node {}\", this.getNode().getNodeId());\r\n\t\tSerialMessage result = new SerialMessage(this.getNode().getNodeId(), SerialMessageClass.SendData, SerialMessageType.Request, SerialMessageClass.SendData, SerialMessagePriority.Set);\r\n    \tbyte[] newPayload = { \t(byte) this.getNode().getNodeId(), \r\n    \t\t\t\t\t\t\t3, \r\n\t\t\t\t\t\t\t\t(byte) getCommandClass().getKey(), \r\n\t\t\t\t\t\t\t\t(byte) BASIC_SET,\r\n\t\t\t\t\t\t\t\t(byte) level\r\n\t\t\t\t\t\t\t\t};\r\n    \tresult.setMessagePayload(newPayload);\r\n    \treturn result;\t\t\r\n\t}", "label": 0}
{"code": "function IndexEntrySee($txta, $txtb)\n\t{\n\t\tif ($this->directionality == 'rtl') { // *OTL*\n\t\t\t// ONLY DO THIS IF NOT IN TAGS\n\t\t\tif ($txta == strip_tags($txta)) {\n\t\t\t\t$txta = str_replace(':', ' - ', $txta); // *OTL*\n\t\t\t}\n\t\t\tif ($txtb == strip_tags($txtb)) {\n\t\t\t\t$txtb = str_replace(':', ' - ', $txtb); // *OTL*\n\t\t\t}\n\t\t} // *OTL*\n\t\telse { // *OTL*\n\t\t\tif ($txta == strip_tags($txta)) {\n\t\t\t\t$txta = str_replace(':', ', ', $txta);\n\t\t\t}\n\t\t\tif ($txtb == strip_tags($txtb)) {\n\t\t\t\t$txtb = str_replace(':', ', ', $txtb);\n\t\t\t}\n\t\t} // *OTL*\n\t\t$this->Reference[] = ['t' => $txta . ' - see ' . $txtb, 'p' => []];\n\t}", "label": 2}
{"code": "function( thing, method, internal ) {\n\n                var thingName, thingMethod,\n                    thingIsObject = $.isPlainObject( thing ),\n                    thingObject = thingIsObject ? thing : {}\n\n                if ( thing ) {\n\n                    // If the thing isn\u2019t an object, make it one.\n                    if ( !thingIsObject ) {\n                        thingObject[ thing ] = method\n                    }\n\n                    // Go through the things to bind to.\n                    for ( thingName in thingObject ) {\n\n                        // Grab the method of the thing.\n                        thingMethod = thingObject[ thingName ]\n\n                        // If it was an internal binding, prefix it.\n                        if ( internal ) {\n                            thingName = '_' + thingName\n                        }\n\n                        // Make sure the thing methods collection exists.\n                        STATE.methods[ thingName ] = STATE.methods[ thingName ] || []\n\n                        // Add the method to the relative method collection.\n                        STATE.methods[ thingName ].push( thingMethod )\n                    }\n                }\n\n                return P\n            }", "label": 3}
{"code": "function (memberValue, memberName) {\n        if (this._filterAttribute(memberName, memberValue)) {\n            return;\n        }\n        var newVisibility = _gpfVisibilityKeywords.indexOf(memberName);\n        if (_GPF_VISIBILITY_UNKNOWN === newVisibility) {\n            return this._addMember(memberName, memberValue, this._deduceVisibility(memberName));\n        }\n        if (_GPF_VISIBILITY_UNKNOWN !== this._defaultVisibility) {\n            gpf.Error.classInvalidVisibility();\n        }\n        this._processDefinition(memberValue, newVisibility);\n    }", "label": 3}
{"code": "function keys(path, opts) {\n  let env = toUnderscore(path);\n\n  if (!opts.caseSensitive) {\n    env = env.toUpperCase();\n    return Object.keys(process.env).filter(key =>\n      key.toUpperCase().startsWith(env)\n    );\n  }\n  return Object.keys(process.env).filter(key => key.startsWith(env));\n}", "label": 3}
{"code": "def inspect_fields\n      fields.map do |name, field|\n        unless name == \"_id\"\n          as = field.options[:as]\n          \"#{name}#{as ? \"(#{as})\" : nil}: #{@attributes[name].inspect}\"\n        end\n      end.compact\n    end", "label": 4}
{"code": "public void unlink(Object obj, ObjectReferenceDescriptor ord, boolean insert)\r\n    {\r\n       linkOrUnlink(false, obj, ord, insert);\r\n    }", "label": 0}
{"code": "def findChangelist(self, description=None):\n        \"\"\"Gets or creates a Changelist object with a description\n\n        :param description: The description to set or lookup\n        :type description: str\n        :returns: :class:`.Changelist`\n        \"\"\"\n        if description is None:\n            change = Default(self)\n        else:\n            if isinstance(description, six.integer_types):\n                change = Changelist(description, self)\n            else:\n                pending = self.run(['changes', '-l', '-s', 'pending', '-c', str(self._client), '-u', self._user])\n                for cl in pending:\n                    if cl['desc'].strip() == description.strip():\n                        LOGGER.debug('Changelist found: {}'.format(cl['change']))\n                        change = Changelist(int(cl['change']), self)\n                        break\n                else:\n                    LOGGER.debug('No changelist found, creating one')\n                    change = Changelist.create(description, self)\n                    change.client = self._client\n                    change.save()\n\n        return change", "label": 1}
{"code": "def strip_tags(string)\n      if defined?(Loofah)\n        # Instead of strip_tags we will use Loofah to strip tags from now on\n        Loofah.fragment(string).text(encode_special_chars: false)\n      else\n        helpers.strip_tags(string)\n      end\n    end", "label": 4}
{"code": "public function compose(array $sourceObjects, $name, array $options = [])\n    {\n        if (count($sourceObjects) < 2) {\n            throw new \\InvalidArgumentException('Must provide at least two objects to compose.');\n        }\n\n        $options += [\n            'destinationBucket' => $this->name(),\n            'destinationObject' => $name,\n            'destinationPredefinedAcl' => isset($options['predefinedAcl']) ? $options['predefinedAcl'] : null,\n            'destination' => isset($options['metadata']) ? $options['metadata'] : null,\n            'userProject' => $this->identity['userProject'],\n            'sourceObjects' => array_map(function ($sourceObject) {\n                $name = null;\n                $generation = null;\n\n                if ($sourceObject instanceof StorageObject) {\n                    $name = $sourceObject->name();\n                    $generation = isset($sourceObject->identity()['generation'])\n                        ? $sourceObject->identity()['generation']\n                        : null;\n                }\n\n                return array_filter([\n                    'name' => $name ?: $sourceObject,\n                    'generation' => $generation\n                ]);\n            }, $sourceObjects)\n        ];\n\n        if (!isset($options['destination']['contentType'])) {\n            $options['destination']['contentType'] = Psr7\\mimetype_from_filename($name);\n        }\n\n        if ($options['destination']['contentType'] === null) {\n            throw new \\InvalidArgumentException('A content type could not be detected and must be provided manually.');\n        }\n\n        unset($options['metadata']);\n        unset($options['predefinedAcl']);\n\n        $response = $this->connection->composeObject(array_filter($options));\n\n        return new StorageObject(\n            $this->connection,\n            $response['name'],\n            $this->identity['bucket'],\n            $response['generation'],\n            $response + array_filter([\n                'requesterProjectId' => $this->identity['userProject']\n            ])\n        );\n    }", "label": 2}
{"code": "def alias_command(alias_name, name, *args)\n      @commands[alias_name.to_s] = command name\n      @aliases[alias_name.to_s] = args\n    end", "label": 4}
{"code": "func (cl *Client) dialFirst(ctx context.Context, addr string) dialResult {\n\tctx, cancel := context.WithCancel(ctx)\n\t// As soon as we return one connection, cancel the others.\n\tdefer cancel()\n\tleft := 0\n\tresCh := make(chan dialResult, left)\n\tfunc() {\n\t\tcl.lock()\n\t\tdefer cl.unlock()\n\t\tcl.eachListener(func(s socket) bool {\n\t\t\tnetwork := s.Addr().Network()\n\t\t\tif peerNetworkEnabled(parseNetworkString(network), cl.config) {\n\t\t\t\tleft++\n\t\t\t\tgo func() {\n\t\t\t\t\tcte := cl.config.ConnTracker.Wait(\n\t\t\t\t\t\tctx,\n\t\t\t\t\t\tconntrack.Entry{network, s.Addr().String(), addr},\n\t\t\t\t\t\t\"dial torrent client\",\n\t\t\t\t\t\t0,\n\t\t\t\t\t)\n\t\t\t\t\t// Try to avoid committing to a dial if the context is complete as it's\n\t\t\t\t\t// difficult to determine which dial errors allow us to forget the connection\n\t\t\t\t\t// tracking entry handle.\n\t\t\t\t\tif ctx.Err() != nil {\n\t\t\t\t\t\tif cte != nil {\n\t\t\t\t\t\t\tcte.Forget()\n\t\t\t\t\t\t}\n\t\t\t\t\t\tresCh <- dialResult{}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tc, err := s.dial(ctx, addr)\n\t\t\t\t\t// This is a bit optimistic, but it looks non-trivial to thread\n\t\t\t\t\t// this through the proxy code. Set it now in case we close the\n\t\t\t\t\t// connection forthwith.\n\t\t\t\t\tif tc, ok := c.(*net.TCPConn); ok {\n\t\t\t\t\t\ttc.SetLinger(0)\n\t\t\t\t\t}\n\t\t\t\t\tcountDialResult(err)\n\t\t\t\t\tdr := dialResult{c, network}\n\t\t\t\t\tif c == nil {\n\t\t\t\t\t\tif err != nil && forgettableDialError(err) {\n\t\t\t\t\t\t\tcte.Forget()\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tcte.Done()\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdr.Conn = closeWrapper{c, func() error {\n\t\t\t\t\t\t\terr := c.Close()\n\t\t\t\t\t\t\tcte.Done()\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}}\n\t\t\t\t\t}\n\t\t\t\t\tresCh <- dr\n\t\t\t\t}()\n\t\t\t}\n\t\t\treturn true\n\t\t})\n\t}()\n\tvar res dialResult\n\t// Wait for a successful connection.\n\tfunc() {\n\t\tdefer perf.ScopeTimer()()\n\t\tfor ; left > 0 && res.Conn == nil; left-- {\n\t\t\tres = <-resCh\n\t\t}\n\t}()\n\t// There are still incompleted dials.\n\tgo func() {\n\t\tfor ; left > 0; left-- {\n\t\t\tconn := (<-resCh).Conn\n\t\t\tif conn != nil {\n\t\t\t\tconn.Close()\n\t\t\t}\n\t\t}\n\t}()\n\tif res.Conn != nil {\n\t\tgo torrent.Add(fmt.Sprintf(\"network dialed first: %s\", res.Conn.RemoteAddr().Network()), 1)\n\t}\n\treturn res\n}", "label": 5}
{"code": "function init(opts) {\n    opts = opts || {};\n\n    // include pancakes instance into options that we pass to plugins\n    opts.pluginOptions = opts.pluginOptions || {};\n    opts.pluginOptions.pancakes = exports;\n\n    injector = new DependencyInjector(opts);\n    var ClientPlugin = opts.clientPlugin;\n    var ServerPlugin = opts.serverPlugin;\n\n    if (ClientPlugin) { clientPlugin = new ClientPlugin(opts); }\n    if (ServerPlugin) { serverPlugin = new ServerPlugin(opts); }\n\n    apiRouteHandler.init({ injector: injector });\n    webRouteHandler.init({ injector: injector, clientPlugin: clientPlugin, rootDir: opts.rootDir });\n}", "label": 3}
{"code": "public static base_response clear(nitro_service client, nsconfig resource) throws Exception {\n\t\tnsconfig clearresource = new nsconfig();\n\t\tclearresource.force = resource.force;\n\t\tclearresource.level = resource.level;\n\t\treturn clearresource.perform_operation(client,\"clear\");\n\t}", "label": 0}
{"code": "def role_id(name)\n      json = client.get(\"/v1/auth/approle/role/#{encode_path(name)}/role-id\")\n      return Secret.decode(json).data[:role_id]\n    rescue HTTPError => e\n      return nil if e.code == 404\n      raise\n    end", "label": 4}
{"code": "func (s *APIServer) getClusterCACert(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tlocalCA, err := auth.GetClusterCACert()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn localCA, nil\n}", "label": 5}
{"code": "def create(*args)\n      arguments(args, required: [:user, :repo]) do\n        permit VALID_REF_PARAM_NAMES\n        assert_required REQUIRED_REF_PARAMS\n      end\n      params = arguments.params\n      validate_reference params['ref']\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/git/refs\", params)\n    end", "label": 4}
{"code": "func (a *CellView) HandleEvent(e tcell.Event) bool {\n\tif a.model == nil {\n\t\treturn false\n\t}\n\tswitch e := e.(type) {\n\tcase *tcell.EventKey:\n\t\tswitch e.Key() {\n\t\tcase tcell.KeyUp, tcell.KeyCtrlP:\n\t\t\ta.keyUp()\n\t\t\treturn true\n\t\tcase tcell.KeyDown, tcell.KeyCtrlN:\n\t\t\ta.keyDown()\n\t\t\treturn true\n\t\tcase tcell.KeyRight, tcell.KeyCtrlF:\n\t\t\ta.keyRight()\n\t\t\treturn true\n\t\tcase tcell.KeyLeft, tcell.KeyCtrlB:\n\t\t\ta.keyLeft()\n\t\t\treturn true\n\t\tcase tcell.KeyPgDn:\n\t\t\ta.keyPgDn()\n\t\t\treturn true\n\t\tcase tcell.KeyPgUp:\n\t\t\ta.keyPgUp()\n\t\t\treturn true\n\t\tcase tcell.KeyEnd:\n\t\t\ta.keyEnd()\n\t\t\treturn true\n\t\tcase tcell.KeyHome:\n\t\t\ta.keyHome()\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "def generate(site)\n      @site = site\n      collections.each do |name, meta|\n        Jekyll.logger.info \"Jekyll Feed:\", \"Generating feed for #{name}\"\n        (meta[\"categories\"] + [nil]).each do |category|\n          path = feed_path(:collection => name, :category => category)\n          next if file_exists?(path)\n\n          @site.pages << make_page(path, :collection => name, :category => category)\n        end\n      end\n    end", "label": 4}
{"code": "func newApp(ra *schema.RuntimeApp, podManifest *schema.PodManifest, pod *pkgPod.Pod, appState appStateFunc) (*v1.App, error) {\n\tapp := &v1.App{\n\t\tName:            ra.Name.String(),\n\t\tImageID:         ra.Image.ID.String(),\n\t\tUserAnnotations: ra.App.UserAnnotations,\n\t\tUserLabels:      ra.App.UserLabels,\n\t}\n\n\tpodVols := podManifest.Volumes\n\tpodVolsByName := make(map[types.ACName]types.Volume, len(podVols))\n\tfor i := range podManifest.Volumes {\n\t\tpodVolsByName[podVols[i].Name] = podVols[i]\n\t}\n\n\tfor _, mnt := range ra.Mounts {\n\t\treadOnly := false\n\t\tvar hostPath string\n\t\t// AppVolume is optional\n\t\tif av := mnt.AppVolume; av != nil {\n\t\t\thostPath = av.Source\n\t\t\tif ro := av.ReadOnly; ro != nil {\n\t\t\t\treadOnly = *ro\n\t\t\t}\n\t\t} else {\n\t\t\thostPath = podVolsByName[mnt.Volume].Source\n\t\t\tif ro := podVolsByName[mnt.Volume].ReadOnly; ro != nil {\n\t\t\t\treadOnly = *ro\n\t\t\t}\n\t\t}\n\t\tapp.Mounts = append(app.Mounts, &v1.Mount{\n\t\t\tName:          mnt.Volume.String(),\n\t\t\tContainerPath: mnt.Path,\n\t\t\tHostPath:      hostPath,\n\t\t\tReadOnly:      readOnly,\n\t\t})\n\t}\n\n\t// Generate state.\n\tif err := appState(app, pod); err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting app's state: %v\", err)\n\t}\n\n\treturn app, nil\n}", "label": 5}
{"code": "public static long count(nitro_service service, String certkey) throws Exception{\n\t\tsslcertkey_crldistribution_binding obj = new sslcertkey_crldistribution_binding();\n\t\tobj.set_certkey(certkey);\n\t\toptions option = new options();\n\t\toption.set_count(true);\n\t\tsslcertkey_crldistribution_binding response[] = (sslcertkey_crldistribution_binding[]) obj.get_resources(service,option);\n\t\tif (response != null) {\n\t\t\treturn response[0].__count;\n\t\t}\n\t\treturn 0;\n\t}", "label": 0}
{"code": "public function setStatements($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->statements = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def decode(value: str) -> Union[str, None, bool, int, float]:\n    \"\"\"\n    Decode encoded credential attribute value.\n\n    :param value: numeric string to decode\n    :return: decoded value, stringified if original was neither str, bool, int, nor float\n    \"\"\"\n\n    assert value.isdigit() or value[0] == '-' and value[1:].isdigit()\n\n    if -I32_BOUND <= int(value) < I32_BOUND:  # it's an i32: it is its own encoding\n        return int(value)\n    elif int(value) == I32_BOUND:\n        return None\n\n    (prefix, value) = (int(value[0]), int(value[1:]))\n    ival = int(value) - I32_BOUND\n    if ival == 0:\n        return ''  # special case: empty string encodes as 2**31\n    elif ival == 1:\n        return False  # sentinel for bool False\n    elif ival == 2:\n        return True  # sentinel for bool True\n\n    blen = ceil(log(ival, 16)/2)\n    ibytes = unhexlify(ival.to_bytes(blen, 'big'))\n    return DECODE_PREFIX.get(prefix, str)(ibytes.decode())", "label": 1}
{"code": "def detect_link_tag_time(newer_tag)\n      # if tag is nil - set current time\n      newer_tag_time = newer_tag.nil? ? Time.new : get_time_of_tag(newer_tag)\n\n      # if it's future release tag - set this value\n      if newer_tag.nil? && options[:future_release]\n        newer_tag_name = options[:future_release]\n        newer_tag_link = options[:future_release]\n      else\n        # put unreleased label if there is no name for the tag\n        newer_tag_name = newer_tag.nil? ? options[:unreleased_label] : newer_tag[\"name\"]\n        newer_tag_link = newer_tag.nil? ? \"HEAD\" : newer_tag_name\n      end\n      [newer_tag_link, newer_tag_name, newer_tag_time]\n    end", "label": 4}
{"code": "public function proxy($event): LambdaResponse\n    {\n        if (! isset($event['httpMethod'])) {\n            throw new \\Exception('The lambda was not invoked via HTTP through API Gateway: this is not supported by this runtime');\n        }\n\n        $request = $this->eventToFastCgiRequest($event);\n\n        try {\n            $response = $this->client->sendRequest($request);\n        } catch (\\Throwable $e) {\n            throw new FastCgiCommunicationFailed(sprintf(\n                'Error communicating with PHP-FPM to read the HTTP response. A root cause of this can be that the Lambda (or PHP) timed out, for example when trying to connect to a remote API or database, if this happens continuously check for those! Original exception message: %s %s',\n                get_class($e),\n                $e->getMessage()\n            ), 0, $e);\n        }\n\n        $responseHeaders = $response->getHeaders();\n        $responseHeaders = array_change_key_case($responseHeaders, CASE_LOWER);\n\n        // Extract the status code\n        if (isset($responseHeaders['status'])) {\n            [$status] = explode(' ', $responseHeaders['status']);\n        } else {\n            $status = 200;\n        }\n        unset($responseHeaders['status']);\n\n        return new LambdaResponse((int) $status, $responseHeaders, $response->getBody());\n    }", "label": 2}
{"code": "public static vrid6_interface_binding[] get(nitro_service service, Long id) throws Exception{\n\t\tvrid6_interface_binding obj = new vrid6_interface_binding();\n\t\tobj.set_id(id);\n\t\tvrid6_interface_binding response[] = (vrid6_interface_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func DirSize(path string) (int64, error) {\n\tseenInode := make(map[uint64]struct{})\n\n\tif _, err := os.Stat(path); err == nil {\n\t\tvar sz int64\n\t\terr := filepath.Walk(path, func(path string, info os.FileInfo, err error) error {\n\t\t\tif hasHardLinks(info) {\n\t\t\t\tino := getInode(info)\n\t\t\t\tif _, ok := seenInode[ino]; !ok {\n\t\t\t\t\tseenInode[ino] = struct{}{}\n\t\t\t\t\tsz += info.Size()\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tsz += info.Size()\n\t\t\t}\n\t\t\treturn err\n\t\t})\n\t\treturn sz, err\n\t}\n\n\treturn 0, nil\n}", "label": 5}
{"code": "def find(path)\n      results = []\n      Find.find(path) do |fpath|\n        if FileTest.directory?(fpath)\n          next unless ignores\n\n          ignores.each do |ignore|\n            next unless fpath.include?(ignore.realpath.to_s)\n\n            puts \"Ignoring Directory: #{fpath}\" if options[:verbose]\n            Find.prune\n          end\n        end\n        results << fpath if yield fpath\n      end\n      results\n    end", "label": 4}
{"code": "def enable_symlink_privilege():\n\t\"\"\"\n\tTry to assign the symlink privilege to the current process token.\n\tReturn True if the assignment is successful.\n\t\"\"\"\n\t# create a space in memory for a TOKEN_PRIVILEGES structure\n\t#  with one element\n\tsize = ctypes.sizeof(privilege.TOKEN_PRIVILEGES)\n\tsize += ctypes.sizeof(privilege.LUID_AND_ATTRIBUTES)\n\tbuffer = ctypes.create_string_buffer(size)\n\ttp = ctypes.cast(buffer, ctypes.POINTER(privilege.TOKEN_PRIVILEGES)).contents\n\ttp.count = 1\n\ttp.get_array()[0].enable()\n\ttp.get_array()[0].LUID = get_symlink_luid()\n\ttoken = get_process_token()\n\tres = privilege.AdjustTokenPrivileges(token, False, tp, 0, None, None)\n\tif res == 0:\n\t\traise RuntimeError(\"Error in AdjustTokenPrivileges\")\n\n\tERROR_NOT_ALL_ASSIGNED = 1300\n\treturn ctypes.windll.kernel32.GetLastError() != ERROR_NOT_ALL_ASSIGNED", "label": 1}
{"code": "def decay(function, field, options = {})\n      field_options = options.extract!(:origin, :scale, :offset, :decay).delete_if { |_, v| v.nil? }\n      scoring = options.merge(function => {\n        field => field_options\n      })\n      chain { criteria.update_scores scoring }\n    end", "label": 4}
{"code": "function jsonCompare(arg, options) {\n    var sortOrder;\n    if (typeof arg === 'string') {\n        sortOrder = new SortOrder_1.SortOrder();\n        sortOrder.fromJSON([arg]);\n    }\n    else if (_.isArray(arg)) {\n        sortOrder = new SortOrder_1.SortOrder();\n        sortOrder.fromJSON(arg);\n    }\n    else {\n        sortOrder = arg;\n    }\n    var comparator = new SortOrderComparator(sortOrder, options);\n    return (_.bind(comparator.compare, comparator));\n}", "label": 3}
{"code": "func (c *Client) GetNodes(namespace string, opts ...services.MarshalOption) ([]services.Server, error) {\n\tif namespace == \"\" {\n\t\treturn nil, trace.BadParameter(MissingNamespaceError)\n\t}\n\tcfg, err := services.CollectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tout, err := c.Get(c.Endpoint(\"namespaces\", namespace, \"nodes\"), url.Values{\n\t\t\"skip_validation\": []string{fmt.Sprintf(\"%t\", cfg.SkipValidation)},\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tvar items []json.RawMessage\n\tif err := json.Unmarshal(out.Bytes(), &items); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tre := make([]services.Server, len(items))\n\tfor i, raw := range items {\n\t\ts, err := services.GetServerMarshaler().UnmarshalServer(\n\t\t\traw,\n\t\t\tservices.KindNode,\n\t\t\tservices.AddOptions(opts, services.SkipValidation())...)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tre[i] = s\n\t}\n\n\treturn re, nil\n}", "label": 5}
{"code": "protected synchronized void registerOpenDatabase(DatabaseImpl newDB)\r\n    {\r\n        DatabaseImpl old_db = getCurrentDatabase();\r\n        if (old_db != null)\r\n        {\r\n            try\r\n            {\r\n                if (old_db.isOpen())\r\n                {\r\n                    log.warn(\"## There is still an opened database, close old one ##\");\r\n                    old_db.close();\r\n                }\r\n            }\r\n            catch (Throwable t)\r\n            {\r\n                //ignore\r\n            }\r\n        }\r\n        if (log.isDebugEnabled()) log.debug(\"Set current database \" + newDB + \" PBKey was \" + newDB.getPBKey());\r\n        setCurrentDatabase(newDB);\r\n//        usedDatabases.add(newDB.getPBKey());\r\n    }", "label": 0}
{"code": "public function publishDiagnostics(string $uri, array $diagnostics): Promise\n    {\n        return $this->handler->notify('textDocument/publishDiagnostics', [\n            'uri' => $uri,\n            'diagnostics' => $diagnostics\n        ]);\n    }", "label": 2}
{"code": "func (d *Decoder) readUntil(sep byte) {\n\tfor {\n\t\tb := d.readByte()\n\t\tif b == sep {\n\t\t\treturn\n\t\t}\n\t\td.buf.WriteByte(b)\n\t}\n}", "label": 5}
{"code": "async def send_schema(self, schema_data_json: str) -> str:\n        \"\"\"\n        Send schema to ledger, then retrieve it as written to the ledger and return it.\n        If schema already exists on ledger, log error and return schema.\n\n        :param schema_data_json: schema data json with name, version, attribute names; e.g.,\n\n        ::\n\n            {\n                'name': 'my-schema',\n                'version': '1.234',\n                'attr_names': ['favourite_drink', 'height', 'last_visit_date']\n            }\n\n        :return: schema json as written to ledger (or existed a priori)\n        \"\"\"\n\n        LOGGER.debug('Origin.send_schema >>> schema_data_json: %s', schema_data_json)\n\n        schema_data = json.loads(schema_data_json)\n        s_key = schema_key(schema_id(self.did, schema_data['name'], schema_data['version']))\n        with SCHEMA_CACHE.lock:\n            try:\n                rv_json = await self.get_schema(s_key)\n                LOGGER.error(\n                    'Schema %s version %s already exists on ledger for origin-did %s: not sending',\n                    schema_data['name'],\n                    schema_data['version'],\n                    self.did)\n            except AbsentSchema:  # OK - about to create and send it\n                (_, schema_json) = await anoncreds.issuer_create_schema(\n                    self.did,\n                    schema_data['name'],\n                    schema_data['version'],\n                    json.dumps(schema_data['attr_names']))\n                req_json = await ledger.build_schema_request(self.did, schema_json)\n                resp_json = await self._sign_submit(req_json)\n                resp = json.loads(resp_json)\n                resp_result_txn = resp['result']['txn']\n                rv_json = await self.get_schema(schema_key(schema_id(\n                    resp_result_txn['metadata']['from'],\n                    resp_result_txn['data']['data']['name'],\n                    resp_result_txn['data']['data']['version'])))  # add to cache en passant\n\n        LOGGER.debug('Origin.send_schema <<< %s', rv_json)\n        return rv_json", "label": 1}
{"code": "def verify_default_value_matches_verify_block\n      @available_options.each do |item|\n        next unless item.verify_block && item.default_value\n\n        begin\n          unless @values[item.key] # this is important to not verify if there already is a value there\n            item.verify_block.call(item.default_value)\n          end\n        rescue => ex\n          UI.error(ex)\n          UI.user_error!(\"Invalid default value for #{item.key}, doesn't match verify_block\")\n        end\n      end\n    end", "label": 4}
{"code": "public static function elementTextMatches(WebDriverBy $by, $regexp)\n    {\n        return new static(\n            function (WebDriver $driver) use ($by, $regexp) {\n                try {\n                    return (bool) preg_match($regexp, $driver->findElement($by)->getText());\n                } catch (StaleElementReferenceException $e) {\n                    return null;\n                }\n            }\n        );\n    }", "label": 2}
{"code": "protected function encrypt(\n        Stream $plaintext,\n        array $cipherOptions,\n        MaterialsProvider $provider,\n        MetadataEnvelope $envelope\n    ) {\n        $materialsDescription = $provider->getMaterialsDescription();\n\n        $cipherOptions = array_intersect_key(\n            $cipherOptions,\n            self::$allowedOptions\n        );\n\n        if (empty($cipherOptions['Cipher'])) {\n            throw new \\InvalidArgumentException('An encryption cipher must be'\n                . ' specified in the \"cipher_options\".');\n        }\n\n        if (!self::isSupportedCipher($cipherOptions['Cipher'])) {\n            throw new \\InvalidArgumentException('The cipher requested is not'\n                . ' supported by the SDK.');\n        }\n\n        if (empty($cipherOptions['KeySize'])) {\n            $cipherOptions['KeySize'] = 256;\n        }\n        if (!is_int($cipherOptions['KeySize'])) {\n            throw new \\InvalidArgumentException('The cipher \"KeySize\" must be'\n                . ' an integer.');\n        }\n\n        if (!MaterialsProvider::isSupportedKeySize(\n            $cipherOptions['KeySize']\n        )) {\n            throw new \\InvalidArgumentException('The cipher \"KeySize\" requested'\n                . ' is not supported by AES (128, 192, or 256).');\n        }\n\n        $cipherOptions['Iv'] = $provider->generateIv(\n            $this->getCipherOpenSslName(\n                $cipherOptions['Cipher'],\n                $cipherOptions['KeySize']\n            )\n        );\n\n        $cek = $provider->generateCek($cipherOptions['KeySize']);\n\n        list($encryptingStream, $aesName) = $this->getEncryptingStream(\n            $plaintext,\n            $cek,\n            $cipherOptions\n        );\n\n        // Populate envelope data\n        $envelope[MetadataEnvelope::CONTENT_KEY_V2_HEADER] =\n            $provider->encryptCek(\n                $cek,\n                $materialsDescription\n            );\n        unset($cek);\n\n        $envelope[MetadataEnvelope::IV_HEADER] =\n            base64_encode($cipherOptions['Iv']);\n        $envelope[MetadataEnvelope::KEY_WRAP_ALGORITHM_HEADER] =\n            $provider->getWrapAlgorithmName();\n        $envelope[MetadataEnvelope::CONTENT_CRYPTO_SCHEME_HEADER] = $aesName;\n        $envelope[MetadataEnvelope::UNENCRYPTED_CONTENT_LENGTH_HEADER] =\n            strlen($plaintext);\n        $envelope[MetadataEnvelope::UNENCRYPTED_CONTENT_MD5_HEADER] =\n            base64_encode(md5($plaintext));\n        $envelope[MetadataEnvelope::MATERIALS_DESCRIPTION_HEADER] =\n            json_encode($materialsDescription);\n        if (!empty($cipherOptions['Tag'])) {\n            $envelope[MetadataEnvelope::CRYPTO_TAG_LENGTH_HEADER] =\n                strlen($cipherOptions['Tag']) * 8;\n        }\n\n        return $encryptingStream;\n    }", "label": 2}
{"code": "private function updateComposerReplacesVersion($version, array $component)\n    {\n        $composer = $this->rootPath() .'/composer.json';\n        if (!file_exists($composer)) {\n            throw new \\Exception('Invalid composer.json path');\n        }\n\n        $data = json_decode(file_get_contents($composer), true);\n\n        $data['replace'][$component['name']] = $version;\n\n        file_put_contents($composer, json_encode($data, JSON_PRETTY_PRINT|JSON_UNESCAPED_SLASHES));\n    }", "label": 2}
{"code": "def find_user(username, discrim = nil)\n      users = @users.values.find_all { |e| e.username == username }\n      return users.find { |u| u.discrim == discrim } if discrim\n\n      users\n    end", "label": 4}
{"code": "func mountFsRO(m fs.Mounter, mountPoint string, flags uintptr) error {\n\tflags = flags |\n\t\tsyscall.MS_BIND |\n\t\tsyscall.MS_REMOUNT |\n\t\tsyscall.MS_RDONLY\n\n\tif err := m.Mount(mountPoint, mountPoint, \"\", flags, \"\"); err != nil {\n\t\treturn errwrap.Wrap(fmt.Errorf(\"error remounting read-only %q\", mountPoint), err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public void checkpoint(ObjectEnvelope mod)\r\n            throws org.apache.ojb.broker.PersistenceBrokerException\r\n    {\r\n        mod.doDelete();\r\n        mod.setModificationState(StateTransient.getInstance());\r\n    }", "label": 0}
{"code": "func (a *ACL) SetFileACLDefault(path string) error {\n\tacl_set_file, err := getSymbolPointer(a.lib.handle, \"acl_set_file\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcpath := C.CString(path)\n\tdefer C.free(unsafe.Pointer(cpath))\n\n\tret, err := C.my_acl_set_file(acl_set_file, cpath, C.ACL_TYPE_DEFAULT, a.a)\n\tif ret < 0 {\n\t\treturn errwrap.Wrap(errors.New(\"error calling acl_set_file\"), err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function () {\n        var parts = new RegExp(\"(.*)\\\\.([^\\\\.]+)$\").exec(this._name),\n            NAME_PART = 2,\n            NAMESPACE_PART = 1;\n        if (parts) {\n            this._name = parts[NAME_PART];\n            return parts[NAMESPACE_PART];\n        }\n    }", "label": 3}
{"code": "public LuaScript endScriptReturn(LuaValue value, LuaScriptConfig config) {\n        add(new LuaAstReturnStatement(argument(value)));\n        String scriptText = buildScriptText();\n        return new BasicLuaScript(scriptText, config);\n    }", "label": 0}
{"code": "def add(path)\n      return true unless File.exist?(path)\n\n      metadata[path] = {\n        \"mtime\" => File.mtime(path),\n        \"deps\"  => [],\n      }\n      cache[path] = true\n    end", "label": 4}
{"code": "protected function getAttributes(Blueprint\\BlueprintInterface $blueprint)\n    {\n        return [\n            'type' => $blueprint::getType(),\n            'from_user_id' => ($fromUser = $blueprint->getFromUser()) ? $fromUser->id : null,\n            'subject_id' => ($subject = $blueprint->getSubject()) ? $subject->id : null,\n            'data' => ($data = $blueprint->getData()) ? json_encode($data) : null\n        ];\n    }", "label": 2}
{"code": "func computeAppResources(isolators types.Isolators) (appResources, error) {\n\tres := appResources{}\n\tvar err error\n\n\twithIsolator := func(name string, f func() error) error {\n\t\tok, err := cgroup.IsIsolatorSupported(name)\n\t\tif err != nil {\n\t\t\treturn errwrap.Wrapf(\"could not check for isolator \"+name, err)\n\t\t}\n\n\t\tif !ok {\n\t\t\tfmt.Fprintf(os.Stderr, \"warning: resource/%s isolator set but support disabled in the kernel, skipping\\n\", name)\n\t\t\treturn nil\n\t\t}\n\n\t\treturn f()\n\t}\n\n\tfor _, isolator := range isolators {\n\t\tif err != nil {\n\t\t\treturn res, err\n\t\t}\n\n\t\tswitch v := isolator.Value().(type) {\n\t\tcase *types.ResourceMemory:\n\t\t\terr = withIsolator(\"memory\", func() error {\n\t\t\t\tif v.Limit() == nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\tval := uint64(v.Limit().Value())\n\t\t\t\tres.MemoryLimit = &val\n\t\t\t\treturn nil\n\t\t\t})\n\t\tcase *types.ResourceCPU:\n\t\t\terr = withIsolator(\"cpu\", func() error {\n\t\t\t\tif v.Limit() == nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\tif v.Limit().Value() > MaxMilliValue {\n\t\t\t\t\treturn fmt.Errorf(\"cpu limit exceeds the maximum millivalue: %v\", v.Limit().String())\n\t\t\t\t}\n\n\t\t\t\tval := uint64(v.Limit().MilliValue() / 10)\n\t\t\t\tres.CPUQuota = &val\n\t\t\t\treturn nil\n\t\t\t})\n\t\tcase *types.LinuxCPUShares:\n\t\t\terr = withIsolator(\"cpu\", func() error {\n\t\t\t\tval := uint64(*v)\n\t\t\t\tres.LinuxCPUShares = &val\n\t\t\t\treturn nil\n\t\t\t})\n\t\tcase *types.LinuxOOMScoreAdj:\n\t\t\tval := int(*v)\n\t\t\tres.LinuxOOMScoreAdjust = &val\n\t\t}\n\t}\n\n\treturn res, err\n}", "label": 5}
{"code": "func (p *ProcessStorage) CreateState(role teleport.Role, state StateV2) error {\n\tif err := state.CheckAndSetDefaults(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tvalue, err := json.Marshal(state)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\titem := backend.Item{\n\t\tKey:   backend.Key(statesPrefix, strings.ToLower(role.String()), stateName),\n\t\tValue: value,\n\t}\n\t_, err = p.Create(context.TODO(), item)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static <E, C extends Counter<E>> Counter<E> L2NormalizeInPlace(Counter<E> c) {\r\n    return multiplyInPlace(c, 1.0 / L2Norm(c));\r\n  }", "label": 0}
{"code": "public function isPaginationable()\n    {\n        return ! is_null($this->request->input('start')) &&\n            ! is_null($this->request->input('length')) &&\n            $this->request->input('length') != -1;\n    }", "label": 2}
{"code": "function getType(value) {\n        // inspired by http://techblog.badoo.com/blog/2013/11/01/type-checking-in-javascript/\n\n        // handle null in old IE\n        if (value === null) {\n            return 'null';\n        }\n\n        // handle DOM elements\n        if (value && (value.nodeType === 1 || value.nodeType === 9)) {\n            return 'element';\n        }\n\n        var s = Object.prototype.toString.call(value);\n        var type = s.match(/\\[object (.*?)\\]/)[1].toLowerCase();\n\n        // handle NaN and Infinity\n        if (type === 'number') {\n            if (isNaN(value)) {\n                return 'nan';\n            }\n            if (!isFinite(value)) {\n                return 'infinity';\n            }\n        }\n\n        return type;\n    }", "label": 3}
{"code": "public function generate()\n    {\n        if (!$this->filesystem->exists($path = $this->getPath())) {\n            return $this->filesystem->put($path, $this->getContents());\n        }\n\n        throw new FileAlreadyExistException('File already exists!');\n    }", "label": 2}
{"code": "public static ComplexNumber Add(ComplexNumber z1, ComplexNumber z2) {\r\n        return new ComplexNumber(z1.real + z2.real, z1.imaginary + z2.imaginary);\r\n    }", "label": 0}
{"code": "def stop(service_name, timeout: DEFAULT_TIMEOUT)\n      Puppet.debug _(\"Stopping the %{service_name} service. Timeout set to: %{timeout} seconds\") % { service_name: service_name, timeout: timeout }\n\n      valid_initial_states = SERVICE_STATES.keys - [SERVICE_STOPPED]\n\n      transition_service_state(service_name, valid_initial_states, SERVICE_STOPPED, timeout) do |service|\n        send_service_control_signal(service, SERVICE_CONTROL_STOP)\n      end\n\n      Puppet.debug _(\"Successfully stopped the %{service_name} service\") % { service_name: service_name }\n    end", "label": 4}
{"code": "def pool\n      @lock.synchronize do\n        return @nhp if @nhp\n\n        @nhp = PersistentHTTP.new(\"vault-ruby\", nil, pool_size)\n\n        if proxy_address\n          proxy_uri = URI.parse \"http://#{proxy_address}\"\n\n          proxy_uri.port = proxy_port if proxy_port\n\n          if proxy_username\n            proxy_uri.user = proxy_username\n            proxy_uri.password = proxy_password\n          end\n\n          @nhp.proxy = proxy_uri\n        end\n\n        # Use a custom open timeout\n        if open_timeout || timeout\n          @nhp.open_timeout = (open_timeout || timeout).to_i\n        end\n\n        # Use a custom read timeout\n        if read_timeout || timeout\n          @nhp.read_timeout = (read_timeout || timeout).to_i\n        end\n\n        @nhp.verify_mode = OpenSSL::SSL::VERIFY_PEER\n\n        # Vault requires TLS1.2\n        @nhp.ssl_version = \"TLSv1_2\"\n\n        # Only use secure ciphers\n        @nhp.ciphers = ssl_ciphers\n\n        # Custom pem files, no problem!\n        pem = ssl_pem_contents || (ssl_pem_file ? File.read(ssl_pem_file) : nil)\n        if pem\n          @nhp.cert = OpenSSL::X509::Certificate.new(pem)\n          @nhp.key = OpenSSL::PKey::RSA.new(pem, ssl_pem_passphrase)\n        end\n\n        # Use custom CA cert for verification\n        if ssl_ca_cert\n          @nhp.ca_file = ssl_ca_cert\n        end\n\n        # Use custom CA path that contains CA certs\n        if ssl_ca_path\n          @nhp.ca_path = ssl_ca_path\n        end\n\n        if ssl_cert_store\n          @nhp.cert_store = ssl_cert_store\n        end\n\n        # Naughty, naughty, naughty! Don't blame me when someone hops in\n        # and executes a MITM attack!\n        if !ssl_verify\n          @nhp.verify_mode = OpenSSL::SSL::VERIFY_NONE\n        end\n\n        # Use custom timeout for connecting and verifying via SSL\n        if ssl_timeout || timeout\n          @nhp.ssl_timeout = (ssl_timeout || timeout).to_i\n        end\n\n        @nhp\n      end\n    end", "label": 4}
{"code": "private Database readSingleSchemaFile(DatabaseIO reader, File schemaFile)\r\n    {\r\n        Database model = null;\r\n\r\n        if (!schemaFile.isFile())\r\n        {\r\n            log(\"Path \"+schemaFile.getAbsolutePath()+\" does not denote a schema file\", Project.MSG_ERR);\r\n        }\r\n        else if (!schemaFile.canRead())\r\n        {\r\n            log(\"Could not read schema file \"+schemaFile.getAbsolutePath(), Project.MSG_ERR);\r\n        }\r\n        else\r\n        {\r\n            try\r\n            {\r\n                model = reader.read(schemaFile);\r\n                log(\"Read schema file \"+schemaFile.getAbsolutePath(), Project.MSG_INFO);\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                throw new BuildException(\"Could not read schema file \"+schemaFile.getAbsolutePath()+\": \"+ex.getLocalizedMessage(), ex);\r\n            }\r\n        }\r\n        return model;\r\n    }", "label": 0}
{"code": "function _guardPromiseAll (promises, all, callback) {\n  if (promises.length === 0) {\n    callback()\n  } else {\n    all(promises).then(() => {\n      callback()\n    })\n  }\n}", "label": 3}
{"code": "func NewStubProxy(frontendAddr, backendAddr net.Addr) (Proxy, error) {\n\treturn &StubProxy{\n\t\tfrontendAddr: frontendAddr,\n\t\tbackendAddr:  backendAddr,\n\t}, nil\n}", "label": 5}
{"code": "def set_data(self, data):\n\t\t\"Use this method to set the data for this blob\"\n\t\tif data is None:\n\t\t\tself.data_size = 0\n\t\t\tself.data = None\n\t\t\treturn\n\t\tself.data_size = len(data)\n\t\t# create a string buffer so that null bytes aren't interpreted\n\t\t#  as the end of the string\n\t\tself.data = ctypes.cast(ctypes.create_string_buffer(data), ctypes.c_void_p)", "label": 1}
{"code": "function (execOptions) {\n                var url = this._basePath + 'batch';\n                var data = JSON.stringify({methods: this._batch});\n                sendAjaxRequest(url, data, execOptions).then(\n                    this._resolvePromises.bind(this, this._batch),\n                    this._rejectPromises.bind(this, this._batch)\n                );\n\n                this._batch = [];\n            }", "label": 3}
{"code": "def result\n      if !@executed\n        with_prepared_ast {\n          Execution::Multiplex.run_queries(@schema, [self], context: @context)\n        }\n      end\n      @result ||= Query::Result.new(query: self, values: @result_values)\n    end", "label": 4}
{"code": "public PreparedStatement getUpdateStatement(ClassDescriptor cds) throws PersistenceBrokerSQLException, PersistenceBrokerException\r\n    {\r\n        try\r\n        {\r\n            return cds.getStatementsForClass(m_conMan).getUpdateStmt(m_conMan.getConnection());\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            throw new PersistenceBrokerSQLException(\"Could not build statement ask for\", e);\r\n        }\r\n        catch (LookupException e)\r\n        {\r\n            throw new PersistenceBrokerException(\"Used ConnectionManager instance could not obtain a connection\", e);\r\n        }\r\n    }", "label": 0}
{"code": "public static base_responses add(nitro_service client, nsip6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnsip6 addresources[] = new nsip6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new nsip6();\n\t\t\t\taddresources[i].ipv6address = resources[i].ipv6address;\n\t\t\t\taddresources[i].scope = resources[i].scope;\n\t\t\t\taddresources[i].type = resources[i].type;\n\t\t\t\taddresources[i].vlan = resources[i].vlan;\n\t\t\t\taddresources[i].nd = resources[i].nd;\n\t\t\t\taddresources[i].icmp = resources[i].icmp;\n\t\t\t\taddresources[i].vserver = resources[i].vserver;\n\t\t\t\taddresources[i].telnet = resources[i].telnet;\n\t\t\t\taddresources[i].ftp = resources[i].ftp;\n\t\t\t\taddresources[i].gui = resources[i].gui;\n\t\t\t\taddresources[i].ssh = resources[i].ssh;\n\t\t\t\taddresources[i].snmp = resources[i].snmp;\n\t\t\t\taddresources[i].mgmtaccess = resources[i].mgmtaccess;\n\t\t\t\taddresources[i].restrictaccess = resources[i].restrictaccess;\n\t\t\t\taddresources[i].dynamicrouting = resources[i].dynamicrouting;\n\t\t\t\taddresources[i].hostroute = resources[i].hostroute;\n\t\t\t\taddresources[i].ip6hostrtgw = resources[i].ip6hostrtgw;\n\t\t\t\taddresources[i].metric = resources[i].metric;\n\t\t\t\taddresources[i].vserverrhilevel = resources[i].vserverrhilevel;\n\t\t\t\taddresources[i].ospf6lsatype = resources[i].ospf6lsatype;\n\t\t\t\taddresources[i].ospfarea = resources[i].ospfarea;\n\t\t\t\taddresources[i].state = resources[i].state;\n\t\t\t\taddresources[i].map = resources[i].map;\n\t\t\t\taddresources[i].ownernode = resources[i].ownernode;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function _gpfArrayEnumerator (array) {\n    var pos = -1;\n    return {\n        reset: function () {\n            pos = -1;\n        },\n        moveNext: function (eventsHandler) {\n            var result;\n            ++pos;\n            result = pos < array.length;\n            if (!result && eventsHandler) {\n                _gpfEventsFire.call(this, _GPF_EVENT_END_OF_DATA, {}, eventsHandler);\n            }\n            return result;\n        },\n        current: function () {\n            return array[pos];\n        }\n    };\n}", "label": 3}
{"code": "private static function isCli()\n    {\n        if (self::$cli === null) {\n            //initial setter\n            if (php_sapi_name() == 'cli') {\n                self::$cli = true;\n            } else {\n                self::$cli = false;\n            }\n        }\n\n        return self::$cli;\n    }", "label": 2}
{"code": "func DirExists(t TestingT, path string, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.DirExists(t, path, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "label": 5}
{"code": "def show_data_file(fname):\n    \"\"\" shows a data file in CSV format - all files live in CORE folder \"\"\"\n    txt = '<H2>' + fname + '</H2>'\n    print (fname)\n    #try:\n    txt += web.read_csv_to_html_table(fname, 'Y')  # it is ok to use a table for actual table data\n    #except:\n    #\ttxt += '<H2>ERROR - cant read file</H2>'\n    #txt += web.read_csv_to_html_list(fname)  # only use this for single column lists\n    \n    txt += '</div>\\n'\n    return txt", "label": 1}
{"code": "function (dataWithContext) {\n    return _.mapValues(dataWithContext, function (scenario) {\n      return scenario.map(function (response) {\n        return response.scenario;\n      });\n    });\n  }", "label": 3}
{"code": "public void setAttributeEditable(Attribute attribute, boolean editable) {\n\t\tattribute.setEditable(editable);\n\t\tif (!(attribute instanceof LazyAttribute)) { // should not instantiate lazy attributes!\n\t\t\tif (attribute instanceof ManyToOneAttribute) {\n\t\t\t\tsetAttributeEditable(((ManyToOneAttribute) attribute).getValue(), editable);\n\t\t\t} else if (attribute instanceof OneToManyAttribute) {\n\t\t\t\tList<AssociationValue> values = ((OneToManyAttribute) attribute).getValue();\n\t\t\t\tfor (AssociationValue value : values) {\n\t\t\t\t\tsetAttributeEditable(value, editable);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "label": 0}
{"code": "public static void Forward(double[] data) {\n\n        double[] result = new double[data.length];\n        double sum;\n        double scale = Math.sqrt(2.0 / data.length);\n        for (int f = 0; f < data.length; f++) {\n            sum = 0;\n            for (int t = 0; t < data.length; t++) {\n                double cos = Math.cos(((2.0 * t + 1.0) * f * Math.PI) / (2.0 * data.length));\n                sum += data[t] * cos * alpha(f);\n            }\n            result[f] = scale * sum;\n        }\n        for (int i = 0; i < data.length; i++) {\n            data[i] = result[i];\n        }\n    }", "label": 0}
{"code": "def pending_job(job)\n      update(job_class: job.class.to_s, job_id: job.job_id, status: Hyrax::Operation::PENDING)\n    end", "label": 4}
{"code": "def []=(key, value)\n      entry = find_entry(key)\n      @dirty = true\n      if entry.nil?\n        @entries << [key, value]\n      else\n        entry[1] = value\n      end\n    end", "label": 4}
{"code": "func (p *PortBinding) Equal(o *PortBinding) bool {\n\tif p == o {\n\t\treturn true\n\t}\n\n\tif o == nil {\n\t\treturn false\n\t}\n\n\tif p.Proto != o.Proto || p.Port != o.Port ||\n\t\tp.HostPort != o.HostPort || p.HostPortEnd != o.HostPortEnd {\n\t\treturn false\n\t}\n\n\tif p.IP != nil {\n\t\tif !p.IP.Equal(o.IP) {\n\t\t\treturn false\n\t\t}\n\t} else {\n\t\tif o.IP != nil {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif p.HostIP != nil {\n\t\tif !p.HostIP.Equal(o.HostIP) {\n\t\t\treturn false\n\t\t}\n\t} else {\n\t\tif o.HostIP != nil {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "function (err, results) {\n\t\t\tif (err) {\n\t\t\t\treturn cb(err);\n\t\t\t}\n\n\t\t\t// Generate file id\n\t\t\tvar id = options.filename || utils.uid(24);\n\n\t\t\t//\n\t\t\t// Generate the headers to be send to Rackspace\n\t\t\t//\n\n\t\t\tvar headers = {};\n\t\t\t// set the content-length of transfer-encoding as appropriate\n\t\t\tif (fromFile) {\n\t\t\t\theaders['content-length'] = results.stats.size;\n\t\t\t} else {\n\t\t\t\tif (source.headers && source.headers['content-length'])\n\t\t\t\t\theaders['content-length'] = source.headers['content-length'];\n\t\t\t\telse\n\t\t\t\t\theaders['transfer-encoding'] = 'chunked';\n\t\t\t}\n\n\t\t\t// Add any additonal headers\n\t\t\tvar sKey;\n\t\t\tfor (sKey in options.headers) {\n\t\t\t\tif (options.headers.hasOwnProperty(sKey)) {\n\t\t\t\t\theaders[sKey] = options.headers[sKey];\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//\n\t\t\t// Generate the cloud request options\n\t\t\t//\n\t\t\tvar _options = {\n\t\t\t\tcontainer : results.container.name,\n\t\t\t\tremote : id,\n\t\t\t\theaders : headers,\n\t\t\t\tmetadata : options.meta,\n\t\t\t\tcontentType : type\n\t\t\t};\n\n\t\t\tvar readStream;\n\t\t\tif (fromFile)\n\t\t\t\treadStream = fs.createReadStream(source);\n\t\t\telse {\n\t\t\t\treadStream = source;\n\t\t\t\tsource.resume();\n\t\t\t\tif (source.headers) {\n\t\t\t\t\t// We want to remove any headers from the source stream so they don't clobber our own headers.\n\t\t\t\t\tdelete source.headers;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tvar writeStream = o1._client.upload(_options);\n\n\t\t\twriteStream.on('error', cb);\n\t\t\twriteStream.on('success', function (file) {\n\t\t\t\tresults.container.count++;\n\t\t\t\tcb(null, results.container.name + '/' + id);\n\t\t\t});\n\n\t\t\treadStream.pipe(writeStream);\n\t\t}", "label": 3}
{"code": "func (dal *DjangoAdminLog) Save(db XODB) error {\n\tif dal.Exists() {\n\t\treturn dal.Update(db)\n\t}\n\n\treturn dal.Insert(db)\n}", "label": 5}
{"code": "public Set<String> rangeByLex(final LexRange lexRange) {\n        return doWithJedis(new JedisCallable<Set<String>>() {\n            @Override\n            public Set<String> call(Jedis jedis) {\n                if (lexRange.hasLimit()) {\n                    return jedis.zrangeByLex(getKey(), lexRange.from(), lexRange.to(), lexRange.offset(), lexRange.count());\n                } else {\n                    return jedis.zrangeByLex(getKey(), lexRange.from(), lexRange.to());\n                }\n            }\n        });\n    }", "label": 0}
{"code": "func NewTerminal(ctx *ServerContext) (Terminal, error) {\n\t// It doesn't matter what mode the cluster is in, if this is a Teleport node\n\t// return a local terminal.\n\tif ctx.srv.Component() == teleport.ComponentNode {\n\t\treturn newLocalTerminal(ctx)\n\t}\n\n\t// If this is not a Teleport node, find out what mode the cluster is in and\n\t// return the correct terminal.\n\tif ctx.ClusterConfig.GetSessionRecording() == services.RecordAtProxy {\n\t\treturn newRemoteTerminal(ctx)\n\t}\n\treturn newLocalTerminal(ctx)\n}", "label": 5}
{"code": "def indent_line\n      result = false\n      level = calculate_indentation\n      return result if level.nil?\n      @buffer.save_excursion do\n        @buffer.beginning_of_line\n        @buffer.composite_edit do\n          if @buffer.looking_at?(/[ \\t]+/)\n            s = @buffer.match_string(0)\n            break if /\\t/ !~ s && s.size == level\n            @buffer.delete_region(@buffer.match_beginning(0),\n                                  @buffer.match_end(0))\n          else\n            break if level == 0\n          end\n          @buffer.indent_to(level)\n        end\n        result = true\n      end\n      pos = @buffer.point\n      @buffer.beginning_of_line\n      @buffer.forward_char while /[ \\t]/ =~ @buffer.char_after\n      if @buffer.point < pos\n        @buffer.goto_char(pos)\n      end\n      result\n    end", "label": 4}
{"code": "function () {\n\n\tvar currTime = new Date();\n\tvar overtime = (SR.Settings.INTERVAL_STAT_REPORT * 2);\n\n\t// remove servers no longer reporting\n\tfor (var serverID in SR.Report.servers) {\n\t\tvar stat = SR.Report.servers[serverID];\n\t\t\n\t\tif (!stat || !stat.reportedTime)\n\t\t\tcontinue;\n\t\t\n\t\t// server considered dead\n\t\tif (currTime - stat.reportedTime > overtime) {\n\t\t\tvar ip_port = stat.server.IP + ':' + stat.server.port;\n\t\t\tLOG.sys(ip_port + ' overtime: ' + overtime + ' last: ' + stat.reportedTime);\n\n\t\t\tLOG.error('server: ' + ip_port + ' (' + stat.server.type + ') not responding after ' + overtime + ' ms, mark dead...', 'SR.Monitor');\n\t\t\tSR.Report.removeStat(serverID);\n\t\t\t\n\t\t\t// recycle port if it's from a local server\n\t\t\tif (stat.server.IP === SR.Settings.SERVER_INFO.IP) {\n\t\t\t\tLOG.warn('server is a local server, re-cycle its ports...', 'SR.Monitor');\n\t\t\t\tl_recyclePort(stat.ports);\n\t\t\t}\n\t\t}\n\t}\n}", "label": 3}
{"code": "public Tokenizer<Tree> getTokenizer(final Reader r) {\r\n    return new AbstractTokenizer<Tree>() {\r\n      TreeReader tr = trf.newTreeReader(r);\r\n      @Override\r\n      public Tree getNext() {\r\n        try {\r\n          return tr.readTree();\r\n        }\r\n        catch(IOException e) {\r\n          System.err.println(\"Error in reading tree.\");\r\n          return null;\r\n        }\r\n      }\r\n    };\r\n  }", "label": 0}
{"code": "public static dnssrvrec[] get(nitro_service service, dnssrvrec obj[]) throws Exception{\n\t\tif (obj != null && obj.length > 0) {\n\t\t\tdnssrvrec response[] = new dnssrvrec[obj.length];\n\t\t\tfor (int i=0;i<obj.length;i++) {\n\t\t\t\toptions option = new options();\n\t\t\t\toption.set_args(nitro_util.object_to_string_withoutquotes(obj[i]));\n\t\t\t\tresponse[i] = (dnssrvrec) obj[i].get_resource(service,option);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "func (nm DatastoreNamespaceManager) CreateDirectory(ctx context.Context, ds *Datastore, displayName string, policy string) (string, error) {\n\n\treq := &types.CreateDirectory{\n\t\tThis:        nm.Reference(),\n\t\tDatastore:   ds.Reference(),\n\t\tDisplayName: displayName,\n\t\tPolicy:      policy,\n\t}\n\n\tresp, err := methods.CreateDirectory(ctx, nm.c, req)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn resp.Returnval, nil\n}", "label": 5}
{"code": "def validate_target(target)\n      error_message = \"You can't specify target (#{target}) as alias because it is real action name\"\n      raise Error, error_message if aliased_actions.values.flatten.include? target\n    end", "label": 4}
{"code": "function off(eventsInput, callback)\n  {\n    // Remove ALL listeners\n    if ( !isDefined( eventsInput ) )\n    {\n      deleteProperty( this, '$$on' );\n    }\n    else\n    {\n      var events = toArray( eventsInput, ' ' );\n\n      // Remove listeners for given events\n      if ( !isFunction( callback ) )\n      {\n        for (var i = 0; i < events.length; i++)\n        {\n          deleteProperty( this.$$on, events[i] );\n        }\n      }\n      // Remove specific listener\n      else\n      {\n        for (var i = 0; i < events.length; i++)\n        {\n          offListeners( this.$$on, events[i], callback );\n        }\n      }\n    }\n\n    return this;\n  }", "label": 3}
{"code": "def load(cls, filename, format=None):\n        \"\"\" Return an instance of the class that is saved in the file with the\n            given filename in the specified format.\n        \"\"\"\n        if format is None:\n            # try to derive protocol from file extension\n            format = format_from_extension(filename)\n        with file(filename, 'rbU') as fp:\n            obj = cls.load_from_file_object(fp, format)\n            obj.filename = filename\n            return obj", "label": 1}
{"code": "public static base_response unset(nitro_service client, dnssrvrec resource, String[] args) throws Exception{\n\t\tdnssrvrec unsetresource = new dnssrvrec();\n\t\tunsetresource.domain = resource.domain;\n\t\tunsetresource.target = resource.target;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function upToSourceRow (target) {\n        var current = target;\n        while (current && (!current.tagName || current.tagName.toLowerCase() !== \"tr\")) {\n            current = current.parentNode;\n        }\n        return current;\n    }", "label": 3}
{"code": "def getLogger(cls, name=None):\n        \"\"\"\n        Retrieves the Python native logger\n\n        :param name:    The name of the logger instance in the VSG namespace (VSG.<name>); a None value will use the VSG root.\n        :return:        The instacne of the Python logger object.\n        \"\"\"\n        return logging.getLogger(\"{0}.{1}\".format(cls.BASENAME, name) if name else cls.BASENAME)", "label": 1}
{"code": "def post_json(self, url, data, cls=None, **kwargs):\n        \"\"\"\n        POST data to the api-server\n\n        :param url: resource location (eg: \"/type/uuid\")\n        :type url: str\n        :param cls: JSONEncoder class\n        :type cls: JSONEncoder\n        \"\"\"\n        kwargs['data'] = to_json(data, cls=cls)\n        kwargs['headers'] = self.default_headers\n        return self.post(url, **kwargs).json()", "label": 1}
{"code": "private void CalculateMap(IntRange inRange, IntRange outRange, int[] map) {\r\n        double k = 0, b = 0;\r\n\r\n        if (inRange.getMax() != inRange.getMin()) {\r\n            k = (double) (outRange.getMax() - outRange.getMin()) / (double) (inRange.getMax() - inRange.getMin());\r\n            b = (double) (outRange.getMin()) - k * inRange.getMin();\r\n        }\r\n\r\n        for (int i = 0; i < 256; i++) {\r\n            int v = (int) i;\r\n\r\n            if (v >= inRange.getMax())\r\n                v = outRange.getMax();\r\n            else if (v <= inRange.getMin())\r\n                v = outRange.getMin();\r\n            else\r\n                v = (int) (k * v + b);\r\n\r\n            map[i] = v;\r\n        }\r\n    }", "label": 0}
{"code": "def run_itx_resistance_assessment(job, rsem_files, univ_options, reports_options):\n    \"\"\"\n    A wrapper for assess_itx_resistance.\n\n    :param dict rsem_files: Results from running rsem\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict reports_options: Options specific to reporting modules\n    :return: The results of running assess_itx_resistance\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    return job.addChildJobFn(assess_itx_resistance, rsem_files['rsem.genes.results'],\n                             univ_options, reports_options).rv()", "label": 1}
{"code": "public static String makeHTMLTable(String[][] table, String[] rowLabels, String[] colLabels) {\r\n    StringBuilder buff = new StringBuilder();\r\n    buff.append(\"<table class=\\\"auto\\\" border=\\\"1\\\" cellspacing=\\\"0\\\">\\n\");\r\n    // top row\r\n    buff.append(\"<tr>\\n\");\r\n    buff.append(\"<td></td>\\n\"); // the top left cell\r\n    for (int j = 0; j < table[0].length; j++) { // assume table is a rectangular matrix\r\n      buff.append(\"<td class=\\\"label\\\">\").append(colLabels[j]).append(\"</td>\\n\");\r\n    }\r\n    buff.append(\"</tr>\\n\");\r\n    // all other rows\r\n    for (int i = 0; i < table.length; i++) {\r\n      // one row\r\n      buff.append(\"<tr>\\n\");\r\n      buff.append(\"<td class=\\\"label\\\">\").append(rowLabels[i]).append(\"</td>\\n\");\r\n      for (int j = 0; j < table[i].length; j++) {\r\n        buff.append(\"<td class=\\\"data\\\">\");\r\n        buff.append(((table[i][j] != null) ? table[i][j] : \"\"));\r\n        buff.append(\"</td>\\n\");\r\n      }\r\n      buff.append(\"</tr>\\n\");\r\n    }\r\n    buff.append(\"</table>\");\r\n    return buff.toString();\r\n  }", "label": 0}
{"code": "public void delete(Object element, boolean testForEquality) {\r\n\tint index = indexOfFromTo(element, 0, size-1, testForEquality);\r\n\tif (index>=0) removeFromTo(index,index);\r\n}", "label": 0}
{"code": "function mark(markName) {\n            if (enabled) {\n                marks[markName] = ts.timestamp();\n                counts[markName] = (counts[markName] || 0) + 1;\n                profilerEvent(markName);\n            }\n        }", "label": 3}
{"code": "def login(user = nil, password = nil)\n      if user.to_s.empty? || password.to_s.empty?\n        require 'credentials_manager/account_manager'\n\n        puts(\"Reading keychain entry, because either user or password were empty\") if Spaceship::Globals.verbose?\n\n        keychain_entry = CredentialsManager::AccountManager.new(user: user, password: password)\n        user ||= keychain_entry.user\n        password = keychain_entry.password\n      end\n\n      if user.to_s.strip.empty? || password.to_s.strip.empty?\n        raise NoUserCredentialsError.new, \"No login data provided\"\n      end\n\n      self.user = user\n      @password = password\n      begin\n        do_login(user, password) # calls `send_login_request` in sub class (which then will redirect back here to `send_shared_login_request`, below)\n      rescue InvalidUserCredentialsError => ex\n        raise ex unless keychain_entry\n\n        if keychain_entry.invalid_credentials\n          login(user)\n        else\n          raise ex\n        end\n      end\n    end", "label": 4}
{"code": "private function show_single_field( $items, $field ) {\n\t\t$key    = null;\n\t\t$values = array();\n\n\t\tforeach ( $items as $item ) {\n\t\t\t$item = (object) $item;\n\n\t\t\tif ( null === $key ) {\n\t\t\t\t$key = $this->find_item_key( $item, $field );\n\t\t\t}\n\n\t\t\tif ( 'json' === $this->args['format'] ) {\n\t\t\t\t$values[] = $item->$key;\n\t\t\t} else {\n\t\t\t\t\\WP_CLI::print_value(\n\t\t\t\t\t$item->$key,\n\t\t\t\t\tarray(\n\t\t\t\t\t\t'format' => $this->args['format'],\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\n\t\tif ( 'json' === $this->args['format'] ) {\n\t\t\techo json_encode( $values );\n\t\t}\n\t}", "label": 2}
{"code": "func (a *AuthWithRoles) GetClusterName(opts ...services.MarshalOption) (services.ClusterName, error) {\n\tif err := a.action(defaults.Namespace, services.KindClusterName, services.VerbRead); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn a.authServer.GetClusterName()\n}", "label": 5}
{"code": "protected void setOffsetAndLength(long offset, int length) throws IOException {\r\n\t\tthis.offset = offset;\r\n\t\tthis.length = length;\r\n\t\tthis.position = 0;\r\n\r\n\t\tif (subStream.position() != offset) {\r\n\t\t\tsubStream.seek(offset);\r\n\t\t}\r\n\t}", "label": 0}
{"code": "public void doLocalClear()\r\n    {\r\n        if(log.isDebugEnabled()) log.debug(\"Clear materialization cache\");\r\n        invokeCounter = 0;\r\n        enabledReadCache = false;\r\n        objectBuffer.clear();\r\n    }", "label": 0}
{"code": "public function setState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferState::class);\n        $this->state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (nDB *NetworkDB) Watch(tname, nid, key string) (*events.Channel, func()) {\n\tvar matcher events.Matcher\n\n\tif tname != \"\" || nid != \"\" || key != \"\" {\n\t\tmatcher = events.MatcherFunc(func(ev events.Event) bool {\n\t\t\tvar evt event\n\t\t\tswitch ev := ev.(type) {\n\t\t\tcase CreateEvent:\n\t\t\t\tevt = event(ev)\n\t\t\tcase UpdateEvent:\n\t\t\t\tevt = event(ev)\n\t\t\tcase DeleteEvent:\n\t\t\t\tevt = event(ev)\n\t\t\t}\n\n\t\t\tif tname != \"\" && evt.Table != tname {\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\tif nid != \"\" && evt.NetworkID != nid {\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\tif key != \"\" && evt.Key != key {\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\treturn true\n\t\t})\n\t}\n\n\tch := events.NewChannel(0)\n\tsink := events.Sink(events.NewQueue(ch))\n\n\tif matcher != nil {\n\t\tsink = events.NewFilter(sink, matcher)\n\t}\n\n\tnDB.broadcaster.Add(sink)\n\treturn ch, func() {\n\t\tnDB.broadcaster.Remove(sink)\n\t\tch.Close()\n\t\tsink.Close()\n\t}\n}", "label": 5}
{"code": "def search_results_with_work_count(access, join_field: \"isPartOf_ssim\")\n      admin_sets = search_results(access)\n      ids = admin_sets.map(&:id).join(',')\n      query = \"{!terms f=#{join_field}}#{ids}\"\n      results = ActiveFedora::SolrService.instance.conn.get(\n        ActiveFedora::SolrService.select_path,\n        params: { fq: query,\n                  rows: 0,\n                  'facet.field' => join_field }\n      )\n      counts = results['facet_counts']['facet_fields'][join_field].each_slice(2).to_h\n      file_counts = count_files(admin_sets)\n      admin_sets.map do |admin_set|\n        SearchResultForWorkCount.new(admin_set, counts[admin_set.id].to_i, file_counts[admin_set.id].to_i)\n      end\n    end", "label": 4}
{"code": "private String[] getFksToThisClass()\r\n    {\r\n        String indTable = getCollectionDescriptor().getIndirectionTable();\r\n        String[] fks = getCollectionDescriptor().getFksToThisClass();\r\n        String[] result = new String[fks.length];\r\n\r\n        for (int i = 0; i < result.length; i++)\r\n        {\r\n            result[i] = indTable + \".\" + fks[i];\r\n        }\r\n\r\n        return result;\r\n    }", "label": 0}
{"code": "def h1(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier,'h1_for', &block)\n      define_method(name) do\n        return platform.h1_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "protected function write_heartbeat()\n    {\n        $pkt = new AMQPWriter();\n        $pkt->write_octet(8);\n        $pkt->write_short(0);\n        $pkt->write_long(0);\n        $pkt->write_octet(0xCE);\n        $this->write($pkt->getvalue());\n    }", "label": 2}
{"code": "def new_image(cols, rows, *fill, &info_blk)\n      self << Magick::Image.new(cols, rows, *fill, &info_blk)\n    end", "label": 4}
{"code": "private function enqueueTransforms($document, array $transforms, array $options = [])\n    {\n        $operations = [];\n\n        foreach ($transforms as $transform) {\n            if (!($transform instanceof DocumentTransformInterface)) {\n                continue;\n            }\n\n            $args = $transform->args();\n            if (!$transform->sendRaw()) {\n                if (is_array($args) && !$this->isAssoc($args)) {\n                    $args = $this->valueMapper->encodeArrayValue($args);\n                } else {\n                    $args = $this->valueMapper->encodeValue($args);\n                }\n            }\n\n            $operations[] = [\n                'fieldPath' => $transform->fieldPath()->pathString(),\n                $transform->key() => $args\n            ];\n        }\n\n        if ($operations) {\n            $this->writes[] = $this->createDatabaseWrite(self::TYPE_TRANSFORM, $document, [\n                'fieldTransforms' => $operations\n            ] + $options);\n        }\n    }", "label": 2}
{"code": "function facebookReq(req, res){\n    var redirectUrl = _.has(grasshopper.config.identities, 'facebook') ? grasshopper.config.identities.facebook.redirectUrl : 'defaultRoute';\n\n    BB.bind({token: req.session.token, params: req.query, res: res, req: req, user: null })\n        .then(function(){\n            if(!_.isUndefined(this.token)){\n                this.token = new Buffer(this.token, 'base64'); //A token exists, let's decode it\n\n                return _linkSocialAccount.call(this);\n            }\n            else {\n                return _createSocialAccount.call(this);\n            }\n        })\n        .then(function(){\n            res.redirect(redirectUrl);\n        })\n        .catch(function(err){\n            console.log(err.stack);\n            res.redirect(redirectUrl + '?error='+ err.message);\n        });\n}", "label": 3}
{"code": "def attribute_value(attribute_name)\n      attribute_name = attribute_name.to_s.tr('_', '-') if attribute_name.is_a?(::Symbol)\n      element_call { @element.attribute attribute_name }\n    end", "label": 4}
{"code": "private void unregisterAllServlets() {\n\n        for (String endpoint : registeredServlets) {\n            registeredServlets.remove(endpoint);\n            web.unregister(endpoint);\n            LOG.info(\"endpoint {} unregistered\", endpoint);\n        }\n\n    }", "label": 0}
{"code": "public static gslbsite[] get(nitro_service service, options option) throws Exception{\n\t\tgslbsite obj = new gslbsite();\n\t\tgslbsite[] response = (gslbsite[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def sync_with(name, syncer_id = nil, &block)\n      @syncers << get_class_from_scope(Syncer, name).new(syncer_id, &block)\n    end", "label": 4}
{"code": "function abstractWeightedDegree(name, assign, edgeGetter, graph, options) {\n  if (!isGraph(graph))\n    throw new Error('graphology-metrics/' + name + ': the given graph is not a valid graphology instance.');\n\n  if (edgeGetter !== 'edges' && graph.type === 'undirected')\n    throw new Error('graphology-metrics/' + name + ': cannot compute ' + name + ' on an undirected graph.');\n\n  var singleNode = null;\n\n  // Solving arguments\n  if (arguments.length === 5 && typeof arguments[4] !== 'object') {\n    singleNode = arguments[4];\n  }\n  else if (arguments.length === 6) {\n    singleNode = arguments[4];\n    options = arguments[5];\n  }\n\n  // Solving options\n  options = options || {};\n\n  var attributes = options.attributes || {};\n\n  var weightAttribute = attributes.weight || DEFAULT_WEIGHT_ATTRIBUTE,\n      weightedDegreeAttribute = attributes.weightedDegree || name;\n\n  var edges,\n      d,\n      w,\n      i,\n      l;\n\n  // Computing weighted degree for a single node\n  if (singleNode) {\n    edges = graph[edgeGetter](singleNode);\n    d = 0;\n\n    for (i = 0, l = edges.length; i < l; i++) {\n      w = graph.getEdgeAttribute(edges[i], weightAttribute);\n\n      if (typeof w === 'number')\n        d += w;\n    }\n\n    if (assign) {\n      graph.setNodeAttribute(singleNode, weightedDegreeAttribute, d);\n      return;\n    }\n    else {\n      return d;\n    }\n  }\n\n  // Computing weighted degree for every node\n  // TODO: it might be more performant to iterate on the edges here.\n  var nodes = graph.nodes(),\n      node,\n      weightedDegrees = {},\n      j,\n      m;\n\n  for (i = 0, l = nodes.length; i < l; i++) {\n    node = nodes[i];\n    edges = graph[edgeGetter](node);\n    d = 0;\n\n    for (j = 0, m = edges.length; j < m; j++) {\n      w = graph.getEdgeAttribute(edges[j], weightAttribute);\n\n      if (typeof w === 'number')\n        d += w;\n    }\n\n    if (assign)\n      graph.setNodeAttribute(node, weightedDegreeAttribute, d);\n    else\n      weightedDegrees[node] = d;\n  }\n\n  if (!assign)\n    return weightedDegrees;\n}", "label": 3}
{"code": "func (sb *sandbox) rebuildDNS() error {\n\tcurrRC, err := resolvconf.GetSpecific(sb.config.resolvConfPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(sb.extDNS) == 0 {\n\t\tsb.setExternalResolvers(currRC.Content, types.IPv4, false)\n\t}\n\tvar (\n\t\tdnsList        = []string{sb.resolver.NameServer()}\n\t\tdnsOptionsList = resolvconf.GetOptions(currRC.Content)\n\t\tdnsSearchList  = resolvconf.GetSearchDomains(currRC.Content)\n\t)\n\n\t// external v6 DNS servers has to be listed in resolv.conf\n\tdnsList = append(dnsList, resolvconf.GetNameservers(currRC.Content, types.IPv6)...)\n\n\t// If the user config and embedded DNS server both have ndots option set,\n\t// remember the user's config so that unqualified names not in the docker\n\t// domain can be dropped.\n\tresOptions := sb.resolver.ResolverOptions()\n\ndnsOpt:\n\tfor _, resOpt := range resOptions {\n\t\tif strings.Contains(resOpt, \"ndots\") {\n\t\t\tfor _, option := range dnsOptionsList {\n\t\t\t\tif strings.Contains(option, \"ndots\") {\n\t\t\t\t\tparts := strings.Split(option, \":\")\n\t\t\t\t\tif len(parts) != 2 {\n\t\t\t\t\t\treturn fmt.Errorf(\"invalid ndots option %v\", option)\n\t\t\t\t\t}\n\t\t\t\t\tif num, err := strconv.Atoi(parts[1]); err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"invalid number for ndots option: %v\", parts[1])\n\t\t\t\t\t} else if num >= 0 {\n\t\t\t\t\t\t// if the user sets ndots, use the user setting\n\t\t\t\t\t\tsb.ndotsSet = true\n\t\t\t\t\t\tbreak dnsOpt\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn fmt.Errorf(\"invalid number for ndots option: %v\", num)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif !sb.ndotsSet {\n\t\t// if the user did not set the ndots, set it to 0 to prioritize the service name resolution\n\t\t// Ref: https://linux.die.net/man/5/resolv.conf\n\t\tdnsOptionsList = append(dnsOptionsList, resOptions...)\n\t}\n\n\t_, err = resolvconf.Build(sb.config.resolvConfPath, dnsList, dnsSearchList, dnsOptionsList)\n\treturn err\n}", "label": 5}
{"code": "public static transformpolicy[] get(nitro_service service) throws Exception{\n\t\ttransformpolicy obj = new transformpolicy();\n\t\ttransformpolicy[] response = (transformpolicy[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def rev_c(read):\n    \"\"\"\n    return reverse completment of read\n    \"\"\"\n    rc = []\n    rc_nucs = {'A':'T', 'T':'A', 'G':'C', 'C':'G', 'N':'N'}\n    for base in read:\n        rc.extend(rc_nucs[base.upper()])\n    return rc[::-1]", "label": 1}
{"code": "public void createLinks(ServiceReference<S> declarationBinderRef) {\n        for (D declaration : linkerManagement.getMatchedDeclaration()) {\n            if (linkerManagement.canBeLinked(declaration, declarationBinderRef)) {\n                linkerManagement.link(declaration, declarationBinderRef);\n            }\n        }\n    }", "label": 0}
{"code": "function buildCollection(collectionObj, options) {\n  const items = buildPatterns(collectionObj, options);\n  const pseudoFile = { path: collectionPath(items) };\n  return readFiles(collectionGlob(items), options).then(collData => {\n    const collectionMeta = collData.length ? collData[0].contents : {};\n    collectionObj.collection = Object.assign(\n      {\n        name: titleCase(collectionKey(items)),\n        resourceType: options.keys.collections.singular,\n        id: resourceId(\n          pseudoFile,\n          options.src.patterns.basedir,\n          options.keys.collections.plural\n        )\n      },\n      collectionMeta\n    );\n    checkNamespaceCollision(\n      ['items', 'patterns'],\n      collectionObj.collection,\n      `Collection ${collectionObj.collection.name}`,\n      options\n    );\n    collectionObj.collection.items = items;\n    collectionObj.collection.patterns = buildOrderedPatterns(\n      collectionObj.collection\n    );\n    return collectionObj;\n  });\n}", "label": 3}
{"code": "def _connect_func(builder, obj, signal_name, handler_name,\n                  connect_object, flags, cls):\n    '''Handles GtkBuilder signal connect events'''\n\n    if connect_object is None:\n        extra = ()\n    else:\n        extra = (connect_object,)\n\n    # The handler name refers to an attribute on the template instance,\n    # so ask GtkBuilder for the template instance\n    template_inst = builder.get_object(cls.__gtype_name__)\n\n    if template_inst is None:  # This should never happen\n        errmsg = \"Internal error: cannot find template instance! obj: %s; \" \\\n                 \"signal: %s; handler: %s; connect_obj: %s; class: %s\" % \\\n                 (obj, signal_name, handler_name, connect_object, cls)\n        warnings.warn(errmsg, GtkTemplateWarning)\n        return\n\n    handler = getattr(template_inst, handler_name)\n\n    if flags == GObject.ConnectFlags.AFTER:\n        obj.connect_after(signal_name, handler, *extra)\n    else:\n        obj.connect(signal_name, handler, *extra)\n\n    template_inst.__connected_template_signals__.add(handler_name)", "label": 1}
{"code": "func asInt(param string) int64 {\n\n\ti, err := strconv.ParseInt(param, 0, 64)\n\tpanicIf(err)\n\n\treturn i\n}", "label": 5}
{"code": "func AuthorizedKeyFingerprint(publicKey []byte) (string, error) {\n\tkey, _, _, _, err := ssh.ParseAuthorizedKey(publicKey)\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\treturn Fingerprint(key), nil\n}", "label": 5}
{"code": "def find_candidates(word_string):\n    '''\n    Finds all potential words word_string could have intended to mean. If a word is not incorrectly\n    spelled, it will return this word first, else if will look for one letter edits that are correct.\n    If there are no valid one letter edits, it will perform a two letter edit search.\n\n    If valid corrections are found, all are returned as a set instance. Should a valid word not be\n    found, the original word is returned as a set instance.\n    '''\n    if word_string is None:\n        return {}\n    elif isinstance(word_string, str):\n        return (validate_words([word_string]) or validate_words(list(find_one_letter_edits(word_string)))\n                or validate_words(list(find_two_letter_edits(word_string))) or set([word_string]))\n    else:\n        raise InputError(\"string or none type variable not passed as argument to find_candidates\")", "label": 1}
{"code": "function (account, data, conn) {\n\n\t//if (l_logins.hasOwnProperty(account) === true)\n\t\t//return false;\n\t\n\t// check if user's unique data exists\n\tif (typeof data.data !== 'object') {\n\t\tLOG.error('data field does not exist, cannot add login data');\n\t\treturn false;\n\t}\n\t\n\tLOG.warn('account: ' + account + ' data:', 'addLogin');\n\tLOG.warn(data);\n\t\n\t// attach login name to connection\n\t// NOTE: we attach connection object to the data stored in memory (not clean?)\n\tif (conn) {\n\t\t// NOTE: we use session because this request could come from an HTTP request\n\t\t// that does not have a persistent connectino record in SR.Conn\n\t\tSR.Conn.setSessionName(conn, account);\n\t\tdata._conn = conn;\n\t}\n\t\n\tl_logins[account] = data;\n\tLOG.warn('user [' + account + '] login success, total count: ' + Object.keys(l_logins).length, 'user');\n\n\tdelete data._conn;\n\t//console.log(data);\n\t\n\t// error check: make sure lastStatus field exists\n\tif (data.hasOwnProperty('lastStatus') === false || data.lastStatus === null) \n\t\tdata.lastStatus = {loginCount: 0};\n\t\n\tdata.lastStatus.loginIP = conn.host;\n\tdata.lastStatus.loginCount = data.lastStatus.loginCount + 1;\n\tdata.lastStatus.time = conn.time;\n\n\tSR.DB.updateData(SR.Settings.DB_NAME_ACCOUNT, {account: account}, data,\n\t\t\t\t\t \tfunction () {\n\t\t\t\t\t \t},\n\t\t\t\t\t \tfunction () {\n\t\t\t\t\t \t});\t\n\n\treturn true;\n}", "label": 3}
{"code": "def selected?(str_or_rx)\n      found = frame.radio(label: str_or_rx)\n      return found.selected? if found.exist?\n\n      raise UnknownObjectException, \"Unable to locate radio matching #{str_or_rx.inspect}\"\n    end", "label": 4}
{"code": "function endNode() {\n            if (parent.children) {\n                mergeChildren(parent.children);\n                sortChildren(parent.children);\n            }\n            parent = parentsStack.pop();\n        }", "label": 3}
{"code": "public MIMEType addParameter(String name, String value) {\n        Map<String, String> copy = new LinkedHashMap<>(this.parameters);\n        copy.put(name, value);\n        return new MIMEType(type, subType, copy);\n    }", "label": 0}
{"code": "public function formatEloquentModel($model)\n    {\n        $key = Str::singular($model->getTable());\n\n        if (! $model::$snakeAttributes) {\n            $key = Str::camel($key);\n        }\n\n        return $this->encode([$key => $model->toArray()]);\n    }", "label": 2}
{"code": "public static onlinkipv6prefix[] get(nitro_service service) throws Exception{\n\t\tonlinkipv6prefix obj = new onlinkipv6prefix();\n\t\tonlinkipv6prefix[] response = (onlinkipv6prefix[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func PSpecify(text string, is ...interface{}) bool {\n\tglobalSuite.PushItNode(text, func() {}, types.FlagTypePending, codelocation.New(1), 0)\n\treturn true\n}", "label": 5}
{"code": "public static sslfips get(nitro_service service) throws Exception{\n\t\tsslfips obj = new sslfips();\n\t\tsslfips[] response = (sslfips[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def rai_from_raw(self, amount):\n        \"\"\"\n        Divide a raw amount down by the rai ratio.\n\n        :param amount: Amount in raw to convert to rai\n        :type amount: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.rai_from_raw(amount=1000000000000000000000000)\n        1\n\n        \"\"\"\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('rai_from_raw', payload)\n\n        return int(resp['amount'])", "label": 1}
{"code": "public static vpnglobal_staserver_binding[] get(nitro_service service) throws Exception{\n\t\tvpnglobal_staserver_binding obj = new vpnglobal_staserver_binding();\n\t\tvpnglobal_staserver_binding response[] = (vpnglobal_staserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def error(cls, name, message, *args):\n        \"\"\"\n        Convenience function to log a message at the ERROR level.\n\n        :param name:    The name of the logger instance in the VSG namespace (VSG.<name>)\n        :param message: A message format string.\n        :param args:    The arguments that are are merged into msg using the string formatting operator.\n        :..note:        The native logger's `kwargs` are not used in this function.\n        \"\"\"\n        cls.getLogger(name).error(message, *args)", "label": 1}
{"code": "public static base_responses update(nitro_service client, inat resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tinat updateresources[] = new inat[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new inat();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].privateip = resources[i].privateip;\n\t\t\t\tupdateresources[i].tcpproxy = resources[i].tcpproxy;\n\t\t\t\tupdateresources[i].ftp = resources[i].ftp;\n\t\t\t\tupdateresources[i].tftp = resources[i].tftp;\n\t\t\t\tupdateresources[i].usip = resources[i].usip;\n\t\t\t\tupdateresources[i].usnip = resources[i].usnip;\n\t\t\t\tupdateresources[i].proxyip = resources[i].proxyip;\n\t\t\t\tupdateresources[i].mode = resources[i].mode;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def compile_inline(str)\n      op, arg = /\\A@<(\\w+)>\\{(.*?)\\}\\z/.match(str).captures\n      unless inline_defined?(op)\n        raise CompileError, \"no such inline op: #{op}\"\n      end\n      unless @strategy.respond_to?(\"inline_#{op}\")\n        raise \"strategy does not support inline op: @<#{op}>\"\n      end\n      @strategy.__send__(\"inline_#{op}\", arg)\n    rescue => e\n      error e.message\n      @strategy.nofunc_text(str)\n    end", "label": 4}
{"code": "def iTable2GFF(iTable, fa, contig = False):\n    \"\"\"\n    convert iTable to gff file\n    \"\"\"\n    columns = ['#seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute']\n    gff = {c:[] for c in columns}\n    for insertion in iTable.iterrows():\n        insertion = insertion[1]\n        if insertion['ID'] not in fa:\n            continue\n        # rRNA strand\n        strand = insertion['sequence'].split('strand=', 1)[1].split()[0]\n        # set rRNA positions for reporting features on contig or extracted sequence\n        if contig is True:\n            gene = [int(i) for i in insertion['sequence'].split('pos=', 1)[1].split()[0].split('-')]\n            if strand == '-':\n                offset = -1 * (gene[1])\n            else:\n                offset = gene[0]\n        else:\n            strand = '+'\n            gene = [1, int(insertion['sequence'].split('total-len=', 1)[1].split()[0])]\n            offset = gene[0]\n        insertion['strand'] = strand\n        insertion['offset'] = offset\n        # source for prediction\n        source = insertion['sequence'].split('::model', 1)[0].rsplit(' ', 1)[-1]\n        insertion['source'] = source\n        # rRNA gene\n        geneAnnot = '%s rRNA gene' % (source.split('from', 1)[0])\n        geneNum = insertion['sequence'].split('seq=', 1)[1].split()[0]\n        gff['#seqname'].append(insertion['ID'])\n        gff['source'].append(source)\n        gff['feature'].append('Gene')\n        gff['start'].append(gene[0])\n        gff['end'].append(gene[1])\n        gff['score'].append('.')\n        gff['strand'].append(strand)\n        gff['frame'].append('.')\n        gff['attribute'].append('ID=%s; Name=%s' % (geneNum, geneAnnot))\n        # rRNA\n        gff = parse_rRNA(insertion, fa[insertion['ID']], gff)\n        # insertions\n        gff = parse_insertion(insertion, gff)\n        # orfs\n        gff = parse_orf(insertion, gff)\n        # catalytic RNAs\n        gff = parse_catalytic(insertion, gff)\n    return pd.DataFrame(gff)[columns].drop_duplicates()", "label": 1}
{"code": "def from_config(config):\n    \"\"\"\n    Generate a matrix from a configuration dictionary.\n    \"\"\"\n    matrix = {}\n    variables = config.keys()\n    for entries in product(*config.values()):\n        combination = dict(zip(variables, entries))\n        include = True\n        for value in combination.values():\n            for reducer in value.reducers:\n                if reducer.pattern == '-':\n                    match = not combination[reducer.variable].value\n                else:\n                    match = fnmatch(combination[reducer.variable].value, reducer.pattern)\n                if match if reducer.is_exclude else not match:\n                    include = False\n        if include:\n            key = '-'.join(entry.alias for entry in entries if entry.alias)\n            data = dict(\n                zip(variables, (entry.value for entry in entries))\n            )\n            if key in matrix and data != matrix[key]:\n                raise DuplicateEnvironment(key, data, matrix[key])\n            matrix[key] = data\n    return matrix", "label": 1}
{"code": "function LinkReference(properties) {\n                if (properties)\n                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n                        if (properties[keys[i]] != null)\n                            this[keys[i]] = properties[keys[i]];\n            }", "label": 3}
{"code": "func SetupUserCreds(tc *client.TeleportClient, proxyHost string, creds UserCreds) error {\n\t_, err := tc.AddKey(proxyHost, &creds.Key)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\terr = tc.AddTrustedCA(creds.HostCA)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def render_has_many_form(form_builder, parent, &block)\n      index = parent && form_builder.send(:parent_child_index, parent)\n      template.concat template.capture { yield(form_builder, index) }\n      template.concat has_many_actions(form_builder, \"\".html_safe)\n    end", "label": 4}
{"code": "function getMethodParamHtml(name, param) {\n    return [\n        '<tr>',\n            '<td>',\n                name,\n                param.required ?\n                    '<span title=\"Required field\" style=\"color:red;cursor:default\">&nbsp;*</span>' : '',\n            '</td>',\n            '<td>', param.type || 'As is', '</td>',\n            '<td>', param.description, '</td>',\n        '</tr>'\n    ].join('');\n}", "label": 3}
{"code": "public function getByAction($action)\n    {\n        return isset($this->actions[$action]) ? $this->actions[$action] : null;\n    }", "label": 2}
{"code": "protected function validateAndCompleteToOneAssociationMetadata(ToOneAssociationMetadata $property)\n    {\n        $fieldName = $property->getName();\n\n        if ($property->isOwningSide()) {\n            if (empty($property->getJoinColumns())) {\n                // Apply default join column\n                $property->addJoinColumn(new JoinColumnMetadata());\n            }\n\n            $uniqueConstraintColumns = [];\n\n            foreach ($property->getJoinColumns() as $joinColumn) {\n                /** @var JoinColumnMetadata $joinColumn */\n                if ($property instanceof OneToOneAssociationMetadata && $this->inheritanceType !== InheritanceType::SINGLE_TABLE) {\n                    if (count($property->getJoinColumns()) === 1) {\n                        if (! $property->isPrimaryKey()) {\n                            $joinColumn->setUnique(true);\n                        }\n                    } else {\n                        $uniqueConstraintColumns[] = $joinColumn->getColumnName();\n                    }\n                }\n\n                $joinColumn->setTableName(! $this->isMappedSuperclass ? $this->getTableName() : null);\n\n                if (! $joinColumn->getColumnName()) {\n                    $joinColumn->setColumnName($this->namingStrategy->joinColumnName($fieldName, $this->className));\n                }\n\n                if (! $joinColumn->getReferencedColumnName()) {\n                    $joinColumn->setReferencedColumnName($this->namingStrategy->referenceColumnName());\n                }\n\n                $this->fieldNames[$joinColumn->getColumnName()] = $fieldName;\n            }\n\n            if ($uniqueConstraintColumns) {\n                if (! $this->table) {\n                    throw new RuntimeException(\n                        'ClassMetadata::setTable() has to be called before defining a one to one relationship.'\n                    );\n                }\n\n                $this->table->addUniqueConstraint(\n                    [\n                        'name'    => sprintf('%s_uniq', $fieldName),\n                        'columns' => $uniqueConstraintColumns,\n                        'options' => [],\n                        'flags'   => [],\n                    ]\n                );\n            }\n        }\n\n        if ($property->isOrphanRemoval()) {\n            $cascades = $property->getCascade();\n\n            if (! in_array('remove', $cascades, true)) {\n                $cascades[] = 'remove';\n\n                $property->setCascade($cascades);\n            }\n\n            // @todo guilhermeblanco where is this used?\n            // @todo guilhermeblanco Shouldn\uffff't we iterate through JoinColumns to set non-uniqueness?\n            //$property->setUnique(false);\n        }\n\n        if ($property->isPrimaryKey() && ! $property->isOwningSide()) {\n            throw MappingException::illegalInverseIdentifierAssociation($this->className, $fieldName);\n        }\n    }", "label": 2}
{"code": "func (c *container) start(vm *VirtualMachine) {\n\tif c.id != \"\" {\n\t\tstart := \"start\"\n\t\tif vm.Runtime.PowerState == types.VirtualMachinePowerStateSuspended {\n\t\t\tstart = \"unpause\"\n\t\t}\n\t\tcmd := exec.Command(\"docker\", start, c.id)\n\t\terr := cmd.Run()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s %s: %s\", vm.Name, cmd.Args, err)\n\t\t}\n\t\treturn\n\t}\n\n\tvar args []string\n\n\tfor _, opt := range vm.Config.ExtraConfig {\n\t\tval := opt.GetOptionValue()\n\t\tif val.Key == \"RUN.container\" {\n\t\t\trun := val.Value.(string)\n\t\t\terr := json.Unmarshal([]byte(run), &args)\n\t\t\tif err != nil {\n\t\t\t\targs = []string{run}\n\t\t\t}\n\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif len(args) == 0 {\n\t\treturn\n\t}\n\n\targs = append([]string{\"run\", \"-d\", \"--name\", vm.Name}, args...)\n\tcmd := exec.Command(\"docker\", args...)\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\tlog.Printf(\"%s %s: %s\", vm.Name, cmd.Args, err)\n\t\treturn\n\t}\n\n\tc.id = strings.TrimSpace(string(out))\n\tvm.logPrintf(\"%s %s: %s\", cmd.Path, cmd.Args, c.id)\n\n\tif err = c.inspect(vm); err != nil {\n\t\tlog.Printf(\"%s inspect %s: %s\", vm.Name, c.id, err)\n\t}\n}", "label": 5}
{"code": "private function setSimpleJobProperties(array $options = [])\n    {\n        if (!isset($options['identifier'])) {\n            throw new \\InvalidArgumentException(\n                'A valid identifier is required in order to register a job.'\n            );\n        }\n\n        $options += [\n            'configStorage' => null,\n        ];\n\n        $this->setSerializableClientOptions($options);\n        $identifier = $options['identifier'];\n        $configStorage = $options['configStorage'] ?: $this->defaultConfigStorage();\n\n        $result = $configStorage->lock();\n        if ($result === false) {\n            return false;\n        }\n        $config = $configStorage->load();\n        $config->registerJob(\n            $identifier,\n            function ($id) use ($identifier, $options) {\n                return new SimpleJob($identifier, [$this, 'run'], $id, $options);\n            }\n        );\n        try {\n            $result = $configStorage->save($config);\n        } finally {\n            $configStorage->unlock();\n        }\n        return $result;\n    }", "label": 2}
{"code": "func Deduplicate(in []string) []string {\n\tif len(in) == 0 {\n\t\treturn in\n\t}\n\tout := make([]string, 0, len(in))\n\tseen := make(map[string]bool, len(in))\n\tfor _, val := range in {\n\t\tif _, ok := seen[val]; !ok {\n\t\t\tout = append(out, val)\n\t\t\tseen[val] = true\n\t\t}\n\t}\n\treturn out\n}", "label": 5}
{"code": "def index():\r\n    \"\"\"Handler for showing the GUI index page.\"\"\"\r\n    stats = dict((k, {\"count\": 0}) for k, tt in conf.InputTables)\r\n    countminmax = \"SUM(count) AS count, MIN(day) AS first, MAX(day) AS last\"\r\n    for input, table in [(x, t) for x, tt in conf.InputTables for t in tt]:\r\n        row = db.fetchone(\"counts\", countminmax, type=table)\r\n        if not row[\"count\"]: continue # for input, table\r\n        stats[input][\"count\"] += row[\"count\"]\r\n        for func, key in [(min, \"first\"), (max, \"last\")]:\r\n            stats[input][key] = (row[key] if key not in stats[input]\r\n                                 else func(stats[input][key], row[key]))\r\n    return bottle.template(\"index.tpl\", locals(), conf=conf)", "label": 1}
{"code": "def _l_cv_weight_factor(self):\n        \"\"\"\n        Return multiplier for L-CV weightings in case of enhanced single site analysis.\n\n        Methodology source: Science Report SC050050, eqn. 6.15a and 6.15b\n        \"\"\"\n        b = 0.0047 * sqrt(0) + 0.0023 / 2\n        c = 0.02609 / (self.catchment.record_length - 1)\n        return c / (b + c)", "label": 1}
{"code": "func (m *MockEmbed) ForeignEmbeddedMethod() *bufio.Reader {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"ForeignEmbeddedMethod\")\n\tret0, _ := ret[0].(*bufio.Reader)\n\treturn ret0\n}", "label": 5}
{"code": "function(data, code, callback) {\n    var self = this;\n    var cconfig = this.config.client;\n    var sconfig = this.config.servers[data.oauth2_server_id];\n    request.post({uri: sconfig.server_token_endpoint,\n                  headers: {'content-type': 'application/x-www-form-urlencoded'},\n                  body: querystring.stringify({\n                    grant_type: \"authorization_code\",\n                    client_id: sconfig.client_id,\n                    code: code,\n                    client_secret: sconfig.client_secret,\n                    redirect_uri: cconfig.redirect_uri\n                  })\n                 }, function(error, response, body) {\n                   console.log(body);\n                   if (!error && response.statusCode == 200) {\n                     try {\n                       var methods = self.methods[data.oauth2_server_id];\n                       var token = methods.transform_token_response(body)\n                       callback(null, token);\n                     } catch(err) {\n                       callback(err);\n                     }\n                   } else {\n                     // TODO: check if error code indicates problem on the client,\n                     console.error(error, body);\n                     callback(error);\n                   }\n                 });\n  }", "label": 3}
{"code": "private function fullyQualifiedConfigName($name, $projectId)\n    {\n        try {\n            return InstanceAdminClient::instanceConfigName(\n                $projectId,\n                $name\n            );\n        } catch (ValidationException $e) {\n            return $name;\n        }\n    }", "label": 2}
{"code": "protected static function storeIfDoneProcessingJob($event, $app)\n    {\n        array_pop(static::$processingJobs);\n\n        if (empty(static::$processingJobs)) {\n            static::store($app[EntriesRepository::class]);\n\n            if ($event->connectionName !== 'sync') {\n                static::stopRecording();\n            }\n        }\n    }", "label": 2}
{"code": "def GetTransPosition(df,field,dic,refCol=\"transcript_id\"):\n    \"\"\"\n    Maps a genome position to transcript positon\"\n\n    :param df: a Pandas dataframe\n    :param field: the head of the column containing the genomic position\n    :param dic: a dictionary containing for each transcript the respective bases eg. {ENST23923910:'234,235,236,1021,..'}\n    :param refCol: header of the reference column with IDs, eg. 'transcript_id'\n\n    :returns: position on transcript\n    \"\"\"\n    try:\n        gen=str(int(df[field]))\n        transid=df[refCol]\n        bases=dic.get(transid).split(\",\")\n        bases=bases.index(str(gen))+1\n    except:\n        bases=np.nan\n    return bases", "label": 1}
{"code": "def auto_paging_each(&blk)\n      return enum_for(:auto_paging_each) unless block_given?\n\n      page = self\n      loop do\n        page.each(&blk)\n        page = page.next_page\n        break if page.empty?\n      end\n    end", "label": 4}
{"code": "public function setThreatType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\WebRisk\\V1beta1\\ThreatType::class);\n        $this->threat_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(object, customizer) {\n\n    var foundStack = [], //Stack to keep track of discovered objects\n        queueOfModifiers = [], //Necessary to change our JSON as we take elements from the queue (BFS algorithm)\n        queue = []; //queue of JSON elements, following the BFS algorithm\n\n    //We instantiate our result root.\n    var result = _.isArray(object) ? [] : {};\n\n    //We first put all the JSON source in our queues\n    queue.push(object);\n    queueOfModifiers.push(new ObjectEditor(object, \"\"));\n\n    var positionStack;\n    var nextInsertion;\n\n    //BFS algorithm\n    while(queue.length > 0) {\n\n        //JSON to be modified and its editor\n        var value = queue.shift();\n        var editor = queueOfModifiers.shift();\n        //The path that leads to this JSON, so we can build other paths from it\n        var path = editor.path;\n\n        //We first attempt to make any personalized replacements\n        //If customizer doesn't affect the value, customizer(value) returns undefined and we jump this if\n        if(customizer !== undefined) {\n\n            //By using this variable, customizer(value) is called only once.\n            var customizedValue = customizer(value);\n\n            if(customizedValue !== undefined) value = customizedValue;\n        }\n\n\n        if(typeof value === \"object\") {\n\n            positionStack = _.chain(foundStack)\n                .map(\"value\")\n                .indexOf(value)\n                .value();\n\n            //If the value has already been discovered, we only fix its circular reference\n            if(positionStack !== -1) {\n                nextInsertion = foundStack[positionStack].makePathName();\n            }\n            else {\n                //At the first time we discover a certain value, we put it in the stack\n                foundStack.push(new FoundObject(value, path));\n\n                nextInsertion = value;\n\n                for(var component in value) {\n                    if(_.has(value, component)) {\n                        queue.push(value[component]);\n                        var newPath = path + \"[\" + component + \"]\";\n                        queueOfModifiers.push(new ObjectEditor(result, newPath));\n                    }\n                }\n            }\n        }\n        //If it's an elementary value, it can't be circular, so we just put this value in our JSON result.\n        else {\n            nextInsertion = value;\n        }\n\n        editor.editObject(nextInsertion);\n    }\n\n    return result;\n}", "label": 3}
{"code": "public function setConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\NodeConfig::class);\n        $this->config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (v *ViewPort) GetPhysical() (int, int, int, int) {\n\treturn v.physx, v.physy, v.physx + v.width - 1, v.physy + v.height - 1\n}", "label": 5}
{"code": "def submit_coroutine(self, coro, loop):\n        \"\"\"Schedule and await a coroutine on the specified loop\n\n        The coroutine is wrapped and scheduled using\n        :func:`asyncio.run_coroutine_threadsafe`. While the coroutine is\n        \"awaited\", the result is not available as method returns immediately.\n\n        Args:\n            coro: The :term:`coroutine` to schedule\n            loop: The :class:`event loop <asyncio.BaseEventLoop>` on which to\n                schedule the coroutine\n\n        Note:\n            This method is used internally by :meth:`__call__` and is not meant\n            to be called directly.\n        \"\"\"\n        async def _do_call(_coro):\n            with _IterationGuard(self):\n                await _coro\n        asyncio.run_coroutine_threadsafe(_do_call(coro), loop=loop)", "label": 1}
{"code": "def dump_stats(myStats):\n    \"\"\"\n    Show stats when pings are done\n    \"\"\"\n    print(\"\\n----%s PYTHON PING Statistics----\" % (myStats.thisIP))\n\n    if myStats.pktsSent > 0:\n        myStats.fracLoss = (myStats.pktsSent - myStats.pktsRcvd) \\\n                / myStats.pktsSent\n\n    print((\"%d packets transmitted, %d packets received, \"\n           \"%0.1f%% packet loss\") % (\n        myStats.pktsSent,\n        myStats.pktsRcvd,\n        100.0 * myStats.fracLoss\n    ))\n\n    if myStats.pktsRcvd > 0:\n        print(\"round-trip (ms)  min/avg/max = %d/%0.1f/%d\" % (\n            myStats.minTime,\n            myStats.totTime / myStats.pktsRcvd,\n            myStats.maxTime\n        ))\n\n    print(\"\")\n    return", "label": 1}
{"code": "public function clearMediaCollectionExcept(string $collectionName = 'default', $excludedMedia = [])\n    {\n        if ($excludedMedia instanceof Media) {\n            $excludedMedia = collect()->push($excludedMedia);\n        }\n\n        $excludedMedia = collect($excludedMedia);\n\n        if ($excludedMedia->isEmpty()) {\n            return $this->clearMediaCollection($collectionName);\n        }\n\n        $this->getMedia($collectionName)\n            ->reject(function (Media $media) use ($excludedMedia) {\n                return $excludedMedia->where('id', $media->id)->count();\n            })\n            ->each->delete();\n\n        if ($this->mediaIsPreloaded()) {\n            unset($this->media);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def remove_ref(self, ref):\n        \"\"\"Remove reference from self to ref\n\n        >>> iip = Resource('instance-ip',\n                           uuid='30213cf9-4b03-4afc-b8f9-c9971a216978',\n                           fetch=True)\n        >>> for vmi in iip['virtual_machine_interface_refs']:\n                iip.remove_ref(vmi)\n        >>> iip['virtual_machine_interface_refs']\n        KeyError: u'virtual_machine_interface_refs'\n\n        :param ref: reference to remove\n        :type ref: Resource\n\n        :rtype: Resource\n        \"\"\"\n        self.session.remove_ref(self, ref)\n        return self.fetch()", "label": 1}
{"code": "def parse_user_code\n      epilogue = @scanner.epilogue\n      return unless epilogue.text\n      epilogue.text.scan(/^----([^\\n\\r]*)(?:\\n|\\r\\n|\\r)(.*?)(?=^----|\\Z)/m) do\n        label = canonical_label($~[1])\n        range = epilogue.slice($~.begin(2), $~.end(2))\n        add_user_code(label, range)\n      end\n    end", "label": 4}
{"code": "func NewDefaultArgs() *ArgType {\n\tfkMode := FkModeSmart\n\n\treturn &ArgType{\n\t\tSuffix:              \".xo.go\",\n\t\tInt32Type:           \"int\",\n\t\tUint32Type:          \"uint\",\n\t\tForeignKeyMode:      &fkMode,\n\t\tQueryParamDelimiter: \"%%\",\n\t\tNameConflictSuffix:  \"Val\",\n\n\t\t// KnownTypeMap is the collection of known Go types.\n\t\tKnownTypeMap: map[string]bool{\n\t\t\t\"bool\":        true,\n\t\t\t\"string\":      true,\n\t\t\t\"byte\":        true,\n\t\t\t\"rune\":        true,\n\t\t\t\"int\":         true,\n\t\t\t\"int16\":       true,\n\t\t\t\"int32\":       true,\n\t\t\t\"int64\":       true,\n\t\t\t\"uint\":        true,\n\t\t\t\"uint8\":       true,\n\t\t\t\"uint16\":      true,\n\t\t\t\"uint32\":      true,\n\t\t\t\"uint64\":      true,\n\t\t\t\"float32\":     true,\n\t\t\t\"float64\":     true,\n\t\t\t\"Slice\":       true,\n\t\t\t\"StringSlice\": true,\n\t\t},\n\n\t\t// ShortNameTypeMap is the collection of Go style short names for types, mainly\n\t\t// used for use with declaring a func receiver on a type.\n\t\tShortNameTypeMap: map[string]string{\n\t\t\t\"bool\":        \"b\",\n\t\t\t\"string\":      \"s\",\n\t\t\t\"byte\":        \"b\",\n\t\t\t\"rune\":        \"r\",\n\t\t\t\"int\":         \"i\",\n\t\t\t\"int16\":       \"i\",\n\t\t\t\"int32\":       \"i\",\n\t\t\t\"int64\":       \"i\",\n\t\t\t\"uint\":        \"u\",\n\t\t\t\"uint8\":       \"u\",\n\t\t\t\"uint16\":      \"u\",\n\t\t\t\"uint32\":      \"u\",\n\t\t\t\"uint64\":      \"u\",\n\t\t\t\"float32\":     \"f\",\n\t\t\t\"float64\":     \"f\",\n\t\t\t\"Slice\":       \"s\",\n\t\t\t\"StringSlice\": \"ss\",\n\t\t},\n\t}\n}", "label": 5}
{"code": "def __parse_precipfc_data(data, timeframe):\n    \"\"\"Parse the forecasted precipitation data.\"\"\"\n    result = {AVERAGE: None, TOTAL: None, TIMEFRAME: None}\n\n    log.debug(\"Precipitation data: %s\", data)\n    lines = data.splitlines()\n    index = 1\n    totalrain = 0\n    numberoflines = 0\n    nrlines = min(len(lines), round(float(timeframe) / 5) + 1)\n    # looping through lines of forecasted precipitation data and\n    # not using the time data (HH:MM) int the data. This is to allow for\n    # correct data in case we are running in a different timezone.\n    while index < nrlines:\n        line = lines[index]\n        log.debug(\"__parse_precipfc_data: line: %s\", line)\n        # pylint: disable=unused-variable\n        (val, key) = line.split(\"|\")\n        # See buienradar documentation for this api, attribution\n        # https://www.buienradar.nl/overbuienradar/gratis-weerdata\n        #\n        # Op basis van de door u gewenste coordinaten (latitude en longitude)\n        # kunt u de neerslag tot twee uur vooruit ophalen in tekstvorm. De\n        # data wordt iedere 5 minuten geupdatet. Op deze pagina kunt u de\n        # neerslag in tekst vinden. De waarde 0 geeft geen neerslag aan (droog)\n        # de waarde 255 geeft zware neerslag aan. Gebruik de volgende formule\n        # voor het omrekenen naar de neerslagintensiteit in de eenheid\n        # millimeter per uur (mm/u):\n        #\n        # Neerslagintensiteit = 10^((waarde-109)/32)\n        #\n        # Ter controle: een waarde van 77 is gelijk aan een neerslagintensiteit\n        # van 0,1 mm/u.\n        mmu = 10**(float((int(val) - 109)) / 32)\n        totalrain = totalrain + float(mmu)\n        numberoflines = numberoflines + 1\n        index += 1\n\n    if numberoflines > 0:\n        result[AVERAGE] = round((totalrain / numberoflines), 2)\n    else:\n        result[AVERAGE] = 0\n    result[TOTAL] = round(totalrain / 12, 2)\n    result[TIMEFRAME] = timeframe\n\n    return result", "label": 1}
{"code": "function getMain(src, options, dest) {\n    var meta = grunt.file.readJSON(path.join(src, 'package.json'))\n    if (!meta.main) {\n      fail.fatal(\n        'No main property specified by ' + path.normalize(src.replace(options.srcPrefix, ''))\n      )\n    }\n    var files = typeof meta.main === 'string' ? [meta.main] : meta.main\n    return files.map(function(source) {\n      return {\n        src: path.join(src, source),\n        dest: dest\n      }\n    })\n  }", "label": 3}
{"code": "private Map<String, String> toPayload(Map<String, Object> data) throws LocalOperationException {\n        Map<String, Object> dataClone = new HashMap<String, Object>(data);\n        dataClone.put(\"auth\", getAuthData());\n\n        Map<String, String> payload = new HashMap<String, String>();\n        payload.put(\"params\", jsonifyData(dataClone));\n\n        if (transloadit.shouldSignRequest) {\n            payload.put(\"signature\", getSignature(jsonifyData(dataClone)));\n        }\n        return payload;\n    }", "label": 0}
{"code": "def unlock(self):\n        \"\"\" Unlock the candidate config.\n\n        Purpose: Unlocks the candidate configuration, so that other people can\n               | edit the device. Requires the _session private variable to be\n               | a type of a ncclient.manager.Manager.\n        \"\"\"\n        if isinstance(self._session, manager.Manager):\n            self._session.unlock()", "label": 1}
{"code": "public function close()\n    {\n        $id = session_id();\n        // Make sure the session is unlocked and the expiration time is updated,\n        // even if the write did not occur\n        if ($this->openSessionId !== $id || !$this->sessionWritten) {\n            $result = $this->connection->write($this->formatId($id), '', false);\n            $this->sessionWritten = (bool) $result;\n        }\n\n        return $this->sessionWritten;\n    }", "label": 2}
{"code": "func (rd *Redirector) Start() error {\n\tif rd.BindAddr != \"\" {\n\t\tlog.Debugf(\"Binding to %v.\", rd.BindAddr)\n\t\tlistener, err := net.Listen(\"tcp\", rd.BindAddr)\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err, \"%v: could not bind to %v, make sure the address is host:port format for ipv4 and [ipv6]:port format for ipv6, and the address is not in use\", err, rd.BindAddr)\n\t\t}\n\t\trd.server = &httptest.Server{\n\t\t\tListener: listener,\n\t\t\tConfig:   &http.Server{Handler: rd.mux},\n\t\t}\n\t\trd.server.Start()\n\t} else {\n\t\trd.server = httptest.NewServer(rd.mux)\n\t}\n\tlog.Infof(\"Waiting for response at: %v.\", rd.server.URL)\n\n\t// communicate callback redirect URL to the Teleport Proxy\n\tu, err := url.Parse(rd.server.URL + \"/callback\")\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tquery := u.Query()\n\tquery.Set(\"secret_key\", rd.key.String())\n\tu.RawQuery = query.Encode()\n\n\tout, err := rd.proxyClient.PostJSON(rd.Context, rd.proxyClient.Endpoint(\"webapi\", rd.Protocol, \"login\", \"console\"), SSOLoginConsoleReq{\n\t\tRedirectURL:   u.String(),\n\t\tPublicKey:     rd.PubKey,\n\t\tCertTTL:       rd.TTL,\n\t\tConnectorID:   rd.ConnectorID,\n\t\tCompatibility: rd.Compatibility,\n\t})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tvar re *SSOLoginConsoleResponse\n\terr = json.Unmarshal(out.Bytes(), &re)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t// notice late binding of the redirect URL here, it is referenced\n\t// in the callback handler, but is known only after the request\n\t// is sent to the Teleport Proxy, that's why\n\t// redirectURL is a SyncString\n\trd.redirectURL.Set(re.RedirectURL)\n\treturn nil\n}", "label": 5}
{"code": "public static clusterinstance[] get(nitro_service service) throws Exception{\n\t\tclusterinstance obj = new clusterinstance();\n\t\tclusterinstance[] response = (clusterinstance[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function(description) {\n  // Look for triple backtick code blocks flagged as `glimmer`;\n  // define end of block as triple backticks followed by a newline\n  let matches = description.match(/(```glimmer)(.|\\n)*?```/gi);\n\n  if (matches && matches.length) {\n    matches.map(codeBlock => {\n      let blockEnd = codeBlock.length + description.indexOf(codeBlock);\n      let plainCode = codeBlock.replace(/(```glimmer|```)/gi, '');\n      description = `${description.slice(0, (blockEnd))}${plainCode}${ description.slice(blockEnd)}`;\n    });\n  }\n\n  return description;\n}", "label": 3}
{"code": "func (cl *Client) gotMetadataExtensionMsg(payload []byte, t *Torrent, c *connection) error {\n\tvar d map[string]int\n\terr := bencode.Unmarshal(payload, &d)\n\tif _, ok := err.(bencode.ErrUnusedTrailingBytes); ok {\n\t} else if err != nil {\n\t\treturn fmt.Errorf(\"error unmarshalling bencode: %s\", err)\n\t}\n\tmsgType, ok := d[\"msg_type\"]\n\tif !ok {\n\t\treturn errors.New(\"missing msg_type field\")\n\t}\n\tpiece := d[\"piece\"]\n\tswitch msgType {\n\tcase pp.DataMetadataExtensionMsgType:\n\t\tc.allStats(add(1, func(cs *ConnStats) *Count { return &cs.MetadataChunksRead }))\n\t\tif !c.requestedMetadataPiece(piece) {\n\t\t\treturn fmt.Errorf(\"got unexpected piece %d\", piece)\n\t\t}\n\t\tc.metadataRequests[piece] = false\n\t\tbegin := len(payload) - metadataPieceSize(d[\"total_size\"], piece)\n\t\tif begin < 0 || begin >= len(payload) {\n\t\t\treturn fmt.Errorf(\"data has bad offset in payload: %d\", begin)\n\t\t}\n\t\tt.saveMetadataPiece(piece, payload[begin:])\n\t\tc.lastUsefulChunkReceived = time.Now()\n\t\treturn t.maybeCompleteMetadata()\n\tcase pp.RequestMetadataExtensionMsgType:\n\t\tif !t.haveMetadataPiece(piece) {\n\t\t\tc.Post(t.newMetadataExtensionMessage(c, pp.RejectMetadataExtensionMsgType, d[\"piece\"], nil))\n\t\t\treturn nil\n\t\t}\n\t\tstart := (1 << 14) * piece\n\t\tc.Post(t.newMetadataExtensionMessage(c, pp.DataMetadataExtensionMsgType, piece, t.metadataBytes[start:start+t.metadataPieceSize(piece)]))\n\t\treturn nil\n\tcase pp.RejectMetadataExtensionMsgType:\n\t\treturn nil\n\tdefault:\n\t\treturn errors.New(\"unknown msg_type value\")\n\t}\n}", "label": 5}
{"code": "def getSbus(self, buses=None):\n        \"\"\" Returns the net complex bus power injection vector in p.u.\n        \"\"\"\n        bs = self.buses if buses is None else buses\n        s = array([self.s_surplus(v) / self.base_mva for v in bs])\n        return s", "label": 1}
{"code": "def stage_import_from_filesystem(self, filepath):\n        \"\"\"Stage an import from a filesystem path.\n\n        :param filepath: Local filesystem path as string.\n        :return: :class:`imports.Import <imports.Import>` object\n        \"\"\"\n        schema = ImportSchema()\n        resp = self.service.post(self.base,\n                                 params={'path': filepath})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function translateValue(sceneDrawGroup, ccssProperty, ccssValue) {\n    if (ccssProperty.indexOf('comp-op') >= 0) {\n        switch (ccssValue) {\n            case 'src-over':\n                return 'overlay';\n            case 'plus':\n                return 'add';\n            default:\n                return ccssValue;\n        }\n    }\n    if (referenceCSS[ccssProperty].type === 'color') {\n        return getColorFromLiteral(sceneDrawGroup, ccssValue, ccssProperty.indexOf('fill') >= 0);\n    }\n    if (ccssProperty.indexOf('width') >= 0) {\n        ccssValue += 'px';\n    }\n    if (ccssProperty.indexOf('allow-overlap') >= 0) {\n        ccssValue = !ccssValue;\n    }\n    return ccssValue;\n}", "label": 3}
{"code": "public function handleConnect($conn) {\n        $conn->decor = new IoConnection($conn);\n        $conn->decor->resourceId = (int)$conn->stream;\n\n        $uri = $conn->getRemoteAddress();\n        $conn->decor->remoteAddress = trim(\n            parse_url((strpos($uri, '://') === false ? 'tcp://' : '') . $uri, PHP_URL_HOST),\n            '[]'\n        );\n\n        $this->app->onOpen($conn->decor);\n\n        $conn->on('data', function ($data) use ($conn) {\n            $this->handleData($data, $conn);\n        });\n        $conn->on('close', function () use ($conn) {\n            $this->handleEnd($conn);\n        });\n        $conn->on('error', function (\\Exception $e) use ($conn) {\n            $this->handleError($e, $conn);\n        });\n    }", "label": 2}
{"code": "def run_callbacks(action_name, &block)\n      filter_callbacks(:before, action_name).each { |hook| send hook[:callback] }\n      yield if block_given?\n      filter_callbacks(:after, action_name).each { |hook| send hook[:callback] }\n    end", "label": 4}
{"code": "public function down()\n    {\n        $results = '';\n        foreach ($this->toArray() as $column => $attributes) {\n            $results .= $this->createField($column, $attributes, 'remove');\n        }\n\n        return $results;\n    }", "label": 2}
{"code": "def creator(entry, config):\n        \"\"\"Creator function for creating an instance of a Docker image script.\"\"\"\n        # writing Dockerfile\n        dockerfile = render(config.script, model=config.model, env=config.env,\n                            variables=config.variables, item=config.item)\n        filename = \"dockerfile.dry.run.see.comment\"\n\n        if not config.dry_run:\n            temp = tempfile.NamedTemporaryFile(\n                prefix=\"dockerfile-\", mode='w+t', delete=False)\n            temp.writelines(dockerfile)\n            temp.close()\n            filename = temp.name\n            dockerfile = ''\n\n        # rendering the Bash script for generating the Docker image\n        name = entry['name'] + \"-%s\" % os.getpid() if entry['unique'] else entry['name']\n        tag = render(entry['tag'], model=config.model, env=config.env, item=config.item)\n        template_file = os.path.join(os.path.dirname(__file__), 'templates/docker-image.sh.j2')\n\n        with open(template_file) as handle:\n            template = handle.read()\n            config.script = render(template, name=name, tag=tag,\n                                   dockerfile_content=dockerfile,\n                                   dockerfile_filename=filename)\n\n        return Image(config)", "label": 1}
{"code": "def set_options(options)\n      unless options.respond_to?(:each)\n        raise ArgumentError, 'cannot iterate over value'\n      end\n      options.each { |key, value| set(key, value) }\n    end", "label": 4}
{"code": "function loadPluginsFromDir(dir, config) {\n  try {\n    fs\n      .readdirSync(dir)\n      .filter(resource => {\n        if (path.basename(dir) != 'plugins') return RE_PLUGIN.test(resource);\n        return RE_JS_FILE.test(resource) || fs.statSync(path.join(dir, resource)).isDirectory();\n      })\n      .forEach(resource => {\n        registerPlugin(path.join(dir, resource), config);\n      });\n  } catch (err) {\n    /* ignore */\n  }\n}", "label": 3}
{"code": "def _default_layout(lookup_context, formats, require_layout = false)\n      begin\n        value = _layout(lookup_context, formats) if action_has_layout?\n      rescue NameError => e\n        raise e, \"Could not render layout: #{e.message}\"\n      end\n\n      if require_layout && action_has_layout? && !value\n        raise ArgumentError,\n          \"There was no default layout for #{self.class} in #{view_paths.inspect}\"\n      end\n\n      _normalize_layout(value)\n    end", "label": 4}
{"code": "func (f *Fpdf) out(s string) {\n\tif f.state == 2 {\n\t\tf.pages[f.page].WriteString(s)\n\t\tf.pages[f.page].WriteString(\"\\n\")\n\t} else {\n\t\tf.buffer.WriteString(s)\n\t\tf.buffer.WriteString(\"\\n\")\n\t}\n}", "label": 5}
{"code": "def _set_update(self):\n        \"\"\"\n        Determine if we are creating a new stack or updating and existing one.\n        The update member is set as you would expect at the end of this query.\n\n        Args:\n            None\n\n        Returns:\n            True\n        \"\"\"\n        try:\n            self._updateStack = False\n            stack_name = self._config.get('environment', {}).get('stack_name', None)\n            response = self._cloudFormation.describe_stacks(StackName=stack_name)\n            stack = response['Stacks'][0]\n            if stack['StackStatus'] == 'ROLLBACK_COMPLETE':\n                logging.info('stack is in ROLLBACK_COMPLETE status and should be deleted')\n                del_stack_resp = self._cloudFormation.delete_stack(StackName=stack_name)\n                logging.info('delete started for stack: {}'.format(stack_name))\n                logging.debug('delete_stack returned: {}'.format(json.dumps(del_stack_resp, indent=4)))\n                stack_delete = self.poll_stack()\n                if not stack_delete:\n                    return False\n\n            if stack['StackStatus'] in ['CREATE_COMPLETE', 'UPDATE_COMPLETE', 'UPDATE_ROLLBACK_COMPLETE']:\n                self._updateStack = True\n        except:\n            self._updateStack = False\n\n        logging.info('update_stack: ' + str(self._updateStack))\n        return True", "label": 1}
{"code": "public function setHiveJob($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1\\HiveJob::class);\n        $this->writeOneof(6, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function (event) {\n\n\t// check if connection object exists\n\tif (typeof event.conn === 'undefined') {\n\t\tLOG.error('no connection records, cannot respond to request', l_name);\n\t\treturn false;\n\t}\n\n\t// if no mechanism to store (such as from a bot), just ignore\n\t// TODO: cleaner approach?\n\tif (event.conn.type !== 'socket' ||\n    \tevent.conn.connector.queuedEvents === undefined) {\n\t\treturn true;\n\t}\n\n\tvar socket = event.conn.connector;\n\n\t// check if id exist\n\tif (socket.queuedEvents.hasOwnProperty(event.id) === false) {\n\t\tLOG.error('event not found. id = ' + event.id, l_name);\n\t\tLOG.stack();\n\t\treturn false;\n\t}\n\n\t// remove current event from the socket's event queues\n\tdelete socket.queuedEvents[event.id];\n\n\treturn true;\n}", "label": 3}
{"code": "def send_knock(self, created=False):\n        \"\"\"\n        Send the knock in the associated channels Group\n        \"\"\"\n        knock = self.as_knock(created)\n        if knock:\n            gr = Group('knocker-{0}'.format(knock['language']))\n            gr.send({'text': json.dumps(knock)})", "label": 1}
{"code": "public static vrid6_nsip6_binding[] get(nitro_service service, Long id) throws Exception{\n\t\tvrid6_nsip6_binding obj = new vrid6_nsip6_binding();\n\t\tobj.set_id(id);\n\t\tvrid6_nsip6_binding response[] = (vrid6_nsip6_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def build(self, recipe):\n        \"\"\"\n        Builds a recipe\n\n        :param recipe: Name of the recipe to build.\n        \"\"\"\n        return self.__app.recipes.build(recipe, self._plugin)", "label": 1}
{"code": "func (g *generator) Output() []byte {\n\tsrc, err := format.Source(g.buf.Bytes())\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to format generated source code: %s\\n%s\", err, g.buf.String())\n\t}\n\treturn src\n}", "label": 5}
{"code": "function Segment(properties) {\n                if (properties)\n                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n                        if (properties[keys[i]] != null)\n                            this[keys[i]] = properties[keys[i]];\n            }", "label": 3}
{"code": "protected function connect()\n    {\n        try {\n            // Loop until we connect\n            while (!$this->isConnected()) {\n                // Assume we will connect, until we dont\n                $this->setIsConnected(true);\n\n                // Connect the socket\n                $this->io->connect();\n\n                $this->channels = array();\n                // The connection object itself is treated as channel 0\n                parent::__construct($this, 0);\n\n                $this->input = new AMQPReader(null, $this->io);\n\n                $this->write($this->amqp_protocol_header);\n                $this->wait(array($this->waitHelper->get_wait('connection.start')),false,$this->connection_timeout);\n                $this->x_start_ok(\n                    $this->getLibraryProperties(),\n                    $this->login_method,\n                    $this->login_response,\n                    $this->locale\n                );\n\n                $this->wait_tune_ok = true;\n                while ($this->wait_tune_ok) {\n                    $this->wait(array(\n                        $this->waitHelper->get_wait('connection.secure'),\n                        $this->waitHelper->get_wait('connection.tune')\n                    ));\n                }\n\n                $host = $this->x_open($this->vhost, '', $this->insist);\n                if (!$host) {\n                    //Reconnected\n                    $this->io->reenableHeartbeat();\n                    return null; // we weren't redirected\n                }\n\n                $this->setIsConnected(false);\n                $this->closeChannels();\n\n                // we were redirected, close the socket, loop and try again\n                $this->close_socket();\n            }\n\n        } catch (\\Exception $e) {\n            // Something went wrong, set the connection status\n            $this->setIsConnected(false);\n            $this->closeChannels();\n            $this->close_input();\n            $this->close_socket();\n            throw $e; // Rethrow exception\n        }\n    }", "label": 2}
{"code": "public long countByLex(final LexRange lexRange) {\n        return doWithJedis(new JedisCallable<Long>() {\n            @Override\n            public Long call(Jedis jedis) {\n                return jedis.zlexcount(getKey(), lexRange.from(), lexRange.to());\n            }\n        });\n    }", "label": 0}
{"code": "public static cmpaction get(nitro_service service, String name) throws Exception{\n\t\tcmpaction obj = new cmpaction();\n\t\tobj.set_name(name);\n\t\tcmpaction response = (cmpaction) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static nsrpcnode get(nitro_service service, String ipaddress) throws Exception{\n\t\tnsrpcnode obj = new nsrpcnode();\n\t\tobj.set_ipaddress(ipaddress);\n\t\tnsrpcnode response = (nsrpcnode) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (me *trackerScraper) announce() (ret trackerAnnounceResult) {\n\tdefer func() {\n\t\tret.Completed = time.Now()\n\t}()\n\tret.Interval = 5 * time.Minute\n\tip, err := me.getIp()\n\tif err != nil {\n\t\tret.Err = fmt.Errorf(\"error getting ip: %s\", err)\n\t\treturn\n\t}\n\tme.t.cl.lock()\n\treq := me.t.announceRequest()\n\tme.t.cl.unlock()\n\tres, err := tracker.Announce{\n\t\tHTTPProxy:  me.t.cl.config.HTTPProxy,\n\t\tUserAgent:  me.t.cl.config.HTTPUserAgent,\n\t\tTrackerUrl: me.trackerUrl(ip),\n\t\tRequest:    req,\n\t\tHostHeader: me.u.Host,\n\t\tServerName: me.u.Hostname(),\n\t\tUdpNetwork: me.u.Scheme,\n\t\tClientIp4:  krpc.NodeAddr{IP: me.t.cl.config.PublicIp4},\n\t\tClientIp6:  krpc.NodeAddr{IP: me.t.cl.config.PublicIp6},\n\t}.Do()\n\tif err != nil {\n\t\tret.Err = fmt.Errorf(\"error announcing: %s\", err)\n\t\treturn\n\t}\n\tme.t.AddPeers(Peers(nil).AppendFromTracker(res.Peers))\n\tret.NumPeers = len(res.Peers)\n\tret.Interval = time.Duration(res.Interval) * time.Second\n\treturn\n}", "label": 5}
{"code": "private function getIndividualValue($value)\n    {\n        if (! is_object($value) || ! $this->em->getMetadataFactory()->hasMetadataFor(StaticClassNameConverter::getClass($value))) {\n            return $value;\n        }\n\n        return $this->em->getUnitOfWork()->getSingleIdentifierValue($value);\n    }", "label": 2}
{"code": "private function handleResponse($response)\n    {\n        if ($response instanceof PagedListResponse || $response instanceof GaxPagedListResponse) {\n            $response = $response->getPage()->getResponseObject();\n        }\n\n        if ($response instanceof Message) {\n            return $this->serializer->encodeMessage($response);\n        }\n\n        if ($response instanceof OperationResponse || $response instanceof GaxOperationResponse) {\n            return $response;\n        }\n\n        if ($response instanceof ServerStream || $response instanceof GaxServerStream) {\n            return $this->handleStream($response);\n        }\n\n        return null;\n    }", "label": 2}
{"code": "public String to_string() \n\t{\n\t\tString str = \"\";\n\t\tif (pageno > 0) \n\t\t\tstr = \"pageno=\"+pageno;\n\t\t\n\t\tif (pagesize > 0) \n\t\t{\n\t\t\tif (str.length() > 0)\n\t\t\t\tstr = str + \"&\";\n\t\t\t\n\t\t\tstr = str +\"pagesize=\"+pagesize;\n\t\t}\n\t\t\n\t\tif (detailview) \n\t\t{\n\t\t\tif (str.length() > 0)\n\t\t\t\tstr = str + \"&\";\n\t\t\t\n\t\t\tstr = str +\"view=detail\";\n\t\t}\n\t\t\n\t\tif (count) \n\t\t{\n\t\t\tif (str.length() > 0)\n\t\t\t\tstr = str + \"&\";\n\t\t\t\n\t\t\tstr = str +\"count=yes\";\n\t\t}\n\t\t\n\t\tif (args != null) {\n\t\t\tif (str.length() > 0)\n\t\t\t\tstr = str + \"&\";\n\t\t\tstr = str+\"args=\"+args;\n\t\t}\n\t\tif (filter != null) {\n\t\t\tif (filter.length() > 0)\n\t\t\t\tstr = str + \"&\";\n\t\t\tstr = str+\"filter=\"+filter;\n\t\t}\n\t\treturn str;\n\t}", "label": 0}
{"code": "private function tags($message, $data)\n    {\n        return array_merge(\n            array_keys($message->getTo() ?: []),\n            array_keys($message->getCc() ?: []),\n            array_keys($message->getBcc() ?: []),\n            $data['__telescope'] ?? []\n        );\n    }", "label": 2}
{"code": "function () {\n        if (Utils.isNullOrEmpty(server.spaceGeometries) && !Utils.isNullOrEmpty(server.spaces)) {\n            Object.keys(server.spaces).forEach(function (s) {\n                const geometry = { w: Number.MIN_VALUE, h: Number.MIN_VALUE };\n                server.spaces[s].forEach(function (e) {\n                    geometry.w = Math.max(e.x + e.w, geometry.w);\n                    geometry.h = Math.max(e.y + e.h, geometry.h);\n                });\n                log.debug('Successfully computed geometry for space:', s);\n                server.spaceGeometries[s] = geometry;\n            });\n        }\n        return server.spaceGeometries;\n    }", "label": 3}
{"code": "public static function instance($object = null, $objectDump = null)\n    {\n        $tz = $object;\n\n        if ($tz instanceof static) {\n            return $tz;\n        }\n\n        if ($tz === null) {\n            return new static();\n        }\n\n        if (!$tz instanceof DateTimeZone) {\n            $tz = static::getDateTimeZoneFromName($object);\n        }\n\n        if ($tz === false) {\n            if (Carbon::isStrictModeEnabled()) {\n                throw new InvalidArgumentException('Unknown or bad timezone ('.($objectDump ?: $object).')');\n            }\n\n            return false;\n        }\n\n        return new static($tz->getName());\n    }", "label": 2}
{"code": "public static function appProfileName($project, $instance, $appProfile)\n    {\n        return self::getAppProfileNameTemplate()->render([\n            'project' => $project,\n            'instance' => $instance,\n            'app_profile' => $appProfile,\n        ]);\n    }", "label": 2}
{"code": "def parse_filter(filter_argument = nil, &filter_proc)\n      filter = filter_argument || filter_proc\n\n      if filter\n        SimpleCov::Filter.build_filter(filter)\n      else\n        raise ArgumentError, \"Please specify either a filter or a block to filter with\"\n      end\n    end", "label": 4}
{"code": "public function setAttributes($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Trace\\V2\\Span_Attributes::class);\n        $this->attributes = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def pileup_reads_at_position(samfile, chromosome, base0_position):\n    \"\"\"\n    Returns a pileup column at the specified position. Unclear if a function\n    like this is hiding somewhere in pysam API.\n    \"\"\"\n\n    # TODO: I want to pass truncate=True, stepper=\"all\"\n    # but for some reason I get this error:\n    #      pileup() got an unexpected keyword argument 'truncate'\n    # ...even though these options are listed in the docs for pysam 0.9.0\n    #\n    for column in samfile.pileup(\n            chromosome,\n            start=base0_position,\n            end=base0_position + 1):\n\n        if column.pos != base0_position:\n            # if this column isn't centered on the base before the\n            # variant then keep going\n            continue\n\n        return column.pileups\n\n    # if we get to this point then we never saw a pileup at the\n    # desired position\n    return []", "label": 1}
{"code": "public static rnat_stats get(nitro_service service) throws Exception{\n\t\trnat_stats obj = new rnat_stats();\n\t\trnat_stats[] response = (rnat_stats[])obj.stat_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "func (s *SizeType) ScaleBy(factor float64) SizeType {\n\treturn SizeType{s.Wd * factor, s.Ht * factor}\n}", "label": 5}
{"code": "def stream_logs(self, stdout=True, stderr=True, tail='all', timeout=10.0):\n        \"\"\"\n        Stream container output.\n        \"\"\"\n        return stream_logs(\n            self.inner(), stdout=stdout, stderr=stderr, tail=tail,\n            timeout=timeout)", "label": 1}
{"code": "func (proxy *UDPProxy) Close() {\n\tproxy.listener.Close()\n\tproxy.connTrackLock.Lock()\n\tdefer proxy.connTrackLock.Unlock()\n\tfor _, conn := range proxy.connTrackTable {\n\t\tconn.Close()\n\t}\n}", "label": 5}
{"code": "func (c *CredentialsClient) SSHAgentLogin(ctx context.Context, user string, password string, otpToken string, pubKey []byte, ttl time.Duration, compatibility string) (*auth.SSHLoginResponse, error) {\n\tre, err := c.clt.PostJSON(ctx, c.clt.Endpoint(\"webapi\", \"ssh\", \"certs\"), CreateSSHCertReq{\n\t\tUser:          user,\n\t\tPassword:      password,\n\t\tOTPToken:      otpToken,\n\t\tPubKey:        pubKey,\n\t\tTTL:           ttl,\n\t\tCompatibility: compatibility,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tvar out *auth.SSHLoginResponse\n\terr = json.Unmarshal(re.Bytes(), &out)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn out, nil\n}", "label": 5}
{"code": "def register_action(self, action):\n        \"\"\"Register an action to be showed in the actions list.\n\n        .. note:: A action can't be registered two times. If it happens, then\n        an assert exception will be raised.\n\n        :param action: The action to be registered.\n        \"\"\"\n        assert action.value not in self.actions\n        self.actions[action.value] = action", "label": 1}
{"code": "function(captions) {\n        var VTT_BODY = ['WEBVTT\\n']; //header\n        captions.forEach(function(caption) {\n            if (caption.text.length > 0 && validateText(caption.text)) {\n                VTT_BODY.push(module.exports.formatTime(caption.startTimeMicro) + ' --> ' + module.exports.formatTime(caption.endTimeMicro));\n                VTT_BODY.push(module.exports.renderMacros(caption.text) + '\\n');\n            }\n        });\n        return VTT_BODY.join('\\n');\n    }", "label": 3}
{"code": "def path_for_doc(self, doc_id):\n        \"\"\"Returns doc_dir and doc_filepath for doc_id.\n        \"\"\"\n        full_path = self.path_for_doc_fn(self.repo, doc_id)\n        # _LOG.debug('>>>>>>>>>> GitActionBase.path_for_doc_fn: {}'.format(self.path_for_doc_fn))\n        # _LOG.debug('>>>>>>>>>> GitActionBase.path_for_doc returning: [{}]'.format(full_path))\n        return full_path", "label": 1}
{"code": "def postIncidents(self, name, message, status, visible, **kwargs):\n        '''Create a new incident.\n\n        :param name: Name of the incident\n        :param message: A message (supporting Markdown) to explain more.\n        :param status: Status of the incident.\n        :param visible: Whether the incident is publicly visible.\n        :param component_id: (optional) Component to update.\n        :param component_status: (optional) The status to update the given component with.\n        :param notify: (optional) Whether to notify subscribers.\n        :return: :class:`Response <Response>` object\n        :rtype: requests.Response\n        '''\n\n        kwargs['name'] = name\n        kwargs['message'] = message\n        kwargs['status'] = status\n        kwargs['visible'] = visible\n        return self.__postRequest('/incidents', kwargs)", "label": 1}
{"code": "public static policydataset get(nitro_service service, String name) throws Exception{\n\t\tpolicydataset obj = new policydataset();\n\t\tobj.set_name(name);\n\t\tpolicydataset response = (policydataset) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function append($familyName, $qualifier, $value)\n    {\n        $this->rules[] = (new ReadModifyWriteRule)\n            ->setFamilyName($familyName)\n            ->setColumnQualifier($qualifier)\n            ->setAppendValue($value);\n        return $this;\n    }", "label": 2}
{"code": "function (domObject) {\n                    var selector = this._selector;\n                    if (selector) {\n                        if (this._globalSelector) {\n                            return document.querySelector(selector);\n                        } else {\n                            return domObject.querySelector(selector);\n                        }\n                    }\n                    return undefined;\n                }", "label": 3}
{"code": "function convertUrlSegmentToRegex(segment) {\n\n    // if it has this format \"{stuff}\" - then it's regex-y\n    var beginIdx = segment.indexOf('{');\n    var endIdx = segment.indexOf('}');\n\n    if (beginIdx < 0) {\n        return segment;\n    }\n\n    // if capturing regex and trim trailing \"}\"\n    // this could be a named regex {id:[0-9]+} or just name {companySlug}\n    var pieces = segment.split(':');\n    if (pieces.length === 2) {\n        if ( pieces[1] === (urlPathPatternSymbol + '}') ) {\n            // special case where we want to capture the whole remaining path, even slashes, like /search/a/b/c/\n            return urlPathPattern;\n        }\n        else {\n            return '(' + pieces[1].substring(0, pieces[1].length - 1) + ')';\n        }\n    }\n    else if (pieces.length === 1) {\n        return segment.substring(0, beginIdx) + '[^\\\\/]+' + segment.substring(endIdx + 1);\n    }\n    else {\n        throw new Error('Weird URL segment- don\\'t know how to parse! ' + segment);\n    }\n}", "label": 3}
{"code": "private function imageObject($encode)\n    {\n        if ($this->type === self::TYPE_BYTES) {\n            $bytes = (string) $this->image;\n\n            return [\n                'content' => ($encode) ? base64_encode($bytes) : $bytes\n            ];\n        }\n\n        if ($this->type === self::TYPE_STRING) {\n            $string = $this->image;\n\n            return [\n                'content' => ($encode) ? base64_encode($string) : $string\n            ];\n        }\n\n        return [\n            'source' => [\n                'imageUri' => $this->image\n            ]\n        ];\n    }", "label": 2}
{"code": "def getResourceFile(self, pid, filename, destination=None):\n        \"\"\" Get a file within a resource.\n\n        :param pid: The HydroShare ID of the resource\n        :param filename: String representing the name of the resource file to get.\n        :param destination: String representing the directory to save the resource file to. If None, a stream\n            to the resource file will be returned instead.\n        :return: The path of the downloaded file (if destination was specified), or a stream to the resource\n            file.\n\n        :raises: HydroShareArgumentException if any parameters are invalid.\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n        \"\"\"\n        url = \"{url_base}/resource/{pid}/files/{filename}\".format(url_base=self.url_base,\n                                                                  pid=pid,\n                                                                  filename=filename)\n\n        if destination:\n            if not os.path.isdir(destination):\n                raise HydroShareArgumentException(\"{0} is not a directory.\".format(destination))\n            if not os.access(destination, os.W_OK):\n                raise HydroShareArgumentException(\"You do not have write permissions to directory '{0}'.\".format(destination))\n\n        r = self._request('GET', url, stream=True)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('GET', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid, filename))\n            else:\n                raise HydroShareHTTPException((url, 'GET', r.status_code))\n\n        if destination is None:\n            return r.iter_content(STREAM_CHUNK_SIZE)\n        else:\n            filepath = os.path.join(destination, filename)\n            with open(filepath, 'wb') as fd:\n                for chunk in r.iter_content(STREAM_CHUNK_SIZE):\n                    fd.write(chunk)\n            return filepath", "label": 1}
{"code": "function(obj){\n\tvar hasOwnKey = obj[canSymbol.for(\"can.hasOwnKey\")];\n\tif(hasOwnKey) {\n\t\treturn hasOwnKey.bind(obj);\n\t} else {\n\t\tvar map = makeMap( shapeReflections.getOwnEnumerableKeys(obj) );\n\t\treturn function(key) {\n\t\t\treturn map.get(key);\n\t\t};\n\t}\n}", "label": 3}
{"code": "def color(x, y, method)\n      Kernel.raise ArgumentError, \"Unknown PaintMethod: #{method}\" unless PAINT_METHOD_NAMES.key?(method.to_i)\n      primitive \"color #{x},#{y},#{PAINT_METHOD_NAMES[method.to_i]}\"\n    end", "label": 4}
{"code": "protected function setupRouteProperties(Request $request, $route)\n    {\n        list($this->uri, $this->methods, $this->action) = $this->adapter->getRouteProperties($route, $request);\n\n        $this->versions = Arr::pull($this->action, 'version');\n        $this->conditionalRequest = Arr::pull($this->action, 'conditionalRequest', true);\n        $this->middleware = (array) Arr::pull($this->action, 'middleware', []);\n        $this->throttle = Arr::pull($this->action, 'throttle');\n        $this->scopes = Arr::pull($this->action, 'scopes', []);\n        $this->authenticationProviders = Arr::pull($this->action, 'providers', []);\n        $this->rateLimit = Arr::pull($this->action, 'limit', 0);\n        $this->rateExpiration = Arr::pull($this->action, 'expires', 0);\n\n        // Now that the default route properties have been set we'll go ahead and merge\n        // any controller properties to fully configure the route.\n        $this->mergeControllerProperties();\n\n        // If we have a string based throttle then we'll new up an instance of the\n        // throttle through the container.\n        if (is_string($this->throttle)) {\n            $this->throttle = $this->container->make($this->throttle);\n        }\n    }", "label": 2}
{"code": "function _nthchild($f, $c)\n\t{\n\t\t// $f is formula e.g. 2N+1 split into a preg_match array\n\t\t// $c is the comparator value e.g row or column number\n\t\t$c += 1;\n\t\t$select = false;\n\n\t\t$f_count = count($f);\n\t\tif ($f[0] === 'ODD') {\n\t\t\t$a = 2;\n\t\t\t$b = 1;\n\t\t} elseif ($f[0] === 'EVEN') {\n\t\t\t$a = 2;\n\t\t\t$b = 0;\n\t\t} elseif ($f_count === 2) {\n\t\t\t$a = 0;\n\t\t\t$b = $f[1] + 0;\n\t\t} // e.g. (+6)\n\t\telseif ($f_count === 3) {  // e.g. (2N)\n\t\t\tif ($f[2] == '') {\n\t\t\t\t$a = 1;\n\t\t\t} elseif ($f[2] == '-') {\n\t\t\t\t$a = -1;\n\t\t\t} else {\n\t\t\t\t$a = $f[2] + 0;\n\t\t\t}\n\t\t\t$b = 0;\n\t\t} elseif ($f_count === 4) {  // e.g. (2N+6)\n\t\t\tif ($f[2] == '') {\n\t\t\t\t$a = 1;\n\t\t\t} elseif ($f[2] == '-') {\n\t\t\t\t$a = -1;\n\t\t\t} else {\n\t\t\t\t$a = $f[2] + 0;\n\t\t\t}\n\t\t\t$b = $f[3] + 0;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t\tif ($a > 0) {\n\t\t\tif (((($c % $a) - $b) % $a) === 0 && $c >= $b) {\n\t\t\t\t$select = true;\n\t\t\t}\n\t\t} elseif ($a == 0) {\n\t\t\tif ($c == $b) {\n\t\t\t\t$select = true;\n\t\t\t}\n\t\t} else {  // if ($a<0)\n\t\t\tif (((($c % $a) - $b) % $a) === 0 && $c <= $b) {\n\t\t\t\t$select = true;\n\t\t\t}\n\t\t}\n\t\treturn $select;\n\t}", "label": 2}
{"code": "private long getTotalUploadSize() throws IOException {\n        long size = 0;\n        for (Map.Entry<String, File> entry : files.entrySet()) {\n            size += entry.getValue().length();\n        }\n\n        for (Map.Entry<String, InputStream> entry : fileStreams.entrySet()) {\n            size += entry.getValue().available();\n        }\n        return size;\n    }", "label": 0}
{"code": "public static double calculateBoundedness(double D, int N, double timelag, double confRadius){\n\t\tdouble r = confRadius;\n\t\tdouble cov_area = a(N)*D*timelag;\n\t\tdouble res = cov_area/(4*r*r);\n\t\treturn res;\n\t}", "label": 0}
{"code": "function () {\n\n\tLOG.warn('appinfo sent to lobby:');\n\tLOG.warn(l_appinfo);\n\t\n    // notify AppManager we're ready\n    l_notifyLobby('SR_APP_READY', l_appinfo, 'SR_APP_READY_RES',\n        function (event) {\n\n            if (event.data.op === true)\n                LOG.sys('SR_APP_READY returns ok', 'l_HandlerPool');\n            else\n                LOG.error('SR_APP_READY returns fail', 'l_HandlerPool');\n\n\t\t\t// call onDone if exists (but just once)\n            if (l_onDone) {\n\t\t\t\tUTIL.safeCall(l_onDone);\n\t\t\t\tl_onDone = undefined;\n\t\t\t}\t\t\t\n        }\n    );\n}", "label": 3}
{"code": "def collection_check_boxes(method, collection, value_method, label_method, options = {}, html_options = {})\n      fieldset_wrapper options[:legend_title] do\n        super(method, collection, value_method, label_method, options, html_options) do |builder|\n          if block_given?\n            yield builder\n          else\n            builder.label { builder.check_box + builder.text }\n          end\n        end\n      end\n    end", "label": 4}
{"code": "function createExport(exportOptions, content) {\n    if (!content) return content;\n\n    const type = exportOptions.type;\n    const name = exportOptions.name;\n    const exportFunction = exportFabric(type);\n\n    return exportFunction(name, content);\n}", "label": 3}
{"code": "public function wait_for_pending_acks($timeout = 0)\n    {\n        $functions = array(\n            $this->waitHelper->get_wait('basic.ack'),\n            $this->waitHelper->get_wait('basic.nack'),\n        );\n\n        while (count($this->published_messages) !== 0) {\n            if ($timeout > 0) {\n                $this->wait($functions, true, $timeout);\n            } else {\n                $this->wait($functions);\n            }\n        }\n    }", "label": 2}
{"code": "function(userId) {\n    return new Promise((resolve, reject) => {\n      this._start()\n          .uri('/api/user')\n          .urlSegment(userId)\n          .get()\n          .go(this._responseHandler(resolve, reject));\n    });\n  }", "label": 3}
{"code": "public function setStartDate($date, $inclusive = null)\n    {\n        if (!$date = call_user_func([$this->dateClass, 'make'], $date)) {\n            throw new InvalidArgumentException('Invalid start date.');\n        }\n\n        $this->startDate = $date;\n\n        if ($inclusive !== null) {\n            $this->toggleOptions(static::EXCLUDE_START_DATE, !$inclusive);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def static_build(values)\n      hash_content = values.group_by(&:key).map do |key, values_for_key|\n        \"#{frozen_string(key)} => #{merged_value(key, values_for_key)}\"\n      end.join(', ')\n\n      arguments = [@is_html, @attr_wrapper, @escape_attrs, @hyphenate_data_attrs]\n      code = \"::Haml::AttributeBuilder.build_attributes\"\\\n        \"(#{arguments.map { |a| Haml::Util.inspect_obj(a) }.join(', ')}, { #{hash_content} })\"\n      [:static, eval(code).to_s]\n    end", "label": 4}
{"code": "func AuthGroupPermissionByGroupIDPermissionID(db XODB, groupID float64, permissionID float64) (*AuthGroupPermission, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, group_id, permission_id ` +\n\t\t`FROM django.auth_group_permissions ` +\n\t\t`WHERE group_id = :1 AND permission_id = :2`\n\n\t// run query\n\tXOLog(sqlstr, groupID, permissionID)\n\tagp := AuthGroupPermission{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, groupID, permissionID).Scan(&agp.ID, &agp.GroupID, &agp.PermissionID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &agp, nil\n}", "label": 5}
{"code": "def is_reparse_point(path):\n\t\"\"\"\n\tDetermine if the given path is a reparse point.\n\tReturn False if the file does not exist or the file attributes cannot\n\tbe determined.\n\t\"\"\"\n\tres = api.GetFileAttributes(path)\n\treturn (\n\t\tres != api.INVALID_FILE_ATTRIBUTES\n\t\tand bool(res & api.FILE_ATTRIBUTE_REPARSE_POINT)\n\t)", "label": 1}
{"code": "function scrapVideo(window){\n   var $ = window.$;\n   var url = window.location.href;\n   var thumbs = [];\n\n   // Open Graph protocol by Facebook: <meta property=\"og:video\" content=\"(*)\"/>\n   $('meta').each(function(){\n      var property = $(this).attr('property');\n      var content = $(this).attr('content');\n      if(property === 'og:video' && content){\n         thumbs.push(utils.toURL(content));\n      }\n   });\n\n   $('video, embed').each(function(){\n      var src = $(this).attr('src');\n      if(src) thumbs.push(utils.toURL(src,url));\n   });\n\n   return thumbs;\n}", "label": 3}
{"code": "def retrieve\n    fail \"Provider #{provider.class.name} is not functional on this host\" if self.provider.is_a?(Puppet::Provider) and ! provider.class.suitable?\n\n    result = Puppet::Resource.new(self.class, title)\n\n    # Provide the name, so we know we'll always refer to a real thing\n    result[:name] = self[:name] unless self[:name] == title\n\n    if ensure_prop = property(:ensure) or (self.class.needs_ensure_retrieved and self.class.validattr?(:ensure) and ensure_prop = newattr(:ensure))\n      result[:ensure] = ensure_state = ensure_prop.retrieve\n    else\n      ensure_state = nil\n    end\n\n    properties.each do |property|\n      next if property.name == :ensure\n      if ensure_state == :absent\n        result[property] = :absent\n      else\n        result[property] = property.retrieve\n      end\n    end\n\n    result\n  end", "label": 4}
{"code": "function findViewForLine(cm, lineN) {\n    if (lineN >= cm.display.viewFrom && lineN < cm.display.viewTo)\n      return cm.display.view[findViewIndex(cm, lineN)];\n    var ext = cm.display.externalMeasured;\n    if (ext && lineN >= ext.lineN && lineN < ext.lineN + ext.size)\n      return ext;\n  }", "label": 3}
{"code": "public static void startMockJadexAgent(String agent_name,\n            String agent_path, MockConfiguration configuration,\n            BeastTestCase story) {\n\n        story.startAgent(agent_name, agent_path);\n        story.sendMessageToAgent(agent_name, SFipa.INFORM, configuration);\n        story.setExecutionTime(2000); // To get time to execute the DF rename goal\n    }", "label": 0}
{"code": "def put(self, filepath):\n        \"\"\"\n        Change the group or permissions of the specified file. Action\n        must be specified when calling this method.\n        \"\"\"\n        action = self.get_body_argument('action')\n\n        if action['action'] == 'update_group':\n            newgrp = action['group']\n            try:\n                self.fs.update_group(filepath,newgrp)\n                self.write({'msg':'Updated group for {}'.format(filepath)})\n            except OSError:\n                raise tornado.web.HTTPError(404)\n        elif action['action'] == 'update_permissions':\n            newperms = action['permissions']\n            try:\n                self.fs.update_permissions(filepath,newperms)\n                self.write({'msg':'Updated permissions for {}'.format(filepath)})\n            except OSError:\n                raise tornado.web.HTTPError(404)\n        else:\n            raise tornado.web.HTTPError(400)", "label": 1}
{"code": "func (c *Manager) GetCategory(ctx context.Context, id string) (*Category, error) {\n\tif isName(id) {\n\t\tcat, err := c.GetCategories(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor i := range cat {\n\t\t\tif cat[i].Name == id {\n\t\t\t\treturn &cat[i], nil\n\t\t\t}\n\t\t}\n\t}\n\turl := internal.URL(c, internal.CategoryPath).WithID(id)\n\tvar res Category\n\treturn &res, c.Do(ctx, url.Request(http.MethodGet), &res)\n}", "label": 5}
{"code": "def number_match?(number, regex)\n      match = number.match(cr(\"^(?:#{regex})$\"))\n      match && match.to_s.length == number.length\n    end", "label": 4}
{"code": "def read(length)\n      handle_errors do\n        data = read_from_socket(length)\n        raise IOError unless (data.length > 0 || length == 0)\n        while data.length < length\n          chunk = read_from_socket(length - data.length)\n          raise IOError unless (chunk.length > 0 || length == 0)\n          data << chunk\n        end\n        data\n      end\n    end", "label": 4}
{"code": "final void dispatchToAppender(final String message) {\n    // dispatch a copy, since events should be treated as being immutable\n    final FoundationFileRollingAppender appender = this.getSource();\n    if (appender != null) {\n      appender.append(new FileRollEvent(this, message));\n    }\n  }", "label": 0}
{"code": "function(data) {\n        var json = {},\n            index = 0,\n            id,\n            text,\n            startTimeMicro,\n            durationMicro,\n            invalidText = /^\\s+$/,\n            endTimeMicro,\n            time,\n            lastNonEmptyLine;\n\n        function getLastNonEmptyLine(linesArray) {\n            var idx = linesArray.length - 1;\n            while (idx >= 0 && !linesArray[idx]) {\n                idx--;\n            }\n            return idx;\n        }\n\n        json.captions = [];\n        lastNonEmptyLine = getLastNonEmptyLine(data) + 1;\n\n        while (index < lastNonEmptyLine) {\n            if (data[index]) {\n                text = [];\n                //Find the ID line..\n                if (/^[0-9]+$/.test(data[index])) {\n                    //found id line\n                    id = parseInt(data[index], 10);\n                    index++;\n                }\n                if (!data[index].split) {\n                    // for some reason this is not a string\n                    index++;\n                    continue;\n                }\n                //next line has to be timestamp right? right?\n                time = data[index].split(/[\\t ]*-->[\\t ]*/);\n                startTimeMicro = module.exports.translateTime(time[0]);\n                endTimeMicro = module.exports.translateTime(time[1]);\n                durationMicro = parseInt(parseInt(endTimeMicro, 10) - parseInt(startTimeMicro, 10), 10);\n                if (!startTimeMicro || !endTimeMicro) {\n                    // no valid timestamp\n                    index++;\n                    continue;\n                }\n                index++;\n                while (data[index]) {\n                    text.push(data[index]);\n                    index++;\n                    if (!data[index] && !invalidText.test(text.join('\\n'))) {\n                        json.captions.push({\n                            id: id,\n                            text: module.exports.addMacros(text.join('\\n')),\n                            startTimeMicro: startTimeMicro,\n                            durationSeconds: parseInt(durationMicro / 1000, 10) / 1000,\n                            endTimeMicro: endTimeMicro\n                        });\n                        break;\n                    }\n                }\n            }\n            index++;\n        }\n        return json.captions;\n\n    }", "label": 3}
{"code": "def read_float\n      s = read_string(cache: false)\n      result = if s == 'nan'\n                 0.0 / 0\n               elsif s == 'inf'\n                 1.0 / 0\n               elsif s == '-inf'\n                 -1.0 / 0\n               else\n                 s.to_f\n               end\n      @object_cache << result\n      result\n    end", "label": 4}
{"code": "func PgDependsByClassidObjidObjsubid(db XODB, classid pgtypes.Oid, objid pgtypes.Oid, objsubid int) ([]*PgDepend, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, classid, objid, objsubid, refclassid, refobjid, refobjsubid, deptype ` +\n\t\t`FROM pg_catalog.pg_depend ` +\n\t\t`WHERE classid = $1 AND objid = $2 AND objsubid = $3`\n\n\t// run query\n\tXOLog(sqlstr, classid, objid, objsubid)\n\tq, err := db.Query(sqlstr, classid, objid, objsubid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*PgDepend{}\n\tfor q.Next() {\n\t\tpd := PgDepend{}\n\n\t\t// scan\n\t\terr = q.Scan(&pd.Tableoid, &pd.Cmax, &pd.Xmax, &pd.Cmin, &pd.Xmin, &pd.Ctid, &pd.Classid, &pd.Objid, &pd.Objsubid, &pd.Refclassid, &pd.Refobjid, &pd.Refobjsubid, &pd.Deptype)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &pd)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def national_and_data(data, country_match, not_valid = false)\n      result = data.select { |k, _v| k != :types && k != :formats }\n      phone = country_match.to_a.last\n      result[:national] = phone\n      result[:format] = number_format(phone, data[Core::FORMATS])\n      result.merge! all_number_types(phone, data[Core::TYPES], not_valid)\n      result[:valid] = [] if not_valid\n\n      { result[:id] => result }\n    end", "label": 4}
{"code": "def text(params = {})\n      # TODO: some helper for key transformation for two supported formats\n      k = key.split('.')\n      k.unshift('activity') if k.first != 'activity'\n      k = k.join('.')\n\n      I18n.t(k, parameters.merge(params) || {})\n    end", "label": 4}
{"code": "def record_result(self, res, prg=''):\n        \"\"\"\n        record the output of the command. Records the result, can have \n        multiple results, so will need to work out a consistent way to aggregate this\n        \"\"\"\n        self._log(self.logFileResult , force_to_string(res), prg)", "label": 1}
{"code": "public function readOnlyTransaction(array $options = [])\n    {\n        $transaction = $this->operation->beginTransaction([\n            // if empty, force request to encode as {} rather than [].\n            'readOnly' => $this->pluck('transactionOptions', $options, false) ?: (object) []\n        ], $options);\n\n        return new ReadOnlyTransaction(\n            $this->operation,\n            $this->projectId,\n            $transaction\n        );\n    }", "label": 2}
{"code": "def process(self, txt, mode):\n        \"\"\"\n        Top level function to process the command, mainly\n        depending on mode.\n        This should work by using the function name defined\n        in all_commamnds\n        \"\"\"\n        result = ''\n        if mode == 'ADD':  # already in add mode, so add data\n            if txt in self.all_commands['cmd'][0]:\n                self.show_output('Returning to Command mode')\n                mode = 'COMMAND'\n                self.prompt = '> '\n            else:\n                self.show_output('Adding Text : ', txt)\n                result = self.cmd_add(txt)\n        elif mode == 'QUERY':\n            if txt in self.all_commands['cmd'][0]:\n                self.show_output('Returning to Command mode')\n                mode = 'COMMAND'\n                self.prompt = '> '\n            else:\n                self.show_output('Query : ', txt)\n                result = self.cmd_query(txt)\n        else:   \n            if txt in self.all_commands['exit'][0]:\n                self.cmd_exit()\n                \n            elif txt in self.all_commands['help'][0]:\n                self.cmd_help()\n                \n            elif txt in self.all_commands['cmd'][0]:\n                result = 'Returning to Command mode'\n                mode = 'COMMAND'\n                self.prompt = '> '\n                \n            elif txt in self.all_commands['add'][0]:\n                result = 'Entering Add mode'\n                mode = 'ADD'\n                self.prompt = 'ADD > '\n            \n            elif txt in self.all_commands['query'][0]:\n                result = 'Entering Query mode'\n                mode = 'QUERY'\n                self.prompt = '?? > '\n            else:\n                result = 'Unknown command - type help for list of commands'\n\n        return result, mode", "label": 1}
{"code": "function parseDate(fmt, date) {\n    var indexMap = {}; // contains reGroupPosition -> typeLetter or [typeLetter, value array]\n    var reIndex = 1;\n    var timezoneOffsetMatch;\n    var timezoneIndex;\n    var match;\n\n    var format = replace(fmt, /^\\?/);\n    if (format!=fmt && !trim(date))\n      return _null;\n\n    if (match = /^\\[([+-])(\\d\\d)(\\d\\d)\\]\\s*(.*)/.exec(format)) {\n      timezoneOffsetMatch = match;\n      format = match[4];\n    }\n\n    var parser = new RegExp(format.replace(/(.)(\\1*)(?:\\[([^\\]]*)\\])?/g, function(wholeMatch, placeholderChar, placeholderDigits, param) {\n      if (/[dmhkyhs]/i.test(placeholderChar)) {\n        indexMap[reIndex++] = placeholderChar;\n        var plen = placeholderDigits.length+1;\n        return \"(\\\\d\"+(plen<2?\"+\":(\"{1,\"+plen+\"}\"))+\")\";\n      }\n      else if (placeholderChar == 'z') {\n        timezoneIndex = reIndex;\n        reIndex += 3;\n        return \"([+-])(\\\\d\\\\d)(\\\\d\\\\d)\";\n      }\n      else if (/[Nna]/.test(placeholderChar)) {\n        indexMap[reIndex++] = [placeholderChar, param && param.split(',')];\n        return \"([a-zA-Z\\\\u0080-\\\\u1fff]+)\";\n      }\n      else if (/w/i.test(placeholderChar))\n        return \"[a-zA-Z\\\\u0080-\\\\u1fff]+\";\n      else if (/\\s/.test(placeholderChar))\n        return \"\\\\s+\";\n      else\n        return escapeRegExp(wholeMatch);\n    }));\n\n    if (!(match = parser.exec(date)))\n      return undef;\n\n    var ctorArgs = [0, 0, 0, 0, 0, 0,  0];\n    for (var i = 1; i < reIndex; i++) {\n      var matchVal = match[i];\n      var indexEntry = indexMap[i];\n      if (isList(indexEntry)) { // for a, n or N\n        var placeholderChar = indexEntry[0];\n        var mapEntry  = PARSE_DATE_MAP[placeholderChar];\n        var ctorIndex = mapEntry[0];\n        var valList = indexEntry[1] || mapEntry[1];\n        var listValue = find(valList, function(v, index) { if (startsWith(matchVal.toLowerCase(), v.toLowerCase())) return index; });\n        if (listValue == _null)\n          return undef;\n        if (placeholderChar == 'a')\n          ctorArgs[ctorIndex] += listValue * 12;\n        else\n          ctorArgs[ctorIndex] = listValue;\n      }\n      else if (indexEntry) { // for numeric values (yHmMs)\n        var value = parseFloat(matchVal);\n        var mapEntry  = PARSE_DATE_MAP[indexEntry];\n        if (isList(mapEntry))\n          ctorArgs[mapEntry[0]] += value - mapEntry[1];\n        else\n          ctorArgs[mapEntry] += value;\n      }\n    }\n    var d = new Date(ctorArgs[0], ctorArgs[1], ctorArgs[2], ctorArgs[3], ctorArgs[4], ctorArgs[5], ctorArgs[6]);\n    return dateAdd(d, 'minutes', -getTimezone(timezoneOffsetMatch, 1, d) - getTimezone(match, timezoneIndex, d));\n  }", "label": 3}
{"code": "def fetch_extra_data(resource):\n    \"\"\"Return a dict with extra data retrieved from cern oauth.\"\"\"\n    person_id = resource.get('PersonID', [None])[0]\n    identity_class = resource.get('IdentityClass', [None])[0]\n    department = resource.get('Department', [None])[0]\n\n    return dict(\n        person_id=person_id,\n        identity_class=identity_class,\n        department=department\n    )", "label": 1}
{"code": "func Drop(path string) {\n\tpathMutex.Lock()\n\tdefer pathMutex.Unlock()\n\n\tdelete(pathMap, path)\n}", "label": 5}
{"code": "def to_xml_string(str = '')\n      str << '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n      str << ('<cp:coreProperties xmlns:cp=\"' << CORE_NS << '\" xmlns:dc=\"' << CORE_NS_DC << '\" ')\n      str << ('xmlns:dcmitype=\"' << CORE_NS_DCMIT << '\" xmlns:dcterms=\"' << CORE_NS_DCT << '\" ')\n      str << ('xmlns:xsi=\"' << CORE_NS_XSI << '\">')\n      str << ('<dc:creator>' << self.creator << '</dc:creator>')\n      str << ('<dcterms:created xsi:type=\"dcterms:W3CDTF\">' << (created || Time.now).strftime('%Y-%m-%dT%H:%M:%S') << 'Z</dcterms:created>')\n      str << '<cp:revision>0</cp:revision>'\n      str << '</cp:coreProperties>'\n    end", "label": 4}
{"code": "public static int cudnnConvolutionForward(\n        cudnnHandle handle, \n        Pointer alpha, \n        cudnnTensorDescriptor xDesc, \n        Pointer x, \n        cudnnFilterDescriptor wDesc, \n        Pointer w, \n        cudnnConvolutionDescriptor convDesc, \n        int algo, \n        Pointer workSpace, \n        long workSpaceSizeInBytes, \n        Pointer beta, \n        cudnnTensorDescriptor yDesc, \n        Pointer y)\n    {\n        return checkResult(cudnnConvolutionForwardNative(handle, alpha, xDesc, x, wDesc, w, convDesc, algo, workSpace, workSpaceSizeInBytes, beta, yDesc, y));\n    }", "label": 0}
{"code": "public static function georadius(CommandInterface $command, $prefix)\n    {\n        if ($arguments = $command->getArguments()) {\n            $arguments[0] = \"$prefix{$arguments[0]}\";\n            $startIndex = $command->getId() === 'GEORADIUS' ? 5 : 4;\n\n            if (($count = count($arguments)) > $startIndex) {\n                for ($i = $startIndex; $i < $count; ++$i) {\n                    switch (strtoupper($arguments[$i])) {\n                        case 'STORE':\n                        case 'STOREDIST':\n                            $arguments[$i] = \"$prefix{$arguments[++$i]}\";\n                            break;\n\n                    }\n                }\n            }\n\n            $command->setRawArguments($arguments);\n        }\n    }", "label": 2}
{"code": "function _gpfEventsIsValidHandler (eventHandler) {\n    var type = typeof eventHandler,\n        validator = _gpfEventsHandlerValidators[type];\n    if (validator === undefined) {\n        return false;\n    }\n    return validator(eventHandler);\n}", "label": 3}
{"code": "def getWordList(ipFile, delim):\n    \"\"\"\n    extract a unique list of words and have line numbers that word appears\n    \"\"\"\n    indexedWords = {}\n    totWords = 0\n    totLines = 0\n    with codecs.open(ipFile, \"r\",encoding='utf-8', errors='replace') as f:\n        for line in f:\n            totLines = totLines + 1\n            words = multi_split(line, delim)\n            totWords = totWords + len(words)\n            for word in words:\n                cleanedWord = word.lower().strip()\n                if cleanedWord not in indexedWords:\n                    indexedWords[cleanedWord] =  str(totLines)\n                else:\n                    indexedWords[cleanedWord] = indexedWords[cleanedWord] + ' ' + str(totLines)\n    return totWords, totLines, indexedWords", "label": 1}
{"code": "function (mehegan, cache) {\n  if (mehegan instanceof Mehegan) return mehegan;\n\n  // If no cache is provided, return string as Mehegan symbol\n  if (!cache) return fromString(mehegan);\n\n  // Otherwise, try to retrieve symbol from cache, creating a new symbol if it's not found\n  if (!cache[mehegan]) cache[mehegan] = fromString(mehegan);\n  return cache[mehegan];\n}", "label": 3}
{"code": "public static base_responses delete(nitro_service client, route resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\troute deleteresources[] = new route[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tdeleteresources[i] = new route();\n\t\t\t\tdeleteresources[i].network = resources[i].network;\n\t\t\t\tdeleteresources[i].netmask = resources[i].netmask;\n\t\t\t\tdeleteresources[i].gateway = resources[i].gateway;\n\t\t\t\tdeleteresources[i].td = resources[i].td;\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setMutations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Bigtable\\V2\\Mutation::class);\n        $this->mutations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def retrieve_payment(location_id, payment_id, opts = {})\n      data, _status_code, _headers = retrieve_payment_with_http_info(location_id, payment_id, opts)\n      return data\n    end", "label": 4}
{"code": "func prepareOverlay(lower, treeStoreID, cdir, dest, appName, lbl string,\n\tgid int, fm os.FileMode) (*overlay.MountCfg, error) {\n\tfi, err := os.Stat(lower)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\timgMode := fi.Mode()\n\n\tdst := path.Join(dest, \"rootfs\")\n\tif err := os.MkdirAll(dst, imgMode); err != nil {\n\t\treturn nil, err\n\t}\n\n\toverlayDir := path.Join(cdir, \"overlay\")\n\tif err := os.MkdirAll(overlayDir, fm); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Since the parent directory (rkt/pods/$STATE/$POD_UUID) has the 'S_ISGID' bit, here\n\t// we need to explicitly turn the bit off when creating this overlay\n\t// directory so that it won't inherit the bit. Otherwise the files\n\t// created by users within the pod will inherit the 'S_ISGID' bit\n\t// as well.\n\tif err := os.Chmod(overlayDir, fm); err != nil {\n\t\treturn nil, err\n\t}\n\n\timgDir := path.Join(overlayDir, treeStoreID)\n\tif err := os.MkdirAll(imgDir, fm); err != nil {\n\t\treturn nil, err\n\t}\n\t// Also make 'rkt/pods/$STATE/$POD_UUID/overlay/$IMAGE_ID' to be readable by 'rkt' group\n\t// As 'rkt' status will read the 'rkt/pods/$STATE/$POD_UUID/overlay/$IMAGE_ID/upper/rkt/status/$APP'\n\t// to get exgid\n\tif err := os.Chown(imgDir, -1, gid); err != nil {\n\t\treturn nil, err\n\t}\n\n\tupper := path.Join(imgDir, \"upper\", appName)\n\tif err := os.MkdirAll(upper, imgMode); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := label.SetFileLabel(upper, lbl); err != nil {\n\t\treturn nil, err\n\t}\n\n\twork := path.Join(imgDir, \"work\", appName)\n\tif err := os.MkdirAll(work, fm); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := label.SetFileLabel(work, lbl); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &overlay.MountCfg{lower, upper, work, dst, lbl}, nil\n}", "label": 5}
{"code": "private function getS3Args($path)\n    {\n        $parts = explode('/', str_replace('s3://', '', $path), 2);\n        $args = ['Bucket' => $parts[0]];\n        if (isset($parts[1])) {\n            $args['Key'] = $parts[1];\n        }\n\n        return $args;\n    }", "label": 2}
{"code": "function iterateObject(obj, fn) {\n    var i = 0\n      , keys = []\n      ;\n\n    if (Array.isArray(obj)) {\n        for (; i < obj.length; ++i) {\n            if (fn(obj[i], i, obj) === false) {\n                break;\n            }\n        }\n    } else if (typeof obj === \"object\" && obj !== null) {\n        keys = Object.keys(obj);\n        for (; i < keys.length; ++i) {\n            if (fn(obj[keys[i]], keys[i], obj) === false) {\n                break;\n            }\n        }\n    }\n}", "label": 3}
{"code": "@Override\r\n  public boolean add(E o) {\r\n    Integer index = indexes.get(o);\r\n    if (index == null && ! locked) {\r\n      index = objects.size();\r\n      objects.add(o);\r\n      indexes.put(o, index);\r\n      return true;\r\n    }\r\n    return false;\r\n  }", "label": 0}
{"code": "private RgbaColor withHsl(int index, float value) {\n        float[] HSL = convertToHsl();\n        HSL[index] = value;\n        return RgbaColor.fromHsl(HSL);\n    }", "label": 0}
{"code": "public static aaa_stats get(nitro_service service) throws Exception{\n\t\taaa_stats obj = new aaa_stats();\n\t\taaa_stats[] response = (aaa_stats[])obj.stat_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "function _visitSpecializations(entities, visitedEntities) {\n  for (var entityName in entities) {\n    if (!visitedEntities.hasOwnProperty(entityName)) {\n      visitedEntities[entityName] = entities[entityName];\n\n      _visitSpecializations(\n        entities[entityName].directSpecializations,\n        visitedEntities\n      );\n    }\n  }\n}", "label": 3}
{"code": "def blastdb(fasta, maxfile = 10000000):\n    \"\"\"\n    make blast db\n    \"\"\"\n    db = fasta.rsplit('.', 1)[0]\n    type = check_type(fasta)\n    if type == 'nucl':\n        type = ['nhr', type]\n    else:\n        type = ['phr', type]\n    if os.path.exists('%s.%s' % (db, type[0])) is False \\\n            and os.path.exists('%s.00.%s' % (db, type[0])) is False:\n        print('# ... making blastdb for: %s' % (fasta), file=sys.stderr)\n        os.system('makeblastdb \\\n                -in %s -out %s -dbtype %s -max_file_sz %s >> log.txt' \\\n                % (fasta, db, type[1], maxfile))\n    else:\n        print('# ... database found for: %s' % (fasta), file=sys.stderr)\n    return db", "label": 1}
{"code": "function Message(name, attrs, opts) {\n  opts = opts || {};\n\n  if (!types.isValidName(name)) {\n    throw new Error(f('invalid message name: %s', name));\n  }\n  this._name = name;\n\n  var recordName = f('org.apache.avro.ipc.%sRequest', name);\n  this._requestType = types.createType({\n    name: recordName,\n    type: 'record',\n    namespace: opts.namespace || '', // Don't leak request namespace.\n    fields: attrs.request\n  }, opts);\n  // We remove the record from the registry to prevent it from being exported\n  // in the protocol's schema.\n  delete opts.registry[recordName];\n\n  if (!attrs.response) {\n    throw new Error('missing response');\n  }\n  this._responseType = types.createType(attrs.response, opts);\n\n  var errors = attrs.errors || [];\n  errors.unshift('string');\n  this._errorType = types.createType(errors, opts);\n\n  this._oneWay = !!attrs['one-way'];\n  if (this._oneWay) {\n    if (this._responseType.getTypeName() !== 'null' || errors.length > 1) {\n      throw new Error('unapplicable one-way parameter');\n    }\n  }\n}", "label": 3}
{"code": "def match(other)\n      other = other.type if other.instance_of? AnnotatedArgType\n      return true if other.instance_of? WildQuery\n      return false unless other.instance_of? MethodType\n      return false unless @ret.match(other.ret)\n      if @block == nil\n        return false unless other.block == nil\n      else\n        return false if other.block == nil\n        return false unless @block.match(other.block)\n      end\n      # Check arg matches; logic is similar to pre_cond\n      states = [[0,0]] # [position in self, position in other]\n      until states.empty?\n        s_arg, o_arg = states.pop\n        return true if s_arg == @args.size && o_arg == other.args.size # everything matches\n        next if s_arg >= @args.size # match not possible, not enough args in self\n        if @args[s_arg].instance_of? DotsQuery then\n          if o_arg == other.args.size\n            # no args left in other, skip ...\n            states << [s_arg+1, o_arg]\n          else\n            states << [s_arg+1, o_arg+1] # match, no more matches to ...\n            states << [s_arg, o_arg+1]   # match, more matches to ... coming\n          end\n        else\n          next if o_arg == other.args.size # match not possible, not enough args in other\n          s_arg_t = @args[s_arg]\n          s_arg_t = s_arg_t.type if s_arg_t.instance_of? AnnotatedArgType\n          o_arg_t = other.args[o_arg]\n          o_arg_t = o_arg_t.type if o_arg_t.instance_of? AnnotatedArgType\n          next unless s_arg_t.match(o_arg_t)\n          states << [s_arg+1, o_arg+1]\n        end\n      end\n      return false\n    end", "label": 4}
{"code": "def locus_read_generator(\n        samfile,\n        chromosome,\n        base1_position_before_variant,\n        base1_position_after_variant,\n        use_duplicate_reads=USE_DUPLICATE_READS,\n        use_secondary_alignments=USE_SECONDARY_ALIGNMENTS,\n        min_mapping_quality=MIN_READ_MAPPING_QUALITY):\n    \"\"\"\n    Generator that yields a sequence of ReadAtLocus records for reads which\n    contain the positions before and after a variant. The actual work to figure\n    out if what's between those positions matches a variant happens later in\n    the `variant_reads` module.\n\n    Parameters\n    ----------\n    samfile : pysam.AlignmentFile\n\n    chromosome : str\n\n    base1_position_before_variant : int\n        Genomic position of reference nucleotide before a variant\n\n    base1_position_after_variant : int\n        Genomic position of reference nucleotide before a variant\n\n    use_duplicate_reads : bool\n        By default, we're ignoring any duplicate reads\n\n    use_secondary_alignments : bool\n        By default we are using secondary alignments, set this to False to\n        only use primary alignments of reads.\n\n    min_mapping_quality : int\n        Drop reads below this mapping quality\n\n    Yields ReadAtLocus objects\n    \"\"\"\n    logger.debug(\n        \"Gathering reads at locus %s: %d-%d\",\n        chromosome,\n        base1_position_before_variant,\n        base1_position_after_variant)\n    base0_position_before_variant = base1_position_before_variant - 1\n    base0_position_after_variant = base1_position_after_variant - 1\n\n    count = 0\n\n    # We get a pileup at the base before the variant and then check to make sure\n    # that reads also overlap the reference position after the variant.\n    #\n    # TODO: scan over a wider interval of pileups and collect reads that don't\n    # overlap the bases before/after a variant due to splicing\n    for pileup_element in pileup_reads_at_position(\n            samfile=samfile,\n            chromosome=chromosome,\n            base0_position=base0_position_before_variant):\n        read = LocusRead.from_pysam_pileup_element(\n            pileup_element,\n            base0_position_before_variant=base0_position_before_variant,\n            base0_position_after_variant=base0_position_after_variant,\n            use_secondary_alignments=use_secondary_alignments,\n            use_duplicate_reads=use_duplicate_reads,\n            min_mapping_quality=min_mapping_quality)\n\n        if read is not None:\n            count += 1\n            yield read\n\n    logger.info(\n        \"Found %d reads overlapping locus %s: %d-%d\",\n        count,\n        chromosome,\n        base1_position_before_variant,\n        base1_position_after_variant)", "label": 1}
{"code": "public void deleteObject(Object object)\r\n    {\r\n        PersistenceBroker broker = null;\r\n        try\r\n        {\r\n            broker = getBroker();\r\n            broker.delete(object);\r\n        }\r\n        finally\r\n        {\r\n            if (broker != null) broker.close();\r\n        }\r\n    }", "label": 0}
{"code": "public static void saveContentMap(Map<String, String> map, File file) throws IOException {\n\n    FileWriter out = new FileWriter(file);\n    for (String key : map.keySet()) {\n      if (map.get(key) != null) {\n        out.write(key.replace(\":\", \"#escapedtwodots#\") + \":\"\n            + map.get(key).replace(\":\", \"#escapedtwodots#\") + \"\\r\\n\");\n      }\n    }\n    out.close();\n  }", "label": 0}
{"code": "func (d *driver) CreateEndpoint(nid, eid string, ifInfo driverapi.InterfaceInfo,\n\tepOptions map[string]interface{}) error {\n\tdefer osl.InitOSContext()()\n\n\tif err := validateID(nid, eid); err != nil {\n\t\treturn err\n\t}\n\tn, err := d.getNetwork(nid)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"network id %q not found\", nid)\n\t}\n\tif ifInfo.MacAddress() != nil {\n\t\treturn fmt.Errorf(\"%s interfaces do not support custom mac address assignment\", ipvlanType)\n\t}\n\tep := &endpoint{\n\t\tid:     eid,\n\t\tnid:    nid,\n\t\taddr:   ifInfo.Address(),\n\t\taddrv6: ifInfo.AddressIPv6(),\n\t}\n\tif ep.addr == nil {\n\t\treturn fmt.Errorf(\"create endpoint was not passed an IP address\")\n\t}\n\t// disallow port mapping -p\n\tif opt, ok := epOptions[netlabel.PortMap]; ok {\n\t\tif _, ok := opt.([]types.PortBinding); ok {\n\t\t\tif len(opt.([]types.PortBinding)) > 0 {\n\t\t\t\tlogrus.Warnf(\"%s driver does not support port mappings\", ipvlanType)\n\t\t\t}\n\t\t}\n\t}\n\t// disallow port exposure --expose\n\tif opt, ok := epOptions[netlabel.ExposedPorts]; ok {\n\t\tif _, ok := opt.([]types.TransportPort); ok {\n\t\t\tif len(opt.([]types.TransportPort)) > 0 {\n\t\t\t\tlogrus.Warnf(\"%s driver does not support port exposures\", ipvlanType)\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := d.storeUpdate(ep); err != nil {\n\t\treturn fmt.Errorf(\"failed to save ipvlan endpoint %.7s to store: %v\", ep.id, err)\n\t}\n\n\tn.addEndpoint(ep)\n\n\treturn nil\n}", "label": 5}
{"code": "def country_prefix(country)\n      country = country.to_s.upcase\n      Phonelib.phone_data[country] && \\\n        Phonelib.phone_data[country][Core::COUNTRY_CODE]\n    end", "label": 4}
{"code": "function writeCollections(drizzleData) {\n  return Promise.all(walkCollections(drizzleData.patterns, drizzleData)).then(\n    writePromises => drizzleData,\n    error => DrizzleError.error(error, drizzleData.options.debug)\n  );\n}", "label": 3}
{"code": "func (c *Client) UpdateSession(req session.UpdateRequest) error {\n\tif err := req.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err := c.PutJSON(c.Endpoint(\"namespaces\", req.Namespace, \"sessions\", string(req.ID)), updateSessionReq{Update: req})\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "public function write_longlong($n)\n    {\n        if ($n < 0) {\n            throw new AMQPInvalidArgumentException('Longlong out of range: ' . $n);\n        }\n\n        // if PHP_INT_MAX is big enough for that\n        // direct $n<=PHP_INT_MAX check is unreliable on 64bit (values close to max) due to limited float precision\n        if (bcadd($n, -PHP_INT_MAX, 0) <= 0) {\n            // trick explained in http://www.php.net/manual/fr/function.pack.php#109328\n            if ($this->is64bits) {\n                list($hi, $lo) = $this->splitIntoQuads($n);\n            } else {\n                $hi = 0;\n                $lo = $n;\n            } //on 32bits hi quad is 0 a priori\n            $this->out .= pack('NN', $hi, $lo);\n        } else {\n            try {\n                $this->out .= self::packBigEndian($n, 8);\n            } catch (AMQPOutOfBoundsException $ex) {\n                throw new AMQPInvalidArgumentException('Longlong out of range: ' . $n, 0, $ex);\n            }\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def self_compare(fastas, id2desc, algorithm):\n    \"\"\"\n    compare genome to self to get the best possible bit score for each ORF\n    \"\"\"\n    for fasta in fastas:\n        blast = open(search(fasta, fasta, method = algorithm, alignment = 'local'))\n        for hit in best_blast(blast, 1):\n            id, bit = hit[0].split()[0], float(hit[-1])\n            id2desc[id].append(bit)\n    return id2desc", "label": 1}
{"code": "func (m *MockIndex) Other() hash.Hash {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"Other\")\n\tret0, _ := ret[0].(hash.Hash)\n\treturn ret0\n}", "label": 5}
{"code": "function checkContainingStores(objStoreNames) {\n    return objStoreNames.every(function (storeName) {\n        return (indexOf.call(this.database.objectStoreNames, storeName) !== -1);\n    }, this);\n}", "label": 3}
{"code": "func NewTLSServer(handler http.Handler) *Server {\n\tts := NewUnstartedServer(handler, \"\")\n\tts.StartTLS()\n\treturn ts\n}", "label": 5}
{"code": "func (a *AuthCommand) GenerateKeys() error {\n\tkeygen, err := native.New(context.TODO(), native.PrecomputeKeys(0))\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdefer keygen.Close()\n\tprivBytes, pubBytes, err := keygen.GenerateKeyPair(\"\")\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\terr = ioutil.WriteFile(a.genPubPath, pubBytes, 0600)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\terr = ioutil.WriteFile(a.genPrivPath, privBytes, 0600)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\tfmt.Printf(\"wrote public key to: %v and private key to: %v\\n\", a.genPubPath, a.genPrivPath)\n\treturn nil\n}", "label": 5}
{"code": "def limit(value = nil, &block)\n      chain { criteria.update_request_options size: block || Integer(value) }\n    end", "label": 4}
{"code": "def initialize_value_objects\n      @value_objects = SimpleTypedList.new Cfvo\n      @value_objects.concat [Cfvo.new(:type => :percent, :val => 0), Cfvo.new(:type => :percent, :val => 33), Cfvo.new(:type => :percent, :val => 67)]\n      @value_objects.lock\n    end", "label": 4}
{"code": "public static function invisibilityOfElementWithText(WebDriverBy $by, $text)\n    {\n        return new static(\n            function (WebDriver $driver) use ($by, $text) {\n                try {\n                    return !($driver->findElement($by)->getText() === $text);\n                } catch (NoSuchElementException $e) {\n                    return true;\n                } catch (StaleElementReferenceException $e) {\n                    return true;\n                }\n            }\n        );\n    }", "label": 2}
{"code": "function(message, title, options) {\n        this.message = message;\n        this.title = title || MessageBox.defaultTitle;\n        this.options = options || MessageBox.defaultOptions;\n    }", "label": 3}
{"code": "func (ev *EventKey) Name() string {\n\ts := \"\"\n\tm := []string{}\n\tif ev.mod&ModShift != 0 {\n\t\tm = append(m, \"Shift\")\n\t}\n\tif ev.mod&ModAlt != 0 {\n\t\tm = append(m, \"Alt\")\n\t}\n\tif ev.mod&ModMeta != 0 {\n\t\tm = append(m, \"Meta\")\n\t}\n\tif ev.mod&ModCtrl != 0 {\n\t\tm = append(m, \"Ctrl\")\n\t}\n\n\tok := false\n\tif s, ok = KeyNames[ev.key]; !ok {\n\t\tif ev.key == KeyRune {\n\t\t\ts = \"Rune[\" + string(ev.ch) + \"]\"\n\t\t} else {\n\t\t\ts = fmt.Sprintf(\"Key[%d,%d]\", ev.key, int(ev.ch))\n\t\t}\n\t}\n\tif len(m) != 0 {\n\t\tif ev.mod&ModCtrl != 0 && strings.HasPrefix(s, \"Ctrl-\") {\n\t\t\ts = s[5:]\n\t\t}\n\t\treturn fmt.Sprintf(\"%s+%s\", strings.Join(m, \"+\"), s)\n\t}\n\treturn s\n}", "label": 5}
{"code": "public double dot(Vector3d v1) {\n        return x * v1.x + y * v1.y + z * v1.z;\n    }", "label": 0}
{"code": "function info() {\n    var _console4;\n\n    if (LatticeLogs.failFast(LatticeLogs.INFO)) return;\n\n    for (var _len6 = arguments.length, args = new Array(_len6), _key6 = 0; _key6 < _len6; _key6++) {\n      args[_key6] = arguments[_key6];\n    }\n\n    (_console4 = console).info.apply(_console4, (0, _toConsumableArray2.default)(args.map(LatticeLogs.argMapper)));\n  }", "label": 3}
{"code": "public static <IN extends CoreMap> CRFClassifier<IN> getJarClassifier(String resourceName, Properties props) {\r\n    CRFClassifier<IN> crf = new CRFClassifier<IN>();\r\n    crf.loadJarClassifier(resourceName, props);\r\n    return crf;\r\n  }", "label": 0}
{"code": "protected function indentPrettyPrintedJson($jsonString, $indentStyle, $defaultIndentSize = 2)\n    {\n        $indentChar = $this->getIndentCharForIndentStyle($indentStyle);\n        $indentSize = $this->getPrettyPrintIndentSize() ?: $defaultIndentSize;\n\n        // If the given indentation style is allowed to have various indent size\n        // (number of chars, that are used to indent one level in each line),\n        // indent the JSON string with given (or default) indent size.\n        if ($this->hasVariousIndentSize($indentStyle)) {\n            return $this->peformIndentation($jsonString, $indentChar, $indentSize);\n        }\n\n        // Otherwise following the convention, that indent styles, that does not\n        // allowed to have various indent size (e.g. tab) are indented using\n        // one tabulation character per one indent level in each line.\n        return $this->peformIndentation($jsonString, $indentChar);\n    }", "label": 2}
{"code": "def clean(self):\n        \"\"\"Return cleaned fields as a dict, determine which geom takes\n        precedence.\n        \"\"\"\n        data = super(RasterQueryForm, self).clean()\n        geom = data.pop('upload', None) or data.pop('bbox', None)\n        if geom:\n            data['g'] = geom\n        return data", "label": 1}
{"code": "def process_token(self, tok):\n        \"\"\"count lines and track position of classes and functions\"\"\"\n        if tok[0] == Token.Text:\n            count = tok[1].count('\\n')\n            if count:\n                self._line += count  # adjust linecount\n\n        if self._detector.process(tok):\n            pass  # works been completed in the detector\n        elif tok[0] == Token.Punctuation:\n            if tok[0] == Token.Punctuation and tok[1] == '{':\n                self._scope += 1\n            if tok[0] == Token.Punctuation and tok[1] == '}':\n                self._scope += -1\n                if self._scope == 0 and self._curr is not None:\n                    self._curr['end'] = self._line  # close last scope\n                    self._curr = None\n        elif tok[0] == Token.Name.Class and self._scope == 0:\n            self.add_scope('Class', tok[1], self._line)\n        elif tok[0] == Token.Name.Function and self._scope in [0, 1]:\n            self.add_scope('Function', tok[1], self._line, self._scope == 1)", "label": 1}
{"code": "function concatUnique(aItems, bItems, algebra) {\n\tvar idTree = {};\n\tvar aSet;\n\t// IE 9 and 10 don't have Set.\n\tif(typeof Set !== \"undefined\") {\n\t\taSet = new Set();  // jshint ignore:line\n\t}\n\n\taItems.forEach(function(item) {\n\t\tvar keyNode = idTree;\n\t\tif(aSet) {\n\t\t\taSet.add(item);\n\t\t}\n\t\teach(algebra.clauses.id, function(prop) {\n\t\t\tvar propVal = getProp(item, prop);\n\t\t\tif(keyNode && typeof propVal !== \"undefined\") {\n\t\t\t\tkeyNode = keyNode[propVal] = keyNode[propVal] || {};\n\t\t\t} else {\n\t\t\t\tkeyNode = undefined;\n\t\t\t}\n\t\t});\n\t});\n\n\treturn aItems.concat(bItems.filter(function(item) {\n\t\tvar keyNode = idTree;\n\t\tif(aSet && aSet.has(item)) {\n\t\t\treturn false;\n\t\t}\n\t\t// IE9/10 case\n\t\tif(!aSet && aItems.indexOf(item) > -1) {\n\t\t\treturn false;\n\t\t}\n\t\teach(algebra.clauses.id, function(prop) {\n\t\t\tkeyNode = keyNode && keyNode[getProp(item, prop)];\n\t\t});\n\t\treturn keyNode === idTree || !keyNode;\n\t}));\n}", "label": 3}
{"code": "func (m *Martini) RunOnAddr(addr string) {\n\t// TODO: Should probably be implemented using a new instance of http.Server in place of\n\t// calling http.ListenAndServer directly, so that it could be stored in the martini struct for later use.\n\t// This would also allow to improve testing when a custom host and port are passed.\n\n\tlogger := m.Injector.Get(reflect.TypeOf(m.logger)).Interface().(*log.Logger)\n\tlogger.Printf(\"listening on %s (%s)\\n\", addr, Env)\n\tlogger.Fatalln(http.ListenAndServe(addr, m))\n}", "label": 5}
{"code": "public function setLastAttempt($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Tasks\\V2\\Attempt::class);\n        $this->last_attempt = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def prefix_iter(self, ns_uri):\n        \"\"\"Gets an iterator over the prefixes for the given namespace.\"\"\"\n        ni = self.__lookup_uri(ns_uri)\n        return iter(ni.prefixes)", "label": 1}
{"code": "func endsWith(fl FieldLevel) bool {\n\treturn strings.HasSuffix(fl.Field().String(), fl.Param())\n}", "label": 5}
{"code": "def site_url(url):\n    \"\"\"\n    Determine the server URL.\n    \"\"\"\n    base_url = 'http://%s' % socket.gethostname()\n\n    if server.port is not 80:\n        base_url += ':%d' % server.port\n\n    return urlparse.urljoin(base_url, url)", "label": 1}
{"code": "function spawn(cmd, args, opts) {\n  const spawn = require('child_process').spawn;\n  const _ = require('lodash');\n  return new Promise((resolve, reject) => {\n    const p = spawn(cmd, typeof args === 'string' ? args.split(' ') : args, _.merge({stdio: argv.quiet ? ['ignore', 'pipe', 'pipe'] : ['ignore', 1, 2]}, opts));\n    const out = [];\n    if (p.stdout) {\n      p.stdout.on('data', (chunk) => out.push(chunk));\n    }\n    if (p.stderr) {\n      p.stderr.on('data', (chunk) => out.push(chunk));\n    }\n    p.on('close', (code, signal) => {\n      if (code === 0) {\n        console.info(cmd, 'ok status code', code, signal);\n        resolve(code);\n      } else {\n        console.error(cmd, 'status code', code, signal);\n        if (args.quiet) {\n          // log output what has been captured\n          console.log(out.join('\\n'));\n        }\n        reject(`${cmd} failed with status code ${code} ${signal}`);\n      }\n    });\n  });\n}", "label": 3}
{"code": "public function getUpdateSchemaSql(array $classes, $saveMode = false)\n    {\n        $sm = $this->em->getConnection()->getSchemaManager();\n\n        $fromSchema = $sm->createSchema();\n        $toSchema   = $this->getSchemaFromMetadata($classes);\n\n        $comparator = new Comparator();\n        $schemaDiff = $comparator->compare($fromSchema, $toSchema);\n\n        if ($saveMode) {\n            return $schemaDiff->toSaveSql($this->platform);\n        }\n\n        return $schemaDiff->toSql($this->platform);\n    }", "label": 2}
{"code": "def wrap_layout(layout_name, &block)\n      # Save current buffer for later\n      buf_was = save_buffer\n\n      # Find a layout for this file\n      layout_file = ::Middleman::TemplateRenderer.locate_layout(@app, layout_name, current_engine)\n\n      # Get the layout engine\n      extension = File.extname(layout_file[:relative_path])\n      engine = extension[1..-1].to_sym\n\n      # Store last engine for later (could be inside nested renders)\n      self.current_engine = engine\n      engine_was = current_engine\n\n      # By default, no content is captured\n      content = ''\n\n      # Attempt to capture HTML from block\n      begin\n        content = capture_html(&block) if block_given?\n      ensure\n        # Reset stored buffer, regardless of success\n        restore_buffer(buf_was)\n      end\n\n      @vertices <<= ::Middleman::Dependencies::FileVertex.from_source_file(@app, layout_file)\n\n      # Render the layout, with the contents of the block inside.\n      concat_safe_content render_file(layout_file, @locs, @opts) { content }\n    ensure\n      # Reset engine back to template's value, regardless of success\n      self.current_engine = engine_was\n    end", "label": 4}
{"code": "public static function start($title, User $user)\n    {\n        $discussion = new static;\n\n        $discussion->title = $title;\n        $discussion->created_at = Carbon::now();\n        $discussion->user_id = $user->id;\n\n        $discussion->setRelation('user', $user);\n\n        $discussion->raise(new Started($discussion));\n\n        return $discussion;\n    }", "label": 2}
{"code": "function(values, delaySort, equals)\n  {\n    var removed = [];\n    var removedIndices = [];\n\n    if ( isArray( values ) && values.length )\n    {\n      for (var i = 0; i < values.length; i++)\n      {\n        var value = values[ i ];\n        var k = this.indexOf( value, equals );\n\n        if ( k !== -1 )\n        {\n          removedIndices.push( k );\n          removed.push( value );\n        }\n      }\n\n      removedIndices.sort();\n\n      for (var i = removedIndices.length - 1; i >= 0; i--)\n      {\n        AP.splice.call( this, removedIndices[ i ], 1 );\n      }\n\n      this.trigger( Collection.Events.Removes, [this, removed, removedIndices] );\n\n      if ( !delaySort )\n      {\n        this.sort( undefined, undefined, true );\n      }\n    }\n\n    return removed;\n  }", "label": 3}
{"code": "public final void train(Collection<Tree> trees, double weight) {\r\n    // scan data\r\n    for (Tree tree : trees) {\r\n      train(tree, weight);\r\n    }\r\n  }", "label": 0}
{"code": "public function setClientCertificateConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\ClientCertificateConfig::class);\n        $this->client_certificate_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function (hash) {\n  return new Promise((resolve, reject) => {\n    request(`${ ipfsProtocol }://${ ipfsHost }/ipfs/${hash}`, function (err, response, body) {\n      if (err) {\n        reject(err);\n      } else {\n        resolve(response);\n      }\n    });\n  });\n}", "label": 3}
{"code": "public static String stringFromFile(String filename, String encoding) {\r\n    try {\r\n      StringBuilder sb = new StringBuilder();\r\n      BufferedReader in = new BufferedReader(new EncodingFileReader(filename,encoding));\r\n      String line;\r\n      while ((line = in.readLine()) != null) {\r\n        sb.append(line);\r\n        sb.append(eolChar);\r\n      }\r\n      in.close();\r\n      return sb.toString();\r\n    }\r\n    catch (IOException e) {\r\n      e.printStackTrace();\r\n      return null;\r\n    }\r\n  }", "label": 0}
{"code": "def select_user(user, role = 'Depositor')\n      first('a.select2-choice').click\n      find('.select2-input').set(user.user_key)\n      sleep 1\n      first('div.select2-result-label').click\n      within('div.add-users') do\n        select(role)\n        find('input.edit-collection-add-sharing-button').click\n      end\n    end", "label": 4}
{"code": "func (cli *NetworkCli) Cmd(chain string, args ...string) error {\n\tif len(args) > 2 {\n\t\tmethod, exists := cli.getMethod(args[:3]...)\n\t\tif exists {\n\t\t\treturn method(chain+\" \"+args[0]+\" \"+args[1], args[3:]...)\n\t\t}\n\t}\n\tif len(args) > 1 {\n\t\tmethod, exists := cli.getMethod(args[:2]...)\n\t\tif exists {\n\t\t\treturn method(chain+\" \"+args[0], args[2:]...)\n\t\t}\n\t}\n\tif len(args) > 0 {\n\t\tmethod, exists := cli.getMethod(args[0])\n\t\tif !exists {\n\t\t\treturn fmt.Errorf(\"%s: '%s' is not a %s command. See '%s --help'\", chain, args[0], chain, chain)\n\t\t}\n\t\treturn method(chain, args[1:]...)\n\t}\n\tflag.Usage()\n\treturn nil\n}", "label": 5}
{"code": "private static boolean isAssignableFrom(Type from, GenericArrayType to) {\n\t\tType toGenericComponentType = to.getGenericComponentType();\n\t\tif (toGenericComponentType instanceof ParameterizedType) {\n\t\t\tType t = from;\n\t\t\tif (from instanceof GenericArrayType) {\n\t\t\t\tt = ((GenericArrayType) from).getGenericComponentType();\n\t\t\t} else if (from instanceof Class) {\n\t\t\t\tClass<?> classType = (Class<?>) from;\n\t\t\t\twhile (classType.isArray()) {\n\t\t\t\t\tclassType = classType.getComponentType();\n\t\t\t\t}\n\t\t\t\tt = classType;\n\t\t\t}\n\t\t\treturn isAssignableFrom(t,\n\t\t\t\t\t(ParameterizedType) toGenericComponentType,\n\t\t\t\t\tnew HashMap<String, Type>());\n\t\t}\n\t\t// No generic defined on \"to\"; therefore, return true and let other\n\t\t// checks determine assignability\n\t\treturn true;\n\t}", "label": 0}
{"code": "protected function registerNotificationSerializers()\n    {\n        $blueprints = [];\n        $serializers = [\n            'discussionRenamed' => BasicDiscussionSerializer::class\n        ];\n\n        $this->app->make('events')->fire(\n            new ConfigureNotificationTypes($blueprints, $serializers)\n        );\n\n        foreach ($serializers as $type => $serializer) {\n            NotificationSerializer::setSubjectSerializer($type, $serializer);\n        }\n    }", "label": 2}
{"code": "public static function getSignContent($data): string\n    {\n        $buff = '';\n\n        foreach ($data as $k => $v) {\n            $buff .= ($k != 'sign' && $v != '' && !is_array($v)) ? $k.'='.$v.'&' : '';\n        }\n\n        Log::debug('Wechat Generate Sign Content Before Trim', [$data, $buff]);\n\n        return trim($buff, '&');\n    }", "label": 2}
{"code": "def call(self, action, params=None):\n        \"\"\"\n        Makes an RPC call to the server and returns the json response\n\n        :param action: RPC method to call\n        :type action: str\n\n        :param params: Dict of arguments to send with RPC call\n        :type params: dict\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n        :raises: :py:exc:`requests.exceptions.RequestException`\n\n        >>> rpc.call(\n        ...     action='account_balance',\n        ...     params={\n        ...         'account': 'xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3'\n        ...     })\n        {'balance': '325586539664609129644855132177',\n         'pending': '2309370940000000000000000000000000'}\n\n        \"\"\"\n        params = params or {}\n        params['action'] = action\n\n        resp = self.session.post(self.host, json=params, timeout=self.timeout)\n\n        result = resp.json()\n\n        if 'error' in result:\n            raise RPCException(result['error'])\n\n        return result", "label": 1}
{"code": "function lib(val) {\n  var p = path.join(process.cwd(), val);\n  return require(p);\n}", "label": 3}
{"code": "def index(self, record):\n        \"\"\"Index a record.\n\n        The caller is responsible for ensuring that the record has already been\n        committed to the database. If a newer version of a record has already\n        been indexed then the provided record will not be indexed. This\n        behavior can be controlled by providing a different ``version_type``\n        when initializing ``RecordIndexer``.\n\n        :param record: Record instance.\n        \"\"\"\n        index, doc_type = self.record_to_index(record)\n\n        return self.client.index(\n            id=str(record.id),\n            version=record.revision_id,\n            version_type=self._version_type,\n            index=index,\n            doc_type=doc_type,\n            body=self._prepare_record(record, index, doc_type),\n        )", "label": 1}
{"code": "function insert(match, commenttype, statement, file) {\n    var location = path.resolve(reference, file)\n      , data = '';\n\n    //\n    // If it's not an absolute path, try to require.resolve the file.\n    //\n    if (!fs.existsSync(location)) try {\n      location = require.resolve(file);\n    } catch (e) { }\n\n    if (!fs.existsSync(location)) {\n      return self.critical(\n          '// [square] @%s statement %s in %s does not exist'\n        , statement\n        , file.red\n        , reference.red\n      );\n    }\n\n    if (~seen.indexOf(location)) {\n      return self.critical('recursive [square] import statement detected %s', match);\n    }\n\n    // We processed the file, mark it as seen to protect us against recursive\n    // includes.\n    seen.push(location);\n\n    data += self.commentWrap('[square] Directive: ' + location, extension);\n    data += fs.readFileSync(location, 'utf8').trim();\n\n    // Pass the contents back in to the directive again so we can also process\n    // the directives inside the directive.\n    return self.directive(data, extension, path.dirname(location), seen);\n  }", "label": 3}
{"code": "function( el, error ) {\r\n        // We want display errors ?\r\n        if ( !this.options.showErrorMessages ) {\r\n          // because of form not valid, set handler true for break submit\r\n          this.handler = true;\r\n          return;\r\n        }\r\n        var elParent = this.parents( el );\r\n        // If the parent element undefined, that means el is an object. So we need to transform to the element\r\n        if( typeof elParent === 'undefined' ) elParent = el[0].parentNode;\r\n        // if there is an error window which previously opened for el, return\r\n        if ( elParent.querySelectorAll( '.'+ this.options.errorTemplateClass ).length ) return;\r\n        // Create the error window object which will be appear\r\n        var errorObject = document.createElement('span');\r\n        errorObject.className = this.options.errorTemplateClass + ' '+this.options.errorTemplateClass + '--' + this.options.bubblePosition;\r\n        // if error display is bubble, calculate to positions\r\n        if( this.options.display === 'bubble' ) {\r\n          var pos, W = 0, H = 0;\r\n          // !! Here, JQuery functions are using to support the IE8\r\n          pos = $( el ).position();\r\n\r\n          if ( this.options.bubblePosition === 'bottom' ){\r\n            H = el.offsetHeight;\r\n          }\r\n          else {\r\n            W = el.offsetWidth;\r\n          }\r\n          errorObject.innerHTML = '';\r\n          errorObject.style.top = pos.top + H + this.options.bubbleGapTop +'px';\r\n          errorObject.style.left = pos.left + W + this.options.bubbleGapLeft +'px'\r\n        }\r\n        elParent.appendChild( errorObject );\r\n        errorObject.innerHTML = error ;\r\n\r\n        // we have an error so we need to break submit\r\n        // set to handler true\r\n        this.handler = true;\r\n      }", "label": 3}
{"code": "func (c *Manager) CreateLibrary(ctx context.Context, library Library) (string, error) {\n\tif library.Type != \"LOCAL\" {\n\t\treturn \"\", fmt.Errorf(\"unsupported library type: %q\", library.Type)\n\t}\n\tspec := struct {\n\t\tLibrary Library `json:\"create_spec\"`\n\t}{library}\n\turl := internal.URL(c, internal.LocalLibraryPath)\n\tvar res string\n\treturn res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "def perform!\n      @started_at = Time.now.utc\n      @time = package.time = started_at.strftime(\"%Y.%m.%d.%H.%M.%S\")\n\n      log!(:started)\n      before_hook\n\n      procedures.each do |procedure|\n        procedure.is_a?(Proc) ? procedure.call : procedure.each(&:perform!)\n      end\n\n      syncers.each(&:perform!)\n    rescue Interrupt\n      @interrupted = true\n      raise\n    rescue Exception => err\n      @exception = err\n    ensure\n      unless @interrupted\n        set_exit_status\n        @finished_at = Time.now.utc\n        log!(:finished)\n        after_hook\n      end\n    end", "label": 4}
{"code": "def grayspec(k):\n    \"\"\"\n    List of gray-scale colors in HSV space as web hex triplets.\n\n    For integer argument k, returns list of `k` gray-scale colors, increasingly \n    light, linearly in the HSV color space, as web hex triplets.\n\n    Technical dependency of :func:`tabular.spreadsheet.aggregate_in`.\n\n    **Parameters**\n\n            **k** :  positive integer\n\n                    Number of gray-scale colors to return.\n\n    **Returns**\n\n            **glist** :  list of strings\n\n                    List of `k` gray-scale colors.\n\n    \"\"\"\n    ll = .5\n    ul = .8\n    delta = (ul - ll) / k\n    return [GrayScale(t) for t in np.arange(ll, ul, delta)]", "label": 1}
{"code": "def add_record(self, record):\n        \"\"\"Add a record to the community.\n\n        :param record: Record object.\n        :type record: `invenio_records.api.Record`\n        \"\"\"\n        key = current_app.config['COMMUNITIES_RECORD_KEY']\n        record.setdefault(key, [])\n\n        if self.has_record(record):\n            current_app.logger.warning(\n                'Community addition: record {uuid} is already in community '\n                '\"{comm}\"'.format(uuid=record.id, comm=self.id))\n        else:\n            record[key].append(self.id)\n            record[key] = sorted(record[key])\n        if current_app.config['COMMUNITIES_OAI_ENABLED']:\n            if not self.oaiset.has_record(record):\n                self.oaiset.add_record(record)", "label": 1}
{"code": "def run_callbacks(kind)\n      callbacks = __callbacks[kind.to_sym]\n\n      if callbacks.empty?\n        yield if block_given?\n      else\n        env = Filters::Environment.new(self, false, nil)\n        next_sequence = callbacks.compile\n\n        invoke_sequence = Proc.new do\n          skipped = nil\n          while true\n            current = next_sequence\n            current.invoke_before(env)\n            if current.final?\n              env.value = !env.halted && (!block_given? || yield)\n            elsif current.skip?(env)\n              (skipped ||= []) << current\n              next_sequence = next_sequence.nested\n              next\n            else\n              next_sequence = next_sequence.nested\n              begin\n                target, block, method, *arguments = current.expand_call_template(env, invoke_sequence)\n                target.send(method, *arguments, &block)\n              ensure\n                next_sequence = current\n              end\n            end\n            current.invoke_after(env)\n            skipped.pop.invoke_after(env) while skipped && skipped.first\n            break env.value\n          end\n        end\n\n        # Common case: no 'around' callbacks defined\n        if next_sequence.final?\n          next_sequence.invoke_before(env)\n          env.value = !env.halted && (!block_given? || yield)\n          next_sequence.invoke_after(env)\n          env.value\n        else\n          invoke_sequence.call\n        end\n      end\n    end", "label": 4}
{"code": "func RetryErrorf(format string, params ...interface{}) error {\n\treturn retry(fmt.Sprintf(format, params...))\n}", "label": 5}
{"code": "def extract_information_for_specific_variable\n      reference = @entry.at_xpath('./*/cda:outboundRelationship/cda:criteriaReference',\n                                  HQMF2::Document::NAMESPACES)\n      if reference\n        ref_id = strip_tokens(\n          \"#{HQMF2::Utilities.attr_val(reference, 'cda:id/@extension')}_#{HQMF2::Utilities.attr_val(reference, 'cda:id/@root')}\")\n      end\n      reference_criteria = @data_criteria_references[ref_id] if ref_id\n      # if the reference is derived, pull from the original variable\n      if reference_criteria && reference_criteria.definition == 'derived'\n        reference_criteria = @data_criteria_references[\"GROUP_#{ref_id}\"]\n      end\n      return unless reference_criteria\n      handle_specific_variable_ref(reference_criteria)\n    end", "label": 4}
{"code": "function _getUserSocialDetails(){\n    return BB\n        .bind(this)\n        .then(function() {\n            return pinterest\n                .query()\n                .get('me/?fields=id,first_name,last_name,url,username,image&access_token=' + this.params.access_token)\n                .request();\n        })\n        .then(function(res){\n            this.socialUserInfo = res[1].data;\n        });\n}", "label": 3}
{"code": "public function setStringValue($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Trace\\V2\\TruncatableString::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (f *Fpdf) Ln(h float64) {\n\tf.x = f.lMargin\n\tif h < 0 {\n\t\tf.y += f.lasth\n\t} else {\n\t\tf.y += h\n\t}\n}", "label": 5}
{"code": "func (t *FpdfTpl) ID() string {\n\treturn fmt.Sprintf(\"%x\", sha1.Sum(t.Bytes()))\n}", "label": 5}
{"code": "function() {\n      if (this.options.applevel === true || this.options.applevel === false) return this.options.applevel;\n      return this.options.session_token == null;\n    }", "label": 3}
{"code": "private void processProperties() {\n        state = true;\n        try {\n            importerServiceFilter = getFilter(importerServiceFilterProperty);\n        } catch (InvalidFilterException invalidFilterException) {\n            LOG.debug(\"The value of the Property \" + FILTER_IMPORTERSERVICE_PROPERTY + \" is invalid,\"\n                    + \" the recuperation of the Filter has failed. The instance gonna stop.\", invalidFilterException);\n            state = false;\n            return;\n        }\n\n        try {\n            importDeclarationFilter = getFilter(importDeclarationFilterProperty);\n        } catch (InvalidFilterException invalidFilterException) {\n            LOG.debug(\"The value of the Property \" + FILTER_IMPORTDECLARATION_PROPERTY + \" is invalid,\"\n                    + \" the recuperation of the Filter has failed. The instance gonna stop.\", invalidFilterException);\n            state = false;\n            return;\n        }\n    }", "label": 0}
{"code": "public function setAppProfile($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\Admin\\V2\\AppProfile::class);\n        $this->app_profile = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static ComplexNumber Tan(ComplexNumber z1) {\r\n        ComplexNumber result = new ComplexNumber();\r\n\r\n        if (z1.imaginary == 0.0) {\r\n            result.real = Math.tan(z1.real);\r\n            result.imaginary = 0.0;\r\n        } else {\r\n            double real2 = 2 * z1.real;\r\n            double imag2 = 2 * z1.imaginary;\r\n            double denom = Math.cos(real2) + Math.cosh(real2);\r\n\r\n            result.real = Math.sin(real2) / denom;\r\n            result.imaginary = Math.sinh(imag2) / denom;\r\n        }\r\n\r\n        return result;\r\n    }", "label": 0}
{"code": "func (m VirtualDiskManager) CreateVirtualDisk(\n\tctx context.Context,\n\tname string, datacenter *Datacenter,\n\tspec types.BaseVirtualDiskSpec) (*Task, error) {\n\n\treq := types.CreateVirtualDisk_Task{\n\t\tThis: m.Reference(),\n\t\tName: name,\n\t\tSpec: spec,\n\t}\n\n\tif datacenter != nil {\n\t\tref := datacenter.Reference()\n\t\treq.Datacenter = &ref\n\t}\n\n\tres, err := methods.CreateVirtualDisk_Task(ctx, m.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewTask(m.c, res.Returnval), nil\n}", "label": 5}
{"code": "function convertArrayCell (cell) {\n  const {item} = cell\n  const arrayOptions = _.chain(item)\n  .pick(ARRAY_CELL_PROPERTIES)\n  .assign({\n    itemCell: convertCell(item)\n  })\n  .value()\n  return {\n    arrayOptions,\n    model: cell.model\n  }\n}", "label": 3}
{"code": "private void createStringMappings(MtasTokenIdFactory mtasTokenIdFactory,\n      Level level, String stringValue, int offsetStart, int offsetEnd,\n      int position) throws IOException {\n    // System.out.println(\"createStringMappings string \");\n    String[] stringValues = MtasPennTreebankReader.createStrings(stringValue,\n        Pattern.quote(STRING_SPLITTER));\n    if (stringValues.length > 0 && !stringValues[0].trim().isEmpty()) {\n      MtasToken token = new MtasTokenString(mtasTokenIdFactory.createTokenId(),\n          \"t\", filterString(stringValues[0].trim()), position);\n      token.setOffset(offsetStart, offsetEnd);\n      tokenCollection.add(token);\n      level.tokens.add(token);\n    }\n    if (stringValues.length > 1 && !stringValues[1].trim().isEmpty()) {\n      MtasToken token = new MtasTokenString(mtasTokenIdFactory.createTokenId(),\n          \"lemma\", filterString(stringValues[1].trim()), position);\n      token.setOffset(offsetStart, offsetEnd);\n      tokenCollection.add(token);\n      level.tokens.add(token);\n    }\n  }", "label": 0}
{"code": "protected function storeTags($results)\n    {\n        $this->table('telescope_entries_tags')->insert($results->flatMap(function ($tags, $uuid) {\n            return collect($tags)->map(function ($tag) use ($uuid) {\n                return [\n                    'entry_uuid' => $uuid,\n                    'tag' => $tag,\n                ];\n            });\n        })->all());\n    }", "label": 2}
{"code": "function (sectionId) {\n        let section = server.state.get('sections[' + sectionId + ']');\n        if (section.app && section.app.url) {\n            log.debug('Flushing application at URL:', section.app.url);\n            request.post(section.app.url + '/instances/' + sectionId + '/flush', _handleRequestError);\n        }\n        server.state.get('groups').forEach(function (e, groupId) {\n            if (e.includes(parseInt(sectionId, 10))) {\n                // The outcome of this operation is logged within the internal utility method\n                if (e.length === 1) {\n                    _deleteGroupById(groupId);\n                } else {\n                    e.splice(e.indexOf(parseInt(sectionId, 10)), 1);\n                    server.state.set('groups[' + groupId + ']', e);\n                }\n            }\n        });\n        server.state.set('sections[' + sectionId + ']', {});\n\n        server.wss.clients.forEach(function (c) {\n            if (c.readyState === Constants.WEBSOCKET_READY) {\n                c.safeSend(JSON.stringify({ appId: Constants.APP_NAME, message: { action: Constants.Action.DELETE, id: parseInt(sectionId, 10) } }));\n            }\n        });\n    }", "label": 3}
{"code": "function parseIfJson(val) {\n    if (_.isString(val)) {\n        val = val.trim();\n        if (val.substring(0, 1) === '{' && val.substring(val.length - 1) === '}') {\n            try {\n                val = JSON.parse(val);\n            }\n            catch (ex) {\n                /* eslint no-console:0 */\n                console.log(ex);\n            }\n        }\n    }\n    return val;\n}", "label": 3}
{"code": "def before(name, context = proc {}, *args, &block)\n      name = format('%s_%s', 'before_', name.to_s).to_sym\n\n      if block_given?\n        @hooks.append(name, block)\n\n        self\n      else\n        @hooks.execute(name, context, *args)\n      end\n    end", "label": 4}
{"code": "function router(config = {}) {\n    $extend(settings, config);\n\n    // Update scrollBehavior property in case that was changed\n    history.scrollBehavior = settings.scrollBehavior;\n    history.transition = settings.transition;\n\n    return router;\n}", "label": 3}
{"code": "function processMultiBytePacket (o) {\n  if (o.multiPacketBuffer) {\n    o.multiPacketBuffer = Buffer.concat([Buffer.from(o.multiPacketBuffer), Buffer.from(o.rawDataPacket.slice(k.OBCIGanglionPacket19Bit.dataStart, k.OBCIGanglionPacket19Bit.dataStop))]);\n  } else {\n    o.multiPacketBuffer = o.rawDataPacket.slice(k.OBCIGanglionPacket19Bit.dataStart, k.OBCIGanglionPacket19Bit.dataStop);\n  }\n}", "label": 3}
{"code": "def around_http_request(*filters, &block)\n      unless VCR.fibers_available?\n        raise Errors::NotSupportedError.new \\\n          \"VCR::Configuration#around_http_request requires fibers, \" +\n          \"which are not available on your ruby intepreter.\"\n      end\n\n      fibers = {}\n      fiber_errors = {}\n      hook_allowed, hook_declaration = false, caller.first\n      before_http_request(*filters) do |request|\n        hook_allowed = true\n        start_new_fiber_for(request, fibers, fiber_errors, hook_declaration, block)\n      end\n\n      after_http_request(lambda { hook_allowed }) do |request, response|\n        fiber = fibers.delete(Thread.current)\n        resume_fiber(fiber, fiber_errors, response, hook_declaration)\n      end\n    end", "label": 4}
{"code": "function createInstantiatedSymbolTable(symbols, mapper, mappingThisOnly) {\n            var result = ts.createMap();\n            for (var _i = 0, symbols_2 = symbols; _i < symbols_2.length; _i++) {\n                var symbol = symbols_2[_i];\n                result[symbol.name] = mappingThisOnly && isIndependentMember(symbol) ? symbol : instantiateSymbol(symbol, mapper);\n            }\n            return result;\n        }", "label": 3}
{"code": "public function setAssignments($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->assignments = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function handleBuildExtensionsResponse(BuildExtensionsResponse $buildExtensionsResponse): ExtensionsResponse\n    {\n        $requestEnd = Carbon::now();\n        $requestEndPrecise = $this->getTime();\n\n        return new ExtensionsResponse(\n            'tracing',\n            [\n                'version' => 1,\n                'startTime' => $this->requestStart->format(Carbon::RFC3339_EXTENDED),\n                'endTime' => $requestEnd->format(Carbon::RFC3339_EXTENDED),\n                'duration' => $this->diffTimeInNanoseconds($this->requestStartPrecise, $requestEndPrecise),\n                'execution' => [\n                    'resolvers' => $this->resolverTraces,\n                ],\n            ]\n        );\n    }", "label": 2}
{"code": "function resolvePrimaryKey(attrNode, context) {\n    const errorContext = context.errorContext;\n    context.errorContext = ' in primaryKey' + errorContext;\n\n    const neededDataSources = [];\n\n    Object.keys(attrNode.dataSources).forEach(dataSourceName => {\n        if (attrNode.dataSources[dataSourceName].joinParentKey) return;\n        neededDataSources.push(dataSourceName);\n    });\n\n    attrNode.resolvedPrimaryKey = resolveKey(\n        attrNode.primaryKey,\n        attrNode,\n        {\n            neededDataSources,\n            allowMultiValued: false\n        },\n        context\n    );\n\n    // enable \"equal\" filter:\n    attrNode.primaryKey.forEach(primaryKeyAttrPath => {\n        const primaryKeyAttrNode = getLocalAttribute(primaryKeyAttrPath, attrNode, context);\n\n        if (!primaryKeyAttrNode.filter && attrNode.primaryKey.length === 1) {\n            if (!primaryKeyAttrNode.hidden) {\n                primaryKeyAttrNode.filter = ['equal'];\n            }\n        }\n    });\n\n    context.errorContext = errorContext;\n}", "label": 3}
{"code": "function convertPropertyNames (context, pkg, map , root, waiting) {\n\tif(!map) {\n\t\treturn map;\n\t}\n\tvar clone = {}, value;\n\tfor(var property in map ) {\n\t\tvalue = convertName(context, pkg, map, root, property, waiting);\n\t\tif(typeof value === 'string') {\n\t\t\tclone[value] = map[property];\n\t\t}\n\n\t\t// do root paths b/c we don't know if they are going to be included with the package name or not.\n\t\tif(root) {\n\t\t\tvalue = convertName(context, pkg, map, false, property, waiting);\n\t\t\tif(typeof value === 'string') {\n\t\t\t\tclone[value] = map[property];\n\t\t\t}\n\t\t}\n\t}\n\treturn clone;\n}", "label": 3}
{"code": "func GenerateUserCreds(process *service.TeleportProcess, username string) (*UserCreds, error) {\n\tpriv, pub, err := testauthority.New().GenerateKeyPair(\"\")\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ta := process.GetAuthServer()\n\tsshCert, x509Cert, err := a.GenerateUserCerts(pub, username, time.Hour, teleport.CertificateFormatStandard)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tclusterName, err := a.GetClusterName()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tca, err := a.GetCertAuthority(services.CertAuthID{\n\t\tType:       services.HostCA,\n\t\tDomainName: clusterName.GetClusterName(),\n\t}, false)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &UserCreds{\n\t\tHostCA: ca,\n\t\tKey: client.Key{\n\t\t\tPriv:    priv,\n\t\t\tPub:     pub,\n\t\t\tCert:    sshCert,\n\t\t\tTLSCert: x509Cert,\n\t\t},\n\t}, nil\n}", "label": 5}
{"code": "func Username() (string, error) {\n\tu, err := user.Current()\n\tif err != nil {\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\treturn u.Username, nil\n}", "label": 5}
{"code": "def from_string(string, mime=False, filename=None):\n    \"\"\" Reads in string, attempts to identify content based\n    off magic number and will return the file extension.\n    If mime is True it will return the mime type instead.\n    If filename is provided it will be used in the computation.\n\n    :param string: string representation to check\n    :param mime: Return mime, not extension\n    :param filename: original filename\n    :return: guessed extension or mime\n    \"\"\"\n    head, foot = _string_details(string)\n    ext = ext_from_filename(filename) if filename else None\n    return _magic(head, foot, mime, ext)", "label": 1}
{"code": "function (id) {\n    for (var key in this.active) {\n      if (this.active.hasOwnProperty(key) && this.active[key].id === id) {\n        return true;\n      }\n    }\n    return false;\n  }", "label": 3}
{"code": "function getPropagatingFlagsOfTypes(types, excludeKinds) {\n            var result = 0;\n            for (var _i = 0, types_3 = types; _i < types_3.length; _i++) {\n                var type = types_3[_i];\n                if (!(type.flags & excludeKinds)) {\n                    result |= type.flags;\n                }\n            }\n            return result & 234881024 /* PropagatingFlags */;\n        }", "label": 3}
{"code": "func connectToAuthService(cfg *service.Config) (client auth.ClientI, err error) {\n\t// connect to the local auth server by default:\n\tcfg.Auth.Enabled = true\n\tif len(cfg.AuthServers) == 0 {\n\t\tcfg.AuthServers = []utils.NetAddr{\n\t\t\t*defaults.AuthConnectAddr(),\n\t\t}\n\t}\n\t// read the host SSH keys and use them to open an SSH connection to the auth service\n\ti, err := auth.ReadLocalIdentity(filepath.Join(cfg.DataDir, teleport.ComponentProcess), auth.IdentityID{Role: teleport.RoleAdmin, HostUUID: cfg.HostUUID})\n\tif err != nil {\n\t\t// the \"admin\" identity is not present? this means the tctl is running NOT on the auth server.\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn nil, trace.AccessDenied(\"tctl must be used on the auth server\")\n\t\t}\n\t\treturn nil, trace.Wrap(err)\n\t}\n\ttlsConfig, err := i.TLSConfig(cfg.CipherSuites)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tclient, err = auth.NewTLSClient(auth.ClientConfig{Addrs: cfg.AuthServers, TLS: tlsConfig})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Check connectivity by calling something on the client.\n\t_, err = client.GetClusterName()\n\tif err != nil {\n\t\tutils.Consolef(os.Stderr, teleport.ComponentClient,\n\t\t\t\"Cannot connect to the auth server: %v.\\nIs the auth server running on %v?\",\n\t\t\terr, cfg.AuthServers[0].Addr)\n\t\tos.Exit(1)\n\t}\n\treturn client, nil\n}", "label": 5}
{"code": "function wrapIterator(iterator)\n{\n  var stream = this;\n\n  return function(item, key, cb)\n  {\n    var aborter\n      , wrappedCb = async(wrapIteratorCallback.call(stream, cb, key))\n      ;\n\n    stream.jobs[key] = wrappedCb;\n\n    // it's either shortcut (item, cb)\n    if (iterator.length == 2)\n    {\n      aborter = iterator(item, wrappedCb);\n    }\n    // or long format (item, key, cb)\n    else\n    {\n      aborter = iterator(item, key, wrappedCb);\n    }\n\n    return aborter;\n  };\n}", "label": 3}
{"code": "func (h *Handler) hostCredentials(w http.ResponseWriter, r *http.Request, p httprouter.Params) (interface{}, error) {\n\tvar req auth.RegisterUsingTokenRequest\n\tif err := httplib.ReadJSON(r, &req); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tauthClient := h.cfg.ProxyClient\n\tpackedKeys, err := authClient.RegisterUsingToken(req)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn packedKeys, nil\n}", "label": 5}
{"code": "def oauth_logout_handler(sender_app, user=None):\n    \"\"\"Remove all access tokens from session on logout.\"\"\"\n    oauth = current_app.extensions['oauthlib.client']\n    for remote in oauth.remote_apps.values():\n        token_delete(remote)\n    db.session.commit()", "label": 1}
{"code": "public function snapshot(array $options = [])\n    {\n        if ($this->isRunningTransaction) {\n            throw new \\BadMethodCallException('Nested transactions are not supported by this client.');\n        }\n\n        $options += [\n            'singleUse' => false\n        ];\n\n        $options['transactionOptions'] = $this->configureSnapshotOptions($options);\n\n        $session = $this->selectSession(\n            SessionPoolInterface::CONTEXT_READ,\n            $this->pluck('sessionOptions', $options, false) ?: []\n        );\n\n        try {\n            return $this->operation->snapshot($session, $options);\n        } finally {\n            $session->setExpiration();\n        }\n    }", "label": 2}
{"code": "func (pc *PropertyCollector) Fetch(ctx *Context, req *internal.Fetch) soap.HasFault {\n\tbody := new(internal.FetchBody)\n\n\tif req.This == vim25.ServiceInstance && req.Prop == \"content\" {\n\t\tcontent := ctx.Map.content()\n\t\t// ovftool uses API version for 6.0 and fails when these fields are non-nil; TODO\n\t\tcontent.VStorageObjectManager = nil\n\t\tcontent.HostProfileManager = nil\n\t\tcontent.HostSpecManager = nil\n\t\tcontent.CryptoManager = nil\n\t\tcontent.HostProfileManager = nil\n\t\tcontent.HealthUpdateManager = nil\n\t\tcontent.FailoverClusterConfigurator = nil\n\t\tcontent.FailoverClusterManager = nil\n\t\tbody.Res = &internal.FetchResponse{\n\t\t\tReturnval: content,\n\t\t}\n\t\treturn body\n\t}\n\n\tif ctx.Map.Get(req.This) == nil {\n\t\t// The Fetch method supports use of super class types, this is a quick hack to support the cases used by ovftool\n\t\tswitch req.This.Type {\n\t\tcase \"ManagedEntity\":\n\t\t\tfor o := range ctx.Map.objects {\n\t\t\t\tif o.Value == req.This.Value {\n\t\t\t\t\treq.This.Type = o.Type\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase \"ComputeResource\":\n\t\t\treq.This.Type = \"Cluster\" + req.This.Type\n\t\t}\n\t}\n\n\tres := pc.RetrievePropertiesEx(ctx, &types.RetrievePropertiesEx{\n\t\tSpecSet: []types.PropertyFilterSpec{{\n\t\t\tPropSet: []types.PropertySpec{{\n\t\t\t\tType:    req.This.Type,\n\t\t\t\tPathSet: []string{req.Prop},\n\t\t\t}},\n\t\t\tObjectSet: []types.ObjectSpec{{\n\t\t\t\tObj: req.This,\n\t\t\t}},\n\t\t}}})\n\n\tif res.Fault() != nil {\n\t\treturn res\n\t}\n\n\tobj := res.(*methods.RetrievePropertiesExBody).Res.Returnval.Objects[0]\n\tif len(obj.PropSet) == 0 {\n\t\tfault := obj.MissingSet[0].Fault\n\t\tbody.Fault_ = Fault(fault.LocalizedMessage, fault.Fault)\n\t\treturn body\n\t}\n\n\tbody.Res = &internal.FetchResponse{\n\t\tReturnval: obj.PropSet[0].Val,\n\t}\n\treturn body\n}", "label": 5}
{"code": "func FromBytesOrNil(input []byte) UUID {\n\tuuid, err := FromBytes(input)\n\tif err != nil {\n\t\treturn Nil\n\t}\n\treturn uuid\n}", "label": 5}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getNotification(\n            $options + $this->identity\n        );\n    }", "label": 2}
{"code": "public static base_response clear(nitro_service client) throws Exception {\n\t\tnd6 clearresource = new nd6();\n\t\treturn clearresource.perform_operation(client,\"clear\");\n\t}", "label": 0}
{"code": "func (h *Handle) MarshalJSON() ([]byte, error) {\n\tm := map[string]interface{}{\n\t\t\"id\": h.id,\n\t}\n\n\tb, err := h.ToByteArray()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm[\"sequence\"] = b\n\treturn json.Marshal(m)\n}", "label": 5}
{"code": "def set_paths(from, to)\n      @context ||= context\n      from = ensure_leading_slash(from)\n      data.merge!(\n        \"permalink\" => from,\n        \"redirect\"  => {\n          \"from\" => from,\n          \"to\"   => to =~ %r!^https?://! ? to : absolute_url(to),\n        }\n      )\n    end", "label": 4}
{"code": "private static synchronized boolean isLog4JConfigured()\r\n    {\r\n        if(!log4jConfigured)\r\n        {\r\n            Enumeration en = org.apache.log4j.Logger.getRootLogger().getAllAppenders();\r\n\r\n            if (!(en instanceof org.apache.log4j.helpers.NullEnumeration))\r\n            {\r\n                log4jConfigured = true;\r\n            }\r\n            else\r\n            {\r\n                Enumeration cats = LogManager.getCurrentLoggers();\r\n                while (cats.hasMoreElements())\r\n                {\r\n                    org.apache.log4j.Logger c = (org.apache.log4j.Logger) cats.nextElement();\r\n                    if (!(c.getAllAppenders() instanceof org.apache.log4j.helpers.NullEnumeration))\r\n                    {\r\n                        log4jConfigured = true;\r\n                    }\r\n                }\r\n            }\r\n            if(log4jConfigured)\r\n            {\r\n                String msg = \"Log4J is already configured, will not search for log4j properties file\";\r\n                LoggerFactory.getBootLogger().info(msg);\r\n            }\r\n            else\r\n            {\r\n                LoggerFactory.getBootLogger().info(\"Log4J is not configured\");\r\n            }\r\n        }\r\n        return log4jConfigured;\r\n    }", "label": 0}
{"code": "def edge_average(a):\n    \"Return the mean value around the edge of an array.\"\n\n    if len(np.ravel(a)) < 2:\n        return float(a[0])\n    else:\n        top_edge = a[0]\n        bottom_edge = a[-1]\n        left_edge = a[1:-1,0]\n        right_edge = a[1:-1,-1]\n\n        edge_sum = np.sum(top_edge) + np.sum(bottom_edge) + np.sum(left_edge) + np.sum(right_edge)\n        num_values = len(top_edge)+len(bottom_edge)+len(left_edge)+len(right_edge)\n\n        return float(edge_sum)/num_values", "label": 1}
{"code": "def copy_mac_app\n      exe_name = Gym.project.build_settings(key: \"EXECUTABLE_NAME\")\n      app_path = File.join(BuildCommandGenerator.archive_path, \"Products/Applications/#{exe_name}.app\")\n      UI.crash!(\"Couldn't find application in '#{BuildCommandGenerator.archive_path}'\") unless File.exist?(app_path)\n      FileUtils.cp_r(app_path, File.expand_path(Gym.config[:output_directory]), remove_destination: true)\n      app_path = File.join(Gym.config[:output_directory], File.basename(app_path))\n      UI.success(\"Successfully exported the .app file:\")\n      UI.message(app_path)\n      app_path\n    end", "label": 4}
{"code": "def update_item(location_id, item_id, body, opts = {})\n      data, _status_code, _headers = update_item_with_http_info(location_id, item_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "function () {\n        this._files = {};\n        this._global = new _File();\n        Object.keys(this._data).forEach(function (fileName) {\n            var fileCoverage = this._computeFileCoverage(fileName);\n            this._files[fileCoverage.name] = fileCoverage;\n            this._global.statements.add(fileCoverage.statements);\n            this._global.functions.add(fileCoverage.functions);\n            this._global.branches.add(fileCoverage.branches);\n        }, this);\n    }", "label": 3}
{"code": "def create(self, resource):\n        \"\"\"Create a new config.\n\n        :param resource: :class:`configs.Config <configs.Config>` object\n        :return: :class:`configs.Config <configs.Config>` object\n        :rtype: configs.Config\n        \"\"\"\n        schema = self.CREATE_SCHEMA\n        json = self.service.encode(schema, resource)\n\n        schema = self.GET_SCHEMA\n        resp = self.service.create(self.base, json)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "public long addAll(final String... members) {\n        return doWithJedis(new JedisCallable<Long>() {\n            @Override\n            public Long call(Jedis jedis) {\n                return jedis.sadd(getKey(), members);\n            }\n        });\n    }", "label": 0}
{"code": "def parse_unifrac_v1_8(unifrac, file_data):\n    \"\"\"\n    Function to parse data from older version of unifrac file obtained from Qiime version\n    1.8 and earlier.\n\n    :type unifrac: dict\n    :param unifracFN: The path to the unifrac results file\n\n    :type file_data: list\n    :param file_data: Unifrac data lines after stripping whitespace characters.\n    \"\"\"\n    for line in file_data:\n        if line == \"\":\n            break\n        line = line.split(\"\\t\")\n        unifrac[\"pcd\"][line[0]] = [float(e) for e in line[1:]]\n\n    unifrac[\"eigvals\"] = [float(entry) for entry in file_data[-2].split(\"\\t\")[1:]]\n    unifrac[\"varexp\"] = [float(entry) for entry in file_data[-1].split(\"\\t\")[1:]]\n    return unifrac", "label": 1}
{"code": "public static base_response unset(nitro_service client, coparameter resource, String[] args) throws Exception{\n\t\tcoparameter unsetresource = new coparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def with(new_options = Options::Redacted.new)\n      clone.tap do |client|\n        opts = validate_options!(new_options)\n        client.options.update(opts)\n        Database.create(client)\n        # We can't use the same cluster if some options that would affect it\n        # have changed.\n        if cluster_modifying?(opts)\n          Cluster.create(client)\n        end\n      end\n    end", "label": 4}
{"code": "public static function requestBuilder(callable $serializer)\n    {\n        return function (callable $handler) use ($serializer) {\n            return function (CommandInterface $command) use ($serializer, $handler) {\n                return $handler($command, $serializer($command));\n            };\n        };\n    }", "label": 2}
{"code": "def state_pop(self):\n        \"Restore the state of the output functions saved by state_push.\"\n        for of in self.output_fns:\n            if hasattr(of,'state_pop'):\n                of.state_pop()\n        super(PatternGenerator, self).state_pop()", "label": 1}
{"code": "def calculate_dimensions(image, long_side, short_side):\n    \"\"\"Returns the thumbnail dimensions depending on the images format.\"\"\"\n    if image.width >= image.height:\n        return '{0}x{1}'.format(long_side, short_side)\n    return '{0}x{1}'.format(short_side, long_side)", "label": 1}
{"code": "public String getAccuracyDescription(int numDigits) {\r\n    NumberFormat nf = NumberFormat.getNumberInstance();\r\n    nf.setMaximumFractionDigits(numDigits);\r\n    Triple<Double, Integer, Integer> accu = getAccuracyInfo();\r\n    return nf.format(accu.first()) + \"  (\" + accu.second() + \"/\" + (accu.second() + accu.third()) + \")\";\r\n  }", "label": 0}
{"code": "function _getPersistantFacebookToken(){\n    return facebook.query()\n            .get('/oauth/access_token?' +\n                'grant_type=fb_exchange_token&' +\n                'client_id=' + appId + '&' +\n                'client_secret=' + secret + '&' +\n                'fb_exchange_token=' + this.options.code)\n            .request()\n            .then(function (res) {\n                // Bad tokens result in a 200 with an error object\n                if (res[1].error) {\n                    throw new Error(res[1].error.message);\n                }\n\n                this.creds = querystring.parse(res[1]);\n            }.bind(this));\n}", "label": 3}
{"code": "def blank?(value)\n      value.nil? ||\n      value.respond_to?(:empty?) && value.empty? ||\n      BLANK_REGEX === value\n    end", "label": 4}
{"code": "def export!(classes = nil)\n      classes ||= SEED_CLASSES\n      classes.each do |klass|\n        klass = \"ComfortableMexicanSofa::Seeds::#{klass}::Exporter\"\n        klass.constantize.new(from, to).export!\n      end\n    end", "label": 4}
{"code": "function createRules(rulesToCreate, cb) {\n\n    function addRule(ruleToCreate, addRuleCallback) {\n      var fr = new rulesModel(ruleToCreate);\n\n      fr.save(function(err, frdoc) {\n        if (err) {\n          return addRuleCallback(err);\n        }\n        return addRuleCallback(null, frdoc);\n      });\n    }\n\n    async.map(rulesToCreate, addRule, cb);\n  }", "label": 3}
{"code": "def extract_haml(fileobj, keywords, comment_tags, options):\n    \"\"\" babel translation token extract function for haml files \"\"\"\n\n    import haml\n    from mako import lexer, parsetree\n    from mako.ext.babelplugin import extract_nodes \n\n    encoding = options.get('input_encoding', options.get('encoding', None))\n    template_node = lexer.Lexer(haml.preprocessor(fileobj.read()), input_encoding=encoding).parse()\n    for extracted in extract_nodes(template_node.get_children(), keywords, comment_tags, options):\n        yield extracted", "label": 1}
{"code": "public function setAutoGenerateProxyClasses($autoGenerate) : void\n    {\n        $proxyManagerConfig = $this->getProxyManagerConfiguration();\n\n        switch ((int) $autoGenerate) {\n            case ProxyFactory::AUTOGENERATE_ALWAYS:\n            case ProxyFactory::AUTOGENERATE_FILE_NOT_EXISTS:\n                $proxyManagerConfig->setGeneratorStrategy(new FileWriterGeneratorStrategy(\n                    new FileLocator($proxyManagerConfig->getProxiesTargetDir())\n                ));\n\n                return;\n            case ProxyFactory::AUTOGENERATE_NEVER:\n            case ProxyFactory::AUTOGENERATE_EVAL:\n            default:\n                $proxyManagerConfig->setGeneratorStrategy(new EvaluatingGeneratorStrategy());\n\n                return;\n        }\n    }", "label": 2}
{"code": "public static rewritepolicy_csvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\trewritepolicy_csvserver_binding obj = new rewritepolicy_csvserver_binding();\n\t\tobj.set_name(name);\n\t\trewritepolicy_csvserver_binding response[] = (rewritepolicy_csvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function delete(DocumentReference $document, array $options = [])\n    {\n        $this->writer->delete($document->name(), $options);\n\n        return $this;\n    }", "label": 2}
{"code": "def enabled?(source_type)\n      # the default is false if any sources are set to true, true otherwise\n      default = !self[\"sources\"].any? { |_, enabled| enabled }\n      self[\"sources\"].fetch(source_type, default)\n    end", "label": 4}
{"code": "func (s *SizeType) ScaleToHeight(height float64) SizeType {\n\twidth := s.Wd * height / s.Ht\n\treturn SizeType{width, height}\n}", "label": 5}
{"code": "public static function mapCommand(callable $f)\n    {\n        return function (callable $handler) use ($f) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler, $f) {\n                return $handler($f($command), $request);\n            };\n        };\n    }", "label": 2}
{"code": "def request_uri=(new_request_uri)\n      if !new_request_uri.respond_to?(:to_str)\n        raise TypeError, \"Can't convert #{new_request_uri.class} into String.\"\n      end\n      if self.absolute? && self.scheme !~ /^https?$/i\n        raise InvalidURIError,\n          \"Cannot set an HTTP request URI for a non-HTTP URI.\"\n      end\n      new_request_uri = new_request_uri.to_str\n      path_component = new_request_uri[/^([^\\?]*)\\??(?:.*)$/, 1]\n      query_component = new_request_uri[/^(?:[^\\?]*)\\?(.*)$/, 1]\n      path_component = path_component.to_s\n      path_component = (!path_component.empty? ? path_component : SLASH)\n      self.path = path_component\n      self.query = query_component\n\n      # Reset dependent values\n      remove_composite_values\n    end", "label": 4}
{"code": "public static function profileName($project, $tenant, $profile)\n    {\n        return self::getProfileNameTemplate()->render([\n            'project' => $project,\n            'tenant' => $tenant,\n            'profile' => $profile,\n        ]);\n    }", "label": 2}
{"code": "protected static function gatherSchemaImportsRecursively(string $path): string\n    {\n        if (! file_exists($path)) {\n            self::throwFileNotFoundException($path);\n        }\n\n        return (new Collection(file($path)))\n            ->map(function (string $line) use ($path) {\n                if (! Str::startsWith(trim($line), '#import ')) {\n                    return rtrim($line, PHP_EOL).PHP_EOL;\n                }\n\n                $importFileName = trim(Str::after($line, '#import '));\n                $importFilePath = dirname($path).'/'.$importFileName;\n\n                if (! Str::contains($importFileName, '*')) {\n                    $realPath = realpath($importFilePath);\n\n                    if (! $realPath) {\n                        self::throwFileNotFoundException($importFilePath);\n                    }\n\n                    return self::gatherSchemaImportsRecursively($realPath);\n                }\n\n                $importFilePaths = glob($importFilePath);\n\n                return (new Collection($importFilePaths))\n                    ->map(function ($file) {\n                        return self::gatherSchemaImportsRecursively($file);\n                    })\n                    ->implode('');\n            })\n            ->implode('');\n    }", "label": 2}
{"code": "function containsMatchingReferenceDiscriminant(source, target) {\n            return target.kind === 172 /* PropertyAccessExpression */ &&\n                containsMatchingReference(source, target.expression) &&\n                isDiscriminantProperty(getDeclaredTypeOfReference(target.expression), target.name.text);\n        }", "label": 3}
{"code": "func (nm DatastoreNamespaceManager) DeleteDirectory(ctx context.Context, dc *Datacenter, datastorePath string) error {\n\n\treq := &types.DeleteDirectory{\n\t\tThis:          nm.Reference(),\n\t\tDatastorePath: datastorePath,\n\t}\n\n\tif dc != nil {\n\t\tref := dc.Reference()\n\t\treq.Datacenter = &ref\n\t}\n\n\tif _, err := methods.DeleteDirectory(ctx, nm.c, req); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static function registryName($project, $location, $registry)\n    {\n        return self::getRegistryNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'registry' => $registry,\n        ]);\n    }", "label": 2}
{"code": "func (c *controller) getConfigNetwork(name string) (*network, error) {\n\tvar n Network\n\n\ts := func(current Network) bool {\n\t\tif current.Info().ConfigOnly() && current.Name() == name {\n\t\t\tn = current\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}\n\n\tc.WalkNetworks(s)\n\n\tif n == nil {\n\t\treturn nil, types.NotFoundErrorf(\"configuration network %q not found\", name)\n\t}\n\n\treturn n.(*network), nil\n}", "label": 5}
{"code": "func (h *Handler) WithAuth(fn ContextHandler) httprouter.Handle {\n\treturn httplib.MakeHandler(func(w http.ResponseWriter, r *http.Request, p httprouter.Params) (interface{}, error) {\n\t\tctx, err := h.AuthenticateRequest(w, r, true)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn fn(w, r, p, ctx)\n\t})\n}", "label": 5}
{"code": "public function sendRemoveAccount($lg = null, $lc = null, $feedback = null)\n    {\n        $msgId = $this->createIqId();\n        if ($feedback != null && strlen($feedback) > 0) {\n            if ($lg == null) {\n                $lg = '';\n            }\n\n            if ($lc == null) {\n                $lc = '';\n            }\n\n            $child = new ProtocolNode('body',\n                [\n                    'lg' => $lg,\n                    'lc' => $lc,\n                ], null, $feedback);\n            $childNode = [$child];\n        } else {\n            $childNode = null;\n        }\n\n        $removeNode = new ProtocolNode('remove', null, $childNode, null);\n        $node = new ProtocolNode('iq',\n            [\n                'to'    => Constants::WHATSAPP_SERVER,\n                'xmlns' => 'urn:xmpp:whatsapp:account',\n                'type'  => 'get',\n                'id'    => $msgId,\n            ], [$removeNode], null);\n\n        $this->sendNode($node);\n        $this->waitForServer($msgId);\n    }", "label": 2}
{"code": "def _encode_caveat_v1(condition, root_key, third_party_pub_key, key):\n    '''Create a JSON-encoded third-party caveat.\n\n    The third_party_pub_key key represents the PublicKey of the third party\n    we're encrypting the caveat for; the key is the public/private key pair of\n    the party that's adding the caveat.\n\n    @param condition string\n    @param root_key bytes\n    @param third_party_pub_key (PublicKey)\n    @param key (PrivateKey)\n    @return a base64 encoded bytes\n    '''\n    plain_data = json.dumps({\n        'RootKey': base64.b64encode(root_key).decode('ascii'),\n        'Condition': condition\n    })\n    box = nacl.public.Box(key.key, third_party_pub_key.key)\n\n    encrypted = box.encrypt(six.b(plain_data))\n    nonce = encrypted[0:nacl.public.Box.NONCE_SIZE]\n    encrypted = encrypted[nacl.public.Box.NONCE_SIZE:]\n    return base64.b64encode(six.b(json.dumps({\n        'ThirdPartyPublicKey': str(third_party_pub_key),\n        'FirstPartyPublicKey': str(key.public_key),\n        'Nonce': base64.b64encode(nonce).decode('ascii'),\n        'Id': base64.b64encode(encrypted).decode('ascii')\n    })))", "label": 1}
{"code": "function listDeployedForms(req, res, next) {\n  var projectForms = req.appformsResultPayload.data || [];\n  logger.debug(\"Middleware: listDeployedForms: \", {connection: req.connectionOptions, projectForms: projectForms});\n\n  //Only Want The Project Ids\n  projectForms = _.map(projectForms, function(form) {\n    if (_.isObject(form)) {\n      return form._id;\n    } else {\n      return form;\n    }\n  });\n\n  forms.findForms(req.connectionOptions, projectForms, formsResultHandlers(constants.resultTypes.forms, req, next));\n}", "label": 3}
{"code": "function(values)\n  {\n    this.length = 0;\n\n    if ( isArray( values ) )\n    {\n      AP.push.apply( this, values );\n    }\n    else if ( isValue( values ) )\n    {\n      AP.push.call( this, values );\n    }\n\n    this.trigger( Collection.Events.Reset, [this] );\n    this.sort( undefined, undefined, true );\n\n    return this;\n  }", "label": 3}
{"code": "func (t *Torrent) reapPieceTouchers(piece pieceIndex) (ret []*connection) {\n\tfor c := range t.pieces[piece].dirtiers {\n\t\tdelete(c.peerTouchedPieces, piece)\n\t\tret = append(ret, c)\n\t}\n\tt.pieces[piece].dirtiers = nil\n\treturn\n}", "label": 5}
{"code": "func PgAmopByAmopfamilyAmoplefttypeAmoprighttypeAmopstrategy(db XODB, amopfamily pgtypes.Oid, amoplefttype pgtypes.Oid, amoprighttype pgtypes.Oid, amopstrategy int16) (*PgAmop, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, amopfamily, amoplefttype, amoprighttype, amopstrategy, amoppurpose, amopopr, amopmethod, amopsortfamily ` +\n\t\t`FROM pg_catalog.pg_amop ` +\n\t\t`WHERE amopfamily = $1 AND amoplefttype = $2 AND amoprighttype = $3 AND amopstrategy = $4`\n\n\t// run query\n\tXOLog(sqlstr, amopfamily, amoplefttype, amoprighttype, amopstrategy)\n\tpa := PgAmop{}\n\n\terr = db.QueryRow(sqlstr, amopfamily, amoplefttype, amoprighttype, amopstrategy).Scan(&pa.Tableoid, &pa.Cmax, &pa.Xmax, &pa.Cmin, &pa.Xmin, &pa.Oid, &pa.Ctid, &pa.Amopfamily, &pa.Amoplefttype, &pa.Amoprighttype, &pa.Amopstrategy, &pa.Amoppurpose, &pa.Amopopr, &pa.Amopmethod, &pa.Amopsortfamily)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "def routes_table\n      routes = Jets::Router.routes\n\n      return \"Your routes table is empty.\" if routes.empty?\n\n      text = \"Verb | Path | Controller#action\\n\"\n      text << \"--- | --- | ---\\n\"\n      routes.each do |route|\n        text << \"#{route.method} | #{route.path} | #{route.to}\\n\"\n      end\n      html = Kramdown::Document.new(text).to_html\n      puts html\n      html\n    end", "label": 4}
{"code": "public function setUnreachable($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->unreachable = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def delegate(attribute_name, method_names):\n    \"\"\"Pass the call to the attribute called attribute_name for every method listed in method_names.\"\"\"\n    # hack for python 2.7 as nonlocal is not available\n    info = {\n        'attribute': attribute_name,\n        'methods': method_names\n    }\n\n    def decorator(cls):\n        \"\"\"Decorate class.\"\"\"\n        attribute = info['attribute']\n        if attribute.startswith(\"__\"):\n            attribute = \"_\" + cls.__name__ + attribute\n        for name in info['methods']:\n            setattr(cls, name, eval(\"lambda self, *a, **kw: \"\n                                    \"self.{0}.{1}(*a, **kw)\".format(attribute, name)))\n        return cls\n    return decorator", "label": 1}
{"code": "protected function binseqToArray($seq, array $barcodeData)\n\t{\n\t\t$len = strlen($seq);\n\t\t$w = 0;\n\t\t$k = 0;\n\t\tfor ($i = 0; $i < $len; ++$i) {\n\t\t\t$w += 1;\n\t\t\tif (($i == ($len - 1)) or (($i < ($len - 1)) and ($seq[$i] != $seq[($i + 1)]))) {\n\t\t\t\tif ($seq[$i] == '1') {\n\t\t\t\t\t$t = true; // bar\n\t\t\t\t} else {\n\t\t\t\t\t$t = false; // space\n\t\t\t\t}\n\t\t\t\t$barcodeData['bcode'][$k] = ['t' => $t, 'w' => $w, 'h' => 1, 'p' => 0];\n\t\t\t\t$barcodeData['maxw'] += $w;\n\t\t\t\t++$k;\n\t\t\t\t$w = 0;\n\t\t\t}\n\t\t}\n\t\treturn $barcodeData;\n\t}", "label": 2}
{"code": "def to_options\n      @options.merge(\n        environment: environment,\n        env_config:  env_config,\n        apps_path:   apps_path,\n        rackup:      rackup,\n        host:        host,\n        port:        port\n      )\n    end", "label": 4}
{"code": "func (fs *FSLocalKeyStore) GetCerts(proxy string) (*x509.CertPool, error) {\n\tdir, err := fs.dirFor(proxy, false)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tbytes, err := ioutil.ReadFile(filepath.Join(dir, fileNameTLSCerts))\n\tif err != nil {\n\t\treturn nil, trace.ConvertSystemError(err)\n\t}\n\tpool := x509.NewCertPool()\n\tfor len(bytes) > 0 {\n\t\tvar block *pem.Block\n\t\tblock, bytes = pem.Decode(bytes)\n\t\tif block == nil {\n\t\t\tbreak\n\t\t}\n\t\tif block.Type != \"CERTIFICATE\" || len(block.Headers) != 0 {\n\t\t\tfs.log.Debugf(\"Skipping PEM block type=%v headers=%v.\", block.Type, block.Headers)\n\t\t\tcontinue\n\t\t}\n\n\t\tcert, err := x509.ParseCertificate(block.Bytes)\n\t\tif err != nil {\n\t\t\treturn nil, trace.BadParameter(\"failed to parse certificate: %v\", err)\n\t\t}\n\t\tfs.log.Debugf(\"Adding trusted cluster certificate authority %q to trusted pool.\", cert.Issuer)\n\t\tpool.AddCert(cert)\n\t}\n\treturn pool, nil\n}", "label": 5}
{"code": "def retrieve_participatory_spaces\n      Decidim.participatory_space_manifests.map do |space_manifest|\n        next unless space_manifest.name == :participatory_processes # Temporal limitation\n        space_manifest.participatory_spaces.call(@organization)\n      end.flatten.compact\n    end", "label": 4}
{"code": "function(currentNode, newNode, ignoreElements) {\n      var currentCaret, activeElement,\n          currentNodeContainsActiveElement = false;\n      try {\n        activeElement = document.activeElement;\n      } catch (error) {\n        activeElement = null;\n      }\n      if (activeElement && currentNode && $.contains(activeElement, currentNode)) {\n        currentNodeContainsActiveElement = true;\n      }\n      if (currentNodeContainsActiveElement && this.supportsSelection(activeElement)) {\n        currentCaret = this.getCaretPosition(activeElement);\n      }\n      this.hotswap(currentNode, newNode, ignoreElements);\n      if (currentNodeContainsActiveElement && this.supportsSelection(activeElement)) {\n        this.setCaretPosition(activeElement, currentCaret);\n      }\n    }", "label": 3}
{"code": "func (r *Registry) ViewManager() *ViewManager {\n\treturn r.Get(r.content().ViewManager.Reference()).(*ViewManager)\n}", "label": 5}
{"code": "def check_properties(mcs, attributes):\n        \"\"\"Check whether intersections exist.\n\n        :type attributes: dict\n        \"\"\"\n        include, exclude = mcs.get_prepared_include_exclude(attributes)\n        properties = mcs.get_properties(attributes)\n        intersections = list(\n            set(properties).intersection(include if include else exclude))\n        if not intersections:\n            return None\n\n        attr_name = '__include__' if include else '__exclude__'\n\n        raise AttributeError(\n            \"It is not allowed to mention already defined properties: \"\n            \"{0} in {1} attributes.\".format(\", \".join(intersections),\n                                            attr_name))", "label": 1}
{"code": "def create_zip_from_folder(zip_file, fldr, mode=\"r\"):\n    \"\"\"\n    add all the files from the folder fldr\n    to the archive\n    \"\"\"\n    #print('zip from folder - adding folder : ', fldr)\n    zipf = zipfile.ZipFile(zip_file, 'w')\n    for root, dirs, files in os.walk(fldr):\n        for file in files:\n            fullname = os.path.join(root, file)\n            #print('zip - adding file : ', fullname)\n            zipf.write(fullname)\n    \n    \n    zipf.close()", "label": 1}
{"code": "def api_url\n      @api_url ||= Addressable::URI.new(\n        :scheme => scheme, :host => host, :port => port,\n        :path => path_with_base(\"/_api\", resource_path)\n      ).normalize.to_s\n    end", "label": 4}
{"code": "function getThreshold(fromStep, toStep, now)\n{\n\tlet threshold\n\n\t// Allows custom thresholds when moving\n\t// from a specific step to a specific step.\n\tif (fromStep && (fromStep.id || fromStep.unit)) {\n\t\tthreshold = toStep[`threshold_for_${fromStep.id || fromStep.unit}`]\n\t}\n\n\t// If no custom threshold is set for this transition\n\t// then use the usual threshold for the next step.\n\tif (threshold === undefined) {\n\t\tthreshold = toStep.threshold\n\t}\n\n\t// Convert threshold to a number.\n\tif (typeof threshold === 'function') {\n\t\tthreshold = threshold(now)\n\t}\n\n\t// Throw if no threshold is found.\n\tif (fromStep && typeof threshold !== 'number') {\n\t\t// Babel transforms `typeof` into some \"branches\"\n\t\t// so istanbul will show this as \"branch not covered\".\n\t\t/* istanbul ignore next */\n\t\tconst type = typeof threshold\n\t\tthrow new Error(`Each step of a gradation must have a threshold defined except for the first one. Got \"${threshold}\", ${type}. Step: ${JSON.stringify(toStep)}`)\n\t}\n\n\treturn threshold\n}", "label": 3}
{"code": "function(setA, setB, property1, property2){\n\t// p for param\n\t// v for value\n\tvar numProps = numericProperties(setA, setB, property1, property2);\n\tvar sAv1 = numProps.sAv1,\n\t\tsAv2 = numProps.sAv2,\n\t\tsBv1 = numProps.sBv1,\n\t\tsBv2 = numProps.sBv2,\n\t\tcount = sAv2 - sAv1 + 1;\n\n\tvar after = {\n\t\tdifference: [sBv2+1, sAv2],\n\t\tintersection: [sAv1,sBv2],\n\t\tunion: [sBv1, sAv2],\n\t\tcount: count,\n\t\tmeta: \"after\"\n\t};\n\tvar before = {\n\t\tdifference: [sAv1, sBv1-1],\n\t\tintersection: [sBv1,sAv2],\n\t\tunion: [sAv1, sBv2],\n\t\tcount: count,\n\t\tmeta: \"before\"\n\t};\n\n\t// if the sets are equal\n\tif(sAv1 === sBv1 && sAv2 === sBv2) {\n\t\treturn {\n\t\t\tintersection: [sAv1,sAv2],\n\t\t\tunion: [sAv1,sAv2],\n\t\t\tcount: count,\n\t\t\tmeta: \"equal\"\n\t\t};\n\t}\n\t// A starts at B but A ends later\n\telse if( sAv1 === sBv1 && sBv2 < sAv2 ) {\n\t\treturn after;\n\t}\n\t// A end at B but A starts earlier\n\telse if( sAv2 === sBv2 && sBv1 > sAv1 ) {\n\t\treturn before;\n\t}\n\t// B contains A\n\telse if( within(sAv1, [sBv1, sBv2]) && within(sAv2, [sBv1, sBv2]) ) {\n\t\treturn {\n\t\t\tintersection: [sAv1,sAv2],\n\t\t\tunion: [sBv1, sBv2],\n\t\t\tcount: count,\n\t\t\tmeta: \"subset\"\n\t\t};\n\t}\n\t// A contains B\n\telse if( within(sBv1, [sAv1, sAv2]) && within(sBv2, [sAv1, sAv2]) ) {\n\t\treturn {\n\t\t\tintersection: [sBv1,sBv2],\n\t\t\t// there is a difference in what A has\n\t\t\tdifference: [null, null],\n\t\t\tunion: [sAv1, sAv2],\n\t\t\tcount: count,\n\t\t\tmeta: \"superset\"\n\t\t};\n\t}\n\t// setA starts earlier and overlaps setB\n\telse if(sAv1 < sBv1 && within(sAv2, [sBv1, sBv2]) ) {\n\t\treturn before;\n\t}\n\t// setB starts earlier and overlaps setA\n\telse if(sBv1 < sAv1 && within(sBv2, [sAv1, sAv2]) ) {\n\t\treturn after;\n\t}\n\t// side by side ... nothing intersection\n\telse if(sAv2 === sBv1-1) {\n\t\treturn {\n\t\t\tdifference: [sAv1,sAv2],\n\t\t\tunion: [sAv1, sBv2],\n\t\t\tcount: count,\n\t\t\tmeta: \"disjoint-before\"\n\t\t};\n\t}\n\n\telse if(sBv2 === sAv1 - 1) {\n\t\treturn {\n\t\t\tdifference: [sAv1,sAv2],\n\t\t\tunion: [sBv1, sAv2],\n\t\t\tcount: count,\n\t\t\tmeta: \"disjoint-after\"\n\t\t};\n\t}\n\tif(!isNaN(count)) {\n\t\treturn {\n\t\t\tcount: count,\n\t\t\tmeta: \"disjoint\"\n\t\t};\n\t}\n\n}", "label": 3}
{"code": "public static <E> void addInPlace(Counter<E> target, double value) {\r\n    for (E key : target.keySet()) {\r\n      target.incrementCount(key, value);\r\n    }\r\n  }", "label": 0}
{"code": "def main():\n    \"\"\"Get status from APC NIS and print output on stdout.\"\"\"\n    # No need to use \"proper\" names on such simple code.\n    # pylint: disable=invalid-name\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--host\", default=\"localhost\")\n    p.add_argument(\"--port\", type=int, default=3551)\n    p.add_argument(\"--strip-units\", action=\"store_true\", default=False)\n    args = p.parse_args()\n    status.print_status(\n        status.get(args.host, args.port),\n        strip_units=args.strip_units\n    )", "label": 1}
{"code": "function copyBuffer(buf, pos, len) {\n  var copy = new Buffer(len);\n  buf.copy(copy, 0, pos, pos + len);\n  return copy;\n}", "label": 3}
{"code": "def on_deleted(self, event):\n        \"\"\"\n        Event Handler when a file is deleted\n        \"\"\"\n        key = 'filesystem:file_deleted'\n        data = {\n            'filepath': event.src_path,\n            'is_directory': event.is_directory,\n            'dirpath': os.path.dirname(event.src_path)\n        }\n\n        bmsg = BroadcastMessage(key=key, data=data)\n        BroadcastManager.broadcast(bmsg)", "label": 1}
{"code": "func (fe *fieldError) StructField() string {\n\t// return fe.structField\n\treturn fe.structNs[len(fe.structNs)-int(fe.structfieldLen):]\n}", "label": 5}
{"code": "public static policystringmap get(nitro_service service, String name) throws Exception{\n\t\tpolicystringmap obj = new policystringmap();\n\t\tobj.set_name(name);\n\t\tpolicystringmap response = (policystringmap) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private void handleRequestNodeInfoResponse(SerialMessage incomingMessage) {\n\t\tlogger.trace(\"Handle RequestNodeInfo Response\");\n\t\tif(incomingMessage.getMessageBuffer()[2] != 0x00)\n\t\t\tlogger.debug(\"Request node info successfully placed on stack.\");\n\t\telse\n\t\t\tlogger.error(\"Request node info not placed on stack due to error.\");\n\t}", "label": 0}
{"code": "protected function performJsonEncoding($content, array $jsonEncodeOptions = [])\n    {\n        $jsonEncodeOptions = $this->filterJsonEncodeOptions($jsonEncodeOptions);\n\n        $optionsBitmask = $this->calucateJsonEncodeOptionsBitmask($jsonEncodeOptions);\n\n        if (($encodedString = json_encode($content, $optionsBitmask)) === false) {\n            throw new \\ErrorException('Error encoding data in JSON format: '.json_last_error());\n        }\n\n        return $encodedString;\n    }", "label": 2}
{"code": "public function mutateRows(array $rowMutations, array $options = [])\n    {\n        if (!$this->isAssoc($rowMutations)) {\n            throw new \\InvalidArgumentException(\n                'Expected rowMutations to be of type associative array, instead got list.'\n            );\n        }\n        $entries = [];\n        foreach ($rowMutations as $rowKey => $mutations) {\n            $entries[] = $this->toEntry($rowKey, $mutations);\n        }\n        $this->mutateRowsWithEntries($entries, $options);\n    }", "label": 2}
{"code": "def remove(filename)\n      path = File.join(dir, filename)\n      gzip = \"#{path}.gz\"\n      logical_path = files[filename]['logical_path']\n\n      if assets[logical_path] == filename\n        assets.delete(logical_path)\n      end\n\n      files.delete(filename)\n      FileUtils.rm(path) if File.exist?(path)\n      FileUtils.rm(gzip) if File.exist?(gzip)\n\n      save\n\n      logger.info \"Removed #{filename}\"\n\n      nil\n    end", "label": 4}
{"code": "public static base_responses update(nitro_service client, route resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\troute updateresources[] = new route[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new route();\n\t\t\t\tupdateresources[i].network = resources[i].network;\n\t\t\t\tupdateresources[i].netmask = resources[i].netmask;\n\t\t\t\tupdateresources[i].gateway = resources[i].gateway;\n\t\t\t\tupdateresources[i].td = resources[i].td;\n\t\t\t\tupdateresources[i].distance = resources[i].distance;\n\t\t\t\tupdateresources[i].cost1 = resources[i].cost1;\n\t\t\t\tupdateresources[i].weight = resources[i].weight;\n\t\t\t\tupdateresources[i].advertise = resources[i].advertise;\n\t\t\t\tupdateresources[i].protocol = resources[i].protocol;\n\t\t\t\tupdateresources[i].msr = resources[i].msr;\n\t\t\t\tupdateresources[i].monitor = resources[i].monitor;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function order($property, $direction = self::ORDER_DEFAULT)\n    {\n        $this->query['order'][] = [\n            'property' => $this->propertyName($property),\n            'direction' => $direction\n        ];\n\n        return $this;\n    }", "label": 2}
{"code": "function Schema(options) {\n  this.options = options || {};\n  this.data = new Data();\n  this.isSchema = true;\n  this.utils = utils;\n  this.initSchema();\n  this.addFields(this.options);\n  var only = utils.arrayify(this.options.pick || this.options.only);\n  utils.define(this.options, 'only', only);\n}", "label": 3}
{"code": "async def dump_container(obj, container, container_type, params=None, field_archiver=None):\n    \"\"\"\n    Serializes container as popo\n\n    :param obj:\n    :param container:\n    :param container_type:\n    :param params:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    field_archiver = field_archiver if field_archiver else dump_field\n    elem_type = params[0] if params else None\n    if elem_type is None:\n        elem_type = container_type.ELEM_TYPE\n\n    obj = [] if obj is None else get_elem(obj)\n    if container is None:\n        return None\n    for elem in container:\n        fvalue = await field_archiver(None, elem, elem_type, params[1:] if params else None)\n        obj.append(fvalue)\n    return obj", "label": 1}
{"code": "def call(obj, method, *args, **kwargs):\n    \"\"\"\n    Allows to call any method of any object with parameters.\n\n    Because come on! It's bloody stupid that Django's templating engine doesn't\n    allow that.\n\n    Usage::\n\n        {% call myobj 'mymethod' myvar foobar=myvar2 as result %}\n        {% call myobj 'mydict' 'mykey' as result %}\n        {% call myobj 'myattribute' as result %}\n\n    :param obj: The object which has the method that you would like to call\n    :param method: A string representing the attribute on the object that\n      should be called.\n\n    \"\"\"\n    function_or_dict_or_member = getattr(obj, method)\n    if callable(function_or_dict_or_member):\n        # If it is a function, let's call it\n        return function_or_dict_or_member(*args, **kwargs)\n    if not len(args):\n        # If it is a member, lets return it\n        return function_or_dict_or_member\n    # If it is a dict, let's access one of it's keys\n    return function_or_dict_or_member[args[0]]", "label": 1}
{"code": "function copyFiles (inSrc, outSrc, files) {\n\treturn new Promise((res, rej) => {\n\t\tfor (const file of files) {\n\t\t\tcopySync(`./${inSrc}/${file}`, `./${outSrc}/${file}`);\n\t\t}\n\t\tres();\n\t});\n}", "label": 3}
{"code": "def reconnect\n      tries = 0\n      begin\n        data_store.reconnect\n      rescue Redis::BaseConnectionError\n        if (tries += 1) <= 3\n          log_with_severity :error, \"Error reconnecting to Redis; retrying\"\n          sleep(tries)\n          retry\n        else\n          log_with_severity :error, \"Error reconnecting to Redis; quitting\"\n          raise\n        end\n      end\n    end", "label": 4}
{"code": "public static filterpolicy_lbvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tfilterpolicy_lbvserver_binding obj = new filterpolicy_lbvserver_binding();\n\t\tobj.set_name(name);\n\t\tfilterpolicy_lbvserver_binding response[] = (filterpolicy_lbvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static boolean containsAtLeastOneNonBlank(List<String> list){\n\t\tfor(String str : list){\n\t\t\tif(StringUtils.isNotBlank(str)){\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "label": 0}
{"code": "func MakeTable(headers []string) Table {\n\tt := MakeHeadlessTable(len(headers))\n\tfor i := range t.columns {\n\t\tt.columns[i].title = headers[i]\n\t\tt.columns[i].width = len(headers[i])\n\t}\n\treturn t\n}", "label": 5}
{"code": "def assign_provider_attrs(user, auth_hash)\n      attrs = auth_hash['info'].slice(*user.attribute_names)\n      user.assign_attributes(attrs)\n    end", "label": 4}
{"code": "def delete(v)\n      return unless include? v\n      raise ArgumentError, \"Item is protected and cannot be deleted\" if protected? index(v)\n      @list.delete v\n    end", "label": 4}
{"code": "function _gpfRemoveEventListener (event, eventsHandler) {\n    /*jshint validthis:true*/ // will be invoked as an object method\n    var listeners = this._eventDispatcherListeners,\n        eventListeners,\n        index;\n    if (listeners) {\n        eventListeners = listeners[event];\n        if (undefined !== eventListeners) {\n            index = eventListeners.indexOf(eventsHandler);\n            if (-1 !== index) {\n                eventListeners.splice(index, 1);\n            }\n        }\n    }\n    return this;\n}", "label": 3}
{"code": "def require(key)\n      return key.map { |k| require(k) } if key.is_a?(Array)\n      value = self[key]\n      if value.present? || value == false\n        value\n      else\n        raise ParameterMissing.new(key)\n      end\n    end", "label": 4}
{"code": "public function diffInWeekendDays($date = null, $absolute = true)\n    {\n        return $this->diffInDaysFiltered(function (CarbonInterface $date) {\n            return $date->isWeekend();\n        }, $date, $absolute);\n    }", "label": 2}
{"code": "public function rowCounts()\n    {\n        if (!$this->rowCounts) {\n            foreach ($this->data['resultSets'] as $resultSet) {\n                $this->rowCounts[] = $resultSet['stats']['rowCountExact'];\n            }\n        }\n\n        return $this->rowCounts;\n    }", "label": 2}
{"code": "function Unswitch(settings) {\n  const buttonState = {};\n  let axesPosition = 8;\n\n  for (let i = buttonMappings.length - 1; i >= 0; i -= 1) {\n    buttonState[buttonMappings[i]] = { pressed: false };\n  }\n\n  this.update = () => {\n    const gamepads = navigator.getGamepads();\n    for (let i = Object.keys(gamepads).length - 1; i >= 0; i -= 1) {\n      if (gamepads[i] && gamepads[i].id && gamepads[i].id.indexOf(settings.side) !== -1) {\n        this.observe(gamepads[i]);\n        break;\n      }\n    }\n  };\n\n  this.observe = (pad) => {\n    const { buttons, axes } = pad;\n    for (let j = buttonMappings.length - 1; j >= 0; j -= 1) {\n      const button = buttonMappings[j];\n      if (buttonState[button].pressed !== buttons[j].pressed) {\n        buttonState[button].pressed = buttons[j].pressed;\n        if (settings[button]) {\n          settings[button](buttonState[button].pressed);\n        }\n\n        if (settings.buttons) {\n          settings.buttons(button, buttonState[button].pressed, settings.side);\n        }\n      }\n    }\n    if (settings.axes) {\n      const position = getAxesPosition(axes, buttons);\n      if (position !== axesPosition) {\n        settings.axes(position);\n        axesPosition = position;\n      }\n    }\n  };\n}", "label": 3}
{"code": "def block_count(self):\n        \"\"\"\n        Reports the number of blocks in the ledger and unchecked synchronizing\n        blocks\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.block_count()\n        {\n          \"count\": 1000,\n          \"unchecked\": 10\n        }\n\n        \"\"\"\n\n        resp = self.call('block_count')\n\n        for k, v in resp.items():\n            resp[k] = int(v)\n\n        return resp", "label": 1}
{"code": "public function getTraitsOfClass($class)\n    {\n        $definitions = [];\n\n        // in case there is a hierarchy of classes\n        $classes = $this->getSuperClasses($class);\n        if (is_array($classes)) {\n            foreach ($classes as $subClass) {\n                if (isset($subClass['traits'])) {\n                    foreach ($subClass['traits'] as $classTrait) {\n                        foreach ($this->traits as $trait) {\n                            if ($classTrait === $trait['trait']) {\n                                $traitDefinition[$trait['trait']] = $trait;\n                                $definitions = array_merge($definitions, $traitDefinition);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        // trait used by the given class\n        $classDefinition = isset($this->classes[$class]) ? $this->classes[$class] : null;\n        if (!$classDefinition || empty($classDefinition['traits'])) {\n            return $definitions;\n        }\n        $classTraits = $classDefinition['traits'];\n        foreach ($this->traits as $trait) {\n            foreach ($classTraits as $classTrait => $name) {\n                if ($trait['trait'] === $name) {\n                    $traitDefinition[$name] = $trait;\n                    $definitions = array_merge($definitions, $traitDefinition);\n                }\n            }\n        }\n\n        return $definitions;\n    }", "label": 2}
{"code": "def fail(exception)\n      begin\n        run_failure_hooks(exception)\n      rescue Exception => e\n        raise e\n      ensure\n        Failure.create \\\n          :payload   => payload,\n          :exception => exception,\n          :worker    => worker,\n          :queue     => queue\n      end\n    end", "label": 4}
{"code": "func (tc *TeleportClient) ConnectToProxy(ctx context.Context) (*ProxyClient, error) {\n\tvar err error\n\tvar proxyClient *ProxyClient\n\n\t// Use connectContext and the cancel function to signal when a response is\n\t// returned from connectToProxy.\n\tconnectContext, cancel := context.WithCancel(context.Background())\n\tgo func() {\n\t\tdefer cancel()\n\t\tproxyClient, err = tc.connectToProxy(ctx)\n\t}()\n\n\tselect {\n\t// ConnectToProxy returned a result, return that back to the caller.\n\tcase <-connectContext.Done():\n\t\treturn proxyClient, trace.Wrap(err)\n\t// The passed in context timed out. This is often due to the network being\n\t// down and the user hitting Ctrl-C.\n\tcase <-ctx.Done():\n\t\treturn nil, trace.ConnectionProblem(ctx.Err(), \"connection canceled\")\n\t}\n}", "label": 5}
{"code": "public static base_responses add(nitro_service client, snmpmanager resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmpmanager addresources[] = new snmpmanager[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new snmpmanager();\n\t\t\t\taddresources[i].ipaddress = resources[i].ipaddress;\n\t\t\t\taddresources[i].netmask = resources[i].netmask;\n\t\t\t\taddresources[i].domainresolveretry = resources[i].domainresolveretry;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def edit(self, resource):\n        \"\"\"Edit a config.\n\n        :param resource: :class:`configs.Config <configs.Config>` object\n        :return: :class:`configs.Config <configs.Config>` object\n        :rtype: configs.Config\n        \"\"\"\n        schema = self.EDIT_SCHEMA\n        json = self.service.encode(schema, resource)\n\n        schema = self.GET_SCHEMA\n        resp = self.service.edit(self.base, resource.id, json)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function configurePushDevice(options) {\n    return Q.when(promiseRegistrationEventResponse, function (registrationEventResponse) {\n        if (!registrationEventResponse) {\n            // either there is no configuration or since this method was called,\n            // registration was canceled\n            return Q.resolve(undefined);\n        }\n        // remaining implementation in push.ts as this is independent of Cordova...\n        return push.registerPushDevice(registrationEventResponse.registrationId, options);\n    });\n}", "label": 3}
{"code": "private function isCollection($name)\n    {\n        if (!$this->isRelative($name)) {\n            $name = $this->relativeName($name);\n        }\n\n        $parts = $this->splitName($name);\n        return count($parts) % 2 === 1;\n    }", "label": 2}
{"code": "def build_request(verb, uri, opts = {}) # rubocop:disable Style/OptionHash\n      opts    = @default_options.merge(opts)\n      uri     = make_request_uri(uri, opts)\n      headers = make_request_headers(opts)\n      body    = make_request_body(opts, headers)\n\n      req = HTTP::Request.new(\n        :verb           => verb,\n        :uri            => uri,\n        :uri_normalizer => opts.feature(:normalize_uri)&.normalizer,\n        :proxy          => opts.proxy,\n        :headers        => headers,\n        :body           => body\n      )\n\n      opts.features.inject(req) do |request, (_name, feature)|\n        feature.wrap_request(request)\n      end\n    end", "label": 4}
{"code": "public static base_responses enable(nitro_service client, Long clid[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (clid != null && clid.length > 0) {\n\t\t\tclusterinstance enableresources[] = new clusterinstance[clid.length];\n\t\t\tfor (int i=0;i<clid.length;i++){\n\t\t\t\tenableresources[i] = new clusterinstance();\n\t\t\t\tenableresources[i].clid = clid[i];\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, enableresources,\"enable\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def get_application_default scope = nil, options = {}\n      creds = DefaultCredentials.from_env(scope, options) ||\n              DefaultCredentials.from_well_known_path(scope, options) ||\n              DefaultCredentials.from_system_default_path(scope, options)\n      return creds unless creds.nil?\n      unless GCECredentials.on_gce? options\n        # Clear cache of the result of GCECredentials.on_gce?\n        GCECredentials.unmemoize_all\n        raise NOT_FOUND_ERROR\n      end\n      GCECredentials.new\n    end", "label": 4}
{"code": "private String[] readXMLDeclaration(Reader r) throws KNXMLException\r\n\t{\r\n\t\tfinal StringBuffer buf = new StringBuffer(100);\r\n\t\ttry {\r\n\t\t\tfor (int c = 0; (c = r.read()) != -1 && c != '?';)\r\n\t\t\t\tbuf.append((char) c);\r\n\t\t}\r\n\t\tcatch (final IOException e) {\r\n\t\t\tthrow new KNXMLException(\"reading XML declaration, \" + e.getMessage(), buf\r\n\t\t\t\t.toString(), 0);\r\n\t\t}\r\n\t\tString s = buf.toString().trim();\r\n\r\n\t\tString version = null;\r\n\t\tString encoding = null;\r\n\t\tString standalone = null;\r\n\r\n\t\tfor (int state = 0; state < 3; ++state)\r\n\t\t\tif (state == 0 && s.startsWith(\"version\")) {\r\n\t\t\t\tversion = getAttValue(s = s.substring(7));\r\n\t\t\t\ts = s.substring(s.indexOf(version) + version.length() + 1).trim();\r\n\t\t\t}\r\n\t\t\telse if (state == 1 && s.startsWith(\"encoding\")) {\r\n\t\t\t\tencoding = getAttValue(s = s.substring(8));\r\n\t\t\t\ts = s.substring(s.indexOf(encoding) + encoding.length() + 1).trim();\r\n\t\t\t}\r\n\t\t\telse if (state == 1 || state == 2) {\r\n\t\t\t\tif (s.startsWith(\"standalone\")) {\r\n\t\t\t\t\tstandalone = getAttValue(s);\r\n\t\t\t\t\tif (!standalone.equals(\"yes\") && !standalone.equals(\"no\"))\r\n\t\t\t\t\t\tthrow new KNXMLException(\"invalid standalone pseudo-attribute\",\r\n\t\t\t\t\t\t\tstandalone, 0);\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t\tthrow new KNXMLException(\"unknown XML declaration pseudo-attribute\", s, 0);\r\n\t\treturn new String[] { version, encoding, standalone };\r\n\t}", "label": 0}
{"code": "def string_to_hash(markup)\n      options = {}\n\n      if match = markup.match(Syntax)\n        markup.scan(TagAttributes) do |key, value|\n          options[key.to_sym] = value.gsub(/\\A\"|\"\\z/, \"\")\n        end\n      end\n\n      options\n    end", "label": 4}
{"code": "public function setPosixAccounts($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\OsLogin\\Common\\PosixAccount::class);\n        $this->posix_accounts = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function resolveEnvSources(env) {\n  let paths = [];\n\n  if (process.env[env]) {\n    paths = process.env[env].includes(path.delimiter) ? process.env[env].split(path.delimiter) : [process.env[env]];\n  }\n\n  return paths;\n}", "label": 3}
{"code": "function createDitcherInstance(mongoUrl, callback) {\n  // Default config used by ditcher if no connection string\n  // is provided\n  var config = {\n    database: {\n      host: process.env.MONGODB_HOST || '127.0.0.1',\n      port: process.env.FH_LOCAL_DB_PORT || 27017,\n      name: 'FH_LOCAL'\n    }\n  };\n\n  if (mongoUrl) {\n    try {\n      config = utils.parseMongoConnectionURL(mongoUrl);\n    } catch(e) {\n      return callback(e);\n    }\n  }\n\n  var versString = (mongoUrl) ? \"db per app\" : \"shared db\";\n  var ditcher = new fhditcher.Ditcher(config, logger, versString, function () {\n    return callback(null, ditcher);\n  });\n}", "label": 3}
{"code": "public int[] getVertexPointIndices() {\n        int[] indices = new int[numVertices];\n        for (int i = 0; i < numVertices; i++) {\n            indices[i] = vertexPointIndices[i];\n        }\n        return indices;\n    }", "label": 0}
{"code": "public function setLogoAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\EntityAnnotation::class);\n        $this->logo_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def configure_cache\n      Jekyll::Cache.cache_dir = in_source_dir(config[\"cache_dir\"], \"Jekyll/Cache\")\n      Jekyll::Cache.disable_disk_cache! if safe\n    end", "label": 4}
{"code": "func (s *remoteSite) nextConn() (*remoteConn, error) {\n\ts.Lock()\n\tdefer s.Unlock()\n\n\ts.removeInvalidConns()\n\n\tfor i := 0; i < len(s.connections); i++ {\n\t\ts.lastUsed = (s.lastUsed + 1) % len(s.connections)\n\t\tremoteConn := s.connections[s.lastUsed]\n\t\t// connection could have been initated, but agent\n\t\t// on the other side is not ready yet.\n\t\t// Proxy assumes that connection is ready to serve when\n\t\t// it has received a first heartbeat, otherwise\n\t\t// it could attempt to use it before the agent\n\t\t// had a chance to start handling connection requests,\n\t\t// what could lead to proxy marking the connection\n\t\t// as invalid without a good reason.\n\t\tif remoteConn.isReady() {\n\t\t\treturn remoteConn, nil\n\t\t}\n\t}\n\n\treturn nil, trace.NotFound(\"%v is offline: no active tunnels to %v found\", s.GetName(), s.srv.ClusterName)\n}", "label": 5}
{"code": "def add_exception_time(time)\n      return if time.nil?\n      rule = SingleOccurrenceRule.new(time)\n      add_exception_rule rule\n      time\n    end", "label": 4}
{"code": "func (c *TopCommand) Initialize(app *kingpin.Application, config *service.Config) {\n\tc.config = config\n\tc.top = app.Command(\"top\", \"Report diagnostic information\")\n\tc.diagURL = c.top.Arg(\"diag-addr\", \"Diagnostic HTTP URL\").Default(\"http://127.0.0.1:3434\").String()\n\tc.refreshPeriod = c.top.Arg(\"refresh\", \"Refresh period\").Default(\"5s\").Duration()\n}", "label": 5}
{"code": "func defaultIP(addr *net.TCPAddr) string {\n\tif !addr.IP.IsUnspecified() {\n\t\treturn addr.IP.String()\n\t}\n\n\tnics, err := net.Interfaces()\n\tif err != nil {\n\t\treturn addr.IP.String()\n\t}\n\n\tfor _, nic := range nics {\n\t\tif nic.Name == \"docker0\" || strings.HasPrefix(nic.Name, \"vmnet\") {\n\t\t\tcontinue\n\t\t}\n\t\taddrs, aerr := nic.Addrs()\n\t\tif aerr != nil {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, addr := range addrs {\n\t\t\tif ip, ok := addr.(*net.IPNet); ok && !ip.IP.IsLoopback() {\n\t\t\t\tif ip.IP.To4() != nil {\n\t\t\t\t\treturn ip.IP.String()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn addr.IP.String()\n}", "label": 5}
{"code": "def all_fields\n      fields = public_attributes.map do |name, type|\n        @template.content_tag(:div, input_field(name, type), class: \"field\")\n      end\n\n      safe_join(fields)\n    end", "label": 4}
{"code": "def advance(options)\n      # If we're advancing a value of variable length (i.e., years, weeks, months, days), advance from #time,\n      # otherwise advance from #utc, for accuracy when moving across DST boundaries\n      if options.values_at(:years, :weeks, :months, :days).any?\n        method_missing(:advance, options)\n      else\n        utc.advance(options).in_time_zone(time_zone)\n      end\n    end", "label": 4}
{"code": "function nest (str, refs, escape) {\n\t\tvar res = [], match\n\n\t\tvar a = 0\n\t\twhile (match = re.exec(str)) {\n\t\t\tif (a++ > 10e3) throw Error('Circular references in parenthesis')\n\n\t\t\tres.push(str.slice(0, match.index))\n\n\t\t\tres.push(nest(refs[match[1]], refs))\n\n\t\t\tstr = str.slice(match.index + match[0].length)\n\t\t}\n\n\t\tres.push(str)\n\n\t\treturn res\n\t}", "label": 3}
{"code": "function servicesRunning() {\n\t\t\tvar composeArgs = ['ps'];\n\n\t\t\t// If we're tailing just the main service's logs, then we only check that service\n\t\t\tif (service === '<%= dockerCompose.options.mainService %>') {\n\t\t\t\tcomposeArgs.push(grunt.config.get('dockerCompose.options.mainService'));\n\t\t\t}\n\n\t\t\t// get the stdout of docker-compose ps, store as Array, and drop the header lines.\n\t\t\tvar serviceList = spawn('docker-compose', composeArgs).stdout.toString().split('\\n').slice(2),\n\t\t\t\tupCount = 0;\n\n\t\t\t// if we are left with 1 line or less, then nothing is running.\n\t\t\tif (serviceList.length <= 1) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tfunction isUp(service) {\n\t\t\t\tif (service.indexOf('Up') > 0) {\n\t\t\t\t\tupCount++;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tserviceList.forEach(isUp);\n\n\t\t\treturn upCount > 0;\n\t\t}", "label": 3}
{"code": "public static base_responses update(nitro_service client, snmpuser resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmpuser updateresources[] = new snmpuser[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new snmpuser();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].group = resources[i].group;\n\t\t\t\tupdateresources[i].authtype = resources[i].authtype;\n\t\t\t\tupdateresources[i].authpasswd = resources[i].authpasswd;\n\t\t\t\tupdateresources[i].privtype = resources[i].privtype;\n\t\t\t\tupdateresources[i].privpasswd = resources[i].privpasswd;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function Handler(level) {\n\tlevel = level || Logger.NOTSET;\n\n\tif (Logger.getLevelName(level) === '') {\n\t\tthrow new Error('Argument 1 of Handler.constructor has unsupported'\n\t\t\t+ ' value \\'' + level + '\\'');\n\t}\n\n\tFilterer.call(this);\n\n\t/**\n\t * @private\n\t * @type {number}\n\t */\n\tthis._level = level;\n\n\t/**\n\t * @private\n\t * @type {Object}\n\t */\n\tthis._formatter = null;\n}", "label": 3}
{"code": "def get_configs(self):\n        \"\"\"\n        Return a list of all installed configs.\n        \"\"\"\n        self.check_configs_ready()\n\n        result = []\n        for bot in self.bots.values():\n            result.extend(list(bot.get_models()))\n        return result", "label": 1}
{"code": "public function loginAction(Request $request): Response\n    {\n        $authenticationUtils = $this->get('security.authentication_utils');\n        $error = $authenticationUtils->getLastAuthenticationError();\n        $lastUsername = $authenticationUtils->getLastUsername();\n\n        $options = $request->attributes->get('_sylius');\n\n        $template = $options['template'] ?? null;\n        Assert::notNull($template, 'Template is not configured.');\n\n        $formType = $options['form'] ?? UserLoginType::class;\n        $form = $this->get('form.factory')->createNamed('', $formType);\n\n        return $this->render($template, [\n            'form' => $form->createView(),\n            'last_username' => $lastUsername,\n            'error' => $error,\n        ]);\n    }", "label": 2}
{"code": "public synchronized void createImportationDeclaration(String deviceId, String deviceType, String deviceSubType) {\n        Map<String, Object> metadata = new HashMap<String, Object>();\n        metadata.put(Constants.DEVICE_ID, deviceId);\n        metadata.put(Constants.DEVICE_TYPE, deviceType);\n        metadata.put(Constants.DEVICE_TYPE_SUB, deviceSubType);\n        metadata.put(\"scope\", \"generic\");\n        ImportDeclaration declaration = ImportDeclarationBuilder.fromMetadata(metadata).build();\n\n        importDeclarations.put(deviceId, declaration);\n\n        registerImportDeclaration(declaration);\n    }", "label": 0}
{"code": "private static function extract_tarball( $tarball, $dest ) {\n\n\t\tif ( class_exists( 'PharData' ) ) {\n\t\t\ttry {\n\t\t\t\t$phar    = new PharData( $tarball );\n\t\t\t\t$tempdir = implode(\n\t\t\t\t\tDIRECTORY_SEPARATOR,\n\t\t\t\t\tarray(\n\t\t\t\t\t\tdirname( $tarball ),\n\t\t\t\t\t\tUtils\\basename( $tarball, '.tar.gz' ),\n\t\t\t\t\t\t$phar->getFilename(),\n\t\t\t\t\t)\n\t\t\t\t);\n\n\t\t\t\t$phar->extractTo( dirname( $tempdir ), null, true );\n\n\t\t\t\tself::copy_overwrite_files( $tempdir, $dest );\n\n\t\t\t\tself::rmdir( dirname( $tempdir ) );\n\t\t\t\treturn;\n\t\t\t} catch ( \\Exception $e ) {\n\t\t\t\tWP_CLI::warning( \"PharData failed, falling back to 'tar xz' (\" . $e->getMessage() . ')' );\n\t\t\t\t// Fall through to trying `tar xz` below\n\t\t\t}\n\t\t}\n\t\t// Note: directory must exist for tar --directory to work.\n\t\t$cmd         = Utils\\esc_cmd( 'tar xz --strip-components=1 --directory=%s -f %s', $dest, $tarball );\n\t\t$process_run = WP_CLI::launch( $cmd, false /*exit_on_error*/, true /*return_detailed*/ );\n\t\tif ( 0 !== $process_run->return_code ) {\n\t\t\tthrow new \\Exception( sprintf( 'Failed to execute `%s`: %s.', $cmd, self::tar_error_msg( $process_run ) ) );\n\t\t}\n\t}", "label": 2}
{"code": "function writeFile(filePath, fileContent, regex) {\n\tfs.writeFileSync(filePath, fileContent.replace(regex, ''));\n}", "label": 3}
{"code": "function() {\n      var behaviorContext = Behavior.prototype.prepare.apply(this) || {};\n      behaviorContext.data = this.data.toJSON();\n      behaviorContext.loading = this.isLoading();\n      behaviorContext.loadingIds = this.isLoadingIds();\n      behaviorContext.loadingObjects = this.isLoadingObjects();\n      return behaviorContext;\n    }", "label": 3}
{"code": "protected function validate_key( $key ) {\n\t\t$url_parts = Utils\\parse_url( $key, -1, false );\n\t\tif ( ! empty( $url_parts['scheme'] ) ) { // is url\n\t\t\t$parts   = array( 'misc' );\n\t\t\t$parts[] = $url_parts['scheme'] . '-' . $url_parts['host'] .\n\t\t\t\t( empty( $url_parts['port'] ) ? '' : '-' . $url_parts['port'] );\n\t\t\t$parts[] = substr( $url_parts['path'], 1 ) .\n\t\t\t\t( empty( $url_parts['query'] ) ? '' : '-' . $url_parts['query'] );\n\t\t} else {\n\t\t\t$key   = str_replace( '\\\\', '/', $key );\n\t\t\t$parts = explode( '/', ltrim( $key ) );\n\t\t}\n\n\t\t$parts = preg_replace( \"#[^{$this->whitelist}]#i\", '-', $parts );\n\n\t\treturn implode( '/', $parts );\n\t}", "label": 2}
{"code": "def process_shells_ordered(self, shells):\n        \"\"\"Processing a list of shells one after the other.\"\"\"\n        output = []\n        for shell in shells:\n            entry = shell['entry']\n            config = ShellConfig(script=entry['script'], title=entry['title'] if 'title' in entry else '',\n                                 model=shell['model'], env=shell['env'], item=shell['item'],\n                                 dry_run=shell['dry_run'], debug=shell['debug'], strict=shell['strict'],\n                                 variables=shell['variables'],\n                                 temporary_scripts_path=shell['temporary_scripts_path'])\n            result = Adapter(self.process_shell(get_creator_by_name(shell['creator']), entry, config))\n            output += result.output\n            self.__handle_variable(entry, result.output)\n            if not result.success:\n                return {'success': False, 'output': output}\n        return {'success': True, 'output': output}", "label": 1}
{"code": "function addAttribute() {\n    var attribute =\n      arguments.length === 1 && arguments[0] instanceof attributes.Attribute ?\n        arguments[0] :\n        attributes.Attribute.resolve.apply(\n          null,\n          Array.prototype.slice.call(arguments)\n        );\n\n    var newAttributes = attributes.AttributeDictionary.concat(\n      _attributes,\n      attribute\n    );\n\n    if (_Entity) {\n      _loadEntityAttribute(attribute);\n    }\n\n    _attributes = newAttributes;\n  }", "label": 3}
{"code": "def update_file(file_data)\n      sha = file_data['sha256']\n      file_dir = create_cache_dir(file_data['sha256'])\n      file_path = File.join(file_dir, File.basename(file_data['filename']))\n      if check_file(file_path, sha)\n        @logger.debug(\"Using prexisting task file: #{file_path}\")\n        return file_path\n      end\n\n      @logger.debug(\"Queueing download for: #{file_path}\")\n      serial_execute { download_file(file_path, sha, file_data['uri']) }\n    end", "label": 4}
{"code": "def write_collection_begin(elem_type, size)\n      if size <= 14\n        write_byte(size << 4 | CompactTypes.get_compact_type(elem_type))\n      else\n        write_byte(0xf0 | CompactTypes.get_compact_type(elem_type))\n        write_varint32(size)\n      end\n    end", "label": 4}
{"code": "def convert_html_entities(text_string):\n    '''\n    Converts HTML5 character references within text_string to their corresponding unicode characters\n    and returns converted string as type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a non-string argument be passed\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        return html.unescape(text_string).replace(\"&quot;\", \"'\")\n    else:\n        raise InputError(\"string not passed as argument for text_string\")", "label": 1}
{"code": "protected org.apache.log4j.helpers.PatternParser createPatternParser(final String pattern) {\n\t\treturn new FoundationLoggingPatternParser(pattern);\n\t}", "label": 0}
{"code": "public static dnspolicy64_lbvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tdnspolicy64_lbvserver_binding obj = new dnspolicy64_lbvserver_binding();\n\t\tobj.set_name(name);\n\t\tdnspolicy64_lbvserver_binding response[] = (dnspolicy64_lbvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "protected function getCustomRelationship($model, $name)\n    {\n        $relationship = static::$dispatcher->until(\n            new GetApiRelationship($this, $name, $model)\n        );\n\n        if ($relationship && ! ($relationship instanceof Relationship)) {\n            throw new LogicException(\n                'GetApiRelationship handler must return an instance of '.Relationship::class\n            );\n        }\n\n        return $relationship;\n    }", "label": 2}
{"code": "def _load_npy(self, filename):\n        \"\"\"\n        Load image using Numpy.\n        \"\"\"\n        self._channel_data = []\n        self._original_channel_data = []\n        file_channel_data = np.load(filename)\n        file_channel_data = file_channel_data / file_channel_data.max()\n\n        for i in range(file_channel_data.shape[2]):\n            self._channel_data.append(file_channel_data[:, :, i])\n            self._original_channel_data.append(file_channel_data[:, :, i])\n\n        self._image = file_channel_data.sum(2) / file_channel_data.shape[2]", "label": 1}
{"code": "public static base_response update(nitro_service client, vpnclientlessaccesspolicy resource) throws Exception {\n\t\tvpnclientlessaccesspolicy updateresource = new vpnclientlessaccesspolicy();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.rule = resource.rule;\n\t\tupdateresource.profilename = resource.profilename;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "@GET\n    @Produces({MediaType.TEXT_HTML, MediaType.APPLICATION_JSON})\n    @Path(\"/{name}\" + ServerAPI.GET_CORPORATE_GROUPIDS)\n    public Response getCorporateGroupIdPrefix(@PathParam(\"name\") final String organizationId){\n        LOG.info(\"Got a get corporate groupId prefix request for organization \" + organizationId +\".\");\n\n        final ListView view = new ListView(\"Organization \" + organizationId, \"Corporate GroupId Prefix\");\n        final List<String> corporateGroupIds = getOrganizationHandler().getCorporateGroupIds(organizationId);\n        view.addAll(corporateGroupIds);\n\n        return Response.ok(view).build();\n    }", "label": 0}
{"code": "public function setStructuredDegree($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\Degree::class);\n        $this->writeOneof(7, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def shuffle_genome(genome, cat, fraction = float(100), plot = True, \\\n        alpha = 0.1, beta = 100000, \\\n        min_length = 1000, max_length = 200000):\n    \"\"\"\n    randomly shuffle genome\n    \"\"\"\n    header = '>randomized_%s' % (genome.name)\n    sequence = list(''.join([i[1] for i in parse_fasta(genome)]))\n    length = len(sequence)\n    shuffled = []\n    # break genome into pieces\n    while sequence is not False:\n        s = int(random.gammavariate(alpha, beta))\n        if s <= min_length or s >= max_length:\n            continue\n        if len(sequence) < s:\n            seq = sequence[0:]\n        else:\n            seq = sequence[0:s]\n        sequence = sequence[s:]\n#        if bool(random.getrandbits(1)) is True:\n#            seq = rev_c(seq)\n#            print('fragment length: %s reverse complement: True' % ('{:,}'.format(s)), file=sys.stderr)\n#        else:\n#            print('fragment length: %s reverse complement: False' % ('{:,}'.format(s)), file=sys.stderr)\n        shuffled.append(''.join(seq))\n        if sequence == []:\n            break\n    # shuffle pieces\n    random.shuffle(shuffled)\n    # subset fragments\n    if fraction == float(100):\n        subset = shuffled\n    else:\n        max_pieces = int(length * fraction/100)\n        subset, total = [], 0\n        for fragment in shuffled:\n            length = len(fragment)\n            if total + length <= max_pieces:\n                subset.append(fragment)\n                total += length\n            else:\n                diff = max_pieces - total\n                subset.append(fragment[0:diff])\n                break\n    # combine sequences, if requested\n    if cat is True:\n        yield [header, ''.join(subset)]\n    else:\n        for i, seq in enumerate(subset):\n            yield ['%s fragment:%s' % (header, i), seq]", "label": 1}
{"code": "function iniFileSet(file, section, key, value, options) {\n  options = _.sanitize(options, {encoding: 'utf-8', retryOnENOENT: true});\n  if (typeof key === 'object') {\n    if (typeof value === 'object') {\n      options = value;\n    } else {\n      options = {};\n    }\n  }\n  if (!exists(file)) {\n    touch(file, '', options);\n  } else if (!isFile(file)) {\n    throw new Error(`File ${file} is not a file`);\n  }\n  const config = ini.parse(read(file, {encoding: options.encoding}));\n  if (!_.isEmpty(section)) {\n    config[section] = config[section] || {};\n    section = config[section];\n  } else {\n    section = config;\n  }\n  if (typeof key === 'string') {\n    section[key] = value;\n  } else {\n    _.merge(section, key);\n  }\n  write(file, ini.stringify(config), options);\n}", "label": 3}
{"code": "func setMacVlanMode(mode string) (netlink.MacvlanMode, error) {\n\tswitch mode {\n\tcase modePrivate:\n\t\treturn netlink.MACVLAN_MODE_PRIVATE, nil\n\tcase modeVepa:\n\t\treturn netlink.MACVLAN_MODE_VEPA, nil\n\tcase modeBridge:\n\t\treturn netlink.MACVLAN_MODE_BRIDGE, nil\n\tcase modePassthru:\n\t\treturn netlink.MACVLAN_MODE_PASSTHRU, nil\n\tdefault:\n\t\treturn 0, fmt.Errorf(\"unknown macvlan mode: %s\", mode)\n\t}\n}", "label": 5}
{"code": "function(next) {\n            if (!cluster.isWorker && !core.worker && process.getuid() == 0) {\n                lib.findFileSync(core.path.spool).forEach(function(p) { lib.chownSync(core.uid, core.gid, p); });\n            }\n            next();\n        }", "label": 3}
{"code": "public function noCalendar(bool $noCalendar = true) : self\n    {\n        $this->enableTime();\n        $this->set('data-fields--datetime-no-calendar', var_export($noCalendar, true));\n\n        return $this;\n    }", "label": 2}
{"code": "function updateObject(entityObject) {\n  var mongoAdapter = this;\n\n  expect(arguments).to.have.length(\n    1,\n    'Invalid arguments length when updating an object in a MongoAdapter ' +\n    '(it has to be passed 1 argument)'\n  );\n\n  return new Promise(function (resolve, reject) {\n    expect(entityObject).to.be.an.instanceOf(\n      Entity,\n      'Invalid argument \"entityObject\" when updating an object in a ' +\n      'MongoAdapter (it has to be an Entity instance)'\n    );\n\n    var EntityClass = entityObject.Entity;\n\n    mongoAdapter\n      .getDatabase()\n      .then(function (database) {\n        return database\n          .collection(getEntityCollectionName(EntityClass))\n          .updateOne(\n            {_id: entityObject.id},\n            {$set: objectToDocument(entityObject, true)}\n          );\n      })\n      .then(function (result) {\n        expect(result.matchedCount).to.equal(\n          1,\n          'Invalid result.matchedCount return of collection.updateOne ' +\n          'in MongoDB driver when inserting an Object (it should be 1)'\n        );\n\n        resolve();\n      })\n      .catch(reject);\n  });\n}", "label": 3}
{"code": "public static base_response update(nitro_service client, route resource) throws Exception {\n\t\troute updateresource = new route();\n\t\tupdateresource.network = resource.network;\n\t\tupdateresource.netmask = resource.netmask;\n\t\tupdateresource.gateway = resource.gateway;\n\t\tupdateresource.td = resource.td;\n\t\tupdateresource.distance = resource.distance;\n\t\tupdateresource.cost1 = resource.cost1;\n\t\tupdateresource.weight = resource.weight;\n\t\tupdateresource.advertise = resource.advertise;\n\t\tupdateresource.protocol = resource.protocol;\n\t\tupdateresource.msr = resource.msr;\n\t\tupdateresource.monitor = resource.monitor;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def dump_collection(cfg, f, indent=0):\n    '''Save a collection of attributes'''\n\n    for i, value in enumerate(cfg):\n        dump_value(None, value, f, indent)\n        if i < len(cfg) - 1:\n            f.write(u',\\n')", "label": 1}
{"code": "func FSUnlock(f *os.File) error {\n\tif err := syscall.Flock(int(f.Fd()), syscall.LOCK_UN); err != nil {\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def greedy_merge_helper(\n        variant_sequences,\n        min_overlap_size=MIN_VARIANT_SEQUENCE_ASSEMBLY_OVERLAP_SIZE):\n    \"\"\"\n    Returns a list of merged VariantSequence objects, and True if any\n    were successfully merged.\n    \"\"\"\n    merged_variant_sequences = {}\n    merged_any = False\n\n    # here we'll keep track of sequences that haven't been merged yet, and add them in at the end\n    unmerged_variant_sequences = set(variant_sequences)\n    for i in range(len(variant_sequences)):\n        sequence1 = variant_sequences[i]\n        # it works to loop over the triangle (i+1 onwards) because combine() tries flipping the\n        # arguments if sequence1 is on the right of sequence2\n        for j in range(i + 1, len(variant_sequences)):\n            sequence2 = variant_sequences[j]\n            combined = sequence1.combine(sequence2)\n            if combined is None:\n                continue\n            if combined.sequence in merged_variant_sequences:\n                existing = merged_variant_sequences[combined.sequence]\n                # the existing VariantSequence and the newly merged\n                # VariantSequence should differ only in which reads support them\n                combined = combined.add_reads(existing.reads)\n            merged_variant_sequences[combined.sequence] = combined\n            unmerged_variant_sequences.discard(sequence1)\n            unmerged_variant_sequences.discard(sequence2)\n            merged_any = True\n    result = list(merged_variant_sequences.values()) + list(unmerged_variant_sequences)\n    return result, merged_any", "label": 1}
{"code": "public Document removeDocument(String key) throws PrintingException {\n\t\tif (documentMap.containsKey(key)) {\n\t\t\treturn documentMap.remove(key);\n\t\t} else {\n\t\t\tthrow new PrintingException(PrintingException.DOCUMENT_NOT_FOUND, key);\n\t\t}\n\t}", "label": 0}
{"code": "function (key, ch) {\n  key = note.create(key || 'C');\n  ch = chord.create(ch);\n\n  return new Mehegan(getNumeral(key, ch.root), getQuality(ch));\n}", "label": 3}
{"code": "public static function make($var)\n    {\n        if ($var instanceof DateInterval) {\n            return static::instance($var);\n        }\n\n        if (!is_string($var)) {\n            return null;\n        }\n\n        $var = trim($var);\n\n        if (preg_match('/^P[T0-9]/', $var)) {\n            return new static($var);\n        }\n\n        if (preg_match('/^(?:\\h*\\d+(?:\\.\\d+)?\\h*[a-z]+)+$/i', $var)) {\n            return static::fromString($var);\n        }\n\n        /** @var static $interval */\n        $interval = static::createFromDateString($var);\n\n        return $interval->isEmpty() ? null : $interval;\n    }", "label": 2}
{"code": "func (p *pkg) scopeOf(id *ast.Ident) *types.Scope {\n\tvar scope *types.Scope\n\tif obj := p.typesInfo.ObjectOf(id); obj != nil {\n\t\tscope = obj.Parent()\n\t}\n\tif scope == p.typesPkg.Scope() {\n\t\t// We were given a top-level identifier.\n\t\t// Use the file-level scope instead of the package-level scope.\n\t\tpos := id.Pos()\n\t\tfor _, f := range p.files {\n\t\t\tif f.f.Pos() <= pos && pos < f.f.End() {\n\t\t\t\tscope = p.typesInfo.Scopes[f.f]\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn scope\n}", "label": 5}
{"code": "def check_for_missing_documents!(result, ids)\n      if (result.size < ids.size) && Mongoid.raise_not_found_error\n        raise Errors::DocumentNotFound.new(klass, ids, ids - result.map(&:_id))\n      end\n    end", "label": 4}
{"code": "func adminCreds() (*int, *int, error) {\n\tif runtime.GOOS != teleport.LinuxOS {\n\t\treturn nil, nil, nil\n\t}\n\t// if the user member of adm linux group,\n\t// make audit log folder readable by admins\n\tisAdmin, err := utils.IsGroupMember(teleport.LinuxAdminGID)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\tif !isAdmin {\n\t\treturn nil, nil, nil\n\t}\n\tuid := os.Getuid()\n\tgid := teleport.LinuxAdminGID\n\treturn &uid, &gid, nil\n}", "label": 5}
{"code": "public static function getOrMethod($method)\n    {\n        if (! Str::contains(Str::lower($method), 'or')) {\n            return 'or' . ucfirst($method);\n        }\n\n        return $method;\n    }", "label": 2}
{"code": "public static systembackup[] get(nitro_service service, options option) throws Exception{\n\t\tsystembackup obj = new systembackup();\n\t\tsystembackup[] response = (systembackup[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def retrieve_order(location_id, order_id, opts = {})\n      data, _status_code, _headers = retrieve_order_with_http_info(location_id, order_id, opts)\n      return data\n    end", "label": 4}
{"code": "def get_plaintext_citations(bibtex):\n    \"\"\"\n    Parse a BibTeX file to get a clean list of plaintext citations.\n\n    :param bibtex: Either the path to the BibTeX file or the content of a \\\n            BibTeX file.\n    :returns:  A list of cleaned plaintext citations.\n    \"\"\"\n    parser = BibTexParser()\n    parser.customization = convert_to_unicode\n    # Load the BibTeX\n    if os.path.isfile(bibtex):\n        with open(bibtex) as fh:\n            bib_database = bibtexparser.load(fh, parser=parser)\n    else:\n        bib_database = bibtexparser.loads(bibtex, parser=parser)\n    # Convert bibentries to plaintext\n    bibentries = [bibentry_as_plaintext(bibentry)\n                  for bibentry in bib_database.entries]\n    # Return them\n    return bibentries", "label": 1}
{"code": "def vcs_init(self):\n        \"\"\"Initialize VCS repository.\"\"\"\n        VCS(os.path.join(self.outdir, self.name), self.pkg_data)", "label": 1}
{"code": "function getArgumentIndexForTemplatePiece(spanIndex, node, position) {\n            // Because the TemplateStringsArray is the first argument, we have to offset each substitution expression by 1.\n            // There are three cases we can encounter:\n            //      1. We are precisely in the template literal (argIndex = 0).\n            //      2. We are in or to the right of the substitution expression (argIndex = spanIndex + 1).\n            //      3. We are directly to the right of the template literal, but because we look for the token on the left,\n            //          not enough to put us in the substitution expression; we should consider ourselves part of\n            //          the *next* span's expression by offsetting the index (argIndex = (spanIndex + 1) + 1).\n            //\n            // Example: f  `# abcd $#{#  1 + 1#  }# efghi ${ #\"#hello\"#  }  #  `\n            //              ^       ^ ^       ^   ^          ^ ^      ^     ^\n            // Case:        1       1 3       2   1          3 2      2     1\n            ts.Debug.assert(position >= node.getStart(), \"Assumed 'position' could not occur before node.\");\n            if (ts.isTemplateLiteralKind(node.kind)) {\n                if (ts.isInsideTemplateLiteral(node, position)) {\n                    return 0;\n                }\n                return spanIndex + 2;\n            }\n            return spanIndex + 1;\n        }", "label": 3}
{"code": "public static <T> T columnStringToObject(Class<?> objClass, String str, Pattern delimiterPattern, String[] fieldNames)\r\n          throws InstantiationException, IllegalAccessException, NoSuchMethodException, NoSuchFieldException, InvocationTargetException\r\n  {\r\n    String[] fields = delimiterPattern.split(str);\r\n    T item = ErasureUtils.<T>uncheckedCast(objClass.newInstance());\r\n    for (int i = 0; i < fields.length; i++) {\r\n      try {\r\n        Field field = objClass.getDeclaredField(fieldNames[i]);\r\n        field.set(item, fields[i]);\r\n      } catch (IllegalAccessException ex) {\r\n        Method method = objClass.getDeclaredMethod(\"set\" + StringUtils.capitalize(fieldNames[i]), String.class);\r\n        method.invoke(item, fields[i]);\r\n      }\r\n    }\r\n    return item;\r\n  }", "label": 0}
{"code": "public void registerDestructionCallback(String name, Runnable callback) {\n\t\tBean bean = beans.get(name);\n\t\tif (null == bean) {\n\t\t\tbean = new Bean();\n\t\t\tbeans.put(name, bean);\n\t\t}\n\t\tbean.destructionCallback = callback;\n\t}", "label": 0}
{"code": "def payment_begin(self, wallet):\n        \"\"\"\n        Begin a new payment session. Searches wallet for an account that's\n        marked as available and has a 0 balance. If one is found, the account\n        number is returned and is marked as unavailable. If no account is\n        found, a new account is created, placed in the wallet, and returned.\n\n        :param wallet: Wallet to begin payment in\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.payment_begin(\n        ... wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('payment_begin', payload)\n\n        return resp['account']", "label": 1}
{"code": "def find_word_prob(word_string, word_total=sum(WORD_DISTRIBUTION.values())):\n    '''\n    Finds the relative probability of the word appearing given context of a base corpus.\n    Returns this probability value as a float instance.\n    '''\n    if word_string is None:\n        return 0\n    elif isinstance(word_string, str):\n        return WORD_DISTRIBUTION[word_string] / word_total\n    else:\n        raise InputError(\"string or none type variable not passed as argument to find_word_prob\")", "label": 1}
{"code": "def to_xml_string(str='')\n      add_worksheet(name: 'Sheet1') unless worksheets.size > 0\n      str << '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n      str << ('<workbook xmlns=\"' << XML_NS << '\" xmlns:r=\"' << XML_NS_R << '\">')\n      str << ('<workbookPr date1904=\"' << @@date1904.to_s << '\"/>')\n      views.to_xml_string(str)\n      str << '<sheets>'\n      if is_reversed\n        worksheets.reverse_each { |sheet| sheet.to_sheet_node_xml_string(str) }\n      else\n        worksheets.each { |sheet| sheet.to_sheet_node_xml_string(str) }\n      end\n      str << '</sheets>'\n      defined_names.to_xml_string(str)\n      unless pivot_tables.empty?\n        str << '<pivotCaches>'\n        pivot_tables.each do |pivot_table|\n          str << ('<pivotCache cacheId=\"' << pivot_table.cache_definition.cache_id.to_s << '\" r:id=\"' << pivot_table.cache_definition.rId << '\"/>')\n        end\n        str << '</pivotCaches>'\n      end\n      str << '</workbook>'\n    end", "label": 4}
{"code": "def release\n      @refresh_mutex.synchronize {\n        @unlock = true\n\n        delete\n\n        @refresh_signal.signal\n      }\n\n\n      @refresh_thread.join if @refresh_thread\n      @event_manager.create_event(\n        {\n          user: Config.current_job.username,\n          action: 'release',\n          object_type: 'lock',\n          object_name: @name,\n          task: @task_id,\n          deployment: @deployment_name,\n        }\n      )\n    end", "label": 4}
{"code": "def send(self, message):\n        \"\"\"\n        Sends data to the server on the\n        subscription channel.\n\n        :param data: The JSON data to send.\n        \"\"\"\n        self.logger.debug('Send message: {}'.format(message))\n\n        if self.state == 'pending' or self.state == 'connection_pending':\n            self.logger.info('Connection not established. Add message to queue.')\n            self.message_queue.append(message)\n            return\n        elif self.state == 'unsubscribed' or self.state == 'rejected':\n            self.logger.warning('Not subscribed! Message discarded.')\n            return\n\n        data = {\n            'command': 'message',\n            'identifier': self._identifier_string(),\n            'data': message.raw_message()\n        }\n\n        self.connection.send(data)", "label": 1}
{"code": "function get(attr) {\n          var val = dotty.get(attrs, attr);\n          if (val === undefined) {\n            this.emit('undefined',\n              'WARNING: Undefined environment variable: ' + attr, attr);\n          }\n          return val;\n        }", "label": 3}
{"code": "func (mi *MetaInfo) SetDefaults() {\n\tmi.Comment = \"yoloham\"\n\tmi.CreatedBy = \"github.com/anacrolix/torrent\"\n\tmi.CreationDate = time.Now().Unix()\n\t// mi.Info.PieceLength = 256 * 1024\n}", "label": 5}
{"code": "public static vpnvserver_rewritepolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_rewritepolicy_binding obj = new vpnvserver_rewritepolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_rewritepolicy_binding response[] = (vpnvserver_rewritepolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setMode($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Datastore\\V1\\CommitRequest_Mode::class);\n        $this->mode = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_responses add(nitro_service client, nspbr6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnspbr6 addresources[] = new nspbr6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new nspbr6();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].td = resources[i].td;\n\t\t\t\taddresources[i].action = resources[i].action;\n\t\t\t\taddresources[i].srcipv6 = resources[i].srcipv6;\n\t\t\t\taddresources[i].srcipop = resources[i].srcipop;\n\t\t\t\taddresources[i].srcipv6val = resources[i].srcipv6val;\n\t\t\t\taddresources[i].srcport = resources[i].srcport;\n\t\t\t\taddresources[i].srcportop = resources[i].srcportop;\n\t\t\t\taddresources[i].srcportval = resources[i].srcportval;\n\t\t\t\taddresources[i].destipv6 = resources[i].destipv6;\n\t\t\t\taddresources[i].destipop = resources[i].destipop;\n\t\t\t\taddresources[i].destipv6val = resources[i].destipv6val;\n\t\t\t\taddresources[i].destport = resources[i].destport;\n\t\t\t\taddresources[i].destportop = resources[i].destportop;\n\t\t\t\taddresources[i].destportval = resources[i].destportval;\n\t\t\t\taddresources[i].srcmac = resources[i].srcmac;\n\t\t\t\taddresources[i].protocol = resources[i].protocol;\n\t\t\t\taddresources[i].protocolnumber = resources[i].protocolnumber;\n\t\t\t\taddresources[i].vlan = resources[i].vlan;\n\t\t\t\taddresources[i].Interface = resources[i].Interface;\n\t\t\t\taddresources[i].priority = resources[i].priority;\n\t\t\t\taddresources[i].state = resources[i].state;\n\t\t\t\taddresources[i].msr = resources[i].msr;\n\t\t\t\taddresources[i].monitor = resources[i].monitor;\n\t\t\t\taddresources[i].nexthop = resources[i].nexthop;\n\t\t\t\taddresources[i].nexthopval = resources[i].nexthopval;\n\t\t\t\taddresources[i].nexthopvlan = resources[i].nexthopvlan;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func byteSliceContains(a []byte, b byte) bool {\n\tfor _, v := range a {\n\t\tif v == b {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "public final int getJdbcType()\r\n    {\r\n        switch (this.fieldSource)\r\n        {\r\n            case SOURCE_FIELD :\r\n                return this.getFieldRef().getJdbcType().getType();\r\n            case SOURCE_NULL :\r\n                return java.sql.Types.NULL;\r\n            case SOURCE_VALUE :\r\n                return java.sql.Types.VARCHAR;\r\n            default :\r\n                return java.sql.Types.NULL;\r\n        }\r\n    }", "label": 0}
{"code": "public function select(array $fieldPaths)\n    {\n        $fields = [];\n        foreach ($fieldPaths as $field) {\n            if (!($field instanceof FieldPath)) {\n                $field = FieldPath::fromString($field);\n            }\n\n            $fields[] = [\n                'fieldPath' => $field->pathString()\n            ];\n        }\n\n        if (!$fields) {\n            $fields[] = [\n                'fieldPath' => self::DOCUMENT_ID\n            ];\n        }\n\n        return $this->newQuery([\n            'select' => [\n                'fields' => $fields\n            ]\n        ], true);\n    }", "label": 2}
{"code": "public static servicegroup_stats get(nitro_service service, String servicegroupname) throws Exception{\n\t\tservicegroup_stats obj = new servicegroup_stats();\n\t\tobj.set_servicegroupname(servicegroupname);\n\t\tservicegroup_stats response = (servicegroup_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def del_method(self, m):\n        \"\"\"Remove an instance method or function if it exists\n\n        Args:\n            m: The instance method or function to remove\n        \"\"\"\n        if isinstance(m, types.FunctionType) and not iscoroutinefunction(m):\n            wrkey = ('function', id(m))\n        else:\n            f, obj = get_method_vars(m)\n            wrkey = (f, id(obj))\n        if wrkey in self:\n            del self[wrkey]", "label": 1}
{"code": "public static base_response update(nitro_service client, clusterinstance resource) throws Exception {\n\t\tclusterinstance updateresource = new clusterinstance();\n\t\tupdateresource.clid = resource.clid;\n\t\tupdateresource.deadinterval = resource.deadinterval;\n\t\tupdateresource.hellointerval = resource.hellointerval;\n\t\tupdateresource.preemption = resource.preemption;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "function() {\n      this.undelegateEvents(); // always undelegate events - backbone sometimes doesn't.\n      Backbone.View.prototype.delegateEvents.call(this);\n      this.__generateFeedbackBindings();\n      this.__generateFeedbackCellCallbacks();\n      _.each(this.getTrackedViews(), function(view) {\n        if (view.isAttachedToParent()) {\n          view.delegateEvents();\n        }\n      });\n    }", "label": 3}
{"code": "public static int[] ConcatenateInt(List<int[]> arrays) {\n\n        int size = 0;\n        for (int i = 0; i < arrays.size(); i++) {\n            size += arrays.get(i).length;\n        }\n\n        int[] all = new int[size];\n        int idx = 0;\n\n        for (int i = 0; i < arrays.size(); i++) {\n            int[] v = arrays.get(i);\n            for (int j = 0; j < v.length; j++) {\n                all[idx++] = v[i];\n            }\n        }\n\n        return all;\n    }", "label": 0}
{"code": "def show\n      @user_collections = user_collections\n\n      respond_to do |wants|\n        wants.html { presenter && parent_presenter }\n        wants.json do\n          # load and authorize @curation_concern manually because it's skipped for html\n          @curation_concern = _curation_concern_type.find(params[:id]) unless curation_concern\n          authorize! :show, @curation_concern\n          render :show, status: :ok\n        end\n        additional_response_formats(wants)\n        wants.ttl do\n          render body: presenter.export_as_ttl, content_type: 'text/turtle'\n        end\n        wants.jsonld do\n          render body: presenter.export_as_jsonld, content_type: 'application/ld+json'\n        end\n        wants.nt do\n          render body: presenter.export_as_nt, content_type: 'application/n-triples'\n        end\n      end\n    end", "label": 4}
{"code": "def scale(table):\n    \"\"\"\n    scale table based on the column with the largest sum\n    \"\"\"\n    t = []\n    columns = [[] for i in table[0]]\n    for row in table:\n        for i, v in enumerate(row):\n            columns[i].append(v)\n    sums = [float(sum(i)) for i in columns]\n    scale_to = float(max(sums))\n    scale_factor = [scale_to/i for i in sums if i != 0]\n    for row in table:\n        t.append([a * b for a,b in zip(row, scale_factor)])\n    return t", "label": 1}
{"code": "function(opts) {\n  // If opts is a string, assume libpath\n  if(_.isString(opts)) {\n    opts = { path: opts }\n  }\n\n  if(!opts) opts = {};\n  var libpath = opts['path'];\n\n  this._library = this._createLibrary(libpath);\n}", "label": 3}
{"code": "def _to_string(inp: str) -> str:\n        \"\"\" Convert a URL or file name to a string \"\"\"\n        if '://' in inp:\n            req = requests.get(inp)\n            if not req.ok:\n                raise ValueError(f\"Unable to read {inp}\")\n            return req.text\n        else:\n            with open(inp) as infile:\n                return infile.read()", "label": 1}
{"code": "def addcols(X, cols, names=None):\n    \"\"\"\n    Add one or more columns to a numpy ndarray.\n\n    Technical dependency of :func:`tabular.spreadsheet.aggregate_in`.\n\n    Implemented by the tabarray method \n    :func:`tabular.tab.tabarray.addcols`.\n\n    **Parameters**\n\n            **X** :  numpy ndarray with structured dtype or recarray\n\n                    The recarray to add columns to.\n\n            **cols** :  numpy ndarray, or list of arrays of columns\n            \n                    Column(s) to add.\n\n            **names**:  list of strings, optional\n\n                    Names of the new columns. Only applicable when `cols` is a \n                    list of arrays.\n\n    **Returns**\n\n            **out** :  numpy ndarray with structured dtype\n\n                    New numpy array made up of `X` plus the new columns.\n\n    **See also:**  :func:`tabular.spreadsheet.colstack`\n\n    \"\"\"\n\n    if isinstance(names,str):\n        names = [n.strip() for n in names.split(',')]\n\n    if isinstance(cols, list):\n        if any([isinstance(x,np.ndarray) or isinstance(x,list) or \\\n                                     isinstance(x,tuple) for x in cols]):\n            assert all([len(x) == len(X) for x in cols]), \\\n                   'Trying to add columns of wrong length.'\n            assert names != None and len(cols) == len(names), \\\n                   'Number of columns to add must equal number of new names.'\n            cols = utils.fromarrays(cols,type=np.ndarray,names = names)\n        else:\n            assert len(cols) == len(X), 'Trying to add column of wrong length.'\n            cols = utils.fromarrays([cols], type=np.ndarray,names=names)\n    else:\n        assert isinstance(cols, np.ndarray)\n        if cols.dtype.names == None:\n            cols = utils.fromarrays([cols],type=np.ndarray, names=names)\n\n    Replacements = [a for a in cols.dtype.names if a in X.dtype.names]\n    if len(Replacements) > 0:\n        print('Replacing columns', \n              [a for a in cols.dtype.names if a in X.dtype.names])\n\n    return utils.fromarrays(\n      [X[a] if a not in cols.dtype.names else cols[a] for a in X.dtype.names] + \n      [cols[a] for a in cols.dtype.names if a not in X.dtype.names], \n      type=np.ndarray,\n      names=list(X.dtype.names) + [a for a in cols.dtype.names \n                                   if a not in X.dtype.names])", "label": 1}
{"code": "public void ifHasMemberWithTag(String template, Properties attributes) throws XDocletException\r\n    {\r\n        ArrayList allMemberNames = new ArrayList();\r\n        HashMap allMembers = new HashMap();\r\n        boolean hasTag = false;\r\n\r\n        addMembers(allMemberNames, allMembers, getCurrentClass(), null, null, null);\r\n        for (Iterator it = allMemberNames.iterator(); it.hasNext(); ) {\r\n            XMember member = (XMember) allMembers.get(it.next());\r\n\r\n            if (member instanceof XField) {\r\n                setCurrentField((XField)member);\r\n                if (hasTag(attributes, FOR_FIELD)) {\r\n                    hasTag = true;\r\n                }\r\n                setCurrentField(null);\r\n            }\r\n            else if (member instanceof XMethod) {\r\n                setCurrentMethod((XMethod)member);\r\n                if (hasTag(attributes, FOR_METHOD)) {\r\n                    hasTag = true;\r\n                }\r\n                setCurrentMethod(null);\r\n            }\r\n            if (hasTag) {\r\n                generate(template);\r\n                break;\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "function erroz(error) {\n\n    var errorFn = function (data) {\n\n        //apply all attributes on the instance\n        for (var errKey in errorFn.prototype) {\n            if (errorFn.prototype.hasOwnProperty(errKey)) {\n                this[errKey] = errorFn.prototype[errKey];\n            }\n        }\n\n        //overwrite message if invoked with string\n        if (typeof data === \"string\") {\n            this.message = data;\n            data = {};\n        }\n\n        this.data = data || {};\n\n        this.message = this.message || erroz.options.renderMessage(error.template || \"\", this.data);\n\n        errorFn.super_.call(this, this.constructor);\n    };\n\n    util.inherits(errorFn, AbstractError);\n\n    //add static error properties (name, status, etc)\n    for (var errKey in error) {\n        if (error.hasOwnProperty(errKey)) {\n            errorFn.prototype[errKey] = error[errKey];\n        }\n    }\n\n    /**\n     * return an object containing only JSend attributes\n     * @returns {{status: *, code: *, message: *, data: (*|string|Object[]|Object|String)}}\n     */\n    errorFn.prototype.toJSend = function () {\n        var data = this.data;\n\n        if (erroz.options.includeStack && this.stack) {\n            data.stack = this.stack;\n        }\n\n        if (!this.status) {\n            this.status = deriveStatusFromStatusCode(this.statusCode);\n        }\n\n        return {\n            status: this.status,\n            code: this.code,\n            message: this.message,\n            data: data\n        };\n    };\n\n    return errorFn;\n}", "label": 3}
{"code": "public function addChecksum($checksum, $inBinaryForm = false)\n    {\n        // Error if hash is already calculated\n        if ($this->hash) {\n            throw new \\LogicException('You may not add more checksums to a '\n                . 'complete tree hash.');\n        }\n\n        // Convert the checksum to binary form if necessary\n        $this->checksums[] = $inBinaryForm ? $checksum : hex2bin($checksum);\n\n        return $this;\n    }", "label": 2}
{"code": "public function utcOffset(int $offset = null)\n    {\n        if (func_num_args() < 1) {\n            return $this->offsetMinutes;\n        }\n\n        return $this->setTimezone(static::safeCreateDateTimeZone($offset / static::MINUTES_PER_HOUR));\n    }", "label": 2}
{"code": "def find(options=nil, &block)\n      options = validate_options(options)\n\n      start do |imap|\n        options[:read_only] ? imap.examine(options[:mailbox]) : imap.select(options[:mailbox])\n        uids = imap.uid_search(options[:keys], options[:search_charset])\n        uids.reverse! if options[:what].to_sym == :last\n        uids = uids.first(options[:count]) if options[:count].is_a?(Integer)\n        uids.reverse! if (options[:what].to_sym == :last && options[:order].to_sym == :asc) ||\n                                (options[:what].to_sym != :last && options[:order].to_sym == :desc)\n\n        if block_given?\n          uids.each do |uid|\n            uid = options[:uid].to_i unless options[:uid].nil?\n            fetchdata = imap.uid_fetch(uid, ['RFC822', 'FLAGS'])[0]\n            new_message = Mail.new(fetchdata.attr['RFC822'])\n            new_message.mark_for_delete = true if options[:delete_after_find]\n\n            if block.arity == 4\n              yield new_message, imap, uid, fetchdata.attr['FLAGS']\n            elsif block.arity == 3\n              yield new_message, imap, uid\n            else\n              yield new_message\n            end\n\n            imap.uid_store(uid, \"+FLAGS\", [Net::IMAP::DELETED]) if options[:delete_after_find] && new_message.is_marked_for_delete?\n            break unless options[:uid].nil?\n          end\n          imap.expunge if options[:delete_after_find]\n        else\n          emails = []\n          uids.each do |uid|\n            uid = options[:uid].to_i unless options[:uid].nil?\n            fetchdata = imap.uid_fetch(uid, ['RFC822'])[0]\n            emails << Mail.new(fetchdata.attr['RFC822'])\n            imap.uid_store(uid, \"+FLAGS\", [Net::IMAP::DELETED]) if options[:delete_after_find]\n            break unless options[:uid].nil?\n          end\n          imap.expunge if options[:delete_after_find]\n          emails.size == 1 && options[:count] == 1 ? emails.first : emails\n        end\n      end\n    end", "label": 4}
{"code": "public function setWordList($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CustomInfoType_Dictionary_WordList::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def filter_directories(modified_files)\n      modified_files.reject do |file|\n        File.directory?(file) && !Overcommit::Utils::FileUtils.symlink?(file)\n      end\n    end", "label": 4}
{"code": "async def _get_rev_reg_def(self, rr_id: str) -> str:\n        \"\"\"\n        Get revocation registry definition from ledger by its identifier. Raise AbsentRevReg\n        for no such revocation registry, logging any error condition and raising BadLedgerTxn\n        on bad request.\n\n        Retrieve the revocation registry definition from the agent's revocation cache if it has it;\n        cache it en passant if it does not (and such a revocation registry definition exists on the ledger).\n\n        :param rr_id: (revocation registry) identifier string, of the format\n            '<issuer-did>:4:<issuer-did>:3:CL:<schema-seq-no>:<tag>:CL_ACCUM:<tag>'\n        :return: revocation registry definition json as retrieved from ledger\n        \"\"\"\n\n        LOGGER.debug('_BaseAgent._get_rev_reg_def >>> rr_id: %s', rr_id)\n\n        rv_json = json.dumps({})\n\n        with REVO_CACHE.lock:\n            revo_cache_entry = REVO_CACHE.get(rr_id, None)\n            rr_def = revo_cache_entry.rev_reg_def if revo_cache_entry else None\n            if rr_def:\n                LOGGER.info('_BaseAgent._get_rev_reg_def: rev reg def for %s from cache', rr_id)\n                rv_json = json.dumps(rr_def)\n            else:\n                get_rrd_req_json = await ledger.build_get_revoc_reg_def_request(self.did, rr_id)\n                resp_json = await self._submit(get_rrd_req_json)\n                try:\n                    (_, rv_json) = await ledger.parse_get_revoc_reg_def_response(resp_json)\n                    rr_def = json.loads(rv_json)\n                except IndyError:  # ledger replied, but there is no such rev reg\n                    LOGGER.debug('_BaseAgent._get_rev_reg_def: <!< no rev reg exists on %s', rr_id)\n                    raise AbsentRevReg('No rev reg exists on {}'.format(rr_id))\n\n                if revo_cache_entry is None:\n                    REVO_CACHE[rr_id] = RevoCacheEntry(rr_def, None)\n                else:\n                    REVO_CACHE[rr_id].rev_reg_def = rr_def\n\n        LOGGER.debug('_BaseAgent._get_rev_reg_def <<< %s', rv_json)\n        return rv_json", "label": 1}
{"code": "public function setSparkSqlJob($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\SparkSqlJob::class);\n        $this->writeOneof(12, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func main() {\n\tflag.Parse()\n\n\tstage1initcommon.InitDebug(debug)\n\n\tlog, diag, _ = rktlog.NewLogSet(\"app-rm\", debug)\n\tif !debug {\n\t\tdiag.SetOutput(ioutil.Discard)\n\t}\n\n\tappName, err := types.NewACName(flagApp)\n\tif err != nil {\n\t\tlog.FatalE(\"invalid app name\", err)\n\t}\n\n\tenterCmd := stage1common.PrepareEnterCmd(false)\n\tswitch flagStage {\n\tcase 0:\n\t\t// clean resources in stage0\n\t\terr = cleanupStage0(appName, enterCmd)\n\tcase 1:\n\t\t// clean resources in stage1\n\t\terr = cleanupStage1(appName, enterCmd)\n\tdefault:\n\t\t// unknown step\n\t\terr = fmt.Errorf(\"unsupported cleaning step %d\", flagStage)\n\t}\n\tif err != nil {\n\t\tlog.FatalE(\"cleanup error\", err)\n\t}\n\n\tos.Exit(0)\n}", "label": 5}
{"code": "public static nssimpleacl get(nitro_service service, String aclname) throws Exception{\n\t\tnssimpleacl obj = new nssimpleacl();\n\t\tobj.set_aclname(aclname);\n\t\tnssimpleacl response = (nssimpleacl) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getFocusColor(colors) {\n  if (Color(colors.primary).luminosity() >= 0.8) {\n    return colors.accent;\n  }\n\n  return colors.primary;\n}", "label": 3}
{"code": "public static base_response unset(nitro_service client, inatparam resource, String[] args) throws Exception{\n\t\tinatparam unsetresource = new inatparam();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def get(preference = {})\n      return preference if PREFERENCES.values.include?(preference.class)\n      Mongo::Lint.validate_underscore_read_preference(preference)\n      PREFERENCES.fetch((preference[:mode] || :primary).to_sym).new(preference)\n    end", "label": 4}
{"code": "public static onlinkipv6prefix get(nitro_service service, String ipv6prefix) throws Exception{\n\t\tonlinkipv6prefix obj = new onlinkipv6prefix();\n\t\tobj.set_ipv6prefix(ipv6prefix);\n\t\tonlinkipv6prefix response = (onlinkipv6prefix) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static void Forward(double[] data) {\n        double[] result = new double[data.length];\n\n        for (int k = 0; k < result.length; k++) {\n            double sum = 0;\n            for (int n = 0; n < data.length; n++) {\n                double theta = ((2.0 * Math.PI) / data.length) * k * n;\n                sum += data[n] * cas(theta);\n            }\n            result[k] = (1.0 / Math.sqrt(data.length)) * sum;\n        }\n\n        for (int i = 0; i < result.length; i++) {\n            data[i] = result[i];\n        }\n\n    }", "label": 0}
{"code": "def unwrap_token(wrapper)\n      # If provided a secret, grab the token. This is really just to make the\n      # API a bit nicer.\n      if wrapper.is_a?(Secret)\n        wrapper = wrapper.wrap_info.token\n      end\n\n      # Unwrap\n      response = unwrap(wrapper)\n\n      # If nothing was there, return nil\n      if response.nil? || response.auth.nil?\n        return nil\n      end\n\n      return response.auth.client_token\n    rescue HTTPError => e\n      raise\n    end", "label": 4}
{"code": "func PgTypeByOid(db XODB, oid pgtypes.Oid) (*PgType, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, typname, typnamespace, typowner, typlen, typbyval, typtype, typcategory, typispreferred, typisdefined, typdelim, typrelid, typelem, typarray, typinput, typoutput, typreceive, typsend, typmodin, typmodout, typanalyze, typalign, typstorage, typnotnull, typbasetype, typtypmod, typndims, typcollation, typdefaultbin, typdefault, typacl ` +\n\t\t`FROM pg_catalog.pg_type ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpt := PgType{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pt.Tableoid, &pt.Cmax, &pt.Xmax, &pt.Cmin, &pt.Xmin, &pt.Oid, &pt.Ctid, &pt.Typname, &pt.Typnamespace, &pt.Typowner, &pt.Typlen, &pt.Typbyval, &pt.Typtype, &pt.Typcategory, &pt.Typispreferred, &pt.Typisdefined, &pt.Typdelim, &pt.Typrelid, &pt.Typelem, &pt.Typarray, &pt.Typinput, &pt.Typoutput, &pt.Typreceive, &pt.Typsend, &pt.Typmodin, &pt.Typmodout, &pt.Typanalyze, &pt.Typalign, &pt.Typstorage, &pt.Typnotnull, &pt.Typbasetype, &pt.Typtypmod, &pt.Typndims, &pt.Typcollation, &pt.Typdefaultbin, &pt.Typdefault, &pt.Typacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pt, nil\n}", "label": 5}
{"code": "def post(path, body = '', headers = {})\n      headers = { 'Content-Type' => 'application/json' }.merge(headers)\n      request(:post, path, body, merge_default_headers(headers))\n    end", "label": 4}
{"code": "def component_ids=(component_version_ids_to_set)\n      content_view_components.destroy_all\n      component_version_ids_to_set.each do |content_view_version_id|\n        cvv = ContentViewVersion.find(content_view_version_id)\n        content_view_components.build(:content_view_version => cvv,\n                                      :latest => false,\n                                      :composite_content_view => self)\n      end\n    end", "label": 4}
{"code": "public function setOptions(array $options = [])\n    {\n        $options += [\n            'maxMemberDepth' => self::DEFAULT_MAX_MEMBER_DEPTH,\n            'maxPayloadSize' => self::DEFAULT_MAX_PAYLOAD_SIZE,\n            'maxMembers' => self::DEFAULT_MAX_MEMBERS,\n            'maxValueLength' => self::DEFAULT_MAX_STRING_LENGTH\n        ];\n        $this->maxMemberDepth = $options['maxMemberDepth'];\n        $this->maxPayloadSize = $options['maxPayloadSize'];\n        $this->maxValueLength = $options['maxValueLength'];\n        $this->maxMembers = $options['maxMembers'];\n    }", "label": 2}
{"code": "def strip_text_after_string(txt, junk):\n    \"\"\" used to strip any poorly documented comments at the end of function defs \"\"\"\n    if junk in txt:\n        return txt[:txt.find(junk)]\n    else:\n        return txt", "label": 1}
{"code": "public static vridparam get(nitro_service service) throws Exception{\n\t\tvridparam obj = new vridparam();\n\t\tvridparam[] response = (vridparam[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public void set(Vector3d v1) {\n        x = v1.x;\n        y = v1.y;\n        z = v1.z;\n    }", "label": 0}
{"code": "function (classDef) {\n            var attributes,\n                Super;\n            while (classDef) { // !undefined && !null\n                attributes = classDef._attributes;\n                if (attributes) {\n                    attributes._copy(this);\n                }\n                Super = classDef._Super;\n                if (Super === Object) { // Can't go upper\n                    break;\n                } else {\n                    classDef = _gpfGetClassDefinition(Super);\n                }\n            }\n            return this;\n        }", "label": 3}
{"code": "func (s *Store) ResolveName(name string) ([]string, bool, error) {\n\tvar (\n\t\taciInfos []*ACIInfo\n\t\tfound    bool\n\t)\n\terr := s.db.Do(func(tx *sql.Tx) error {\n\t\tvar err error\n\t\taciInfos, found, err = GetACIInfosWithName(tx, name)\n\t\treturn err\n\t})\n\tif err != nil {\n\t\treturn nil, found, errwrap.Wrap(errors.New(\"error retrieving ACI Infos\"), err)\n\t}\n\n\tkeys := make([]string, len(aciInfos))\n\tfor i, aciInfo := range aciInfos {\n\t\tkeys[i] = aciInfo.BlobKey\n\t}\n\n\treturn keys, found, nil\n}", "label": 5}
{"code": "function createTempDir(options) {\n  options = _.opts(options, {cleanup: true});\n  return _createTemporaryPath(fs.mkdirSync, options.cleanup);\n}", "label": 3}
{"code": "private function formatPrecondition(array $options, $mustExist = false)\n    {\n        if (!isset($options['precondition']) && !$mustExist) {\n            return $options;\n        }\n\n        $precondition = isset($options['precondition'])\n            ? $options['precondition']\n            : [];\n\n        if (isset($precondition['updateTime'])) {\n            return $options;\n        }\n\n        if ($mustExist) {\n            $precondition['exists'] = true;\n        }\n\n        $options['precondition'] = $precondition;\n\n        return $options;\n    }", "label": 2}
{"code": "public function rawColumns(array $columns, $merge = false)\n    {\n        if ($merge) {\n            $config = $this->config->get('datatables.columns');\n\n            $this->columnDef['raw'] = array_merge($config['raw'], $columns);\n        } else {\n            $this->columnDef['raw'] = $columns;\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def text(options={})\n      result = serialize_root.children.inner_text rescue \"\"\n      if options[:encode_special_chars] == false\n        result # possibly dangerous if rendered in a browser\n      else\n        encode_special_chars result\n      end\n    end", "label": 4}
{"code": "def scan(table, query = {}, opts = {})\n      benchmark('Scan', table, query) { adapter.scan(table, query, opts) }\n    end", "label": 4}
{"code": "func PgTables(db models.XODB, schema string, relkind string) ([]*models.Table, error) {\n\tvar err error\n\n\t// get the tables\n\trows, err := models.PgTables(db, schema, relkind)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Get the tables that have a sequence defined.\n\tsequences, err := models.PgSequences(db, schema)\n\tif err != nil {\n\t\t// Set it to an empty set on error.\n\t\tsequences = []*models.Sequence{}\n\t}\n\n\t// Add information about manual FK.\n\tvar tables []*models.Table\n\tfor _, row := range rows {\n\t\tmanualPk := true\n\t\t// Look for a match in the table name where it contains the sequence\n\t\tfor _, sequence := range sequences {\n\t\t\tif sequence.TableName == row.TableName {\n\t\t\t\tmanualPk = false\n\t\t\t}\n\t\t}\n\t\ttables = append(tables, &models.Table{\n\t\t\tTableName: row.TableName,\n\t\t\tType:      row.Type,\n\t\t\tManualPk:  manualPk,\n\t\t})\n\t}\n\n\treturn tables, nil\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, responderpolicy resource) throws Exception {\n\t\tresponderpolicy addresource = new responderpolicy();\n\t\taddresource.name = resource.name;\n\t\taddresource.rule = resource.rule;\n\t\taddresource.action = resource.action;\n\t\taddresource.undefaction = resource.undefaction;\n\t\taddresource.comment = resource.comment;\n\t\taddresource.logaction = resource.logaction;\n\t\taddresource.appflowaction = resource.appflowaction;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def style(self):\n        \"\"\"Returns a default Style.\"\"\"\n        style = mapnik.Style()\n        rule = mapnik.Rule()\n        self._symbolizer = self.symbolizer()\n        rule.symbols.append(self._symbolizer)\n        style.rules.append(rule)\n        return style", "label": 1}
{"code": "private function checkCache()\n    {\n        $cache = get_site_option('bedrock_autoloader');\n\n        if ($cache === false || (isset($cache['plugins'], $cache['count']) && count($cache['plugins']) !== $cache['count'])) {\n            $this->updateCache();\n            return;\n        }\n\n        self::$cache = $cache;\n    }", "label": 2}
{"code": "public static function create($source)\n    {\n        if (is_array($source)) {\n            $source = new Collection($source);\n        }\n\n        return parent::create($source);\n    }", "label": 2}
{"code": "def process_actions(actions):\n    \"\"\"Process queue actions.\"\"\"\n    queue = current_app.config['INDEXER_MQ_QUEUE']\n    with establish_connection() as c:\n        q = queue(c)\n        for action in actions:\n            q = action(q)", "label": 1}
{"code": "def setup(self, helper=None, **create_kwargs):\n        \"\"\"\n        Setup this resource so that is ready to be used in a test. If the\n        resource has already been created, this call does nothing.\n\n        For most resources, this just involves creating the resource in Docker.\n\n        :param helper:\n            The resource helper to use, if one was not provided when this\n            resource definition was created.\n        :param **create_kwargs: Keyword arguments passed to :meth:`.create`.\n\n        :returns:\n            This definition instance. Useful for creating and setting up a\n            resource in a single step::\n\n                volume = VolumeDefinition('volly').setup(helper=docker_helper)\n        \"\"\"\n        if self.created:\n            return\n\n        self.set_helper(helper)\n        self.create(**create_kwargs)\n        return self", "label": 1}
{"code": "public function setMasterAuthorizedNetworksConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\MasterAuthorizedNetworksConfig::class);\n        $this->master_authorized_networks_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static int secondsDiff(Date earlierDate, Date laterDate) {\n        if (earlierDate == null || laterDate == null) {\n            return 0;\n        }\n\n        return (int) ((laterDate.getTime() / SECOND_MILLIS) - (earlierDate.getTime() / SECOND_MILLIS));\n    }", "label": 0}
{"code": "public void updateLinks(ServiceReference<S> serviceReference) {\n        for (D declaration : linkerManagement.getMatchedDeclaration()) {\n            boolean isAlreadyLinked = declaration.getStatus().getServiceReferencesBounded().contains(serviceReference);\n            boolean canBeLinked = linkerManagement.canBeLinked(declaration, serviceReference);\n            if (isAlreadyLinked && !canBeLinked) {\n                linkerManagement.unlink(declaration, serviceReference);\n            } else if (!isAlreadyLinked && canBeLinked) {\n                linkerManagement.link(declaration, serviceReference);\n            }\n        }\n    }", "label": 0}
{"code": "func (i *Handle) GetService(s *Service) (*Service, error) {\n\n\tres, err := i.doGetServicesCmd(s)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We are looking for exactly one service otherwise error out\n\tif len(res) != 1 {\n\t\treturn nil, fmt.Errorf(\"Expected only one service obtained=%d\", len(res))\n\t}\n\n\treturn res[0], nil\n}", "label": 5}
{"code": "def member?(*args)\n      params   = arguments(args, required: [:org_name, :user]).params\n      org_name = arguments.org_name\n      user     = arguments.user\n\n      response = if params.delete('public')\n                   get_request(\"/orgs/#{org_name}/public_members/#{user}\", params)\n                 else\n                   get_request(\"/orgs/#{org_name}/members/#{user}\", params)\n                 end\n      response.status == 204\n    rescue Github::Error::NotFound\n      false\n    end", "label": 4}
{"code": "function (runner, url, browser) {\n    this.id = null;\n    this.taskId = null;\n    this.user = runner.user;\n    this.key = runner.key;\n    this.framework = runner.framework;\n    this.pollInterval = runner.pollInterval;\n    this.statusCheckAttempts = runner.statusCheckAttempts;\n    this.url = url;\n    this.platform = _.isArray(browser) ? browser : [browser.platform || '', browser.browserName || '', browser.version || ''];\n    this.build = runner.build;\n    this.public = browser.public || runner.public || \"team\";\n    this.tags = browser.tags || runner.tags;\n    this.testName = browser.name || runner.testName;\n    this.sauceConfig = runner.sauceConfig;\n    this.tunneled = runner.tunneled;\n    this.tunnelId = runner.tunnelId;\n  }", "label": 3}
{"code": "public void connect(final String serialPortName)\n\t\t\tthrows SerialInterfaceException {\n\t\tlogger.info(\"Connecting to serial port {}\", serialPortName);\n\t\ttry {\n\t\t\tCommPortIdentifier portIdentifier = CommPortIdentifier.getPortIdentifier(serialPortName);\n\t\t\tCommPort commPort = portIdentifier.open(\"org.openhab.binding.zwave\",2000);\n\t\t\tthis.serialPort = (SerialPort) commPort;\n\t\t\tthis.serialPort.setSerialPortParams(115200,SerialPort.DATABITS_8,SerialPort.STOPBITS_1,SerialPort.PARITY_NONE);\n\t\t\tthis.serialPort.enableReceiveThreshold(1);\n\t\t\tthis.serialPort.enableReceiveTimeout(ZWAVE_RECEIVE_TIMEOUT);\n\t\t\tthis.receiveThread = new ZWaveReceiveThread();\n\t\t\tthis.receiveThread.start();\n\t\t\tthis.sendThread = new ZWaveSendThread();\n\t\t\tthis.sendThread.start();\n\n\t\t\tlogger.info(\"Serial port is initialized\");\n\t\t} catch (NoSuchPortException e) {\n\t\t\tlogger.error(e.getLocalizedMessage());\n\t\t\tthrow new SerialInterfaceException(e.getLocalizedMessage(), e);\n\t\t} catch (PortInUseException e) {\n\t\t\tlogger.error(e.getLocalizedMessage());\n\t\t\tthrow new SerialInterfaceException(e.getLocalizedMessage(), e);\n\t\t} catch (UnsupportedCommOperationException e) {\n\t\t\tlogger.error(e.getLocalizedMessage());\n\t\t\tthrow new SerialInterfaceException(e.getLocalizedMessage(), e);\n\t\t}\n\t}", "label": 0}
{"code": "public static base_response unset(nitro_service client, rnatparam resource, String[] args) throws Exception{\n\t\trnatparam unsetresource = new rnatparam();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function _gpfHostJava () {\n\n    _gpfDosPath = String(java.lang.System.getProperty(\"file.separator\")) === \"\\\\\";\n\n    // Define console APIs\n    _gpfMainContext.console = _gpfConsoleGenerate(print);\n\n    /* istanbul ignore next */ // exit.1\n    _gpfExit = function (code) {\n        java.lang.System.exit(code);\n    };\n\n}", "label": 3}
{"code": "public static function extractColumnName($str, $wantsAlias)\n    {\n        $matches = explode(' as ', Str::lower($str));\n\n        if (! empty($matches)) {\n            if ($wantsAlias) {\n                return array_pop($matches);\n            }\n\n            return array_shift($matches);\n        } elseif (strpos($str, '.')) {\n            $array = explode('.', $str);\n\n            return array_pop($array);\n        }\n\n        return $str;\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, autoscaleaction resource) throws Exception {\n\t\tautoscaleaction updateresource = new autoscaleaction();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.profilename = resource.profilename;\n\t\tupdateresource.parameters = resource.parameters;\n\t\tupdateresource.vmdestroygraceperiod = resource.vmdestroygraceperiod;\n\t\tupdateresource.quiettime = resource.quiettime;\n\t\tupdateresource.vserver = resource.vserver;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (s *Store) RemoveACI(key string) error {\n\timageKeyLock, err := lock.ExclusiveKeyLock(s.imageLockDir, key)\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"error locking image\"), err)\n\t}\n\tdefer imageKeyLock.Close()\n\n\t// Firstly remove aciinfo and remote from the db in an unique transaction.\n\t// remote needs to be removed or a GetRemote will return a blobKey not\n\t// referenced by any ACIInfo.\n\terr = s.db.Do(func(tx *sql.Tx) error {\n\t\tif _, found, err := GetACIInfoWithBlobKey(tx, key); err != nil {\n\t\t\treturn errwrap.Wrap(errors.New(\"error getting aciinfo\"), err)\n\t\t} else if !found {\n\t\t\treturn fmt.Errorf(\"cannot find image with key: %s\", key)\n\t\t}\n\n\t\tif err := RemoveACIInfo(tx, key); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := RemoveRemote(tx, key); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn errwrap.Wrap(fmt.Errorf(\"cannot remove image with ID: %s from db\", key), err)\n\t}\n\n\t// Then remove non transactional entries from the blob, imageManifest\n\t// and tree store.\n\t// TODO(sgotti). Now that the ACIInfo is removed the image doesn't\n\t// exists anymore, but errors removing non transactional entries can\n\t// leave stale data that will require a cas GC to be implemented.\n\tvar storeErrors []error\n\tfor _, ds := range s.stores {\n\t\tif err := ds.Erase(key); err != nil {\n\t\t\t// If there's an error save it and continue with the other stores\n\t\t\tstoreErrors = append(storeErrors, err)\n\t\t}\n\t}\n\tif len(storeErrors) > 0 {\n\t\treturn &StoreRemovalError{errors: storeErrors}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static int Median( int[] values ){\n        int total = 0, n = values.length;\n\n        // for all values\n        for ( int i = 0; i < n; i++ )\n        {\n            // accumalate total\n            total += values[i];\n        }\n\n        int halfTotal = total / 2;\n        int median = 0, v = 0;\n\n        // find median value\n        for ( ; median < n; median++ )\n        {\n            v += values[median];\n            if ( v >= halfTotal )\n                break;\n        }\n\n        return median;\n    }", "label": 0}
{"code": "func (c *NodeClient) listenAndForward(ctx context.Context, ln net.Listener, remoteAddr string) {\n\tdefer ln.Close()\n\tdefer c.Close()\n\n\tfor {\n\t\t// Accept connections from the client.\n\t\tconn, err := ln.Accept()\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"Port forwarding failed: %v.\", err)\n\t\t\tbreak\n\t\t}\n\n\t\t// Proxy the connection to the remote address.\n\t\tgo func() {\n\t\t\terr := c.proxyConnection(ctx, conn, remoteAddr)\n\t\t\tif err != nil {\n\t\t\t\tlog.Warnf(\"Failed to proxy connection: %v.\", err)\n\t\t\t}\n\t\t}()\n\t}\n}", "label": 5}
{"code": "function isHidden(collection, pattern, patternKey) {\n  return (\n    (collection.hidden && collection.hidden.indexOf(patternKey) !== -1) ||\n    (pattern.data && pattern.data.hidden)\n  );\n}", "label": 3}
{"code": "def configured_service!\n      if s = configuration[:service] and services.keys.include?(s)\n        return s\n      else\n        raise(\n          Geocoder::ConfigurationError,\n          \"When using MaxMind you MUST specify a service name: \" +\n          \"Geocoder.configure(:maxmind => {:service => ...}), \" +\n          \"where '...' is one of: #{services.keys.inspect}\"\n        )\n      end\n    end", "label": 4}
{"code": "def display_names\n      list = element.addresses.map { |a| a.display_name }\n      Mail::AddressContainer.new(self, list)\n    end", "label": 4}
{"code": "def start(options = {})\n      setup(options)\n      UI.debug \"Guard starts all plugins\"\n      Runner.new.run(:start)\n      listener.start\n\n      watched = Guard.state.session.watchdirs.join(\"', '\")\n      UI.info \"Guard is now watching at '#{ watched }'\"\n\n      exitcode = 0\n      begin\n        while interactor.foreground != :exit\n          Guard.queue.process while Guard.queue.pending?\n        end\n      rescue Interrupt\n      rescue SystemExit => e\n        exitcode = e.status\n      end\n\n      exitcode\n    ensure\n      stop\n    end", "label": 4}
{"code": "function(id, options) {\n      options = opts(this, options);\n      return new APICall({\n        action: 'account/' + id,\n        type: 'GET',\n        query: server_params(options),\n        options: options\n      });\n    }", "label": 3}
{"code": "@SuppressWarnings(\"unchecked\")\n  private static void getParamsFromJSON(Map<String, String> params, String json) {\n    JSONParser parser = new JSONParser(json);\n    try {\n      Object o = ObjectBuilder.getVal(parser);\n      if (!(o instanceof Map))\n        return;\n      Map<String, Object> map = (Map<String, Object>) o;\n      // To make consistent with json.param handling, we should make query\n      // params come after json params (i.e. query params should\n      // appear to overwrite json params.\n\n      // Solr params are based on String though, so we need to convert\n      for (Map.Entry<String, Object> entry : map.entrySet()) {\n        String key = entry.getKey();\n        Object val = entry.getValue();\n        if (params.get(key) != null) {\n          continue;\n        }\n        if (val == null) {\n          params.remove(key);\n        } else if (val instanceof String) {\n          params.put(key, (String) val);\n        }\n      }\n    } catch (Exception e) {\n      log.debug(\"ignore parse exceptions at this stage, they may be caused by incomplete macro expansions\", e);\n      return;\n    }\n  }", "label": 0}
{"code": "def index(options = {}, &block)\n      options[:as] ||= :table\n      config.set_page_presenter :index, ActiveAdmin::PagePresenter.new(options, &block)\n    end", "label": 4}
{"code": "function padLeft(str, bits){\n\tbits = bits || config.bits\n\tvar missing = str.length % bits;\n\treturn (missing ? new Array(bits - missing + 1).join('0') : '') + str;\n}", "label": 3}
{"code": "public Iterator select(String predicate) throws org.odmg.QueryInvalidException\r\n    {\r\n        return this.query(predicate).iterator();\r\n    }", "label": 0}
{"code": "public void errorFuture(UUID taskId, Exception e) {\n        DistributedFuture<GROUP, Serializable> future = remove(taskId);\n        if(future != null) {\n            future.setException(e);\n        }\n    }", "label": 0}
{"code": "func (c *Client) Download(ctx context.Context, src string) (io.ReadCloser, int64, error) {\n\tvc := c.ProcessManager.Client()\n\n\tinfo, err := c.FileManager.InitiateFileTransferFromGuest(ctx, c.Authentication, src)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tu, err := c.FileManager.TransferURL(ctx, info.Url)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tp := soap.DefaultDownload\n\n\tf, n, err := vc.Download(ctx, u, &p)\n\tif err != nil {\n\t\treturn nil, n, err\n\t}\n\n\tif strings.HasPrefix(src, \"/archive:/\") || isDir(src) {\n\t\tf = &archiveReader{ReadCloser: f} // look for the gzip trailer\n\t}\n\n\treturn f, n, nil\n}", "label": 5}
{"code": "def _data_to_hist(self, data, **kwargs):\n        \"\"\"Return bin_edges, histogram array\"\"\"\n        if hasattr(self, 'bin_edges'):\n            kwargs.setdefault('bins', self.bin_edges)\n\n        if len(data) == 1 and isinstance(data[0], COLUMNAR_DATA_SOURCES):\n            data = data[0]\n\n            if self.axis_names is None:\n                raise ValueError(\"When histogramming from a columnar data source, \"\n                                 \"axis_names or dimensions is mandatory\")\n            is_dask = False\n            if WE_HAVE_DASK:\n                is_dask = isinstance(data, dask.dataframe.DataFrame)\n\n            if is_dask:\n                fake_histogram = Histdd(axis_names=self.axis_names, bins=kwargs['bins'])\n\n                partial_hists = []\n                for partition in data.to_delayed():\n                    ph = dask.delayed(Histdd)(partition, axis_names=self.axis_names, bins=kwargs['bins'])\n                    ph = dask.delayed(lambda x: x.histogram)(ph)\n                    ph = dask.array.from_delayed(ph,\n                                                 shape=fake_histogram.histogram.shape,\n                                                 dtype=fake_histogram.histogram.dtype)\n                    partial_hists.append(ph)\n                partial_hists = dask.array.stack(partial_hists, axis=0)\n\n                compute_options = kwargs.get('compute_options', {})\n                for k, v in DEFAULT_DASK_COMPUTE_KWARGS.items():\n                    compute_options.setdefault(k, v)\n                histogram = partial_hists.sum(axis=0).compute(**compute_options)\n\n                bin_edges = fake_histogram.bin_edges\n                return histogram, bin_edges\n\n            else:\n                data = np.vstack([data[x].values for x in self.axis_names])\n\n        data = np.array(data).T\n        return np.histogramdd(data,\n                              bins=kwargs.get('bins'),\n                              weights=kwargs.get('weights'),\n                              range=kwargs.get('range'))", "label": 1}
{"code": "function setResponsive(name) {\n    if (name) {\n        setResponsiveComponents.call(this, name);\n    } else {\n        _utils2[\"default\"].forEach(Object.keys(this._component), (function (name) {\n            setResponsiveComponents.call(this, name);\n        }).bind(this));\n    }\n\n    if (_utils2[\"default\"].isUndefined(name)) {\n        _utils2[\"default\"].forEach(this._matchMedias._orders, (function (query) {\n            if (this._matchMedias[query].matches) {\n                _utils2[\"default\"].forIn(this._responsiveStyles[query], (function (style, key) {\n                    if (!this._styles[key]) {\n                        this._styles[key] = {};\n                    }\n\n                    this[key] = _utils2[\"default\"].merge(this._styles[key], (0, _reactPrefixer2[\"default\"])(style));\n                }).bind(this));\n            }\n        }).bind(this));\n    }\n}", "label": 3}
{"code": "public function getMimeType(): string\n    {\n        $mimes = new MimeTypes();\n\n        $type = $mimes->getMimeType($this->getAttribute('extension'));\n\n        return $type ?? 'unknown';\n    }", "label": 2}
{"code": "func (f *file) lintPackageComment() {\n\tif f.isTest() {\n\t\treturn\n\t}\n\n\tconst ref = styleGuideBase + \"#package-comments\"\n\tprefix := \"Package \" + f.f.Name.Name + \" \"\n\n\t// Look for a detached package comment.\n\t// First, scan for the last comment that occurs before the \"package\" keyword.\n\tvar lastCG *ast.CommentGroup\n\tfor _, cg := range f.f.Comments {\n\t\tif cg.Pos() > f.f.Package {\n\t\t\t// Gone past \"package\" keyword.\n\t\t\tbreak\n\t\t}\n\t\tlastCG = cg\n\t}\n\tif lastCG != nil && strings.HasPrefix(lastCG.Text(), prefix) {\n\t\tendPos := f.fset.Position(lastCG.End())\n\t\tpkgPos := f.fset.Position(f.f.Package)\n\t\tif endPos.Line+1 < pkgPos.Line {\n\t\t\t// There isn't a great place to anchor this error;\n\t\t\t// the start of the blank lines between the doc and the package statement\n\t\t\t// is at least pointing at the location of the problem.\n\t\t\tpos := token.Position{\n\t\t\t\tFilename: endPos.Filename,\n\t\t\t\t// Offset not set; it is non-trivial, and doesn't appear to be needed.\n\t\t\t\tLine:   endPos.Line + 1,\n\t\t\t\tColumn: 1,\n\t\t\t}\n\t\t\tf.pkg.errorfAt(pos, 0.9, link(ref), category(\"comments\"), \"package comment is detached; there should be no blank lines between it and the package statement\")\n\t\t\treturn\n\t\t}\n\t}\n\n\tif f.f.Doc == nil {\n\t\tf.errorf(f.f, 0.2, link(ref), category(\"comments\"), \"should have a package comment, unless it's in another file for this package\")\n\t\treturn\n\t}\n\ts := f.f.Doc.Text()\n\tif ts := strings.TrimLeft(s, \" \\t\"); ts != s {\n\t\tf.errorf(f.f.Doc, 1, link(ref), category(\"comments\"), \"package comment should not have leading space\")\n\t\ts = ts\n\t}\n\t// Only non-main packages need to keep to this form.\n\tif !f.pkg.main && !strings.HasPrefix(s, prefix) {\n\t\tf.errorf(f.f.Doc, 1, link(ref), category(\"comments\"), `package comment should be of the form \"%s...\"`, prefix)\n\t}\n}", "label": 5}
{"code": "function (settings) {\n  var tempo = 60e6 / settings.tempo; // Microseconds per beat\n  var setTempo = Buffer.concat([new Buffer([0, 0xFF, 0x51, 0x03]), padNumber(tempo, 3)]);\n  var length = setTempo.length + trackFooter.length;\n\n  return Buffer.concat([trackHeader, padNumber(length, 4), setTempo, trackFooter]);\n}", "label": 3}
{"code": "func SetProxyMode(tsrv reversetunnel.Server) ServerOption {\n\treturn func(s *Server) error {\n\t\t// always set proxy mode to true,\n\t\t// because in some tests reverse tunnel is disabled,\n\t\t// but proxy is still used without it.\n\t\ts.proxyMode = true\n\t\ts.proxyTun = tsrv\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "function(nodeUnitTaskName) {\n    grunt.registerTask(nodeUnitTaskName, 'Nodeunit sync runner', function() {\n      try {\n        var result = execSync('node_modules/.bin/nodeunit --reporter=\"minimal\"', { encoding: 'utf8' });\n        grunt.log.writeln(result);\n      } catch (e) {\n        grunt.fail.warn(e);\n      }\n    });\n  }", "label": 3}
{"code": "public static double Y0(double x) {\r\n        if (x < 8.0) {\r\n            double y = x * x;\r\n\r\n            double ans1 = -2957821389.0 + y * (7062834065.0 + y * (-512359803.6\r\n                    + y * (10879881.29 + y * (-86327.92757 + y * 228.4622733))));\r\n            double ans2 = 40076544269.0 + y * (745249964.8 + y * (7189466.438\r\n                    + y * (47447.26470 + y * (226.1030244 + y * 1.0))));\r\n\r\n            return (ans1 / ans2) + 0.636619772 * J0(x) * Math.log(x);\r\n        } else {\r\n            double z = 8.0 / x;\r\n            double y = z * z;\r\n            double xx = x - 0.785398164;\r\n\r\n            double ans1 = 1.0 + y * (-0.1098628627e-2 + y * (0.2734510407e-4\r\n                    + y * (-0.2073370639e-5 + y * 0.2093887211e-6)));\r\n            double ans2 = -0.1562499995e-1 + y * (0.1430488765e-3\r\n                    + y * (-0.6911147651e-5 + y * (0.7621095161e-6\r\n                    + y * (-0.934945152e-7))));\r\n            return Math.sqrt(0.636619772 / x) *\r\n                    (Math.sin(xx) * ans1 + z * Math.cos(xx) * ans2);\r\n        }\r\n    }", "label": 0}
{"code": "function normalizePage(content) {\n    var data = {\n        \"head-start\": [],\n        \"head\": [],\n        \"head-end\": [],\n        body: []\n    };\n\n    if (typeof content === \"string\") {\n        data.body.push(content);\n    } else {\n        [\"head-start\", \"head\", \"head-end\", \"body\"].forEach(function (section) {\n            var sectionContent = content[section];\n            if (!sectionContent) {\n                return;\n            }\n\n            if (!_.isArray(sectionContent)) {\n                data[section].push(sectionContent);\n            } else {\n                data[section] = sectionContent;\n            }\n        });\n    }\n\n    return data;\n}", "label": 3}
{"code": "func (enc *Encoder) Encode(v interface{}) error {\n\terr := enc.p.marshalValue(reflect.ValueOf(v), nil, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn enc.p.Flush()\n}", "label": 5}
{"code": "def define_group(name, &block)\n      subconfig = self.class.new(self)\n      subconfig.filter = name\n      subconfig.docs_dir = self.docs_dir.join(name.to_s)\n      yield subconfig\n      groups << subconfig\n    end", "label": 4}
{"code": "def get(self, *args, **kwargs):\n        \"\"\"\n        This renders the form or, if needed, does the http redirects.\n        \"\"\"\n        step_url = kwargs.get('step', None)\n        if step_url is None:\n            if 'reset' in self.request.GET:\n                self.storage.reset()\n                self.storage.current_step = self.steps.first\n            if self.request.GET:\n                query_string = \"?%s\" % self.request.GET.urlencode()\n            else:\n                query_string = \"\"\n            next_step_url = reverse(self.url_name, kwargs={\n                'step': self.steps.current,\n            }) + query_string\n            return redirect(next_step_url)\n\n        # is the current step the \"done\" name/view?\n        elif step_url == self.done_step_name:\n            last_step = self.steps.last\n            return self.render_done(self.get_form(step=last_step,\n                data=self.storage.get_step_data(last_step),\n                files=self.storage.get_step_files(last_step)\n            ), **kwargs)\n\n        # is the url step name not equal to the step in the storage?\n        # if yes, change the step in the storage (if name exists)\n        elif step_url == self.steps.current:\n            # URL step name and storage step name are equal, render!\n            return self.render(self.get_form(\n                data=self.storage.current_step_data,\n                files=self.storage.current_step_data,\n            ), **kwargs)\n\n        elif step_url in self.get_form_list():\n            self.storage.current_step = step_url\n            return self.render(self.get_form(\n                data=self.storage.current_step_data,\n                files=self.storage.current_step_data,\n            ), **kwargs)\n\n        # invalid step name, reset to first and redirect.\n        else:\n            self.storage.current_step = self.steps.first\n            return redirect(self.url_name, step=self.steps.first)", "label": 1}
{"code": "function checkWhitelist(str, whitelist, context) {\n    if (whitelist.indexOf(str) === -1) {\n        throw new ImplementationError(\n            'Invalid \"' + str + '\" (allowed: ' + whitelist.join(', ') + ')' + context.errorContext\n        );\n    }\n    return str;\n}", "label": 3}
{"code": "func chunksFileName(dataDir string, sessionID session.ID, offset int64) string {\n\treturn filepath.Join(dataDir, fmt.Sprintf(\"%v-%v.chunks.gz\", sessionID.String(), offset))\n}", "label": 5}
{"code": "public static vlan_interface_binding[] get(nitro_service service, Long id) throws Exception{\n\t\tvlan_interface_binding obj = new vlan_interface_binding();\n\t\tobj.set_id(id);\n\t\tvlan_interface_binding response[] = (vlan_interface_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def inch\n      line  =  Builders::Signature[self]\n      line  =  line.gsub(\"__dry_initializer_options__\", \"options\")\n      lines =  [\"@!method initialize(#{line})\"]\n      lines += [\"Initializes an instance of #{extended_class}\"]\n      lines += definitions.values.map(&:inch)\n      lines += [\"@return [#{extended_class}]\"]\n      lines.join(\"\\n\")\n    end", "label": 4}
{"code": "function splitSelector (sel, splitter, inBracket) {\n  if (sel.indexOf(splitter) < 0) return [sel]\n  for (var c, i = 0, n = 0, instr = '', prev = 0, d = []; c = sel.charAt(i); i++) {\n    if (instr) {\n      if (c == instr && sel.charAt(i-1)!='\\\\') instr = '';\n      continue\n    }\n    if (c == '\"' || c == '\\'') instr = c;\n    /* istanbul ignore if  */\n    if(!inBracket){\n      if (c == '(' || c == '[') n++;\n      if (c == ')' || c == ']') n--;\n    }\n    if (!n && c == splitter) d.push(sel.substring(prev, i)), prev = i + 1;\n  }\n  return d.concat(sel.substring(prev))\n}", "label": 3}
{"code": "def modify_roles(add, remove, reason = nil)\n      add_role_ids = role_id_array(add)\n      remove_role_ids = role_id_array(remove)\n      old_role_ids = @roles.map(&:id)\n      new_role_ids = (old_role_ids - remove_role_ids + add_role_ids).uniq\n\n      API::Server.update_member(@bot.token, @server.id, @user.id, roles: new_role_ids, reason: reason)\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, locationparameter resource) throws Exception {\n\t\tlocationparameter updateresource = new locationparameter();\n\t\tupdateresource.context = resource.context;\n\t\tupdateresource.q1label = resource.q1label;\n\t\tupdateresource.q2label = resource.q2label;\n\t\tupdateresource.q3label = resource.q3label;\n\t\tupdateresource.q4label = resource.q4label;\n\t\tupdateresource.q5label = resource.q5label;\n\t\tupdateresource.q6label = resource.q6label;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public static Map<String, List<String>> getResponseHeaders(String stringUrl,\n      boolean followRedirects) throws IOException {\n    URL url = new URL(stringUrl);\n    HttpURLConnection conn = (HttpURLConnection) url.openConnection();\n    conn.setInstanceFollowRedirects(followRedirects);\n    \n    InputStream is = conn.getInputStream();\n    if (\"gzip\".equals(conn.getContentEncoding())) {\n       is = new GZIPInputStream(is);\n    }\n\n    Map<String, List<String>> headers = new LinkedHashMap<String, List<String>>(conn.getHeaderFields());\n    headers.put(\"X-Content\", Arrays.asList(MyStreamUtils.readContent(is)));\n    headers.put(\"X-URL\", Arrays.asList(conn.getURL().toString()));\n    headers.put(\"X-Status\", Arrays.asList(String.valueOf(conn.getResponseCode())));\n    \n    return headers;\n  }", "label": 0}
{"code": "def AppendIndexDictionaryToFile(uniqueWords, ndxFile, ipFile, useShortFileName='Y'):\n    \"\"\" \n    Save the list of unique words to the master list \n    \"\"\"\n    if useShortFileName == 'Y':\n        f = os.path.basename(ipFile)\n    else:\n        f = ipFile\n    with open(ndxFile, \"a\", encoding='utf-8', errors='replace') as ndx:\n        word_keys = uniqueWords.keys()\n        #uniqueWords.sort()\n        for word in sorted(word_keys):\n            if word != '':\n                line_nums = uniqueWords[word]\n                ndx.write(f + ', ' + word + ', ')\n                for line_num in line_nums:\n                    ndx.write(str(line_num))\n                ndx.write('\\n')", "label": 1}
{"code": "def filter_ambiguity(records, percent=0.5):  # , repeats=6)\n    \"\"\"\n    Filters out sequences with too much ambiguity as defined by the method\n    parameters.\n\n    :type records: list\n    :param records: A list of sequences\n    :type repeats: int\n    :param repeats: Defines the number of repeated N that trigger truncating a\n                    sequence.\n    :type percent: float\n    :param percent: Defines the overall percentage of N in a sequence that\n                     will cause the sequence to be filtered out.\n    \"\"\"\n    seqs = []\n    # Ns = ''.join(['N' for _ in range(repeats)])\n    count = 0\n    for record in records:\n        if record.seq.count('N')/float(len(record)) < percent:\n#            pos = record.seq.find(Ns)\n#            if pos >= 0:\n#                record.seq = Seq(str(record.seq)[:pos])\n            seqs.append(record)\n        count += 1\n\n    return seqs, count", "label": 1}
{"code": "def _qmed_from_amax_records(self):\n        \"\"\"\n        Return QMED estimate based on annual maximum flow records.\n\n        :return: QMED in m\u00b3/s\n        :rtype: float\n        \"\"\"\n        valid_flows = valid_flows_array(self.catchment)\n        n = len(valid_flows)\n        if n < 2:\n            raise InsufficientDataError(\"Insufficient annual maximum flow records available for catchment {}.\"\n                                        .format(self.catchment.id))\n        return np.median(valid_flows)", "label": 1}
{"code": "public function configureSharedFolders($projectPath, $projectDirectory)\n    {\n        $folders = [\n            [\n                'map' => $projectPath,\n                'to' => \"/home/vagrant/{$projectDirectory}\",\n            ],\n        ];\n\n        if (isset($this->attributes['folders']) && ! empty($this->attributes['folders'])) {\n            foreach ($this->attributes['folders'] as $index => $user_folder) {\n                if (isset($user_folder['map']) && empty($folders[$index]['map'])) {\n                    $folders[$index]['map'] = dirname($projectPath).'/'.basename($user_folder['map']);\n                }\n\n                if (isset($user_folder['to'])) {\n                    $folders[$index]['to'] = $user_folder['to'];\n                }\n\n                if (isset($user_folder['type'])) {\n                    $folders[$index]['type'] = $user_folder['type'];\n                }\n            }\n        }\n\n        $this->update(['folders' => $folders]);\n\n        return $this;\n    }", "label": 2}
{"code": "public function pushCriteria($criteria)\n    {\n        if (is_string($criteria)) {\n            $criteria = new $criteria;\n        }\n        if (!$criteria instanceof CriteriaInterface) {\n            throw new RepositoryException(\"Class \" . get_class($criteria) . \" must be an instance of Prettus\\\\Repository\\\\Contracts\\\\CriteriaInterface\");\n        }\n        $this->criteria->push($criteria);\n\n        return $this;\n    }", "label": 2}
{"code": "def encode_caveat(condition, root_key, third_party_info, key, ns):\n    '''Encrypt a third-party caveat.\n\n    The third_party_info key holds information about the\n    third party we're encrypting the caveat for; the key is the\n    public/private key pair of the party that's adding the caveat.\n\n    The caveat will be encoded according to the version information\n    found in third_party_info.\n\n    @param condition string\n    @param root_key bytes\n    @param third_party_info object\n    @param key nacl key\n    @param ns not used yet\n    @return bytes\n    '''\n    if third_party_info.version == VERSION_1:\n        return _encode_caveat_v1(condition, root_key,\n                                 third_party_info.public_key, key)\n    if (third_party_info.version == VERSION_2 or\n            third_party_info.version == VERSION_3):\n        return _encode_caveat_v2_v3(third_party_info.version, condition,\n                                    root_key, third_party_info.public_key,\n                                    key, ns)\n    raise NotImplementedError('only bakery v1, v2, v3 supported')", "label": 1}
{"code": "public function setLink($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Trace\\V2\\Span\\Link::class);\n        $this->link = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private function getDocumentReference(\n        ConnectionInterface $connection,\n        ValueMapper $mapper,\n        $projectId,\n        $database,\n        $name\n    ) {\n        if ($this->isRelative($name)) {\n            try {\n                $name = $this->fullName($projectId, $database, $name);\n            } catch (ValidationException $e) {\n                // The GAPIC parser does not support special characters in paths,\n                // but Firestore does. If an exception is raised by the parser,\n                // we'll check for special characters. If they exist, we'll\n                // manually construct a document path.\n                $hasSpecialChars = preg_match('/[!@#$%^&*(),.?\":{}|<>]/', $name) === 1;\n\n                //@codeCoverageIgnoreStart\n                if (!$hasSpecialChars) {\n                    throw $e;\n                }\n                //@codeCoverageIgnoreEnd\n\n                $base = $this->databaseName($projectId, $database);\n                $name = $base .'/documents/'. $name;\n            }\n        }\n\n        if (!$this->isDocument($name)) {\n            throw new \\InvalidArgumentException('Given path is not a valid document path.');\n        }\n\n        return new DocumentReference(\n            $connection,\n            $mapper,\n            $this->getCollectionReference(\n                $connection,\n                $mapper,\n                $projectId,\n                $database,\n                $this->parentPath($name)\n            ),\n            $name\n        );\n    }", "label": 2}
{"code": "private function getArgMessage($name, $args = [], $useRequired = false)\n    {\n        $arg = $this->argDefinitions[$name];\n        $msg = '';\n        $modifiers = [];\n        if (isset($arg['valid'])) {\n            $modifiers[] = implode('|', $arg['valid']);\n        }\n        if (isset($arg['choice'])) {\n            $modifiers[] = 'One of ' . implode(', ', $arg['choice']);\n        }\n        if ($modifiers) {\n            $msg .= '(' . implode('; ', $modifiers) . ')';\n        }\n        $msg = wordwrap(\"{$name}: {$msg}\", 75, \"\\n  \");\n\n        if ($useRequired && is_callable($arg['required'])) {\n            $msg .= \"\\n\\n  \";\n            $msg .= str_replace(\"\\n\", \"\\n  \", call_user_func($arg['required'], $args));\n        } elseif (isset($arg['doc'])) {\n            $msg .= wordwrap(\"\\n\\n  {$arg['doc']}\", 75, \"\\n  \");\n        }\n\n        return $msg;\n    }", "label": 2}
{"code": "def from_dict(cls, serialized):\n        '''Create an error from a JSON-deserialized object\n        @param serialized the object holding the serialized error {dict}\n        '''\n        # Some servers return lower case field names for message and code.\n        # The Go client is tolerant of this, so be similarly tolerant here.\n        def field(name):\n            return serialized.get(name) or serialized.get(name.lower())\n        return Error(\n            code=field('Code'),\n            message=field('Message'),\n            info=ErrorInfo.from_dict(field('Info')),\n            version=bakery.LATEST_VERSION,\n        )", "label": 1}
{"code": "public function setSurrogateType($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CustomInfoType_SurrogateType::class);\n        $this->writeOneof(4, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def target_files_in_dir(base_dir = Dir.pwd)\n      # Support Windows: Backslashes from command-line -> forward slashes\n      if File::ALT_SEPARATOR\n        base_dir = base_dir.gsub(File::ALT_SEPARATOR, File::SEPARATOR)\n      end\n      all_files = find_files(base_dir, File::FNM_DOTMATCH)\n      hidden_files = Set.new(all_files - find_files(base_dir, 0))\n      base_dir_config = @config_store.for(base_dir)\n\n      target_files = all_files.select do |file|\n        to_inspect?(file, hidden_files, base_dir_config)\n      end\n\n      # Most recently modified file first.\n      target_files.sort_by! { |path| -Integer(File.mtime(path)) } if fail_fast?\n\n      target_files\n    end", "label": 4}
{"code": "func GetCertAuthoritySchema() string {\n\treturn fmt.Sprintf(V2SchemaTemplate, MetadataSchema, fmt.Sprintf(CertAuthoritySpecV2Schema, RotationSchema, RoleMapSchema), DefaultDefinitions)\n}", "label": 5}
{"code": "public static base_response delete(nitro_service client, nssimpleacl resource) throws Exception {\n\t\tnssimpleacl deleteresource = new nssimpleacl();\n\t\tdeleteresource.aclname = resource.aclname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def connect(host=None, database=None, user=None, password=None, **kwargs):\n    \"\"\"Create a database connection.\"\"\"\n\n    host = host or os.environ['PGHOST']\n    database = database or os.environ['PGDATABASE']\n    user = user or os.environ['PGUSER']\n    password = password or os.environ['PGPASSWORD']\n\n    return psycopg2.connect(host=host,\n                            database=database,\n                            user=user,\n                            password=password,\n                            **kwargs)", "label": 1}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getSink($options + [\n            'sinkName' => $this->formattedName\n        ]);\n    }", "label": 2}
{"code": "def update_fields(fields)\n      attributes[:id]        = fields['id'] || attributes[:id]\n      attributes[:idPlugin]  = fields['idPlugin'] || attributes[:idPlugin]\n      attributes[:scope]     = fields['scope'] || attributes[:scope]\n      attributes[:value]     = JSON.parse(fields['value']).presence if fields.has_key?('value')\n      attributes[:idModel]   = fields['idModel'] || attributes[:idModel]\n      attributes[:access]    = fields['access'] || attributes[:access]\n      self\n    end", "label": 4}
{"code": "func AfterEach(body interface{}, timeout ...float64) bool {\n\tglobalSuite.PushAfterEachNode(body, codelocation.New(1), parseTimeout(timeout...))\n\treturn true\n}", "label": 5}
{"code": "function Subscription (queue, options) {\n        assert.object(queue, 'queue');\n        assert.object(options, 'options');\n\n        this.MAX_DISPOSE_RETRIES = 3;\n        this.retryDelay = 1000;\n        this.queue = queue;\n        this.options = options;\n        this._disposed = false;\n    }", "label": 3}
{"code": "def fibonacci(n)\n      seq = [1, 1]\n      3.upto(n) do\n        seq << seq[-1] + seq[-2]\n      end\n      seq[n-1] # n is 1-based\n    end", "label": 4}
{"code": "function toDrupalMajorVersion(version) {\n    var regex = /^(\\d+)\\.\\d+\\.[x\\d+]/;\n    var match = version.match(regex)\n    if (match) {\n      return match[1] + '.x';\n    }\n\n    return version;\n  }", "label": 3}
{"code": "def from_json(data):\n        \"\"\"\n        Convert JSON into a in memory file storage.\n\n        Args:\n            data (str): valid JSON with path and filenames and\n                        the base64 encoding of the file content.\n\n        Returns:\n            InMemoryFiles: in memory file storage\n        \"\"\"\n        memfiles = InMemoryFiles()\n        memfiles.files = json.loads(data)\n        return memfiles", "label": 1}
{"code": "def permute(x: SYM, perm: List[int]) -> SYM:\n    \"\"\"Perumute a vector\"\"\"\n    x_s = []\n    for i in perm:\n        x_s.append(x[i])\n    return ca.vertcat(*x_s)", "label": 1}
{"code": "function (opts) {\n  var paths = es.through();\n  var files = es.through();\n  \n  paths.pipe(es.writeArray(function (err, srcs) {\n    gulp.src(srcs, opts).pipe(files);\n  }));\n  \n  return es.duplex(paths, files);\n}", "label": 3}
{"code": "public static void addTTLIndex(DBCollection collection, String field, int ttl) {\n        if (ttl <= 0) {\n            throw new IllegalArgumentException(\"TTL must be positive\");\n        }\n        collection.createIndex(new BasicDBObject(field, 1), new BasicDBObject(\"expireAfterSeconds\", ttl));\n    }", "label": 0}
{"code": "public static function getFQCLNFromNameObject(\n        PhpParser\\Node\\Name $class_name,\n        Aliases $aliases\n    ) {\n        /** @var string|null */\n        $resolved_name = $class_name->getAttribute('resolvedName');\n\n        if ($resolved_name) {\n            return $resolved_name;\n        }\n\n        if ($class_name instanceof PhpParser\\Node\\Name\\FullyQualified) {\n            return implode('\\\\', $class_name->parts);\n        }\n\n        if (in_array($class_name->parts[0], ['self', 'static', 'parent'], true)) {\n            return $class_name->parts[0];\n        }\n\n        return Type::getFQCLNFromString(\n            implode('\\\\', $class_name->parts),\n            $aliases\n        );\n    }", "label": 2}
{"code": "def load_configuration(settings)\n      configuration = settings.with_indifferent_access\n      self.options = configuration[:options]\n      self.clients = configuration[:clients]\n      set_log_levels\n    end", "label": 4}
{"code": "public static int minutesDiff(Date earlierDate, Date laterDate) {\n        if (earlierDate == null || laterDate == null) {\n            return 0;\n        }\n\n        return (int) ((laterDate.getTime() / MINUTE_MILLIS) - (earlierDate.getTime() / MINUTE_MILLIS));\n    }", "label": 0}
{"code": "def update(object = {})\n      meta_tags = object.respond_to?(:to_meta_tags) ? object.to_meta_tags : object\n      @meta_tags.deep_merge! normalize_open_graph(meta_tags)\n    end", "label": 4}
{"code": "def predict_sequence(self, X, A, pi, inference='smoothing'):\n        \"\"\"\n        Calculate class probabilities for a sequence of data.\n\n        Parameters\n        ----------\n        X : array\n            Test data, of dimension N times d (rows are time frames, columns\n            are data dimensions)\n        A : class transition matrix, where A[i,j] contains p(y_t=j|y_{t-1}=i)\n        pi : vector of initial class probabilities\n        inference : can be 'smoothing' or 'filtering'.\n\n        Returns:\n        -------\n        y_prob : array\n            An array of dimension N times n_inlier_classes+1, containing\n            the probabilities of each row of X being one of the inlier\n            classes, or the outlier class (last column).\n        \"\"\"\n        obsll = self.predict_proba(X)\n        T, S = obsll.shape\n        alpha = np.zeros((T, S))\n\n        alpha[0, :] = pi\n        for t in range(1, T):\n            alpha[t, :] = np.dot(alpha[t-1, :], A)\n            for s in range(S):\n                alpha[t, s] *= obsll[t, s]\n            alpha[t, :] = alpha[t, :]/sum(alpha[t, :])\n\n        if inference == 'filtering':\n            return alpha\n        else:\n            beta = np.zeros((T, S))\n            gamma = np.zeros((T, S))\n            beta[T-1, :] = np.ones(S)\n            for t in range(T-2, -1, -1):\n                for i in range(S):\n                    for j in range(S):\n                        beta[t, i] += A[i, j]*obsll[t+1, j]*beta[t+1, j]\n                beta[t, :] = beta[t, :]/sum(beta[t, :])\n\n            for t in range(T):\n                gamma[t, :] = alpha[t, :]*beta[t, :]\n                gamma[t, :] = gamma[t, :]/sum(gamma[t, :])\n\n            return gamma", "label": 1}
{"code": "func (args Arguments) Diff(objects []interface{}) (string, int) {\n\t//TODO: could return string as error and nil for No difference\n\n\tvar output = \"\\n\"\n\tvar differences int\n\n\tvar maxArgCount = len(args)\n\tif len(objects) > maxArgCount {\n\t\tmaxArgCount = len(objects)\n\t}\n\n\tfor i := 0; i < maxArgCount; i++ {\n\t\tvar actual, expected interface{}\n\t\tvar actualFmt, expectedFmt string\n\n\t\tif len(objects) <= i {\n\t\t\tactual = \"(Missing)\"\n\t\t\tactualFmt = \"(Missing)\"\n\t\t} else {\n\t\t\tactual = objects[i]\n\t\t\tactualFmt = fmt.Sprintf(\"(%[1]T=%[1]v)\", actual)\n\t\t}\n\n\t\tif len(args) <= i {\n\t\t\texpected = \"(Missing)\"\n\t\t\texpectedFmt = \"(Missing)\"\n\t\t} else {\n\t\t\texpected = args[i]\n\t\t\texpectedFmt = fmt.Sprintf(\"(%[1]T=%[1]v)\", expected)\n\t\t}\n\n\t\tif matcher, ok := expected.(argumentMatcher); ok {\n\t\t\tif matcher.Matches(actual) {\n\t\t\t\toutput = fmt.Sprintf(\"%s\\t%d: PASS:  %s matched by %s\\n\", output, i, actualFmt, matcher)\n\t\t\t} else {\n\t\t\t\tdifferences++\n\t\t\t\toutput = fmt.Sprintf(\"%s\\t%d: FAIL:  %s not matched by %s\\n\", output, i, actualFmt, matcher)\n\t\t\t}\n\t\t} else if reflect.TypeOf(expected) == reflect.TypeOf((*AnythingOfTypeArgument)(nil)).Elem() {\n\n\t\t\t// type checking\n\t\t\tif reflect.TypeOf(actual).Name() != string(expected.(AnythingOfTypeArgument)) && reflect.TypeOf(actual).String() != string(expected.(AnythingOfTypeArgument)) {\n\t\t\t\t// not match\n\t\t\t\tdifferences++\n\t\t\t\toutput = fmt.Sprintf(\"%s\\t%d: FAIL:  type %s != type %s - %s\\n\", output, i, expected, reflect.TypeOf(actual).Name(), actualFmt)\n\t\t\t}\n\n\t\t} else {\n\n\t\t\t// normal checking\n\n\t\t\tif assert.ObjectsAreEqual(expected, Anything) || assert.ObjectsAreEqual(actual, Anything) || assert.ObjectsAreEqual(actual, expected) {\n\t\t\t\t// match\n\t\t\t\toutput = fmt.Sprintf(\"%s\\t%d: PASS:  %s == %s\\n\", output, i, actualFmt, expectedFmt)\n\t\t\t} else {\n\t\t\t\t// not match\n\t\t\t\tdifferences++\n\t\t\t\toutput = fmt.Sprintf(\"%s\\t%d: FAIL:  %s != %s\\n\", output, i, actualFmt, expectedFmt)\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif differences == 0 {\n\t\treturn \"No differences.\", differences\n\t}\n\n\treturn output, differences\n\n}", "label": 5}
{"code": "def powerline_shell():\n    '''Install and set up powerline-shell prompt.\n\n    More infos:\n     * https://github.com/banga/powerline-shell\n     * https://github.com/ohnonot/powerline-shell\n     * https://askubuntu.com/questions/283908/how-can-i-install-and-use-powerline-plugin\n    '''\n    assert env.host == 'localhost', 'This task cannot run on a remote host'\n\n    # set up fonts for powerline\n\n    checkup_git_repo_legacy('https://github.com/powerline/fonts.git',\n                            name='powerline-fonts')\n    run('cd ~/repos/powerline-fonts && ./install.sh')\n#    run('fc-cache -vf ~/.local/share/fonts')\n    prefix = 'URxvt*font: '\n    from config import fontlist\n    line = prefix + fontlist\n    update_or_append_line(filename='~/.Xresources', prefix=prefix,\n            new_line=line)\n    if env.host_string == 'localhost':\n        run('xrdb  ~/.Xresources')\n\n    # set up powerline-shell\n\n    checkup_git_repo_legacy('https://github.com/banga/powerline-shell.git')\n#    checkup_git_repo_legacy('https://github.com/ohnonot/powerline-shell.git')\n    install_file_legacy(path='~/repos/powerline-shell/config.py')\n    run('cd ~/repos/powerline-shell && ./install.py')\n\n    question = 'Use normal question mark (u003F) for untracked files instead '\\\n        'of fancy \"black question mark ornament\" (u2753, which may not work)?'\n    if query_yes_no(question, default='yes'):\n        filename = '~/repos/powerline-shell/powerline-shell.py'\n        update_or_append_line(filename, keep_backup=False,\n                              prefix=\"        'untracked': u'\\u2753',\",\n                              new_line=\"        'untracked': u'\\u003F',\")\n        run(flo('chmod u+x  {filename}'))\n\n    bash_snippet = '~/.bashrc_powerline_shell'\n    install_file_legacy(path=bash_snippet)\n    prefix = flo('if [ -f {bash_snippet} ]; ')\n    enabler = flo('if [ -f {bash_snippet} ]; then source {bash_snippet}; fi')\n    uncomment_or_update_or_append_line(filename='~/.bashrc', prefix=prefix,\n                                       new_line=enabler)", "label": 1}
{"code": "func New(path string) (*Handle, error) {\n\tsetup()\n\n\tn := netns.None()\n\tif path != \"\" {\n\t\tvar err error\n\t\tn, err = netns.GetFromPath(path)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tdefer n.Close()\n\n\tsock, err := nl.GetNetlinkSocketAt(n, netns.None(), syscall.NETLINK_GENERIC)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Add operation timeout to avoid deadlocks\n\ttv := syscall.NsecToTimeval(netlinkSendSocketTimeout.Nanoseconds())\n\tif err := sock.SetSendTimeout(&tv); err != nil {\n\t\treturn nil, err\n\t}\n\ttv = syscall.NsecToTimeval(netlinkRecvSocketsTimeout.Nanoseconds())\n\tif err := sock.SetReceiveTimeout(&tv); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Handle{sock: sock}, nil\n}", "label": 5}
{"code": "def load_model(file)\n      begin\n        require_dependency(file)\n      rescue Exception => e\n        Logger.new($stdout).warn(e.message)\n      end\n    end", "label": 4}
{"code": "def get_ignition_type(root):\n    \"\"\"Gets ignition type and target.\n\n    Args:\n        root (`~xml.etree.ElementTree.Element`): Root of ReSpecTh XML file\n\n    Returns:\n        properties (`dict`): Dictionary with ignition type/target information\n    \"\"\"\n    properties = {}\n    elem = root.find('ignitionType')\n\n    if elem is None:\n        raise MissingElementError('ignitionType')\n    elem = elem.attrib\n\n    if 'target' in elem:\n        ign_target = elem['target'].rstrip(';').upper()\n    else:\n        raise MissingAttributeError('target', 'ignitionType')\n\n    if 'type' in elem:\n        ign_type = elem['type']\n        if ign_type == 'baseline max intercept from d/dt':\n            ign_type = 'd/dt max extrapolated'\n    else:\n        raise MissingAttributeError('type', 'ignitionType')\n\n    # ReSpecTh allows multiple ignition targets\n    if len(ign_target.split(';')) > 1:\n        raise NotImplementedError('Multiple ignition targets not supported.')\n\n    # Acceptable ignition targets include pressure, temperature, and species\n    # concentrations\n    if ign_target == 'OHEX':\n        ign_target = 'OH*'\n    elif ign_target == 'CHEX':\n        ign_target = 'CH*'\n    elif ign_target == 'P':\n        ign_target = 'pressure'\n    elif ign_target == 'T':\n        ign_target = 'temperature'\n\n    if ign_target not in ['pressure', 'temperature', 'OH', 'OH*', 'CH*', 'CH']:\n        raise KeywordError(ign_target + ' not valid ignition target')\n\n    if ign_type not in ['max', 'd/dt max', '1/2 max', 'min', 'd/dt max extrapolated']:\n        raise KeywordError(ign_type + ' not valid ignition type')\n\n    properties['type'] = ign_type\n    properties['target'] = ign_target\n\n    return properties", "label": 1}
{"code": "def process_from_async_handler(payload)\n      payload = Rollbar::JSON.load(payload) if payload.is_a?(String)\n\n      item = Item.build_with(payload,\n                             :notifier => self,\n                             :configuration => configuration,\n                             :logger => logger)\n\n      Rollbar.silenced do\n        begin\n          process_item(item)\n        rescue StandardError => e\n          report_internal_error(e)\n\n          raise\n        end\n      end\n    end", "label": 4}
{"code": "def from_variant_and_transcript(\n            cls, variant, transcript, context_size):\n        \"\"\"\n        Extracts the reference sequence around a variant locus on a particular\n        transcript.\n\n        Parameters\n        ----------\n        variant : varcode.Variant\n\n        transcript : pyensembl.Transcript\n\n        context_size : int\n\n        Returns SequenceKey object.\n\n        Can also return None if Transcript lacks sufficiently long sequence\n        \"\"\"\n\n        full_transcript_sequence = transcript.sequence\n\n        if full_transcript_sequence is None:\n            logger.warn(\n                \"Expected transcript %s (overlapping %s) to have sequence\",\n                transcript.name,\n                variant)\n            return None\n\n        # get the interbase range of offsets which capture all reference\n        # bases modified by the variant\n        variant_start_offset, variant_end_offset = \\\n            interbase_range_affected_by_variant_on_transcript(\n                variant=variant,\n                transcript=transcript)\n\n        reference_cdna_at_variant = full_transcript_sequence[\n            variant_start_offset:variant_end_offset]\n\n        if not variant_matches_reference_sequence(\n                variant=variant,\n                strand=transcript.strand,\n                ref_seq_on_transcript=reference_cdna_at_variant):\n            logger.warn(\n                \"Variant %s doesn't match reference sequence on transcript %s: \"\n                \"may span splice junction\",\n                variant,\n                transcript)\n            return None\n\n        if len(full_transcript_sequence) < 6:\n            # need at least 6 nucleotides for a start and stop codon\n            logger.warn(\n                \"Sequence of %s (overlapping %s) too short: %d\",\n                transcript,\n                variant,\n                len(full_transcript_sequence))\n            return None\n\n        logger.info(\n            \"Interbase offset range on %s for variant %s = %d:%d\",\n            transcript.name,\n            variant,\n            variant_start_offset,\n            variant_end_offset)\n\n        reference_cdna_before_variant = full_transcript_sequence[\n            max(0, variant_start_offset - context_size):\n            variant_start_offset]\n\n        reference_cdna_after_variant = full_transcript_sequence[\n            variant_end_offset:\n            variant_end_offset + context_size]\n\n        return ReferenceSequenceKey(\n            strand=transcript.strand,\n            sequence_before_variant_locus=reference_cdna_before_variant,\n            sequence_at_variant_locus=reference_cdna_at_variant,\n            sequence_after_variant_locus=reference_cdna_after_variant)", "label": 1}
{"code": "function findObjects(EntityClass, query, params) {\n  expect(arguments).to.have.length.within(\n    2,\n    3,\n    'Invalid arguments length when inserting an object in a MongoAdapter ' +\n    '(it has to be passed 2 or 3 arguments)'\n  );\n\n  function findDocuments(db) {\n    // cleaning params\n    params = params || {};\n    params.sort = params.sort || {id: 1};\n    params.skip = params.skip || 0;\n    params.limit = params.limit || 0;\n\n    if (params.sort.hasOwnProperty('id')) {\n      params.sort._id = params.sort.id;\n      delete params.sort.id;\n    }\n\n    return _buildCursor(db, EntityClass, query, params)\n        .skip(params.skip)\n        .limit(params.limit)\n        .sort(params.sort)\n        .toArray();\n  }\n\n  function populateEntities(docs) {\n    var entities = [];\n    for (var i = 0; i < docs.length; i++) {\n      entities.push(documentToObject(docs[i], EntityClass.adapterName));\n    }\n    return entities;\n  }\n\n  return this.getDatabase()\n    .then(findDocuments)\n    .then(populateEntities);\n}", "label": 3}
{"code": "function resolveNodeModules(pkgpath) {\n  let dir = pkgpath;\n  let dirs = [];\n  let depth = maxFileSystemDepth;\n  let parent;\n  let nodeModulespath;\n\n  while (true) {\n    parent = path.dirname(dir);\n    // Stop if we hit max file system depth or root\n    // Convert to lowercase to fix problems on Windows\n    if (!--depth || parent.toLowerCase() === dir.toLowerCase()) {\n      break;\n    }\n\n    nodeModulespath = path.resolve(dir, 'node_modules');\n\n    if (exists(nodeModulespath)) dirs.push(nodeModulespath);\n\n    // Walk\n    dir = parent;\n  }\n\n  return dirs;\n}", "label": 3}
{"code": "function decode_param(val) {\n  if (typeof val !== 'string' || val.length === 0) {\n    return val;\n  }\n\n  try {\n    return decodeURIComponent(val);\n  } catch (err) {\n    if (err instanceof URIError) {\n      err.message = `Failed to decode param '${val}'`;\n      err.status = err.statusCode = 400;\n    }\n\n    throw err;\n  }\n}", "label": 3}
{"code": "public static function invalidScope($scope, $redirectUri = null)\n    {\n        $errorMessage = 'The requested scope is invalid, unknown, or malformed';\n\n        if (empty($scope)) {\n            $hint = 'Specify a scope in the request or set a default scope';\n        } else {\n            $hint = sprintf(\n                'Check the `%s` scope',\n                htmlspecialchars($scope, ENT_QUOTES, 'UTF-8', false)\n            );\n        }\n\n        return new static($errorMessage, 5, 'invalid_scope', 400, $hint, $redirectUri);\n    }", "label": 2}
{"code": "function(callback) {\n  async.parallelAsync([\n    tox.addGroupchat.bind(tox),\n    tox.getAV().addGroupchat.bind(tox.getAV())\n  ]).then(function(results) {\n    groupchats['text'] = results[0];\n    groupchats['av'] = results[1];\n  }).finally(callback);\n}", "label": 3}
{"code": "def oauth_get_user(client_id, account_info=None, access_token=None):\n    \"\"\"Retrieve user object for the given request.\n\n    Uses either the access token or extracted account information to retrieve\n    the user object.\n\n    :param client_id: The client id.\n    :param account_info: The dictionary with the account info.\n        (Default: ``None``)\n    :param access_token: The access token. (Default: ``None``)\n    :returns: A :class:`invenio_accounts.models.User` instance or ``None``.\n    \"\"\"\n    if access_token:\n        token = RemoteToken.get_by_token(client_id, access_token)\n        if token:\n            return token.remote_account.user\n\n    if account_info:\n        external_id = _get_external_id(account_info)\n        if external_id:\n            user_identity = UserIdentity.query.filter_by(\n                id=external_id['id'], method=external_id['method']).first()\n            if user_identity:\n                return user_identity.user\n        email = account_info.get('user', {}).get('email')\n        if email:\n            return User.query.filter_by(email=email).one_or_none()\n    return None", "label": 1}
{"code": "public static function titleMatches($titleRegexp)\n    {\n        return new static(\n            function (WebDriver $driver) use ($titleRegexp) {\n                return (bool) preg_match($titleRegexp, $driver->getTitle());\n            }\n        );\n    }", "label": 2}
{"code": "function parseList(list, whitelist, context) {\n    const parsed = list.split(',');\n    parsed.forEach(item => checkWhitelist(item, whitelist, context));\n    return parsed;\n}", "label": 3}
{"code": "func (c *Manager) AttachTag(ctx context.Context, tagID string, ref mo.Reference) error {\n\tid, err := c.tagID(ctx, tagID)\n\tif err != nil {\n\t\treturn err\n\t}\n\tspec := internal.NewAssociation(ref)\n\turl := internal.URL(c, internal.AssociationPath).WithID(id).WithAction(\"attach\")\n\treturn c.Do(ctx, url.Request(http.MethodPost, spec), nil)\n}", "label": 5}
{"code": "public void add(Vector3d v1, Vector3d v2) {\n        x = v1.x + v2.x;\n        y = v1.y + v2.y;\n        z = v1.z + v2.z;\n    }", "label": 0}
{"code": "public static tunneltrafficpolicy[] get(nitro_service service, options option) throws Exception{\n\t\ttunneltrafficpolicy obj = new tunneltrafficpolicy();\n\t\ttunneltrafficpolicy[] response = (tunneltrafficpolicy[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static base_responses unlink(nitro_service client, sslcertkey resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslcertkey unlinkresources[] = new sslcertkey[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tunlinkresources[i] = new sslcertkey();\n\t\t\t\tunlinkresources[i].certkey = resources[i].certkey;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, unlinkresources,\"unlink\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def clear(self):\n        \"\"\"\n        Clears grid to be EMPTY\n        \"\"\"\n        self.grid = [[EMPTY for dummy_col in range(self.grid_width)] for dummy_row in range(self.grid_height)]", "label": 1}
{"code": "def method_missing(m, *args, &block)\n      begin\n        results = client.send(m, *args, &block)\n      rescue Exception => e # rubocop:disable Lint/RescueException\n        raise unless e.class.to_s == symbol.to_s && backoff < backoff_limit\n\n        @backoff = backoff + (iteration * iteration * 0.5)\n        @iteration += 1\n        sleep backoff\n        results = self.send(m, *args, &block)\n      end\n\n      reset_backoff\n\n      results\n    end", "label": 4}
{"code": "def decode_escapes(s):\n    '''Unescape libconfig string literals'''\n    def decode_match(match):\n        return codecs.decode(match.group(0), 'unicode-escape')\n\n    return ESCAPE_SEQUENCE_RE.sub(decode_match, s)", "label": 1}
{"code": "public static base_responses delete(nitro_service client, String communityname[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (communityname != null && communityname.length > 0) {\n\t\t\tsnmpcommunity deleteresources[] = new snmpcommunity[communityname.length];\n\t\t\tfor (int i=0;i<communityname.length;i++){\n\t\t\t\tdeleteresources[i] = new snmpcommunity();\n\t\t\t\tdeleteresources[i].communityname = communityname[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function toggle(progress) {\n  var opts = this.options;\n  var element = this.element;\n  var times = Object.keys(opts);\n\n  times.forEach(function(time) {\n    var css = opts[time];\n\n    if (progress > time) {\n      element.classList.add(css);\n    } else {\n      element.classList.remove(css);\n    }\n  });\n}", "label": 3}
{"code": "public function setFaceAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\FaceAnnotation::class);\n        $this->face_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private function validateValue($value, $type, $allowNull = false)\n    {\n        if (!is_numeric($value) && (!$allowNull || ($allowNull && $value !== null))) {\n            throw new InvalidArgumentException(sprintf(\n                'Given %s must be a numeric value.',\n                $type\n            ));\n        }\n\n        return $allowNull && $value === null\n            ? $value\n            : (float) $value;\n    }", "label": 2}
{"code": "public function setMin($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Value::class);\n        $this->min = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response add(nitro_service client, nd6 resource) throws Exception {\n\t\tnd6 addresource = new nd6();\n\t\taddresource.neighbor = resource.neighbor;\n\t\taddresource.mac = resource.mac;\n\t\taddresource.ifnum = resource.ifnum;\n\t\taddresource.vlan = resource.vlan;\n\t\taddresource.td = resource.td;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public static nsxmlnamespace get(nitro_service service, String prefix) throws Exception{\n\t\tnsxmlnamespace obj = new nsxmlnamespace();\n\t\tobj.set_prefix(prefix);\n\t\tnsxmlnamespace response = (nsxmlnamespace) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function isCollection(obj) {\n  if (isPattern(obj)) {\n    return false;\n  }\n  return Object.keys(obj).some(childKey => isPattern(obj[childKey]));\n}", "label": 3}
{"code": "def handle_attribute_value(attribute, value)\n      type = attribute.at_xpath('./cda:value/@xsi:type', NAMESPACES).try(:value)\n      case type\n      when 'II'\n        if value.nil?\n          value = attribute.at_xpath('./cda:value/@extension', NAMESPACES).try(:value)\n        end\n        HQMF::Identifier.new(type,\n                             attribute.at_xpath('./cda:value/@root', NAMESPACES).try(:value),\n                             attribute.at_xpath('./cda:value/@extension', NAMESPACES).try(:value))\n      when 'ED'\n        HQMF::ED.new(type, value, attribute.at_xpath('./cda:value/@mediaType', NAMESPACES).try(:value))\n      when 'CD'\n        HQMF::Coded.new('CD',\n                        attribute.at_xpath('./cda:value/@codeSystem', NAMESPACES).try(:value),\n                        attribute.at_xpath('./cda:value/@code', NAMESPACES).try(:value),\n                        attribute.at_xpath('./cda:value/@valueSet', NAMESPACES).try(:value),\n                        attribute.at_xpath('./cda:value/cda:displayName/@value', NAMESPACES).try(:value))\n      else\n        value.present? ? HQMF::GenericValueContainer.new(type, value) : HQMF::AnyValue.new(type)\n      end\n    end", "label": 4}
{"code": "function setLevel(level) {\n    opts.level = level;\n    let logLevelIndex = levels.indexOf(opts.level.toUpperCase());\n\n    levels.forEach((logLevel) => {\n      let fn;\n      if (logLevelIndex <= levels.indexOf(logLevel)) {\n        fn = logWrap(logLevel);\n      } else {\n        fn = noop;\n      }\n      API[logLevel.toLowerCase()] = fn;\n    });\n  }", "label": 3}
{"code": "func GetStaticTokensSchema(extensionSchema string) string {\n\tvar staticTokensSchema string\n\tif staticTokensSchema == \"\" {\n\t\tstaticTokensSchema = fmt.Sprintf(StaticTokensSpecSchemaTemplate, \"\")\n\t} else {\n\t\tstaticTokensSchema = fmt.Sprintf(StaticTokensSpecSchemaTemplate, \",\"+extensionSchema)\n\t}\n\treturn fmt.Sprintf(V2SchemaTemplate, MetadataSchema, staticTokensSchema, DefaultDefinitions)\n}", "label": 5}
{"code": "function get_mod (parsed) {\n  var id = parsed.id;\n\n  // id -> '@kael/a@1.1.0/b'\n  return mods[id] || (mods[id] = {\n    // package scope:\n    s: parsed.s,\n    // package name: 'a'\n    n: parsed.n,\n    // package version: '1.1.0'\n    v: parsed.v,\n    // module path: '/b'\n    p: parsed.p,\n    // module id: 'a@1.1.0/b'\n    id: id,\n    // package id: 'a@1.1.0'\n    k: parsed.k,\n    // version map of the current module\n    m: {},\n    // loading queue\n    l: [],\n    // If there is no path, it must be a main entry.\n    // Actually, there will always be a path when defining a module,\n    // but `get_mod` method is called when a module has been required,\n    // and not loaded and defined.\n    // When we `require('foo')`, `foo` must be a main module of a package.\n    main: !parsed.p\n    // map: {Object} The map of aliases to real module id\n  });\n}", "label": 3}
{"code": "public function listBreakpoints(array $args = [])\n    {\n        return $this->send([$this->controllerClient, 'listActiveBreakpoints'], [\n            $this->pluck('debuggeeId', $args),\n            $args\n        ]);\n    }", "label": 2}
{"code": "public static function getConfigForPath($path, $base_dir, $output_format)\n    {\n        $config_path = self::locateConfigFile($path);\n\n        if (!$config_path) {\n            if ($output_format === ProjectAnalyzer::TYPE_CONSOLE) {\n                exit(\n                    'Could not locate a config XML file in path ' . $path . '. Have you run \\'psalm --init\\' ?' .\n                    PHP_EOL\n                );\n            }\n            throw new ConfigException('Config not found for path ' . $path);\n        }\n\n        return self::loadFromXMLFile($config_path, $base_dir);\n    }", "label": 2}
{"code": "function handler(notification) {\n        debug('summoner received a mention notification!');\n        return notification.getUser()\n            .then((user) => {\n                debug(`summoner responding to summons by ${user.name}`);\n                const index = Math.floor(Math.random() * messages.length);\n                const message = messages[index].replace(/%(\\w+)%/g, (_, key) => {\n                    let value = user[key];\n                    if (key === 'name' && !value) {\n                        value = user.username;\n                    }\n                    value = value || `%${key}%`;\n                    if (typeof value !== 'string') {\n                        value = `%${key}%`;\n                    }\n                    return value;\n                });\n                debug(`summoner replying with: ${message}`);\n                return forum.Post.reply(notification.topicId, notification.postId, message);\n            }).catch((err) => {\n                forum.emit('error', err);\n                return Promise.reject(err);\n            });\n    }", "label": 3}
{"code": "function() {\n      var privateCollection = this.privateCollection;\n      if (!this.parentBehavior.returnSingleResult) {\n        return privateCollection.toJSON();\n      }\n\n      if (privateCollection.length === 0) {\n        return undefined;\n      } else if (privateCollection.length === 1) {\n        var singleResultModel = privateCollection.at(0);\n        return singleResultModel.toJSON();\n      } else {\n        throw new Error('Multiple results found, but single result expected: ' + JSON.stringify(privateCollection.toJSON()));\n      }\n    }", "label": 3}
{"code": "def scan(host, port=80, url=None, https=False, timeout=1, max_size=65535):\n    \"\"\"\n    Scan a network port\n\n    Parameters\n    ----------\n    host : str\n        Host or ip address to scan\n\n    port : int, optional\n        Port to scan, default=80\n\n    url : str, optional\n        URL to perform get request to on the host and port specified\n\n    https : bool, optional\n        Perform ssl connection on the socket, default=False\n\n    timeout : float\n        Timeout for network operations, default=1\n\n    Returns\n    -------\n    dict\n        Result dictionary that contains the following keys:\n            host - The host or IP address that was scanned\n            port - The port number that was scanned\n            state - The state of the port, will be either \"open\" or \"closed\"\n            durations - An ordered dictionary with floating point value of the\n            time elapsed for each connection operation\n\n    Raises\n    ------\n    ScanFailed - The scan operation failed\n    \"\"\"\n    starts = OrderedDict()\n    ends = OrderedDict()\n    port = int(port)\n    result = dict(\n        host=host, port=port, state='closed', durations=OrderedDict()\n    )\n    if url:\n        timeout = 1\n        result['code'] = None\n\n    starts['all'] = starts['dns'] = datetime.datetime.now()\n\n    # DNS Lookup\n    try:\n        hostip = socket.gethostbyname(host)\n        result['ip'] = hostip\n        ends['dns'] = datetime.datetime.now()\n    except socket.gaierror:\n        raise ScanFailed('DNS Lookup failed', result=result)\n\n    # TCP Connect\n    starts['connect'] = datetime.datetime.now()\n    network_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    network_socket.settimeout(timeout)\n    result_connection = network_socket.connect_ex((hostip, port))\n    ends['connect'] = datetime.datetime.now()\n\n    # SSL\n    if https:\n        starts['ssl'] = datetime.datetime.now()\n        try:\n            network_socket = ssl.wrap_socket(network_socket)\n        except socket.timeout:\n            raise ScanFailed('SSL socket timeout', result=result)\n        ends['ssl'] = datetime.datetime.now()\n\n    # Get request\n    if result_connection == 0 and url:\n        starts['request'] = datetime.datetime.now()\n        network_socket.send(\n            \"GET {0} HTTP/1.0\\r\\nHost: {1}\\r\\n\\r\\n\".format(\n                url, host\n            ).encode('ascii'))\n        if max_size:\n            data = network_socket.recv(max_size)\n        else:\n            data = network_socket.recv()\n        result['length'] = len(data)\n        data = data.decode('ascii', errors='ignore')\n        result['response'] = (data)\n        try:\n            result['code'] = int(data.split('\\n')[0].split()[1])\n        except IndexError:\n            pass\n        ends['request'] = datetime.datetime.now()\n    network_socket.close()\n\n    # Calculate durations\n    ends['all'] = datetime.datetime.now()\n    for duration in starts.keys():\n        if duration in ends.keys():\n            result['durations'][duration] = ends[duration] - starts[duration]\n    if result_connection == 0:\n        result['state'] = 'open'\n    return result", "label": 1}
{"code": "private function connectWithTimeout($socket, $address, ParametersInterface $parameters)\n    {\n        socket_set_nonblock($socket);\n\n        if (@socket_connect($socket, $address, (int) $parameters->port) === false) {\n            $error = socket_last_error();\n\n            if ($error != SOCKET_EINPROGRESS && $error != SOCKET_EALREADY) {\n                $this->emitSocketError();\n            }\n        }\n\n        socket_set_block($socket);\n\n        $null = null;\n        $selectable = array($socket);\n\n        $timeout = (isset($parameters->timeout) ? (float) $parameters->timeout : 5.0);\n        $timeoutSecs = floor($timeout);\n        $timeoutUSecs = ($timeout - $timeoutSecs) * 1000000;\n\n        $selected = socket_select($selectable, $selectable, $null, $timeoutSecs, $timeoutUSecs);\n\n        if ($selected === 2) {\n            $this->onConnectionError('Connection refused.', SOCKET_ECONNREFUSED);\n        }\n\n        if ($selected === 0) {\n            $this->onConnectionError('Connection timed out.', SOCKET_ETIMEDOUT);\n        }\n\n        if ($selected === false) {\n            $this->emitSocketError();\n        }\n    }", "label": 2}
{"code": "public static base_responses add(nitro_service client, autoscaleprofile resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tautoscaleprofile addresources[] = new autoscaleprofile[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new autoscaleprofile();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].type = resources[i].type;\n\t\t\t\taddresources[i].url = resources[i].url;\n\t\t\t\taddresources[i].apikey = resources[i].apikey;\n\t\t\t\taddresources[i].sharedsecret = resources[i].sharedsecret;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def norm(table):\n    \"\"\"\n    fit to normal distribution\n    \"\"\"\n    print('# norm dist is broken', file=sys.stderr)\n    exit()\n    from matplotlib.pyplot import hist as hist\n    t = []\n    for i in table:\n        t.append(np.ndarray.tolist(hist(i, bins = len(i), normed = True)[0]))\n    return t", "label": 1}
{"code": "public function updateBatch($table, array $dataSet, array $options = [])\n    {\n        $mutations = [];\n        foreach ($dataSet as $data) {\n            $mutations[] = $this->operation->mutation(Operation::OP_UPDATE, $table, $data);\n        }\n\n        return $this->commitInSingleUseTransaction($mutations, $options);\n    }", "label": 2}
{"code": "def split_by_category(biom_cols, mapping, category_id):\n    \"\"\"\n    Split up the column data in a biom table by mapping category value.\n    \"\"\"\n    columns = defaultdict(list)\n    for i, col in enumerate(biom_cols):\n        columns[mapping[col['id']][category_id]].append((i, col))\n\n    return columns", "label": 1}
{"code": "function Refs(a, b) {\n\n  if (!(this instanceof Refs)) {\n    return new Refs(a, b);\n  }\n\n  // link\n  a.inverse = b;\n  b.inverse = a;\n\n  this.props = {};\n  this.props[a.name] = a;\n  this.props[b.name] = b;\n}", "label": 3}
{"code": "private ShardInformation createShardInformation(String shard) {\n    ShardInformation shardInformation = new ShardInformation(shard);\n    ModifiableSolrParams solrParams = new ModifiableSolrParams();\n    solrParams.add(CommonParams.Q, \"*:*\");\n    solrParams.add(CommonParams.ROWS, \"0\");\n    solrParams.add(CommonParams.HEADER_ECHO_PARAMS, \"none\");\n    solrParams.add(ShardParams.IS_SHARD, CommonParams.TRUE);\n    solrParams.add(MtasSolrSearchComponent.PARAM_MTAS, CommonParams.TRUE);\n    solrParams.add(MtasSolrComponentStatus.PARAM_MTAS_STATUS, CommonParams.TRUE);\n    solrParams.add(\n        MtasSolrComponentStatus.PARAM_MTAS_STATUS + \".\" + MtasSolrComponentStatus.NAME_MTAS_STATUS_MTASHANDLER,\n        CommonParams.TRUE);\n    solrParams.add(\n        MtasSolrComponentStatus.PARAM_MTAS_STATUS + \".\" + MtasSolrComponentStatus.NAME_MTAS_STATUS_NUMBEROFSEGMENTS,\n        CommonParams.TRUE);\n    solrParams.add(\n        MtasSolrComponentStatus.PARAM_MTAS_STATUS + \".\" + MtasSolrComponentStatus.NAME_MTAS_STATUS_NUMBEROFDOCUMENTS,\n        CommonParams.TRUE);\n    SolrClient solrClient = new HttpSolrClient.Builder(shard).build();\n    try {  \n      QueryResponse response = solrClient.query(solrParams);\n      Object mtasHandlerObject = Objects.requireNonNull(\n          response.getResponse().findRecursive(MtasSolrSearchComponent.NAME, MtasSolrComponentStatus.NAME,\n              MtasSolrComponentStatus.NAME_MTAS_STATUS_MTASHANDLER),\n          \"no number of segments for \" + shard);\n      Object numberOfSegmentsObject = Objects.requireNonNull(\n          response.getResponse().findRecursive(MtasSolrSearchComponent.NAME, MtasSolrComponentStatus.NAME,\n              MtasSolrComponentStatus.NAME_MTAS_STATUS_NUMBEROFSEGMENTS),\n          \"no number of documents for \" + shard);\n      Object numberOfDocumentsObject = Objects.requireNonNull(\n          response.getResponse().findRecursive(MtasSolrSearchComponent.NAME, MtasSolrComponentStatus.NAME,\n              MtasSolrComponentStatus.NAME_MTAS_STATUS_NUMBEROFDOCUMENTS),\n          \"no name for \" + shard);\n      Object nameObject = Objects.requireNonNull(response.getResponse().findRecursive(MtasSolrSearchComponent.NAME,\n          MtasSolrComponentStatus.NAME, ShardInformation.NAME_NAME), \"no handler for \" + shard);\n      if (mtasHandlerObject instanceof String) {\n        shardInformation.mtasHandler = (String) mtasHandlerObject;\n      }\n      if (numberOfSegmentsObject instanceof Integer) {\n        shardInformation.numberOfSegments = (Integer) numberOfSegmentsObject;\n      }\n      if (numberOfDocumentsObject instanceof Integer) {\n        shardInformation.numberOfDocuments = ((Integer) numberOfDocumentsObject).longValue();\n      }\n      if (nameObject instanceof String) {\n        shardInformation.name = (String) nameObject;\n      }\n      shardIndex.put(shard, shardInformation);\n    } catch (NullPointerException | SolrServerException | IOException e) {\n      log.error(e);\n      return null;\n    } finally {\n      if (solrClient != null) {\n        try {\n          solrClient.close();\n        } catch (IOException e) {\n          log.error(e);\n        }\n      }\n    }\n    return shardInformation;\n  }", "label": 0}
{"code": "public function setDetectedBreak($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\TextAnnotation_DetectedBreak::class);\n        $this->detected_break = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(theDialog) {\n            $(theDialog.host).css('opacity', 0);\n            $(theDialog.blockout).css('opacity', 0);\n\n            setTimeout(function() {\n                ko.removeNode(theDialog.host);\n                ko.removeNode(theDialog.blockout);\n            }, this.removeDelay);\n\n            if (!dialog.isOpen()) {\n                var html = $(\"html\");\n                var oldScrollTop = html.scrollTop(); // necessary for Firefox.\n                html.css(\"overflow-y\", \"\").scrollTop(oldScrollTop);\n\n                if(theDialog.oldInlineMarginRight) {\n                    $(\"body\").css(\"margin-right\", theDialog.oldBodyMarginRight);\n                } else {\n                    $(\"body\").css(\"margin-right\", '');\n                }\n            }\n        }", "label": 3}
{"code": "def load_yaml_file(file_path: str):\n    \"\"\"Load a YAML file from path\"\"\"\n    with codecs.open(file_path, 'r') as f:\n        return yaml.safe_load(f)", "label": 1}
{"code": "def get_oa_policy(doi):\n    \"\"\"\n    Get OA policy for a given DOI.\n\n    .. note::\n\n        Uses beta.dissem.in API.\n\n    :param doi: A canonical DOI.\n    :returns: The OpenAccess policy for the associated publications, or \\\n            ``None`` if unknown.\n\n    >>> tmp = get_oa_policy('10.1209/0295-5075/111/40005'); (tmp[\"published\"], tmp[\"preprint\"], tmp[\"postprint\"], tmp[\"romeo_id\"])\n    ('can', 'can', 'can', '1896')\n\n    >>> get_oa_policy('10.1215/9780822387268') is None\n    True\n    \"\"\"\n    try:\n        request = requests.get(\"%s%s\" % (DISSEMIN_API, doi))\n        request.raise_for_status()\n        result = request.json()\n        assert result[\"status\"] == \"ok\"\n        return ([i\n                 for i in result[\"paper\"][\"publications\"]\n                 if i[\"doi\"] == doi][0])[\"policy\"]\n    except (AssertionError, ValueError,\n            KeyError, RequestException, IndexError):\n        return None", "label": 1}
{"code": "public function autoload( $class ) {\n\n\t\t// Iterate over namespaces to find a match.\n\t\tforeach ( $this->namespaces as $namespace ) {\n\n\t\t\t// Move on if the object does not belong to the current namespace.\n\t\t\tif ( 0 !== strpos( $class, $namespace['root'] ) ) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t// Remove namespace root level to correspond with root filesystem, and\n\t\t\t// replace the namespace separator \"\\\" by the system-dependent directory separator.\n\t\t\t$filename = str_replace(\n\t\t\t\tarray( $namespace['root'], '\\\\' ),\n\t\t\t\tarray( '', DIRECTORY_SEPARATOR ),\n\t\t\t\t$class\n\t\t\t);\n\n\t\t\t// Remove a leading backslash from the class name.\n\t\t\t$filename = $this->remove_leading_backslash( $filename );\n\n\t\t\t// Change to lower case if requested.\n\t\t\tif ( $namespace['lowercase'] ) {\n\t\t\t\t$filename = strtolower( $filename );\n\t\t\t}\n\n\t\t\t// Change underscores into hyphens if requested.\n\t\t\tif ( $namespace['underscores'] ) {\n\t\t\t\t$filename = str_replace( '_', '-', $filename );\n\t\t\t}\n\n\t\t\t// Add base_dir, prefix and suffix.\n\t\t\t$filepath = $namespace['base_dir']\n\t\t\t\t. $namespace['prefix']\n\t\t\t\t. $filename\n\t\t\t\t. $namespace['suffix'];\n\n\t\t\t// Throw an exception if the file does not exist or is not readable.\n\t\t\tif ( is_readable( $filepath ) ) {\n\t\t\t\trequire_once $filepath;\n\t\t\t}\n\t\t}\n\t}", "label": 2}
{"code": "def create_default_access_for(permission_template:, workflow:)\n        permission_template.access_grants.create(agent_type: 'group', agent_id: ::Ability.registered_group_name, access: Hyrax::PermissionTemplateAccess::DEPOSIT)\n        deposit = Sipity::Role[Hyrax::RoleRegistry::DEPOSITING]\n        workflow.update_responsibilities(role: deposit, agents: Hyrax::Group.new('registered'))\n      end", "label": 4}
{"code": "function checkModule(pth, cb) {\n  checkStrider(pth, function(err, config){\n    if (err) return cb(err);\n    if (config){\n      config.dir = pth;\n      return cb(null, config);\n    }\n    checkPackageJson(pth, function(err, config){\n      if (err) return cb(err);\n      if (config){\n        config.dir = pth;\n        return cb(null, config);\n      }\n      return cb(null, false);\n    });\n  });\n}", "label": 3}
{"code": "function(data, hashId, key) {\n        if (hashId == -1) {\n            // record key\n            data.inputChar = key;\n            data.lastEvent = \"input\";\n        } else if (data.inputChar && data.$lastHash == hashId && data.$lastKey == key) {\n            // check for repeated keypress \n            if (data.lastEvent == \"input\") {\n                data.lastEvent = \"input1\";\n            } else if (data.lastEvent == \"input1\") {\n                // simulate textinput\n                return true;\n            }\n        } else {\n            // reset\n            data.$lastHash = hashId;\n            data.$lastKey = key;\n            data.lastEvent = \"keypress\";\n        }\n    }", "label": 3}
{"code": "private function openPath($path)\n    {\n        $url = (array) parse_url($path) + [\n            'scheme' => '',\n            'path' => '',\n            'host' => ''\n        ];\n        $this->protocol = $url['scheme'];\n        $this->file = ltrim($url['path'], '/');\n        $client = self::getClient($this->protocol);\n        $this->bucket = $client->bucket($url['host']);\n        return $client;\n    }", "label": 2}
{"code": "def instantiate_definition(definition, loader)\n    case definition\n    when Model::PlanDefinition\n      instantiate_PlanDefinition(definition, loader)\n    when Model::FunctionDefinition\n      instantiate_FunctionDefinition(definition, loader)\n    when Model::TypeAlias\n      instantiate_TypeAlias(definition, loader)\n    when Model::TypeMapping\n      instantiate_TypeMapping(definition, loader)\n    else\n      raise Puppet::ParseError, \"Internal Error: Unknown type of definition - got '#{definition.class}'\"\n    end\n  end", "label": 4}
{"code": "def each_message(topic:, start_from_beginning: true, max_wait_time: 5, min_bytes: 1, max_bytes: 1048576, &block)\n      default_offset ||= start_from_beginning ? :earliest : :latest\n      offsets = Hash.new { default_offset }\n\n      loop do\n        operation = FetchOperation.new(\n          cluster: @cluster,\n          logger: @logger,\n          min_bytes: min_bytes,\n          max_wait_time: max_wait_time,\n        )\n\n        @cluster.partitions_for(topic).map(&:partition_id).each do |partition|\n          partition_offset = offsets[partition]\n          operation.fetch_from_partition(topic, partition, offset: partition_offset, max_bytes: max_bytes)\n        end\n\n        batches = operation.execute\n\n        batches.each do |batch|\n          batch.messages.each(&block)\n          offsets[batch.partition] = batch.last_offset + 1 unless batch.unknown_last_offset?\n        end\n      end\n    end", "label": 4}
{"code": "async def remove(self) -> None:\n        \"\"\"\n        Remove serialized wallet if it exists.\n        \"\"\"\n\n        LOGGER.debug('Wallet.remove >>>')\n\n        try:\n            LOGGER.info('Removing wallet: %s', self.name)\n            await wallet.delete_wallet(json.dumps(self.cfg), json.dumps(self.access_creds))\n        except IndyError as x_indy:\n            LOGGER.info('Abstaining from wallet removal; indy-sdk error code %s', x_indy.error_code)\n\n        LOGGER.debug('Wallet.remove <<<')", "label": 1}
{"code": "protected Connection newConnectionFromDriverManager(JdbcConnectionDescriptor jcd)\r\n            throws LookupException\r\n    {\r\n        Connection retval = null;\r\n        // use JDBC DriverManager\r\n        final String driver = jcd.getDriver();\r\n        final String url = getDbURL(jcd);\r\n        try\r\n        {\r\n            // loads the driver - NB call to newInstance() added to force initialisation\r\n            ClassHelper.getClass(driver, true);\r\n            final String user = jcd.getUserName();\r\n            final String password = jcd.getPassWord();\r\n            final Properties properties = getJdbcProperties(jcd, user, password);\r\n            if (properties.isEmpty())\r\n            {\r\n                if (user == null)\r\n                {\r\n                    retval = DriverManager.getConnection(url);\r\n                }\r\n                else\r\n                {\r\n                    retval = DriverManager.getConnection(url, user, password);\r\n                }\r\n            }\r\n            else\r\n            {\r\n                retval = DriverManager.getConnection(url, properties);\r\n            }\r\n        }\r\n        catch (SQLException sqlEx)\r\n        {\r\n            log.error(\"Error getting Connection from DriverManager with url (\" + url + \") and driver (\" + driver + \")\", sqlEx);\r\n            throw new LookupException(\"Error getting Connection from DriverManager with url (\" + url + \") and driver (\" + driver + \")\", sqlEx);\r\n        }\r\n        catch (ClassNotFoundException cnfEx)\r\n        {\r\n            log.error(cnfEx);\r\n            throw new LookupException(\"A class was not found\", cnfEx);\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            log.error(\"Instantiation of jdbc driver failed\", e);\r\n            throw new LookupException(\"Instantiation of jdbc driver failed\", e);\r\n        }\r\n        // initialize connection\r\n        initializeJdbcConnection(retval, jcd);\r\n        if(log.isDebugEnabled()) log.debug(\"Create new connection using DriverManager: \"+retval);\r\n        return retval;\r\n    }", "label": 0}
{"code": "public PlanarImage toDirectColorModel(RenderedImage img) {\n\t\tBufferedImage dest = new BufferedImage(img.getWidth(), img.getHeight(), BufferedImage.TYPE_4BYTE_ABGR);\n\t\tBufferedImage source = new BufferedImage(img.getColorModel(), (WritableRaster) img.getData(), img\n\t\t\t\t.getColorModel().isAlphaPremultiplied(), null);\n\t\tColorConvertOp op = new ColorConvertOp(null);\n\t\top.filter(source, dest);\n\t\treturn PlanarImage.wrapRenderedImage(dest);\n\t}", "label": 0}
{"code": "function serializeCurrentNode(currentNode) {\n  var children = currentNode.children;\n  if (!children) {\n    return null;\n  }\n  var len = children.length;\n  var arr = new Array(len);\n  var i = -1;\n  while (++i < len) {\n    arr[i] = serializeCurrentNode(children[i]);\n  }\n  if (currentNode.count) {\n    return [arr, currentNode.count];\n  } else {\n    return [arr];\n  }\n}", "label": 3}
{"code": "function addInject(obj, inject) {\n    if(!exists(inject)) {\n      return;\n    }\n\n    var injectMe;\n\n    if (inject === '$injector') {\n      injectMe = new di.Inject(di.Injector);\n    } else if (isObject(inject)) {\n      if(isString(inject.inject)){\n        injectMe = new di.Inject(inject.inject);\n      } else if(isString(inject.promise)) {\n        injectMe = new di.InjectPromise(inject.promise);\n      } else if(isString(inject.lazy)) {\n        injectMe = new di.InjectLazy(inject.lazy);\n      }\n    } else {\n      injectMe = new di.Inject(inject);\n    }\n\n    di.annotate(obj, injectMe);\n  }", "label": 3}
{"code": "def remove_child(child)\n      name = child.association_name\n      if child.embedded_one?\n        remove_ivar(name)\n      else\n        relation = send(name)\n        relation.send(:delete_one, child)\n      end\n    end", "label": 4}
{"code": "func CloseOnExec(fd int, set bool) error {\n\tflag := uintptr(0)\n\tif set {\n\t\tflag = syscall.FD_CLOEXEC\n\t}\n\t_, _, err := syscall.RawSyscall(syscall.SYS_FCNTL, uintptr(fd), syscall.F_SETFD, flag)\n\tif err != 0 {\n\t\treturn syscall.Errno(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static base_response unset(nitro_service client, tmsessionparameter resource, String[] args) throws Exception{\n\t\ttmsessionparameter unsetresource = new tmsessionparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def run\n      log.info \"synapse: starting...\"\n      statsd_increment('synapse.start')\n\n      # start all the watchers\n      statsd_time('synapse.watchers.start.time') do\n        @service_watchers.map do |watcher|\n          begin\n            watcher.start\n            statsd_increment(\"synapse.watcher.start\", ['start_result:success', \"watcher_name:#{watcher.name}\"])\n          rescue Exception => e\n            statsd_increment(\"synapse.watcher.start\", ['start_result:fail', \"watcher_name:#{watcher.name}\", \"exception_name:#{e.class.name}\", \"exception_message:#{e.message}\"])\n            raise e\n          end\n        end\n      end\n\n      statsd_time('synapse.main_loop.elapsed_time') do\n        # main loop\n        loops = 0\n        loop do\n          @service_watchers.each do |w|\n            alive = w.ping?\n            statsd_increment('synapse.watcher.ping.count', [\"watcher_name:#{w.name}\", \"ping_result:#{alive ? \"success\" : \"failure\"}\"])\n            raise \"synapse: service watcher #{w.name} failed ping!\" unless alive\n          end\n\n          if @config_updated\n            @config_updated = false\n            statsd_increment('synapse.config.update')\n            @config_generators.each do |config_generator|\n              log.info \"synapse: configuring #{config_generator.name}\"\n              begin\n                config_generator.update_config(@service_watchers)\n              rescue StandardError => e\n                statsd_increment(\"synapse.config.update_failed\", [\"config_name:#{config_generator.name}\"])\n                log.error \"synapse: update config failed for config #{config_generator.name} with exception #{e}\"\n                raise e\n              end\n            end\n          end\n\n          sleep 1\n          @config_generators.each do |config_generator|\n            config_generator.tick(@service_watchers)\n          end\n\n          loops += 1\n          log.debug \"synapse: still running at #{Time.now}\" if (loops % 60) == 0\n        end\n      end\n\n    rescue StandardError => e\n      statsd_increment('synapse.stop', ['stop_avenue:abort', 'stop_location:main_loop', \"exception_name:#{e.class.name}\", \"exception_message:#{e.message}\"])\n      log.error \"synapse: encountered unexpected exception #{e.inspect} in main thread\"\n      raise e\n    ensure\n      log.warn \"synapse: exiting; sending stop signal to all watchers\"\n\n      # stop all the watchers\n      @service_watchers.map do |w|\n        begin\n          w.stop\n          statsd_increment(\"synapse.watcher.stop\", ['stop_avenue:clean', 'stop_location:main_loop', \"watcher_name:#{w.name}\"])\n        rescue Exception => e\n          statsd_increment(\"synapse.watcher.stop\", ['stop_avenue:exception', 'stop_location:main_loop', \"watcher_name:#{w.name}\", \"exception_name:#{e.class.name}\", \"exception_message:#{e.message}\"])\n          raise e\n        end\n      end\n      statsd_increment('synapse.stop', ['stop_avenue:clean', 'stop_location:main_loop'])\n    end", "label": 4}
{"code": "public Module getModule(final String name, final String version) throws GrapesCommunicationException {\n        final Client client = getClient();\n        final WebResource resource = client.resource(serverURL).path(RequestUtils.getModulePath(name, version));\n        final ClientResponse response = resource.accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);\n\n        client.destroy();\n        if(ClientResponse.Status.OK.getStatusCode() != response.getStatus()){\n            final String message = String.format(FAILED_TO_GET_MODULE, \"get module details\", name, version);\n            if(LOG.isErrorEnabled()) {\n                LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, message, response.getStatus()));\n            }\n            throw new GrapesCommunicationException(message, response.getStatus());\n        }\n\n        return response.getEntity(Module.class);\n    }", "label": 0}
{"code": "function _gpfBuildPropertyFunc (template, member) {\n    var src,\n        params,\n        start,\n        end;\n    // Replace all occurrences of _MEMBER_ with the right name\n    src = template.toString().split(\"_MEMBER_\").join(member);\n    // Extract parameters\n    start = src.indexOf(\"(\") + 1;\n    end = src.indexOf(\")\", start) - 1;\n    params = src.substr(start, end - start + 1).split(\",\").map(function (name) {\n        return name.trim();\n    });\n    // Extract body\n    start = src.indexOf(\"{\") + 1;\n    end = src.lastIndexOf(\"}\") - 1;\n    src = src.substr(start, end - start + 1);\n    return _gpfFunc(params, src);\n}", "label": 3}
{"code": "function getBooleanFromRegisterQuery (str, regEx, offset) {\n  let regExArr = str.match(regEx);\n  if (regExArr) {\n    const num = parseInt(str.charAt(regExArr.index + offset));\n    if (!Number.isNaN(num)) {\n      return Boolean(num);\n    } else {\n      throw new Error(k.OBCIErrorInvalidData);\n    }\n  } else {\n    throw new Error(k.OBCIErrorMissingRegisterSetting);\n  }\n}", "label": 3}
{"code": "def indexes(table, stream)\n        if (indexes = @connection.indexes(table)).any?\n          add_index_statements = indexes.map do |index|\n            table_name = remove_prefix_and_suffix(index.table).inspect\n            \"  add_index #{([table_name] + index_parts(index)).join(', ')}\"\n          end\n\n          stream.puts add_index_statements.sort.join(\"\\n\")\n          stream.puts\n        end\n      end", "label": 4}
{"code": "def new_tile(self, num=1):\n        \"\"\"\n        Create a new tile in a randomly selected empty \n        square.  The tile should be 2 90% of the time and\n        4 10% of the time.\n        \"\"\"\n        for _ in range(num):                \n            if random.random() > .5: \n                new_tile = self.pieces[0]\n            else:\n                new_tile = self.pieces[1]\n            \n            # check for game over\n            blanks = self.count_blank_positions()\n            \n            if blanks == 0:\n                print (\"GAME OVER\")\n            else:\n                res = self.find_random_blank_cell()\n                row = res[0]\n                col = res[1]\n                self.set_tile(row, col, new_tile)", "label": 1}
{"code": "def push_pq(self, tokens):\n        \"\"\" Creates and Load object, populates it with data, finds its Bus and\n        adds it.\n        \"\"\"\n        logger.debug(\"Pushing PQ data: %s\" % tokens)\n\n        bus = self.case.buses[tokens[\"bus_no\"] - 1]\n        bus.p_demand = tokens[\"p\"]\n        bus.q_demand = tokens[\"q\"]", "label": 1}
{"code": "def to_sql\n      @to_sql ||= begin\n        if eager_loading?\n          apply_join_dependency do |relation, join_dependency|\n            relation = join_dependency.apply_column_aliases(relation)\n            relation.to_sql\n          end\n        else\n          conn = klass.connection\n          conn.unprepared_statement { conn.to_sql(arel) }\n        end\n      end\n    end", "label": 4}
{"code": "public function setSuggestions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_Suggestions::class);\n        $this->writeOneof(9, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func New(c *Config) (*NetworkDB, error) {\n\t// The garbage collection logic for entries leverage the presence of the network.\n\t// For this reason the expiration time of the network is put slightly higher than the entry expiration so that\n\t// there is at least 5 extra cycle to make sure that all the entries are properly deleted before deleting the network.\n\tc.reapNetworkInterval = c.reapEntryInterval + 5*reapPeriod\n\n\tnDB := &NetworkDB{\n\t\tconfig:         c,\n\t\tindexes:        make(map[int]*radix.Tree),\n\t\tnetworks:       make(map[string]map[string]*network),\n\t\tnodes:          make(map[string]*node),\n\t\tfailedNodes:    make(map[string]*node),\n\t\tleftNodes:      make(map[string]*node),\n\t\tnetworkNodes:   make(map[string][]string),\n\t\tbulkSyncAckTbl: make(map[string]chan struct{}),\n\t\tbroadcaster:    events.NewBroadcaster(),\n\t}\n\n\tnDB.indexes[byTable] = radix.New()\n\tnDB.indexes[byNetwork] = radix.New()\n\n\tlogrus.Infof(\"New memberlist node - Node:%v will use memberlist nodeID:%v with config:%+v\", c.Hostname, c.NodeID, c)\n\tif err := nDB.clusterInit(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn nDB, nil\n}", "label": 5}
{"code": "public static base_response update(nitro_service client, lbparameter resource) throws Exception {\n\t\tlbparameter updateresource = new lbparameter();\n\t\tupdateresource.httponlycookieflag = resource.httponlycookieflag;\n\t\tupdateresource.consolidatedlconn = resource.consolidatedlconn;\n\t\tupdateresource.useportforhashlb = resource.useportforhashlb;\n\t\tupdateresource.preferdirectroute = resource.preferdirectroute;\n\t\tupdateresource.startuprrfactor = resource.startuprrfactor;\n\t\tupdateresource.monitorskipmaxclient = resource.monitorskipmaxclient;\n\t\tupdateresource.monitorconnectionclose = resource.monitorconnectionclose;\n\t\tupdateresource.vserverspecificmac = resource.vserverspecificmac;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def poll(self):\n        \"\"\"\n        Poll\n        \n        Check for a non-response string generated by LCDd and return any string read.\n        LCDd generates strings for key presses, menu events & screen visibility changes.\n        \"\"\"\n        if select.select([self.tn], [], [], 0) == ([self.tn], [], []):\n            response = urllib.unquote(self.tn.read_until(b\"\\n\").decode())\n            if self.debug: print \"Telnet Poll: %s\" % (response[:-1])\n            # TODO Keep track of which screen is displayed\n            return response\n        else:\n            return None", "label": 1}
{"code": "def next_offset_for(topic, partition)\n      offset = @processed_offsets.fetch(topic, {}).fetch(partition) {\n        committed_offset_for(topic, partition)\n      }\n\n      # A negative offset means that no offset has been committed, so we need to\n      # resolve the default offset for the topic.\n      if offset < 0\n        resolve_offset(topic, partition)\n      else\n        # The next offset is the last offset.\n        offset\n      end\n    end", "label": 4}
{"code": "function isModel(object) {\n    if (!object || typeof object !== 'object') {\n        return false;\n    }\n    else if ('isModel' in object) {\n        diag.debug.assert(function () { return object.isModel === Model.prototype.isPrototypeOf(object); });\n        return object.isModel;\n    }\n    else {\n        return Model.prototype.isPrototypeOf(object);\n    }\n}", "label": 3}
{"code": "func (f *PropertyFilter) apply(ctx *Context, change types.ObjectUpdate) types.ObjectUpdate {\n\tparents := make(map[string]bool)\n\tset := change.ChangeSet\n\tchange.ChangeSet = nil\n\n\tfor i, p := range set {\n\t\tif f.matches(ctx, change.Obj, &p) {\n\t\t\tif p.Name != set[i].Name {\n\t\t\t\t// update matches a parent field from the spec.\n\t\t\t\tif parents[p.Name] {\n\t\t\t\t\tcontinue // only return 1 instance of the parent\n\t\t\t\t}\n\t\t\t\tparents[p.Name] = true\n\t\t\t}\n\t\t\tchange.ChangeSet = append(change.ChangeSet, p)\n\t\t}\n\t}\n\n\treturn change\n}", "label": 5}
{"code": "def allow(self, ctx, acls):\n        '''Allow access to any ACL members that was equal to the user name.\n\n        That is, some user u is considered a member of group u and no other.\n        '''\n        for acl in acls:\n            if self._identity == acl:\n                return True\n        return False", "label": 1}
{"code": "public static nspbr[] get(nitro_service service) throws Exception{\n\t\tnspbr obj = new nspbr();\n\t\tnspbr[] response = (nspbr[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static rnatip_stats[] get(nitro_service service, options option) throws Exception{\n\t\trnatip_stats obj = new rnatip_stats();\n\t\trnatip_stats[] response = (rnatip_stats[])obj.stat_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static dnssrvrec get(nitro_service service, dnssrvrec obj) throws Exception{\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(obj));\n\t\tdnssrvrec response = (dnssrvrec) obj.get_resource(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def create_column_index(annotations):\n    \"\"\"\n    Create a pd.MultiIndex using the column names and any categorical rows.\n    Note that also non-main columns will be assigned a default category ''.\n    \"\"\"\n    _column_index = OrderedDict({'Column Name' : annotations['Column Name']})\n    categorical_rows = annotation_rows('C:', annotations)\n    _column_index.update(categorical_rows)\n    numerical_rows = {name: [float(x) if x != '' else float('NaN') for x in values]\n            for name, values in annotation_rows('N:', annotations).items()} # to floats\n    _column_index.update(numerical_rows)\n    column_index = pd.MultiIndex.from_tuples(list(zip(*_column_index.values())), names=list(_column_index.keys()))\n    if len(column_index.names) == 1:\n        # flatten single-level index\n        name = column_index.names[0]\n        column_index = column_index.get_level_values(name)\n    return column_index", "label": 1}
{"code": "def collection_radio_buttons(method, collection, value_method, label_method, options = {}, html_options = {})\n      fieldset_wrapper options[:legend_title] do\n        super(method, collection, value_method, label_method, options, html_options) do |builder|\n          if block_given?\n            yield builder\n          else\n            builder.label { builder.radio_button + builder.text }\n          end\n        end\n      end\n    end", "label": 4}
{"code": "func NewLimiter(config LimiterConfig) (*Limiter, error) {\n\tvar err error\n\tlimiter := Limiter{}\n\n\tlimiter.ConnectionsLimiter, err = NewConnectionsLimiter(config)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tlimiter.rateLimiter, err = NewRateLimiter(config)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &limiter, nil\n}", "label": 5}
{"code": "public static String createFirstLowCaseName(String scenarioDescription) {\n        String[] words = scenarioDescription.trim().split(\" \");\n        String name = \"\";\n        for (int i = 0; i < words.length; i++) {\n            name += changeFirstLetterToCapital(words[i]);\n        }\n        return changeFirstLetterToLowerCase(name);\n    }", "label": 0}
{"code": "def cleanup(self):\n        \"\"\"Run cleanup script of pipeline when hook is configured.\"\"\"\n        if self.data.hooks and len(self.data.hooks.cleanup) > 0:\n            env = self.data.env_list[0].copy()\n            env.update({'PIPELINE_RESULT': 'SUCCESS', 'PIPELINE_SHELL_EXIT_CODE': '0'})\n            config = ShellConfig(script=self.data.hooks.cleanup, model=self.model,\n                                 env=env, dry_run=self.options.dry_run,\n                                 debug=self.options.debug, strict=self.options.strict,\n                                 temporary_scripts_path=self.options.temporary_scripts_path)\n            cleanup_shell = Bash(config)\n            for line in cleanup_shell.process():\n                yield line", "label": 1}
{"code": "private function getColumnName($columns, $index)\n    {\n        return (isset($columns[$index]['name']) && $columns[$index]['name'])\n            ? $columns[$index]['name']\n            : $index;\n    }", "label": 2}
{"code": "public static base_responses update(nitro_service client, autoscaleprofile resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tautoscaleprofile updateresources[] = new autoscaleprofile[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new autoscaleprofile();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].url = resources[i].url;\n\t\t\t\tupdateresources[i].apikey = resources[i].apikey;\n\t\t\t\tupdateresources[i].sharedsecret = resources[i].sharedsecret;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function() {\n\t\t\t\tself.value += stepValue;\n\t\t\t\tself.setValue(self.value);\n\t\t\t\tself.triggerScrollEvent(self.value);\n\n\t\t\t\tif (isFinishedScrolling()) {\n\t\t\t\t\tclearInterval(self.pageScrollTimer);\n\t\t\t\t}\n\t\t\t}", "label": 3}
{"code": "def uncompress_body(response)\n      case response['content-encoding']\n      when 'gzip'\n        # ZLib::GzipReader has an associated encoding, by default Encoding.default_external\n        return Zlib::GzipReader.new(StringIO.new(response.body), :encoding => Encoding::BINARY).read\n      when 'deflate'\n        return Zlib::Inflate.new.inflate(response.body)\n      when nil, 'identity'\n        return response.body\n      else\n        raise Net::HTTPError.new(_(\"Unknown content encoding - %{encoding}\") % { encoding: response['content-encoding'] }, response)\n      end\n    end", "label": 4}
{"code": "public SelectStatement getPreparedSelectByPkStatement(ClassDescriptor cld)\r\n    {\r\n        SelectStatement sql;\r\n        SqlForClass sfc = getSqlForClass(cld);\r\n        sql = sfc.getSelectByPKSql();\r\n        if(sql == null)\r\n        {\r\n            sql = new SqlSelectByPkStatement(m_platform, cld, logger);\r\n\r\n            // set the sql string\r\n            sfc.setSelectByPKSql(sql);\r\n\r\n            if(logger.isDebugEnabled())\r\n            {\r\n                logger.debug(\"SQL:\" + sql.getStatement());\r\n            }\r\n        }\r\n        return sql;\r\n    }", "label": 0}
{"code": "function wrapElements(els, wrapper) {\n  var wrapperEl = document.createElement(wrapper);\n\n  // make sure elements are in an array\n  if (els instanceof HTMLElement) {\n    els = [els];\n  } else {\n    els = Array.prototype.slice.call(els);\n  }\n\n  _each(els, function (el) {\n    // put it into the wrapper, remove it from its parent\n    el.parentNode.removeChild(el);\n    wrapperEl.appendChild(el);\n  });\n\n  // return the wrapped elements\n  return wrapperEl;\n}", "label": 3}
{"code": "def yaml_file_to_dict(script_name, path=None):\n    \"\"\"Read yaml file and return the dict.\n\n    It assumes the module file exists with the defaults.\n    If the CONDOOR_{SCRIPT_NAME} env is set then the user file from the env is loaded and merged with the default\n\n    There can be user file located in ~/.condoor directory with the {script_name}.yaml filename. If exists\n    it is merget with default config.\n    \"\"\"\n    def load_yaml(file_path):\n        \"\"\"Load YAML file from full file path and return dict.\"\"\"\n        with open(file_path, 'r') as yamlfile:\n            try:\n                dictionary = yaml.load(yamlfile)\n            except yaml.YAMLError:\n                return {}\n        return dictionary\n\n    def merge(user, default):\n        \"\"\"Merge two dicts.\"\"\"\n        if isinstance(user, dict) and isinstance(default, dict):\n            for k, v in default.iteritems():\n                if k not in user:\n                    user[k] = v\n                else:\n                    user[k] = merge(user[k], v)\n        return user\n\n    if path is None:\n        path = os.path.abspath('.')\n\n    config_file_path = os.path.join(path, script_name + '.yaml')\n    if not os.path.exists(config_file_path):\n        raise RuntimeError('Config file does not exist: {}'.format(config_file_path))\n\n    default_dict = load_yaml(config_file_path)\n\n    user_config_file_path = os.path.join(os.path.expanduser('~'), '.condoor', os.path.basename(script_name) + '.yaml')\n    user_config_file_path = os.getenv('CONDOOR_' + os.path.basename(script_name).upper(), user_config_file_path)\n    if os.path.exists(user_config_file_path):\n        user_dict = load_yaml(user_config_file_path)\n        if user_dict:\n            default_dict = merge(user_dict, default_dict)\n    return default_dict", "label": 1}
{"code": "def to_xml_string(str = '')\n      return if empty?\n      str << '<definedNames>'\n      each { |defined_name| defined_name.to_xml_string(str) }\n      str << '</definedNames>'\n    end", "label": 4}
{"code": "func wrapStructLevelFunc(fn StructLevelFunc) StructLevelFuncCtx {\n\treturn func(ctx context.Context, sl StructLevel) {\n\t\tfn(sl)\n\t}\n}", "label": 5}
{"code": "public double remove(E key) {\r\n    totalCount -= getCount(key); // subtract removed count from total (may be 0)\r\n    MutableInteger val = map.remove(key);\r\n    if (val == null) {\r\n      return Double.NaN;\r\n    } else {\r\n      return val.doubleValue();\r\n    }\r\n  }", "label": 0}
{"code": "public void removeCorporateGroupId(final String organizationId, final String corporateGroupId) {\n        final DbOrganization dbOrganization = getOrganization(organizationId);\n\n        if(dbOrganization.getCorporateGroupIdPrefixes().contains(corporateGroupId)){\n            dbOrganization.getCorporateGroupIdPrefixes().remove(corporateGroupId);\n            repositoryHandler.store(dbOrganization);\n        }\n\n        repositoryHandler.removeModulesOrganization(corporateGroupId, dbOrganization);\n    }", "label": 0}
{"code": "function(str, index) {\n    // replace {{ xxx }}\n    var obj = this\n    str = str.replace(interpolateReg, function(match, interpolate) {\n      try {\n        /*jslint evil: true */\n        var funcNames = ['','index'].concat(fakerFuncNames).concat(['return ' + interpolate + ';']),\n        func = new (Function.prototype.bind.apply(Function, funcNames)),\n        funcs = [function(){return index}].concat(fakerFuncs);\n\n        return func.apply(obj, funcs);\n        \n      } catch(e)  {\n        return e.message;\n      }\n    });\n\n    // if result is true or false, parse it to boolean\n    if(/^(true|false)$/.test(str)) {\n      str = str === 'true';\n    }\n\n    // if result is digit, parse it to float\n    if(/^[-+]?\\d*\\.?\\d+$/.test(str)) {\n      str = parseFloat(str);\n    }\n\n    return str;\n  }", "label": 3}
{"code": "def starts_with_reserved_character?(stringish)\n      string = stringish.respond_to?(:children) ? stringish.children.first : stringish\n      string =~ %r{\\A\\s*[/#-=%~]}\n    end", "label": 4}
{"code": "function obMerge(prefix, ob1, ob2 /*, ...*/)\n    {\n        for (var i=2; i<arguments.length; ++i)\n        {\n            for (var nm in arguments[i]) \n            {\n                if (arguments[i].hasOwnProperty(nm) || typeof arguments[i][nm] == 'function')\n                {\n                    if (typeof(arguments[i][nm]) == 'object' && arguments[i][nm] != null)\n                    {\n                        ob1[prefix+nm] = (arguments[i][nm] instanceof Array) ? new Array : new Object;\n                        obMerge('', ob1[prefix+nm], arguments[i][nm]);\n                    }\n                    else\n                    {\n                        ob1[prefix+nm] = arguments[i][nm]; \n                    }\n                }\n            }\n        }\n        return ob1;\n    }", "label": 3}
{"code": "public function setRegion($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Monitoring\\V3\\UptimeCheckRegion::class);\n        $this->region = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "static Object getLCState(StateManagerInternal sm)\r\n\t{\r\n\t\t// unfortunately the LifeCycleState classes are package private.\r\n\t\t// so we have to do some dirty reflection hack to access them\r\n\t\ttry\r\n\t\t{\r\n\t\t\tField myLC = sm.getClass().getDeclaredField(\"myLC\");\r\n\t\t\tmyLC.setAccessible(true);\r\n\t\t\treturn myLC.get(sm);\r\n\t\t}\r\n\t\tcatch (NoSuchFieldException e)\r\n\t\t{\r\n\t\t\treturn e;\r\n\t\t}\r\n\t\tcatch (IllegalAccessException e)\r\n\t\t{\r\n\t\t\treturn e;\r\n\t\t}\t\r\n\t}", "label": 0}
{"code": "def last_offsets_for(*topics)\n      @cluster.add_target_topics(topics)\n      topics.map {|topic|\n        partition_ids = @cluster.partitions_for(topic).collect(&:partition_id)\n        partition_offsets = @cluster.resolve_offsets(topic, partition_ids, :latest)\n        [topic, partition_offsets.collect { |k, v| [k, v - 1] }.to_h]\n      }.to_h\n    end", "label": 4}
{"code": "func (*TeleportOIDCConnectorMarshaler) UnmarshalOIDCConnector(bytes []byte, opts ...MarshalOption) (OIDCConnector, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar h ResourceHeader\n\terr = utils.FastUnmarshal(bytes, &h)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch h.Version {\n\tcase \"\":\n\t\tvar c OIDCConnectorV1\n\t\terr := json.Unmarshal(bytes, &c)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn c.V2(), nil\n\tcase V2:\n\t\tvar c OIDCConnectorV2\n\t\tif cfg.SkipValidation {\n\t\t\tif err := utils.FastUnmarshal(bytes, &c); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t} else {\n\t\t\tif err := utils.UnmarshalWithSchema(GetOIDCConnectorSchema(), &c, bytes); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t}\n\n\t\tif err := c.CheckAndSetDefaults(); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tif cfg.ID != 0 {\n\t\t\tc.SetResourceID(cfg.ID)\n\t\t}\n\t\tif !cfg.Expires.IsZero() {\n\t\t\tc.SetExpiry(cfg.Expires)\n\t\t}\n\t\treturn &c, nil\n\t}\n\n\treturn nil, trace.BadParameter(\"OIDC connector resource version %v is not supported\", h.Version)\n}", "label": 5}
{"code": "def execute_on_vm(vm, options)\n      check_runable_on(vm)\n\n      options     = options.clone\n      _method     = options.delete(:_method)\n      _rebootable = options.delete(:_rebootable)\n\n      options = vm.config.vbguest.to_hash.merge(options)\n      machine = VagrantVbguest::Machine.new(vm, options)\n      status  = machine.state\n      vm.env.ui.send((:ok == status ? :success : :warn), I18n.t(\"vagrant_vbguest.status.#{status}\", machine.info))\n\n      if _method != :status\n        machine.send(_method)\n      end\n\n      reboot!(vm, options) if _rebootable && machine.reboot?\n    rescue VagrantVbguest::Installer::NoInstallerFoundError => e\n      vm.env.ui.error e.message\n    end", "label": 4}
{"code": "func (flag *HostConnectFlag) Spec(c *vim25.Client) types.HostConnectSpec {\n\tspec := flag.HostConnectSpec\n\n\tif spec.SslThumbprint == \"\" {\n\t\tspec.SslThumbprint = c.Thumbprint(spec.HostName)\n\n\t\tif spec.SslThumbprint == \"\" && flag.noverify {\n\t\t\tvar info object.HostCertificateInfo\n\t\t\tt := c.Transport.(*http.Transport)\n\t\t\t_ = info.FromURL(&url.URL{Host: spec.HostName}, t.TLSClientConfig)\n\t\t\tspec.SslThumbprint = info.ThumbprintSHA1\n\t\t}\n\t}\n\n\treturn spec\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, vpath resource) throws Exception {\n\t\tvpath addresource = new vpath();\n\t\taddresource.name = resource.name;\n\t\taddresource.destip = resource.destip;\n\t\taddresource.encapmode = resource.encapmode;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def to_stream(confirm_valid=false)\n      return false unless !confirm_valid || self.validate.empty?\n      Relationship.clear_cached_instances\n      zip = write_parts(Zip::OutputStream.new(StringIO.new, true))\n      stream = zip.close_buffer\n      stream.rewind\n      stream\n    end", "label": 4}
{"code": "function createFetchInstance(defaultConfig) {\n    const context = fetchFactory(defaultConfig);\n    const instance = bind(context.request, context);\n\n    // Copy properties from context\n    extend(instance, context, context);\n\n    return instance;\n}", "label": 3}
{"code": "public static base_response unset(nitro_service client, nsacl6 resource, String[] args) throws Exception{\n\t\tnsacl6 unsetresource = new nsacl6();\n\t\tunsetresource.acl6name = resource.acl6name;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def single_item_action_form_fields(form, document, action)\n        render 'hyrax/dashboard/collections/single_item_action_fields', form: form, document: document, action: action\n      end", "label": 4}
{"code": "func GC() {\n\tgpmLock.Lock()\n\tif len(garbagePathMap) == 0 {\n\t\t// No need for GC if map is empty\n\t\tgpmLock.Unlock()\n\t\treturn\n\t}\n\tgpmLock.Unlock()\n\n\t// if content exists in the garbage paths\n\t// we can trigger GC to run, providing a\n\t// channel to be notified on completion\n\twaitGC := make(chan struct{})\n\tgpmChan <- waitGC\n\t// wait for GC completion\n\t<-waitGC\n}", "label": 5}
{"code": "def _calc_frames(stats):\n    \"\"\"\n    Compute a DataFrame summary of a Stats object.\n    \"\"\"\n    timings = []\n    callers = []\n    for key, values in iteritems(stats.stats):\n        timings.append(\n            pd.Series(\n                key + values[:-1],\n                index=timing_colnames,\n            )\n        )\n        for caller_key, caller_values in iteritems(values[-1]):\n            callers.append(\n                pd.Series(\n                    key + caller_key + caller_values,\n                    index=caller_columns,\n                )\n            )\n\n    timings_df = pd.DataFrame(timings)\n    callers_df = pd.DataFrame(callers)\n    timings_df['filename:funcname'] = \\\n        (timings_df['filename'] + ':' + timings_df['funcname'])\n    timings_df = timings_df.groupby('filename:funcname').sum()\n    return timings_df, callers_df", "label": 1}
{"code": "def get_instance_variable_pins(namespace, scope = :instance)\n      result = []\n      result.concat store.get_instance_variables(namespace, scope)\n      sc = qualify(store.get_superclass(namespace), namespace)\n      until sc.nil?\n        result.concat store.get_instance_variables(sc, scope)\n        sc = qualify(store.get_superclass(sc), sc)\n      end\n      result\n    end", "label": 4}
{"code": "func PrecomputeKeys(count int) KeygenOption {\n\treturn func(k *Keygen) error {\n\t\tk.precomputeCount = count\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public function getFullNativeName(): string\n    {\n        if (!$this->nativeName) {\n            $this->nativeName = $this->getNames()['nativeName'];\n        }\n\n        return $this->nativeName;\n    }", "label": 2}
{"code": "def compose_telegram(body):\n    \"\"\" Compose a SCS message\n\n        body: list containing the body of the message.\n        returns: full telegram expressed (bytes instance)\n    \"\"\"\n\n    msg = [b\"A8\"] + body + [checksum_bytes(body)] + [b\"A3\"]\n    return str.encode(\"\".join([x.decode() for x in msg]))", "label": 1}
{"code": "def DEFAULT_RENAMER(L, Names=None):\n    \"\"\"\n    Renames overlapping column names of numpy ndarrays with structured dtypes\n\n    Rename the columns by using a simple convention:\n\n    *   If `L` is a list, it will append the number in the list to the key \n        associated with the array.\n\n    *   If `L` is a dictionary, the algorithm will append the string \n        representation of the key associated with an array to the overlapping \n        columns from that array.\n\n    Default renamer function used by :func:`tabular.spreadsheet.join`\n\n    **Parameters**\n\n            **L** :  list or dictionary\n\n                    Numpy recarrays with columns to be renamed.\n\n    **Returns**\n\n            **D** :  dictionary of dictionaries\n\n                    Dictionary mapping each input numpy recarray to a \n                    dictionary mapping each original column name to its new \n                    name following the convention above.\n\n    \"\"\"\n    if isinstance(L,dict):\n        Names = L.keys()\n        LL = L.values()\n    else:\n        if Names == None:\n            Names = range(len(L))\n        else:\n            assert len(Names) == len(L)\n        LL = L\n\n    commons = Commons([l.dtype.names for l in LL])\n\n    D = {}\n    for (i,l) in zip(Names, LL):\n        d = {}\n        for c in commons:\n            if c in l.dtype.names:\n                d[c] = c + '_' + str(i)\n        if d:\n            D[i] = d\n\n    return D", "label": 1}
{"code": "private function getExpired()\n    {\n        if (count($this->expired) < 1) {\n            return null;\n        }\n        $expired = key($this->expired);\n        $this->increment($this->expired);\n        return $expired;\n    }", "label": 2}
{"code": "public base_response login(String username, String password, Long timeout) throws Exception\n\t{\n\t\tthis.set_credential(username, password);\n\t\tthis.set_timeout(timeout);\n\t\treturn this.login();\n\t}", "label": 0}
{"code": "def guard(name, options = {})\n      @plugin_options = options.merge(watchers: [], callbacks: [])\n\n      yield if block_given?\n\n      @current_groups ||= []\n      groups = @current_groups && @current_groups.last || [:default]\n      groups.each do |group|\n        opts = @plugin_options.merge(group: group)\n        # TODO: let plugins be added *after* evaluation\n        Guard.state.session.plugins.add(name, opts)\n      end\n\n      @plugin_options = nil\n    end", "label": 4}
{"code": "func (t *Torrent) setInfoBytes(b []byte) error {\n\tif metainfo.HashBytes(b) != t.infoHash {\n\t\treturn errors.New(\"info bytes have wrong hash\")\n\t}\n\tvar info metainfo.Info\n\tif err := bencode.Unmarshal(b, &info); err != nil {\n\t\treturn fmt.Errorf(\"error unmarshalling info bytes: %s\", err)\n\t}\n\tif err := t.setInfo(&info); err != nil {\n\t\treturn err\n\t}\n\tt.metadataBytes = b\n\tt.metadataCompletedChunks = nil\n\tt.onSetInfo()\n\treturn nil\n}", "label": 5}
{"code": "function findType (node, typeInfo, nestedCall) {\n  typeInfo = typeInfo || { noNull: false, isArray: false, noNullArrayValues: false }\n  if (!node) {\n    return typeInfo\n  }\n\n  // Validate nested call, the parser will check first if the array can be null\n  // then it will check if the values inside can be null\n  if (!nestedCall && node.kind === 'NonNullType') {\n    typeInfo.noNull = true\n  }\n\n  // If it is an array, validate if the values inside can be null\n  if (nestedCall && typeInfo.isArray && node.kind === 'NonNullType') {\n    typeInfo.noNullArrayValues = true\n  }\n\n  if (node.kind === 'ListType') {\n    typeInfo.isArray = true\n  }\n\n  if (node.name) {\n    typeInfo.type = node.name.value\n  }\n\n  return findType(node.type, typeInfo, true)\n}", "label": 3}
{"code": "def defer_validation(&block)\n      raise LocalJumpError, \"No block given.\" unless block\n      @validation_deferred = true\n      block.call()\n      @validation_deferred = false\n      validate\n      return nil\n    end", "label": 4}
{"code": "func (a *CellView) SetCursorY(y int) {\n\ta.SetCursor(a.cursorX, y)\n}", "label": 5}
{"code": "public function update(Collection $updates)\n    {\n        foreach ($updates as $update) {\n            $entry = $this->table('telescope_entries')\n                            ->where('uuid', $update->uuid)\n                            ->where('type', $update->type)\n                            ->first();\n\n            if (! $entry) {\n                continue;\n            }\n\n            $content = json_encode(array_merge(\n                json_decode($entry->content, true) ?: [], $update->changes\n            ));\n\n            $this->table('telescope_entries')\n                            ->where('uuid', $update->uuid)\n                            ->where('type', $update->type)\n                            ->update(['content' => $content]);\n\n            $this->updateTags($update);\n        }\n    }", "label": 2}
{"code": "function addTo(name) {\n            var indexName = name,\n                match = name.match(/^([^\\(]*)\\s*\\(([^\\)]*)\\)\\s*/),\n                params = match && match[2];\n            name = match && match[1] || name;\n\n            if (!index[indexName]) {\n                if (params) {\n                    // there can be no function calls here because of the regex match\n                    /*jshint evil: true */\n                    params = eval('[' + params + ']');\n                }\n                var mixin = _mixins[name],\n                    checkAgain = false,\n                    skip = false;\n\n                if (mixin) {\n                    if (typeof mixin === 'function') {\n                        if (_initiatedOnce[name]) {\n                            if (!initiatedOnce[name]) {\n                                initiatedOnce[name] = [];\n                                // add the placeholder so the mixin ends up in the right place\n                                // we will replace all names with the appropriate mixins at the end\n                                // (so we have all of the appropriate arguments)\n                                mixin = name;\n                            } else {\n                                // but we only want to add it a single time\n                                skip = true;\n                            }\n                            if (params) {\n                                initiatedOnce[name].push(params);\n                            }\n                        } else {\n                            mixin = mixin.apply(this, params || []);\n                            checkAgain = true;\n                        }\n                    } else if (params) {\n                        throw new Error('the mixin \"' + name + '\" does not support parameters');\n                    }\n                    get(_dependsOn[name], index, initiatedOnce, rtn);\n                    get(_dependsInjected[name], index, initiatedOnce, rtn);\n\n                    index[indexName] = true;\n                    if (checkAgain) {\n                        get([mixin], index, initiatedOnce, rtn);\n                    } else if (!skip) {\n                        checkForInlineMixins(mixin, rtn);\n                        rtn.push(mixin);\n                    }\n\n                } else {\n                    throw new Error('invalid mixin \"' + name + '\"');\n                }\n            }\n        }", "label": 3}
{"code": "public static base_response update(nitro_service client, vridparam resource) throws Exception {\n\t\tvridparam updateresource = new vridparam();\n\t\tupdateresource.sendtomaster = resource.sendtomaster;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "public static base_responses update(nitro_service client, sslocspresponder resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslocspresponder updateresources[] = new sslocspresponder[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new sslocspresponder();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].url = resources[i].url;\n\t\t\t\tupdateresources[i].cache = resources[i].cache;\n\t\t\t\tupdateresources[i].cachetimeout = resources[i].cachetimeout;\n\t\t\t\tupdateresources[i].batchingdepth = resources[i].batchingdepth;\n\t\t\t\tupdateresources[i].batchingdelay = resources[i].batchingdelay;\n\t\t\t\tupdateresources[i].resptimeout = resources[i].resptimeout;\n\t\t\t\tupdateresources[i].respondercert = resources[i].respondercert;\n\t\t\t\tupdateresources[i].trustresponder = resources[i].trustresponder;\n\t\t\t\tupdateresources[i].producedattimeskew = resources[i].producedattimeskew;\n\t\t\t\tupdateresources[i].signingcert = resources[i].signingcert;\n\t\t\t\tupdateresources[i].usenonce = resources[i].usenonce;\n\t\t\t\tupdateresources[i].insertclientcert = resources[i].insertclientcert;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (ctrl *Controller) RecordCall(receiver interface{}, method string, args ...interface{}) *Call {\n\tctrl.T.Helper()\n\n\trecv := reflect.ValueOf(receiver)\n\tfor i := 0; i < recv.Type().NumMethod(); i++ {\n\t\tif recv.Type().Method(i).Name == method {\n\t\t\treturn ctrl.RecordCallWithMethodType(receiver, method, recv.Method(i).Type(), args...)\n\t\t}\n\t}\n\tctrl.T.Fatalf(\"gomock: failed finding method %s on %T\", method, receiver)\n\tpanic(\"unreachable\")\n}", "label": 5}
{"code": "public function setRunAttempt($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\ListTransferRunsRequest_RunAttempt::class);\n        $this->run_attempt = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func loopbackPool(proxyAddr string) *x509.CertPool {\n\tif !utils.IsLoopback(proxyAddr) {\n\t\tlog.Debugf(\"not using loopback pool for remote proxy addr: %v\", proxyAddr)\n\t\treturn nil\n\t}\n\tlog.Debugf(\"attempting to use loopback pool for local proxy addr: %v\", proxyAddr)\n\tcertPool := x509.NewCertPool()\n\n\tcertPath := filepath.Join(defaults.DataDir, defaults.SelfSignedCertPath)\n\tpemByte, err := ioutil.ReadFile(certPath)\n\tif err != nil {\n\t\tlog.Debugf(\"could not open any path in: %v\", certPath)\n\t\treturn nil\n\t}\n\n\tfor {\n\t\tvar block *pem.Block\n\t\tblock, pemByte = pem.Decode(pemByte)\n\t\tif block == nil {\n\t\t\tbreak\n\t\t}\n\t\tcert, err := x509.ParseCertificate(block.Bytes)\n\t\tif err != nil {\n\t\t\tlog.Debugf(\"could not parse cert in: %v, err: %v\", certPath, err)\n\t\t\treturn nil\n\t\t}\n\t\tcertPool.AddCert(cert)\n\t}\n\tlog.Debugf(\"using local pool for loopback proxy: %v, err: %v\", certPath, err)\n\treturn certPool\n}", "label": 5}
{"code": "protected function fillJenkins() : self\n    {\n        if (isset($this->env['JENKINS_URL']) && isset($this->env['BUILD_NUMBER'])) {\n            $this->readEnv['CI_BUILD_NUMBER'] = $this->env['BUILD_NUMBER'];\n            $this->readEnv['CI_BUILD_URL'] = $this->env['JENKINS_URL'];\n            $this->env['CI_NAME'] = 'jenkins';\n\n            // backup\n            $this->readEnv['BUILD_NUMBER'] = $this->env['BUILD_NUMBER'];\n            $this->readEnv['JENKINS_URL'] = $this->env['JENKINS_URL'];\n            $this->readEnv['CI_NAME'] = $this->env['CI_NAME'];\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function es5Fn(fn) {\n  let s = fn.toString();\n\n  //const name = fn.name;\n\n  //if (s.startsWith('function (')) {\n  //s = 'function ' + (name || '_fn' + nextFnName++) + ' (' + s.substring(10);\n  /*} else */\n  if (!s.startsWith('function')) {\n    s = 'function ' + s;\n  }\n\n  return s;\n}", "label": 3}
{"code": "def get_uri_schemaloc_map(self):\n        \"\"\"Constructs and returns a map from namespace URI to schema location\n        URI.  Namespaces without schema locations are excluded.\"\"\"\n        mapping = {}\n\n        for ni in six.itervalues(self.__ns_uri_map):\n            if ni.schema_location:\n                mapping[ni.uri] = ni.schema_location\n\n        return mapping", "label": 1}
{"code": "function BpmnQuestionnaire(options) {\n\n  // Check if options was provided\n  if (!options) {\n    throw new Error('No options provided');\n  }\n\n  if (has(options, 'questionnaireJson')) {\n    this.questionnaireJson = options.questionnaireJson;\n  } else {\n\n    // Report error\n    throw new Error('No questionnaire specified');\n  }\n\n  // Events\n  this.events = new EventEmitter();\n\n  // Services\n  this.services = {\n    translator: (function(){\n      var translator;\n\n      if(has(options, 'plugins.translator')) {\n        // translator = new Translator(options.plugins.translator)\n        translator = new Translator(options.plugins.translator);\n      } else {\n        translator = new Translator();\n      }\n\n      return translator.translate.bind(translator);\n    }())\n  }\n\n  // Check if types were provided\n  if (options.types) {\n    this.types = options.types;\n  }\n\n  // Check if questions were provided\n  if (this.questionnaireJson.questions.length) {\n    this.questions = [];\n    var that = this;\n\n    // Create questions\n    this.questionnaireJson.questions.forEach(function(question, index) {\n\n      // Check if type of question was provided\n      if (!typeof that.types[question.type] === 'function') {\n\n        // Report error\n        throw new Error('Type not specified');\n      } else {\n\n        // Add instance of question to array of questions\n        that.questions.push(\n          new that.types[question.type](index, question, that)\n        );\n      }\n    });\n  } else {\n\n    // Report error\n    throw new Error('No questions specified');\n  }\n\n  // Initial state is immutable\n  this.initState = Immutable({\n    currentQuestion: 0,\n    progress:        0,\n    view:            'intro'\n  });\n\n  // Set state to mutable copy of initial state\n  this.state = this.initState.asMutable({deep: true});\n\n  // Set up loop\n  this.loop = mainLoop(this.state, this.render.bind(this), {\n    create: require(\"virtual-dom/create-element\"),\n    diff:   require(\"virtual-dom/diff\"),\n    patch:  require(\"virtual-dom/patch\")\n  });\n\n  // Check if container element was specified\n  if (!options.container) {\n    throw new Error('No container element specified');\n  }\n\n  // Append questionnaire to container element\n  if (typeof options.container === 'string') {\n\n    // Search for element with given ID\n    var container = document.getElementById(options.container);\n\n    // Error handling\n    if (!container) {\n      throw new Error('Container element not found');\n    }\n\n    this.container = container;\n  } else if (options.container.appendChild) {\n\n    // Append questionnaire\n    this.container = options.container;\n  } else {\n    throw new Error('Container element not found');\n  }\n\n  // Append questionnaire\n  this.container.appendChild(this.loop.target);\n}", "label": 3}
{"code": "def read_settings(instance_id, remote_ip = nil)\n      check_instance_ips(remote_ip, instance_id) if remote_ip\n\n      get_instance(instance_id).settings\n    end", "label": 4}
{"code": "func (s *AuthServer) ValidateToken(token string) (roles teleport.Roles, e error) {\n\ttkns, err := s.GetCache().GetStaticTokens()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// First check if the token is a static token. If it is, return right away.\n\t// Static tokens have no expiration.\n\tfor _, st := range tkns.GetStaticTokens() {\n\t\tif st.GetName() == token {\n\t\t\treturn st.GetRoles(), nil\n\t\t}\n\t}\n\n\t// If it's not a static token, check if it's a ephemeral token in the backend.\n\t// If a ephemeral token is found, make sure it's still valid.\n\ttok, err := s.GetCache().GetToken(token)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif !s.checkTokenTTL(tok) {\n\t\treturn nil, trace.AccessDenied(\"token expired\")\n\t}\n\n\treturn tok.GetRoles(), nil\n}", "label": 5}
{"code": "function(dnsaddr) {\n  var domain = getAddressDomain(dnsaddr);\n  if(domain !== undefined && clients[domain] !== undefined)\n    return clients[domain];\n}", "label": 3}
{"code": "public static base_response add(nitro_service client, locationfile resource) throws Exception {\n\t\tlocationfile addresource = new locationfile();\n\t\taddresource.Locationfile = resource.Locationfile;\n\t\taddresource.format = resource.format;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def create_sample_file(ip, op, num_lines): \n    \"\"\" make a short version of an RDF file \"\"\"\n    with open(ip, \"rb\") as f:\n        with open(op, \"wb\") as fout:\n            for _ in range(num_lines):\n                fout.write(f.readline() )", "label": 1}
{"code": "func (a *AuthServer) SetCache(clt AuthCache) {\n\ta.lock.Lock()\n\tdefer a.lock.Unlock()\n\ta.cache = clt\n}", "label": 5}
{"code": "def extract_headers!(options = {})\n      extract = {\n        wrap_ttl: Vault::Client::WRAP_TTL_HEADER,\n      }\n\n      {}.tap do |h|\n        extract.each do |k,v|\n          if options[k]\n            h[v] = options.delete(k)\n          end\n        end\n      end\n    end", "label": 4}
{"code": "def stream_logs(container, timeout=10.0, **logs_kwargs):\n    \"\"\"\n    Stream logs from a Docker container within a timeout.\n\n    :param ~docker.models.containers.Container container:\n        Container who's log lines to stream.\n    :param timeout:\n        Timeout value in seconds.\n    :param logs_kwargs:\n        Additional keyword arguments to pass to ``container.logs()``. For\n        example, the ``stdout`` and ``stderr`` boolean arguments can be used to\n        determine whether to stream stdout or stderr or both (the default).\n\n    :raises TimeoutError:\n        When the timeout value is reached before the logs have completed.\n    \"\"\"\n    stream = container.logs(stream=True, **logs_kwargs)\n    return stream_timeout(\n        stream, timeout, 'Timeout waiting for container logs.')", "label": 1}
{"code": "function bracketDevicePixelRatio() {\n      var i, scale,\n        brackets = [ 1, 1.3, 1.5, 2, 2.6, 3 ],\n        baseRatio = window.devicePixelRatio || 1;\n\n      for ( i = 0; i < brackets.length; i++ ) {\n        scale = brackets[ i ];\n\n        if ( scale >= baseRatio || ( baseRatio - scale ) < 0.1 ) {\n          return scale;\n        }\n      }\n      return brackets[ brackets.length - 1 ];\n    }", "label": 3}
{"code": "public function setField($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\StructuredQuery_FieldReference::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def num_channels(self):\n        \"\"\"\n        Get the number of channels in the input generators.\n        \"\"\"\n        if(self.inspect_value('index') is None):\n            if(len(self.generators)>0):\n                return self.generators[0].num_channels()\n            return 0\n\n        return self.get_current_generator().num_channels()", "label": 1}
{"code": "public E get(int i) {\r\n    if (i < 0 || i >= objects.size())\r\n      throw new ArrayIndexOutOfBoundsException(\"Index \" + i + \r\n                                               \" outside the bounds [0,\" + \r\n                                               size() + \")\");\r\n    return objects.get(i);\r\n  }", "label": 0}
{"code": "def set(self, key, value, lease=None, return_previous=None, timeout=None):\n        \"\"\"\n        Set the value for the key in the key-value store.\n\n        Setting a value on a key increments the revision\n        of the key-value store and generates one event in\n        the event history.\n\n        :param key: key is the key, in bytes, to put into\n            the key-value store.\n        :type key: bytes\n\n        :param value: value is the value, in bytes, to\n            associate with the key in the key-value store.\n        :key value: bytes\n\n        :param lease: Lease to associate the key in the\n            key-value store with.\n        :type lease: instance of :class:`txaioetcd.Lease` or None\n\n        :param return_previous: If set, return the previous key-value.\n        :type return_previous: bool or None\n\n        :param timeout: Request timeout in seconds.\n        :type timeout: int\n\n        :returns: Revision info\n        :rtype: instance of :class:`txaioetcd.Revision`\n        \"\"\"\n        assembler = commons.PutRequestAssembler(self._url, key, value, lease, return_previous)\n\n        obj = yield self._post(assembler.url, assembler.data, timeout)\n\n        revision = Revision._parse(obj)\n\n        returnValue(revision)", "label": 1}
{"code": "func (w *Wrapper) UpsertAuthServer(s services.Server) error {\n\treturn w.Write.UpsertAuthServer(s)\n}", "label": 5}
{"code": "public function setHeadwearLikelihood($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Vision\\V1\\Likelihood::class);\n        $this->headwear_likelihood = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(base, filter)\n  {\n    if ( this.base )\n    {\n      this.base.database.off( Database.Events.ModelUpdated, this.onModelUpdated );\n    }\n\n    ModelCollection.prototype.init.call( this, base.database );\n\n    Filtering.init.call( this, base, filter );\n\n    base.database.on( Database.Events.ModelUpdated, this.onModelUpdated );\n\n    return this;\n  }", "label": 3}
{"code": "protected function sendSetPicture($jid, $filepath)\n    {\n        $nodeID = $this->createIqId();\n\n        $data = preprocessProfilePicture($filepath);\n        $preview = createIconGD($filepath, 96, true);\n\n        $picture = new ProtocolNode('picture', ['type' => 'image'], null, $data);\n        $preview = new ProtocolNode('picture', ['type' => 'preview'], null, $preview);\n\n        $node = new ProtocolNode('iq', [\n            'id'    => $nodeID,\n            'to'    => $this->getJID($jid),\n            'type'  => 'set',\n            'xmlns' => 'w:profile:picture',\n        ], [$picture, $preview], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "def interface_errors(self):\n        \"\"\" Parse 'show interfaces extensive' and return interfaces with errors.\n\n        Purpose: This function is called for the -e flag. It will let the user\n               | know if there are any interfaces with errors, and what those\n               | interfaces are.\n\n        @returns: The output that should be shown to the user.\n        @rtype: str\n        \"\"\"\n        output = []  # used to store the list of interfaces with errors.\n        # get a string of each physical and logical interface element\n        dev_response = self._session.command('sh interfaces extensive')\n        ints = dev_response.xpath('//physical-interface')\n        ints += dev_response.xpath('//logical-interface')\n        for i in ints:\n            # Grab the interface name for user output.\n            int_name = i.xpath('name')[0].text.strip()\n            # Only check certain interface types.\n            if (('ge' or 'fe' or 'ae' or 'xe' or 'so' or 'et' or 'vlan' or\n                 'lo0' or 'irb') in int_name):\n                try:\n                    status = (i.xpath('admin-status')[0].text.strip() +\n                              '/' + i.xpath('oper-status')[0].text.strip())\n                except IndexError:\n                    pass\n                else:\n                    for error in self._error_parse(i, \"input\"):\n                        output.append(\"%s (%s)%s\" % (int_name, status,\n                                                     error))\n                    for error in self._error_parse(i, \"output\"):\n                        output.append(\"%s (%s)%s\" % (int_name, status,\n                                                     error))\n        if output == []:\n            output.append('No interface errors were detected on this device.')\n        return '\\n'.join(output) + '\\n'", "label": 1}
{"code": "def _create_meta_cache(self):\n        \"\"\" Try to dump metadata to a file. \"\"\"\n        try:\n            with open(self._cache_filename, 'wb') as f:\n                compat.pickle.dump(self._document_meta, f, 1)\n        except (IOError, compat.pickle.PickleError):\n            pass", "label": 1}
{"code": "public static gslbsite_binding get(nitro_service service, String sitename) throws Exception{\n\t\tgslbsite_binding obj = new gslbsite_binding();\n\t\tobj.set_sitename(sitename);\n\t\tgslbsite_binding response = (gslbsite_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function parseElePath(elePath, type = 'component') {\n  const arr = elePath.split('/');\n  const feature = _.kebabCase(arr.shift());\n  let name = arr.pop();\n  if (type === 'action') name = _.camelCase(name);\n  else if (type === 'component') name = pascalCase(name);\n  else throw new Error('Unknown element type: ' + type + ' of ' + elePath);\n  elePath = [feature, ...arr, name].join('/');\n\n  const ele = {\n    name,\n    path: elePath,\n    feature,\n  };\n\n  if (type === 'component') {\n    ele.modulePath = `src/features/${elePath}.js`;\n    ele.testPath = `tests/features/${elePath}.test.js`;\n    ele.stylePath = `src/features/${elePath}.${config.getRekitConfig().css}`;\n  } else if (type === 'action') {\n    ele.modulePath = `src/features/${feature}/redux/${name}.js`;\n    ele.testPath = `tests/features/${feature}/redux/${name}.test.js`;\n  }\n  return ele;\n}", "label": 3}
{"code": "func (l HostFirewallRulesetList) Enabled() HostFirewallRulesetList {\n\tvar matches HostFirewallRulesetList\n\n\tfor _, rs := range l {\n\t\tif rs.Enabled {\n\t\t\tmatches = append(matches, rs)\n\t\t}\n\t}\n\n\treturn matches\n}", "label": 5}
{"code": "protected function write( $handle, $str ) {\n\t\tswitch ( $handle ) {\n\t\t\tcase STDOUT:\n\t\t\t\t$this->stdout .= $str;\n\t\t\t\tbreak;\n\t\t\tcase STDERR:\n\t\t\t\t$this->stderr .= $str;\n\t\t\t\tbreak;\n\t\t}\n\t}", "label": 2}
{"code": "public static base_response delete(nitro_service client, String name) throws Exception {\n\t\tnetbridge deleteresource = new netbridge();\n\t\tdeleteresource.name = name;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def _supervise(plugin, task, *args)\n      catch self.class.stopping_symbol_for(plugin) do\n        plugin.hook(\"#{ task }_begin\", *args)\n        result = UI.options.with_progname(plugin.class.name) do\n          begin\n            plugin.send(task, *args)\n          rescue Interrupt\n            throw(:task_has_failed)\n          end\n        end\n        plugin.hook(\"#{ task }_end\", result)\n        result\n      end\n    rescue ScriptError, StandardError, RuntimeError\n      UI.error(\"#{ plugin.class.name } failed to achieve its\"\\\n                        \" <#{ task }>, exception was:\" \\\n                        \"\\n#{ $!.class }: #{ $!.message }\" \\\n                        \"\\n#{ $!.backtrace.join(\"\\n\") }\")\n      Guard.state.session.plugins.remove(plugin)\n      UI.info(\"\\n#{ plugin.class.name } has just been fired\")\n      $!\n    end", "label": 4}
{"code": "function write(filepath, contents) {\n  return mkdirp(path.dirname(filepath)).then(() => {\n    return writeFile(filepath, contents);\n  });\n}", "label": 3}
{"code": "func (b *BoxLayout) RemoveWidget(widget Widget) {\n\tchanged := false\n\tfor i := 0; i < len(b.cells); i++ {\n\t\tif b.cells[i].widget == widget {\n\t\t\tb.cells = append(b.cells[:i], b.cells[i+1:]...)\n\t\t\tchanged = true\n\t\t}\n\t}\n\tif !changed {\n\t\treturn\n\t}\n\tb.changed = true\n\twidget.Unwatch(b)\n\tb.layout()\n\tb.PostEventWidgetContent(b)\n}", "label": 5}
{"code": "public function discover()\n    {\n        if (!$this->connectionFactory) {\n            throw new ClientException('Discovery requires a connection factory');\n        }\n\n        RETRY_FETCH: {\n            try {\n                if ($connection = $this->getMaster()) {\n                    $this->discoverFromMaster($connection, $this->connectionFactory);\n                } elseif ($connection = $this->pickSlave()) {\n                    $this->discoverFromSlave($connection, $this->connectionFactory);\n                } else {\n                    throw new ClientException('No connection available for discovery');\n                }\n            } catch (ConnectionException $exception) {\n                $this->remove($connection);\n                goto RETRY_FETCH;\n            }\n        }\n    }", "label": 2}
{"code": "func (f *file) lintErrorf() {\n\tf.walk(func(node ast.Node) bool {\n\t\tce, ok := node.(*ast.CallExpr)\n\t\tif !ok || len(ce.Args) != 1 {\n\t\t\treturn true\n\t\t}\n\t\tisErrorsNew := isPkgDot(ce.Fun, \"errors\", \"New\")\n\t\tvar isTestingError bool\n\t\tse, ok := ce.Fun.(*ast.SelectorExpr)\n\t\tif ok && se.Sel.Name == \"Error\" {\n\t\t\tif typ := f.pkg.typeOf(se.X); typ != nil {\n\t\t\t\tisTestingError = typ.String() == \"*testing.T\"\n\t\t\t}\n\t\t}\n\t\tif !isErrorsNew && !isTestingError {\n\t\t\treturn true\n\t\t}\n\t\tif !f.imports(\"errors\") {\n\t\t\treturn true\n\t\t}\n\t\targ := ce.Args[0]\n\t\tce, ok = arg.(*ast.CallExpr)\n\t\tif !ok || !isPkgDot(ce.Fun, \"fmt\", \"Sprintf\") {\n\t\t\treturn true\n\t\t}\n\t\terrorfPrefix := \"fmt\"\n\t\tif isTestingError {\n\t\t\terrorfPrefix = f.render(se.X)\n\t\t}\n\t\tp := f.errorf(node, 1, category(\"errors\"), \"should replace %s(fmt.Sprintf(...)) with %s.Errorf(...)\", f.render(se), errorfPrefix)\n\n\t\tm := f.srcLineWithMatch(ce, `^(.*)`+f.render(se)+`\\(fmt\\.Sprintf\\((.*)\\)\\)(.*)$`)\n\t\tif m != nil {\n\t\t\tp.ReplacementLine = m[1] + errorfPrefix + \".Errorf(\" + m[2] + \")\" + m[3]\n\t\t}\n\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "public static function map()\n    {\n        $permissions = [];\n\n        foreach (static::get() as $permission) {\n            $permissions[$permission->permission][] = (string) $permission->group_id;\n        }\n\n        return $permissions;\n    }", "label": 2}
{"code": "function(user) {\n      if (!this._shouldAllowUser(user)) {\n        return false;\n      }\n      user.leaveRoom();\n      this.members.push(user);\n      user.room = this;\n      if (this.minRoomMembers !== null &&\n          this.members.length >= this.minRoomMembers) {\n        this._hasReachedMin = true;\n      }\n      this._emitEvent('newMember', this, user);\n      this._serverMessageMembers(this.isLobby ? 'lobbyMemberJoined' : 'roomMemberJoined', _.pick(user, 'id', 'name'));\n      user._serverMessage('joinedRoom', _.pick(this, 'name'));\n      return true;\n    }", "label": 3}
{"code": "def process_allow_action(processors, action, argument):\n    \"\"\"Process allow action.\"\"\"\n    for processor in processors:\n        processor(action, argument)\n    db.session.commit()", "label": 1}
{"code": "def _hbf_handle_child_elements(self, obj, ntl):\n        \"\"\"\n        Indirect recursion through _gen_hbf_el\n        \"\"\"\n        # accumulate a list of the children names in ko, and\n        #   the a dictionary of tag to xml elements.\n        # repetition of a tag means that it will map to a list of\n        #   xml elements\n        cd = {}\n        ko = []\n        ks = set()\n        for child in ntl:\n            k = child.nodeName\n            if k == 'meta' and (not self._badgerfish_style_conversion):\n                matk, matv = self._transform_meta_key_value(child)\n                if matk is not None:\n                    _add_value_to_dict_bf(obj, matk, matv)\n            else:\n                if k not in ks:\n                    ko.append(k)\n                    ks.add(k)\n                _add_value_to_dict_bf(cd, k, child)\n\n        # Converts the child XML elements to dicts by recursion and\n        #   adds these to the dict.\n        for k in ko:\n            v = _index_list_of_values(cd, k)\n            dcl = []\n            ct = None\n            for xc in v:\n                ct, dc = self._gen_hbf_el(xc)\n                dcl.append(dc)\n            # this assertion will trip is the hacky stripping of namespaces\n            #   results in a name clash among the tags of the children\n            assert ct not in obj\n            obj[ct] = dcl\n\n        # delete redundant about attributes that are used in XML, but not JSON (last rule of HoneyBadgerFish)\n        _cull_redundant_about(obj)\n        return obj", "label": 1}
{"code": "def delete\n      options = range_key ? { range_key: Dumping.dump_field(read_attribute(range_key), self.class.attributes[range_key]) } : {}\n\n      # Add an optimistic locking check if the lock_version column exists\n      if self.class.attributes[:lock_version]\n        conditions = { if: {} }\n        conditions[:if][:lock_version] =\n          if changes[:lock_version].nil?\n            lock_version\n          else\n            changes[:lock_version][0]\n          end\n        options[:conditions] = conditions\n      end\n      Dynamoid.adapter.delete(self.class.table_name, hash_key, options)\n    rescue Dynamoid::Errors::ConditionalCheckFailedException\n      raise Dynamoid::Errors::StaleObjectError.new(self, 'delete')\n    end", "label": 4}
{"code": "def create_random_string(length=7, chars='ABCDEFGHJKMNPQRSTUVWXYZ23456789',\n                         repetitions=False):\n    \"\"\"\n    Returns a random string, based on the provided arguments.\n\n    It returns capital letters and numbers by default.\n    Ambiguous characters are left out, repetitions will be avoided.\n\n    \"\"\"\n    if repetitions:\n        return ''.join(random.choice(chars) for _ in range(length))\n    return ''.join(random.sample(chars, length))", "label": 1}
{"code": "public function setLevel($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\SkillProficiencyLevel::class);\n        $this->level = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function localizedLanguages(array $options = [])\n    {\n        $response = $this->connection->listLanguages($options + [\n            'key' => $this->key,\n            'target' => $this->targetLanguage\n        ]);\n\n        return array_map(function ($language) {\n            return array_filter([\n                'code' => $language['language'],\n                'name' => isset($language['name']) ? $language['name'] : null\n            ]);\n        }, $response['data']['languages']);\n    }", "label": 2}
{"code": "def available_gems\n      return [] unless gemfile_path\n      dsl = Bundler::Dsl.evaluate(gemfile_path, nil, true)\n      return dsl.dependencies.map(&:name)\n    end", "label": 4}
{"code": "def parse_raw_file(file)\n      data = {}\n      File.readlines(file).each do |line|\n        line = str_clean line, false\n        next if line.empty? || line[0] == '#'\n        prefix, line_data = line.split('|')\n        data[prefix] = line_data && line_data.strip.split('&')\n      end\n      data\n    end", "label": 4}
{"code": "public function getResource($key = null)\n    {\n        if (is_null($key)) {\n            return $this->resources;\n        }\n\n        return $this->resources->get($key);\n    }", "label": 2}
{"code": "def send(self, data):\n        \"\"\"\n        Sends data to the server.\n        \"\"\"\n        self.logger.debug('Send data: {}'.format(data))\n\n        if not self.connected:\n            self.logger.warning('Connection not established. Return...')\n            return\n\n        self.websocket.send(json.dumps(data))", "label": 1}
{"code": "func NewReverseTunnel(clusterName string, dialAddrs []string) ReverseTunnel {\n\treturn &ReverseTunnelV2{\n\t\tKind:    KindReverseTunnel,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName:      clusterName,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: ReverseTunnelSpecV2{\n\t\t\tClusterName: clusterName,\n\t\t\tDialAddrs:   dialAddrs,\n\t\t},\n\t}\n}", "label": 5}
{"code": "public void ifMemberTagValueEquals(String template, Properties attributes) throws XDocletException\r\n    {\r\n        if (getCurrentField() != null) {\r\n            if (isTagValueEqual(attributes, FOR_FIELD)) {\r\n                generate(template);\r\n            }\r\n        }\r\n        else if (getCurrentMethod() != null) {\r\n            if (isTagValueEqual(attributes, FOR_METHOD)) {\r\n                generate(template);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public function deserialize($jsonString, $className)\n    {\n        if (!$this->isValidClassName($className)) {\n            throw new \\Exception($className.' is not defined in OpenApi PHP Annotations');\n        }\n        return $this->doDeserialize(json_decode($jsonString), $className);\n    }", "label": 2}
{"code": "def _get_v_angle(self, case, B, v_angle_guess, p_businj, iref):\n        \"\"\" Calculates the voltage phase angles.\n        \"\"\"\n        buses = case.connected_buses\n\n        pv_idxs = [bus._i for bus in buses if bus.type == PV]\n        pq_idxs = [bus._i for bus in buses if bus.type == PQ]\n        pvpq_idxs = pv_idxs + pq_idxs\n        pvpq_rows = [[i] for i in pvpq_idxs]\n\n        # Get the susceptance matrix with the column and row corresponding to\n        # the reference bus removed.\n        Bpvpq = B[pvpq_rows, pvpq_idxs]\n\n        Bref = B[pvpq_rows, [iref]]\n\n        # Bus active power injections (generation - load) adjusted for phase\n        # shifters and real shunts.\n        p_surplus = array([case.s_surplus(v).real for v in buses])\n        g_shunt = array([bus.g_shunt for bus in buses])\n        Pbus = (p_surplus - p_businj - g_shunt) / case.base_mva\n\n        Pbus.shape = len(Pbus), 1\n\n        A = Bpvpq\n        b = Pbus[pvpq_idxs] - Bref * v_angle_guess[iref]\n\n#        x, res, rank, s = linalg.lstsq(A.todense(), b)\n        x = spsolve(A, b)\n\n        # Insert the reference voltage angle of the slack bus.\n        v_angle = r_[x[:iref], v_angle_guess[iref], x[iref:]]\n\n        return v_angle, Pbus[iref]", "label": 1}
{"code": "public function setCropHints($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\CropHint::class);\n        $this->crop_hints = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static final Rect getViewportBounds() {\n        return new Rect(Window.getScrollLeft(), Window.getScrollTop(), Window.getClientWidth(), Window.getClientHeight());\n    }", "label": 0}
{"code": "public Point2D.Double minDistancePointSpline(Point2D.Double p, int nPointsPerSegment){\n\t\t\tdouble minDistance = Double.MAX_VALUE;\n\t\t\tPoint2D.Double minDistancePoint = null;\n\t\t    int numberOfSplines = spline.getN();\n\t\t    double[] knots = spline.getKnots();\n\t\t    for(int i = 0; i < numberOfSplines; i++){\n\t\t    \tdouble x = knots[i];\n\t\t    \tdouble stopx = knots[i+1];\n\t\t    \tdouble dx = (stopx-x)/nPointsPerSegment;\n\t\t    \t\n\t\t    \tfor(int j = 0; j < nPointsPerSegment; j++){\n\t\t    \t\tPoint2D.Double candidate = new Point2D.Double(x, spline.value(x));\n\t\t    \t\tdouble d = p.distance(candidate);\n\t\t    \t\tif(d<minDistance){\n\t\t    \t\t\tminDistance = d;\n\t\t    \t\t\tminDistancePoint = candidate;\n\t\t    \t\t}\n\t\t    \t\tx += dx;\n\t\t    \t}\n\t\t    \t\n\t\t    }\n\t\t    return minDistancePoint;\n\t}", "label": 0}
{"code": "def drag_and_drop_on(other)\n      assert_is_element other\n\n      value = element_call(:wait_for_present) do\n        driver.action\n              .drag_and_drop(@element, other.wd)\n              .perform\n      end\n      browser.after_hooks.run\n      value\n    end", "label": 4}
{"code": "def __parse_fc_data(fc_data):\n    \"\"\"Parse the forecast data from the json section.\"\"\"\n    fc = []\n    for day in fc_data:\n        fcdata = {\n            CONDITION: __cond_from_desc(\n                __get_str(\n                    day,\n                    __WEATHERDESCRIPTION)\n            ),\n            TEMPERATURE: __get_float(day, __MAXTEMPERATURE),\n            MIN_TEMP: __get_float(day, __MINTEMPERATURE),\n            MAX_TEMP: __get_float(day, __MAXTEMPERATURE),\n            SUN_CHANCE: __get_int(day, __SUNCHANCE),\n            RAIN_CHANCE: __get_int(day, __RAINCHANCE),\n            RAIN: __get_float(day, __MMRAINMAX),\n            MIN_RAIN: __get_float(day, __MMRAINMIN),  # new\n            MAX_RAIN: __get_float(day, __MMRAINMAX),  # new\n            SNOW: 0,  # for compatibility\n            WINDFORCE: __get_int(day, __WIND),\n            WINDDIRECTION: __get_str(day, __WINDDIRECTION),      # new\n            DATETIME: __to_localdatetime(__get_str(day, __DAY)),\n        }\n        fcdata[CONDITION][IMAGE] = day[__ICONURL]\n\n        fc.append(fcdata)\n    return fc", "label": 1}
{"code": "function injectFlapjack(flapjack, moduleStack, options) {\n        options = options || {};\n\n        // if server is false, then return null\n        var moduleInfo = annotations.getModuleInfo(flapjack);\n        if (moduleInfo && moduleInfo.server === false && !options.test) {\n            return null;\n        }\n\n        // param map is combo of param map set by user, params discovered and current annotation\n        var aliases = _.extend({}, this.aliases, annotations.getServerAliases(flapjack, null));\n        var params = annotations.getParameters(flapjack);\n        var deps = options.dependencies || {};\n        var paramModules = [];\n        var me = this;\n\n        // loop through the params so we can collect the object that will be injected\n        _.each(params, function (param) {\n            var dep = deps[param];\n\n            // if mapping exists, switch to the mapping (ex. pancakes -> lib/pancakes)\n            if (aliases[param]) {\n                param = aliases[param];\n            }\n\n            // either get the module from the input dependencies or recursively call inject\n            try {\n                paramModules.push(dep || deps[param] || me.loadModule(param, moduleStack));\n            }\n            catch (ex) {\n                var errMsg = ex.stack || ex;\n                throw new Error('While injecting function, ran into invalid parameter.\\nparam: ' + param +\n                '\\nstack: ' + JSON.stringify(moduleStack) + '\\nfunction: ' +\n                flapjack.toString().substring(0, 100) + '...\\nerror: ' + errMsg);\n            }\n        });\n\n        // call the flapjack function passing in the array of modules as parameters\n        return flapjack.apply(null, paramModules);\n    }", "label": 3}
{"code": "def create(description='<Created by Python>', connection=None):\n        \"\"\"Creates a new changelist\n\n        :param connection: Connection to use to create the changelist\n        :type connection: :class:`.Connection`\n        :param description: Description for new changelist\n        :type description: str\n        :returns: :class:`.Changelist`\n        \"\"\"\n        connection = connection or Connection()\n        description = description.replace('\\n', '\\n\\t')\n        form = NEW_FORMAT.format(client=str(connection.client), description=description)\n        result = connection.run(['change', '-i'], stdin=form, marshal_output=False)\n\n        return Changelist(int(result.split()[1]), connection)", "label": 1}
{"code": "def invalid_credentials(force: false)\n      puts(\"The login credentials for '#{user}' seem to be wrong\".red)\n\n      if fetch_password_from_env\n        puts(\"The password was taken from the environment variable\")\n        puts(\"Please make sure it is correct\")\n        return false\n      end\n\n      if force || agree(\"Do you want to re-enter your password? (y/n)\", true)\n        puts(\"Removing Keychain entry for user '#{user}'...\".yellow) if mac?\n        remove_from_keychain\n        ask_for_login\n        return true\n      end\n      false\n    end", "label": 4}
{"code": "public function setSnapshots($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Bigtable\\Admin\\V2\\Snapshot::class);\n        $this->snapshots = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function(microseconds) {\n        var milliseconds = microseconds / 1000;\n        if (moment.utc(milliseconds).format(\"HH\") > 0) {\n            return moment.utc(milliseconds).format(\"HH:mm:ss.SSS\");\n        }\n        return moment.utc(milliseconds).format(\"mm:ss.SSS\");\n    }", "label": 3}
{"code": "def charts\n      charts = @anchors.select { |a| a.object.is_a?(GraphicFrame) }\n      charts.map { |a| a.object.chart }\n    end", "label": 4}
{"code": "def connect(self):\n        \"\"\"\n        Establish the connection. This is done automatically for you.\n\n        If you lose the connection, you can manually run this to be re-connected.\n        \"\"\"\n        self.conn = boto.connect_s3(self.AWS_ACCESS_KEY_ID, self.AWS_SECRET_ACCESS_KEY, debug=self.S3UTILS_DEBUG_LEVEL)\n\n        self.bucket = self.conn.get_bucket(self.AWS_STORAGE_BUCKET_NAME)\n\n        self.k = Key(self.bucket)", "label": 1}
{"code": "public static void validate(final License license) {\n        // A license should have a name\n        if(license.getName() == null ||\n                license.getName().isEmpty()){\n            throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                    .entity(\"License name should not be empty!\")\n                    .build());\n        }\n\n        // A license should have a long name\n        if(license.getLongName() == null ||\n                license.getLongName().isEmpty()){\n            throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                    .entity(\"License long name should not be empty!\")\n                    .build());\n        }\n\n        // If there is a regexp, it should compile\n        if(license.getRegexp() != null &&\n                !license.getRegexp().isEmpty()){\n            try{\n                Pattern.compile(license.getRegexp());\n            }\n            catch (PatternSyntaxException e){\n                throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                        .entity(\"License regexp does not compile!\").build());\n            }\n\n            Pattern regex = Pattern.compile(\"[&%//]\");\n            if(regex.matcher(license.getRegexp()).find()){\n                throw new WebApplicationException(Response.status(Response.Status.BAD_REQUEST)\n                        .entity(\"License regexp does not compile!\").build());\n            }\n\n        }\n    }", "label": 0}
{"code": "def remove_study(self, first_arg, sec_arg, third_arg, fourth_arg=None, commit_msg=None):\n        \"\"\"Remove a study\n        Given a study_id, branch and optionally an\n        author, remove a study on the given branch\n        and attribute the commit to author.\n        Returns the SHA of the commit on branch.\n        \"\"\"\n        if fourth_arg is None:\n            study_id, branch_name, author = first_arg, sec_arg, third_arg\n            gh_user = branch_name.split('_study_')[0]\n            parent_sha = self.get_master_sha()\n        else:\n            gh_user, study_id, parent_sha, author = first_arg, sec_arg, third_arg, fourth_arg\n        if commit_msg is None:\n            commit_msg = \"Delete Study #%s via OpenTree API\" % study_id\n        return self._remove_document(gh_user, study_id, parent_sha, author, commit_msg)", "label": 1}
{"code": "def which(executable)\n      if File.file?(executable) && File.executable?(executable)\n        executable\n      elsif ENV['PATH']\n        path = ENV['PATH'].split(File::PATH_SEPARATOR).find do |p|\n          abs_path = File.join(p, executable)\n          File.file?(abs_path) && File.executable?(abs_path)\n        end\n        path && File.expand_path(executable, path)\n      end\n    end", "label": 4}
{"code": "public static vpnsessionaction[] get(nitro_service service) throws Exception{\n\t\tvpnsessionaction obj = new vpnsessionaction();\n\t\tvpnsessionaction[] response = (vpnsessionaction[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def manual_update_license(self, fd, filename='cdrouter.lic'):\n        \"\"\"Update the license on your CDRouter system manually by uploading a\n        .lic license from the CDRouter Support Lounge.\n\n        :param fd: File-like object to upload.\n        :param filename: (optional) Filename to use for license as string.\n        :return: :class:`system.Upgrade <system.Upgrade>` object\n        :rtype: system.Upgrade\n        \"\"\"\n        schema = UpgradeSchema()\n        resp = self.service.post(self.base+'license/',\n                                 files={'file': (filename, fd)})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "def fetchone(table, cols=\"*\", where=(), group=\"\", order=(), limit=(), **kwargs):\r\n    \"\"\"Convenience wrapper for database SELECT and fetch one.\"\"\"\r\n    return select(table, cols, where, group, order, limit, **kwargs).fetchone()", "label": 1}
{"code": "function validatePropertyType(property, type, recursive) {\n    return type && (\n        (recursive && typeof property === 'object') ||\n        (type === 'string' && typeof property === 'string') ||\n        (type === 'number' && typeof property === 'number') ||\n        (type === 'uuid' && isUuid(property)) ||\n        (type === 'uuidList' && isUuidList(property))\n    );\n}", "label": 3}
{"code": "func ParseKey(key string) ([]string, error) {\n\tchain := strings.Split(strings.Trim(key, \"/\"), \"/\")\n\n\t// The key must at least be equal to the rootChain in order to be considered as valid\n\tif len(chain) <= len(rootChain) || !reflect.DeepEqual(chain[0:len(rootChain)], rootChain) {\n\t\treturn nil, types.BadRequestErrorf(\"invalid Key : %s\", key)\n\t}\n\treturn chain[len(rootChain):], nil\n}", "label": 5}
{"code": "def new_resources_bundle(name, platform, product_group = nil)\n      product_group ||= products_group\n      ProjectHelper.new_resources_bundle(self, name, platform, product_group)\n    end", "label": 4}
{"code": "function Field(type, config) {\n  if (utils.typeOf(type) === 'object') {\n    config = type;\n    type = null;\n  }\n\n  if (!utils.isObject(config)) {\n    throw new TypeError('expected config to be an object');\n  }\n\n  this.types = type || config.type || config.types || [];\n  this.types = typeof this.types === 'string'\n    ? this.types.split(/\\W/)\n    : this.types;\n\n  if (typeof this.types === 'undefined' || this.types.length === 0) {\n    throw new TypeError('expected type to be a string or array of JavaScript native types');\n  }\n\n  for (var key in config) {\n    this[key] = config[key];\n  }\n\n  if (!config.hasOwnProperty('required')) {\n    this.required = false;\n  }\n  if (!config.hasOwnProperty('optional')) {\n    this.optional = true;\n  }\n  if (this.required === true) {\n    this.optional = false;\n  }\n  if (this.optional === false) {\n    this.required = true;\n  }\n}", "label": 3}
{"code": "public static File createFolder(String path, String dest_dir)\n            throws BeastException {\n        File f = new File(dest_dir);\n        if (!f.isDirectory()) {\n            try {\n                f.mkdirs();\n            } catch (Exception e) {\n                logger.severe(\"Problem creating directory: \" + path\n                        + File.separator + dest_dir);\n            }\n        }\n\n        String folderPath = createFolderPath(path);\n\n        f = new File(f, folderPath);\n        if (!f.isDirectory()) {\n            try {\n                f.mkdirs();\n            } catch (Exception e) {\n                String message = \"Problem creating directory: \" + path\n                        + File.separator + dest_dir;\n                logger.severe(message);\n                throw new BeastException(message, e);\n            }\n        }\n\n        return f;\n    }", "label": 0}
{"code": "public function rename($from, $to)\n    {\n        $url = (array) parse_url($to) + [\n            'path' => '',\n            'host' => ''\n        ];\n\n        $destinationBucket = $url['host'];\n        $destinationPath = substr($url['path'], 1);\n\n        $this->dir_opendir($from, []);\n        foreach ($this->directoryIterator as $file) {\n            $name = $file->name();\n            $newPath = str_replace($this->file, $destinationPath, $name);\n\n            $obj = $this->bucket->object($name);\n            try {\n                $obj->rename($newPath, ['destinationBucket' => $destinationBucket]);\n            } catch (ServiceException $e) {\n                // If any rename calls fail, abort and return false\n                return false;\n            }\n        }\n        return true;\n    }", "label": 2}
{"code": "def write_temporary_file(content, prefix='', suffix=''):\n    \"\"\"\n    Generating a temporary file with content.\n\n    Args:\n        content (str): file content (usually a script, Dockerfile, playbook or config file)\n        prefix (str): the filename starts with this prefix (default: no prefix)\n        suffix (str): the filename ends with this suffix (default: no suffix)\n\n    Returns:\n        str: name of the temporary file\n\n    Note:\n        You are responsible for the deletion of the file.\n    \"\"\"\n    temp = tempfile.NamedTemporaryFile(prefix=prefix, suffix=suffix, mode='w+t', delete=False)\n    temp.writelines(content)\n    temp.close()\n    return temp.name", "label": 1}
{"code": "def set_cas(key, value, cas, ttl=nil, options=nil)\n      ttl ||= @options[:expires_in].to_i\n      perform(:set, key, value, ttl, cas, options)\n    end", "label": 4}
{"code": "public static nslimitidentifier_stats get(nitro_service service, String name) throws Exception{\n\t\tnslimitidentifier_stats obj = new nslimitidentifier_stats();\n\t\tobj.set_name(name);\n\t\tnslimitidentifier_stats response = (nslimitidentifier_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def to_xml_string(str = '')\n      str << ('<conditionalFormatting sqref=\"' << sqref << '\">')\n      str << rules.collect{ |rule| rule.to_xml_string }.join(' ')\n      str << '</conditionalFormatting>'\n    end", "label": 4}
{"code": "function (statusCode, text) {\n                    var resp = this._response;\n                    resp.writeHead(statusCode, {\"Content-Type\": \"text/plain\"});\n                    resp.write([\n                        \"port    : \" + this._options.port,\n                        \"method  : \" + this._request.method,\n                        \"url     : \" + this._request.url,\n                        \"root    : \" + this._options.root,\n                        \"path    : \" + this._filePath,\n                        \"headers : \"\n                        + JSON.stringify(this._request.headers, null, \"\\t\\t\"),\n                        text\n                    ].join(\"\\n\"));\n                    resp.end();\n                }", "label": 3}
{"code": "func (c *SessionContext) newRemoteClient(cluster reversetunnel.RemoteSite) (auth.ClientI, net.Conn, error) {\n\tclt, err := c.tryRemoteTLSClient(cluster)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\treturn clt, nil, nil\n}", "label": 5}
{"code": "public function scopeWithTelescopeOptions($query, $type, EntryQueryOptions $options)\n    {\n        $this->whereType($query, $type)\n                ->whereBatchId($query, $options)\n                ->whereTag($query, $options)\n                ->whereFamilyHash($query, $options)\n                ->whereBeforeSequence($query, $options)\n                ->filter($query, $options);\n\n        return $query;\n    }", "label": 2}
{"code": "public static base_responses update(nitro_service client, nsxmlnamespace resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnsxmlnamespace updateresources[] = new nsxmlnamespace[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new nsxmlnamespace();\n\t\t\t\tupdateresources[i].prefix = resources[i].prefix;\n\t\t\t\tupdateresources[i].Namespace = resources[i].Namespace;\n\t\t\t\tupdateresources[i].description = resources[i].description;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def edit(community):\n    \"\"\"Create or edit a community.\"\"\"\n    form = EditCommunityForm(formdata=request.values, obj=community)\n    deleteform = DeleteCommunityForm()\n    ctx = mycommunities_ctx()\n    ctx.update({\n        'form': form,\n        'is_new': False,\n        'community': community,\n        'deleteform': deleteform,\n    })\n\n    if form.validate_on_submit():\n        for field, val in form.data.items():\n            setattr(community, field, val)\n\n        file = request.files.get('logo', None)\n        if file:\n            if not community.save_logo(file.stream, file.filename):\n                form.logo.errors.append(_(\n                    'Cannot add this file as a logo. Supported formats: '\n                    'PNG, JPG and SVG. Max file size: 1.5 MB.'))\n\n        if not form.logo.errors:\n            db.session.commit()\n            flash(\"Community successfully edited.\", category='success')\n            return redirect(url_for('.edit', community_id=community.id))\n\n    return render_template(\n        current_app.config['COMMUNITIES_EDIT_TEMPLATE'],\n        **ctx\n    )", "label": 1}
{"code": "def uri_to_path(uri)\n    return unless uri.is_a?(URI)\n\n    # CGI.unescape doesn't handle space rules properly in uri paths\n    # URI.unescape does, but returns strings in their original encoding\n    path = URI.unescape(uri.path.encode(Encoding::UTF_8))\n\n    if Puppet::Util::Platform.windows? && uri.scheme == 'file'\n      if uri.host\n        path = \"//#{uri.host}\" + path # UNC\n      else\n        path.sub!(/^\\//, '')\n      end\n    end\n\n    path\n  end", "label": 4}
{"code": "function process(payload) {\n  var advAString = payload.substr(10,2);\n  advAString += payload.substr(8,2);\n  advAString += payload.substr(6,2);\n  advAString += payload.substr(4,2);\n  advAString += payload.substr(2,2);\n  advAString += payload.substr(0,2);\n  return new identifier(identifier.ADVA48, advAString);\n}", "label": 3}
{"code": "func (s *Server) DisableDiagnostic() {\n\ts.Lock()\n\tdefer s.Unlock()\n\n\ts.srv.Shutdown(context.Background())\n\ts.srv = nil\n\ts.enable = 0\n\tlogrus.Info(\"Disabling the diagnostic server\")\n}", "label": 5}
{"code": "def name(currency, *, plural=False):\n\t\"\"\" return name of currency \"\"\"\n\tcurrency = validate_currency(currency)\n\tif plural:\n\t\treturn _currencies[currency]['name_plural']\n\treturn _currencies[currency]['name']", "label": 1}
{"code": "def save_csv(self, filename, write_header_separately=True):\n        \"\"\"\n        save the default array as a CSV file\n        \"\"\"\n        txt = ''\n        #print(\"SAVING arr = \", self.arr)\n        \n        with open(filename, \"w\") as f:\n            if write_header_separately:\n                f.write(','.join([c for c in self.header]) + '\\n')\n            for row in self.arr:\n                #print('save_csv: saving row = ', row)\n                txt = ','.join([self.force_to_string(col) for col in row])\n                #print(txt)\n                f.write(txt + '\\n')\n            f.write('\\n')", "label": 1}
{"code": "public function sendGetStatuses($jids)\n    {\n        if (!is_array($jids)) {\n            $jids = [$jids];\n        }\n\n        $children = [];\n        foreach ($jids as $jid) {\n            $children[] = new ProtocolNode('user', ['jid' => $this->getJID($jid)], null, null);\n        }\n\n        $iqId = $this->nodeId['getstatuses'] = $this->createIqId();\n\n        $node = new ProtocolNode('iq',\n            [\n                'to'    => Constants::WHATSAPP_SERVER,\n                'type'  => 'get',\n                'xmlns' => 'status',\n                'id'    => $iqId,\n            ], [\n                new ProtocolNode('status', null, $children, null),\n            ], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "func GetFactories() []*BeeFactoryInterface {\n\tr := []*BeeFactoryInterface{}\n\tfor _, factory := range factories {\n\t\tr = append(r, factory)\n\t}\n\n\treturn r\n}", "label": 5}
{"code": "func (s *AuthServer) GetOTPData(user string) (string, []byte, error) {\n\t// get otp key from backend\n\totpSecret, err := s.GetTOTP(user)\n\tif err != nil {\n\t\treturn \"\", nil, trace.Wrap(err)\n\t}\n\n\t// create otp url\n\tparams := map[string][]byte{\"secret\": []byte(otpSecret)}\n\totpURL := utils.GenerateOTPURL(\"totp\", user, params)\n\n\t// create the qr code\n\totpQR, err := utils.GenerateQRCode(otpURL)\n\tif err != nil {\n\t\treturn \"\", nil, trace.Wrap(err)\n\t}\n\n\treturn otpURL, otpQR, nil\n}", "label": 5}
{"code": "def ufo_env\n      settings = YAML.load_file(\"#{Ufo.root}/.ufo/settings.yml\")\n      env = settings.find do |_env, section|\n        section ||= {}\n        ENV['AWS_PROFILE'] && ENV['AWS_PROFILE'] == section['aws_profile']\n      end\n\n      ufo_env = env.first if env\n      ufo_env = ENV['UFO_ENV'] if ENV['UFO_ENV'] # highest precedence\n      ufo_env || 'development'\n    end", "label": 4}
{"code": "public function getPaddedUnit($unit, $length = 2, $padString = '0', $padType = STR_PAD_LEFT)\n    {\n        return ($this->$unit < 0 ? '-' : '').str_pad(abs($this->$unit), $length, $padString, $padType);\n    }", "label": 2}
{"code": "function(properties)\n  {\n    var resolver = createPropertyResolver( properties );\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var resolved = resolver( this[ i ] );\n\n      if ( isValue( resolved ) )\n      {\n        return resolved;\n      }\n    }\n  }", "label": 3}
{"code": "function deepObj(pathKeys, obj, createEntries = true) {\n  return pathKeys.reduce((prev, curr) => {\n    if (typeof prev[curr] === 'undefined') {\n      if (createEntries) {\n        prev[curr] = {};\n      } else {\n        DrizzleError.error(\n          new DrizzleError(\n            `Property ${curr} not found on supplied object`,\n            DrizzleError.LEVELS.ERROR\n          )\n        );\n      }\n    }\n    return prev[curr];\n  }, obj);\n}", "label": 3}
{"code": "final public void addPositionRange(int start, int end) {\n    if (tokenPosition == null) {\n      tokenPosition = new MtasPosition(start, end);\n    } else {\n      int[] positions = new int[end - start + 1];\n      for (int i = start; i <= end; i++) {\n        positions[i - start] = i;\n      }\n      tokenPosition.add(positions);\n    }\n  }", "label": 0}
{"code": "def set_created_at\n      self.created_at ||= DateTime.now.in_time_zone(Time.zone) if Dynamoid::Config.timestamps\n    end", "label": 4}
{"code": "def avatar=(avatar)\n      if avatar.respond_to? :read\n        # Set the file to binary mode if supported, so we don't get problems with Windows\n        avatar.binmode if avatar.respond_to?(:binmode)\n\n        avatar_string = 'data:image/jpg;base64,'\n        avatar_string += Base64.strict_encode64(avatar.read)\n        update_profile_data(avatar: avatar_string)\n      else\n        update_profile_data(avatar: avatar)\n      end\n    end", "label": 4}
{"code": "def d2Sbr_dV2(Cbr, Ybr, V, lam):\n    \"\"\" Computes 2nd derivatives of complex power flow w.r.t. voltage.\n    \"\"\"\n    nb = len(V)\n\n    diaglam = spdiag(lam)\n    diagV = spdiag(V)\n\n    A = Ybr.H * diaglam * Cbr\n    B = conj(diagV) * A * diagV\n    D = spdiag(mul((A*V), conj(V)))\n    E = spdiag(mul((A.T * conj(V)), V))\n    F = B + B.T\n    G = spdiag(div(matrix(1.0, (nb, 1)), abs(V)))\n\n    Haa = F - D - E\n    Hva = 1j * G * (B - B.T - D + E)\n    Hav = Hva.T\n    Hvv = G * F * G\n\n    return Haa, Hav, Hva, Hvv", "label": 1}
{"code": "def get_by_token(cls, client_id, access_token, token_type=''):\n        \"\"\"Get RemoteAccount object for token.\n\n        :param client_id: The client id.\n        :param access_token: The access token.\n        :param token_type: The token type. (Default: ``''``)\n        :returns: A :class:`invenio_oauthclient.models.RemoteToken` instance.\n        \"\"\"\n        return cls.query.options(db.joinedload('remote_account')).filter(\n            RemoteAccount.id == RemoteToken.id_remote_account,\n            RemoteAccount.client_id == client_id,\n            RemoteToken.token_type == token_type,\n            RemoteToken.access_token == access_token,\n        ).first()", "label": 1}
{"code": "func (t *TLSServer) Serve(listener net.Listener) error {\n\treturn t.Server.Serve(tls.NewListener(listener, t.TLS))\n}", "label": 5}
{"code": "function(userId, offset, limit) {\n    return new Promise((resolve, reject) => {\n      this._start()\n          .uri('/api/report/user-login')\n          .urlParameter('userId', userId)\n          .urlParameter('offset', offset)\n          .urlParameter('limit', limit)\n          .get()\n          .go(this._responseHandler(resolve, reject));\n    });\n  }", "label": 3}
{"code": "private function validateParsedBody(Request $request)\n    {\n        $bodyParams = $request->all();\n\n        if (null === $bodyParams) {\n            throw new InvariantViolation(\n                'Request is expected to provide parsed body for \"multipart/form-data\" requests but got null'\n            );\n        }\n\n        if (!is_array($bodyParams)) {\n            throw new RequestError(\n                'GraphQL Server expects JSON object or array, but got ' . Utils::printSafeJson($bodyParams)\n            );\n        }\n\n        if (empty($bodyParams)) {\n            throw new InvariantViolation(\n                'Request is expected to provide parsed body for \"multipart/form-data\" requests but got empty array'\n            );\n        }\n    }", "label": 2}
{"code": "public Optional<SoyMsgBundle> resolve(final Optional<Locale> locale) throws IOException {\n        if (!locale.isPresent()) {\n            return Optional.absent();\n        }\n\n        synchronized (msgBundles) {\n            SoyMsgBundle soyMsgBundle = null;\n            if (isHotReloadModeOff()) {\n                soyMsgBundle = msgBundles.get(locale.get());\n            }\n            if (soyMsgBundle == null) {\n                soyMsgBundle = createSoyMsgBundle(locale.get());\n                if (soyMsgBundle == null) {\n                    soyMsgBundle = createSoyMsgBundle(new Locale(locale.get().getLanguage()));\n                }\n\n                if (soyMsgBundle == null && fallbackToEnglish) {\n                    soyMsgBundle = createSoyMsgBundle(Locale.ENGLISH);\n                }\n\n                if (soyMsgBundle == null) {\n                    return Optional.absent();\n                }\n\n                if (isHotReloadModeOff()) {\n                    msgBundles.put(locale.get(), soyMsgBundle);\n                }\n            }\n\n            return Optional.fromNullable(soyMsgBundle);\n        }\n    }", "label": 0}
{"code": "func (f *Fpdf) newLink(x, y, w, h float64, link int, linkStr string) {\n\t// linkList, ok := f.pageLinks[f.page]\n\t// if !ok {\n\t// linkList = make([]linkType, 0, 8)\n\t// f.pageLinks[f.page] = linkList\n\t// }\n\tf.pageLinks[f.page] = append(f.pageLinks[f.page],\n\t\tlinkType{x * f.k, f.hPt - y*f.k, w * f.k, h * f.k, link, linkStr})\n}", "label": 5}
{"code": "function (peerURL) {\n        let host = peerURL;\n        /* istanbul ignore else */\n        // The host should never be null, empty or undefined based on how this method is used.\n        // This check is an additional precaution.\n        if (host) {\n            if (host.indexOf('//') >= 0) {\n                host = host.substring(host.indexOf('//') + 2);\n            }\n            if (host.indexOf('/') >= 0) {\n                host = host.substring(0, host.indexOf('/'));\n            }\n        }\n        return host;\n    }", "label": 3}
{"code": "def attributesGTF(inGTF):\n    \"\"\"\n    List the type of attributes in a the attribute section of a GTF file\n\n    :param inGTF: GTF dataframe to be analysed\n    :returns: a list of attributes present in the attribute section\n\n    \"\"\"\n    df=pd.DataFrame(inGTF['attribute'].str.split(\";\").tolist())\n    desc=[]\n    for i in df.columns.tolist():\n        val=df[[i]].dropna()\n        val=pd.DataFrame(val[i].str.split(' \"').tolist())[0]\n        val=list(set(val))\n        for v in val:\n            if len(v) > 0:\n                l=v.split(\" \")\n                if len(l)>1:\n                    l=l[1]\n                else:\n                    l=l[0]\n                desc.append(l)\n    desc=list(set(desc))\n    finaldesc=[]\n    for d in desc:\n        if len(d) > 0:\n            finaldesc.append(d)\n    return finaldesc", "label": 1}
{"code": "public function register($name, $value, $hash = null)\n    {\n        return $this->doRegister($name, $value, 0, $hash);\n    }", "label": 2}
{"code": "def store_with(name, storage_id = nil, &block)\n      @storages << get_class_from_scope(Storage, name)\n        .new(self, storage_id, &block)\n    end", "label": 4}
{"code": "def _fadn_par(vec, geom):\n    \"\"\"First non-zero Atomic Displacement that is Non-Parallel with Vec\n\n    Utility function to identify the first atomic displacement in a geometry\n    that is both (a) not the zero vector and (b) non-(anti-)parallel with a\n    reference vector.\n\n    Parameters\n    ----------\n    vec\n        length-3 |npfloat_| --\n        Reference vector. Does not need to be normalized.\n\n    geom\n        length-3N |npfloat_| --\n        *CENTERED* molecular geometry.\n\n    Returns\n    -------\n    out_vec\n        length-3 |npfloat_| --\n        Normalized non-zero atomic displacement not (anti-)parallel to vec.\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n    from ..const import PRM\n    from ..error import InertiaError\n    from .vector import parallel_check as parchk\n\n    # Geom and vec must both be the right shape\n    if not (len(geom.shape) == 1 and geom.shape[0] % 3 == 0):\n        raise ValueError(\"Geometry is not length 3N\")\n    ## end if\n    if not vec.shape == (3,):\n        raise ValueError(\"Reference vector is not length 3\")\n    ## end if\n\n    # vec must not be the zero vector\n    if spla.norm(vec) < PRM.ZERO_VEC_TOL:\n        raise ValueError(\"Reference vector norm is too small\")\n    ## end if\n\n     # Normalize the ref vec\n    vec = vec / spla.norm(vec)\n\n    # Iterate over reshaped geometry\n    for disp in geom.reshape((geom.shape[0]//3, 3)):\n        # See if the displacement is nonzero and nonparallel to the ref vec\n        if spla.norm(disp) >= PRM.ZERO_VEC_TOL and \\\n                not parchk(disp.reshape(3), vec):\n            # This is the displacement you are looking for\n            out_vec = disp / spla.norm(disp)\n            break\n            ## end if\n        ## end if\n    ## next disp\n    else:\n        # Nothing fit the bill - must be a linear molecule?\n        raise InertiaError(InertiaError.BAD_GEOM,\n                    \"Linear molecule, no non-parallel displacement\", \"\")\n    ## end for disp\n\n    # Return the resulting vector\n    return out_vec", "label": 1}
{"code": "func (t *TestTLSServer) Start() error {\n\tvar err error\n\tif t.Listener == nil {\n\t\tt.Listener, err = net.Listen(\"tcp\", \"127.0.0.1:0\")\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\tgo t.TLSServer.Serve(t.Listener)\n\treturn nil\n}", "label": 5}
{"code": "public function find($id): EntryResult\n    {\n        $entry = EntryModel::on($this->connection)->whereUuid($id)->firstOrFail();\n\n        $tags = $this->table('telescope_entries_tags')\n                        ->where('entry_uuid', $id)\n                        ->pluck('tag')\n                        ->all();\n\n        return new EntryResult(\n            $entry->uuid,\n            null,\n            $entry->batch_id,\n            $entry->type,\n            $entry->family_hash,\n            $entry->content,\n            $entry->created_at,\n            $tags\n        );\n    }", "label": 2}
{"code": "public function setInclusionMode($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\SecurityCenter\\V1\\OrganizationSettings_AssetDiscoveryConfig_InclusionMode::class);\n        $this->inclusion_mode = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def deleteResourceFile(self, pid, filename):\n        \"\"\"\n        Delete a resource file\n\n        :param pid: The HydroShare ID of the resource\n        :param filename: String representing the name of the resource file to delete\n\n        :return: Dictionary containing 'resource_id' the ID of the resource from which the file was deleted, and\n            'file_name' the filename of the file deleted.\n\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource or resource file was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n        \"\"\"\n        url = \"{url_base}/resource/{pid}/files/{filename}\".format(url_base=self.url_base,\n                                                                  pid=pid,\n                                                                  filename=filename)\n\n        r = self._request('DELETE', url)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('DELETE', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid, filename))\n            else:\n                raise HydroShareHTTPException((url, 'DELETE', r.status_code))\n\n        response = r.json()\n        assert(response['resource_id'] == pid)\n        return response['resource_id']", "label": 1}
{"code": "func (t *FpdfTpl) childrensTemplates() []Template {\n\tchildrenTmpls := make([]Template, 0)\n\n\tfor x := 0; x < len(t.templates); x++ {\n\t\ttmpls := t.templates[x].Templates()\n\t\tchildrenTmpls = append(childrenTmpls, tmpls...)\n\t}\n\n\treturn childrenTmpls\n}", "label": 5}
{"code": "def aggregate_periods(self, periods):\n        \"\"\"Returns list of ndarrays averaged to a given number of periods.\n\n        Arguments:\n        periods -- desired number of periods as int\n        \"\"\"\n        try:\n            fieldname = self.raster_field.name\n        except TypeError:\n            raise exceptions.FieldDoesNotExist('Raster field not found')\n        arrays = self.arrays(fieldname)\n        arr = arrays[0]\n        if len(arrays) > 1:\n            if getattr(arr, 'ndim', 0) > 2:\n                arrays = np.vstack(arrays)\n            fill = getattr(arr, 'fill_value', None)\n            arr = np.ma.masked_values(arrays, fill, copy=False)\n        # Try to reshape using equal sizes first and fall back to unequal\n        # splits.\n        try:\n            means = arr.reshape((periods, -1)).mean(axis=1)\n        except ValueError:\n            means = np.array([a.mean() for a in np.array_split(arr, periods)])\n        obj = self[0]\n        setattr(obj, fieldname, means)\n        return [obj]", "label": 1}
{"code": "def all(pattern: SCAN_PATTERN, count: DEFAULT_COUNT)\n      redis { |conn| conn.sscan_each(UNIQUE_SET, match: pattern, count: count).to_a }\n    end", "label": 4}
{"code": "def _getsolution(self, config, section, **kwargs):\n        \"\"\"\n        Creates a VSG solution from a configparser instance.\n\n        :param object config: The instance of the configparser class\n        :param str section: The section name to read.\n        :param kwargs:  List of additional keyworded arguments to be passed into the VSGSolution.\n        :return: A valid VSGSolution instance if succesful; None otherwise.\n        \"\"\"\n        if section not in config:\n            raise ValueError('Section [{}] not found in [{}]'.format(section, ', '.join(config.sections())))\n\n        s = VSGSolution(**kwargs)\n\n        s.Name = config.get(section, 'name', fallback=s.Name)\n        s.FileName = os.path.normpath(config.get(section, 'filename', fallback=s.FileName))\n        s.VSVersion = config.getfloat(section, 'visual_studio_version', fallback=s.VSVersion)\n        if not s.VSVersion:\n            raise ValueError('Solution section [%s] requires a value for Visual Studio Version (visual_studio_version)' % section)\n\n        project_sections = config.getlist(section, 'projects', fallback=[])\n        for project_section in project_sections:\n            project = self._getproject(config, project_section, VSVersion=s.VSVersion)\n            s.Projects.append(project)\n\n        return s", "label": 1}
{"code": "func (s *CA) DeleteCertAuthority(id services.CertAuthID) error {\n\tif err := id.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t// when removing a services.CertAuthority also remove any deactivated\n\t// services.CertAuthority as well if they exist.\n\terr := s.Delete(context.TODO(), backend.Key(authoritiesPrefix, deactivatedPrefix, string(id.Type), id.DomainName))\n\tif err != nil {\n\t\tif !trace.IsNotFound(err) {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\terr = s.Delete(context.TODO(), backend.Key(authoritiesPrefix, string(id.Type), id.DomainName))\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function grid(): array\n    {\n        return [\n            TD::set('id', 'ID')\n                ->align(TD::ALIGN_CENTER)\n                ->width('100px')\n                ->filter('numeric')\n                ->sort()\n                ->linkPost(),\n\n            TD::set('name', 'Name')\n                ->width('250px')\n                ->locale()\n                ->column('content.name')\n                ->filter('text')\n                ->sort()\n                ->linkPost('name'),\n\n            TD::set('status')\n                ->sort(),\n\n            TD::set('phone', 'Phone')\n                ->locale()\n                ->column('content.phone')\n                ->filter('text')\n                ->linkPost('phone'),\n\n            TD::set('publish_at', 'Date of publication')\n                ->filter('date')\n                ->sort()\n                ->align(TD::ALIGN_RIGHT)\n                ->render(function ($item) {\n                    return optional($item->publish_at)->toDateString();\n                }),\n\n            TD::set('created_at', 'Date of creation')\n                ->filter('date')\n                ->align(TD::ALIGN_RIGHT)\n                ->sort()\n                ->render(function ($item) {\n                    return $item->created_at->toDateString();\n                }),\n        ];\n    }", "label": 2}
{"code": "public static responderpolicylabel_stats get(nitro_service service, String labelname) throws Exception{\n\t\tresponderpolicylabel_stats obj = new responderpolicylabel_stats();\n\t\tobj.set_labelname(labelname);\n\t\tresponderpolicylabel_stats response = (responderpolicylabel_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void addIterator(OJBIterator iterator)\r\n    {\r\n        /**\r\n         * only add iterators that are not null and non-empty.\r\n         */\r\n        if (iterator != null)\r\n        {\r\n            if (iterator.hasNext())\r\n            {\r\n                setNextIterator();\r\n                m_rsIterators.add(iterator);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "protected function isSortReadOnly(CommandInterface $command)\n    {\n        $arguments = $command->getArguments();\n        $argc = count($arguments);\n\n        if ($argc > 1) {\n            for ($i = 1; $i < $argc; ++$i) {\n                $argument = strtoupper($arguments[$i]);\n                if ($argument === 'STORE') {\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }", "label": 2}
{"code": "function _parse(type, obj, options)\n{\n    if (!obj) return _checkResult(type, lib.newError(\"empty \" + type), obj, options);\n    try {\n        obj = _parseResult(type, obj, options);\n    } catch(err) {\n        obj = _checkResult(type, err, obj, options);\n    }\n    return obj;\n}", "label": 3}
{"code": "func (s *handler) ok(w http.ResponseWriter, val ...interface{}) {\n\tw.WriteHeader(http.StatusOK)\n\n\tif len(val) == 0 {\n\t\treturn\n\t}\n\n\terr := json.NewEncoder(w).Encode(struct {\n\t\tValue interface{} `json:\"value,omitempty\"`\n\t}{\n\t\tval[0],\n\t})\n\n\tif err != nil {\n\t\tlog.Panic(err)\n\t}\n}", "label": 5}
{"code": "public function setSchedule($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Schedule::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static function getTagClassName($tag)\n\t{\n\t\tstatic $map = [\n\t\t\t'BARCODE' => 'BarCode',\n\t\t\t'BLOCKQUOTE' => 'BlockQuote',\n\t\t\t'COLUMN_BREAK' => 'ColumnBreak',\n\t\t\t'COLUMNBREAK' => 'ColumnBreak',\n\t\t\t'DOTTAB' => 'DotTab',\n\t\t\t'FIELDSET' => 'FieldSet',\n\t\t\t'FIGCAPTION' => 'FigCaption',\n\t\t\t'FORMFEED' => 'FormFeed',\n\t\t\t'HGROUP' => 'HGroup',\n\t\t\t'INDEXENTRY' => 'IndexEntry',\n\t\t\t'INDEXINSERT' => 'IndexInsert',\n\t\t\t'NEWCOLUMN' => 'NewColumn',\n\t\t\t'NEWPAGE' => 'NewPage',\n\t\t\t'PAGEFOOTER' => 'PageFooter',\n\t\t\t'PAGEHEADER' => 'PageHeader',\n\t\t\t'PAGE_BREAK' => 'PageBreak',\n\t\t\t'PAGEBREAK' => 'PageBreak',\n\t\t\t'SETHTMLPAGEFOOTER' => 'SetHtmlPageFooter',\n\t\t\t'SETHTMLPAGEHEADER' => 'SetHtmlPageHeader',\n\t\t\t'SETPAGEFOOTER' => 'SetPageFooter',\n\t\t\t'SETPAGEHEADER' => 'SetPageHeader',\n\t\t\t'TBODY' => 'TBody',\n\t\t\t'TFOOT' => 'TFoot',\n\t\t\t'THEAD' => 'THead',\n\t\t\t'TEXTAREA' => 'TextArea',\n\t\t\t'TEXTCIRCLE' => 'TextCircle',\n\t\t\t'TOCENTRY' => 'TocEntry',\n\t\t\t'TOCPAGEBREAK' => 'TocPageBreak',\n\t\t\t'VAR' => 'VarTag',\n\t\t\t'WATERMARKIMAGE' => 'WatermarkImage',\n\t\t\t'WATERMARKTEXT' => 'WatermarkText',\n\t\t];\n\n\t\t$className = 'Mpdf\\Tag\\\\';\n\t\t$className .= isset($map[$tag]) ? $map[$tag] : ucfirst(strtolower($tag));\n\n\t\treturn $className;\n\t}", "label": 2}
{"code": "def respth2ck(argv=None):\n    \"\"\"Command-line entry point for converting a ReSpecTh XML file to a ChemKED YAML file.\n    \"\"\"\n    parser = ArgumentParser(\n        description='Convert a ReSpecTh XML file to a ChemKED YAML file.'\n        )\n    parser.add_argument('-i', '--input',\n                        type=str,\n                        required=True,\n                        help='Input filename (e.g., \"file1.yaml\")'\n                        )\n    parser.add_argument('-o', '--output',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='Output filename (e.g., \"file1.xml\")'\n                        )\n    parser.add_argument('-fa', '--file-author',\n                        dest='file_author',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='File author name to override original'\n                        )\n    parser.add_argument('-fo', '--file-author-orcid',\n                        dest='file_author_orcid',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='File author ORCID'\n                        )\n\n    args = parser.parse_args(argv)\n\n    filename_ck = args.output\n    filename_xml = args.input\n\n    properties = ReSpecTh_to_ChemKED(filename_xml, args.file_author, args.file_author_orcid,\n                                     validate=True)\n\n    # set output filename and path\n    if not filename_ck:\n        filename_ck = os.path.join(os.path.dirname(filename_xml),\n                                   os.path.splitext(os.path.basename(filename_xml))[0] + '.yaml'\n                                   )\n\n    with open(filename_ck, 'w') as outfile:\n        yaml.dump(properties, outfile, default_flow_style=False)\n    print('Converted to ' + filename_ck)", "label": 1}
{"code": "public boolean hasNullPKField(ClassDescriptor cld, Object obj)\r\n    {\r\n        FieldDescriptor[] fields = cld.getPkFields();\r\n        boolean hasNull = false;\r\n        // an unmaterialized proxy object can never have nullified PK's\r\n        IndirectionHandler handler = ProxyHelper.getIndirectionHandler(obj);\r\n        if(handler == null || handler.alreadyMaterialized())\r\n        {\r\n            if(handler != null) obj = handler.getRealSubject();\r\n            FieldDescriptor fld;\r\n            for(int i = 0; i < fields.length; i++)\r\n            {\r\n                fld = fields[i];\r\n                hasNull = representsNull(fld, fld.getPersistentField().get(obj));\r\n                if(hasNull) break;\r\n            }\r\n        }\r\n        return hasNull;\r\n    }", "label": 0}
{"code": "func (m HostCertificateManager) ListCACertificateRevocationLists(ctx context.Context) ([]string, error) {\n\treq := types.ListCACertificateRevocationLists{\n\t\tThis: m.Reference(),\n\t}\n\n\tres, err := methods.ListCACertificateRevocationLists(ctx, m.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn res.Returnval, nil\n}", "label": 5}
{"code": "function forAsync(items, iter, callback) {\n\tvar keys = Object.keys(items);\n\tvar step = function (err, callback) {\n\t\tnextTick(function () {\n\t\t\tif (err) {\n\t\t\t\treturn callback(err);\n\t\t\t}\n\t\t\tif (keys.length === 0) {\n\t\t\t\treturn callback();\n\t\t\t}\n\t\t\tvar key = keys.pop();\n\t\t\titer(items[key], key, function (err) {\n\t\t\t\tstep(err, callback);\n\t\t\t});\n\t\t});\n\t};\n\tstep(null, callback);\n}", "label": 3}
{"code": "function( entireComponent ) {\n\n                // Insert a new component holder in the root or box.\n                if ( entireComponent ) P.$root.html( createWrappedComponent() )\n                else P.$root.find( '.' + CLASSES.box ).html( P.component.nodes( STATE.open ) )\n\n                // Trigger the queued \u201crender\u201d events.\n                return P.trigger( 'render' )\n            }", "label": 3}
{"code": "func (cn *connection) allStats(f func(*ConnStats)) {\n\tf(&cn.stats)\n\tif cn.reconciledHandshakeStats {\n\t\tcn.postHandshakeStats(f)\n\t}\n}", "label": 5}
{"code": "function apiAuthorizer (args, ctx, acl) {\n    const { token = {}, groups } = ctx;\n    const { groups: tokenGroups = [] } = token;\n\n    if (typeof acl === 'function') {\n        return acl(args, ctx);\n    }\n\n    let check = groups;\n    if (Array.isArray(acl)) {\n        check = [...groups, ...acl];\n    }\n\n    return tokenGroups.some(g => check.includes(g.group));\n}", "label": 3}
{"code": "def check(domain, prefix, code, strategies='*'):\n    \"\"\"\n    Check the ownership of a domain by going thru a serie of strategies.\n    If at least one strategy succeed, the domain is considered verified,\n    and this methods returns true.\n\n    The prefix is a fixed DNS safe string like \"yourservice-domain-verification\"\n    and the code is a random value associated to this domain. It is advised to\n    prefix the code by a fixed value that is unique to your service like\n    \"yourservice2k3dWdk9dwz\".\n\n    By default all available strategies are tested. You can limit the check\n    to a limited set of strategies by passing a comma separated list of\n    strategy names like \"nds_txt,dns_cname\". See the \"strategies\" module\n    for a full list of avaialble strategies.\n    \"\"\"\n    if strategies == '*' or 'dns_txt' in strategies:\n        if check_dns_txt(domain, prefix, code):\n            return True\n    if strategies == '*' or 'dns_cname' in strategies:\n        if check_dns_cname(domain, prefix, code):\n            return True\n    if strategies == '*' or 'meta_tag' in strategies:\n        if check_meta_tag(domain, prefix, code):\n            return True\n    if strategies == '*' or 'html_file' in strategies:\n        if check_html_file(domain, prefix, code):\n            return True\n    return False", "label": 1}
{"code": "func OptionOriginResolvConfPath(path string) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tsb.config.originResolvConfPath = path\n\t}\n}", "label": 5}
{"code": "public static crvserver_binding get(nitro_service service, String name) throws Exception{\n\t\tcrvserver_binding obj = new crvserver_binding();\n\t\tobj.set_name(name);\n\t\tcrvserver_binding response = (crvserver_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (c *Config) ProcessOptions(options ...Option) {\n\tfor _, opt := range options {\n\t\tif opt != nil {\n\t\t\topt(c)\n\t\t}\n\t}\n}", "label": 5}
{"code": "@Override\n\tpublic Result getResult() throws Exception {\n\t\tResult returnResult = result;\n\n\t\t// If we've chained to other Actions, we need to find the last result\n\t\twhile (returnResult instanceof ActionChainResult) {\n\t\t\tActionProxy aProxy = ((ActionChainResult) returnResult).getProxy();\n\n\t\t\tif (aProxy != null) {\n\t\t\t\tResult proxyResult = aProxy.getInvocation().getResult();\n\n\t\t\t\tif ((proxyResult != null) && (aProxy.getExecuteResult())) {\n\t\t\t\t\treturnResult = proxyResult;\n\t\t\t\t} else {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\treturn returnResult;\n\t}", "label": 0}
{"code": "func SandboxContainerWalker(out *Sandbox, containerID string) SandboxWalker {\n\treturn func(sb Sandbox) bool {\n\t\tif sb.ContainerID() == containerID {\n\t\t\t*out = sb\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}\n}", "label": 5}
{"code": "def _add_and_commit(self, doc_filepath, author, commit_msg):\n        \"\"\"Low level function used internally when you have an absolute filepath to add and commit\"\"\"\n        try:\n            git(self.gitdir, self.gitwd, \"add\", doc_filepath)\n            git(self.gitdir, self.gitwd, \"commit\", author=author, message=commit_msg)\n        except Exception as e:\n            # We can ignore this if no changes are new,\n            # otherwise raise a 400\n            if \"nothing to commit\" in e.message:  # @EJM is this dangerous?\n                _LOG.debug('\"nothing to commit\" found in error response')\n            else:\n                _LOG.exception('\"git commit\" failed')\n                self.reset_hard()\n                raise", "label": 1}
{"code": "func AsBool(v string) bool {\n\tif v == \"\" {\n\t\treturn false\n\t}\n\tout, _ := ParseBool(v)\n\treturn out\n}", "label": 5}
{"code": "private void prepareInitialState(boolean isNewObject)\r\n    {\r\n        // determine appropriate modification state\r\n        ModificationState initialState;\r\n        if(isNewObject)\r\n        {\r\n            // if object is not already persistent it must be marked as new\r\n            // it must be marked as dirty because it must be stored even if it will not modified during tx\r\n            initialState = StateNewDirty.getInstance();\r\n        }\r\n        else if(isDeleted(oid))\r\n        {\r\n            // if object is already persistent it will be marked as old.\r\n            // it is marked as dirty as it has been deleted during tx and now it is inserted again,\r\n            // possibly with new field values.\r\n            initialState = StateOldDirty.getInstance();\r\n        }\r\n        else\r\n        {\r\n            // if object is already persistent it will be marked as old.\r\n            // it is marked as clean as it has not been modified during tx already\r\n            initialState = StateOldClean.getInstance();\r\n        }\r\n        // remember it:\r\n        modificationState = initialState;\r\n    }", "label": 0}
{"code": "public static appfwlearningsettings[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tappfwlearningsettings obj = new appfwlearningsettings();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tappfwlearningsettings[] response = (appfwlearningsettings[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (k *Keygen) precomputeKeys() {\n\tfor {\n\t\tprivPem, pubBytes, err := GenerateKeyPair(\"\")\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"Unable to generate key pair: %v.\", err)\n\t\t\tcontinue\n\t\t}\n\t\tkey := keyPair{\n\t\t\tprivPem:  privPem,\n\t\t\tpubBytes: pubBytes,\n\t\t}\n\n\t\tselect {\n\t\tcase <-k.ctx.Done():\n\t\t\tlog.Infof(\"Stopping key precomputation routine.\")\n\t\t\treturn\n\t\tcase k.keysCh <- key:\n\t\t\tcontinue\n\t\t}\n\t}\n}", "label": 5}
{"code": "public static function clusterName($project, $instance, $cluster)\n    {\n        return self::getClusterNameTemplate()->render([\n            'project' => $project,\n            'instance' => $instance,\n            'cluster' => $cluster,\n        ]);\n    }", "label": 2}
{"code": "def add_crosshair_to_image(fname, opFilename):\n    \"\"\" convert an image by adding a cross hair \"\"\"\n    im = Image.open(fname)\n    draw = ImageDraw.Draw(im)\n    draw.line((0, 0) + im.size, fill=(255, 255, 255))\n    draw.line((0, im.size[1], im.size[0], 0), fill=(255, 255, 255))\n    del draw  \n    im.save(opFilename)", "label": 1}
{"code": "public static inat get(nitro_service service, String name) throws Exception{\n\t\tinat obj = new inat();\n\t\tobj.set_name(name);\n\t\tinat response = (inat) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function skipAtomic(doc, pos, bias, mayClear) {\n    var flipped = false, curPos = pos;\n    var dir = bias || 1;\n    doc.cantEdit = false;\n    search: for (;;) {\n      var line = getLine(doc, curPos.line);\n      if (line.markedSpans) {\n        for (var i = 0; i < line.markedSpans.length; ++i) {\n          var sp = line.markedSpans[i], m = sp.marker;\n          if ((sp.from == null || (m.inclusiveLeft ? sp.from <= curPos.ch : sp.from < curPos.ch)) &&\n              (sp.to == null || (m.inclusiveRight ? sp.to >= curPos.ch : sp.to > curPos.ch))) {\n            if (mayClear) {\n              signal(m, \"beforeCursorEnter\");\n              if (m.explicitlyCleared) {\n                if (!line.markedSpans) break;\n                else {--i; continue;}\n              }\n            }\n            if (!m.atomic) continue;\n            var newPos = m.find(dir < 0 ? -1 : 1);\n            if (cmp(newPos, curPos) == 0) {\n              newPos.ch += dir;\n              if (newPos.ch < 0) {\n                if (newPos.line > doc.first) newPos = clipPos(doc, Pos(newPos.line - 1));\n                else newPos = null;\n              } else if (newPos.ch > line.text.length) {\n                if (newPos.line < doc.first + doc.size - 1) newPos = Pos(newPos.line + 1, 0);\n                else newPos = null;\n              }\n              if (!newPos) {\n                if (flipped) {\n                  // Driven in a corner -- no valid cursor position found at all\n                  // -- try again *with* clearing, if we didn't already\n                  if (!mayClear) return skipAtomic(doc, pos, bias, true);\n                  // Otherwise, turn off editing until further notice, and return the start of the doc\n                  doc.cantEdit = true;\n                  return Pos(doc.first, 0);\n                }\n                flipped = true; newPos = pos; dir = -dir;\n              }\n            }\n            curPos = newPos;\n            continue search;\n          }\n        }\n      }\n      return curPos;\n    }\n  }", "label": 3}
{"code": "function submissionToPDF(params, cb) {\n  logger.debug(\"renderPDF submissionToPDF\", params);\n  params = params || {};\n\n  var maxConcurrentPhantomPerWorker = params.maxConcurrentPhantomPerWorker || config.get().maxConcurrentPhantomPerWorker;\n\n  if (!params.submission || !params.submission.formSubmittedAgainst || !params.options || !params.options.location) {\n    return cb(\"Invalid Submission Data. Expected a submission and location parameter.\");\n  }\n\n  pdfGenerationQueue = pdfGenerationQueue || createPDFGenerationQueue(maxConcurrentPhantomPerWorker);\n\n  //Adding the export task to the queue\n  pdfGenerationQueue.push(params, cb);\n}", "label": 3}
{"code": "func (nDB *NetworkDB) changeNodeState(nodeName string, newState nodeState) (bool, error) {\n\tn, currState, m := nDB.findNode(nodeName)\n\tif n == nil {\n\t\treturn false, fmt.Errorf(\"node %s not found\", nodeName)\n\t}\n\n\tswitch newState {\n\tcase nodeActiveState:\n\t\tif currState == nodeActiveState {\n\t\t\treturn false, nil\n\t\t}\n\n\t\tdelete(m, nodeName)\n\t\t// reset the node reap time\n\t\tn.reapTime = 0\n\t\tnDB.nodes[nodeName] = n\n\tcase nodeLeftState:\n\t\tif currState == nodeLeftState {\n\t\t\treturn false, nil\n\t\t}\n\n\t\tdelete(m, nodeName)\n\t\tnDB.leftNodes[nodeName] = n\n\tcase nodeFailedState:\n\t\tif currState == nodeFailedState {\n\t\t\treturn false, nil\n\t\t}\n\n\t\tdelete(m, nodeName)\n\t\tnDB.failedNodes[nodeName] = n\n\t}\n\n\tlogrus.Infof(\"Node %s change state %s --> %s\", nodeName, nodeStateName[currState], nodeStateName[newState])\n\n\tif newState == nodeLeftState || newState == nodeFailedState {\n\t\t// set the node reap time, if not already set\n\t\t// It is possible that a node passes from failed to left and the reaptime was already set so keep that value\n\t\tif n.reapTime == 0 {\n\t\t\tn.reapTime = nodeReapInterval\n\t\t}\n\t\t// The node leave or fails, delete all the entries created by it.\n\t\t// If the node was temporary down, deleting the entries will guarantee that the CREATE events will be accepted\n\t\t// If the node instead left because was going down, then it makes sense to just delete all its state\n\t\tnDB.deleteNodeFromNetworks(n.Name)\n\t\tnDB.deleteNodeTableEntries(n.Name)\n\t}\n\n\treturn true, nil\n}", "label": 5}
{"code": "public ArrayList<IntPoint> process(ImageSource fastBitmap) {\r\n        //FastBitmap l = new FastBitmap(fastBitmap);\r\n        if (points == null) {\r\n            apply(fastBitmap);\r\n        }\r\n\r\n        int width = fastBitmap.getWidth();\r\n        int height = fastBitmap.getHeight();\r\n        points = new ArrayList<IntPoint>();\r\n\r\n        if (fastBitmap.isGrayscale()) {\r\n            for (int x = 0; x < height; x++) {\r\n                for (int y = 0; y < width; y++) {\r\n                    if (fastBitmap.getRGB(y, x) == 255) points.add(new IntPoint(y, x));\r\n                }\r\n            }\r\n        } else {\r\n            for (int x = 0; x < height; x++) {\r\n                for (int y = 0; y < width; y++) {\r\n                    // TODO Check for green and blue?\r\n                    if (fastBitmap.getR(y, x) == 255) points.add(new IntPoint(y, x));\r\n                }\r\n            }\r\n        }\r\n\r\n        return points;\r\n    }", "label": 0}
{"code": "public void checkpoint(ObjectEnvelope mod)\r\n            throws org.apache.ojb.broker.PersistenceBrokerException\r\n    {\r\n        mod.doUpdate();\r\n    }", "label": 0}
{"code": "def scheme=(new_scheme)\n      if new_scheme && !new_scheme.respond_to?(:to_str)\n        raise TypeError, \"Can't convert #{new_scheme.class} into String.\"\n      elsif new_scheme\n        new_scheme = new_scheme.to_str\n      end\n      if new_scheme && new_scheme !~ /\\A[a-z][a-z0-9\\.\\+\\-]*\\z/i\n        raise InvalidURIError, \"Invalid scheme format: #{new_scheme}\"\n      end\n      @scheme = new_scheme\n      @scheme = nil if @scheme.to_s.strip.empty?\n\n      # Reset dependent values\n      remove_instance_variable(:@normalized_scheme) if defined?(@normalized_scheme)\n      remove_composite_values\n\n      # Ensure we haven't created an invalid URI\n      validate()\n    end", "label": 4}
{"code": "public function setSupportedBy($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::ENUM, \\Google\\Cloud\\Dlp\\V2\\InfoTypeSupportedBy::class);\n        $this->supported_by = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def sort(input, property = nil)\n      ary = InputIterator.new(input)\n\n      return [] if ary.empty?\n\n      if property.nil?\n        ary.sort do |a, b|\n          nil_safe_compare(a, b)\n        end\n      elsif ary.all? { |el| el.respond_to?(:[]) }\n        begin\n          ary.sort { |a, b| nil_safe_compare(a[property], b[property]) }\n        rescue TypeError\n          raise_property_error(property)\n        end\n      end\n    end", "label": 4}
{"code": "def verify_notification(data):\n    \"\"\"\n    Function to verify notification came from a trusted source\n\n    Returns True if verfied, False if not verified\n    \"\"\"\n    pemfile = grab_keyfile(data['SigningCertURL'])\n    cert = crypto.load_certificate(crypto.FILETYPE_PEM, pemfile)\n    signature = base64.decodestring(six.b(data['Signature']))\n\n    if data['Type'] == \"Notification\":\n        hash_format = NOTIFICATION_HASH_FORMAT\n    else:\n        hash_format = SUBSCRIPTION_HASH_FORMAT\n\n    try:\n        crypto.verify(\n            cert, signature, six.b(hash_format.format(**data)), 'sha1')\n    except crypto.Error:\n        return False\n    return True", "label": 1}
{"code": "def add_constraint(self, name, tpe, val):\n        \"\"\"\n        adds a constraint for the plan\n        \"\"\"\n        self.constraint.append([name, tpe, val])", "label": 1}
{"code": "public function getRepository()\n    {\n        $repositoryGenerator = new RepositoryInterfaceGenerator([\n            'name' => $this->name,\n        ]);\n\n        $repository = $repositoryGenerator->getRootNamespace() . '\\\\' . $repositoryGenerator->getName();\n\n        return 'use ' . str_replace([\n            \"\\\\\",\n            '/'\n        ], '\\\\', $repository) . 'Repository;';\n    }", "label": 2}
{"code": "function(apiClient) {\n    this.apiClient = apiClient || ApiClient.instance;\n\n\n\n    /**\n     * Find organization\n     * Find organization\n     * @param {String} organizationId organization id\n     * @return {Promise} a {@link https://www.promisejs.org/|Promise}, with data of type {@link module:model/Organization}\n     */\n    this.findOrganization = function(organizationId) {\n      var postBody = null;\n\n      // verify the required parameter 'organizationId' is set\n      if (organizationId == undefined || organizationId == null) {\n        throw \"Missing the required parameter 'organizationId' when calling findOrganization\";\n      }\n\n\n      var pathParams = {\n        'organizationId': organizationId\n      };\n      var queryParams = {\n      };\n      var headerParams = {\n      };\n      var formParams = {\n      };\n\n      var authNames = ['basicAuth'];\n      var contentTypes = ['application/json;charset=utf-8'];\n      var accepts = ['application/json;charset=utf-8'];\n      var returnType = Organization;\n\n      return this.apiClient.callApi(\n        '/organizations/{organizationId}', 'GET',\n        pathParams, queryParams, headerParams, formParams, postBody,\n        authNames, contentTypes, accepts, returnType\n      );\n    }\n\n\n    /**\n     * List organizations\n     * List organizations\n     * @param {Object} opts Optional parameters\n     * @param {String} opts.businessName Filter by organization&#39;s business name\n     * @param {String} opts.businessCode Filter by organization&#39;s business code\n     * @param {String} opts.search Search organizations by free-text query\n     * @param {String} opts.sortBy define order (NATURAL or SCORE). Default is NATURAL\n     * @param {String} opts.sortDir ASC or DESC. Default is ASC\n     * @param {Integer} opts.firstResult First result\n     * @param {Integer} opts.maxResults Max results\n     * @return {Promise} a {@link https://www.promisejs.org/|Promise}, with data of type {@link Array.<module:model/Organization>}\n     */\n    this.listOrganizations = function(opts) {\n      opts = opts || {};\n      var postBody = null;\n\n\n      var pathParams = {\n      };\n      var queryParams = {\n        'businessName': opts['businessName'],\n        'businessCode': opts['businessCode'],\n        'search': opts['search'],\n        'sortBy': opts['sortBy'],\n        'sortDir': opts['sortDir'],\n        'firstResult': opts['firstResult'],\n        'maxResults': opts['maxResults']\n      };\n      var headerParams = {\n      };\n      var formParams = {\n      };\n\n      var authNames = ['basicAuth'];\n      var contentTypes = ['application/json;charset=utf-8'];\n      var accepts = ['application/json;charset=utf-8'];\n      var returnType = [Organization];\n\n      return this.apiClient.callApi(\n        '/organizations', 'GET',\n        pathParams, queryParams, headerParams, formParams, postBody,\n        authNames, contentTypes, accepts, returnType\n      );\n    }\n  }", "label": 3}
{"code": "def calc_pident_ignore_gaps(a, b):\n    \"\"\"\n    calculate percent identity\n    \"\"\"\n    m = 0 # matches\n    mm = 0 # mismatches\n    for A, B in zip(list(a), list(b)):\n        if A == '-' or A == '.' or B == '-' or B == '.':\n            continue\n        if A == B:\n            m += 1\n        else:\n            mm += 1\n    try:\n        return float(float(m)/float((m + mm))) * 100\n    except:\n        return 0", "label": 1}
{"code": "def logger(logger, level = :info, format = :apache)\n      default_options[:logger]     = logger\n      default_options[:log_level]  = level\n      default_options[:log_format] = format\n    end", "label": 4}
{"code": "public function setType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dlp\\V2\\ByteContentItem_BytesType::class);\n        $this->type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def _call_migrate(self, module, connection_param):\n        \"\"\"Subclasses should call this method instead of `module.migrate` directly,\n        to support `db_config` optional argument.\n        \"\"\"\n        args = [connection_param]\n        spec = inspect.getargspec(module.migrate)\n        if len(spec.args) == 2:\n            args.append(self.db_config)\n        return module.migrate(*args)", "label": 1}
{"code": "def run_filter_radia(job, bams, radia_file, univ_options, radia_options, chrom):\n    \"\"\"\n    Run filterradia on the RADIA output.\n\n    :param dict bams: Dict of bam and bai for tumor DNA-Seq, normal DNA-Seq and tumor RNA-Seq\n    :param toil.fileStore.FileID radia_file: The vcf from runnning RADIA\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict radia_options: Options specific to RADIA\n    :param str chrom: Chromosome to process\n    :return: fsID for the filtered chromsome vcf\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'rna.bam': bams['tumor_rna'],\n        'rna.bam.bai': bams['tumor_rnai'],\n        'tumor.bam': bams['tumor_dna'],\n        'tumor.bam.bai': bams['tumor_dnai'],\n        'normal.bam': bams['normal_dna'],\n        'normal.bam.bai': bams['normal_dnai'],\n        'radia.vcf': radia_file,\n        'genome.fa.tar.gz': radia_options['genome_fasta'],\n        'genome.fa.fai.tar.gz': radia_options['genome_fai'],\n        'cosmic_beds': radia_options['cosmic_beds'],\n        'dbsnp_beds': radia_options['dbsnp_beds'],\n        'retrogene_beds': radia_options['retrogene_beds'],\n        'pseudogene_beds': radia_options['pseudogene_beds'],\n        'gencode_beds': radia_options['gencode_beds']\n    }\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n\n    for key in ('genome.fa', 'genome.fa.fai'):\n        input_files[key] = untargz(input_files[key + '.tar.gz'], work_dir)\n    for key in ('cosmic_beds', 'dbsnp_beds', 'retrogene_beds', 'pseudogene_beds', 'gencode_beds'):\n        input_files[key] = untargz(input_files[key], work_dir)\n\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    filterradia_log = ''.join([work_dir, '/radia_filtered_', chrom, '_radia.log'])\n    parameters = [univ_options['patient'],  # shortID\n                  chrom.lstrip('chr'),\n                  input_files['radia.vcf'],\n                  '/data',\n                  '/home/radia/scripts',\n                  '-d', input_files['dbsnp_beds'],\n                  '-r', input_files['retrogene_beds'],\n                  '-p', input_files['pseudogene_beds'],\n                  '-c', input_files['cosmic_beds'],\n                  '-t', input_files['gencode_beds'],\n                  '--noSnpEff',\n                  '--noBlacklist',\n                  '--noTargets',\n                  '--noRnaBlacklist',\n                  '-f', input_files['genome.fa'],\n                  '--log=INFO',\n                  '-g', docker_path(filterradia_log)]\n    docker_call(tool='filterradia',\n                tool_parameters=parameters, work_dir=work_dir, dockerhub=univ_options['dockerhub'],\n                tool_version=radia_options['version'])\n    output_file = ''.join([work_dir, '/', chrom, '.vcf'])\n    os.rename(''.join([work_dir, '/', univ_options['patient'], '_', chrom, '.vcf']), output_file)\n    output_fsid = job.fileStore.writeGlobalFile(output_file)\n    export_results(job, output_fsid, output_file, univ_options, subfolder='mutations/radia')\n    job.fileStore.logToMaster('Ran filter-radia on %s:%s successfully'\n                              % (univ_options['patient'], chrom))\n    return output_fsid", "label": 1}
{"code": "def load_variables():\n    \"\"\"Load variables from environment variables.\"\"\"\n    if (not os.environ.get(\"PYCONFLUENCE_TOKEN\") or\n            not os.environ.get(\"PYCONFLUENCE_USER\") or\n            not os.environ.get(\"PYCONFLUENCE_ORG\")):\n        print (\"One or more pyconfluence environment variables are not set. \"\n               \"See README for directions on how to resolve this.\")\n        sys.exit(\"Error\")\n\n    global token\n    global user\n    global base_url\n    token = os.environ[\"PYCONFLUENCE_TOKEN\"]\n    user = os.environ[\"PYCONFLUENCE_USER\"]\n    base_url = (\"https://\" + os.environ[\"PYCONFLUENCE_ORG\"] + \".atlassian\"\n                \".net/wiki/rest/api/content\")", "label": 1}
{"code": "def bf(items, targets, **kwargs):\n    \"\"\"Best-Fit\n\n    Complexity O(n^2)\n    \"\"\"\n    bins = [(target, []) for target in targets]\n    skip = []\n\n    for item in items:\n        containers = []\n        capacities = []\n        for target, content in bins:\n            capacity = target - sum(content)\n            if item <= capacity:\n                containers.append(content)\n                capacities.append(capacity - item)\n\n        if len(capacities):\n            weighted = zip(containers, weight(capacities, **kwargs))\n            content, _ = min(weighted, key=operator.itemgetter(1))\n            content.append(item)\n        else:\n            skip.append(item)\n    return bins, skip", "label": 1}
{"code": "public function setAnnotation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Trace\\V2\\Span_TimeEvent_Annotation::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def remove_namespace(self, ns_uri):\n        \"\"\"Removes the indicated namespace from this set.\"\"\"\n        if not self.contains_namespace(ns_uri):\n            return\n\n        ni = self.__ns_uri_map.pop(ns_uri)\n        for prefix in ni.prefixes:\n            del self.__prefix_map[prefix]", "label": 1}
{"code": "function() {\n      var oldViews = this.getItemViews();\n      var newViews = this.__createItemViews();\n      var staleViews = this.__getStaleItemViews();\n      var sizeOfOldViews = _.size(oldViews);\n      var sizeOfNewViews = _.size(newViews);\n      var sizeOfStaleViews = _.size(staleViews);\n      var sizeOfFinalViews = sizeOfOldViews - sizeOfStaleViews + sizeOfNewViews;\n      var changes = sizeOfNewViews + sizeOfStaleViews;\n      var percentChange = changes / Math.max(sizeOfFinalViews, 1);\n      var fromEmptyToNotEmpty = !sizeOfOldViews && sizeOfNewViews;\n      var fromNotEmptyToEmpty = sizeOfOldViews && sizeOfOldViews === sizeOfStaleViews && !sizeOfNewViews;\n      var threshold = this.updateThreshold || 0.5;\n      var signficantChanges = percentChange >= threshold;\n      if (changes <= 0) {\n        return this.reorder();\n      }\n      // A switch from empty to not empty or vise versa, needs a new render\n      var renderNeeded = fromEmptyToNotEmpty || fromNotEmptyToEmpty || signficantChanges;\n      if (renderNeeded) {\n        this.__removeStaleItemViews(staleViews);\n        this.__delayedRender();\n      } else {\n        this.__updateByAddingRemoving(oldViews, newViews, staleViews);\n      }\n    }", "label": 3}
{"code": "function getDefaultValue(entity) {\n  expect(arguments).to.have.length(\n    1,\n    'Invalid arguments length when getting the default value of an Attribute ' +\n    'to an Entity instance (it has to be given 1 argument)'\n  );\n\n  expect(entity).to.be.an.instanceOf(\n    models.Entity,\n    'Invalid type of argument \"entity\" when getting the default value of an ' +\n    'Attribute to an Entity instance (it has to be an Entity)'\n  );\n\n  if (typeof this.default === 'function') {\n    return this.default.call(entity);\n  } else {\n    return this.default;\n  }\n}", "label": 3}
{"code": "protected function resolveRelationColumn($column)\n    {\n        $parts      = explode('.', $column);\n        $columnName = array_pop($parts);\n        $relation   = implode('.', $parts);\n\n        if ($this->isNotEagerLoaded($relation)) {\n            return $column;\n        }\n\n        return $this->joinEagerLoadedColumn($relation, $columnName);\n    }", "label": 2}
{"code": "public function setCurrentVersion($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\StoredInfoTypeVersion::class);\n        $this->current_version = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (g GridType) X(dataX float64) float64 {\n\treturn g.xm*dataX + g.xb\n}", "label": 5}
{"code": "public function setLabels($var)\n    {\n        $arr = GPBUtil::checkMapField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->labels = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function recordMail(MessageSent $event)\n    {\n        if (! Telescope::isRecording()) {\n            return;\n        }\n\n        Telescope::recordMail(IncomingEntry::make([\n            'mailable' => $this->getMailable($event),\n            'queued' => $this->getQueuedStatus($event),\n            'from' => $event->message->getFrom(),\n            'replyTo' => $event->message->getReplyTo(),\n            'to' => $event->message->getTo(),\n            'cc' => $event->message->getCc(),\n            'bcc' => $event->message->getBcc(),\n            'subject' => $event->message->getSubject(),\n            'html' => $event->message->getBody(),\n            'raw' => $event->message->toString(),\n        ])->tags($this->tags($event->message, $event->data)));\n    }", "label": 2}
{"code": "async def _seed2did(self) -> str:\n        \"\"\"\n        Derive DID, as per indy-sdk, from seed.\n\n        :return: DID\n        \"\"\"\n\n        rv = None\n        dids_with_meta = json.loads(await did.list_my_dids_with_meta(self.handle))  # list\n\n        if dids_with_meta:\n            for did_with_meta in dids_with_meta:  # dict\n                if 'metadata' in did_with_meta:\n                    try:\n                        meta = json.loads(did_with_meta['metadata'])\n                        if isinstance(meta, dict) and meta.get('seed', None) == self._seed:\n                            rv = did_with_meta.get('did')\n                    except json.decoder.JSONDecodeError:\n                        continue  # it's not one of ours, carry on\n\n        if not rv:  # seed not in metadata, generate did again on temp wallet\n            temp_wallet = await Wallet(\n                self._seed,\n                '{}.seed2did'.format(self.name),\n                None,\n                {'auto-remove': True}).create()\n\n            rv = temp_wallet.did\n            await temp_wallet.remove()\n\n        return rv", "label": 1}
{"code": "public function setContext($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\DevTools\\Source\\V1\\SourceContext::class);\n        $this->context = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static String pennPOSToWordnetPOS(String s) {\r\n    if (s.matches(\"NN|NNP|NNS|NNPS\")) {\r\n      return \"noun\";\r\n    }\r\n    if (s.matches(\"VB|VBD|VBG|VBN|VBZ|VBP|MD\")) {\r\n      return \"verb\";\r\n    }\r\n    if (s.matches(\"JJ|JJR|JJS|CD\")) {\r\n      return \"adjective\";\r\n    }\r\n    if (s.matches(\"RB|RBR|RBS|RP|WRB\")) {\r\n      return \"adverb\";\r\n    }\r\n    return null;\r\n  }", "label": 0}
{"code": "public static systemcore[] get(nitro_service service, systemcore_args args) throws Exception{\n\t\tsystemcore obj = new systemcore();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tsystemcore[] response = (systemcore[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _transform_coefficients(self, NN, HHw, CCw, ffparm, polycf,\n                               any_pwl, npol, nw):\n        \"\"\" Transforms quadratic coefficients for w into coefficients for x.\n        \"\"\"\n        nnw = any_pwl + npol + nw\n        M = csr_matrix((ffparm[:, 3], (range(nnw), range(nnw))))\n        MR = M * ffparm[:, 2] # FIXME: Possibly column 1.\n        HMR = HHw * MR\n        MN = M * NN\n        HH = MN.T * HHw * MN\n        CC = MN.T * (CCw - HMR)\n        # Constant term of cost.\n        C0 = 1./2. * MR.T * HMR + sum(polycf[:, 2])\n\n        return HH, CC, C0[0]", "label": 1}
{"code": "private function createDatabaseWriteOperation($type, $document, array $options = [])\n    {\n        switch ($type) {\n            case self::TYPE_UPDATE:\n                return [\n                    'update' => [\n                        'name' => $document,\n                        'fields' => $this->pluck('fields', $options)\n                    ]\n                ];\n                break;\n\n            case self::TYPE_DELETE:\n                return ['delete' => $document];\n                break;\n\n            case self::TYPE_TRANSFORM:\n                return [\n                    'transform' => [\n                        'document' => $document,\n                        'fieldTransforms' => $this->pluck('fieldTransforms', $options)\n                    ]\n                ];\n                break;\n\n            // @codeCoverageIgnoreStart\n            default:\n                throw new \\InvalidArgumentException(sprintf(\n                    'Write operation type `%s is not valid. Allowed values are update, delete, verify, transform.',\n                    $type\n                ));\n                break;\n            // @codeCoverageIgnoreEnd\n        }\n    }", "label": 2}
{"code": "func (c *Client) CheckPassword(user string, password []byte, otpToken string) error {\n\t_, err := c.PostJSON(\n\t\tc.Endpoint(\"users\", user, \"web\", \"password\", \"check\"),\n\t\tcheckPasswordReq{\n\t\t\tPassword: string(password),\n\t\t\tOTPToken: otpToken,\n\t\t})\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def download_blob_to(file) #:doc:\n        file.binmode\n        blob.download { |chunk| file.write(chunk) }\n        file.flush\n        file.rewind\n      end", "label": 4}
{"code": "def make_unique_name(base, existing=[], format=\"%s_%s\"):\n    \"\"\" Return a name, unique within a context, based on the specified name.\n\n    @param base: the desired base name of the generated unique name.\n    @param existing: a sequence of the existing names to avoid returning.\n    @param format: a formatting specification for how the name is made unique.\n    \"\"\"\n    count = 2\n    name = base\n    while name in existing:\n        name = format % (base, count)\n        count += 1\n\n    return name", "label": 1}
{"code": "def nsfw=(nsfw)\n      raise ArgumentError, 'nsfw value must be true or false' unless nsfw.is_a?(TrueClass) || nsfw.is_a?(FalseClass)\n\n      update_channel_data(nsfw: nsfw)\n    end", "label": 4}
{"code": "OTMConnection getConnection()\r\n    {\r\n        if (m_connection == null)\r\n        {\r\n            OTMConnectionRuntimeException ex = new OTMConnectionRuntimeException(\"Connection is null.\");\r\n            sendEvents(ConnectionEvent.CONNECTION_ERROR_OCCURRED, ex, null);\r\n        }\r\n        return m_connection;\r\n    }", "label": 0}
{"code": "def upload_trailer_preview(app_version, upload_trailer_preview, device)\n      raise \"app_version is required\" unless app_version\n      raise \"upload_trailer_preview is required\" unless upload_trailer_preview\n      raise \"device is required\" unless device\n\n      du_client.upload_trailer_preview(app_version, upload_trailer_preview, content_provider_id, sso_token_for_image, device)\n    end", "label": 4}
{"code": "public function documents(array $options = [])\n    {\n        $maxRetries = $this->pluck('maxRetries', $options, false);\n        $maxRetries = $maxRetries === null\n            ? FirestoreClient::MAX_RETRIES\n            : $maxRetries;\n\n        $rows = (new ExponentialBackoff($maxRetries))->execute(function () use ($options) {\n            $query = $this->finalQueryPrepare($this->query);\n            $generator = $this->connection->runQuery($this->arrayFilterRemoveNull([\n                'parent' => $this->parent,\n                'structuredQuery' => $query,\n                'retries' => 0\n            ]) + $options);\n\n            // cache collection references\n            $collections = [];\n\n            $out = [];\n            while ($generator->valid()) {\n                $result = $generator->current();\n\n                if (isset($result['document']) && $result['document']) {\n                    $collectionName = $this->parentPath($result['document']['name']);\n                    if (!isset($collections[$collectionName])) {\n                        $collections[$collectionName] = new CollectionReference(\n                            $this->connection,\n                            $this->valueMapper,\n                            $collectionName\n                        );\n                    }\n\n                    $ref = new DocumentReference(\n                        $this->connection,\n                        $this->valueMapper,\n                        $collections[$collectionName],\n                        $result['document']['name']\n                    );\n\n                    $document = $result['document'];\n                    $document['readTime'] = $result['readTime'];\n\n                    $out[] = $this->createSnapshotWithData($this->valueMapper, $ref, $document);\n                }\n\n                $generator->next();\n            }\n\n            return $out;\n        });\n\n        return new QuerySnapshot($this, $rows);\n    }", "label": 2}
{"code": "public static base_response delete(nitro_service client, nsip6 resource) throws Exception {\n\t\tnsip6 deleteresource = new nsip6();\n\t\tdeleteresource.ipv6address = resource.ipv6address;\n\t\tdeleteresource.td = resource.td;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "function(cb) {\n            log.log('git fetch origin ' + repoDir);\n            git(repoDir, ['fetch', 'origin'], function(err, stdout, stderr) {\n                if (err) {\n                    log.error('Unable to fetch at ' + repoDir + ':', err.msg);\n                }\n                cb(null, {fetch: {stdout: stdout, stderr: stderr}})\n            });\n        }", "label": 3}
{"code": "def normalize!(params)\n      case params\n      when Hash\n        params.keys.each do |k|\n          params[k.to_s] = params.delete(k)\n          normalize!(params[k.to_s])\n        end\n      when Array\n        params.map! do |el|\n          normalize!(el)\n        end\n      end\n      params\n    end", "label": 4}
{"code": "public static responderpolicy_binding get(nitro_service service, String name) throws Exception{\n\t\tresponderpolicy_binding obj = new responderpolicy_binding();\n\t\tobj.set_name(name);\n\t\tresponderpolicy_binding response = (responderpolicy_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def searchable_resource_human_name(resource, count: 5)\n      resource = if resource.is_a?(String)\n                   resource.constantize\n                 else\n                   resource\n                 end\n\n      resource.model_name.human(count: count)\n    end", "label": 4}
{"code": "def texture_floodfill(x, y, texture)\n      target = pixel_color(x, y)\n      texture_flood_fill(target, texture, x, y, FloodfillMethod)\n    end", "label": 4}
{"code": "func NewMockIndex(ctrl *gomock.Controller) *MockIndex {\n\tmock := &MockIndex{ctrl: ctrl}\n\tmock.recorder = &MockIndexMockRecorder{mock}\n\treturn mock\n}", "label": 5}
{"code": "protected void checkProxyPrefetchingLimit(DefBase def, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n        if (def.hasProperty(PropertyHelper.OJB_PROPERTY_PROXY_PREFETCHING_LIMIT))\r\n        {\r\n            if (!def.hasProperty(PropertyHelper.OJB_PROPERTY_PROXY))\r\n            {\r\n                if (def instanceof ClassDescriptorDef)\r\n                {\r\n                    LogHelper.warn(true,\r\n                                   ConstraintsBase.class,\r\n                                   \"checkProxyPrefetchingLimit\",\r\n                                   \"The class \"+def.getName()+\" has a proxy-prefetching-limit property but no proxy property\");\r\n                }\r\n                else\r\n                {    \r\n                    LogHelper.warn(true,\r\n                                   ConstraintsBase.class,\r\n                                   \"checkProxyPrefetchingLimit\",\r\n                                   \"The feature \"+def.getName()+\" in class \"+def.getOwner().getName()+\" has a proxy-prefetching-limit property but no proxy property\");\r\n                }\r\n            }\r\n    \r\n            String propValue = def.getProperty(PropertyHelper.OJB_PROPERTY_PROXY_PREFETCHING_LIMIT);\r\n    \r\n            try\r\n            {\r\n                int value = Integer.parseInt(propValue);\r\n    \r\n                if (value < 0)\r\n                {\r\n                    if (def instanceof ClassDescriptorDef)\r\n                    {\r\n                        throw new ConstraintException(\"The proxy-prefetching-limit value of class \"+def.getName()+\" must be a non-negative number\");\r\n                    }\r\n                    else\r\n                    {    \r\n                        throw new ConstraintException(\"The proxy-prefetching-limit value of the feature \"+def.getName()+\" in class \"+def.getOwner().getName()+\" must be a non-negative number\");\r\n                    }\r\n                }\r\n            }\r\n            catch (NumberFormatException ex)\r\n            {\r\n                if (def instanceof ClassDescriptorDef)\r\n                {\r\n                    throw new ConstraintException(\"The proxy-prefetching-limit value of the class \"+def.getName()+\" is not a number\");\r\n                }\r\n                else\r\n                {    \r\n                    throw new ConstraintException(\"The proxy-prefetching-limit value of the feature \"+def.getName()+\" in class \"+def.getOwner().getName()+\" is not a number\");\r\n                }\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def generator(self, Xgen, Xexc, Xgov, Vgen):\n        \"\"\" Generator model.\n\n        Based on Generator.m from MatDyn by Stijn Cole, developed at Katholieke\n        Universiteit Leuven. See U{http://www.esat.kuleuven.be/electa/teaching/\n        matdyn/} for more information.\n        \"\"\"\n        generators = self.dyn_generators\n        omegas = 2 * pi * self.freq\n\n        F = zeros(Xgen.shape)\n\n        typ1 = [g._i for g in generators if g.model == CLASSICAL]\n        typ2 = [g._i for g in generators if g.model == FOURTH_ORDER]\n\n        # Generator type 1: classical model\n        omega = Xgen[typ1, 1]\n        Pm0 = Xgov[typ1, 0]\n\n        H = array([g.h for g in generators])[typ1]\n        D = array([g.d for g in generators])[typ1]\n\n        Pe = Vgen[typ1, 2]\n\n        ddelta = omega = omegas\n        domega = pi * self.freq / H * (-D * (omega - omegas) + Pm0 - Pe)\n        dEq = zeros(len(typ1))\n\n        F[typ1, :] = c_[ddelta, domega, dEq]\n\n        # Generator type 2: 4th order model\n        omega = Xgen[typ2, 1]\n        Eq_tr = Xgen[typ2, 2]\n        Ed_tr = Xgen[typ2, 3]\n\n        H = array([g.h for g in generators])\n        D = array([g.d for g in generators])\n        xd = array([g.xd for g in generators])\n        xq = array([g.xq for g in generators])\n        xd_tr = array([g.xd_tr for g in generators])\n        xq_tr = array([g.xq_tr for g in generators])\n        Td0_tr = array([g.td for g in generators])\n        Tq0_tr = array([g.tq for g in generators])\n\n        Id = Vgen[typ2, 0]\n        Iq = Vgen[typ2, 1]\n        Pe = Vgen[typ2, 2]\n\n        Efd = Xexc[typ2, 0]\n        Pm = Xgov[typ2, 0]\n\n        ddelta = omega - omegas\n        domega = pi * self.freq / H * (-D * (omega - omegas) + Pm - Pe)\n        dEq = 1 / Td0_tr * (Efd - Eq_tr + (xd - xd_tr) * Id)\n        dEd = 1 / Tq0_tr * (-Ed_tr - (xq - xq_tr) * Iq)\n\n        F[typ2, :] = c_[ddelta, domega, dEq, dEd]\n\n        # Generator type 3:\n\n        # Generator type 4:\n\n        return F", "label": 1}
{"code": "func (g GridType) XY(dataX, dataY float64) (x, y float64) {\n\treturn g.xm*dataX + g.xb, g.ym*dataY + g.yb\n}", "label": 5}
{"code": "public function setIdValues($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->id_values = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (app *Application) Update() {\n\tev := &eventAppUpdate{}\n\tev.SetEventNow()\n\tif scr := app.screen; scr != nil {\n\t\tgo func() { scr.PostEventWait(ev) }()\n\t}\n}", "label": 5}
{"code": "def save_as(project_path, name, shared = true)\n      scheme_folder_path = if shared\n                             self.class.shared_data_dir(project_path)\n                           else\n                             self.class.user_data_dir(project_path)\n                           end\n      scheme_folder_path.mkpath\n      scheme_path = scheme_folder_path + \"#{name}.xcscheme\"\n      @file_path = scheme_path\n      File.open(scheme_path, 'w') do |f|\n        f.write(to_s)\n      end\n    end", "label": 4}
{"code": "def build\n      root = ENV['MM_ROOT'] || Dir.pwd\n\n      raise Thor::Error, 'Error: Could not find a Middleman project config, perhaps you are in the wrong folder?' unless File.exist?(File.join(root, 'config.rb'))\n\n      require 'middleman-core'\n      require 'middleman-core/logger'\n      require 'middleman-core/builder'\n      require 'fileutils'\n\n      verbose = options['verbose'] ? 0 : 1\n      instrument = options['instrument']\n\n      builder = nil\n      cli_options = options\n\n      ::Middleman::Logger.singleton(verbose, instrument)\n\n      ::Middleman::Util.instrument 'builder.setup' do\n        missing_and_changed = !options['only_changed'] && options['missing_and_changed']\n        should_track_dependencies = options['only_changed'] || missing_and_changed || options['track_dependencies']\n        data_collection_depth = options['data_collection_depth']\n\n        @app = ::Middleman::Application.new do\n          config[:mode] = :build\n          config[:show_exceptions] = false\n          config[:cli_options] = cli_options.each_with_object({}) do |(k, v), sum|\n            sum[k] = v\n          end\n          config[:track_data_access] = should_track_dependencies\n          config[:data_collection_depth] = data_collection_depth\n        end\n\n        builder = Middleman::Builder.new(@app,\n                                         glob: options['glob'],\n                                         dry_run: options['dry_run'],\n                                         clean: options['clean'],\n                                         parallel: options['parallel'],\n                                         only_changed: options['only_changed'],\n                                         missing_and_changed: missing_and_changed,\n                                         track_dependencies: should_track_dependencies,\n                                         visualize_graph: options['visualize_graph'])\n        builder.thor = self\n        builder.on_build_event(&method(:on_event))\n      end\n\n      ::Middleman::Util.instrument 'builder.run' do\n        if builder.run!\n          clean_directories! if options['clean']\n          puts 'Project built successfully.'\n        else\n          msg = 'There were errors during this build'\n          msg << ', re-run with `middleman build --verbose` to see the full exception.' unless options['verbose']\n          shell.say msg, :red\n\n          exit(1)\n        end\n      end\n    end", "label": 4}
{"code": "function _gpfRequireConfigureAddOption (name, handler, highPriority) {\n    if (highPriority) {\n        _gpfRequireConfigureOptionNames.unshift(name);\n    } else {\n        _gpfRequireConfigureOptionNames.push(name);\n    }\n    _gpfRequireConfigureHandler[name] = handler;\n}", "label": 3}
{"code": "func WriteHostUUID(dataDir string, id string) error {\n\terr := ioutil.WriteFile(filepath.Join(dataDir, HostUUIDFile), []byte(id), os.ModeExclusive|0400)\n\tif err != nil {\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static nslimitselector[] get(nitro_service service) throws Exception{\n\t\tnslimitselector obj = new nslimitselector();\n\t\tnslimitselector[] response = (nslimitselector[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def hidden_field(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'hidden_field_for', &block)\n      define_method(name) do\n        return platform.hidden_field_value_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").value\n      end\n    end", "label": 4}
{"code": "public static auditnslogpolicy_lbvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauditnslogpolicy_lbvserver_binding obj = new auditnslogpolicy_lbvserver_binding();\n\t\tobj.set_name(name);\n\t\tauditnslogpolicy_lbvserver_binding response[] = (auditnslogpolicy_lbvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _debug_dump_dom(el):\n    \"\"\"Debugging helper. Prints out `el` contents.\"\"\"\n    import xml.dom.minidom\n    s = [el.nodeName]\n    att_container = el.attributes\n    for i in range(att_container.length):\n        attr = att_container.item(i)\n        s.append('  @{a}=\"{v}\"'.format(a=attr.name, v=attr.value))\n    for c in el.childNodes:\n        if c.nodeType == xml.dom.minidom.Node.TEXT_NODE:\n            s.append('  {a} type=\"TEXT\" data=\"{d}\"'.format(a=c.nodeName, d=c.data))\n        else:\n            s.append('  {a} child'.format(a=c.nodeName))\n    return '\\n'.join(s)", "label": 1}
{"code": "def is_reachable(self):\n        \"\"\"Return if host is reachable.\"\"\"\n        if self.verify_reachability and \\\n                hasattr(self.verify_reachability, '__call__'):\n            return self.verify_reachability(host=self.hostname, port=self.port)\n        # assume is reachable if can't verify\n        return True", "label": 1}
{"code": "def get_patient_mhc_haplotype(job, patient_dict):\n    \"\"\"\n    Convenience function to get the mhc haplotype from the patient dict\n\n    :param dict patient_dict: dict of patient info\n    :return: The MHCI and MHCII haplotypes\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    haplotype_archive = job.fileStore.readGlobalFile(patient_dict['hla_haplotype_files'])\n    haplotype_archive = untargz(haplotype_archive, os.getcwd())\n    output_dict = {}\n    for filename in 'mhci_alleles.list', 'mhcii_alleles.list':\n        output_dict[filename] = job.fileStore.writeGlobalFile(os.path.join(haplotype_archive,\n                                                                           filename))\n    return output_dict", "label": 1}
{"code": "function getRoutes(req, res) {\n        var index = {\n            name: about.name,\n            version: about.version,\n            description: about.description,\n            routes: app.routes\n        };\n        return res.json(index);\n    }", "label": 3}
{"code": "public static ResourceResolutionContext context(ResourceResolutionComponent[] components,\n                                                    Map<String, Object> messageParams) {\n        return new ResourceResolutionContext(components, messageParams);\n    }", "label": 0}
{"code": "function validateCallbacks(options) {\n            if (options.successCallback && typeof options.successCallback !== 'function') {\n                throw new Error(TAG + 'Success callback must be a function.');\n            } else {\n                options.successCallback = options.successCallback || enplug.noop;\n            }\n\n            if (options.errorCallback && typeof options.errorCallback !== 'function') {\n                throw new Error(TAG + 'Error callback must be a function.');\n            } else {\n                options.errorCallback = options.errorCallback || enplug.noop;\n            }\n        }", "label": 3}
{"code": "function(o) {\n    var a = [];\n    _.each(o, function(value, key) {\n      a.push({file:key,method:value});\n    });\n    return a;\n  }", "label": 3}
{"code": "function encryptJson(password, json) {\n    return Q.all([\n        randomBytes(pbkdf2SaltLen),\n        randomBytes(cipherIvLen)\n    ]).spread(function (salt, iv) {\n        return pbkdf2(password, salt, pbkdf2Iterations, pbkdf2KeyLen, pbkdf2Digest).then(function (key) {\n            var cipher = crypto.createCipheriv(cipherAlgorithm, key, iv);\n            var value = cipher.update(JSON.stringify(json), 'utf8', 'base64');\n            value += cipher.final('base64');\n            var data = {\n                salt: salt.toString('base64'),\n                iv: iv.toString('base64'),\n                value: value\n            };\n            var tag = cipher.getAuthTag();\n            if (tag) {\n                data.tag = tag.toString('base64');\n            }\n            return data;\n        });\n    });\n}", "label": 3}
{"code": "protected function processMediaImage($node)\n    {\n        $media = $node->getChild('media');\n\n        if ($media != null) {\n            $filename = $media->getAttribute('file');\n            $url = $media->getAttribute('url');\n\n            //save thumbnail\n            file_put_contents($this->dataFolder.Constants::MEDIA_FOLDER.DIRECTORY_SEPARATOR.'thumb_'.$filename, $media->getData());\n            //download and save original\n            file_put_contents($this->dataFolder.Constants::MEDIA_FOLDER.DIRECTORY_SEPARATOR.$filename, file_get_contents($url));\n        }\n    }", "label": 2}
{"code": "public ValueContainer[] getKeyValues(ClassDescriptor cld, Identity oid, boolean convertToSql) throws PersistenceBrokerException\r\n    {\r\n        FieldDescriptor[] pkFields = cld.getPkFields();\r\n        ValueContainer[] result = new ValueContainer[pkFields.length];\r\n        Object[] pkValues = oid.getPrimaryKeyValues();\r\n\r\n        try\r\n        {\r\n            for(int i = 0; i < result.length; i++)\r\n            {\r\n                FieldDescriptor fd = pkFields[i];\r\n                Object cv = pkValues[i];\r\n                if(convertToSql)\r\n                {\r\n                    // BRJ : apply type and value mapping\r\n                    cv = fd.getFieldConversion().javaToSql(cv);\r\n                }\r\n                result[i] = new ValueContainer(cv, fd.getJdbcType());\r\n            }\r\n        }\r\n        catch(Exception e)\r\n        {\r\n            throw new PersistenceBrokerException(\"Can't generate primary key values for given Identity \" + oid, e);\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "func containsAllKeyValues(actualKVs []*v1alpha.KeyValue, requiredKVs []*v1alpha.KeyValue) bool {\n\tfor _, requiredKV := range requiredKVs {\n\t\tactualValue, ok := findInKeyValues(actualKVs, requiredKV.Key)\n\t\tif !ok || actualValue != requiredKV.Value {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "label": 5}
{"code": "public function setDailyMaintenanceWindow($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\DailyMaintenanceWindow::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (k *Keygen) GenerateUserCert(c services.UserCertParams) ([]byte, error) {\n\tif c.TTL < defaults.MinCertDuration {\n\t\treturn nil, trace.BadParameter(\"wrong certificate TTL\")\n\t}\n\tif len(c.AllowedLogins) == 0 {\n\t\treturn nil, trace.BadParameter(\"allowedLogins: need allowed OS logins\")\n\t}\n\tpubKey, _, _, _, err := ssh.ParseAuthorizedKey(c.PublicUserKey)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvalidBefore := uint64(ssh.CertTimeInfinity)\n\tif c.TTL != 0 {\n\t\tb := k.clock.Now().UTC().Add(c.TTL)\n\t\tvalidBefore = uint64(b.Unix())\n\t\tlog.Debugf(\"generated user key for %v with expiry on (%v) %v\", c.AllowedLogins, validBefore, b)\n\t}\n\tcert := &ssh.Certificate{\n\t\t// we have to use key id to identify teleport user\n\t\tKeyId:           c.Username,\n\t\tValidPrincipals: c.AllowedLogins,\n\t\tKey:             pubKey,\n\t\tValidAfter:      uint64(k.clock.Now().UTC().Add(-1 * time.Minute).Unix()),\n\t\tValidBefore:     validBefore,\n\t\tCertType:        ssh.UserCert,\n\t}\n\tcert.Permissions.Extensions = map[string]string{\n\t\tteleport.CertExtensionPermitPTY:            \"\",\n\t\tteleport.CertExtensionPermitPortForwarding: \"\",\n\t}\n\tif c.PermitAgentForwarding {\n\t\tcert.Permissions.Extensions[teleport.CertExtensionPermitAgentForwarding] = \"\"\n\t}\n\tif !c.PermitPortForwarding {\n\t\tdelete(cert.Permissions.Extensions, teleport.CertExtensionPermitPortForwarding)\n\t}\n\tif len(c.Roles) != 0 {\n\t\t// only add roles to the certificate extensions if the standard format was\n\t\t// requested. we allow the option to omit this to support older versions of\n\t\t// OpenSSH due to a bug in <= OpenSSH 7.1\n\t\t// https://bugzilla.mindrot.org/show_bug.cgi?id=2387\n\t\tif c.CertificateFormat == teleport.CertificateFormatStandard {\n\t\t\troles, err := services.MarshalCertRoles(c.Roles)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\tcert.Permissions.Extensions[teleport.CertExtensionTeleportRoles] = roles\n\t\t}\n\t}\n\tsigner, err := ssh.ParsePrivateKey(c.PrivateCASigningKey)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif err := cert.SignCert(rand.Reader, signer); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn ssh.MarshalAuthorizedKey(cert), nil\n}", "label": 5}
{"code": "def restored_front_matter\n      front_matter.map do |key, value|\n        value = \"null\" if value.nil?\n        [key, value]\n      end.to_h\n    end", "label": 4}
{"code": "public function setImageRedactionConfigs($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\RedactImageRequest\\ImageRedactionConfig::class);\n        $this->image_redaction_configs = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response export(nitro_service client, application resource) throws Exception {\n\t\tapplication exportresource = new application();\n\t\texportresource.appname = resource.appname;\n\t\texportresource.apptemplatefilename = resource.apptemplatefilename;\n\t\texportresource.deploymentfilename = resource.deploymentfilename;\n\t\treturn exportresource.perform_operation(client,\"export\");\n\t}", "label": 0}
{"code": "function setScrollTop(cm, val) {\n    if (Math.abs(cm.doc.scrollTop - val) < 2) return;\n    cm.doc.scrollTop = val;\n    if (!gecko) updateDisplaySimple(cm, {top: val});\n    if (cm.display.scroller.scrollTop != val) cm.display.scroller.scrollTop = val;\n    cm.display.scrollbars.setScrollTop(val);\n    if (gecko) updateDisplaySimple(cm);\n    startWorker(cm, 100);\n  }", "label": 3}
{"code": "def relationships\n      rels = Axlsx::Relationships.new\n      rels << Relationship.new(self, WORKBOOK_R, WORKBOOK_PN)\n      rels << Relationship.new(self, CORE_R, CORE_PN)\n      rels << Relationship.new(self, APP_R, APP_PN)\n      rels.lock\n      rels\n    end", "label": 4}
{"code": "def is_elem_ref(elem_ref):\n    \"\"\"\n    Returns true if the elem_ref is an element reference\n\n    :param elem_ref:\n    :return:\n    \"\"\"\n    return (\n        elem_ref\n        and isinstance(elem_ref, tuple)\n        and len(elem_ref) == 3\n        and (elem_ref[0] == ElemRefObj or elem_ref[0] == ElemRefArr)\n    )", "label": 1}
{"code": "func MyTableColumns(db XODB, schema string, table string) ([]*Column, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`ordinal_position AS field_ordinal, ` +\n\t\t`column_name, ` +\n\t\t`IF(data_type = 'enum', column_name, column_type) AS data_type, ` +\n\t\t`IF(is_nullable = 'YES', false, true) AS not_null, ` +\n\t\t`column_default AS default_value, ` +\n\t\t`IF(column_key = 'PRI', true, false) AS is_primary_key ` +\n\t\t`FROM information_schema.columns ` +\n\t\t`WHERE table_schema = ? AND table_name = ? ` +\n\t\t`ORDER BY ordinal_position`\n\n\t// run query\n\tXOLog(sqlstr, schema, table)\n\tq, err := db.Query(sqlstr, schema, table)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*Column{}\n\tfor q.Next() {\n\t\tc := Column{}\n\n\t\t// scan\n\t\terr = q.Scan(&c.FieldOrdinal, &c.ColumnName, &c.DataType, &c.NotNull, &c.DefaultValue, &c.IsPrimaryKey)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &c)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public int compareTo(WordLemmaTag wordLemmaTag) {\r\n    int first = word().compareTo(wordLemmaTag.word());\r\n    if (first != 0)\r\n      return first;\r\n    int second = lemma().compareTo(wordLemmaTag.lemma());\r\n    if (second != 0)\r\n      return second;\r\n    else\r\n      return tag().compareTo(wordLemmaTag.tag());\r\n  }", "label": 0}
{"code": "def count_stages(self, matrix_name):\n        \"\"\"\n        Number of registered stages for given matrix name.\n\n        Parameters:\n            matrix_name (str): name of the matrix\n\n        Returns:\n            int: number of reported stages for given matrix name.\n        \"\"\"\n        return len(self.data[matrix_name]) if matrix_name in self.data else 0", "label": 1}
{"code": "private function executeUpdates($class)\n    {\n        $className        = $class->getClassName();\n        $persister        = $this->getEntityPersister($className);\n        $preUpdateInvoke  = $this->listenersInvoker->getSubscribedSystems($class, Events::preUpdate);\n        $postUpdateInvoke = $this->listenersInvoker->getSubscribedSystems($class, Events::postUpdate);\n\n        foreach ($this->entityUpdates as $oid => $entity) {\n            if ($this->em->getClassMetadata(get_class($entity))->getClassName() !== $className) {\n                continue;\n            }\n\n            if ($preUpdateInvoke !== ListenersInvoker::INVOKE_NONE) {\n                $this->listenersInvoker->invoke($class, Events::preUpdate, $entity, new PreUpdateEventArgs($entity, $this->em, $this->getEntityChangeSet($entity)), $preUpdateInvoke);\n\n                $this->recomputeSingleEntityChangeSet($class, $entity);\n            }\n\n            if (! empty($this->entityChangeSets[$oid])) {\n                $persister->update($entity);\n            }\n\n            unset($this->entityUpdates[$oid]);\n\n            if ($postUpdateInvoke !== ListenersInvoker::INVOKE_NONE) {\n                $this->listenersInvoker->invoke($class, Events::postUpdate, $entity, new LifecycleEventArgs($entity, $this->em), $postUpdateInvoke);\n            }\n        }\n    }", "label": 2}
{"code": "public function setExcludeInfoTypes($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\ExcludeInfoTypes::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def sources\n      @sources ||= Licensed::Sources::Source.sources\n                                            .select { |source_class| enabled?(source_class.type) }\n                                            .map { |source_class| source_class.new(self) }\n    end", "label": 4}
{"code": "function createJsonPreprocessor(logger, basePath, config) {\n  const log = logger.create('preprocessor.json');\n  const conf = config || {};\n  const stripPrefix = new RegExp(`^${(conf.stripPrefix || '')}`);\n\n  return function(content, file, done) {\n    log.debug('Processing \"%s\".', file.originalPath);\n\n    // Build json path file.\n    const jsonPath = file.originalPath\n        .replace(`${basePath}/`, '')\n        .replace(stripPrefix, '');\n\n    const template = createTemplate(conf.varName || '__json__');\n\n    // Update file path\n    file.path = `${file.path}.js`;\n\n    try {\n      const o = JSON.parse(content.trim());\n      done(util.format(template, jsonPath, JSON.stringify(o)));\n    } catch (e) {\n      log.error('Json representation of %s is not valid !', file.originalPath);\n      done('');\n    }\n  };\n}", "label": 3}
{"code": "func (s *Store) GetImageManifest(key string) (*schema.ImageManifest, error) {\n\timj, err := s.GetImageManifestJSON(key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar im *schema.ImageManifest\n\tif err = json.Unmarshal(imj, &im); err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"error unmarshalling image manifest\"), err)\n\t}\n\treturn im, nil\n}", "label": 5}
{"code": "def slider(question, *args, &block)\n      options = Utils.extract_options!(args)\n      slider = Slider.new(self, options)\n      slider.call(question, &block)\n    end", "label": 4}
{"code": "func (g *rfc4122Generator) getClockSequence() (uint64, uint16, error) {\n\tvar err error\n\tg.clockSequenceOnce.Do(func() {\n\t\tbuf := make([]byte, 2)\n\t\tif _, err = io.ReadFull(g.rand, buf); err != nil {\n\t\t\treturn\n\t\t}\n\t\tg.clockSequence = binary.BigEndian.Uint16(buf)\n\t})\n\tif err != nil {\n\t\treturn 0, 0, err\n\t}\n\n\tg.storageMutex.Lock()\n\tdefer g.storageMutex.Unlock()\n\n\ttimeNow := g.getEpoch()\n\t// Clock didn't change since last UUID generation.\n\t// Should increase clock sequence.\n\tif timeNow <= g.lastTime {\n\t\tg.clockSequence++\n\t}\n\tg.lastTime = timeNow\n\n\treturn timeNow, g.clockSequence, nil\n}", "label": 5}
{"code": "def unlocked_reload\n      return if !@index_file.file?\n\n      data = nil\n      begin\n        data = JSON.load(@index_file.read)\n      rescue JSON::ParserError\n        raise Errors::CorruptMachineIndex, path: @index_file.to_s\n      end\n\n      if data\n        if !data[\"version\"] || data[\"version\"].to_i != 1\n          raise Errors::CorruptMachineIndex, path: @index_file.to_s\n        end\n\n        @machines = data[\"machines\"] || {}\n      end\n    end", "label": 4}
{"code": "func (n *network) applyConfigurationTo(to *network) error {\n\tto.enableIPv6 = n.enableIPv6\n\tif len(n.labels) > 0 {\n\t\tto.labels = make(map[string]string, len(n.labels))\n\t\tfor k, v := range n.labels {\n\t\t\tif _, ok := to.labels[k]; !ok {\n\t\t\t\tto.labels[k] = v\n\t\t\t}\n\t\t}\n\t}\n\tif len(n.ipamType) != 0 {\n\t\tto.ipamType = n.ipamType\n\t}\n\tif len(n.ipamOptions) > 0 {\n\t\tto.ipamOptions = make(map[string]string, len(n.ipamOptions))\n\t\tfor k, v := range n.ipamOptions {\n\t\t\tif _, ok := to.ipamOptions[k]; !ok {\n\t\t\t\tto.ipamOptions[k] = v\n\t\t\t}\n\t\t}\n\t}\n\tif len(n.ipamV4Config) > 0 {\n\t\tto.ipamV4Config = make([]*IpamConf, 0, len(n.ipamV4Config))\n\t\tto.ipamV4Config = append(to.ipamV4Config, n.ipamV4Config...)\n\t}\n\tif len(n.ipamV6Config) > 0 {\n\t\tto.ipamV6Config = make([]*IpamConf, 0, len(n.ipamV6Config))\n\t\tto.ipamV6Config = append(to.ipamV6Config, n.ipamV6Config...)\n\t}\n\tif len(n.generic) > 0 {\n\t\tto.generic = options.Generic{}\n\t\tfor k, v := range n.generic {\n\t\t\tto.generic[k] = v\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function search(req, res, next) {\n  var projectForms = req.appformsResultPayload.data || [];\n  //Only Want The Project Ids\n  projectForms = _.map(projectForms, function(form) {\n    if (_.isObject(form)) {\n      return form._id;\n    } else {\n      return form;\n    }\n  });\n\n  var formsToFind = req.body || [];\n\n  formsToFind = _.filter(projectForms, function(projFormId) {\n    return formsToFind.indexOf(projFormId) > -1;\n  });\n\n  logger.debug(\"Middleware: search forms: \", {connection: req.connectionOptions, projectForms: projectForms});\n\n  forms.findForms(req.connectionOptions, formsToFind, function(err, formsList) {\n    if (err) {\n      return next(err);\n    }\n\n    async.map(formsList, function(foundForm, cb) {\n      var getParams = {\n        \"_id\": foundForm._id,\n        \"showAdminFields\": false\n      };\n      forms.getForm(_.extend(_.clone(req.connectionOptions), getParams), cb);\n    }, formsResultHandlers(constants.resultTypes.forms, req, next));\n  });\n}", "label": 3}
{"code": "function makeRespondMiddleware(opts) {\n  opts = Object.assign({}, opts)\n\n  // Make the respond function.\n  const respond = makeRespond(opts)\n\n  /**\n   * Installs the functions in the context.\n   *\n   * @param  {KoaContext} ctx\n   */\n  function patch(ctx) {\n    const statusMethods = Object.assign({}, opts.statusMethods, statusCodeMap)\n    ctx.send = respond.bind(ctx, ctx)\n\n    // Bind status methods.\n    for (const method in statusMethods) {\n      const code = statusMethods[method]\n      ctx[method] = respond.bind(ctx, ctx, code)\n    }\n\n    // Bind other methods\n    const methods = Object.assign({}, opts.methods)\n    for (const method in methods) {\n      const fn = methods[method]\n      ctx[method] = fn.bind(ctx, ctx)\n    }\n\n    return ctx\n  }\n\n  /**\n   * The respond middleware adds the methods to the context.\n   *\n   * @param  {KoaContext} ctx\n   */\n  function respondMiddleware(ctx, next) {\n    patch(ctx)\n    return next()\n  }\n\n  // Tack on the patch method to allow Koa 1 users\n  // to install it, too.\n  respondMiddleware.patch = patch\n  return respondMiddleware\n}", "label": 3}
{"code": "def fields=(unfolded_fields)\n      @fields = Mail::FieldList.new\n\n      if unfolded_fields.size > self.class.maximum_amount\n        Kernel.warn \"WARNING: More than #{self.class.maximum_amount} header fields; only using the first #{self.class.maximum_amount} and ignoring the rest\"\n        unfolded_fields = unfolded_fields.slice(0...self.class.maximum_amount)\n      end\n\n      unfolded_fields.each do |field|\n        if field = Field.parse(field, charset)\n          @fields.add_field field\n        end\n      end\n    end", "label": 4}
{"code": "private void checkAnonymous(FieldDescriptorDef fieldDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        String access = fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_ACCESS);\r\n\r\n        if (!\"anonymous\".equals(access))\r\n        {\r\n            throw new ConstraintException(\"The access property of the field \"+fieldDef.getName()+\" defined in class \"+fieldDef.getOwner().getName()+\" cannot be changed\");\r\n        }\r\n\r\n        if ((fieldDef.getName() == null) || (fieldDef.getName().length() == 0))\r\n        {\r\n            throw new ConstraintException(\"An anonymous field defined in class \"+fieldDef.getOwner().getName()+\" has no name\");\r\n        }\r\n    }", "label": 0}
{"code": "function convertDiffToMessages(diff, actualOnly = false, includeTimeouts = false, timeout = undefined, comparisonLines = [], paths = []) {\n    if (diff.tree && Object.keys(diff.tree).length > 0) {\n        const keys = Object.keys(diff.tree);\n        keys.forEach(key => {\n            const _paths = [...paths];\n            _paths.push(key);\n            convertDiffToMessages(diff.tree[key], actualOnly, includeTimeouts, timeout, comparisonLines, _paths);\n        });\n    }\n    else {\n        let _paths = paths.join('');\n        if (_paths.charAt(0) === '.') {\n            _paths = _paths.substring(1);\n        }\n        const _actual = printValue(diff.actual);\n        const _expected = printValue(diff.expected);\n        let compareStr = '';\n        if (actualOnly) {\n            compareStr = (typeof diff.actual === 'undefined') ?\n                '' : `{actual: <${_actual}>}\\n`;\n        }\n        else {\n            compareStr = (typeof diff.actual === 'undefined' && typeof diff.expected === 'undefined') ?\n                '' : `{actual: <${_actual}>, expected: <${_expected}>}\\n`;\n        }\n        const timeoutStr = (includeTimeouts) ? ` within ${timeout || diff.timeout}ms` : '';\n        comparisonLines.push(`${diff.constructorName} at path '${_paths}'${timeoutStr}\\n${compareStr}( ${diff.selector} )`);\n    }\n    return comparisonLines;\n}", "label": 3}
{"code": "def normalize\n      # This is a special exception for the frequently misused feed\n      # URI scheme.\n      if normalized_scheme == \"feed\"\n        if self.to_s =~ /^feed:\\/*http:\\/*/\n          return URI.parse(\n            self.to_s[/^feed:\\/*(http:\\/*.*)/, 1]\n          ).normalize\n        end\n      end\n\n      return self.class.new(\n        :scheme => normalized_scheme,\n        :authority => normalized_authority,\n        :path => normalized_path,\n        :query => normalized_query,\n        :fragment => normalized_fragment\n      )\n    end", "label": 4}
{"code": "private function getFormattedTopic($topic)\n    {\n        if ($topic instanceof Topic) {\n            return sprintf(self::NOTIFICATION_TEMPLATE, $topic->name());\n        }\n\n        if (!is_string($topic)) {\n            throw new \\InvalidArgumentException(\n                '$topic may only be a string or instance of Google\\Cloud\\PubSub\\Topic'\n            );\n        }\n\n        if (preg_match('/projects\\/[^\\/]*\\/topics\\/(.*)/', $topic) === 1) {\n            return sprintf(self::NOTIFICATION_TEMPLATE, $topic);\n        }\n\n        if (!$this->projectId) {\n            throw new GoogleException(\n                'No project ID was provided, ' .\n                'and we were unable to detect a default project ID.'\n            );\n        }\n\n        return sprintf(\n            self::NOTIFICATION_TEMPLATE,\n            sprintf(self::TOPIC_TEMPLATE, $this->projectId, $topic)\n        );\n    }", "label": 2}
{"code": "def tile(self, bbox, z=0, format=None, clip=True):\n        \"\"\"Returns a GeoQuerySet intersecting a tile boundary.\n\n        Arguments:\n        bbox -- tile extent as geometry\n        Keyword args:\n        z -- tile zoom level used as basis for geometry simplification\n        format -- vector tile format as str (pbf, geojson)\n        clip -- clip geometries to tile boundary as boolean\n        \"\"\"\n        # Tile grid uses 3857, but GeoJSON coordinates should be in 4326.\n        tile_srid = 3857\n        bbox = getattr(bbox, 'geos', bbox)\n        clone = filter_geometry(self, intersects=bbox)\n        field = clone.geo_field\n        srid = field.srid\n        sql = field.name\n        try:\n            tilew = self.tilewidths[z]\n        except IndexError:\n            tilew = self.tilewidths[-1]\n        if bbox.srid != srid:\n            bbox = bbox.transform(srid, clone=True)\n        # Estimate tile width in degrees instead of meters.\n        if bbox.srs.geographic:\n            p = geos.Point(tilew, tilew, srid=tile_srid)\n            p.transform(srid)\n            tilew = p.x\n        if clip:\n            bufbox = bbox.buffer(tilew)\n            sql = geofn.Intersection(sql, bufbox.envelope)\n        sql = SimplifyPreserveTopology(sql, tilew)\n        if format == 'pbf':\n            return clone.pbf(bbox, geo_col=sql)\n        sql = geofn.Transform(sql, 4326)\n        return clone.annotate(**{format: sql})", "label": 1}
{"code": "def set_working_days(working_days)\n      @working_days = (working_days || default_working_days).map do |day|\n        day.downcase.strip[0..2].tap do |normalised_day|\n          raise \"Invalid day #{day}\" unless DAY_NAMES.include?(normalised_day)\n        end\n      end\n      extra_working_dates_names = @extra_working_dates.map { |d| d.strftime(\"%a\").downcase }\n      return if (extra_working_dates_names & @working_days).none?\n      raise ArgumentError, 'Extra working dates cannot be on working days'\n    end", "label": 4}
{"code": "function(model, cascade, options)\n  {\n    var db = this;\n\n    // If we have it in the models, remove it!\n    this.removeFromModels( model );\n\n    // If we're offline and we have a pending save - cancel the pending save.\n    if ( model.$status === Model.Status.SavePending )\n    {\n      Rekord.debug( Rekord.Debugs.REMOVE_CANCEL_SAVE, db, model );\n    }\n\n    model.$status = Model.Status.RemovePending;\n\n    model.$addOperation( RemoveLocal, cascade, options );\n  }", "label": 3}
{"code": "func (v *ViewPort) GetVisible() (int, int, int, int) {\n\treturn v.viewx, v.viewy, v.viewx + v.width - 1, v.viewy + v.height - 1\n}", "label": 5}
{"code": "public static String slurpReader(Reader reader) {\r\n    BufferedReader r = new BufferedReader(reader);\r\n    StringBuilder buff = new StringBuilder();\r\n    try {\r\n      char[] chars = new char[SLURPBUFFSIZE];\r\n      while (true) {\r\n        int amountRead = r.read(chars, 0, SLURPBUFFSIZE);\r\n        if (amountRead < 0) {\r\n          break;\r\n        }\r\n        buff.append(chars, 0, amountRead);\r\n      }\r\n      r.close();\r\n    } catch (Exception e) {\r\n      throw new RuntimeIOException(\"slurpReader IO problem\", e);\r\n    }\r\n    return buff.toString();\r\n  }", "label": 0}
{"code": "public function modifyPushConfig(array $pushConfig, array $options = [])\n    {\n        $this->connection->modifyPushConfig($options + [\n            'subscription' => $this->name,\n            'pushConfig' => $pushConfig\n        ]);\n    }", "label": 2}
{"code": "private FullTypeSignature getTypeSignature(Class<?> clazz) {\r\n\t\tStringBuilder sb = new StringBuilder();\r\n\t\tif (clazz.isArray()) {\r\n\t\t\tsb.append(clazz.getName());\r\n\t\t} else if (clazz.isPrimitive()) {\r\n\t\t\tsb.append(primitiveTypesMap.get(clazz).toString());\r\n\t\t} else {\r\n\t\t\tsb.append('L').append(clazz.getName()).append(';');\r\n\t\t}\r\n\t\treturn TypeSignatureFactory.getTypeSignature(sb.toString(), false);\r\n\r\n\t}", "label": 0}
{"code": "func (s *Server) handleRecordingProxy(req *ssh.Request) {\n\tvar recordingProxy bool\n\n\tlog.Debugf(\"Global request (%v, %v) received\", req.Type, req.WantReply)\n\n\tif req.WantReply {\n\t\t// get the cluster config, if we can't get it, reply false\n\t\tclusterConfig, err := s.authService.GetClusterConfig()\n\t\tif err != nil {\n\t\t\terr := req.Reply(false, nil)\n\t\t\tif err != nil {\n\t\t\t\tlog.Warnf(\"Unable to respond to global request (%v, %v): %v\", req.Type, req.WantReply, err)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t// reply true that we were able to process the message and reply with a\n\t\t// bool if we are in recording mode or not\n\t\trecordingProxy = clusterConfig.GetSessionRecording() == services.RecordAtProxy\n\t\terr = req.Reply(true, []byte(strconv.FormatBool(recordingProxy)))\n\t\tif err != nil {\n\t\t\tlog.Warnf(\"Unable to respond to global request (%v, %v): %v: %v\", req.Type, req.WantReply, recordingProxy, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\tlog.Debugf(\"Replied to global request (%v, %v): %v\", req.Type, req.WantReply, recordingProxy)\n}", "label": 5}
{"code": "func NetworkOverlaps(netX *net.IPNet, netY *net.IPNet) bool {\n\treturn netX.Contains(netY.IP) || netY.Contains(netX.IP)\n}", "label": 5}
{"code": "def rai_to_raw(self, amount):\n        \"\"\"\n        Multiply an rai amount by the rai ratio.\n\n        :param amount: Amount in rai to convert to raw\n        :type amount: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.rai_to_raw(amount=1)\n        1000000000000000000000000\n\n        \"\"\"\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('rai_to_raw', payload)\n\n        return int(resp['amount'])", "label": 1}
{"code": "public static Object newInstance(String className) throws InstantiationException,\r\n                                                              IllegalAccessException,\r\n                                                              ClassNotFoundException\r\n    {\r\n        return newInstance(getClass(className));\r\n    }", "label": 0}
{"code": "public static double getRadiusToBoundedness(double D, int N, double timelag, double B){\n\t\tdouble cov_area = a(N)*D*timelag;\n\t\tdouble radius = Math.sqrt(cov_area/(4*B));\n\t\treturn radius;\n\t}", "label": 0}
{"code": "def new_active_call(method, marshal, unmarshal,\n                        deadline: nil,\n                        parent: nil,\n                        credentials: nil)\n      deadline = from_relative_time(@timeout) if deadline.nil?\n      # Provide each new client call with its own completion queue\n      call = @ch.create_call(parent, # parent call\n                             @propagate_mask, # propagation options\n                             method,\n                             nil, # host use nil,\n                             deadline)\n      call.set_credentials! credentials unless credentials.nil?\n      ActiveCall.new(call, marshal, unmarshal, deadline,\n                     started: false)\n    end", "label": 4}
{"code": "function handleResourceContext(attrNode, context) {\n    let dataSource;\n    let lastDataSourceName;\n\n    const errorContext = context.errorContext;\n\n    if (attrNode.resource) {\n        if ('subFilters' in attrNode) {\n            throw new ImplementationError(\n                'Adding subFilters for included sub-resource is not allowed' + context.errorContext\n            );\n        }\n        if ('primaryKey' in attrNode) {\n            throw new ImplementationError(\n                'Overwriting primaryKey for included sub-resource is not allowed' + context.errorContext\n            );\n        }\n    } else if (!('primaryKey' in attrNode)) {\n        throw new ImplementationError('Missing primaryKey' + context.errorContext);\n    }\n\n    if (attrNode.dataSources) {\n        Object.keys(attrNode.dataSources).forEach(dataSourceName => {\n            lastDataSourceName = dataSourceName;\n            context.dataSourceAttributes[dataSourceName] = [];\n\n            dataSource = attrNode.dataSources[dataSourceName];\n\n            if (dataSource.inherit) {\n                if (!attrNode.resource) {\n                    throw new ImplementationError(\n                        `DataSource \"${dataSourceName}\" is defined as \"inherit\" but has no included resource`\n                    );\n                }\n                context.errorContext = ' in inherit' + errorContext;\n                dataSource.inherit = checkWhitelist(dataSource.inherit, ['true', 'inherit', 'replace'], context);\n                if (dataSource.inherit === 'true') {\n                    dataSource.inherit = 'inherit';\n                }\n                context.errorContext = errorContext;\n            }\n\n            if (!dataSource.type && !dataSource.inherit) {\n                throw new ImplementationError(\n                    `DataSource \"${dataSourceName}\" misses \"type\" option${context.errorContext}`\n                );\n            }\n\n            if (dataSource.joinParentKey) {\n                context.errorContext = ' in joinParentKey' + errorContext;\n                dataSource.joinParentKey = parsePrimaryKey(dataSource.joinParentKey, context);\n                context.errorContext = errorContext;\n            }\n\n            if (dataSource.joinChildKey) {\n                context.errorContext = ' in joinChildKey' + errorContext;\n                dataSource.joinChildKey = parsePrimaryKey(dataSource.joinChildKey, context);\n                context.errorContext = errorContext;\n            }\n        });\n    }\n\n    if (attrNode.joinVia) {\n        if (!attrNode.dataSources[attrNode.joinVia]) {\n            throw new ImplementationError(`Unknown DataSource \"${attrNode.joinVia}\" in joinVia` + context.errorContext);\n        } else {\n            dataSource = attrNode.dataSources[attrNode.joinVia];\n\n            if (!dataSource.joinParentKey) {\n                throw new ImplementationError(\n                    `DataSource \"${lastDataSourceName}\" misses \"joinParentKey\" option` + context.errorContext\n                );\n            }\n\n            if (!dataSource.joinChildKey) {\n                throw new ImplementationError(\n                    `DataSource \"${lastDataSourceName}\" misses \"joinChildKey\" option` + context.errorContext\n                );\n            }\n        }\n    }\n}", "label": 3}
{"code": "private void appendJoin(StringBuffer where, StringBuffer buf, Join join)\r\n    {\r\n        buf.append(\",\");\r\n        appendTableWithJoins(join.right, where, buf);\r\n        if (where.length() > 0)\r\n        {\r\n            where.append(\" AND \");\r\n        }\r\n        join.appendJoinEqualities(where);\r\n    }", "label": 0}
{"code": "public function find_subcommand( &$args ) {\n\t\t$name = array_shift( $args );\n\n\t\t$subcommands = $this->get_subcommands();\n\n\t\tif ( ! isset( $subcommands[ $name ] ) ) {\n\t\t\t$aliases = self::get_aliases( $subcommands );\n\n\t\t\tif ( isset( $aliases[ $name ] ) ) {\n\t\t\t\t$name = $aliases[ $name ];\n\t\t\t}\n\t\t}\n\n\t\tif ( ! isset( $subcommands[ $name ] ) ) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn $subcommands[ $name ];\n\t}", "label": 2}
{"code": "def load(source):\n    \"\"\"\n    Load OpenCorpora corpus.\n\n    The ``source`` can be any of the following:\n\n    - a file name/path\n    - a file object\n    - a file-like object\n    - a URL using the HTTP or FTP protocol\n\n    \"\"\"\n    parser = get_xml_parser()\n    return etree.parse(source, parser=parser).getroot()", "label": 1}
{"code": "public static void setCurrentPersistenceBroker(PBKey key, PersistenceBrokerInternal broker)\r\n            throws PBFactoryException\r\n    {\r\n        HashMap map = (HashMap) currentBrokerMap.get();\r\n        WeakHashMap set = null;\r\n        if(map == null)\r\n        {\r\n            map = new HashMap();\r\n            currentBrokerMap.set(map);\r\n\r\n            synchronized(lock) {\r\n                loadedHMs.add(map);\r\n            }\r\n        }\r\n        else\r\n        {\r\n            set = (WeakHashMap) map.get(key);\r\n        }\r\n\r\n        if(set == null)\r\n        {\r\n            // We emulate weak HashSet using WeakHashMap\r\n            set = new WeakHashMap();\r\n            map.put(key, set);\r\n        }\r\n        set.put(broker, null);\r\n    }", "label": 0}
{"code": "def element_id_by_label(browser, label):\n    \"\"\"Return the id of a label's for attribute\"\"\"\n    label = XPathSelector(browser,\n                          unicode('//label[contains(., \"%s\")]' % label))\n    if not label:\n        return False\n    return label.get_attribute('for')", "label": 1}
{"code": "def contains(opts, *rest)\n      build_where_chain(opts, rest) do |arel|\n        case arel\n        when Arel::Nodes::In, Arel::Nodes::Equality\n          column = left_column(arel) || column_from_association(arel)\n\n          if [:hstore, :jsonb].include?(column.type)\n            Arel::Nodes::ContainsHStore.new(arel.left, arel.right)\n          elsif column.try(:array)\n            Arel::Nodes::ContainsArray.new(arel.left, arel.right)\n          else\n            raise ArgumentError, \"Invalid argument for .where.contains(), got #{arel.class}\"\n          end\n        else\n          raise ArgumentError, \"Invalid argument for .where.contains(), got #{arel.class}\"\n        end\n      end\n    end", "label": 4}
{"code": "private function getPropertyValue(array $property, $className = Entity::class)\n    {\n        $type = $this->getValueType($property);\n        return $this->convertValue($type, $property[$type], $className);\n    }", "label": 2}
{"code": "public function setTriggers($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\JobTrigger\\Trigger::class);\n        $this->triggers = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def rounding(price, currency):\n\t\"\"\" rounding currency value based on its max decimal digits \"\"\"\n\tcurrency = validate_currency(currency)\n\tprice = validate_price(price)\n\tif decimals(currency) == 0:\n\t\treturn round(int(price), decimals(currency))\n\treturn round(price, decimals(currency))", "label": 1}
{"code": "def to_xml_string(str = '')\n      return if empty?\n      str << '<protectedRanges>'\n      each { |range| range.to_xml_string(str) }\n      str << '</protectedRanges>'\n    end", "label": 4}
{"code": "public static FullTypeSignature getTypeSignature(String typeSignatureString,\n\t\t\tboolean useInternalFormFullyQualifiedName) {\n\t\tString key;\n\t\tif (!useInternalFormFullyQualifiedName) {\n\t\t\tkey = typeSignatureString.replace('.', '/')\n\t\t\t\t\t.replace('$', '.');\n\t\t} else {\n\t\t\tkey = typeSignatureString;\n\t\t}\n\n\t\t// we always use the internal form as a key for cache\n\t\tFullTypeSignature typeSignature = typeSignatureCache\n\t\t\t\t.get(key);\n\t\tif (typeSignature == null) {\n\t\t\tClassFileTypeSignatureParser typeSignatureParser = new ClassFileTypeSignatureParser(\n\t\t\t\t\ttypeSignatureString);\n\t\t\ttypeSignatureParser.setUseInternalFormFullyQualifiedName(useInternalFormFullyQualifiedName);\n\t\t\ttypeSignature = typeSignatureParser.parseTypeSignature();\n\t\t\ttypeSignatureCache.put(typeSignatureString, typeSignature);\n\t\t}\n\t\treturn typeSignature;\n\t}", "label": 0}
{"code": "function (values, schema) {\n\n    var publicList = find(schema, 'public')\n        , arrElem;\n\n    for (var value in values) {\n        if (publicList[value]) {\n            if (_.isArray(publicList[value])) {\n                for (var thisArrayElem in publicList[value]) {\n\n                    if (!_.isArray(values[value])) {\n                        // Delete values due to it should be an array defined in schema\n                        delete(values[value]);\n                    }\n                    else {\n                        for (var thisValue in values[value]) {\n                            values[value][thisValue] = unsetPublicSet(values[value][thisValue], publicList[value][thisArrayElem]);\n\n                            if (_.isEmpty(values[value][thisValue])) {\n                                (values[value]).splice(thisValue);\n                            }\n                        }\n\n                        if (_.isEmpty(values[value])) {\n                            delete(values[value]);\n                        }\n                    }\n                }\n            }\n            else {\n                if (publicList[value].public) {\n                    if (publicList[value].public == false || (publicList[value].public.hasOwnProperty('set') && publicList[value].public.set != true)) {\n                        delete(values[value]);\n                    }\n                }\n            }\n        }\n    }\n    return values;\n}", "label": 3}
{"code": "func NewWhereParser(ctx RuleContext) (predicate.Parser, error) {\n\treturn predicate.NewParser(predicate.Def{\n\t\tOperators: predicate.Operators{\n\t\t\tAND: predicate.And,\n\t\t\tOR:  predicate.Or,\n\t\t\tNOT: predicate.Not,\n\t\t},\n\t\tFunctions: map[string]interface{}{\n\t\t\t\"equals\":   predicate.Equals,\n\t\t\t\"contains\": predicate.Contains,\n\t\t\t// system.catype is a function that returns cert authority type,\n\t\t\t// it returns empty values for unrecognized values to\n\t\t\t// pass static rule checks.\n\t\t\t\"system.catype\": func() (interface{}, error) {\n\t\t\t\tresource, err := ctx.GetResource()\n\t\t\t\tif err != nil {\n\t\t\t\t\tif trace.IsNotFound(err) {\n\t\t\t\t\t\treturn \"\", nil\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t\t}\n\t\t\t\tca, ok := resource.(CertAuthority)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn \"\", nil\n\t\t\t\t}\n\t\t\t\treturn string(ca.GetType()), nil\n\t\t\t},\n\t\t},\n\t\tGetIdentifier: ctx.GetIdentifier,\n\t\tGetProperty:   GetStringMapValue,\n\t})\n}", "label": 5}
{"code": "def tee(iterable, n=2):\n    \"\"\"Return n independent iterators from a single iterable.\n\n    Once tee() has made a split, the original iterable should not be used\n    anywhere else; otherwise, the iterable could get advanced without the tee\n    objects being informed.\n\n    This itertool may require significant auxiliary storage (depending on how\n    much temporary data needs to be stored). In general, if one iterator uses\n    most or all of the data before another iterator starts, it is faster to use\n    list() instead of tee().\n    \"\"\"\n    tees = tuple(AsyncTeeIterable(iterable) for _ in range(n))\n    for tee in tees:\n\n        tee._siblings = tees\n\n    return tees", "label": 1}
{"code": "function(input)\n  {\n    var key = this.buildKeyFromInput( input );\n    var index = this.map.indices[ key ];\n\n    return index === undefined ? -1 : index;\n  }", "label": 3}
{"code": "public function setDeleteFromFamily($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\Mutation_DeleteFromFamily::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def _matches(field, params):\n    \"\"\"Return True if the input TypedField `field` contains instance attributes\n    that match the input parameters.\n\n    Args:\n        field: A TypedField instance.\n        params: A dictionary of TypedField instance attribute-to-value mappings.\n\n    Returns:\n        True if the input TypedField matches the input parameters.\n    \"\"\"\n    fieldattrs = six.iteritems(params)\n    return all(getattr(field, attr) == val for attr, val in fieldattrs)", "label": 1}
{"code": "def make_package_index(download_dir):\n    \"\"\"\n    Create a pypi server like file structure below download directory.\n\n    :param download_dir:    Download directory with packages.\n\n    EXAMPLE BEFORE:\n      +-- downloads/\n           +-- alice-1.0.zip\n           +-- alice-1.0.tar.gz\n           +-- bob-1.3.0.tar.gz\n           +-- bob-1.4.2.tar.gz\n           +-- charly-1.0.tar.bz2\n\n    EXAMPLE AFTERWARDS:\n      +-- downloads/\n           +-- simple/\n           |      +-- alice/index.html   --> ../../alice-*.*\n           |      +-- bob/index.html     --> ../../bob-*.*\n           |      +-- charly/index.html  --> ../../charly-*.*\n           |      +-- index.html  --> alice/index.html, bob/index.html, ...\n           +-- alice-1.0.zip\n           +-- alice-1.0.tar.gz\n           +-- bob-1.3.0.tar.gz\n           +-- bob-1.4.2.tar.gz\n           +-- charly-1.0.tar.bz2\n    \"\"\"\n    if not os.path.isdir(download_dir):\n        raise ValueError(\"No such directory: %r\" % download_dir)\n\n    pkg_rootdir = os.path.join(download_dir, \"simple\")\n    if os.path.isdir(pkg_rootdir):\n        shutil.rmtree(pkg_rootdir, ignore_errors=True)\n    os.mkdir(pkg_rootdir)\n\n    # -- STEP: Collect all packages.\n    package_map = {}\n    packages = []\n    for filename in sorted(os.listdir(download_dir)):\n        if not Package.isa(filename):\n            continue\n        pkg_filepath = os.path.join(download_dir, filename)\n        package_name = Package.get_pkgname(pkg_filepath)\n        package = package_map.get(package_name, None)\n        if not package:\n            # -- NEW PACKAGE DETECTED: Store/register package.\n            package = Package(pkg_filepath)\n            package_map[package.name] = package\n            packages.append(package)\n        else:\n            # -- SAME PACKAGE: Collect other variant/version.\n            package.files.append(pkg_filepath)\n\n    # -- STEP: Make local PYTHON PACKAGE INDEX.\n    root_package = Package(None, \"Python Package Index\")\n    root_package.files = [ os.path.join(pkg_rootdir, pkg.name, \"index.html\")\n                           for pkg in packages ]\n    make_index_for(root_package, pkg_rootdir)\n    for package in packages:\n        index_dir = os.path.join(pkg_rootdir, package.name)\n        make_index_for(package, index_dir)", "label": 1}
{"code": "function (data) {\n                var me = this;\n                me._waitForData();\n                me._dataInResolve(data);\n                return new Promise(function (resolve, reject) {\n                    me._dataOutResolve = resolve;\n                    me._dataOutReject = reject;\n                }).then(function (value) {\n                    delete me._dataOutResolve;\n                    delete me._dataOutReject;\n                    return value;\n                }, function (reason) {\n                    delete me._dataOutResolve;\n                    delete me._dataOutReject;\n                    return Promise.reject(reason);\n                });\n            }", "label": 3}
{"code": "def prepare_lazy(obj, args, ctx)\n      GraphQL::Execution::Lazy.new {\n        lazy_resolve(obj, args, ctx)\n      }\n    end", "label": 4}
{"code": "func (i *Handle) UpdateService(s *Service) error {\n\treturn i.doCmd(s, nil, ipvsCmdSetService)\n}", "label": 5}
{"code": "def undir_name(name)\n      name = name.dup\n      name.gsub!(VAGRANT_COLON, \":\")\n      name.gsub!(VAGRANT_SLASH, \"/\")\n      name\n    end", "label": 4}
{"code": "private function emulatorBaseUri($emulatorHost)\n    {\n        $emulatorUriComponents = parse_url($emulatorHost);\n        $emulatorUriComponents = array_merge(['scheme' => 'http', 'port' => ''], $emulatorUriComponents);\n        $baseUri = \"{$emulatorUriComponents['scheme']}://{$emulatorUriComponents['host']}\";\n        $baseUri .= $emulatorUriComponents['port'] ? \":{$emulatorUriComponents['port']}/\" : '/';\n\n        return $baseUri;\n    }", "label": 2}
{"code": "func execAction(action Action, opts map[string]interface{}) bool {\n\ta := Action{\n\t\tBee:  action.Bee,\n\t\tName: action.Name,\n\t}\n\n\tfor _, opt := range action.Options {\n\t\tph := Placeholder{\n\t\t\tName: opt.Name,\n\t\t}\n\n\t\tswitch opt.Value.(type) {\n\t\tcase string:\n\t\t\tvar value bytes.Buffer\n\n\t\t\ttmpl, err := template.New(action.Bee + \"_\" + action.Name + \"_\" + opt.Name).Funcs(templatehelper.FuncMap).Parse(opt.Value.(string))\n\t\t\tif err == nil {\n\t\t\t\terr = tmpl.Execute(&value, opts)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\n\t\t\tph.Type = \"string\"\n\t\t\tph.Value = value.String()\n\n\t\tdefault:\n\t\t\tph.Type = opt.Type\n\t\t\tph.Value = opt.Value\n\t\t}\n\t\ta.Options = append(a.Options, ph)\n\t}\n\n\tbee := GetBee(a.Bee)\n\tif (*bee).IsRunning() {\n\t\t(*bee).LogAction()\n\n\t\tlog.Println(\"\\tExecuting action:\", a.Bee, \"/\", a.Name, \"-\", GetActionDescriptor(&a).Description)\n\t\tfor _, v := range a.Options {\n\t\t\tlog.Println(\"\\t\\tOptions:\", v)\n\t\t}\n\n\t\t(*bee).Action(a)\n\t} else {\n\t\tlog.Println(\"\\tNot executing action on stopped bee:\", a.Bee, \"/\", a.Name, \"-\", GetActionDescriptor(&a).Description)\n\t\tfor _, v := range a.Options {\n\t\t\tlog.Println(\"\\t\\tOptions:\", v)\n\t\t}\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "def exists?\n      if located? && stale?\n        Watir.logger.deprecate 'Checking `#exists? == false` to determine a stale element',\n                               '`#stale? == true`',\n                               reference: 'http://watir.com/staleness-changes',\n                               ids: [:stale_exists]\n        # TODO: Change this to `reset!` after removing deprecation\n        return false\n      end\n\n      assert_exists\n      true\n    rescue UnknownObjectException, UnknownFrameException\n      false\n    end", "label": 4}
{"code": "def more_like_this(object, *types, &block)\n      mlt = new_more_like_this(object, *types, &block)\n      mlt.execute\n    end", "label": 4}
{"code": "func (nDB *NetworkDB) LeaveNetwork(nid string) error {\n\tltime := nDB.networkClock.Increment()\n\tif err := nDB.sendNetworkEvent(nid, NetworkEventTypeLeave, ltime); err != nil {\n\t\treturn fmt.Errorf(\"failed to send leave network event for %s: %v\", nid, err)\n\t}\n\n\tnDB.Lock()\n\tdefer nDB.Unlock()\n\n\t// Remove myself from the list of the nodes participating to the network\n\tnDB.deleteNetworkNode(nid, nDB.config.NodeID)\n\n\t// Update all the local entries marking them for deletion and delete all the remote entries\n\tnDB.deleteNodeNetworkEntries(nid, nDB.config.NodeID)\n\n\tnodeNetworks, ok := nDB.networks[nDB.config.NodeID]\n\tif !ok {\n\t\treturn fmt.Errorf(\"could not find self node for network %s while trying to leave\", nid)\n\t}\n\n\tn, ok := nodeNetworks[nid]\n\tif !ok {\n\t\treturn fmt.Errorf(\"could not find network %s while trying to leave\", nid)\n\t}\n\n\tlogrus.Debugf(\"%v(%v): leaving network %s\", nDB.config.Hostname, nDB.config.NodeID, nid)\n\tn.ltime = ltime\n\tn.reapTime = nDB.config.reapNetworkInterval\n\tn.leaving = true\n\treturn nil\n}", "label": 5}
{"code": "def proxy_bypass? host, port\n    host = host.downcase\n    host_port = [host, port].join ':'\n\n    @no_proxy.each do |name|\n      return true if host[-name.length, name.length] == name or\n         host_port[-name.length, name.length] == name\n    end\n\n    false\n  end", "label": 4}
{"code": "public function setJoyLikelihood($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Vision\\V1\\Likelihood::class);\n        $this->joy_likelihood = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response delete(nitro_service client, String xmlcontenttypevalue) throws Exception {\n\t\tappfwxmlcontenttype deleteresource = new appfwxmlcontenttype();\n\t\tdeleteresource.xmlcontenttypevalue = xmlcontenttypevalue;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def pause_knocks(obj):\n    \"\"\"\n    Context manager to suspend sending knocks for the given model\n\n    :param obj: model instance\n    \"\"\"\n    if not hasattr(_thread_locals, 'knock_enabled'):\n        _thread_locals.knock_enabled = {}\n    obj.__class__._disconnect()\n    _thread_locals.knock_enabled[obj.__class__] = False\n    yield\n    _thread_locals.knock_enabled[obj.__class__] = True\n    obj.__class__._connect()", "label": 1}
{"code": "def add(self, timestamp, information):\n        \"\"\"\n        Add event information.\n\n        Args:\n            timestamp (int): event timestamp.\n            information (dict): event information.\n\n        Raises:\n            RuntimeError: when validation of parameters has failed.\n        \"\"\"\n        try:\n            item = Schema(CollectorStage.schema_event_items()).validate({\n                'timestamp': timestamp, 'information': information\n            })\n            self.events.append(item)\n        except SchemaError as exception:\n            Logger.get_logger(__name__).error(exception)\n            raise RuntimeError(str(exception))", "label": 1}
{"code": "func ApplyPropertyChange(obj Reference, changes []types.PropertyChange) {\n\tt := typeInfoForType(obj.Reference().Type)\n\tv := reflect.ValueOf(obj)\n\n\tfor _, p := range changes {\n\t\trv, ok := t.props[p.Name]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tassignValue(v, rv, reflect.ValueOf(p.Val))\n\t}\n}", "label": 5}
{"code": "def oauth_link_external_id(user, external_id=None):\n    \"\"\"Link a user to an external id.\n\n    :param user: A :class:`invenio_accounts.models.User` instance.\n    :param external_id: The external id associated with the user.\n        (Default: ``None``)\n    :raises invenio_oauthclient.errors.AlreadyLinkedError: Raised if already\n        exists a link.\n    \"\"\"\n    try:\n        with db.session.begin_nested():\n            db.session.add(UserIdentity(\n                id=external_id['id'],\n                method=external_id['method'],\n                id_user=user.id\n            ))\n    except IntegrityError:\n        raise AlreadyLinkedError(user, external_id)", "label": 1}
{"code": "function set(path, value, opts) {\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n\n  let env = toUnderscore(path);\n  if (!opts.caseSensitive) {\n    env = env.toUpperCase();\n  }\n\n  del(path, opts);\n  process.env[env] = stringify(value, opts);\n}", "label": 3}
{"code": "def read_using_run_batch\n      ops = { RECV_MESSAGE => nil }\n      ops[RECV_INITIAL_METADATA] = nil unless @metadata_received\n      begin\n        batch_result = @call.run_batch(ops)\n        unless @metadata_received\n          @call.metadata = batch_result.metadata\n          @metadata_received = true\n        end\n        batch_result\n      rescue GRPC::Core::CallError => e\n        GRPC.logger.warn('bidi call: read_using_run_batch failed')\n        GRPC.logger.warn(e)\n        nil\n      end\n    end", "label": 4}
{"code": "def run_on_changes(modified, added, removed)\n      types = {\n        MODIFICATION_TASKS => modified,\n        ADDITION_TASKS => added,\n        REMOVAL_TASKS => removed\n      }\n\n      UI.clearable\n\n      Guard.state.scope.grouped_plugins.each do |_group, plugins|\n        _run_group_plugins(plugins) do |plugin|\n          UI.clear\n          types.each do |tasks, unmatched_paths|\n            next if unmatched_paths.empty?\n            match_result = Watcher.match_files(plugin, unmatched_paths)\n            next if match_result.empty?\n            task = tasks.detect { |meth| plugin.respond_to?(meth) }\n            _supervise(plugin, task, match_result) if task\n          end\n        end\n      end\n    end", "label": 4}
{"code": "protected function processInboundData($data)\n    {\n        $node = $this->reader->nextTree($data);\n        if ($node != null) {\n            $this->processInboundDataNode($node);\n        }\n    }", "label": 2}
{"code": "public function setVertices($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\Vertex::class);\n        $this->vertices = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (t *Torrent) SetDisplayName(dn string) {\n\tt.nameMu.Lock()\n\tdefer t.nameMu.Unlock()\n\tif t.haveInfo() {\n\t\treturn\n\t}\n\tt.displayName = dn\n}", "label": 5}
{"code": "public static String generateQuery(final String key, final Object value) {\n\t\tfinal Map<String, Object> params = new HashMap<>();\n\t\tparams.put(key, value);\n\t\treturn generateQuery(params);\n\t}", "label": 0}
{"code": "def encode_uvarint(n, data):\n    '''encodes integer into variable-length format into data.'''\n    if n < 0:\n        raise ValueError('only support positive integer')\n    while True:\n        this_byte = n & 127\n        n >>= 7\n        if n == 0:\n            data.append(this_byte)\n            break\n        data.append(this_byte | 128)", "label": 1}
{"code": "function readDirectory (srcDir) {\n  let srcTree = {}\n  const entries = fs.readdirSync(srcDir)\n\n  entries.forEach(function (entry) {\n    const filePath = path.join(srcDir, entry)\n    if (fs.lstatSync(filePath).isDirectory()) {\n      srcTree[entry] = readDirectory(filePath)\n    } else {\n      srcTree[entry] = fs.readFileSync(filePath, {\n        encoding: 'utf8'\n      })\n    }\n  })\n\n  return srcTree\n}", "label": 3}
{"code": "public void ifHasProperty(String template, Properties attributes) throws XDocletException\r\n    {\r\n        String value = getPropertyValue(attributes.getProperty(ATTRIBUTE_LEVEL), attributes.getProperty(ATTRIBUTE_NAME));\r\n\r\n        if (value != null)\r\n        {\r\n            generate(template);\r\n        }\r\n    }", "label": 0}
{"code": "private function interactiveCommitRelease(OutputInterface $output, array $commit, array $components)\n    {\n        $commitRelease = $this->processCommit($output, $commit, $components);\n\n        $proceed = false;\n        do {\n            $this->displayCommitSummary($output, $commitRelease);\n\n            $output->writeln('');\n\n            $choices = [\n                'Proceed without changes',\n                'Change Release Message',\n                'Change Release Type to Patch',\n                'Change Release Type to Minor',\n                'Change Release Type to Major',\n                'Start over'\n            ];\n            $q = $this->choice('Choose an action', $choices, $choices[0]);\n\n            $action = $this->askQuestion($q);\n            $action = $this->removeDefaultFromChoice($action);\n\n            switch ($action) {\n                case $choices[0]:\n                    $proceed = true;\n                    break;\n\n                case $choices[1]:\n                    $commitRelease = $this->handleChange($output, $commitRelease);\n                    break;\n\n                case $choices[2]: // patch\n                    $commitRelease = $this->handleChange($output, $commitRelease, self::LEVEL_PATCH);\n                    break;\n\n                case $choices[3]: // minor\n                    $commitRelease = $this->handleChange($output, $commitRelease, self::LEVEL_MINOR);\n                    break;\n\n                case $choices[4]: // major\n                    $commitRelease = $this->handleChange($output, $commitRelease, self::LEVEL_MAJOR);\n                    break;\n\n                case $choices[5]:\n                    $commitRelease = $this->processCommit($output, $commit, $components);\n                    break;\n            }\n        } while (!$proceed);\n\n        $output->writeln('');\n\n        return $commitRelease;\n    }", "label": 2}
{"code": "function (node) {\n        var ownerDocument = node.ownerDocument,\n            qualified = _gpfWebGetNamespaceAndName(this._nodeName);\n        if (qualified) {\n            return ownerDocument.createElementNS(qualified.namespace, qualified.name);\n        }\n        return ownerDocument.createElement(this._nodeName);\n    }", "label": 3}
{"code": "private function handleInfoResponse($response)\n    {\n        $info = array();\n\n        foreach (preg_split('/\\r?\\n/', $response) as $row) {\n            if (strpos($row, ':') === false) {\n                continue;\n            }\n\n            list($k, $v) = explode(':', $row, 2);\n            $info[$k] = $v;\n        }\n\n        return $info;\n    }", "label": 2}
{"code": "def fetch_text(type)\n      UI.user_error!(\"Valid parameters :keyword, :title\") unless [:keyword, :title].include?(type)\n\n      # Try to get it from a keyword.strings or title.strings file\n      strings_path = File.join(File.expand_path(\"..\", screenshot.path), \"#{type}.strings\")\n      if File.exist?(strings_path)\n        parsed = StringsParser.parse(strings_path)\n        text_array = parsed.find { |k, v| screenshot.path.upcase.include?(k.upcase) }\n        return text_array.last if text_array && text_array.last.length > 0 # Ignore empty string\n      end\n\n      UI.verbose(\"Falling back to text in Framefile.json as there was nothing specified in the #{type}.strings file\")\n\n      # No string files, fallback to Framefile config\n      text = fetch_config[type.to_s]['text'] if fetch_config[type.to_s] && fetch_config[type.to_s]['text'] && fetch_config[type.to_s]['text'].length > 0 # Ignore empty string\n      return text\n    end", "label": 4}
{"code": "def retrieve_employee_role(role_id, opts = {})\n      data, _status_code, _headers = retrieve_employee_role_with_http_info(role_id, opts)\n      return data\n    end", "label": 4}
{"code": "public static dnsnsrec get(nitro_service service, String domain) throws Exception{\n\t\tdnsnsrec obj = new dnsnsrec();\n\t\tobj.set_domain(domain);\n\t\tdnsnsrec response = (dnsnsrec) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static double Cosh(double x, int nTerms) {\r\n        if (nTerms < 2) return x;\r\n        if (nTerms == 2) {\r\n            return 1 + (x * x) / 2D;\r\n        } else {\r\n\r\n            double mult = x * x;\r\n            double fact = 2;\r\n            int factS = 4;\r\n            double result = 1 + mult / fact;\r\n            for (int i = 3; i <= nTerms; i++) {\r\n                mult *= x * x;\r\n                fact *= factS * (factS - 1);\r\n                factS += 2;\r\n                result += mult / fact;\r\n            }\r\n\r\n            return result;\r\n        }\r\n    }", "label": 0}
{"code": "func (ds *datastore) PutObjectAtomic(kvObject KVObject) error {\n\tvar (\n\t\tprevious *store.KVPair\n\t\tpair     *store.KVPair\n\t\terr      error\n\t)\n\tif ds.sequential {\n\t\tds.Lock()\n\t\tdefer ds.Unlock()\n\t}\n\n\tif kvObject == nil {\n\t\treturn types.BadRequestErrorf(\"invalid KV Object : nil\")\n\t}\n\n\tkvObjValue := kvObject.Value()\n\n\tif kvObjValue == nil {\n\t\treturn types.BadRequestErrorf(\"invalid KV Object with a nil Value for key %s\", Key(kvObject.Key()...))\n\t}\n\n\tif kvObject.Skip() {\n\t\tgoto add_cache\n\t}\n\n\tif kvObject.Exists() {\n\t\tprevious = &store.KVPair{Key: Key(kvObject.Key()...), LastIndex: kvObject.Index()}\n\t} else {\n\t\tprevious = nil\n\t}\n\n\t_, pair, err = ds.store.AtomicPut(Key(kvObject.Key()...), kvObjValue, previous, nil)\n\tif err != nil {\n\t\tif err == store.ErrKeyExists {\n\t\t\treturn ErrKeyModified\n\t\t}\n\t\treturn err\n\t}\n\n\tkvObject.SetIndex(pair.LastIndex)\n\nadd_cache:\n\tif ds.cache != nil {\n\t\t// If persistent store is skipped, sequencing needs to\n\t\t// happen in cache.\n\t\treturn ds.cache.add(kvObject, kvObject.Skip())\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static autoscalepolicy_binding get(nitro_service service, String name) throws Exception{\n\t\tautoscalepolicy_binding obj = new autoscalepolicy_binding();\n\t\tobj.set_name(name);\n\t\tautoscalepolicy_binding response = (autoscalepolicy_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function resolveProvide(obj, override) {\n    var provide = override || obj.$provide;\n\n    if(isString(provide)) {\n      return provideName(obj, provide);\n    }\n\n    if(isObject(provide)) {\n      if (isString(provide.promise)) {\n        return providePromise(obj, provide.promise);\n      } else if (isString(provide.provide)) {\n        return provideName(obj, provide.provide);\n      }\n    }\n  }", "label": 3}
{"code": "function buildPatterns(collectionObj, options) {\n  const patterns = {};\n  for (const childKey in collectionObj) {\n    if (isPattern(collectionObj[childKey])) {\n      patterns[childKey] = buildPattern(collectionObj[childKey], options);\n      delete collectionObj[childKey];\n    }\n  }\n  return patterns;\n}", "label": 3}
{"code": "function _select (node, expr) {\n        var\n            resultSet,\n            nodeSet = [node];\n        while (expr) {\n            resultSet = [];\n            _test(nodeSet, expr, resultSet);\n            if (0 === resultSet.length) {\n                return [];\n            }\n            nodeSet = resultSet;\n            if (expr.filter) {\n                resultSet = [];\n                _each(nodeSet, _filter, expr.filter, resultSet);\n                if (0 === resultSet.length) {\n                    return [];\n                }\n                nodeSet = resultSet;\n            }\n            expr = expr.then;\n        }\n        return resultSet;\n    }", "label": 3}
{"code": "function() {\n        var distDir = this.readConfig('distDir');\n        var packedDirName = this.readConfig('packedDirName');\n        var archivePath = this.readConfig('archivePath');\n\n        if (packedDirName) {\n          packedDirName = path.join(archivePath, packedDirName);\n          this.log('moving ' + distDir + ' to ' + packedDirName);\n\n          this.distDir = packedDirName;\n          return move(distDir, packedDirName);\n        }\n\n        return RSVP.resolve();\n      }", "label": 3}
{"code": "function writer(err, collections) {\n    if (err) return done(err);\n\n    // @TODO make sure that self.write only accepts 2 arguments and reads the\n    // type from the supplied collection object.\n    self.logger.debug('Writing files');\n    async.map(collections, self.write.bind(self), done);\n  }", "label": 3}
{"code": "public static function &processors()\n    {\n        if (!self::$processors) {\n            // Add default processors.\n            self::$processors = [\n                new MergeIntoOpenApi(),\n                new MergeIntoComponents(),\n                new ImportTraits(),\n                new AugmentSchemas(),\n                new AugmentProperties(),\n                new BuildPaths(),\n                // new HandleReferences(),\n\n                new InheritProperties(),\n                new AugmentOperations(),\n                new AugmentParameters(),\n                new MergeJsonContent(),\n                new MergeXmlContent(),\n                new OperationId(),\n                new CleanUnmerged(),\n            ];\n        }\n\n        return self::$processors;\n    }", "label": 2}
{"code": "func (ta *TextArea) SetLines(lines []string) {\n\tta.Init()\n\tm := ta.model\n\tm.width = 0\n\tm.height = len(lines)\n\tm.lines = append([]string{}, lines...)\n\tfor _, l := range lines {\n\t\tif len(l) > m.width {\n\t\t\tm.width = len(l)\n\t\t}\n\t}\n\tta.CellView.SetModel(m)\n}", "label": 5}
{"code": "def to_a\n      hash = {}\n      @to_a ||=\n        elements_with_tags.map.with_index do |(el, tag_name), idx|\n          selector = @selector.dup\n          selector[:index] = idx unless idx.zero?\n          element = element_class.new(@query_scope, selector)\n          if [HTMLElement, Input].include? element.class\n            construct_subtype(element, hash, tag_name).tap { |e| e.cache = el }\n          else\n            element.tap { |e| e.cache = el }\n          end\n        end\n    end", "label": 4}
{"code": "def push_doc_to_remote(self, remote_name, doc_id=None):\n        \"\"\"This will push the master branch to the remote named `remote_name`\n        using the mirroring strategy to cut down on locking of the working repo.\n\n        `doc_id` is used to determine which shard should be pushed.\n        if `doc_id` is None, all shards are pushed.\n        \"\"\"\n        if doc_id is None:\n            ret = True\n            # @TODO should spawn a thread of each shard...\n            for shard in self._shards:\n                if not shard.push_to_remote(remote_name):\n                    ret = False\n            return ret\n        shard = self.get_shard(doc_id)\n        return shard.push_to_remote(remote_name)", "label": 1}
{"code": "public function setOptions($options)\n    {\n        if (!is_int($options) && !is_null($options)) {\n            throw new InvalidArgumentException('Invalid options.');\n        }\n\n        $this->options = $options ?: 0;\n\n        $this->handleChangedParameters();\n\n        return $this;\n    }", "label": 2}
{"code": "function formatAttributes(outNode, profile) {\n\tconst node = outNode.node;\n\n\treturn node.attributes.map(attr => {\n\t\tif (attr.options.implied && attr.value == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tconst attrName = profile.attribute(attr.name);\n\t\tlet attrValue = null;\n\n\t\t// handle boolean attributes\n\t\tif (attr.options.boolean || profile.get('booleanAttributes').indexOf(attrName.toLowerCase()) !== -1) {\n\t\t\tif (profile.get('compactBooleanAttributes') && attr.value == null) {\n\t\t\t\treturn ` ${attrName}`;\n\t\t\t} else if (attr.value == null) {\n\t\t\t\tattrValue = attrName;\n\t\t\t}\n\t\t}\n\n\t\tif (attrValue == null) {\n\t\t\tattrValue = outNode.renderFields(attr.value);\n\t\t}\n\n\t\treturn attr.options.before && attr.options.after\n\t\t\t? ` ${attrName}=${attr.options.before+attrValue+attr.options.after}`\n\t\t\t: ` ${attrName}=${profile.quote(attrValue)}`;\n\t}).join('');\n}", "label": 3}
{"code": "function omit(req, blacklist) {\n    return omitBy(req, (value, key) => blacklist.includes(key));\n}", "label": 3}
{"code": "function addInitiatedOnce(name, mixin, params) {\n            mixin = mixin.call(this, params || []);\n            // find the name placeholder in the return arr and replace it with the mixin\n            var index = rtn.indexOf(name);\n            rtn.splice(index, 1, mixin);\n        }", "label": 3}
{"code": "func (v ContainerView) Find(ctx context.Context, kind []string, filter property.Filter) ([]types.ManagedObjectReference, error) {\n\tif len(filter) == 0 {\n\t\t// Ensure we have at least 1 filter to avoid retrieving all properties.\n\t\tfilter = property.Filter{\"name\": \"*\"}\n\t}\n\n\tvar content []types.ObjectContent\n\n\terr := v.Retrieve(ctx, kind, filter.Keys(), &content)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn filter.MatchObjectContent(content), nil\n}", "label": 5}
{"code": "func (t *TextBar) Size() (int, int) {\n\tw, h := 0, 0\n\n\tww, wh := t.left.Size()\n\tw += ww\n\tif wh > h {\n\t\th = wh\n\t}\n\tww, wh = t.center.Size()\n\tw += ww\n\tif wh > h {\n\t\th = wh\n\t}\n\tww, wh = t.right.Size()\n\tw += ww\n\tif wh > h {\n\t\th = wh\n\t}\n\treturn w, h\n}", "label": 5}
{"code": "public function setType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Bigtable\\Admin\\V2\\Instance_Type::class);\n        $this->type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private function getConnectionType(array $config)\n    {\n        $isGrpcExtensionLoaded = $this->isGrpcLoaded();\n        $defaultTransport = $isGrpcExtensionLoaded ? 'grpc' : 'rest';\n        $transport = isset($config['transport'])\n            ? strtolower($config['transport'])\n            : $defaultTransport;\n\n        if ($transport === 'grpc') {\n            if (!$isGrpcExtensionLoaded) {\n                throw new GoogleException(\n                    'gRPC support has been requested but required dependencies ' .\n                    'have not been found. ' . $this->getGrpcInstallationMessage()\n                );\n            }\n        }\n\n        return $transport;\n    }", "label": 2}
{"code": "public function fromCode($code, $context)\n    {\n        $tokens = token_get_all($code);\n\n        return $this->fromTokens($tokens, $context);\n    }", "label": 2}
{"code": "public static csvserver_cspolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tcsvserver_cspolicy_binding obj = new csvserver_cspolicy_binding();\n\t\tobj.set_name(name);\n\t\tcsvserver_cspolicy_binding response[] = (csvserver_cspolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void fillFromToWith(int from, int to, Object val) {\r\n\tcheckRangeFromTo(from,to,this.size);\r\n\tfor (int i=from; i<=to;) setQuick(i++,val); \r\n}", "label": 0}
{"code": "function (arrays, config, onDone) {\n\t\n\tvar names = [];\n\t\t\n\t// load array's content from DB, if any\t\n\tSR.DB.getArray(SR.Settings.DB_NAME_SYNC,\n\t\t\t\t\tfunction (result) {\n\t\t\t\t\t\t// NOTE: if array does not exist it'll return success with an empty array\n\t\t\t\t\t\tif (result === null || result.length === 0) {\n\t\t\t\t\t\t\tLOG.warn('no arrays found, cannot load', 'SR.Sync');\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tvar array_limit = (typeof config.limit === 'number' ? config.limit : 0);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tLOG.sys('arrays exist, try to load (limit: ' + array_limit + ')', 'SR.Sync');\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tfor (var i=0; i < result.length; i++) {\n\t\t\t\t\t\t\t\tvar record = result[i];\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tvar arr = arrays[record.name] = [];\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t// load data (clone is better?)\n\t\t\t\t\t\t\t\tvar limit = (record.data.length > array_limit ? array_limit : record.data.length);\n\n\t\t\t\t\t\t\t\tvar start = record.data.length - limit;\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tfor (var j=0; j < limit; j++)\n\t\t\t\t\t\t\t\t\tarr[j] = UTIL.clone(record.data[start+j]);\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t// override array's default behavior\n\t\t\t\t\t\t\t\tarr.push = l_push;\n\t\n\t\t\t\t\t\t\t\t// store array's name\n\t\t\t\t\t\t\t\tarr._name = record.name;\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t// store last stored index (next index to store)\n\t\t\t\t\t\t\t\tarr._index = j;\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tLOG.sys('[' + record.name + '] DB record length: ' + record.data.length + ' start: ' + start + ' actual limit: ' + limit + ' _index: ' + arr._index, 'SR.Sync');\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tl_names[record.name] = arr;\n\t\t\t\t\t\t\t\tnames.push(record.name);\n\t\t\t\t\t\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t}\n\t\t\t\t\t\tUTIL.safeCall(onDone, names);\n\t\t\t\t\t\t\n\t\t\t\t\t}, \n\t\t\t\t\tfunction (result) {\n\t\t\t\t\t\tUTIL.safeCall(onDone, names);\n\t\t\t\t\t}, \n\t\t\t\t\t{});\n}", "label": 3}
{"code": "public function setRowKeys($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::BYTES);\n        $this->row_keys = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setStructuredQuery($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\StructuredQuery::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (l VirtualDeviceList) InsertIso(device *types.VirtualCdrom, iso string) *types.VirtualCdrom {\n\tdevice.Backing = &types.VirtualCdromIsoBackingInfo{\n\t\tVirtualDeviceFileBackingInfo: types.VirtualDeviceFileBackingInfo{\n\t\t\tFileName: iso,\n\t\t},\n\t}\n\n\treturn device\n}", "label": 5}
{"code": "public function setTransferRuns($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferRun::class);\n        $this->transfer_runs = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def to_xml_string(str = '')\n      str << '<cfRule '\n      serialized_attributes str\n      str << '>'\n      str << ('<formula>' << [*self.formula].join('</formula><formula>') << '</formula>') if @formula\n      @color_scale.to_xml_string(str) if @color_scale && @type == :colorScale\n      @data_bar.to_xml_string(str) if @data_bar && @type == :dataBar\n      @icon_set.to_xml_string(str) if @icon_set && @type == :iconSet\n      str << '</cfRule>'\n    end", "label": 4}
{"code": "def has_visible_scopes?(resource)\n      resource.participatory_space.scopes_enabled? &&\n        resource.scope.present? &&\n        resource.participatory_space.scope != resource.scope\n    end", "label": 4}
{"code": "public static String formatConnectionEstablishmentMessage(final String connectionName, final String host, final String connectionReason) {\n\t\treturn CON_ESTABLISHMENT_FORMAT.format(new Object[] { connectionName, host, connectionReason });\n\t}", "label": 0}
{"code": "def each\n      process(@initial_result).each { |doc| yield doc }\n      while more?\n        return kill_cursors if exhausted?\n        get_more.each { |doc| yield doc }\n      end\n    end", "label": 4}
{"code": "def parse_star_fusion(infile):\n    \"\"\"\n    Parses STAR-Fusion format and returns an Expando object with basic features\n\n    :param str infile: path to STAR-Fusion prediction file\n    :return: Fusion prediction attributes\n    :rtype: bd2k.util.expando.Expando\n    \"\"\"\n    reader = csv.reader(infile, delimiter='\\t')\n    header = reader.next()\n    header = {key: index for index, key in enumerate(header)}\n\n    features = ['LeftGene', 'LeftLocalBreakpoint', 'LeftBreakpoint',\n                'RightGene', 'RightLocalBreakpoint', 'RightBreakpoint',\n                'LargeAnchorSupport', 'JunctionReadCount', 'SpanningFragCount']\n\n    for line in reader:\n        yield Expando(dict((feature, line[header[feature]]) for feature in features))", "label": 1}
{"code": "public static boolean isAssignableFrom(TypeReference<?> from, TypeReference<?> to) {\n\t\tif (from == null) {\n\t\t\treturn false;\n\t\t}\n\n\t\tif (to.equals(from)) {\n\t\t\treturn true;\n\t\t}\n\n\t\tif (to.getType() instanceof Class) {\n\t\t\treturn to.getRawType().isAssignableFrom(from.getRawType());\n\t\t} else if (to.getType() instanceof ParameterizedType) {\n\t\t\treturn isAssignableFrom(from.getType(), (ParameterizedType) to\n\t\t\t\t\t.getType(), new HashMap<String, Type>());\n\t\t} else if (to.getType() instanceof GenericArrayType) {\n\t\t\treturn to.getRawType().isAssignableFrom(from.getRawType())\n\t\t\t\t\t&& isAssignableFrom(from.getType(), (GenericArrayType) to\n\t\t\t\t\t\t\t.getType());\n\t\t} else {\n\t\t\tthrow new AssertionError(\"Unexpected Type : \" + to);\n\t\t}\n\t}", "label": 0}
{"code": "def deliver!(mail)\n      envelope = Mail::SmtpEnvelope.new(mail)\n      response = smtp.sendmail(dot_stuff(envelope.message), envelope.from, envelope.to)\n      settings[:return_response] ? response : self\n    end", "label": 4}
{"code": "function (key, value) {\n                if (docMode8) { // IE8 setAttribute bug\n                    this.element[key] = value;\n                } else {\n                    this.element.setAttribute(key, value);\n                }\n            }", "label": 3}
{"code": "def path(state, rule)\n      rule.symbols.each_with_object([]) do |tok, path|\n        goto = state.gotos[tok]\n        path << goto\n        state = goto.to_state\n      end\n    end", "label": 4}
{"code": "public Integer next() {\n\t\tfor(int i = currentIndex; i < t.size(); i++){\n\t\t\tif(i+timelag>=t.size()){\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tif((t.get(i) != null) && (t.get(i+timelag) != null)){\n\t\t\t\tif(overlap){\n\t\t\t\t\tcurrentIndex = i+1;\n\t\t\t\t}\n\t\t\t\telse{\n\t\t\t\t\tcurrentIndex = i+timelag;\n\t\t\t\t}\n\t\t\t\treturn i;\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn null;\n\t}", "label": 0}
{"code": "function isLodashPluginWithSemanticUiReact(plugin) {\n    if (Array.isArray(plugin)) {\n        // Babel 6 plugin is a tuple as an array [id, options]\n        return (\n            [\"lodash\", \"babel-plugin-lodash\"].includes(plugin[0].key) &&\n            [].concat(plugin[1].id).includes(\"semantic-ui-react\")\n        );\n    } else if (plugin != null && typeof plugin === \"object\") {\n      // Babel 7 plugin is an object { key, options, ... }\n        return (\n            /[/\\\\]node_modules([/\\\\].*)?[/\\\\]babel-plugin-lodash([/\\\\].*)?$/.test(plugin.key) &&\n            plugin.options &&\n            plugin.options.id &&\n            [].concat(plugin.options.id).includes(\"semantic-ui-react\")\n        );\n    } else {\n        return false;\n    }\n}", "label": 3}
{"code": "func (nDB *NetworkDB) Close() {\n\tif err := nDB.clusterLeave(); err != nil {\n\t\tlogrus.Errorf(\"%v(%v) Could not close DB: %v\", nDB.config.Hostname, nDB.config.NodeID, err)\n\t}\n\n\t//Avoid (*Broadcaster).run goroutine leak\n\tnDB.broadcaster.Close()\n}", "label": 5}
{"code": "func (c *Manager) FindLibrary(ctx context.Context, search Find) ([]string, error) {\n\turl := internal.URL(c, internal.LibraryPath).WithAction(\"find\")\n\tspec := struct {\n\t\tSpec Find `json:\"spec\"`\n\t}{search}\n\tvar res []string\n\treturn res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "function convertMatches(files, options, dest) {\n    return files.map(function(source) {\n      return {\n        src: source,\n        dest: path.join(\n          // Build a destination from the new source if no dest\n          // was specified\n          dest != null ? dest : path.dirname(source).replace(options.srcPrefix + sep, ''),\n          path.basename(source)\n        )\n      }\n    })\n  }", "label": 3}
{"code": "public static base_response delete(nitro_service client, dnsaaaarec resource) throws Exception {\n\t\tdnsaaaarec deleteresource = new dnsaaaarec();\n\t\tdeleteresource.hostname = resource.hostname;\n\t\tdeleteresource.ipv6address = resource.ipv6address;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def _get_generator_ramping_construct(self):\n        \"\"\" Returns a construct for an array of generator ramping data.\n        \"\"\"\n        supply_no = integer.setResultsName(\"supply_no\")\n        s_rating = real.setResultsName(\"s_rating\") # MVA\n        up_rate = real.setResultsName(\"up_rate\") # p.u./h\n        down_rate = real.setResultsName(\"down_rate\") # p.u./h\n        min_period_up = real.setResultsName(\"min_period_up\") # h\n        min_period_down = real.setResultsName(\"min_period_down\") # h\n        initial_period_up = integer.setResultsName(\"initial_period_up\")\n        initial_period_down = integer.setResultsName(\"initial_period_down\")\n        c_startup = real.setResultsName(\"c_startup\") # $\n        status = boolean.setResultsName(\"status\")\n\n        g_ramp_data = supply_no + s_rating + up_rate + down_rate + \\\n            min_period_up + min_period_down + initial_period_up + \\\n            initial_period_down + c_startup + status + scolon\n\n        g_ramp_array = Literal(\"Rmpg.con\") + \"=\" + \"[\" + \\\n            ZeroOrMore(g_ramp_data + Optional(\"]\" + scolon))\n\n        return g_ramp_array", "label": 1}
{"code": "public static sslpolicy_sslpolicylabel_binding[] get(nitro_service service, String name) throws Exception{\n\t\tsslpolicy_sslpolicylabel_binding obj = new sslpolicy_sslpolicylabel_binding();\n\t\tobj.set_name(name);\n\t\tsslpolicy_sslpolicylabel_binding response[] = (sslpolicy_sslpolicylabel_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def read_credentials(fname):\n    \"\"\"\n    read a simple text file from a private location to get\n    username and password\n    \"\"\"\n    with open(fname, 'r') as f:\n        username = f.readline().strip('\\n')\n        password = f.readline().strip('\\n')\n    return username, password", "label": 1}
{"code": "public function setTenants($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\Tenant::class);\n        $this->tenants = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (l *LiteBackend) Imported(ctx context.Context) (imported bool, err error) {\n\terr = l.inTransaction(ctx, func(tx *sql.Tx) error {\n\t\tq, err := tx.PrepareContext(ctx,\n\t\t\t\"SELECT imported from meta LIMIT 1\")\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\trow := q.QueryRowContext(ctx)\n\t\tif err := row.Scan(&imported); err != nil {\n\t\t\tif err != sql.ErrNoRows {\n\t\t\t\treturn trace.Wrap(err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn imported, err\n}", "label": 5}
{"code": "def _l_cv_weight(self, donor_catchment):\n        \"\"\"\n        Return L-CV weighting for a donor catchment.\n\n        Methodology source: Science Report SC050050, eqn. 6.18 and 6.22a\n        \"\"\"\n        try:\n            dist = donor_catchment.similarity_dist\n        except AttributeError:\n            dist = self._similarity_distance(self.catchment, donor_catchment)\n        b = 0.0047 * sqrt(dist) + 0.0023 / 2\n        c = 0.02609 / (donor_catchment.record_length - 1)\n        return 1 / (b + c)", "label": 1}
{"code": "function(event) {\n\t\t\t\t\t\t\t\tvar options = opts;\n\t\t\t\t\t\t\t\t//find the currently selected tool if comes from keystroke\n\t\t\t\t\t\t\t\tif (event.type === 'keydown') {\n\t\t\t\t\t\t\t\t\tvar flyoutIsSelected = $(options.parent + '_show').hasClass('tool_button_current');\n\t\t\t\t\t\t\t\t\tvar currentOperation = $(options.parent + '_show').attr('data-curopt');\n\t\t\t\t\t\t\t\t\t$.each(holders[opts.parent], function(i, tool) {\n\t\t\t\t\t\t\t\t\t\tif (tool.sel == currentOperation) {\n\t\t\t\t\t\t\t\t\t\t\tif (!event.shiftKey || !flyoutIsSelected) {\n\t\t\t\t\t\t\t\t\t\t\t\toptions = tool;\n\t\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\t\toptions = holders[opts.parent][i+1] || holders[opts.parent][0];\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif ($(this).hasClass('disabled')) {return false;}\n\t\t\t\t\t\t\t\tif (toolButtonClick(show_sel)) {\n\t\t\t\t\t\t\t\t\toptions.fn();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tvar icon;\n\t\t\t\t\t\t\t\tif (options.icon) {\n\t\t\t\t\t\t\t\t\ticon = $.getSvgIcon(options.icon, true);\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\ticon = $(options.sel).children().eq(0).clone();\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\ticon[0].setAttribute('width', shower.width());\n\t\t\t\t\t\t\t\ticon[0].setAttribute('height', shower.height());\n\t\t\t\t\t\t\t\tshower.children(':not(.flyout_arrow_horiz)').remove();\n\t\t\t\t\t\t\t\tshower.append(icon).attr('data-curopt', options.sel); // This sets the current mode\n\t\t\t\t\t\t\t}", "label": 3}
{"code": "public String[] getAttributeNames()\r\n    {\r\n        Set      keys   = (attributeMap == null ? new HashSet() : attributeMap.keySet());\r\n        String[] result = new String[keys.size()];\r\n\r\n        keys.toArray(result);\r\n        return result;\r\n    }", "label": 0}
{"code": "public static function constructResolver(string $className, string $methodName): Closure\n    {\n        if (! method_exists($className, $methodName)) {\n            throw new DefinitionException(\"Method '{$methodName}' does not exist on class '{$className}'\");\n        }\n\n        return Closure::fromCallable([app($className), $methodName]);\n    }", "label": 2}
{"code": "func (h *Handle) Destroy() error {\n\tfor {\n\t\tif err := h.deleteFromStore(); err != nil {\n\t\t\tif _, ok := err.(types.RetryError); !ok {\n\t\t\t\treturn fmt.Errorf(\"internal failure while destroying the sequence: %v\", err)\n\t\t\t}\n\t\t\t// Fetch latest\n\t\t\tif err := h.store.GetObject(datastore.Key(h.Key()...), h); err != nil {\n\t\t\t\tif err == datastore.ErrKeyNotFound { // already removed\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\treturn fmt.Errorf(\"failed to fetch from store when destroying the sequence: %v\", err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public static base_responses update(nitro_service client, rnat resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\trnat updateresources[] = new rnat[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new rnat();\n\t\t\t\tupdateresources[i].network = resources[i].network;\n\t\t\t\tupdateresources[i].netmask = resources[i].netmask;\n\t\t\t\tupdateresources[i].natip = resources[i].natip;\n\t\t\t\tupdateresources[i].td = resources[i].td;\n\t\t\t\tupdateresources[i].aclname = resources[i].aclname;\n\t\t\t\tupdateresources[i].redirectport = resources[i].redirectport;\n\t\t\t\tupdateresources[i].natip2 = resources[i].natip2;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def proxy_from_env\n    env_proxy = ENV['http_proxy'] || ENV['HTTP_PROXY']\n\n    return nil if env_proxy.nil? or env_proxy.empty?\n\n    uri = URI normalize_uri env_proxy\n\n    env_no_proxy = ENV['no_proxy'] || ENV['NO_PROXY']\n\n    # '*' is special case for always bypass\n    return nil if env_no_proxy == '*'\n\n    if env_no_proxy then\n      uri.query = \"no_proxy=#{escape(env_no_proxy)}\"\n    end\n\n    unless uri.user or uri.password then\n      uri.user     = escape ENV['http_proxy_user'] || ENV['HTTP_PROXY_USER']\n      uri.password = escape ENV['http_proxy_pass'] || ENV['HTTP_PROXY_PASS']\n    end\n\n    uri\n  end", "label": 4}
{"code": "protected function getEmailData(User $user, $email)\n    {\n        $token = $this->generateToken($user, $email);\n\n        return [\n            '{username}' => $user->display_name,\n            '{url}' => $this->url->to('forum')->route('confirmEmail', ['token' => $token->token]),\n            '{forum}' => $this->settings->get('forum_title')\n        ];\n    }", "label": 2}
{"code": "function() {\n    if (!builds.length) { return; } // this shouldn't happen\n\n    var build = builds.shift();\n    var buildCallback = function(stats) {\n      cb(build.buildName, stats);\n      if (builds.length) {\n        runNextBuild();\n      }\n    };\n    console.log(colors.cyan('[Starting build]'), build.buildName);\n    executeBuild(build, buildCallback);\n  }", "label": 3}
{"code": "function parseDirectory(dataStr) {\n\t\tlet currChar = '';\n\t\tlet directory = '';\n\t\tlet pos = 24;\n\n\t\twhile (currChar !== '\\x1E') {\n\t\t\tcurrChar = dataStr.charAt(pos);\n\t\t\tif (currChar !== 'x1E') {\n\t\t\t\tdirectory += currChar;\n\t\t\t}\n\n\t\t\tpos++;\n\n\t\t\tif (pos > dataStr.length) {\n\t\t\t\tthrow new Error('Invalid record');\n\t\t\t}\n\t\t}\n\n\t\treturn directory;\n\t}", "label": 3}
{"code": "def missing_interpolation_argument_handler\n      @@missing_interpolation_argument_handler ||= lambda do |missing_key, provided_hash, string|\n        raise MissingInterpolationArgument.new(missing_key, provided_hash, string)\n      end\n    end", "label": 4}
{"code": "public static function getFactor($source, $target)\n    {\n        $source = self::standardizeUnit($source);\n        $target = self::standardizeUnit($target);\n        $factors = static::getFlipCascadeFactors();\n        if (isset($factors[$source])) {\n            [$to, $factor] = $factors[$source];\n            if ($to === $target) {\n                return $factor;\n            }\n        }\n\n        return null;\n    }", "label": 2}
{"code": "func DjangoContentTypeByAppLabelModel(db XODB, appLabel string, model string) (*DjangoContentType, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, app_label, model ` +\n\t\t`FROM django.django_content_type ` +\n\t\t`WHERE app_label = ? AND model = ?`\n\n\t// run query\n\tXOLog(sqlstr, appLabel, model)\n\tdct := DjangoContentType{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, appLabel, model).Scan(&dct.ID, &dct.AppLabel, &dct.Model)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dct, nil\n}", "label": 5}
{"code": "public static final int findValueInListBox(ListBox list, String value) {\n\tfor (int i=0; i<list.getItemCount(); i++) {\n\t    if (value.equals(list.getValue(i))) {\n\t\treturn i;\n\t    }\n\t}\n\treturn -1;\n    }", "label": 0}
{"code": "func (t *FpdfTpl) FromPages() []Template {\n\tp := make([]Template, t.NumPages())\n\tfor x := 1; x <= t.NumPages(); x++ {\n\t\t// the only error is when accessing a\n\t\t// non existing template... that can't happen\n\t\t// here\n\t\tp[x-1], _ = t.FromPage(x)\n\t}\n\n\treturn p\n}", "label": 5}
{"code": "def serialized_tag(tagname, str, additional_attributes = {}, &block)\n      str << \"<#{tagname} \"\n      serialized_attributes(str, additional_attributes)\n      if block_given?\n        str << '>'\n        yield\n        str << \"</#{tagname}>\"\n      else\n        str << '/>'\n      end\n    end", "label": 4}
{"code": "function(input, callback, context, remoteData)\n  {\n    var db = this;\n    var promise = new Promise();\n\n    promise.success( callback, context || db );\n\n    function checkModel()\n    {\n      var result = db.parseModel( input, remoteData );\n\n      if ( result !== false && !promise.isComplete() && db.initialized )\n      {\n        var remoteLoaded = db.remoteLoaded || !db.hasLoad( Load.All );\n        var missingModel = (result === null || !result.$isSaved());\n        var lazyLoad = db.hasLoad( Load.Lazy );\n\n        if ( lazyLoad && remoteLoaded && missingModel )\n        {\n          if ( !result )\n          {\n            result = db.keyHandler.buildObjectFromKey( db.keyHandler.buildKeyFromInput( input ) );\n          }\n\n          result.$once( Model.Events.RemoteGets, function()\n          {\n            if ( !promise.isComplete() )\n            {\n              if ( isObject( input ) )\n              {\n                result.$set( input );\n              }\n\n              promise.resolve( result.$isSaved() ? result : null );\n            }\n          });\n\n          result.$refresh( Cascade.All, db.fetchOptions );\n        }\n        else\n        {\n          promise.resolve( result );\n        }\n      }\n\n      return promise.isComplete() ? false : true;\n    }\n\n    if ( checkModel() )\n    {\n      db.ready( checkModel, db, true );\n    }\n\n    return promise;\n  }", "label": 3}
{"code": "function indexTranslations() {\n  const { translations = {} } = getComponentsSettings();\n\n  return index({\n    file: 'translations.js',\n    config: {\n      type: TYPE_TRANSLATIONS,\n      config: translations,\n    },\n    defaultContent: 'export default null;\\n',\n    ...getIndexLogTranslations(TYPE_TRANSLATIONS),\n  });\n}", "label": 3}
{"code": "def compare_seqs_leven(seqs):\n    \"\"\"\n    calculate Levenshtein ratio of sequences\n    \"\"\"\n    A, B, ignore_gaps = seqs\n    a, b = remove_gaps(A[1], B[1]) # actual sequences\n    if len(a) != len(b):\n        print('# reads are not the same length', file=sys.stderr)\n        exit()\n    pident = lr(a, b) * 100\n    return A[0], B[0], pident", "label": 1}
{"code": "func (c *Manager) WaitOnLibraryItemUpdateSession(\n\tctx context.Context, sessionID string,\n\tinterval time.Duration, intervalCallback func()) error {\n\n\t// Wait until the upload operation is complete to return.\n\tfor {\n\t\tsession, err := c.GetLibraryItemUpdateSession(ctx, sessionID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif session.State != \"ACTIVE\" {\n\t\t\treturn nil\n\t\t}\n\t\ttime.Sleep(interval)\n\t\tif intervalCallback != nil {\n\t\t\tintervalCallback()\n\t\t}\n\t}\n}", "label": 5}
{"code": "public function walkIndexBy($indexBy)\n    {\n        $pathExpression = $indexBy->simpleStateFieldPathExpression;\n        $alias          = $pathExpression->identificationVariable;\n        $field          = $pathExpression->field;\n\n        if (isset($this->scalarFields[$alias][$field])) {\n            $this->rsm->addIndexByScalar($this->scalarFields[$alias][$field]);\n\n            return;\n        }\n\n        $this->rsm->addIndexBy($alias, $field);\n    }", "label": 2}
{"code": "public function runQuery(QueryInterface $query, array $options = [])\n    {\n        return $this->operation->runQuery($query, $options + [\n            'transaction' => $this->transactionId\n        ]);\n    }", "label": 2}
{"code": "public int compare(Object objA, Object objB)\r\n    {\r\n        String idAStr = ((FieldDescriptorDef)_fields.get(objA)).getProperty(\"id\");\r\n        String idBStr = ((FieldDescriptorDef)_fields.get(objB)).getProperty(\"id\");\r\n        int    idA;\r\n        int    idB;\r\n\r\n        try\r\n        {\r\n            idA = Integer.parseInt(idAStr);\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            return 1;\r\n        }\r\n        try\r\n        {\r\n            idB = Integer.parseInt(idBStr);\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            return -1;\r\n        }\r\n        return idA < idB ? -1 : (idA > idB ? 1 : 0);\r\n    }", "label": 0}
{"code": "def log_path_options(opts)\n      arr_opts = []\n\n      arr_opts << opts[:object] if opts[:object].is_a? String\n      arr_opts << '--' << opts[:path_limiter] if opts[:path_limiter]\n      arr_opts\n    end", "label": 4}
{"code": "def retrieve_title_and_description_for_model\n      # drop \"* Value Set\" from titles\n      exact_desc = title.split(' ')[0...-3].join(' ')\n      # don't drop anything for patient characterstic titles\n      exact_desc = title if @definition.start_with?('patient_characteristic') && !title.end_with?('Value Set')\n\n      # remove * Value Set from title\n      title_match = title.match(/(.*) \\w+ [Vv]alue [Ss]et/)\n      @title = title_match[1] if title_match && title_match.length > 1\n\n      @description = \"#{@description}: #{exact_desc}\"\n    end", "label": 4}
{"code": "def collect_plugins_in(provides_map, collected)\n      provides_map.each_key do |plugin|\n        if plugin.eql?(\"_plugins\")\n          collected.concat(provides_map[plugin])\n        else\n          collect_plugins_in(provides_map[plugin], collected)\n        end\n      end\n      collected\n    end", "label": 4}
{"code": "def page_url(url)\n      define_method(\"goto\") do\n        platform.navigate_to self.page_url_value\n      end\n\n      define_method('page_url_value') do\n        lookup = url.kind_of?(Symbol) ? self.send(url) : url\n        erb = ERB.new(%Q{#{lookup}})\n        merged_params = self.class.instance_variable_get(\"@merged_params\")\n        params = merged_params ? merged_params : self.class.params\n        erb.result(binding)\n      end\n    end", "label": 4}
{"code": "def read_with_retry(session = nil, server_selector = nil, &block)\n      if session.nil? && server_selector.nil?\n        # Older versions of Mongoid call read_with_retry without arguments.\n        # This is already not correct in a MongoDB 3.6+ environment with\n        # sessions. For compatibility we emulate the legacy driver behavior\n        # here but upgrading Mongoid is strongly recommended.\n        unless $_mongo_read_with_retry_warned\n          $_mongo_read_with_retry_warned = true\n          Logger.logger.warn(\"Legacy read_with_retry invocation - please update the application and/or its dependencies\")\n        end\n        # Since we don't have a session, we cannot use the modern read retries.\n        # And we need to select a server but we don't have a server selector.\n        # Use PrimaryPreferred which will work as long as there is a data\n        # bearing node in the cluster; the block may select a different server\n        # which is fine.\n        server_selector = ServerSelector.get(mode: :primary_preferred)\n        legacy_read_with_retry(nil, server_selector, &block)\n      elsif session && session.retry_reads?\n        modern_read_with_retry(session, server_selector, &block)\n      elsif client.max_read_retries > 0\n        legacy_read_with_retry(session, server_selector, &block)\n      else\n        server = select_server(cluster, server_selector)\n        yield server\n      end\n    end", "label": 4}
{"code": "def _subscribe(self):\n        \"\"\" Subscribe to the device.\n\n        A subscription serves two purposes:\n        - Returns state (on/off).\n        - Enables state changes on the device\n          for a short period of time.\n        \"\"\"\n        cmd = MAGIC + SUBSCRIBE + self._mac \\\n            + PADDING_1 + self._mac_reversed + PADDING_1\n        status = self._udp_transact(cmd, self._subscribe_resp)\n        if status is not None:\n            self.last_subscribed = time.time()\n            return status == ON\n        else:\n            raise S20Exception(\n                \"No status could be found for {}\".format(self.host))", "label": 1}
{"code": "def __get_ws_distance(wstation, latitude, longitude):\n    \"\"\"Get the distance to the weatherstation from wstation section of json.\n\n    wstation: weerstation section of buienradar json (dict)\n    latitude: our latitude\n    longitude: our longitude\n    \"\"\"\n    if wstation:\n        try:\n            wslat = float(wstation[__LAT])\n            wslon = float(wstation[__LON])\n\n            dist = vincenty((latitude, longitude), (wslat, wslon))\n            log.debug(\"calc distance: %s (latitude: %s, longitude: \"\n                      \"%s, wslat: %s, wslon: %s)\", dist, latitude,\n                      longitude, wslat, wslon)\n            return dist\n        except (ValueError, TypeError, KeyError):\n            # value does not exist, or is not a float\n            return None\n    else:\n        return None", "label": 1}
{"code": "def check_geom(c1, a1, c2, a2, tol=_DEF.XYZ_COORD_MATCH_TOL):\n    \"\"\" Check for consistency of two geometries and atom symbol lists\n\n    Cartesian coordinates are considered consistent with the input\n    coords if each component matches to within `tol`.  If coords or\n    atoms vectors are passed that are of mismatched lengths, a\n    |False| value is returned.\n\n    Both coords vectors must be three times the length of the atoms vectors\n    or a :exc:`~exceptions.ValueError` is raised.\n\n    Parameters\n    ----------\n    c1\n        length-3N |npfloat_| --\n        Vector of first set of stacked 'lab-frame' Cartesian coordinates\n\n    a1\n        length-N |str| or |int| --\n        Vector of first set of atom symbols or atomic numbers\n\n    c2\n        length-3N |npfloat_| --\n        Vector of second set of stacked 'lab-frame' Cartesian coordinates\n\n    a2\n        length-N |str| or |int| --\n        Vector of second set of atom symbols or atomic numbers\n\n    tol\n        |float|, optional --\n        Tolerance for acceptable deviation of each geometry coordinate\n        from that in the reference instance to still be considered\n        matching. Default value is specified by\n        :attr:`opan.const.DEF.XYZ_COORD_MATCH_TOL`)\n\n    Returns\n    -------\n    match\n        |bool| --\n        Whether input coords and atoms match (|True|) or\n        not (|False|)\n\n    fail_type\n        :class:`~opan.const.EnumCheckGeomMismatch` or |None|\n        -- Type of check failure\n\n        If `match` == |True|:\n\n            Returns as |None|\n\n        If `match` == |False|:\n\n            An :class:`~opan.const.EnumCheckGeomMismatch` value\n            indicating the reason for the failed match:\n\n                :attr:`~opan.const.EnumCheckGeomMismatch.DIMENSION`\n                -- Mismatch in geometry size (number of atoms)\n\n                :attr:`~opan.const.EnumCheckGeomMismatch.COORDS`\n                -- Mismatch in one or more coordinates\n\n                :attr:`~opan.const.EnumCheckGeomMismatch.ATOMS`\n                -- Mismatch in one or more atoms\n\n    fail_loc\n        length-3N |bool| or length-N |bool| or |None| --\n        Mismatched elements\n\n        If `match` == |True|:\n\n            Returns as |None|\n\n        If `match` == |False|:\n\n            For \"array-level\" problems such as a dimension mismatch, a\n            |None| value is returned.\n\n            For \"element-level\" problems, a vector is returned\n            indicating positions of mismatch in either `coords` or `atoms`,\n            depending on the value of `fail_type`.\n\n                |True| elements indicate **MATCHING** values\n\n                |False| elements mark **MISMATCHES**\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If a pair of coords & atoms array lengths is inconsistent:\n\n        .. code-block:: python\n\n            if len(c1) != 3 * len(a1) or len(c2) != 3 * len(a2):\n                raise ValueError(...)\n\n    \"\"\"\n\n    # Import(s)\n    from ..const import atom_num\n    import numpy as np\n    from ..const import EnumCheckGeomMismatch as ECGM\n\n    # Initialize return value to success condition\n    match = True\n\n    #** Check coords for suitable shape. Assume 1-D np.arrays.\n    if not len(c1.shape) == 1:\n        # Cannot coerce to vector; complain.\n        raise ValueError((\"'c1' is not a vector.\"))\n    ## end if\n    if not len(c2.shape) == 1:\n        # Cannot coerce to vector; complain.\n        raise ValueError((\"'c2' is not a vector.\"))\n    ## end if\n\n    #** Check atoms for suitable shape. Assume lists of strings, so\n    # convert to np.array to check.\n    if not len(a1.shape) == 1:\n        # Not a vector; complain\n        raise ValueError((\"'a1' is not a simple list.\"))\n    ## end if\n    if not len(a2.shape) == 1:\n        # Not a vector; complain.\n        raise ValueError((\"'a2' is not a simple list.\"))\n    ## end if\n\n    #** Confirm proper lengths of coords vs atoms\n    if not c1.shape[0] == 3 * a1.shape[0]:\n        raise ValueError(\"len(c1) != 3*len(a1)\")\n    ## end if\n    if not c2.shape[0] == 3 * a2.shape[0]:\n        raise ValueError(\"len(c2) != 3*len(a2)\")\n    ## end if\n\n    #** Confirm matching lengths of coords and atoms w/corresponding\n    #  objects among the two geometries\n    if not c1.shape[0] == c2.shape[0]:\n        match = False\n        fail_type = ECGM.DIMENSION\n        return match, fail_type, None\n    ## end if\n\n    #** Element-wise check for geometry match to within 'tol'\n    fail_loc = np.less_equal(np.abs(np.subtract(c1,c2)), tol)\n    if sum(fail_loc) != c2.shape[0]:\n        # Count of matching coordinates should equal the number of\n        #  coordinates. If not, complain with 'coord_mismatch' fail type.\n        match = False\n        fail_type = ECGM.COORDS\n        return match, fail_type, fail_loc\n    ## end if\n\n    #** Element-wise check for atoms match. Quietly convert both input and\n    #  instance atom arrays to atom_nums to allow np.equals comparison.\n    if np.issubdtype(a1.dtype, np.dtype('str')):\n        # Presume atomic symbol data and attempt conversion\n        a1 = np.array([atom_num[e] for e in a1])\n    ## end if\n    if np.issubdtype(a2.dtype, np.dtype('str')):\n        # Presume atomic symbol data and attempt conversion\n        a2 = np.array([atom_num[e] for e in a2])\n    ## end if\n    fail_loc = np.equal(a1, a2)\n\n    #** Perform the test to ensure all atoms match.\n    if sum(fail_loc) != a2.shape[0]:\n        # Count of matching atoms should equal number of atoms. If not,\n        #  complain with the 'atom_mismatch' fail type.\n        match = False\n        fail_type = ECGM.ATOMS\n        return match, fail_type, fail_loc\n\n    #** If reached here, all tests passed; return success.\n    return match, None, None", "label": 1}
{"code": "public function setExtra($extra)\n    {\n        if (isset($extra['secret']) && strlen($extra['secret']) > 17) {\n            $extra['secret'] = hex2bin($extra['secret']);\n        }\n        if (isset($extra['secret']) && strlen($extra['secret']) == 17) {\n            $extra['secret'] = substr($extra['secret'], 0, 16);\n        }\n        $this->extra = $extra;\n    }", "label": 2}
{"code": "func (w *Watch) String() string {\n\treturn fmt.Sprintf(\"Watcher(name=%v, prefixes=%v)\", w.Name, string(bytes.Join(w.Prefixes, []byte(\", \"))))\n}", "label": 5}
{"code": "function mergeHelper(base, mixin, name, mergeArrays) {\n    if (Array.isArray(mixin[name])) {\n        if (!mergeArrays && base[name] && Array.isArray(base[name])) {\n            base[name] = base[name].concat(mixin[name]);\n        } else {\n            base[name] = mixin[name];\n        }\n    } else if (typeof mixin[name] === 'object' && mixin[name] !== null) {\n        let newBase = base[name] || {};\n        if (Array.isArray(newBase)) {\n            newBase = {};\n        }\n        mergeInner(newBase, mixin[name], mergeArrays);\n        base[name] = newBase;\n    } else {\n        base[name] = mixin[name];\n    }\n}", "label": 3}
{"code": "public static authenticationradiuspolicy_vpnglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationradiuspolicy_vpnglobal_binding obj = new authenticationradiuspolicy_vpnglobal_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationradiuspolicy_vpnglobal_binding response[] = (authenticationradiuspolicy_vpnglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def fft_convolve(in1, in2, conv_device=\"cpu\", conv_mode=\"linear\", store_on_gpu=False):\n    \"\"\"\n    This function determines the convolution of two inputs using the FFT. Contains an implementation for both CPU\n    and GPU.\n\n    INPUTS:\n    in1             (no default):           Array containing one set of data, possibly an image.\n    in2             (no default):           Gpuarray containing the FFT of the PSF.\n    conv_device     (default = \"cpu\"):      Parameter which allows specification of \"cpu\" or \"gpu\".\n    conv_mode       (default = \"linear\"):   Mode specifier for the convolution - \"linear\" or \"circular\".\n    \"\"\"\n\n    # NOTE: Circular convolution assumes a periodic repetition of the input. This can cause edge effects. Linear\n    # convolution pads the input with zeros to avoid this problem but is consequently heavier on computation and\n    # memory.\n\n    if conv_device=='gpu':\n\n        if conv_mode==\"linear\":\n            fft_in1 = pad_array(in1)\n            fft_in1 = gpu_r2c_fft(fft_in1, store_on_gpu=True)\n            fft_in2 = in2\n\n            conv_in1_in2 = fft_in1*fft_in2\n\n            conv_in1_in2 = contiguous_slice(fft_shift(gpu_c2r_ifft(conv_in1_in2, is_gpuarray=True, store_on_gpu=True)))\n\n            if store_on_gpu:\n                return conv_in1_in2\n            else:\n                return conv_in1_in2.get()\n\n        elif conv_mode==\"circular\":\n            fft_in1 = gpu_r2c_fft(in1, store_on_gpu=True)\n            fft_in2 = in2\n\n            conv_in1_in2 = fft_in1*fft_in2\n\n            conv_in1_in2 = fft_shift(gpu_c2r_ifft(conv_in1_in2, is_gpuarray=True, store_on_gpu=True))\n\n            if store_on_gpu:\n                return conv_in1_in2\n            else:\n                return conv_in1_in2.get()\n    else:\n\n        if conv_mode==\"linear\":\n            fft_in1 = pad_array(in1)\n            fft_in2 = in2\n\n            out1_slice = tuple(slice(0.5*sz,1.5*sz) for sz in in1.shape)\n\n            return np.require(np.fft.fftshift(np.fft.irfft2(fft_in2*np.fft.rfft2(fft_in1)))[out1_slice], np.float32, 'C')\n\n        elif conv_mode==\"circular\":\n            return np.fft.fftshift(np.fft.irfft2(in2*np.fft.rfft2(in1)))", "label": 1}
{"code": "public static function history(History $history)\n    {\n        return function (callable $handler) use ($history) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler, $history) {\n                $ticket = $history->start($command, $request);\n                return $handler($command, $request)\n                    ->then(\n                        function ($result) use ($history, $ticket) {\n                            $history->finish($ticket, $result);\n                            return $result;\n                        },\n                        function ($reason) use ($history, $ticket) {\n                            $history->finish($ticket, $reason);\n                            return Promise\\rejection_for($reason);\n                        }\n                    );\n            };\n        };\n    }", "label": 2}
{"code": "def all(options = nil, &block)\n      options = options ? Hash[options] : {}\n      options[:count] = :all\n      find(options, &block)\n    end", "label": 4}
{"code": "public void executeInsert(ClassDescriptor cld, Object obj) throws PersistenceBrokerException\r\n    {\r\n        if (logger.isDebugEnabled())\r\n        {\r\n            logger.debug(\"executeInsert: \" + obj);\r\n        }\r\n        final StatementManagerIF sm = broker.serviceStatementManager();\r\n        PreparedStatement stmt = null;\r\n        try\r\n        {\r\n            stmt = sm.getInsertStatement(cld);\r\n            if (stmt == null)\r\n            {\r\n                logger.error(\"getInsertStatement returned a null statement\");\r\n                throw new PersistenceBrokerException(\"getInsertStatement returned a null statement\");\r\n            }\r\n            // before bind values perform autoincrement sequence columns\r\n            assignAutoincrementSequences(cld, obj);\r\n            sm.bindInsert(stmt, cld, obj);\r\n            if (logger.isDebugEnabled())\r\n                logger.debug(\"executeInsert: \" + stmt);\r\n            stmt.executeUpdate();\r\n            // after insert read and assign identity columns\r\n            assignAutoincrementIdentityColumns(cld, obj);\r\n\r\n            // Harvest any return values.\r\n            harvestReturnValues(cld.getInsertProcedure(), obj, stmt);\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            logger.error(\"PersistenceBrokerException during the execution of the insert: \" + e.getMessage(), e);\r\n            throw e;\r\n        }\r\n        catch(SequenceManagerException e)\r\n        {\r\n            throw new PersistenceBrokerException(\"Error while try to assign identity value\", e);\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            final String sql = broker.serviceSqlGenerator().getPreparedInsertStatement(cld).getStatement();\r\n            throw ExceptionHelper.generateException(e, sql, cld, logger, obj);\r\n        }\r\n        finally\r\n        {\r\n            sm.closeResources(stmt, null);\r\n        }\r\n    }", "label": 0}
{"code": "public static function includeInArray($item, $array)\n    {\n        if (self::isItemOrderInvalid($item, $array)) {\n            return array_merge($array, [$item['name'] => $item['content']]);\n        }\n\n        $count = 0;\n        $last  = $array;\n        $first = [];\n        foreach ($array as $key => $value) {\n            if ($count == $item['order']) {\n                return array_merge($first, [$item['name'] => $item['content']], $last);\n            }\n\n            unset($last[$key]);\n            $first[$key] = $value;\n\n            $count++;\n        }\n    }", "label": 2}
{"code": "def build_request(method)\n      Request.create(method) do |req|\n        req.params  = params.dup\n        req.headers = headers.dup\n        req.options = options\n        yield(req) if block_given?\n      end\n    end", "label": 4}
{"code": "function toPromise( obj ) {\n    if( !obj ) {\n        return obj;\n    }\n    if( isPromise( obj ) ) {\n        return obj;\n    }\n    if( isGeneratorFunction( obj ) || isGenerator( obj ) ) {\n        return co.call( this, obj );\n    }\n    if( 'function' == typeof obj ) {\n        return thunkToPromise.call( this, obj );\n    }\n    if( Array.isArray( obj ) ) {\n        return arrayToPromise.call( this, obj );\n    }\n    if( isObject( obj ) ) {\n        return objectToPromise.call( this, obj );\n    }\n    return obj;\n}", "label": 3}
{"code": "function needsAnUpdate(dataSource, currentTime) {\n  //The last time the Data Source was refreshed\n  var lastRefreshedMs = new Date(dataSource.cache[0].lastRefreshed).valueOf();\n  currentTime = new Date(currentTime);\n  var conf = config.get();\n  var defaults = config.defaults();\n\n  //The number of minutes between backoffs\n  var minsPerBackOffIndex = conf.minsPerBackOffIndex || defaults.minsPerBackOffIndex;\n\n  //The number of milliseconds to wait until the Data Source needs to be refreshed.\n  var refreshIntervalMs = dataSource.refreshInterval * MIN_MS;\n\n  var backOffIndex = dataSource.cache[0].backOffIndex || 0;\n\n  //The number of milliseconds to wait because of backing off from errors.\n  var backOffMs = backOffIndex * (minsPerBackOffIndex * MIN_MS);\n  //Will only wait a max of a week between failed updates.\n  backOffMs = Math.min(backOffMs, conf.dsMaxIntervalMs || defaults.dsMaxIntervalMs);\n\n  //The next time the Data Source will refresh will either be normal interval or the backOff interval, whichever is the largest.\n  var nextRefreshMs = Math.max(refreshIntervalMs, backOffMs);\n\n  //Checking if the total of the three times is <= currentTime. If it is, then the data source should try to update.\n  return new Date(lastRefreshedMs + nextRefreshMs) <= currentTime;\n}", "label": 3}
{"code": "protected void buildSuperJoinTree(TableAlias left, ClassDescriptor cld, String name, boolean useOuterJoin)\r\n    {\r\n        ClassDescriptor superCld = cld.getSuperClassDescriptor();\r\n        if (superCld != null)\r\n        {\r\n            SuperReferenceDescriptor superRef = cld.getSuperReference();\r\n            FieldDescriptor[] leftFields = superRef.getForeignKeyFieldDescriptors(cld);\r\n            TableAlias base_alias = getTableAliasForPath(name, null, null);\r\n            String aliasName = String.valueOf(getAliasChar()) + m_aliasCount++;\r\n            TableAlias right = new TableAlias(superCld, aliasName, useOuterJoin, null);\r\n\r\n            Join join1to1 = new Join(left, leftFields, right, superCld.getPkFields(), useOuterJoin, \"superClass\");\r\n            base_alias.addJoin(join1to1);\r\n\r\n            buildSuperJoinTree(right, superCld, name, useOuterJoin);\r\n        }\r\n    }", "label": 0}
{"code": "public static transformpolicylabel[] get(nitro_service service) throws Exception{\n\t\ttransformpolicylabel obj = new transformpolicylabel();\n\t\ttransformpolicylabel[] response = (transformpolicylabel[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static dnscnamerec[] get(nitro_service service, dnscnamerec_args args) throws Exception{\n\t\tdnscnamerec obj = new dnscnamerec();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tdnscnamerec[] response = (dnscnamerec[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function () { \r\n\t\t\t\tif(this.is_focused()) { return; }\r\n\t\t\t\tvar f = $.jstree._focused();\r\n\t\t\t\tif(f) { f.unset_focus(); }\r\n\r\n\t\t\t\tthis.get_container().addClass(\"jstree-focused\"); \r\n\t\t\t\tfocused_instance = this.get_index(); \r\n\t\t\t\tthis.__callback();\r\n\t\t\t}", "label": 3}
{"code": "function extend (host, methods) {\n  for (var name in methods) {\n    if (!host[name]) {\n      host[name] = methods[name];\n    }\n  }\n}", "label": 3}
{"code": "def keypair_from_seed(seed, index=0):\n    \"\"\"\n    Generates a deterministic keypair from `seed` based on `index`\n\n    :param seed: bytes value of seed\n    :type seed: bytes\n\n    :param index: offset from seed\n    :type index: int\n\n    :return: dict of the form: {\n        'private': private_key\n        'public': public_key\n    }\n    \"\"\"\n\n    h = blake2b(digest_size=32)\n    h.update(seed + struct.pack(\">L\", index))\n    priv_key = h.digest()\n    pub_key = private_to_public_key(priv_key)\n    return {'private': priv_key, 'public': pub_key}", "label": 1}
{"code": "func Fini(drv driverapi.Driver) {\n\td := drv.(*driver)\n\n\t// Notify the peer go routine to return\n\tif d.peerOpCancel != nil {\n\t\td.peerOpCancel()\n\t}\n\n\tif d.exitCh != nil {\n\t\twaitCh := make(chan struct{})\n\n\t\td.exitCh <- waitCh\n\n\t\t<-waitCh\n\t}\n}", "label": 5}
{"code": "public String processObjectCache(Properties attributes) throws XDocletException\r\n    {\r\n        ObjectCacheDef objCacheDef = _curClassDef.setObjectCache(attributes.getProperty(ATTRIBUTE_CLASS));\r\n        String         attrName;\r\n\r\n        attributes.remove(ATTRIBUTE_CLASS);\r\n        for (Enumeration attrNames = attributes.propertyNames(); attrNames.hasMoreElements(); )\r\n        {\r\n            attrName = (String)attrNames.nextElement();\r\n            objCacheDef.setProperty(attrName, attributes.getProperty(attrName));\r\n        }\r\n        return \"\";\r\n    }", "label": 0}
{"code": "function getNumElementsFromNonIndexedArrays(arrays) {\n    var key = Object.keys(arrays)[0];\n    var array = arrays[key];\n    if (isArrayBuffer(array)) {\n      return array.numElements;\n    } else {\n      return array.data.length / array.numComponents;\n    }\n  }", "label": 3}
{"code": "def ignore_path(path):\n        \"\"\"\n        Verify whether to ignore a path.\n\n        Args:\n            path (str): path to check.\n\n        Returns:\n            bool: True when to ignore given path.\n        \"\"\"\n        ignore = False\n        for name in ['.tox', 'dist', 'build', 'node_modules', 'htmlcov']:\n            if path.find(name) >= 0:\n                ignore = True\n                break\n        return ignore", "label": 1}
{"code": "function filter_email(value) {\n    var m = EMAIL_RE.exec(value);\n    if(m == null) throw OptError('Excpeted an email address.');\n    return m[1];\n}", "label": 3}
{"code": "function createDOM (rootDoc, id, option) {\n  var el = rootDoc.getElementById(id);\n  var head = rootDoc.getElementsByTagName('head')[0];\n  if(el) {\n    if(option.append) return el\n    el.parentNode && el.parentNode.removeChild(el);\n  }\n  el = rootDoc.createElement('style');\n  head.appendChild(el);\n  el.setAttribute('id', id);\n  if (option.attrs)\n    for (var i in option.attrs) {\n      el.setAttribute(i, option.attrs[i]);\n    }\n  return el\n}", "label": 3}
{"code": "public function valueObject($value, $exclude = false, $meaning = null)\n    {\n        switch (gettype($value)) {\n            case 'boolean':\n                $propertyValue = [\n                    'booleanValue' => $value\n                ];\n\n                break;\n\n            case 'integer':\n                $propertyValue = [\n                    'integerValue' => $value\n                ];\n\n                break;\n\n            case 'double':\n                $propertyValue = [\n                    'doubleValue' => $value\n                ];\n\n                break;\n\n            case 'string':\n                $propertyValue = [\n                    'stringValue' => $value\n                ];\n\n                break;\n\n            case 'array':\n                if (!empty($value) && $this->isAssoc($value)) {\n                    $propertyValue = $this->convertArrayToEntityValue($value);\n                } else {\n                    $propertyValue = $this->convertArrayToArrayValue($value);\n                }\n\n                break;\n\n            case 'object':\n                $propertyValue = $this->objectProperty($value);\n                break;\n\n            case 'resource':\n                $content = stream_get_contents($value);\n\n                $propertyValue = [\n                    'blobValue' => ($this->encode)\n                        ? base64_encode($content)\n                        : $content\n                ];\n                break;\n\n            case 'NULL':\n                $propertyValue = [\n                    'nullValue' => null\n                ];\n                break;\n\n            //@codeCoverageIgnoreStart\n            case 'unknown type':\n                throw new \\InvalidArgumentException(sprintf(\n                    'Unknown type for `%s',\n                    $content\n                ));\n                break;\n\n            default:\n                throw new \\InvalidArgumentException(sprintf(\n                    'Invalid type for `%s',\n                    $content\n                ));\n                break;\n            //@codeCoverageIgnoreEnd\n        }\n\n        if ($exclude) {\n            $propertyValue['excludeFromIndexes'] = true;\n        }\n\n        if ($meaning) {\n            $propertyValue['meaning'] = $meaning;\n        }\n\n        return $propertyValue;\n    }", "label": 2}
{"code": "func getEventValue(event *kube_api.Event) (string, error) {\n\t// TODO: check whether indenting is required.\n\tbytes, err := json.MarshalIndent(event, \"\", \" \")\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(bytes), nil\n}", "label": 5}
{"code": "def get_fastq_2(job, patient_id, sample_type, fastq_1):\n    \"\"\"\n    For a path to a fastq_1 file, return a fastq_2 file with the same prefix and naming scheme.\n\n    :param str patient_id: The patient_id\n    :param str sample_type: The sample type of the file\n    :param str fastq_1: The path to the fastq_1 file\n    :return: The path to the fastq_2 file\n    :rtype: str\n    \"\"\"\n    prefix, extn = fastq_1, 'temp'\n    final_extn = ''\n    while extn:\n        prefix, extn = os.path.splitext(prefix)\n        final_extn = extn + final_extn\n        if prefix.endswith('1'):\n            prefix = prefix[:-1]\n            job.fileStore.logToMaster('\"%s\" prefix for \"%s\" determined to be %s'\n                                      % (sample_type, patient_id, prefix))\n            break\n    else:\n        raise ParameterError('Could not determine prefix from provided fastq (%s). Is it '\n                             'of the form <fastq_prefix>1.[fq/fastq][.gz]?' % fastq_1)\n    if final_extn not in ['.fastq', '.fastq.gz', '.fq', '.fq.gz']:\n        raise ParameterError('If and _2 fastq path is not specified, only .fastq, .fq or '\n                             'their gzippped extensions are accepted. Could not process '\n                             '%s:%s.' % (patient_id, sample_type + '_fastq_1'))\n    return ''.join([prefix, '2', final_extn])", "label": 1}
{"code": "def current_user_name_or_id\n      require 'etc' if !defined?(Etc)\n      begin\n        user = Etc.getpwuid(Process.uid)\n      rescue ArgumentError\n        user = nil\n      end\n      if user\n        return user.name\n      else\n        return \"##{Process.uid}\"\n      end\n    end", "label": 4}
{"code": "def max_version(self):\n        \"\"\"Version with the most downloads.\n\n        :return: A tuple of the form (version, n_downloads)\n        \"\"\"\n        data = self.version_downloads\n        if not data:\n            return None, 0\n        return max(data.items(), key=lambda item: item[1])", "label": 1}
{"code": "public double[][] getPositionsAsArray(){\n\t\tdouble[][] posAsArr = new double[size()][3];\n\t\tfor(int i = 0; i < size(); i++){\n\t\t\tif(get(i)!=null){\n\t\t\t\tposAsArr[i][0] = get(i).x;\n\t\t\t\tposAsArr[i][1] = get(i).y;\n\t\t\t\tposAsArr[i][2] = get(i).z;\n\t\t\t}\n\t\t\telse{\n\t\t\t\tposAsArr[i] = null;\n\t\t\t}\n\t\t}\n\t\treturn posAsArr;\n\t}", "label": 0}
{"code": "def message(self, executor_id, slave_id, message):\n        \"\"\"Sends a message from the framework to one of its executors.\n\n        These messages are best effort; do not expect a framework message to be\n        retransmitted in any reliable fashion.\n        \"\"\"\n        logging.info('Sends message `{}` to executor `{}` on slave `{}`'.format(\n                     message, executor_id, slave_id))\n        return self.driver.sendFrameworkMessage(encode(executor_id),\n                                                encode(slave_id),\n                                                message)", "label": 1}
{"code": "def storage scope: nil, retries: nil, timeout: nil\n      Google::Cloud.storage @project, @keyfile, scope: scope,\n                                                retries: (retries || @retries),\n                                                timeout: (timeout || @timeout)\n    end", "label": 4}
{"code": "public function getReadHash(): string\n    {\n        $hash = hash_final($this->read_hash, true);\n        if ($this->rev) {\n            $hash = strrev($hash);\n        }\n        $this->read_hash = null;\n        $this->read_check_after = 0;\n        $this->read_check_pos = 0;\n\n        return $hash;\n    }", "label": 2}
{"code": "public static Method getSetterPropertyMethod(Class<?> type,\r\n\t\t\tString propertyName) {\r\n\t\tString sourceMethodName = \"set\"\r\n\t\t\t\t+ BeanUtils.capitalizePropertyName(propertyName);\r\n\r\n\t\tMethod sourceMethod = BeanUtils.getMethod(type, sourceMethodName);\r\n\r\n\t\treturn sourceMethod;\r\n\t}", "label": 0}
{"code": "def _sqlfile_to_statements(sql):\n    \"\"\"\n    Takes a SQL string containing 0 or more statements and returns a \n    list of individual statements as strings. Comments and\n    empty statements are ignored.\n    \"\"\"\n    statements = (sqlparse.format(stmt, strip_comments=True).strip() for stmt in sqlparse.split(sql))\n    return [stmt for stmt in statements if stmt]", "label": 1}
{"code": "def show_details(self):\n        \"\"\"\n        extended print details of happiness parameters\n        \"\"\"\n        res = str(self)\n        res += '\\nDETAILS\\n'\n        for f in self.factors:\n            res += str(f)\n\n        return res", "label": 1}
{"code": "function loadIfExists(path, moduleStack, errMsg) {\n        var servicesDir = this.injector.servicesDir;\n        var servicesFullPath = this.injector.rootDir + '/' + servicesDir;\n\n        // if the file doesn't exist, either throw an error (if msg passed in), else just return null\n        if (!fs.existsSync(p.join(servicesFullPath, path + '.js'))) {\n            if (errMsg) {\n                throw new Error(errMsg + ' ' + servicesFullPath + path + '.js');\n            }\n            else {\n                return null;\n            }\n        }\n\n        // else load the module\n        return this.injector.loadModule(servicesDir + path, moduleStack);\n    }", "label": 3}
{"code": "function (key) {\n                    Array.prototype[i].apply(series[key + 'Data'], Array.prototype.slice.call(args, 2));\n                }", "label": 3}
{"code": "private function normalizeElement($kind, $identifier, $identifierType)\n    {\n        $identifierType = $this->determineIdentifierType($identifier, $identifierType);\n\n        $element = [];\n        $element['kind'] = $kind;\n\n        if (!is_null($identifier)) {\n            $element[$identifierType] = $identifier;\n        }\n\n        return $element;\n    }", "label": 2}
{"code": "public double distance(Vector3d v) {\n        double dx = x - v.x;\n        double dy = y - v.y;\n        double dz = z - v.z;\n\n        return Math.sqrt(dx * dx + dy * dy + dz * dz);\n    }", "label": 0}
{"code": "def evict_if_expired(name)\n      if (result = @cache[name]) && (result.expired? || @cache_expiration_service.expired?(name))\n        Puppet.debug {\"Evicting cache entry for environment '#{name}'\"}\n        @cache_expiration_service.evicted(name)\n        clear(name)\n        Puppet.settings.clear_environment_settings(name)\n      end\n    end", "label": 4}
{"code": "def filter_contour(imageFile, opFile):\n    \"\"\" convert an image by applying a contour \"\"\"\n    im = Image.open(imageFile)\n    im1 = im.filter(ImageFilter.CONTOUR)\n    im1.save(opFile)", "label": 1}
{"code": "def deactivate(self, plugins=[]):\n        \"\"\"\n        Deactivates given plugins.\n\n        A given plugin must be activated, otherwise it is ignored and no action takes place (no signals are fired,\n        no deactivate functions are called.)\n\n        A deactivated plugin is still loaded and initialised and can be reactivated by calling :func:`activate` again.\n        It is also still registered in the :class:`.PluginManager` and can be requested via :func:`get`.\n\n        :param plugins: List of plugin names\n        :type plugins: list of strings\n        \"\"\"\n        self._log.debug(\"Plugins Deactivation started\")\n\n        if not isinstance(plugins, list):\n            raise AttributeError(\"plugins must be a list, not %s\" % type(plugins))\n\n        self._log.debug(\"Plugins to deactivate: %s\" % \", \".join(plugins))\n\n        plugins_deactivated = []\n        for plugin_name in plugins:\n            if not isinstance(plugin_name, str):\n                raise AttributeError(\"plugin name must be a str, not %s\" % type(plugin_name))\n\n            if plugin_name not in self._plugins.keys():\n                self._log.info(\"Unknown activated plugin %s\" % plugin_name)\n                continue\n            else:\n                self._log.debug(\"Deactivating plugin %s\" % plugin_name)\n                if not self._plugins[plugin_name].active:\n                    self._log.warning(\"Plugin %s seems to be already deactivated\" % plugin_name)\n                else:\n                    try:\n                        self._plugins[plugin_name].deactivate()\n                    except Exception as e:\n                        raise_from(\n                            PluginNotDeactivatableException(\"Plugin %s could not be deactivated\" % plugin_name), e)\n                    else:\n                        self._log.debug(\"Plugin %s deactivated\" % plugin_name)\n                        plugins_deactivated.append(plugin_name)\n\n        self._log.info(\"Plugins deactivated: %s\" % \", \".join(plugins_deactivated))", "label": 1}
{"code": "def update_token(self, token, secret):\n        \"\"\"Update token with new values.\n\n        :param token: The token value.\n        :param secret: The secret key.\n        \"\"\"\n        if self.access_token != token or self.secret != secret:\n            with db.session.begin_nested():\n                self.access_token = token\n                self.secret = secret\n                db.session.add(self)", "label": 1}
{"code": "public function setDeviceInfo($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\DeviceInfo::class);\n        $this->device_info = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (h *AuthHandlers) isProxy() bool {\n\tif h.Component == teleport.ComponentProxy {\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "function Signature(properties) {\n                if (properties)\n                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n                        if (properties[keys[i]] != null)\n                            this[keys[i]] = properties[keys[i]];\n            }", "label": 3}
{"code": "func mountOverlay(pod *pkgPod.Pod, app *schema.RuntimeApp, dest string) error {\n\tif _, err := os.Stat(dest); err != nil {\n\t\treturn err\n\t}\n\n\ts, err := imagestore.NewStore(getDataDir())\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"cannot open store\"), err)\n\t}\n\n\tts, err := treestore.NewStore(treeStoreDir(), s)\n\tif err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"cannot open treestore\"), err)\n\t}\n\n\ttreeStoreID, err := pod.GetAppTreeStoreID(app.Name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlower := ts.GetRootFS(treeStoreID)\n\timgDir := filepath.Join(filepath.Join(pod.Path(), \"overlay\"), treeStoreID)\n\tif _, err := os.Stat(imgDir); err != nil {\n\t\treturn err\n\t}\n\tupper := filepath.Join(imgDir, \"upper\", app.Name.String())\n\tif _, err := os.Stat(upper); err != nil {\n\t\treturn err\n\t}\n\twork := filepath.Join(imgDir, \"work\", app.Name.String())\n\tif _, err := os.Stat(work); err != nil {\n\t\treturn err\n\t}\n\n\tif err := overlay.Mount(&overlay.MountCfg{lower, upper, work, dest, \"\"}); err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"problem mounting overlayfs directory\"), err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function setSpeechEventType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Speech\\V1\\StreamingRecognizeResponse_SpeechEventType::class);\n        $this->speech_event_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function isDark (r, g, b) {\n  /**\n   * W3C perceived brightness calculator\n   * @see {@link https://www.w3.org/TR/AERT/#color-contrast}\n   */\n  const brightness = ((r * 299) + (g * 587) + (b * 114)) / 1000\n\n  if (brightness < 140) {\n    return true\n  }\n\n  return false\n}", "label": 3}
{"code": "func (s *CA) CompareAndSwapCertAuthority(new, existing services.CertAuthority) error {\n\tif err := new.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tnewValue, err := services.GetCertAuthorityMarshaler().MarshalCertAuthority(new)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tnewItem := backend.Item{\n\t\tKey:     backend.Key(authoritiesPrefix, string(new.GetType()), new.GetName()),\n\t\tValue:   newValue,\n\t\tExpires: new.Expiry(),\n\t}\n\n\texistingValue, err := services.GetCertAuthorityMarshaler().MarshalCertAuthority(existing)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\texistingItem := backend.Item{\n\t\tKey:     backend.Key(authoritiesPrefix, string(existing.GetType()), existing.GetName()),\n\t\tValue:   existingValue,\n\t\tExpires: existing.Expiry(),\n\t}\n\n\t_, err = s.CompareAndSwap(context.TODO(), existingItem, newItem)\n\tif err != nil {\n\t\tif trace.IsCompareFailed(err) {\n\t\t\treturn trace.CompareFailed(\"cluster %v settings have been updated, try again\", new.GetName())\n\t\t}\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def set_up_api_connection\n      logger.info \"connecting to rabbitmq HTTP API (#{api_config.sanitized_uri})\"\n\n      with_authentication_error_handler do\n        with_connection_error_handler do\n          @api_client = CarrotTop.new(host: api_config.host, port: api_config.port,\n                                      user: api_config.username, password: api_config.password,\n                                      ssl: api_config.ssl)\n          @api_client.exchanges\n        end\n      end\n    end", "label": 4}
{"code": "function chainSerialPorts(clientPort, serverPort) {\n    var observer = new OpenEventObserver(clientPort, serverPort);\n\n    function serverPortWrite(data) {\n        try {\n            debug('writing to serverPort', data);\n            if (! Buffer.isBuffer(data)) {\n                data = new Buffer(data);\n            }\n            serverPort.write(data);\n        }\n        catch (ex) {\n            debug('error reading message', ex);\n        }\n    }\n\n    function clientPortWrite(data) {\n        try {\n            debug('writing to clientPort', data);\n            if (! Buffer.isBuffer(data)) {\n                data = new Buffer(data);\n            }\n            clientPort.write(data);\n        }\n        catch (ex) {\n            debug('error reading message', ex);\n        }\n    }\n\n    observer.once('open', function (data) {\n        serverPort.on('data', function (data) {\n            clientPortWrite(data);\n        });\n\n        clientPort.on('data', function (data) {\n            serverPortWrite(data);\n        });\n    });\n}", "label": 3}
{"code": "def _parse_local_location(loc):\n    '''Parse a local caveat location as generated by LocalThirdPartyCaveat.\n\n    This is of the form:\n\n        local <version> <pubkey>\n\n    where <version> is the bakery version of the client that we're\n    adding the local caveat for.\n\n    It returns None if the location does not represent a local\n    caveat location.\n    @return a ThirdPartyInfo.\n    '''\n    if not (loc.startswith('local ')):\n        return None\n    v = VERSION_1\n    fields = loc.split()\n    fields = fields[1:]  # Skip 'local'\n    if len(fields) == 2:\n        try:\n            v = int(fields[0])\n        except ValueError:\n            return None\n        fields = fields[1:]\n    if len(fields) == 1:\n        key = PublicKey.deserialize(fields[0])\n        return ThirdPartyInfo(public_key=key, version=v)\n    return None", "label": 1}
{"code": "func (s *service) assignIPToEndpoint(ip, eID string) (bool, int) {\n\treturn s.ipToEndpoint.Insert(ip, eID)\n}", "label": 5}
{"code": "public static base_responses delete(nitro_service client, String neighbor[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (neighbor != null && neighbor.length > 0) {\n\t\t\tnd6 deleteresources[] = new nd6[neighbor.length];\n\t\t\tfor (int i=0;i<neighbor.length;i++){\n\t\t\t\tdeleteresources[i] = new nd6();\n\t\t\t\tdeleteresources[i].neighbor = neighbor[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public function setDates($start, $end)\n    {\n        $this->setStartDate($start);\n        $this->setEndDate($end);\n\n        return $this;\n    }", "label": 2}
{"code": "private function getStubName()\n    {\n        if ($this->option('plain') === true) {\n            $stub = '/controller-plain.stub';\n        } elseif ($this->option('api') === true) {\n            $stub = '/controller-api.stub';\n        } else {\n            $stub = '/controller.stub';\n        }\n\n        return $stub;\n    }", "label": 2}
{"code": "public static Chart getMSDLineChart(Trajectory t, int lagMin, int lagMax) {\n\t\treturn getMSDLineChart(t, lagMin, lagMax, new MeanSquaredDisplacmentFeature(t,\n\t\t\t\tlagMin));\n\t}", "label": 0}
{"code": "public function setContentAttribute($value)\n    {\n        $this->attributes['content'] = $value ? static::$formatter->parse($value, $this) : null;\n    }", "label": 2}
{"code": "func InternalErrorf(format string, params ...interface{}) error {\n\treturn internal(fmt.Sprintf(format, params...))\n}", "label": 5}
{"code": "func (c *Client) GenerateHostCert(\n\tkey []byte, hostID, nodeName string, principals []string, clusterName string, roles teleport.Roles, ttl time.Duration) ([]byte, error) {\n\n\tout, err := c.PostJSON(c.Endpoint(\"ca\", \"host\", \"certs\"),\n\t\tgenerateHostCertReq{\n\t\t\tKey:         key,\n\t\t\tHostID:      hostID,\n\t\t\tNodeName:    nodeName,\n\t\t\tPrincipals:  principals,\n\t\t\tClusterName: clusterName,\n\t\t\tRoles:       roles,\n\t\t\tTTL:         ttl,\n\t\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tvar cert string\n\tif err := json.Unmarshal(out.Bytes(), &cert); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn []byte(cert), nil\n}", "label": 5}
{"code": "public static gslbsite[] get(nitro_service service, String sitename[]) throws Exception{\n\t\tif (sitename !=null && sitename.length>0) {\n\t\t\tgslbsite response[] = new gslbsite[sitename.length];\n\t\t\tgslbsite obj[] = new gslbsite[sitename.length];\n\t\t\tfor (int i=0;i<sitename.length;i++) {\n\t\t\t\tobj[i] = new gslbsite();\n\t\t\t\tobj[i].set_sitename(sitename[i]);\n\t\t\t\tresponse[i] = (gslbsite) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public static appfwpolicylabel_binding get(nitro_service service, String labelname) throws Exception{\n\t\tappfwpolicylabel_binding obj = new appfwpolicylabel_binding();\n\t\tobj.set_labelname(labelname);\n\t\tappfwpolicylabel_binding response = (appfwpolicylabel_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (l *LoadBalancer) Serve() error {\n\tdefer l.waitCancel()\n\tbackoffTimer := time.NewTicker(5 * time.Second)\n\tdefer backoffTimer.Stop()\n\tfor {\n\t\tconn, err := l.listener.Accept()\n\t\tif err != nil {\n\t\t\tif l.isClosed() {\n\t\t\t\treturn trace.ConnectionProblem(nil, \"listener is closed\")\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-backoffTimer.C:\n\t\t\t\tl.Debugf(\"backoff on network error\")\n\t\t\tcase <-l.ctx.Done():\n\t\t\t\treturn trace.ConnectionProblem(nil, \"context is closing\")\n\t\t\t}\n\t\t}\n\t\tgo l.forwardConnection(conn)\n\t}\n}", "label": 5}
{"code": "def get(self, community_id):\n        \"\"\"Get the details of the specified community.\n\n        .. http:get:: /communities/(string:id)\n            Returns a JSON dictionary with the details of the specified\n            community.\n            **Request**:\n            .. sourcecode:: http\n                GET /communities/communities/comm1 HTTP/1.1\n                Accept: application/json\n                Content-Type: application/json\n                Host: localhost:5000\n            :reqheader Content-Type: application/json\n            :query string id: ID of an specific community to get more\n                              information.\n            **Response**:\n            .. sourcecode:: http\n                HTTP/1.0 200 OK\n                Content-Length: 334\n                Content-Type: application/json\n                {\n                    \"id_user\": 1,\n                    \"description\": \"\",\n                    \"title\": \"\",\n                    \"created\": \"2016-04-05T14:56:37.051462\",\n                    \"id\": \"comm1\",\n                    \"page\": \"\",\n                    \"curation_policy\": \"\"\n                }\n\n            :resheader Content-Type: application/json\n            :statuscode 200: no error\n            :statuscode 404: page not found\n        \"\"\"\n        community = Community.get(community_id)\n        if not community:\n            abort(404)\n        etag = community.version_id\n        self.check_etag(etag)\n        response = self.make_response(\n            community, links_item_factory=default_links_item_factory)\n        response.set_etag(etag)\n        return response", "label": 1}
{"code": "def get_user_info(remote):\n    \"\"\"Get user information from Globus.\n\n    See the docs here for v2/oauth/userinfo:\n    https://docs.globus.org/api/auth/reference/\n    \"\"\"\n    response = remote.get(GLOBUS_USER_INFO_URL)\n    user_info = get_dict_from_response(response)\n    response.data['username'] = response.data['preferred_username']\n    if '@' in response.data['username']:\n        user_info['username'], _ = response.data['username'].split('@')\n    return user_info", "label": 1}
{"code": "public function sync(Blueprint\\BlueprintInterface $blueprint, array $users)\n    {\n        $attributes = $this->getAttributes($blueprint);\n\n        // Find all existing notification records in the database matching this\n        // blueprint. We will begin by assuming that they all need to be\n        // deleted in order to match the provided list of users.\n        $toDelete = Notification::where($attributes)->get();\n        $toUndelete = [];\n        $newRecipients = [];\n\n        // For each of the provided users, check to see if they already have\n        // a notification record in the database. If they do, we will make sure\n        // it isn't marked as deleted. If they don't, we will want to create a\n        // new record for them.\n        foreach ($users as $user) {\n            if (! ($user instanceof User)) {\n                continue;\n            }\n\n            $existing = $toDelete->first(function ($notification, $i) use ($user) {\n                return $notification->user_id === $user->id;\n            });\n\n            if ($existing) {\n                $toUndelete[] = $existing->id;\n                $toDelete->forget($toDelete->search($existing));\n            } elseif (! static::$onePerUser || ! in_array($user->id, static::$sentTo)) {\n                $newRecipients[] = $user;\n                static::$sentTo[] = $user->id;\n            }\n        }\n\n        // Delete all of the remaining notification records which weren't\n        // removed from this collection by the above loop. Un-delete the\n        // existing records that we want to keep.\n        if (count($toDelete)) {\n            $this->setDeleted($toDelete->pluck('id')->all(), true);\n        }\n\n        if (count($toUndelete)) {\n            $this->setDeleted($toUndelete, false);\n        }\n\n        // Create a notification record, and send an email, for all users\n        // receiving this notification for the first time (we know because they\n        // didn't have a record in the database).\n        if (count($newRecipients)) {\n            $this->sendNotifications($blueprint, $newRecipients);\n        }\n    }", "label": 2}
{"code": "func IsDir(dirPath string) bool {\n\tfi, err := os.Stat(dirPath)\n\tif err == nil {\n\t\treturn fi.IsDir()\n\t}\n\treturn false\n}", "label": 5}
{"code": "public static base_responses unset(nitro_service client, String sitename[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (sitename != null && sitename.length > 0) {\n\t\t\tgslbsite unsetresources[] = new gslbsite[sitename.length];\n\t\t\tfor (int i=0;i<sitename.length;i++){\n\t\t\t\tunsetresources[i] = new gslbsite();\n\t\t\t\tunsetresources[i].sitename = sitename[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def post_attr_hash(post_attr)\n      # Build a hash map based on the specified post attribute ( post attr =>\n      # array of posts ) then sort each array in reverse order.\n      @post_attr_hash[post_attr] ||= begin\n        hash = Hash.new { |h, key| h[key] = [] }\n        posts.docs.each do |p|\n          p.data[post_attr]&.each { |t| hash[t] << p }\n        end\n        hash.each_value { |posts| posts.sort!.reverse! }\n        hash\n      end\n    end", "label": 4}
{"code": "def ignore_property?(prop_node)\n      return true if prop_node.name.any? { |part| !part.is_a?(String) }\n\n      config['ignore_unspecified'] &&\n        @preferred_order &&\n        !@preferred_order.include?(prop_node.name.join)\n    end", "label": 4}
{"code": "def define_baseargs(self, parser):\n        '''\n        Define basic command-line arguments required by the script.\n        @parser is a parser object created using the `argparse` module.\n        returns: None\n        '''\n        parser.add_argument('--name', default=sys.argv[0],\n            help='Name to identify this instance')\n        parser.add_argument('--log-level', default=None,\n            help='Logging level as picked from the logging module')\n        parser.add_argument('--log-format', default=None,\n            # TODO add more formats\n            choices=(\"json\", \"pretty\",),\n            help=(\"Force the format of the logs. By default, if the \"\n                  \"command is from a terminal, print colorful logs. \"\n                  \"Otherwise print json.\"),\n        )\n        parser.add_argument('--log-file', default=None,\n            help='Writes logs to log file if specified, default: %(default)s',\n        )\n        parser.add_argument('--quiet', default=False, action=\"store_true\",\n            help='if true, does not print logs to stderr, default: %(default)s',\n        )\n        parser.add_argument('--metric-grouping-interval', default=None, type=int,\n            help='To group metrics based on time interval ex:10 i.e;(10 sec)',\n        )\n        parser.add_argument('--debug', default=False, action=\"store_true\",\n            help='To run the code in debug mode',\n        )", "label": 1}
{"code": "public function getDefaultCurlOptionsMiddleware()\n    {\n        return Middleware::mapCommand(function (CommandInterface $cmd) {\n            $defaultCurlOptions = [\n                CURLOPT_TCP_KEEPALIVE => 1,\n            ];\n            if (!isset($cmd['@http']['curl'])) {\n                $cmd['@http']['curl'] = $defaultCurlOptions;\n            } else {\n                $cmd['@http']['curl'] += $defaultCurlOptions;\n            }\n            return $cmd;\n        });\n    }", "label": 2}
{"code": "private function getInstanceAdminClient()\n    {\n        //@codeCoverageIgnoreStart\n        if ($this->instanceAdminClient) {\n            return $this->instanceAdminClient;\n        }\n        //@codeCoverageIgnoreEnd\n\n        $this->instanceAdminClient = new InstanceAdminClient($this->grpcConfig);\n\n        return $this->instanceAdminClient;\n    }", "label": 2}
{"code": "public RedwoodConfiguration printChannels(final int width){\r\n     tasks.add(new Runnable() { public void run() { Redwood.Util.printChannels(width);} });\r\n    return this;\r\n  }", "label": 0}
{"code": "public function setPayload($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\AutoMl\\V1beta1\\AnnotationPayload::class);\n        $this->payload = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def match(self, item):\n        \"\"\"\n        Return ``True`` if the expected matchers are matched in any order,\n        otherwise ``False``.\n        \"\"\"\n        if not self._unused_matchers:\n            raise RuntimeError('Matcher exhausted, no more matchers to use')\n\n        for matcher in self._unused_matchers:\n            if matcher(item):\n                self._used_matchers.append(matcher)\n                break\n\n        if not self._unused_matchers:\n            # All patterns have been matched\n            return True\n\n        return False", "label": 1}
{"code": "public static aaaparameter get(nitro_service service) throws Exception{\n\t\taaaparameter obj = new aaaparameter();\n\t\taaaparameter[] response = (aaaparameter[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "protected void appendTableWithJoins(TableAlias alias, StringBuffer where, StringBuffer buf)\r\n    {\r\n        int stmtFromPos = 0;\r\n        byte joinSyntax = getJoinSyntaxType();\r\n\r\n        if (joinSyntax == SQL92_JOIN_SYNTAX)\r\n        {\r\n            stmtFromPos = buf.length(); // store position of join (by: Terry Dexter)\r\n        }\r\n\r\n        if (alias == getRoot())\r\n        {\r\n            // BRJ: also add indirection table to FROM-clause for MtoNQuery \r\n            if (getQuery() instanceof MtoNQuery)\r\n            {\r\n                MtoNQuery mnQuery = (MtoNQuery)m_query; \r\n                buf.append(getTableAliasForPath(mnQuery.getIndirectionTable(), null).getTableAndAlias());\r\n                buf.append(\", \");\r\n            }           \r\n            buf.append(alias.getTableAndAlias());\r\n        }\r\n        else if (joinSyntax != SQL92_NOPAREN_JOIN_SYNTAX)\r\n        {\r\n            buf.append(alias.getTableAndAlias());\r\n        }\r\n\r\n        if (!alias.hasJoins())\r\n        {\r\n            return;\r\n        }\r\n\r\n        for (Iterator it = alias.iterateJoins(); it.hasNext();)\r\n        {\r\n            Join join = (Join) it.next();\r\n\r\n            if (joinSyntax == SQL92_JOIN_SYNTAX)\r\n            {\r\n                appendJoinSQL92(join, where, buf);\r\n                if (it.hasNext())\r\n                {\r\n                    buf.insert(stmtFromPos, \"(\");\r\n                    buf.append(\")\");\r\n                }\r\n            }\r\n            else if (joinSyntax == SQL92_NOPAREN_JOIN_SYNTAX)\r\n            {\r\n                appendJoinSQL92NoParen(join, where, buf);\r\n            }\r\n            else\r\n            {\r\n                appendJoin(where, buf, join);\r\n            }\r\n\r\n        }\r\n    }", "label": 0}
{"code": "func (s *AuthServer) rotateAndFetchSignupToken(token string) (*services.SignupToken, error) {\n\tvar err error\n\n\t// Fetch original signup token.\n\tst, err := s.GetSignupToken(token)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Generate and set new OTP code for user in *services.SignupToken.\n\taccountName := st.User.V2().GetName() + \"@\" + s.AuthServiceName\n\tst.OTPKey, st.OTPQRCode, err = s.initializeTOTP(accountName)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Upsert token into backend.\n\terr = s.UpsertSignupToken(token, *st, st.Expires.Sub(s.clock.Now()))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn st, nil\n}", "label": 5}
{"code": "public void afterLoading(CollectionProxyDefaultImpl colProxy)\r\n    {\r\n        if (log.isDebugEnabled()) log.debug(\"loading a proxied collection a collection: \" + colProxy);\r\n        Collection data = colProxy.getData();\r\n        for (Iterator iterator = data.iterator(); iterator.hasNext();)\r\n        {\r\n            Object o = iterator.next();\r\n            if(!isOpen())\r\n            {\r\n                log.error(\"Collection proxy materialization outside of a running tx, obj=\" + o);\r\n                try{throw new Exception(\"Collection proxy materialization outside of a running tx, obj=\" + o);}\r\n                catch(Exception e)\r\n                {e.printStackTrace();}\r\n            }\r\n            else\r\n            {\r\n                Identity oid = getBroker().serviceIdentity().buildIdentity(o);\r\n                ClassDescriptor cld = getBroker().getClassDescriptor(ProxyHelper.getRealClass(o));\r\n                RuntimeObject rt = new RuntimeObject(o, oid, cld, false, ProxyHelper.isProxy(o));\r\n                lockAndRegister(rt, Transaction.READ, isImplicitLocking(), getRegistrationList());\r\n            }\r\n        }\r\n        unregisterFromCollectionProxy(colProxy);\r\n    }", "label": 0}
{"code": "private static boolean matches(@Nonnull final Pattern pattern, @Nonnull final CharSequence chars) {\n\t\treturn pattern.matcher(chars).matches();\n\t}", "label": 0}
{"code": "function getNumFromThreeCSVADSRegisterQuery (str, regEx, offset) {\n  let regExArr = str.match(regEx);\n  if (regExArr) {\n    const bit2 = parseInt(str.charAt(regExArr.index + offset));\n    const bit1 = parseInt(str.charAt(regExArr.index + offset + 3));\n    const bit0 = parseInt(str.charAt(regExArr.index + offset + 6));\n    if (!Number.isNaN(bit2) && !Number.isNaN(bit1) && !Number.isNaN(bit0)) {\n      return bit2 << 2 | bit1 << 1 | bit0;\n    } else {\n      throw new Error(k.OBCIErrorInvalidData);\n    }\n  } else {\n    throw new Error(k.OBCIErrorMissingRegisterSetting);\n  }\n}", "label": 3}
{"code": "def _init_entri(self, laman):\n        \"\"\"Membuat objek-objek entri dari laman yang diambil.\n\n        :param laman: Laman respons yang dikembalikan oleh KBBI daring.\n        :type laman: Response\n        \"\"\"\n\n        sup = BeautifulSoup(laman.text, 'html.parser')\n        estr = ''\n        for label in sup.find('hr').next_siblings:\n            if label.name == 'hr':\n                self.entri.append(Entri(estr))\n                break\n            if label.name == 'h2':\n                if estr:\n                    self.entri.append(Entri(estr))\n                estr = ''\n            estr += str(label).strip()", "label": 1}
{"code": "def update_fields(fields)\n      attributes[:id]                     = fields[SYMBOL_TO_STRING[:id]] || attributes[:id]\n      attributes[:short_id]               = fields[SYMBOL_TO_STRING[:short_id]] || attributes[:short_id]\n      attributes[:name]                   = fields[SYMBOL_TO_STRING[:name]] || fields[:name] || attributes[:name]\n      attributes[:desc]                   = fields[SYMBOL_TO_STRING[:desc]] || fields[:desc] || attributes[:desc]\n      attributes[:due]                    = Time.iso8601(fields[SYMBOL_TO_STRING[:due]]) rescue nil if fields.has_key?(SYMBOL_TO_STRING[:due])\n      attributes[:due]                    = fields[:due] if fields.has_key?(:due)\n      attributes[:due_complete]           = fields[SYMBOL_TO_STRING[:due_complete]] if fields.has_key?(SYMBOL_TO_STRING[:due_complete])\n      attributes[:due_complete]           ||= false\n      attributes[:closed]                 = fields[SYMBOL_TO_STRING[:closed]] if fields.has_key?(SYMBOL_TO_STRING[:closed])\n      attributes[:url]                    = fields[SYMBOL_TO_STRING[:url]] || attributes[:url]\n      attributes[:short_url]              = fields[SYMBOL_TO_STRING[:short_url]] || attributes[:short_url]\n      attributes[:board_id]               = fields[SYMBOL_TO_STRING[:board_id]] || attributes[:board_id]\n      attributes[:member_ids]             = fields[SYMBOL_TO_STRING[:member_ids]] || fields[:member_ids] || attributes[:member_ids]\n      attributes[:list_id]                = fields[SYMBOL_TO_STRING[:list_id]] || fields[:list_id] || attributes[:list_id]\n      attributes[:pos]                    = fields[SYMBOL_TO_STRING[:pos]] || fields[:pos] || attributes[:pos]\n      attributes[:labels]                 = (fields[SYMBOL_TO_STRING[:labels]] || []).map { |lbl| Trello::Label.new(lbl) }.presence || attributes[:labels].presence || []\n      attributes[:card_labels]            = fields[SYMBOL_TO_STRING[:card_labels]] || fields[:card_labels] || attributes[:card_labels]\n      attributes[:last_activity_date]     = Time.iso8601(fields[SYMBOL_TO_STRING[:last_activity_date]]) rescue nil if fields.has_key?(SYMBOL_TO_STRING[:last_activity_date])\n      attributes[:cover_image_id]         = fields[SYMBOL_TO_STRING[:cover_image_id]] || attributes[:cover_image_id]\n      attributes[:badges]                 = fields[SYMBOL_TO_STRING[:badges]] || attributes[:badges]\n      attributes[:card_members]           = fields[SYMBOL_TO_STRING[:card_members]] || attributes[:card_members]\n      attributes[:source_card_id]         = fields[SYMBOL_TO_STRING[:source_card_id]] || fields[:source_card_id] || attributes[:source_card_id]\n      attributes[:source_card_properties] = fields[SYMBOL_TO_STRING[:source_card_properties]] || fields[:source_card_properties] || attributes[:source_card_properties]\n      self\n    end", "label": 4}
{"code": "def print_errors(self, file_name):\n        \"\"\"\n        Prints the errors observed for a file\n        \"\"\"\n        for error in self.get_messages(file_name):\n            print('\\t', error.__unicode__())", "label": 1}
{"code": "def delete_file(f, ignore_errors=False):\n\t\"\"\"\n\tdelete a single file\n\t\"\"\"\n\ttry:\n\t\tos.remove(f)\n\texcept Exception as ex:\n\t\tif ignore_errors:\n\t\t\treturn\n\t\tprint('ERROR deleting file ' + str(ex))", "label": 1}
{"code": "def get_state(self, as_str=False):\n        \"\"\"Returns user state. See ``UserState``.\n\n        :param bool as_str: Return human-friendly state name instead of an ID.\n        :rtype: int|str\n        \"\"\"\n\n        uid = self.user_id\n\n        if self._iface_user.get_id() == uid:\n            result = self._iface.get_my_state()\n\n        else:\n            result = self._iface.get_state(uid)\n\n        if as_str:\n            return UserState.get_alias(result)\n\n        return result", "label": 1}
{"code": "public static nsxmlnamespace[] get(nitro_service service, String prefix[]) throws Exception{\n\t\tif (prefix !=null && prefix.length>0) {\n\t\t\tnsxmlnamespace response[] = new nsxmlnamespace[prefix.length];\n\t\t\tnsxmlnamespace obj[] = new nsxmlnamespace[prefix.length];\n\t\t\tfor (int i=0;i<prefix.length;i++) {\n\t\t\t\tobj[i] = new nsxmlnamespace();\n\t\t\t\tobj[i].set_prefix(prefix[i]);\n\t\t\t\tresponse[i] = (nsxmlnamespace) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "public static double SymmetricChiSquareDivergence(double[] p, double[] q) {\n        double r = 0;\n        for (int i = 0; i < p.length; i++) {\n            double den = p[i] * q[i];\n            if (den != 0) {\n                double p1 = p[i] - q[i];\n                double p2 = p[i] + q[i];\n                r += (p1 * p1 * p2) / den;\n            }\n        }\n\n        return r;\n    }", "label": 0}
{"code": "protected function dispatch(InternalRequest $request)\n    {\n        $this->routeStack[] = $this->router->getCurrentRoute();\n\n        $this->clearCachedFacadeInstance();\n\n        try {\n            $this->container->instance('request', $request);\n\n            $response = $this->router->dispatch($request);\n\n            if (! $response->isSuccessful() && ! $response->isRedirection()) {\n                throw new InternalHttpException($response);\n            }\n\n            if (! $this->raw) {\n                $response = $response->getOriginalContent();\n            }\n        } catch (HttpExceptionInterface $exception) {\n            $this->refreshRequestStack();\n\n            throw $exception;\n        }\n\n        $this->refreshRequestStack();\n\n        return $response;\n    }", "label": 2}
{"code": "def convert_nils_to_empty_hashes(hash)\n      hash.each_with_object({}) do |(key, value), h|\n        h[key] =\n          case value\n          when nil  then {}\n          when Hash then convert_nils_to_empty_hashes(value)\n          else\n            value\n          end\n      end\n    end", "label": 4}
{"code": "def bot_application\n      return unless @type == :bot\n\n      response = API.oauth_application(token)\n      Application.new(JSON.parse(response), self)\n    end", "label": 4}
{"code": "def number_valid_and_possible?(number, p_regex, v_regex, not_valid = false)\n      possible = number_match?(number, p_regex)\n\n      return [!not_valid && possible, possible] if p_regex == v_regex\n      valid = !not_valid && possible && number_match?(number, v_regex)\n\n      [valid && possible, possible]\n    end", "label": 4}
{"code": "func (uw *UnitWriter) AppReaperUnit(appName types.ACName, binPath string, opts ...*unit.UnitOption) {\n\tif uw.err != nil {\n\t\treturn\n\t}\n\n\topts = append(opts, []*unit.UnitOption{\n\t\tunit.NewUnitOption(\"Unit\", \"Description\", fmt.Sprintf(\"%s Reaper\", appName)),\n\t\tunit.NewUnitOption(\"Unit\", \"DefaultDependencies\", \"false\"),\n\t\tunit.NewUnitOption(\"Unit\", \"StopWhenUnneeded\", \"yes\"),\n\t\tunit.NewUnitOption(\"Unit\", \"Before\", \"halt.target\"),\n\t\tunit.NewUnitOption(\"Unit\", \"Conflicts\", \"exit.target\"),\n\t\tunit.NewUnitOption(\"Unit\", \"Conflicts\", \"halt.target\"),\n\t\tunit.NewUnitOption(\"Unit\", \"Conflicts\", \"poweroff.target\"),\n\t\tunit.NewUnitOption(\"Service\", \"RemainAfterExit\", \"yes\"),\n\t\tunit.NewUnitOption(\"Service\", \"ExecStop\", fmt.Sprintf(\n\t\t\t\"/reaper.sh \\\"%s\\\" \\\"%s\\\" \\\"%s\\\"\",\n\t\t\tappName,\n\t\t\tcommon.RelAppRootfsPath(appName),\n\t\t\tbinPath,\n\t\t)),\n\t}...)\n\n\tuw.WriteUnit(\n\t\tServiceUnitPath(uw.p.Root, types.ACName(fmt.Sprintf(\"reaper-%s\", appName))),\n\t\tfmt.Sprintf(\"failed to write app %q reaper service\", appName),\n\t\topts...,\n\t)\n}", "label": 5}
{"code": "function partitionValueToIndex (partition, value) {\n  var group;\n\n  if (!partition) {\n    // no(sub)partitioning return first element\n    return 0;\n  }\n\n  // with (sub)partitioning\n  group = partition.groups.get(value, 'value');\n\n  if (group) {\n    // string in partition\n    return group.groupIndex;\n  } else {\n    // string not in partition\n    return -1;\n  }\n}", "label": 3}
{"code": "def getFasta(opened_file, sequence_name):\n    \"\"\"\n    Retrieves a sequence from an opened multifasta file\n\n    :param opened_file: an opened multifasta file eg. opened_file=open(\"/path/to/file.fa\",'r+')\n    :param sequence_name: the name of the sequence to be retrieved eg. for '>2 dna:chromosome chromosome:GRCm38:2:1:182113224:1 REF' use: sequence_name=str(2)\n\n    returns: a string with the sequence of interest\n    \"\"\"\n\n    lines = opened_file.readlines()\n    seq=str(\"\")\n    for i in range(0, len(lines)):\n        line = lines[i]\n        if line[0] == \">\":\n            fChr=line.split(\" \")[0].split(\"\\n\")[0]\n            fChr=fChr[1:]\n            if fChr == sequence_name:\n                s=i\n                code=['N','A','C','T','G']\n                firstbase=lines[s+1][0]\n                while firstbase in code:\n                    s=s + 1\n                    seq=seq+lines[s]\n                    firstbase=lines[s+1][0]\n\n    if len(seq)==0:\n        seq=None\n    else:\n        seq=seq.split(\"\\n\")\n        seq=\"\".join(seq)\n\n    return seq", "label": 1}
{"code": "def bam_conversion(job, samfile, sample_type, univ_options, samtools_options):\n    \"\"\"\n    Convert a sam to a bam.\n\n    :param dict samfile: The input sam file\n    :param str sample_type: Description of the sample to inject into the filename\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict samtools_options: Options specific to samtools\n    :return: fsID for the generated bam\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        sample_type + '.sam': samfile}\n    input_files = get_files_from_filestore(job, input_files, work_dir,\n                                           docker=True)\n    bamfile = '/'.join([work_dir, sample_type + '.bam'])\n    parameters = ['view',\n                  '-bS',\n                  '-o', docker_path(bamfile),\n                  input_files[sample_type + '.sam']\n                  ]\n    docker_call(tool='samtools', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=samtools_options['version'])\n    output_file = job.fileStore.writeGlobalFile(bamfile)\n    # The samfile is no longer useful so delete it\n    job.fileStore.deleteGlobalFile(samfile)\n    job.fileStore.logToMaster('Ran sam2bam on %s:%s successfully'\n                              % (univ_options['patient'], sample_type))\n    return output_file", "label": 1}
{"code": "def _adjust_limits(self):\n        \"\"\" Sets the active power limits, 'p_max' and 'p_min', according to\n        the pwl cost function points.\n        \"\"\"\n        if not self.is_load:\n#            self.p_min = min([point[0] for point in self.p_cost])\n            self.p_max = max([point[0] for point in self.p_cost])\n        else:\n            p_min = min([point[0] for point in self.p_cost])\n            self.p_max = 0.0\n            self.q_min = self.q_min * p_min / self.p_min\n            self.q_max = self.q_max * p_min / self.p_min\n            self.p_min = p_min", "label": 1}
{"code": "def error_reporting scope: nil, timeout: nil, client_config: nil\n      Google::Cloud.error_reporting @project, @keyfile,\n                                    scope: scope,\n                                    timeout: (timeout || @timeout),\n                                    client_config: client_config\n    end", "label": 4}
{"code": "def register_service(self, service):\n        \"\"\"\n            Register service into the system. Called by Services.\n        \"\"\"\n        if service not in self.services:\n            self.services.append(service)", "label": 1}
{"code": "func CertAuthoritiesToV1(in []CertAuthority) ([]CertAuthorityV1, error) {\n\tout := make([]CertAuthorityV1, len(in))\n\ttype cav1 interface {\n\t\tV1() *CertAuthorityV1\n\t}\n\tfor i, ca := range in {\n\t\tv1, ok := ca.(cav1)\n\t\tif !ok {\n\t\t\treturn nil, trace.BadParameter(\"could not transform object to V1\")\n\t\t}\n\t\tout[i] = *(v1.V1())\n\t}\n\treturn out, nil\n}", "label": 5}
{"code": "def set_cell_values(sheet, x, y, i, v, value_type, formula, table_cell, str_v, style_name)\n      key = [y, x + i]\n      @cell_type[sheet] ||= {}\n      @cell_type[sheet][key] = value_type.to_sym if value_type\n      @formula[sheet] ||= {}\n      if formula\n        ['of:', 'oooc:'].each do |prefix|\n          if formula[0, prefix.length] == prefix\n            formula = formula[prefix.length..-1]\n          end\n        end\n        @formula[sheet][key] = formula\n      end\n      @cell[sheet] ||= {}\n      @style[sheet] ||= {}\n      @style[sheet][key] = style_name\n      case @cell_type[sheet][key]\n      when :float\n        @cell[sheet][key] = (table_cell.attributes['value'].to_s.include?(\".\") || table_cell.children.first.text.include?(\".\")) ? v.to_f : v.to_i\n      when :percentage\n        @cell[sheet][key] = v.to_f\n      when :string\n        @cell[sheet][key] = str_v\n      when :date\n        # TODO: if table_cell.attributes['date-value'].size != \"XXXX-XX-XX\".size\n        if attribute(table_cell, 'date-value').size != 'XXXX-XX-XX'.size\n          #-- dann ist noch eine Uhrzeit vorhanden\n          #-- \"1961-11-21T12:17:18\"\n          @cell[sheet][key]      = DateTime.parse(attribute(table_cell, 'date-value').to_s)\n          @cell_type[sheet][key] = :datetime\n        else\n          @cell[sheet][key] = table_cell.attributes['date-value']\n        end\n      when :time\n        hms = v.split(':')\n        @cell[sheet][key] = hms[0].to_i * 3600 + hms[1].to_i * 60 + hms[2].to_i\n      else\n        @cell[sheet][key] = v\n      end\n    end", "label": 4}
{"code": "public static protocolip_stats get(nitro_service service) throws Exception{\n\t\tprotocolip_stats obj = new protocolip_stats();\n\t\tprotocolip_stats[] response = (protocolip_stats[])obj.stat_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def populate(self, installed_bots=None):\n        \"\"\"\n        Load bots.\n        Import each bot module.\n        It is thread-safe and idempotent, but not re-entrant.\n        \"\"\"\n        if self.ready:\n            return\n\n        # populate() might be called by two threads in parallel on servers\n        # that create threads before initializing the WSGI callable.\n        with self._lock:\n            if self.ready:\n                return\n\n            # An RLock prevents other threads from entering this section. The\n            # compare and set operation below is atomic.\n            if self.loading:\n                # Prevent re-entrant calls to avoid running AppConfig.ready()\n                # methods twice.\n                raise RuntimeError(\"populate() isn't re-entrant\")\n            self.loading = True\n\n            # Phase 1: Initialize bots\n            for entry in installed_bots or {}:\n                if isinstance(entry, Bot):\n                    cls = entry\n                    entry = '.'.join([cls.__module__, cls.__name__])\n                bot_reg = BotRegistry.create(entry)\n                if bot_reg.label in self.bots:\n                    raise ImproperlyConfigured(\n                        \"Bot labels aren't unique, \"\n                        \"duplicates: %s\" % bot_reg.label)\n\n                self.bots[bot_reg.label] = bot_reg\n                bot_reg.bots = self\n\n            # Check for duplicate bot names.\n            counts = Counter(\n                bot_reg.name for bot_reg in self.bots.values())\n            duplicates = [\n                name for name, count in counts.most_common() if count > 1]\n            if duplicates:\n                raise ImproperlyConfigured(\n                    \"Bot names aren't unique, \"\n                    \"duplicates: %s\" % \", \".join(duplicates))\n\n            self.bots_ready = True\n\n            # Phase 2: import config files\n            for bot in self.bots.values():\n                bot.import_configs()\n\n            self.configs_ready = True\n\n            self.ready = True", "label": 1}
{"code": "func (t *FpdfTpl) FromPage(page int) (Template, error) {\n\t// pages start at 1\n\tif page == 0 {\n\t\treturn nil, errors.New(\"Pages start at 1 No template will have a page 0\")\n\t}\n\n\tif page > t.NumPages() {\n\t\treturn nil, fmt.Errorf(\"The template does not have a page %d\", page)\n\t}\n\t// if it is already pointing to the correct page\n\t// there is no need to create a new template\n\tif t.page == page {\n\t\treturn t, nil\n\t}\n\n\tt2 := *t\n\tt2.page = page\n\treturn &t2, nil\n}", "label": 5}
{"code": "private List<StyleFilter> initStyleFilters(List<FeatureStyleInfo> styleDefinitions) throws GeomajasException {\n\t\tList<StyleFilter> styleFilters = new ArrayList<StyleFilter>();\n\t\tif (styleDefinitions == null || styleDefinitions.size() == 0) {\n\t\t\tstyleFilters.add(new StyleFilterImpl()); // use default.\n\t\t} else {\n\t\t\tfor (FeatureStyleInfo styleDef : styleDefinitions) {\n\t\t\t\tStyleFilterImpl styleFilterImpl = null;\n\t\t\t\tString formula = styleDef.getFormula();\n\t\t\t\tif (null != formula && formula.length() > 0) {\n\t\t\t\t\tstyleFilterImpl = new StyleFilterImpl(filterService.parseFilter(formula), styleDef);\n\t\t\t\t} else {\n\t\t\t\t\tstyleFilterImpl = new StyleFilterImpl(Filter.INCLUDE, styleDef);\n\t\t\t\t}\n\t\t\t\tstyleFilters.add(styleFilterImpl);\n\t\t\t}\n\t\t}\n\t\treturn styleFilters;\n\t}", "label": 0}
{"code": "def unregister_worker(exception = nil)\n      # If we're still processing a job, make sure it gets logged as a\n      # failure.\n      if (hash = processing) && !hash.empty?\n        job = Job.new(hash['queue'], hash['payload'])\n        # Ensure the proper worker is attached to this job, even if\n        # it's not the precise instance that died.\n        job.worker = self\n        begin\n          job.fail(exception || DirtyExit.new(\"Job still being processed\"))\n        rescue RuntimeError => e\n          log_with_severity :error, e.message\n        end\n      end\n\n      kill_background_threads\n\n      data_store.unregister_worker(self) do\n        Stat.clear(\"processed:#{self}\")\n        Stat.clear(\"failed:#{self}\")\n      end\n    rescue Exception => exception_while_unregistering\n      message = exception_while_unregistering.message\n      if exception\n        message += \"\\nOriginal Exception (#{exception.class}): #{exception.message}\"\n        message += \"\\n  #{exception.backtrace.join(\"  \\n\")}\" if exception.backtrace\n      end\n      fail(exception_while_unregistering.class,\n           message,\n           exception_while_unregistering.backtrace)\n    end", "label": 4}
{"code": "func (r *Registry) Get(ref types.ManagedObjectReference) mo.Reference {\n\tr.m.Lock()\n\tdefer r.m.Unlock()\n\n\treturn r.objects[ref]\n}", "label": 5}
{"code": "function () {\n                var me = this;\n                if (!me._dataInPromise) {\n                    me._dataInPromise = new Promise(function (resolve) {\n                        me._dataInResolve = resolve;\n                    }).then(function (data) {\n                        delete me._dataInPromise;\n                        delete me._dataInResolve;\n                        return data;\n                    });\n                }\n                return me._dataInPromise;\n            }", "label": 3}
{"code": "func GetSpecific(path string) (*File, error) {\n\tresolv, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\thash, err := ioutils.HashData(bytes.NewReader(resolv))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &File{Content: resolv, Hash: hash}, nil\n}", "label": 5}
{"code": "public function name()\n    {\n        return SpannerClient::sessionName(\n            $this->projectId,\n            $this->instance,\n            $this->database,\n            $this->name\n        );\n    }", "label": 2}
{"code": "public function snapshot(array $options = [])\n    {\n        $options += [\n            'transactionOptions' => [],\n        ];\n\n        // Single Use transactions are not supported in batch mode.\n        $options['transactionOptions']['singleUse'] = false;\n\n        $transactionOptions = $this->pluck('transactionOptions', $options);\n        $transactionOptions['returnReadTimestamp'] = true;\n\n        $transactionOptions = $this->configureSnapshotOptions($transactionOptions);\n\n        $session = $this->operation->createSession(\n            $this->databaseName,\n            $this->pluck('sessionOptions', $options, false) ?: []\n        );\n\n        return $this->operation->snapshot($session, [\n            'className' => BatchSnapshot::class,\n            'transactionOptions' => $transactionOptions\n        ] + $options);\n    }", "label": 2}
{"code": "def add(self, action=None, subject=None, **conditions):\n        \"\"\"\n        Add ability are allowed using two arguments.\n\n        The first one is the action you're setting the permission for,\n        the second one is the class of object you're setting it on.\n        the third one is the subject's conditions must be matches or a function\n        to be test.\n\n        self.add('update', Article)\n        self.add('update', Article, user_id=1)\n        self.add('update', Article, user_id=1, title='hello')\n        self.add('update', Article, function=test_title)\n        \"\"\"\n        self.add_rule(Rule(True, action, subject, **conditions))", "label": 1}
{"code": "def display_scale_help\n      return if service.running_count >= service.desired_count\n\n      events = service[\"events\"][0..3] # only check most recent 4 messages\n      error_event = events.find do |e|\n        e.message =~ /was unable to place a task/\n      end\n      return unless error_event\n\n      puts \"There is an issue scaling the #{@service.color(:green)} service to #{service.desired_count}.  Here's the error:\"\n      puts error_event.message.color(:red)\n      if service.launch_type == \"EC2\"\n        puts \"If AutoScaling is set up for the container instances, it can take a little time to add additional instances. You'll see this message until the capacity is added.\"\n      end\n    end", "label": 4}
{"code": "def get_subfolder(txt):\n    \"\"\"\n    extracts a displayable subfolder name from full filename\n    \"\"\"\n    root_folder = os.sep + 'aikif' + os.sep\n    ndx = txt.find(root_folder, 1)\n    return txt[ndx:].replace('__init__.py', '')", "label": 1}
{"code": "public function run()\n    {\n        $process = $this->getProcess();\n\n        $process->setTimeout($this->timeout);\n\n        if ($this->console instanceof Command) {\n            $process->run(function ($type, $line) {\n                $this->console->line($line);\n            });\n        }\n\n        return $process;\n    }", "label": 2}
{"code": "protected function executePipeline(ConnectionInterface $connection, \\SplQueue $commands)\n    {\n        foreach ($commands as $command) {\n            $connection->writeRequest($command);\n        }\n\n        $responses = array();\n        $exceptions = $this->throwServerExceptions();\n\n        while (!$commands->isEmpty()) {\n            $command = $commands->dequeue();\n            $response = $connection->readResponse($command);\n\n            if (!$response instanceof ResponseInterface) {\n                $responses[] = $command->parseResponse($response);\n            } elseif ($response instanceof ErrorResponseInterface && $exceptions) {\n                $this->exception($connection, $response);\n            } else {\n                $responses[] = $response;\n            }\n        }\n\n        return $responses;\n    }", "label": 2}
{"code": "public static systemuser[] get(nitro_service service) throws Exception{\n\t\tsystemuser obj = new systemuser();\n\t\tsystemuser[] response = (systemuser[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function updateSubscribers(req, res, next) {\n  var updateSubscribersParams = {\n    _id: req.params.id\n  };\n\n  var subscribers = req.body.subscribers;\n\n  logger.debug(\"Middleware: listSubscribers: \", {params: updateSubscribersParams, subscribers: subscribers});\n\n  forms.updateNotifications(_.extend(req.connectionOptions, updateSubscribersParams), subscribers, formsResultHandlers(constants.resultTypes.forms, req, next));\n}", "label": 3}
{"code": "def _setup():\n    \"\"\" Set up module.\n\n    Open a UDP socket, and listen in a thread.\n    \"\"\"\n    _SOCKET.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n    _SOCKET.bind(('', PORT))\n    udp = threading.Thread(target=_listen, daemon=True)\n    udp.start()", "label": 1}
{"code": "func kvmNetArgs(nds []kvm.NetDescriber) []string {\n\tvar qemuArgs []string\n\n\tfor _, nd := range nds {\n\t\tqemuArgs = append(qemuArgs, []string{\"-net\", \"nic,model=virtio\"}...)\n\t\tqemuNic := fmt.Sprintf(\"tap,ifname=%s,script=no,downscript=no,vhost=on\", nd.IfName())\n\t\tqemuArgs = append(qemuArgs, []string{\"-net\", qemuNic}...)\n\t}\n\n\treturn qemuArgs\n}", "label": 5}
{"code": "private static function streamForParent(array $sockets)\n    {\n        list($for_read, $for_write) = $sockets;\n\n        // The parent will not use the write channel, so it\n        // must be closed to prevent deadlock.\n        fclose($for_write);\n\n        // stream_select will be used to read multiple streams, so these\n        // must be set to non-blocking mode.\n        if (!stream_set_blocking($for_read, false)) {\n            error_log('unable to set read stream to non-blocking');\n            exit(self::EXIT_FAILURE);\n        }\n\n        return $for_read;\n    }", "label": 2}
{"code": "function _gpfHttMockMatchRequest (mockedRequest, request) {\n    var url = mockedRequest.url,\n        match;\n    url.lastIndex = 0;\n    match = url.exec(request.url);\n    if (match) {\n        return mockedRequest.response.apply(mockedRequest, [request].concat(_gpfArrayTail(match)));\n    }\n}", "label": 3}
{"code": "func (c *githubAPIClient) getTeams() ([]teamResponse, error) {\n\tvar result []teamResponse\n\n\tbytes, nextPage, err := c.get(\"/user/teams\")\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Extract the first page of results and append them to the full result set.\n\tvar teams []teamResponse\n\terr = json.Unmarshal(bytes, &teams)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tresult = append(result, teams...)\n\n\t// If the response returned a next page link, continue following the next\n\t// page links until all teams have been retrieved.\n\tvar count int\n\tfor nextPage != \"\" {\n\t\t// To prevent this from looping forever, don't fetch more than a set number\n\t\t// of pages, print an error when it does happen, and return the results up\n\t\t// to that point.\n\t\tif count > MaxPages {\n\t\t\twarningMessage := \"Truncating list of teams used to populate claims: \" +\n\t\t\t\t\"hit maximum number pages that can be fetched from GitHub.\"\n\n\t\t\t// Print warning to Teleport logs as well as the Audit Log.\n\t\t\tlog.Warnf(warningMessage)\n\t\t\tc.authServer.EmitAuditEvent(events.UserSSOLoginFailure, events.EventFields{\n\t\t\t\tevents.LoginMethod:        events.LoginMethodGithub,\n\t\t\t\tevents.AuthAttemptMessage: warningMessage,\n\t\t\t})\n\n\t\t\treturn result, nil\n\t\t}\n\n\t\tu, err := url.Parse(nextPage)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\n\t\tbytes, nextPage, err = c.get(u.RequestURI())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\n\t\terr = json.Unmarshal(bytes, &teams)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\n\t\t// Append this page of teams to full result set.\n\t\tresult = append(result, teams...)\n\n\t\tcount = count + 1\n\t}\n\n\treturn result, nil\n}", "label": 5}
{"code": "def create_discount(location_id, body, opts = {})\n      data, _status_code, _headers = create_discount_with_http_info(location_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "func kvmNetArgs(nds []kvm.NetDescriber) []string {\n\tvar lkvmArgs []string\n\n\tfor _, nd := range nds {\n\t\tlkvmArgs = append(lkvmArgs, \"--network\")\n\t\tlkvmArgs = append(\n\t\t\tlkvmArgs,\n\t\t\tfmt.Sprintf(\"mode=tap,tapif=%s,host_ip=%s,guest_ip=%s\", nd.IfName(), nd.Gateway(), nd.GuestIP()),\n\t\t)\n\t}\n\n\treturn lkvmArgs\n}", "label": 5}
{"code": "func (c *Client) CreateUserWithOTP(token, password, otpToken string) (services.WebSession, error) {\n\tout, err := c.PostJSON(c.Endpoint(\"signuptokens\", \"users\"), createUserWithTokenReq{\n\t\tToken:    token,\n\t\tPassword: password,\n\t\tOTPToken: otpToken,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn services.GetWebSessionMarshaler().UnmarshalWebSession(out.Bytes())\n}", "label": 5}
{"code": "function commit(result) {\n  var url = result.html_url\n  //user opted not to commit anything\n  if (argv.b || argv.bare) {\n    return Promise.resolve(url)\n  }\n  return getMessage().then(function(message) {\n    return gitCommit({\n      message: message,\n      url: url + '.git'\n    }).catch(function() {\n      console.warn(chalk.dim(\"git commands ignored\"))\n      return Promise.resolve(url)\n    }).then(function() {\n      return url\n    })\n  })\n}", "label": 3}
{"code": "public void setAlias(String alias)\r\n\t{\r\n\t\tm_alias = alias;\r\n\t\tString attributePath = (String)getAttribute();\r\n\t\tboolean allPathsAliased = true;\r\n\t\tm_userAlias = new UserAlias(alias, attributePath, allPathsAliased);\r\n\t\t\r\n\t}", "label": 0}
{"code": "def get(self, filepath):\n        \"\"\"\n        Get the contents of the specified file.\n        \"\"\"\n        exists = self.fs.exists(filepath)\n        if exists:\n            mime = magic.Magic(mime=True)\n            mime_type = mime.from_file(filepath)\n            if mime_type in self.unsupported_types:\n                self.set_status(204)\n                return\n            else:\n                contents = self.fs.read_file(filepath)\n            self.write({'filepath':filepath,'contents': contents})\n        else:\n            raise tornado.web.HTTPError(404)", "label": 1}
{"code": "public function setPeriod($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\ErrorReporting\\V1beta1\\QueryTimeRange_Period::class);\n        $this->period = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def get_patterns(all_patterns, type)\n      type = Core::FIXED_LINE if type == Core::FIXED_OR_MOBILE\n      patterns = all_patterns[type]\n\n      if patterns\n        [\n          type_regex(patterns, Core::POSSIBLE_PATTERN),\n          type_regex(patterns, Core::VALID_PATTERN)\n        ]\n      else\n        [nil, nil]\n      end\n    end", "label": 4}
{"code": "function isAppServer(inputpaths, serverConfig) {\n  // Test if 'p' is in 'dirs'\n  function contains(dirs, p) {\n    if (!Array.isArray(dirs)) dirs = [dirs];\n    return dirs.some(dir => {\n      return indir(dir, p);\n    });\n  }\n\n  return serverConfig != undefined && serverConfig.file != undefined && contains(inputpaths, serverConfig.file);\n}", "label": 3}
{"code": "function getId(id){\n        if(_.isObject(id) && !_.isUndefined(id.id)){\n            if (objectIdRegex.test(id.id)) {\n                id = id.id;\n            }\n            else {\n                id = null;\n            }\n        }\n        return id;\n    }", "label": 3}
{"code": "func (a *AuthWithRoles) DeleteNamespace(name string) error {\n\tif err := a.action(defaults.Namespace, services.KindNamespace, services.VerbDelete); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.DeleteNamespace(name)\n}", "label": 5}
{"code": "public function setContentOptions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::ENUM, \\Google\\Cloud\\Dlp\\V2\\ContentOption::class);\n        $this->content_options = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def infer_media(filepath)\n      require 'mime/types'\n      types = MIME::Types.type_for(filepath)\n      types.empty? ? 'application/octet-stream' : types.first\n    rescue LoadError\n      raise Github::Error::UnknownMedia.new(filepath)\n    end", "label": 4}
{"code": "public void initSize(Rectangle rectangle) {\n\t\ttemplate = writer.getDirectContent().createTemplate(rectangle.getWidth(), rectangle.getHeight());\n\t}", "label": 0}
{"code": "func (l *Lease) Complete(ctx context.Context) error {\n\treq := types.HttpNfcLeaseComplete{\n\t\tThis: l.Reference(),\n\t}\n\n\t_, err := methods.HttpNfcLeaseComplete(ctx, l.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "private static function parse_reference_links( $longdesc ) {\n\t\t$description = '';\n\t\tforeach ( explode( \"\\n\", $longdesc ) as $line ) {\n\t\t\tif ( 0 === strpos( $line, '#' ) ) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t$description .= $line . \"\\n\";\n\t\t}\n\n\t\t// Fires if it has description text at the head of `$longdesc`.\n\t\tif ( $description ) {\n\t\t\t$links   = array(); // An array of URLs from the description.\n\t\t\t$pattern = '/\\[.+?\\]\\((https?:\\/\\/.+?)\\)/';\n\t\t\t$newdesc = preg_replace_callback(\n\t\t\t\t$pattern,\n\t\t\t\tfunction( $matches ) use ( &$links ) {\n\t\t\t\t\tstatic $count = 0;\n\t\t\t\t\t$count++;\n\t\t\t\t\t$links[] = $matches[1];\n\t\t\t\t\treturn str_replace( '(' . $matches[1] . ')', '[' . $count . ']', $matches[0] );\n\t\t\t\t},\n\t\t\t\t$description\n\t\t\t);\n\n\t\t\t$footnote   = '';\n\t\t\t$link_count = count( $links );\n\t\t\tfor ( $i = 0; $i < $link_count; $i++ ) {\n\t\t\t\t$n         = $i + 1;\n\t\t\t\t$footnote .= '[' . $n . '] ' . $links[ $i ] . \"\\n\";\n\t\t\t}\n\n\t\t\tif ( $footnote ) {\n\t\t\t\t$newdesc  = trim( $newdesc ) . \"\\n\\n---\\n\" . $footnote;\n\t\t\t\t$longdesc = str_replace( trim( $description ), trim( $newdesc ), $longdesc );\n\t\t\t}\n\t\t}\n\n\t\treturn $longdesc;\n\t}", "label": 2}
{"code": "function() {\n      var idContainerDefinition = this.ids.idContainer;\n      var idContainer;\n      if (_.isUndefined(idContainerDefinition)) {\n        idContainer = undefined;\n      } else if (_.isFunction(idContainerDefinition)) {\n        var idContainerFxn = _.bind(idContainerDefinition, this);\n        idContainer = idContainerFxn();\n      } else if (_.isObject(idContainerDefinition)) {\n        idContainer = idContainerDefinition;\n      } else {\n        throw new Error('Invalid idContainer.  Not an object or function: ' + JSON.stringify(this.ids));\n      }\n      return idContainer;\n    }", "label": 3}
{"code": "public static sslcertkey[] get(nitro_service service, String certkey[]) throws Exception{\n\t\tif (certkey !=null && certkey.length>0) {\n\t\t\tsslcertkey response[] = new sslcertkey[certkey.length];\n\t\t\tsslcertkey obj[] = new sslcertkey[certkey.length];\n\t\t\tfor (int i=0;i<certkey.length;i++) {\n\t\t\t\tobj[i] = new sslcertkey();\n\t\t\t\tobj[i].set_certkey(certkey[i]);\n\t\t\t\tresponse[i] = (sslcertkey) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def from_text(cls, text, mapping='mapping'):\n        \"\"\"\n        Create a Profile instance from the Unicode graphemes found in `text`.\n\n        Parameters\n        ----------\n        text\n        mapping\n\n        Returns\n        -------\n        A Profile instance.\n\n        \"\"\"\n        graphemes = Counter(grapheme_pattern.findall(text))\n        specs = [\n            OrderedDict([\n                (cls.GRAPHEME_COL, grapheme),\n                ('frequency', frequency),\n                (mapping, grapheme)])\n            for grapheme, frequency in graphemes.most_common()]\n        return cls(*specs)", "label": 1}
{"code": "public static base_response Reboot(nitro_service client, reboot resource) throws Exception {\n\t\treboot Rebootresource = new reboot();\n\t\tRebootresource.warm = resource.warm;\n\t\treturn Rebootresource.perform_operation(client);\n\t}", "label": 0}
{"code": "function (list) {\n\t\n\tfor (var i=0; i < list.length; i++) {\n\t\tfor (var j=0; j < l_entries.length; j++) {\n\t\t\tif (list[i] === l_entries[j]) {\n\t\t\t\tl_entries.splice(j, 1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\t\n\t}\n}", "label": 3}
{"code": "public final boolean roll(final LoggingEvent loggingEvent) {\n    for (int i = 0; i < this.fileRollables.length; i++) {\n      if (this.fileRollables[i].roll(loggingEvent)) {\n        return true;\n      }\n    }\n    return false;\n  }", "label": 0}
{"code": "function(modelIdentifier) {\n            var model = this.get(modelIdentifier);\n            parentClass.remove.apply(this, arguments);\n            if (model) {\n              var trackedIdsWithoutModel = this.getTrackedIds();\n              trackedIdsWithoutModel = _.without(trackedIdsWithoutModel, model.id);\n              this.trackIds(trackedIdsWithoutModel);\n            }\n          }", "label": 3}
{"code": "func replaceHost(addr *utils.NetAddr, newHost string) {\n\t_, port, err := net.SplitHostPort(addr.Addr)\n\tif err != nil {\n\t\tlog.Errorf(\"failed parsing address: '%v'\", addr.Addr)\n\t}\n\taddr.Addr = net.JoinHostPort(newHost, port)\n}", "label": 5}
{"code": "func (s *APIServer) upsertNodes(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {\n\tvar req upsertNodesReq\n\tif err := httplib.ReadJSON(r, &req); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif !services.IsValidNamespace(req.Namespace) {\n\t\treturn nil, trace.BadParameter(\"invalid namespace %q\", req.Namespace)\n\t}\n\n\tnodes, err := services.GetServerMarshaler().UnmarshalServers(req.Nodes)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\terr = auth.UpsertNodes(req.Namespace, nodes)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn message(\"ok\"), nil\n}", "label": 5}
{"code": "func (s Strings) Addrs(defaultPort int) ([]NetAddr, error) {\n\taddrs := make([]NetAddr, len(s))\n\tfor i, val := range s {\n\t\taddr, err := ParseHostPortAddr(val, defaultPort)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\taddrs[i] = *addr\n\t}\n\treturn addrs, nil\n}", "label": 5}
{"code": "func (ep *endpoint) disableService() {\n\tep.Lock()\n\tdefer ep.Unlock()\n\tep.serviceEnabled = false\n}", "label": 5}
{"code": "public static Map<String, Automaton> createAutomatonMap(String prefix,\n      List<String> valueList, Boolean filter) {\n    HashMap<String, Automaton> automatonMap = new HashMap<>();\n    if (valueList != null) {\n      for (String item : valueList) {\n        if (filter) {\n          item = item.replaceAll(\"([\\\\\\\"\\\\)\\\\(\\\\<\\\\>\\\\.\\\\@\\\\#\\\\]\\\\[\\\\{\\\\}])\",\n              \"\\\\\\\\$1\");\n        }\n        automatonMap.put(item,\n            new RegExp(prefix + MtasToken.DELIMITER + item + \"\\u0000*\")\n                .toAutomaton());\n      }\n    }\n    return automatonMap;\n  }", "label": 0}
{"code": "func (info *Info) writeFiles(w io.Writer, open func(fi FileInfo) (io.ReadCloser, error)) error {\n\tfor _, fi := range info.UpvertedFiles() {\n\t\tr, err := open(fi)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error opening %v: %s\", fi, err)\n\t\t}\n\t\twn, err := io.CopyN(w, r, fi.Length)\n\t\tr.Close()\n\t\tif wn != fi.Length {\n\t\t\treturn fmt.Errorf(\"error copying %v: %s\", fi, err)\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "void nextExecuted(String sql) throws SQLException\r\n    {\r\n        count++;\r\n\r\n        if (_order.contains(sql))\r\n        {\r\n            return;\r\n        }\r\n\r\n        String sqlCmd = sql.substring(0, 7);\r\n        String rest = sql.substring(sqlCmd.equals(\"UPDATE \") ? 7 // \"UPDATE \"\r\n                : 12); // \"INSERT INTO \" or \"DELETE FROM \"\r\n        String tableName = rest.substring(0, rest.indexOf(' '));\r\n        HashSet fkTables = (HashSet) _fkInfo.get(tableName);\r\n\r\n        // we should not change order of INSERT/DELETE/UPDATE\r\n        // statements for the same table\r\n        if (_touched.contains(tableName))\r\n        {\r\n            executeBatch();\r\n        }\r\n        if (sqlCmd.equals(\"INSERT \"))\r\n        {\r\n            if (_dontInsert != null && _dontInsert.contains(tableName))\r\n            {\r\n                // one of the previous INSERTs contained a table\r\n                // that references this table.\r\n                // Let's execute that previous INSERT right now so that\r\n                // in the future INSERTs into this table will go first\r\n                // in the _order array.\r\n                executeBatch();\r\n            }\r\n        }\r\n        else\r\n        //if (sqlCmd.equals(\"DELETE \") || sqlCmd.equals(\"UPDATE \"))\r\n        {\r\n            // We process UPDATEs in the same way as DELETEs\r\n            // because setting FK to NULL in UPDATE is equivalent\r\n            // to DELETE from the referential integrity point of view.\r\n\r\n            if (_deleted != null && fkTables != null)\r\n            {\r\n                HashSet intersection = (HashSet) _deleted.clone();\r\n\r\n                intersection.retainAll(fkTables);\r\n                if (!intersection.isEmpty())\r\n                {\r\n                    // one of the previous DELETEs contained a table\r\n                    // that is referenced from this table.\r\n                    // Let's execute that previous DELETE right now so that\r\n                    // in the future DELETEs into this table will go first\r\n                    // in the _order array.\r\n                    executeBatch();\r\n                }\r\n            }\r\n        }\r\n\r\n        _order.add(sql);\r\n\r\n        _touched.add(tableName);\r\n        if (sqlCmd.equals(\"INSERT \"))\r\n        {\r\n            if (fkTables != null)\r\n            {\r\n                if (_dontInsert == null)\r\n                {\r\n                    _dontInsert = new HashSet();\r\n                }\r\n                _dontInsert.addAll(fkTables);\r\n            }\r\n        }\r\n        else if (sqlCmd.equals(\"DELETE \"))\r\n        {\r\n            if (_deleted == null)\r\n            {\r\n                _deleted = new HashSet();\r\n            }\r\n            _deleted.add(tableName);\r\n        }\r\n    }", "label": 0}
{"code": "function wrapCallback(callback)\n{\n  var stream = this;\n\n  var wrapped = function(error, result)\n  {\n    return finisher.call(stream, error, result, callback);\n  };\n\n  return wrapped;\n}", "label": 3}
{"code": "def install_user_command_legacy(command, **substitutions):\n    '''Install command executable file into users bin dir.\n\n    If a custom executable exists it would be installed instead of the \"normal\"\n    one.  The executable also could exist as a <command>.template file.\n    '''\n    path = flo('~/bin/{command}')\n    install_file_legacy(path, **substitutions)\n    run(flo('chmod 755 {path}'))", "label": 1}
{"code": "protected function resolveName(Name $name, $type) {\n        $resolvedName = $this->nameContext->getResolvedName($name, $type);\n        if (null !== $resolvedName) {\n            $name->setAttribute('resolvedName', $resolvedName->toString());\n        }\n        return $name;\n    }", "label": 2}
{"code": "func Build(path, IP, hostname, domainname string, extraContent []Record) error {\n\tdefer pathLock(path)()\n\n\tcontent := bytes.NewBuffer(nil)\n\tif IP != \"\" {\n\t\t//set main record\n\t\tvar mainRec Record\n\t\tmainRec.IP = IP\n\t\t// User might have provided a FQDN in hostname or split it across hostname\n\t\t// and domainname.  We want the FQDN and the bare hostname.\n\t\tfqdn := hostname\n\t\tif domainname != \"\" {\n\t\t\tfqdn = fmt.Sprintf(\"%s.%s\", fqdn, domainname)\n\t\t}\n\t\tparts := strings.SplitN(fqdn, \".\", 2)\n\t\tif len(parts) == 2 {\n\t\t\tmainRec.Hosts = fmt.Sprintf(\"%s %s\", fqdn, parts[0])\n\t\t} else {\n\t\t\tmainRec.Hosts = fqdn\n\t\t}\n\t\tif _, err := mainRec.WriteTo(content); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// Write defaultContent slice to buffer\n\tfor _, r := range defaultContent {\n\t\tif _, err := r.WriteTo(content); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// Write extra content from function arguments\n\tfor _, r := range extraContent {\n\t\tif _, err := r.WriteTo(content); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ioutil.WriteFile(path, content.Bytes(), 0644)\n}", "label": 5}
{"code": "def generate_header(newer_tag_name, newer_tag_link, newer_tag_time, older_tag_name, project_url)\n      header = \"\"\n\n      # Generate date string:\n      time_string = newer_tag_time.strftime(@options[:date_format])\n\n      # Generate tag name and link\n      release_url = if @options[:release_url]\n                      format(@options[:release_url], newer_tag_link)\n                    else\n                      \"#{project_url}/tree/#{newer_tag_link}\"\n                    end\n      header += if newer_tag_name.equal?(@options[:unreleased_label])\n                  \"## [#{newer_tag_name}](#{release_url})\\n\\n\"\n                else\n                  \"## [#{newer_tag_name}](#{release_url}) (#{time_string})\\n\\n\"\n                end\n\n      if @options[:compare_link] && older_tag_name\n        # Generate compare link\n        header += \"[Full Changelog](#{project_url}/compare/#{older_tag_name}...#{newer_tag_link})\\n\\n\"\n      end\n\n      header\n    end", "label": 4}
{"code": "public function setAddonsConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\AddonsConfig::class);\n        $this->addons_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (v VirtualMachine) Answer(ctx context.Context, id, answer string) error {\n\treq := types.AnswerVM{\n\t\tThis:         v.Reference(),\n\t\tQuestionId:   id,\n\t\tAnswerChoice: answer,\n\t}\n\n\t_, err := methods.AnswerVM(ctx, v.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function getRelationships(model) {\n    const modelName = model.constructor.name;\n    const properties = typed_conversions_1.hashToArray(exports.relationshipsByModel[modelName], \"property\") || [];\n    let parent = Object.getPrototypeOf(model.constructor);\n    while (parent.name) {\n        const subClass = new parent();\n        const subClassName = subClass.constructor.name;\n        properties.push(...typed_conversions_1.hashToArray(exports.relationshipsByModel[subClassName], \"property\"));\n        parent = Object.getPrototypeOf(subClass.constructor);\n    }\n    return properties;\n}", "label": 3}
{"code": "def dynamic_fields\n      fields = []\n      variant_combinations.each do |field_variants|\n        FIELD_TYPES.each do |type|\n          fields << DynamicField.new(type, field_variants)\n        end\n      end\n      fields\n    end", "label": 4}
{"code": "def render_activities(activities, options = {})\n      activities.map { |activity| Renderable.render(activity, self, options.dup) }.join.html_safe\n    end", "label": 4}
{"code": "function _eq(evt, size, init) {\n    const sz = evt.size;\n    const mn = evt.min;\n    const mx = evt.max;\n    const ex = evt.each || init;\n\n    // Check match against rules\n    return (! sz && ! mn && ! mx) ||\n        (sz && sz === size) ||\n        (mn && size >= mn && (ex || current < mn) && (! mx || size <= mx)) ||\n        (mx && size <= mx && (ex || current > mx) && (! mn || size >= mn));\n}", "label": 3}
{"code": "function cmd(args) {\n            var def = Q.defer();\n            grunt.util.spawn({ cmd: 'git', args: args }, def.resolve);\n            return def.promise;\n        }", "label": 3}
{"code": "function createPropertyResolver(properties)\n{\n  if ( isFunction( properties ) )\n  {\n    return properties;\n  }\n  else if ( isString( properties ) )\n  {\n    if ( properties in PropertyResolvers )\n    {\n      return PropertyResolvers[ properties ];\n    }\n\n    if ( isFormatInput( properties ) )\n    {\n      return createFormatter( properties );\n    }\n    else if ( isParseInput( properties ) )\n    {\n      return createParser( properties );\n    }\n    else\n    {\n      return function resolveProperty(model)\n      {\n        return model ? model[ properties ] : undefined;\n      };\n    }\n  }\n  else if ( isArray( properties ) )\n  {\n    return function resolveProperties(model)\n    {\n      return pull( model, properties );\n    };\n  }\n  else if ( isObject( properties ) )\n  {\n    var propsArray = [];\n    var propsResolver = [];\n\n    for (var prop in properties)\n    {\n      propsArray.push( prop );\n      propsResolver.push( createPropertyResolver( properties[ prop ] ) );\n    }\n\n    return function resolvePropertyObject(model)\n    {\n      var resolved = {};\n\n      for (var i = 0; i < propsArray.length; i++)\n      {\n        var prop = propsArray[ i ];\n\n        resolved[ prop ] = propsResolver[ i ]( model[ prop ] );\n      }\n\n      return resolved;\n    };\n  }\n  else\n  {\n    return function resolveNone(model)\n    {\n      return model;\n    };\n  }\n}", "label": 3}
{"code": "public function GetInstance(\\Google\\Cloud\\Redis\\V1\\GetInstanceRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.cloud.redis.v1.CloudRedis/GetInstance',\n        $argument,\n        ['\\Google\\Cloud\\Redis\\V1\\Instance', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, cmpparameter resource) throws Exception {\n\t\tcmpparameter updateresource = new cmpparameter();\n\t\tupdateresource.cmplevel = resource.cmplevel;\n\t\tupdateresource.quantumsize = resource.quantumsize;\n\t\tupdateresource.servercmp = resource.servercmp;\n\t\tupdateresource.heurexpiry = resource.heurexpiry;\n\t\tupdateresource.heurexpirythres = resource.heurexpirythres;\n\t\tupdateresource.heurexpiryhistwt = resource.heurexpiryhistwt;\n\t\tupdateresource.minressize = resource.minressize;\n\t\tupdateresource.cmpbypasspct = resource.cmpbypasspct;\n\t\tupdateresource.cmponpush = resource.cmponpush;\n\t\tupdateresource.policytype = resource.policytype;\n\t\tupdateresource.addvaryheader = resource.addvaryheader;\n\t\tupdateresource.externalcache = resource.externalcache;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "private boolean isEqual(FieldDescriptorDef first, FieldDescriptorDef second)\r\n    {\r\n        return first.getName().equals(second.getName()) &&\r\n               first.getProperty(PropertyHelper.OJB_PROPERTY_COLUMN).equals(second.getProperty(PropertyHelper.OJB_PROPERTY_COLUMN)) &&\r\n               first.getProperty(PropertyHelper.OJB_PROPERTY_JDBC_TYPE).equals(second.getProperty(PropertyHelper.OJB_PROPERTY_JDBC_TYPE));\r\n    }", "label": 0}
{"code": "def select(*str_or_rx)\n      results = str_or_rx.flatten.map { |v| select_by v }\n      results.first\n    end", "label": 4}
{"code": "public static clusterinstance[] get(nitro_service service, Long clid[]) throws Exception{\n\t\tif (clid !=null && clid.length>0) {\n\t\t\tclusterinstance response[] = new clusterinstance[clid.length];\n\t\t\tclusterinstance obj[] = new clusterinstance[clid.length];\n\t\t\tfor (int i=0;i<clid.length;i++) {\n\t\t\t\tobj[i] = new clusterinstance();\n\t\t\t\tobj[i].set_clid(clid[i]);\n\t\t\t\tresponse[i] = (clusterinstance) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def _updatePropensities(self, lastState, lastAction, reward):\n        \"\"\" Update the propensities for all actions. The propensity for last\n        action chosen will be updated using the feedback value that resulted\n        from performing the action.\n\n        If j is the index of the last action chosen, r_j is the reward received\n        for performing j, i is the current action being updated, q_i is the\n        propensity for i, and phi is the recency parameter, then this update\n        function can be expressed as::\n\n                q_i = (1-phi) * q_i + E(i, r_j)\n        \"\"\"\n        phi = self.recency\n\n        for action in range(self.module.numActions):\n            carryOver = (1 - phi) * self.module.getValue(lastState, action)\n            experience = self._experience(lastState, action, lastAction,reward)\n\n            self.module.updateValue(lastState, action, carryOver + experience)", "label": 1}
{"code": "func (auup *AuthUserUserPermission) Save(db XODB) error {\n\tif auup.Exists() {\n\t\treturn auup.Update(db)\n\t}\n\n\treturn auup.Insert(db)\n}", "label": 5}
{"code": "function promiseWrap(x) {\r\n  if(x.then && typeof x.then === \"function\") {\r\n    return x;    \r\n  }\r\n  var deferred = q.defer();\r\n  deferred.resolve(x);\r\n  return deferred.promise;\r\n}", "label": 3}
{"code": "func (i *Handle) parseService(msg []byte) (*Service, error) {\n\n\tvar s *Service\n\n\t//Remove General header for this message and parse the NetLink message\n\thdr := deserializeGenlMsg(msg)\n\tNetLinkAttrs, err := nl.ParseRouteAttr(msg[hdr.Len():])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(NetLinkAttrs) == 0 {\n\t\treturn nil, fmt.Errorf(\"error no valid netlink message found while parsing service record\")\n\t}\n\n\t//Now Parse and get IPVS related attributes messages packed in this message.\n\tipvsAttrs, err := nl.ParseRouteAttr(NetLinkAttrs[0].Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//Assemble all the IPVS related attribute messages and create a service record\n\ts, err = assembleService(ipvsAttrs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn s, nil\n}", "label": 5}
{"code": "protected function processProfilePicture($node)\n    {\n        $pictureNode = $node->getChild('picture');\n\n        if ($pictureNode != null) {\n            if ($pictureNode->getAttribute('type') == 'preview') {\n                $filename = $this->dataFolder.Constants::PICTURES_FOLDER.DIRECTORY_SEPARATOR.'preview_'.$node->getAttribute('from').'jpg';\n            } else {\n                $filename = $this->dataFolder.Constants::PICTURES_FOLDER.DIRECTORY_SEPARATOR.$node->getAttribute('from').'.jpg';\n            }\n\n            file_put_contents($filename, $pictureNode->getData());\n        }\n    }", "label": 2}
{"code": "def get_data(self):\n\t\t\"Get the data for this blob\"\n\t\tarray = ctypes.POINTER(ctypes.c_char * len(self))\n\t\treturn ctypes.cast(self.data, array).contents.raw", "label": 1}
{"code": "function getDbIndexes(modelKlass) {\n    const modelName = modelKlass.constructor.name;\n    return modelName === \"Model\"\n        ? typed_conversions_1.hashToArray(exports.indexesForModel[modelName])\n        : (typed_conversions_1.hashToArray(exports.indexesForModel[modelName]) || []).concat(typed_conversions_1.hashToArray(exports.indexesForModel.Model));\n}", "label": 3}
{"code": "func (s *ClusterConfigurationService) SetClusterName(c services.ClusterName) error {\n\tvalue, err := services.GetClusterNameMarshaler().Marshal(c)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t_, err = s.Create(context.TODO(), backend.Item{\n\t\tKey:     backend.Key(clusterConfigPrefix, namePrefix),\n\t\tValue:   value,\n\t\tExpires: c.Expiry(),\n\t})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def _parse_args(self, args):\n        \"\"\"Parses any supplied command-line args and provides help text. \"\"\"\n\n        parser = ArgumentParser(description=\"Runs pylint recursively on a directory\")\n\n        parser.add_argument(\n            \"-v\",\n            \"--verbose\",\n            dest=\"verbose\",\n            action=\"store_true\",\n            default=False,\n            help=\"Verbose mode (report which files were found for testing).\",\n        )\n\n        parser.add_argument(\n            \"--rcfile\",\n            dest=\"rcfile\",\n            action=\"store\",\n            default=\".pylintrc\",\n            help=\"A relative or absolute path to your pylint rcfile. Defaults to\\\n                            `.pylintrc` at the current working directory\",\n        )\n\n        parser.add_argument(\n            \"-V\",\n            \"--version\",\n            action=\"version\",\n            version=\"%(prog)s ({0}) for Python {1}\".format(__version__, PYTHON_VERSION),\n        )\n\n        options, _ = parser.parse_known_args(args)\n\n        self.verbose = options.verbose\n\n        if options.rcfile:\n            if not os.path.isfile(options.rcfile):\n                options.rcfile = os.getcwd() + \"/\" + options.rcfile\n            self.rcfile = options.rcfile\n\n        return options", "label": 1}
{"code": "private function getContacts()\n    {\n        try {\n            //Get whatsapp's Groups this user belongs to.\n            $this->waGroupList = [];\n            $this->getGroupList();\n            if (is_array($this->waGroupList)) {\n                $this->contacts = array_merge($this->contacts, $this->waGroupList);\n            }\n\n            //Get contacts from google if gmail account configured.\n            $googleContacts = [];\n            if (isset($this->config[$this->from]['email'])) {\n                $email = $this->config[$this->from]['email'];\n\n                if (stripos($email, 'gmail') !== false || stripos($email, 'googlemail') !== false) {\n                    $google = new GoogleContacts();\n                    $googleContacts = $google->getContacts($this->config, $this->from);\n                    if (is_array($googleContacts)) {\n                        $this->contacts = array_merge($this->contacts, $googleContacts);\n                    }\n                }\n            }\n\n            if (isset($this->contacts)) {\n                exit(json_encode([\n                    'success'  => true,\n                    'type'     => 'contacts',\n                    'data'     => $this->contacts,\n                    'messages' => $this->messages,\n                ]));\n            }\n        } catch (Exception $e) {\n            exit(json_encode([\n                'success'  => false,\n                'type'     => 'contacts',\n                'errormsg' => $e->getMessage(),\n            ]));\n        }\n    }", "label": 2}
{"code": "def files_content(record, identifier, path, frag_content)\n      # preparing attachments\n      files = frag_content.split(\"\\n\").collect do |filename|\n        file_handler = File.open(File.join(path, filename))\n        {\n          io:           file_handler,\n          filename:     filename,\n          content_type: MimeMagic.by_magic(file_handler)\n        }\n      end\n\n      # ensuring that old attachments get removed\n      ids_destroy = []\n      if (frag = record.fragments.find_by(identifier: identifier))\n        ids_destroy = frag.attachments.pluck(:id)\n      end\n\n      [files, ids_destroy]\n    end", "label": 4}
{"code": "public AssemblyResponse save(boolean isResumable)\n            throws RequestException, LocalOperationException {\n        Request request = new Request(getClient());\n        options.put(\"steps\", steps.toMap());\n\n        // only do tus uploads if files will be uploaded\n        if (isResumable && getFilesCount() > 0) {\n            Map<String, String> tusOptions = new HashMap<String, String>();\n            tusOptions.put(\"tus_num_expected_upload_files\", Integer.toString(getFilesCount()));\n\n            AssemblyResponse response = new AssemblyResponse(\n                    request.post(\"/assemblies\", options, tusOptions, null, null), true);\n\n            // check if the assembly returned an error\n            if (response.hasError()) {\n                throw new RequestException(\"Request to Assembly failed: \" + response.json().getString(\"error\"));\n            }\n\n            try {\n                handleTusUpload(response);\n            } catch (IOException e) {\n                throw new LocalOperationException(e);\n            } catch (ProtocolException e) {\n                throw new RequestException(e);\n            }\n            return response;\n        } else {\n            return new AssemblyResponse(request.post(\"/assemblies\", options, null, files, fileStreams));\n        }\n    }", "label": 0}
{"code": "public void set_protocol(String protocol) throws nitro_exception\n\t{\n\t\tif (protocol == null || !(protocol.equalsIgnoreCase(\"http\") ||protocol.equalsIgnoreCase(\"https\"))) {\n\t\t\tthrow new nitro_exception(\"error: protocol value \" + protocol + \" is not supported\");\n\t\t}\n\t\tthis.protocol = protocol;\n\t}", "label": 0}
{"code": "func (i *Handle) NewService(s *Service) error {\n\treturn i.doCmd(s, nil, ipvsCmdNewService)\n}", "label": 5}
{"code": "def display_image\n      return nil unless ::FileSet.exists?(id) && solr_document.image? && current_ability.can?(:read, id)\n      # @todo this is slow, find a better way (perhaps index iiif url):\n      original_file = ::FileSet.find(id).original_file\n\n      url = Hyrax.config.iiif_image_url_builder.call(\n        original_file.id,\n        request.base_url,\n        Hyrax.config.iiif_image_size_default\n      )\n      # @see https://github.com/samvera-labs/iiif_manifest\n      IIIFManifest::DisplayImage.new(url,\n                                     width: 640,\n                                     height: 480,\n                                     iiif_endpoint: iiif_endpoint(original_file.id))\n    end", "label": 4}
{"code": "function terminator(callback)\n{\n  if (!Object.keys(this.jobs).length)\n  {\n    return;\n  }\n\n  // fast forward iteration index\n  this.index = this.size;\n\n  // abort jobs\n  abort(this);\n\n  // send back results we have so far\n  async(callback)(null, this.results);\n}", "label": 3}
{"code": "function serialOrdered(list, iterator, sortMethod, callback)\n{\n  var state = initState(list, sortMethod);\n\n  iterate(list, iterator, state, function iteratorHandler(error, result)\n  {\n    if (error)\n    {\n      callback(error, result);\n      return;\n    }\n\n    state.index++;\n\n    // are we there yet?\n    if (state.index < (state['keyedList'] || list).length)\n    {\n      iterate(list, iterator, state, iteratorHandler);\n      return;\n    }\n\n    // done here\n    callback(null, state.results);\n  });\n\n  return terminator.bind(state, callback);\n}", "label": 3}
{"code": "func GetExtensionManager(c *vim25.Client) (*ExtensionManager, error) {\n\tif c.ServiceContent.ExtensionManager == nil {\n\t\treturn nil, ErrNotSupported\n\t}\n\treturn NewExtensionManager(c), nil\n}", "label": 5}
{"code": "@Api\n\tpublic void setUrl(String url) throws LayerException {\n\t\ttry {\n\t\t\tthis.url = url;\n\t\t\tMap<String, Object> params = new HashMap<String, Object>();\n\t\t\tparams.put(\"url\", url);\n\t\t\tDataStore store = DataStoreFactory.create(params);\n\t\t\tsetDataStore(store);\n\t\t} catch (IOException ioe) {\n\t\t\tthrow new LayerException(ioe, ExceptionCode.INVALID_SHAPE_FILE_URL, url);\n\t\t}\n\t}", "label": 0}
{"code": "func (self *Queue) DelayedGopCount(n int) *QueueCursor {\n\tcursor := self.newCursor()\n\tcursor.init = func(buf *pktque.Buf, videoidx int) pktque.BufPos {\n\t\ti := buf.Tail - 1\n\t\tif videoidx != -1 {\n\t\t\tfor gop := 0; buf.IsValidPos(i) && gop < n; i-- {\n\t\t\t\tpkt := buf.Get(i)\n\t\t\t\tif pkt.Idx == int8(self.videoidx) && pkt.IsKeyFrame {\n\t\t\t\t\tgop++\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn i\n\t}\n\treturn cursor\n}", "label": 5}
{"code": "function lengthInUtf8Bytes(str) {\n\t\tconst m = encodeURIComponent(str).match(/%[89ABab]/g);\n\t\treturn str.length + (m ? m.length : 0);\n\t}", "label": 3}
{"code": "function createTemplateValue(start, end) {\n    var value = \"\";\n    while (start <= end) {\n      if (tokens[start].value) {\n        value += tokens[start].value;\n      } else if (tokens[start].type !== tt.template) {\n        value += tokens[start].type.label;\n      }\n      start++;\n    }\n    return value;\n  }", "label": 3}
{"code": "def delete(entry)\n      return true if !entry.id\n\n      @lock.synchronize do\n        with_index_lock do\n          return true if !@machines[entry.id]\n\n          # If we don't have the lock, then we need to acquire it.\n          if !@machine_locks[entry.id]\n            raise \"Unlocked delete on machine: #{entry.id}\"\n          end\n\n          # Reload so we have the latest data, then delete and save\n          unlocked_reload\n          @machines.delete(entry.id)\n          unlocked_save\n\n          # Release access on this machine\n          unlocked_release(entry.id)\n        end\n      end\n\n      true\n    end", "label": 4}
{"code": "func (t *Torrent) Drop() {\n\tt.cl.lock()\n\tt.cl.dropTorrent(t.infoHash)\n\tt.cl.unlock()\n}", "label": 5}
{"code": "function decorateSend(q, scope, transport) {\n        var original = transport.send;\n        transport.send = function (options) {\n\n            // Store originals\n            var defer = q.defer(),\n                onSuccess = options.successCallback || angular.noop,\n                onError = options.errorCallback || angular.noop;\n\n            options.successCallback = function (result) {\n                scope.$apply(function () {\n                    defer.resolve(result);\n                    onSuccess(result);\n                });\n            };\n\n            options.errorCallback = function (result) {\n                scope.$apply(function () {\n                    defer.reject(result);\n                    onError(result);\n                });\n            };\n\n            // Call the original transport method\n            // but use our promise as the return value\n            original.call(transport, options);\n            return defer.promise;\n        };\n    }", "label": 3}
{"code": "def list_modifier_lists(location_id, opts = {})\n      data, _status_code, _headers = list_modifier_lists_with_http_info(location_id, opts)\n      return data\n    end", "label": 4}
{"code": "public void setClassOfObject(Class c)\r\n    {\r\n        m_Class = c;\r\n        isAbstract = Modifier.isAbstract(m_Class.getModifiers());\r\n        // TODO : Shouldn't the HashMap in DescriptorRepository be updated as well?\r\n    }", "label": 0}
{"code": "function parseResponse(event) {\n            try {\n                var response = JSON.parse(event.data);\n\n                // Check for success key to ignore messages being sent\n                if (response.namespace === namespace && typeof response.success === 'boolean') {\n                    return response;\n                }\n\n                return false;\n            } catch (e) {}\n\n            return false;\n        }", "label": 3}
{"code": "public static tunnelip_stats get(nitro_service service, String tunnelip) throws Exception{\n\t\ttunnelip_stats obj = new tunnelip_stats();\n\t\tobj.set_tunnelip(tunnelip);\n\t\ttunnelip_stats response = (tunnelip_stats) obj.stat_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (d *Decoder) syntaxError(msg string) error {\n\treturn &SyntaxError{Msg: msg, Line: d.line}\n}", "label": 5}
{"code": "func MakeAudioCodecType(base uint32) (c CodecType) {\n\tc = CodecType(base)<<codecTypeOtherBits | CodecType(codecTypeAudioBit)\n\treturn\n}", "label": 5}
{"code": "def write_junit(target = self.class.default_target)\n      # Open a File Object for IO if target is a string containing a filename or path\n      target = File.open(target, 'w') if target.is_a? String\n\n      document = REXML::Document.new\n      document << REXML::XMLDecl.new\n      testsuites = REXML::Element.new('testsuites')\n\n      id = 0\n      events.each do |testsuite_name, testcases|\n        testsuite = REXML::Element.new('testsuite')\n        testsuite.attributes['name'] = testsuite_name\n        testsuite.attributes['tests'] = testcases.length\n        testsuite.attributes['errors'] = testcases.select(&:error?).length\n        testsuite.attributes['failures'] = testcases.select(&:failure?).length\n        testsuite.attributes['skipped'] = testcases.select(&:skipped?).length\n        testsuite.attributes['time'] = 0\n        testsuite.attributes['timestamp'] = Time.now.strftime('%Y-%m-%dT%H:%M:%S')\n        testsuite.attributes['hostname'] = Socket.gethostname\n        testsuite.attributes['id'] = id\n        testsuite.attributes['package'] = testsuite_name\n        testsuite.add_element('properties')\n        testcases.each { |r| testsuite.elements << r.to_junit }\n        testsuite.add_element('system-out')\n        testsuite.add_element('system-err')\n\n        testsuites.elements << testsuite\n        id += 1\n      end\n\n      document.elements << testsuites\n      document.write(target, 2)\n    ensure\n      target.close if target.is_a? File\n    end", "label": 4}
{"code": "def default( sym, val = nil )\n      if val\n        header[sym] = val\n      elsif field = header[sym]\n        field.default\n      end\n    end", "label": 4}
{"code": "def summarise_events(self):\n        \"\"\"\n        takes the logfiles and produces an event summary matrix\n            date        command result  process source\n            20140421    9       40      178     9\n            20140423    0       0       6       0\n            20140424    19      1       47      19\n            20140425    24      0       117     24\n            20140426    16      0       83      16\n            20140427    1       0       6       1\n            20140429    0       0       0       4\n\n        \"\"\"\n        all_dates = []\n        d_command = self._count_by_date(self.command_file, all_dates)\n        d_result  = self._count_by_date(self.result_file,  all_dates)\n        d_process = self._count_by_date(self.process_file, all_dates)\n        d_source  = self._count_by_date(self.source_file,  all_dates)\n\n        with open(self.log_sum, \"w\") as sum_file:\n            sum_file.write('date,command,result,process,source\\n')\n            for dte in sorted(set(all_dates)):\n                sum_file.write(dte + ',')\n                if dte in d_command:\n                    sum_file.write(str(d_command[dte]) + ',')\n                else:\n                    sum_file.write('0,')\n                if dte in d_result:\n                    sum_file.write(str(d_result[dte]) + ',')\n                else:\n                    sum_file.write('0,')\n                if dte in d_process:\n                    sum_file.write(str(d_process[dte]) + ',')\n                else:\n                    sum_file.write('0,')\n                if dte in d_source:\n                    sum_file.write(str(d_source[dte]) + '\\n')\n                else:\n                    sum_file.write('0\\n')", "label": 1}
{"code": "def as_feature(data):\n    \"\"\"Returns a Feature or FeatureCollection.\n\n    Arguments:\n    data -- Sequence or Mapping of Feature-like or FeatureCollection-like data\n    \"\"\"\n    if not isinstance(data, (Feature, FeatureCollection)):\n        if is_featurelike(data):\n            data = Feature(**data)\n        elif has_features(data):\n            data = FeatureCollection(**data)\n        elif isinstance(data, collections.Sequence):\n            data = FeatureCollection(features=data)\n        elif has_layer(data):\n            data = LayerCollection(data)\n        elif has_coordinates(data):\n            data = Feature(geometry=data)\n        elif isinstance(data, collections.Mapping) and not data:\n            data = Feature()\n    return data", "label": 1}
{"code": "func (p *ProcessStorage) ReadIdentity(name string, role teleport.Role) (*Identity, error) {\n\tif name == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing parameter name\")\n\t}\n\titem, err := p.Get(context.TODO(), backend.Key(idsPrefix, strings.ToLower(role.String()), name))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar res IdentityV2\n\tif err := utils.UnmarshalWithSchema(GetIdentitySchema(), &res, item.Value); err != nil {\n\t\treturn nil, trace.BadParameter(err.Error())\n\t}\n\treturn ReadIdentityFromKeyPair(&PackedKeys{\n\t\tKey:        res.Spec.Key,\n\t\tCert:       res.Spec.SSHCert,\n\t\tTLSCert:    res.Spec.TLSCert,\n\t\tTLSCACerts: res.Spec.TLSCACerts,\n\t\tSSHCACerts: res.Spec.SSHCACerts,\n\t})\n}", "label": 5}
{"code": "public RedwoodConfiguration clear(){\r\n    tasks = new LinkedList<Runnable>();\r\n    tasks.add(new Runnable(){ public void run(){\r\n      Redwood.clearHandlers();\r\n      Redwood.restoreSystemStreams();\r\n      Redwood.clearLoggingClasses();\r\n    } });\r\n    return this;\r\n  }", "label": 0}
{"code": "def get_tool_by_name(self, nme):\n        \"\"\"\n        get the tool object by name or file\n        \"\"\"\n        for t in self.lstTools:\n            if 'name' in t:\n                if t['name'] == nme:\n                    return t\n            if 'file' in t:\n                if t['file'] == nme:\n                    return t\n        return None", "label": 1}
{"code": "public function setAppEngineRouting($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Scheduler\\V1beta1\\AppEngineRouting::class);\n        $this->app_engine_routing = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static List<DbModule> getAllSubmodules(final DbModule module) {\n        final List<DbModule> submodules = new ArrayList<DbModule>();\n        submodules.addAll(module.getSubmodules());\n\n        for(final DbModule submodule: module.getSubmodules()){\n            submodules.addAll(getAllSubmodules(submodule));\n        }\n\n        return submodules;\n    }", "label": 0}
{"code": "def linear_constraints(self):\n        \"\"\" Returns the linear constraints.\n        \"\"\"\n        if self.lin_N == 0:\n            return None, array([]), array([])\n\n        A = lil_matrix((self.lin_N, self.var_N), dtype=float64)\n        l = -Inf * ones(self.lin_N)\n        u = -l\n\n        for lin in self.lin_constraints:\n            if lin.N:                   # non-zero number of rows to add\n                Ak = lin.A              # A for kth linear constrain set\n                i1 = lin.i1             # starting row index\n                iN = lin.iN             # ending row index\n                vsl = lin.vs            # var set list\n                kN = -1                 # initialize last col of Ak used\n                Ai = lil_matrix((lin.N, self.var_N), dtype=float64)\n                for v in vsl:\n                    var = self.get_var(v)\n                    j1 = var.i1         # starting column in A\n                    jN = var.iN         # ending column in A\n                    k1 = kN + 1         # starting column in Ak\n                    kN = kN + var.N     # ending column in Ak\n\n                    if j1 == jN:\n                        # FIXME: Single column slicing broken in lil.\n                        for i in range(Ai.shape[0]):\n                            Ai[i, j1] = Ak[i, k1]\n                    else:\n                        Ai[:, j1:jN + 1] = Ak[:, k1:kN + 1]\n\n                A[i1:iN + 1, :] = Ai\n                l[i1:iN + 1] = lin.l\n                u[i1:iN + 1] = lin.u\n\n        return A.tocsr(), l, u", "label": 1}
{"code": "func (self AudioFrame) Slice(start int, end int) (out AudioFrame) {\n\tif start > end {\n\t\tpanic(fmt.Sprintf(\"av: AudioFrame split failed start=%d end=%d invalid\", start, end))\n\t}\n\tout = self\n\tout.Data = append([][]byte(nil), out.Data...)\n\tout.SampleCount = end - start\n\tsize := self.SampleFormat.BytesPerSample()\n\tfor i := range out.Data {\n\t\tout.Data[i] = out.Data[i][start*size : end*size]\n\t}\n\treturn\n}", "label": 5}
{"code": "def none_of(value, *args):\n    \"\"\" None of the items in value should match \"\"\"\n\n    if len(args):\n        value = (value,) + args\n\n    return ExpectationNone(value)", "label": 1}
{"code": "protected String classOf(List<IN> lineInfos, int pos) {\r\n    Datum<String, String> d = makeDatum(lineInfos, pos, featureFactory);\r\n    return classifier.classOf(d);\r\n  }", "label": 0}
{"code": "public void configure(Configuration pConfig) throws ConfigurationException\r\n    {\r\n        if (pConfig instanceof PBPoolConfiguration)\r\n        {\r\n            PBPoolConfiguration conf = (PBPoolConfiguration) pConfig;\r\n            this.setMaxActive(conf.getMaxActive());\r\n            this.setMaxIdle(conf.getMaxIdle());\r\n            this.setMaxWait(conf.getMaxWaitMillis());\r\n            this.setMinEvictableIdleTimeMillis(conf.getMinEvictableIdleTimeMillis());\r\n            this.setTimeBetweenEvictionRunsMillis(conf.getTimeBetweenEvictionRunsMilli());\r\n            this.setWhenExhaustedAction(conf.getWhenExhaustedAction());\r\n        }\r\n        else\r\n        {\r\n            LoggerFactory.getDefaultLogger().error(this.getClass().getName() +\r\n                    \" cannot read configuration properties, use default.\");\r\n        }\r\n    }", "label": 0}
{"code": "private function applyDateFilter($objectsIterator, $startDate, $endDate)\n    {\n        // If either a start or end date was provided, filter out dates that\n        // don't match the date range.\n        if ($startDate || $endDate) {\n            $fn = function ($object) use ($startDate, $endDate) {\n                if (!preg_match('/[0-9]{8}T[0-9]{4}Z/', $object['Key'], $m)) {\n                    return false;\n                }\n                $date = strtotime($m[0]);\n\n                return (!$startDate || $date >= $startDate)\n                    && (!$endDate || $date <= $endDate);\n            };\n            $objectsIterator = new \\CallbackFilterIterator($objectsIterator, $fn);\n        }\n\n        return $objectsIterator;\n    }", "label": 2}
{"code": "def fix_pdf(pdf_file, destination):\n    \"\"\"\n    Fix malformed pdf files when data are present after '%%EOF'\n\n    ..note ::\n\n        Originally from sciunto, https://github.com/sciunto/tear-pages\n\n    :param pdfFile: PDF filepath\n    :param destination: destination\n    \"\"\"\n    tmp = tempfile.NamedTemporaryFile()\n    with open(tmp.name, 'wb') as output:\n        with open(pdf_file, \"rb\") as fh:\n            for line in fh:\n                output.write(line)\n                if b'%%EOF' in line:\n                    break\n    shutil.copy(tmp.name, destination)", "label": 1}
{"code": "public static function afterStatementAnalysis(\n        PhpParser\\Node\\Stmt $stmt,\n        Context $context,\n        StatementsSource $statements_source,\n        Codebase $codebase,\n        array &$file_replacements = []\n    ) {\n        if ($stmt instanceof PhpParser\\Node\\Stmt\\Echo_) {\n            foreach ($stmt->exprs as $expr) {\n                if (!isset($expr->inferredType) || $expr->inferredType->hasMixed()) {\n                    if (IssueBuffer::accepts(\n                        new ArgumentTypeCoercion(\n                            'Echo requires an unescaped string, ' . $expr->inferredType . ' provided',\n                            new CodeLocation($statements_source, $expr),\n                            'echo'\n                        ),\n                        $statements_source->getSuppressedIssues()\n                    )) {\n                        // keep soldiering on\n                    }\n\n                    continue;\n                }\n\n                $types = $expr->inferredType->getTypes();\n\n                foreach ($types as $type) {\n                    if ($type instanceof \\Psalm\\Type\\Atomic\\TString\n                        && !$type instanceof \\Psalm\\Type\\Atomic\\TLiteralString\n                        && !$type instanceof \\Psalm\\Type\\Atomic\\THtmlEscapedString\n                    ) {\n                        if (IssueBuffer::accepts(\n                            new ArgumentTypeCoercion(\n                                'Echo requires an unescaped string, ' . $expr->inferredType . ' provided',\n                                new CodeLocation($statements_source, $expr),\n                                'echo'\n                            ),\n                            $statements_source->getSuppressedIssues()\n                        )) {\n                            // keep soldiering on\n                        }\n                    }\n                }\n            }\n        }\n    }", "label": 2}
{"code": "public function getIsoName(): string\n    {\n        $name = $this->getFullIsoName();\n\n        return trim(strstr($name, ',', true) ?: $name);\n    }", "label": 2}
{"code": "@Override\r\n  public V get(Object key) {\r\n    // key could be not in original or in deltaMap\r\n    // key could be not in original but in deltaMap\r\n    // key could be in original but removed from deltaMap\r\n    // key could be in original but mapped to something else in deltaMap\r\n    V deltaResult = deltaMap.get(key);\r\n    if (deltaResult == null) {\r\n      return originalMap.get(key);\r\n    }\r\n    if (deltaResult == nullValue) {\r\n      return null;\r\n    }\r\n    if (deltaResult == removedValue) {\r\n      return null;\r\n    }\r\n    return deltaResult;\r\n  }", "label": 0}
{"code": "def run_transgene(job, snpeffed_file, univ_options, transgene_options):\n    \"\"\"\n    This module will run transgene on the input vcf file from the aggregator and produce the\n    peptides for MHC prediction\n\n    ARGUMENTS\n    1. snpeffed_file: <JSid for snpeffed vcf>\n    2. univ_options: Dict of universal arguments used by almost all tools\n         univ_options\n                +- 'dockerhub': <dockerhub to use>\n    3. transgene_options: Dict of parameters specific to transgene\n         transgene_options\n                +- 'gencode_peptide_fasta': <JSid for the gencode protein fasta>\n\n    RETURN VALUES\n    1. output_files: Dict of transgened n-mer peptide fastas\n         output_files\n                |- 'transgened_tumor_9_mer_snpeffed.faa': <JSid>\n                |- 'transgened_tumor_10_mer_snpeffed.faa': <JSid>\n                +- 'transgened_tumor_15_mer_snpeffed.faa': <JSid>\n\n    This module corresponds to node 17 on the tree\n    \"\"\"\n    job.fileStore.logToMaster('Running transgene on %s' % univ_options['patient'])\n    work_dir = job.fileStore.getLocalTempDir()\n    input_files = {\n        'snpeffed_muts.vcf': snpeffed_file,\n        'pepts.fa': transgene_options['gencode_peptide_fasta']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    parameters = ['--peptides', input_files['pepts.fa'],\n                  '--snpeff', input_files['snpeffed_muts.vcf'],\n                  '--prefix', 'transgened',\n                  '--pep_lens', '9,10,15']\n    docker_call(tool='transgene', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'])\n    output_files = defaultdict()\n    for peplen in ['9', '10', '15']:\n        peptfile = '_'.join(['transgened_tumor', peplen, 'mer_snpeffed.faa'])\n        mapfile = '_'.join(['transgened_tumor', peplen, 'mer_snpeffed.faa.map'])\n        output_files[peptfile] = job.fileStore.writeGlobalFile(os.path.join(work_dir, peptfile))\n        output_files[mapfile] = job.fileStore.writeGlobalFile(os.path.join(work_dir, mapfile))\n    return output_files", "label": 1}
{"code": "function $E(tag, props) {\n    var elem = document.createElement(tag);\n    for(var p in props) {\n      if(typeof props[p] == \"object\") {\n        $.extend(elem[p], props[p]);\n      } else {\n        elem[p] = props[p];\n      }\n    }\n    if (tag == \"canvas\" && !supportsCanvas && G_vmlCanvasManager) {\n      elem = G_vmlCanvasManager.initElement(document.body.appendChild(elem));\n    }\n    return elem;\n  }", "label": 3}
{"code": "def validate_read_preference!(command)\n      return unless in_transaction? && non_primary_read_preference_mode?(command)\n\n      raise Mongo::Error::InvalidTransactionOperation.new(\n        Mongo::Error::InvalidTransactionOperation::INVALID_READ_PREFERENCE)\n    end", "label": 4}
{"code": "def checkout(target, options = {})\n      options[:strategy] ||= :safe\n      options.delete(:paths)\n\n      return checkout_head(options) if target == \"HEAD\"\n\n      if target.kind_of?(Rugged::Branch)\n        branch = target\n      else\n        branch = branches[target]\n      end\n\n      if branch\n        self.checkout_tree(branch.target, options)\n\n        if branch.remote?\n          references.create(\"HEAD\", branch.target_id, force: true)\n        else\n          references.create(\"HEAD\", branch.canonical_name, force: true)\n        end\n      else\n        commit = Commit.lookup(self, self.rev_parse_oid(target))\n        references.create(\"HEAD\", commit.oid, force: true)\n        self.checkout_tree(commit, options)\n      end\n    end", "label": 4}
{"code": "public static vpnurl[] get(nitro_service service) throws Exception{\n\t\tvpnurl obj = new vpnurl();\n\t\tvpnurl[] response = (vpnurl[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function intercept(req, res, next) {\n    if (\n         !route.test(req.url)           // Incorrect URL.\n      || !req.headers.authorization     // Missing authorization.\n      || options.method !== req.method  // Invalid method.\n    ) return next();\n\n    //\n    // Handle unauthorized requests.\n    //\n    if (authorization !== req.headers.authorization) {\n      res.statusCode = 401;\n      res.setHeader('Content-Type', 'application/json');\n\n      return res.end(JSON.stringify({\n        ok: false,\n        reason: [\n          'I am programmed to protect, and sacrifice if necessary.',\n          'Feel the power of my lazers! Pew pew!'\n        ].join(' ')\n      }));\n    }\n\n    var primus = this\n      , buff = '';\n\n    if (typeof options.middleware === 'function') {\n      options.middleware(primus, parse, req, res, next);\n    } else {\n      //\n      // Receive the data from the socket. The `setEncoding` ensures that Unicode\n      // chars are correctly buffered and parsed before the `data` event is\n      // emitted.\n      //\n      req.setEncoding('utf8');\n      req.on('data', function data(chunk) {\n        buff += chunk;\n      }).once('end', function end() {\n        parse(primus, buff, res);\n      });\n    }\n  }", "label": 3}
{"code": "function(){\n\tvar clauses = this.clauses = {\n\t\twhere: {},\n\t\torder: {},\n\t\tpaginate: {},\n\t\tid: {}\n\t};\n\tthis.translators = {\n\t\twhere: new Translate(\"where\", {\n\t\t\tfromSet: function(set, setRemainder){\n\t\t\t\treturn setRemainder;\n\t\t\t},\n\t\t\ttoSet: function(set, wheres){\n\t\t\t\treturn assign(set, wheres);\n\t\t\t}\n\t\t})\n\t};\n\tvar self = this;\n\teach(arguments, function(arg) {\n\n\t\tif(arg) {\n\t\t\tif(arg instanceof Translate) {\n\t\t\t\tself.translators[arg.clause] = arg;\n\t\t\t} else {\n\t\t\t\tassign(clauses[arg.constructor.type || 'where'], arg);\n\t\t\t}\n\t\t}\n\t});\n}", "label": 3}
{"code": "def request(params={}, &block)\n      # @data has defaults, merge in new params to override\n      datum = @data.merge(params)\n      datum[:headers] = @data[:headers].merge(datum[:headers] || {})\n\n      validate_params(:request, params, datum[:middlewares])\n      # If the user passed in new middleware, we want to validate that the original connection parameters\n      # are still valid with the provided middleware.\n      if params[:middlewares]\n        validate_params(:connection, @data, datum[:middlewares])\n      end\n\n      if datum[:user] || datum[:password]\n        user, pass = Utils.unescape_uri(datum[:user].to_s), Utils.unescape_uri(datum[:password].to_s)\n        datum[:headers]['Authorization'] ||= 'Basic ' + [\"#{user}:#{pass}\"].pack('m').delete(Excon::CR_NL)\n      end\n\n      if datum[:scheme] == UNIX\n        datum[:headers]['Host']   ||= ''\n      else\n        datum[:headers]['Host']   ||= datum[:host] + port_string(datum)\n      end\n\n      # if path is empty or doesn't start with '/', insert one\n      unless datum[:path][0, 1] == '/'\n        datum[:path] = datum[:path].dup.insert(0, '/')\n      end\n\n      if block_given?\n        Excon.display_warning('Excon requests with a block are deprecated, pass :response_block instead.')\n        datum[:response_block] = Proc.new\n      end\n\n      datum[:connection] = self\n\n      datum[:stack] = datum[:middlewares].map do |middleware|\n        lambda {|stack| middleware.new(stack)}\n      end.reverse.inject(self) do |middlewares, middleware|\n        middleware.call(middlewares)\n      end\n      datum = datum[:stack].request_call(datum)\n\n      unless datum[:pipeline]\n        datum = response(datum)\n\n        if datum[:persistent]\n          if key = datum[:response][:headers].keys.detect {|k| k.casecmp('Connection') == 0 }\n            if datum[:response][:headers][key].casecmp('close') == 0\n              reset\n            end\n          end\n        else\n          reset\n        end\n\n        Excon::Response.new(datum[:response])\n      else\n        datum\n      end\n    rescue => error\n      reset\n\n      # If we didn't get far enough to initialize datum and the middleware stack, just raise\n      raise error if !datum\n\n      datum[:error] = error\n      if datum[:stack]\n        datum[:stack].error_call(datum)\n      else\n        raise error\n      end\n    end", "label": 4}
{"code": "private void checkGAs(List l)\r\n\t{\r\n\t\tfor (final Iterator i = l.iterator(); i.hasNext();)\r\n\t\t\tif (!(i.next() instanceof GroupAddress))\r\n\t\t\t\tthrow new KNXIllegalArgumentException(\"not a group address list\");\r\n\t}", "label": 0}
{"code": "func PgAmopByOid(db XODB, oid pgtypes.Oid) (*PgAmop, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, amopfamily, amoplefttype, amoprighttype, amopstrategy, amoppurpose, amopopr, amopmethod, amopsortfamily ` +\n\t\t`FROM pg_catalog.pg_amop ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpa := PgAmop{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pa.Tableoid, &pa.Cmax, &pa.Xmax, &pa.Cmin, &pa.Xmin, &pa.Oid, &pa.Ctid, &pa.Amopfamily, &pa.Amoplefttype, &pa.Amoprighttype, &pa.Amopstrategy, &pa.Amoppurpose, &pa.Amopopr, &pa.Amopmethod, &pa.Amopsortfamily)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "def get_content(self, start=None, end=None):\n        \"\"\"\n        Retrieve the content of the requested resource which is located\n        at the given absolute path.\n        This method should either return a byte string or an iterator\n        of byte strings.  The latter is preferred for large files\n        as it helps reduce memory fragmentation.\n        \"\"\"\n        with open(self.filepath, \"rb\") as file:\n            if start is not None:\n                file.seek(start)\n            if end is not None:\n                remaining = end - (start or 0)\n            else:\n                remaining = None\n            while True:\n                chunk_size = 64 * 1024\n                if remaining is not None and remaining < chunk_size:\n                    chunk_size = remaining\n                chunk = file.read(chunk_size)\n                if chunk:\n                    if remaining is not None:\n                        remaining -= len(chunk)\n                    yield chunk\n                else:\n                    if remaining is not None:\n                        assert remaining == 0\n                    return", "label": 1}
{"code": "def transliterate(string, replacement = \"?\", locale: nil)\n      raise ArgumentError, \"Can only transliterate strings. Received #{string.class.name}\" unless string.is_a?(String)\n\n      I18n.transliterate(\n        ActiveSupport::Multibyte::Unicode.tidy_bytes(string).unicode_normalize(:nfc),\n        replacement: replacement,\n        locale: locale\n      )\n    end", "label": 4}
{"code": "def capture(options = {})\n      if block_given?\n        begin\n          yield\n        rescue Error\n          raise # Don't capture Raven errors\n        rescue Exception => e\n          capture_type(e, options)\n          raise\n        end\n      else\n        install_at_exit_hook(options)\n      end\n    end", "label": 4}
{"code": "def parse(data)\n      sections = data.split(/^## .+?$/)\n      headings = data.scan(/^## .+?$/)\n\n      headings.each_with_index.map do |heading, index|\n        section = parse_heading(heading)\n        section[\"content\"] = sections.at(index + 1)\n        section\n      end\n    end", "label": 4}
{"code": "function getFullTheme(req, res, next) {\n  req.getFullTheme = true;\n\n  getTheme(req, res, next);\n}", "label": 3}
{"code": "func New(ctx context.Context, params backend.Params) (*EtcdBackend, error) {\n\tvar err error\n\tif params == nil {\n\t\treturn nil, trace.BadParameter(\"missing etcd configuration\")\n\t}\n\n\t// convert generic backend parameters structure to etcd config:\n\tvar cfg *Config\n\tif err = utils.ObjectToStruct(params, &cfg); err != nil {\n\t\treturn nil, trace.BadParameter(\"invalid etcd configuration: %v\", err)\n\t}\n\tif err = cfg.Validate(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tbuf, err := backend.NewCircularBuffer(ctx, cfg.BufferSize)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tcloseCtx, cancel := context.WithCancel(ctx)\n\twatchStarted, signalWatchStart := context.WithCancel(ctx)\n\tb := &EtcdBackend{\n\t\tEntry:            log.WithFields(log.Fields{trace.Component: GetName()}),\n\t\tcfg:              cfg,\n\t\tnodes:            cfg.Nodes,\n\t\tcancelC:          make(chan bool, 1),\n\t\tstopC:            make(chan bool, 1),\n\t\tclock:            clockwork.NewRealClock(),\n\t\tcancel:           cancel,\n\t\tctx:              closeCtx,\n\t\twatchStarted:     watchStarted,\n\t\tsignalWatchStart: signalWatchStart,\n\t\tbuf:              buf,\n\t}\n\tif err = b.reconnect(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\t// Wrap backend in a input sanitizer and return it.\n\treturn b, nil\n}", "label": 5}
{"code": "def _add_device(self, scs_id, ha_id, name):\n        \"\"\" Add device to the list of known ones \"\"\"\n        if scs_id in self._devices:\n            return\n\n        self._devices[scs_id] = {\n            'name': name,\n            'ha_id': ha_id\n        }", "label": 1}
{"code": "func execChains(event *Event) {\n\tfor _, c := range chains {\n\t\tif c.Event.Name != event.Name || c.Event.Bee != event.Bee {\n\t\t\tcontinue\n\t\t}\n\n\t\tm := make(map[string]interface{})\n\t\tfor _, opt := range event.Options {\n\t\t\tm[opt.Name] = opt.Value\n\t\t}\n\t\tctx.FillMap(m)\n\n\t\tfailed := false\n\t\tlog.Println(\"Executing chain:\", c.Name, \"-\", c.Description)\n\t\tfor _, el := range c.Filters {\n\t\t\tif execFilter(el, m) {\n\t\t\t\tlog.Println(\"\\t\\tPassed filter!\")\n\t\t\t} else {\n\t\t\t\tlog.Println(\"\\t\\tDid not pass filter!\")\n\t\t\t\tfailed = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif failed {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, el := range c.Actions {\n\t\t\taction := GetAction(el)\n\t\t\tif action == nil {\n\t\t\t\tlog.Println(\"\\t\\tERROR: Unknown action referenced!\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\texecAction(*action, m)\n\t\t}\n\t}\n}", "label": 5}
{"code": "def add_lane(lane, override = false)\n      lanes[lane.platform] ||= {}\n\n      if !override && lanes[lane.platform][lane.name]\n        UI.user_error!(\"Lane '#{lane.name}' was defined multiple times!\")\n      end\n\n      lanes[lane.platform][lane.name] = lane\n    end", "label": 4}
{"code": "def pretty_dict_str(d, indent=2):\n    \"\"\"shows JSON indented representation of d\"\"\"\n    b = StringIO()\n    write_pretty_dict_str(b, d, indent=indent)\n    return b.getvalue()", "label": 1}
{"code": "public function state(array $options = [])\n    {\n        $info = $this->info($options);\n\n        return (isset($info['state']))\n            ? $info['state']\n            : null;\n    }", "label": 2}
{"code": "def serialize(output, confirm_valid=false)\n      return false unless !confirm_valid || self.validate.empty?\n      Relationship.clear_cached_instances\n      Zip::OutputStream.open(output) do |zip|\n        write_parts(zip)\n      end\n      true\n    end", "label": 4}
{"code": "function isPropertyOrKey(path) {\n  return path.parentPath.get('key') === path || path.parentPath.get('property') === path;\n}", "label": 3}
{"code": "def hash_from_file_content(string)\n      hash = {}\n      string.split(\"\\n\").each do |line|\n        uncommented_line = strip_comment(line)\n        if include = extract_include(uncommented_line)\n          @includes.push normalized_xcconfig_path(include)\n        else\n          key, value = extract_key_value(uncommented_line)\n          next unless key\n          value.gsub!(INHERITED_REGEXP) { |m| hash.fetch(key, m) }\n          hash[key] = value\n        end\n      end\n      hash\n    end", "label": 4}
{"code": "function (numberOfCalls, branchDefinition) {\n        [\"if\", \"else\"].forEach(function (label, index) {\n            ++this.count;\n            this._testedOrIgnored(numberOfCalls[index], branchDefinition.locations[index]);\n        }, this);\n    }", "label": 3}
{"code": "public static base_responses delete(nitro_service client, clusterinstance resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tclusterinstance deleteresources[] = new clusterinstance[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tdeleteresources[i] = new clusterinstance();\n\t\t\t\tdeleteresources[i].clid = resources[i].clid;\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def each(&block)\n      @ids.each_slice(@page_size) do |page_of_ids|\n        resources = @paging_block.call(page_of_ids)\n        resources.each(&block)\n      end\n    end", "label": 4}
{"code": "func (r *reader) Read(b []byte) (int, error) {\n\tn, err := r.r.Read(b)\n\tr.pos += int64(n)\n\n\tif err != nil && err != io.EOF {\n\t\treturn n, err\n\t}\n\n\tq := readerReport{\n\t\tt:    time.Now(),\n\t\tpos:  r.pos,\n\t\tsize: r.size,\n\t\tbps:  &r.bps,\n\t}\n\n\tselect {\n\tcase r.ch <- q:\n\tcase <-r.ctx.Done():\n\t}\n\n\treturn n, err\n}", "label": 5}
{"code": "public static String readTag(Reader r) throws IOException {\r\n    if ( ! r.ready()) {\r\n      return null;\r\n    }\r\n    StringBuilder b = new StringBuilder(\"<\");\r\n    int c = r.read();\r\n    while (c >= 0) {\r\n      b.append((char) c);\r\n      if (c == '>') {\r\n        break;\r\n      }\r\n      c = r.read();\r\n    }\r\n    if (b.length() == 1) {\r\n      return null;\r\n    }\r\n    return b.toString();\r\n  }", "label": 0}
{"code": "def licenses(self):\n        \"\"\"OSI Approved license.\"\"\"\n        return {self._acronym_lic(l): l for l in self.resp_text.split('\\n')\n                if l.startswith(self.prefix_lic)}", "label": 1}
{"code": "public static appfwprofile_crosssitescripting_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappfwprofile_crosssitescripting_binding obj = new appfwprofile_crosssitescripting_binding();\n\t\tobj.set_name(name);\n\t\tappfwprofile_crosssitescripting_binding response[] = (appfwprofile_crosssitescripting_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func makeStoredLabels(labels []string) map[string]string {\n\tstoredLabels := make(map[string]string)\n\tfor _, s := range labels {\n\t\tsplit := strings.SplitN(s, \"=\", 2)\n\t\tif len(split) == 1 {\n\t\t\tstoredLabels[split[0]] = split[0]\n\t\t} else {\n\t\t\tstoredLabels[split[1]] = split[0]\n\t\t}\n\t}\n\treturn storedLabels\n}", "label": 5}
{"code": "def process_bounce(message, notification):\n    \"\"\"Function to process a bounce notification\"\"\"\n    mail = message['mail']\n    bounce = message['bounce']\n\n    bounces = []\n    for recipient in bounce['bouncedRecipients']:\n        # Create each bounce record. Add to a list for reference later.\n        bounces += [Bounce.objects.create(\n            sns_topic=notification['TopicArn'],\n            sns_messageid=notification['MessageId'],\n            mail_timestamp=clean_time(mail['timestamp']),\n            mail_id=mail['messageId'],\n            mail_from=mail['source'],\n            address=recipient['emailAddress'],\n            feedback_id=bounce['feedbackId'],\n            feedback_timestamp=clean_time(bounce['timestamp']),\n            hard=bool(bounce['bounceType'] == 'Permanent'),\n            bounce_type=bounce['bounceType'],\n            bounce_subtype=bounce['bounceSubType'],\n            reporting_mta=bounce.get('reportingMTA'),\n            action=recipient.get('action'),\n            status=recipient.get('status'),\n            diagnostic_code=recipient.get('diagnosticCode')\n        )]\n\n    # Send signals for each bounce.\n    for bounce in bounces:\n        signals.feedback.send(\n            sender=Bounce,\n            instance=bounce,\n            message=message,\n            notification=notification\n        )\n\n    logger.info('Logged %s Bounce(s)', str(len(bounces)))\n\n    return HttpResponse('Bounce Processed')", "label": 1}
{"code": "def _fill_parameters(self):\n        \"\"\"\n        Fill in the _parameters dict from the properties file.\n\n        Args:\n            None\n\n        Returns:\n            True\n\n        Todo:\n            Figure out what could go wrong and at least acknowledge the the\n            fact that Murphy was an optimist.\n        \"\"\"\n        self._parameters = self._config.get('parameters', {})\n        self._fill_defaults()\n\n        for k in self._parameters.keys():\n            try:\n                if self._parameters[k].startswith(self.SSM) and self._parameters[k].endswith(']'):\n                    parts = self._parameters[k].split(':')\n                    tmp = parts[1].replace(']', '')\n                    val = self._get_ssm_parameter(tmp)\n                    if val:\n                        self._parameters[k] = val\n                    else:\n                        logging.error('SSM parameter {} not found'.format(tmp))\n                        return False\n                elif self._parameters[k] == self.ASK:\n                    val = None\n                    a1 = '__x___'\n                    a2 = '__y___'\n                    prompt1 = \"Enter value for '{}': \".format(k)\n                    prompt2 = \"Confirm value for '{}': \".format(k)\n                    while a1 != a2:\n                        a1 = getpass.getpass(prompt=prompt1)\n                        a2 = getpass.getpass(prompt=prompt2)\n                        if a1 == a2:\n                            val = a1\n                        else:\n                            print('values do not match, try again')\n                    self._parameters[k] = val\n            except:\n                pass\n\n        return True", "label": 1}
{"code": "def cmd_add(self, txt):\n        \"\"\"\n        Enter add mode - all text entered now will be \n        processed as adding information until cancelled\n        \"\"\"\n        self.show_output('Adding ', txt)\n        self.raw.add(txt)\n        print(self.raw)\n        return 'Added ' + txt", "label": 1}
{"code": "def _predict(self, fit, df):\n        \"\"\"\n        Return a df with predictions and confidence interval\n\n        Notes\n        -----\n        The df will contain the following columns:\n        - 'predicted': the model output\n        - 'interval_u', 'interval_l': upper and lower confidence bounds.\n\n        The result will depend on the following attributes of self:\n        confint : float (default=0.95)\n            Confidence level for two-sided hypothesis\n        allow_negative_predictions : bool (default=True)\n            If False, correct negative predictions to zero (typically for energy consumption predictions)\n\n        Parameters\n        ----------\n        fit : Statsmodels fit\n        df : pandas DataFrame or None (default)\n            If None, use self.df\n\n\n        Returns\n        -------\n        df_res : pandas DataFrame\n            Copy of df with additional columns 'predicted', 'interval_u' and 'interval_l'\n        \"\"\"\n\n        # Add model results to data as column 'predictions'\n        df_res = df.copy()\n        if 'Intercept' in fit.model.exog_names:\n            df_res['Intercept'] = 1.0\n        df_res['predicted'] = fit.predict(df_res)\n        if not self.allow_negative_predictions:\n            df_res.loc[df_res['predicted'] < 0, 'predicted'] = 0\n\n        prstd, interval_l, interval_u = wls_prediction_std(fit,\n                                                           df_res[fit.model.exog_names],\n                                                           alpha=1 - self.confint)\n        df_res['interval_l'] = interval_l\n        df_res['interval_u'] = interval_u\n\n        if 'Intercept' in df_res:\n            df_res.drop(labels=['Intercept'], axis=1, inplace=True)\n\n        return df_res", "label": 1}
{"code": "def options(path, options = {}, &block)\n      perform_request Net::HTTP::Options, path, options, &block\n    end", "label": 4}
{"code": "func (b *BoxLayout) InsertWidget(index int, widget Widget, fill float64) {\n\tc := &boxLayoutCell{\n\t\twidget: widget,\n\t\tfill:   fill,\n\t\tview:   NewViewPort(b.view, 0, 0, 0, 0),\n\t}\n\tc.widget.SetView(c.view)\n\tif index < 0 {\n\t\tindex = 0\n\t}\n\tif index > len(b.cells) {\n\t\tindex = len(b.cells)\n\t}\n\tb.cells = append(b.cells, c)\n\tcopy(b.cells[index+1:], b.cells[index:])\n\tb.cells[index] = c\n\twidget.Watch(b)\n\tb.layout()\n\tb.PostEventWidgetContent(b)\n}", "label": 5}
{"code": "function convertProperty(obj, propertyName, original){\n        var observable,\n            isArray,\n            lookup = obj.__observable__ || (obj.__observable__ = {});\n\n        if(original === undefined){\n            original = obj[propertyName];\n        }\n\n        if (system.isArray(original)) {\n            observable = ko.observableArray(original);\n            makeObservableArray(original, observable);\n            isArray = true;\n        } else if (typeof original == \"function\") {\n            if(ko.isObservable(original)){\n                observable = original;\n            }else{\n                return null;\n            }\n        } else if(system.isPromise(original)) {\n            observable = ko.observable();\n\n            original.then(function (result) {\n                if(system.isArray(result)) {\n                    var oa = ko.observableArray(result);\n                    makeObservableArray(result, oa);\n                    result = oa;\n                }\n\n                observable(result);\n            });\n        } else {\n            observable = ko.observable(original);\n            convertObject(original);\n        }\n\n        Object.defineProperty(obj, propertyName, {\n            configurable: true,\n            enumerable: true,\n            get: observable,\n            set: ko.isWriteableObservable(observable) ? (function (newValue) {\n                if (newValue && system.isPromise(newValue)) {\n                    newValue.then(function (result) {\n                        innerSetter(observable, result, system.isArray(result));\n                    });\n                } else {\n                    innerSetter(observable, newValue, isArray);\n                }\n            }) : undefined\n        });\n\n        lookup[propertyName] = observable;\n        return observable;\n    }", "label": 3}
{"code": "func (r *Registry) getEntityDatacenter(item mo.Entity) *Datacenter {\n\treturn r.getEntityParent(item, \"Datacenter\").(*Datacenter)\n}", "label": 5}
{"code": "def dispatch(self, request):\n        \"\"\"Takes a request and dispatches its data to a jsonrpc method.\n\n        :param request: a werkzeug request with json data\n        :type request: werkzeug.wrappers.Request\n        :return: json output of the corresponding method\n        :rtype: str\n\n        .. versionadded:: 0.1.0\n        \"\"\"\n        def _wrapped():\n            messages = self._get_request_messages(request)\n            results = [self._dispatch_and_handle_errors(message) for message in messages]\n            non_notification_results = [x for x in results if x is not None]\n            if len(non_notification_results) == 0:\n                return None\n            elif len(messages) == 1:\n                return non_notification_results[0]\n            else:\n                return non_notification_results\n\n        result, _ = self._handle_exceptions(_wrapped)\n        if result is not None:\n            return self._encode_complete_result(result)", "label": 1}
{"code": "protected function basic_deliver($reader, $message)\n    {\n        $consumer_tag = $reader->read_shortstr();\n        $delivery_tag = $reader->read_longlong();\n        $redelivered = $reader->read_bit();\n        $exchange = $reader->read_shortstr();\n        $routing_key = $reader->read_shortstr();\n\n        $message->delivery_info = array(\n            'channel' => $this,\n            'consumer_tag' => $consumer_tag,\n            'delivery_tag' => $delivery_tag,\n            'redelivered' => $redelivered,\n            'exchange' => $exchange,\n            'routing_key' => $routing_key\n        );\n\n        if (isset($this->callbacks[$consumer_tag])) {\n            call_user_func($this->callbacks[$consumer_tag], $message);\n        }\n    }", "label": 2}
{"code": "function(properties, value, equals)\n  {\n    var where = createWhere( properties, value, equals );\n\n    for (var i = this.length - 1; i >= 0; i--)\n    {\n      var model = this[ i ];\n\n      if ( where( model ) )\n      {\n        return model;\n      }\n    }\n\n    return null;\n  }", "label": 3}
{"code": "public function parserResult($result)\n    {\n        if ($this->presenter instanceof PresenterInterface) {\n            if ($result instanceof Collection || $result instanceof LengthAwarePaginator) {\n                $result->each(function ($model) {\n                    if ($model instanceof Presentable) {\n                        $model->setPresenter($this->presenter);\n                    }\n\n                    return $model;\n                });\n            } elseif ($result instanceof Presentable) {\n                $result = $result->setPresenter($this->presenter);\n            }\n\n            if (!$this->skipPresenter) {\n                return $this->presenter->present($result);\n            }\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "def type(name)\n    # Avoid loading if name obviously is not a type name\n    if name.to_s.include?(':')\n      return nil\n    end\n\n    @types ||= {}\n\n    # We are overwhelmingly symbols here, which usually match, so it is worth\n    # having this special-case to return quickly.  Like, 25K symbols vs. 300\n    # strings in this method. --daniel 2012-07-17\n    return @types[name] if @types.include? name\n\n    # Try mangling the name, if it is a string.\n    if name.is_a? String\n      name = name.downcase.intern\n      return @types[name] if @types.include? name\n    end\n    # Try loading the type.\n    if typeloader.load(name, Puppet.lookup(:current_environment))\n      #TRANSLATORS 'puppet/type/%{name}' should not be translated\n      Puppet.warning(_(\"Loaded puppet/type/%{name} but no class was created\") % { name: name }) unless @types.include? name\n    elsif !Puppet[:always_retry_plugins]\n      # PUP-5482 - Only look for a type once if plugin retry is disabled\n      @types[name] = nil\n    end\n\n    # ...and I guess that is that, eh.\n    return @types[name]\n  end", "label": 4}
{"code": "def fill_form(form, data):\n    \"\"\"Prefill form with data.\n\n    :param form: The form to fill.\n    :param data: The data to insert in the form.\n    :returns: A pre-filled form.\n    \"\"\"\n    for (key, value) in data.items():\n        if hasattr(form, key):\n            if isinstance(value, dict):\n                fill_form(getattr(form, key), value)\n            else:\n                getattr(form, key).data = value\n    return form", "label": 1}
{"code": "func (ca *CertAuthorityV2) SetSigningKeys(keys [][]byte) error {\n\tca.Spec.SigningKeys = keys\n\treturn nil\n}", "label": 5}
{"code": "def host\n      return @host if defined?(@host)\n\n      # Determine the host class to use. \":detect\" is an old Vagrant config\n      # that shouldn't be valid anymore, but we respect it here by assuming\n      # its old behavior. No need to deprecate this because I thin it is\n      # fairly harmless.\n      host_klass = vagrantfile.config.vagrant.host\n      host_klass = nil if host_klass == :detect\n\n      begin\n        @host = Host.new(\n          host_klass,\n          Vagrant.plugin(\"2\").manager.hosts,\n          Vagrant.plugin(\"2\").manager.host_capabilities,\n          self)\n      rescue Errors::CapabilityHostNotDetected\n        # If the auto-detect failed, then we create a brand new host\n        # with no capabilities and use that. This should almost never happen\n        # since Vagrant works on most host OS's now, so this is a \"slow path\"\n        klass = Class.new(Vagrant.plugin(\"2\", :host)) do\n          def detect?(env); true; end\n        end\n\n        hosts     = { generic: [klass, nil] }\n        host_caps = {}\n\n        @host = Host.new(:generic, hosts, host_caps, self)\n      rescue Errors::CapabilityHostExplicitNotDetected => e\n        raise Errors::HostExplicitNotDetected, e.extra_data\n      end\n    end", "label": 4}
{"code": "function _gpfBuildMimeTypeFromMappings (path, mappings) {\n    _gpfObjectForEach(mappings, function (extensions, key) {\n        var mimeType = path + key;\n        if (0 === extensions) {\n            _createMimeTypeExtensionMapping(mimeType, \".\" + key);\n\n        } else if (\"string\" === typeof extensions) {\n            extensions.split(\",\").forEach(function (extension) {\n                _createMimeTypeExtensionMapping(mimeType, \".\" + extension);\n            });\n\n        } else { // Assuming extensions is an object\n            _gpfBuildMimeTypeFromMappings(mimeType + \"/\", extensions);\n        }\n    });\n}", "label": 3}
{"code": "def inspector_started_query(query, inspector)\n      puts(\"\")\n      puts(\"Looking for related GitHub issues on #{inspector.repo_owner}/#{inspector.repo_name}...\")\n      puts(\"Search query: #{query}\") if FastlaneCore::Globals.verbose?\n      puts(\"\")\n    end", "label": 4}
{"code": "function loadFromOptions(opts) {\n  var defCfg = loadDefault()\n  var cfg = opts.config ? loadFromFile(opts.config) : loadDefault()\n\n  // Command line config override file loaded config\n  for (var k in opts) {\n    defCfg.hasOwnProperty(k) && (defCfg[k] !== opts[k] && (cfg[k] = opts[k]))\n  }\n\n  return cfg\n}", "label": 3}
{"code": "def tracking_save(sender, instance, raw, using, update_fields, **kwargs):\n    \"\"\"\n    Post save, detect creation or changes and log them.\n    We need post_save to have the object for a create.\n    \"\"\"\n    if _has_changed(instance):\n        if instance._original_fields['pk'] is None:\n            # Create\n            _create_create_tracking_event(instance)\n        else:\n            # Update\n            _create_update_tracking_event(instance)\n    if _has_changed_related(instance):\n        # Because an object need to be saved before being related,\n        # it can only be an update\n        _create_update_tracking_related_event(instance)\n    if _has_changed(instance) or _has_changed_related(instance):\n        _set_original_fields(instance)", "label": 1}
{"code": "private function createPromise()\n    {\n        // Create the promise\n        $promise = call_user_func($this->promiseCreator, $this);\n        $this->promiseCreator = null;\n\n        // Cleans up the promise state and references.\n        $cleanup = function () {\n            $this->before = $this->client = $this->queue = null;\n        };\n\n        // When done, ensure cleanup and that any remaining are processed.\n        return $promise->then(\n            function () use ($cleanup)  {\n                return Promise\\promise_for($this->flushQueue())\n                    ->then($cleanup);\n            },\n            function ($reason) use ($cleanup)  {\n                $cleanup();\n                return Promise\\rejection_for($reason);\n            }\n        );\n    }", "label": 2}
{"code": "def escape_wildcards(unescaped)\n      case ActiveRecord::Base.connection.adapter_name\n      when \"Mysql2\".freeze, \"PostgreSQL\".freeze\n        # Necessary for PostgreSQL and MySQL\n        unescaped.to_s.gsub(/([\\\\%_.])/, '\\\\\\\\\\\\1')\n      else\n        unescaped\n      end\n    end", "label": 4}
{"code": "def main(argv):\n    \"\"\"This function sets up a command-line option parser and then calls print_matching_trees\n    to do all of the real work.\n    \"\"\"\n    import argparse\n    description = 'Uses Open Tree of Life web services to try to find a tree with the value property pair specified. ' \\\n                  'setting --fuzzy will allow fuzzy matching'\n    parser = argparse.ArgumentParser(prog='ot-get-tree', description=description)\n    parser.add_argument('arg_dict', type=json.loads, help='name(s) for which we will try to find OTT IDs')\n    parser.add_argument('--property', default=None, type=str, required=False)\n    parser.add_argument('--fuzzy', action='store_true', default=False,\n                        required=False)  # exact matching and verbose not working atm...\n    parser.add_argument('--verbose', action='store_true', default=False, required=False)\n    try:\n        args = parser.parse_args(argv)\n        arg_dict = args.arg_dict\n        exact = not args.fuzzy\n        verbose = args.verbose\n    except:\n        arg_dict = {'ot:studyId': 'ot_308'}\n        sys.stderr.write('Running a demonstration query with {}\\n'.format(arg_dict))\n        exact = True\n        verbose = False\n    print_matching_studies(arg_dict, exact=exact, verbose=verbose)", "label": 1}
{"code": "func New(u *url.URL, settings []vim.BaseOptionValue) (string, http.Handler) {\n\tfor i := range settings {\n\t\tsetting := settings[i].GetOptionValue()\n\t\tif setting.Key == \"config.vpxd.sso.sts.uri\" {\n\t\t\tendpoint, _ := url.Parse(setting.Value.(string))\n\t\t\tendpoint.Host = u.Host\n\t\t\tsetting.Value = endpoint.String()\n\t\t\tsettings[i] = setting\n\t\t\treturn endpoint.Path, new(handler)\n\t\t}\n\t}\n\treturn \"\", nil\n}", "label": 5}
{"code": "public function setInstance($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Redis\\V1\\Instance::class);\n        $this->instance = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def execute_transaction(conn, statements: Iterable):\n    \"\"\"Execute several statements in single DB transaction.\"\"\"\n\n    with conn:\n        with conn.cursor() as cursor:\n            for statement in statements:\n                cursor.execute(statement)\n        conn.commit()", "label": 1}
{"code": "def run_matrix(self, matrix_definition, document):\n        \"\"\"\n        Running pipeline via a matrix.\n\n        Args:\n            matrix_definition (dict): one concrete matrix item.\n            document (dict): spline document (complete) as loaded from yaml file.\n        \"\"\"\n        matrix = Matrix(matrix_definition, 'matrix(parallel)' in document)\n\n        process_data = MatrixProcessData()\n        process_data.options = self.options\n        process_data.pipeline = document['pipeline']\n        process_data.model = {} if 'model' not in document else document['model']\n        process_data.hooks = Hooks(document)\n\n        return matrix.process(process_data)", "label": 1}
{"code": "def create_customer_card(customer_id, body, opts = {})\n      data, _status_code, _headers = create_customer_card_with_http_info(customer_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "public static int cudnnGetRNNDataDescriptor(\n        cudnnRNNDataDescriptor RNNDataDesc, \n        int[] dataType, \n        int[] layout, \n        int[] maxSeqLength, \n        int[] batchSize, \n        int[] vectorSize, \n        int arrayLengthRequested, \n        int[] seqLengthArray, \n        Pointer paddingFill)\n    {\n        return checkResult(cudnnGetRNNDataDescriptorNative(RNNDataDesc, dataType, layout, maxSeqLength, batchSize, vectorSize, arrayLengthRequested, seqLengthArray, paddingFill));\n    }", "label": 0}
{"code": "func (uw *UnitWriter) AppUnit(ra *schema.RuntimeApp, binPath string, opts ...*unit.UnitOption) {\n\tif uw.err != nil {\n\t\treturn\n\t}\n\n\tif len(ra.App.Exec) == 0 {\n\t\tuw.err = fmt.Errorf(`image %q has an empty \"exec\" (try --exec=BINARY)`,\n\t\t\tuw.p.AppNameToImageName(ra.Name))\n\t\treturn\n\t}\n\n\tpa, err := prepareApp(uw.p, ra)\n\tif err != nil {\n\t\tuw.err = err\n\t\treturn\n\t}\n\n\tappName := ra.Name.String()\n\timgName := uw.p.AppNameToImageName(ra.Name)\n\t/* Write the generic unit options */\n\topts = append(opts, []*unit.UnitOption{\n\t\tunit.NewUnitOption(\"Unit\", \"Description\", fmt.Sprintf(\"Application=%v Image=%v\", appName, imgName)),\n\t\tunit.NewUnitOption(\"Unit\", \"DefaultDependencies\", \"false\"),\n\t\tunit.NewUnitOption(\"Unit\", \"Wants\", fmt.Sprintf(\"reaper-%s.service\", appName)),\n\t\tunit.NewUnitOption(\"Service\", \"Restart\", \"no\"),\n\n\t\t// This helps working around a race\n\t\t// (https://github.com/systemd/systemd/issues/2913) that causes the\n\t\t// systemd unit name not getting written to the journal if the unit is\n\t\t// short-lived and runs as non-root.\n\t\tunit.NewUnitOption(\"Service\", \"SyslogIdentifier\", appName),\n\t}...)\n\n\t// Setup I/O for iottymux (stdin/stdout/stderr)\n\topts = append(opts, uw.SetupAppIO(uw.p, ra, binPath)...)\n\n\tif supportsNotify(uw.p, ra.Name.String()) {\n\t\topts = append(opts, unit.NewUnitOption(\"Service\", \"Type\", \"notify\"))\n\t}\n\n\t// Some pre-start jobs take a long time, set the timeout to 0\n\topts = append(opts, unit.NewUnitOption(\"Service\", \"TimeoutStartSec\", \"0\"))\n\n\topts = append(opts, unit.NewUnitOption(\"Unit\", \"Requires\", \"sysusers.service\"))\n\topts = append(opts, unit.NewUnitOption(\"Unit\", \"After\", \"sysusers.service\"))\n\n\topts = uw.appSystemdUnit(pa, binPath, opts)\n\n\tuw.WriteUnit(ServiceUnitPath(uw.p.Root, ra.Name), \"failed to create service unit file\", opts...)\n\tuw.Activate(ServiceUnitName(ra.Name), ServiceWantPath(uw.p.Root, ra.Name))\n\n}", "label": 5}
{"code": "def activate(self, page=None):\n        \"\"\"Activates overlay with browser, optionally opened at a given page.\n\n        :param str page: Overlay page alias (see OVERLAY_PAGE_*)\n            or a custom URL.\n\n        \"\"\"\n        page = page or ''\n\n        if '://' in page:\n            self._iface.activate_overlay_url(page)\n\n        else:\n            self._iface.activate_overlay_game(page)", "label": 1}
{"code": "function (message) {\n      if (options.force) {\n        grunt.log.error(message);\n      } else {\n        grunt.warn(message);\n      }\n    }", "label": 3}
{"code": "public Set<ConstraintViolation> validate(DataSetInfo info) {\r\n\t\tSet<ConstraintViolation> errors = new LinkedHashSet<ConstraintViolation>();\r\n\t\ttry {\r\n\t\t\tif (info.isMandatory() && get(info.getDataSetNumber()) == null) {\r\n\t\t\t\terrors.add(new ConstraintViolation(info, ConstraintViolation.MANDATORY_MISSING));\r\n\t\t\t}\r\n\t\t\tif (!info.isRepeatable() && getAll(info.getDataSetNumber()).size() > 1) {\r\n\t\t\t\terrors.add(new ConstraintViolation(info, ConstraintViolation.REPEATABLE_REPEATED));\r\n\t\t\t}\r\n\t\t} catch (SerializationException e) {\r\n\t\t\terrors.add(new ConstraintViolation(info, ConstraintViolation.INVALID_VALUE));\r\n\t\t}\r\n\t\treturn errors;\r\n\t}", "label": 0}
{"code": "func generateFontID(fdt fontDefType) (string, error) {\n\t// file can be different if generated in different instance\n\tfdt.File = \"\"\n\tb, err := json.Marshal(&fdt)\n\treturn fmt.Sprintf(\"%x\", sha1.Sum(b)), err\n}", "label": 5}
{"code": "protected function getScanOptions()\n    {\n        $options = array();\n\n        if (strlen($this->match) > 0) {\n            $options['MATCH'] = $this->match;\n        }\n\n        if ($this->count > 0) {\n            $options['COUNT'] = $this->count;\n        }\n\n        return $options;\n    }", "label": 2}
{"code": "public function setViolence($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Vision\\V1\\Likelihood::class);\n        $this->violence = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func getEnterArgv(p *pkgPod.Pod, cmdArgs []string) ([]string, error) {\n\tvar argv []string\n\tif len(cmdArgs) < 2 {\n\t\tstderr.Printf(\"no command specified, assuming %q\", defaultCmd)\n\t\targv = []string{defaultCmd}\n\t} else {\n\t\targv = cmdArgs[1:]\n\t}\n\n\treturn argv, nil\n}", "label": 5}
{"code": "public static function mapResult(callable $f)\n    {\n        return function (callable $handler) use ($f) {\n            return function (\n                CommandInterface $command,\n                RequestInterface $request = null\n            ) use ($handler, $f) {\n                return $handler($command, $request)->then($f);\n            };\n        };\n    }", "label": 2}
{"code": "def color_diffs(string):\n    \"\"\" Add color ANSI codes for diff lines.\n\n    Purpose: Adds the ANSI/win32 color coding for terminal output to output\n           | produced from difflib.\n\n    @param string: The string to be replacing\n    @type string: str\n\n    @returns: The new string with ANSI codes injected.\n    @rtype: str\n    \"\"\"\n    string = string.replace('--- ', color('--- ', 'red'))\n    string = string.replace('\\n+++ ', color('\\n+++ '))\n    string = string.replace('\\n-', color('\\n-', 'red'))\n    string = string.replace('\\n+', color('\\n+'))\n    string = string.replace('\\n@@ ', color('\\n@@ ', 'yel'))\n    return string", "label": 1}
{"code": "function charWidth(display) {\n    if (display.cachedCharWidth != null) return display.cachedCharWidth;\n    var anchor = elt(\"span\", \"xxxxxxxxxx\");\n    var pre = elt(\"pre\", [anchor]);\n    removeChildrenAndAdd(display.measure, pre);\n    var rect = anchor.getBoundingClientRect(), width = (rect.right - rect.left) / 10;\n    if (width > 2) display.cachedCharWidth = width;\n    return width || 10;\n  }", "label": 3}
{"code": "def validate_config(key: str, config: dict) -> None:\n    \"\"\"\n    Call jsonschema validation to raise JSONValidation on non-compliance or silently pass.\n\n    :param key: validation schema key of interest\n    :param config: configuration dict to validate\n    \"\"\"\n\n    try:\n        jsonschema.validate(config, CONFIG_JSON_SCHEMA[key])\n    except jsonschema.ValidationError as x_validation:\n        raise JSONValidation('JSON validation error on {} configuration: {}'.format(key, x_validation.message))\n    except jsonschema.SchemaError as x_schema:\n        raise JSONValidation('JSON schema error on {} specification: {}'.format(key, x_schema.message))", "label": 1}
{"code": "private void query(String zipcode) {\n                        /* Setup YQL query statement using dynamic zipcode. The statement searches geo.places\n                        for the zipcode and returns XML which includes the WOEID. For more info about YQL go\n                        to: http://developer.yahoo.com/yql/ */\n        String qry = URLEncoder.encode(\"SELECT woeid FROM geo.places WHERE text=\" + zipcode + \" LIMIT 1\");\n\n        // Generate request URI using the query statement\n        URL url;\n        try {\n            // get URL content\n            url = new URL(\"http://query.yahooapis.com/v1/public/yql?q=\" + qry);\n            URLConnection conn = url.openConnection();\n\n            InputStream content = conn.getInputStream();\n            parseResponse(content);\n\n        } catch (MalformedURLException e) {\n            e.printStackTrace();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }", "label": 0}
{"code": "func SendData(client riemanngo.Client, events []riemanngo.Event) error {\n\t// do nothing if we are not connected\n\tif client == nil {\n\t\tglog.Warningf(\"Riemann sink not connected\")\n\t\treturn nil\n\t}\n\tstart := time.Now()\n\t_, err := riemanngo.SendEvents(client, &events)\n\tend := time.Now()\n\tif err == nil {\n\t\tglog.V(4).Infof(\"Exported %d events to riemann in %s\", len(events), end.Sub(start))\n\t\treturn nil\n\t} else {\n\t\tglog.Warningf(\"There were errors sending events to Riemman, forcing reconnection. Error : %+v\", err)\n\t\treturn err\n\t}\n}", "label": 5}
{"code": "func (f *Fpdf) HTMLBasicNew() (html HTMLBasicType) {\n\thtml.pdf = f\n\thtml.Link.ClrR, html.Link.ClrG, html.Link.ClrB = 0, 0, 128\n\thtml.Link.Bold, html.Link.Italic, html.Link.Underscore = false, false, true\n\treturn\n}", "label": 5}
{"code": "def simple_execute(chain, event)\n      return nil if chain.empty?\n\n      args = chain.split(' ')\n      execute_command(args[0].to_sym, event, args[1..-1])\n    end", "label": 4}
{"code": "func PgTsConfigByCfgnameCfgnamespace(db XODB, cfgname pgtypes.Name, cfgnamespace pgtypes.Oid) (*PgTsConfig, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, cfgname, cfgnamespace, cfgowner, cfgparser ` +\n\t\t`FROM pg_catalog.pg_ts_config ` +\n\t\t`WHERE cfgname = $1 AND cfgnamespace = $2`\n\n\t// run query\n\tXOLog(sqlstr, cfgname, cfgnamespace)\n\tptc := PgTsConfig{}\n\n\terr = db.QueryRow(sqlstr, cfgname, cfgnamespace).Scan(&ptc.Tableoid, &ptc.Cmax, &ptc.Xmax, &ptc.Cmin, &ptc.Xmin, &ptc.Oid, &ptc.Ctid, &ptc.Cfgname, &ptc.Cfgnamespace, &ptc.Cfgowner, &ptc.Cfgparser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ptc, nil\n}", "label": 5}
{"code": "func (c *LicenseV3) SetLabels(labels map[string]string) {\n\tc.Metadata.Labels = labels\n}", "label": 5}
{"code": "public void disconnect() {\n\t\tif (sendThread != null) {\n\t\t\tsendThread.interrupt();\n\t\t\ttry {\n\t\t\t\tsendThread.join();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t}\n\t\t\tsendThread = null;\n\t\t}\n\t\tif (receiveThread != null) {\n\t\t\treceiveThread.interrupt();\n\t\t\ttry {\n\t\t\t\treceiveThread.join();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t}\n\t\t\treceiveThread = null;\n\t\t}\n\t\tif(transactionCompleted.availablePermits() < 0)\n\t\t\ttransactionCompleted.release(transactionCompleted.availablePermits());\n\t\t\n\t\ttransactionCompleted.drainPermits();\n\t\tlogger.trace(\"Transaction completed permit count -> {}\", transactionCompleted.availablePermits());\n\t\tif (this.serialPort != null) {\n\t\t\tthis.serialPort.close();\n\t\t\tthis.serialPort = null;\n\t\t}\n\t\tlogger.info(\"Disconnected from serial port\");\n\t}", "label": 0}
{"code": "protected function validateCurrentDate()\n    {\n        if ($this->current === null) {\n            $this->rewind();\n        }\n\n        // Check after the first rewind to avoid repeating the initial validation.\n        if ($this->validationResult !== null) {\n            return $this->validationResult;\n        }\n\n        return $this->validationResult = $this->checkFilters();\n    }", "label": 2}
{"code": "public static base_response create(nitro_service client, ssldhparam resource) throws Exception {\n\t\tssldhparam createresource = new ssldhparam();\n\t\tcreateresource.dhfile = resource.dhfile;\n\t\tcreateresource.bits = resource.bits;\n\t\tcreateresource.gen = resource.gen;\n\t\treturn createresource.perform_operation(client,\"create\");\n\t}", "label": 0}
{"code": "def get_creator_by_name(name):\n    \"\"\"\n    Get creator function by name.\n\n    Args:\n        name (str): name of the creator function.\n\n    Returns:\n        function: creater function.\n    \"\"\"\n    return {'docker(container)': Container.creator,\n            'shell': Bash.creator, 'docker(image)': Image.creator,\n            'python': Script.creator, 'packer': Packer.creator,\n            'ansible(simple)': Ansible.creator}[name]", "label": 1}
{"code": "private void deEndify(List<CoreLabel> tokens) {\r\n    if (flags.retainEntitySubclassification) {\r\n      return;\r\n    }\r\n    tokens = new PaddedList<CoreLabel>(tokens, new CoreLabel());\r\n    int k = tokens.size();\r\n    String[] newAnswers = new String[k];\r\n    for (int i = 0; i < k; i++) {\r\n      CoreLabel c = tokens.get(i);\r\n      CoreLabel p = tokens.get(i - 1);\r\n      if (c.get(AnswerAnnotation.class).length() > 1 && c.get(AnswerAnnotation.class).charAt(1) == '-') {\r\n        String base = c.get(AnswerAnnotation.class).substring(2);\r\n        String pBase = (p.get(AnswerAnnotation.class).length() <= 2 ? p.get(AnswerAnnotation.class) : p.get(AnswerAnnotation.class).substring(2));\r\n        boolean isSecond = (base.equals(pBase));\r\n        boolean isStart = (c.get(AnswerAnnotation.class).charAt(0) == 'B' || c.get(AnswerAnnotation.class).charAt(0) == 'S');\r\n        if (isSecond && isStart) {\r\n          newAnswers[i] = intern(\"B-\" + base);\r\n        } else {\r\n          newAnswers[i] = intern(\"I-\" + base);\r\n        }\r\n      } else {\r\n        newAnswers[i] = c.get(AnswerAnnotation.class);\r\n      }\r\n    }\r\n    for (int i = 0; i < k; i++) {\r\n      CoreLabel c = tokens.get(i);\r\n      c.set(AnswerAnnotation.class, newAnswers[i]);\r\n    }\r\n  }", "label": 0}
{"code": "public function sendChangeNumber($number, $identity)\n    {\n        $msgId = $this->createIqId();\n\n        $usernameNode = new ProtocolNode('username', null, null, $number);\n        $passwordNode = new ProtocolNode('password', null, null, urldecode($identity));\n\n        $modifyNode = new ProtocolNode('modify', null, [$usernameNode, $passwordNode], null);\n\n        $iqNode = new ProtocolNode('iq',\n            [\n                'xmlns' => 'urn:xmpp:whatsapp:account',\n                'id'    => $msgId,\n                'type'  => 'get',\n                'to'    => 'c.us',\n            ], [$modifyNode], null);\n\n        $this->sendNode($iqNode);\n    }", "label": 2}
{"code": "func connectProxyTransport(sconn ssh.Conn, addr string) (net.Conn, error) {\n\tchannel, _, err := sconn.OpenChannel(chanTransport, nil)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Send a special SSH out-of-band request called \"teleport-transport\"\n\t// the agent on the other side will create a new TCP/IP connection to\n\t// 'addr' on its network and will start proxying that connection over\n\t// this SSH channel.\n\tok, err := channel.SendRequest(chanTransportDialReq, true, []byte(addr))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif !ok {\n\t\tdefer channel.Close()\n\n\t\t// Pull the error message from the tunnel client (remote cluster)\n\t\t// passed to us via stderr.\n\t\terrMessage, _ := ioutil.ReadAll(channel.Stderr())\n\t\tif errMessage == nil {\n\t\t\terrMessage = []byte(\"failed connecting to \" + addr)\n\t\t}\n\t\treturn nil, trace.Errorf(strings.TrimSpace(string(errMessage)))\n\t}\n\n\treturn utils.NewChConn(sconn, channel), nil\n}", "label": 5}
{"code": "func (sink *influxdbSink) composeAggregateQuery(metricName string, labels map[string]string, aggregations []core.AggregationType, metricKeys []core.HistoricalKey, start, end time.Time, bucketSize time.Duration) string {\n\tseriesName, fieldName := sink.metricToSeriesAndField(metricName)\n\n\tvar bucketSizeNanoSeconds int64 = 0\n\tif bucketSize != 0 {\n\t\tbucketSizeNanoSeconds = int64(bucketSize.Nanoseconds() / int64(time.Microsecond/time.Nanosecond))\n\t}\n\n\tqueries := make([]string, len(metricKeys))\n\tfor i, key := range metricKeys {\n\t\tpred := sink.keyToSelector(key)\n\t\tif labels != nil {\n\t\t\tpred += fmt.Sprintf(\" AND %s\", sink.labelsToPredicate(labels))\n\t\t}\n\t\tif !start.IsZero() {\n\t\t\tpred += fmt.Sprintf(\" AND time > '%s'\", start.Format(time.RFC3339))\n\t\t}\n\t\tif !end.IsZero() {\n\t\t\tpred += fmt.Sprintf(\" AND time < '%s'\", end.Format(time.RFC3339))\n\t\t}\n\n\t\taggParts := make([]string, len(aggregations))\n\t\tfor i, agg := range aggregations {\n\t\t\taggParts[i] = sink.aggregationFunc(agg, fieldName)\n\t\t}\n\n\t\tqueries[i] = fmt.Sprintf(\"SELECT %s FROM %q WHERE %s\", strings.Join(aggParts, \", \"), seriesName, pred)\n\n\t\tif bucketSize != 0 {\n\t\t\t// group by time requires we have at least one time bound\n\t\t\tif start.IsZero() && end.IsZero() {\n\t\t\t\tqueries[i] += fmt.Sprintf(\" AND time < now()\")\n\t\t\t}\n\n\t\t\t// fill(none) makes sure we skip data points will null values (otherwise we'll get a *bunch* of null\n\t\t\t// values when we go back beyond the time where we started collecting data).\n\t\t\tqueries[i] += fmt.Sprintf(\" GROUP BY time(%vu) fill(none)\", bucketSizeNanoSeconds)\n\t\t}\n\t}\n\n\treturn strings.Join(queries, \"; \")\n}", "label": 5}
{"code": "function addReview(reviews, review) {\n  if (!reviews.length) {\n    return [review];\n  }\n\n  var i = reviews.length - 1;\n  for (; i >= 0; i -= 1) {\n    if (reviews[i].ts <= review.ts) {\n      break;\n    }\n  }\n\n  var newReviews = reviews.slice(0);\n  newReviews.splice(i + 1, 0, review);\n\n  return newReviews;\n}", "label": 3}
{"code": "public boolean find() {\r\n    if (findIterator == null) {\r\n      findIterator = root.iterator();\r\n    }\r\n    if (findCurrent != null && matches()) {\r\n      return true;\r\n    }\r\n    while (findIterator.hasNext()) {\r\n      findCurrent = findIterator.next();\r\n      resetChildIter(findCurrent);\r\n      if (matches()) {\r\n        return true;\r\n      }\r\n    }\r\n    return false;\r\n  }", "label": 0}
{"code": "public static cachepolicy_stats[] get(nitro_service service) throws Exception{\n\t\tcachepolicy_stats obj = new cachepolicy_stats();\n\t\tcachepolicy_stats[] response = (cachepolicy_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def database_url(self):\n        \"\"\"\n        Returns a \"database URL\" for use with DJ-Database-URL and similar\n        libraries.\n        \"\"\"\n        return 'postgres://{}:{}@{}/{}'.format(\n            self.user, self.password, self.name, self.database)", "label": 1}
{"code": "def incr(key, amt=1, ttl=nil, default=nil)\n      raise ArgumentError, \"Positive values only: #{amt}\" if amt < 0\n      perform(:incr, key, amt.to_i, ttl_or_default(ttl), default)\n    end", "label": 4}
{"code": "public function scheduleForInsert($entity)\n    {\n        $oid = spl_object_id($entity);\n\n        if (isset($this->entityUpdates[$oid])) {\n            throw new InvalidArgumentException('Dirty entity can not be scheduled for insertion.');\n        }\n\n        if (isset($this->entityDeletions[$oid])) {\n            throw ORMInvalidArgumentException::scheduleInsertForRemovedEntity($entity);\n        }\n        if (isset($this->originalEntityData[$oid]) && ! isset($this->entityInsertions[$oid])) {\n            throw ORMInvalidArgumentException::scheduleInsertForManagedEntity($entity);\n        }\n\n        if (isset($this->entityInsertions[$oid])) {\n            throw ORMInvalidArgumentException::scheduleInsertTwice($entity);\n        }\n\n        $this->entityInsertions[$oid] = $entity;\n\n        if (isset($this->entityIdentifiers[$oid])) {\n            $this->addToIdentityMap($entity);\n        }\n\n        if ($entity instanceof NotifyPropertyChanged) {\n            $entity->addPropertyChangedListener($this);\n        }\n    }", "label": 2}
{"code": "def coerce_non_null_input(value_name, ctx)\n      if @values_by_name.key?(value_name)\n        @values_by_name.fetch(value_name).value\n      elsif match_by_value = @values_by_name.find { |k, v| v.value == value_name }\n        # this is for matching default values, which are \"inputs\", but they're\n        # the Ruby value, not the GraphQL string.\n        match_by_value[1].value\n      else\n        nil\n      end\n    end", "label": 4}
{"code": "public function filter($property, $operator, $value)\n    {\n        if (!isset($this->query['filter']) || !isset($this->query['filter']['compositeFilter'])) {\n            $this->initializeFilter();\n        }\n\n        $this->query['filter']['compositeFilter']['filters'][] = [\n            'propertyFilter' => [\n                'property' => $this->propertyName($property),\n                'value' => $this->entityMapper->valueObject($value),\n                'op' => $this->mapOperator($operator)\n            ]\n        ];\n\n        return $this;\n    }", "label": 2}
{"code": "func AppImageManifestPath(root string, appName types.ACName) string {\n\treturn filepath.Join(AppInfoPath(root, appName), aci.ManifestFile)\n}", "label": 5}
{"code": "public static vpntrafficpolicy_aaagroup_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpntrafficpolicy_aaagroup_binding obj = new vpntrafficpolicy_aaagroup_binding();\n\t\tobj.set_name(name);\n\t\tvpntrafficpolicy_aaagroup_binding response[] = (vpntrafficpolicy_aaagroup_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def place_market_order(self, side: Side, amount: Number) -> Order:\n        \"\"\"Place a market order.\"\"\"\n        return self.place_order(side, OrderType.MARKET, amount)", "label": 1}
{"code": "public TreeNode getModuleTree(final String moduleId) {\n        final ModuleHandler moduleHandler = new ModuleHandler(repoHandler);\n        final DbModule module = moduleHandler.getModule(moduleId);\n\n        final TreeNode tree = new TreeNode();\n        tree.setName(module.getName());\n\n        // Add submodules\n        for (final DbModule submodule : module.getSubmodules()) {\n            addModuleToTree(submodule, tree);\n        }\n\n        return tree;\n    }", "label": 0}
{"code": "public static rnat6_nsip6_binding[] get(nitro_service service, String name) throws Exception{\n\t\trnat6_nsip6_binding obj = new rnat6_nsip6_binding();\n\t\tobj.set_name(name);\n\t\trnat6_nsip6_binding response[] = (rnat6_nsip6_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def find_comma_position(arg) # rubocop:disable Metrics/AbcSize, Metrics/CyclomaticComplexity\n      offset = 0\n      pos = arg.source_range.end_pos\n\n      if character_at(pos, offset) != ','\n        loop do\n          offset += 1\n          break if (right_char = character_at(pos, offset)) == ','\n          offset = -offset\n          break if (left_char = character_at(pos, offset)) == ','\n          offset = -offset\n\n          next unless right_char.nil? && left_char.nil?\n          offset = 0\n          pos = Sass::Source::Position.new(pos.line + 1, 1)\n          break if character_at(pos, offset) == ','\n        end\n      end\n\n      Sass::Source::Position.new(pos.line, pos.offset + offset)\n    end", "label": 4}
{"code": "public function tags(array $tags)\n    {\n        $this->tags = array_unique(array_merge($this->tags, $tags));\n\n        return $this;\n    }", "label": 2}
{"code": "public function marshalJson($json)\n    {\n        $data = json_decode($json);\n        if (!($data instanceof \\stdClass)) {\n            throw new \\InvalidArgumentException(\n                'The JSON document must be valid and be an object at its root.'\n            );\n        }\n\n        return current($this->marshalValue($data));\n    }", "label": 2}
{"code": "function initCasperCli(casperArgs) {\n        var baseTestsPath = fs.pathJoin(phantom.casperPath, 'tests');\n\n        if (!!casperArgs.options.version) {\n            return __terminate(phantom.casperVersion.toString())\n        } else if (casperArgs.get(0) === \"test\") {\n            phantom.casperScript = fs.absolute(fs.pathJoin(baseTestsPath, 'run.js'));\n            phantom.casperTest = true;\n            casperArgs.drop(\"test\");\n            phantom.casperScriptBaseDir = fs.dirname(casperArgs.get(0));\n        } else if (casperArgs.get(0) === \"selftest\") {\n            phantom.casperScript = fs.absolute(fs.pathJoin(baseTestsPath, 'run.js'));\n            phantom.casperSelfTest = phantom.casperTest = true;\n            casperArgs.options.includes = fs.pathJoin(baseTestsPath, 'selftest.js');\n            if (casperArgs.args.length <= 1) {\n                casperArgs.args.push(fs.pathJoin(baseTestsPath, 'suites'));\n            }\n            casperArgs.drop(\"selftest\");\n            phantom.casperScriptBaseDir = fs.dirname(casperArgs.get(1) || fs.dirname(phantom.casperScript));\n        } else if (casperArgs.args.length === 0 || !!casperArgs.options.help) {\n            return printHelp();\n        }\n\n        if (!phantom.casperScript) {\n            phantom.casperScript = casperArgs.get(0);\n        }\n\n        if (!fs.isFile(phantom.casperScript)) {\n            return __die('Unable to open file: ' + phantom.casperScript);\n        }\n\n        if (!phantom.casperScriptBaseDir) {\n            var scriptDir = fs.dirname(phantom.casperScript);\n            if (scriptDir === phantom.casperScript) {\n                scriptDir = '.';\n            }\n            phantom.casperScriptBaseDir = fs.absolute(scriptDir);\n        }\n\n        // filter out the called script name from casper args\n        casperArgs.drop(phantom.casperScript);\n    }", "label": 3}
{"code": "public static base_response add(nitro_service client, dbdbprofile resource) throws Exception {\n\t\tdbdbprofile addresource = new dbdbprofile();\n\t\taddresource.name = resource.name;\n\t\taddresource.interpretquery = resource.interpretquery;\n\t\taddresource.stickiness = resource.stickiness;\n\t\taddresource.kcdaccount = resource.kcdaccount;\n\t\taddresource.conmultiplex = resource.conmultiplex;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "private static function set_wp_root( $path ) {\n\t\tif ( ! defined( 'ABSPATH' ) ) {\n\t\t\t// phpcs:ignore WordPress.NamingConventions.PrefixAllGlobals.NonPrefixedConstantFound -- Declaring a WP native constant.\n\t\t\tdefine( 'ABSPATH', Utils\\normalize_path( Utils\\trailingslashit( $path ) ) );\n\t\t} elseif ( ! is_null( $path ) ) {\n\t\t\tWP_CLI::error_multi_line(\n\t\t\t\tarray(\n\t\t\t\t\t'The --path parameter cannot be used when ABSPATH is already defined elsewhere',\n\t\t\t\t\t'ABSPATH is defined as: \"' . ABSPATH . '\"',\n\t\t\t\t)\n\t\t\t);\n\t\t}\n\t\tWP_CLI::debug( 'ABSPATH defined: ' . ABSPATH, 'bootstrap' );\n\n\t\t$_SERVER['DOCUMENT_ROOT'] = realpath( $path );\n\t}", "label": 2}
{"code": "public function recognize($audio, array $options = [])\n    {\n        $results = [];\n        $response = $this->connection->recognize(\n            $this->formatRequest($audio, $options)\n        );\n\n        if (!isset($response['results'])) {\n            return $results;\n        }\n\n        foreach ($response['results'] as $result) {\n            $results[] = new Result($result);\n        }\n\n        return $results;\n    }", "label": 2}
{"code": "function buildCSVsForSingleForm(formSubmissionModel, params, formId, callback) {\n  logger.debug(\"buildCSVsForSingleForm\", params, formId);\n\n  var date = params.date;\n  var searchParams = params.searchParams || {};\n  var fieldHeader = searchParams.fieldHeader;\n  var downloadUrl = searchParams.downloadUrl || \"\";\n\n  formId = formId.toString();\n\n  params.statusUpdaterFunction({\n    message: \"Starting export of submissions for form with ID:\" + formId\n  });\n\n  generateQuery(_.defaults({\n    formId: formId\n  }, searchParams), function(err, singleFormQuery) {\n    if (err) {\n      return callback(err);\n    }\n\n    async.waterfall([\n      async.apply(buildCompositeForm, formSubmissionModel, formId, singleFormQuery, params.statusUpdaterFunction),\n      function buildSubmissionCSVForSingleForm(mergedFields, formName, cb) {\n        buildCSVsForSingleMergedForm(formSubmissionModel, {\n          date: date,\n          fieldHeader: fieldHeader,\n          downloadUrl: downloadUrl,\n          mergedFields: mergedFields,\n          formName: formName,\n          formId: formId,\n          exportCounter: params.exportCounter,\n          singleFormQuery: singleFormQuery,\n          statusUpdaterFunction: params.statusUpdaterFunction\n        }, cb);\n      }\n    ], callback);\n  });\n}", "label": 3}
{"code": "private function pluckName($type, $name)\n    {\n        if (!isset($this->regexes[$type])) {\n            throw new InvalidArgumentException(sprintf(\n                'Regex `%s` is not defined',\n                $type\n            ));\n        }\n\n        $matches = [];\n        $res = preg_match($this->regexes[$type], $name, $matches);\n        return ($res === 1) ? $matches[1] : null;\n    }", "label": 2}
{"code": "public static aaauser_vpnurl_binding[] get(nitro_service service, String username) throws Exception{\n\t\taaauser_vpnurl_binding obj = new aaauser_vpnurl_binding();\n\t\tobj.set_username(username);\n\t\taaauser_vpnurl_binding response[] = (aaauser_vpnurl_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getQueryResults(\n            $options + $this->identity\n        );\n    }", "label": 2}
{"code": "function findSourceFile(fileName, path, isDefaultLib, isReference, refFile, refPos, refEnd) {\n            if (filesByName.contains(path)) {\n                var file_1 = filesByName.get(path);\n                // try to check if we've already seen this file but with a different casing in path\n                // NOTE: this only makes sense for case-insensitive file systems\n                if (file_1 && options.forceConsistentCasingInFileNames && ts.getNormalizedAbsolutePath(file_1.fileName, currentDirectory) !== ts.getNormalizedAbsolutePath(fileName, currentDirectory)) {\n                    reportFileNamesDifferOnlyInCasingError(fileName, file_1.fileName, refFile, refPos, refEnd);\n                }\n                // If the file was previously found via a node_modules search, but is now being processed as a root file,\n                // then everything it sucks in may also be marked incorrectly, and needs to be checked again.\n                if (file_1 && sourceFilesFoundSearchingNodeModules[file_1.path] && currentNodeModulesDepth == 0) {\n                    sourceFilesFoundSearchingNodeModules[file_1.path] = false;\n                    if (!options.noResolve) {\n                        processReferencedFiles(file_1, ts.getDirectoryPath(fileName), isDefaultLib);\n                        processTypeReferenceDirectives(file_1);\n                    }\n                    modulesWithElidedImports[file_1.path] = false;\n                    processImportedModules(file_1, ts.getDirectoryPath(fileName));\n                }\n                else if (file_1 && modulesWithElidedImports[file_1.path]) {\n                    if (currentNodeModulesDepth < maxNodeModulesJsDepth) {\n                        modulesWithElidedImports[file_1.path] = false;\n                        processImportedModules(file_1, ts.getDirectoryPath(fileName));\n                    }\n                }\n                return file_1;\n            }\n            // We haven't looked for this file, do so now and cache result\n            var file = host.getSourceFile(fileName, options.target, function (hostErrorMessage) {\n                if (refFile !== undefined && refPos !== undefined && refEnd !== undefined) {\n                    fileProcessingDiagnostics.add(ts.createFileDiagnostic(refFile, refPos, refEnd - refPos, ts.Diagnostics.Cannot_read_file_0_Colon_1, fileName, hostErrorMessage));\n                }\n                else {\n                    fileProcessingDiagnostics.add(ts.createCompilerDiagnostic(ts.Diagnostics.Cannot_read_file_0_Colon_1, fileName, hostErrorMessage));\n                }\n            });\n            filesByName.set(path, file);\n            if (file) {\n                sourceFilesFoundSearchingNodeModules[path] = (currentNodeModulesDepth > 0);\n                file.path = path;\n                if (host.useCaseSensitiveFileNames()) {\n                    // for case-sensitive file systems check if we've already seen some file with similar filename ignoring case\n                    var existingFile = filesByNameIgnoreCase.get(path);\n                    if (existingFile) {\n                        reportFileNamesDifferOnlyInCasingError(fileName, existingFile.fileName, refFile, refPos, refEnd);\n                    }\n                    else {\n                        filesByNameIgnoreCase.set(path, file);\n                    }\n                }\n                skipDefaultLib = skipDefaultLib || file.hasNoDefaultLib;\n                var basePath = ts.getDirectoryPath(fileName);\n                if (!options.noResolve) {\n                    processReferencedFiles(file, basePath, isDefaultLib);\n                    processTypeReferenceDirectives(file);\n                }\n                // always process imported modules to record module name resolutions\n                processImportedModules(file, basePath);\n                if (isDefaultLib) {\n                    files.unshift(file);\n                }\n                else {\n                    files.push(file);\n                }\n            }\n            return file;\n        }", "label": 3}
{"code": "func NewScreen() (Screen, error) {\n\t// Windows is happier if we try for a console screen first.\n\tif s, _ := NewConsoleScreen(); s != nil {\n\t\treturn s, nil\n\t} else if s, e := NewTerminfoScreen(); s != nil {\n\t\treturn s, nil\n\t} else {\n\t\treturn nil, e\n\t}\n}", "label": 5}
{"code": "function(l) {\n    debug('Attaching link ' + l.name + ':' + l.handle + ' after begin received');\n    if (l.state() !== 'attached' && l.state() !== 'attaching') l.attach();\n  }", "label": 3}
{"code": "def strict(*types):\n    \"\"\"Decorator, type check production rule output\"\"\"\n\n    def decorate(func):\n        @wraps(func)\n        def wrapper(self, p):\n            func(self, p)\n            if not isinstance(p[0], types):\n                raise YAMLStrictTypeError(p[0], types, func)\n\n        wrapper.co_firstlineno = func.__code__.co_firstlineno\n        return wrapper\n\n    return decorate", "label": 1}
{"code": "public function rewind()\n    {\n        $this->key = 0;\n        $this->current = call_user_func([$this->dateClass, 'make'], $this->startDate);\n        $settings = $this->getSettings();\n        $locale = $this->getLocalTranslator()->getLocale();\n        if ($locale) {\n            $settings['locale'] = $locale;\n        }\n        $this->current->settings($settings);\n        $this->timezone = static::intervalHasTime($this->dateInterval) ? $this->current->getTimezone() : null;\n\n        if ($this->timezone) {\n            $this->current = $this->current->utc();\n        }\n\n        $this->validationResult = null;\n\n        if ($this->isStartExcluded() || $this->validateCurrentDate() === false) {\n            $this->incrementCurrentDateUntilValid();\n        }\n    }", "label": 2}
{"code": "protected function applyConditions(array $where)\n    {\n        foreach ($where as $field => $value) {\n            if (is_array($value)) {\n                list($field, $condition, $val) = $value;\n                $this->model = $this->model->where($field, $condition, $val);\n            } else {\n                $this->model = $this->model->where($field, '=', $value);\n            }\n        }\n    }", "label": 2}
{"code": "public static <T> String join(Collection<T> col, String delim) {\n    StringBuilder sb = new StringBuilder();\n    Iterator<T> iter = col.iterator();\n    if (iter.hasNext())\n      sb.append(iter.next().toString());\n    while (iter.hasNext()) {\n      sb.append(delim);\n      sb.append(iter.next().toString());\n    }\n    return sb.toString();\n  }", "label": 0}
{"code": "public function setDataProtectionMode($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Redis\\V1beta1\\FailoverInstanceRequest_DataProtectionMode::class);\n        $this->data_protection_mode = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(allElements){\n            if (allElements.length == 1) {\n                return allElements[0];\n            }\n\n            var withoutCommentsOrEmptyText = [];\n\n            for (var i = 0; i < allElements.length; i++) {\n                var current = allElements[i];\n                if (current.nodeType != 8) {\n                    if (current.nodeType == 3) {\n                        var result = /\\S/.test(current.nodeValue);\n                        if (!result) {\n                            continue;\n                        }\n                    }\n\n                    withoutCommentsOrEmptyText.push(current);\n                }\n            }\n\n            if (withoutCommentsOrEmptyText.length > 1) {\n                return $(withoutCommentsOrEmptyText).wrapAll('<div class=\"durandal-wrapper\"></div>').parent().get(0);\n            }\n\n            return withoutCommentsOrEmptyText[0];\n        }", "label": 3}
{"code": "def check_adjacent_properties(properties)\n      properties[0..-2].zip(properties[1..-1]).each do |first, second|\n        next unless first.line == second.line\n\n        add_lint(second, \"Property '#{second.name.join}' should be placed on own line\")\n      end\n    end", "label": 4}
{"code": "function() {\n      this.__normalizeAndValidateUpdateEvents();\n      var updateEvents = _.flatten(_.map(this.updateEvents, this.__parseUpdateEvent, this));\n      return _.compact(updateEvents);\n    }", "label": 3}
{"code": "function(m) {\n\tconsole.log([m.a, m.b, m.c, m.d, m.e, m.f]);\n}", "label": 3}
{"code": "func (s Strings) MarshalYAML() (interface{}, error) {\n\tif len(s) == 1 {\n\t\treturn s[0], nil\n\t}\n\treturn []string(s), nil\n}", "label": 5}
{"code": "public function setRemovals($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\WebRisk\\V1beta1\\ThreatEntryRemovals::class);\n        $this->removals = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function autoload($className)\n    {\n        if (0 === strpos($className, $this->prefix)) {\n            $parts = explode('\\\\', substr($className, $this->prefixLength));\n            $filepath = $this->directory.DIRECTORY_SEPARATOR.implode(DIRECTORY_SEPARATOR, $parts).'.php';\n\n            if (is_file($filepath)) {\n                require $filepath;\n            }\n        }\n    }", "label": 2}
{"code": "public function getPayload()\n    {\n        $payload = $this->payload;\n\n        // The \"message\" property is deprecated and replaced by \"error_description\"\n        // TODO: remove \"message\" property\n        if (isset($payload['error_description']) && !isset($payload['message'])) {\n            $payload['message'] = $payload['error_description'];\n        }\n\n        return $payload;\n    }", "label": 2}
{"code": "func populateAggregations(rawRowName string, rawVal []interface{}, val *core.TimestampedAggregationValue, aggregationLookup map[core.AggregationType]int, wasInt map[string]bool) error {\n\tfor _, aggregation := range core.MultiTypedAggregations {\n\t\tif err := setAggregationValueIfPresent(aggregation, rawVal, &val.AggregationValue, aggregationLookup, wasInt); err != nil {\n\t\t\tglog.Errorf(\"Unable to parse field %q in series %q: %v\", aggregation, rawRowName, err)\n\t\t\treturn fmt.Errorf(\"Unable to parse values in series %q\", rawRowName)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function moveToDest(srcDir, destDir) {\n  if (!this.options.cleanOutput) {\n    return srcDir;\n  }\n  var content, cssDir, src;\n  var copiedCache = this.copiedCache || {};\n  var copied = {};\n  var options = this.options;\n  var tree = this.walkDir(srcDir, {cache: this.cache});\n  var cache = tree.paths;\n  var generated = tree.changed;\n  var linkedFiles = [];\n  for (var i = 0; i < generated.length; i += 1) {\n    file = generated[i];\n    if (cache[file].isDirectory || copiedCache[file] === cache[file].statsHash) {\n      continue;\n    }\n    src = srcDir + '/' + file;\n    if (file.substr(-4) === '.css') {\n      content = fs.readFileSync(src);\n      cssDir = path.dirname(file);\n      while ((linkedFile = urlRe.exec(content))) {\n        linkedFile = (linkedFile[1][0] === '/') ? linkedFile[1].substr(1) : path.normalize(cssDir + '/' + linkedFile[1]);\n        linkedFiles.push(linkedFile);\n      }\n    }\n    mkdirp(destDir + '/' + path.dirname(file));\n    symlinkOrCopy(src, destDir + '/' + file);\n    copied[file] = cache[file].statsHash;\n  }\n\n  for (i = 0; i < linkedFiles.length; i += 1) {\n    file = linkedFiles[i];\n    if (file in copied) { continue; }\n    if (!cache[file] || copiedCache[file] !== cache[file].statsHash) {\n      copied[file] = cache[file] && cache[file].statsHash;\n      mkdirp(destDir + '/' + path.dirname(file));\n      symlinkOrCopy(srcDir + '/' + file, destDir + '/' + file);\n    }\n  }\n  this.copiedCache = copied;\n  return destDir;\n}", "label": 3}
{"code": "def %(other)\n      if Duration === other || Scalar === other\n        Duration.build(value % other.value)\n      elsif Numeric === other\n        Duration.build(value % other)\n      else\n        raise_type_error(other)\n      end\n    end", "label": 4}
{"code": "private function transactionSelector(array &$options, array $previous = [])\n    {\n        $options += [\n            'begin' => false,\n            'transactionType' => SessionPoolInterface::CONTEXT_READ,\n        ];\n\n        $res = $this->transactionOptions($options, $previous);\n\n        // TransactionSelector uses a different key name for singleUseTransaction\n        // and transactionId than transactionOptions, so we'll rewrite those here\n        // so transactionOptions works as expected for commitRequest.\n\n        $type = $res[1];\n        if ($type === 'singleUseTransaction') {\n            $type = 'singleUse';\n        } elseif ($type === 'transactionId') {\n            $type = 'id';\n        }\n\n        return [\n            [$type => $res[0]],\n            $res[2]\n        ];\n    }", "label": 2}
{"code": "func (f *file) lintElses() {\n\t// We don't want to flag if { } else if { } else { } constructions.\n\t// They will appear as an IfStmt whose Else field is also an IfStmt.\n\t// Record such a node so we ignore it when we visit it.\n\tignore := make(map[*ast.IfStmt]bool)\n\n\tf.walk(func(node ast.Node) bool {\n\t\tifStmt, ok := node.(*ast.IfStmt)\n\t\tif !ok || ifStmt.Else == nil {\n\t\t\treturn true\n\t\t}\n\t\tif elseif, ok := ifStmt.Else.(*ast.IfStmt); ok {\n\t\t\tignore[elseif] = true\n\t\t\treturn true\n\t\t}\n\t\tif ignore[ifStmt] {\n\t\t\treturn true\n\t\t}\n\t\tif _, ok := ifStmt.Else.(*ast.BlockStmt); !ok {\n\t\t\t// only care about elses without conditions\n\t\t\treturn true\n\t\t}\n\t\tif len(ifStmt.Body.List) == 0 {\n\t\t\treturn true\n\t\t}\n\t\tshortDecl := false // does the if statement have a \":=\" initialization statement?\n\t\tif ifStmt.Init != nil {\n\t\t\tif as, ok := ifStmt.Init.(*ast.AssignStmt); ok && as.Tok == token.DEFINE {\n\t\t\t\tshortDecl = true\n\t\t\t}\n\t\t}\n\t\tlastStmt := ifStmt.Body.List[len(ifStmt.Body.List)-1]\n\t\tif _, ok := lastStmt.(*ast.ReturnStmt); ok {\n\t\t\textra := \"\"\n\t\t\tif shortDecl {\n\t\t\t\textra = \" (move short variable declaration to its own line if necessary)\"\n\t\t\t}\n\t\t\tf.errorf(ifStmt.Else, 1, link(styleGuideBase+\"#indent-error-flow\"), category(\"indent\"), \"if block ends with a return statement, so drop this else and outdent its block\"+extra)\n\t\t}\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "def remove_filter(name)\n      defined.delete name.to_s.downcase\n      if constants.map(&:to_s).include?(name.to_s)\n        remove_const name.to_sym\n      end\n    end", "label": 4}
{"code": "public static Object getObjectFromColumn(ResultSet rs, Integer jdbcType, int columnId)\r\n            throws SQLException\r\n    {\r\n        return getObjectFromColumn(rs, null, jdbcType, null, columnId);\r\n    }", "label": 0}
{"code": "func (a *allocator) ReleasePool(poolID string) error {\n\tlogrus.Debugf(\"ReleasePool(%s)\", poolID)\n\treturn nil\n}", "label": 5}
{"code": "def _initial_voltage(self, buses, generators):\n        \"\"\" Returns the initial vector of complex bus voltages.\n\n        The bus voltage vector contains the set point for generator\n        (including ref bus) buses, and the reference angle of the swing\n        bus, as well as an initial guess for remaining magnitudes and\n        angles.\n        \"\"\"\n        Vm = array([bus.v_magnitude for bus in buses])\n\n        # Initial bus voltage angles in radians.\n        Va = array([bus.v_angle * (pi / 180.0) for bus in buses])\n\n        V = Vm * exp(1j * Va)\n\n        # Get generator set points.\n        for g in generators:\n            i = g.bus._i\n            V[i] = g.v_magnitude / abs(V[i]) * V[i]\n\n        return V", "label": 1}
{"code": "def export(self):\n        \"\"\"return the object in a file\"\"\"\n\n        with open(self.export_url, 'w', encoding='utf-8') as file:\n            file.write(self.build())\n            if self.open_browser:\n                webbrowser.open_new_tab(self.export_url)", "label": 1}
{"code": "function validateBotApi (botFactory, postBackTest, textTest, acl) {\n    /** @deprecated way to validate bot */\n    if (postBackTest && typeof postBackTest === 'object') {\n\n        // @ts-ignore\n        return validate(botFactory, postBackTest, textTest, acl)\n            .then((res) => {\n                if (!res.ok) {\n                    throw new Error(res.error);\n                }\n            });\n    }\n\n    return {\n        async validateBot (args, ctx) {\n            if (!apiAuthorizer(args, ctx, acl)) {\n                return null;\n            }\n\n            const validationRequestBody = args.bot;\n\n            const bot = botFactory();\n\n            return validate(bot, validationRequestBody, postBackTest, textTest);\n        }\n    };\n}", "label": 3}
{"code": "def insert_successor(create_params, path)\n      self.class.transaction do\n        new_successor = self.class.create!(create_params)\n        if library?\n          if path\n            old_successor = path.first\n            old_successor.prior = new_successor\n          end\n          save_successor new_successor\n        elsif successor.nil?\n          save_successor new_successor\n        else\n          old_successor = successor\n          old_successor.prior = new_successor\n          save_successor new_successor\n        end\n        fail HttpErrors::UnprocessableEntity, _('An environment is missing a prior') unless all_have_prior?\n        new_successor\n      end\n    end", "label": 4}
{"code": "def signature_unsafe(m, sk, pk, hash_func=H):\n    \"\"\"\n    Not safe to use with secret keys or secret data.\n    See module docstring.  This function should be used for testing only.\n    \"\"\"\n    h = hash_func(sk)\n    a = 2 ** (b - 2) + sum(2 ** i * bit(h, i) for i in range(3, b - 2))\n    r = Hint(bytearray([h[j] for j in range(b // 8, b // 4)]) + m)\n    R = scalarmult_B(r)\n    S = (r + Hint(encodepoint(R) + pk + m) * a) % l\n    return bytes(encodepoint(R) + encodeint(S))", "label": 1}
{"code": "func (dm *DjangoMigration) Update(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !dm._exists {\n\t\treturn errors.New(\"update failed: does not exist\")\n\t}\n\n\t// if deleted, bail\n\tif dm._deleted {\n\t\treturn errors.New(\"update failed: marked for deletion\")\n\t}\n\n\t// sql query\n\tconst sqlstr = `UPDATE django.django_migrations SET ` +\n\t\t`app = :1, name = :2, applied = :3` +\n\t\t` WHERE id = :4`\n\n\t// run query\n\tXOLog(sqlstr, dm.App, dm.Name, dm.Applied, dm.ID)\n\t_, err = db.Exec(sqlstr, dm.App, dm.Name, dm.Applied, dm.ID)\n\treturn err\n}", "label": 5}
{"code": "protected function handleArgDirectivesRecursively(\n        InputType $type,\n        InputValueDefinitionNode $astNode,\n        array $argumentPath\n    ): void {\n        if ($type instanceof NonNull) {\n            $this->handleArgDirectivesRecursively(\n                $type->getWrappedType(),\n                $astNode,\n                $argumentPath\n            );\n\n            return;\n        }\n\n        $directives = $this->directiveFactory->createArgDirectives($astNode);\n\n        if (\n            $directives->contains(function (Directive $directive): bool {\n                return $directive instanceof SpreadDirective;\n            })\n            && $type instanceof InputObjectType\n        ) {\n            $this->spreadPaths [] = $argumentPath;\n        }\n\n        // Handle the argument itself. At this point, it can be wrapped\n        // in a list or an input object\n        $this->handleArgWithAssociatedDirectives($type, $astNode, $directives, $argumentPath);\n\n        // If we no value or null is given, we bail here to prevent\n        // infinitely going down a chain of nested input objects\n        if (! $this->argValueExists($argumentPath) || $this->argValue($argumentPath) === null) {\n            return;\n        }\n\n        if ($type instanceof InputObjectType) {\n            foreach ($type->getFields() as $field) {\n                $this->handleArgDirectivesRecursively(\n                    $field->type,\n                    $field->astNode,\n                    array_merge($argumentPath, [$field->name])\n                );\n            }\n        }\n\n        if ($type instanceof ListOfType) {\n            foreach ($this->argValue($argumentPath) as $index => $value) {\n                // here we are passing by reference so the `$argValue[$key]` is intended.\n                $this->handleArgDirectivesRecursively(\n                    $type->ofType,\n                    $astNode,\n                    array_merge($argumentPath, [$index])\n                );\n            }\n        }\n    }", "label": 2}
{"code": "public void readData(BufferedReader in) throws IOException {\r\n    String line, value;\r\n    // skip old variables if still present\r\n    lexOptions.readData(in);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    try {\r\n      tlpParams = (TreebankLangParserParams) Class.forName(value).newInstance();\r\n    } catch (Exception e) {\r\n      IOException ioe = new IOException(\"Problem instantiating parserParams: \" + line);\r\n      ioe.initCause(e);\r\n      throw ioe;\r\n    }\r\n    line = in.readLine();\r\n    // ensure backwards compatibility\r\n    if (line.matches(\"^forceCNF.*\")) {\r\n      value = line.substring(line.indexOf(' ') + 1);\r\n      forceCNF = Boolean.parseBoolean(value);\r\n      line = in.readLine();\r\n    }\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    doPCFG = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    doDep = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    freeDependencies = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    directional = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    genStop = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    distance = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    coarseDistance = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    dcTags = Boolean.parseBoolean(value);\r\n    line = in.readLine();\r\n    if ( ! line.matches(\"^nPrune.*\")) {\r\n      throw new RuntimeException(\"Expected nPrune, found: \" + line);\r\n    }\r\n    value = line.substring(line.indexOf(' ') + 1);\r\n    nodePrune = Boolean.parseBoolean(value);\r\n    line = in.readLine(); // get rid of last line\r\n    if (line.length() != 0) {\r\n      throw new RuntimeException(\"Expected blank line, found: \" + line);\r\n    }\r\n  }", "label": 0}
{"code": "func (c *Manager) CreateCategory(ctx context.Context, category *Category) (string, error) {\n\t// create avoids the annoyance of CreateTag requiring field keys to be included in the request,\n\t// even though the field value can be empty.\n\ttype create struct {\n\t\tName            string   `json:\"name\"`\n\t\tDescription     string   `json:\"description\"`\n\t\tCardinality     string   `json:\"cardinality\"`\n\t\tAssociableTypes []string `json:\"associable_types\"`\n\t}\n\tspec := struct {\n\t\tCategory create `json:\"create_spec\"`\n\t}{\n\t\tCategory: create{\n\t\t\tName:            category.Name,\n\t\t\tDescription:     category.Description,\n\t\t\tCardinality:     category.Cardinality,\n\t\t\tAssociableTypes: category.AssociableTypes,\n\t\t},\n\t}\n\tif spec.Category.AssociableTypes == nil {\n\t\t// otherwise create fails with invalid_argument\n\t\tspec.Category.AssociableTypes = []string{}\n\t}\n\turl := internal.URL(c, internal.CategoryPath)\n\tvar res string\n\treturn res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "def container(wobj)\n      s = @epub.container\n      if !s.nil? && !wobj.nil?\n        wobj.puts s\n      end\n    end", "label": 4}
{"code": "func eventsFileName(dataDir string, sessionID session.ID, eventIndex int64) string {\n\treturn filepath.Join(dataDir, fmt.Sprintf(\"%v-%v.events.gz\", sessionID.String(), eventIndex))\n}", "label": 5}
{"code": "function process(advertiserData, cursor) {\n  var iBeacon = {};\n  var data = advertiserData.manufacturerSpecificData.data;\n\n  iBeacon.uuid = data.substr(4,32);\n  iBeacon.major = data.substr(36,4);\n  iBeacon.minor = data.substr(40,4);\n  iBeacon.txPower = pdu.convertTxPower(data.substr(44,2));\n\n  var licenseeName = licenseeNames[iBeacon.uuid];\n  if(typeof licenseeName === 'undefined') {\n    licenseeName = 'Unknown';\n  }\n  iBeacon.licenseeName = licenseeName;\n\n  advertiserData.manufacturerSpecificData.iBeacon = iBeacon;\n\n  return cursor + 46;\n}", "label": 3}
{"code": "function concat(methodDictionary, func, name) {\n  expect(arguments).to.have.length(\n    3,\n    'Invalid arguments length when concatenating a MethodDictionary (it has ' +\n    'to be passed 3 arguments)'\n  );\n\n  expect(methodDictionary).to.be.instanceof(\n    MethodDictionary,\n    'Invalid argument \"methodDictionary\" when concatenating a ' +\n    'MethodDictionary (it has to be a MethodDictionary)'\n  );\n\n  expect(func).to.be.a(\n    'function',\n    'Invalid argument \"func\" when concatenating a MethodDictionary ' +\n    '(it has to be a function)'\n  );\n\n  expect(name).to.be.a(\n    'string',\n    'Invalid argument \"name\" when concatenating a MethodDictionary ' +\n    '(it has to be a string)'\n  );\n\n  expect(methodDictionary).to.not.have.ownProperty(\n    name,\n    'Duplicated method name \"' + name + '\"'\n  );\n\n  var currentMethods = {};\n\n  for (var currentMethod in methodDictionary) {\n    currentMethods[currentMethod] = methodDictionary[currentMethod];\n  }\n\n  currentMethods[name] = func;\n\n  return new MethodDictionary(currentMethods);\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, sslcertkey resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslcertkey addresources[] = new sslcertkey[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new sslcertkey();\n\t\t\t\taddresources[i].certkey = resources[i].certkey;\n\t\t\t\taddresources[i].cert = resources[i].cert;\n\t\t\t\taddresources[i].key = resources[i].key;\n\t\t\t\taddresources[i].password = resources[i].password;\n\t\t\t\taddresources[i].fipskey = resources[i].fipskey;\n\t\t\t\taddresources[i].inform = resources[i].inform;\n\t\t\t\taddresources[i].passplain = resources[i].passplain;\n\t\t\t\taddresources[i].expirymonitor = resources[i].expirymonitor;\n\t\t\t\taddresources[i].notificationperiod = resources[i].notificationperiod;\n\t\t\t\taddresources[i].bundle = resources[i].bundle;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def monthrange(cls, year, month):\n        \"\"\"Returns the number of days in a month\"\"\"\n        functions.check_valid_bs_range(NepDate(year, month, 1))\n        return values.NEPALI_MONTH_DAY_DATA[year][month - 1]", "label": 1}
{"code": "def background_image=(bg_image)\n      warn 'background_image= has no effect in nested RVG objects' if @nested\n      raise ArgumentError, \"background image must be an Image (got #{bg_image.class})\" if bg_image && !bg_image.is_a?(Magick::Image)\n\n      @background_image = bg_image\n    end", "label": 4}
{"code": "function CodeMirror(place, options) {\n    if (!(this instanceof CodeMirror)) return new CodeMirror(place, options);\n\n    this.options = options = options ? copyObj(options) : {};\n    // Determine effective options based on given values and defaults.\n    copyObj(defaults, options, false);\n    setGuttersForLineNumbers(options);\n\n    var doc = options.value;\n    if (typeof doc == \"string\") doc = new Doc(doc, options.mode);\n    this.doc = doc;\n\n    var display = this.display = new Display(place, doc);\n    display.wrapper.CodeMirror = this;\n    updateGutters(this);\n    themeChanged(this);\n    if (options.lineWrapping)\n      this.display.wrapper.className += \" CodeMirror-wrap\";\n    if (options.autofocus && !mobile) focusInput(this);\n    initScrollbars(this);\n\n    this.state = {\n      keyMaps: [],  // stores maps added by addKeyMap\n      overlays: [], // highlighting overlays, as added by addOverlay\n      modeGen: 0,   // bumped when mode/overlay changes, used to invalidate highlighting info\n      overwrite: false, focused: false,\n      suppressEdits: false, // used to disable editing during key handlers when in readOnly mode\n      pasteIncoming: false, cutIncoming: false, // help recognize paste/cut edits in readInput\n      draggingText: false,\n      highlight: new Delayed(), // stores highlight worker timeout\n      keySeq: null  // Unfinished key sequence\n    };\n\n    // Override magic textarea content restore that IE sometimes does\n    // on our hidden textarea on reload\n    if (ie && ie_version < 11) setTimeout(bind(resetInput, this, true), 20);\n\n    registerEventHandlers(this);\n    ensureGlobalHandlers();\n\n    startOperation(this);\n    this.curOp.forceUpdate = true;\n    attachDoc(this, doc);\n\n    if ((options.autofocus && !mobile) || activeElt() == display.input)\n      setTimeout(bind(onFocus, this), 20);\n    else\n      onBlur(this);\n\n    for (var opt in optionHandlers) if (optionHandlers.hasOwnProperty(opt))\n      optionHandlers[opt](this, options[opt], Init);\n    maybeUpdateLineNumberWidth(this);\n    if (options.finishInit) options.finishInit(this);\n    for (var i = 0; i < initHooks.length; ++i) initHooks[i](this);\n    endOperation(this);\n    // Suppress optimizelegibility in Webkit, since it breaks text\n    // measuring on line wrapping boundaries.\n    if (webkit && options.lineWrapping &&\n        getComputedStyle(display.lineDiv).textRendering == \"optimizelegibility\")\n      display.lineDiv.style.textRendering = \"auto\";\n  }", "label": 3}
{"code": "public function insertRow(array $row, array $options = [])\n    {\n        $row = ['data' => $row];\n\n        if (isset($options['insertId'])) {\n            $row['insertId'] = $options['insertId'];\n            unset($options['insertId']);\n        }\n\n        return $this->insertRows([$row], $options);\n    }", "label": 2}
{"code": "function build_doc_map(docs) {\n  var map = {};\n  _.each(docs, function(tag) {\n    if (map[tag[\"tagname\"]])\n      map[tag[\"tagname\"]].push(tag);\n    else\n      map[tag[\"tagname\"]] = new Array(tag);\n  });\n  return map;\n}", "label": 3}
{"code": "func AnyTTL(clock clockwork.Clock, times ...time.Time) time.Duration {\n\tfor _, t := range times {\n\t\tif !t.IsZero() {\n\t\t\treturn TTL(clock, t)\n\t\t}\n\t}\n\treturn Forever\n}", "label": 5}
{"code": "async function run(options) {\n  const {\n    source, output = '-', reverse, justToc, h1, noCache, rootNamespace,\n  } = options\n  const stream = getStream(source, reverse, false)\n  // todo: figure out why can't create a pass-through, pipe into it and pause it\n\n  const { types, locations } = await getTypedefs(stream, rootNamespace)\n\n  const stream3 = getStream(source, reverse, true)\n  const doc = new Documentary({ locations, types, noCache, objectMode: true })\n  stream3.pipe(doc)\n  const tocPromise = getToc(doc, h1, locations)\n\n  const c = new Catchment()\n  await whichStream({\n    readable: doc,\n    writable: c,\n  })\n  const toc = await tocPromise\n  const result = (await c.promise)\n    .replace('%%_DOCUMENTARY_TOC_CHANGE_LATER_%%', toc)\n    .replace(/%%DTOC_(.+?)_(\\d+)%%/g, '')\n\n  if (justToc) {\n    console.log(toc)\n    process.exit()\n  }\n  if (output != '-') {\n    console.log('Saved documentation to %s', output)\n    await write(output, result)\n  } else {\n    console.log(result)\n  }\n  return [...Object.keys(locations), ...doc.assets]\n}", "label": 3}
{"code": "def unescape_uri(str)\n      str = str.dup\n      binary_encode(str)\n      str.gsub(ESCAPED) { $1.hex.chr }\n    end", "label": 4}
{"code": "def persistent_cookie_path\n      if ENV[\"SPACESHIP_COOKIE_PATH\"]\n        path = File.expand_path(File.join(ENV[\"SPACESHIP_COOKIE_PATH\"], \"spaceship\", self.user, \"cookie\"))\n      else\n        [File.join(self.fastlane_user_dir, \"spaceship\"), \"~/.spaceship\", \"/var/tmp/spaceship\", \"#{Dir.tmpdir}/spaceship\"].each do |dir|\n          dir_parts = File.split(dir)\n          if directory_accessible?(File.expand_path(dir_parts.first))\n            path = File.expand_path(File.join(dir, self.user, \"cookie\"))\n            break\n          end\n        end\n      end\n\n      return path\n    end", "label": 4}
{"code": "def request_response(req, metadata: {})\n      raise_error_if_already_executed\n      ops = {\n        SEND_MESSAGE => @marshal.call(req),\n        SEND_CLOSE_FROM_CLIENT => nil,\n        RECV_INITIAL_METADATA => nil,\n        RECV_MESSAGE => nil,\n        RECV_STATUS_ON_CLIENT => nil\n      }\n      @send_initial_md_mutex.synchronize do\n        # Metadata might have already been sent if this is an operation view\n        unless @metadata_sent\n          ops[SEND_INITIAL_METADATA] = @metadata_to_send.merge!(metadata)\n        end\n        @metadata_sent = true\n      end\n\n      begin\n        batch_result = @call.run_batch(ops)\n        # no need to check for cancellation after a CallError because this\n        # batch contains a RECV_STATUS op\n      ensure\n        set_input_stream_done\n        set_output_stream_done\n      end\n\n      @call.metadata = batch_result.metadata\n      attach_status_results_and_complete_call(batch_result)\n      get_message_from_batch_result(batch_result)\n    end", "label": 4}
{"code": "function loadMappings(rootDir, paths) {\n        var mappings = {}, i, j, fullPath, fileNames, fileName, path, name, val;\n\n        if (!paths) {\n            return mappings;\n        }\n\n        for (i = 0; i < paths.length; i++) {\n            path = paths[i];\n            fullPath = rootDir + '/' + path;\n\n            // if the directory doesn't exist, then skip to the next loop iteration\n            if (!fs.existsSync(p.normalize(fullPath))) {\n                continue;\n            }\n\n            // loop through all files in this folder\n            fileNames = fs.readdirSync(p.normalize(fullPath));\n\n            for (j = 0; j < fileNames.length; j++) {\n                fileName = fileNames[j];\n\n                // if it is a javascript file and it DOES NOT end in .service.js, then save the mapping\n                if (utils.isJavaScript(fileName) && !fileName.match(/^.*\\.service\\.js$/)) {\n                    name = utils.getCamelCase(fileName);\n                    val = utils.getModulePath(path, fileName);\n                    mappings[name] = val;\n                    mappings[name.substring(0, 1).toUpperCase() + name.substring(1)] = val;  // store PascalCase as well\n                }\n\n                // else if we are dealing with a directory, recurse down into the folder\n                else if (fs.lstatSync(p.join(fullPath, fileName)).isDirectory()) {\n                    _.extend(mappings, this.loadMappings(rootDir, [path + '/' + fileName]));\n                }\n            }\n        }\n\n        return mappings;\n    }", "label": 3}
{"code": "def file_handle(fnh, mode=\"rU\"):\n    \"\"\"\n    Takes either a file path or an open file handle, checks validity and returns an open\n    file handle or raises an appropriate Exception.\n\n    :type fnh: str\n    :param fnh: It is the full path to a file, or open file handle\n\n    :type mode: str\n    :param mode: The way in which this file will be used, for example to read or write or\n                 both. By default, file will be opened in rU mode.\n\n    :return: Returns an opened file for appropriate usage.\n    \"\"\"\n    handle = None\n    if isinstance(fnh, file):\n        if fnh.closed:\n            raise ValueError(\"Input file is closed.\")\n        handle = fnh\n    elif isinstance(fnh, str):\n        handle = open(fnh, mode)\n\n    return handle", "label": 1}
{"code": "public static base_response enable(nitro_service client, nsfeature resource) throws Exception {\n\t\tnsfeature enableresource = new nsfeature();\n\t\tenableresource.feature = resource.feature;\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "def stock2fa(stock):\n    \"\"\"\n    convert stockholm to fasta\n    \"\"\"\n    seqs = {}\n    for line in stock:\n        if line.startswith('#') is False and line.startswith(' ') is False and len(line) > 3:\n            id, seq = line.strip().split()\n            id = id.rsplit('/', 1)[0]\n            id = re.split('[0-9]\\|', id, 1)[-1]\n            if id not in seqs:\n                seqs[id] = []\n            seqs[id].append(seq)\n        if line.startswith('//'):\n            break\n    return seqs", "label": 1}
{"code": "def role(id)\n      id = id.resolve_id\n      @roles.find { |e| e.id == id }\n    end", "label": 4}
{"code": "public static lbvserver[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tlbvserver obj = new lbvserver();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tlbvserver[] response = (lbvserver[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (res, res_obj) {\n\n    // return response if exist, otherwise response might be returned \n    // AFTER some callback is done handling (i.e., response will be returned within the handler)\n    if (typeof res_obj === 'string') {\n        LOG.sys('replying a string: ' + res_obj);\n        res.writeHead(200, {'Content-Type': 'text/plain'});                     \n        res.end(res_obj);            \n    }\n    else {\n        LOG.sys('replying a JSON: ' + JSON.stringify(res_obj));\n        res.writeHead(200, {'Content-Type': 'application/json'});                     \n        res.end(JSON.stringify(res_obj));        \n    }\n}", "label": 3}
{"code": "private function validatePlugins()\n    {\n        foreach (self::$cache['plugins'] as $plugin_file => $plugin_info) {\n            if (!file_exists(WPMU_PLUGIN_DIR . '/' . $plugin_file)) {\n                $this->updateCache();\n                break;\n            }\n        }\n    }", "label": 2}
{"code": "function(opt_syncRateSeconds, callback) {\n      var query = misc.parseUrlQuery();\n      var url = (query.hftUrl || window.location.href).replace(\"ws:\", \"http:\");\n\n      var syncRateMS = (opt_syncRateSeconds || 10) * 1000;\n      var timeOffset = 0;\n\n      var syncToServer = function(queueNext) {\n        var sendTime = getLocalTime();\n        io.sendJSON(url, {cmd: 'time'}, function(exception, obj) {\n          if (exception) {\n            console.error(\"syncToServer: \" + exception);\n          } else {\n            var receiveTime = getLocalTime();\n            var duration = receiveTime - sendTime;\n            var serverTime = obj.time + duration * 0.5;\n            timeOffset = serverTime - receiveTime;\n            if (callback) {\n              callback();\n              callback = undefined;\n            }\n            //g_services.logger.log(\"duration: \", duration, \" timeOff:\", timeOffset);\n          }\n\n          if (queueNext) {\n            setTimeout(function() {\n              syncToServer(true);\n            }, syncRateMS);\n          }\n        });\n      };\n      var syncToServerNoQueue = function() {\n        syncToServer(false);\n      };\n      syncToServer(true);\n      setTimeout(syncToServerNoQueue, 1000);\n      setTimeout(syncToServerNoQueue, 2000);\n      setTimeout(syncToServerNoQueue, 4000);\n\n      /**\n       * Gets the current time in seconds.\n       * @private\n       */\n      this.getTime = function() {\n        return getLocalTime() + timeOffset;\n      };\n\n    }", "label": 3}
{"code": "function isObject(obj) {\n  const objType = typeof obj;\n  return objType === 'object' && Boolean(obj) && !Array.isArray(obj);\n}", "label": 3}
{"code": "func (k *authKeepAliver) Error() error {\n\tk.RLock()\n\tdefer k.RUnlock()\n\treturn k.err\n}", "label": 5}
{"code": "func (f Filter) MatchProperty(prop types.DynamicProperty) bool {\n\tmatch, ok := f[prop.Name]\n\tif !ok {\n\t\treturn false\n\t}\n\n\tif match == prop.Val {\n\t\treturn true\n\t}\n\n\tptype := reflect.TypeOf(prop.Val)\n\n\tif strings.HasPrefix(ptype.Name(), \"ArrayOf\") {\n\t\tpval := reflect.ValueOf(prop.Val).Field(0)\n\n\t\tfor i := 0; i < pval.Len(); i++ {\n\t\t\tprop.Val = pval.Index(i).Interface()\n\n\t\t\tif f.MatchProperty(prop) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\n\t\treturn false\n\t}\n\n\tif reflect.TypeOf(match) != ptype {\n\t\ts, ok := match.(string)\n\t\tif !ok {\n\t\t\treturn false\n\t\t}\n\n\t\t// convert if we can\n\t\tswitch prop.Val.(type) {\n\t\tcase bool:\n\t\t\tmatch, _ = strconv.ParseBool(s)\n\t\tcase int16:\n\t\t\tx, _ := strconv.ParseInt(s, 10, 16)\n\t\t\tmatch = int16(x)\n\t\tcase int32:\n\t\t\tx, _ := strconv.ParseInt(s, 10, 32)\n\t\t\tmatch = int32(x)\n\t\tcase int64:\n\t\t\tmatch, _ = strconv.ParseInt(s, 10, 64)\n\t\tcase float32:\n\t\t\tx, _ := strconv.ParseFloat(s, 32)\n\t\t\tmatch = float32(x)\n\t\tcase float64:\n\t\t\tmatch, _ = strconv.ParseFloat(s, 64)\n\t\tcase fmt.Stringer:\n\t\t\tprop.Val = prop.Val.(fmt.Stringer).String()\n\t\tdefault:\n\t\t\tif ptype.Kind() != reflect.String {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t// An enum type we can convert to a string type\n\t\t\tprop.Val = reflect.ValueOf(prop.Val).String()\n\t\t}\n\t}\n\n\tswitch pval := prop.Val.(type) {\n\tcase string:\n\t\ts := match.(string)\n\t\tif s == \"*\" {\n\t\t\treturn true // TODO: path.Match fails if s contains a '/'\n\t\t}\n\t\tm, _ := path.Match(s, pval)\n\t\treturn m\n\tdefault:\n\t\treturn reflect.DeepEqual(match, pval)\n\t}\n}", "label": 5}
{"code": "function saveAuditLogEntryAndUpdateDataSource(params, callback) {\n  var cacheElement = params.cacheElement;\n  var dataSourceDocument = params.dataSourceDocument;\n  var dataSourceData = params.dataSourceData;\n\n  async.waterfall([\n    function saveAuditLog(cb) {\n      //An Audit Log Entry Is Based On The Cache Update Entry.\n      var auditLogEntry = cacheElement.toJSON();\n      //Adding Service Details To The Audit Log Entry\n      _.extend(auditLogEntry, _.pick(dataSourceDocument, \"serviceGuid\", \"endpoint\"));\n      //Adding the audit log\n      var AuditLog = models.get(params.connections.mongooseConnection, models.MODELNAMES.DATA_SOURCE_AUDIT_LOG);\n      auditLogEntry.dataSource = dataSourceDocument._id;\n\n      var auditLogToSave = new AuditLog(auditLogEntry);\n\n      auditLogToSave.save(function(err, savedAuditLog) {\n        if (err) {\n          return cb(err);\n        }\n        dataSourceDocument.auditLogs.push(savedAuditLog);\n\n        return cb();\n      });\n    },\n    function saveDataSource(cb) {\n\n      //Having Attempted To Save, the updated data source has to be validated again to clear old validation errors before trying to save again.\n      dataSourceDocument.validate(function() {\n        //Data Source Data Is Now valid, can save it - whether it is in an error state or not.\n        dataSourceDocument.save(function(err) {\n          if (err) {\n            dataSourceData.error = buildErrorResponse({\n              error: err,\n              userDetail: \"Unexpected Error When Saving Data Source Data\",\n              code: ERROR_CODES.FH_FORMS_UNEXPECTED_ERROR\n            });\n\n            logger.error(\"Error Updating Data Source \", {error: dataSourceData.error, dataSourceDocument: dataSourceDocument, cache: dataSourceDocument.cache[0]});\n\n            //Not interested in the document if the save is invalid\n            dataSourceData = _.omit(dataSourceData, 'document');\n\n            return cb(undefined, dataSourceData);\n          }\n\n          logger.debug(\"updateDataSourceEntry: Finished Updating Data Source\", dataSourceDocument);\n\n          //Save Was Successful, return updated document\n          dataSourceData.document = dataSourceDocument;\n\n          return cb(undefined, dataSourceData);\n        });\n      });\n\n    }\n  ], callback);\n}", "label": 3}
{"code": "def color_floodfill(x, y, fill)\n      target = pixel_color(x, y)\n      color_flood_fill(target, fill, x, y, Magick::FloodfillMethod)\n    end", "label": 4}
{"code": "@SuppressWarnings(\"unchecked\")\n\tpublic static Type getSuperclassTypeParameter(Class<?> subclass) {\n\t\tType superclass = subclass.getGenericSuperclass();\n\t\tif (superclass instanceof Class) {\n\t\t\tthrow new RuntimeException(\"Missing type parameter.\");\n\t\t}\n\t\treturn ((ParameterizedType) superclass).getActualTypeArguments()[0];\n\t}", "label": 0}
{"code": "func (tl TypeLoader) LoadIndexes(args *ArgType, tableMap map[string]*Type) (map[string]*Index, error) {\n\tvar err error\n\n\tixMap := map[string]*Index{}\n\tfor _, t := range tableMap {\n\t\t// load table indexes\n\t\terr = tl.LoadTableIndexes(args, t, ixMap)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// generate templates\n\tfor _, ix := range ixMap {\n\t\terr = args.ExecuteTemplate(IndexTemplate, ix.Type.Name, ix.Index.IndexName, ix)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn ixMap, nil\n}", "label": 5}
{"code": "func (a *HistoricalApi) nodeAggregations(request *restful.Request, response *restful.Response) {\n\tkey := core.HistoricalKey{\n\t\tObjectType: core.MetricSetTypeNode,\n\t\tNodeName:   request.PathParameter(\"node-name\"),\n\t}\n\ta.processAggregationRequest(key, request, response)\n}", "label": 5}
{"code": "public void addWord(MtasCQLParserWordFullCondition w) throws ParseException {\n    assert w.getCondition()\n        .not() == false : \"condition word should be positive in sentence definition\";\n    if (!simplified) {\n      partList.add(w);\n    } else {\n      throw new ParseException(\"already simplified\");\n    }\n  }", "label": 0}
{"code": "def model_to_dict(instance, **options):\n    \"Takes a model instance and converts it into a dict.\"\n\n    options = _defaults(options)\n    attrs = {}\n\n    if options['prehook']:\n        if isinstance(options['prehook'], collections.Callable):\n            instance = options['prehook'](instance)\n            if instance is None:\n                return attrs\n\n    # Items in the `fields` list are the output aliases, not the raw\n    # accessors (field, method, property names)\n    for alias in options['fields']:\n\n        # Get the accessor for the object\n        accessor = options['aliases'].get(alias, alias)\n\n        # Create the key that will be used in the output dict\n        key = options['prefix'] + alias\n\n        # Optionally camelcase the key\n        if options['camelcase']:\n            key = convert_to_camel(key)\n\n        # Get the field value. Use the mapped value to the actually property or\n        # method name. `value` may be a number of things, so the various types\n        # are checked below.\n        value = get_field_value(instance, accessor,\n                                allow_missing=options['allow_missing'])\n\n        # Related objects, perform some checks on their options\n        if isinstance(value, (models.Model, QuerySet)):\n            _options = _defaults(options['related'].get(accessor, {}))\n\n            # If the `prefix` follows the below template, generate the\n            # `prefix` for the related object\n            if '%(accessor)s' in _options['prefix']:\n                _options['prefix'] = _options['prefix'] % {'accessor': alias}\n\n            if isinstance(value, models.Model):\n                if len(_options['fields']) == 1 and _options['flat'] \\\n                        and not _options['merge']:\n                    value = list(serialize(value, **_options).values())[0]\n                else:\n                    # Recurse, get the dict representation\n                    _attrs = serialize(value, **_options)\n\n                    # Check if this object should be merged into the parent,\n                    # otherwise nest it under the accessor name\n                    if _options['merge']:\n                        attrs.update(_attrs)\n                        continue\n\n                    value = _attrs\n            else:\n                value = serialize(value, **_options)\n\n        attrs[key] = value\n\n    # Apply post-hook to serialized attributes\n    if options['posthook']:\n        attrs = options['posthook'](instance, attrs)\n\n    return attrs", "label": 1}
{"code": "function () {\n            if (this._content) {\n                var error = new gpf.Error.InvalidCSV();\n                this._setReadError(error);\n                return Promise.reject(error);\n            }\n            this._completeReadBuffer();\n            return Promise.resolve();\n        }", "label": 3}
{"code": "def send_offsets_to_transaction(batch:, group_id:)\n      @transaction_manager.send_offsets_to_txn(offsets: { batch.topic => { batch.partition => { offset: batch.last_offset + 1, leader_epoch: batch.leader_epoch } } }, group_id: group_id)\n    end", "label": 4}
{"code": "public void forAllIndexDescriptorColumns(String template, Properties attributes) throws XDocletException\r\n    {\r\n        String             fields = _curIndexDescriptorDef.getProperty(PropertyHelper.OJB_PROPERTY_FIELDS);\r\n        FieldDescriptorDef fieldDef;\r\n        String             name;\r\n\r\n        for (CommaListIterator it = new CommaListIterator(fields); it.hasNext();)\r\n        {\r\n            name     = it.getNext();\r\n            fieldDef = _curClassDef.getField(name);\r\n            if (fieldDef == null)\r\n            {\r\n                throw new XDocletException(Translator.getString(XDocletModulesOjbMessages.class,\r\n                                           XDocletModulesOjbMessages.INDEX_FIELD_MISSING,\r\n                                           new String[]{name, _curIndexDescriptorDef.getName(), _curClassDef.getName()}));\r\n            }\r\n            _curIndexColumn = fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_COLUMN);\r\n            generate(template);\r\n        }\r\n        _curIndexColumn = null;\r\n    }", "label": 0}
{"code": "public function stream_stat()\n    {\n        $mode = $this->stream->isWritable()\n            ? self::FILE_WRITABLE_MODE\n            : self::FILE_READABLE_MODE;\n        return $this->makeStatArray([\n            'mode'    => $mode,\n            'size'    => $this->stream->getSize()\n        ]);\n    }", "label": 2}
{"code": "public void addRoute(String path, Class<? extends Actor> actorClass) throws RouteAlreadyMappedException {\n        addRoute(new Route(path, false), actorClass);\n    }", "label": 0}
{"code": "public function close($reply_code = 0, $reply_text = '', $method_sig = array(0, 0))\n    {\n        $result = null;\n        $this->io->disableHeartbeat();\n        if (empty($this->protocolWriter) || !$this->isConnected()) {\n            return $result;\n        }\n\n        try {\n            $this->closeChannels();\n            list($class_id, $method_id, $args) = $this->protocolWriter->connectionClose(\n                $reply_code,\n                $reply_text,\n                $method_sig[0],\n                $method_sig[1]\n            );\n            $this->send_method_frame(array($class_id, $method_id), $args);\n            $result = $this->wait(\n                array($this->waitHelper->get_wait('connection.close_ok')),\n                false,\n                $this->connection_timeout\n            );\n        } catch (\\Exception $exception) {\n            $this->do_close();\n            throw $exception;\n        }\n\n        $this->setIsConnected(false);\n\n        return $result;\n    }", "label": 2}
{"code": "public void bind(Object object, String name)\r\n            throws ObjectNameNotUniqueException\r\n    {\r\n        /**\r\n         * Is DB open? ODMG 3.0 says it has to be to call bind.\r\n         */\r\n        if (!this.isOpen())\r\n        {\r\n            throw new DatabaseClosedException(\"Database is not open. Must have an open DB to call bind.\");\r\n        }\r\n        /**\r\n         * Is Tx open? ODMG 3.0 says it has to be to call bind.\r\n         */\r\n        TransactionImpl tx = getTransaction();\r\n        if (tx == null || !tx.isOpen())\r\n        {\r\n            throw new TransactionNotInProgressException(\"Tx is not open. Must have an open TX to call bind.\");\r\n        }\r\n\r\n        tx.getNamedRootsMap().bind(object, name);\r\n    }", "label": 0}
{"code": "protected function convertNamedTypeNode(NamedTypeNode $node): Type\n    {\n        $nodeName = $node->name->value;\n        switch ($nodeName) {\n            case 'ID':\n                return Type::id();\n            case 'Int':\n                return Type::int();\n            case 'Boolean':\n                return Type::boolean();\n            case 'Float':\n                return Type::float();\n            case 'String':\n                return Type::string();\n            default:\n                return $this->typeRegistry->get($nodeName);\n        }\n    }", "label": 2}
{"code": "public function beginTransaction($transactionOptions, array $options = [])\n    {\n        $res = $this->connection->beginTransaction([\n            'projectId' => $this->projectId,\n            'transactionOptions' => $transactionOptions\n        ] + $options);\n\n        return $res['transaction'];\n    }", "label": 2}
{"code": "def generate_content\n      content = \"\"\n\n      if @issues.any?\n        content += \"#{@prefix}\\n\\n\" unless @options[:simple_list] || @prefix.blank?\n        @issues.each do |issue|\n          merge_string = get_string_for_issue(issue)\n          content += \"- \" unless @body_only\n          content += \"#{merge_string}\\n\"\n        end\n        content += \"\\n\"\n      end\n      content\n    end", "label": 4}
{"code": "def autodoc_skip_member_handler(app, what, name, obj, skip, options):\n    \"\"\"\n    Skip un parseable functions.\n\n    :type app: sphinx.application.Sphinx\n    :param str what: the type of the object which the docstring belongs to\n        (one of \"module\", \"class\", \"exception\", \"function\", \"method\", \"attribute\")\n    :param str name: the fully qualified name of the object\n    :param type obj: the object itself\n    :param bool skip: a boolean indicating if autodoc will skip this member\n    :param sphinx.ext.autodoc.Options options: the options given to the directive\n    :rtype: bool\n    \"\"\"\n    if 'YAMLTokens' in name:\n        return True\n    return False", "label": 1}
{"code": "def ctr_geom(geom, masses):\n    \"\"\" Returns geometry shifted to center of mass.\n\n    Helper function to automate / encapsulate translation of a geometry to its\n    center of mass.\n\n    Parameters\n    ----------\n    geom\n        length-3N |npfloat_| --\n        Original coordinates of the atoms\n\n    masses\n        length-N OR length-3N |npfloat_| --\n        Atomic masses of the atoms. Length-3N option is to allow calculation of\n        a per-coordinate perturbed value.\n\n    Returns\n    -------\n    ctr_geom\n        length-3N |npfloat_| --\n        Atomic coordinates after shift to center of mass\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If shapes of `geom` & `masses` are inconsistent\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Calculate the shift vector. Possible bad shape of geom or masses is\n    #  addressed internally by the ctr_mass call.\n    shift = np.tile(ctr_mass(geom, masses), geom.shape[0] / 3)\n\n    # Shift the geometry and return\n    ctr_geom = geom - shift\n    return ctr_geom", "label": 1}
{"code": "@SuppressWarnings(\"deprecation\")\n\tpublic static boolean dateTimeEquals(java.util.Date d1, java.util.Date d2) {\n        if (d1 == null || d2 == null) {\n            return false;\n        }\n\n        return d1.getDate() == d2.getDate()\n                && d1.getMonth() == d2.getMonth()\n                && d1.getYear() == d2.getYear()\n                && d1.getHours() == d2.getHours()\n                && d1.getMinutes() == d2.getMinutes()\n                && d1.getSeconds() == d2.getSeconds();\n    }", "label": 0}
{"code": "def userdata_to_db(session, method='update', autocommit=False):\n    \"\"\"\n    Add catchments from a user folder to the database.\n\n    The user folder is specified in the ``config.ini`` file like this::\n\n        [import]\n        folder = path/to/import/folder\n\n    If this configuration key does not exist this will be silently ignored.\n\n    :param session: database session to use, typically `floodestimation.db.Session()`\n    :type session: :class:`sqlalchemy.orm.session.Session`\n    :param method: - ``create``: only new catchments will be loaded, it must not already exist in the database.\n                   - ``update``: any existing catchment in the database will be updated. Otherwise it will be created.\n    :type method: str\n    :param autocommit: Whether to commit the database session immediately. Default: ``False``.\n    :type autocommit: bool\n    \"\"\"\n\n    try:\n        folder = config['import']['folder']\n    except KeyError:\n        return\n    if folder:\n        folder_to_db(folder, session, method=method, autocommit=autocommit)", "label": 1}
{"code": "function copy(o) {\n  expect(arguments).to.have.length(\n    1,\n    'Invalid argument length when copying an object (it has to be passed ' +\n    '1 argument)'\n  );\n\n  expect(o).to.be.an(\n    'object',\n    'Invalid argument \"o\" when copying an object (it has to be an object)'\n  );\n\n  var oCopy = {};\n\n  for (var property in o) {\n    oCopy[property] = o[property];\n  }\n\n  return oCopy;\n}", "label": 3}
{"code": "def user_group_select_field(form, name)\n      form.select(name,\n                  current_user.user_groups.verified.map { |g| [g.name, g.id] },\n                  selected: form.object.user_group_id.presence,\n                  include_blank: current_user.name,\n                  label: t(\"new.amendment_author\", scope: \"decidim.amendments\"))\n    end", "label": 4}
{"code": "def profile_distribution(data):\n    \"\"\"\n    Compute the mean, standard deviation, min, quartile1, quartile2, quartile3, and max of a vector\n\n    Parameters\n    ----------\n    data: array of real values\n\n    Returns\n    -------\n    features = dictionary containing the min, max, mean, and standard deviation\n    \"\"\"\n    if len(data) == 0:\n        return (data, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n    else:\n        ddof = 1 if len(data) > 1 else 0\n        dist_mean = np.mean(data)\n        dist_stdev = np.std(data, ddof=ddof)\n        dist_min, dist_quartile1, dist_quartile2, dist_quartile3, dist_max = np.percentile(data, [0,25,50,75,100])\n        dist_skew = skew(data)\n        dist_kurtosis = kurtosis(data)\n    return (data, dist_mean, dist_stdev, dist_skew, dist_kurtosis, dist_min, dist_quartile1, dist_quartile2, dist_quartile3, dist_max)", "label": 1}
{"code": "function updatePositions(elements) {\n  if (!audioReady)\n    return;\n\n  for (let i = 0; i < elements.length; i++) {\n    let x = (elements[i].x - 0.5) * dimensions.width / 2;\n    let y = 0;\n    let z = (elements[i].y - 0.5) * dimensions.depth / 2;\n    if (i == 0) {\n      pannerNode.setPosition(x, y, z);\n      foaSource.setPosition(x, y, z);\n      toaSource.setPosition(x, y, z);\n    } else {\n      audioContext.listener.setPosition(x, y, z);\n      foaScene.setListenerPosition(x, y, z);\n      toaScene.setListenerPosition(x, y, z);\n    }\n  }\n}", "label": 3}
{"code": "public void clear()\r\n    {\r\n        Class collClass = getCollectionClass();\r\n\r\n        // ECER: assure we notify all objects being removed, \r\n        // necessary for RemovalAwareCollections...\r\n        if (IRemovalAwareCollection.class.isAssignableFrom(collClass))\r\n        {\r\n            getData().clear();\r\n        }\r\n        else\r\n        {\r\n            Collection coll;\r\n            // BRJ: use an empty collection so isLoaded will return true\r\n            // for non RemovalAwareCollections only !! \r\n            try\r\n            {\r\n                coll = (Collection) collClass.newInstance();\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                coll = new ArrayList();\r\n            }\r\n\r\n            setData(coll);\r\n        }\r\n        _size = 0;\r\n    }", "label": 0}
{"code": "func (m Manager) EventCategory(ctx context.Context, event types.BaseEvent) (string, error) {\n\t// Most of the event details are included in the Event.FullFormattedMessage, but the category\n\t// is only available via the EventManager description.eventInfo property.  The value of this\n\t// property is static, so we fetch and once and cache.\n\teventCategory, err := m.eventCategoryMap(ctx)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tswitch e := event.(type) {\n\tcase *types.EventEx:\n\t\tif e.Severity == \"\" {\n\t\t\treturn \"info\", nil\n\t\t}\n\t\treturn e.Severity, nil\n\t}\n\n\tclass := reflect.TypeOf(event).Elem().Name()\n\n\treturn eventCategory[class], nil\n}", "label": 5}
{"code": "def is_symlink(path):\n\t\"\"\"\n\tAssuming path is a reparse point, determine if it's a symlink.\n\t\"\"\"\n\tpath = _patch_path(path)\n\ttry:\n\t\treturn _is_symlink(next(find_files(path)))\n\t# comment below workaround for PyCQA/pyflakes#376\n\texcept WindowsError as orig_error:  # noqa: F841\n\t\ttmpl = \"Error accessing {path}: {orig_error.message}\"\n\t\traise builtins.WindowsError(tmpl.format(**locals()))", "label": 1}
{"code": "def content(self):\n        \"\"\"\n        Return parsed data. Parse it if not already parsed.\n\n        Returns:\n            list: list of dictionaries (one for each parsed line).\n        \"\"\"\n        if self._content is None:\n            self._content = self.parse_files()\n        return self._content", "label": 1}
{"code": "func (config *configuration) processIPAM(id string, ipamV4Data, ipamV6Data []driverapi.IPAMData) error {\n\tif len(ipamV4Data) > 0 {\n\t\tfor _, ipd := range ipamV4Data {\n\t\t\ts := &ipv4Subnet{\n\t\t\t\tSubnetIP: ipd.Pool.String(),\n\t\t\t\tGwIP:     ipd.Gateway.String(),\n\t\t\t}\n\t\t\tconfig.Ipv4Subnets = append(config.Ipv4Subnets, s)\n\t\t}\n\t}\n\tif len(ipamV6Data) > 0 {\n\t\tfor _, ipd := range ipamV6Data {\n\t\t\ts := &ipv6Subnet{\n\t\t\t\tSubnetIP: ipd.Pool.String(),\n\t\t\t\tGwIP:     ipd.Gateway.String(),\n\t\t\t}\n\t\t\tconfig.Ipv6Subnets = append(config.Ipv6Subnets, s)\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func GetAllACIInfos(tx *sql.Tx, sortfields []string, ascending bool) ([]*ACIInfo, error) {\n\tvar aciinfos []*ACIInfo\n\tquery := \"SELECT * from aciinfo\"\n\tif len(sortfields) > 0 {\n\t\tquery += fmt.Sprintf(\" ORDER BY %s \", strings.Join(sortfields, \", \"))\n\t\tif ascending {\n\t\t\tquery += \"ASC\"\n\t\t} else {\n\t\t\tquery += \"DESC\"\n\t\t}\n\t}\n\trows, err := tx.Query(query)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer rows.Close()\n\tfor rows.Next() {\n\t\taciinfo := &ACIInfo{}\n\t\tif err := aciinfoRowScan(rows, aciinfo); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\taciinfos = append(aciinfos, aciinfo)\n\t}\n\tif err := rows.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn aciinfos, err\n}", "label": 5}
{"code": "def update_page_cell(location_id, page_id, body, opts = {})\n      data, _status_code, _headers = update_page_cell_with_http_info(location_id, page_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "def renew_self(increment = 0, options = {})\n      headers = extract_headers!(options)\n      json = client.put(\"/v1/auth/token/renew-self\", JSON.fast_generate(\n        increment: increment,\n      ), headers)\n      return Secret.decode(json)\n    end", "label": 4}
{"code": "def sorted_users\n      users = []\n      ::User.find_each do |user|\n        users.push(UserRecord.new(user.id, user.user_key, date_since_last_cache(user)))\n      end\n      users.sort_by(&:last_stats_update)\n    end", "label": 4}
{"code": "def fetch(self, remote='origin'):\n        \"\"\"fetch from a remote\"\"\"\n        git(self.gitdir, \"fetch\", remote, _env=self.env())", "label": 1}
{"code": "def create(cls, user_id, client_id, extra_data):\n        \"\"\"Create new remote account for user.\n\n        :param user_id: User id.\n        :param client_id: Client id.\n        :param extra_data: JSON-serializable dictionary of any extra data that\n            needs to be save together with this link.\n        :returns: A :class:`invenio_oauthclient.models.RemoteAccount` instance.\n        \"\"\"\n        with db.session.begin_nested():\n            account = cls(\n                user_id=user_id,\n                client_id=client_id,\n                extra_data=extra_data or dict()\n            )\n            db.session.add(account)\n        return account", "label": 1}
{"code": "def member(id, request = true)\n      id = id.resolve_id\n      return @members[id] if member_cached?(id)\n      return nil unless request\n\n      member = @bot.member(self, id)\n      @members[id] = member unless member.nil?\n    rescue StandardError\n      nil\n    end", "label": 4}
{"code": "private static String buildErrorMsg(List<String> dependencies, String message) {\n        final StringBuilder buffer = new StringBuilder();\n        boolean isFirstElement = true;\n        for (String dependency : dependencies) {\n            if (!isFirstElement) {\n                buffer.append(\", \");\n            }\n            // check if it is an instance of Artifact - add the gavc else append the object\n            buffer.append(dependency);\n\n            isFirstElement = false;\n        }\n        return String.format(message, buffer.toString());\n    }", "label": 0}
{"code": "func Lgetxattr(path string, attr string) ([]byte, error) {\n\tpathBytes, err := syscall.BytePtrFromString(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tattrBytes, err := syscall.BytePtrFromString(attr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdest := make([]byte, 128)\n\tdestBytes := unsafe.Pointer(&dest[0])\n\tsz, _, errno := syscall.Syscall6(syscall.SYS_LGETXATTR, uintptr(unsafe.Pointer(pathBytes)), uintptr(unsafe.Pointer(attrBytes)), uintptr(destBytes), uintptr(len(dest)), 0, 0)\n\tif errno == syscall.ENODATA {\n\t\treturn nil, nil\n\t}\n\tif errno == syscall.ERANGE {\n\t\tdest = make([]byte, sz)\n\t\tdestBytes := unsafe.Pointer(&dest[0])\n\t\tsz, _, errno = syscall.Syscall6(syscall.SYS_LGETXATTR, uintptr(unsafe.Pointer(pathBytes)), uintptr(unsafe.Pointer(attrBytes)), uintptr(destBytes), uintptr(len(dest)), 0, 0)\n\t}\n\tif errno != 0 {\n\t\treturn nil, errno\n\t}\n\n\treturn dest[:sz], nil\n}", "label": 5}
{"code": "def _fadn_orth(vec, geom):\n    \"\"\"First non-zero Atomic Displacement Non-Orthogonal to Vec\n\n    Utility function to identify the first atomic displacement in a geometry\n    that is (a) not the zero vector; and (b) not normal to the reference vector.\n\n    Parameters\n    ----------\n    vec\n        length-3 |npfloat_| --\n        Reference vector. Does not need to be normalized.\n\n    geom\n        length-3N |npfloat_| --\n        *CENTERED* molecular geometry\n\n    Returns\n    -------\n    out_vec\n        length-3 |npfloat_| --\n        Normalized non-zero atomic displacement not orthogonal to vec\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n    from ..const import PRM\n    from ..error import InertiaError\n    from .vector import orthonorm_check as onchk\n\n    # Geom and vec must both be the right shape\n    if not (len(geom.shape) == 1 and geom.shape[0] % 3 == 0):\n        raise ValueError(\"Geometry is not length 3N\")\n    ## end if\n    if not vec.shape == (3,):\n        raise ValueError(\"Reference vector is not length 3\")\n    ## end if\n\n    # vec must not be the zero vector\n    if spla.norm(vec) < PRM.ZERO_VEC_TOL:\n        raise ValueError(\"Reference vector norm is too small\")\n    ## end if\n\n    # Normalize the ref vec\n    vec = vec / spla.norm(vec)\n\n    # Iterate over reshaped geometry\n    for disp in geom.reshape((geom.shape[0]//3, 3)):\n        # See if the displacement is nonzero and not orthonormal. Trailing\n        #  [0] index is to retrieve only the success/fail bool.\n        if spla.norm(disp) >= PRM.ZERO_VEC_TOL and not onchk(\n                np.column_stack((disp / spla.norm(disp),\n                vec / spla.norm(vec))))[0]:\n            # This is the displacement you are looking for\n            out_vec = disp / spla.norm(disp)\n            return out_vec\n            ## end if\n        ## end if\n    ## next disp\n    else:\n        # Nothing fit the bill - must be atom, linear, or planar\n        raise InertiaError(InertiaError.BAD_GEOM,\n                    \"No suitable atomic displacement found\", \"\")", "label": 1}
{"code": "def compute_file_metrics(processors, language, key, token_list):\n    \"\"\"use processors to compute file metrics.\"\"\"\n    # multiply iterator\n    tli = itertools.tee(token_list, len(processors))\n    metrics = OrderedDict()\n\n    # reset all processors\n    for p in processors:\n        p.reset()\n\n    # process all tokens\n    for p, tl in zip(processors, tli):\n        p.process_file(language, key, tl)\n\n    # collect metrics from all processors\n    for p in processors:\n        metrics.update(p.metrics)\n\n    return metrics", "label": 1}
{"code": "function iterate(list, iterator, state, callback)\n{\n  // store current index\n  var key = state['keyedList'] ? state['keyedList'][state.index] : state.index;\n\n  state.jobs[key] = runJob(iterator, key, list[key], function(error, output)\n  {\n    // don't repeat yourself\n    // skip secondary callbacks\n    if (!(key in state.jobs))\n    {\n      return;\n    }\n\n    // clean up jobs\n    delete state.jobs[key];\n\n    if (error)\n    {\n      // don't process rest of the results\n      // stop still active jobs\n      // and reset the list\n      abort(state);\n    }\n    else\n    {\n      state.results[key] = output;\n    }\n\n    // return salvaged results\n    callback(error, state.results);\n  });\n}", "label": 3}
{"code": "func (u *UUID) SetVariant(v byte) {\n\tswitch v {\n\tcase VariantNCS:\n\t\tu[8] = (u[8]&(0xff>>1) | (0x00 << 7))\n\tcase VariantRFC4122:\n\t\tu[8] = (u[8]&(0xff>>2) | (0x02 << 6))\n\tcase VariantMicrosoft:\n\t\tu[8] = (u[8]&(0xff>>3) | (0x06 << 5))\n\tcase VariantFuture:\n\t\tfallthrough\n\tdefault:\n\t\tu[8] = (u[8]&(0xff>>3) | (0x07 << 5))\n\t}\n}", "label": 5}
{"code": "def wget(ftp, f = False, exclude = False, name = False, md5 = False, tries = 10):\n    \"\"\"\n    download files with wget\n    \"\"\"\n    # file name\n    if f is False:\n        f = ftp.rsplit('/', 1)[-1]\n    # downloaded file if it does not already exist\n    # check md5s on server (optional)\n    t = 0\n    while md5check(f, ftp, md5, exclude) is not True:\n        t += 1\n        if name is not False:\n            print('# downloading:', name, f)\n        if exclude is False:\n            command = 'wget -q --random-wait %s' % (ftp)\n        else:\n            command = 'wget -q --random-wait -R %s %s' % (exclude, ftp)\n        p = Popen(command, shell = True)\n        p.communicate()\n        if t >= tries:\n            print('not downloaded:', name, f)\n            return [f, False]\n    return [f, True]", "label": 1}
{"code": "func (s *PresenceService) CreateRemoteCluster(rc services.RemoteCluster) error {\n\tvalue, err := json.Marshal(rc)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\titem := backend.Item{\n\t\tKey:     backend.Key(remoteClustersPrefix, rc.GetName()),\n\t\tValue:   value,\n\t\tExpires: rc.Expiry(),\n\t}\n\t_, err = s.Create(context.TODO(), item)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "protected function removeMiddlewareFromApp()\n    {\n        if ($this->middlewareRemoved) {\n            return;\n        }\n\n        $this->middlewareRemoved = true;\n\n        $reflection = new ReflectionClass($this->app);\n        $property = $reflection->getProperty('middleware');\n        $property->setAccessible(true);\n        $oldMiddlewares = $property->getValue($this->app);\n        $newMiddlewares = [];\n        foreach ($oldMiddlewares as $middle) {\n            if ((new ReflectionClass($middle))->hasMethod('terminate') && $middle != 'Dingo\\Api\\Http\\Middleware\\Request') {\n                $newMiddlewares = array_merge($newMiddlewares, [$middle]);\n            }\n        }\n        $property->setValue($this->app, $newMiddlewares);\n        $property->setAccessible(false);\n    }", "label": 2}
{"code": "protected void appendWhereClause(FieldDescriptor[] fields, StringBuffer stmt) throws PersistenceBrokerException\r\n    {\r\n        stmt.append(\" WHERE \");\r\n\r\n        for(int i = 0; i < fields.length; i++)\r\n        {\r\n            FieldDescriptor fmd = fields[i];\r\n\r\n            stmt.append(fmd.getColumnName());\r\n            stmt.append(\" = ? \");\r\n            if(i < fields.length - 1)\r\n            {\r\n                stmt.append(\" AND \");\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public function setChannelDescriptors($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Monitoring\\V3\\NotificationChannelDescriptor::class);\n        $this->channel_descriptors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *crontime) nextValidHour(baseTime time.Time) {\n\tfor _, hour := range c.hour {\n\t\tif c.calculatedTime.Day() == baseTime.Day() {\n\t\t\tif !hasPassed(hour, c.calculatedTime.Hour()) {\n\t\t\t\tc.calculatedTime = setHour(c.calculatedTime, hour)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else {\n\t\t\tc.calculatedTime = setHour(c.calculatedTime, hour)\n\t\t\treturn\n\t\t}\n\t}\n\t// If no result was found try it again in the following day.\n\tc.calculatedTime = c.calculatedTime.AddDate(0, 0, 1)    // <-|\n\tc.calculatedTime = setHour(c.calculatedTime, c.hour[0]) //   |\n\t//log.Println(\"Cronbee: Hour\", c.calculatedTime, baseTime) // |\n\tc.nextValidMonth(baseTime) // May trigger a new month --------|\n\tc.nextValidDay(baseTime)\n\tc.nextValidHour(baseTime)\n}", "label": 5}
{"code": "def fragment=(new_fragment)\n      if new_fragment && !new_fragment.respond_to?(:to_str)\n        raise TypeError, \"Can't convert #{new_fragment.class} into String.\"\n      end\n      @fragment = new_fragment ? new_fragment.to_str : nil\n\n      # Reset dependent values\n      remove_instance_variable(:@normalized_fragment) if defined?(@normalized_fragment)\n      remove_composite_values\n\n      # Ensure we haven't created an invalid URI\n      validate()\n    end", "label": 4}
{"code": "def set_preferred_prefix_for_namespace(self, ns_uri, prefix, add_if_not_exist=False):\n        \"\"\"Sets the preferred prefix for ns_uri.  If add_if_not_exist is True,\n        the prefix is added if it's not already registered.  Otherwise,\n        setting an unknown prefix as preferred is an error.  The default\n        is False.  Setting to None always works, and indicates a preference\n        to use the namespace as a default.  The given namespace must already\n        be in this set.\n\n        Args:\n            ns_uri (str): the namespace URI whose prefix is to be set\n            prefix (str): the preferred prefix to set\n            add_if_not_exist (bool): Whether to add the prefix if it is not\n                already set as a prefix of ``ns_uri``.\n\n        Raises:\n            NamespaceNotFoundError: If namespace ``ns_uri`` isn't in this set.\n            DuplicatePrefixError: If ``prefix`` already maps to a different\n                namespace.\n        \"\"\"\n        ni = self.__lookup_uri(ns_uri)\n\n        if not prefix:\n            ni.preferred_prefix = None\n        elif prefix in ni.prefixes:\n            ni.preferred_prefix = prefix\n        elif add_if_not_exist:\n            self.add_prefix(ns_uri, prefix, set_as_preferred=True)\n        else:\n            raise PrefixNotFoundError(prefix)", "label": 1}
{"code": "def _get_links(self,):\n        \"\"\" \n        return the list of links of a node\n        \"\"\"\n        res = ''\n        if self.links:\n            for l in self.links:\n                res += ' links = ' + str(l[0]) + '\\n'\n                if l[0].child_nodes:\n                    for chld in l[0].child_nodes:\n                        res += '   child = ' + str(chld) + '\\n'\n                if l[0].links:\n                    for lnk in l[0].links:\n                        res += '   sublink = ' + str(lnk[0]) + '\\n'\n        else:\n            res += ' links = None\\n'\n            \n        return res", "label": 1}
{"code": "func (s *Service) Dispatch(request []byte) []byte {\n\tmsg := bytes.SplitN(request, []byte{' '}, 2)\n\tname := msg[0]\n\n\t// Trim NULL byte terminator\n\tname = bytes.TrimRight(name, \"\\x00\")\n\n\thandler, ok := s.handlers[string(name)]\n\n\tif !ok {\n\t\tlog.Printf(\"unknown command: %q\\n\", name)\n\t\treturn []byte(\"Unknown Command\")\n\t}\n\n\tvar args []byte\n\tif len(msg) == 2 {\n\t\targs = msg[1]\n\t}\n\n\tresponse, err := handler(args)\n\tif err == nil {\n\t\tresponse = append([]byte(\"OK \"), response...)\n\t} else {\n\t\tlog.Printf(\"error calling %s: %s\\n\", name, err)\n\t\tresponse = append([]byte(\"ERR \"), response...)\n\t}\n\n\treturn response\n}", "label": 5}
{"code": "public function sendGroupsParticipantsRemove($groupId, $participant)\n    {\n        $msgId = $this->createMsgId();\n        $this->sendGroupsChangeParticipants($groupId, $participant, 'remove', $msgId);\n    }", "label": 2}
{"code": "protected function queue_declare_ok($reader)\n    {\n        $queue = $reader->read_shortstr();\n        $message_count = $reader->read_long();\n        $consumer_count = $reader->read_long();\n\n        return array($queue, $message_count, $consumer_count);\n    }", "label": 2}
{"code": "def determine_template(options)\n        keys = options.has_key?(:locals) ? options[:locals].keys : []\n\n        if options.key?(:body)\n          Template::Text.new(options[:body])\n        elsif options.key?(:plain)\n          Template::Text.new(options[:plain])\n        elsif options.key?(:html)\n          Template::HTML.new(options[:html], formats.first)\n        elsif options.key?(:file)\n          if File.exist?(options[:file])\n            Template::RawFile.new(options[:file])\n          else\n            ActiveSupport::Deprecation.warn \"render file: should be given the absolute path to a file\"\n            @lookup_context.with_fallbacks.find_template(options[:file], nil, false, keys, @details)\n          end\n        elsif options.key?(:inline)\n          handler = Template.handler_for_extension(options[:type] || \"erb\")\n          format = if handler.respond_to?(:default_format)\n            handler.default_format\n          else\n            @lookup_context.formats.first\n          end\n          Template::Inline.new(options[:inline], \"inline template\", handler, locals: keys, format: format)\n        elsif options.key?(:template)\n          if options[:template].respond_to?(:render)\n            options[:template]\n          else\n            @lookup_context.find_template(options[:template], options[:prefixes], false, keys, @details)\n          end\n        else\n          raise ArgumentError, \"You invoked render but did not give any of :partial, :template, :inline, :file, :plain, :html or :body option.\"\n        end\n      end", "label": 4}
{"code": "void unbind(String key)\r\n    {\r\n        NamedEntry entry = new NamedEntry(key, null, false);\r\n        localUnbind(key);\r\n        addForDeletion(entry);\r\n    }", "label": 0}
{"code": "func (f *Fpdf) Writef(h float64, fmtStr string, args ...interface{}) {\n\tf.write(h, sprintf(fmtStr, args...), 0, \"\")\n}", "label": 5}
{"code": "function parseDirectoryEntries(directoryStr) {\n\t\tconst directoryEntries = [];\n\t\tlet pos = 0;\n\t\tlet count = 0;\n\n\t\twhile (directoryStr.length - pos >= 12) {\n\t\t\tdirectoryEntries[count] = directoryStr.substring(pos, pos + 12);\n\t\t\tpos += 12;\n\t\t\tcount++;\n\t\t}\n\n\t\treturn directoryEntries;\n\t}", "label": 3}
{"code": "public static String readContent(InputStream is) {\n    String ret = \"\";\n    try {\n      String line;\n      BufferedReader in = new BufferedReader(new InputStreamReader(is));\n      StringBuffer out = new StringBuffer();\n\n      while ((line = in.readLine()) != null) {\n        out.append(line).append(CARRIAGE_RETURN);\n      }\n      ret = out.toString();\n    } catch (Exception e) {\n      e.printStackTrace();\n    }\n\n    return ret;\n  }", "label": 0}
{"code": "def list2html(lst):\n    \"\"\" \n    convert a list to html using table formatting \n    \"\"\"\n    txt = '<TABLE width=100% border=0>'\n    for l in lst:\n        txt += '<TR>\\n'\n        if type(l) is str:\n            txt+= '<TD>' + l + '</TD>\\n'\n        elif type(l) is list:\n            txt+= '<TD>'\n            for i in l:\n                txt += i + ', '\n            txt+= '</TD>'\n        else:\n            txt+= '<TD>' + str(l) + '</TD>\\n'\n        txt += '</TR>\\n'\n    txt += '</TABLE><BR>\\n'\n    return txt", "label": 1}
{"code": "public static nsappflowparam get(nitro_service service) throws Exception{\n\t\tnsappflowparam obj = new nsappflowparam();\n\t\tnsappflowparam[] response = (nsappflowparam[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "def _fetch_secrets(vault_url, path, token):\n        \"\"\"Read data from the vault path\"\"\"\n        url = _url_joiner(vault_url, 'v1', path)\n        resp = requests.get(url, headers=VaultLoader._get_headers(token))\n        resp.raise_for_status()\n        data = resp.json()\n        if data.get('errors'):\n            raise VaultException(u'Error fetching Vault secrets from path {}: {}'\n                                 .format(path, data['errors']))\n        return data['data']", "label": 1}
{"code": "private void checkOrderby(CollectionDescriptorDef collDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        String orderbySpec = collDef.getProperty(PropertyHelper.OJB_PROPERTY_ORDERBY);\r\n\r\n        if ((orderbySpec == null) || (orderbySpec.length() == 0))\r\n        {\r\n            return;\r\n        }\r\n\r\n        ClassDescriptorDef ownerClass       = (ClassDescriptorDef)collDef.getOwner();\r\n        String             elementClassName = collDef.getProperty(PropertyHelper.OJB_PROPERTY_ELEMENT_CLASS_REF).replace('$', '.');\r\n        ClassDescriptorDef elementClass     = ((ModelDef)ownerClass.getOwner()).getClass(elementClassName);\r\n        FieldDescriptorDef fieldDef;\r\n        String             token;\r\n        String             fieldName;\r\n        String             ordering;\r\n        int                pos;\r\n\r\n        for (CommaListIterator it = new CommaListIterator(orderbySpec); it.hasNext();)\r\n        {\r\n            token = it.getNext();\r\n            pos   = token.indexOf('=');\r\n            if (pos == -1)\r\n            {\r\n                fieldName = token;\r\n                ordering  = null;\r\n            }\r\n            else\r\n            {\r\n                fieldName = token.substring(0, pos);\r\n                ordering  = token.substring(pos + 1);\r\n            }\r\n            fieldDef = elementClass.getField(fieldName);\r\n            if (fieldDef == null)\r\n            {\r\n                throw new ConstraintException(\"The field \"+fieldName+\" specified in the orderby attribute of the collection \"+collDef.getName()+\" in class \"+ownerClass.getName()+\" hasn't been found in the element class \"+elementClass.getName());\r\n            }\r\n            if ((ordering != null) && (ordering.length() > 0) &&\r\n                !\"ASC\".equals(ordering) && !\"DESC\".equals(ordering))\r\n            {\r\n                throw new ConstraintException(\"The ordering \"+ordering+\" specified in the orderby attribute of the collection \"+collDef.getName()+\" in class \"+ownerClass.getName()+\" is invalid\");\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public String get(final long index) {\n        return doWithJedis(new JedisCallable<String>() {\n            @Override\n            public String call(Jedis jedis) {\n                return jedis.lindex(getKey(), index);\n            }\n        });\n    }", "label": 0}
{"code": "func GetOwnCgroupPath(controller string) (string, error) {\n\tparts, err := parseCgroupController(\"/proc/self/cgroup\", controller)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn parts[2], nil\n}", "label": 5}
{"code": "function getAdminDbUrl(mongoConnectionString, formUser, poolSize) {\n  var parsedMongoUrl = mongoUrlParser.parse(mongoConnectionString);\n  parsedMongoUrl.username = formUser.user;\n  parsedMongoUrl.password = formUser.pass;\n  //according to this: https://docs.mongodb.com/v2.4/reference/user-privileges/#any-database-roles, this type of user should be created in the `admin` database.\n  parsedMongoUrl.database = \"admin\";\n  parsedMongoUrl.options = parsedMongoUrl.options || {};\n  parsedMongoUrl.options.poolSize = poolSize || MONGODB_DEFAULT_POOL_SIZE;\n  var mongourl = mongoUrlParser.format(parsedMongoUrl);\n  return mongourl;\n}", "label": 3}
{"code": "func NewAgentPool(cfg AgentPoolConfig) (*AgentPool, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tctx, cancel := context.WithCancel(cfg.Context)\n\tpool := &AgentPool{\n\t\tagents:     make(map[agentKey][]*Agent),\n\t\tcfg:        cfg,\n\t\tctx:        ctx,\n\t\tcancel:     cancel,\n\t\tdiscoveryC: make(chan *discoveryRequest),\n\t}\n\tpool.Entry = log.WithFields(log.Fields{\n\t\ttrace.Component: teleport.ComponentReverseTunnelAgent,\n\t\ttrace.ComponentFields: log.Fields{\n\t\t\t\"cluster\": cfg.Cluster,\n\t\t},\n\t})\n\treturn pool, nil\n}", "label": 5}
{"code": "def set_prompt(f, attribute, options)\n      options[:prompt] = 'Select One' if is_association?(f, attribute) && f.object.class.reflect_on_association(attribute).macro == :belongs_to && options[:prompt].nil? && !options[:two_pane]\n    end", "label": 4}
{"code": "func (c Common) ObjectName(ctx context.Context) (string, error) {\n\tvar o mo.ManagedEntity\n\n\terr := c.Properties(ctx, c.Reference(), []string{\"name\"}, &o)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif o.Name != \"\" {\n\t\treturn o.Name, nil\n\t}\n\n\t// Network has its own \"name\" field...\n\tvar n mo.Network\n\n\terr = c.Properties(ctx, c.Reference(), []string{\"name\"}, &n)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn n.Name, nil\n}", "label": 5}
{"code": "def TEST():\n    \"\"\"\n    Modules for testing happiness of 'persons' in 'worlds'\n    based on simplistic preferences. Just a toy - dont take seriously\n\n        ----- WORLD SUMMARY for : Mars -----\n        population = 0\n        tax_rate   = 0.0\n        tradition  = 0.9\n        equity     = 0.0\n        Preferences for Rover\n        tax_min  = 0.0\n        equity  = 0.0\n        tax_max  = 0.9\n        tradition  = 0.9\n\n        Rover is Indifferent in Mars (0)\n        DETAILS\n                    tax: Economic = 0.1 -> 0.3\n              tradition: Personal = 0.3 -> 0.9\n                 equity: Personal = 0.1 -> 0.9\n                 growth: Economic = 0.01 -> 0.09\n\n\n    \"\"\"\n    w = World('Mars', [0, 0.0, 0.9, 0.0])\n    print(w)\n    p = Person('Rover', {'tax_min':0.0, 'tax_max':0.9,'tradition':0.9, 'equity':0.0})\n    print(p)\n\n    h = Happiness(p,w)\n    #h.add_factor(HappinessFactors(name, type, min, max))\n    h.add_factor(HappinessFactors('tax', 'Economic', 0.1, 0.3))\n    h.add_factor(HappinessFactors('tradition', 'Personal', 0.3, 0.9))\n    h.add_factor(HappinessFactors('equity', 'Personal', 0.1, 0.9))\n    h.add_factor(HappinessFactors('growth', 'Economic', 0.01, 0.09))\n    print(h.show_details())", "label": 1}
{"code": "func (o HostNetworkSystem) RemoveVirtualSwitch(ctx context.Context, vswitchName string) error {\n\treq := types.RemoveVirtualSwitch{\n\t\tThis:        o.Reference(),\n\t\tVswitchName: vswitchName,\n\t}\n\n\t_, err := methods.RemoveVirtualSwitch(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func (h *hawkularSink) pointToLabeledMetricHeader(ms *core.MetricSet, metric core.LabeledMetric, timestamp time.Time) (*metrics.MetricHeader, error) {\n\n\tname := h.idName(ms, metric.Name)\n\tif resourceID, found := metric.Labels[core.LabelResourceID.Key]; found {\n\t\tname = h.idName(ms, metric.Name+separator+resourceID)\n\t}\n\n\tvar value float64\n\tif metric.ValueType == core.ValueInt64 {\n\t\tvalue = float64(metric.IntValue)\n\t} else {\n\t\tvalue = float64(metric.FloatValue)\n\t}\n\n\tm := metrics.Datapoint{\n\t\tValue:     value,\n\t\tTimestamp: timestamp,\n\t}\n\n\tmh := &metrics.MetricHeader{\n\t\tID:   name,\n\t\tData: []metrics.Datapoint{m},\n\t\tType: heapsterTypeToHawkularType(metric.MetricType),\n\t}\n\n\treturn mh, nil\n}", "label": 5}
{"code": "public function setInstanceNames($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->instance_names = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def init(self, app_id=None):\n        \"\"\"Initializes Steam API library.\n\n        :param str|int app_id: Application ID.\n        :raises: SteamApiStartupError\n        \"\"\"\n        self.set_app_id(app_id)\n\n        err_msg = (\n            'Unable to initialize. Check Steam client is running '\n            'and Steam application ID is defined in steam_appid.txt or passed to Api.'\n        )\n\n        if self._lib.steam_init():\n\n            try:\n                _set_client(self._lib.Client())\n\n                self.utils = Utils()\n                self.current_user = CurrentUser()\n                self.friends = Friends()\n                self.groups = Groups()\n                self.apps = Applications()\n                self.overlay = Overlay()\n                self.screenshots = Screenshots()\n\n            except Exception as e:\n                raise SteamApiStartupError('%s:\\n%s' % (err_msg, e))\n\n        else:\n            raise SteamApiStartupError(err_msg)", "label": 1}
{"code": "def matrix_worker(data):\n    \"\"\"\n    Run pipelines in parallel.\n\n    Args:\n        data(dict): parameters for the pipeline (model, options, ...).\n    Returns:\n        dict: with two fields: success True/False and captured output (list of str).\n    \"\"\"\n    matrix = data['matrix']\n    Logger.get_logger(__name__ + '.worker').info(\n        \"Processing pipeline for matrix entry '%s'\", matrix['name'])\n\n    env = matrix['env'].copy()\n    env.update({'PIPELINE_MATRIX': matrix['name']})\n\n    pipeline = Pipeline(model=data['model'], env=env, options=data['options'])\n    pipeline.hooks = data['hooks']\n    return pipeline.process(data['pipeline'])", "label": 1}
{"code": "public function gc($maxlifetime)\n    {\n        if ($this->gcLimit === 0) {\n            return true;\n        }\n        try {\n            $query = $this->datastore->query()\n                ->kind($this->kind)\n                ->filter('t', '<', time() - $maxlifetime)\n                ->order('t')\n                ->keysOnly()\n                ->limit($this->gcLimit);\n            $result = $this->datastore->runQuery(\n                $query,\n                ['namespaceId' => $this->namespaceId]\n            );\n            $keys = [];\n            /* @var Entity $e */\n            foreach ($result as $e) {\n                $keys[] = $e->key();\n            }\n            if (!empty($keys)) {\n                $this->datastore->deleteBatch($keys);\n            }\n        } catch (Exception $e) {\n            trigger_error(\n                sprintf('Session gc failed: %s', $e->getMessage()),\n                E_USER_WARNING\n            );\n            return false;\n        }\n        return true;\n    }", "label": 2}
{"code": "def rowstack(seq, mode='nulls', nullvals=None):\n    '''\n    Vertically stack a sequence of numpy ndarrays with structured dtype\n\n    Analog of numpy.vstack\n\n    Implemented by the tabarray method\n    :func:`tabular.tab.tabarray.rowstack` which uses \n    :func:`tabular.tabarray.tab_rowstack`.\n\n    **Parameters**\n\n            **seq** :  sequence of numpy recarrays\n\n                    List, tuple, etc. of numpy recarrays to stack vertically.\n\n            **mode** :  string in ['nulls', 'commons', 'abort']\n\n                    Denotes how to proceed if the recarrays have different\n                    dtypes, e.g. different sets of named columns.\n\n                    *   if `mode` == ``nulls``, the resulting set of columns is\n                        determined by the union of the dtypes of all recarrays\n                        to be stacked, and missing data is filled with null \n                        values as defined by \n                        :func:`tabular.spreadsheet.nullvalue`; this is the \n                        default mode.\n\n                    *   elif `mode` == ``commons``, the resulting set of \n                        columns is determined by the intersection of the dtypes \n                        of all recarrays to be stacked, e.g. common columns.\n\n                    *   elif `mode` == ``abort``, raise an error when the\n                        recarrays to stack have different dtypes.\n\n    **Returns**\n\n            **out** :  numpy ndarray with structured dtype\n\n                    Result of vertically stacking the arrays in `seq`.\n\n    **See also:**  `numpy.vstack \n    <http://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html>`_.\n\n    '''\n\n    if nullvals == None:\n        nullvals = utils.DEFAULT_NULLVALUEFORMAT\n    #newseq = [ss for ss in seq if len(ss) > 0]\n    if len(seq) > 1:\n        assert mode in ['commons','nulls','abort'], \\\n             ('\"mode\" argument must either by \"commons\", \"abort\", or \"nulls\".')\n        if mode == 'abort':\n            if not all([set(l.dtype.names) == set(seq[0].dtype.names) \n                        for l in seq]):\n                raise ValueError('Some column names are different.')\n            else:\n                mode = 'commons'\n        if mode == 'nulls':\n            names =  utils.uniqify(utils.listunion([list(s.dtype.names) \n                                       for s in seq if s.dtype.names != None]))\n            formats = [max([s.dtype[att] for s in seq if s.dtype.names != None \n                       and att in s.dtype.names]).str for att in names]         \n            dtype = np.dtype(zip(names,formats))\n            return utils.fromarrays([utils.listunion([s[att].tolist() \n                        if (s.dtype.names != None and att in s.dtype.names) \n                        else [nullvals(format)] * len(s) for s in seq]) \n                        for (att, format) in zip(names, formats)], type=np.ndarray,\n                        dtype=dtype)\n        elif mode == 'commons':\n            names = [x for x in seq[0].dtype.names \n                     if all([x in l.dtype.names for l in seq[1:]])]\n            formats = [max([a.dtype[att] for a in seq]).str for att in names]\n            return utils.fromrecords(utils.listunion(\n                    [ar.tolist() for ar in seq]), type=np.ndarray,\n                          names=names, formats=formats)\n    else:\n        return seq[0]", "label": 1}
{"code": "function getPos(el) {\n  var rect = el.getBoundingClientRect(),\n    scrollY = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop;\n\n  return {\n    top: rect.top + scrollY,\n    bottom: rect.top + rect.height + scrollY,\n    height: rect.height\n  };\n}", "label": 3}
{"code": "protected function createBinding($resolver, array $parameters = [], Closure $callback = null)\n    {\n        return new Binding($this->container, $resolver, $parameters, $callback);\n    }", "label": 2}
{"code": "def louvain_clustering(self, X=None, res=1, method='modularity'):\n        \"\"\"Runs Louvain clustering using the vtraag implementation. Assumes\n        that 'louvain' optional dependency is installed.\n\n        Parameters\n        ----------\n        res - float, optional, default 1\n            The resolution parameter which tunes the number of clusters Louvain\n            finds.\n\n        method - str, optional, default 'modularity'\n            Can be 'modularity' or 'significance', which are two different\n            optimizing funcitons in the Louvain algorithm.\n\n        \"\"\"\n\n        if X is None:\n            X = self.adata.uns['neighbors']['connectivities']\n            save = True\n        else:\n            if not sp.isspmatrix_csr(X):\n                X = sp.csr_matrix(X)\n            save = False\n\n        import igraph as ig\n        import louvain\n\n        adjacency = sparse_knn(X.dot(X.T) / self.k, self.k).tocsr()\n        sources, targets = adjacency.nonzero()\n        weights = adjacency[sources, targets]\n        if isinstance(weights, np.matrix):\n            weights = weights.A1\n        g = ig.Graph(directed=True)\n        g.add_vertices(adjacency.shape[0])\n        g.add_edges(list(zip(sources, targets)))\n        try:\n            g.es['weight'] = weights\n        except BaseException:\n            pass\n\n        if method == 'significance':\n            cl = louvain.find_partition(g, louvain.SignificanceVertexPartition)\n        else:\n            cl = louvain.find_partition(\n                g,\n                louvain.RBConfigurationVertexPartition,\n                resolution_parameter=res)\n\n        if save:\n            self.adata.obs['louvain_clusters'] = pd.Categorical(np.array(cl.membership))\n        else:\n            return np.array(cl.membership)", "label": 1}
{"code": "public static filterpolicy_csvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tfilterpolicy_csvserver_binding obj = new filterpolicy_csvserver_binding();\n\t\tobj.set_name(name);\n\t\tfilterpolicy_csvserver_binding response[] = (filterpolicy_csvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def render_all_layouts(layouts, payload, info)\n      _renderer.layouts = layouts\n      self.output = _renderer.place_in_layouts(output, payload, info)\n    ensure\n      @_renderer = nil # this will allow the modifications above to disappear\n    end", "label": 4}
{"code": "func (s *Rotation) Matches(rotation Rotation) bool {\n\treturn s.CurrentID == rotation.CurrentID && s.State == rotation.State && s.Phase == rotation.Phase\n}", "label": 5}
{"code": "def auto_paginate(auto=false)\n      if (current_api.auto_pagination? || auto) && self.body.is_a?(Array)\n        resources_bodies = []\n        each_page { |resource| resources_bodies += resource.body }\n        self.body = resources_bodies\n      end\n      self\n    end", "label": 4}
{"code": "def delete(*args)\n      arguments(args, required: [:user, :repo, :path]) do\n        assert_required %w[ path message sha ]\n      end\n\n      delete_request(\"/repos/#{arguments.user}/#{arguments.repo}/contents/#{arguments.path}\", arguments.params)\n    end", "label": 4}
{"code": "def merge source\n      unless directory == '*' || source_hash.key?(source.filename)\n        # Reload the config to determine if a new source should be included\n        @config = Solargraph::Workspace::Config.new(directory)\n        return false unless config.calculated.include?(source.filename)\n      end\n      source_hash[source.filename] = source\n      true\n    end", "label": 4}
{"code": "public static double Sin(double x, int nTerms) {\r\n        if (nTerms < 2) return x;\r\n        if (nTerms == 2) {\r\n            return x - (x * x * x) / 6D;\r\n        } else {\r\n\r\n            double mult = x * x * x;\r\n            double fact = 6;\r\n            double sign = 1;\r\n            int factS = 5;\r\n            double result = x - mult / fact;\r\n            for (int i = 3; i <= nTerms; i++) {\r\n                mult *= x * x;\r\n                fact *= factS * (factS - 1);\r\n                factS += 2;\r\n                result += sign * (mult / fact);\r\n                sign *= -1;\r\n            }\r\n\r\n            return result;\r\n        }\r\n    }", "label": 0}
{"code": "def _process_group(input_group, required_group, groupname, append_subgroups=None):\n    \"\"\"\n    Process one group from the input yaml.  Ensure it has the required entries.  If there is a\n    subgroup that should be processed and then appended to the rest of the subgroups in that group,\n    handle it accordingly.\n\n    :param dict input_group: The dict of values of the input group\n    :param dict required_group: The dict of required values for the input group\n    :param str groupname: The name of the group being processed\n    :param list append_subgroups: list of subgroups to append to each, other subgroup in this group\n    :return: processed dict of entries for the group\n    :rtype: dict\n    \"\"\"\n    if append_subgroups is None:\n        append_subgroups = []\n    tool_options = {}\n    for key in input_group:\n        _ensure_set_contains(input_group[key], required_group.get(key, {}), groupname + '::' + key)\n        if key in append_subgroups:\n            continue\n        else:\n            tool_options[key] = input_group[key]\n    for key in input_group:\n        if key in append_subgroups:\n            continue\n        else:\n            for yek in append_subgroups:\n                tool_options[key].update(input_group[yek])\n    return tool_options", "label": 1}
{"code": "def add_attachment(attachment, name = '')\n      # Is it a file object or a string (url)?\n      if attachment.respond_to?(:path) && attachment.respond_to?(:read)\n        client.post(\"/cards/#{id}/attachments\", {\n            file: attachment,\n            name: name\n          })\n      else\n        client.post(\"/cards/#{id}/attachments\", {\n            url: attachment,\n            name: name\n          })\n      end\n    end", "label": 4}
{"code": "function getServiceInfo(serviceName, adapterMap) {\n        var serviceInfo = { serviceName: serviceName };\n        var serviceParts = utils.splitCamelCase(serviceName);  // turn oneTwoThree into ['one', 'two', 'three']\n        var nbrParts = serviceParts.length;\n\n        // first check to see if the second to last part is an adapter\n        serviceInfo.adapterName = serviceParts[nbrParts - 2];  // NOTE: last item in array is 'Service'\n        if (adapterMap[serviceInfo.adapterName]) {\n            serviceInfo.resourceName = serviceParts.slice(0, nbrParts - 2).join('.');\n        }\n        // if not, it means we are dealing with a straight service (ex. postService)\n        else {\n            serviceInfo.adapterName = 'service';\n            serviceInfo.resourceName = serviceParts.slice(0, nbrParts - 1).join('.');\n        }\n\n        serviceInfo.adapterImpl = adapterMap[serviceInfo.adapterName];\n\n        return serviceInfo;\n    }", "label": 3}
{"code": "function add_shared(hash, customTags, doc_map) {\n    hash = utils.merge(hash, {\n      \"inheritable\" : !!doc_map[\"inheritable\"],\n      \"inheritdoc\" : extract(doc_map, \"inheritdoc\"),\n      \"related\" : extract(doc_map, \"related\"),\n      \"see\" : extract(doc_map, \"see\"),\n      \"private\" : extract(doc_map, \"private\") !== null ? true : false,\n      \"experimental\" : extract(doc_map, \"experimental\") !== null ? true : false,\n      \"ignore\" : extract(doc_map, \"ignore\") !== null ? true : false,\n      \"author\" : extract_plural(doc_map[\"author\"] || []),\n      \"version\" : extract(doc_map, \"version\"),\n      \"since\" : extract(doc_map, \"since\"),\n      \"todo\" : extract(doc_map, \"todo\")\n    });\n\n    if (customTags !== undefined) {\n      var custom = {};\n      _.each(customTags, function(tag) {\n        var text = extract(doc_map, tag);\n        if (text !== null) {\n          custom[tag] = text.doc.length > 0 ? text.doc : true;\n        }\n      });\n\n      hash = utils.merge(hash, custom);\n    }\n\n    return hash;\n}", "label": 3}
{"code": "def filelist2html(lst, fldr, hasHeader='N'):\n    \"\"\" \n    formats a standard filelist to htmk using table formats \n    \"\"\"\n    txt = '<TABLE width=100% border=0>'\n    numRows = 1\n    if lst:\n        for l in lst:\n            if hasHeader == 'Y':\n                if numRows == 1:\n                    td_begin = '<TH>'\n                    td_end = '</TH>'\n                else:\n                    td_begin = '<TD>'\n                    td_end = '</TD>'\n            else:\n                td_begin = '<TD>'\n                td_end = '</TD>'\n            numRows += 1\n            txt += '<TR>'\n            if type(l) is str:\n                txt += td_begin + link_file(l, fldr) + td_end\n            elif type(l) is list:\n                txt += td_begin\n                for i in l:\n                    txt+= link_file(i, fldr) + '; '\n                txt += td_end\n            else:\n                txt += td_begin + str(l) + td_end\n            txt += '</TR>\\n'\n    txt += '</TABLE><BR>\\n'\n    return txt", "label": 1}
{"code": "function isRequireCall(expression, checkArgumentIsStringLiteral) {\n        // of the form 'require(\"name\")'\n        var isRequire = expression.kind === 174 /* CallExpression */ &&\n            expression.expression.kind === 69 /* Identifier */ &&\n            expression.expression.text === \"require\" &&\n            expression.arguments.length === 1;\n        return isRequire && (!checkArgumentIsStringLiteral || expression.arguments[0].kind === 9 /* StringLiteral */);\n    }", "label": 3}
{"code": "def group_for_view_by(view_by, measures)\n      if view_by.nil? || measures.nil?\n        return nil\n      else\n        return {\n          metric: measures.first,\n          dimension: view_by,\n          rank: \"DESCENDING\",\n          limit: 3\n        }\n      end\n    end", "label": 4}
{"code": "def op_cmd(self, command, req_format='text', xpath_expr=\"\"):\n        \"\"\" Execute an operational mode command.\n\n        Purpose: Used to send an operational mode command to the connected\n               | device. This requires and uses a paramiko.SSHClient() as\n               | the handler so that we can easily pass and allow all pipe\n               | commands to be used.\n               |\n               | We indiscriminately attach ' | no-more' on the end of\n               | every command so the device doesn't hold output. The\n               | req_format parameter can be set to 'xml' to force raw\n               | xml output in the reply.\n\n        @param command: The single command that to retrieve output from the\n                      | device. Any pipes will be taken into account.\n        @type command: str\n        @param req_format: The desired format of the response, defaults to\n                         | 'text', but also accepts 'xml'. **NOTE**: 'xml'\n                         | will still return a string, not a libxml ElementTree\n        @type req_format: str\n\n        @returns: The reply from the device.\n        @rtype: str\n        \"\"\"\n        if not command:\n            raise InvalidCommandError(\"Parameter 'command' cannot be empty\")\n        if req_format.lower() == 'xml' or xpath_expr:\n            command = command.strip() + ' | display xml'\n        command = command.strip() + ' | no-more\\n'\n        out = ''\n        # when logging in as root, we use _shell to get the response.\n        if self.username == 'root':\n            self._shell.send(command)\n            time.sleep(3)\n            while self._shell.recv_ready():\n                out += self._shell.recv(999999)\n                time.sleep(.75)\n            # take off the command being sent and the prompt at the end.\n            out = '\\n'.join(out.split('\\n')[1:-2])\n        # not logging in as root, and can grab the output as normal.\n        else:\n            stdin, stdout, stderr = self._session.exec_command(command=command,\n                                           timeout=float(self.session_timeout))\n            stdin.close()\n            # read normal output\n            while not stdout.channel.exit_status_ready():\n                out += stdout.read()\n            stdout.close()\n            # read errors\n            while not stderr.channel.exit_status_ready():\n                out += stderr.read()\n            stderr.close()\n        return out if not xpath_expr else xpath(out, xpath_expr)", "label": 1}
{"code": "public function createDatabase($name, array $options = [])\n    {\n        $instantiation = $this->pluckArray(['sessionPool'], $options);\n\n        $database = $this->database($name, $instantiation);\n        return $database->create($options);\n    }", "label": 2}
{"code": "public int compare(Object objA, Object objB)\r\n    {\r\n        String idAStr = _table.getColumn((String)objA).getProperty(\"id\");\r\n        String idBStr = _table.getColumn((String)objB).getProperty(\"id\");\r\n        int idA;\r\n        int idB;\r\n\r\n        try {\r\n            idA = Integer.parseInt(idAStr);\r\n        }\r\n        catch (Exception ex) {\r\n            return 1;\r\n        }\r\n        try {\r\n            idB = Integer.parseInt(idBStr);\r\n        }\r\n        catch (Exception ex) {\r\n            return -1;\r\n        }\r\n        return idA < idB ? -1 : (idA > idB ? 1 : 0);\r\n    }", "label": 0}
{"code": "def _is_user_directory(self, pathname):\n      \"\"\"Check whether `pathname` is a valid user data directory\n\n      This method is meant to be called on the contents of the userdata dir.\n      As such, it will return True when `pathname` refers to a directory name\n      that can be interpreted as a users' userID.\n      \"\"\"\n      fullpath = os.path.join(self.userdata_location(), pathname)\n      # SteamOS puts a directory named 'anonymous' in the userdata directory\n      # by default. Since we assume that pathname is a userID, ignore any name\n      # that can't be converted to a number\n      return os.path.isdir(fullpath) and pathname.isdigit()", "label": 1}
{"code": "def S(Document, *fields):\n\t\"\"\"Generate a MongoDB sort order list using the Django ORM style.\"\"\"\n\t\n\tresult = []\n\t\n\tfor field in fields:\n\t\tif isinstance(field, tuple):  # Unpack existing tuple.\n\t\t\tfield, direction = field\n\t\t\tresult.append((field, direction))\n\t\t\tcontinue\n\t\t\n\t\tdirection = ASCENDING\n\t\t\n\t\tif not field.startswith('__'):\n\t\t\tfield = field.replace('__', '.')\n\t\t\n\t\tif field[0] == '-':\n\t\t\tdirection = DESCENDING\n\t\t\n\t\tif field[0] in ('+', '-'):\n\t\t\tfield = field[1:]\n\t\t\n\t\t_field = traverse(Document, field, default=None)\n\t\t\n\t\tresult.append(((~_field) if _field else field, direction))\n\t\n\treturn result", "label": 1}
{"code": "function SortOrderComparator(sortOrder, options) {\n        this.sortOrder = sortOrder;\n        this.options = {\n            casesensitive: false\n        };\n        if (options) {\n            _.extend(this.options, options);\n        }\n        this.expressions = new Array(sortOrder.sortFields.length);\n        for (var i = 0; i < this.expressions.length; ++i) {\n            this.expressions[i] = new JsonPath_1.JsonPath(sortOrder.sortFields[i].name);\n        }\n    }", "label": 3}
{"code": "function importThemes(req, res, next) {\n  var options = req.connectionOptions;\n\n  var themesToImport = req.body || [];\n\n  if (!_.isArray(req.body)) {\n    return next(\"Expected An Array Of Themes\");\n  }\n\n  forms.importThemes(options, themesToImport, resultHandler(constants.resultTypes.themes, req, next));\n}", "label": 3}
{"code": "def clean(name)\n      return false if exists?(name)\n      path = File.join(directory, dir_name(name))\n      FileUtils.rm_rf(path)\n    end", "label": 4}
{"code": "function showWarningsForParams(params) {\n  for (var param in params) {\n    if (!isValidParameter(param)) {\n      warn(\"Unknown parameter \\\"\".concat(param, \"\\\"\"));\n    }\n\n    if (params.toast && toastIncompatibleParams.indexOf(param) !== -1) {\n      warn(\"The parameter \\\"\".concat(param, \"\\\" is incompatible with toasts\"));\n    }\n\n    if (isDeprecatedParameter(param)) {\n      warnOnce(\"The parameter \\\"\".concat(param, \"\\\" is deprecated and will be removed in the next major release.\"));\n    }\n  }\n}", "label": 3}
{"code": "def build_sphinx(pkg_data, projectdir):\n    \"\"\"Build sphinx documentation.\n\n    :rtype: int\n    :return: subprocess.call return code\n\n    :param `bootstrap_py.control.PackageData` pkg_data: package meta data\n    :param str projectdir: project root directory\n    \"\"\"\n    try:\n        version, _minor_version = pkg_data.version.rsplit('.', 1)\n    except ValueError:\n        version = pkg_data.version\n    args = ' '.join(('sphinx-quickstart',\n                     '--sep',\n                     '-q',\n                     '-p \"{name}\"',\n                     '-a \"{author}\"',\n                     '-v \"{version}\"',\n                     '-r \"{release}\"',\n                     '-l en',\n                     '--suffix=.rst',\n                     '--master=index',\n                     '--ext-autodoc',\n                     '--ext-viewcode',\n                     '--makefile',\n                     '{projectdir}')).format(name=pkg_data.name,\n                                             author=pkg_data.author,\n                                             version=version,\n                                             release=pkg_data.version,\n                                             projectdir=projectdir)\n    if subprocess.call(shlex.split(args)) == 0:\n        _touch_gitkeep(projectdir)", "label": 1}
{"code": "public function setHttpEnabledState($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Iot\\V1\\HttpState::class);\n        $this->http_enabled_state = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def to_sheet_node_xml_string(str='')\n      add_autofilter_defined_name_to_workbook\n      str << '<sheet '\n      serialized_attributes str\n      str << ('name=\"' << name << '\" ')\n      str << ('r:id=\"' << rId << '\"></sheet>')\n    end", "label": 4}
{"code": "def get_query_params(request, *args):\n    \"\"\"\n    Allows to change one of the URL get parameter while keeping all the others.\n\n    Usage::\n\n      {% load libs_tags %}\n      {% get_query_params request \"page\" page_obj.next_page_number as query %}\n      <a href=\"?{{ query }}\">Next</a>\n\n    You can also pass in several pairs of keys and values::\n\n      {% get_query_params request \"page\" 1 \"foobar\" 2 as query %}\n\n    You often need this when you have a paginated set of objects with filters.\n\n    Your url would look something like ``/?region=1&gender=m``. Your paginator\n    needs to create links with ``&page=2`` in them but you must keep the\n    filter values when switching pages.\n\n    :param request: The request instance.\n    :param *args: Make sure to always pass in paris of args. One is the key,\n      one is the value. If you set the value of a key to \"!remove\" that\n      parameter will not be included in the returned query.\n\n    \"\"\"\n    query = request.GET.copy()\n    index = 1\n    key = ''\n    for arg in args:\n        if index % 2 != 0:\n            key = arg\n        else:\n            if arg == \"!remove\":\n                try:\n                    query.pop(key)\n                except KeyError:\n                    pass\n            else:\n                query[key] = arg\n        index += 1\n    return query.urlencode()", "label": 1}
{"code": "def url\n      sch = @options[:ssl] ? \"https\" : \"http\"\n      hosts = Array(@options[:host])\n      @url ||= if hosts.first.include?(\":\")\n                 URI(\"#{sch}://[#{hosts.first}]:#{port}\").to_s\n               else\n                 URI(\"#{sch}://#{hosts.first}:#{port}\").to_s\n               end\n    end", "label": 4}
{"code": "def def_method(object, name, *local_names)\n      method = object.is_a?(Module) ? :module_eval : :instance_eval\n\n      object.send(method, \"def #{name}(_haml_locals = {}); #{@temple_engine.precompiled_with_ambles(local_names)}; end\",\n                  @options.filename, @options.line)\n    end", "label": 4}
{"code": "def add(name, options)\n      @properties[name.to_sym] = Property.new(name.to_sym, options[:type], options[:default])\n    end", "label": 4}
{"code": "def normalize_keys(locale, key, scope, separator = nil)\n      separator ||= I18n.default_separator\n\n      keys = []\n      keys.concat normalize_key(locale, separator)\n      keys.concat normalize_key(scope, separator)\n      keys.concat normalize_key(key, separator)\n      keys\n    end", "label": 4}
{"code": "def gpu_r2c_fft(in1, is_gpuarray=False, store_on_gpu=False):\n    \"\"\"\n    This function makes use of the scikits implementation of the FFT for GPUs to take the real to complex FFT.\n\n    INPUTS:\n    in1             (no default):       The array on which the FFT is to be performed.\n    is_gpuarray     (default=True):     Boolean specifier for whether or not input is on the gpu.\n    store_on_gpu    (default=False):    Boolean specifier for whether the result is to be left on the gpu or not.\n\n    OUTPUTS:\n    gpu_out1                            The gpu array containing the result.\n    OR\n    gpu_out1.get()                      The result from the gpu array.\n    \"\"\"\n\n    if is_gpuarray:\n        gpu_in1 = in1\n    else:\n        gpu_in1 = gpuarray.to_gpu_async(in1.astype(np.float32))\n\n    output_size = np.array(in1.shape)\n    output_size[1] = 0.5*output_size[1] + 1\n\n    gpu_out1 = gpuarray.empty([output_size[0], output_size[1]], np.complex64)\n    gpu_plan = Plan(gpu_in1.shape, np.float32, np.complex64)\n    fft(gpu_in1, gpu_out1, gpu_plan)\n\n    if store_on_gpu:\n        return gpu_out1\n    else:\n        return gpu_out1.get()", "label": 1}
{"code": "def add_role(role, reason = nil)\n      role_ids = role_id_array(role)\n\n      if role_ids.count == 1\n        API::Server.add_member_role(@bot.token, @server.id, @user.id, role_ids[0], reason)\n      else\n        old_role_ids = @roles.map(&:id)\n        new_role_ids = (old_role_ids + role_ids).uniq\n        API::Server.update_member(@bot.token, @server.id, @user.id, roles: new_role_ids, reason: reason)\n      end\n    end", "label": 4}
{"code": "func (d Datastore) Type(ctx context.Context) (types.HostFileSystemVolumeFileSystemType, error) {\n\tvar mds mo.Datastore\n\n\tif err := d.Properties(ctx, d.Reference(), []string{\"summary.type\"}, &mds); err != nil {\n\t\treturn types.HostFileSystemVolumeFileSystemType(\"\"), err\n\t}\n\treturn types.HostFileSystemVolumeFileSystemType(mds.Summary.Type), nil\n}", "label": 5}
{"code": "def instantiate_definitions(program, loader)\n    program.definitions.each { |d| instantiate_definition(d, loader) }\n    nil\n  end", "label": 4}
{"code": "func (s *PresenceService) DeleteAllNodes(namespace string) error {\n\tstartKey := backend.Key(nodesPrefix, namespace)\n\treturn s.DeleteRange(context.TODO(), startKey, backend.RangeEnd(startKey))\n}", "label": 5}
{"code": "public function getPackageName()\n    {\n        if (is_null($this->version)) {\n            return $this->name . ':dev-master';\n        }\n\n        return $this->name . ':' . $this->version;\n    }", "label": 2}
{"code": "function (a, b) {\n        var done = this._done,\n            indexOfA,\n            comparedWith;\n        indexOfA = done.indexOf(a);\n        while (-1 < indexOfA) {\n            comparedWith = this._getPair(done, indexOfA);\n            if (comparedWith === b) {\n                return false; // Already compared\n            }\n            indexOfA = done.indexOf(a, indexOfA + 1);\n        }\n        return true;\n    }", "label": 3}
{"code": "public function removeById($connectionID)\n    {\n        if (isset($this->pool[$connectionID])) {\n            unset(\n                $this->pool[$connectionID],\n                $this->slotsMap\n            );\n\n            return true;\n        }\n\n        return false;\n    }", "label": 2}
{"code": "def write_case_data(self, file):\n        \"\"\" Writes the case data as CSV.\n        \"\"\"\n        writer = self._get_writer(file)\n        writer.writerow([\"Name\", \"base_mva\"])\n        writer.writerow([self.case.name, self.case.base_mva])", "label": 1}
{"code": "def extract_applicable_files(config, options)\n      included_patterns = options[:files]\n      excluded_patterns = config['exclude']\n      excluded_patterns += options.fetch(:excluded_files, [])\n\n      HamlLint::FileFinder.new(config).find(included_patterns, excluded_patterns)\n    end", "label": 4}
{"code": "func (n *network) getSubnetforIPv6(ip *net.IPNet) *ipv6Subnet {\n\tfor _, s := range n.config.Ipv6Subnets {\n\t\t_, snet, err := net.ParseCIDR(s.SubnetIP)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\t// first check if the mask lengths are the same\n\t\ti, _ := snet.Mask.Size()\n\t\tj, _ := ip.Mask.Size()\n\t\tif i != j {\n\t\t\tcontinue\n\t\t}\n\t\tif snet.Contains(ip.IP) {\n\t\t\treturn s\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function Connection (type, sender, from) {\n\t\n\t// provide default 'from' values\n\tfrom = from || {};\n\t\n\t// connection-specific UUID\n\tthis.connID = UTIL.createUUID();\n\t\n\t// a project-specific / supplied name (can be account or app name)\n\tthis.name = '';\n\n\t// sender function associated with this connection\n\tthis.connector = sender;\n\t\n\t// store pointers on how to respond\n\tthis.type = type;\n\t\n\t// where the connection comes from (default to nothing)\n\tthis.host = from.host || '';\n\tthis.port = from.port || 0;\n\n\t// time when this connection is established\n\tthis.time =\tnew Date();\n\t\n\t// append cookie, if available (this is useful if the event will be relayed to another server to execute,\n\t// cookie can then be preserved\n\tif (from.cookie)\n\t\tthis.cookie = from.cookie;\n}", "label": 3}
{"code": "protected function parseDatabaseStats($str)\n    {\n        $db = array();\n\n        foreach (explode(',', $str) as $dbvar) {\n            list($dbvk, $dbvv) = explode('=', $dbvar);\n            $db[trim($dbvk)] = $dbvv;\n        }\n\n        return $db;\n    }", "label": 2}
{"code": "function(notification, options) {\n      options = opts(this, options);\n      return new APICall({\n        action: 'push',\n        type: 'POST',\n        query: server_params(options),\n        options: options,\n        data: JSON.stringify(notification)\n      });\n    }", "label": 3}
{"code": "public function setDataRefreshType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\DataSource_DataRefreshType::class);\n        $this->data_refresh_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function analyzeSentiment($content, array $options = [])\n    {\n        return new Annotation(\n            $this->connection->analyzeSentiment(\n                $this->formatRequest($content, $options)\n            )\n        );\n    }", "label": 2}
{"code": "def get_report_rst(self):\n        \"\"\"\n        formats the project into a report in RST format\n        \"\"\"\n        res = ''\n        res += '-----------------------------------\\n' \n        res += self.nme  + '\\n'\n        res += '-----------------------------------\\n\\n'\n        res += self.desc + '\\n'\n        res += self.fldr + '\\n\\n'\n        res += '.. contents:: \\n\\n\\n'\n\n        res += 'Overview\\n' + '===========================================\\n\\n'\n        res += 'This document contains details on the project ' + self.nme + '\\n\\n'\n        \n        for d in self.details:\n            res += ' - ' + d[0] + ' = ' + d[1] + '\\n\\n'\n            \n        \n        res += '\\nTABLES\\n' + '===========================================\\n\\n'\n        \n        for t in self.datatables:\n            res +=  t.name + '\\n'\n            res += '-------------------------\\n\\n'\n            res += t.format_rst() + '\\n\\n'\n        \n        \n        \n        return res", "label": 1}
{"code": "public List<DbModule> getAncestors(final String gavc, final FiltersHolder filters) {\n        final DbArtifact dbArtifact = getArtifact(gavc);\n        return repositoryHandler.getAncestors(dbArtifact, filters);\n    }", "label": 0}
{"code": "function add(elePath, args) {\n  if (!args || !args.urlPath) return;\n  const ele = parseElePath(elePath, 'component');\n  const routePath = `src/features/${ele.feature}/route.js`;\n  if (!vio.fileExists(routePath)) {\n    throw new Error(`route.add failed: file not found ${routePath}`);\n  }\n\n  const { urlPath } = args;\n  refactor.addImportFrom(routePath, './', '', ele.name);\n\n  const ast1 = ast.getAst(routePath, true);\n  const arrNode = getChildRoutesNode(ast1);\n  if (arrNode) {\n    const rule = `{ path: '${urlPath}', component: ${ele.name}${\n      args.isIndex ? ', isIndex: true' : ''\n    } }`;\n    const changes = refactor.addToArrayByNode(arrNode, rule);\n    const code = refactor.updateSourceCode(vio.getContent(routePath), changes);\n    vio.save(routePath, code);\n  } else {\n    throw new Error(\n      `You are adding a route rule, but can't find childRoutes property in '${routePath}', please check.`\n    );\n  }\n}", "label": 3}
{"code": "public function delete(BlueprintInterface $blueprint)\n    {\n        Notification::where($this->getAttributes($blueprint))->update(['is_deleted' => true]);\n    }", "label": 2}
{"code": "function requireOverrideInjection(requireMe, provides, injects, directory) {\n    return _require(requireMe, provides, injects, directory, overrideInjection);\n  }", "label": 3}
{"code": "def add_section(name)\n      if section_exists?(name)\n        raise IniParseError.new(_(\"Section %{name} is already defined, cannot redefine\") % { name: name.inspect }, @file)\n      end\n\n      section = Section.new(name, @file)\n      @contents << section\n\n      section\n    end", "label": 4}
{"code": "def append_new_context(klass, *args)\n      klass.new(*args).tap do |new_context|\n        new_context.register_with_parent(current_context)\n      end\n    end", "label": 4}
{"code": "function checkClassPropertyAccess(node, left, type, prop) {\n            var flags = getDeclarationFlagsFromSymbol(prop);\n            var declaringClass = getDeclaredTypeOfSymbol(getParentOfSymbol(prop));\n            var errorNode = node.kind === 172 /* PropertyAccessExpression */ || node.kind === 218 /* VariableDeclaration */ ?\n                node.name :\n                node.right;\n            if (left.kind === 95 /* SuperKeyword */) {\n                // TS 1.0 spec (April 2014): 4.8.2\n                // - In a constructor, instance member function, instance member accessor, or\n                //   instance member variable initializer where this references a derived class instance,\n                //   a super property access is permitted and must specify a public instance member function of the base class.\n                // - In a static member function or static member accessor\n                //   where this references the constructor function object of a derived class,\n                //   a super property access is permitted and must specify a public static member function of the base class.\n                if (languageVersion < 2 /* ES6 */ && getDeclarationKindFromSymbol(prop) !== 147 /* MethodDeclaration */) {\n                    // `prop` refers to a *property* declared in the super class\n                    // rather than a *method*, so it does not satisfy the above criteria.\n                    error(errorNode, ts.Diagnostics.Only_public_and_protected_methods_of_the_base_class_are_accessible_via_the_super_keyword);\n                    return false;\n                }\n                if (flags & 128 /* Abstract */) {\n                    // A method cannot be accessed in a super property access if the method is abstract.\n                    // This error could mask a private property access error. But, a member\n                    // cannot simultaneously be private and abstract, so this will trigger an\n                    // additional error elsewhere.\n                    error(errorNode, ts.Diagnostics.Abstract_method_0_in_class_1_cannot_be_accessed_via_super_expression, symbolToString(prop), typeToString(declaringClass));\n                    return false;\n                }\n            }\n            // Public properties are otherwise accessible.\n            if (!(flags & (8 /* Private */ | 16 /* Protected */))) {\n                return true;\n            }\n            // Property is known to be private or protected at this point\n            // Private property is accessible if the property is within the declaring class\n            if (flags & 8 /* Private */) {\n                var declaringClassDeclaration = getClassLikeDeclarationOfSymbol(getParentOfSymbol(prop));\n                if (!isNodeWithinClass(node, declaringClassDeclaration)) {\n                    error(errorNode, ts.Diagnostics.Property_0_is_private_and_only_accessible_within_class_1, symbolToString(prop), typeToString(declaringClass));\n                    return false;\n                }\n                return true;\n            }\n            // Property is known to be protected at this point\n            // All protected properties of a supertype are accessible in a super access\n            if (left.kind === 95 /* SuperKeyword */) {\n                return true;\n            }\n            // Get the enclosing class that has the declaring class as its base type\n            var enclosingClass = forEachEnclosingClass(node, function (enclosingDeclaration) {\n                var enclosingClass = getDeclaredTypeOfSymbol(getSymbolOfNode(enclosingDeclaration));\n                return hasBaseType(enclosingClass, declaringClass) ? enclosingClass : undefined;\n            });\n            // A protected property is accessible if the property is within the declaring class or classes derived from it\n            if (!enclosingClass) {\n                error(errorNode, ts.Diagnostics.Property_0_is_protected_and_only_accessible_within_class_1_and_its_subclasses, symbolToString(prop), typeToString(declaringClass));\n                return false;\n            }\n            // No further restrictions for static properties\n            if (flags & 32 /* Static */) {\n                return true;\n            }\n            // An instance property must be accessed through an instance of the enclosing class\n            if (type.flags & 268435456 /* ThisType */) {\n                // get the original type -- represented as the type constraint of the 'this' type\n                type = getConstraintOfTypeParameter(type);\n            }\n            // TODO: why is the first part of this check here?\n            if (!(getTargetType(type).flags & (32768 /* Class */ | 65536 /* Interface */) && hasBaseType(type, enclosingClass))) {\n                error(errorNode, ts.Diagnostics.Property_0_is_protected_and_only_accessible_through_an_instance_of_class_1, symbolToString(prop), typeToString(enclosingClass));\n                return false;\n            }\n            return true;\n        }", "label": 3}
{"code": "def NormInt(df,sampleA,sampleB):\n    \"\"\"\n    Normalizes intensities of a gene in two samples\n\n    :param df: dataframe output of GetData()\n    :param sampleA: column header of sample A\n    :param sampleB: column header of sample B\n\n    :returns: normalized intensities\n    \"\"\"\n\n    c1=df[sampleA]\n    c2=df[sampleB]\n    return np.log10(np.sqrt(c1*c2))", "label": 1}
{"code": "def space_before?\n      position = begin_pos.zero? ? begin_pos : begin_pos - 1\n      pos.source_buffer.source.match(/\\G\\s/, position)\n    end", "label": 4}
{"code": "function loadEntity(Entity) {\n    expect(arguments).to.have.length(\n      1,\n      'Invalid arguments length when loading an entity in a ' +\n      'MongoAdapter (it has to be passed 1 argument)'\n    );\n\n    expect(Entity).to.be.a(\n      'function',\n      'Invalid argument \"Entity\" when loading an entity in a ' +\n      'MongoAdapter (it has to be an Entity class)'\n    );\n\n    expect(classes.isGeneral(entity.models.Entity, Entity)).to.be.equal(\n      true,\n      'Invalid argument \"Entity\" when loading an entity in a ' +\n      'MongoAdapter (it has to be an Entity class)'\n    );\n\n    expect(Entity.dataName).to.not.equal(\n      '',\n      'The dataName of an Entity cannot be an empty string in a MongoAdapter'\n    );\n\n    expect(Entity.dataName).to.not.match(\n      /^system\\./,\n      'The dataName of an Entity cannot start with \"system.\" in a MongoAdapter'\n    );\n\n    expect(Entity.dataName).to.not.contain(\n      '$',\n      'The dataName of an Entity cannot contain \"$\" in a MongoAdapter'\n    );\n\n    expect(Entity.dataName).to.not.contain(\n      '\\0',\n      'The dataName of an Entity cannot contain \"\\0\" in a MongoAdapter'\n    );\n\n    expect(_collections).to.not.have.ownProperty(\n      Entity.dataName,\n      'Failed to load the Entity called \"' + Entity.specification.name +\n      '\" because it is not possible to have Entities with duplicated ' +\n      'dataName in a MongoAdapter'\n    );\n\n    _collections[Entity.dataName] = [];\n  }", "label": 3}
{"code": "def _track_class_related_field(cls, field):\n    \"\"\" Track a field on a related model \"\"\"\n    # field = field on current model\n    # related_field = field on related model\n    (field, related_field) = field.split('__', 1)\n    field_obj = cls._meta.get_field(field)\n    related_cls = field_obj.remote_field.model\n    related_name = field_obj.remote_field.get_accessor_name()\n\n    if not hasattr(related_cls, '_tracked_related_fields'):\n        setattr(related_cls, '_tracked_related_fields', {})\n    if related_field not in related_cls._tracked_related_fields.keys():\n        related_cls._tracked_related_fields[related_field] = []\n\n    # There can be several field from different or same model\n    # related to a single model.\n    # Thus _tracked_related_fields will be of the form:\n    # {\n    #     'field name on related model': [\n    #         ('field name on current model', 'field name to current model'),\n    #         ('field name on another model', 'field name to another model'),\n    #         ...\n    #     ],\n    #     ...\n    # }\n\n    related_cls._tracked_related_fields[related_field].append(\n        (field, related_name)\n    )\n    _add_signals_to_cls(related_cls)\n    # Detect m2m fields changes\n    if isinstance(related_cls._meta.get_field(related_field), ManyToManyField):\n        m2m_changed.connect(\n            tracking_m2m,\n            sender=getattr(related_cls, related_field).through,\n            dispatch_uid=repr(related_cls),\n        )", "label": 1}
{"code": "def generate_require_paths\n      return configured_require_paths unless gemspec?\n      result = []\n      gemspecs.each do |file|\n        base = File.dirname(file)\n        # @todo Evaluating gemspec files violates the goal of not running\n        #   workspace code, but this is how Gem::Specification.load does it\n        #   anyway.\n        begin\n          spec = eval(File.read(file), binding, file)\n          next unless Gem::Specification === spec\n          result.concat(spec.require_paths.map { |path| File.join(base, path) })\n        rescue Exception => e\n          # Don't die if we have an error during eval-ing a gem spec.\n          # Concat the default lib directory instead.\n          Solargraph.logger.warn \"Error reading #{file}: [#{e.class}] #{e.message}\"\n          result.push File.join(base, 'lib')\n        end\n      end\n      result.concat config.require_paths\n      result.push File.join(directory, 'lib') if result.empty?\n      result\n    end", "label": 4}
{"code": "func Key(key ...string) string {\n\tkeychain := append(rootChain, key...)\n\tstr := strings.Join(keychain, \"/\")\n\treturn str + \"/\"\n}", "label": 5}
{"code": "function fileDelete(src, options) {\n  options = _.sanitize(options, {exclude: [], deleteDirs: true, onlyEmptyDirs: false});\n  let result = true;\n  const files = _matchingFilesArray(src, options);\n  _.each(files, (f) => {\n    const fileWasDeleted = _fileDelete(f, options);\n    result = result && fileWasDeleted;\n  });\n  return result;\n}", "label": 3}
{"code": "function () {\n\t\t\t\t\tif(paused === true) {\n\t\t\t\t\t\tpaused = false;\n\t\t\t\t\t\tnode.onChangeWithPriority(options.priority, do_get);\n\t\t\t\t\t\tif(options.run_on_create !== false) {\n\t\t\t\t\t\t\tif (constraint_solver.semaphore >= 0) {\n\t\t\t\t\t\t\t\tnode.get(false);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\teach(node._changeListeners, constraint_solver.add_in_call_stack, constraint_solver);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn true; // successfully resumed\n\t\t\t\t\t}\n\t\t\t\t\treturn false;\n\t\t\t\t}", "label": 3}
{"code": "function getModelAndCollectionEvents(type, context) {\n        var key = '__' + type + CAP_EVENTS,\n            modelEvents = getState(key, context);\n        if (!modelEvents) {\n            modelEvents = {};\n            var stateVar = {};\n            stateVar[key] = modelEvents;\n            setState(stateVar, context, false);\n        }\n        return modelEvents;\n    }", "label": 3}
{"code": "func (s *Service) About(w http.ResponseWriter, r *http.Request) {\n\tvar about struct {\n\t\tMethods []string\n\t\tTypes   []string\n\t}\n\n\tseen := make(map[string]bool)\n\n\tf := reflect.TypeOf((*soap.HasFault)(nil)).Elem()\n\n\tfor _, obj := range Map.objects {\n\t\tkind := obj.Reference().Type\n\t\tif seen[kind] {\n\t\t\tcontinue\n\t\t}\n\t\tseen[kind] = true\n\n\t\tabout.Types = append(about.Types, kind)\n\n\t\tt := reflect.TypeOf(obj)\n\t\tfor i := 0; i < t.NumMethod(); i++ {\n\t\t\tm := t.Method(i)\n\t\t\tif seen[m.Name] {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tseen[m.Name] = true\n\n\t\t\tin := m.Type.NumIn()\n\t\t\tif in < 2 || in > 3 { // at least 2 params (receiver and request), optionally a 3rd param (context)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif m.Type.NumOut() != 1 || m.Type.Out(0) != f { // all methods return soap.HasFault\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tabout.Methods = append(about.Methods, strings.Replace(m.Name, \"Task\", \"_Task\", 1))\n\t\t}\n\t}\n\n\tsort.Strings(about.Methods)\n\tsort.Strings(about.Types)\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\tenc := json.NewEncoder(w)\n\tenc.SetIndent(\"\", \"  \")\n\t_ = enc.Encode(&about)\n}", "label": 5}
{"code": "@ArgumentsChecked\n\t@Throws(IllegalNullArgumentException.class)\n\tpublic static double checkDouble(@Nonnull final Number number) {\n\t\tCheck.notNull(number, \"number\");\n\t\tif (!isInDoubleRange(number)) {\n\t\t\tthrow new IllegalNumberRangeException(number.toString(), DOUBLE_MIN, DOUBLE_MAX);\n\t\t}\n\n\t\treturn number.doubleValue();\n\t}", "label": 0}
{"code": "function(str, context) {\n\n\t\treturn cjs(function() {\n\t\t\ttry {\n\t\t\t\tvar node = jsep(cjs.get(str));\n\t\t\t\tif(node.type === LITERAL) {\n\t\t\t\t\treturn node.value;\n\t\t\t\t} else {\n\t\t\t\t\treturn get_node_value(node, context, [context]);\n\t\t\t\t}\n\t\t\t} catch(e) {\n\t\t\t\tconsole.error(e);\n\t\t\t}\n\t\t});\n\t}", "label": 3}
{"code": "def new_from_files(self, basepath, basename, repo, \\\n                    bohrs=False, \\\n                    software=_E_SW.ORCA, \\\n                    repo_clobber=False, **kwargs):\n        \"\"\" Initialize with data from files.\n\n        \"\"\"\n\n        # Imports\n        import os\n        from os import path as osp\n        from ..xyz import OpanXYZ as OX\n        from ..grad import OrcaEngrad as OE\n        from ..hess import OrcaHess as OH\n        from .repo import OpanAnharmRepo as OR\n        from ..const import EnumDispDirection as E_DDir, EnumFileType as E_FT\n        from ..const import EnumSoftware as E_SW\n        from ..const import DEF\n        from ..error import AnharmError as ANHErr\n\n##        # Store working directory for restore?\n##        prev_dir = os.getcwd()\n\n        # Complain if anything is already bound\n        if not self.w_xyz == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"XYZ object is already bound\",\n                    \"\")\n        ## end if\n        if not self.w_grad == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"GRAD object is already bound\",\n                    \"\")\n        ## end if\n        if not self.w_hess == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"HESS object is already bound\",\n                    \"\")\n        ## end if\n        if not self.repo == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"Repository object is already bound\",\n                    \"\")\n        ## end if\n\n        # RESUME: vpt2--factor for loading from different software pkgs\n\n        # Load the three data files\n        self.w_xyz = OX( osp.join(basepath, \\\n                basename + osp.extsep + xyz_ext) )\n        self.w_grad = OE( osp.join(basepath, \\\n                basename + osp.extsep + engrad_ext), \\\n                0, E_DDir.NO_DISP, 0.0 )\n        self.w_hess = OH( osp.join(basepath, \\\n                basename + osp.extsep + hess_ext), \\\n                0, E_DDir.NO_DISP, 0.0 )\n\n        # Only accept new repos for now\n        if not isinstance(repo, str):\n            raise TypeError(\"Must create new repository when loading \" +\n                    \"a new dataset.\")\n        ## end if\n\n        # Repo is string, treat as filename and try to load\n        # Check if it's a complete path\n        # If it's a relative path, prepend the basepath\n        if osp.split(repo[0]) > 0 and not osp.isabs(repo):\n            repo = osp.join(basepath, repo)\n        ## end if\n\n        # Complain if it's a directory\n        if osp.isdir(repo):\n            raise IOError(\"Cannot bind repository -- specified \" +\n                    \"location is a directory\")\n        ## end if\n\n        # If file exists ...\n        if osp.isfile(repo):\n                # Depending on clobber, either delete existing or raise error\n                if repo_clobber:\n                    # Clobber old repo\n                    os.remove(repo)\n                else:\n                    # Raise error\n                    raise IOError(\"Target repository file exists and \" +\n                            \"clobber is disabled.\")\n                ## end if\n            ## end if\n\n        # Should be good to create the repo\n        self.repo = OR(repo)", "label": 1}
{"code": "public Iterator<?> getElements(Filter filter, int offset, int maxResultSize) throws LayerException {\n\t\tif (null == filter) {\n\t\t\tfilter = Filter.INCLUDE;\n\t\t}\n\t\tList<Object> filteredList = new ArrayList<Object>();\n\t\ttry {\n\t\t\tsynchronized (featuresById) {\n\t\t\t\tfor (Object feature : featuresById.values()) {\n\t\t\t\t\tif (filter.evaluate(feature)) {\n\t\t\t\t\t\tfilteredList.add(feature);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (Exception e) { // NOSONAR\n\t\t\tthrow new LayerException(e, ExceptionCode.FILTER_EVALUATION_PROBLEM, filter, getId());\n\t\t}\n\t\t// Sorting of elements.\n\t\tif (comparator != null) {\n\t\t\tCollections.sort(filteredList, comparator);\n\t\t}\n\t\tif (maxResultSize > 0) {\n\t\t\tint fromIndex = Math.max(0, offset);\n\t\t\tint toIndex = Math.min(offset + maxResultSize, filteredList.size());\n\t\t\ttoIndex = Math.max(fromIndex, toIndex);\n\t\t\treturn filteredList.subList(fromIndex, toIndex).iterator();\n\t\t} else {\n\t\t\treturn filteredList.iterator();\n\t\t}\n\t}", "label": 0}
{"code": "def ordered_list(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'ordered_list_for', &block)\n      define_method(name) do\n        return platform.ordered_list_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "def node_for_line(line)\n      find(-> { HamlLint::Tree::NullNode.new }) { |node| node.line_numbers.cover?(line) }\n    end", "label": 4}
{"code": "function _gpfDefineCore (name, Super, definition) {\n    var NewClass = _gpfDefineFactory(name, Super, definition);\n    _gpfDefineUpdateContext(name, NewClass);\n    return NewClass;\n}", "label": 3}
{"code": "public void addForeignKeyField(int newId)\r\n    {\r\n        if (m_ForeignKeyFields == null)\r\n        {\r\n            m_ForeignKeyFields = new Vector();\r\n        }\r\n        m_ForeignKeyFields.add(new Integer(newId));\r\n    }", "label": 0}
{"code": "func (f *Fpdf) SplitLines(txt []byte, w float64) [][]byte {\n\t// Function contributed by Bruno Michel\n\tlines := [][]byte{}\n\tcw := &f.currentFont.Cw\n\twmax := int(math.Ceil((w - 2*f.cMargin) * 1000 / f.fontSize))\n\ts := bytes.Replace(txt, []byte(\"\\r\"), []byte{}, -1)\n\tnb := len(s)\n\tfor nb > 0 && s[nb-1] == '\\n' {\n\t\tnb--\n\t}\n\ts = s[0:nb]\n\tsep := -1\n\ti := 0\n\tj := 0\n\tl := 0\n\tfor i < nb {\n\t\tc := s[i]\n\t\tl += cw[c]\n\t\tif c == ' ' || c == '\\t' || c == '\\n' {\n\t\t\tsep = i\n\t\t}\n\t\tif c == '\\n' || l > wmax {\n\t\t\tif sep == -1 {\n\t\t\t\tif i == j {\n\t\t\t\t\ti++\n\t\t\t\t}\n\t\t\t\tsep = i\n\t\t\t} else {\n\t\t\t\ti = sep + 1\n\t\t\t}\n\t\t\tlines = append(lines, s[j:sep])\n\t\t\tsep = -1\n\t\t\tj = i\n\t\t\tl = 0\n\t\t} else {\n\t\t\ti++\n\t\t}\n\t}\n\tif i != j {\n\t\tlines = append(lines, s[j:i])\n\t}\n\treturn lines\n}", "label": 5}
{"code": "public function setWorkerConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1\\InstanceGroupConfig::class);\n        $this->worker_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function base64(text, operation) {\n  operation = operation || 'encode';\n  if (operation === 'decode') {\n    return (new Buffer(text, 'base64')).toString();\n  } else {\n    return (new Buffer(text)).toString('base64');\n  }\n}", "label": 3}
{"code": "func (c *Manager) AddLibraryItemFile(ctx context.Context, sessionID string, updateFile UpdateFile) (*UpdateFileInfo, error) {\n\turl := internal.URL(c, internal.LibraryItemUpdateSessionFile).WithID(sessionID).WithAction(\"add\")\n\tspec := struct {\n\t\tFileSpec UpdateFile `json:\"file_spec\"`\n\t}{updateFile}\n\tvar res UpdateFileInfo\n\treturn &res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "public static hanode_routemonitor_binding[] get(nitro_service service, Long id) throws Exception{\n\t\thanode_routemonitor_binding obj = new hanode_routemonitor_binding();\n\t\tobj.set_id(id);\n\t\thanode_routemonitor_binding response[] = (hanode_routemonitor_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def on_event(event_type, target, extra = nil)\n      case event_type\n      when :error\n        say_status :error, target, :red\n        shell.say extra, :red if options['verbose'] || options['bail']\n\n        raise 'Build error' if options['bail']\n      when :deleted\n        say_status :remove, target, :green\n      when :created\n        say_status :create, target, :green\n      when :identical\n        say_status :identical, target, :blue\n      when :skipped\n        say_status :skipped, target, :blue\n      when :updated\n        say_status :updated, target, :yellow\n      else\n        say_status event_type, extra, :blue\n      end\n    end", "label": 4}
{"code": "public function setApplications($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->applications = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public RedwoodConfiguration neatExit(){\r\n    tasks.add(new Runnable() { public void run() {\r\n      Runtime.getRuntime().addShutdownHook(new Thread(){\r\n        @Override public void run(){ Redwood.stop(); }\r\n      });\r\n    }});\r\n    return this;\r\n  }", "label": 0}
{"code": "func (me *prioritizedPeers) Add(p Peer) bool {\n\treturn me.om.ReplaceOrInsert(prioritizedPeersItem{me.getPrio(p), p}) != nil\n}", "label": 5}
{"code": "def say(message = '', options = {})\n      message = message.to_s\n      return if message.empty?\n\n      statement = Statement.new(self, options)\n      statement.call(message)\n    end", "label": 4}
{"code": "public static function compileBlade($str, $data = [])\n    {\n        if (view()->exists($str)) {\n            return view($str, $data)->render();\n        }\n\n        ob_start() && extract($data, EXTR_SKIP);\n        eval('?>' . app('blade.compiler')->compileString($str));\n        $str = ob_get_contents();\n        ob_end_clean();\n\n        return $str;\n    }", "label": 2}
{"code": "def haml_file?(file)\n      return false unless ::FileTest.file?(file)\n\n      VALID_EXTENSIONS.include?(::File.extname(file))\n    end", "label": 4}
{"code": "public function find_subcommand( &$args ) {\n\t\t$command = array_shift( $args );\n\n\t\tUtils\\load_command( $command );\n\n\t\tif ( ! isset( $this->subcommands[ $command ] ) ) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn $this->subcommands[ $command ];\n\t}", "label": 2}
{"code": "public void enqueue(SerialMessage serialMessage) {\n\t\tthis.sendQueue.add(serialMessage);\n\t\tlogger.debug(\"Enqueueing message. Queue length = {}\", this.sendQueue.size());\n\t}", "label": 0}
{"code": "function getUnionTypeFromSortedList(types, aliasSymbol, aliasTypeArguments) {\n            if (types.length === 0) {\n                return neverType;\n            }\n            if (types.length === 1) {\n                return types[0];\n            }\n            var id = getTypeListId(types);\n            var type = unionTypes[id];\n            if (!type) {\n                var propagatedFlags = getPropagatingFlagsOfTypes(types, /*excludeKinds*/ 6144 /* Nullable */);\n                type = unionTypes[id] = createObjectType(524288 /* Union */ | propagatedFlags);\n                type.types = types;\n                type.aliasSymbol = aliasSymbol;\n                type.aliasTypeArguments = aliasTypeArguments;\n            }\n            return type;\n        }", "label": 3}
{"code": "public function subscriptions(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $subscription) {\n                    return $this->subscriptionFactory(\n                        $subscription['name'],\n                        $subscription['topic'],\n                        $subscription\n                    );\n                },\n                [$this->connection, 'listSubscriptions'],\n                $options + ['project' => $this->formatName('project', $this->projectId)],\n                [\n                    'itemsKey' => 'subscriptions',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "function makeVarMap(filename) {\n  var map = {vars: {}, media: {}, selector: {}};\n\n  function resolveImport(path, basedir) {\n    if (path[0] === '/')\n      return path;\n\n    if (path[0] === '.')\n      return pathResolve(join(basedir, path));\n\n    // webpack treats anything starting w/ ~ as a module name, which we're\n    // about to do below, so just remove leading tildes\n    path = path.replace(/^~/, '');\n\n    return resolve.sync(path, {\n      basedir: basedir,\n      packageFilter: function (package) {\n        var newPackage = extend({}, package);\n\n        if (newPackage.style != null)\n          newPackage.main = newPackage.style;\n\n        return newPackage;\n      }\n    });\n  }\n\n  function processRules(rule) {\n    // only variables declared for `:root` are supported for now\n    if (rule.type !== 'rule' ||\n        rule.selectors.length !== 1 ||\n        rule.selectors[0] !== ':root' ||\n        rule.parent.type !== 'root')\n      return;\n\n    rule.each(function (decl) {\n      var prop = decl.prop;\n      var value = decl.value;\n\n      if (prop && prop.indexOf('--') === 0)\n        map.vars[prop] = value;\n    });\n  }\n\n  function processAtRuleCustom(atRule) {\n    if (atRule.name && ['custom-media', 'custom-selector'].indexOf(atRule.name) !== -1) {\n      var type = atRule.name.split('-')[1];\n      var name = atRule.params.split(/\\s+/, 1)[0];\n      var nameRe = new RegExp('^' + name + '\\\\s+');\n\n      map[type][name] = atRule.params.replace(nameRe, '');\n    }\n  }\n\n  function isUrl(string) {\n    return /(https?:)?\\/\\//.test(string);\n  }\n\n  function process(fn) {\n    var style = postcss().process(fs.readFileSync(fn, 'utf8'));\n\n    // recurse into each import. because we make the recursive call before\n    // extracting values (depth-first, post-order traversal), files that import\n    // libraries can re-define variable declarations, which more-closely\n    // matches the browser's behavior\n    style.root.eachAtRule(function (atRule) {\n      if (atRule.name !== 'import')\n        return;\n\n      var stripped = stripQuotes(unwrapUrl(atRule.params));\n\n      if(isUrl(stripped)) {\n        return;\n      }\n\n      process(resolveImport(stripped, dirname(fn)));\n    });\n\n    // extract variable definitions\n    style.root.eachRule(processRules);\n\n    // extract custom definitions\n    style.root.eachAtRule(processAtRuleCustom);\n  }\n\n  process(pathResolve(filename));\n\n  return map;\n}", "label": 3}
{"code": "private function pluck($key, array &$arr, $isRequired = true)\n    {\n        if (!array_key_exists($key, $arr)) {\n            if ($isRequired) {\n                throw new \\InvalidArgumentException(\n                    \"Key $key does not exist in the provided array.\"\n                );\n            }\n\n            return null;\n        }\n\n        $value = $arr[$key];\n        unset($arr[$key]);\n        return $value;\n    }", "label": 2}
{"code": "function getOverloadedConfigFromEnvironment() {\n  var env = typeof document === 'undefined' ? {} : document.documentElement.dataset;\n  var platformUrl = env.zpPlatformUrl;\n  var appName = env.zpSandboxid;\n  return {\n    platformUrl: platformUrl,\n    appName: appName\n  };\n}", "label": 3}
{"code": "def parse_gbk(gbks):\n    \"\"\"\n    parse gbk file\n    \"\"\"\n    for gbk in gbks:\n        for record in SeqIO.parse(open(gbk), 'genbank'):\n            for feature in record.features:\n                if feature.type == 'gene':\n                    try:\n                        locus = feature.qualifiers['locus_tag'][0]\n                    except:\n                        continue\n                if feature.type == 'CDS':\n                    try:\n                        locus = feature.qualifiers['locus_tag'][0]\n                    except:\n                        pass\n                    start = int(feature.location.start) + int(feature.qualifiers['codon_start'][0])\n                    end, strand = int(feature.location.end), feature.location.strand\n                    if strand is None:\n                        strand = 1\n                    else:\n                        strand = -1\n                    contig = record.id\n#                    contig = record.id.rsplit('.', 1)[0]\n                    yield contig, [locus, \\\n                            [start, end, strand], \\\n                            feature.qualifiers]", "label": 1}
{"code": "function getTokenAtPosition(sourceFile, position, includeJsDocComment) {\n        if (includeJsDocComment === void 0) { includeJsDocComment = false; }\n        return getTokenAtPositionWorker(sourceFile, position, /*allowPositionInLeadingTrivia*/ true, /*includeItemAtEndPosition*/ undefined, includeJsDocComment);\n    }", "label": 3}
{"code": "protected function filterByScopes(array $route)\n    {\n        foreach ($this->option('scopes') as $scope) {\n            if (Str::contains($route['scopes'], $scope)) {\n                return true;\n            }\n        }\n\n        return false;\n    }", "label": 2}
{"code": "def getfile(self, section, option, raw=False, vars=None, fallback=\"\", validate=False):\n        \"\"\"\n        A convenience method which coerces the option in the specified section to a file.\n        \"\"\"\n        v = self.get(section, option, raw=raw, vars=vars, fallback=fallback)\n        v = self._convert_to_path(v)\n        return v if not validate or os.path.isfile(v) else fallback", "label": 1}
{"code": "public function setFieldFilter($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1\\StructuredQuery_FieldFilter::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public static lbvserver[] get(nitro_service service) throws Exception{\n\t\tlbvserver obj = new lbvserver();\n\t\tlbvserver[] response = (lbvserver[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func appendOptionsList(opts []*unit.UnitOption, section, property, prefix string, vals ...string) []*unit.UnitOption {\n\tfor _, v := range vals {\n\t\topts = append(opts, unit.NewUnitOption(section, property, fmt.Sprintf(\"%s%s\", prefix, v)))\n\t}\n\treturn opts\n}", "label": 5}
{"code": "protected Object buildOrRefreshObject(Map row, ClassDescriptor targetClassDescriptor, Object targetObject)\r\n    {\r\n        Object result = targetObject;\r\n        FieldDescriptor fmd;\r\n        FieldDescriptor[] fields = targetClassDescriptor.getFieldDescriptor(true);\r\n\r\n        if(targetObject == null)\r\n        {\r\n            // 1. create new object instance if needed\r\n            result = ClassHelper.buildNewObjectInstance(targetClassDescriptor);\r\n        }\r\n\r\n        // 2. fill all scalar attributes of the new object\r\n        for (int i = 0; i < fields.length; i++)\r\n        {\r\n            fmd = fields[i];\r\n            fmd.getPersistentField().set(result, row.get(fmd.getColumnName()));\r\n        }\r\n\r\n        if(targetObject == null)\r\n        {\r\n            // 3. for new build objects, invoke the initialization method for the class if one is provided\r\n            Method initializationMethod = targetClassDescriptor.getInitializationMethod();\r\n            if (initializationMethod != null)\r\n            {\r\n                try\r\n                {\r\n                    initializationMethod.invoke(result, NO_ARGS);\r\n                }\r\n                catch (Exception ex)\r\n                {\r\n                    throw new PersistenceBrokerException(\"Unable to invoke initialization method:\" + initializationMethod.getName() + \" for class:\" + m_cld.getClassOfObject(), ex);\r\n                }\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def authenticate_by_cookie(authenticatable_class)\n      key = cookie_name(authenticatable_class)\n      authenticatable_id = cookies.encrypted[key]\n      return unless authenticatable_id\n\n      authenticatable_class.find_by(id: authenticatable_id)\n    end", "label": 4}
{"code": "def index():\n    \"\"\"List linked accounts.\"\"\"\n    oauth = current_app.extensions['oauthlib.client']\n\n    services = []\n    service_map = {}\n    i = 0\n\n    for appid, conf in six.iteritems(\n            current_app.config['OAUTHCLIENT_REMOTE_APPS']):\n        if not conf.get('hide', False):\n            services.append(dict(\n                appid=appid,\n                title=conf['title'],\n                icon=conf.get('icon', None),\n                description=conf.get('description', None),\n                account=None\n            ))\n            service_map[oauth.remote_apps[appid].consumer_key] = i\n            i += 1\n\n    # Fetch already linked accounts\n    accounts = RemoteAccount.query.filter_by(\n        user_id=current_user.get_id()\n    ).all()\n\n    for a in accounts:\n        if a.client_id in service_map:\n            services[service_map[a.client_id]]['account'] = a\n\n    # Sort according to title\n    services.sort(key=itemgetter('title'))\n\n    return render_template(\n        'invenio_oauthclient/settings/index.html',\n        services=services\n    )", "label": 1}
{"code": "def _on_message(self, socket, message):\n        \"\"\"\n        Called aways when a message arrives.\n        \"\"\"\n        data = json.loads(message)\n        message_type = None\n        identifier = None\n        subscription = None\n\n        if 'type' in data:\n            message_type = data['type']\n\n        if 'identifier' in data:\n            identifier = json.loads(data['identifier'])\n\n        if identifier is not None:\n            subscription = self.find_subscription(identifier)\n\n        if subscription is not None:\n            subscription.received(data)\n        elif message_type == 'welcome':\n            self.logger.debug('Welcome message received.')\n\n            for subscription in self.subscriptions.values():\n                if subscription.state == 'connection_pending':\n                    subscription.create()\n\n        elif message_type == 'ping':\n            if self.log_ping:\n                self.logger.debug('Ping received.')\n        else:\n            self.logger.warning('Message not supported. (Message: {})'.format(message))", "label": 1}
{"code": "def headers(h = nil)\n      if h\n        raise ArgumentError, 'Headers must be an object which responds to #to_hash' unless h.respond_to?(:to_hash)\n        default_options[:headers] ||= {}\n        default_options[:headers].merge!(h.to_hash)\n      else\n        default_options[:headers] || {}\n      end\n    end", "label": 4}
{"code": "def approle(role_id, secret_id=nil)\n      payload = { role_id: role_id }\n      payload[:secret_id] = secret_id if secret_id\n      json = client.post(\"/v1/auth/approle/login\", JSON.fast_generate(payload))\n      secret = Secret.decode(json)\n      client.token = secret.auth.client_token\n      return secret\n    end", "label": 4}
{"code": "def drop(opts = {})\n      client.send(:with_session, opts) do |session|\n        Operation::Drop.new({\n                              selector: { :drop => name },\n                              db_name: database.name,\n                              write_concern: write_concern,\n                              session: session\n                              }).execute(next_primary)\n      end\n    rescue Error::OperationFailure => ex\n      raise ex unless ex.message =~ /ns not found/\n      false\n    end", "label": 4}
{"code": "def sanitize(action)\n      permissions = @permitted[action]\n\n      if permissions.respond_to?(:call)\n        cast_to_hash permissions.call(default_params)\n      elsif permissions.present?\n        cast_to_hash permit_keys(default_params, permissions)\n      else\n        unknown_action!(action)\n      end\n    end", "label": 4}
{"code": "function encodeLastRecordedSourceMapSpan() {\n            if (!lastRecordedSourceMapSpan || lastRecordedSourceMapSpan === lastEncodedSourceMapSpan) {\n                return;\n            }\n            var prevEncodedEmittedColumn = lastEncodedSourceMapSpan.emittedColumn;\n            // Line/Comma delimiters\n            if (lastEncodedSourceMapSpan.emittedLine === lastRecordedSourceMapSpan.emittedLine) {\n                // Emit comma to separate the entry\n                if (sourceMapData.sourceMapMappings) {\n                    sourceMapData.sourceMapMappings += \",\";\n                }\n            }\n            else {\n                // Emit line delimiters\n                for (var encodedLine = lastEncodedSourceMapSpan.emittedLine; encodedLine < lastRecordedSourceMapSpan.emittedLine; encodedLine++) {\n                    sourceMapData.sourceMapMappings += \";\";\n                }\n                prevEncodedEmittedColumn = 1;\n            }\n            // 1. Relative Column 0 based\n            sourceMapData.sourceMapMappings += base64VLQFormatEncode(lastRecordedSourceMapSpan.emittedColumn - prevEncodedEmittedColumn);\n            // 2. Relative sourceIndex\n            sourceMapData.sourceMapMappings += base64VLQFormatEncode(lastRecordedSourceMapSpan.sourceIndex - lastEncodedSourceMapSpan.sourceIndex);\n            // 3. Relative sourceLine 0 based\n            sourceMapData.sourceMapMappings += base64VLQFormatEncode(lastRecordedSourceMapSpan.sourceLine - lastEncodedSourceMapSpan.sourceLine);\n            // 4. Relative sourceColumn 0 based\n            sourceMapData.sourceMapMappings += base64VLQFormatEncode(lastRecordedSourceMapSpan.sourceColumn - lastEncodedSourceMapSpan.sourceColumn);\n            // 5. Relative namePosition 0 based\n            if (lastRecordedSourceMapSpan.nameIndex >= 0) {\n                ts.Debug.assert(false, \"We do not support name index right now, Make sure to update updateLastEncodedAndRecordedSpans when we start using this\");\n                sourceMapData.sourceMapMappings += base64VLQFormatEncode(lastRecordedSourceMapSpan.nameIndex - lastEncodedNameIndex);\n                lastEncodedNameIndex = lastRecordedSourceMapSpan.nameIndex;\n            }\n            lastEncodedSourceMapSpan = lastRecordedSourceMapSpan;\n            sourceMapData.sourceMapDecodedMappings.push(lastEncodedSourceMapSpan);\n        }", "label": 3}
{"code": "def relation_names(inclusions)\n      inclusions.is_a?(Hash) ? inclusions.keys : Array.wrap(inclusions)\n    end", "label": 4}
{"code": "private static int getTrimmedHeight(BufferedImage img) {\n    int width = img.getWidth();\n    int height = img.getHeight();\n    int trimmedHeight = 0;\n\n    for (int i = 0; i < width; i++) {\n      for (int j = height - 1; j >= 0; j--) {\n        if (img.getRGB(i, j) != Color.WHITE.getRGB() && j > trimmedHeight) {\n          trimmedHeight = j;\n          break;\n        }\n      }\n    }\n\n    return trimmedHeight;\n  }", "label": 0}
{"code": "public function setNodes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dataproc\\V1beta2\\WorkflowNode::class);\n        $this->nodes = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def all_languages\n      Dir.entries(metadata_path)\n         .select { |f| File.directory?(File.join(metadata_path, f)) }\n         .reject { |f| f.start_with?('.') }\n         .sort { |x, y| x <=> y }\n    end", "label": 4}
{"code": "def matches(self, txt: str) -> bool:\n        \"\"\"Determine whether txt matches pattern\n\n        :param txt: text to check\n        :return: True if match\n        \"\"\"\n        # rval = ref.getText()[1:-1].encode('utf-8').decode('unicode-escape')\n        if r'\\\\u' in self.pattern_re.pattern:\n            txt = txt.encode('utf-8').decode('unicode-escape')\n        match = self.pattern_re.match(txt)\n        return match is not None and match.end() == len(txt)", "label": 1}
{"code": "public static function fromString($path, $splitPath = true)\n    {\n        self::validateString($path);\n\n        $parts = $splitPath\n            ? explode('.', $path)\n            : [$path];\n\n        return new self($parts);\n    }", "label": 2}
{"code": "def remove(self):\n        \"\"\"\n        Removes the subscription.\n        \"\"\"\n        self.logger.debug('Remove subscription from server...')\n\n        data = {\n            'command': 'unsubscribe',\n            'identifier': self._identifier_string()\n        }\n\n        self.connection.send(data)\n        self.state = 'unsubscribed'", "label": 1}
{"code": "public static List<Integer> asList(int[] a) {\r\n    List<Integer> result = new ArrayList<Integer>(a.length);\r\n    for (int i = 0; i < a.length; i++) {\r\n      result.add(Integer.valueOf(a[i]));\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "def duplicate_child_info(child_ref)\n      @title ||= child_ref.title\n      @type ||= child_ref.subset_operators\n      @definition ||= child_ref.definition\n      @status ||= child_ref.status\n      @code_list_id ||= child_ref.code_list_id\n      @temporal_references = child_ref.temporal_references if @temporal_references.empty?\n      @subset_operators ||= child_ref.subset_operators\n      @variable ||= child_ref.variable\n      @value ||= child_ref.value\n    end", "label": 4}
{"code": "def _get_local_fields(self, model):\n        \"Return the names of all locally defined fields on the model class.\"\n        local = [f for f in model._meta.fields]\n        m2m = [f for f in model._meta.many_to_many]\n        fields = local + m2m\n        names = tuple([x.name for x in fields])\n\n        return {\n            ':local': dict(list(zip(names, fields))),\n        }", "label": 1}
{"code": "func (ap *AuthPermission) Update(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !ap._exists {\n\t\treturn errors.New(\"update failed: does not exist\")\n\t}\n\n\t// if deleted, bail\n\tif ap._deleted {\n\t\treturn errors.New(\"update failed: marked for deletion\")\n\t}\n\n\t// sql query\n\tconst sqlstr = `UPDATE auth_permission SET ` +\n\t\t`content_type_id = ?, codename = ?, name = ?` +\n\t\t` WHERE id = ?`\n\n\t// run query\n\tXOLog(sqlstr, ap.ContentTypeID, ap.Codename, ap.Name, ap.ID)\n\t_, err = db.Exec(sqlstr, ap.ContentTypeID, ap.Codename, ap.Name, ap.ID)\n\treturn err\n}", "label": 5}
{"code": "function MaxFunction(win) { \n  var self = this, r;\n  self.win = win;\n  self.name = \"max\";\n  self.type = \"ordered_reverse\";\n  self.init = function() { r = null; };\n  self.accumulate = function(v) { if (v == null) { return; } if (r == null) { r = v; return; } r = (v > r) ? v : r; };\n  self.compensate = function(v) { r = self.win.max(); };\n  self.emit = function()  { return r; };\n  self.make = function(win) { return new MaxFunction(win); };\n}", "label": 3}
{"code": "public function register()\n    {\n        if (PHP_VERSION_ID >= 50400) {\n            session_set_save_handler($this, true);\n        } else {\n            session_set_save_handler(\n                array($this, 'open'),\n                array($this, 'close'),\n                array($this, 'read'),\n                array($this, 'write'),\n                array($this, 'destroy'),\n                array($this, 'gc')\n            );\n        }\n    }", "label": 2}
{"code": "func fieldContains(fl FieldLevel) bool {\n\tfield := fl.Field()\n\n\tcurrentField, _, ok := fl.GetStructFieldOK()\n\n\tif !ok {\n\t\treturn false\n\t}\n\n\treturn strings.Contains(field.String(), currentField.String())\n}", "label": 5}
{"code": "def make_request_uri(uri, opts)\n      uri = uri.to_s\n\n      if default_options.persistent? && uri !~ HTTP_OR_HTTPS_RE\n        uri = \"#{default_options.persistent}#{uri}\"\n      end\n\n      uri = HTTP::URI.parse uri\n\n      if opts.params && !opts.params.empty?\n        uri.query_values = uri.query_values(Array).to_a.concat(opts.params.to_a)\n      end\n\n      # Some proxies (seen on WEBRick) fail if URL has\n      # empty path (e.g. `http://example.com`) while it's RFC-complaint:\n      # http://tools.ietf.org/html/rfc1738#section-3.1\n      uri.path = \"/\" if uri.path.empty?\n\n      uri\n    end", "label": 4}
{"code": "def snr_ratio(in1, in2):\n    \"\"\"\n    The following function simply calculates the signal to noise ratio between two signals.\n\n    INPUTS:\n    in1         (no default):   Array containing values for signal 1.\n    in2         (no default):   Array containing values for signal 2.\n\n    OUTPUTS:\n    out1                        The ratio of the signal to noise ratios of two signals.\n    \"\"\"\n\n    out1 = 20*(np.log10(np.linalg.norm(in1)/np.linalg.norm(in1-in2)))\n\n    return out1", "label": 1}
{"code": "func GetInit(ipamName string) func(ic ipamapi.Callback, l, g interface{}) error {\n\treturn func(ic ipamapi.Callback, l, g interface{}) error {\n\t\treturn ic.RegisterIpamDriver(ipamName, &allocator{})\n\t}\n}", "label": 5}
{"code": "function svg_overflow($x, $y)\n\t{\n\t\t$x2 = $x;\n\t\t$y2 = $y;\n\t\tif (isset($this->svg_attribs['overflow'])) {\n\t\t\tif ($this->svg_attribs['overflow'] == 'hidden') {\n\t\t\t\t// Not sure if this is supposed to strip off units, but since I dont use any I will omlt this step\n\t\t\t\t$svg_w = preg_replace(\"/([0-9\\.]*)(.*)/i\", \"$1\", $this->svg_attribs['width']);\n\t\t\t\t$svg_h = preg_replace(\"/([0-9\\.]*)(.*)/i\", \"$1\", $this->svg_attribs['height']);\n\n\t\t\t\t// $xmax = floor($this->svg_attribs['width']);\n\t\t\t\t$xmax = floor($svg_w);\n\t\t\t\t$xmin = 0;\n\t\t\t\t// $ymax = floor(($this->svg_attribs['height'] * -1));\n\t\t\t\t$ymax = floor(($svg_h * -1));\n\t\t\t\t$ymin = 0;\n\n\t\t\t\tif ($x > $xmax) {\n\t\t\t\t\t$x2 = $xmax; // right edge\n\t\t\t\t}\n\t\t\t\tif ($x < $xmin) {\n\t\t\t\t\t$x2 = $xmin; // left edge\n\t\t\t\t}\n\t\t\t\tif ($y < $ymax) {\n\t\t\t\t\t$y2 = $ymax; // bottom\n\t\t\t\t}\n\t\t\t\tif ($y > $ymin) {\n\t\t\t\t\t$y2 = $ymin; // top\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn ['x' => $x2, 'y' => $y2];\n\t}", "label": 2}
{"code": "private function normalizePath(array $path)\n    {\n        // If the path is associative (i.e. not nested), wrap it up.\n        if ($this->isAssoc($path)) {\n            $path = [$path];\n        }\n\n        $res = [];\n        foreach ($path as $index => $pathElement) {\n            if (!isset($pathElement['kind'])) {\n                throw new InvalidArgumentException('Each path element must contain a kind.');\n            }\n\n            $incomplete = (!isset($pathElement['id']) && !isset($pathElement['name']));\n            if ($index < count($path) -1 && $incomplete) {\n                throw new InvalidArgumentException(\n                    'Only the final pathElement may omit a name or ID.'\n                );\n            }\n\n            if (isset($pathElement['id']) && !is_string($pathElement['id'])) {\n                $pathElement['id'] = (string) $pathElement['id'];\n            }\n\n            $res[] = $pathElement;\n        }\n\n        return $res;\n    }", "label": 2}
{"code": "function (name) {\n            var result;\n            this._sources.every(function (source) {\n                if (source.getName() === name) {\n                    result = this._update(source);\n                    return false;\n                }\n                return true;\n            }, this);\n            return result;\n        }", "label": 3}
{"code": "func ESX() *Model {\n\treturn &Model{\n\t\tServiceContent: esx.ServiceContent,\n\t\tRootFolder:     esx.RootFolder,\n\t\tAutostart:      true,\n\t\tDatastore:      1,\n\t\tMachine:        2,\n\t\tDelayConfig: DelayConfig{\n\t\t\tDelay:       0,\n\t\t\tDelayJitter: 0,\n\t\t\tMethodDelay: nil,\n\t\t},\n\t}\n}", "label": 5}
{"code": "function isSqlQuery(literal) {\n  if (!literal) {\n    return false;\n  }\n\n  try {\n    parser.parse(literal);\n  } catch (error) {\n    return false;\n  }\n\n  return true;\n}", "label": 3}
{"code": "function proxifySteps(stepDefinitions) {\n    return new Proxy(stepDefinitions, {\n        get: (target, name, receiver) => stepsGetter(target, name, receiver),\n        set: (target, name, value) => stepsSetter(target, name, value),\n    });\n}", "label": 3}
{"code": "def with_restart_on_deadlock\n      yield\n    rescue ActiveRecord::StatementInvalid => exception\n      if exception.message =~ /deadlock/i || exception.message =~ /database is locked/i\n        ActiveSupport::Notifications.publish('deadlock_restart.double_entry', :exception => exception)\n\n        raise ActiveRecord::RestartTransaction\n      else\n        raise\n      end\n    end", "label": 4}
{"code": "protected boolean setFieldIfNecessary(String field, Object value) {\n\t\tif (!isOpen())\n\t\t\tthrow new ClosedObjectException(\"The Document object is closed.\");\n\n\t\tif (!compareFieldValue(field, value)) {\n\t\t\t_doc.setField(field, value);\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}", "label": 0}
{"code": "def parse_codons(ref, start, end, strand):\n    \"\"\"\n    parse codon nucleotide positions in range start -> end, wrt strand\n    \"\"\"\n    codon = []\n    c = cycle([1, 2, 3])\n    ref = ref[start - 1:end]\n    if strand == -1:\n        ref = rc_stats(ref)\n    for pos in ref:\n        n = next(c)\n        codon.append(pos)\n        if n == 3:\n            yield codon\n            codon = []", "label": 1}
{"code": "public function setSeverity($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\TransferMessage_MessageSeverity::class);\n        $this->severity = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (t *Torrent) queuePieceCheck(pieceIndex pieceIndex) {\n\tpiece := &t.pieces[pieceIndex]\n\tif piece.queuedForHash() {\n\t\treturn\n\t}\n\tt.piecesQueuedForHash.Add(bitmap.BitIndex(pieceIndex))\n\tt.publishPieceChange(pieceIndex)\n\tt.updatePiecePriority(pieceIndex)\n\tgo t.verifyPiece(pieceIndex)\n}", "label": 5}
{"code": "protected ServiceRegistration registerProxy(Object objectProxy, Class clazz) {\n        Dictionary<String, Object> props = new Hashtable<String, Object>();\n        ServiceRegistration registration;\n        registration = context.registerService(clazz, objectProxy, props);\n\n        return registration;\n    }", "label": 0}
{"code": "function verifyProfile(profile, profileKey) {\n    if (!profile.file && !profile.url) {\n        throw new Error(`[${profileKey}] Must specify a file or url in the configuration.`);\n    }\n    if (!profile.output) {\n        throw new Error(`[${profileKey}] Must specify an output file path in the configuration.`);\n    }\n    if (!profile.generator) {\n        throw new Error(`[${profileKey}] Must specify a generator in the configuration.`);\n    }\n    if (profile.generator.toLowerCase() === 'core') {\n        throw new Error(`[${profileKey}] Invalid generator ${profile.generator}. This name is reserved.`);\n    }\n    if (profile.generator.match(/^[\\w-]+-language$/i)) {\n        throw new Error(`[${profileKey}] Invalid generator ${profile.generator}. The -language suffix is reserved for language helper packages.`);\n    }\n    profile.debug = profile.debug || {};\n    profile.filters = profile.filters || {};\n    profile.transforms = profile.transforms || {};\n    profile.options = profile.options || {};\n}", "label": 3}
{"code": "function isIdentifier() {\n            if (token() === 69 /* Identifier */) {\n                return true;\n            }\n            // If we have a 'yield' keyword, and we're in the [yield] context, then 'yield' is\n            // considered a keyword and is not an identifier.\n            if (token() === 114 /* YieldKeyword */ && inYieldContext()) {\n                return false;\n            }\n            // If we have a 'await' keyword, and we're in the [Await] context, then 'await' is\n            // considered a keyword and is not an identifier.\n            if (token() === 119 /* AwaitKeyword */ && inAwaitContext()) {\n                return false;\n            }\n            return token() > 105 /* LastReservedWord */;\n        }", "label": 3}
{"code": "func NewController(t TestReporter) *Controller {\n\th, ok := t.(TestHelper)\n\tif !ok {\n\t\th = nopTestHelper{t}\n\t}\n\n\treturn &Controller{\n\t\tT:             h,\n\t\texpectedCalls: newCallSet(),\n\t}\n}", "label": 5}
{"code": "def unset(entity, *types):\n    \"\"\"Unset the TypedFields on the input `entity`.\n\n    Args:\n        entity: A mixbox.Entity object.\n        *types: A variable-length list of TypedField subclasses. If not\n            provided, defaults to TypedField.\n    \"\"\"\n    if not types:\n        types = (TypedField,)\n\n    fields = list(entity._fields.keys())\n    remove = (x for x in fields if isinstance(x, types))\n\n    for field in remove:\n        del entity._fields[field]", "label": 1}
{"code": "func NewLoadBalancer(ctx context.Context, frontend NetAddr, backends ...NetAddr) (*LoadBalancer, error) {\n\tif ctx == nil {\n\t\treturn nil, trace.BadParameter(\"missing parameter context\")\n\t}\n\twaitCtx, waitCancel := context.WithCancel(ctx)\n\treturn &LoadBalancer{\n\t\tfrontend:     frontend,\n\t\tctx:          ctx,\n\t\tbackends:     backends,\n\t\tcurrentIndex: -1,\n\t\twaitCtx:      waitCtx,\n\t\twaitCancel:   waitCancel,\n\t\tEntry: log.WithFields(log.Fields{\n\t\t\ttrace.Component: \"loadbalancer\",\n\t\t\ttrace.ComponentFields: log.Fields{\n\t\t\t\t\"listen\": frontend.String(),\n\t\t\t},\n\t\t}),\n\t\tconnections: make(map[NetAddr]map[int64]net.Conn),\n\t}, nil\n}", "label": 5}
{"code": "public ShardInformation getShardInformation(String shard) {\n    ShardInformation shardInformation = shardIndex.get(Objects.requireNonNull(shard, \"shard required\"));\n    if (shardInformation == null) {\n      shardInformation = createShardInformation(shard);\n    }\n    return shardInformation;\n  }", "label": 0}
{"code": "def scatter(self, projection=None, c=None, cmap='rainbow', linewidth=0.0,\n                edgecolor='k', axes=None, colorbar=True, s=10, **kwargs):\n        \"\"\"Display a scatter plot.\n\n        Displays a scatter plot using the SAM projection or another input\n        projection with or without annotations.\n\n        Parameters\n        ----------\n\n        projection - ndarray of floats, optional, default None\n            An N x 2 matrix, where N is the number of data points. If None,\n            use an existing SAM projection (default t-SNE). Can take on values\n            'umap' or 'tsne' to specify either the SAM UMAP embedding or\n            SAM t-SNE embedding.\n\n        c - ndarray or str, optional, default None\n            Colors for each cell in the scatter plot. Can be a vector of\n            floats or strings for cell annotations. Can also be a key\n            for sam.adata.obs (i.e. 'louvain_clusters').\n\n        axes - matplotlib axis, optional, default None\n            Plot output to the specified, existing axes. If None, create new\n            figure window.\n\n        cmap - string, optional, default 'rainbow'\n            The colormap to use for the input color values.\n\n        colorbar - bool, optional default True\n            If True, display a colorbar indicating which values / annotations\n            correspond to which color in the scatter plot.\n\n        Keyword arguments -\n            All other keyword arguments that can be passed into\n            matplotlib.pyplot.scatter can be used.\n        \"\"\"\n\n        if (not PLOTTING):\n            print(\"matplotlib not installed!\")\n        else:\n            if(isinstance(projection, str)):\n                try:\n                    dt = self.adata.obsm[projection]\n                except KeyError:\n                    print('Please create a projection first using run_umap or'\n                          'run_tsne')\n\n            elif(projection is None):\n                try:\n                    dt = self.adata.obsm['X_umap']\n                except KeyError:\n                    try:\n                        dt = self.adata.obsm['X_tsne']\n                    except KeyError:\n                        print(\"Please create either a t-SNE or UMAP projection\"\n                              \"first.\")\n                        return\n            else:\n                dt = projection\n\n            if(axes is None):\n                plt.figure()\n                axes = plt.gca()\n\n            if(c is None):\n                plt.scatter(dt[:, 0], dt[:, 1], s=s,\n                            linewidth=linewidth, edgecolor=edgecolor, **kwargs)\n            else:\n\n                if isinstance(c, str):\n                    try:\n                        c = self.adata.obs[c].get_values()\n                    except KeyError:\n                        0  # do nothing\n\n                if((isinstance(c[0], str) or isinstance(c[0], np.str_)) and\n                   (isinstance(c, np.ndarray) or isinstance(c, list))):\n                    i = ut.convert_annotations(c)\n                    ui, ai = np.unique(i, return_index=True)\n                    cax = axes.scatter(dt[:,0], dt[:,1], c=i, cmap=cmap, s=s,\n                                       linewidth=linewidth,\n                                       edgecolor=edgecolor,\n                                       **kwargs)\n\n                    if(colorbar):\n                        cbar = plt.colorbar(cax, ax=axes, ticks=ui)\n                        cbar.ax.set_yticklabels(c[ai])\n                else:\n                    if not (isinstance(c, np.ndarray) or isinstance(c, list)):\n                        colorbar = False\n                    i = c\n\n                    cax = axes.scatter(dt[:,0], dt[:,1], c=i, cmap=cmap, s=s,\n                                       linewidth=linewidth,\n                                       edgecolor=edgecolor,\n                                       **kwargs)\n\n                    if(colorbar):\n                        plt.colorbar(cax, ax=axes)", "label": 1}
{"code": "def old_path(self, full_path):\n        \"\"\"Remove self.extension from path or raise MagicError.\"\"\"\n        if self.matches(full_path):\n            return full_path[:-len(self.extension)]\n        else:\n            raise MagicError(\"Path does not match this magic.\")", "label": 1}
{"code": "def localize(object, locale: nil, format: nil, **options)\n      locale ||= config.locale\n      raise Disabled.new('l') if locale == false\n      enforce_available_locales!(locale)\n\n      format ||= :default\n      config.backend.localize(locale, object, format, options)\n    end", "label": 4}
{"code": "func FIt(text string, body interface{}, timeout ...float64) bool {\n\tglobalSuite.PushItNode(text, body, types.FlagTypeFocused, codelocation.New(1), parseTimeout(timeout...))\n\treturn true\n}", "label": 5}
{"code": "def bulk_copy(self, ids):\n        \"\"\"Bulk copy a set of results.\n\n        :param ids: Int list of result IDs.\n        :return: :class:`results.Result <results.Result>` list\n        \"\"\"\n        schema = ResultSchema()\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)", "label": 1}
{"code": "def transform_raw_abundance(biomf, fn=math.log10, sampleIDs=None, sample_abd=True):\n    \"\"\"\n    Function to transform the total abundance calculation for each sample ID to another\n    format based on user given transformation function.\n\n    :type biomf: A BIOM file.\n    :param biomf: OTU table format.\n\n    :param fn: Mathematical function which is used to transform smax to another format.\n               By default, the function has been given as base 10 logarithm.\n\n    :rtype: dict\n    :return: Returns a dictionary similar to output of raw_abundance function but with\n             the abundance values modified by the mathematical operation. By default, the\n             operation performed on the abundances is base 10 logarithm.\n    \"\"\"\n    totals = raw_abundance(biomf, sampleIDs, sample_abd)\n    return {sid: fn(abd) for sid, abd in totals.items()}", "label": 1}
{"code": "private static function parseRange($range, $partSize)\n    {\n        // Strip away the prefix and suffix.\n        if (strpos($range, 'bytes') !== false) {\n            $range = substr($range, 6, -2);\n        }\n\n        // Split that range into it's parts.\n        list($firstByte, $lastByte) = explode('-', $range);\n\n        // Calculate and return range index and range size\n        return [\n            intval($firstByte / $partSize) + 1,\n            $lastByte - $firstByte + 1,\n        ];\n    }", "label": 2}
{"code": "function vertextes(parent, exist = [], item, _path) {\n    return [...parent.children].reduce( (acc, node, index) => {\n        if(node.tagName === \"IMG\") {\n            //const [ name, props = {} ] = JSON.parse(node.getAttribute(\"m2\") || \"[]\");\n            node.setAttribute(\"m2\", JSON.stringify([\n                `*${imgcounter++}`, { resources: [ {type: \"img\", url: node.getAttribute(\"src\") } ]}\n            ]));\n            item = [];\n        }\n        /*\n        if(node.tagName === \"link\" && node.getAttribute(\"rel\") === \"stylesheet\") {\n            exist[1].resources.push( {type: \"style\", url: node.getAttribute(\"href\") } );\n            node.remove();\n            return acc;\n        }*/\n        if(node.getAttribute(\"m2\")) {\n            const m2data = transform(node, item, _path);\n\n            if(!m2data[1].template && exist[1].type !== \"switcher\") {\n                const placer = document.createElement(\"div\");\n                placer.setAttribute(\"data-pid\", m2data[1].pid );\n                node.parentNode.replaceChild(placer, node);\n            }\n            node.remove();\n            acc.push( m2data );\n        }\n        else {\n            vertextes(node, exist, item, _path);\n        }\n        return acc;\n    }, exist);\n}", "label": 3}
{"code": "def to_xml_string(str='')\n      Axlsx::sanitize(@shared_xml_string)\n      str << ('<?xml version=\"1.0\" encoding=\"UTF-8\"?><sst xmlns=\"' << XML_NS << '\"')\n      str << (' count=\"' << @count.to_s << '\" uniqueCount=\"' << unique_count.to_s << '\"')\n      str << (' xml:space=\"' << xml_space.to_s << '\">' << @shared_xml_string << '</sst>')\n    end", "label": 4}
{"code": "def already_json_response(response_code, json_text, options = {})\n      version_header = FFI_Yajl::Encoder.encode(\n        \"min_version\" => MIN_API_VERSION.to_s,\n        \"max_version\" => MAX_API_VERSION.to_s,\n        \"request_version\" => options[:request_version] || DEFAULT_REQUEST_VERSION.to_s,\n        \"response_version\" => options[:response_version] || DEFAULT_RESPONSE_VERSION.to_s\n      )\n\n      headers = {\n        \"Content-Type\" => \"application/json\",\n        \"X-Ops-Server-API-Version\" => version_header,\n      }\n      headers.merge!(options[:headers]) if options[:headers]\n\n      [ response_code, headers, json_text ]\n    end", "label": 4}
{"code": "public static base_response unset(nitro_service client, appfwconfidfield resource, String[] args) throws Exception{\n\t\tappfwconfidfield unsetresource = new appfwconfidfield();\n\t\tunsetresource.fieldname = resource.fieldname;\n\t\tunsetresource.url = resource.url;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public static base_response delete(nitro_service client, snmpmanager resource) throws Exception {\n\t\tsnmpmanager deleteresource = new snmpmanager();\n\t\tdeleteresource.ipaddress = resource.ipaddress;\n\t\tdeleteresource.netmask = resource.netmask;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "function publish(target, data, done) {\n        if(data.enabled !== true)\n            return grunt.fail.fatal('publishing is disabled; set \"publish.enabled\" to true to enable');\n\n        if(!data.path)\n            return grunt.fail.fatal('the \"publish.path\" attribute must be provided for the publish task');\n\n        if(!data.message)\n            return grunt.fail.fatal('the \"publish.message\" attribute must be provided for the publish task');\n\n        /**\n         * provide the defaults for the git commands.  by default, we are assuming the markdown repo is stored\n         * in a separate directory, so our git commands need to support that...provide the git-dir and work-tree\n         * paths.  the standard publish process is:\n         *\n         * git add .\n         * git commit -m <configured commit message>\n         * git push <remoteName> <remoteBranch> (defaults to upstream master)\n         *\n         */\n        _.defaults(data, {\n            addCmd: ['--git-dir='+ data.path +'/.git', '--work-tree='+ data.path, 'add', '.'],\n            commitCmd: ['--git-dir='+ data.path +'/.git', '--work-tree='+ data.path, 'commit', '-m', data.message],\n            pushCmd: ['--git-dir='+ data.path +'/.git', '--work-tree='+ data.path, 'push', data.remoteName || 'upstream', data.remoteBranch || 'master']\n        });\n\n        //run the git commands, using promises to handle when complete\n        function cmd(args) {\n            var def = Q.defer();\n            grunt.util.spawn({ cmd: 'git', args: args }, def.resolve);\n            return def.promise;\n        }\n\n        //add, commit, and publish the doc repository\n        cmd(data.addCmd)\n            .then(cmd.bind(this, data.commitCmd))\n            .then(cmd.bind(this, data.pushCmd))\n            .then(done);\n    }", "label": 3}
{"code": "function (element, settings, bindingContext, fromBinding) {\n            compositionCount++;\n\n            if(!fromBinding){\n                settings = composition.getSettings(function() { return settings; }, element);\n            }\n\n            if (settings.compositionComplete) {\n                compositionCompleteCallbacks.push(function () {\n                    settings.compositionComplete(settings.child, settings.parent, settings);\n                });\n            }\n\n            compositionCompleteCallbacks.push(function () {\n                if(settings.composingNewView && settings.model && settings.model.compositionComplete){\n                    settings.model.compositionComplete(settings.child, settings.parent, settings);\n                }\n            });\n\n            var hostState = getHostState(element);\n\n            settings.activeView = hostState.activeView;\n            settings.parent = element;\n            settings.triggerAttach = triggerAttach;\n            settings.bindingContext = bindingContext;\n\n            if (settings.cacheViews && !settings.viewElements) {\n                settings.viewElements = hostState.childElements;\n            }\n\n            if (!settings.model) {\n                if (!settings.view) {\n                    this.bindAndShow(null, settings);\n                } else {\n                    settings.area = settings.area || 'partial';\n                    settings.preserveContext = true;\n\n                    viewLocator.locateView(settings.view, settings.area, settings.viewElements).then(function (child) {\n                        composition.bindAndShow(child, settings);\n                    });\n                }\n            } else if (system.isString(settings.model)) {\n                system.acquire(settings.model).then(function (module) {\n                    settings.model = system.resolveObject(module);\n                    composition.inject(settings);\n                }).fail(function(err){\n                    system.error('Failed to load composed module (' + settings.model + '). Details: ' + err.message);\n                });\n            } else {\n                composition.inject(settings);\n            }\n        }", "label": 3}
{"code": "public function getResumableUploader($data, array $options = [])\n    {\n        if ($this->isObjectNameRequired($data) && !isset($options['name'])) {\n            throw new \\InvalidArgumentException('A name is required when data is of type string or null.');\n        }\n\n        return $this->connection->insertObject(\n            $this->formatEncryptionHeaders($options) + $this->identity + [\n                'data' => $data,\n                'resumable' => true\n            ]\n        );\n    }", "label": 2}
{"code": "def dispatch(self, request, *args, **kwargs):\n        \"\"\"\n        This method gets called by the routing engine. The first argument is\n        `request` which contains a `HttpRequest` instance.\n        The request is stored in `self.request` for later use. The storage\n        instance is stored in `self.storage`.\n\n        After processing the request using the `dispatch` method, the\n        response gets updated by the storage engine (for example add cookies).\n        \"\"\"\n        # add the storage engine to the current formwizard instance\n        self.wizard_name = self.get_wizard_name()\n        self.prefix = self.get_prefix()\n        self.storage = get_storage(self.storage_name, self.prefix, request,\n            getattr(self, 'file_storage', None))\n        self.steps = StepsHelper(self)\n        response = super(WizardView, self).dispatch(request, *args, **kwargs)\n\n        # update the response (e.g. adding cookies)\n        self.storage.update_response(response)\n        return response", "label": 1}
{"code": "public static dbdbprofile[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tdbdbprofile obj = new dbdbprofile();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tdbdbprofile[] response = (dbdbprofile[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def getMethodByName(obj, name):\n\n    \"\"\"searches for an object with the name given inside the object given.\n       \"obj.child.meth\" will return the meth obj.\n    \"\"\"\n    try:#to get a method by asking the service\n        obj = obj._getMethodByName(name)\n    except:\n        #assumed a childObject is ment \n        #split the name from objName.childObjName... -> [objName, childObjName, ...]\n        #and get all objects up to the last in list with name checking from the service object\n        names = name.split(\".\")\n        for name in names:\n            if nameAllowed(name):\n                obj = getattr(obj, name)\n            else:\n                raise MethodNameNotAllowed()\n        \n    return obj", "label": 1}
{"code": "function(callback, context)\n  {\n    var db = this;\n    var promise = new Promise();\n    var success = this.handleRefreshSuccess( promise );\n    var failure = this.handleRefreshFailure( promise );\n\n    promise.complete( callback, context || db );\n\n    batchExecute(function()\n    {\n      db.executeRefresh( success, failure );\n    });\n\n    return promise;\n  }", "label": 3}
{"code": "def lookup_hist(self, mh):\n        \"\"\"Return histogram within binning of Histdd mh, with values looked up in this histogram.\n\n        This is not rebinning: no interpolation /renormalization is performed.\n        It's just a lookup.\n        \"\"\"\n        result = mh.similar_blank_histogram()\n        points = np.stack([mh.all_axis_bin_centers(i)\n                           for i in range(mh.dimensions)]).reshape(mh.dimensions, -1)\n        values = self.lookup(*points)\n        result.histogram = values.reshape(result.histogram.shape)\n        return result", "label": 1}
{"code": "public function validateScopes($scopes, $redirectUri = null)\n    {\n        if (!\\is_array($scopes)) {\n            $scopes = $this->convertScopesQueryStringToArray($scopes);\n        }\n\n        $validScopes = [];\n\n        foreach ($scopes as $scopeItem) {\n            $scope = $this->scopeRepository->getScopeEntityByIdentifier($scopeItem);\n\n            if ($scope instanceof ScopeEntityInterface === false) {\n                throw OAuthServerException::invalidScope($scopeItem, $redirectUri);\n            }\n\n            $validScopes[] = $scope;\n        }\n\n        return $validScopes;\n    }", "label": 2}
{"code": "func (cli *NetworkCli) CmdNetworkRm(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"rm\", \"NETWORK\", \"Deletes a network\", false)\n\tcmd.Require(flag.Exact, 1)\n\terr := cmd.ParseFlags(args, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\tid, err := lookupNetworkID(cli, cmd.Arg(0))\n\tif err != nil {\n\t\treturn err\n\t}\n\t_, _, err = readBody(cli.call(\"DELETE\", \"/networks/\"+id, nil, nil))\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func (i *IpamInfo) MarshalJSON() ([]byte, error) {\n\tm := map[string]interface{}{\n\t\t\"PoolID\": i.PoolID,\n\t}\n\tv, err := json.Marshal(&i.IPAMData)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm[\"IPAMData\"] = string(v)\n\n\tif i.Meta != nil {\n\t\tm[\"Meta\"] = i.Meta\n\t}\n\treturn json.Marshal(m)\n}", "label": 5}
{"code": "def delete(item)\n      SidekiqUniqueJobs::UniqueArgs.digest(item)\n      SidekiqUniqueJobs::Locksmith.new(item).delete!\n    end", "label": 4}
{"code": "function Rekord(options)\n{\n  var promise = Rekord.get( options.name );\n\n  if ( promise.isComplete() )\n  {\n    return promise.results[0];\n  }\n\n  Rekord.trigger( Rekord.Events.Options, [options] );\n\n  var database = new Database( options );\n\n  var model = Class.dynamic(\n    Model,\n    new Model( database ),\n    database.className,\n    '(props, remoteData) { this.$init( props, remoteData ) }'\n  );\n\n  database.Model = model;\n  model.Database = database;\n\n  Rekord.classes[ database.name ] = model;\n\n  Rekord.trigger( Rekord.Events.Plugins, [model, database, options] );\n\n  if ( Rekord.autoload )\n  {\n    database.loadBegin(function onLoadFinish(success)\n    {\n      if ( success )\n      {\n        database.loadFinish();\n      }\n    });\n  }\n  else\n  {\n    Rekord.unloaded.push( database );\n  }\n\n  Rekord.get( database.name ).resolve( model );\n  Rekord.get( database.className ).resolve( model );\n\n  Rekord.debug( Rekord.Debugs.CREATION, database, options );\n\n  return model;\n}", "label": 3}
{"code": "private void cascadeMarkedForDeletion()\r\n    {\r\n        List alreadyPrepared = new ArrayList();\r\n        for(int i = 0; i < markedForDeletionList.size(); i++)\r\n        {\r\n            ObjectEnvelope mod = (ObjectEnvelope) markedForDeletionList.get(i);\r\n            // if the object wasn't associated with another object, start cascade delete\r\n            if(!isNewAssociatedObject(mod.getIdentity()))\r\n            {\r\n                cascadeDeleteFor(mod, alreadyPrepared);\r\n                alreadyPrepared.clear();\r\n            }\r\n        }\r\n        markedForDeletionList.clear();\r\n    }", "label": 0}
{"code": "function _gpfErrorDeclare (source, dictionary) {\n    _gpfIgnore(source);\n    _gpfObjectForEach(dictionary, function (message, name) {\n        var code = ++_gpfLastErrorCode;\n        gpf.Error[\"CODE_\" + name.toUpperCase()] = code;\n        gpf.Error[name] = _gpfGenenerateErrorFunction(code, name, message);\n    });\n}", "label": 3}
{"code": "def find_in_batches(start: nil, finish: nil, batch_size: 1000, error_on_ignore: nil)\n      relation = self\n      unless block_given?\n        return to_enum(:find_in_batches, start: start, finish: finish, batch_size: batch_size, error_on_ignore: error_on_ignore) do\n          total = apply_limits(relation, start, finish).size\n          (total - 1).div(batch_size) + 1\n        end\n      end\n\n      in_batches(of: batch_size, start: start, finish: finish, load: true, error_on_ignore: error_on_ignore) do |batch|\n        yield batch.to_a\n      end\n    end", "label": 4}
{"code": "@Override\n\tpublic void visit(Rule rule) {\n\t\tRule copy = null;\n\t\tFilter filterCopy = null;\n\n\t\tif (rule.getFilter() != null) {\n\t\t\tFilter filter = rule.getFilter();\n\t\t\tfilterCopy = copy(filter);\n\t\t}\n\n\t\tList<Symbolizer> symsCopy = new ArrayList<Symbolizer>();\n\t\tfor (Symbolizer sym : rule.symbolizers()) {\n\t\t\tif (!skipSymbolizer(sym)) {\n\t\t\t\tSymbolizer symCopy = copy(sym);\n\t\t\t\tsymsCopy.add(symCopy);\n\t\t\t}\n\t\t}\n\n\t\tGraphic[] legendCopy = rule.getLegendGraphic();\n\t\tfor (int i = 0; i < legendCopy.length; i++) {\n\t\t\tlegendCopy[i] = copy(legendCopy[i]);\n\t\t}\n\n\t\tDescription descCopy = rule.getDescription();\n\t\tdescCopy = copy(descCopy);\n\n\t\tcopy = sf.createRule();\n\t\tcopy.symbolizers().addAll(symsCopy);\n\t\tcopy.setDescription(descCopy);\n\t\tcopy.setLegendGraphic(legendCopy);\n\t\tcopy.setName(rule.getName());\n\t\tcopy.setFilter(filterCopy);\n\t\tcopy.setElseFilter(rule.isElseFilter());\n\t\tcopy.setMaxScaleDenominator(rule.getMaxScaleDenominator());\n\t\tcopy.setMinScaleDenominator(rule.getMinScaleDenominator());\n\n\t\tif (STRICT && !copy.equals(rule)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Was unable to duplicate provided Rule:\" + rule);\n\t\t}\n\t\tpages.push(copy);\n\t}", "label": 0}
{"code": "func getDictField(dict reflect.Value, key string) dictField {\n\t// get valuev as a map value or as a struct field\n\tswitch dict.Kind() {\n\tcase reflect.Map:\n\t\tvalue := reflect.New(dict.Type().Elem()).Elem()\n\t\treturn dictField{\n\t\t\tValue: value,\n\t\t\tOk:    true,\n\t\t\tSet: func() {\n\t\t\t\tif dict.IsNil() {\n\t\t\t\t\tdict.Set(reflect.MakeMap(dict.Type()))\n\t\t\t\t}\n\t\t\t\t// Assigns the value into the map.\n\t\t\t\tdict.SetMapIndex(reflect.ValueOf(key).Convert(dict.Type().Key()), value)\n\t\t\t},\n\t\t}\n\tcase reflect.Struct:\n\t\tsf, ok := getStructFieldForKey(dict.Type(), key)\n\t\tif !ok {\n\t\t\treturn dictField{}\n\t\t}\n\t\tif sf.r.PkgPath != \"\" {\n\t\t\tpanic(&UnmarshalFieldError{\n\t\t\t\tKey:   key,\n\t\t\t\tType:  dict.Type(),\n\t\t\t\tField: sf.r,\n\t\t\t})\n\t\t}\n\t\treturn dictField{\n\t\t\tValue: dict.FieldByIndex(sf.r.Index),\n\t\t\tOk:    true,\n\t\t\tSet:   func() {},\n\t\t\tIgnoreUnmarshalTypeError: sf.tag.IgnoreUnmarshalTypeError(),\n\t\t}\n\tdefault:\n\t\treturn dictField{}\n\t}\n}", "label": 5}
{"code": "function next( ret ) {\n            if( ret.done ) {\n                return resolve( ret.value );\n            }\n            var value = toPromise.call( ctx, ret.value );\n            if( value && isPromise( value ) ) {\n                return value.then( onFulfilled, onRejected );\n            }\n            return onRejected( new TypeError( 'You may only yield a function, promise, generator, array, or object, '\n                                              + 'but the following object was passed: \"' + String( ret.value )\n                                              + '\"' ) );\n        }", "label": 3}
{"code": "public static function verifyServices(array $config, Request $request = null)\n    {\n        $request = (isset($request)) ? $request : Request::createFromGlobals();\n        foreach (self::getAvailableHttpDrivers() as $driver) {\n            $driver = new $driver($request, $config, new Curl());\n            if ($driver instanceof VerifiesService && ! is_null($driver->verifyRequest($request))) {\n                return true;\n            }\n        }\n\n        return false;\n    }", "label": 2}
{"code": "func (s *Server) Shutdown(ctx context.Context) error {\n\t// wait until connections drain off\n\terr := s.srv.Shutdown(ctx)\n\ts.cancel()\n\ts.reg.Close()\n\tif s.heartbeat != nil {\n\t\tif err := s.heartbeat.Close(); err != nil {\n\t\t\ts.Warningf(\"Failed to close heartbeat: %v.\", err)\n\t\t}\n\t\ts.heartbeat = nil\n\t}\n\treturn err\n}", "label": 5}
{"code": "def value=(path)\n      path = path.gsub(File::SEPARATOR, File::ALT_SEPARATOR) if File::ALT_SEPARATOR\n      element_call { @element.send_keys path }\n    end", "label": 4}
{"code": "public int compare(final Version other) throws IncomparableException{\n\t\t// Cannot compare branch versions and others \n\t\tif(!isBranch().equals(other.isBranch())){\n\t\t\tthrow new IncomparableException();\n\t\t}\n\t\t\n\t\t// Compare digits\n\t\tfinal int minDigitSize = getDigitsSize() < other.getDigitsSize()? getDigitsSize(): other.getDigitsSize();\n\t\t\n\t\tfor(int i = 0; i < minDigitSize ; i++){\n\t\t\tif(!getDigit(i).equals(other.getDigit(i))){\n\t\t\t\treturn getDigit(i).compareTo(other.getDigit(i));\n\t\t\t}\n\t\t}\n\t\t\n\t\t// If not the same number of digits and the first digits are equals, the longest is the newer\n\t\tif(!getDigitsSize().equals(other.getDigitsSize())){\n\t\t\treturn getDigitsSize() > other.getDigitsSize()? 1: -1;\n\t\t}\n\n        if(isBranch() && !getBranchId().equals(other.getBranchId())){\n\t\t\treturn getBranchId().compareTo(other.getBranchId());\n\t\t}\n\t\t\n\t\t// if the digits are the same, a snapshot is newer than a release\n\t\tif(isSnapshot() && other.isRelease()){\n\t\t\treturn 1;\n\t\t}\n\t\t\n\t\tif(isRelease() && other.isSnapshot()){\n\t\t\treturn -1;\n\t\t}\n\t\t\n\t\t// if both versions are releases, compare the releaseID\n\t\tif(isRelease() && other.isRelease()){\n\t\t\treturn getReleaseId().compareTo(other.getReleaseId());\n\t\t}\n\t\t\n\t\treturn 0;\n\t}", "label": 0}
{"code": "private function filter($items, $path, $type)\n    {\n        if (!$items) {\n            return null;\n        }\n\n        return array_filter($items, function ($item) use ($path, $type) {\n            $itemCopy = $item;\n\n            // key into the value with the given path\n            foreach ($path as $key) {\n                $itemCopy = $itemCopy[$key];\n            }\n\n            if (strtolower($itemCopy) === strtolower($type)) {\n                return $item;\n            }\n        });\n    }", "label": 2}
{"code": "def fresh(options = {})\n      @profile_name = nil\n      @credentials_path = nil\n      @config_path = nil\n      @parsed_credentials = {}\n      @parsed_config = nil\n      @config_enabled = options[:config_enabled] ? true : false\n      @profile_name = determine_profile(options)\n      @credentials_path = options[:credentials_path] ||\n        determine_credentials_path\n      load_credentials_file if loadable?(@credentials_path)\n      if @config_enabled\n        @config_path = options[:config_path] || determine_config_path\n        load_config_file if loadable?(@config_path)\n      end\n    end", "label": 4}
{"code": "func (l VirtualDeviceList) EjectIso(device *types.VirtualCdrom) *types.VirtualCdrom {\n\tl.setDefaultCdromBacking(device)\n\treturn device\n}", "label": 5}
{"code": "function (uuid) {\n        var intervalData = null;\n        var i = 0;\n        var len = 0;\n        var actionData = null;\n\n        if (typeof uuid !== 'string') {\n            return false;\n        }\n\n        intervalData = uuidMap[uuid];\n\n        if (!intervalData) {\n            return false;\n        }\n\n        uuidMap[uuid] = null;\n\n        len = intervalData.actions.length;\n\n        for (; i < len; i += 1) {\n            actionData = intervalData.actions[i];\n            if (actionData.uuid === uuid) {\n                intervalData.actions.splice(i, 1);\n                break;\n            }\n        }\n\n        if (intervalData.actions.length === 0) {\n            clearInterval(intervalData.id);\n            intervalsMap[intervalData.interval] = null;\n        }\n\n        return true;\n    }", "label": 3}
{"code": "def handle_input(self, input_hdr):\n        \"\"\"\n        This method tries to ensure that the input data has the correct dimensions.\n\n        INPUTS:\n        input_hdr   (no default)    Header from which data shape is to be extracted.\n        \"\"\"\n\n        input_slice = input_hdr['NAXIS']*[0]\n\n        for i in range(input_hdr['NAXIS']):\n            if input_hdr['CTYPE%d'%(i+1)].startswith(\"RA\"):\n                input_slice[-1] = slice(None)\n            if input_hdr['CTYPE%d'%(i+1)].startswith(\"DEC\"):\n                input_slice[-2] = slice(None)\n\n        return input_slice", "label": 1}
{"code": "func (fe *fieldError) Error() string {\n\treturn fmt.Sprintf(fieldErrMsg, fe.ns, fe.Field(), fe.tag)\n}", "label": 5}
{"code": "def add_reads(self, reads):\n        \"\"\"\n        Create another VariantSequence with more supporting reads.\n        \"\"\"\n        if len(reads) == 0:\n            return self\n        new_reads = self.reads.union(reads)\n        if len(new_reads) > len(self.reads):\n            return VariantSequence(\n                prefix=self.prefix,\n                alt=self.alt,\n                suffix=self.suffix,\n                reads=new_reads)\n        else:\n            return self", "label": 1}
{"code": "def __getStationName(name, id):\n    \"\"\"Construct a staiion name.\"\"\"\n    name = name.replace(\"Meetstation\", \"\")\n    name = name.strip()\n    name += \" (%s)\" % id\n    return name", "label": 1}
{"code": "public function setResult($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\InspectDataSourceDetails_Result::class);\n        $this->result = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function handleCommandError(ex) {\n    // If the command throws an exception, display the error message and command help.\n    if (ex instanceof Error) {\n        console.log(chalk.red(ex.message));\n    } else {\n        console.log(chalk.red(ex));\n    }\n    console.log();\n    const helpArgs = {\n        _: [command]\n    };\n    helpCommand(helpArgs);\n}", "label": 3}
{"code": "function name(fp, options) {\n  var opts = options || {};\n  if (typeof opts.namespace === 'function') {\n    return opts.namespace(fp, opts);\n  }\n  if (typeof opts.namespace === false) {\n    return fp;\n  }\n  var ext = path.extname(fp);\n  return path.basename(fp, ext);\n}", "label": 3}
{"code": "func (a *allocator) ReleasePool(poolID string) error {\n\treq := &api.ReleasePoolRequest{PoolID: poolID}\n\tres := &api.ReleasePoolResponse{}\n\treturn a.call(\"ReleasePool\", req, res)\n}", "label": 5}
{"code": "def checklist(ctx):\n    \"\"\"Checklist for releasing this project.\"\"\"\n    checklist = \"\"\"PRE-RELEASE CHECKLIST:\n[ ]  Everything is checked in\n[ ]  All tests pass w/ tox\n\nRELEASE CHECKLIST:\n[{x1}]  Bump version to new-version and tag repository (via bump_version)\n[{x2}]  Build packages (sdist, bdist_wheel via prepare)\n[{x3}]  Register and upload packages to testpypi repository (first)\n[{x4}]    Verify release is OK and packages from testpypi are usable\n[{x5}]  Register and upload packages to pypi repository\n[{x6}]  Push last changes to Github repository\n\nPOST-RELEASE CHECKLIST:\n[ ]  Bump version to new-develop-version (via bump_version)\n[ ]  Adapt CHANGES (if necessary)\n[ ]  Commit latest changes to Github repository\n\"\"\"\n    steps = dict(x1=None, x2=None, x3=None, x4=None, x5=None, x6=None)\n    yesno_map = {True: \"x\", False: \"_\", None: \" \"}\n    answers = {name: yesno_map[value]\n               for name, value in steps.items()}\n    print(checklist.format(**answers))", "label": 1}
{"code": "public List<String> subList(final long fromIndex, final long toIndex) {\n        return doWithJedis(new JedisCallable<List<String>>() {\n            @Override\n            public List<String> call(Jedis jedis) {\n                return jedis.lrange(getKey(), fromIndex, toIndex);\n            }\n        });\n    }", "label": 0}
{"code": "protected static boolean fileDoesNotExist(String file, String path,\n            String dest_dir) {\n\n        File f = new File(dest_dir);\n        if (!f.isDirectory())\n            return false;\n\n        String folderPath = createFolderPath(path);\n\n        f = new File(f, folderPath);\n\n        File javaFile = new File(f, file);\n        boolean result = !javaFile.exists();\n\n        return result;\n    }", "label": 0}
{"code": "public static base_response change(nitro_service client, responderhtmlpage resource) throws Exception {\n\t\tresponderhtmlpage updateresource = new responderhtmlpage();\n\t\tupdateresource.name = resource.name;\n\t\treturn updateresource.perform_operation(client,\"update\");\n\t}", "label": 0}
{"code": "func ExistChain(chain string, table Table) bool {\n\tif _, err := Raw(\"-t\", string(table), \"-nL\", chain); err == nil {\n\t\treturn true\n\t}\n\treturn false\n}", "label": 5}
{"code": "function (values, options, callback) {\n                var deferred = Q.defer();\n                var args = ArgumentHelpers.prepareArguments(options, callback)\n                    , wrapper = {};\n                options = args.options;\n                callback = Qext.makeNodeResolver(deferred, args.callback);\n\n                //Check for mongo's another possible syntax with '$' operators, e.g. '$set', '$setOnInsert' and set wrapper\n                values = values || {};\n\n                for (var element in values) {\n                    if (element.match(/\\$/i)) {\n                        wrapper[element] = values[element];\n                        options.flat = options.flat != undefined ? options.flat : true\n                    }\n                }\n\n                // If nothing to wrap just validate values\n                if (_.isEmpty(wrapper)) {\n                    ModelValidator.validate(values, this.prototype, options, function (err, validatedValues) {\n                        callback(err, validatedValues);\n                    });\n                }\n                else {\n                    // If wrapping elements like $set, $inc etc found, validate each and rewrite to values\n                    values = {};\n                    var errors = {};\n                    var wrapperOptions = {};\n                    for (var wrapperElem in wrapper) {\n\n                        wrapperOptions = _.clone(options);\n                        if (options && options.partial && _.isObject(options.partial)) {\n                            if (options.partial[wrapperElem] !== undefined) {\n                                wrapperOptions['partial'] = options.partial[wrapperElem];\n                            }\n                        }\n\n                        if (options && options.validate && _.isObject(options.validate)) {\n                            if (options.validate[wrapperElem] !== undefined) {\n                                wrapperOptions['validate'] = options.validate[wrapperElem];\n                            }\n                        }\n\n                        if (options.validate && options.validate[wrapperElem] === false) {\n                            values[wrapperElem] = wrapper[wrapperElem];\n                        }\n                        else {\n                            ModelValidator.validate(wrapper[wrapperElem], this.prototype, wrapperOptions, function (err, validatedValues) {\n                                if (err) {\n                                    errors = err;\n                                }\n                                values[wrapperElem] = validatedValues;\n                            });\n                        }\n                    }\n\n                    if (_.isEmpty(errors)) {\n                        errors = null;\n                    }\n                    callback(errors, values);\n                }\n\n                return deferred.promise;\n            }", "label": 3}
{"code": "def wait_until(depr_timeout = nil, depr_message = nil, timeout: nil, message: nil, interval: nil, **opt, &blk)\n      if depr_message || depr_timeout\n        Watir.logger.deprecate 'Using arguments for #wait_until', 'keywords', ids: [:timeout_arguments]\n        timeout = depr_timeout\n        message = depr_message\n      end\n      message ||= proc { |obj| \"waiting for true condition on #{obj.inspect}\" }\n\n      # TODO: Consider throwing argument error for mixing block & options\n      proc = create_proc(opt, &blk)\n\n      Wait.until(timeout: timeout, message: message, interval: interval, object: self, &proc)\n\n      self\n    end", "label": 4}
{"code": "public function destroy($id)\n    {\n        $this->openSessionId = $id;\n        // Delete the session data using the selected locking strategy\n        $this->sessionWritten\n            = $this->connection->delete($this->formatId($id));\n\n        return $this->sessionWritten;\n    }", "label": 2}
{"code": "public function setProductGroupedResults($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\ProductSearchResults\\GroupedResult::class);\n        $this->product_grouped_results = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def print_status(raw_status, strip_units=False):\n    \"\"\"\n    Print the status to stdout in the same format as the original apcaccess.\n    \"\"\"\n    lines = split(raw_status)\n    if strip_units:\n        lines = strip_units_from_lines(lines)\n    for line in lines:\n        print(line)", "label": 1}
{"code": "func getTmpROC(s *imagestore.Store, path string) (*removeOnClose, error) {\n\th := sha512.New()\n\th.Write([]byte(path))\n\tpathHash := s.HashToKey(h)\n\n\ttmp, err := s.TmpNamedFile(pathHash)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"error setting up temporary file\"), err)\n\t}\n\n\t// let's lock the file to avoid concurrent writes to the temporary file, it\n\t// will go away when removing the temp file\n\t_, err = lock.TryExclusiveLock(tmp.Name(), lock.RegFile)\n\tif err != nil {\n\t\tif err != lock.ErrLocked {\n\t\t\treturn nil, errwrap.Wrap(errors.New(\"failed to lock temporary file\"), err)\n\t\t}\n\t\tlog.Printf(\"another rkt instance is downloading this file, waiting...\")\n\t\t_, err = lock.ExclusiveLock(tmp.Name(), lock.RegFile)\n\t\tif err != nil {\n\t\t\treturn nil, errwrap.Wrap(errors.New(\"failed to lock temporary file\"), err)\n\t\t}\n\t}\n\n\treturn &removeOnClose{File: tmp}, nil\n}", "label": 5}
{"code": "func (s *service) removeIPToEndpoint(ip, eID string) (bool, int) {\n\treturn s.ipToEndpoint.Remove(ip, eID)\n}", "label": 5}
{"code": "public static nsacl6 get(nitro_service service, String acl6name) throws Exception{\n\t\tnsacl6 obj = new nsacl6();\n\t\tobj.set_acl6name(acl6name);\n\t\tnsacl6 response = (nsacl6) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _confidence(matches, ext=None):\n    \"\"\" Rough confidence based on string length and file extension\"\"\"\n    results = []\n    for match in matches:\n        con = (0.8 if len(match.extension) > 9 else\n               float(\"0.{0}\".format(len(match.extension))))\n        if ext == match.extension:\n            con = 0.9\n        results.append(\n            PureMagicWithConfidence(confidence=con, **match._asdict()))\n    return sorted(results, key=lambda x: x.confidence, reverse=True)", "label": 1}
{"code": "function createBasicTranslation(memberName, type, i, options) {\n  var node = {};\n\n  node[\"id\"] = memberName;\n  node[\"type\"] = type;\n\n  if (i[\"inheritdoc\"] !== undefined) {\n    node[\"inheritdoc\"] = i[\"inheritdoc\"].src;\n  }\n  else if (i[\"doc\"] !== undefined) {\n    node[\"description\"] = i[\"doc\"];\n    // short description lasts until the first empty line\n    node[\"short_description\"] = node[\"description\"].replace(/\\n\\n[\\s\\S]*$/, '\\n');\n  }\n  else {\n    node[\"undocumented\"] = true;\n  }\n\n  node[\"line\"] = i[\"linenr\"];\n\n  if (i[\"private\"] !== undefined)\n    node[\"private\"] = i[\"private\"];\n\n  if (i[\"experimental\"] !== undefined)\n    node[\"experimental\"] = i[\"experimental\"];\n\n  if (i[\"ignore\"] !== undefined)\n    node[\"ignore\"] = i[\"ignore\"];\n    \n  if (i[\"chainable\"] !== undefined)\n    node[\"chainable\"] = i[\"chainable\"];\n\n  if (i[\"see\"] !== undefined)\n    node[\"related_to\"] = i[\"see\"].name;\n\n  if (i[\"author\"] !== undefined && i[\"author\"].length > 0)\n    node[\"author\"] = i[\"author\"].doc;\n  \n  if (i[\"version\"] !== undefined)\n    node[\"version\"] = i[\"version\"].doc;\n  \n  if (i[\"since\"] !== undefined)\n    node[\"since\"] = i[\"since\"].doc;\n\n  if (i[\"author\"] !== undefined)\n    node[\"author\"] = i[\"author\"];\n\n  if (i[\"related\"] !== undefined)\n    node[\"related\"] = i[\"related\"].name;\n\n  if (options.customTags) {\n    _.each(options.customTags, function(tag) {\n      if (i[tag] !== undefined)\n        node[tag] = i[tag];\n    });\n  }\n\n  return node;\n}", "label": 3}
{"code": "protected function preOrder($payload): Collection\n    {\n        $payload['sign'] = Support::generateSign($payload);\n\n        Events::dispatch(Events::METHOD_CALLED, new Events\\MethodCalled('Wechat', 'PreOrder', '', $payload));\n\n        return Support::requestApi('pay/unifiedorder', $payload);\n    }", "label": 2}
{"code": "def set_sensitive_parameters(sensitive_parameters)\n    sensitive_parameters.each do |name|\n      p = parameter(name)\n      if p.is_a?(Puppet::Property)\n        p.sensitive = true\n      elsif p.is_a?(Puppet::Parameter)\n        warning(_(\"Unable to mark '%{name}' as sensitive: %{name} is a parameter and not a property, and cannot be automatically redacted.\") %\n                    { name: name })\n      elsif self.class.attrclass(name)\n        warning(_(\"Unable to mark '%{name}' as sensitive: the property itself was not assigned a value.\") % { name: name })\n      else\n        err(_(\"Unable to mark '%{name}' as sensitive: the property itself is not defined on %{type}.\") % { name: name, type: type })\n      end\n    end\n\n    parameters.each do |name, param|\n      next if param.sensitive\n      if param.is_a?(Puppet::Parameter)\n        param.sensitive = param.is_sensitive if param.respond_to?(:is_sensitive)\n      end\n    end\n  end", "label": 4}
{"code": "func (self *Transcoder) Streams() (streams []av.CodecData, err error) {\n\tfor _, stream := range self.streams {\n\t\tstreams = append(streams, stream.codec)\n\t}\n\treturn\n}", "label": 5}
{"code": "public void processField(String template, Properties attributes) throws XDocletException\r\n    {\r\n        String             name              = OjbMemberTagsHandler.getMemberName();\r\n        String             defaultType       = getDefaultJdbcTypeForCurrentMember();\r\n        String             defaultConversion = getDefaultJdbcConversionForCurrentMember();\r\n        FieldDescriptorDef fieldDef          = _curClassDef.getField(name);\r\n        String             attrName;\r\n\r\n        if (fieldDef == null)\r\n        {\r\n            fieldDef = new FieldDescriptorDef(name);\r\n            _curClassDef.addField(fieldDef);\r\n        }\r\n        LogHelper.debug(false, OjbTagsHandler.class, \"processField\", \"  Processing field \"+fieldDef.getName());\r\n\r\n        for (Enumeration attrNames = attributes.propertyNames(); attrNames.hasMoreElements(); )\r\n        {\r\n            attrName = (String)attrNames.nextElement();\r\n            fieldDef.setProperty(attrName, attributes.getProperty(attrName));\r\n        }\r\n        // storing additional info for later use\r\n        fieldDef.setProperty(PropertyHelper.OJB_PROPERTY_JAVA_TYPE,\r\n                             OjbMemberTagsHandler.getMemberType().getQualifiedName());\r\n        fieldDef.setProperty(PropertyHelper.OJB_PROPERTY_DEFAULT_JDBC_TYPE, defaultType);\r\n        if (defaultConversion != null)\r\n        {    \r\n            fieldDef.setProperty(PropertyHelper.OJB_PROPERTY_DEFAULT_CONVERSION, defaultConversion);\r\n        }\r\n\r\n        _curFieldDef = fieldDef;\r\n        generate(template);\r\n        _curFieldDef = null;\r\n    }", "label": 0}
{"code": "def locale=(value)\n      if value\n        config = I18n.config.respond_to?(:original_config) ? I18n.config.original_config : I18n.config\n        config.locale = value\n      end\n\n      super(default_locale)\n    end", "label": 4}
{"code": "def get_defaults():\n    \"\"\"\n    Returns a dictionary of variables and their possibly os-dependent defaults.\n    \n    \"\"\"\n    DEFAULTS = {}\n    # Determine the run-time pipe read/write buffer.\n    if 'PC_PIPE_BUF' in os.pathconf_names:\n        # unix\n        x, y = os.pipe()\n        DEFAULTS['PIPE_BUF'] = os.fpathconf(x, \"PC_PIPE_BUF\")\n    else:\n        # in Jython 16384\n        # on windows 512\n        # in jython in windows 512\n        DEFAULTS['PIPE_BUF'] = 512\n\n    # Determine the run-time socket buffers.\n    # Note that this number is determine on the papy server\n    # and inherited by the clients.\n    tcp_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    DEFAULTS['TCP_SNDBUF'] = tcp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_SNDBUF)\n    DEFAULTS['TCP_RCVBUF'] = tcp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_RCVBUF)\n    udp_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    DEFAULTS['UDP_SNDBUF'] = udp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_SNDBUF)\n    DEFAULTS['UDP_RCVBUF'] = udp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_RCVBUF)\n\n    # check the ip visible from the world.\n    DEFAULTS['WHATS_MYIP_URL'] = \\\n    'http://www.whatismyip.com/automation/n09230945.asp'\n    return DEFAULTS", "label": 1}
{"code": "public static function catch($e, $tags = [])\n    {\n        if ($e instanceof Throwable && ! $e instanceof Exception) {\n            $e = new FatalThrowableError($e);\n        }\n\n        event(new MessageLogged('error', $e->getMessage(), [\n            'exception' => $e,\n            'telescope' => $tags,\n        ]));\n    }", "label": 2}
{"code": "func (a *ArgType) BuildIndexFuncName(ixTpl *Index) {\n\t// build func name\n\tfuncName := ixTpl.Type.Name\n\tif !ixTpl.Index.IsUnique {\n\t\tfuncName = inflector.Pluralize(ixTpl.Type.Name)\n\t}\n\tfuncName = funcName + \"By\"\n\n\t// add param names\n\tparamNames := []string{}\n\n\tixName := fmtIndexName(ixTpl.Index.IndexName, ixTpl.Type.Table.TableName)\n\tif a.UseIndexNames && ixName != \"\" {\n\t\tparamNames = append(paramNames, ixName)\n\t} else {\n\t\tfor _, f := range ixTpl.Fields {\n\t\t\tparamNames = append(paramNames, f.Name)\n\t\t}\n\t}\n\n\t// store resulting name back\n\tixTpl.FuncName = funcName + strings.Join(paramNames, \"\")\n}", "label": 5}
{"code": "function canFollow(keyword1, keyword2) {\n            if (ts.isAccessibilityModifier(keyword1)) {\n                if (keyword2 === 123 /* GetKeyword */ ||\n                    keyword2 === 131 /* SetKeyword */ ||\n                    keyword2 === 121 /* ConstructorKeyword */ ||\n                    keyword2 === 113 /* StaticKeyword */) {\n                    // Allow things like \"public get\", \"public constructor\" and \"public static\".\n                    // These are all legal.\n                    return true;\n                }\n                // Any other keyword following \"public\" is actually an identifier an not a real\n                // keyword.\n                return false;\n            }\n            // Assume any other keyword combination is legal.  This can be refined in the future\n            // if there are more cases we want the classifier to be better at.\n            return true;\n        }", "label": 3}
{"code": "func OptionExecRoot(execRoot string) Option {\n\treturn func(c *Config) {\n\t\tc.Daemon.ExecRoot = execRoot\n\t\tosl.SetBasePath(execRoot)\n\t}\n}", "label": 5}
{"code": "def to_s\n      str = ''\n      if @width > 0\n        fmt = @width.truncate == @width ? '%d' : '%.2f'\n        str << format(fmt, @width)\n        str << '%' if @flag == PercentGeometry\n      end\n\n      str << 'x' if (@width > 0 && @flag != PercentGeometry) || (@height > 0)\n\n      if @height > 0\n        fmt = @height.truncate == @height ? '%d' : '%.2f'\n        str << format(fmt, @height)\n        str << '%' if @flag == PercentGeometry\n      end\n      str << format('%+d%+d', @x, @y) if @x != 0 || @y != 0\n      str << FLAGS[@flag.to_i] if @flag != PercentGeometry\n      str\n    end", "label": 4}
{"code": "def invitation_instructions(user, token, opts = {})\n      with_user(user) do\n        @token = token\n        @organization = user.organization\n        @opts = opts\n\n        opts[:subject] = I18n.t(\"devise.mailer.#{opts[:invitation_instructions]}.subject\", organization: user.organization.name) if opts[:invitation_instructions]\n      end\n\n      devise_mail(user, opts[:invitation_instructions] || :invitation_instructions, opts)\n    end", "label": 4}
{"code": "public function log($level, $message, array $context = [])\n    {\n        $this->validateLogLevel($level);\n        $options = [];\n\n        if (isset($context['exception'])\n            && ($context['exception'] instanceof \\Exception || $context['exception'] instanceof \\Throwable)) {\n            $context['exception'] = (string) $context['exception'];\n        }\n\n        if (isset($context['stackdriverOptions'])) {\n            $options = $context['stackdriverOptions'];\n            unset($context['stackdriverOptions']);\n        }\n\n        $formatter = new NormalizerFormatter();\n        $processor = new PsrLogMessageProcessor();\n        $processedData = $processor([\n            'message' => (string) $message,\n            'context' => $formatter->format($context)\n        ]);\n        $jsonPayload = [$this->messageKey => $processedData['message']];\n\n        // Adding labels for log request correlation.\n        $labels = $this->getLabels();\n        if (!empty($labels)) {\n            $options['labels'] =\n                (isset($options['labels'])\n                 ? $options['labels']\n                 : []) + $labels;\n            // Copy over the value for 'appengine.googleapis.com/trace_id' to\n            // `trace` option too.\n            if (isset($labels['appengine.googleapis.com/trace_id'])) {\n                $options['trace'] =\n                    $labels['appengine.googleapis.com/trace_id'];\n            }\n        }\n        // Adding MonitoredResource\n        $resource = $this->metadataProvider->monitoredResource();\n        if (!empty($resource)) {\n            $options['resource'] =\n                (isset($options['resource'])\n                 ? $options['resource']\n                 : []) + $resource;\n        }\n        $entry = $this->logger->entry(\n            $jsonPayload + $processedData['context'],\n            $options + [\n                'severity' => $level\n            ]\n        );\n        $this->sendEntry($entry);\n    }", "label": 2}
{"code": "def remove(community_id, record_id):\n    \"\"\"Remove a record from community.\"\"\"\n    c = Community.get(community_id)\n    assert c is not None\n    c.remove_record(record_id)\n    db.session.commit()\n    RecordIndexer().index_by_id(record_id)", "label": 1}
{"code": "func Stage1RootfsPath(root string) string {\n\treturn filepath.Join(Stage1ImagePath(root), aci.RootfsDir)\n}", "label": 5}
{"code": "func GetAction(id string) *Action {\n\tfor _, a := range actions {\n\t\tif a.ID == id {\n\t\t\treturn &a\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static function instanceName($project, $location, $instance)\n    {\n        return self::getInstanceNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'instance' => $instance,\n        ]);\n    }", "label": 2}
{"code": "function (arr) {\n\n\t// extract collection name\n\tif (arr && typeof arr._name === 'string') {\n\n\t\tvar size = arr.length - arr._index;\n\n\t\tif (size <= 0)\n\t\t\treturn false;\n\t\t\n\t\tLOG.sys('try to store to array [' + arr._name + '], # of elements to store: ' + size, 'SR.Sync');\n\t\t\t\t\n\t\t// TODO: wasteful of space?\n\t\t// NOTE: only new array entries will be stored to DB\n\t\tvar elements = [];\n\t\tfor (var i=arr._index; i < arr.length; i++)\n\t\t\telements.push(arr[i]);\n\n\t\t// update index count (regardless of update success or not?)\n\t\tarr._index = arr.length;\n\t\t\n\t\t// TODO: find right way to store\n\t\t// store away\n\t\t// NOTE: $each is used here (try to hide it?)\n\t\tSR.DB.updateArray(SR.Settings.DB_NAME_SYNC, {name: arr._name}, {data: elements},\n\t\t\tfunction (result) {\n\t\t\t\tLOG.sys('update array success: ' + result, 'SR.Sync');\n\t\t\t}, \n\t\t\tfunction (result) {\n\t\t\t\tLOG.error('update array fail: ' + result, 'SR.Sync');\n\t\t\t}\n\t\t);\n\t\treturn true;\n\t}\n\telse\n\t\tLOG.error('cannot store to DB, arr_name unavailable', 'SR.Sync');\n\t\t\n\treturn false;\n}", "label": 3}
{"code": "public function setShotChangeDetectionConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\VideoIntelligence\\V1\\ShotChangeDetectionConfig::class);\n        $this->shot_change_detection_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def clean(self):\n        \"\"\"\n        Remove all data by dropping and recreating the configured database.\n\n        .. note::\n\n            Only the configured database is removed. Any other databases\n            remain untouched.\n        \"\"\"\n        self.exec_pg_success(['dropdb', '-U', self.user, self.database])\n        self.exec_pg_success(['createdb', '-U', self.user, self.database])", "label": 1}
{"code": "function (chords, settings) {\n  var chordEvents = makeChordEvents(chords, settings);\n\n  // Set all channels\n  var setPatches = _.reduce(_.range(0xf), function (buffer, channel) {\n    return Buffer.concat([buffer, makePatchEvent(channel, settings.chordPatch)]);\n  }, new Buffer(0));\n\n  var length = setPatches.length + chordEvents.length + trackFooter.length;\n\n  return Buffer.concat([trackHeader, padNumber(length, 4), setPatches, chordEvents, trackFooter]);\n}", "label": 3}
{"code": "public void writeData(Writer w) throws IOException {\r\n    PrintWriter out = new PrintWriter(w);\r\n\r\n    for (IntTaggedWord itw : seenCounter.keySet()) {\r\n      out.println(itw.toLexicalEntry(wordIndex, tagIndex) + \" SEEN \" + seenCounter.getCount(itw));\r\n    }\r\n    for (IntTaggedWord itw : getUnknownWordModel().unSeenCounter().keySet()) {\r\n      out.println(itw.toLexicalEntry(wordIndex, tagIndex) + \" UNSEEN \" + getUnknownWordModel().unSeenCounter().getCount(itw));\r\n    }\r\n    for (int i = 0; i < smooth.length; i++) {\r\n      out.println(\"smooth[\" + i + \"] = \" + smooth[i]);\r\n    }\r\n    out.flush();\r\n  }", "label": 0}
{"code": "def format(file_metrics, build_metrics):\n    \"\"\"compute output in JSON format.\"\"\"\n    metrics = {'files': file_metrics}\n    if build_metrics:\n        metrics['build'] = build_metrics\n    body = json.dumps(metrics, sort_keys=True, indent=4) + '\\n'\n    return body", "label": 1}
{"code": "protected static String ConvertBinaryOperator(int oper)\r\n    {\r\n        // Convert the operator into the proper string\r\n        String oper_string;\r\n        switch (oper)\r\n        {\r\n            default:\r\n            case EQUAL:\r\n                oper_string = \"=\";\r\n                break;\r\n            case LIKE:\r\n                oper_string = \"LIKE\";\r\n                break;\r\n            case NOT_EQUAL:\r\n                oper_string = \"!=\";\r\n                break;\r\n            case LESS_THAN:\r\n                oper_string = \"<\";\r\n                break;\r\n            case GREATER_THAN:\r\n                oper_string = \">\";\r\n                break;\r\n            case GREATER_EQUAL:\r\n                oper_string = \">=\";\r\n                break;\r\n            case LESS_EQUAL:\r\n                oper_string = \"<=\";\r\n                break;\r\n        }\r\n        return oper_string;\r\n    }", "label": 0}
{"code": "public Object copy(final Object obj, final PersistenceBroker broker)\r\n    {\r\n        return clone(obj, IdentityMapFactory.getIdentityMap(), broker);\r\n    }", "label": 0}
{"code": "public function setObjectAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\VideoIntelligence\\V1\\ObjectTrackingAnnotation::class);\n        $this->object_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function decryptJson(password, data) {\n    var salt = new Buffer(data.salt, 'base64');\n    return pbkdf2(password, salt, pbkdf2Iterations, pbkdf2KeyLen, pbkdf2Digest).then(function (key) {\n        var iv = new Buffer(data.iv, 'base64');\n        var decipher = crypto.createDecipheriv(cipherAlgorithm, key, iv);\n        var tag = data.tag;\n        if (tag) {\n            decipher.setAuthTag(new Buffer(tag, 'base64'));\n        }\n        var value = decipher.update(data.value, 'base64', 'utf8');\n        value += decipher.final('utf8');\n        return value;\n    }).then(JSON.parse);\n}", "label": 3}
{"code": "def interbase_range_affected_by_variant_on_transcript(variant, transcript):\n    \"\"\"\n    Convert from a variant's position in global genomic coordinates on the\n    forward strand to an interval of interbase offsets on a particular\n    transcript's mRNA.\n\n    Parameters\n    ----------\n    variant : varcode.Variant\n\n    transcript : pyensembl.Transcript\n\n    Assumes that the transcript overlaps the variant.\n\n    Returns (start, end) tuple of offsets into the transcript's cDNA sequence\n    which indicates which bases in the reference sequence are affected by a\n    variant.\n\n    Example:\n        The insertion of \"TTT\" into the middle of an exon would result in an\n        offset pair such as (100,100) since no reference bases are changed\n        or deleted by an insertion.\n\n        On the other hand, deletion the preceding \"CGG\" at that same locus could\n        result in an offset pair such as (97, 100)\n    \"\"\"\n    if variant.is_insertion:\n        if transcript.strand == \"+\":\n            # base-1 position of an insertion is the genomic nucleotide\n            # before any inserted mutant nucleotides, so the start offset\n            # of the actual inserted nucleotides is one past that reference\n            # position\n            start_offset = transcript.spliced_offset(variant.start) + 1\n        else:\n            # on the negative strand the genomic base-1 position actually\n            # refers to the transcript base *after* the insertion, so we can\n            # use that as the interbase coordinate for where the insertion\n            # occurs\n            start_offset = transcript.spliced_offset(variant.start)\n        # an insertion happens *between* two reference bases\n        # so the start:end offsets coincide\n        end_offset = start_offset\n    else:\n        # reference bases affected by substitution or deletion defined by\n        # range starting at first affected base\n        offsets = []\n        assert len(variant.ref) > 0\n        for dna_pos in range(variant.start, variant.start + len(variant.ref)):\n            try:\n                offsets.append(transcript.spliced_offset(dna_pos))\n            except ValueError:\n                logger.info(\n                    \"Couldn't find position %d from %s on exons of %s\",\n                    dna_pos,\n                    variant,\n                    transcript)\n        if len(offsets) == 0:\n            raise ValueError(\n                \"Couldn't find any exonic reference bases affected by %s on %s\",\n                variant,\n                transcript)\n        start_offset = min(offsets)\n        end_offset = max(offsets) + 1\n    return (start_offset, end_offset)", "label": 1}
{"code": "func (info *ImageInfoType) GobEncode() (buf []byte, err error) {\n\tfields := []interface{}{info.data, info.smask, info.n, info.w, info.h, info.cs,\n\t\tinfo.pal, info.bpc, info.f, info.dp, info.trns, info.scale, info.dpi}\n\tw := new(bytes.Buffer)\n\tencoder := gob.NewEncoder(w)\n\tfor j := 0; j < len(fields) && err == nil; j++ {\n\t\terr = encoder.Encode(fields[j])\n\t}\n\tif err == nil {\n\t\tbuf = w.Bytes()\n\t}\n\treturn\n}", "label": 5}
{"code": "function msDiff(t1, t2) {\n  t1 = (t1[0] * 1e9 + t1[1]) / 1e6;\n  t2 = (t2[0] * 1e9 + t2[1]) / 1e6;\n  return Math.ceil((t1 - t2) * 100) / 100;\n}", "label": 3}
{"code": "public function createToken($endpoint, $region, $username)\n    {\n        $uri = new Uri($endpoint);\n        $uri = $uri->withPath('/');\n        $uri = $uri->withQuery('Action=connect&DBUser=' . $username);\n\n        $request = new Request('GET', $uri);\n        $signer = new SignatureV4('rds-db', $region);\n        $provider = $this->credentialProvider;\n\n        $url = (string) $signer->presign(\n            $request,\n            $provider()->wait(),\n            '+15 minutes'\n        )->getUri();\n\n        // Remove 2 extra slash from the presigned url result\n        return substr($url, 2);\n    }", "label": 2}
{"code": "function list(req, res, next) {\n  forms.getAllAppForms(req.connectionOptions, formsResultHandlers(constants.resultTypes.formProjects, req, next));\n}", "label": 3}
{"code": "def get_transaction_coordinator(transactional_id:)\n      @logger.debug \"Getting transaction coordinator for `#{transactional_id}`\"\n\n      refresh_metadata_if_necessary!\n\n      if transactional_id.nil?\n        # Get a random_broker\n        @logger.debug \"Transaction ID is not available. Choose a random broker.\"\n        return random_broker\n      else\n        get_coordinator(Kafka::Protocol::COORDINATOR_TYPE_TRANSACTION, transactional_id)\n      end\n    end", "label": 4}
{"code": "function (hostname, port, prefix, url, method, body, auth) {\n      var options = {\n        hostname: hostname,\n        port: port,\n        path: prefix + url,\n        method: method,\n        headers: {\n          'Content-Type': 'application/json;charset=utf-8',\n          'Content-Length': Buffer.byteLength(body, 'utf8')\n        }\n      };\n\n      // check if auth information is available\n      if (auth) {\n        options.auth = auth;\n      }\n\n      return options;\n    }", "label": 3}
{"code": "func (f *FileNameV3) FromString(name string) {\n\tp := new(FileName)\n\tp.FromString(name)\n\tf.Name = p.Name\n\tf.Length = p.Length\n}", "label": 5}
{"code": "private void refreshInstance(Object cachedInstance, Identity oid, ClassDescriptor cld)\n    {\n        // read in fresh copy from the db, but do not cache it\n        Object freshInstance = getPlainDBObject(cld, oid);\n\n        // update all primitive typed attributes\n        FieldDescriptor[] fields = cld.getFieldDescriptions();\n        FieldDescriptor fmd;\n        PersistentField fld;\n        for (int i = 0; i < fields.length; i++)\n        {\n            fmd = fields[i];\n            fld = fmd.getPersistentField();\n            fld.set(cachedInstance, fld.get(freshInstance));\n        }\n    }", "label": 0}
{"code": "func (f *file) firstLineOf(node, match ast.Node) string {\n\tline := f.render(node)\n\tif i := strings.Index(line, \"\\n\"); i >= 0 {\n\t\tline = line[:i]\n\t}\n\treturn f.indentOf(match) + line\n}", "label": 5}
{"code": "public static sslaction get(nitro_service service, String name) throws Exception{\n\t\tsslaction obj = new sslaction();\n\t\tobj.set_name(name);\n\t\tsslaction response = (sslaction) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func PgTsParserByOid(db XODB, oid pgtypes.Oid) (*PgTsParser, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, prsname, prsnamespace, prsstart, prstoken, prsend, prsheadline, prslextype ` +\n\t\t`FROM pg_catalog.pg_ts_parser ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tptp := PgTsParser{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&ptp.Tableoid, &ptp.Cmax, &ptp.Xmax, &ptp.Cmin, &ptp.Xmin, &ptp.Oid, &ptp.Ctid, &ptp.Prsname, &ptp.Prsnamespace, &ptp.Prsstart, &ptp.Prstoken, &ptp.Prsend, &ptp.Prsheadline, &ptp.Prslextype)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ptp, nil\n}", "label": 5}
{"code": "function abstractDensity(type, multi, graph) {\n  var order,\n      size;\n\n  // Retrieving order & size\n  if (arguments.length > 3) {\n    order = graph;\n    size = arguments[3];\n\n    if (typeof order !== 'number')\n      throw new Error('graphology-metrics/density: given order is not a number.');\n\n    if (typeof size !== 'number')\n      throw new Error('graphology-metrics/density: given size is not a number.');\n  }\n  else {\n\n    if (!isGraph(graph))\n      throw new Error('graphology-metrics/density: given graph is not a valid graphology instance.');\n\n    order = graph.order;\n    size = graph.size;\n\n    if (graph.multi && multi === false)\n      size = simpleSizeForMultiGraphs(graph);\n  }\n\n  // When the graph has only one node, its density is 0\n  if (order < 2)\n    return 0;\n\n  // Guessing type & multi\n  if (type === null)\n    type = graph.type;\n  if (multi === null)\n    multi = graph.multi;\n\n  // Getting the correct function\n  var fn;\n\n  if (type === 'undirected')\n    fn = undirectedDensity;\n  else if (type === 'directed')\n    fn = directedDensity;\n  else\n    fn = mixedDensity;\n\n  // Applying the function\n  return fn(order, size);\n}", "label": 3}
{"code": "public function setDataSources($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\BigQuery\\DataTransfer\\V1\\DataSource::class);\n        $this->data_sources = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def where(input, property, target_value = nil)\n      ary = InputIterator.new(input)\n\n      if ary.empty?\n        []\n      elsif ary.first.respond_to?(:[]) && target_value.nil?\n        begin\n          ary.select { |item| item[property] }\n        rescue TypeError\n          raise_property_error(property)\n        end\n      elsif ary.first.respond_to?(:[])\n        begin\n          ary.select { |item| item[property] == target_value }\n        rescue TypeError\n          raise_property_error(property)\n        end\n      end\n    end", "label": 4}
{"code": "private function moveToNextState(CellChunk $chunk)\n    {\n        $this->state = $chunk->getValueSize() > 0\n            ? self::$rowStateEnum['CELL_IN_PROGRESS']\n            : self::$rowStateEnum['ROW_IN_PROGRESS'];\n    }", "label": 2}
{"code": "func PgStatisticByStarelidStaattnumStainherit(db XODB, starelid pgtypes.Oid, staattnum int16, stainherit bool) (*PgStatistic, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, starelid, staattnum, stainherit, stanullfrac, stawidth, stadistinct, stakind1, stakind2, stakind3, stakind4, stakind5, staop1, staop2, staop3, staop4, staop5, stanumbers1, stanumbers2, stanumbers3, stanumbers4, stanumbers5, stavalues1, stavalues2, stavalues3, stavalues4, stavalues5 ` +\n\t\t`FROM pg_catalog.pg_statistic ` +\n\t\t`WHERE starelid = $1 AND staattnum = $2 AND stainherit = $3`\n\n\t// run query\n\tXOLog(sqlstr, starelid, staattnum, stainherit)\n\tps := PgStatistic{}\n\n\terr = db.QueryRow(sqlstr, starelid, staattnum, stainherit).Scan(&ps.Tableoid, &ps.Cmax, &ps.Xmax, &ps.Cmin, &ps.Xmin, &ps.Ctid, &ps.Starelid, &ps.Staattnum, &ps.Stainherit, &ps.Stanullfrac, &ps.Stawidth, &ps.Stadistinct, &ps.Stakind1, &ps.Stakind2, &ps.Stakind3, &ps.Stakind4, &ps.Stakind5, &ps.Staop1, &ps.Staop2, &ps.Staop3, &ps.Staop4, &ps.Staop5, &ps.Stanumbers1, &ps.Stanumbers2, &ps.Stanumbers3, &ps.Stanumbers4, &ps.Stanumbers5, &ps.Stavalues1, &ps.Stavalues2, &ps.Stavalues3, &ps.Stavalues4, &ps.Stavalues5)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ps, nil\n}", "label": 5}
{"code": "func (info *ImageInfoType) Extent() (wd, ht float64) {\n\treturn info.Width(), info.Height()\n}", "label": 5}
{"code": "func uploadFile(ctx context.Context, m *library.Manager, sessionID string, ovafile string, filename string) error {\n\tvar updateFileInfo library.UpdateFile\n\n\tfmt.Printf(\"Uploading %s from %s\\n\", filename, ovafile)\n\tsize, md5String, _ := getOVAFileInfo(ovafile, filename)\n\n\t// Get the URI for the file upload\n\n\tupdateFileInfo.Name = filename\n\tupdateFileInfo.Size = &size\n\tupdateFileInfo.SourceType = \"PUSH\"\n\tupdateFileInfo.Checksum = &library.Checksum{\n\t\tAlgorithm: \"MD5\",\n\t\tChecksum:  md5String,\n\t}\n\n\taddFileInfo, err := m.AddLibraryItemFile(ctx, sessionID, updateFileInfo)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tof, err := NewOVAFile(ovafile)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer of.Close()\n\n\t// Setup to point to the OVA file to be transferred\n\t_, err = of.Find(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq, err := http.NewRequest(\"PUT\", addFileInfo.UploadEndpoint.URI, of)\n\tif err != nil {\n\t\treturn err\n\t}\n\treq.Header.Set(\"vmware-api-session-id\", sessionID)\n\n\treturn m.Do(ctx, req, nil)\n}", "label": 5}
{"code": "def _create_edge_by_target(self):\n        \"\"\"creates a edge_by_target dict with the same edge objects as the edge_by_source.\n        Also adds an '@id' field to each edge.\"\"\"\n        ebt = {}\n        for edge_dict in self._edge_by_source.values():\n            for edge_id, edge in edge_dict.items():\n                target_id = edge['@target']\n                edge['@id'] = edge_id\n                assert target_id not in ebt\n                ebt[target_id] = edge\n        # _check_rev_dict(self._tree, ebt)\n        return ebt", "label": 1}
{"code": "func GetSandboxForExternalKey(basePath string, key string) (Sandbox, error) {\n\tif err := createNamespaceFile(key); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := mountNetworkNamespace(basePath, key); err != nil {\n\t\treturn nil, err\n\t}\n\tn := &networkNamespace{path: key, nextIfIndex: make(map[string]int)}\n\n\tsboxNs, err := netns.GetFromPath(n.path)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed get network namespace %q: %v\", n.path, err)\n\t}\n\tdefer sboxNs.Close()\n\n\tn.nlHandle, err = netlink.NewHandleAt(sboxNs, syscall.NETLINK_ROUTE)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create a netlink handle: %v\", err)\n\t}\n\n\terr = n.nlHandle.SetSocketTimeout(ns.NetlinkSocketsTimeout)\n\tif err != nil {\n\t\tlogrus.Warnf(\"Failed to set the timeout on the sandbox netlink handle sockets: %v\", err)\n\t}\n\n\t// As starting point, disable IPv6 on all interfaces\n\terr = setIPv6(n.path, \"all\", false)\n\tif err != nil {\n\t\tlogrus.Warnf(\"Failed to disable IPv6 on all interfaces on network namespace %q: %v\", n.path, err)\n\t}\n\n\tif err = n.loopbackUp(); err != nil {\n\t\tn.nlHandle.Delete()\n\t\treturn nil, err\n\t}\n\n\treturn n, nil\n}", "label": 5}
{"code": "def transporter_for_selected_team(options)\n      generic_transporter = FastlaneCore::ItunesTransporter.new(options[:username], nil, false, options[:itc_provider])\n      return generic_transporter unless options[:itc_provider].nil? && Spaceship::Tunes.client.teams.count > 1\n\n      begin\n        team = Spaceship::Tunes.client.teams.find { |t| t['contentProvider']['contentProviderId'].to_s == Spaceship::Tunes.client.team_id }\n        name = team['contentProvider']['name']\n        provider_id = generic_transporter.provider_ids[name]\n        UI.verbose(\"Inferred provider id #{provider_id} for team #{name}.\")\n        return FastlaneCore::ItunesTransporter.new(options[:username], nil, false, provider_id)\n      rescue => ex\n        UI.verbose(\"Couldn't infer a provider short name for team with id #{Spaceship::Tunes.client.team_id} automatically: #{ex}. Proceeding without provider short name.\")\n        return generic_transporter\n      end\n    end", "label": 4}
{"code": "def command(name, attributes = {}, &block)\n      @commands ||= {}\n      if name.is_a? Array\n        new_command = nil\n\n        name.each do |e|\n          new_command = Command.new(e, attributes, &block)\n          @commands[e] = new_command\n        end\n\n        new_command\n      else\n        new_command = Command.new(name, attributes, &block)\n        new_command.attributes[:aliases].each do |aliased_name|\n          @commands[aliased_name] = CommandAlias.new(aliased_name, new_command)\n        end\n        @commands[name] = new_command\n      end\n    end", "label": 4}
{"code": "def _max_lengths():\n    \"\"\" The length of the largest magic string + its offset\"\"\"\n    max_header_length = max([len(x.byte_match) + x.offset\n                             for x in magic_header_array])\n    max_footer_length = max([len(x.byte_match) + abs(x.offset)\n                             for x in magic_footer_array])\n    return max_header_length, max_footer_length", "label": 1}
{"code": "def get_by_name(self, name): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a device by name.\n\n        :param name: Device name as string.\n        :return: :class:`devices.Device <devices.Device>` object\n        :rtype: devices.Device\n        \"\"\"\n        rs, _ = self.list(filter=field('name').eq(name), limit=1)\n        if len(rs) is 0:\n            raise CDRouterError('no such device')\n        return rs[0]", "label": 1}
{"code": "def dispatch(message, channel)\n      if channel =~ /\\Aslanger:/\n        # Messages received from the Redis channel slanger:*  carry info on\n        # subscriptions. Update our subscribers accordingly.\n        update_subscribers message\n      else\n        push Oj.dump(message, mode: :compat)\n      end\n    end", "label": 4}
{"code": "public static int cudnnGetCTCLossWorkspaceSize(\n        cudnnHandle handle, \n        cudnnTensorDescriptor probsDesc, /** Tensor descriptor for probabilities, the dimensions are T,N,A (T is the\n                                                timing steps, N is the mini batch size, A is the alphabet size) */\n        cudnnTensorDescriptor gradientsDesc, /** Tensor descriptor for gradients, the\n                                                    dimensions are T,N,A. To compute costs\n                                                    only, set it to NULL */\n        int[] labels, /** labels, in CPU memory */\n        int[] labelLengths, /** the length of each label, in CPU memory */\n        int[] inputLengths, /** the lengths of timing steps in each batch, in CPU memory */\n        int algo, /** algorithm selected, supported now 0 and 1 */\n        cudnnCTCLossDescriptor ctcLossDesc, \n        long[] sizeInBytes)/** pointer to the returned workspace size */\n    {\n        return checkResult(cudnnGetCTCLossWorkspaceSizeNative(handle, probsDesc, gradientsDesc, labels, labelLengths, inputLengths, algo, ctcLossDesc, sizeInBytes));\n    }", "label": 0}
{"code": "def activate_solution(solution)\n      retried = false\n      begin\n        @logger.debug(\"Activating solution set: #{solution.map(&:full_name)}\")\n        solution.each do |activation_request|\n          unless activation_request.full_spec.activated?\n            @logger.debug(\"Activating gem #{activation_request.full_spec.full_name}\")\n            activation_request.full_spec.activate\n            if(defined?(::Bundler))\n              @logger.debug(\"Marking gem #{activation_request.full_spec.full_name} loaded within Bundler.\")\n              ::Bundler.rubygems.mark_loaded activation_request.full_spec\n            end\n          end\n        end\n      rescue Gem::LoadError => e\n        # Depending on the version of Ruby, the ordering of the solution set\n        # will be either 0..n (molinillo) or n..0 (pre-molinillo). Instead of\n        # attempting to determine what's in use, or if it has some how changed\n        # again, just reverse order on failure and attempt again.\n        if retried\n          @logger.error(\"Failed to load solution set - #{e.class}: #{e}\")\n          matcher = e.message.match(/Could not find '(?<gem_name>[^']+)'/)\n          if matcher && !matcher[\"gem_name\"].empty?\n            desired_activation_request = solution.detect do |request|\n              request.name == matcher[\"gem_name\"]\n            end\n            if desired_activation_request && !desired_activation_request.full_spec.activated?\n              activation_request = desired_activation_request\n              @logger.warn(\"Found misordered activation request for #{desired_activation_request.full_name}. Moving to solution HEAD.\")\n              solution.delete(desired_activation_request)\n              solution.unshift(desired_activation_request)\n              retry\n            end\n          end\n\n          raise\n        else\n          @logger.debug(\"Failed to load solution set. Retrying with reverse order.\")\n          retried = true\n          solution.reverse!\n          retry\n        end\n      end\n    end", "label": 4}
{"code": "function getExportDefaultTempVariableName() {\n            var baseName = \"_default\";\n            if (!(baseName in currentIdentifiers)) {\n                return baseName;\n            }\n            var count = 0;\n            while (true) {\n                count++;\n                var name_23 = baseName + \"_\" + count;\n                if (!(name_23 in currentIdentifiers)) {\n                    return name_23;\n                }\n            }\n        }", "label": 3}
{"code": "def update_available(after_days=1):\n    \"\"\"\n    Check whether updated NRFA data is available.\n\n    :param after_days: Only check if not checked previously since a certain number of days ago\n    :type after_days: float\n    :return: `True` if update available, `False` if not, `None` if remote location cannot be reached.\n    :rtype: bool or None\n    \"\"\"\n    never_downloaded = not bool(config.get('nrfa', 'downloaded_on', fallback=None) or None)\n    if never_downloaded:\n        config.set_datetime('nrfa', 'update_checked_on', datetime.utcnow())\n        config.save()\n        return True\n\n    last_checked_on = config.get_datetime('nrfa', 'update_checked_on', fallback=None) or datetime.fromtimestamp(0)\n    if datetime.utcnow() < last_checked_on + timedelta(days=after_days):\n        return False\n\n    current_version = LooseVersion(config.get('nrfa', 'version', fallback='0') or '0')\n    try:\n        with urlopen(config['nrfa']['oh_json_url'], timeout=10) as f:\n            remote_version = LooseVersion(json.loads(f.read().decode('utf-8'))['nrfa_version'])\n        config.set_datetime('nrfa', 'update_checked_on', datetime.utcnow())\n        config.save()\n        return remote_version > current_version\n    except URLError:\n        return None", "label": 1}
{"code": "function(value, equals)\n  {\n    var equality = equals || equalsStrict;\n\n    for (var i = 0; i < this.length; i++)\n    {\n      if ( equality( value, this[ i ] ) )\n      {\n        return i;\n      }\n    }\n\n    return -1;\n  }", "label": 3}
{"code": "async function pakoUnzip(inputData) {\n  let strm\n  let pos = 0\n  let i = 0\n  const chunks = []\n  let inflator\n  do {\n    const remainingInput = inputData.slice(pos)\n    inflator = new Inflate()\n    strm = inflator.strm\n    inflator.push(remainingInput, Z_SYNC_FLUSH)\n    if (inflator.err) throw new Error(inflator.msg)\n\n    pos += strm.next_in\n    chunks[i] = Buffer.from(inflator.result)\n    i += 1\n  } while (strm.avail_in)\n\n  const result = Buffer.concat(chunks)\n  return result\n}", "label": 3}
{"code": "def escape_uri(str)\n      str = str.dup\n      binary_encode(str)\n      str.gsub(UNESCAPED) { \"%%%02X\" % $1[0].ord }\n    end", "label": 4}
{"code": "func (sink *influxdbSink) GetMetricNames(metricKey core.HistoricalKey) ([]string, error) {\n\tif err := sink.checkSanitizedKey(&metricKey); err != nil {\n\t\treturn nil, err\n\t}\n\treturn sink.stringListQuery(fmt.Sprintf(\"SHOW MEASUREMENTS WHERE %s\", sink.keyToSelector(metricKey)), \"Unable to list available metrics\")\n}", "label": 5}
{"code": "public void remove(Identity oid)\r\n    {\r\n        //processQueue();\r\n        if(oid != null)\r\n        {\r\n            removeTracedIdentity(oid);\r\n            objectTable.remove(buildKey(oid));\r\n            if(log.isDebugEnabled()) log.debug(\"Remove object \" + oid);\r\n        }\r\n    }", "label": 0}
{"code": "function SelectList(options) {\n\t\tthis.options = $.extend({\n\t\t\tholder: null,\n\t\t\tmaxVisibleItems: 10,\n\t\t\tselectOnClick: true,\n\t\t\tuseHoverClass: false,\n\t\t\tuseCustomScroll: false,\n\t\t\thandleResize: true,\n\t\t\tmultipleSelectWithoutKey: false,\n\t\t\talwaysPreventMouseWheel: false,\n\t\t\tindexAttribute: 'data-index',\n\t\t\tcloneClassPrefix: 'jcf-option-',\n\t\t\tcontainerStructure: '<span class=\"jcf-list\"><span class=\"jcf-list-content\"></span></span>',\n\t\t\tcontainerSelector: '.jcf-list-content',\n\t\t\tcaptionClass: 'jcf-optgroup-caption',\n\t\t\tdisabledClass: 'jcf-disabled',\n\t\t\toptionClass: 'jcf-option',\n\t\t\tgroupClass: 'jcf-optgroup',\n\t\t\thoverClass: 'jcf-hover',\n\t\t\tselectedClass: 'jcf-selected',\n\t\t\tscrollClass: 'jcf-scroll-active'\n\t\t}, options);\n\t\tthis.init();\n\t}", "label": 3}
{"code": "public static function unregister($protocol = null)\n    {\n        $protocol = $protocol ?: self::DEFAULT_PROTOCOL;\n        stream_wrapper_unregister($protocol);\n        unset(self::$clients[$protocol]);\n    }", "label": 2}
{"code": "def undo!(append: Logidze.append_on_undo)\n      version = log_data.previous_version\n      return false if version.nil?\n\n      switch_to!(version.version, append: append)\n    end", "label": 4}
{"code": "function traverseMeshes( cb ) {\n\n\t\t\tobject.traverse( function ( child ) {\n\n\t\t\t\tif ( child.isMesh === true ) {\n\n\t\t\t\t\tvar mesh = child;\n\t\t\t\t\tvar geometry = mesh.geometry;\n\n\t\t\t\t\tif ( geometry.isGeometry === true ) {\n\n\t\t\t\t\t\tgeometry = geomToBufferGeom.get( geometry );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( geometry.isBufferGeometry === true ) {\n\n\t\t\t\t\t\tif ( geometry.getAttribute( 'position' ) !== undefined ) {\n\n\t\t\t\t\t\t\tcb( mesh, geometry );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} );\n\n\t\t}", "label": 3}
{"code": "func (m *MockIndex) Map(arg0 map[int]hash.Hash) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"Map\", arg0)\n}", "label": 5}
{"code": "func GetEnabledCgroups() (map[int][]string, error) {\n\tcgroupsFile, err := os.Open(\"/proc/cgroups\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer cgroupsFile.Close()\n\n\tcgroups, err := parseCgroups(cgroupsFile)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"error parsing /proc/cgroups\"), err)\n\t}\n\n\treturn cgroups, nil\n}", "label": 5}
{"code": "public static cmppolicylabel_policybinding_binding[] get(nitro_service service, String labelname) throws Exception{\n\t\tcmppolicylabel_policybinding_binding obj = new cmppolicylabel_policybinding_binding();\n\t\tobj.set_labelname(labelname);\n\t\tcmppolicylabel_policybinding_binding response[] = (cmppolicylabel_policybinding_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def create_content_spec(**kwargs):\n    \"\"\"Sugar. factory for a PhyloSchema object.\n\n    Repackages the kwargs to kwargs for PhyloSchema so that our\n    PhyloSchema.__init__ does not have to be soo rich\n    \"\"\"\n    format_str = kwargs.get('format', 'nexson')\n    nexson_version = kwargs.get('nexson_version', 'native')\n    otu_label = kwargs.get('otu_label')\n    if otu_label is None:\n        otu_label = kwargs.get('tip_label')\n    content = kwargs.get('content')\n    if content is not None:\n        content_id = kwargs.get('content_id')\n        if content_id is None:\n            content_id = _get_content_id_from(**kwargs)\n    else:\n        content, content_id = _sniff_content_from_kwargs(**kwargs)\n    if content is None:\n        content = 'study'\n    return PhyloSchema(content=content,\n                       content_id=content_id,\n                       format_str=format_str,\n                       version=nexson_version,\n                       otu_label=otu_label,\n                       repo_nexml2json=kwargs.get('repo_nexml2json'),\n                       bracket_ingroup=bool(kwargs.get('bracket_ingroup', False)),\n                       cull_nonmatching=kwargs.get('cull_nonmatching'))", "label": 1}
{"code": "def reset_signal_handlers\n      Signal.list_trappable.each_key do |signal|\n        begin\n          prev_handler = trap(signal, DEFAULT)\n          if prev_handler != DEFAULT\n            @previous_signal_handlers[signal] = prev_handler\n          end\n        rescue ArgumentError\n          # Signal cannot be trapped; ignore it.\n        end\n      end\n      trap('HUP', IGNORE)\n      PhusionPassenger.call_event(:after_installing_signal_handlers)\n    end", "label": 4}
{"code": "func (bee *Bee) LogFatal(args ...interface{}) {\n\ta := []interface{}{\"[\" + bee.Name() + \"]:\"}\n\tfor _, v := range args {\n\t\ta = append(a, v)\n\t}\n\tlog.Panicln(a...)\n\tLog(bee.Name(), fmt.Sprintln(args...), 2)\n}", "label": 5}
{"code": "def unique_temp(name)\n      name = name.to_s\n      if name && !name.empty?\n        name = name\n               .to_s\n               .gsub('<=>', '$lt_eq_gt')\n               .gsub('===', '$eq_eq_eq')\n               .gsub('==', '$eq_eq')\n               .gsub('=~', '$eq_tilde')\n               .gsub('!~', '$excl_tilde')\n               .gsub('!=', '$not_eq')\n               .gsub('<=', '$lt_eq')\n               .gsub('>=', '$gt_eq')\n               .gsub('=', '$eq')\n               .gsub('?', '$ques')\n               .gsub('!', '$excl')\n               .gsub('/', '$slash')\n               .gsub('%', '$percent')\n               .gsub('+', '$plus')\n               .gsub('-', '$minus')\n               .gsub('<', '$lt')\n               .gsub('>', '$gt')\n               .gsub(/[^\\w\\$]/, '$')\n      end\n      unique = (@unique += 1)\n      \"#{'$' unless name.start_with?('$')}#{name}$#{unique}\"\n    end", "label": 4}
{"code": "def remove_role(role):\n    \"\"\"Remove a action for a role.\"\"\"\n    def processor(action, argument):\n        ActionRoles.query_by_action(action, argument=argument).filter(\n            ActionRoles.role_id == role.id\n        ).delete(synchronize_session=False)\n    return processor", "label": 1}
{"code": "def from_variant_and_transcript(\n            cls,\n            variant,\n            transcript,\n            context_size):\n        \"\"\"\n        Extracts the reference sequence around a variant locus on a particular\n        transcript and determines the reading frame at the start of that\n        sequence context.\n\n        Parameters\n        ----------\n        variant : varcode.Variant\n\n        transcript : pyensembl.Transcript\n\n        context_size : int\n\n        Returns SequenceKeyWithReadingFrame object or None if Transcript lacks\n        coding sequence, protein sequence or annotated start/stop codons.\n        \"\"\"\n        if not transcript.contains_start_codon:\n            logger.info(\n                \"Expected transcript %s for variant %s to have start codon\",\n                transcript.name,\n                variant)\n            return None\n\n        if not transcript.contains_stop_codon:\n            logger.info(\n                \"Expected transcript %s for variant %s to have stop codon\",\n                transcript.name,\n                variant)\n            return None\n\n        if not transcript.protein_sequence:\n            logger.info(\n                \"Expected transript %s for variant %s to have protein sequence\",\n                transcript.name,\n                variant)\n            return None\n\n        sequence_key = ReferenceSequenceKey.from_variant_and_transcript(\n            variant=variant,\n            transcript=transcript,\n            context_size=context_size)\n\n        if sequence_key is None:\n            logger.info(\n                \"No sequence key for variant %s on transcript %s\",\n                variant,\n                transcript.name)\n            return None\n\n        return cls.from_variant_and_transcript_and_sequence_key(\n            variant=variant,\n            transcript=transcript,\n            sequence_key=sequence_key)", "label": 1}
{"code": "function query(value, field, expression) {\n    if (!expression) {\n        return value;\n    }\n\n    var expressionQuery = {};\n    expressionQuery[expression] = value;\n    return expressionQuery;\n}", "label": 3}
{"code": "public function setMoreResults($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Datastore\\V1\\QueryResultBatch_MoreResultsType::class);\n        $this->more_results = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def find_one_and_update(filter, update, options = {})\n      find(filter, options).find_one_and_update(update, options)\n    end", "label": 4}
{"code": "func GetVersion() (major, minor, micro int, err error) {\n\tout, err := exec.Command(iptablesPath, \"--version\").CombinedOutput()\n\tif err == nil {\n\t\tmajor, minor, micro = parseVersionNumbers(string(out))\n\t}\n\treturn\n}", "label": 5}
{"code": "def secret_id_accessors(role_name, options = {})\n      headers = extract_headers!(options)\n      json = client.list(\"/v1/auth/approle/role/#{encode_path(role_name)}/secret-id\", options, headers)\n      return Secret.decode(json).data[:keys] || []\n    rescue HTTPError => e\n      return [] if e.code == 404\n      raise\n    end", "label": 4}
{"code": "def pencil3():\n    '''Install or update latest Pencil version 3, a GUI prototyping tool.\n\n    While it is the newer one and the GUI is more fancy, it is the \"more beta\"\n    version of pencil.  For exmaple, to display a svg export may fail from\n    within a reveal.js presentation.\n\n    More info:\n        Homepage: http://pencil.evolus.vn/Next.html\n        github repo: https://github.com/evolus/pencil\n    '''\n    repo_name = 'pencil3'\n    repo_dir = flo('~/repos/{repo_name}')\n    print_msg('## fetch latest pencil\\n')\n    checkup_git_repo_legacy(url='https://github.com/evolus/pencil.git',\n                            name=repo_name)\n    run(flo('cd {repo_dir} && npm install'), msg='\\n## install npms\\n')\n    install_user_command_legacy('pencil3', pencil3_repodir=repo_dir)\n    print_msg('\\nNow You can start pencil version 3 with this command:\\n\\n'\n              '    pencil3')", "label": 1}
{"code": "function(session, args, callback) {\n\n        // Parse the arguments using optimist\n        var argv = optimist.parse(args);\n\n        // Update the environment to indicate who the specified user now is\n        session.env('me', argv._[0] || 'unknown');\n\n        // The callback always needs to be invoked to finish the command\n        return callback();\n    }", "label": 3}
{"code": "def where_am_i():\n    \"\"\"\n    high level function that can estimate where user is based \n    on predefined setups.\n    \"\"\"\n    locations = {'Work':0, 'Home':0}\n    for ssid in scan_for_ssids():\n        #print('checking scanned_ssid ', ssid)\n        for l in logged_ssids:\n            #print('checking logged_ssid ', l)\n            if l['name'] == ssid:\n                locations[l['location']] += 1\n                #print('MATCH')\n    print('Where Am I: SSIDS Matching Home = ', locations['Home'], ' SSIDs matching Work = ', locations['Work'])\n    \n    return max(locations.keys(), key=lambda k: locations[k])", "label": 1}
{"code": "func (t *Text) calcY(height int) int {\n\tif t.align&VAlignCenter != 0 {\n\t\treturn (height - len(t.lengths)) / 2\n\t}\n\tif t.align&VAlignBottom != 0 {\n\t\treturn height - len(t.lengths)\n\t}\n\treturn 0\n}", "label": 5}
{"code": "def change_paths_to_absolutes!(values)\n      values.each do |key, value|\n        if value.kind_of?(Hash)\n          change_paths_to_absolutes!(value) # recursive call\n        elsif value.kind_of?(Array)\n          value.each do |current|\n            change_paths_to_absolutes!(current) if current.kind_of?(Hash) # recursive call\n          end\n        else\n          if ['font', 'background'].include?(key)\n            # Change the paths to relative ones\n            # `replace`: to change the content of the string, so it's actually stored\n            if @path # where is the config file. We don't have a config file in tests\n              containing_folder = File.expand_path('..', @path)\n              value.replace(File.join(containing_folder, value))\n            end\n          end\n        end\n      end\n    end", "label": 4}
{"code": "def normalized_path\n      @normalized_path ||= begin\n        path = self.path.to_s\n        if self.scheme == nil && path =~ NORMPATH\n          # Relative paths with colons in the first segment are ambiguous.\n          path = path.sub(\":\", \"%2F\")\n        end\n        # String#split(delimeter, -1) uses the more strict splitting behavior\n        # found by default in Python.\n        result = path.strip.split(SLASH, -1).map do |segment|\n          Addressable::URI.normalize_component(\n            segment,\n            Addressable::URI::CharacterClasses::PCHAR\n          )\n        end.join(SLASH)\n\n        result = URI.normalize_path(result)\n        if result.empty? &&\n            [\"http\", \"https\", \"ftp\", \"tftp\"].include?(self.normalized_scheme)\n          result = SLASH.dup\n        end\n        result\n      end\n      # All normalized values should be UTF-8\n      @normalized_path.force_encoding(Encoding::UTF_8) if @normalized_path\n      @normalized_path\n    end", "label": 4}
{"code": "def mean_otu_pct_abundance(ra, otuIDs):\n    \"\"\"\n    Calculate the mean OTU abundance percentage.\n\n    :type ra: Dict\n    :param ra: 'ra' refers to a dictionary keyed on SampleIDs, and the values are\n               dictionaries keyed on OTUID's and their values represent the relative\n               abundance of that OTUID in that SampleID. 'ra' is the output of\n               relative_abundance() function.\n\n    :type otuIDs: List\n    :param otuIDs: A list of OTUID's for which the percentage abundance needs to be\n                   measured.\n\n    :rtype: dict\n    :return: A dictionary of OTUID and their percent relative abundance as key/value pair.\n    \"\"\"\n    sids = ra.keys()\n    otumeans = defaultdict(int)\n\n    for oid in otuIDs:\n        otumeans[oid] = sum([ra[sid][oid] for sid in sids\n                             if oid in ra[sid]]) / len(sids) * 100\n    return otumeans", "label": 1}
{"code": "func (s *Strings) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\t// try unmarshal as string\n\tvar val string\n\terr := unmarshal(&val)\n\tif err == nil {\n\t\t*s = []string{val}\n\t\treturn nil\n\t}\n\n\t// try unmarshal as slice\n\tvar slice []string\n\terr = unmarshal(&slice)\n\tif err == nil {\n\t\t*s = slice\n\t\treturn nil\n\t}\n\n\treturn err\n}", "label": 5}
{"code": "def redirect(uri, *args)\n      if env['HTTP_VERSION'] == 'HTTP/1.1' and env[\"REQUEST_METHOD\"] != 'GET'\n        status 303\n      else\n        status 302\n      end\n\n      # According to RFC 2616 section 14.30, \"the field value consists of a\n      # single absolute URI\"\n      response['Location'] = uri(uri, settings.absolute_redirects?, settings.prefixed_redirects?)\n      halt(*args)\n    end", "label": 4}
{"code": "def find_emoji(name)\n      LOGGER.out(\"Resolving emoji #{name}\")\n      emoji.find { |element| element.name == name }\n    end", "label": 4}
{"code": "public static base_responses update(nitro_service client, snmpgroup resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsnmpgroup updateresources[] = new snmpgroup[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tupdateresources[i] = new snmpgroup();\n\t\t\t\tupdateresources[i].name = resources[i].name;\n\t\t\t\tupdateresources[i].securitylevel = resources[i].securitylevel;\n\t\t\t\tupdateresources[i].readviewname = resources[i].readviewname;\n\t\t\t}\n\t\t\tresult = update_bulk_request(client, updateresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function merge(target, source) {\n                target.additionalNodes = target.additionalNodes || [];\n                target.additionalNodes.push(source.node);\n                if (source.additionalNodes) {\n                    (_a = target.additionalNodes).push.apply(_a, source.additionalNodes);\n                }\n                target.children = ts.concatenate(target.children, source.children);\n                if (target.children) {\n                    mergeChildren(target.children);\n                    sortChildren(target.children);\n                }\n                var _a;\n            }", "label": 3}
{"code": "def show_grid_from_file(self, fname):\n        \"\"\"\n        reads a saved grid file and paints it on the canvas\n        \"\"\"\n        with open(fname, \"r\") as f:\n            for y, row in enumerate(f):\n                for x, val in enumerate(row):\n                    self.draw_cell(y, x, val)", "label": 1}
{"code": "func (i *TeleInstance) StopProxy() error {\n\tvar errors []error\n\n\tfor _, p := range i.Nodes {\n\t\tif p.Config.Proxy.Enabled {\n\t\t\tif err := p.Close(); err != nil {\n\t\t\t\terrors = append(errors, err)\n\t\t\t\tlog.Errorf(\"Failed closing extra proxy: %v.\", err)\n\t\t\t}\n\t\t\tif err := p.Wait(); err != nil {\n\t\t\t\terrors = append(errors, err)\n\t\t\t\tlog.Errorf(\"Failed to stop extra proxy: %v.\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn trace.NewAggregate(errors...)\n}", "label": 5}
{"code": "protected function sendBroadcast($targets, $node, $type)\n    {\n        if (!is_array($targets)) {\n            $targets = [$targets];\n        }\n\n        $toNodes = [];\n        foreach ($targets as $target) {\n            $jid = $this->getJID($target);\n            $hash = ['jid' => $jid];\n            $toNode = new ProtocolNode('to', $hash, null, null);\n            $toNodes[] = $toNode;\n        }\n\n        $broadcastNode = new ProtocolNode('broadcast', null, $toNodes, null);\n\n        $msgId = $this->createMsgId();\n\n        $messageNode = new ProtocolNode('message',\n            [\n                'to'   => time().'@broadcast',\n                'type' => $type,\n                'id'   => $msgId,\n            ], [$node, $broadcastNode], null);\n\n        $this->sendNode($messageNode);\n        $this->waitForServer($msgId);\n        //listen for response\n        $this->eventManager()->fire('onSendMessage',\n            [\n                $this->phoneNumber,\n                $targets,\n                $msgId,\n                $node,\n            ]);\n\n        return $msgId;\n    }", "label": 2}
{"code": "public static lbvserver_transformpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_transformpolicy_binding obj = new lbvserver_transformpolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_transformpolicy_binding response[] = (lbvserver_transformpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func PgExtensionByExtname(db XODB, extname pgtypes.Name) (*PgExtension, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, extname, extowner, extnamespace, extrelocatable, extversion, extconfig, extcondition ` +\n\t\t`FROM pg_catalog.pg_extension ` +\n\t\t`WHERE extname = $1`\n\n\t// run query\n\tXOLog(sqlstr, extname)\n\tpe := PgExtension{}\n\n\terr = db.QueryRow(sqlstr, extname).Scan(&pe.Tableoid, &pe.Cmax, &pe.Xmax, &pe.Cmin, &pe.Xmin, &pe.Oid, &pe.Ctid, &pe.Extname, &pe.Extowner, &pe.Extnamespace, &pe.Extrelocatable, &pe.Extversion, &pe.Extconfig, &pe.Extcondition)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pe, nil\n}", "label": 5}
{"code": "function onPushNotificationNotification(response) {\n    // assignments avoiding changes of implementation state during promise chain\n    var plugin = pushPlugin;\n    var callback = pushCallback;\n    return Q(response).then(function (r) {\n        diag.debug.assert(r === response, 'just begins promise chain avoiding explicit try-catch');\n        return callback(undefined, response) || response;\n    }).then(function (r) {\n        diag.debug.assert(r === response, 'push callback must respond same object');\n        return Q.Promise(function (resolve, reject) {\n            try {\n                if ('notId' in response.additionalData) {\n                    plugin.finish(resolve, reject, response.additionalData.notId);\n                }\n                else {\n                    plugin.finish(resolve, reject);\n                }\n            }\n            catch (error) {\n                reject(error);\n            }\n        });\n    }).done(undefined, function (error) {\n        return Q(callback(error, response) || response).catch(function (e) {\n            diag.debug.assert(e === error, 'push callback failed: ' + e.message);\n            return response;\n        });\n    });\n}", "label": 3}
{"code": "func SingularizeIdentifier(s string) string {\n\tif i := reverseIndexRune(s, '_'); i != -1 {\n\t\ts = s[:i] + \"_\" + inflector.Singularize(s[i+1:])\n\t} else {\n\t\ts = inflector.Singularize(s)\n\t}\n\n\treturn snaker.SnakeToCamelIdentifier(s)\n}", "label": 5}
{"code": "def last_child(node)\n      last = node.children.inject(node) do |lowest, child|\n        return lowest unless child.respond_to?(:line)\n        lowest.line < child.line ? child : lowest\n      end\n\n      # In this case, none of the children have associated line numbers or the\n      # node has no children at all, so return `nil`.\n      return if last == node\n\n      last\n    end", "label": 4}
{"code": "def get_conf(name)\n      env = get(name)\n      if env\n        Puppet::Settings::EnvironmentConf.static_for(env, Puppet[:environment_timeout], Puppet[:static_catalogs], Puppet[:rich_data])\n      else\n        nil\n      end\n    end", "label": 4}
{"code": "func (s *Session) Get(ref types.ManagedObjectReference) mo.Reference {\n\tobj := s.Registry.Get(ref)\n\tif obj != nil {\n\t\treturn obj\n\t}\n\n\t// Return a session \"view\" of certain singleton objects\n\tswitch ref.Type {\n\tcase \"SessionManager\":\n\t\t// Clone SessionManager so the PropertyCollector can properly report CurrentSession\n\t\tm := *Map.SessionManager()\n\t\tm.CurrentSession = &s.UserSession\n\n\t\t// TODO: we could maintain SessionList as part of the SessionManager singleton\n\t\tfor _, session := range m.sessions {\n\t\t\tm.SessionList = append(m.SessionList, session.UserSession)\n\t\t}\n\n\t\treturn &m\n\tcase \"PropertyCollector\":\n\t\tif ref == Map.content().PropertyCollector {\n\t\t\treturn s.Put(NewPropertyCollector(ref))\n\t\t}\n\t}\n\n\treturn Map.Get(ref)\n}", "label": 5}
{"code": "def print_there(x, y, text):\n    \"\"\"\"\n    allows display of a game of life on a console via\n    resetting cursor position to a set point - looks 'ok'\n    for testing but not production quality.\n    \"\"\"\n    sys.stdout.write(\"\\x1b7\\x1b[%d;%df%s\\x1b8\" % (x, y, text))\n    sys.stdout.flush()", "label": 1}
{"code": "function logStashAppender(config, fields, layout) {\n    var time = process.hrtime(),\n        messages = [],\n        timeOutId = 0;\n\n    layout = layout || logstashLayout;\n\n    //Setup the connection to logstash\n    function pushToStash(config, msg) {\n        var client = net.connect({host: config.host, port: config.port}, function () {\n            client.write(msg);\n            client.end();\n        });\n        //Fail silently\n        client.on('error', function (evt) {\n            if (true === config.debug) {\n                console.log('An error happened in the logstash appender!', evt);\n            }\n        });\n    }\n\n    return function (logEvt) {\n        //do stuff with the logging event\n        var data = layout(logEvt, fields);\n\n        if (config.batch === true) {\n            messages.push(data);\n            clearTimeout(timeOutId);\n            if ((process.hrtime(time)[0] >= config.batchTimeout || messages.length > config.batchSize)) {\n                pushToStash(config, messages.join(''));\n                time = process.hrtime();\n                messages = [];\n            } else {\n                timeOutId = setTimeout(function () {\n                    pushToStash(config, messages.join(''));\n                    time = process.hrtime();\n                    messages = [];\n                }, 1000);\n            }\n        } else {\n            pushToStash(config, data);\n        }\n    };\n}", "label": 3}
{"code": "public function setRepresentative($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\ErrorReporting\\V1beta1\\ErrorEvent::class);\n        $this->representative = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function getBasePaths(path, includes, useCaseSensitiveFileNames) {\n        // Storage for our results in the form of literal paths (e.g. the paths as written by the user).\n        var basePaths = [path];\n        if (includes) {\n            // Storage for literal base paths amongst the include patterns.\n            var includeBasePaths = [];\n            for (var _i = 0, includes_1 = includes; _i < includes_1.length; _i++) {\n                var include = includes_1[_i];\n                // We also need to check the relative paths by converting them to absolute and normalizing\n                // in case they escape the base path (e.g \"..\\somedirectory\")\n                var absolute = isRootedDiskPath(include) ? include : normalizePath(combinePaths(path, include));\n                var wildcardOffset = indexOfAnyCharCode(absolute, wildcardCharCodes);\n                var includeBasePath = wildcardOffset < 0\n                    ? removeTrailingDirectorySeparator(getDirectoryPath(absolute))\n                    : absolute.substring(0, absolute.lastIndexOf(ts.directorySeparator, wildcardOffset));\n                // Append the literal and canonical candidate base paths.\n                includeBasePaths.push(includeBasePath);\n            }\n            // Sort the offsets array using either the literal or canonical path representations.\n            includeBasePaths.sort(useCaseSensitiveFileNames ? compareStrings : compareStringsCaseInsensitive);\n            // Iterate over each include base path and include unique base paths that are not a\n            // subpath of an existing base path\n            include: for (var i = 0; i < includeBasePaths.length; i++) {\n                var includeBasePath = includeBasePaths[i];\n                for (var j = 0; j < basePaths.length; j++) {\n                    if (containsPath(basePaths[j], includeBasePath, path, !useCaseSensitiveFileNames)) {\n                        continue include;\n                    }\n                }\n                basePaths.push(includeBasePath);\n            }\n        }\n        return basePaths;\n    }", "label": 3}
{"code": "protected function makeControllerInstance()\n    {\n        list($this->controllerClass, $this->controllerMethod) = explode('@', $this->action['uses']);\n\n        $this->container->instance($this->controllerClass,\n            $this->controller = $this->container->make($this->controllerClass));\n\n        return $this->controller;\n    }", "label": 2}
{"code": "func SetUUID(uuid string) ServerOption {\n\treturn func(s *Server) error {\n\t\ts.uuid = uuid\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public static aaauser_binding get(nitro_service service, String username) throws Exception{\n\t\taaauser_binding obj = new aaauser_binding();\n\t\tobj.set_username(username);\n\t\taaauser_binding response = (aaauser_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static vpnglobal_intranetip_binding[] get(nitro_service service) throws Exception{\n\t\tvpnglobal_intranetip_binding obj = new vpnglobal_intranetip_binding();\n\t\tvpnglobal_intranetip_binding response[] = (vpnglobal_intranetip_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private void addJoin(TableAlias left, Object[] leftKeys, TableAlias right, Object[] rightKeys, boolean outer,\r\n            String name)\r\n    {\r\n        TableAlias extAlias, rightCopy;\r\n\r\n        left.addJoin(new Join(left, leftKeys, right, rightKeys, outer, name));\r\n\r\n        // build join between left and extents of right\r\n        if (right.hasExtents())\r\n        {\r\n            for (int i = 0; i < right.extents.size(); i++)\r\n            {\r\n                extAlias = (TableAlias) right.extents.get(i);\r\n                FieldDescriptor[] extKeys = getExtentFieldDescriptors(extAlias, (FieldDescriptor[]) rightKeys);\r\n\r\n                left.addJoin(new Join(left, leftKeys, extAlias, extKeys, true, name));\r\n            }\r\n        }\r\n\r\n        // we need to copy the alias on the right for each extent on the left\r\n        if (left.hasExtents())\r\n        {\r\n            for (int i = 0; i < left.extents.size(); i++)\r\n            {\r\n                extAlias = (TableAlias) left.extents.get(i);\r\n                FieldDescriptor[] extKeys = getExtentFieldDescriptors(extAlias, (FieldDescriptor[]) leftKeys);\r\n                rightCopy = right.copy(\"C\" + i);\r\n\r\n                // copies are treated like normal extents\r\n                right.extents.add(rightCopy);\r\n                right.extents.addAll(rightCopy.extents);\r\n\r\n                addJoin(extAlias, extKeys, rightCopy, rightKeys, true, name);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "def register_model(klass)\n      LOCK.synchronize do\n        models.push(klass) unless models.include?(klass)\n      end\n    end", "label": 4}
{"code": "func (d *driver) createNetwork(config *configuration) error {\n\tnetworkList := d.getNetworks()\n\tfor _, nw := range networkList {\n\t\tif config.Parent == nw.config.Parent {\n\t\t\treturn fmt.Errorf(\"network %s is already using parent interface %s\",\n\t\t\t\tgetDummyName(stringid.TruncateID(nw.config.ID)), config.Parent)\n\t\t}\n\t}\n\tif !parentExists(config.Parent) {\n\t\t// if the --internal flag is set, create a dummy link\n\t\tif config.Internal {\n\t\t\terr := createDummyLink(config.Parent, getDummyName(stringid.TruncateID(config.ID)))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tconfig.CreatedSlaveLink = true\n\t\t\t// notify the user in logs they have limited communications\n\t\t\tif config.Parent == getDummyName(stringid.TruncateID(config.ID)) {\n\t\t\t\tlogrus.Debugf(\"Empty -o parent= and --internal flags limit communications to other containers inside of network: %s\",\n\t\t\t\t\tconfig.Parent)\n\t\t\t}\n\t\t} else {\n\t\t\t// if the subinterface parent_iface.vlan_id checks do not pass, return err.\n\t\t\t//  a valid example is 'eth0.10' for a parent iface 'eth0' with a vlan id '10'\n\t\t\terr := createVlanLink(config.Parent)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\t// if driver created the networks slave link, record it for future deletion\n\t\t\tconfig.CreatedSlaveLink = true\n\t\t}\n\t}\n\tn := &network{\n\t\tid:        config.ID,\n\t\tdriver:    d,\n\t\tendpoints: endpointTable{},\n\t\tconfig:    config,\n\t}\n\t// add the *network\n\td.addNetwork(n)\n\n\treturn nil\n}", "label": 5}
{"code": "function (e) {\n            var chart = this.chart,\n              hasPinched = this.hasPinched;\n\n            if (this.selectionMarker) {\n                var selectionData = {\n                      xAxis: [],\n                      yAxis: [],\n                      originalEvent: e.originalEvent || e\n                  },\n                  selectionBox = this.selectionMarker,\n                  selectionLeft = selectionBox.attr ? selectionBox.attr('x') : selectionBox.x,\n                  selectionTop = selectionBox.attr ? selectionBox.attr('y') : selectionBox.y,\n                  selectionWidth = selectionBox.attr ? selectionBox.attr('width') : selectionBox.width,\n                  selectionHeight = selectionBox.attr ? selectionBox.attr('height') : selectionBox.height,\n                  runZoom;\n\n                // a selection has been made\n                if (this.hasDragged || hasPinched) {\n\n                    // record each axis' min and max\n                    each(chart.axes, function (axis) {\n                        if (axis.zoomEnabled) {\n                            var horiz = axis.horiz,\n                              minPixelPadding = e.type === 'touchend' ? axis.minPixelPadding: 0, // #1207, #3075\n                              selectionMin = axis.toValue((horiz ? selectionLeft : selectionTop) + minPixelPadding),\n                              selectionMax = axis.toValue((horiz ? selectionLeft + selectionWidth : selectionTop + selectionHeight) - minPixelPadding);\n\n                            if (!isNaN(selectionMin) && !isNaN(selectionMax)) { // #859\n                                selectionData[axis.coll].push({\n                                    axis: axis,\n                                    min: mathMin(selectionMin, selectionMax), // for reversed axes,\n                                    max: mathMax(selectionMin, selectionMax)\n                                });\n                                runZoom = true;\n                            }\n                        }\n                    });\n                    if (runZoom) {\n                        fireEvent(chart, 'selection', selectionData, function (args) {\n                            chart.zoom(extend(args, hasPinched ? { animation: false } : null));\n                        });\n                    }\n\n                }\n                this.selectionMarker = this.selectionMarker.destroy();\n\n                // Reset scaling preview\n                if (hasPinched) {\n                    this.scaleGroups();\n                }\n            }\n\n            // Reset all\n            if (chart) { // it may be destroyed on mouse up - #877\n                css(chart.container, { cursor: chart._cursor });\n                chart.cancelClick = this.hasDragged > 10; // #370\n                chart.mouseIsDown = this.hasDragged = this.hasPinched = false;\n                this.pinchDown = [];\n            }\n        }", "label": 3}
{"code": "public static base_response delete(nitro_service client, snmptrap resource) throws Exception {\n\t\tsnmptrap deleteresource = new snmptrap();\n\t\tdeleteresource.trapclass = resource.trapclass;\n\t\tdeleteresource.trapdestination = resource.trapdestination;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "func (o *OIDCConnectorV2) V1() *OIDCConnectorV1 {\n\treturn &OIDCConnectorV1{\n\t\tID:            o.Metadata.Name,\n\t\tIssuerURL:     o.Spec.IssuerURL,\n\t\tClientID:      o.Spec.ClientID,\n\t\tClientSecret:  o.Spec.ClientSecret,\n\t\tRedirectURL:   o.Spec.RedirectURL,\n\t\tDisplay:       o.Spec.Display,\n\t\tScope:         o.Spec.Scope,\n\t\tClaimsToRoles: o.Spec.ClaimsToRoles,\n\t}\n}", "label": 5}
{"code": "def _ref_bus_angle_constraint(self, buses, Va, xmin, xmax):\n        \"\"\" Adds a constraint on the reference bus angles.\n        \"\"\"\n        refs = [bus._i for bus in buses if bus.type == REFERENCE]\n        Varefs = array([b.v_angle for b in buses if b.type == REFERENCE])\n\n        xmin[Va.i1 - 1 + refs] = Varefs\n        xmax[Va.iN - 1 + refs] = Varefs\n\n        return xmin, xmax", "label": 1}
{"code": "public static base_responses unset(nitro_service client, String selectorname[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (selectorname != null && selectorname.length > 0) {\n\t\t\tnslimitselector unsetresources[] = new nslimitselector[selectorname.length];\n\t\t\tfor (int i=0;i<selectorname.length;i++){\n\t\t\t\tunsetresources[i] = new nslimitselector();\n\t\t\t\tunsetresources[i].selectorname = selectorname[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public int compare(Vector3 o1, Vector3 o2) {\n\t\tint ans = 0;\n\n\t\tif (o1 != null && o2 != null) {\n\t\t\tVector3 d1 = o1;\n\t\t\tVector3 d2 = o2;\n\n\t\t\tif (d1.x > d2.x)\n\t\t\t\treturn 1;\n\t\t\tif (d1.x < d2.x)\n\t\t\t\treturn -1;\n\t\t\t// x1 == x2\n\t\t\tif (d1.y > d2.y)\n\t\t\t\treturn 1;\n\t\t\tif (d1.y < d2.y)\n\t\t\t\treturn -1;\n\t\t} else {\n\t\t\tif (o1 == null && o2 == null)\n\t\t\t\treturn 0;\n\t\t\tif (o1 == null && o2 != null)\n\t\t\t\treturn 1;\n\t\t\tif (o1 != null && o2 == null)\n\t\t\t\treturn -1;\n\t\t}\n\t\t\n\t\treturn ans;\n\t}", "label": 0}
{"code": "public void getGradient(int[] batch, double[] gradient) {\n        for (int i=0; i<batch.length; i++) {\n            addGradient(i, gradient);\n        }\n    }", "label": 0}
{"code": "public static java.util.Date toDateTime(Object value) throws ParseException {\n        if (value == null) {\n            return null;\n        }\n        if (value instanceof java.util.Date) {\n            return (java.util.Date) value;\n        }\n        if (value instanceof String) {\n            if (\"\".equals((String) value)) {\n                return null;\n            }\n            return IN_DATETIME_FORMAT.parse((String) value);\n        }\n\n        return IN_DATETIME_FORMAT.parse(value.toString());\n    }", "label": 0}
{"code": "protected function whereBatchId($query, EntryQueryOptions $options)\n    {\n        $query->when($options->batchId, function ($query, $batchId) {\n            return $query->where('batch_id', $batchId);\n        });\n\n        return $this;\n    }", "label": 2}
{"code": "def pickle_loads(inbox):\n    \"\"\"\n    Deserializes the first element of the input using the pickle protocol.\n    \n    \"\"\"\n    gc.disable()\n    obj = cPickle.loads(inbox[0])\n    gc.enable()\n    return obj", "label": 1}
{"code": "def update_cell(self, row, col):\n        \"\"\"\n        Function that computes the update for one cell in the Game of Life\n        \"\"\"\n        # compute number of living neighbors\n        neighbors = self.eight_neighbors(row, col)\n        living_neighbors = 0\n        for neighbor in neighbors:\n            if not self.is_empty(neighbor[0], neighbor[1]):\n                living_neighbors += 1\n            \n        # logic for Game of life        \n        if (living_neighbors == 3) or (living_neighbors == 2 and not self.is_empty(row, col)):\n            return mod_grid.FULL\n        else:\n            return mod_grid.EMPTY", "label": 1}
{"code": "func (s Style) Background(c Color) Style {\n\tif c == ColorDefault {\n\t\treturn (s &^ (0x1ffffff | styleBgSet))\n\t}\n\treturn (s &^ (0x1ffffff)) | (Style(c) & 0x1ffffff) | styleBgSet\n}", "label": 5}
{"code": "def contrail_error_handler(f):\n    \"\"\"Handle HTTP errors returned by the API server\n    \"\"\"\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        try:\n            return f(*args, **kwargs)\n        except HttpError as e:\n            # Replace message by details to provide a\n            # meaningful message\n            if e.details:\n                e.message, e.details = e.details, e.message\n                e.args = (\"%s (HTTP %s)\" % (e.message, e.http_status),)\n            raise\n    return wrapper", "label": 1}
{"code": "def pause(topic, partition, timeout: nil, max_timeout: nil, exponential_backoff: false)\n      if max_timeout && !exponential_backoff\n        raise ArgumentError, \"`max_timeout` only makes sense when `exponential_backoff` is enabled\"\n      end\n\n      pause_for(topic, partition).pause!(\n        timeout: timeout,\n        max_timeout: max_timeout,\n        exponential_backoff: exponential_backoff,\n      )\n    end", "label": 4}
{"code": "function renderTemplate(templateFile, data, options) {\n    return renderTemplateText(read(normalizeTemplate(templateFile)), data, options);\n  }", "label": 3}
{"code": "def each_srv_record(domain, service_name = :puppet, &block)\n      if (domain.nil? or domain.empty?)\n        Puppet.debug \"Domain not known; skipping SRV lookup\"\n        return\n      end\n\n      Puppet.debug \"Searching for SRV records for domain: #{domain}\"\n\n      case service_name\n        when :puppet then service = '_x-puppet'\n        when :file   then service = '_x-puppet-fileserver'\n        else              service = \"_x-puppet-#{service_name.to_s}\"\n      end\n      record_name = \"#{service}._tcp.#{domain}\"\n\n      if @record_cache.has_key?(service_name) && !expired?(service_name)\n        records = @record_cache[service_name].records\n        Puppet.debug \"Using cached record for #{record_name}\"\n      else\n        records = @resolver.getresources(record_name, Resolv::DNS::Resource::IN::SRV)\n        if records.size > 0\n          @record_cache[service_name] = CacheEntry.new(records)\n        end\n        Puppet.debug \"Found #{records.size} SRV records for: #{record_name}\"\n      end\n\n      if records.size == 0 && service_name != :puppet\n        # Try the generic :puppet service if no SRV records were found\n        # for the specific service.\n        each_srv_record(domain, :puppet, &block)\n      else\n        each_priority(records) do |recs|\n          while next_rr = recs.delete(find_weighted_server(recs))\n            Puppet.debug \"Yielding next server of #{next_rr.target.to_s}:#{next_rr.port}\"\n            yield next_rr.target.to_s, next_rr.port\n          end\n        end\n      end\n    end", "label": 4}
{"code": "func TunnelAuthDialer(proxyAddr string, sshConfig *ssh.ClientConfig) auth.DialContext {\n\treturn func(ctx context.Context, network string, addr string) (net.Conn, error) {\n\t\t// Connect to the reverse tunnel server.\n\t\tdialer := proxy.DialerFromEnvironment(proxyAddr)\n\t\tsconn, err := dialer.Dial(\"tcp\", proxyAddr, sshConfig)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\n\t\tconn, err := connectProxyTransport(sconn.Conn, RemoteAuthServer)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn conn, nil\n\t}\n}", "label": 5}
{"code": "def extractUnits(self, inp):\n        \"\"\"Collects all the valid units from an inp string. Works by\n        appending consecutive words from the string and cross-referncing\n        them with a set of valid units.\n\n        Args:\n            inp (str): Some text which hopefully contains descriptions\n                of different units.\n\n        Returns:\n            A list of strings, each entry in which is a valid quantities\n            unit.\n        \"\"\"\n        inp = self._preprocess(inp)\n\n        units = []\n        description = \"\"\n        for w in inp.split(' '):\n            if self.isValidUnit(w) or w == '/':\n                if description:\n                    description += \" \"\n                description += w\n            else:\n                if description:\n                    units.append(description)\n                description = \"\"\n\n        if description:\n            units.append(description)\n        return units", "label": 1}
{"code": "public function setApplicationDateFilters($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\ApplicationDateFilter::class);\n        $this->application_date_filters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "private void checkRowReader(ClassDescriptorDef classDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (!CHECKLEVEL_STRICT.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n        \r\n        String rowReaderName  = classDef.getProperty(PropertyHelper.OJB_PROPERTY_ROW_READER);\r\n\r\n        if (rowReaderName == null)\r\n        {\r\n            return;\r\n        }\r\n\r\n        try\r\n        {\r\n            InheritanceHelper helper = new InheritanceHelper();\r\n\r\n            if (!helper.isSameOrSubTypeOf(rowReaderName, ROW_READER_INTERFACE))\r\n            {\r\n                throw new ConstraintException(\"The class \"+rowReaderName+\" specified as row-reader of class \"+classDef.getName()+\" does not implement the interface \"+ROW_READER_INTERFACE);\r\n            }\r\n        }\r\n        catch (ClassNotFoundException ex)\r\n        {\r\n            throw new ConstraintException(\"Could not find the class \"+ex.getMessage()+\" on the classpath while checking the row-reader class \"+rowReaderName+\" of class \"+classDef.getName());\r\n        }\r\n    }", "label": 0}
{"code": "function(properties, startingValue, compareFunction)\n  {\n    var comparator = compareFunction || compare;\n    var resolver = createPropertyResolver( properties );\n    var max = startingValue;\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var resolved = resolver( this[ i ] );\n\n      if ( comparator( max, resolved, true ) < 0 )\n      {\n        max = resolved;\n      }\n    }\n\n    return max;\n  }", "label": 3}
{"code": "func GetEventDescriptor(event *Event) EventDescriptor {\n\tbee := GetBee(event.Bee)\n\tif bee == nil {\n\t\tpanic(\"Bee \" + event.Bee + \" not registered\")\n\t}\n\tfactory := (*GetFactory((*bee).Namespace()))\n\tfor _, ev := range factory.Events() {\n\t\tif ev.Name == event.Name {\n\t\t\treturn ev\n\t\t}\n\t}\n\n\treturn EventDescriptor{}\n}", "label": 5}
{"code": "public static String getPrefixFromValue(String value) {\n    if (value == null) {\n      return null;\n    } else if (value.contains(DELIMITER)) {\n      String[] list = value.split(DELIMITER);\n      if (list != null && list.length > 0) {\n        return list[0].replaceAll(\"\\u0000\", \"\");\n      } else {\n        return null;\n      }\n    } else {\n      return value.replaceAll(\"\\u0000\", \"\");\n    }\n  }", "label": 0}
{"code": "def _get_id_and_model(self, id_or_model):\n        \"\"\"\n        Get both the model and ID of an object that could be an ID or a model.\n\n        :param id_or_model:\n            The object that could be an ID string or a model object.\n        :param model_collection:\n            The collection to which the model belongs.\n        \"\"\"\n        if isinstance(id_or_model, self.collection.model):\n            model = id_or_model\n        elif isinstance(id_or_model, str):\n            # Assume we have an ID string\n            model = self.collection.get(id_or_model)\n        else:\n            raise TypeError('Unexpected type {}, expected {} or {}'.format(\n                type(id_or_model), str, self.collection.model))\n\n        return model.id, model", "label": 1}
{"code": "public static <E> Counter<E> absoluteDifference(Counter<E> c1, Counter<E> c2) {\r\n    Counter<E> result = c1.getFactory().create();\r\n    for (E key : Sets.union(c1.keySet(), c2.keySet())) {\r\n      double newCount = Math.abs(c1.getCount(key) - c2.getCount(key));\r\n      if (newCount > 0) {\r\n        result.setCount(key, newCount);\r\n      }\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "def evaluate(self):\n        \"\"\" Converts the current expression into a single matcher, applying\n            coordination operators to operands according to their binding rules\n        \"\"\"\n\n        # Apply Shunting Yard algorithm to convert the infix expression\n        # into Reverse Polish Notation. Since we have a very limited\n        # set of operators and binding rules, the implementation becomes\n        # really simple. The expression is formed of hamcrest matcher instances\n        # and operators identifiers (ints).\n        ops = []\n        rpn = []\n        for token in self.expr:\n            if isinstance(token, int):\n                while len(ops) and token <= ops[-1]:\n                    rpn.append(ops.pop())\n                ops.append(token)\n            else:\n                rpn.append(token)\n\n        # Append the remaining operators\n        while len(ops):\n            rpn.append(ops.pop())\n\n        # Walk the RPN expression to create AllOf/AnyOf matchers\n        stack = []\n        for token in rpn:\n            if isinstance(token, int):\n                # Handle the NOT case in a special way since it's unary\n                if token == OPERATOR.NOT:\n                    stack[-1] = IsNot(stack[-1])\n                    continue\n\n                # Our operators always need two operands\n                if len(stack) < 2:\n                    raise RuntimeError('Unable to build a valid expression. Not enough operands available.')\n\n                # Check what kind of matcher we need to create\n                if token == OPERATOR.OR:\n                    matcher = hc.any_of(*stack[-2:])\n                else:  # AND, BUT\n                    matcher = hc.all_of(*stack[-2:])\n\n                stack[-2:] = [matcher]\n            else:\n                stack.append(token)\n\n        if len(stack) != 1:\n            raise RuntimeError('Unable to build a valid expression. The RPN stack should have just one item.')\n\n        matcher = stack.pop()\n\n        # If a description has been given include it in the matcher\n        if self.description:\n            matcher = hc.described_as(self.description, matcher)\n\n        return matcher", "label": 1}
{"code": "func (tsdbSink *openTSDBSink) putDefaultTags(datapoint *opentsdbclient.DataPoint) {\n\tdatapoint.Tags[clusterNameTagName] = tsdbSink.clusterName\n}", "label": 5}
{"code": "def write_validate(ctx, param, value):\n    \"\"\" Validate the -w option.\n\n    Purpose: Validates the `-w`|`--write` option. Two arguments are expected.\n           | The first is the mode, which must be in ['s', 'single', 'm',\n           |  'multiple']. The mode determins if we're writing to one file for\n           | all device output, or to a separate file for each device being\n           | handled.\n           |\n           | The second expected argument is the filepath of the desired\n           | output file. This will automatically be prepended with the IP or\n           | hostname of the device if we're writing to multiple files.\n\n    @param ctx: The click context paramter, for receiving the object dictionary\n              | being manipulated by other previous functions. Needed by any\n              | function with the @click.pass_context decorator. Callback\n              | functions such as this one receive this automatically.\n    @type ctx: click.Context\n    @param param: param is passed into a validation callback function by click.\n                | We do not use it.\n    @type param: None\n    @param value: The value that the user supplied for the write option.\n    @type value: str\n\n    @returns: The value that the user supplied, if it passed validation.\n            | Otherwise, raises click.BadParameter\n    @rtype: str\n    \"\"\"\n    if value != (\"default\", \"default\"):\n        try:\n            mode, dest_file = (value[0], value[1])\n        except IndexError:\n            raise click.BadParameter('Expecting two arguments, one for how to '\n                                     'output (s, single, m, multiple), and '\n                                     'the second is a filepath where to put'\n                                     ' the output.')\n        if mode.lower() not in ['s', 'single', 'm', 'multiple']:\n            raise click.BadParameter('The first argument of the -w/--write '\n                                     'option must specifies whether to write'\n                                     ' to one file per device, or all device'\n                                     ' output to a single file. Valid options'\n                                     ' are \"s\", \"single\", \"m\", and \"multiple\"')\n        # we've passed the checks, so set the 'out' context variable to our\n        # tuple of the mode, and the destination file.\n        ctx.obj['out'] = (mode.lower(), dest_file)\n    else:  # they didn't use -w, so set the context variable accordingly.\n        ctx.obj['out'] = None", "label": 1}
{"code": "function FileHandler(filename, mode, encoding, delay) {\n\tmode = mode || 'a';\n\tencoding = typeof encoding !== 'undefined' ? encoding : 'utf8';\n\tdelay = typeof delay !== 'undefined' ? delay : false;\n\n\t/**\n\t * @private\n\t * @type {string}\n\t */\n\tthis._filename = filename;\n\n\t/**\n\t * @private\n\t * @type {string}\n\t */\n\tthis._mode = mode;\n\n\t/**\n\t * @private\n\t * @type {string}\n\t */\n\tthis._encoding = encoding;\n\n\tif (delay) {\n\t\tStreamHandler.call(this);\n\t\tthis._stream = null;\n\n\t} else {\n\t\tStreamHandler.call(this, this._open());\n\t}\n}", "label": 3}
{"code": "public function encodeValuesAsSimpleType(array $values, $allowMixedArrayType = false)\n    {\n        $res = [];\n        foreach ($values as $value) {\n            $type = null;\n            $definition = null;\n            if (is_array($value) && (empty($value) || !$this->isAssoc($value))) {\n                $type = Database::TYPE_ARRAY;\n                $definition = new ArrayType(null);\n            }\n\n            $res[] = $this->paramType($value, $type, $definition, $allowMixedArrayType)[0];\n        }\n\n        return $res;\n    }", "label": 2}
{"code": "function cloneEntityName(node, parent) {\n        var clone = cloneNode(node, node, node.flags, parent);\n        if (isQualifiedName(clone)) {\n            var left = clone.left, right = clone.right;\n            clone.left = cloneEntityName(left, clone);\n            clone.right = cloneNode(right, right, right.flags, parent);\n        }\n        return clone;\n    }", "label": 3}
{"code": "public static tmtrafficaction[] get(nitro_service service) throws Exception{\n\t\ttmtrafficaction obj = new tmtrafficaction();\n\t\ttmtrafficaction[] response = (tmtrafficaction[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function build(options) {\n  options = Object.assign({}, options)\n\n  return resolveStyleguide(options)\n  .then(function (styleguide) {\n    success('Styleguide.write:', 'start writing ...')\n    return styleguide.write()\n  })\n  .then(function (styleguide) {\n    success('Styleguide.write:', 'finished writing')\n    return styleguide\n  })\n  .catch(function (e) {\n    error('Cli.build', 'failed to build Styleguide', e)\n    throw (e)\n  })\n}", "label": 3}
{"code": "function aceInitialized(hook, context){\n  var editorInfo = context.editorInfo;\n  editorInfo.ace_doInsertHeading = _(doInsertHeading).bind(context);\n}", "label": 3}
{"code": "def config_file_contents\n      output = []\n      output << HEADING\n      output << 'linters:' if linters_with_lints.any?\n      linters_with_lints.each do |linter, files|\n        output << generate_config_for_linter(linter, files)\n      end\n      output.join(\"\\n\\n\")\n    end", "label": 4}
{"code": "func (u *Uploader) Scan() error {\n\tdf, err := os.Open(u.scanDir)\n\terr = trace.ConvertSystemError(err)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdefer df.Close()\n\tentries, err := df.Readdir(-1)\n\tif err != nil {\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\tvar count int\n\tfor i := range entries {\n\t\tfi := entries[i]\n\t\tif fi.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tif !strings.HasSuffix(fi.Name(), \"completed\") {\n\t\t\tcontinue\n\t\t}\n\t\tparts := strings.Split(fi.Name(), \".\")\n\t\tif len(parts) < 2 {\n\t\t\tu.Debugf(\"Uploader, skipping unknown file: %v\", fi.Name())\n\t\t\tcontinue\n\t\t}\n\t\tsessionID := session.ID(parts[0])\n\t\tlockFilePath := filepath.Join(u.scanDir, fi.Name())\n\t\tif err := u.uploadFile(lockFilePath, sessionID); err != nil {\n\t\t\tif trace.IsCompareFailed(err) {\n\t\t\t\tu.Debugf(\"Uploader detected locked file %v, another process is uploading it.\", lockFilePath)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\tcount += 1\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static ipset_nsip6_binding[] get(nitro_service service, String name) throws Exception{\n\t\tipset_nsip6_binding obj = new ipset_nsip6_binding();\n\t\tobj.set_name(name);\n\t\tipset_nsip6_binding response[] = (ipset_nsip6_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (c *githubAPIClient) getUser() (*userResponse, error) {\n\t// Ignore pagination links, we should never get more than a single user here.\n\tbytes, _, err := c.get(\"/user\")\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar user userResponse\n\terr = json.Unmarshal(bytes, &user)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &user, nil\n}", "label": 5}
{"code": "public function setProduct($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\Product::class);\n        $this->product = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function deleteAppForms(cb) {\n        var appId = params.appId;\n\n        async.series([\n          function(cb) { // first remove the form itself\n            var appFormsModel = models.get(connections.mongooseConnection, models.MODELNAMES.APP_FORMS);\n            appFormsModel.find({appId: appId}).remove().exec(cb);\n          },\n          function(cb) { // remove deleted from from any groups\n            groups.removeAppFromAllGroups(connections, appId, cb);\n          },\n          function deleteThemeRefrences(cb) {\n            var appThemeModel  = models.get(connections.mongooseConnection, models.MODELNAMES.APP_THEMES);\n            appThemeModel.find({\"appId\":appId}).remove().exec(cb);\n          },\n          function deleteAppConfigReferences(cb) {\n            var appConfigModel = models.get(connections.mongooseConnection, models.MODELNAMES.APP_CONFIG);\n            appConfigModel.find({\"appId\":appId}).remove().exec(cb);\n          }\n        ], function(err) {\n          if (err) {\n            return cb(err);\n          }\n          return cb(null);\n        });\n      }", "label": 3}
{"code": "def create_instance(res)\n      response = res.parsed_response\n\n      # if there was an error, throw it\n      raise_error(response['error'], res.code) if response.nil? || response.key?('error')\n\n      # There must be a top level entity\n      # This is either one of payment, refund, or collection at present\n      begin\n        class_name = response['entity'].split('_').collect(&:capitalize).join\n\n        klass = Razorpay.const_get class_name\n      rescue NameError\n        # Use Entity class if we don't find any\n        klass = Razorpay::Entity\n      end\n      klass.new(response)\n    end", "label": 4}
{"code": "private void init_jdbcTypes() throws SQLException\r\n    {\r\n        ReportQuery q = (ReportQuery) getQueryObject().getQuery();\r\n        m_jdbcTypes = new int[m_attributeCount];\r\n        \r\n        // try to get jdbcTypes from Query\r\n        if (q.getJdbcTypes() != null)\r\n        {\r\n            m_jdbcTypes = q.getJdbcTypes();\r\n        }\r\n        else\r\n        {\r\n            ResultSetMetaData rsMetaData = getRsAndStmt().m_rs.getMetaData();\r\n            for (int i = 0; i < m_attributeCount; i++)\r\n            {\r\n                m_jdbcTypes[i] = rsMetaData.getColumnType(i + 1);\r\n            }\r\n            \r\n        }\r\n    }", "label": 0}
{"code": "def write_branch_data(self, file):\n        \"\"\" Writes branch data as CSV.\n        \"\"\"\n        writer = self._get_writer(file)\n        writer.writerow(BRANCH_ATTRS)\n        for branch in self.case.branches:\n            writer.writerow([getattr(branch, a) for a in BRANCH_ATTRS])", "label": 1}
{"code": "public function insertOrUpdateBatch($table, array $dataSet, array $options = [])\n    {\n        $mutations = [];\n        foreach ($dataSet as $data) {\n            $mutations[] = $this->operation->mutation(Operation::OP_INSERT_OR_UPDATE, $table, $data);\n        }\n\n        return $this->commitInSingleUseTransaction($mutations, $options);\n    }", "label": 2}
{"code": "def get_networks(self, contents):\n        \"\"\"Process config contents with cdrouter-cli -print-networks-json.\n\n        :param contents: Config contents as string.\n        :return: :class:`configs.Networks <configs.Networks>` object\n        :rtype: configs.Networks\n        \"\"\"\n        schema = NetworksSchema()\n        resp = self.service.post(self.base,\n                                 params={'process': 'networks'}, json={'contents': contents})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function GetFloatDivInfo($blklvl = 0, $clear = false)\n\t{\n\t\t// If blklvl specified, only returns floats at that level - for ClearFloats\n\t\t$l_exists = false;\n\t\t$r_exists = false;\n\t\t$l_max = 0;\n\t\t$r_max = 0;\n\t\t$l_width = 0;\n\t\t$r_width = 0;\n\t\tif (count($this->floatDivs)) {\n\t\t\t$currpos = ($this->page * 1000 + $this->y);\n\t\t\tforeach ($this->floatDivs as $f) {\n\t\t\t\tif (($clear && $f['blockContext'] == $this->blk[$blklvl]['blockContext']) || (!$clear && $currpos >= $f['startpos'] && $currpos < ($f['endpos'] - 0.001) && $f['blklvl'] > $blklvl && $f['blockContext'] == $this->blk[$blklvl]['blockContext'])) {\n\t\t\t\t\tif ($f['side'] == 'L') {\n\t\t\t\t\t\t$l_exists = true;\n\t\t\t\t\t\t$l_max = max($l_max, $f['endpos']);\n\t\t\t\t\t\t$l_width = max($l_width, $f['w']);\n\t\t\t\t\t}\n\t\t\t\t\tif ($f['side'] == 'R') {\n\t\t\t\t\t\t$r_exists = true;\n\t\t\t\t\t\t$r_max = max($r_max, $f['endpos']);\n\t\t\t\t\t\t$r_width = max($r_width, $f['w']);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn [$l_exists, $r_exists, $l_max, $r_max, $l_width, $r_width];\n\t}", "label": 2}
{"code": "func (v *ViewPort) ValidateViewY() {\n\tif v.viewy >= v.limy-v.height {\n\t\tv.viewy = (v.limy - v.height)\n\t}\n\tif v.viewy < 0 {\n\t\tv.viewy = 0\n\t}\n}", "label": 5}
{"code": "func (s *SubnetKey) FromString(str string) error {\n\tif str == \"\" || !strings.Contains(str, \"/\") {\n\t\treturn types.BadRequestErrorf(\"invalid string form for subnetkey: %s\", str)\n\t}\n\n\tp := strings.Split(str, \"/\")\n\tif len(p) != 3 && len(p) != 5 {\n\t\treturn types.BadRequestErrorf(\"invalid string form for subnetkey: %s\", str)\n\t}\n\ts.AddressSpace = p[0]\n\ts.Subnet = fmt.Sprintf(\"%s/%s\", p[1], p[2])\n\tif len(p) == 5 {\n\t\ts.ChildSubnet = fmt.Sprintf(\"%s/%s\", p[3], p[4])\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function ZPassThrough(options) {\n\tif(options) {\n\t\tif(options.objectMode) {\n\t\t\toptions.readableObjectMode = true;\n\t\t\toptions.writableObjectMode = true;\n\t\t}\n\t\tif(options.readableObjectMode && options.writableObjectMode) {\n\t\t\toptions.objectMode = true;\n\t\t}\n\t}\n\tPassThrough.call(this, options);\n\t// note: exclamation marks are used to convert to booleans\n\tif(options && !options.objectMode && (!options.readableObjectMode) !== (!options.writableObjectMode)) {\n\t\tthis._writableState.objectMode = !!options.writableObjectMode;\n\t\tthis._readableState.objectMode = !!options.readableObjectMode;\n\t}\n\tif(options && options.readableObjectMode) {\n\t\tthis._readableState.highWaterMark = 16;\n\t}\n\tif(options && options.writableObjectMode) {\n\t\tthis._writableState.highWaterMark = 16;\n\t}\n\tstreamMixins.call(this, PassThrough.prototype, options);\n\treadableMixins.call(this, options);\n\twritableMixins.call(this, options);\n}", "label": 3}
{"code": "def split_ls(func):\n    \"\"\"Decorator to split files into manageable chunks as not to exceed the windows cmd limit\n\n    :param func: Function to call for each chunk\n    :type func: :py:class:Function\n    \"\"\"\n    @wraps(func)\n    def wrapper(self, files, silent=True, exclude_deleted=False):\n        if not isinstance(files, (tuple, list)):\n            files = [files]\n\n        counter = 0\n        index = 0\n        results = []\n\n        while files:\n            if index >= len(files):\n                results += func(self, files, silent, exclude_deleted)\n                break\n\n            length = len(str(files[index]))\n            if length + counter > CHAR_LIMIT:\n                # -- at our limit\n                runfiles = files[:index]\n                files = files[index:]\n                counter = 0\n                index = 0\n                results += func(self, runfiles, silent, exclude_deleted)\n                runfiles = None\n                del runfiles\n            else:\n                index += 1\n                counter += length\n\n        return results\n\n    return wrapper", "label": 1}
{"code": "func ReleaseLock(ctx context.Context, backend Backend, lockName string) error {\n\tif lockName == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter lockName\")\n\t}\n\tkey := []byte(filepath.Join(locksPrefix, lockName))\n\tif err := backend.Delete(ctx, key); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func generateAddress(ordinal uint64, network *net.IPNet) net.IP {\n\tvar address [16]byte\n\n\t// Get network portion of IP\n\tif getAddressVersion(network.IP) == v4 {\n\t\tcopy(address[:], network.IP.To4())\n\t} else {\n\t\tcopy(address[:], network.IP)\n\t}\n\n\tend := len(network.Mask)\n\taddIntToIP(address[:end], ordinal)\n\n\treturn net.IP(address[:end])\n}", "label": 5}
{"code": "def update_fields(fields)\n      attributes[:id]      = fields['id'] || attributes[:id]\n      attributes[:state]   = fields['state'] || attributes[:state]\n      attributes[:item_id] = fields['idCheckItem'] || attributes[:item_id]\n      self\n    end", "label": 4}
{"code": "public static vrid6[] get(nitro_service service) throws Exception{\n\t\tvrid6 obj = new vrid6();\n\t\tvrid6[] response = (vrid6[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def run(self, cmd, stdin=None, marshal_output=True, **kwargs):\n        \"\"\"Runs a p4 command and returns a list of dictionary objects\n\n        :param cmd: Command to run\n        :type cmd: list\n        :param stdin: Standard Input to send to the process\n        :type stdin: str\n        :param marshal_output: Whether or not to marshal the output from the command\n        :type marshal_output: bool\n        :param kwargs: Passes any other keyword arguments to subprocess\n        :raises: :class:`.error.CommandError`\n        :returns: list, records of results\n        \"\"\"\n        records = []\n        args = [self._executable, \"-u\", self._user, \"-p\", self._port]\n\n        if self._client:\n            args += [\"-c\", str(self._client)]\n\n        if marshal_output:\n            args.append('-G')\n\n        if isinstance(cmd, six.string_types):\n            raise ValueError('String commands are not supported, please use a list')\n\n        args += cmd\n\n        command = ' '.join(args)\n\n        startupinfo = None\n        if os.name == 'nt':\n            startupinfo = subprocess.STARTUPINFO()\n            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n\n        proc = subprocess.Popen(\n            args,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            startupinfo=startupinfo,\n            **kwargs\n        )\n\n        if stdin:\n            proc.stdin.write(six.b(stdin))\n\n        if marshal_output:\n            try:\n                while True:\n                    record = marshal.load(proc.stdout)\n                    if record.get(b'code', '') == b'error' and record[b'severity'] >= self._level:\n                        proc.stdin.close()\n                        proc.stdout.close()\n                        raise errors.CommandError(record[b'data'], record, command)\n                    if isinstance(record, dict):\n                        if six.PY2:\n                            records.append(record)\n                        else:\n                            records.append({str(k, 'utf8'): str(v) if isinstance(v, int) else str(v, 'utf8', errors='ignore') for k, v in record.items()})\n            except EOFError:\n                pass\n\n            stdout, stderr = proc.communicate()\n        else:\n            records, stderr = proc.communicate()\n\n        if stderr:\n            raise errors.CommandError(stderr, command)\n\n        return records", "label": 1}
{"code": "def have_rakefile # :nodoc:\n      @rakefiles.each do |fn|\n        if File.exist?(fn)\n          others = FileList.glob(fn, File::FNM_CASEFOLD)\n          return others.size == 1 ? others.first : fn\n        elsif fn == \"\"\n          return fn\n        end\n      end\n      return nil\n    end", "label": 4}
{"code": "func (ts *Store) GetImageHash(id string) (string, error) {\n\ttreepath := ts.GetPath(id)\n\n\timgHash, err := ioutil.ReadFile(filepath.Join(treepath, imagefilename))\n\tif err != nil {\n\t\treturn \"\", errwrap.Wrap(errors.New(\"cannot read image file\"), err)\n\t}\n\n\treturn string(imgHash), nil\n}", "label": 5}
{"code": "def run_callback(method, *args)\n      case method\n      when Symbol\n        send(method, *args)\n      when Proc\n        instance_exec(*args, &method)\n      else\n        raise \"Please register with callbacks using a symbol or a block/proc.\"\n      end\n    end", "label": 4}
{"code": "func OptionPortMapping(portBindings []types.PortBinding) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tif sb.config.generic == nil {\n\t\t\tsb.config.generic = make(map[string]interface{})\n\t\t}\n\t\t// Store a copy of the bindings as generic data to pass to the driver\n\t\tpbs := make([]types.PortBinding, len(portBindings))\n\t\tcopy(pbs, portBindings)\n\t\tsb.config.generic[netlabel.PortMap] = pbs\n\t}\n}", "label": 5}
{"code": "def copy_file_if_needed!(filename: nil, dry_run: false)\n      needs_update = file_needs_update?(filename: filename)\n      UI.verbose(\"file #{filename} needs an update\") if needs_update\n\n      # Ok, we know if this file needs an update, can return now if it's a dry run\n      return needs_update if dry_run\n\n      unless needs_update\n        # no work needed, just return\n        return false\n      end\n\n      source = File.join(self.source_swift_code_file_folder_path, \"/#{filename}\")\n      target = File.join(self.target_swift_code_file_folder_path, \"/#{filename}\")\n\n      FileUtils.cp(source, target)\n      UI.verbose(\"Copied #{source} to #{target}\")\n      return true\n    end", "label": 4}
{"code": "func OpenFile(path string) (*os.File, error) {\n\tnewPath, err := NormalizePath(path)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tfi, err := os.Stat(newPath)\n\tif err != nil {\n\t\treturn nil, trace.ConvertSystemError(err)\n\t}\n\tif fi.IsDir() {\n\t\treturn nil, trace.BadParameter(\"%v is not a file\", path)\n\t}\n\tf, err := os.Open(newPath)\n\tif err != nil {\n\t\treturn nil, trace.ConvertSystemError(err)\n\t}\n\treturn f, nil\n}", "label": 5}
{"code": "def charset=(charset)\n      content_type = parsed_content_type_header.mime_type\n      if false == charset\n        set_content_type content_type, nil\n      else\n        set_content_type content_type, charset || self.class.default_charset\n      end\n    end", "label": 4}
{"code": "func newSink(c influxdb_common.InfluxdbConfig) core.DataSink {\n\tclient, err := influxdb_common.NewClient(c)\n\tif err != nil {\n\t\tglog.Errorf(\"issues while creating an InfluxDB sink: %v, will retry on use\", err)\n\t}\n\treturn &influxdbSink{\n\t\tclient:  client, // can be nil\n\t\tc:       c,\n\t\tconChan: make(chan struct{}, c.Concurrency),\n\t}\n}", "label": 5}
{"code": "def update_discount(location_id, discount_id, body, opts = {})\n      data, _status_code, _headers = update_discount_with_http_info(location_id, discount_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "def ensure_dir(d):\n    \"\"\"\n    Check to make sure the supplied directory path does not exist, if so, create it. The\n    method catches OSError exceptions and returns a descriptive message instead of\n    re-raising the error.\n\n    :type d: str\n    :param d: It is the full path to a directory.\n\n    :return: Does not return anything, but creates a directory path if it doesn't exist\n             already.\n    \"\"\"\n    if not os.path.exists(d):\n        try:\n            os.makedirs(d)\n        except OSError as oe:\n            # should not happen with os.makedirs\n            # ENOENT: No such file or directory\n            if os.errno == errno.ENOENT:\n                msg = twdd(\"\"\"One or more directories in the path ({}) do not exist. If\n                           you are specifying a new directory for output, please ensure\n                           all other directories in the path currently exist.\"\"\")\n                return msg.format(d)\n            else:\n                msg = twdd(\"\"\"An error occurred trying to create the output directory\n                           ({}) with message: {}\"\"\")\n                return msg.format(d, oe.strerror)", "label": 1}
{"code": "func (d *DialParams) CheckAndSetDefaults() error {\n\tif d.From == nil {\n\t\treturn trace.BadParameter(\"parameter From required\")\n\t}\n\tif d.To == nil {\n\t\treturn trace.BadParameter(\"parameter To required\")\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function setUpdateMask($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\DocumentMask::class);\n        $this->update_mask = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def make_cursor(path, init_statements=(), _connectioncache={}):\r\n    \"\"\"Returns a cursor to the database, making new connection if not cached.\"\"\"\r\n    connection = _connectioncache.get(path)\r\n    if not connection:\r\n        is_new = not os.path.exists(path) or not os.path.getsize(path)\r\n        try: is_new and os.makedirs(os.path.dirname(path))\r\n        except OSError: pass\r\n        connection = sqlite3.connect(path, isolation_level=None,\r\n            check_same_thread=False, detect_types=sqlite3.PARSE_DECLTYPES)\r\n        for x in init_statements or (): connection.execute(x)\r\n        try: is_new and \":memory:\" not in path.lower() and os.chmod(path, 0707)\r\n        except OSError: pass\r\n        connection.row_factory = lambda cur, row: dict(sqlite3.Row(cur, row))\r\n        _connectioncache[path] = connection\r\n    return connection.cursor()", "label": 1}
{"code": "def get(self, filepath):\n        \"\"\"\n        Get file details for the specified file.\n        \"\"\"\n        try:\n            res = self.fs.get_file_details(filepath)\n            res = res.to_dict()\n            self.write(res)\n        except OSError:\n            raise tornado.web.HTTPError(404)", "label": 1}
{"code": "function commentWrap(string, type) {\n  let open, close;\n\n  if (type == 'html') {\n    open = '<!-- ';\n    close = ' -->';\n  } else {\n    open = '/* ';\n    close = ' */';\n  }\n\n  return open + string + close;\n}", "label": 3}
{"code": "func (f *Fpdf) GetDrawSpotColor() (name string, c, m, y, k byte) {\n\treturn f.returnSpotColor(f.color.draw)\n}", "label": 5}
{"code": "def stage_import_from_file(self, fd, filename='upload.gz'):\n        \"\"\"Stage an import from a file upload.\n\n        :param fd: File-like object to upload.\n        :param filename: (optional) Filename to use for import as string.\n        :return: :class:`imports.Import <imports.Import>` object\n        \"\"\"\n        schema = ImportSchema()\n        resp = self.service.post(self.base,\n                                 files={'file': (filename, fd)})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function getEaseType(type){\n  switch(type) {\n    case KeyframeInterpolationType.BEZIER:\n      return EASE_TYPE.BEZIER;\n    break;\n\n    case KeyframeInterpolationType.LINEAR:\n      return EASE_TYPE.LINEAR;\n    break;\n\n    case KeyframeInterpolationType.HOLD:\n      return EASE_TYPE.HOLD;\n    break;\n\n    default:\n      throw new Error('unknown ease type');\n    break;\n  }\n}", "label": 3}
{"code": "@POST\n    @Path(\"/{name}\" + ServerAPI.GET_CORPORATE_GROUPIDS)\n    public Response addCorporateGroupIdPrefix(@Auth final DbCredential credential, @PathParam(\"name\") final String organizationId, final String corporateGroupId){\n        LOG.info(\"Got an add a corporate groupId prefix request for organization \" + organizationId +\".\");\n        if(!credential.getRoles().contains(DbCredential.AvailableRoles.DATA_UPDATER)){\n            throw new WebApplicationException(Response.status(Response.Status.UNAUTHORIZED).build());\n        }\n\n        if(corporateGroupId == null || corporateGroupId.isEmpty()){\n            LOG.error(\"No corporate GroupId to add!\");\n            throw new WebApplicationException(Response.serverError().status(HttpStatus.BAD_REQUEST_400)\n                    .entity(\"CorporateGroupId to add should be in the query content.\").build());\n        }\n\n        getOrganizationHandler().addCorporateGroupId(organizationId, corporateGroupId);\n        return Response.ok().status(HttpStatus.CREATED_201).build();\n    }", "label": 0}
{"code": "void stop() {\n        try {\n            dm.stop(getBundleContext());\n        } catch (DirectoryMonitoringException e) {\n            LOG.error(\"Failed to stop \" + DirectoryMonitor.class.getName() + \" for the directory \" + monitoredDirectory, e);\n        }\n        declarationsFiles.clear();\n        declarationRegistrationManager.unregisterAll();\n    }", "label": 0}
{"code": "function (key) {\n            var ret = pick(this[key], this.element ? this.element.getAttribute(key) : null, 0);\n\n            if (/^[\\-0-9\\.]+$/.test(ret)) { // is numerical\n                ret = parseFloat(ret);\n            }\n            return ret;\n        }", "label": 3}
{"code": "func (process *TeleportProcess) notifyParent() {\n\tsignalPipe, err := process.importSignalPipe()\n\tif err != nil {\n\t\tif !trace.IsNotFound(err) {\n\t\t\tprocess.Warningf(\"Failed to import signal pipe\")\n\t\t}\n\t\tprocess.Debugf(\"No signal pipe to import, must be first Teleport process.\")\n\t\treturn\n\t}\n\tdefer signalPipe.Close()\n\n\tctx, cancel := context.WithTimeout(process.ExitContext(), signalPipeTimeout)\n\tdefer cancel()\n\n\teventC := make(chan Event, 1)\n\tprocess.WaitForEvent(ctx, TeleportReadyEvent, eventC)\n\tselect {\n\tcase <-eventC:\n\t\tprocess.Infof(\"New service has started successfully.\")\n\tcase <-ctx.Done():\n\t\tprocess.Errorf(\"Timeout waiting for a forked process to start: %v. Initiating self-shutdown.\", ctx.Err())\n\t\tif err := process.Close(); err != nil {\n\t\t\tprocess.Warningf(\"Failed to shutdown process: %v.\", err)\n\t\t}\n\t\treturn\n\t}\n\n\tif err := process.writeToSignalPipe(signalPipe, fmt.Sprintf(\"Process %v has started.\", os.Getpid())); err != nil {\n\t\tprocess.Warningf(\"Failed to write to signal pipe: %v\", err)\n\t\t// despite the failure, it's ok to proceed,\n\t\t// it could mean that the parent process has crashed and the pipe\n\t\t// is no longer valid.\n\t}\n}", "label": 5}
{"code": "func (pm *PortMapper) Map(container net.Addr, hostIP net.IP, hostPort int, useProxy bool) (host net.Addr, err error) {\n\treturn pm.MapRange(container, hostIP, hostPort, hostPort, useProxy)\n}", "label": 5}
{"code": "def run!\n      trace = @always_trace || false\n      require_program :version, :description\n      trap('INT') { abort program(:int_message) } if program(:int_message)\n      trap('INT') { program(:int_block).call } if program(:int_block)\n      global_option('-h', '--help', 'Display help documentation') do\n        args = @args - %w(-h --help)\n        command(:help).run(*args)\n        return\n      end\n      global_option('-v', '--version', 'Display version information') do\n        say version\n        return\n      end\n      global_option('-t', '--trace', 'Display backtrace when an error occurs') { trace = true } unless @never_trace || @always_trace\n      parse_global_options\n      remove_global_options options, @args\n      if trace\n        run_active_command\n      else\n        begin\n          run_active_command\n        rescue InvalidCommandError => e\n          abort \"#{e}. Use --help for more information\"\n        rescue \\\n          OptionParser::InvalidOption,\n          OptionParser::InvalidArgument,\n          OptionParser::MissingArgument => e\n          abort e.to_s\n        rescue => e\n          if @never_trace\n            abort \"error: #{e}.\"\n          else\n            abort \"error: #{e}. Use --trace to view backtrace\"\n          end\n        end\n      end\n    end", "label": 4}
{"code": "private function mergeCommitIntoRelease(array $release, array $commitRelease)\n    {\n        foreach ($commitRelease as $key => $commit) {\n            if (!isset($release[$key])) {\n                $release[$key] = [\n                    'level' => $commit['level'],\n                    'messages' => [$commit['message']]\n                ];\n            } else {\n                $release[$key]['messages'][] = $commit['message'];\n                $release[$key]['level'] = ($release[$key]['level'] >= $commit['level'])\n                    ? $release[$key]['level']\n                    : $commit['level'];\n            }\n        }\n\n        return $release;\n    }", "label": 2}
{"code": "func CreateOptionAlias(name string, alias string) EndpointOption {\n\treturn func(ep *endpoint) {\n\t\tif ep.aliases == nil {\n\t\t\tep.aliases = make(map[string]string)\n\t\t}\n\t\tep.aliases[alias] = name\n\t}\n}", "label": 5}
{"code": "def patch_os_module():\n\t\"\"\"\n\tjaraco.windows provides the os.symlink and os.readlink functions.\n\tMonkey-patch the os module to include them if not present.\n\t\"\"\"\n\tif not hasattr(os, 'symlink'):\n\t\tos.symlink = symlink\n\t\tos.path.islink = islink\n\tif not hasattr(os, 'readlink'):\n\t\tos.readlink = readlink", "label": 1}
{"code": "def run_somaticsniper_full(job, tumor_bam, normal_bam, univ_options, somaticsniper_options):\n    \"\"\"\n    Run SomaticSniper on the DNA bams.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict somaticsniper_options: Options specific to SomaticSniper\n    :return: fsID to the genome-level vcf\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'tumor.bam': tumor_bam['tumor_dna_fix_pg_sorted.bam'],\n        'tumor.bam.bai': tumor_bam['tumor_dna_fix_pg_sorted.bam.bai'],\n        'normal.bam': normal_bam['normal_dna_fix_pg_sorted.bam'],\n        'normal.bam.bai': normal_bam['normal_dna_fix_pg_sorted.bam.bai'],\n        'genome.fa.tar.gz': somaticsniper_options['genome_fasta'],\n        'genome.fa.fai.tar.gz': somaticsniper_options['genome_fai']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n\n    for key in ('genome.fa', 'genome.fa.fai'):\n        input_files[key] = untargz(input_files[key + '.tar.gz'], work_dir)\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    output_file = os.path.join(work_dir, 'somatic-sniper_full.vcf')\n    parameters = ['-f', input_files['genome.fa'],\n                  '-F', 'vcf',\n                  '-G',\n                  '-L',\n                  '-q', '1',\n                  '-Q', '15',\n                  input_files['tumor.bam'],\n                  input_files['normal.bam'],\n                  docker_path(output_file)]\n    docker_call(tool='somaticsniper', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=somaticsniper_options['version'])\n    outfile = job.fileStore.writeGlobalFile(output_file)\n    job.fileStore.logToMaster('Ran SomaticSniper on %s successfully' % univ_options['patient'])\n    return outfile", "label": 1}
{"code": "function authPlayers(channel, info) {\n\n        var code, player, token;\n        playerId = info.cookies.player;\n        token = info.cookies.token;\n\n\n        // Code not existing.\n        if (!code) {\n            console.log('not existing token: ', token);\n            return false;\n        }\n\n        if (code.checkedOut) {\n            console.log('token was already checked out: ', token);\n            return false;\n        }\n\n        // Code in use.\n        //  usage is for LOCAL check, IsUsed for MTURK\n        if (code.valid === false) {\n            if (code.disconnected) {\n                return true;\n            }\n            else {\n                console.log('token already in use: ', token);\n                return false;\n            }\n        }\n\n        // Client Authorized\n        return true;\n    }", "label": 3}
{"code": "def op_userflags(*flags, &block)\n      # Avoid an unnecessary set + commit operation.\n      return if flags.empty?\n\n      unrecognized_flags = flags.reject { |flag| ADS_USERFLAGS.keys.include?(flag) }\n      unless unrecognized_flags.empty?\n        raise ArgumentError, _(\"Unrecognized ADS UserFlags: %{unrecognized_flags}\") % { unrecognized_flags: unrecognized_flags.join(', ') }\n      end\n\n      self['UserFlags'] = flags.inject(self['UserFlags'], &block)\n    end", "label": 4}
{"code": "def extract_full_title\n      site_title = extract(:site) || ''\n      title      = extract_title || []\n      separator  = extract_separator\n      reverse    = extract(:reverse) == true\n\n      TextNormalizer.normalize_title(site_title, title, separator, reverse)\n    end", "label": 4}
{"code": "function loadAppConfigs() {\n        var appConfigs = {};\n        var appDir = path.join(this.injector.rootDir, '/app');\n\n        if (!fs.existsSync(appDir)) {\n            return appConfigs;\n        }\n\n        var me = this;\n        var appNames = fs.readdirSync(appDir);\n\n        _.each(appNames, function (appName) {\n            appConfigs[appName] = me.injector.loadModule('app/' + appName + '/' + appName + '.app');\n        });\n\n        return appConfigs;\n    }", "label": 3}
{"code": "def query_string_to_hash(query_string)\n      query = CGI.parse(URI.parse(query_string).query)\n      Hash[query.collect { |key, value| [key.to_sym, value.first] }]\n    end", "label": 4}
{"code": "public static base_response delete(nitro_service client, String servicename) throws Exception {\n\t\tgslbservice deleteresource = new gslbservice();\n\t\tdeleteresource.servicename = servicename;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "public function setVisuallySimilarImages($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\WebDetection\\WebImage::class);\n        $this->visually_similar_images = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def get(key)\n      return nil if !@items.key?(key)\n      return @results_cache[key] if @results_cache.key?(key)\n      @results_cache[key] = @items[key].call\n    end", "label": 4}
{"code": "func (t *Torrent) initiateConn(peer Peer) {\n\tif peer.Id == t.cl.peerID {\n\t\treturn\n\t}\n\tif t.cl.badPeerIPPort(peer.IP, peer.Port) {\n\t\treturn\n\t}\n\taddr := IpPort{peer.IP, uint16(peer.Port)}\n\tif t.addrActive(addr.String()) {\n\t\treturn\n\t}\n\tt.halfOpen[addr.String()] = peer\n\tgo t.cl.outgoingConnection(t, addr, peer.Source)\n}", "label": 5}
{"code": "def addinstance(self, testfile, features, classlabel=\"?\"):\n        \"\"\"Adds an instance to a specific file. Especially suitable for generating test files\"\"\"\n\n        features = self.validatefeatures(features)\n\n        if self.delimiter in classlabel:\n            raise ValueError(\"Class label contains delimiter: \" + self.delimiter)\n\n\n        f = io.open(testfile,'a', encoding=self.encoding)\n        f.write(self.delimiter.join(features) + self.delimiter + classlabel + \"\\n\")\n        f.close()", "label": 1}
{"code": "def entries\n      return [] unless exists?\n\n      @entries ||=\n        Utils.safe_glob(collection_dir, [\"**\", \"*\"], File::FNM_DOTMATCH).map do |entry|\n          entry[\"#{collection_dir}/\"] = \"\"\n          entry\n        end\n    end", "label": 4}
{"code": "def get_protected_page(url, user, pwd, filename):\n    \"\"\"\n    having problems with urllib on a specific site so trying requests\n    \"\"\"\n    import requests\n    r = requests.get(url, auth=(user, pwd))\n    print(r.status_code)\n    if r.status_code == 200:\n        print('success')\n        with open(filename, 'wb') as fd:\n            for chunk in r.iter_content(4096):\n                fd.write(chunk)\n        lg.record_result(\"Success - downloaded \" + url)\n    else:\n        lg.record_result('network_tools.get_protected_page:Failed to downloaded ' + url + ' (status code = ' + str(r.status_code) + ')')", "label": 1}
{"code": "def query_columns(conn, query, name=None):\n    \"\"\"Lightweight query to retrieve column list of select query.\n\n    Notes\n    -----\n    Strongly urged to specify a cursor name for performance.\n    \"\"\"\n\n    with conn.cursor(name) as cursor:\n        cursor.itersize = 1\n        cursor.execute(query)\n        cursor.fetchmany(0)\n        column_names = [column.name for column in cursor.description]\n\n    return column_names", "label": 1}
{"code": "public function setModelEvaluation($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\AutoMl\\V1beta1\\ModelEvaluation::class);\n        $this->model_evaluation = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def most_visited_pages_legend_chart():\n    \"\"\"Chart for most visited pages legend.\"\"\"\n    return {\n        'chart': {\n            'type': 'bar',\n            'height': 200,\n        },\n        'title': {\n            'text': _('Legend')\n        },\n        'xAxis': {\n            'categories': [\n                _('Project URL'),\n                _('Old project URL'),\n                _('Asset URL'),\n                _('Old asset URL'),\n                _('Common asset URL'),\n                _('False-negative project URL'),\n                _('Suspicious URL (potential attack)')\n            ],\n            'title': {\n                'text': None\n            }\n        },\n        'yAxis': {\n            'title': {\n                'text': None,\n                'align': 'high'\n            },\n            'labels': {\n                'overflow': 'justify'\n            }\n        },\n        'tooltip': {\n            'enabled': False\n        },\n        'legend': {\n            'enabled': False\n        },\n        'credits': {\n            'enabled': False\n        },\n        'series': [{\n            'name': _('Legend'),\n            'data': [\n                {'color': URL_TYPE_COLOR[PROJECT], 'y': 1},\n                {'color': URL_TYPE_COLOR[OLD_PROJECT], 'y': 1},\n                {'color': URL_TYPE_COLOR[ASSET], 'y': 1},\n                {'color': URL_TYPE_COLOR[OLD_ASSET], 'y': 1},\n                {'color': URL_TYPE_COLOR[COMMON_ASSET], 'y': 1},\n                {'color': URL_TYPE_COLOR[FALSE_NEGATIVE], 'y': 1},\n                {'color': URL_TYPE_COLOR[SUSPICIOUS], 'y': 1},\n            ]\n        }]\n    }", "label": 1}
{"code": "public static Map<String, ByteRunAutomaton> byteRunAutomatonMap(\n      Map<String, Automaton> automatonMap) {\n    HashMap<String, ByteRunAutomaton> byteRunAutomatonMap = new HashMap<>();\n    if (automatonMap != null) {\n      for (Entry<String, Automaton> entry : automatonMap.entrySet()) {\n        byteRunAutomatonMap.put(entry.getKey(),\n            new ByteRunAutomaton(entry.getValue()));\n      }\n    }\n    return byteRunAutomatonMap;\n  }", "label": 0}
{"code": "func CertPoolFromCertAuthorities(cas []CertAuthority) (*x509.CertPool, error) {\n\tcertPool := x509.NewCertPool()\n\tfor _, ca := range cas {\n\t\tkeyPairs := ca.GetTLSKeyPairs()\n\t\tif len(keyPairs) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, keyPair := range keyPairs {\n\t\t\tcert, err := tlsca.ParseCertificatePEM(keyPair.Cert)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, trace.Wrap(err)\n\t\t\t}\n\t\t\tcertPool.AddCert(cert)\n\t\t}\n\t\treturn certPool, nil\n\t}\n\treturn certPool, nil\n}", "label": 5}
{"code": "public void setIntegerAttribute(String name, Integer value) {\n\t\tensureValue();\n\t\tAttribute attribute = new IntegerAttribute(value);\n\t\tattribute.setEditable(isEditable(name));\n\t\tgetValue().getAllAttributes().put(name, attribute);\n\t}", "label": 0}
{"code": "function xmlFileGet(file, element, attributeName, options) {\n  options = _.sanitize(options, {encoding: 'utf-8', retryOnENOENT: true, default: null});\n\n  const doc = loadXmlFile(file, options);\n  const node = getXmlNode(doc, element);\n\n  let value;\n  if (_.isEmpty(attributeName)) {\n    value = _.map(node.childNodes, 'nodeValue');\n  } else {\n    value = node.getAttribute(attributeName);\n    // Always return an array\n    value = [value];\n  }\n  return _.isUndefined(value) ? options.default : value;\n}", "label": 3}
{"code": "private void checkPrimaryKey(ClassDescriptorDef classDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        if (classDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_GENERATE_TABLE_INFO, true) &&\r\n            classDef.getPrimaryKeys().isEmpty())\r\n        {\r\n            LogHelper.warn(true,\r\n                           getClass(),\r\n                           \"checkPrimaryKey\",\r\n                           \"The class \"+classDef.getName()+\" has no primary key\");\r\n        }\r\n    }", "label": 0}
{"code": "func fillDrawOp(styleStr string) (opStr string) {\n\tswitch strings.ToUpper(styleStr) {\n\tcase \"\", \"D\":\n\t\t// Stroke the path.\n\t\topStr = \"S\"\n\tcase \"F\":\n\t\t// fill the path, using the nonzero winding number rule\n\t\topStr = \"f\"\n\tcase \"F*\":\n\t\t// fill the path, using the even-odd rule\n\t\topStr = \"f*\"\n\tcase \"FD\", \"DF\":\n\t\t// fill and then stroke the path, using the nonzero winding number rule\n\t\topStr = \"B\"\n\tcase \"FD*\", \"DF*\":\n\t\t// fill and then stroke the path, using the even-odd rule\n\t\topStr = \"B*\"\n\tdefault:\n\t\topStr = styleStr\n\t}\n\treturn\n}", "label": 5}
{"code": "def http_purge_url(url):\n    \"\"\"\n    Do an HTTP PURGE of the given asset.\n    The URL is run through urlparse and must point to the varnish instance not the varnishadm\n    \"\"\"\n    url = urlparse(url)\n    connection = HTTPConnection(url.hostname, url.port or 80)\n    path = url.path or '/'\n    connection.request('PURGE', '%s?%s' % (path, url.query) if url.query else path, '',\n                       {'Host': '%s:%s' % (url.hostname, url.port) if url.port else url.hostname})\n    response = connection.getresponse()\n    if response.status != 200:\n        logging.error('Purge failed with status: %s' % response.status)\n    return response", "label": 1}
{"code": "def progress_stats(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Compute progress stats for a result.\n\n        :param id: Result ID as an int.\n        :return: :class:`results.Progress <results.Progress>` object\n        :rtype: results.Progress\n        \"\"\"\n        schema = ProgressSchema()\n        resp = self.service.get(self.base+str(id)+'/', params={'stats': 'progress'})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "protected function closeChannels()\n    {\n        foreach ($this->channels as $key => $channel) {\n            // channels[0] is this connection object, so don't close it yet\n            if ($key === 0) {\n                continue;\n            }\n            try {\n                $channel->close();\n            } catch (\\Exception $e) {\n                /* Ignore closing errors */\n            }\n        }\n    }", "label": 2}
{"code": "public function setUpgradeOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\AutoUpgradeOptions::class);\n        $this->upgrade_options = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static ipset get(nitro_service service, String name) throws Exception{\n\t\tipset obj = new ipset();\n\t\tobj.set_name(name);\n\t\tipset response = (ipset) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def fetch_value(path)\n      specifics = @data['data'].select { |a| path.include?(a['filter']) }\n\n      default = @data['default']\n\n      values = default.clone\n      specifics.each do |specific|\n        values = values.fastlane_deep_merge(specific)\n      end\n\n      change_paths_to_absolutes!(values)\n      validate_values(values)\n\n      values\n    end", "label": 4}
{"code": "public static function addColumns($tableName, array $columnDefinitions)\n    {\n        return [\n            'up' => function (Builder $schema) use ($tableName, $columnDefinitions) {\n                $schema->table($tableName, function (Blueprint $table) use ($schema, $columnDefinitions) {\n                    foreach ($columnDefinitions as $columnName => $options) {\n                        $type = array_shift($options);\n                        $table->addColumn($type, $columnName, $options);\n                    }\n                });\n            },\n            'down' => function (Builder $schema) use ($tableName, $columnDefinitions) {\n                $schema->table($tableName, function (Blueprint $table) use ($columnDefinitions) {\n                    $table->dropColumn(array_keys($columnDefinitions));\n                });\n            }\n        ];\n    }", "label": 2}
{"code": "def register(self, classes=[]):\n        \"\"\"\n        Registers new plugins.\n\n        The registration only creates a new entry for a plugin inside the _classes dictionary.\n        It does not activate or even initialise the plugin.\n\n        A plugin must be a class, which inherits directly or indirectly from GwBasePattern.\n\n        :param classes: List of plugin classes\n        :type classes: list\n        \"\"\"\n        if not isinstance(classes, list):\n            raise AttributeError(\"plugins must be a list, not %s.\" % type(classes))\n\n        plugin_registered = []\n\n        for plugin_class in classes:\n            plugin_name = plugin_class.__name__\n            self.register_class(plugin_class, plugin_name)\n            self._log.debug(\"Plugin %s registered\" % plugin_name)\n            plugin_registered.append(plugin_name)\n\n        self._log.info(\"Plugins registered: %s\" % \", \".join(plugin_registered))", "label": 1}
{"code": "def is_valid_python(tkn: str) -> bool:\n    \"\"\"Determine whether tkn is a valid python identifier\n\n    :param tkn:\n    :return:\n    \"\"\"\n    try:\n        root = ast.parse(tkn)\n    except SyntaxError:\n        return False\n    return len(root.body) == 1 and isinstance(root.body[0], ast.Expr) and isinstance(root.body[0].value, ast.Name)", "label": 1}
{"code": "public double nextDouble(double lo, double hi) {\n        if (lo < 0) {\n            if (nextInt(2) == 0)\n                return -nextDouble(0, -lo);\n            else\n                return nextDouble(0, hi);\n        } else {\n            return (lo + (hi - lo) * nextDouble());\n        }\n    }", "label": 0}
{"code": "def create_message(data)\n      message = Discordrb::Message.new(data, self)\n      return message if message.from_bot? && !@should_parse_self\n      return message if message.webhook? && !@attributes[:webhook_commands]\n\n      unless message.author\n        Discordrb::LOGGER.warn(\"Received a message (#{message.inspect}) with nil author! Ignoring, please report this if you can\")\n        return\n      end\n\n      event = CommandEvent.new(message, self)\n\n      chain = trigger?(message)\n      return message unless chain\n\n      # Don't allow spaces between the prefix and the command\n      if chain.start_with?(' ') && !@attributes[:spaces_allowed]\n        debug('Chain starts with a space')\n        return message\n      end\n\n      if chain.strip.empty?\n        debug('Chain is empty')\n        return message\n      end\n\n      execute_chain(chain, event)\n\n      # Return the message so it doesn't get parsed again during the rest of the dispatch handling\n      message\n    end", "label": 4}
{"code": "def _validate_isvalid_quantity(self, isvalid_quantity, field, value):\n        \"\"\"Checks for valid given value and appropriate units.\n\n        Args:\n            isvalid_quantity (`bool`): flag from schema indicating quantity to be checked.\n            field (`str`): property associated with quantity in question.\n            value (`list`): list whose first element is a string representing a value with units\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_quantity': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'list'}}\n        \"\"\"\n        quantity = Q_(value[0])\n        low_lim = 0.0 * units(property_units[field])\n\n        try:\n            if quantity <= low_lim:\n                self._error(\n                    field, 'value must be greater than 0.0 {}'.format(property_units[field]),\n                )\n        except pint.DimensionalityError:\n            self._error(field, 'incompatible units; should be consistent '\n                        'with ' + property_units[field]\n                        )", "label": 1}
{"code": "protected function generateUniqueIdentifier($length = 40)\n    {\n        try {\n            return bin2hex(random_bytes($length));\n            // @codeCoverageIgnoreStart\n        } catch (TypeError $e) {\n            throw OAuthServerException::serverError('An unexpected error has occurred', $e);\n        } catch (Error $e) {\n            throw OAuthServerException::serverError('An unexpected error has occurred', $e);\n        } catch (Exception $e) {\n            // If you get this message, the CSPRNG failed hard.\n            throw OAuthServerException::serverError('Could not generate a random string', $e);\n        }\n        // @codeCoverageIgnoreEnd\n    }", "label": 2}
{"code": "public function find($id, $columns = ['*'])\n    {\n        $this->applyCriteria();\n        $this->applyScope();\n        $model = $this->model->findOrFail($id, $columns);\n        $this->resetModel();\n\n        return $this->parserResult($model);\n    }", "label": 2}
{"code": "protected function getDefaultFilterFunction(array $filters): Closure\n    {\n        return function (Media $media) use ($filters) {\n            foreach ($filters as $property => $value) {\n                if (! Arr::has($media->custom_properties, $property)) {\n                    return false;\n                }\n\n                if (Arr::get($media->custom_properties, $property) !== $value) {\n                    return false;\n                }\n            }\n\n            return true;\n        };\n    }", "label": 2}
{"code": "public boolean isPartOf(GetVectorTileRequest request) {\n\t\tif (Math.abs(request.scale - scale) > EQUALS_DELTA) { return false; }\n\t\tif (code != null ? !code.equals(request.code) : request.code != null) { return false; }\n\t\tif (crs != null ? !crs.equals(request.crs) : request.crs != null) { return false; }\n\t\tif (filter != null ? !filter.equals(request.filter) : request.filter != null) { return false; }\n\t\tif (panOrigin != null ? !panOrigin.equals(request.panOrigin) : request.panOrigin != null) { return false; }\n\t\tif (renderer != null ? !renderer.equals(request.renderer) : request.renderer != null) { return false; }\n\t\tif (styleInfo != null ? !styleInfo.equals(request.styleInfo) : request.styleInfo != null) { return false; }\n\t\tif (paintGeometries && !request.paintGeometries) { return false; }\n\t\tif (paintLabels && !request.paintLabels) { return false; }\n\t\treturn true;\n\t}", "label": 0}
{"code": "def get_user(self):\n        \"\"\" \n        returns the username on this computer \n        \"\"\"\n        for name in ('LOGNAME', 'USER', 'LNAME', 'USERNAME'):\n            user = os.environ.get(name)\n            if user:\n                break     \n        for u in users:\n            if u['name'] == user:\n                return u['type'], u['name']", "label": 1}
{"code": "public function resolve(SourceLocation $location)\n    {\n        $origPath = str_replace('/', DIRECTORY_SEPARATOR, $location->path());\n        $basename = basename($origPath);\n        $prefixes = $this->searchPrefixes($origPath);\n\n        $includePaths = array_filter($this->includePaths, function ($path) {\n            return file_exists($path);\n        });\n\n        // Phase 1: search for an exact file match and try stripping off extra\n        // folders\n        foreach ($prefixes as $prefix) {\n            foreach ($includePaths as $path) {\n                $file = implode(DIRECTORY_SEPARATOR, [$path, $prefix, $basename]);\n                if (file_exists($file)) {\n                    return new SourceLocation($this->realRelativePath($file, $path), $location->line());\n                }\n            }\n        }\n\n        // Phase 2: recursively search folders for a matching file\n        foreach ($includePaths as $includePath) {\n            $iterator = new MatchingFileIterator(\n                $includePath,\n                $origPath\n            );\n            foreach ($iterator as $file => $info) {\n                return new SourceLocation($this->realRelativePath($file, $includePath), $location->line());\n            }\n        }\n\n        return null;\n    }", "label": 2}
{"code": "def move_apps_folder\n      if Dir.exist?(PackageCommandGenerator.apps_path)\n        FileUtils.mv(PackageCommandGenerator.apps_path, File.expand_path(Gym.config[:output_directory]), force: true)\n        apps_path = File.join(File.expand_path(Gym.config[:output_directory]), File.basename(PackageCommandGenerator.apps_path))\n\n        UI.success(\"Successfully exported Apps folder:\")\n        UI.message(apps_path)\n        apps_path\n      end\n    end", "label": 4}
{"code": "public function setLinkOutSuggestion($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_LinkOutSuggestion::class);\n        $this->writeOneof(10, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public ImageSource apply(ImageSource input) {\n        ImageSource originalImage = input;\n\n        int width = originalImage.getWidth();\n        int height = originalImage.getHeight();\n\n        boolean[][] matrix = new boolean[width][height]; // black n white boolean matrix; true = blck, false = white\n\n        // Copy\n        ImageSource filteredImage = new MatrixSource(input);\n\n        int[] histogram = OtsuBinarize.imageHistogram(originalImage);\n\n        int totalNumberOfpixels = height * width;\n\n        int threshold = OtsuBinarize.threshold(histogram, totalNumberOfpixels);\n\n        int black = 0;\n        int white = 255;\n\n        int gray;\n        int alpha;\n        int newColor;\n\n        for (int i = 0; i < width; i++) {\n            for (int j = 0; j < height; j++) {\n                gray = originalImage.getGray(i, j);\n\n                if (gray > threshold) {\n                    matrix[i][j] = false;\n                } else {\n                    matrix[i][j] = true;\n                }\n\n            }\n        }\n\n        int blackTreshold = letterThreshold(originalImage, matrix);\n\n        for (int i = 0; i < width; i++) {\n            for (int j = 0; j < height; j++) {\n                gray = originalImage.getGray(i, j);\n                alpha = originalImage.getA(i, j);\n\n                if (gray > blackTreshold) {\n                    newColor = white;\n                } else {\n                    newColor = black;\n                }\n\n                newColor = ColorHelper.getARGB(newColor, newColor, newColor, alpha);\n                filteredImage.setRGB(i, j, newColor);\n            }\n        }\n\n        return filteredImage;\n    }", "label": 0}
{"code": "public static route6[] get(nitro_service service, route6_args args) throws Exception{\n\t\troute6 obj = new route6();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\troute6[] response = (route6[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setClassificationType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\AutoMl\\V1beta1\\ClassificationType::class);\n        $this->classification_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (f *WaitFilter) Add(obj types.ManagedObjectReference, kind string, ps []string, set ...types.BaseSelectionSpec) *WaitFilter {\n\tspec := types.ObjectSpec{\n\t\tObj:       obj,\n\t\tSelectSet: set,\n\t}\n\n\tpset := types.PropertySpec{\n\t\tType:    kind,\n\t\tPathSet: ps,\n\t}\n\n\tif len(ps) == 0 {\n\t\tpset.All = types.NewBool(true)\n\t}\n\n\tf.Spec.ObjectSet = append(f.Spec.ObjectSet, spec)\n\n\tf.Spec.PropSet = append(f.Spec.PropSet, pset)\n\n\treturn f\n}", "label": 5}
{"code": "func wrapFunc(fn Func) FuncCtx {\n\tif fn == nil {\n\t\treturn nil // be sure not to wrap a bad function.\n\t}\n\treturn func(ctx context.Context, fl FieldLevel) bool {\n\t\treturn fn(fl)\n\t}\n}", "label": 5}
{"code": "func (a *AuthWithRoles) UpsertNodes(namespace string, servers []services.Server) error {\n\tif err := a.action(namespace, services.KindNode, services.VerbCreate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := a.action(namespace, services.KindNode, services.VerbUpdate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.UpsertNodes(namespace, servers)\n}", "label": 5}
{"code": "func (fs *FlagSet) PrintDefaults() {\n\twriter := tabwriter.NewWriter(fs.Out(), 20, 1, 3, ' ', 0)\n\thome := homedir.Get()\n\n\t// Don't substitute when HOME is /\n\tif runtime.GOOS != \"windows\" && home == \"/\" {\n\t\thome = \"\"\n\t}\n\n\t// Add a blank line between cmd description and list of options\n\tif fs.FlagCount() > 0 {\n\t\tfmt.Fprintln(writer, \"\")\n\t}\n\n\tfs.VisitAll(func(flag *Flag) {\n\t\tnames := []string{}\n\t\tfor _, name := range flag.Names {\n\t\t\tif name[0] != '#' {\n\t\t\t\tnames = append(names, name)\n\t\t\t}\n\t\t}\n\t\tif len(names) > 0 && len(flag.Usage) > 0 {\n\t\t\tval := flag.DefValue\n\n\t\t\tif home != \"\" && strings.HasPrefix(val, home) {\n\t\t\t\tval = homedir.GetShortcutString() + val[len(home):]\n\t\t\t}\n\n\t\t\tif isZeroValue(val) {\n\t\t\t\tformat := \"  -%s\"\n\t\t\t\tfmt.Fprintf(writer, format, strings.Join(names, \", -\"))\n\t\t\t} else {\n\t\t\t\tformat := \"  -%s=%s\"\n\t\t\t\tfmt.Fprintf(writer, format, strings.Join(names, \", -\"), val)\n\t\t\t}\n\t\t\tfor _, line := range strings.Split(flag.Usage, \"\\n\") {\n\t\t\t\tfmt.Fprintln(writer, \"\\t\", line)\n\t\t\t}\n\t\t}\n\t})\n\twriter.Flush()\n}", "label": 5}
{"code": "func (tl TypeLoader) LoadTableIndexes(args *ArgType, typeTpl *Type, ixMap map[string]*Index) error {\n\tvar err error\n\tvar priIxLoaded bool\n\n\t// load indexes\n\tindexList, err := tl.IndexList(args.DB, args.Schema, typeTpl.Table.TableName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// process indexes\n\tfor _, ix := range indexList {\n\t\t// save whether or not the primary key index was processed\n\t\tpriIxLoaded = priIxLoaded || ix.IsPrimary || (ix.Origin == \"pk\")\n\n\t\t// create index template\n\t\tixTpl := &Index{\n\t\t\tSchema: args.Schema,\n\t\t\tType:   typeTpl,\n\t\t\tFields: []*Field{},\n\t\t\tIndex:  ix,\n\t\t}\n\n\t\t// load index columns\n\t\terr = tl.LoadIndexColumns(args, ixTpl)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// build func name\n\t\targs.BuildIndexFuncName(ixTpl)\n\n\t\tixMap[typeTpl.Table.TableName+\"_\"+ix.IndexName] = ixTpl\n\t}\n\n\t// search for primary key if it was skipped being set in the type\n\tpk := typeTpl.PrimaryKey\n\tif pk == nil {\n\t\tfor _, f := range typeTpl.Fields {\n\t\t\tif f.Col.IsPrimaryKey {\n\t\t\t\tpk = f\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\t// if no primary key index loaded, but a primary key column was defined in\n\t// the type, then create the definition here. this is needed for sqlite, as\n\t// sqlite doesn't define primary keys in its index list\n\tif args.LoaderType != \"ora\" && !priIxLoaded && pk != nil {\n\t\tixName := typeTpl.Table.TableName + \"_\" + pk.Col.ColumnName + \"_pkey\"\n\t\tixMap[ixName] = &Index{\n\t\t\tFuncName: typeTpl.Name + \"By\" + pk.Name,\n\t\t\tSchema:   args.Schema,\n\t\t\tType:     typeTpl,\n\t\t\tFields:   []*Field{pk},\n\t\t\tIndex: &models.Index{\n\t\t\t\tIndexName: ixName,\n\t\t\t\tIsUnique:  true,\n\t\t\t\tIsPrimary: true,\n\t\t\t},\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func (cl *Client) outgoingConnection(t *Torrent, addr IpPort, ps peerSource) {\n\tcl.dialRateLimiter.Wait(context.Background())\n\tc, err := cl.establishOutgoingConn(t, addr)\n\tcl.lock()\n\tdefer cl.unlock()\n\t// Don't release lock between here and addConnection, unless it's for\n\t// failure.\n\tcl.noLongerHalfOpen(t, addr.String())\n\tif err != nil {\n\t\tif cl.config.Debug {\n\t\t\tcl.logger.Printf(\"error establishing outgoing connection: %s\", err)\n\t\t}\n\t\treturn\n\t}\n\tif c == nil {\n\t\treturn\n\t}\n\tdefer c.Close()\n\tc.Discovery = ps\n\tcl.runHandshookConn(c, t)\n}", "label": 5}
{"code": "static String createStatsType(Set<String> statsItems, String sortType,\n      MtasFunctionParserFunction functionParser) {\n    String statsType = STATS_BASIC;\n    for (String statsItem : statsItems) {\n      if (STATS_FULL_TYPES.contains(statsItem)) {\n        statsType = STATS_FULL;\n        break;\n      } else if (STATS_ADVANCED_TYPES.contains(statsItem)) {\n        statsType = STATS_ADVANCED;\n      } else if (statsType != STATS_ADVANCED\n          && STATS_BASIC_TYPES.contains(statsItem)) {\n        statsType = STATS_BASIC;\n      } else {\n        Matcher m = fpStatsFunctionItems.matcher(statsItem.trim());\n        if (m.find()) {\n          if (STATS_FUNCTIONS.contains(m.group(2).trim())) {\n            statsType = STATS_FULL;\n            break;\n          }\n        }\n      }\n    }\n    if (sortType != null && STATS_TYPES.contains(sortType)) {\n      if (STATS_FULL_TYPES.contains(sortType)) {\n        statsType = STATS_FULL;\n      } else if (STATS_ADVANCED_TYPES.contains(sortType)) {\n        statsType = (statsType == null || statsType != STATS_FULL)\n            ? STATS_ADVANCED : statsType;\n      }\n    }\n    return statsType;\n  }", "label": 0}
{"code": "func decodeSingleUnicodeEscape(in []byte) (rune, bool) {\n\t// We need at least 6 characters total\n\tif len(in) < 6 {\n\t\treturn utf8.RuneError, false\n\t}\n\n\t// Convert hex to decimal\n\th1, h2, h3, h4 := h2I(in[2]), h2I(in[3]), h2I(in[4]), h2I(in[5])\n\tif h1 == badHex || h2 == badHex || h3 == badHex || h4 == badHex {\n\t\treturn utf8.RuneError, false\n\t}\n\n\t// Compose the hex digits\n\treturn rune(h1<<12 + h2<<8 + h3<<4 + h4), true\n}", "label": 5}
{"code": "def _get_model_instance(model_cls, data):\n        \"\"\"Convert dict into object of class of passed model.\n\n        :param class model_cls:\n        :param object data:\n        :rtype DomainModel:\n        \"\"\"\n        if not isinstance(data, (model_cls, dict)):\n            raise TypeError('{0} is not valid type, instance of '\n                            '{1} or dict required'.format(data, model_cls))\n        return model_cls(**data) if isinstance(data, dict) else data", "label": 1}
{"code": "public static base_response renumber(nitro_service client) throws Exception {\n\t\tnspbr6 renumberresource = new nspbr6();\n\t\treturn renumberresource.perform_operation(client,\"renumber\");\n\t}", "label": 0}
{"code": "def line_formatter(array)\n      if array.any? {|item| item.is_a?(Array)}\n        cols = []\n        array.each do |item|\n          if item.is_a?(Array)\n            item.each_with_index { |val,idx| cols[idx] = [cols[idx]||0, (val || '').length].max }\n          end\n        end\n        cols.map { |col| \"%-#{col}s\" }.join(\"  \")\n      else\n        \"%s\"\n      end\n    end", "label": 4}
{"code": "public static base_response disable(nitro_service client, nsfeature resource) throws Exception {\n\t\tnsfeature disableresource = new nsfeature();\n\t\tdisableresource.feature = resource.feature;\n\t\treturn disableresource.perform_operation(client,\"disable\");\n\t}", "label": 0}
{"code": "func OptionPluginGetter(pg plugingetter.PluginGetter) Option {\n\treturn func(c *Config) {\n\t\tc.PluginGetter = pg\n\t}\n}", "label": 5}
{"code": "def _normalize_options(options)\n        _normalize_text(options)\n\n        if options[:html]\n          options[:html] = ERB::Util.html_escape(options[:html])\n        end\n\n        if options[:status]\n          options[:status] = Rack::Utils.status_code(options[:status])\n        end\n\n        super\n      end", "label": 4}
{"code": "private void exitForm(java.awt.event.WindowEvent evt) {//GEN-FIRST:event_exitForm\r\n        Main.getProperties().setProperty(Main.PROPERTY_MAINFRAME_HEIGHT, \"\" + this.getHeight());\r\n        Main.getProperties().setProperty(Main.PROPERTY_MAINFRAME_WIDTH, \"\" + this.getWidth());\r\n        Main.getProperties().setProperty(Main.PROPERTY_MAINFRAME_POSX, \"\" + this.getBounds().x);\r\n        Main.getProperties().setProperty(Main.PROPERTY_MAINFRAME_POSY, \"\" + this.getBounds().y);\r\n        Main.getProperties().storeProperties(\"\");\r\n        System.exit(0);\r\n    }", "label": 0}
{"code": "protected function runClosureMigration($migration, $direction = 'up')\n    {\n        if (is_array($migration) && array_key_exists($direction, $migration)) {\n            call_user_func($migration[$direction], $this->schemaBuilder);\n        } else {\n            throw new Exception('Migration file should contain an array with up/down.');\n        }\n    }", "label": 2}
{"code": "public void setValue(String fieldName, String value) {\r\n    int index = getFieldIndex(fieldName);\r\n    assert(index != -1);\r\n    values[index] = value;\r\n  }", "label": 0}
{"code": "function () {\n\n        // get a event from the front of queue\n        var tmdata = queue.dequeue();\n\n        // whether to keep processing (default is no)\n        busy = false;\n\n        // check if data exists\n        if (tmdata === undefined) {\n            return;\n        }\n\n        // handle the event if handler is available\n        if (handler === null) {\n            console.log(SR.Tags.ERR + 'handler undefined, cannot process event' + ERREND);\n            return;\n        }\n                        \n        switch (handler(tmdata)) {\n\n            // if the event is not handled, re-queue it\n            case false:\n                queue.enqueue(tmdata);\n                break;\n                \n            // return true, keep processing\n            case true:\n                break;\n            \n            /*\n            // NOTE: we do not pause continuing execution, because it's possible for a event\n            //         to consider it finished, re-activate the queue (which it think it has paused), \n            //       but then the execution runs to the end of handler, and returning a undefine to pause icQueue\n            //       this will thus cause a event to indefinitely pause without any on-going progress.\n            //\n            //         Currently if the event has returned, we assume it's been processed. \n            //         If not yet, then it's up to the handler to re-enqueue the event (by returning 'false')\n            //       note that it's possible that the previous event is still being processed \n            //       (for example, waiting for DB to return), while the next event starts processing\n            //       so the ordering may not be preserved.\n            //       The assumption we have is that events are relatively independent from each other\n            //       so such out-of-sequence processing may be \"okay,\" as long as handler will properly re-queue the event\n            //       in case it needs to be processed again\n            // \n            */\n\n            // did not return anything, pause execution\n            default:\n                //console.log(SR.Tags.WARN + 'pause processing event, callee: ' + arguments.callee.name);\n                return;\n                break;                \n        }            \n        \n        // keep processing\n        busy = true;\n        UTIL.asyncCall(processEvent);\n    }", "label": 3}
{"code": "def reload!(print = true)\n      puts \"Reloading...\" if print\n      Rails.application.reloader.reload!\n      true\n    end", "label": 4}
{"code": "func (v *ViewPort) SetSize(width, height int) {\n\tv.height = height\n\tv.width = width\n\tv.ValidateView()\n}", "label": 5}
{"code": "def getCharacterSet(self):\n        '''Get a character set with individual members or ranges.\n\n        Current index is on '[', the start of the character set.\n\n        '''\n        \n        chars = u''\n        c = None\n        cnt = 1\n        start = 0\n\n        while True:\n            escaped_slash = False\n            c = self.next()\n            # print \"pattern   : \", self.pattern\n            # print \"C         : \", c\n            # print \"Slash     : \", c == u'\\\\'\n            # print 'chars     : ', chars\n            # print 'index     : ', self.index\n            # print 'last      : ', self.last()\n            # print 'lookahead : ', self.lookahead()\n            if self.lookahead() == u'-' and not c == u'\\\\':\n                f = c\n                self.next()  # skip hyphen\n                c = self.next()  # get far range\n                if not c or (c in self.meta_chars):\n                    raise StringGenerator.SyntaxError(u\"unexpected end of class range\")\n                chars += self.getCharacterRange(f, c)\n            elif c == u'\\\\':\n                if self.lookahead() in self.meta_chars:\n                    c = self.next()\n                    chars += c\n                    continue\n                elif self.lookahead() in self.string_code:\n                    c = self.next()\n                    chars += self.string_code[c]\n            elif c and c not in self.meta_chars:\n                chars += c\n            if c == u']': \n                if self.lookahead() == u'{':\n                    [start, cnt] = self.getQuantifier()\n                else:\n                    start = -1\n                    cnt = 1\n                break\n            if c and c in self.meta_chars and not self.last() == u\"\\\\\":\n                raise StringGenerator.SyntaxError(u\"Un-escaped character in class definition: %s\" % c)\n            if not c:\n                break\n\n        return StringGenerator.CharacterSet(chars, start, cnt)", "label": 1}
{"code": "func (bee *Bee) Logln(args ...interface{}) {\n\ta := []interface{}{\"[\" + bee.Name() + \"]:\"}\n\tfor _, v := range args {\n\t\ta = append(a, v)\n\t}\n\n\tlog.Println(a...)\n\tLog(bee.Name(), fmt.Sprintln(args...), 0)\n}", "label": 5}
{"code": "public static authenticationradiuspolicy_authenticationvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationradiuspolicy_authenticationvserver_binding obj = new authenticationradiuspolicy_authenticationvserver_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationradiuspolicy_authenticationvserver_binding response[] = (authenticationradiuspolicy_authenticationvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setJobs($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Scheduler\\V1\\Job::class);\n        $this->jobs = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def deserialize_offenses(offenses)\n      source_buffer = Parser::Source::Buffer.new(@filename)\n      source_buffer.source = File.read(@filename, encoding: Encoding::UTF_8)\n      offenses.map! do |o|\n        location = Parser::Source::Range.new(source_buffer,\n                                             o['location']['begin_pos'],\n                                             o['location']['end_pos'])\n        Cop::Offense.new(o['severity'], location,\n                         o['message'],\n                         o['cop_name'], o['status'].to_sym)\n      end\n    end", "label": 4}
{"code": "def convert_types_slow(df):\n    '''This is a slow operation.'''\n    dtypes = get_types(df)\n    for k, v in dtypes.items():\n        t = df[df['key']==k]\n        t['value'] = t['value'].astype(v)\n    df = df.apply(convert_row, axis=1)\n    return df", "label": 1}
{"code": "function(code, data, rawBody) {\n        this.response = {\n            response: {\n                statusCode: code,\n                headers: {\n                    'content-type': 'application/json',\n                },\n            },\n            body: data || \"\",\n            err: null,\n            rawBody: rawBody || false,\n        };\n    }", "label": 3}
{"code": "def _pixelsize(self, p):\n        \"\"\"Calculate line width necessary to cover at least one pixel on all axes.\"\"\"\n        xpixelsize = 1./float(p.xdensity)\n        ypixelsize = 1./float(p.ydensity)\n        return max([xpixelsize,ypixelsize])", "label": 1}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getDataset($options + $this->identity);\n    }", "label": 2}
{"code": "function (error) {\n\n\t\tif (error) {\n\t\t\tvar err = new Error(\"set custom data for account [\" + account + \"] fail\");\n\t\t\terr.name = \"setUser Error\";\n\t\t\tLOG.error('set custom data for account [' + account + '] fail', 'user');\n\t\t\tUTIL.safeCall(onDone, err);\n\t\t}\n\t\telse {\n\t\t\tLOG.warn('set custom data for account [' + account + '] success', 'user');\n\t\t\tUTIL.safeCall(onDone, null);\n\t\t}\t\n\t}", "label": 3}
{"code": "public function from($from, $alias, $indexBy = null)\n    {\n        return $this->add('from', new Expr\\From($from, $alias, $indexBy), true);\n    }", "label": 2}
{"code": "public function getVersions($service)\n    {\n        if (!isset($this->manifest)) {\n            $this->buildVersionsList($service);\n        }\n\n        if (!isset($this->manifest[$service]['versions'])) {\n            return [];\n        }\n\n        return array_values(array_unique($this->manifest[$service]['versions']));\n    }", "label": 2}
{"code": "public static tmtrafficaction get(nitro_service service, String name) throws Exception{\n\t\ttmtrafficaction obj = new tmtrafficaction();\n\t\tobj.set_name(name);\n\t\ttmtrafficaction response = (tmtrafficaction) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setCollectionIds($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->collection_ids = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function appendAttempt(callable $middleware, $name = null)\n    {\n        $this->add(self::ATTEMPT, $name, $middleware);\n    }", "label": 2}
{"code": "def _determine_next_study_id(self):\n        \"\"\"Return the numeric part of the newest study_id\n\n        Checks out master branch as a side effect!\n        \"\"\"\n        if self._doc_counter_lock is None:\n            self._doc_counter_lock = Lock()\n        prefix = self._new_study_prefix\n        lp = len(prefix)\n        n = 0\n        # this function holds the lock for quite awhile,\n        #   but it only called on the first instance of\n        #   of creating a new study\n        with self._doc_counter_lock:\n            with self._index_lock:\n                for k in self.study_index.keys():\n                    if k.startswith(prefix):\n                        try:\n                            pn = int(k[lp:])\n                            if pn > n:\n                                n = pn\n                        except:\n                            pass\n            nsi_contents = self._read_master_branch_resource(self._id_minting_file, is_json=True)\n            if nsi_contents:\n                self._next_study_id = nsi_contents['next_study_id']\n                if self._next_study_id <= n:\n                    m = 'next_study_id in {} is set lower than the ID of an existing study!'\n                    m = m.format(self._id_minting_file)\n                    raise RuntimeError(m)\n            else:\n                # legacy support for repo with no next_study_id.json file\n                self._next_study_id = n\n                self._advance_new_study_id()", "label": 1}
{"code": "public function setChangeType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Firestore\\Admin\\V1\\FieldOperationMetadata_IndexConfigDelta_ChangeType::class);\n        $this->change_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def toxcmd_main(args=None):\n    \"\"\"Command util with subcommands for tox environments.\"\"\"\n    usage = \"USAGE: %(prog)s [OPTIONS] COMMAND args...\"\n    if args is None:\n        args = sys.argv[1:]\n\n    # -- STEP: Build command-line parser.\n    parser = argparse.ArgumentParser(description=inspect.getdoc(toxcmd_main),\n                                     formatter_class=FORMATTER_CLASS)\n    common_parser = parser.add_argument_group(\"Common options\")\n    common_parser.add_argument(\"--version\", action=\"version\", version=VERSION)\n    subparsers = parser.add_subparsers(help=\"commands\")\n    for command in discover_commands():\n        command_parser = subparsers.add_parser(command.name,\n                                               usage=command.usage,\n                                               description=command.description,\n                                               help=command.short_description,\n                                               formatter_class=FORMATTER_CLASS)\n        command_parser.set_defaults(func=command)\n        command.setup_parser(command_parser)\n        command.parser = command_parser\n\n    # -- STEP: Process command-line and run command.\n    options = parser.parse_args(args)\n    command_function = options.func\n    return command_function(options)", "label": 1}
{"code": "def _make_url(major, minor, micro, releaselevel, serial):\n    \"\"\"Make the URL people should start at for this version of coverage.py.\"\"\"\n    url = \"https://django-pagination-bootstrap.readthedocs.io\"\n    if releaselevel != 'final':\n        # For pre-releases, use a version-specific URL.\n        url += \"/en/\" + _make_version(major, minor, micro, releaselevel, serial)\n    return url", "label": 1}
{"code": "def init_with_attributes(attributes, new_record = false) # :nodoc:\n      @new_record = new_record\n      @attributes = attributes\n\n      init_internals\n\n      yield self if block_given?\n\n      _run_find_callbacks\n      _run_initialize_callbacks\n\n      self\n    end", "label": 4}
{"code": "func Run() {\n\t// to see what happens in the package, uncomment the following\n\t//restful.TraceLogger(log.New(os.Stdout, \"[restful] \", log.LstdFlags|log.Lshortfile))\n\n\t// Setup web-service\n\tsmolderConfig := smolder.APIConfig{\n\t\tBaseURL:    canonicalURL,\n\t\tPathPrefix: \"v1/\",\n\t}\n\tcontext := &context.APIContext{\n\t\tConfig: smolderConfig,\n\t}\n\n\twsContainer := smolder.NewSmolderContainer(smolderConfig, nil, nil)\n\twsContainer.Router(restful.CurlyRouter{})\n\tws := new(restful.WebService)\n\tws.Route(ws.GET(\"/images/{subpath:*}\").To(assetHandler))\n\tws.Route(ws.GET(\"/oauth2/{subpath:*}\").To(oauth2Handler))\n\tws.Route(ws.GET(\"/{subpath:*}\").To(assetHandler))\n\tws.Route(ws.GET(\"/\").To(assetHandler))\n\twsContainer.Add(ws)\n\n\tfunc(resources ...smolder.APIResource) {\n\t\tfor _, r := range resources {\n\t\t\tr.Register(wsContainer, smolderConfig, context)\n\t\t}\n\t}(\n\t\t&hives.HiveResource{},\n\t\t&bees.BeeResource{},\n\t\t&chains.ChainResource{},\n\t\t&actions.ActionResource{},\n\t\t&logs.LogResource{},\n\t)\n\n\tserver := &http.Server{Addr: bind, Handler: wsContainer}\n\tgo func() {\n\t\tlog.Fatal(server.ListenAndServe())\n\t}()\n}", "label": 5}
{"code": "def get(*args)\n      arguments(args, required: [:user, :repo, :ref])\n      validate_reference arguments.ref\n      params = arguments.params\n\n      get_request(\"/repos/#{arguments.user}/#{arguments.repo}/git/refs/#{arguments.ref}\", params)\n    end", "label": 4}
{"code": "public static base_response add(nitro_service client, tmtrafficaction resource) throws Exception {\n\t\ttmtrafficaction addresource = new tmtrafficaction();\n\t\taddresource.name = resource.name;\n\t\taddresource.apptimeout = resource.apptimeout;\n\t\taddresource.sso = resource.sso;\n\t\taddresource.formssoaction = resource.formssoaction;\n\t\taddresource.persistentcookie = resource.persistentcookie;\n\t\taddresource.initiatelogout = resource.initiatelogout;\n\t\taddresource.kcdaccount = resource.kcdaccount;\n\t\taddresource.samlssoprofile = resource.samlssoprofile;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public static int randomIntBetween(int min, int max) {\n    Random rand = new Random();\n    return rand.nextInt((max - min) + 1) + min;\n  }", "label": 0}
{"code": "protected <C> C convert(Object object, Class<C> targetClass) {\n        return this.mapper.convertValue(object, targetClass);\n    }", "label": 0}
{"code": "public function getInput()\n    {\n        if (!$this->input) {\n            if ($input = $this['input']) {\n                $this->input = $this->shapeFor($input);\n            } else {\n                $this->input = new StructureShape([], $this->shapeMap);\n            }\n        }\n\n        return $this->input;\n    }", "label": 2}
{"code": "def add_param(self, param_key, param_val):\n        \"\"\"\n        adds parameters as key value pairs\n        \"\"\"\n        self.params.append([param_key, param_val])\n        if param_key == '__success_test':\n            self.success = param_val", "label": 1}
{"code": "function _gpfNewApply (Constructor, parameters) {\n    if (parameters.length > _gpfGenericFactory.length) {\n        _gpfGenericFactory = _gpfGenerateGenericFactory(parameters.length);\n    }\n    return _gpfGenericFactory.apply(Constructor, parameters);\n}", "label": 3}
{"code": "private static function defer_command_addition( $name, $parent, $callable, $args = array() ) {\n\t\t$args['is_deferred']               = true;\n\t\tself::$deferred_additions[ $name ] = array(\n\t\t\t'parent'   => $parent,\n\t\t\t'callable' => $callable,\n\t\t\t'args'     => $args,\n\t\t);\n\t\tself::add_hook(\n\t\t\t\"after_add_command:$parent\",\n\t\t\tfunction () use ( $name ) {\n\t\t\t\t$deferred_additions = WP_CLI::get_deferred_additions();\n\n\t\t\t\tif ( ! array_key_exists( $name, $deferred_additions ) ) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\t$callable = $deferred_additions[ $name ]['callable'];\n\t\t\t\t$args     = $deferred_additions[ $name ]['args'];\n\t\t\t\tWP_CLI::remove_deferred_addition( $name );\n\n\t\t\t\tWP_CLI::add_command( $name, $callable, $args );\n\t\t\t}\n\t\t);\n\t}", "label": 2}
{"code": "function( thing, format ) {\n\n                // Make sure there\u2019s something to get.\n                thing = thing || 'value'\n\n                // If a picker state exists, return that.\n                if ( STATE[ thing ] != null ) {\n                    return STATE[ thing ]\n                }\n\n                // Return the submission value, if that.\n                if ( thing == 'valueSubmit' ) {\n                    if ( P._hidden ) {\n                        return P._hidden.value\n                    }\n                    thing = 'value'\n                }\n\n                // Return the value, if that.\n                if ( thing == 'value' ) {\n                    return ELEMENT.value\n                }\n\n                // Check if a component item exists, return that.\n                if ( thing in P.component.item ) {\n                    if ( typeof format == 'string' ) {\n                        var thingValue = P.component.get( thing )\n                        return thingValue ?\n                            PickerConstructor._.trigger(\n                                P.component.formats.toString,\n                                P.component,\n                                [ format, thingValue ]\n                            ) : ''\n                    }\n                    return P.component.get( thing )\n                }\n            }", "label": 3}
{"code": "public static nsxmlnamespace[] get(nitro_service service) throws Exception{\n\t\tnsxmlnamespace obj = new nsxmlnamespace();\n\t\tnsxmlnamespace[] response = (nsxmlnamespace[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (t *terminal) GetTerminalParams() rsession.TerminalParams {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\treturn t.params\n}", "label": 5}
{"code": "function getParamInfo(params, aliases) {\n    var paramInfo = { converted: [], list: [], ngrefs: [] };\n\n    _.each(params, function (param) {\n        var mappedVal = aliases[param] || param;\n        if (mappedVal === 'angular') {\n            paramInfo.ngrefs.push(param);\n        }\n        else {\n            paramInfo.list.push(param);\n            paramInfo.converted.push(mappedVal);\n        }\n    });\n\n    return paramInfo;\n}", "label": 3}
{"code": "public static vpnvserver_auditnslogpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_auditnslogpolicy_binding obj = new vpnvserver_auditnslogpolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_auditnslogpolicy_binding response[] = (vpnvserver_auditnslogpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function requireModel(filePath, cb) {\n        //check if file exist. if not return error\n        fs.exists(filePath, function (exists) {\n            if (!exists) {\n                soajs.log.error('Requested Model Not Found!');\n                return cb(601);\n            }\n\n            driver.model = require(filePath);\n            return cb();\n        });\n    }", "label": 3}
{"code": "function intersperse(sep, xs) {\r\n    return concat(xs.map(x => [sep, x])).slice(1);\r\n}", "label": 3}
{"code": "func (f *Finder) datacenterPath(ctx context.Context, ref types.ManagedObjectReference) (string, error) {\n\tmes, err := mo.Ancestors(ctx, f.client, f.client.ServiceContent.PropertyCollector, ref)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// Chop leaves under the Datacenter\n\tfor i := len(mes) - 1; i > 0; i-- {\n\t\tif mes[i].Self.Type == \"Datacenter\" {\n\t\t\tbreak\n\t\t}\n\t\tmes = mes[:i]\n\t}\n\n\tvar p string\n\n\tfor _, me := range mes {\n\t\t// Skip root entity in building inventory path.\n\t\tif me.Parent == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tp = p + \"/\" + me.Name\n\t}\n\n\treturn p, nil\n}", "label": 5}
{"code": "function state(list, sortMethod)\n{\n  var isNamedList = !Array.isArray(list)\n    , initState =\n    {\n      index    : 0,\n      keyedList: isNamedList || sortMethod ? Object.keys(list) : null,\n      jobs     : {},\n      results  : isNamedList ? {} : [],\n      size     : isNamedList ? Object.keys(list).length : list.length\n    }\n    ;\n\n  if (sortMethod)\n  {\n    // sort array keys based on it's values\n    // sort object's keys just on own merit\n    initState.keyedList.sort(isNamedList ? sortMethod : function(a, b)\n    {\n      return sortMethod(list[a], list[b]);\n    });\n  }\n\n  return initState;\n}", "label": 3}
{"code": "private static String getBundle(String friendlyName, String className, int truncate)\r\n\t{\r\n\t\ttry {\r\n\t\t\tcl.loadClass(className);\r\n\t\t\tint start = className.length();\r\n\t\t\tfor (int i = 0; i < truncate; ++i)\r\n\t\t\t\tstart = className.lastIndexOf('.', start - 1);\r\n\t\t\tfinal String bundle = className.substring(0, start);\r\n\t\t\treturn \"+ \" + friendlyName + align(friendlyName) + \"- \" + bundle;\r\n\t\t}\r\n\t\tcatch (final ClassNotFoundException e) {}\r\n\t\tcatch (final NoClassDefFoundError e) {}\r\n\t\treturn \"- \" + friendlyName + align(friendlyName) + \"- not available\";\r\n\t}", "label": 0}
{"code": "function readData(fp, options) {\n  // shallow clone options\n  var opts = utils.extend({}, options);\n  // get the loader for this file.\n  var ext = opts.lang || path.extname(fp);\n  if (ext && ext.charAt(0) !== '.') {\n    ext = '.' + ext;\n  }\n  if (!this.dataLoaders.hasOwnProperty(ext)) {\n    return this.dataLoader('read')(fp, opts);\n  }\n  return this.dataLoader(ext)(fp, opts);\n}", "label": 3}
{"code": "func InEpsilonf(t TestingT, expected interface{}, actual interface{}, epsilon float64, msg string, args ...interface{}) bool {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn InEpsilon(t, expected, actual, epsilon, append([]interface{}{msg}, args...)...)\n}", "label": 5}
{"code": "public boolean checkPrefixes(String uri, String[] patterns) {\n\t\tfor (String pattern : patterns) {\n\t\t\tif (pattern.length() > 0) {\n\t\t\t\tif (uri.startsWith(pattern)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "label": 0}
{"code": "public function getRules()\n    {\n        if (!$this->rules) {\n            return '[]';\n        }\n        $results = '[' . PHP_EOL;\n\n        foreach ($this->getSchemaParser()->toArray() as $column => $value) {\n            $results .= \"\\t\\t'{$column}'\\t=>'\\t{$value}',\" . PHP_EOL;\n        }\n\n        return $results . \"\\t\" . ']';\n    }", "label": 2}
{"code": "def signature(timestamp, nonce, verb, uri)\n      signature = [\n        timestamp,\n        nonce,\n        verb.to_s.upcase,\n        uri.request_uri,\n        uri.host,\n        uri.port,\n        '', nil\n      ].join(\"\\n\")\n\n      Base64.strict_encode64(OpenSSL::HMAC.digest(@algorithm, secret, signature))\n    end", "label": 4}
{"code": "def batch_requests(pipeline_params, limit = nil)\n      limit ||= Process.respond_to?(:getrlimit) ? Process.getrlimit(:NOFILE).first : 256\n      responses = []\n\n      pipeline_params.each_slice(limit) do |params|\n        responses.concat(requests(params))\n      end\n\n      responses\n    end", "label": 4}
{"code": "public function setClientEvent($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\ClientEvent::class);\n        $this->client_event = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "protected static final float[] getSpreadInRange(float member, int count, int max, int offset) {\n        // to find the spread, we first find the min that is a\n        // multiple of max/count away from the member\n\n        int interval = max / count;\n        float min = (member + offset) % interval;\n\n        if (min == 0 && member == max) {\n            min += interval;\n        }\n\n        float[] range = new float[count];\n        for (int i = 0; i < count; i++) {\n            range[i] = min + interval * i + offset;\n        }\n\n        return range;\n    }", "label": 0}
{"code": "def relation_options(inclusions, options, name)\n      if inclusions.is_a?(Hash)\n        inclusions[name]\n      else\n        { except: options[:except], only: options[:only] }\n      end\n    end", "label": 4}
{"code": "function IntersperseStream(seperator, options) {\n\tif(typeof seperator === 'object') {\n\t\toptions = seperator;\n\t\tseperator = null;\n\t}\n\toptions = !options ? {} : options;\n\n\tTransform.call(this, options);\n\n\tthis._intersperseBuffer = null;\n\tthis._intersperseSeperator = (seperator === null || seperator === undefined) ? '\\n' : seperator;\n}", "label": 3}
{"code": "function pruneIds(form) {\n  var testForm = _.clone(form);\n  testForm.pages = _.map(testForm.pages, function(page) {\n    page.fields = _.map(page.fields, function(field) {\n      return _.omit(field, '_id');\n    });\n\n    return _.omit(page, '_id');\n  });\n\n  return _.omit(testForm, '_id');\n}", "label": 3}
{"code": "func (c *Manager) ListCategories(ctx context.Context) ([]string, error) {\n\turl := internal.URL(c, internal.CategoryPath)\n\tvar res []string\n\treturn res, c.Do(ctx, url.Request(http.MethodGet), &res)\n}", "label": 5}
{"code": "func Expiry(clock clockwork.Clock, ttl time.Duration) time.Time {\n\tif ttl == 0 {\n\t\treturn time.Time{}\n\t}\n\treturn clock.Now().UTC().Add(ttl)\n}", "label": 5}
{"code": "function split(secret, opts) {\n  if (!secret || (secret && 0 === secret.length)) {\n    throw new TypeError('Secret cannot be empty.')\n  }\n\n  if ('string' === typeof secret) {\n    secret = Buffer.from(secret)\n  }\n\n  if (false === Buffer.isBuffer(secret)) {\n    throw new TypeError('Expecting secret to be a buffer.')\n  }\n\n  if (!opts || 'object' !== typeof opts) {\n    throw new TypeError('Expecting options to be an object.')\n  }\n\n  if ('number' !== typeof opts.shares) {\n    throw new TypeError('Expecting shares to be a number.')\n  }\n\n  if (!opts.shares || opts.shares < 0 || opts.shares > MAX_SHARES) {\n    throw new RangeError(`Shares must be 0 < shares <= ${MAX_SHARES}.`)\n  }\n\n  if ('number' !== typeof opts.threshold) {\n    throw new TypeError('Expecting threshold to be a number.')\n  }\n\n  if (!opts.threshold || opts.threshold < 0 || opts.threshold > opts.shares) {\n    throw new RangeError(`Threshold must be 0 < threshold <= ${opts.shares}.`)\n  }\n\n  if (!opts.random || 'function' !== typeof opts.random) {\n    opts.random = random\n  }\n\n  const hex = codec.hex(secret)\n  const bin = codec.bin(hex, 16)\n  // prepend 1 to get extra padding, we'll account for this later\n  const parts = codec.split('1' + bin, BIT_PADDING, 2)\n\n  for (let i = 0; i < parts.length; ++i) {\n    const p = points(parts[i], opts)\n    for (let j = 0; j < opts.shares; ++j) {\n\n      if (!scratch[j]) {\n        scratch[j] = p[j].x.toString(16)\n      }\n\n      const z = p[j].y.toString(2)\n      const y = scratch[j + MAX_SHARES] || ''\n\n      // y[j] = p[j][y] + y[j]\n      scratch[j + MAX_SHARES] = codec.pad(z) + y\n    }\n  }\n\n  for (let i = 0; i < opts.shares; ++i) {\n    const x = scratch[i]\n    const y = codec.hex(scratch[i + MAX_SHARES], BIN_ENCODING)\n    scratch[i] = codec.encode(x, y)\n    scratch[i] = Buffer.from('0' + scratch[i], 'hex')\n  }\n\n  const result = scratch.slice(0, opts.shares)\n  scratch.fill(0)\n  return result\n}", "label": 3}
{"code": "function handleGuardedRoute(activator, instance, instruction) {\n            var resultOrPromise = router.guardRoute(instance, instruction);\n            if (resultOrPromise) {\n                if (resultOrPromise.then) {\n                    resultOrPromise.then(function(result) {\n                        if (result) {\n                            if (system.isString(result)) {\n                                redirect(result);\n                            } else {\n                                activateRoute(activator, instance, instruction);\n                            }\n                        } else {\n                            cancelNavigation(instance, instruction);\n                        }\n                    });\n                } else {\n                    if (system.isString(resultOrPromise)) {\n                        redirect(resultOrPromise);\n                    } else {\n                        activateRoute(activator, instance, instruction);\n                    }\n                }\n            } else {\n                cancelNavigation(instance, instruction);\n            }\n        }", "label": 3}
{"code": "public function setValues($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\ValueValidation::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def fixity_check_file_version(file_id, version_uri)\n        latest_fixity_check = ChecksumAuditLog.logs_for(file_set.id, checked_uri: version_uri).first\n        return latest_fixity_check unless needs_fixity_check?(latest_fixity_check)\n\n        if async_jobs\n          FixityCheckJob.perform_later(version_uri.to_s, file_set_id: file_set.id, file_id: file_id)\n        else\n          FixityCheckJob.perform_now(version_uri.to_s, file_set_id: file_set.id, file_id: file_id)\n        end\n      end", "label": 4}
{"code": "function _buildEnumeratorOnObjectArray (object) {\n    var attributes = new _gpfA.Map(object).filter(_gpfA.EnumerableAttribute),\n        members = attributes.getMembers();\n    return _gpfArrayEnumerator(object[members[0]]);\n}", "label": 3}
{"code": "def reconnect\n      addresses = cluster.addresses.map(&:to_s)\n\n      @cluster.disconnect! rescue nil\n\n      @cluster = Cluster.new(addresses, monitoring, cluster_options)\n      true\n    end", "label": 4}
{"code": "def get_method_stack fqns, name, scope: :instance\n      get_methods(fqns, scope: scope, visibility: [:private, :protected, :public]).select{|p| p.name == name}\n    end", "label": 4}
{"code": "function aggregateModels (view, modelPath) {\n  const models = {}\n  view.cells.forEach(function (cell) {\n    const newPath = typeof cell.model === 'string' ? modelPath.concat(cell.model) : modelPath\n    pluckModels(cell, newPath, models, view.cellDefinitions)\n  })\n  return models\n}", "label": 3}
{"code": "def in_iframe(identifier, frame=nil, &block)\n      frame = frame.nil? ? [] : frame.dup\n      frame << {iframe: identifier}\n      block.call(frame)\n    end", "label": 4}
{"code": "def make_timestamp(el_time):\n    \"\"\" Generate an hour-minutes-seconds timestamp from an interval in seconds.\n\n    Assumes numeric input of a time interval in seconds.  Converts this\n    interval to a string of the format \"#h #m #s\", indicating the number of\n    hours, minutes, and seconds in the interval.  Intervals greater than 24h\n    are unproblematic.\n\n    Parameters\n    ----------\n    el_time\n        |int| or |float| --\n        Time interval in seconds to be converted to h/m/s format\n\n    Returns\n    -------\n    stamp\n        |str| -- String timestamp in #h #m #s format\n\n    \"\"\"\n\n    # Calc hours\n    hrs = el_time // 3600.0\n\n    # Calc minutes\n    mins = (el_time % 3600.0) // 60.0\n\n    # Calc seconds\n    secs = el_time % 60.0\n\n    # Construct timestamp string\n    stamp = \"{0}h {1}m {2}s\".format(int(hrs), int(mins), int(secs))\n\n    # Return\n    return stamp", "label": 1}
{"code": "func (ag *AuthGroup) Save(db XODB) error {\n\tif ag.Exists() {\n\t\treturn ag.Update(db)\n\t}\n\n\treturn ag.Insert(db)\n}", "label": 5}
{"code": "public static double JaccardDistance(double[] p, double[] q) {\n        double distance = 0;\n        int intersection = 0, union = 0;\n\n        for (int x = 0; x < p.length; x++) {\n            if ((p[x] != 0) || (q[x] != 0)) {\n                if (p[x] == q[x]) {\n                    intersection++;\n                }\n\n                union++;\n            }\n        }\n\n        if (union != 0)\n            distance = 1.0 - ((double) intersection / (double) union);\n        else\n            distance = 0;\n\n        return distance;\n    }", "label": 0}
{"code": "function (req, res) {\n        let sectionId = req.query.oveSectionId;\n        if (sectionId === undefined) {\n            log.debug('Returning parsed result of ' + Constants.SPACES_JSON_FILENAME);\n            Utils.sendMessage(res, HttpStatus.OK, JSON.stringify(server.spaces));\n        } else if (!server.state.get('sections[' + sectionId + ']')) {\n            log.debug('Unable to produce list of spaces for section id:', sectionId);\n            Utils.sendEmptySuccess(res);\n        } else {\n            log.debug('Returning parsed result of ' + Constants.SPACES_JSON_FILENAME + ' for section id:', sectionId);\n            Utils.sendMessage(res, HttpStatus.OK, JSON.stringify(server.state.get('sections[' + sectionId + '][spaces]')));\n        }\n    }", "label": 3}
{"code": "def with_transaction(options=nil)\n      # Non-configurable 120 second timeout for the entire operation\n      deadline = Time.now + 120\n      transaction_in_progress = false\n      loop do\n        commit_options = {}\n        if options\n          commit_options[:write_concern] = options[:write_concern]\n        end\n        start_transaction(options)\n        transaction_in_progress = true\n        begin\n          rv = yield self\n        rescue Exception => e\n          if within_states?(STARTING_TRANSACTION_STATE, TRANSACTION_IN_PROGRESS_STATE)\n            abort_transaction\n            transaction_in_progress = false\n          end\n\n          if Time.now >= deadline\n            transaction_in_progress = false\n            raise\n          end\n\n          if e.is_a?(Mongo::Error) && e.label?(Mongo::Error::TRANSIENT_TRANSACTION_ERROR_LABEL)\n            next\n          end\n\n          raise\n        else\n          if within_states?(TRANSACTION_ABORTED_STATE, NO_TRANSACTION_STATE, TRANSACTION_COMMITTED_STATE)\n            transaction_in_progress = false\n            return rv\n          end\n\n          begin\n            commit_transaction(commit_options)\n            transaction_in_progress = false\n            return rv\n          rescue Mongo::Error => e\n            if e.label?(Mongo::Error::UNKNOWN_TRANSACTION_COMMIT_RESULT_LABEL)\n              # WriteConcernFailed\n              if e.is_a?(Mongo::Error::OperationFailure) && e.code == 64 && e.wtimeout?\n                transaction_in_progress = false\n                raise\n              end\n              if Time.now >= deadline\n                transaction_in_progress = false\n                raise\n              end\n              wc_options = case v = commit_options[:write_concern]\n                when WriteConcern::Base\n                  v.options\n                when nil\n                  {}\n                else\n                  v\n                end\n              commit_options[:write_concern] = wc_options.merge(w: :majority)\n              retry\n            elsif e.label?(Mongo::Error::TRANSIENT_TRANSACTION_ERROR_LABEL)\n              if Time.now >= deadline\n                transaction_in_progress = false\n                raise\n              end\n              next\n            else\n              transaction_in_progress = false\n              raise\n            end\n          end\n        end\n      end\n    ensure\n      if transaction_in_progress\n        log_warn('with_transaction callback altered with_transaction loop, aborting transaction')\n        begin\n          abort_transaction\n        rescue Error::OperationFailure, Error::InvalidTransactionOperation\n        end\n      end\n    end", "label": 4}
{"code": "public function format(array $record)\n    {\n        $message = parent::format($record);\n        list($usec, $sec) = explode(\" \", microtime());\n        $usec = (int)(((float)$usec)*1000000000);\n        $sec = (int)$sec;\n        $payload = [\n            'message' => $message,\n            'timestamp'=> ['seconds' => $sec,\n                           'nanos' => $usec],\n            'thread' => '',\n            'severity' => $record['level_name'],\n        ];\n        if (isset($_SERVER['HTTP_X_CLOUD_TRACE_CONTEXT'])) {\n            $payload['traceId'] = explode(\n                \"/\",\n                $_SERVER['HTTP_X_CLOUD_TRACE_CONTEXT']\n            )[0];\n        }\n        return \"\\n\" . json_encode($payload);\n    }", "label": 2}
{"code": "function _gpfRequireGet(name) {\n        var me = this, promise;\n        if (me.cache[name]) {\n            return me.cache[name];\n        }\n        promise = _gpfRequireLoad.call(me, name);\n        me.cache[name] = promise;\n        return promise[\"catch\"](function (reason) {\n            _gpfRequireDocumentStack(reason, name);\n            return Promise.reject(reason);\n        });\n    }", "label": 3}
{"code": "public static base_response delete(nitro_service client, String ciphergroupname) throws Exception {\n\t\tsslcipher deleteresource = new sslcipher();\n\t\tdeleteresource.ciphergroupname = ciphergroupname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "function(){\n\t\t// If it is already loaded check to see if it's semver compatible\n\t\t// and if so use it. Otherwise reject.\n\t\tvar loadedPkg = this.context.paths[this.fileUrl];\n\t\tif(loadedPkg) {\n\t\t\tthis._fetchedPackage = loadedPkg;\n\t\t\tif(!this.isCompatibleVersion()) {\n\t\t\t\tthis.failed = true;\n\t\t\t}\n\t\t\treturn Promise.resolve();\n\t\t}\n\t}", "label": 3}
{"code": "function (logLevel) {\n            return chalk.bgHex(logLevel.label.bgColor).hex(logLevel.label.color).bold;\n        }", "label": 3}
{"code": "func (c *Client) DownloadFile(ctx context.Context, file string, u *url.URL, param *Download) error {\n\tvar err error\n\tif param == nil {\n\t\tparam = &DefaultDownload\n\t}\n\n\trc, contentLength, err := c.Download(ctx, u, param)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn c.WriteFile(ctx, file, rc, contentLength, param.Progress, param.Writer)\n}", "label": 5}
{"code": "def make_format(format_spec):\n        \"\"\"Build format string from a format specification.\n\n        :param format_spec:     Format specification (as FormatSpec object).\n        :return: Composed format (as string).\n        \"\"\"\n        fill = ''\n        align = ''\n        zero = ''\n        width = format_spec.width\n        if format_spec.align:\n            align = format_spec.align[0]\n            if format_spec.fill:\n                fill = format_spec.fill[0]\n        if format_spec.zero:\n            zero = '0'\n\n        precision_part = \"\"\n        if format_spec.precision:\n            precision_part = \".%s\" % format_spec.precision\n\n        # -- FORMAT-SPEC: [[fill]align][0][width][.precision][type]\n        return \"%s%s%s%s%s%s\" % (fill, align, zero, width,\n                                 precision_part, format_spec.type)", "label": 1}
{"code": "protected function associateRelationModels(string $relationName, EloquentCollection $relationModels): self\n    {\n        $relation = $this->getRelationInstance($relationName);\n\n        $relation->match(\n            $this->models->all(),\n            $relationModels,\n            $relationName\n        );\n\n        return $this;\n    }", "label": 2}
{"code": "func (t *FpdfTpl) childrenImages() map[string]*ImageInfoType {\n\tchildrenImgs := make(map[string]*ImageInfoType)\n\n\tfor x := 0; x < len(t.templates); x++ {\n\t\timgs := t.templates[x].Images()\n\t\tfor key, val := range imgs {\n\t\t\tname := sprintf(\"t%s-%s\", t.templates[x].ID(), key)\n\t\t\tchildrenImgs[name] = val\n\t\t}\n\t}\n\n\treturn childrenImgs\n}", "label": 5}
{"code": "public HashMap<String, IndexInput> getIndexInputList() {\n    HashMap<String, IndexInput> clonedIndexInputList = new HashMap<String, IndexInput>();\n    for (Entry<String, IndexInput> entry : indexInputList.entrySet()) {\n      clonedIndexInputList.put(entry.getKey(), entry.getValue().clone());\n    }\n    return clonedIndexInputList;\n  }", "label": 0}
{"code": "public function setEntityOverrideMode($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\SessionEntityType_EntityOverrideMode::class);\n        $this->entity_override_mode = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function (methodName, params, execOptions) {\n                var requestId = this._getRequestId(methodName, params);\n                var promise = this._getRequestPromise(requestId);\n\n                if (!promise) {\n                    this._addToBatch(methodName, params);\n                    promise = this._createPromise(requestId);\n                    this._run(execOptions);\n                }\n\n                return promise;\n            }", "label": 3}
{"code": "function isFunctionExpression(node) {\n    if (node && node.callee && node.callee.type === 'FunctionExpression') {\n        return true;\n    }\n    return false;\n}", "label": 3}
{"code": "public function handleFailure($idNum, array $items)\n    {\n        if (!$this->failureFile) {\n            $this->initFailureFile();\n        }\n\n        $fp = @fopen($this->failureFile, 'a');\n        @fwrite($fp, serialize([$idNum => $items]) . PHP_EOL);\n        @fclose($fp);\n    }", "label": 2}
{"code": "public void addProcedureArgument(ProcedureArgumentDef argDef)\r\n    {\r\n        argDef.setOwner(this);\r\n        _procedureArguments.put(argDef.getName(), argDef);\r\n    }", "label": 0}
{"code": "function QueryLogic(Type, options){\n    Type = Type || {};\n    var passedHydrator = options && options.toQuery;\n    var passedSerializer = options && options.toParams;\n    var schema;\n    if(Type[schemaSymbol]) {\n        schema = Type[schemaSymbol]();\n    } else {\n        schema = Type;\n    }\n\n    // check that the basics are here\n\n    var id = schema.identity && schema.identity[0];\n    if(!id) {\n        //console.warn(\"can-query given a type without an identity schema.  Using `id` as the identity id.\");\n        schema.identity = [\"id\"];\n    }\n\n    var converter = makeBasicQueryConvert(schema),\n        hydrate,\n        serialize;\n\n    if(passedHydrator) {\n        hydrate = function(query){\n            return converter.hydrate(passedHydrator(query));\n        };\n    } else {\n        hydrate = converter.hydrate;\n    }\n\n    if(passedSerializer) {\n        serialize = function(query){\n            return passedSerializer(converter.serializer.serialize(query));\n        };\n    } else {\n        serialize = converter.serializer.serialize;\n    }\n    this.hydrate = hydrate;\n    this.serialize = serialize;\n    this.schema = schema;\n\n}", "label": 3}
{"code": "func (l VirtualDeviceList) CreateFloppy() (*types.VirtualFloppy, error) {\n\tdevice := &types.VirtualFloppy{}\n\n\tc := l.PickController((*types.VirtualSIOController)(nil))\n\tif c == nil {\n\t\treturn nil, errors.New(\"no available SIO controller\")\n\t}\n\n\tl.AssignController(device, c)\n\n\tl.setDefaultFloppyBacking(device)\n\n\tdevice.Connectable = &types.VirtualDeviceConnectInfo{\n\t\tAllowGuestControl: true,\n\t\tConnected:         true,\n\t\tStartConnected:    true,\n\t}\n\n\treturn device, nil\n}", "label": 5}
{"code": "function evaluate(expr) {\n            if (expr.substring(0, 2) === '==') {\n                return 'write(JSON.stringify('+expr.substring(2).trim()+'));\\n';\n            } else if (expr.substring(0, 1) === '=') {\n                return 'write('+expr.substring(1).trim()+');\\n';\n            } else if (expr.substring(0, 3) === '...') {\n                expr = '//...\\n'+expr.substring(3).trim()+'\\n//.';\n            }\n            if (expr !== '') {\n                return expr+'\\n';\n            }\n            return '';\n        }", "label": 3}
{"code": "func (s Style) Decompose() (fg Color, bg Color, attr AttrMask) {\n\tif s&styleFgSet != 0 {\n\t\tfg = Color(s>>32) & 0x1ffffff\n\t} else {\n\t\tfg = ColorDefault\n\t}\n\tif s&styleBgSet != 0 {\n\t\tbg = Color(s & 0x1ffffff)\n\t} else {\n\t\tbg = ColorDefault\n\t}\n\tattr = AttrMask(s) & attrAll\n\n\treturn fg, bg, attr\n}", "label": 5}
{"code": "def get_card_prices(ctx, currency):\n    \"\"\"Prints out lowest card prices for an application.\n    Comma-separated list of application IDs is supported.\n\n    \"\"\"\n    appid = ctx.obj['appid']\n\n    detailed = True\n\n    appids = [appid]\n    if ',' in appid:\n        appids = [appid.strip() for appid in appid.split(',')]\n        detailed = False\n\n    for appid in appids:\n        print_card_prices(appid, currency, detailed=detailed)\n        click.echo('')", "label": 1}
{"code": "public static base_responses unset(nitro_service client, Long clid[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (clid != null && clid.length > 0) {\n\t\t\tclusterinstance unsetresources[] = new clusterinstance[clid.length];\n\t\t\tfor (int i=0;i<clid.length;i++){\n\t\t\t\tunsetresources[i] = new clusterinstance();\n\t\t\t\tunsetresources[i].clid = clid[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected function configure(ClientInterface $client, array $options)\n    {\n        if (isset($options['exceptions'])) {\n            $this->exceptions = (bool) $options['exceptions'];\n        } else {\n            $this->exceptions = $client->getOptions()->exceptions;\n        }\n\n        if (isset($options['cas'])) {\n            $this->modeCAS = (bool) $options['cas'];\n        }\n\n        if (isset($options['watch']) && $keys = $options['watch']) {\n            $this->watchKeys = $keys;\n        }\n\n        if (isset($options['retry'])) {\n            $this->attempts = (int) $options['retry'];\n        }\n    }", "label": 2}
{"code": "private void handleSerialApiGetInitDataResponse(\n\t\t\tSerialMessage incomingMessage) {\n\t\tlogger.debug(String.format(\"Got MessageSerialApiGetInitData response.\"));\n\t\tthis.isConnected = true;\n\t\tint nodeBytes = incomingMessage.getMessagePayloadByte(2);\n\t\t\n\t\tif (nodeBytes != NODE_BYTES) {\n\t\t\tlogger.error(\"Invalid number of node bytes = {}\", nodeBytes);\n\t\t\treturn;\n\t\t}\n\n\t\tint nodeId = 1;\n\t\t\n\t\t// loop bytes\n\t\tfor (int i = 3;i < 3 + nodeBytes;i++) {\n\t\t\tint incomingByte = incomingMessage.getMessagePayloadByte(i);\n\t\t\t// loop bits in byte\n\t\t\tfor (int j=0;j<8;j++) {\n\t\t\t\tint b1 = incomingByte & (int)Math.pow(2.0D, j);\n\t\t\t\tint b2 = (int)Math.pow(2.0D, j);\n\t\t\t\tif (b1 == b2) {\n\t\t\t\t\tlogger.info(String.format(\"Found node id = %d\", nodeId));\n\t\t\t\t\t// Place nodes in the local ZWave Controller \n\t\t\t\t\tthis.zwaveNodes.put(nodeId, new ZWaveNode(this.homeId, nodeId, this));\n\t\t\t\t\tthis.getNode(nodeId).advanceNodeStage();\n\t\t\t\t}\n\t\t\t\tnodeId++;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlogger.info(\"------------Number of Nodes Found Registered to ZWave Controller------------\");\n\t\tlogger.info(String.format(\"# Nodes = %d\", this.zwaveNodes.size()));\n\t\tlogger.info(\"----------------------------------------------------------------------------\");\n\t\t\n\t\t// Advance node stage for the first node.\n\t}", "label": 0}
{"code": "public static base_responses delete(nitro_service client, String acl6name[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (acl6name != null && acl6name.length > 0) {\n\t\t\tnsacl6 deleteresources[] = new nsacl6[acl6name.length];\n\t\t\tfor (int i=0;i<acl6name.length;i++){\n\t\t\t\tdeleteresources[i] = new nsacl6();\n\t\t\t\tdeleteresources[i].acl6name = acl6name[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function (newOptions, redraw) {\n            var series = this,\n              chart = this.chart,\n            // must use user options when changing type because this.options is merged\n            // in with type specific plotOptions\n              oldOptions = this.userOptions,\n              oldType = this.type,\n              proto = seriesTypes[oldType].prototype,\n              preserve = ['group', 'markerGroup', 'dataLabelsGroup'],\n              n;\n\n            // Make sure groups are not destroyed (#3094)\n            each(preserve, function (prop) {\n                preserve[prop] = series[prop];\n                delete series[prop];\n            });\n\n            // Do the merge, with some forced options\n            newOptions = merge(oldOptions, {\n                animation: false,\n                index: this.index,\n                pointStart: this.xData[0] // when updating after addPoint\n            }, { data: this.options.data }, newOptions);\n\n            // Destroy the series and reinsert methods from the type prototype\n            this.remove(false);\n            for (n in proto) { // Overwrite series-type specific methods (#2270)\n                if (proto.hasOwnProperty(n)) {\n                    this[n] = UNDEFINED;\n                }\n            }\n            extend(this, seriesTypes[newOptions.type || oldType].prototype);\n\n            // Re-register groups (#3094)\n            each(preserve, function (prop) {\n                series[prop] = preserve[prop];\n            });\n\n\n            this.init(chart, newOptions);\n            chart.linkSeries(); // Links are lost in this.remove (#3028)\n            if (pick(redraw, true)) {\n                chart.redraw(false);\n            }\n        }", "label": 3}
{"code": "public static function queueName($project, $location, $queue)\n    {\n        return self::getQueueNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'queue' => $queue,\n        ]);\n    }", "label": 2}
{"code": "def add_item(name, checked = false, position = 'bottom')\n      client.post(\"/checklists/#{id}/checkItems\", {name: name, checked: checked, pos: position})\n    end", "label": 4}
{"code": "def get_dict_from_response(response):\n    \"\"\"Prepare new mapping with 'Value's groupped by 'Type'.\"\"\"\n    result = {}\n    if getattr(response, '_resp') and response._resp.code > 400:\n        return result\n\n    for i in response.data:\n        # strip the schema from the key\n        k = i['Type'].replace(REMOTE_APP_RESOURCE_SCHEMA, '')\n        result.setdefault(k, list())\n        result[k].append(i['Value'])\n    return result", "label": 1}
{"code": "def archive(sha, file = nil, opts = {})\n      opts[:format] ||= 'zip'\n\n      if opts[:format] == 'tgz'\n        opts[:format] = 'tar'\n        opts[:add_gzip] = true\n      end\n\n      if !file\n        tempfile = Tempfile.new('archive')\n        file = tempfile.path\n        # delete it now, before we write to it, so that Ruby doesn't delete it\n        # when it finalizes the Tempfile.\n        tempfile.close!\n      end\n\n      arr_opts = []\n      arr_opts << \"--format=#{opts[:format]}\" if opts[:format]\n      arr_opts << \"--prefix=#{opts[:prefix]}\" if opts[:prefix]\n      arr_opts << \"--remote=#{opts[:remote]}\" if opts[:remote]\n      arr_opts << sha\n      arr_opts << '--' << opts[:path] if opts[:path]\n      command('archive', arr_opts, true, (opts[:add_gzip] ? '| gzip' : '') + \" > #{escape file}\")\n      return file\n    end", "label": 4}
{"code": "private DBHandling createDBHandling() throws BuildException\r\n    {\r\n        if ((_handling == null) || (_handling.length() == 0))\r\n        {\r\n            throw new BuildException(\"No handling specified\");\r\n        }\r\n        try\r\n        {\r\n            String className     = \"org.apache.ojb.broker.platforms.\"+\r\n            \t\t\t\t\t   Character.toTitleCase(_handling.charAt(0))+_handling.substring(1)+\r\n            \t\t\t\t\t   \"DBHandling\";\r\n            Class  handlingClass = ClassHelper.getClass(className);\r\n\r\n            return (DBHandling)handlingClass.newInstance();\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            throw new BuildException(\"Invalid handling '\"+_handling+\"' specified\");\r\n        }\r\n    }", "label": 0}
{"code": "public static base_response delete(nitro_service client, String domain) throws Exception {\n\t\tdnstxtrec deleteresource = new dnstxtrec();\n\t\tdeleteresource.domain = domain;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def remove_kv_store(self, key):\n        \"\"\"Remove a key-value store entry.\n\n        :param key: string\n        \"\"\"\n        data = {\n            'operation': 'DELETE',\n            'key': key\n        }\n        return self.post(self.make_url(\"/useragent-kv\"), data=to_json(data),\n                         headers=self.default_headers).text", "label": 1}
{"code": "function serviceCall(req, res, next) {\n        connector.configureSession(req.params.connection, req.body);\n        res.send(204); // success --> 204 no content\n    }", "label": 3}
{"code": "public Collection<V> put(K key, Collection<V> collection) {\r\n    return map.put(key, collection);\r\n  }", "label": 0}
{"code": "public static function datasetName($project, $location, $dataset)\n    {\n        return self::getDatasetNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'dataset' => $dataset,\n        ]);\n    }", "label": 2}
{"code": "def exec_rabbitmqctl(self, command, args=[], rabbitmqctl_opts=['-q']):\n        \"\"\"\n        Execute a ``rabbitmqctl`` command inside a running container.\n\n        :param command: the command to run\n        :param args: a list of args for the command\n        :param rabbitmqctl_opts:\n            a list of extra options to pass to ``rabbitmqctl``\n        :returns: a tuple of the command exit code and output\n        \"\"\"\n        cmd = ['rabbitmqctl'] + rabbitmqctl_opts + [command] + args\n        return self.inner().exec_run(cmd)", "label": 1}
{"code": "def check_nil_conjunction_on_child\n      if (@preconditions.length == 1 && @preconditions.first.conjunction.nil?)\n        bad_precondition = @preconditions.first\n        if (bad_precondition.restrictions.empty? && bad_precondition.subset.nil? && bad_precondition.expression.nil?)\n          @preconditions = @preconditions.first.preconditions\n          #puts \"\\t FIXED PRECONDITION WITHOUT CONJUNCTION\"\n        else\n          puts \"\\t PRECONDITION WITHOUT CONJUNCTION: Cannot be fixed\"\n        end\n      end\n    end", "label": 4}
{"code": "def cancel_orders(self, order_ids: List[str]) -> List[str]:\n        \"\"\"Cancel multiple orders by a list of IDs.\"\"\"\n        orders_to_cancel = order_ids\n        self.log.debug(f'Canceling orders on {self.name}: ids={orders_to_cancel}')\n        cancelled_orders = []\n\n        if self.dry_run:  # Don't cancel if dry run\n            self.log.warning(f'DRY RUN: Orders cancelled on {self.name}: {orders_to_cancel}')\n            return orders_to_cancel\n\n        try:  # Iterate and cancel orders\n            if self.has_batch_cancel:\n                self._cancel_orders(orders_to_cancel)\n                cancelled_orders.append(orders_to_cancel)\n                orders_to_cancel.clear()\n            else:\n                for i, order_id in enumerate(orders_to_cancel):\n                    self._cancel_order(order_id)\n                    cancelled_orders.append(order_id)\n                    orders_to_cancel.pop(i)\n        except Exception as e:\n            msg = f'Failed to cancel {len(orders_to_cancel)} orders on {self.name}: ids={orders_to_cancel}'\n            raise self.exception(OrderNotFound, msg, e) from e\n\n        self.log.info(f'Orders cancelled on {self.name}: ids={cancelled_orders}')\n        return cancelled_orders", "label": 1}
{"code": "def get_list_of_paths(self):\r\n        \"\"\"\r\n        return a list of unique paths in the file list\r\n        \"\"\"\r\n        all_paths = []\r\n        for p in self.fl_metadata:\r\n            try:\r\n                all_paths.append(p['path'])\r\n            except:\r\n                try:\r\n                    print('cls_filelist - no key path, ignoring folder ' + str(p))\r\n                except:\r\n                    print('cls_filelist - no key path, ignoring odd character folder')\r\n\r\n        return list(set(all_paths))", "label": 1}
{"code": "public HashSet<String> getDataById(String id) throws IOException {\n    if (idToVersion.containsKey(id)) {\n      return get(id);\n    } else {\n      return null;\n    }\n  }", "label": 0}
{"code": "function _gpfHttpParseHeaders (headers) {\n    var result = {};\n    _gpfArrayForEach(_gpfRegExpForEach(_gpfHttpHeadersParserRE, headers), function (match) {\n        result[match[_GPF_HTTP_HELPERS_HEADER_NAME]] = match[_GPF_HTTP_HELPERS_HEADER_VALUE];\n    });\n    return result;\n}", "label": 3}
{"code": "def ping(host, port=80, url=None, https=False, timeout=1, max_size=65535, sequence=0):\n    \"\"\"\n    Ping a host\n\n    Parameters\n    ----------\n    host: str\n        The host or ip address to ping\n\n    port: int, optional\n        The port to ping, default=80\n\n    url: str, optional\n        URL to ping, will do a host/port ping if not provided\n\n    https: bool, optional\n        Connect via ssl, default=False\n\n    timeout: int, optional\n        Number of seconds to wait for a response before timing out, default=1 second\n\n    max_size: int, optional\n        The max size of response that can be retrieved.  This should be a power of 2\n        default=65535.\n\n    sequence: int, optional\n        Sequence number for the ping request\n\n    Returns\n    -------\n    PingResponse:\n        The ping response object\n    \"\"\"\n    try:\n        result = scan(host=host, port=port, url=url, https=https, timeout=timeout, max_size=max_size)\n    except ScanFailed as failure:\n        result = failure.result\n        result['error'] = True\n        result['error_message'] = str(failure)\n    result_obj = PingResponse(\n        host=host, port=port, ip=result.get('ip', None), sequence=sequence,\n        durations=result.get('durations', None),\n        code=result.get('code', None),\n        state=result.get('state', 'unknown'),\n        length=result.get('length', 0),\n        response=result.get('response', None),\n        error=result.get('error', False),\n        error_message=result.get('error_message', None),\n        responding=True if result.get('state', 'unknown') in ['open'] else False,\n        start=datetime.datetime.now(),\n        end=datetime.datetime.now() + result['durations'].get('all', datetime.timedelta(0)) if result.get('durations', None) else None\n    )\n    return result_obj", "label": 1}
{"code": "public static base_response delete(nitro_service client, String fipskeyname) throws Exception {\n\t\tsslfipskey deleteresource = new sslfipskey();\n\t\tdeleteresource.fipskeyname = fipskeyname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "public boolean hasForeignkey(String name)\r\n    {\r\n        String        realName = (name == null ? \"\" : name);\r\n        ForeignkeyDef def      = null;\r\n\r\n        for (Iterator it = getForeignkeys(); it.hasNext();)\r\n        {\r\n            def = (ForeignkeyDef)it.next();\r\n            if (realName.equals(def.getName()))\r\n            {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }", "label": 0}
{"code": "func (m VirtualDiskManager) CopyVirtualDisk(\n\tctx context.Context,\n\tsourceName string, sourceDatacenter *Datacenter,\n\tdestName string, destDatacenter *Datacenter,\n\tdestSpec *types.VirtualDiskSpec, force bool) (*Task, error) {\n\n\treq := types.CopyVirtualDisk_Task{\n\t\tThis:       m.Reference(),\n\t\tSourceName: sourceName,\n\t\tDestName:   destName,\n\t\tDestSpec:   destSpec,\n\t\tForce:      types.NewBool(force),\n\t}\n\n\tif sourceDatacenter != nil {\n\t\tref := sourceDatacenter.Reference()\n\t\treq.SourceDatacenter = &ref\n\t}\n\n\tif destDatacenter != nil {\n\t\tref := destDatacenter.Reference()\n\t\treq.DestDatacenter = &ref\n\t}\n\n\tres, err := methods.CopyVirtualDisk_Task(ctx, m.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewTask(m.c, res.Returnval), nil\n}", "label": 5}
{"code": "function KeysAnd(values) {\n\tvar vals = this.values = {};\n\tcanReflect.eachKey(values, function(value, key) {\n\t\tif (canReflect.isPlainObject(value) && !set.isSpecial(value)) {\n\t\t\tvals[key] = new KeysAnd(value);\n\t\t} else {\n\t\t\tvals[key] = value;\n\t\t}\n\t});\n}", "label": 3}
{"code": "public static gslbsite_gslbservice_binding[] get(nitro_service service, String sitename) throws Exception{\n\t\tgslbsite_gslbservice_binding obj = new gslbsite_gslbservice_binding();\n\t\tobj.set_sitename(sitename);\n\t\tgslbsite_gslbservice_binding response[] = (gslbsite_gslbservice_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def complement\n      if @id.nil?\n        @id = @file.gsub(%r{[\\\\/\\. ]}, '-')\n      end\n      if @id =~ /\\A[^a-z]/i\n        @id = \"rv-#{@id}\"\n      end\n\n      if !@file.nil? && @media.nil?\n        @media = @file.sub(/.+\\./, '').downcase\n      end\n\n      case @media\n      when 'xhtml', 'xml', 'html'\n        @media = 'application/xhtml+xml'\n      when 'css'\n        @media = 'text/css'\n      when 'jpg', 'jpeg', 'image/jpg'\n        @media = 'image/jpeg'\n      when 'png'\n        @media = 'image/png'\n      when 'gif'\n        @media = 'image/gif'\n      when 'svg', 'image/svg'\n        @media = 'image/svg+xml'\n      when 'ttf', 'otf'\n        @media = 'application/vnd.ms-opentype'\n      when 'woff'\n        @media = 'application/font-woff'\n      end\n\n      if @id.nil? || @file.nil? || @media.nil?\n        raise \"Type error: #{id}, #{file}, #{media}, #{title}, #{notoc}\"\n      end\n    end", "label": 4}
{"code": "function getContextualSignature(node) {\n            ts.Debug.assert(node.kind !== 147 /* MethodDeclaration */ || ts.isObjectLiteralMethod(node));\n            var type = getContextualTypeForFunctionLikeDeclaration(node);\n            if (!type) {\n                return undefined;\n            }\n            if (!(type.flags & 524288 /* Union */)) {\n                return getNonGenericSignature(type);\n            }\n            var signatureList;\n            var types = type.types;\n            for (var _i = 0, types_12 = types; _i < types_12.length; _i++) {\n                var current = types_12[_i];\n                var signature = getNonGenericSignature(current);\n                if (signature) {\n                    if (!signatureList) {\n                        // This signature will contribute to contextual union signature\n                        signatureList = [signature];\n                    }\n                    else if (!compareSignaturesIdentical(signatureList[0], signature, /*partialMatch*/ false, /*ignoreThisTypes*/ true, /*ignoreReturnTypes*/ true, compareTypesIdentical)) {\n                        // Signatures aren't identical, do not use\n                        return undefined;\n                    }\n                    else {\n                        // Use this signature for contextual union signature\n                        signatureList.push(signature);\n                    }\n                }\n            }\n            // Result is union of signatures collected (return type is union of return types of this signature set)\n            var result;\n            if (signatureList) {\n                result = cloneSignature(signatureList[0]);\n                // Clear resolved return type we possibly got from cloneSignature\n                result.resolvedReturnType = undefined;\n                result.unionSignatures = signatureList;\n            }\n            return result;\n        }", "label": 3}
{"code": "function mappingContent(mapping) {\n  const { from, to, type } = mapping\n  let result = {\n    from: reduceBundle(from || {}),\n    to: reduceBundle(to || {}),\n    type: [\n      type && type[0] || \"http://www.w3.org/2004/02/skos/core#mappingRelation\"\n    ]\n  }\n  for (let side of [\"from\", \"to\"]) {\n    if ((result[side][memberField(result[side])] || []).length == 0) {\n      let scheme = mapping[side + \"Scheme\"]\n      if (scheme && scheme.uri) {\n        // Create new object to remove all unnecessary properties.\n        result[side + \"Scheme\"] = { uri: scheme.uri }\n      }\n    }\n  }\n  return result\n}", "label": 3}
{"code": "def list_all_python_programs(self):\n        \"\"\"\n        collects a filelist of all .py programs\n        \"\"\"\n        self.tot_lines = 0\n        self.tot_bytes = 0\n        self.tot_files = 0\n        self.tot_loc = 0\n        self.lstPrograms = []\n        fl = mod_fl.FileList([self.fldr], ['*.py'], [\"__pycache__\", \"/venv/\", \"/venv2/\", \".git\"])\n        for fip in fl.get_list():\n            if '__init__.py' not in fip:\n                self.add(fip, 'TODO - add comment')\n                f = mod_file.TextFile(fip)\n                self.tot_lines += f.count_lines_in_file()\n                self.tot_loc += f.count_lines_of_code()\n                self.tot_bytes += f.size\n                self.tot_files += 1\n \n        print('All Python Program Statistics')\n        print('Files = ', self.tot_files, ' Bytes = ', self.tot_bytes, ' Lines = ', self.tot_lines, ' Lines of Code = ', self.tot_loc)", "label": 1}
{"code": "func (p *printer) cachedWriteError() error {\n\t_, err := p.Write(nil)\n\treturn err\n}", "label": 5}
{"code": "function(methodName, alternatives) {\n\treturn function() {\n\t\tvar callback = Array.prototype.slice.call(arguments).pop();\n\t\tif (!Array.isArray(alternatives)) {\n\t\t\talternatives = [alternatives];\n\t\t}\n\n\t\tvar alternativeString;\n\t\tif (alternatives.length === 1) {\n\t\t\talternativeString = alternatives[0];\n\t\t} else {\n\t\t\tvar lastItem = alternatives.pop();\n\t\t\talternativeString = alternatives.join('\", \"') + '\" or \"' +\n\t\t\t\tlastItem;\n\t\t}\n\t\tcallback(MongoError.create({\n\t\t\tmessage: 'Method \"' + methodName + '\" is deprecated, use \"' +\n\t\t\t\talternativeString + '\" instead',\n\t\t\tdriver: true\n\t\t}));\n\t};\n}", "label": 3}
{"code": "function addGroup(group, options) {\n  options = _.opts(options, {gid: null});\n  if (!runningAsRoot()) return;\n  if (!group) throw new Error('You must provide a group');\n  if (groupExists(group)) {\n    return;\n  }\n\n  if (isPlatform('linux')) {\n    _addGroupLinux(group, options);\n  } else if (isPlatform('osx')) {\n    _addGroupOsx(group, options);\n  } else if (isPlatform('windows')) {\n    throw new Error(`Don't know how to add group ${group} on Windows`);\n  } else {\n    throw new Error(`Don't know how to add group ${group} in current platform`);\n  }\n}", "label": 3}
{"code": "function chainAndCall(chainer) {\n    return function(/*step1, step2, ...*/) {\n        var steps = slice.call(arguments);\n\t    var callback = steps.pop();\n\t    chainer.apply(null, steps)(callback);\n    };\n}", "label": 3}
{"code": "function streamer(error, output, callback)\n{\n  if (error && !this.error)\n  {\n    this.error = error;\n    this.pause();\n    this.emit('error', error);\n    // send back value only, as expected\n    callback(error, output && output.value);\n    return;\n  }\n\n  // stream stuff\n  this.push(output);\n\n  // back to original track\n  // send back value only, as expected\n  callback(error, output && output.value);\n}", "label": 3}
{"code": "def singleton(the_class):\n    \"\"\"\n    Decorator for a class to make a singleton out of it.\n\n    @type the_class: class\n    @param the_class: the class that should work as a singleton\n    @rtype: decorator\n    @return: decorator\n    \"\"\"\n    class_instances = {}\n\n    def get_instance(*args, **kwargs):\n        \"\"\"\n        Creating or just return the one and only class instance.\n\n        The singleton depends on the parameters used in __init__\n        @type args: list\n        @param args: positional arguments of the constructor.\n        @type kwargs: dict\n        @param kwargs: named parameters of the constructor.\n        @rtype: decorated class type\n        @return: singleton instance of decorated class.\n        \"\"\"\n        key = (the_class, args, str(kwargs))\n        if key not in class_instances:\n            class_instances[key] = the_class(*args, **kwargs)\n        return class_instances[key]\n\n    return get_instance", "label": 1}
{"code": "protected function getSorter(array $criteria)\n    {\n        $sorter = function ($a, $b) use ($criteria) {\n            foreach ($criteria as $orderable) {\n                $column    = $this->getColumnName($orderable['column']);\n                $direction = $orderable['direction'];\n                if ($direction === 'desc') {\n                    $first  = $b;\n                    $second = $a;\n                } else {\n                    $first  = $a;\n                    $second = $b;\n                }\n                if ($this->config->isCaseInsensitive()) {\n                    $cmp = strnatcasecmp($first[$column], $second[$column]);\n                } else {\n                    $cmp = strnatcmp($first[$column], $second[$column]);\n                }\n                if ($cmp != 0) {\n                    return $cmp;\n                }\n            }\n\n            // all elements were equal\n            return 0;\n        };\n\n        return $sorter;\n    }", "label": 2}
{"code": "def dump(self, **kwargs):\n        import sys\n        '''Print the parse tree and then call render for an example.'''\n        if not self.seq:\n            self.seq = self.getSequence()\n        print(\"StringGenerator version: %s\" % (__version__))\n        print(\"Python version: %s\" % sys.version)\n        # this doesn't work anymore in p3\n        # print(\"Random method provider class: %s\" % randint.im_class.__name__)\n        self.seq.dump()\n        return self.render(**kwargs)", "label": 1}
{"code": "public function setCase($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1beta2\\PartOfSpeech_Case::class);\n        $this->case = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def to_redis_params\n      { url: redis_url }.tap do |params|\n        next if redis_sentinels.nil?\n\n        raise ArgumentError, \"redis_sentinels must be an array; got #{redis_sentinels}\" unless\n          redis_sentinels.is_a?(Array)\n\n        next if redis_sentinels.empty?\n\n        params[:sentinels] = redis_sentinels.map(&method(:parse_sentinel))\n      end\n    end", "label": 4}
{"code": "async def dump_field(obj, elem, elem_type, params=None):\n    \"\"\"\n    Dumps generic field to the popo object representation, according to the element specification.\n    General multiplexer.\n\n    :param obj:\n    :param elem:\n    :param elem_type:\n    :param params:\n    :return:\n    \"\"\"\n    if isinstance(elem, (int, bool)) or issubclass(elem_type, x.UVarintType) or issubclass(elem_type, x.IntType):\n        return set_elem(obj, elem)\n\n    elif issubclass(elem_type, x.BlobType) or isinstance(obj, bytes) or isinstance(obj, bytearray):\n        return set_elem(obj, await dump_blob(elem))\n\n    elif issubclass(elem_type, x.UnicodeType) or isinstance(elem, str):\n        return set_elem(obj, elem)\n\n    elif issubclass(elem_type, x.VariantType):\n        return set_elem(obj, await dump_variant(None, elem, elem_type, params))\n\n    elif issubclass(elem_type, x.ContainerType):  # container ~ simple list\n        return set_elem(obj, await dump_container(None, elem, elem_type, params))\n\n    elif issubclass(elem_type, x.MessageType):\n        return set_elem(obj, await dump_message(None, elem))\n\n    else:\n        raise TypeError", "label": 1}
{"code": "func getAPIKey(options *bees.BeeOptions) string {\n\tvar apiKey string\n\toptions.Bind(\"api_key\", &apiKey)\n\n\tif strings.HasPrefix(apiKey, \"file://\") {\n\t\tbuf, err := ioutil.ReadFile(strings.TrimPrefix(apiKey, \"file://\"))\n\t\tif err != nil {\n\t\t\tpanic(\"Error reading API key file \" + apiKey)\n\t\t}\n\t\tapiKey = string(buf)\n\t}\n\n\tif strings.HasPrefix(apiKey, \"env://\") {\n\t\tbuf := strings.TrimPrefix(apiKey, \"env://\")\n\t\tapiKey = os.Getenv(string(buf))\n\t}\n\n\treturn strings.TrimSpace(apiKey)\n}", "label": 5}
{"code": "function indexTracking() {\n  const { tracking = {} } = getComponentsSettings();\n\n  return index({\n    file: 'tracking.js',\n    config: {\n      type: TYPE_TRACKERS,\n      config: tracking,\n    },\n    ...getIndexLogTranslations(TYPE_TRACKERS),\n  });\n}", "label": 3}
{"code": "public static function throwException($status_code, $message, $results)\n    {\n        switch ($status_code) {\n            case 1:\n                throw new IndexOutOfBoundsException($message, $results);\n            case 2:\n                throw new NoCollectionException($message, $results);\n            case 3:\n                throw new NoStringException($message, $results);\n            case 4:\n                throw new NoStringLengthException($message, $results);\n            case 5:\n                throw new NoStringWrapperException($message, $results);\n            case 6:\n                throw new NoSuchDriverException($message, $results);\n            case 7:\n                throw new NoSuchElementException($message, $results);\n            case 8:\n                throw new NoSuchFrameException($message, $results);\n            case 9:\n                throw new UnknownCommandException($message, $results);\n            case 10:\n                throw new StaleElementReferenceException($message, $results);\n            case 11:\n                throw new ElementNotVisibleException($message, $results);\n            case 12:\n                throw new InvalidElementStateException($message, $results);\n            case 13:\n                throw new UnknownServerException($message, $results);\n            case 14:\n                throw new ExpectedException($message, $results);\n            case 15:\n                throw new ElementNotSelectableException($message, $results);\n            case 16:\n                throw new NoSuchDocumentException($message, $results);\n            case 17:\n                throw new UnexpectedJavascriptException($message, $results);\n            case 18:\n                throw new NoScriptResultException($message, $results);\n            case 19:\n                throw new XPathLookupException($message, $results);\n            case 20:\n                throw new NoSuchCollectionException($message, $results);\n            case 21:\n                throw new TimeOutException($message, $results);\n            case 22:\n                throw new NullPointerException($message, $results);\n            case 23:\n                throw new NoSuchWindowException($message, $results);\n            case 24:\n                throw new InvalidCookieDomainException($message, $results);\n            case 25:\n                throw new UnableToSetCookieException($message, $results);\n            case 26:\n                throw new UnexpectedAlertOpenException($message, $results);\n            case 27:\n                throw new NoAlertOpenException($message, $results);\n            case 28:\n                throw new ScriptTimeoutException($message, $results);\n            case 29:\n                throw new InvalidCoordinatesException($message, $results);\n            case 30:\n                throw new IMENotAvailableException($message, $results);\n            case 31:\n                throw new IMEEngineActivationFailedException($message, $results);\n            case 32:\n                throw new InvalidSelectorException($message, $results);\n            case 33:\n                throw new SessionNotCreatedException($message, $results);\n            case 34:\n                throw new MoveTargetOutOfBoundsException($message, $results);\n            default:\n                throw new UnrecognizedExceptionException($message, $results);\n        }\n    }", "label": 2}
{"code": "function (name) {\n\t\t\treturn function (args, onDone) {\n\t\t\t\t\n\t\t\t\tif (typeof args === 'function') {\n\t\t\t\t\tonDone = args;\n\t\t\t\t\targs = {};\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tconsole.log('calling API [' + name + ']...');\n\t\t\t\t\n\t\t\t\t// NOTE: by default callbacks are always kept\n\t\t\t\tSR.sendEvent(name, args, function (result) {\n\t\t\t\t\tif (result.err) {\n\t\t\t\t\t\tconsole.error(result.err);\n\t\t\t\t\t\treturn SR.safeCall(onDone, result.err);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tSR.safeCall(onDone, null, result.result);\n\t\t\t\t}, undefined, true);\n\t\t\t}\n\t\t}", "label": 3}
{"code": "function getRequest(options,callback){\n    var destroyed = false;\n    var req = request.get(options.url)\n        .set(options.headers)\n        .timeout(options.timeout)\n        .redirects(options.redirects)\n        .buffer(false)\n        .end(function(err,res){\n            if(err && !err.status) return onError(err);\n\n            // Check HTTP status code\n            var isHTTPError = isRedirect(res.status) || isClientError(res.status) || isServerError(res.status);\n            if(isHTTPError) {\n                var reqFormated = req.req;\n                var resFormated = err.response.res;\n                return onError(new HTTPError(reqFormated, resFormated));\n            }\n\n            // Attach event handlers and build the body\n            var body = '';\n            res.on('data',function(chunk){\n                body += chunk;\n            });\n            res.on('end',function(){\n                if(destroyed) return;\n                // Check if a HTTP refresh/redirection is present into the HTML page, if yes refreshes/redirects.\n                var matches = body.match(/<meta[ ]*http-equiv=\"REFRESH\"[ ]*content=\"[0-9]{1,};[ ]*URL=(.*?)\"[ ]*\\/?>/i);\n                if(matches && matches[1]){\n                    options.url = matches[1];\n                    return getRequest(options,callback);\n                }\n                callback(null,body);\n            });\n            res.on('error',onError);\n\n            // Check if content-type is an image, if yes destroy the response and build a HTML page with the image in it\n            if(isImage(res.headers)){\n                res.destroy();\n                destroyed = true;\n                body = '<!DOCTYPE html><html><head></head><body><img src=\"' + options.url + '\" /></body></html>';\n                return callback(null,body);\n            }\n        });\n\n    // Error event handler\n    function onError(err){\n        if(options.retries--) return getRequest(options,callback);\n        callback(err);\n    }\n\n    return req;\n}", "label": 3}
{"code": "public function setFeatures($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\Feature::class);\n        $this->features = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (dm *DjangoMigration) Save(db XODB) error {\n\tif dm.Exists() {\n\t\treturn dm.Update(db)\n\t}\n\n\treturn dm.Insert(db)\n}", "label": 5}
{"code": "function mdLogEntry(version, log) {\n    return util.format(\n        '### %s\\n%s\\n\\n',\n        version,\n        log.map(function (logItem) {\n            return '  * ' + logItem;\n        }).join('\\n')\n    );\n}", "label": 3}
{"code": "function morganMiddleware(req, res, next) {\n    const { ignoreRouteUrls, includeReqHeaders, omitReqProperties } = getConfig('logger');\n    const { format } = getConfig('logger.morgan');\n    // define custom tokens\n    morgan.token('operation-hash', request => get(request, 'body.extensions.persistentQuery.sha256Hash'));\n    morgan.token('operation-name', request => get(request, 'body.operationName'));\n    morgan.token('user-id', request => get(request, 'locals.user.id'));\n    morgan.token('company-id', request => get(request, 'locals.user.companyId'));\n    morgan.token('message', request => request.name || '-');\n    morgan.token('request-id', request => request.id);\n    morgan.token('request-headers', (request) => {\n        const headers = includeReqHeaders === true\n            ? omit(request.headers, omitReqProperties) : {};\n        return JSON.stringify(headers);\n    });\n\n    const logger = getContainer('logger');\n    const formatFormat = json(format);\n    const options = {\n        stream: asStream(logger),\n        skip: skip(ignoreRouteUrls),\n    };\n    return morgan(formatFormat, options)(req, res, next);\n}", "label": 3}
{"code": "def critical(cls, name, message, *args):\n        \"\"\"\n        Convenience function to log a message at the CRITICAL level.\n\n        :param name:    The name of the logger instance in the VSG namespace (VSG.<name>)\n        :param message: A message format string.\n        :param args:    The arguments that are are merged into msg using the string formatting operator.\n        :..note:        The native logger's `kwargs` are not used in this function.\n        \"\"\"\n        cls.getLogger(name).critical(message, *args)", "label": 1}
{"code": "def get_ops(self, key):\n        ''' Returns ops from the key if found otherwise raises a KeyError.\n        '''\n        ops = self._store.get(key)\n        if ops is None:\n            raise KeyError(\n                'cannot get operations for {}'.format(key))\n        return ops", "label": 1}
{"code": "public function setMetadata($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Spanner\\V1\\ResultSetMetadata::class);\n        $this->metadata = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def checkup_git_repo_legacy(url, name=None, base_dir='~/repos',\n                            verbose=False, prefix='', postfix=''):\n    '''Checkout or update a git repo.'''\n    if not name:\n        match = re.match(r'.*/(.+)\\.git', url)\n        assert match, flo(\"Unable to extract repo name from '{url}'\")\n        name = match.group(1)\n    assert name is not None, flo('Cannot extract repo name from repo: {url}')\n    assert name != '', flo('Cannot extract repo name from repo: {url} (empty)')\n    if verbose:\n        name_blue = blue(name)\n        print_msg(flo('{prefix}Checkout or update {name_blue}{postfix}'))\n    if not exists(base_dir):\n        run(flo('mkdir -p {base_dir}'))\n    if not exists(flo('{base_dir}/{name}/.git')):\n        run(flo('  &&  '.join([\n                'cd {base_dir}',\n                'git clone  {url}  {name}'])),\n            msg='clone repo')\n    else:\n        if verbose:\n            print_msg('update: pull from origin')\n        run(flo('cd {base_dir}/{name}  &&  git pull'))\n    return name", "label": 1}
{"code": "function Protocol(name, messages, types, handlers) {\n  if (types === undefined) {\n    // Let's be helpful in case this class is instantiated directly.\n    return createProtocol(name, messages);\n  }\n\n  this._name = name;\n  this._messages = messages;\n  this._types = types;\n  // Shared with subprotocols (via the prototype chain, overwriting is safe).\n  this._handlers = handlers || {};\n  // We cache a string rather than a buffer to not retain an entire slab. This\n  // also lets us use hashes as keys inside maps (e.g. for resolvers).\n  this._hs = utils.getHash(this.getSchema()).toString('binary');\n}", "label": 3}
{"code": "def render_revalidation_failure(self, step, form, **kwargs):\n        \"\"\"\n        Gets called when a form doesn't validate when rendering the done\n        view. By default, it changed the current step to failing forms step\n        and renders the form.\n        \"\"\"\n        self.storage.current_step = step\n        return self.render(form, **kwargs)", "label": 1}
{"code": "function createHandler(to, except, pathFunc, protocol) {\n    return function(req, res, next) {\n        var host = req.hostname || '';\n        var url = req.url;\n\n        if (host in except) {\n            next();\n        } else {\n            var target = new URIjs(pathFunc(host, url))\n              .host(to)\n              .protocol(protocol || '')\n              .href();\n\n            res.redirect(301, target);\n        }\n    };\n}", "label": 3}
{"code": "def delete(table, where=(), **kwargs):\r\n    \"\"\"Convenience wrapper for database DELETE.\"\"\"\r\n    where = dict(where, **kwargs).items()\r\n    sql, args = makeSQL(\"DELETE\", table, where=where)\r\n    return execute(sql, args).rowcount", "label": 1}
{"code": "function _define(/* <exports>, name, dependencies, factory */) {\n            var\n                // extract arguments\n                argv = arguments,\n                argc = argv.length,\n\n                // extract arguments from function call - (exports?, name?, modules?, factory)\n                exports = argv[argc - 4] || {},\n                name = argv[argc - 3] || Math.floor(new Date().getTime() * (Math.random())), // if name is undefined or falsy value we add some timestamp like to name.\n                dependencies = argv[argc - 2] || [],\n                factory = argv[argc - 1],\n\n                // helper variables\n                params = [],\n                dependencies_satisfied = true,\n                dependency_name,\n                result,\n                config_dependencies_iterator = 0,\n                dependencies_iterator = 0,\n                config_dependencies_index = -1;\n\n            if (DEVELOPMENT) {\n                _set_debug_timer();\n            }\n\n            // config dependecies\n            if (_define.prototype.config_dependencies && _define.prototype.config_dependencies.constructor === Array) {\n                var config_dependencies = _define.prototype.config_dependencies || [];\n\n                var config_dependencies_size = config_dependencies.length;\n                for (; config_dependencies_iterator < config_dependencies_size; config_dependencies_iterator++) {\n                    if (name === config_dependencies[config_dependencies_iterator]) {\n                        config_dependencies_index = config_dependencies_iterator;\n                    }\n                }\n                if (config_dependencies_index !== -1) {\n                    config_dependencies.splice(config_dependencies_index, 1)\n                } else {\n                    dependencies = dependencies.concat(config_dependencies);\n                }\n            }\n\n            // find params\n            for (; dependencies_iterator < dependencies.length; dependencies_iterator++) {\n                dependency_name = dependencies[dependencies_iterator];\n\n                // if this dependency exists, push it to param injection\n                if (modules.hasOwnProperty(dependency_name)) {\n                    params.push(modules[dependency_name]);\n                } else if (dependency_name === 'exports') {\n                    params.push(exports);\n                } else {\n                    if (argc !== 4) { // if 4 values, is reexecuting\n                        // no module found. save these arguments for future execution.\n                        define_queue[dependency_name] = define_queue[dependency_name] || [];\n                        define_queue[dependency_name].push([exports, name, dependencies, factory]);\n                    }\n\n                    dependencies_satisfied = false;\n                }\n            }\n\n            // all dependencies are satisfied, so proceed\n            if (dependencies_satisfied) {\n                if (!modules.hasOwnProperty(name)) {\n                    // execute this module\n                    result = factory.apply(this, params);\n\n                    if (result) {\n                        modules[name] = result;\n                    } else {\n                        // assuming result is in exports object\n                        modules[name] = exports;\n                    }\n                }\n\n                // execute others waiting for this module\n                while (define_queue[name] && (argv = define_queue[name].pop())) {\n                    _define.apply(this, argv);\n                }\n            }\n        }", "label": 3}
{"code": "def create_from_disk filename\n      result = false\n      mutex.synchronize do\n        next if File.directory?(filename) || !File.exist?(filename)\n        next unless contain?(filename) || open?(filename) || workspace.would_merge?(filename)\n        @synchronized = false\n        source = Solargraph::Source.load_string(File.read(filename), filename)\n        workspace.merge(source)\n        result = true\n      end\n      result\n    end", "label": 4}
{"code": "function(raw){\n                    var clone = canReflect.serialize(raw);\n                    if(clone.page) {\n                        clone[offset] = clone.page.start;\n                        clone[limit] = (clone.page.end - clone.page.start) + 1;\n                        delete clone.page;\n                    }\n                    return clone;\n                }", "label": 3}
{"code": "def _is_valid(self, log: Optional[Logger] = None) -> bool:\n        \"\"\" Determine whether the current contents are valid \"\"\"\n        return self._validate(self, log)[0]", "label": 1}
{"code": "func PMeasure(text string, _ ...interface{}) bool {\n\tglobalSuite.PushMeasureNode(text, func(b Benchmarker) {}, types.FlagTypePending, codelocation.New(1), 0)\n\treturn true\n}", "label": 5}
{"code": "public static<E> Set<E> retainKeys(Counter<E> counter, Collection<E> matchKeys) {\r\n    Set<E> removed = new HashSet<E>();\r\n    for (E key : counter.keySet()) {\r\n      boolean matched = matchKeys.contains(key);\r\n      if (!matched) {\r\n        removed.add(key);\r\n      }\r\n    }\r\n    for (E key : removed) {\r\n      counter.remove(key);\r\n    }\r\n    return removed;\r\n  }", "label": 0}
{"code": "function _gpfInterfaceIsImplementedBy(interfaceSpecifier, inspectedObject) {\n        var result = true;\n        _gpfObjectForEach(interfaceSpecifier.prototype, function (referenceMethod, name) {\n            if (name === \"constructor\") {\n                // ignore\n                return;\n            }\n            if (_gpfInterfaceIsInvalidMethod(referenceMethod, inspectedObject[name])) {\n                result = false;\n            }\n        });\n        return result;\n    }", "label": 3}
{"code": "public function store($id)\n    {\n        $data = [\n            'title' => request('title'),\n            'excerpt' => request('excerpt', ''),\n            'slug' => request('slug'),\n            'body' => request('body', ''),\n            'published' => request('published'),\n            'author_id' => request('author_id'),\n            'featured_image' => request('featured_image'),\n            'featured_image_caption' => request('featured_image_caption', ''),\n            'publish_date' => request('publish_date', ''),\n            'meta' => request('meta', (object) []),\n        ];\n\n        validator($data, [\n            'publish_date' => 'required|date',\n            'author_id' => 'required',\n            'title' => 'required',\n            'slug' => 'required|'.Rule::unique(config('wink.database_connection').'.wink_posts', 'slug')->ignore(request('id')),\n        ])->validate();\n\n        $entry = $id !== 'new' ? WinkPost::findOrFail($id) : new WinkPost(['id' => request('id')]);\n\n        $entry->fill($data);\n\n        $entry->save();\n\n        $entry->tags()->sync(\n            $this->collectTags(request('tags'))\n        );\n\n        return response()->json([\n            'entry' => $entry,\n        ]);\n    }", "label": 2}
{"code": "def add_range(cells)\n     sqref = if cells.is_a?(String)\n               cells\n             elsif cells.is_a?(SimpleTypedList) || cells.is_a?(Array)\n               Axlsx::cell_range(cells, false)\n             end\n     self << ProtectedRange.new(:sqref => sqref, :name => \"Range#{size}\")\n     last\n    end", "label": 4}
{"code": "public function readAll()\n    {\n        // Chunks contain 3 properties:\n        // - rowContents: The row contents, this essentially is all data\n        //   pertaining to a single family.\n        // - commitRow: This is a boolean telling us the all previous chunks for\n        //   this row are ok to consume.\n        // - resetRow: This is a boolean telling us that all the previous chunks\n        //   are to be discarded.\n\n        foreach ($this->stream as $readRowsResponse) {\n            foreach ($readRowsResponse->getChunks() as $chunk) {\n                switch ($this->state) {\n                    case self::$rowStateEnum['NEW_ROW']:\n                        $this->newRow($chunk);\n                        break;\n                    case self::$rowStateEnum['ROW_IN_PROGRESS']:\n                        $this->rowInProgress($chunk);\n                        break;\n                    case self::$rowStateEnum['CELL_IN_PROGRESS']:\n                        $this->cellInProgress($chunk);\n                        break;\n                }\n\n                if ($chunk->getCommitRow()) {\n                    $row = $this->row;\n                    $rowKey = $this->rowKey;\n                    $this->commit();\n                    yield $rowKey => $row;\n                    $this->numberOfRowsRead++;\n                }\n            }\n        }\n\n        $this->onStreamEnd();\n    }", "label": 2}
{"code": "public function getRootEntities()\n    {\n        $entities = [];\n\n        foreach ($this->dqlParts['from'] as &$fromClause) {\n            if (is_string($fromClause)) {\n                $spacePos = strrpos($fromClause, ' ');\n                $from     = substr($fromClause, 0, $spacePos);\n                $alias    = substr($fromClause, $spacePos + 1);\n\n                $fromClause = new Query\\Expr\\From($from, $alias);\n            }\n\n            $entities[] = $fromClause->getFrom();\n        }\n\n        return $entities;\n    }", "label": 2}
{"code": "def delete_file(path)\n      Jekyll.logger.debug \"DELETING:\", path\n      FileUtils.rm_f sanitized_path(path)\n      site.process\n    end", "label": 4}
{"code": "function moveToSlide(index) {\n          // Wrap around indices.\n          if (index >= $slides.length) index = 0;\n          else if (index < 0) index = $slides.length -1;\n\n          $active_index = $slider.find('.active').index();\n\n          // Only do if index changes\n          if ($active_index != index) {\n            $active = $slides.eq($active_index);\n            $caption = $active.find('.caption');\n\n            $active.removeClass('active');\n            $active.velocity({opacity: 0}, {duration: options.transition, queue: false, easing: 'easeOutQuad',\n                              complete: function() {\n                                $slides.not('.active').velocity({opacity: 0, translateX: 0, translateY: 0}, {duration: 0, queue: false});\n                              } });\n            captionTransition($caption, options.transition);\n\n\n            // Update indicators\n            if (options.indicators) {\n              $indicators.eq($active_index).removeClass('active');\n            }\n\n            $slides.eq(index).velocity({opacity: 1}, {duration: options.transition, queue: false, easing: 'easeOutQuad'});\n            $slides.eq(index).find('.caption').velocity({opacity: 1, translateX: 0, translateY: 0}, {duration: options.transition, delay: options.transition, queue: false, easing: 'easeOutQuad'});\n            $slides.eq(index).addClass('active');\n\n\n            // Update indicators\n            if (options.indicators) {\n              $indicators.eq(index).addClass('active');\n            }\n          }\n        }", "label": 3}
{"code": "def load_psat(cls, fd):\n        \"\"\" Returns a case object from the given PSAT data file.\n        \"\"\"\n        from pylon.io.psat import PSATReader\n        return PSATReader().read(fd)", "label": 1}
{"code": "def prepare_samples(job, patient_dict, univ_options):\n    \"\"\"\n    Obtain the input files for the patient and write them to the file store.\n\n    :param dict patient_dict: The input fastq dict\n           patient_dict:\n               |- 'tumor_dna_fastq_[12]' OR 'tumor_dna_bam': str\n               |- 'tumor_rna_fastq_[12]' OR 'tumor_rna_bam': str\n               |- 'normal_dna_fastq_[12]' OR 'normal_dna_bam': str\n               |- 'mutation_vcf': str\n               |- 'hla_haplotype_files': str\n               +- 'patient_id': str\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :return: Updated fastq dict\n             output_dict:\n                 |- 'tumor_dna_fastq_[12]' OR 'tumor_dna_bam': fsID\n                 |- 'tumor_rna_fastq_[12]' OR 'tumor_rna_bam': fsID\n                 |- 'normal_dna_fastq_[12]' OR 'normal_dna_bam': fsID\n                 |- 'mutation_vcf': fsID\n                 |- 'hla_haplotype_files': fsId\n                 +- 'patient_id': str\n    :rtype: dict\n    \"\"\"\n    job.fileStore.logToMaster('Downloading Inputs for %s' % univ_options['patient'])\n    # For each sample type, check if the prefix is an S3 link or a regular file\n    # Download S3 files.\n    output_dict = {}\n    for input_file in patient_dict:\n        if not input_file.endswith(('bam', 'bai', '_1', '_2', 'files', 'vcf', 'bedpe')):\n            output_dict[input_file] = patient_dict[input_file]\n            continue\n        output_dict[input_file] = get_pipeline_inputs(\n            job, ':'.join([univ_options['patient'], input_file]), patient_dict[input_file],\n            encryption_key=(univ_options['sse_key'] if patient_dict['ssec_encrypted'] else None),\n            per_file_encryption=univ_options['sse_key_is_master'],\n            gdc_download_token=univ_options['gdc_download_token'])\n    return output_dict", "label": 1}
{"code": "func PgAggregateByAggfnoid(db XODB, aggfnoid pgtypes.Regproc) (*PgAggregate, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, aggfnoid, aggkind, aggnumdirectargs, aggtransfn, aggfinalfn, aggmtransfn, aggminvtransfn, aggmfinalfn, aggfinalextra, aggmfinalextra, aggsortop, aggtranstype, aggtransspace, aggmtranstype, aggmtransspace, agginitval, aggminitval ` +\n\t\t`FROM pg_catalog.pg_aggregate ` +\n\t\t`WHERE aggfnoid = $1`\n\n\t// run query\n\tXOLog(sqlstr, aggfnoid)\n\tpa := PgAggregate{}\n\n\terr = db.QueryRow(sqlstr, aggfnoid).Scan(&pa.Tableoid, &pa.Cmax, &pa.Xmax, &pa.Cmin, &pa.Xmin, &pa.Ctid, &pa.Aggfnoid, &pa.Aggkind, &pa.Aggnumdirectargs, &pa.Aggtransfn, &pa.Aggfinalfn, &pa.Aggmtransfn, &pa.Aggminvtransfn, &pa.Aggmfinalfn, &pa.Aggfinalextra, &pa.Aggmfinalextra, &pa.Aggsortop, &pa.Aggtranstype, &pa.Aggtransspace, &pa.Aggmtranstype, &pa.Aggmtransspace, &pa.Agginitval, &pa.Aggminitval)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pa, nil\n}", "label": 5}
{"code": "public static function not(self $condition)\n    {\n        return new static(\n            function (WebDriver $driver) use ($condition) {\n                $result = call_user_func($condition->getApply(), $driver);\n\n                return !$result;\n            }\n        );\n    }", "label": 2}
{"code": "public function setExecutionErrors($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Rpc\\Status::class);\n        $this->execution_errors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function expandModel (model, view) {\n  const modelPath = new BunsenModelPath(model)\n  const modelExpansions = aggregateModels(view, modelPath)\n  let newModel = model\n  _.forEach(modelExpansions, (propertyModel, path) => {\n    newModel = addBunsenModelProperty(newModel, propertyModel, path)\n  })\n  return newModel\n}", "label": 3}
{"code": "def handle_auth_failure!\n      yield\n    rescue Mongo::Error::SocketTimeoutError\n      # possibly cluster is slow, do not give up on it\n      raise\n    rescue Mongo::Error::SocketError\n      # non-timeout network error\n      unknown!\n      pool.disconnect!\n      raise\n    rescue Auth::Unauthorized\n      # auth error, keep server description and topology as they are\n      pool.disconnect!\n      raise\n    end", "label": 4}
{"code": "public static <E> Counter<E> average(Counter<E> c1, Counter<E> c2) {\r\n    Counter<E> average = c1.getFactory().create();\r\n    Set<E> allKeys = new HashSet<E>(c1.keySet());\r\n    allKeys.addAll(c2.keySet());\r\n    for (E key : allKeys) {\r\n      average.setCount(key, (c1.getCount(key) + c2.getCount(key)) * 0.5);\r\n    }\r\n    return average;\r\n  }", "label": 0}
{"code": "public Set<S> getMatchedDeclarationBinder() {\n        Set<S> bindedSet = new HashSet<S>();\n        for (Map.Entry<ServiceReference<S>, BinderDescriptor> e : declarationBinders.entrySet()) {\n            if (e.getValue().match) {\n                bindedSet.add(getDeclarationBinder(e.getKey()));\n            }\n        }\n        return bindedSet;\n    }", "label": 0}
{"code": "private Statement createStatement(Connection con, boolean scrollable, int explicitFetchSizeHint)\r\n        throws java.sql.SQLException\r\n    {\r\n        Statement result;\r\n        try\r\n        {\r\n            // if necessary use JDBC1.0 methods\r\n            if (!FORCEJDBC1_0)\r\n            {\r\n                result =\r\n                    con.createStatement(\r\n                        scrollable\r\n                            ? ResultSet.TYPE_SCROLL_INSENSITIVE\r\n                            : ResultSet.TYPE_FORWARD_ONLY,\r\n                        ResultSet.CONCUR_READ_ONLY);\r\n                afterJdbc2CapableStatementCreate(result, explicitFetchSizeHint);\r\n            }\r\n            else\r\n            {\r\n                result = con.createStatement();\r\n            }\r\n        }\r\n        catch (AbstractMethodError err)\r\n        {\r\n            // if a JDBC1.0 driver is used, the signature\r\n            // createStatement(int, int) is  not defined.\r\n            // we then call the JDBC1.0 variant createStatement()\r\n            log.warn(\"Used driver seems not JDBC 2.0 compatible, use the JDBC 1.0 mode\", err);\r\n            result = con.createStatement();\r\n            FORCEJDBC1_0 = true;\r\n        }\r\n        catch (SQLException eSql)\r\n        {\r\n            // there are JDBC Driver that nominally implement JDBC 2.0, but\r\n            // throw DriverNotCapableExceptions. If we catch one of these\r\n            // we force usage of JDBC 1.0\r\n            if (eSql.getClass().getName()\r\n                .equals(\"interbase.interclient.DriverNotCapableException\"))\r\n            {\r\n                log.warn(\"JDBC 2.0 problems with this interbase driver, we use the JDBC 1.0 mode\");\r\n                FORCEJDBC1_0 = true;\r\n                result = con.createStatement();\r\n            }\r\n            else\r\n            {\r\n                throw eSql;\r\n            }\r\n        }\r\n        try\r\n        {\r\n            platform.afterStatementCreate(result);\r\n        }\r\n        catch (PlatformException e)\r\n        {\r\n            log.error(\"Platform dependend failure\", e);\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "protected function mergeControllerProperties()\n    {\n        if (isset($this->action['uses']) && is_string($this->action['uses']) && Str::contains($this->action['uses'],\n                '@')) {\n            $this->action['controller'] = $this->action['uses'];\n\n            $this->makeControllerInstance();\n        }\n\n        if (! $this->controllerUsesHelpersTrait()) {\n            return;\n        }\n\n        $controller = $this->getControllerInstance();\n\n        $controllerMiddleware = [];\n\n        if (method_exists($controller, 'getMiddleware')) {\n            $controllerMiddleware = $controller->getMiddleware();\n        } elseif (method_exists($controller, 'getMiddlewareForMethod')) {\n            $controllerMiddleware = $controller->getMiddlewareForMethod($this->controllerMethod);\n        }\n\n        $this->middleware = array_merge($this->middleware, $controllerMiddleware);\n\n        if ($property = $this->findControllerPropertyOptions('throttles')) {\n            $this->throttle = $property['class'];\n        }\n\n        if ($property = $this->findControllerPropertyOptions('scopes')) {\n            $this->scopes = array_merge($this->scopes, $property['scopes']);\n        }\n\n        if ($property = $this->findControllerPropertyOptions('authenticationProviders')) {\n            $this->authenticationProviders = array_merge($this->authenticationProviders, $property['providers']);\n        }\n\n        if ($property = $this->findControllerPropertyOptions('rateLimit')) {\n            $this->rateLimit = $property['limit'];\n            $this->rateExpiration = $property['expires'];\n        }\n    }", "label": 2}
{"code": "def exit(self, pub_id, *node_ids):\n        '''Agents will notify the pub they want to leave'''\n        try:\n            pub = self['pubs'][pub_id]\n        except KeyError:\n            raise ValueError('Pub {} is not available'.format(pub_id))\n        for node_id in node_ids:\n            node = self.get_agent(node_id)\n            if pub_id == node['pub']:\n                del node['pub']\n                pub['occupancy'] -= 1", "label": 1}
{"code": "public function setInfoType($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\InfoType::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (o HostNetworkSystem) AddVirtualSwitch(ctx context.Context, vswitchName string, spec *types.HostVirtualSwitchSpec) error {\n\treq := types.AddVirtualSwitch{\n\t\tThis:        o.Reference(),\n\t\tVswitchName: vswitchName,\n\t\tSpec:        spec,\n\t}\n\n\t_, err := methods.AddVirtualSwitch(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, policydataset resource) throws Exception {\n\t\tpolicydataset addresource = new policydataset();\n\t\taddresource.name = resource.name;\n\t\taddresource.type = resource.type;\n\t\taddresource.indextype = resource.indextype;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "func IsHandshakeFailedError(err error) bool {\n\tif err == nil {\n\t\treturn false\n\t}\n\treturn strings.Contains(trace.Unwrap(err).Error(), \"ssh: handshake failed\")\n}", "label": 5}
{"code": "public static String fileNameClean(String s) {\r\n    char[] chars = s.toCharArray();\r\n    StringBuilder sb = new StringBuilder();\r\n    for (char c : chars) {\r\n      if ((c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z') || (c >= '0' && c <= '9') || (c == '_')) {\r\n        sb.append(c);\r\n      } else {\r\n        if (c == ' ' || c == '-') {\r\n          sb.append('_');\r\n        } else {\r\n          sb.append('x').append((int) c).append('x');\r\n        }\r\n      }\r\n    }\r\n    return sb.toString();\r\n  }", "label": 0}
{"code": "func (ns *NodeSession) interactiveSession(callback interactiveCallback) error {\n\t// determine what kind of a terminal we need\n\ttermType := os.Getenv(\"TERM\")\n\tif termType == \"\" {\n\t\ttermType = teleport.SafeTerminalType\n\t}\n\t// create the server-side session:\n\tsess, err := ns.createServerSession()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t// allocate terminal on the server:\n\tremoteTerm, err := ns.allocateTerminal(termType, sess)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdefer remoteTerm.Close()\n\n\t// call the passed callback and give them the established\n\t// ssh session:\n\tif err := callback(sess, remoteTerm); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// Catch term signals, but only if we're attached to a real terminal\n\tif ns.isTerminalAttached() {\n\t\tns.watchSignals(remoteTerm)\n\t}\n\n\t// start piping input into the remote shell and pipe the output from\n\t// the remote shell into stdout:\n\tns.pipeInOut(remoteTerm)\n\n\t// switch the terminal to raw mode (and switch back on exit!)\n\tif ns.isTerminalAttached() {\n\t\tts, err := term.SetRawTerminal(0)\n\t\tif err != nil {\n\t\t\tlog.Warn(err)\n\t\t} else {\n\t\t\tdefer term.RestoreTerminal(0, ts)\n\t\t}\n\t}\n\t// wait for the session to end\n\t<-ns.closer.C\n\treturn nil\n}", "label": 5}
{"code": "def write_field_begin_internal(type, id, type_override=nil)\n      last_id = @last_field.pop\n      \n      # if there's a type override, use that.\n      typeToWrite = type_override || CompactTypes.get_compact_type(type)\n\n      # check if we can use delta encoding for the field id\n      if id > last_id && id - last_id <= 15\n        # write them together\n        write_byte((id - last_id) << 4 | typeToWrite)\n      else\n        # write them separate\n        write_byte(typeToWrite)\n        write_i16(id)\n      end\n\n      @last_field.push(id)\n      nil\n    end", "label": 4}
{"code": "func SetNamespace() error {\n\tinitOnce.Do(Init)\n\tif err := netns.Set(initNs); err != nil {\n\t\tlinkInfo, linkErr := getLink()\n\t\tif linkErr != nil {\n\t\t\tlinkInfo = linkErr.Error()\n\t\t}\n\t\treturn fmt.Errorf(\"failed to set to initial namespace, %v, initns fd %d: %v\", linkInfo, initNs, err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def create_content_with_photo\n      tag = params[:tag]\n      photo = ContentPhoto.create\n\n      key = tag.underscore.camelize + photo.id.to_s\n      new_content = Content.create(tag: tag, key: key)\n\n      # photo.subdomain = subdomain\n      # photo.folder = current_tenant_model.whitelabel_country_code\n      # photo.tenant_id = current_tenant_model.id\n      if params[:file]\n        photo.image = params[:file]\n      end\n      photo.save!\n      new_content.content_photos.push photo\n\n      # http://typeoneerror.com/labs/jsonapi-resources-ember-data/\n      # resource for model\n      resource = Api::V1::WebContentResource.new(new_content, nil)\n\n      # serializer for resource\n      serializer = JSONAPI::ResourceSerializer.new(Api::V1::WebContentResource)\n      # jsonapi-compliant hash (ready to be send to render)\n\n      photo.reload\n      # above needed to ensure image_url is available\n      # might need below if upload in prod is slow..\n\n      # upload_confirmed = false\n      # tries = 0\n      # until upload_confirmed\n      #   if photo.image_url.present?\n      #     upload_confirmed = true\n      #   else\n      #     sleep 1\n      #     photo.reload\n      #     tries += 1\n      #     if tries > 5\n      #       upload_confirmed = true\n      #     end\n      #   end\n      # end\n\n      render json: serializer.serialize_to_hash(resource)\n\n      # return render json: new_content.to_json\n      # return render :json => { :error => \"Sorry...\", :status => \"444\", :data => \"ssss\" }, :status => 422\n    end", "label": 4}
{"code": "public function setManagedGroupConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\ManagedGroupConfig::class);\n        $this->managed_group_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function getFilterFn(layer, symbolizer) {\n    const symbolizers = Object.keys(layer.shader)\n        .filter(property => layer.shader[property].symbolizer === symbolizer);\n\n    //No need to set a callback when at least one property is not filtered (i.e. it always activates the symbolizer)\n    const alwaysActive = symbolizers\n        .reduce((a, property) => a || !layer.shader[property].filtered, false);\n\n    if (alwaysActive) {\n        return undefined;\n    }\n\n    const fn = symbolizers\n        .map((property) => layer.shader[property].js)\n        .reduce((all, arr) => all.concat(arr), [])\n        .join('');\n\n    return wrapFn(`var _value = null; ${fn} return _value !== null;`);\n}", "label": 3}
{"code": "function addUser(user, options) {\n  if (!runningAsRoot()) return;\n  if (!user) throw new Error('You must provide an username');\n  options = _.opts(options, {systemUser: false, home: null, password: null, gid: null, uid: null, groups: []});\n  if (userExists(user)) {\n    return;\n  }\n  if (isPlatform('linux')) {\n    _addUserLinux(user, options);\n  } else if (isPlatform('osx')) {\n    _addUserOsx(user, options);\n  } else if (isPlatform('windows')) {\n    throw new Error(\"Don't know how to add user in Windows\");\n  } else {\n    throw new Error(\"Don't know how to add user in current platform\");\n  }\n}", "label": 3}
{"code": "public function open($savePath, $sessionName)\n    {\n        $this->kind = $sessionName;\n        if (preg_match(self::NAMESPACE_ALLOWED_PATTERN, $savePath) !== 1 ||\n            preg_match(self::NAMESPACE_RESERVED_PATTERN, $savePath) === 1) {\n            throw new InvalidArgumentException(\n                sprintf('The given save_path \"%s\" not allowed', $savePath)\n            );\n        }\n        $this->namespaceId = $savePath;\n        $this->transaction = $this->datastore->transaction();\n        return true;\n    }", "label": 2}
{"code": "public IGoal[] getAgentGoals(final String agent_name, Connector connector) {\n        ((IExternalAccess) connector.getAgentsExternalAccess(agent_name))\n                .scheduleStep(new IComponentStep<Plan>() {\n\n                    public IFuture<Plan> execute(IInternalAccess ia) {\n                        IBDIInternalAccess bia = (IBDIInternalAccess) ia;\n\n                        goals = bia.getGoalbase().getGoals();\n                        return null;\n                    }\n                }).get(new ThreadSuspendable());\n\n        return goals;\n    }", "label": 0}
{"code": "protected function getQueryStringParameter($parameter, ServerRequestInterface $request, $default = null)\n    {\n        return isset($request->getQueryParams()[$parameter]) ? $request->getQueryParams()[$parameter] : $default;\n    }", "label": 2}
{"code": "def get_config(self, config_name, require_ready=True):\n        \"\"\"\n        Return the config with the given case-insensitive config_name.\n        Raise LookupError if no config exists with this name.\n        \"\"\"\n        if require_ready:\n            self.bots.check_configs_ready()\n        else:\n            self.bots.check_bots_ready()\n\n        return self.configs.get(config_name.lower(), {})", "label": 1}
{"code": "def parse_inventory(inventory_output=None):\n    \"\"\"Parse the inventory text and return udi dict.\"\"\"\n    udi = {\n        \"name\": \"\",\n        \"description\": \"\",\n        \"pid\": \"\",\n        \"vid\": \"\",\n        \"sn\": \"\"\n    }\n    if inventory_output is None:\n        return udi\n\n    # find the record with chassis text in name or descr\n    capture_next = False\n    chassis_udi_text = None\n    for line in inventory_output.split('\\n'):\n        lc_line = line.lower()\n        if ('chassis' in lc_line or 'switch system' in lc_line or 'rack' in lc_line) and 'name' in lc_line and 'descr':\n            capture_next = True\n            chassis_udi_text = line\n            continue\n        if capture_next:\n            inventory_output = chassis_udi_text + \"\\n\" + line\n            break\n    match = re.search(r\"(?i)NAME: (?P<name>.*?),? (?i)DESCR\", inventory_output, re.MULTILINE)\n    if match:\n        udi['name'] = match.group('name').strip('\" ,')\n\n    match = re.search(r\"(?i)DESCR: (?P<description>.*)\", inventory_output, re.MULTILINE)\n    if match:\n        udi['description'] = match.group('description').strip('\" ')\n\n    match = re.search(r\"(?i)PID: (?P<pid>.*?),? \", inventory_output, re.MULTILINE)\n    if match:\n        udi['pid'] = match.group('pid')\n\n    match = re.search(r\"(?i)VID: (?P<vid>.*?),? \", inventory_output, re.MULTILINE)\n    if match:\n        udi['vid'] = match.group('vid')\n\n    match = re.search(r\"(?i)SN: (?P<sn>.*)\", inventory_output, re.MULTILINE)\n    if match:\n        udi['sn'] = match.group('sn').strip()\n    return udi", "label": 1}
{"code": "func (p *PoolData) String() string {\n\treturn fmt.Sprintf(\"ParentKey: %s, Pool: %s, Range: %s, RefCount: %d\",\n\t\tp.ParentKey.String(), p.Pool.String(), p.Range, p.RefCount)\n}", "label": 5}
{"code": "public function setRow($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\Row::class);\n        $this->row = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def record_source(self, src, prg=''):\n        \"\"\"\n        function to collect raw data from the web and hard drive\n        Examples - new source file for ontologies, email contacts list, folder for xmas photos\n        \"\"\"\n        self._log(self.logFileSource , force_to_string(src), prg)", "label": 1}
{"code": "public function setCloudStorageFileSet($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CloudStorageFileSet::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def raw_post\n      unless has_header? \"RAW_POST_DATA\"\n        raw_post_body = body\n        set_header(\"RAW_POST_DATA\", raw_post_body.read(content_length))\n        raw_post_body.rewind if raw_post_body.respond_to?(:rewind)\n      end\n      get_header \"RAW_POST_DATA\"\n    end", "label": 4}
{"code": "public function orderBy($fieldPath, $direction = self::DIR_ASCENDING)\n    {\n        $direction = array_key_exists(strtoupper($direction), $this->shortDirections)\n            ? $this->shortDirections[strtoupper($direction)]\n            : $direction;\n\n        if (!in_array($direction, $this->allowedDirections)) {\n            throw new \\InvalidArgumentException(sprintf(\n                'Direction %s is not a valid direction',\n                $direction\n            ));\n        }\n\n        if ($this->queryHas('startAt') || $this->queryHas('endAt')) {\n            throw new \\InvalidArgumentException(\n                'Cannot specify an orderBy constraint after calling any of ' .\n                '`startAt()`, `startAfter()`, `endBefore()` or `endAt`().'\n            );\n        }\n\n        if (!($fieldPath instanceof FieldPath)) {\n            $fieldPath = FieldPath::fromString($fieldPath);\n        }\n\n        return $this->newQuery([\n            'orderBy' => [\n                [\n                    'field' => [\n                        'fieldPath' => $fieldPath->pathString()\n                    ],\n                    'direction' => $direction\n                ]\n            ]\n        ]);\n    }", "label": 2}
{"code": "func importFileDescriptors() ([]FileDescriptor, error) {\n\t// These files may be passed in by the parent process\n\tfilesString := os.Getenv(teleportFilesEnvVar)\n\tif filesString == \"\" {\n\t\treturn nil, nil\n\t}\n\n\tfiles, err := filesFromString(filesString)\n\tif err != nil {\n\t\treturn nil, trace.BadParameter(\"child process has failed to read files, error %q\", err)\n\t}\n\n\tif len(files) != 0 {\n\t\tlog.Infof(\"Child has been passed files: %v\", files)\n\t}\n\n\treturn files, nil\n}", "label": 5}
{"code": "function (match) {\n            var UNQUOTED = 1, QUOTED = 2;\n            if (match[UNQUOTED]) {\n                this._values.push(match[UNQUOTED]);\n            } else\n                /* if (match[QUOTED]) */\n                {\n                    this._values.push(this._unescapeQuoted(match[QUOTED]));\n                }\n        }", "label": 3}
{"code": "public static lbvserver_auditnslogpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_auditnslogpolicy_binding obj = new lbvserver_auditnslogpolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_auditnslogpolicy_binding response[] = (lbvserver_auditnslogpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def arrayuniqify(X, retainorder=False):\n    \"\"\"\n    Very fast uniqify routine for numpy arrays.\n\n    **Parameters**\n\n            **X** :  numpy array\n\n                    Determine the unique elements of this numpy array.\n\n            **retainorder** :  Boolean, optional\n\n                    Whether or not to return indices corresponding to unique \n                    values of `X` that also sort the values.  Default value is \n                    `False`, in which case `[D,s]` is returned.  This can be \n                    used to produce a uniqified version of `X` by simply \n                    taking::\n\n                            X[s][D]\n\n                    or::\n\n                            X[s[D.nonzero()[0]]]\n\n    **Returns**\n\n            **D** :  numpy array\n\n                    List of \"first differences\" in the sorted verion of `X`.  \n                    Returned when `retainorder` is `False` (default).\n\n            **s** :  numpy array\n\n                    Permutation that will sort `X`.  Returned when \n                    `retainorder` is `False` (default).\n\n            **ind** :  numpy array\n\n                    List of indices that correspond to unique values of `X`, \n                    without sorting those values.  Returned when `retainorder` \n                    is `True`.\n\n    **See Also:**\n\n            :func:`tabular.fast.recarrayuniqify`\n\n    \"\"\"\n    s = X.argsort()\n    X = X[s]\n    D = np.append([True],X[1:] != X[:-1])\n    if retainorder:\n        DD = np.append(D.nonzero()[0],len(X))\n        ind = [min(s[x:DD[i+1]]) for (i,x) in enumerate(DD[:-1])]\n        ind.sort()\n        return ind\n    else:\n        return [D,s]", "label": 1}
{"code": "protected function response(Response $response)\n    {\n        $content = $response->getContent();\n\n        if (is_string($content) &&\n            is_array(json_decode($content, true)) &&\n            json_last_error() === JSON_ERROR_NONE) {\n            return $this->contentWithinLimits($content)\n                    ? $this->hideParameters(json_decode($content, true), Telescope::$hiddenResponseParameters)\n                    : 'Purged By Telescope';\n        }\n\n        if ($response instanceof RedirectResponse) {\n            return 'Redirected to '.$response->getTargetUrl();\n        }\n\n        if ($response instanceof IlluminateResponse && $response->getOriginalContent() instanceof View) {\n            return [\n                'view' => $response->getOriginalContent()->getPath(),\n                'data' => $this->extractDataFromView($response->getOriginalContent()),\n            ];\n        }\n\n        return 'HTML Response';\n    }", "label": 2}
{"code": "def write_area_data(self, file):\n        \"\"\" Writes area data to file.\n        \"\"\"\n        file.write(\"%% area data\" + \"\\n\")\n        file.write(\"%\\tno.\\tprice_ref_bus\" + \"\\n\")\n        file.write(\"areas = [\" + \"\\n\")\n        # TODO: Implement areas\n        file.write(\"\\t1\\t1;\" + \"\\n\")\n\n        file.write(\"];\" + \"\\n\")", "label": 1}
{"code": "def write_how_many(self, file):\n        \"\"\" Writes component numbers to a table.\n        \"\"\"\n        report = CaseReport(self.case)\n\n        # Map component labels to attribute names\n        components = [(\"Bus\", \"n_buses\"), (\"Generator\", \"n_generators\"),\n            (\"Committed Generator\", \"n_online_generators\"),\n            (\"Load\", \"n_loads\"), (\"Fixed Load\", \"n_fixed_loads\"),\n            (\"Despatchable Load\", \"n_online_vloads\"), (\"Shunt\", \"n_shunts\"),\n            (\"Branch\", \"n_branches\"), (\"Transformer\", \"n_transformers\"),\n            (\"Inter-tie\", \"n_interties\"), (\"Area\", \"n_areas\")\n        ]\n\n        # Column 1 width\n        longest = max([len(c[0]) for c in components])\n\n        col1_header = \"Object\"\n        col1_width = longest\n        col2_header = \"Quantity\"\n        col2_width = len(col2_header)\n\n        # Row separator\n        sep = \"=\"*col1_width + \" \" + \"=\"*col2_width + \"\\n\"\n\n        # Row headers\n        file.write(sep)\n\n        file.write(col1_header.center(col1_width))\n        file.write(\" \")\n        file.write(\"%s\\n\" % col2_header.center(col2_width))\n\n        file.write(sep)\n\n        # Rows\n        for label, attr in components:\n            col2_value = str(getattr(report, attr))\n            file.write(\"%s %s\\n\" %\n                (label.ljust(col1_width), col2_value.rjust(col2_width)))\n        else:\n            file.write(sep)\n            file.write(\"\\n\")\n\n        del report", "label": 1}
{"code": "def id_to_fqname(self, uuid, type=None):\n        \"\"\"\n        Return fq_name and type for uuid\n\n        If `type` is provided check that uuid is actually\n        a resource of type `type`. Raise HttpError if it's\n        not the case.\n\n        :param uuid: resource uuid\n        :type uuid: UUIDv4 str\n        :param type: resource type\n        :type type: str\n\n        :rtype: dict {'type': str, 'fq_name': FQName}\n        :raises HttpError: uuid not found\n        \"\"\"\n        data = {\n            \"uuid\": uuid\n        }\n        result = self.post_json(self.make_url(\"/id-to-fqname\"), data)\n        result['fq_name'] = FQName(result['fq_name'])\n        if type is not None and not result['type'].replace('_', '-') == type:\n            raise HttpError('uuid %s not found for type %s' % (uuid, type), http_status=404)\n        return result", "label": 1}
{"code": "function (cb) {\n\t\t\to1._client.auth(function (err) {\n\t\t\t\tif (err && !(err instanceof Error)) {\n\t\t\t\t\terr = new Error(err.message || err);\n\t\t\t\t}\n\n\t\t\t\tif (!err) {\n\t\t\t\t\to1.config = {\n\t\t\t\t\t\tstorage : o1._client._serviceUrl\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t\tcb(err);\n\t\t\t});\n\t\t}", "label": 3}
{"code": "function closeConnection() {\n    expect(arguments).to.have.length(\n      0,\n      'Invalid arguments length when closing a connection in a MongoAdapter ' +\n      '(it has to be passed no arguments)'\n    );\n\n    return new Promise(function (resolve, reject) {\n      if (_databaseIsLocked) {\n        _databaseRequestQueue.push(function () {\n          closeConnection()\n            .then(resolve)\n            .catch(reject);\n        });\n      } else if (!_database) {\n        resolve();\n      } else {\n        _databaseIsLocked = true;\n        _database\n          .close()\n          .then(function () {\n            _database = null;\n            _databaseIsLocked = false;\n            resolve();\n            _processDatabaseRequestQueue();\n          })\n          .catch(function (error) {\n            _databaseIsLocked = false;\n            reject(error);\n            _processDatabaseRequestQueue();\n          });\n      }\n    });\n  }", "label": 3}
{"code": "def central_likelihood(self, axis):\n        \"\"\"Returns new histogram with all values replaced by their central likelihoods along axis.\"\"\"\n        result = self.cumulative_density(axis)\n        result.histogram = 1 - 2 * np.abs(result.histogram - 0.5)\n        return result", "label": 1}
{"code": "private function waitForNextAvailableSession()\n    {\n        $elapsedCycles = 0;\n\n        while (true) {\n            $session = $this->config['lock']->synchronize(function () use ($elapsedCycles) {\n                $item = $this->cacheItemPool->getItem($this->cacheKey);\n                $data = $item->get();\n                $session = $this->getSession($data);\n\n                if ($session) {\n                    $this->cacheItemPool->save($item->set($data));\n                    return $session;\n                }\n\n                if ($this->config['maxCyclesToWaitForSession'] <= $elapsedCycles) {\n                    $this->cacheItemPool->save($item->set($data));\n\n                    throw new \\RuntimeException(\n                        'A session did not become available in the allotted number of attempts.'\n                    );\n                }\n            });\n\n            if ($session && $this->handleSession($session)) {\n                return $session;\n            }\n\n            $elapsedCycles++;\n            usleep($this->config['sleepIntervalSeconds'] * 1000000);\n        }\n    }", "label": 2}
{"code": "def get_srid(queryset):\n    \"\"\"Returns the GeoQuerySet spatial reference identifier.\"\"\"\n    try:\n        srid = list(six.viewvalues(queryset.query.annotations))[0].srid\n    except (AttributeError, IndexError):\n        srid = None\n    return srid or geo_field(queryset).srid", "label": 1}
{"code": "def rev_regs(self) -> list:\n        \"\"\"\n        Return list of revocation registry identifiers for which HolderProver has tails files.\n\n        :return: list of revocation registry identifiers for which HolderProver has tails files\n        \"\"\"\n\n        LOGGER.debug('HolderProver.rev_regs >>>')\n\n        rv = [basename(f) for f in Tails.links(self._dir_tails)]\n        LOGGER.debug('HolderProver.rev_regs <<< %s', rv)\n        return rv", "label": 1}
{"code": "function( ajaxOptions, cache, el, fieldName, e ) {\r\n\r\n      var self = this;\r\n\r\n      $( this.tmp.parent ).addClass('validetta-pending');\r\n\r\n      // cache xhr\r\n      this.xhr[ fieldName ] = $.ajax( ajaxOptions )\r\n        .done( function( result ) {\r\n          if( typeof result !== 'object' ) result = JSON.parse( result );\r\n          cache.state = 'resolved';\r\n          cache.result = result;\r\n          if ( cache.event === 'submit' ) {\r\n            self.handler = false;\r\n            $( self.form ).trigger('submit');\r\n          }\r\n          else if( result.valid === false ) {\r\n            self.addErrorClass( self.tmp.parent );\r\n            self.window.open.call( self, el, result.message );\r\n          } else {\r\n            self.addValidClass( self.tmp.parent );\r\n          }\r\n        } )\r\n        .fail( function( jqXHR, textStatus ) {\r\n          if ( textStatus !== 'abort' ) { // Dont throw error if request is aborted\r\n            var _msg = 'Ajax request failed for field ('+ fieldName +') : '+ jqXHR.status +' '+ jqXHR.statusText;\r\n            cache.state = 'rejected';\r\n            cache.result = { valid : false, message : _msg };\r\n            throw new Error( _msg );\r\n          }\r\n        } )\r\n        .always( function( result ) { $( self.tmp.parent ).removeClass('validetta-pending'); } );\r\n\r\n      this.handler = 'pending';\r\n    }", "label": 3}
{"code": "function renameFunctionName(ast, oldName, newName) {\n  // Summary:\n  //  Rename the name of the function first found. Usually used by\n  //  flat function definition file.\n\n  let defNode = null;\n  // Find the definition node of the class\n  traverse(ast, {\n    FunctionDeclaration(path) {\n      if (path.node.id && path.node.id.name === oldName) {\n        defNode = path.node.id;\n      }\n    }\n  });\n\n  if (defNode) {\n    return identifier.renameIdentifier(ast, oldName, newName, defNode);\n  }\n  return [];\n}", "label": 3}
{"code": "public function setFullMatchingImages($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\WebDetection\\WebImage::class);\n        $this->full_matching_images = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response delete(nitro_service client, nd6 resource) throws Exception {\n\t\tnd6 deleteresource = new nd6();\n\t\tdeleteresource.neighbor = resource.neighbor;\n\t\tdeleteresource.vlan = resource.vlan;\n\t\tdeleteresource.td = resource.td;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "public function setFieldId($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\FieldId::class);\n        $this->field_id = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "protected function getHash($query, $criteria, ?array $orderBy = null, $limit = null, $offset = null)\n    {\n        [$params] = $criteria instanceof Criteria\n            ? $this->persister->expandCriteriaParameters($criteria)\n            : $this->persister->expandParameters($criteria);\n\n        return sha1($query . serialize($params) . serialize($orderBy) . $limit . $offset);\n    }", "label": 2}
{"code": "public static base_responses add(nitro_service client, dnsnsrec resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tdnsnsrec addresources[] = new dnsnsrec[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new dnsnsrec();\n\t\t\t\taddresources[i].domain = resources[i].domain;\n\t\t\t\taddresources[i].nameserver = resources[i].nameserver;\n\t\t\t\taddresources[i].ttl = resources[i].ttl;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function (key) {\n      if (key === undefined) {\n        that.push({\n          key: 'DOCUMENT' + sep + docId + sep,\n          lastPass: true\n        })\n        return end()\n      }\n      that.options.indexes.get(key, function (err, val) {\n        if (!err) {\n          that.push({\n            key: key,\n            value: val\n          })\n        }\n        pushValue(docFields[i++])\n      })\n    }", "label": 3}
{"code": "def _on_close(self, socket):\n        \"\"\"\n        Called when the connection was closed.\n        \"\"\"\n        self.logger.debug('Connection closed.')\n\n        for subscription in self.subscriptions.values():\n            if subscription.state == 'subscribed':\n                subscription.state = 'connection_pending'", "label": 1}
{"code": "protected function connection_open_ok($args)\n    {\n        $this->known_hosts = $args->read_shortstr();\n        $this->debug->debug_msg('Open OK! known_hosts: ' . $this->known_hosts);\n    }", "label": 2}
{"code": "protected function makeValidator(array $attributes)\n    {\n        $rules = array_only($this->getRules(), array_keys($attributes));\n\n        $validator = $this->validator->make($attributes, $rules, $this->getMessages());\n\n        $this->events->dispatch(\n            new Validating($this, $validator)\n        );\n\n        return $validator;\n    }", "label": 2}
{"code": "def [](cell_def)\n      sheet_name = cell_def.split('!')[0] if cell_def.match('!')\n      worksheet =  self.worksheets.select { |s| s.name == sheet_name }.first\n      raise ArgumentError, 'Unknown Sheet' unless sheet_name && worksheet.is_a?(Worksheet)\n      worksheet[cell_def.gsub(/.+!/,\"\")]\n    end", "label": 4}
{"code": "function () {\n\n      function draw(color, n) {\n        n = Math.max(parseInt(n), 0);\n\n        write(' ');\n        write('\\u001b[' + color + 'm' + n + '\\u001b[0m');\n        write('\\n');\n      }\n\n      draw(colors.green, this.passed);\n      draw(colors.fail, this.failed);\n      draw(colors.pending, this.pending + ' ');\n      write('\\n');\n\n      cursor.up(this.numberOfLines);\n    }", "label": 3}
{"code": "def getConnectorVersion(self):\n\t\t\"\"\"\n\t\tGET the current Connector version.\n\n\t\t:returns:  asyncResult object, populates error and result fields\n\t\t:rtype: asyncResult\n\t\t\"\"\"\n\t\tresult = asyncResult()\n\t\tdata = self._getURL(\"/\",versioned=False)\n\t\tresult.fill(data)\n\t\tif data.status_code == 200:\n\t\t\tresult.error = False\n\t\telse:\n\t\t\tresult.error = response_codes(\"get_mdc_version\",data.status_code)\n\t\tresult.is_done = True\n\t\treturn result", "label": 1}
{"code": "public String getAlias(String path)\r\n    {\r\n        if (m_allPathsAliased && m_attributePath.lastIndexOf(path) != -1)\r\n        {\r\n            return m_name;\r\n        }\r\n        Object retObj = m_mapping.get(path);\r\n        if (retObj != null)\r\n        {\r\n            return (String) retObj;\r\n        }\r\n        return null;\r\n    }", "label": 0}
{"code": "public static policymap get(nitro_service service, String mappolicyname) throws Exception{\n\t\tpolicymap obj = new policymap();\n\t\tobj.set_mappolicyname(mappolicyname);\n\t\tpolicymap response = (policymap) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (m *Manager) CounterInfoByKey(ctx context.Context) (map[int32]*types.PerfCounterInfo, error) {\n\tm.infoByKey.Lock()\n\tdefer m.infoByKey.Unlock()\n\n\tif m.infoByKey.m != nil {\n\t\treturn m.infoByKey.m, nil\n\t}\n\n\tinfo, err := m.CounterInfo(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tm.infoByKey.m = make(map[int32]*types.PerfCounterInfo)\n\n\tfor i := range info {\n\t\tc := &info[i]\n\n\t\tm.infoByKey.m[c.Key] = c\n\t}\n\n\treturn m.infoByKey.m, nil\n}", "label": 5}
{"code": "def compile!(view)\n        return if @compiled\n\n        # Templates can be used concurrently in threaded environments\n        # so compilation and any instance variable modification must\n        # be synchronized\n        @compile_mutex.synchronize do\n          # Any thread holding this lock will be compiling the template needed\n          # by the threads waiting. So re-check the @compiled flag to avoid\n          # re-compilation\n          return if @compiled\n\n          mod = view.compiled_method_container\n\n          instrument(\"!compile_template\") do\n            compile(mod)\n          end\n\n          @compiled = true\n        end\n      end", "label": 4}
{"code": "def cascadable_child?(kind, child, association)\n      return false if kind == :initialize || kind == :find || kind == :touch\n      return false if kind == :validate && association.validate?\n      child.callback_executable?(kind) ? child.in_callback_state?(kind) : false\n    end", "label": 4}
{"code": "def parse_response!\n      response.body = case @response_format\n        when :xml then Hash.from_xml response.body\n        when :json then JSON response.body\n      end if response.body\n    end", "label": 4}
{"code": "def save_rules(self, op_file):\n        \"\"\" \n        save the rules to file after web updates or program changes \n        \"\"\"\n        with open(op_file, 'w') as f:\n            for m in self.maps:\n                f.write(m.format_for_file_output())", "label": 1}
{"code": "def get_axis_bin_index(self, value, axis):\n        \"\"\"Returns index along axis of bin in histogram which contains value\n        Inclusive on both endpoints\n        \"\"\"\n        axis = self.get_axis_number(axis)\n        bin_edges = self.bin_edges[axis]\n        # The right bin edge of np.histogram is inclusive:\n        if value == bin_edges[-1]:\n            # Minus two: one for bin edges rather than centers, one for 0-based indexing\n            return len(bin_edges) - 2\n        # For all other bins, it is exclusive.\n        result = np.searchsorted(bin_edges, [value], side='right')[0] - 1\n        if not 0 <= result <= len(bin_edges) - 1:\n            raise CoordinateOutOfRangeException(\"Value %s is not in range (%s-%s) of axis %s\" % (\n                value, bin_edges[0], bin_edges[-1], axis))\n        return result", "label": 1}
{"code": "function _start()\n{\n  // first argument \u2013 runner function\n  var runner = arguments[0]\n    // take away first argument\n    , args   = Array.prototype.slice.call(arguments, 1)\n      // second argument - input data\n    , input  = args[0]\n      // last argument - result callback\n    , endCb  = streamify.callback.call(this, args[args.length - 1])\n    ;\n\n  args[args.length - 1] = endCb;\n  // third argument - iterator\n  args[1] = streamify.iterator.call(this, args[1]);\n\n  // allow time for proper setup\n  defer(function()\n  {\n    if (!this.destroyed)\n    {\n      this.terminator = runner.apply(null, args);\n    }\n    else\n    {\n      endCb(null, Array.isArray(input) ? [] : {});\n    }\n  }.bind(this));\n}", "label": 3}
{"code": "func (p *proxyServer) Count() int {\n\tp.Lock()\n\tdefer p.Unlock()\n\treturn p.count\n}", "label": 5}
{"code": "func (t *TextBar) SetCenter(s string, style tcell.Style) {\n\tt.initialize()\n\tif style == tcell.StyleDefault {\n\t\tstyle = t.style\n\t}\n\tt.center.SetText(s)\n\tt.center.SetStyle(style)\n}", "label": 5}
{"code": "def compile\n      parse\n\n      @fragments = re_raise_with_location { process(@sexp).flatten }\n      @fragments << fragment(\"\\n\", nil, s(:newline)) unless @fragments.last.code.end_with?(\"\\n\")\n\n      @result = @fragments.map(&:code).join('')\n    end", "label": 4}
{"code": "function assertArray(attr, data, type) {\n  if (data === null || data === undefined) {\n    return [];\n  }\n\n  if (!Array.isArray(data)) {\n    throw new ParseError(`Attribute ${attr} must be of type \"array\"`);\n  }\n\n  const clone = [];\n\n  for (const d of data) {\n    if (d !== undefined && d !== null) {\n      if (typeof d !== type) {\n        throw new ParseError(`Attribute ${attr} must contain only values of type \"${type}\"`);\n      }\n\n      clone.push(d);\n    }\n  }\n\n  return clone;\n}", "label": 3}
{"code": "func (proxy *ProxyClient) dialAuthServer(ctx context.Context, clusterName string) (net.Conn, error) {\n\tlog.Debugf(\"Client %v is connecting to auth server on cluster %q.\", proxy.clientAddr, clusterName)\n\n\taddress := \"@\" + clusterName\n\n\t// parse destination first:\n\tlocalAddr, err := utils.ParseAddr(\"tcp://\" + proxy.proxyAddress)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tfakeAddr, err := utils.ParseAddr(\"tcp://\" + address)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tproxySession, err := proxy.Client.NewSession()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tproxyWriter, err := proxySession.StdinPipe()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tproxyReader, err := proxySession.StdoutPipe()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tproxyErr, err := proxySession.StderrPipe()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\terr = proxySession.RequestSubsystem(\"proxy:\" + address)\n\tif err != nil {\n\t\t// read the stderr output from the failed SSH session and append\n\t\t// it to the end of our own message:\n\t\tserverErrorMsg, _ := ioutil.ReadAll(proxyErr)\n\t\treturn nil, trace.ConnectionProblem(err, \"failed connecting to node %v. %s\",\n\t\t\tnodeName(strings.Split(address, \"@\")[0]), serverErrorMsg)\n\t}\n\treturn utils.NewPipeNetConn(\n\t\tproxyReader,\n\t\tproxyWriter,\n\t\tproxySession,\n\t\tlocalAddr,\n\t\tfakeAddr,\n\t), nil\n}", "label": 5}
{"code": "func AddReturnRule(chain string) error {\n\tvar (\n\t\ttable = Filter\n\t\targs  = []string{\"-j\", \"RETURN\"}\n\t)\n\n\tif Exists(table, chain, args...) {\n\t\treturn nil\n\t}\n\n\terr := RawCombinedOutput(append([]string{\"-A\", chain}, args...)...)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to add return rule in %s chain: %s\", chain, err.Error())\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def render_resource_editor(version)\n      render partial: \"decidim/shared/version_author\",\n             locals: {\n               author: Decidim.traceability.version_editor(version)\n             }\n    end", "label": 4}
{"code": "def update_from(other)\n      @topic = other.topic\n      @name = other.name\n      @position = other.position\n      @topic = other.topic\n      @recipients = other.recipients\n      @bitrate = other.bitrate\n      @user_limit = other.user_limit\n      @permission_overwrites = other.permission_overwrites\n      @nsfw = other.nsfw\n      @parent_id = other.parent_id\n      @rate_limit_per_user = other.rate_limit_per_user\n    end", "label": 4}
{"code": "public static function migrate(CommandInterface $command, $prefix)\n    {\n        if ($arguments = $command->getArguments()) {\n            $arguments[2] = \"$prefix{$arguments[2]}\";\n            $command->setRawArguments($arguments);\n        }\n    }", "label": 2}
{"code": "func (a *CellView) Size() (int, int) {\n\t// We always return a minimum of two rows, and two columns.\n\tw, h := a.model.GetBounds()\n\t// Clip to a 2x2 minimum square; we can scroll within that.\n\tif w > 2 {\n\t\tw = 2\n\t}\n\tif h > 2 {\n\t\th = 2\n\t}\n\treturn w, h\n}", "label": 5}
{"code": "def fetch_events_async(issues)\n      i       = 0\n      threads = []\n\n      issues.each_slice(MAX_THREAD_NUMBER) do |issues_slice|\n        issues_slice.each do |issue|\n          threads << Thread.new do\n            issue[\"events\"] = []\n            iterate_pages(@client, \"issue_events\", issue[\"number\"]) do |new_event|\n              issue[\"events\"].concat(new_event)\n            end\n            issue[\"events\"] = issue[\"events\"].map { |event| stringify_keys_deep(event.to_hash) }\n            print_in_same_line(\"Fetching events for issues and PR: #{i + 1}/#{issues.count}\")\n            i += 1\n          end\n        end\n        threads.each(&:join)\n        threads = []\n      end\n\n      # to clear line from prev print\n      print_empty_line\n\n      Helper.log.info \"Fetching events for issues and PR: #{i}\"\n    end", "label": 4}
{"code": "func (a *HistoricalApi) clusterAggregations(request *restful.Request, response *restful.Response) {\n\tkey := core.HistoricalKey{ObjectType: core.MetricSetTypeCluster}\n\ta.processAggregationRequest(key, request, response)\n}", "label": 5}
{"code": "public void removeDescriptor(Object validKey)\r\n    {\r\n        PBKey pbKey;\r\n        if (validKey instanceof PBKey)\r\n        {\r\n            pbKey = (PBKey) validKey;\r\n        }\r\n        else if (validKey instanceof JdbcConnectionDescriptor)\r\n        {\r\n            pbKey = ((JdbcConnectionDescriptor) validKey).getPBKey();\r\n        }\r\n        else\r\n        {\r\n            throw new MetadataException(\"Could not remove descriptor, given object was no vaild key: \" +\r\n                    validKey);\r\n        }\r\n        Object removed = null;\r\n        synchronized (jcdMap)\r\n        {\r\n            removed = jcdMap.remove(pbKey);\r\n            jcdAliasToPBKeyMap.remove(pbKey.getAlias());\r\n        }\r\n        log.info(\"Remove descriptor: \" + removed);\r\n    }", "label": 0}
{"code": "def start\n      @stop_mutex.synchronize do\n        fail 'already stopped' if @stopped\n      end\n      until @workers.size == @size.to_i\n        new_worker_queue = Queue.new\n        @ready_workers << new_worker_queue\n        next_thread = Thread.new(new_worker_queue) do |jobs|\n          catch(:exit) do  # allows { throw :exit } to kill a thread\n            loop_execute_jobs(jobs)\n          end\n          remove_current_thread\n        end\n        @workers << next_thread\n      end\n    end", "label": 4}
{"code": "public function setLoadModule($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Trace\\V2\\Module::class);\n        $this->load_module = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def get(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a package.\n\n        :param id: Package ID as an int.\n        :return: :class:`packages.Package <packages.Package>` object\n        :rtype: packages.Package\n        \"\"\"\n        schema = PackageSchema()\n        resp = self.service.get_id(self.base, id)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "def points_distance(x1, y1, x2, y2)\n      Math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n    end", "label": 4}
{"code": "private void addDirectSubTypes(XClass type, ArrayList subTypes)\r\n    {\r\n        if (type.isInterface())\r\n        {\r\n            if (type.getExtendingInterfaces() != null)\r\n            {\r\n                subTypes.addAll(type.getExtendingInterfaces());\r\n            }\r\n            // we have to traverse the implementing classes as these array contains all classes that\r\n            // implement the interface, not only those who have an \"implement\" declaration\r\n            // note that for whatever reason the declared interfaces are not exported via the XClass interface\r\n            // so we have to get them via the underlying class which is hopefully a subclass of AbstractClass\r\n            if (type.getImplementingClasses() != null)\r\n            {\r\n                Collection declaredInterfaces = null;\r\n                XClass     subType;\r\n\r\n                for (Iterator it = type.getImplementingClasses().iterator(); it.hasNext(); )\r\n                {\r\n                    subType = (XClass)it.next();\r\n                    if (subType instanceof AbstractClass)\r\n                    {\r\n                        declaredInterfaces = ((AbstractClass)subType).getDeclaredInterfaces();\r\n                        if ((declaredInterfaces != null) && declaredInterfaces.contains(type))\r\n                        {\r\n                            subTypes.add(subType);\r\n                        }\r\n                    }\r\n                    else\r\n                    {\r\n                        // Otherwise we have to live with the bug\r\n                        subTypes.add(subType);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        else\r\n        {\r\n            subTypes.addAll(type.getDirectSubclasses());\r\n        }\r\n    }", "label": 0}
{"code": "func (m *MockMatcher) String() string {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"String\")\n\tret0, _ := ret[0].(string)\n\treturn ret0\n}", "label": 5}
{"code": "def resize(fname, basewidth, opFilename):\n    \"\"\" resize an image to basewidth \"\"\"\n    if basewidth == 0:\n        basewidth = 300\n    img = Image.open(fname)\n    wpercent = (basewidth/float(img.size[0]))\n    hsize = int((float(img.size[1])*float(wpercent)))\n    img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n    img.save(opFilename)", "label": 1}
{"code": "func (t *Torrent) name() string {\n\tt.nameMu.RLock()\n\tdefer t.nameMu.RUnlock()\n\tif t.haveInfo() {\n\t\treturn t.info.Name\n\t}\n\treturn t.displayName\n}", "label": 5}
{"code": "def loads(s: str, load_module: types.ModuleType, **kwargs):\n    \"\"\" Convert a JSON string into a JSGObject\n\n    :param s: string representation of JSON document\n    :param load_module: module that contains declarations for types\n    :param kwargs: arguments see: json.load for details\n    :return: JSGObject representing the json string\n    \"\"\"\n    return json.loads(s, object_hook=lambda pairs: loads_loader(load_module, pairs), **kwargs)", "label": 1}
{"code": "function () {\n\n\t\tSR.fs.close(l_logs[log_id].fd,\n\t\t\tfunction () {\n\t\t\t\tconsole.log(l_name + '::l_closeLog::' + SR.Tags.YELLOW + 'LogID=' + log_id + ' closed.' + SR.Tags.ERREND);\n\t\t\t\tdelete l_logs[log_id];\n\t\t\t\tonDone(log_id);\n\t\t\t}\n\t\t);\n\t}", "label": 3}
{"code": "public function setModel($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\AutoMl\\V1beta1\\Model::class);\n        $this->model = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static float[][] toFloat(int[][] array) {\n        float[][] n = new float[array.length][array[0].length];\n        for (int i = 0; i < array.length; i++) {\n            for (int j = 0; j < array[0].length; j++) {\n                n[i][j] = (float) array[i][j];\n            }\n        }\n        return n;\n    }", "label": 0}
{"code": "def encrypt_audio(header, buf)\n      raise 'No secret key found, despite encryption being enabled!' unless @secret_key\n\n      box = RbNaCl::SecretBox.new(@secret_key)\n\n      # The nonce is the header of the voice packet with 12 null bytes appended\n      nonce = header + ([0] * 12).pack('C*')\n\n      box.encrypt(nonce, buf)\n    end", "label": 4}
{"code": "def _l_skew_weight(self, donor_catchment):\n        \"\"\"\n        Return L-SKEW weighting for donor catchment.\n\n        Methodology source: Science Report SC050050, eqn. 6.19 and 6.22b\n        \"\"\"\n        try:\n            dist = donor_catchment.similarity_dist\n        except AttributeError:\n            dist = self._similarity_distance(self.catchment, donor_catchment)\n        b = 0.0219 * (1 - exp(-dist / 0.2360))\n        c = 0.2743 / (donor_catchment.record_length - 2)\n        return 1 / (b + c)", "label": 1}
{"code": "function setCSSProperty (styleObj, prop, val) {\n  var value;\n  var important = /^(.*)!(important)\\s*$/i.exec(val);\n  var propCamel = prefixProp(prop);\n  var propDash = prefixProp(prop, true);\n  if(important) {\n    value = important[1];\n    important = important[2];\n    if(styleObj.setProperty) styleObj.setProperty(propDash, value, important);\n    else {\n      // for old IE, cssText is writable, and below is valid for contain !important\n      // don't use styleObj.setAttribute since it's not set important\n      // should do: delete styleObj[propCamel], but not affect result\n\n      // only work on <= IE8: s.style['FONT-SIZE'] = '12px!important'\n      styleObj[propDash.toUpperCase()] = val;\n      // refresh cssText, the whole rule!\n      styleObj.cssText = styleObj.cssText;\n    }\n  } else {\n    styleObj[propCamel] = val;\n  }\n}", "label": 3}
{"code": "def run_cutadapt(job, fastqs, univ_options, cutadapt_options):\n    \"\"\"\n    This module runs cutadapt on the input RNA fastq files and then calls the RNA aligners.\n\n    ARGUMENTS\n    1. fastqs: Dict of list of input RNA-Seq fastqs\n         fastqs\n            +- 'tumor_rna': [<JSid for 1.fastq> , <JSid for 2.fastq>]\n    2. univ_options: Dict of universal arguments used by almost all tools\n         univ_options\n              +- 'dockerhub': <dockerhub to use>\n    3. cutadapt_options: Dict of parameters specific to cutadapt\n         cutadapt_options\n              |- 'a': <sequence of 3' adapter to trim from fwd read>\n              +- 'A': <sequence of 3' adapter to trim from rev read>\n    RETURN VALUES\n    1. output_files: Dict of cutadapted fastqs\n         output_files\n             |- 'rna_cutadapt_1.fastq': <JSid>\n             +- 'rna_cutadapt_2.fastq': <JSid>\n\n    This module corresponds to node 2 on the tree\n    \"\"\"\n    job.fileStore.logToMaster('Running cutadapt on %s' %univ_options['patient'])\n    work_dir = job.fileStore.getLocalTempDir()\n    fq_extn = '.gz' if fastqs['gzipped'] else ''\n    input_files = {\n        'rna_1.fastq' + fq_extn: fastqs['tumor_rna'][0],\n        'rna_2.fastq' + fq_extn: fastqs['tumor_rna'][1]}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    parameters = ['-a', cutadapt_options['a'],  # Fwd read 3' adapter\n                  '-A', cutadapt_options['A'],  # Rev read 3' adapter\n                  '-m', '35',  # Minimum size of read\n                  '-o', docker_path('rna_cutadapt_1.fastq'),  # Output for R1\n                  '-p', docker_path('rna_cutadapt_2.fastq'),  # Output for R2\n                  input_files['rna_1.fastq'],\n                  input_files['rna_2.fastq']]\n    docker_call(tool='cutadapt', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'])\n    output_files = defaultdict()\n    for fastq_file in ['rna_cutadapt_1.fastq', 'rna_cutadapt_2.fastq']:\n        output_files[fastq_file] = job.fileStore.writeGlobalFile('/'.join([work_dir, fastq_file]))\n    return output_files", "label": 1}
{"code": "public static base_response unset(nitro_service client, vridparam resource, String[] args) throws Exception{\n\t\tvridparam unsetresource = new vridparam();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "function returns(func, validator, message) {\n\tmessage = messageBuilder(message || 'vet/utils/returns error!');\n\n\treturn function _returnsInstance() {\n\t\tvar args = arguments;\n\t\tvar result = func.apply(this, arguments);\n\n\t\tif (validator(result)) {\n\t\t\treturn result;\n\t\t} else {\n\t\t\tthrow new Error(message.call(this, result));\n\t\t}\n\t};\n}", "label": 3}
{"code": "public final void begin() {\n    this.file = this.getAppender().getIoFile();\n    if (this.file == null) {\n      this.getAppender().getErrorHandler()\n          .error(\"Scavenger not started: missing log file name\");\n      return;\n    }\n    if (this.getProperties().getScavengeInterval() > -1) {\n      final Thread thread = new Thread(this, \"Log4J File Scavenger\");\n      thread.setDaemon(true);\n      thread.start();\n      this.threadRef = thread;\n    }\n  }", "label": 0}
{"code": "def lock(self):\n        \"\"\" Lock the candidate config. Requires ncclient.manager.Manager. \"\"\"\n        if isinstance(self._session, manager.Manager):\n            self._session.lock()", "label": 1}
{"code": "def unzip_data():\n    \"\"\"\n    Extract all files from downloaded FEH data zip file.\n    \"\"\"\n    with ZipFile(os.path.join(CACHE_FOLDER, CACHE_ZIP), 'r') as zf:\n        zf.extractall(path=CACHE_FOLDER)", "label": 1}
{"code": "private static boolean containsObject(Object searchFor, Object[] searchIn)\r\n    {\r\n        for (int i = 0; i < searchIn.length; i++)\r\n        {\r\n            if (searchFor == searchIn[i])\r\n            {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }", "label": 0}
{"code": "private void checkLocking(FieldDescriptorDef fieldDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        String jdbcType = fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_JDBC_TYPE);\r\n\r\n        if (!\"TIMESTAMP\".equals(jdbcType) && !\"INTEGER\".equals(jdbcType))\r\n        {\r\n            if (fieldDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_LOCKING, false))\r\n            {\r\n                throw new ConstraintException(\"The field \"+fieldDef.getName()+\" in class \"+fieldDef.getOwner().getName()+\" has locking set to true though it is not of TIMESTAMP or INTEGER type\");\r\n            }\r\n            if (fieldDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_UPDATE_LOCK, false))\r\n            {\r\n                throw new ConstraintException(\"The field \"+fieldDef.getName()+\" in class \"+fieldDef.getOwner().getName()+\" has update-lock set to true though it is not of TIMESTAMP or INTEGER type\");\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "func AuthPermissionsByContentTypeID(db XODB, contentTypeID float64) ([]*AuthPermission, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, name, content_type_id, codename ` +\n\t\t`FROM django.auth_permission ` +\n\t\t`WHERE content_type_id = :1`\n\n\t// run query\n\tXOLog(sqlstr, contentTypeID)\n\tq, err := db.Query(sqlstr, contentTypeID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*AuthPermission{}\n\tfor q.Next() {\n\t\tap := AuthPermission{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&ap.ID, &ap.Name, &ap.ContentTypeID, &ap.Codename)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ap)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def _advance_params(self):\n        \"\"\"\n        Explicitly generate new values for these parameters only\n        when appropriate.\n        \"\"\"\n        for p in ['x','y','direction']:\n            self.force_new_dynamic_value(p)\n        self.last_time = self.time_fn()", "label": 1}
{"code": "private org.apache.log4j.Logger getLogger()\r\n\t{\r\n        /*\r\n        Logger interface extends Serializable, thus Log field is\r\n        declared 'transient' and we have to null-check\r\n\t\t*/\r\n\t\tif (logger == null)\r\n\t\t{\r\n\t\t\tlogger = org.apache.log4j.Logger.getLogger(name);\r\n\t\t}\r\n\t\treturn logger;\r\n\t}", "label": 0}
{"code": "func Equal(u1 UUID, u2 UUID) bool {\n\treturn bytes.Equal(u1[:], u2[:])\n}", "label": 5}
{"code": "def _make_version(major, minor, micro, releaselevel, serial):\n    \"\"\"Create a readable version string from version_info tuple components.\"\"\"\n    assert releaselevel in ['alpha', 'beta', 'candidate', 'final']\n    version = \"%d.%d\" % (major, minor)\n    if micro:\n        version += \".%d\" % (micro,)\n    if releaselevel != 'final':\n        short = {'alpha': 'a', 'beta': 'b', 'candidate': 'rc'}[releaselevel]\n        version += \"%s%d\" % (short, serial)\n    return version", "label": 1}
{"code": "function (dirs, done) {\n    var self = this;\n    utils.findExtensions(dirs, function (err, extensions) {\n      if (err) return done(err);\n\n      for (var i = 0; i < extensions.length; i++) {\n        extensions[i].type = extensions[i].type || 'basic';\n        extensions[i].id = extensions[i].id.toLowerCase();\n        if (RESERVED.indexOf(extensions[i].id) !== -1) {\n          return done(new Error('Extension id \"' + extensions[i].id + '\" is reserved. Your plugins are misconfigured.'));\n        }\n        if (self.ids[extensions[i].id]) {\n          // XXX should we die hard, ignore, or warn?\n          return done(new Error('Duplicate extension id! Your plugins are misconfigured.'));\n        }\n        self.ids[extensions[i].id] = true;\n        self.extensions[extensions[i].type][extensions[i].id] = extensions[i];\n      }\n      done();\n    });\n  }", "label": 3}
{"code": "public function fetchParametersAsync(): \\Generator\n    {\n        $refetchable = $this->isRefetchable();\n        if ($this->fetched && !$refetchable) {\n            return $this->params;\n        }\n        $params = yield call([$this, 'getParameters']);\n\n        if (!$refetchable) {\n            $this->params = $params;\n        }\n\n        return $params;\n    }", "label": 2}
{"code": "public function subscribersByTopic(string $topic)\n    {\n        $key = self::TOPIC_KEY.\".{$topic}\";\n\n        if (! $this->cache->has($key)) {\n            return new Collection;\n        }\n\n        $channels = json_decode($this->cache->get($key), true);\n\n        return (new Collection($channels))\n            ->map(function (string $channel): ?Subscriber {\n                return $this->subscriberByChannel($channel);\n            })\n            ->filter()\n            ->values();\n    }", "label": 2}
{"code": "private function entryPointDescription($entryPoint)\n    {\n        switch ($entryPoint->type) {\n            case EntryType::REQUEST:\n                return $entryPoint->content['method'].' '.$entryPoint->content['uri'];\n\n            case EntryType::JOB:\n                return $entryPoint->content['name'];\n\n            case EntryType::COMMAND:\n                return $entryPoint->content['command'];\n        }\n\n        return '';\n    }", "label": 2}
{"code": "function _addRouteRecord(route, parent, exclude = false, ancestors = []) {\n    const { path, name, handler } = route;\n    const finalPath = _normalizePath(path, parent, ancestors);\n\n    // Push path into ancestors array\n    ancestors.push(path);\n\n    const record = {\n        name,\n        parent,\n        handler,\n        path: finalPath,\n        regex: PathToRegexp(finalPath),\n        // redirect, TODO: Look into redirect functionality further\n        before: route.before,\n        init: route.init,\n        update: route.update,\n        after: route.after,\n        unload: route.unload,\n        pop: route.pop,\n        meta: route.meta || {},\n    };\n\n    // Children should be mapped before parent in case of wildcard in parent\n    if (route.children && route.children.length) {\n        let i = 0;\n        const length = route.children.length;\n\n        for (; i < length; i++) {\n            _addRouteRecord(route.children[i], route, exclude, ancestors);\n\n            // After record is added, pop last ancestor off for the next set of paths\n            ancestors.pop();\n        }\n    }\n\n    // Exclude from main mapping/return created route record object\n    if (exclude) {\n        return record;\n    }\n\n    if (! pathMap[record.path]) {\n        pathList.push(record.path);\n        pathMap[record.path] = record;\n    }\n\n    if (name && ! nameMap[name]) {\n        nameMap[name] = record;\n    }\n}", "label": 3}
{"code": "def []=(key, value)\n      @cache[key] = value\n      return unless disk_cache_enabled?\n\n      path = path_to(hash(key))\n      value = new Hash(value) if value.is_a?(Hash) && !value.default.nil?\n      dump(path, value)\n    rescue TypeError\n      Jekyll.logger.debug \"Cache:\", \"Cannot dump object #{key}\"\n    end", "label": 4}
{"code": "def create(cls, community, record, user=None, expires_at=None,\n               notify=True):\n        \"\"\"Create a record inclusion request to a community.\n\n        :param community: Community object.\n        :param record: Record API object.\n        :param expires_at: Time after which the request expires and shouldn't\n            be resolved anymore.\n        \"\"\"\n        if expires_at and expires_at < datetime.utcnow():\n            raise InclusionRequestExpiryTimeError(\n                community=community, record=record)\n\n        if community.has_record(record):\n            raise InclusionRequestObsoleteError(\n                community=community, record=record)\n\n        try:\n            # Create inclusion request\n            with db.session.begin_nested():\n                obj = cls(\n                    id_community=community.id,\n                    id_record=record.id,\n                    user=user,\n                    expires_at=expires_at\n                )\n                db.session.add(obj)\n        except (IntegrityError, FlushError):\n            raise InclusionRequestExistsError(\n                community=community, record=record)\n\n        # Send signal\n        inclusion_request_created.send(\n            current_app._get_current_object(),\n            request=obj,\n            notify=notify\n        )\n\n        return obj", "label": 1}
{"code": "function generateBKP (pkp) {\n  const buffer = new Buffer(pkp, 'base64')\n  const hash = crypto.createHash('sha1')\n  hash.update(buffer)\n  const sha1str = hash.digest('hex').toUpperCase()\n  return sha1str.match(/(.{1,8})/g).join('-')\n}", "label": 3}
{"code": "public static base_response delete(nitro_service client, String sitename) throws Exception {\n\t\tgslbsite deleteresource = new gslbsite();\n\t\tdeleteresource.sitename = sitename;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "public function handleEnd($conn) {\n        try {\n            $this->app->onClose($conn->decor);\n        } catch (\\Exception $e) {\n            $this->handleError($e, $conn);\n        }\n\n        unset($conn->decor);\n    }", "label": 2}
{"code": "async def create_cred_req(self, cred_offer_json: str, cd_id: str) -> (str, str):\n        \"\"\"\n        Create credential request as HolderProver and store in wallet; return credential json and metadata json.\n\n        Raise AbsentLinkSecret if link secret not set.\n\n        :param cred_offer_json: credential offer json\n        :param cd_id: credential definition identifier\n        :return: cred request json and corresponding metadata json as created and stored in wallet\n        \"\"\"\n\n        LOGGER.debug('HolderProver.create_cred_req >>> cred_offer_json: %s, cd_id: %s', cred_offer_json, cd_id)\n\n        self._assert_link_secret('create_cred_req')\n\n        # Check that ledger has schema on ledger where cred def expects - in case of pool reset with extant wallet\n        cred_def_json = await self.get_cred_def(cd_id)\n        schema_seq_no = int(json.loads(cred_def_json)['schemaId'])\n        schema_json = await self.get_schema(schema_seq_no)\n        schema = json.loads(schema_json)\n        if not schema:\n            LOGGER.debug(\n                'HolderProver.create_cred_req: <!< absent schema@#%s, cred req may be for another ledger',\n                schema_seq_no)\n            raise AbsentSchema('Absent schema@#{}, cred req may be for another ledger'.format(schema_seq_no))\n        (cred_req_json, cred_req_metadata_json) = await anoncreds.prover_create_credential_req(\n            self.wallet.handle,\n            self.did,\n            cred_offer_json,\n            cred_def_json,\n            self._link_secret)\n        rv = (cred_req_json, cred_req_metadata_json)\n\n        LOGGER.debug('HolderProver.create_cred_req <<< %s', rv)\n        return rv", "label": 1}
{"code": "public static cmppolicylabel_cmppolicy_binding[] get(nitro_service service, String labelname) throws Exception{\n\t\tcmppolicylabel_cmppolicy_binding obj = new cmppolicylabel_cmppolicy_binding();\n\t\tobj.set_labelname(labelname);\n\t\tcmppolicylabel_cmppolicy_binding response[] = (cmppolicylabel_cmppolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (parameters) {\r\n        parameters = parameters || {};\r\n        if (parameters.logger) {\r\n            this.logger = parameters.logger;\r\n        } else {\r\n            /*eslint-disable no-console*/\r\n            var doLog = function () {\r\n                console.log.apply(console, arguments);\r\n            };\r\n            this.logger = {\r\n                debug: doLog,\r\n                log: doLog,\r\n                info: doLog,\r\n                warn: doLog,\r\n                error: doLog\r\n            };\r\n            console.warn('Since v1.3.0 ExecutorClient requires a logger, falling back on console.log.');\r\n            /*eslint-enable no-console*/\r\n        }\r\n\r\n        this.logger.debug('ctor', {metadata: parameters});\r\n\r\n        this.isNodeJS = (typeof window === 'undefined') && (typeof process === 'object');\r\n        this.isNodeWebkit = (typeof window === 'object') && (typeof process === 'object');\r\n        //console.log(isNode);\r\n        if (this.isNodeJS) {\r\n            this.logger.debug('Running under node');\r\n            this.server = '127.0.0.1';\r\n            this.httpsecure = false;\r\n        }\r\n\r\n        this.server = parameters.server || this.server;\r\n        this.serverPort = parameters.serverPort || this.serverPort;\r\n        this.httpsecure = (parameters.httpsecure !== undefined) ? parameters.httpsecure : this.httpsecure;\r\n        if (this.isNodeJS) {\r\n            this.http = this.httpsecure ? require('https') : require('http');\r\n        }\r\n\r\n        this.origin = '';\r\n        if (this.httpsecure !== undefined && this.server && this.serverPort) {\r\n            this.origin = (this.httpsecure ? 'https://' : 'http://') + this.server + ':' + this.serverPort;\r\n        }\r\n        if (parameters && typeof parameters.relativeUrl === 'string') {\r\n            this.relativeUrl = parameters.relativeUrl;\r\n        } else if (typeof WebGMEGlobal !== 'undefined' && WebGMEGlobal.gmeConfig &&\r\n            typeof WebGMEGlobal.gmeConfig.client.mountedPath === 'string') {\r\n            this.relativeUrl = WebGMEGlobal.gmeConfig.client.mountedPath + '/rest/executor/';\r\n        } else {\r\n            this.relativeUrl = '/rest/executor/';\r\n        }\r\n        this.executorUrl = this.origin + this.relativeUrl;\r\n\r\n        // TODO: TOKEN???\r\n        // TODO: any ways to ask for this or get it from the configuration?\r\n        if (parameters.executorNonce) {\r\n            this.executorNonce = parameters.executorNonce;\r\n        }\r\n\r\n        this.logger.debug('origin', this.origin);\r\n        this.logger.debug('executorUrl', this.executorUrl);\r\n    }", "label": 3}
{"code": "def remove filename\n      return false unless source_hash.key?(filename)\n      source_hash.delete filename\n      true\n    end", "label": 4}
{"code": "public static boolean isSuccess(JsonRtn jsonRtn) {\n        if (jsonRtn == null) {\n            return false;\n        }\n\n        String errCode = jsonRtn.getErrCode();\n        if (StringUtils.isEmpty(errCode) || StringUtils.equals(WECHAT_JSON_RTN_SUCCESS_CODE, errCode)) {\n            return true;\n        }\n\n        return false;\n    }", "label": 0}
{"code": "private void handleMultiInstanceEncapResponse(\r\n\t\t\tSerialMessage serialMessage, int offset) {\r\n\t\tlogger.trace(\"Process Multi-instance Encapsulation\");\r\n\t\tint instance = serialMessage.getMessagePayloadByte(offset);\r\n\t\tint commandClassCode = serialMessage.getMessagePayloadByte(offset + 1);\r\n\t\tCommandClass commandClass = CommandClass.getCommandClass(commandClassCode);\r\n\r\n\t\tif (commandClass == null) {\r\n\t\t\tlogger.error(String.format(\"Unsupported command class 0x%02x\", commandClassCode));\r\n\t\t\treturn;\r\n\t\t}\r\n\t\t\r\n\t\tlogger.debug(String.format(\"Node %d Requested Command Class = %s (0x%02x)\", this.getNode().getNodeId(), commandClass.getLabel() , commandClassCode));\r\n\t\tZWaveCommandClass zwaveCommandClass = this.getNode().getCommandClass(commandClass);\r\n\t\t\r\n\t\tif (zwaveCommandClass == null) {\r\n\t\t\tlogger.error(String.format(\"Unsupported command class %s (0x%02x)\", commandClass.getLabel(), commandClassCode));\r\n\t\t\treturn;\r\n\t\t}\r\n\t\t\r\n\t\tlogger.debug(String.format(\"Node %d, Instance = %d, calling handleApplicationCommandRequest.\", this.getNode().getNodeId(), instance));\r\n\t\tzwaveCommandClass.handleApplicationCommandRequest(serialMessage, offset+ 3, instance);\r\n\t}", "label": 0}
{"code": "func (f *file) lintVarDecls() {\n\tvar lastGen *ast.GenDecl // last GenDecl entered.\n\n\tf.walk(func(node ast.Node) bool {\n\t\tswitch v := node.(type) {\n\t\tcase *ast.GenDecl:\n\t\t\tif v.Tok != token.CONST && v.Tok != token.VAR {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tlastGen = v\n\t\t\treturn true\n\t\tcase *ast.ValueSpec:\n\t\t\tif lastGen.Tok == token.CONST {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif len(v.Names) > 1 || v.Type == nil || len(v.Values) == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\trhs := v.Values[0]\n\t\t\t// An underscore var appears in a common idiom for compile-time interface satisfaction,\n\t\t\t// as in \"var _ Interface = (*Concrete)(nil)\".\n\t\t\tif isIdent(v.Names[0], \"_\") {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t// If the RHS is a zero value, suggest dropping it.\n\t\t\tzero := false\n\t\t\tif lit, ok := rhs.(*ast.BasicLit); ok {\n\t\t\t\tzero = zeroLiteral[lit.Value]\n\t\t\t} else if isIdent(rhs, \"nil\") {\n\t\t\t\tzero = true\n\t\t\t}\n\t\t\tif zero {\n\t\t\t\tf.errorf(rhs, 0.9, category(\"zero-value\"), \"should drop = %s from declaration of var %s; it is the zero value\", f.render(rhs), v.Names[0])\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tlhsTyp := f.pkg.typeOf(v.Type)\n\t\t\trhsTyp := f.pkg.typeOf(rhs)\n\n\t\t\tif !validType(lhsTyp) || !validType(rhsTyp) {\n\t\t\t\t// Type checking failed (often due to missing imports).\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\tif !types.Identical(lhsTyp, rhsTyp) {\n\t\t\t\t// Assignment to a different type is not redundant.\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\t// The next three conditions are for suppressing the warning in situations\n\t\t\t// where we were unable to typecheck.\n\n\t\t\t// If the LHS type is an interface, don't warn, since it is probably a\n\t\t\t// concrete type on the RHS. Note that our feeble lexical check here\n\t\t\t// will only pick up interface{} and other literal interface types;\n\t\t\t// that covers most of the cases we care to exclude right now.\n\t\t\tif _, ok := v.Type.(*ast.InterfaceType); ok {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t// If the RHS is an untyped const, only warn if the LHS type is its default type.\n\t\t\tif defType, ok := f.isUntypedConst(rhs); ok && !isIdent(v.Type, defType) {\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\tf.errorf(v.Type, 0.8, category(\"type-inference\"), \"should omit type %s from declaration of var %s; it will be inferred from the right-hand side\", f.render(v.Type), v.Names[0])\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t})\n}", "label": 5}
{"code": "function parseOptions(options) {\n  let separator\n  let transformer\n\n  if (2 === options.length) {\n    [separator, transformer] = options\n    if (defaultTransformers[transformer]) {\n      transformer = defaultTransformers[transformer] /* Don't validate */\n      validate({ separator })\n    } else {\n      validate({ separator, transformer })\n    }\n  } else if (1 === options.length) {\n    const option = options[0]\n    if (false === option || 'function' === typeof option) {\n      transformer = option /* Don't validate */\n    } else if (defaultTransformers[option]) {\n      transformer = defaultTransformers[option] /* Don't validate */\n    } else {\n      separator = option\n      validate({ separator })\n    }\n  }\n\n  return { separator, transformer }\n}", "label": 3}
{"code": "func RemoveFromSlice(slice []string, values ...string) []string {\n\toutput := make([]string, 0, len(slice))\n\n\tremove := make(map[string]bool)\n\tfor _, value := range values {\n\t\tremove[value] = true\n\t}\n\n\tfor _, s := range slice {\n\t\t_, ok := remove[s]\n\t\tif ok {\n\t\t\tcontinue\n\t\t}\n\t\toutput = append(output, s)\n\t}\n\n\treturn output\n}", "label": 5}
{"code": "def stock2one(stock):\n    \"\"\"\n    convert stockholm to single line format\n    \"\"\"\n    lines = {}\n    for line in stock:\n        line = line.strip()\n        if print_line(line) is True:\n            yield line\n            continue\n        if line.startswith('//'):\n            continue\n        ID, seq = line.rsplit(' ', 1)\n        if ID not in lines:\n            lines[ID] = ''\n        else:\n            # remove preceding white space\n            seq = seq.strip()\n        lines[ID] += seq\n    for ID, line in lines.items():\n        yield '\\t'.join([ID, line])\n    yield '\\n//'", "label": 1}
{"code": "def _none_subst(self, *args):\n        \"\"\" Helper function to insert full ranges for |None| for X_iter methods.\n\n        Custom method, specifically tailored, taking in the arguments from\n        an X_iter method and performing the replacement of |None| after\n        error-checking the arguments for a max of one |None| value, and ensuring\n        that if a |None| is present, no other non-|str| iterables are present.\n\n        Parameters\n        ----------\n        args : 3-5 arguments of |int| or iterable |int|, or |None|\n            First argument is always the indices for the geometries; all\n            following are for the atoms in sequence as required for the\n            particular :samp:`{x}_iter` method\n\n        Returns\n        -------\n        arglist     : 3-5 arguments, matching input params\n            Argument list, with |None| substituted if validly present\n\n        Raises\n        ------\n        ~exceptions.ValueError  : If more than one |None| argument is present\n\n        ~exceptions.ValueError  : If an arg is non-|str| iterable when one\n        |None| is present\n        \"\"\"\n\n        # Imports\n        import numpy as np\n\n        # Initialize argument list return value, and as None not found\n        arglist = [a for a in args]\n        none_found = False\n\n        # Check for None values\n        none_vals = list(map(lambda e: isinstance(e, type(None)), arglist))\n\n        # Error if more than one None; handle if exactly one; pass through if\n        #  none.\n        if np.count_nonzero(none_vals) > 1:\n            raise ValueError(\n                    \"Multiple 'None' values [indices {0}] not supported\"\n                    .format(tuple(np.nonzero(none_vals)[0])))\n        elif np.count_nonzero(none_vals) == 1:\n            # Must be no iterables that are not strings. Thus, an element-wise\n            #  test for iterability and an element-wise test for stringiness\n            #  must give matching arrays\n            if not all(np.equal(list(map(np.iterable, arglist)),\n                        list(map(lambda e: isinstance(e, str), arglist)))):\n                raise ValueError(\n                        \"'None' as parameter invalid with non-str iterables\")\n            ## end if\n\n            # Parameters okay; replace the None with the appropriate range()\n            none_found = True\n            none_loc = np.nonzero(none_vals)[0][0]\n            arglist[none_loc] = \\\n                    range(self.num_geoms if none_loc == 0 else self.num_atoms)\n        ## end if\n\n        # Return the arguments list and the none-found value\n        return arglist", "label": 1}
{"code": "function copyFilesToPack(grunt, buildPath, filesToPack) {\n\treturn function(callback) {\n\t\tgrunt.util.async.forEach(filesToPack, function(fileConfig, callback) {\n\t\t\ttry {\n\t\t\t\tvar filepathDest;\n\t\t\t\tif (detectDestType(grunt, fileConfig.dest) === 'directory') {\n\t\t\t\t\tvar dest = (fileConfig.orig.expand) ? fileConfig.dest : path.join(fileConfig.dest, fileConfig.src);\n\t\t\t\t\tfilepathDest = path.join(buildPath, dest);\n\t\t\t\t} else {\n\t\t\t\t\tfilepathDest = path.join(buildPath, fileConfig.dest);\n\t\t\t\t}\n\n\t\t\t\tif (grunt.file.isDir(fileConfig.src)) {\n\t\t\t\t\tif (fileConfig.directory) {\n\t\t\t\t\t\t// Copy a whole folder to the destination directory.\n\t\t\t\t\t\tgrunt.verbose.writeln('Copying folder \"' + fileConfig.src + '\" to \"' + filepathDest + '\"');\n\t\t\t\t\t\tfs.copyRecursive(fileConfig.src, filepathDest, callback);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Create a folder inside the destination directory.\n\t\t\t\t\t\tgrunt.verbose.writeln('Creating folder \"' + filepathDest + '\"');\n\t\t\t\t\t\tfs.mkdirs(filepathDest, callback);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// Copy a file to the destination directory inside the tmp folder.\n\t\t\t\t\tif (fileConfig.link) {\n\t\t\t\t\t\tgrunt.verbose.writeln('Copying symlink \"' + fileConfig.src + '->' + fileConfig.link + '\" to \"' + filepathDest + '\"');\n\t\t\t\t\t\t//ensure the parent directory exists when making symlinks\n\t\t\t\t\t\tfs.mkdirs(getDirName(filepathDest), function(err) {\n\t\t\t\t\t\t\tif (err) throw err;\n\t\t\t\t\t\t\t_fs.symlink(fileConfig.link, filepathDest, 'file', callback);\n\t\t\t\t\t\t});\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tgrunt.verbose.writeln('Copying file \"' + fileConfig.src + '\" to \"' + filepathDest + '\"');\n\t\t\t\t\t\tgrunt.file.copy(fileConfig.src, filepathDest);\n\t\t\t\t\t\tfs.lstat(fileConfig.src, function(err, stat) {\n\t\t\t\t\t\t\tif (err) throw err;\n\t\t\t\t\t\t\t_fs.chmod(filepathDest, stat.mode, callback);\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t} catch(e) {\n\t\t\t\tcallback(e);\n\t\t\t}\n\t\t}, callback);\n\t};\n}", "label": 3}
{"code": "def site\n      (self.scheme || self.authority) && @site ||= begin\n        site_string = \"\".dup\n        site_string << \"#{self.scheme}:\" if self.scheme != nil\n        site_string << \"//#{self.authority}\" if self.authority != nil\n        site_string\n      end\n    end", "label": 4}
{"code": "def get_by_name(self, name):\n        \"\"\" returns an object Project which matches name \"\"\"\n        for p in self.project_list:\n            if p.nme == name:\n                return p\n        return None", "label": 1}
{"code": "public static responderaction[] get(nitro_service service) throws Exception{\n\t\tresponderaction obj = new responderaction();\n\t\tresponderaction[] response = (responderaction[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function(req, res) {\n    var params = URL.parse(req.url, true).query;\n    var oauth2_server_id = params.provider || this.config.default_server;\n    var next_url = this.nexturl_query(req, params);\n    this.redirects_for_login(oauth2_server_id, res, next_url);\n  }", "label": 3}
{"code": "public function setDesiredAddonsConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\AddonsConfig::class);\n        $this->desired_addons_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def to_xml_string(str = '')\n      str << \"<filters #{serialized_attributes}>\"\n      filter_items.each {  |filter| filter.to_xml_string(str) }\n      date_group_items.each { |date_group_item| date_group_item.to_xml_string(str) }\n      str << '</filters>'\n    end", "label": 4}
{"code": "function addQueryToUrl ({ query, decamelizeQuery=true, url }) {\n  if (!query) return\n  const transformedQuery = decamelizeQuery ? decamelizeKeys(query) : query\n  return {\n    url: url + '?' + stringify(transformedQuery)\n  }\n}", "label": 3}
{"code": "function getInitialModel(routeInfo, page) {\n    var initModelDeps = {\n        appName:    routeInfo.appName,\n        tokens:     routeInfo.tokens,\n        routeInfo:  routeInfo,\n        defaults:   page.defaults,\n        activeUser: routeInfo.activeUser || {},\n        currentScope: {}\n    };\n\n    // if no model, just return empty object\n    if (!page.model) {\n        return Q.when({});\n    }\n    // if function, inject and the returned value is the model\n    else if (_.isFunction(page.model)) {\n        return Q.when(injector.loadModule(page.model, null, { dependencies: initModelDeps }));\n    }\n    else {\n        throw new Error(routeInfo.name + ' page invalid model() format: ' + page.model);\n    }\n}", "label": 3}
{"code": "def _op(self, operation, other, *allowed):\n\t\t\"\"\"A basic operation operating on a single value.\"\"\"\n\t\t\n\t\tf = self._field\n\t\t\n\t\tif self._combining:  # We are a field-compound query fragment, e.g. (Foo.bar & Foo.baz).\n\t\t\treturn reduce(self._combining,\n\t\t\t\t\t(q._op(operation, other, *allowed) for q in f))  # pylint:disable=protected-access\n\t\t\n\t\t# Optimize this away in production; diagnosic aide.\n\t\tif __debug__ and _complex_safety_check(f, {operation} | set(allowed)):  # pragma: no cover\n\t\t\traise NotImplementedError(\"{self!r} does not allow {op} comparison.\".format(self=self, op=operation))\n\t\t\n\t\tif other is not None:\n\t\t\tother = f.transformer.foreign(other, (f, self._document))\n\t\t\n\t\treturn Filter({self._name: {operation: other}})", "label": 1}
{"code": "def c_singleton src, options = {}\n      options = {\n        :expand_types => true,\n        :singleton    => true,\n      }.merge options\n      self.generate src, options\n    end", "label": 4}
{"code": "protected function tcpStreamInitializer(ParametersInterface $parameters)\n    {\n        if (!filter_var($parameters->host, FILTER_VALIDATE_IP, FILTER_FLAG_IPV6)) {\n            $address = \"tcp://$parameters->host:$parameters->port\";\n        } else {\n            $address = \"tcp://[$parameters->host]:$parameters->port\";\n        }\n\n        $flags = STREAM_CLIENT_CONNECT;\n\n        if (isset($parameters->async_connect) && $parameters->async_connect) {\n            $flags |= STREAM_CLIENT_ASYNC_CONNECT;\n        }\n\n        if (isset($parameters->persistent)) {\n            if (false !== $persistent = filter_var($parameters->persistent, FILTER_VALIDATE_BOOLEAN, FILTER_NULL_ON_FAILURE)) {\n                $flags |= STREAM_CLIENT_PERSISTENT;\n\n                if ($persistent === null) {\n                    $address = \"{$address}/{$parameters->persistent}\";\n                }\n            }\n        }\n\n        $resource = $this->createStreamSocket($parameters, $address, $flags);\n\n        return $resource;\n    }", "label": 2}
{"code": "protected <T> T fromJsonString(String json, Class<T> clazz) {\n\t\treturn _gsonParser.fromJson(json, clazz);\n\t}", "label": 0}
{"code": "function yo(generator, options, cwd) {\n  const yeoman = require('yeoman-environment');\n  // call yo internally\n  const yeomanEnv = yeoman.createEnv([], {cwd, env}, quiet ? createQuietTerminalAdapter() : undefined);\n  yeomanEnv.register(require.resolve('generator-phovea/generators/' + generator), 'phovea:' + generator);\n  return new Promise((resolve, reject) => {\n    try {\n      console.log(cwd, chalk.blue('running yo phovea:' + generator));\n      yeomanEnv.run('phovea:' + generator, options, resolve);\n    } catch (e) {\n      console.error('error', e, e.stack);\n      reject(e);\n    }\n  });\n}", "label": 3}
{"code": "function (objPrototype) {\n                var me = this,\n                    statics = _gpfA.AttrConstraintAttribute,\n                    originalAlterPrototype = statics.originalAlterPrototype,\n                    attributes = new _gpfA.Map(me);\n                // Get constraints set for THIS attribute\n                attributes.filter(_gpfAttrConstraint).forEach(function (constraintAttributes) {\n                    constraintAttributes.forEach(function (attribute) {\n                        attribute._check(me, objPrototype);\n                    });\n                });\n                // OK, call _alterPrototype\n                me[originalAlterPrototype](objPrototype);\n            }", "label": 3}
{"code": "function error() {\n    var _console3;\n\n    if (LatticeLogs.failFast(LatticeLogs.ERROR)) return;\n\n    for (var _len5 = arguments.length, args = new Array(_len5), _key5 = 0; _key5 < _len5; _key5++) {\n      args[_key5] = arguments[_key5];\n    }\n\n    (_console3 = console).error.apply(_console3, (0, _toConsumableArray2.default)(args.map(LatticeLogs.argMapper)));\n  }", "label": 3}
{"code": "def register(self, name, content, description=None):\n        \"\"\"\n        Register a new document.\n\n        :param content: Content of this document. Jinja and rst are supported.\n        :type content: str\n        :param name: Unique name of the document for documentation purposes.\n        :param description: Short description of this document\n        \"\"\"\n        return self.__app.documents.register(name, content, self._plugin, description)", "label": 1}
{"code": "def unbind_redundant_bindings(queue, routing_keys)\n      return unless http_api_use_enabled?\n\n      bindings.each do |dest, keys|\n        next unless dest == queue.name\n        keys.reject { |key| routing_keys.include?(key) }.each do |key|\n          logger.debug \"removing redundant binding #{queue.name} <--> #{key}\"\n          queue.unbind(exchange, routing_key: key)\n        end\n      end\n    end", "label": 4}
{"code": "func Stage1ManifestPath(root string) string {\n\treturn filepath.Join(Stage1ImagePath(root), aci.ManifestFile)\n}", "label": 5}
{"code": "def register_service_functions(self, *funcs):\n        \"\"\"\n            Register function in the system namespace. Called by Services.\n        \"\"\"\n        for func in funcs:\n            self.namespace[func.__name__] = func", "label": 1}
{"code": "public static lbvserver_appfwpolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tlbvserver_appfwpolicy_binding obj = new lbvserver_appfwpolicy_binding();\n\t\tobj.set_name(name);\n\t\tlbvserver_appfwpolicy_binding response[] = (lbvserver_appfwpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static aaagroup_vpntrafficpolicy_binding[] get(nitro_service service, String groupname) throws Exception{\n\t\taaagroup_vpntrafficpolicy_binding obj = new aaagroup_vpntrafficpolicy_binding();\n\t\tobj.set_groupname(groupname);\n\t\taaagroup_vpntrafficpolicy_binding response[] = (aaagroup_vpntrafficpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void addBeanToBeanMapping(BeanToBeanMapping beanToBeanMapping) {\r\n\t\tbeanToBeanMappings.put(ClassPair.get(beanToBeanMapping\r\n\t\t\t\t.getSourceClass(), beanToBeanMapping.getDestinationClass()),\r\n\t\t\t\tbeanToBeanMapping);\r\n\t}", "label": 0}
{"code": "def sort_and_index_star(job, star_bams, univ_options, star_options):\n    \"\"\"\n    A wrapper for sorting and indexing the genomic star bam generated by run_star. It is required\n    since run_star returns a dict of 2 bams\n\n    :param dict star_bams: The bams from run_star\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict star_options: Options specific to star\n    :return: Dict containing input bam and the generated index (.bam.bai)\n                     output_files:\n                        |- 'rna_transcriptome.bam': fsID\n                        +- 'rna_genome':\n                                 |- 'rna_sorted.bam': fsID\n                                 +- 'rna_sorted.bam.bai': fsID\n                        +- 'rnaChimeric.out.junction': fsID\n    :rtype: dict\n    \"\"\"\n    star_options['samtools']['n'] = star_options['n']\n    sort = job.wrapJobFn(sort_bamfile, star_bams['rnaAligned.out.bam'], 'rna', univ_options,\n                         samtools_options=star_options['samtools'],\n                         disk=PromisedRequirement(sort_disk, star_bams['rnaAligned.out.bam']))\n    index = job.wrapJobFn(index_bamfile, sort.rv(), 'rna', univ_options,\n                          samtools_options=star_options['samtools'], sample_info='genome_sorted',\n                          disk=PromisedRequirement(index_disk, sort.rv()))\n    job.addChild(sort)\n    sort.addChild(index)\n    return {'rna_genome': index.rv(),\n            'rna_transcriptome.bam': star_bams['rnaAligned.toTranscriptome.out.bam'],\n            'rnaChimeric.out.junction': star_bams['rnaChimeric.out.junction']}", "label": 1}
{"code": "public void requestNodeInfo(int nodeId) {\n\t\tSerialMessage newMessage = new SerialMessage(nodeId, SerialMessage.SerialMessageClass.RequestNodeInfo, SerialMessage.SerialMessageType.Request, SerialMessage.SerialMessageClass.ApplicationUpdate, SerialMessage.SerialMessagePriority.High);\n    \tbyte[] newPayload = { (byte) nodeId };\n    \tnewMessage.setMessagePayload(newPayload);\n    \tthis.enqueue(newMessage);\n\t}", "label": 0}
{"code": "public RuleEnvelope getRule(String ruleId) throws ApiException {\n        ApiResponse<RuleEnvelope> resp = getRuleWithHttpInfo(ruleId);\n        return resp.getData();\n    }", "label": 0}
{"code": "function validateFields(contentType, cb) {\n        if (_.isArray(contentType.fields)) {\n            async.each(contentType.fields, validateField, function(err) {\n                cb(err);\n            });\n        } else {\n            cb();\n        }\n    }", "label": 3}
{"code": "public function setSnapshots($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->snapshots = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def description(self, platform, key):\n        \"\"\"Return the patter description.\"\"\"\n        patterns = self._dict_dscr.get(platform, None)\n        description = patterns.get(key, None)\n        return description", "label": 1}
{"code": "public static csvserver_copolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tcsvserver_copolicy_binding obj = new csvserver_copolicy_binding();\n\t\tobj.set_name(name);\n\t\tcsvserver_copolicy_binding response[] = (csvserver_copolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function pause(id) {\n  if (!timers[id]) return start(id);\n\n  timers[id].elapsed += msDiff(process.hrtime(), timers[id].start);\n}", "label": 3}
{"code": "function () {\n        var\n            newClass,\n            newPrototype,\n            baseClassDef;\n\n        // The new class constructor\n        newClass = _getOldNewClassConstructor(this);\n        this._Constructor = newClass;\n        newClass[_GPF_CLASSDEF_MARKER] = this._uid;\n\n        // Basic JavaScript inheritance mechanism: Defines the newClass prototype as an instance of the super class\n        newPrototype = Object.create(this._Super.prototype);\n\n        // Populate our constructed prototype object\n        newClass.prototype = newPrototype;\n\n        // Enforce the constructor to be what we expect\n        newPrototype.constructor = newClass;\n\n        /*\n         * Defines the link between this class and its base one\n         * (It is necessary to do it here because of the gpf.addAttributes that will test the parent class)\n         */\n        baseClassDef = _gpfGetClassDefinition(this._Super);\n        baseClassDef._Subs.push(newClass);\n\n        /*\n         * 2014-04-28 ABZ Changed again from two passes on all members to two passes in which the first one also\n         * collects attributes to simplify the second pass.\n         */\n        this._processDefinition(this._definition, _GPF_VISIBILITY_UNKNOWN);\n        this._processAttributes();\n\n        // Optimization for the constructor\n        this._resolveConstructor();\n    }", "label": 3}
{"code": "public function assertValid(array $attributes)\n    {\n        $validator = $this->makeValidator($attributes);\n\n        if ($validator->fails()) {\n            throw new ValidationException($validator);\n        }\n    }", "label": 2}
{"code": "def analyse(self, path_and_filename, pattern):\n        \"\"\"\n        Find out lines of code and lines of comments.\n\n        Args:\n            path_and_filename (str): path and filename to parse  for loc and com.\n            pattern (str): regex to search for line commens and block comments\n\n        Returns:\n            int, int: loc and com for given file.\n        \"\"\"\n        with open(path_and_filename) as handle:\n            content = handle.read()\n            loc = content.count('\\n') + 1\n            com = 0\n            for match in re.findall(pattern, content, re.DOTALL):\n                com += match.count('\\n') + 1\n\n            return max(0, loc - com), com", "label": 1}
{"code": "def write_text(target = self.class.default_target)\n      # Open a File Object for IO if target is a string containing a filename or path\n      target = File.open(target, 'w') if target.is_a? String\n      coverage_report = nil\n\n      events.each do |_tool, tool_events|\n        tool_events.each do |event|\n          if event.rspec_puppet_coverage?\n            coverage_report = event.to_text\n          else\n            target.puts(event.to_text) unless event.pass?\n          end\n        end\n      end\n    ensure\n      target.puts \"\\n#{coverage_report}\" if coverage_report\n      target.close if target.is_a? File\n    end", "label": 4}
{"code": "private static void loadFile(String filePath) {\n        final Path path = FileSystems.getDefault().getPath(filePath);\n\n        try {\n            data.clear();\n            data.load(Files.newBufferedReader(path));\n        } catch(IOException e) {\n            LOG.warn(\"Exception while loading \" + path.toString(), e);\n        }\n    }", "label": 0}
{"code": "function(a){var b;\n// the final two arguments are the length, and the entire string itself;\n// we don't care about those.\nif(arguments.length<7)throw new Error(\"markup() must be called from String.prototype.replace()\");return b=e.apply(null,arguments),'<span class=\"'+d[b]+'\">'+a+\"</span>\"}", "label": 3}
{"code": "private UserAlias getUserAlias(Object attribute)\r\n\t{\r\n\t\tif (m_userAlias != null)\r\n\t\t{\r\n\t\t\treturn m_userAlias;\r\n\t\t}\r\n\t\tif (!(attribute instanceof String))\r\n\t\t{\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\tif (m_alias == null)\r\n\t\t{\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\tif (m_aliasPath == null)\r\n\t\t{\r\n\t\t\tboolean allPathsAliased = true;\r\n\t\t\treturn new UserAlias(m_alias, (String)attribute, allPathsAliased);\r\n\t\t}\r\n\t\treturn new UserAlias(m_alias, (String)attribute, m_aliasPath);\r\n\t}", "label": 0}
{"code": "public static dnspolicy64[] get(nitro_service service) throws Exception{\n\t\tdnspolicy64 obj = new dnspolicy64();\n\t\tdnspolicy64[] response = (dnspolicy64[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function CreateInstance(\\Google\\Cloud\\Bigtable\\Admin\\V2\\CreateInstanceRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.bigtable.admin.v2.BigtableInstanceAdmin/CreateInstance',\n        $argument,\n        ['\\Google\\LongRunning\\Operation', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "def attribute_change(attr)\n      attr = database_field_name(attr)\n      [changed_attributes[attr], attributes[attr]] if attribute_changed?(attr)\n    end", "label": 4}
{"code": "public static function visibilityOfElementLocated(WebDriverBy $by)\n    {\n        return new static(\n            function (WebDriver $driver) use ($by) {\n                try {\n                    $element = $driver->findElement($by);\n\n                    return $element->isDisplayed() ? $element : null;\n                } catch (StaleElementReferenceException $e) {\n                    return null;\n                }\n            }\n        );\n    }", "label": 2}
{"code": "def stack_size\n      return 0 unless backtrace\n\n      backtrace.drop_while { |l| ignored_file?(l.first.path) }\n               .take_while { |l| !ignored_file?(l.first.path) }\n               .size\n    end", "label": 4}
{"code": "def docker_environment(env):\n    \"\"\"\n    Transform dictionary of environment variables into Docker -e parameters.\n\n    >>> result = docker_environment({'param1': 'val1', 'param2': 'val2'})\n    >>> result in ['-e \"param1=val1\" -e \"param2=val2\"', '-e \"param2=val2\" -e \"param1=val1\"']\n    True\n    \"\"\"\n    return ' '.join(\n        [\"-e \\\"%s=%s\\\"\" % (key, value.replace(\"$\", \"\\\\$\").replace(\"\\\"\", \"\\\\\\\"\").replace(\"`\", \"\\\\`\"))\n         for key, value in env.items()])", "label": 1}
{"code": "func (r *ReverseTunnelV1) V2() *ReverseTunnelV2 {\n\treturn &ReverseTunnelV2{\n\t\tKind:    KindReverseTunnel,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName:      r.DomainName,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: ReverseTunnelSpecV2{\n\t\t\tClusterName: r.DomainName,\n\t\t\tType:        ProxyTunnel,\n\t\t\tDialAddrs:   r.DialAddrs,\n\t\t},\n\t}\n}", "label": 5}
{"code": "private function fetchCredentials()\n    {\n        $backoff = new ExponentialBackoff($this->retries, $this->getRetryFunction());\n\n        try {\n            return $backoff->execute(\n                [$this->getCredentialsFetcher(), 'fetchAuthToken'],\n                [$this->authHttpHandler]\n            );\n        } catch (\\Exception $ex) {\n            throw $this->convertToGoogleException($ex);\n        }\n    }", "label": 2}
{"code": "def _remote_add(self):\n        \"\"\"Execute git remote add.\"\"\"\n        self.repo.create_remote(\n            'origin',\n            'git@github.com:{username}/{repo}.git'.format(\n                username=self.metadata.username,\n                repo=self.metadata.name))", "label": 1}
{"code": "def account\n      return '123456789' if test?\n      # ensure region set, required for sts.get_caller_identity.account to work\n      ENV['AWS_REGION'] ||= region\n      begin\n        sts.get_caller_identity.account\n      rescue Aws::Errors::MissingCredentialsError\n        puts \"INFO: You're missing AWS credentials. Only local services are currently available\"\n      end\n    end", "label": 4}
{"code": "def _sample_rows(self, X, Y, sample_shape, seed):\n        \"\"\"\n        Stratified uniform sampling of rows, according to the classes in Y.\n        Ensures there are enough samples from each class in Y for cross\n        validation.\n        \"\"\"\n        if sample_shape[0] is None or X.shape[0] <= sample_shape[0]:\n            X_sample, Y_sample = X, Y\n        elif Y is None:\n            np.random.seed(seed)\n            row_indices = np.random.choice(\n                X.shape[0], size=sample_shape[0], replace=False\n            )\n            X_sample, Y_sample = X.iloc[row_indices], Y\n        else:\n            drop_size = X.shape[0] - sample_shape[0]\n            sample_size = sample_shape[0]\n            sss = StratifiedShuffleSplit(\n                n_splits=2, test_size=drop_size, train_size=sample_size, random_state=seed\n            )\n            row_indices, _ = next(sss.split(X, Y))\n            X_sample, Y_sample = X.iloc[row_indices], Y.iloc[row_indices]\n        return (X_sample, Y_sample)", "label": 1}
{"code": "def process_zipfile(zipfilename_or_stream)\n      @sheet_files = []\n\n      unless is_stream?(zipfilename_or_stream)\n        zip_file = Zip::File.open(zipfilename_or_stream)\n      else\n        zip_file = Zip::CentralDirectory.new\n        zip_file.read_from_stream zipfilename_or_stream\n      end\n\n      process_zipfile_entries zip_file.to_a.sort_by(&:name)\n    end", "label": 4}
{"code": "func getStage1InterfaceVersion(cdir string) (int, error) {\n\tb, err := ioutil.ReadFile(common.Stage1ManifestPath(cdir))\n\tif err != nil {\n\t\treturn -1, errwrap.Wrap(errors.New(\"error reading pod manifest\"), err)\n\t}\n\n\ts1m := schema.ImageManifest{}\n\tif err := json.Unmarshal(b, &s1m); err != nil {\n\t\treturn -1, errwrap.Wrap(errors.New(\"error unmarshaling stage1 manifest\"), err)\n\t}\n\n\tif iv, ok := s1m.Annotations.Get(interfaceVersion); ok {\n\t\tv, err := strconv.Atoi(iv)\n\t\tif err != nil {\n\t\t\treturn -1, errwrap.Wrap(errors.New(\"error parsing interface version\"), err)\n\t\t}\n\t\treturn v, nil\n\t}\n\n\t// \"interface-version\" annotation not found, assume version 1\n\treturn 1, nil\n}", "label": 5}
{"code": "function hasFields(model, fields, exists)\n{\n  if ( isArray( fields ) )\n  {\n    for (var i = 0; i < fields.length; i++)\n    {\n      if ( !exists( model[ fields[ i ] ] ) )\n      {\n        return false;\n      }\n    }\n\n    return true;\n  }\n  else // isString( fields )\n  {\n    return exists( model[ fields ] );\n  }\n}", "label": 3}
{"code": "def run_all(scopes = {})\n      UI.clear(force: true)\n      UI.action_with_scopes(\"Run\", scopes)\n      Runner.new.run(:run_all, scopes)\n    end", "label": 4}
{"code": "def toggle_sensor(request, sensorname):\n    \"\"\"\n    This is used only if websocket fails\n    \"\"\"\n    if service.read_only:\n        service.logger.warning(\"Could not perform operation: read only mode enabled\")\n        raise Http404\n    source = request.GET.get('source', 'main')\n    sensor = service.system.namespace[sensorname]\n    sensor.status = not sensor.status\n    service.system.flush()\n    return HttpResponseRedirect(reverse(source))", "label": 1}
{"code": "public function setNormalizedVertices($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\NormalizedVertex::class);\n        $this->normalized_vertices = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setSpeechTranscriptionConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\VideoIntelligence\\V1\\SpeechTranscriptionConfig::class);\n        $this->speech_transcription_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def write(self):\n        \"\"\"\n        Writes the ``.sln`` file to disk.\n        \"\"\"\n        filters = {\n            'MSGUID': lambda x: ('{%s}' % x).upper(),\n            'relslnfile': lambda x: os.path.relpath(x, os.path.dirname(self.FileName))\n        }\n        context = {\n            'sln': self\n        }\n        return self.render(self.__jinja_template__, self.FileName, context, filters)", "label": 1}
{"code": "def allowed_to_accept_and_reject?(emendation)\n      return unless emendation.amendment.evaluating?\n\n      emendation.amendable.created_by?(current_user) || current_user.admin?\n    end", "label": 4}
{"code": "public void sendData(SerialMessage serialMessage)\n\t{\n    \tif (serialMessage.getMessageClass() != SerialMessage.SerialMessageClass.SendData) {\n    \t\tlogger.error(String.format(\"Invalid message class %s (0x%02X) for sendData\", serialMessage.getMessageClass().getLabel(), serialMessage.getMessageClass().getKey()));\n    \t\treturn;\n    \t}\n    \tif (serialMessage.getMessageType() != SerialMessage.SerialMessageType.Request) {\n    \t\tlogger.error(\"Only request messages can be sent\");\n    \t\treturn;\n    \t}\n    \t\n    \tZWaveNode node = this.getNode(serialMessage.getMessageNode());\n    \t\t\t\n    \tif (node.getNodeStage() == NodeStage.NODEBUILDINFO_DEAD) {\n    \t\tlogger.debug(\"Node {} is dead, not sending message.\", node.getNodeId());\n\t\t\treturn;\n    \t}\n\t\t\n    \tif (!node.isListening() && serialMessage.getPriority() != SerialMessage.SerialMessagePriority.Low) {\n\t\t\tZWaveWakeUpCommandClass wakeUpCommandClass = (ZWaveWakeUpCommandClass)node.getCommandClass(ZWaveCommandClass.CommandClass.WAKE_UP);\n\t\t\t\n\t\t\tif (wakeUpCommandClass != null && !wakeUpCommandClass.isAwake()) {\n\t\t\t\twakeUpCommandClass.putInWakeUpQueue(serialMessage); //it's a battery operated device, place in wake-up queue.\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n    \t\n    \tserialMessage.setTransmitOptions(TRANSMIT_OPTION_ACK | TRANSMIT_OPTION_AUTO_ROUTE | TRANSMIT_OPTION_EXPLORE);\n    \tif (++sentDataPointer > 0xFF)\n    \t\tsentDataPointer = 1;\n    \tserialMessage.setCallbackId(sentDataPointer);\n    \tlogger.debug(\"Callback ID = {}\", sentDataPointer);\n    \tthis.enqueue(serialMessage);\n\t}", "label": 0}
{"code": "def _check_rev_dict(tree, ebt):\n    \"\"\"Verifyies that `ebt` is the inverse of the `edgeBySourceId` data member of `tree`\"\"\"\n    ebs = defaultdict(dict)\n    for edge in ebt.values():\n        source_id = edge['@source']\n        edge_id = edge['@id']\n        ebs[source_id][edge_id] = edge\n    assert ebs == tree['edgeBySourceId']", "label": 1}
{"code": "func FSTryWriteLock(f *os.File) error {\n\terr := syscall.Flock(int(f.Fd()), syscall.LOCK_EX|syscall.LOCK_NB)\n\tif err != nil {\n\t\tif err == syscall.EWOULDBLOCK {\n\t\t\treturn trace.CompareFailed(\"lock %v is acquired by another process\", f.Name())\n\t\t}\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "def main(argv):\n    \"\"\"This function sets up a command-line option parser and then calls fetch_and_write_mrca\n    to do all of the real work.\n    \"\"\"\n    import argparse\n    description = 'Uses Open Tree of Life web services to the MRCA for a set of OTT IDs.'\n    parser = argparse.ArgumentParser(prog='ot-tree-of-life-mrca', description=description)\n    parser.add_argument('ottid', nargs='*', type=int, help='OTT IDs')\n    parser.add_argument('--subtree', action='store_true', default=False, required=False,\n                        help='write a newick representation of the subtree rooted at this mrca')\n    parser.add_argument('--induced-subtree', action='store_true', default=False, required=False,\n                        help='write a newick representation of the topology of the requested taxa in the synthetic tree (the subtree pruned to just the queried taxa)')\n    parser.add_argument('--details', action='store_true', default=False, required=False,\n                        help='report more details about the mrca node')\n    args = parser.parse_args(argv)\n    id_list = args.ottid\n    if not id_list:\n        sys.stderr.write('No OTT IDs provided. Running a dummy query with 770302 770315\\n')\n        id_list = [770302, 770315]\n    fetch_and_write_mrca(id_list, args.details, args.subtree, args.induced_subtree, sys.stdout, sys.stderr)", "label": 1}
{"code": "function isCached(project, majorVersion) {\n    var cid = project+majorVersion;\n    return cache[cid] && cache[cid].short_name[0] == project && cache[cid].api_version[0] == majorVersion;\n  }", "label": 3}
{"code": "def process_quantity(self, properties):\n        \"\"\"Process the uncertainty information from a given quantity and return it\n        \"\"\"\n        quant = Q_(properties[0])\n        if len(properties) > 1:\n            unc = properties[1]\n            uncertainty = unc.get('uncertainty', False)\n            upper_uncertainty = unc.get('upper-uncertainty', False)\n            lower_uncertainty = unc.get('lower-uncertainty', False)\n            uncertainty_type = unc.get('uncertainty-type')\n            if uncertainty_type == 'relative':\n                if uncertainty:\n                    quant = quant.plus_minus(float(uncertainty), relative=True)\n                elif upper_uncertainty and lower_uncertainty:\n                    warn('Asymmetric uncertainties are not supported. The '\n                         'maximum of lower-uncertainty and upper-uncertainty '\n                         'has been used as the symmetric uncertainty.')\n                    uncertainty = max(float(upper_uncertainty), float(lower_uncertainty))\n                    quant = quant.plus_minus(uncertainty, relative=True)\n                else:\n                    raise ValueError('Either \"uncertainty\" or \"upper-uncertainty\" and '\n                                     '\"lower-uncertainty\" need to be specified.')\n            elif uncertainty_type == 'absolute':\n                if uncertainty:\n                    uncertainty = Q_(uncertainty)\n                    quant = quant.plus_minus(uncertainty.to(quant.units).magnitude)\n                elif upper_uncertainty and lower_uncertainty:\n                    warn('Asymmetric uncertainties are not supported. The '\n                         'maximum of lower-uncertainty and upper-uncertainty '\n                         'has been used as the symmetric uncertainty.')\n                    uncertainty = max(Q_(upper_uncertainty), Q_(lower_uncertainty))\n                    quant = quant.plus_minus(uncertainty.to(quant.units).magnitude)\n                else:\n                    raise ValueError('Either \"uncertainty\" or \"upper-uncertainty\" and '\n                                     '\"lower-uncertainty\" need to be specified.')\n            else:\n                raise ValueError('uncertainty-type must be one of \"absolute\" or \"relative\"')\n\n        return quant", "label": 1}
{"code": "function (event) {\n\n\t// if event is not from socket, no need to queue\n\t// TODO: remove connection-specific code from here\n\tif (event.conn.type !== 'socket')\n\t\treturn true;\n\n\tvar socket = event.conn.connector;\n\n\t// if no mechanism to store (such as from a bot), just ignore\n\t// TODO: this is not clean\n\tif (typeof socket.queuedEvents === 'undefined')\n\t\tsocket.queuedEvents = {};\n\n\tvar queue_size = Object.keys(socket.queuedEvents).length;\n\tif (queue_size > l_queuedEventsPerSocket) {\n\n\t\tLOG.warn('queued event size: ' + queue_size + ' limit exceeded (' + l_queuedEventsPerSocket + ')', l_name);\n\n\t\t// DEBUG purpose (print out events queued)\n\t\tfor (var i in socket.queuedEvents)\n\t\t\tLOG.sys('queuedEvents[' + i + '] =' + UTIL.stringify(socket.queuedEvents[i].data), l_name);\n\n\t\treturn false;\n\t}\n\n\t// store event with the ID to socket's eventlist\n\tsocket.queuedEvents[event.id] = event;\n\n\treturn true;\n}", "label": 3}
{"code": "private void calculateSCL(double[] x) {\r\n    //System.out.println(\"Checking at: \"+x[0]+\" \"+x[1]+\" \"+x[2]);\r\n    value = 0.0;\r\n    Arrays.fill(derivative, 0.0);\r\n    double[] sums = new double[numClasses];\r\n    double[] probs = new double[numClasses];\r\n    double[] counts = new double[numClasses];\r\n    Arrays.fill(counts, 0.0);\r\n    for (int d = 0; d < data.length; d++) {\r\n      //       if (d == testMin) {\r\n      //         d = testMax - 1;\r\n      //         continue;\r\n      //       }\r\n      int[] features = data[d];\r\n      // activation\r\n      Arrays.fill(sums, 0.0);\r\n      for (int c = 0; c < numClasses; c++) {\r\n        for (int f = 0; f < features.length; f++) {\r\n          int i = indexOf(features[f], c);\r\n          sums[c] += x[i];\r\n        }\r\n      }\r\n      // expectation (slower routine replaced by fast way)\r\n      // double total = Double.NEGATIVE_INFINITY;\r\n      // for (int c=0; c<numClasses; c++) {\r\n      //   total = SloppyMath.logAdd(total, sums[c]);\r\n      // }\r\n      double total = ArrayMath.logSum(sums);\r\n      int ld = labels[d];\r\n      for (int c = 0; c < numClasses; c++) {\r\n        probs[c] = Math.exp(sums[c] - total);\r\n        for (int f = 0; f < features.length; f++) {\r\n          int i = indexOf(features[f], c);\r\n          derivative[i] += probs[ld] * probs[c];\r\n        }\r\n      }\r\n      // observed\r\n      for (int f = 0; f < features.length; f++) {\r\n        int i = indexOf(features[f], labels[d]);\r\n        derivative[i] -= probs[ld];\r\n      }\r\n      value -= probs[ld];\r\n    }\r\n    // priors\r\n    if (true) {\r\n      for (int i = 0; i < x.length; i++) {\r\n        double k = 1.0;\r\n        double w = x[i];\r\n        value += k * w * w / 2.0;\r\n        derivative[i] += k * w;\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "def prepare(self):\n        \"\"\"\n        does some basic validation\n        \"\"\"\n        try:\n            assert(type(self.sender) is Channel)\n            assert(type(self.receiver) is Channel)\n            return True\n        except:\n            return False", "label": 1}
{"code": "def _validate_isvalid_orcid(self, isvalid_orcid, field, value):\n        \"\"\"Checks for valid ORCID if given.\n\n        Args:\n            isvalid_orcid (`bool`): flag from schema indicating ORCID to be checked.\n            field (`str`): 'author'\n            value (`dict`): dictionary of author metadata.\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_orcid': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'dict'}}\n\n        \"\"\"\n        if isvalid_orcid and 'ORCID' in value:\n            try:\n                res = search_orcid(value['ORCID'])\n            except ConnectionError:\n                warn('network not available, ORCID not validated.')\n                return\n            except HTTPError:\n                self._error(field, 'ORCID incorrect or invalid for ' +\n                            value['name']\n                            )\n                return\n\n            family_name = res['name']['family-name']['value']\n            given_name = res['name']['given-names']['value']\n            if not compare_name(given_name, family_name, value['name']):\n                self._error(field, 'Name and ORCID do not match. Name supplied: ' +\n                            value['name'] + '. Name associated with ORCID: ' +\n                            ' '.join([given_name, family_name])\n                            )", "label": 1}
{"code": "def read_ack_from_sock(sock, unpacker)\n      begin\n        raw_data = sock.instance_of?(Fluent::PluginHelper::Socket::WrappedSocket::TLS) ? sock.readpartial(@read_length) : sock.recv(@read_length)\n      rescue Errno::ECONNRESET, EOFError # ECONNRESET for #recv, #EOFError for #readpartial\n        raw_data = \"\"\n      end\n      info = @sock_ack_waiting_mutex.synchronize{ @sock_ack_waiting.find{|i| i.sock == sock } }\n\n      # When connection is closed by remote host, socket is ready to read and #recv returns an empty string that means EOF.\n      # If this happens we assume the data wasn't delivered and retry it.\n      if raw_data.empty?\n        log.warn \"destination node closed the connection. regard it as unavailable.\", host: info.node.host, port: info.node.port\n        info.node.disable!\n        rollback_write(info.chunk_id, update_retry: false)\n        return nil\n      else\n        unpacker.feed(raw_data)\n        res = unpacker.read\n        log.trace \"getting response from destination\", host: info.node.host, port: info.node.port, chunk_id: dump_unique_id_hex(info.chunk_id), response: res\n        if res['ack'] != info.chunk_id_base64\n          # Some errors may have occurred when ack and chunk id is different, so send the chunk again.\n          log.warn \"ack in response and chunk id in sent data are different\", chunk_id: dump_unique_id_hex(info.chunk_id), ack: res['ack']\n          rollback_write(info.chunk_id, update_retry: false)\n          return nil\n        else\n          log.trace \"got a correct ack response\", chunk_id: dump_unique_id_hex(info.chunk_id)\n        end\n        return info.chunk_id\n      end\n    rescue => e\n      log.error \"unexpected error while receiving ack message\", error: e\n      log.error_backtrace\n    ensure\n      info.sock.close_write rescue nil\n      info.sock.close rescue nil\n      @sock_ack_waiting_mutex.synchronize do\n        @sock_ack_waiting.delete(info)\n      end\n    end", "label": 4}
{"code": "@RequestMapping(value=\"/soy/compileJs\", method=GET)\n    public ResponseEntity<String> compile(@RequestParam(required = false, value=\"hash\", defaultValue = \"\") final String hash,\n                                                            @RequestParam(required = true, value = \"file\") final String[] templateFileNames,\n                                                            @RequestParam(required = false, value = \"locale\") String locale,\n                                                            @RequestParam(required = false, value = \"disableProcessors\", defaultValue = \"false\") String disableProcessors,\n                                                            final HttpServletRequest request) throws IOException {\n        return compileJs(templateFileNames, hash, new Boolean(disableProcessors).booleanValue(), request, locale);\n    }", "label": 0}
{"code": "def get_config_object():\n    \"\"\"Thread-safe accessor for the immutable default ConfigWrapper object\"\"\"\n    global _DEFAULT_CONFIG_WRAPPER\n    if _DEFAULT_CONFIG_WRAPPER is not None:\n        return _DEFAULT_CONFIG_WRAPPER\n    with _DEFAULT_CONFIG_WRAPPER_LOCK:\n        if _DEFAULT_CONFIG_WRAPPER is not None:\n            return _DEFAULT_CONFIG_WRAPPER\n        _DEFAULT_CONFIG_WRAPPER = ConfigWrapper()\n        return _DEFAULT_CONFIG_WRAPPER", "label": 1}
{"code": "public static double Sinh(double x, int nTerms) {\r\n        if (nTerms < 2) return x;\r\n        if (nTerms == 2) {\r\n            return x + (x * x * x) / 6D;\r\n        } else {\r\n\r\n            double mult = x * x * x;\r\n            double fact = 6;\r\n            int factS = 5;\r\n            double result = x + mult / fact;\r\n            for (int i = 3; i <= nTerms; i++) {\r\n                mult *= x * x;\r\n                fact *= factS * (factS - 1);\r\n                factS += 2;\r\n                result += mult / fact;\r\n            }\r\n\r\n            return result;\r\n        }\r\n    }", "label": 0}
{"code": "function validatorBarcode(fieldValue, fieldDefinition, previousFieldValues, cb) {\n      if (typeof(fieldValue) !== \"object\" || fieldValue === null) {\n        return cb(new Error(\"Expected object but got \" + typeof(fieldValue)));\n      }\n\n      if (typeof(fieldValue.text) !== \"string\" || fieldValue.text.length === 0) {\n        return cb(new Error(\"Expected text parameter.\"));\n      }\n\n      if (typeof(fieldValue.format) !== \"string\" || fieldValue.format.length === 0) {\n        return cb(new Error(\"Expected format parameter.\"));\n      }\n\n      return cb();\n    }", "label": 3}
{"code": "public function setDetectedLanguages($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\TextAnnotation\\DetectedLanguage::class);\n        $this->detected_languages = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setOp($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Datastore\\V1\\CompositeFilter_Operator::class);\n        $this->op = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function initCache (cachePath) {\n    return new Promise(function (resolve, reject) {\n      mkdirp(cachePath, function (err) {\n        if (err) {\n          reject(err)\n        } else {\n          resolve()\n        }\n      })\n    })\n  }", "label": 3}
{"code": "protected function registerDatabaseDriver()\n    {\n        $this->app->singleton(\n            EntriesRepository::class, DatabaseEntriesRepository::class\n        );\n\n        $this->app->singleton(\n            ClearableRepository::class, DatabaseEntriesRepository::class\n        );\n\n        $this->app->singleton(\n            PrunableRepository::class, DatabaseEntriesRepository::class\n        );\n\n        $this->app->when(DatabaseEntriesRepository::class)\n            ->needs('$connection')\n            ->give(config('telescope.storage.database.connection'));\n\n        $this->app->when(DatabaseEntriesRepository::class)\n            ->needs('$chunkSize')\n            ->give(config('telescope.storage.database.chunk'));\n    }", "label": 2}
{"code": "func GetRiemannClient(config RiemannConfig) (riemanngo.Client, error) {\n\tglog.Infof(\"Connect Riemann client...\")\n\tclient := riemanngo.NewTcpClient(config.Host)\n\truntime.SetFinalizer(client, func(c riemanngo.Client) { c.Close() })\n\t// 5 seconds timeout\n\terr := client.Connect(5)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn client, nil\n}", "label": 5}
{"code": "function getFooterItems (privateKey, items) {\n  const pkp = generatePKP(\n    privateKey,\n    items.dicPopl,\n    items.idProvoz,\n    items.idPokl,\n    items.poradCis,\n    formatDate(items.datTrzby),\n    formatNumber(items.celkTrzba)\n  )\n  const bkp = generateBKP(pkp)\n\n  return {\n    pkp: {\n      attributes: {\n        digest: 'SHA256',\n        cipher: 'RSA2048',\n        encoding: 'base64'\n      },\n      $value: pkp\n    },\n    bkp: {\n      attributes: {\n        digest: 'SHA1',\n        encoding: 'base16'\n      },\n      $value: bkp\n    }\n  }\n}", "label": 3}
{"code": "function fetchOfflineLogin(credentials, serverOptions) {\n    try {\n        var value = localStorage().getItem(computeLocalStorageKey(serverOptions));\n        if (!value) {\n            return Q.resolve(undefined);\n        }\n        return cipher.decryptJson(credentials['password'], JSON.parse(value));\n    }\n    catch (error) {\n        return Q.reject(error);\n    }\n}", "label": 3}
{"code": "public function clearRules($action = null)\n    {\n        if (!$action) {\n            $this->lifecycle = [];\n            return $this;\n        }\n\n        if (!is_string($action) && !is_callable($action)) {\n            throw new \\InvalidArgumentException(\n                sprintf(\n                    'Expected either a string or callable, instead got \\'%s\\'.',\n                    gettype($action)\n                )\n            );\n        }\n\n        if (isset($this->lifecycle['rule'])) {\n            if (is_string($action)) {\n                $action = function ($rule) use ($action) {\n                    return $rule['action']['type'] !== $action;\n                };\n            }\n\n            $this->lifecycle['rule'] = array_filter(\n                $this->lifecycle['rule'],\n                $action\n            );\n\n            if (!$this->lifecycle['rule']) {\n                $this->lifecycle = [];\n            }\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "def participatory_space_lazy(cache: true)\n      return if participatory_space_id.blank? || participatory_space_type.blank?\n      return resouce_lazy if participatory_space_id == resource_id && participatory_space_type == resource_type\n\n      self.class.lazy_relation(participatory_space_id, participatory_space_type, cache)\n    end", "label": 4}
{"code": "public function processReceivedMessage($phone, $from, $id, $type, $time, $name, $data)\n    {\n        $matches = null;\n        $time = date('Y-m-d H:i:s', $time);\n        if (preg_match('/\\d*/', $from, $matches)) {\n            $from = $matches[0];\n        }\n        $this->messages[] = ['phone' => $phone, 'from' => $from, 'id' => $id, 'type' => $type, 'time' => $time, 'name' => $name, 'data' => $data];\n    }", "label": 2}
{"code": "def converters\n      @converters ||= site.converters.select { |c| c.matches(document.extname) }.sort\n    end", "label": 4}
{"code": "func newContext(t time.Duration) context.Context {\n\tctx := context.Background()\n\tif t > 0 {\n\t\tctx, _ = context.WithTimeout(ctx, t)\n\t}\n\treturn ctx\n}", "label": 5}
{"code": "def check(self):\n        \"\"\"Check that the resource exists.\n\n        :raises ResourceNotFound: if the resource doesn't exists\n        \"\"\"\n        if self.fq_name:\n            self['uuid'] = self._check_fq_name(self.fq_name)\n        elif self.uuid:\n            self['fq_name'] = self._check_uuid(self.uuid)\n        return True", "label": 1}
{"code": "def deny(cls, action, **kwargs):\n        \"\"\"Deny the given action need.\n\n        :param action: The action to deny.\n        :returns: A :class:`invenio_access.models.ActionNeedMixin` instance.\n        \"\"\"\n        return cls.create(action, exclude=True, **kwargs)", "label": 1}
{"code": "func (k *Keygen) GenerateHostCert(c services.HostCertParams) ([]byte, error) {\n\tif err := c.Check(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tpubKey, _, _, _, err := ssh.ParseAuthorizedKey(c.PublicHostKey)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tsigner, err := ssh.ParsePrivateKey(c.PrivateCASigningKey)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Build a valid list of principals from the HostID and NodeName and then\n\t// add in any additional principals passed in.\n\tprincipals := BuildPrincipals(c.HostID, c.NodeName, c.ClusterName, c.Roles)\n\tprincipals = append(principals, c.Principals...)\n\tif len(principals) == 0 {\n\t\treturn nil, trace.BadParameter(\"no principals provided: %v, %v, %v\",\n\t\t\tc.HostID, c.NodeName, c.Principals)\n\t}\n\tprincipals = utils.Deduplicate(principals)\n\n\t// create certificate\n\tvalidBefore := uint64(ssh.CertTimeInfinity)\n\tif c.TTL != 0 {\n\t\tb := k.clock.Now().UTC().Add(c.TTL)\n\t\tvalidBefore = uint64(b.Unix())\n\t}\n\tcert := &ssh.Certificate{\n\t\tValidPrincipals: principals,\n\t\tKey:             pubKey,\n\t\tValidAfter:      uint64(k.clock.Now().UTC().Add(-1 * time.Minute).Unix()),\n\t\tValidBefore:     validBefore,\n\t\tCertType:        ssh.HostCert,\n\t}\n\tcert.Permissions.Extensions = make(map[string]string)\n\tcert.Permissions.Extensions[utils.CertExtensionRole] = c.Roles.String()\n\tcert.Permissions.Extensions[utils.CertExtensionAuthority] = string(c.ClusterName)\n\n\t// sign host certificate with private signing key of certificate authority\n\tif err := cert.SignCert(rand.Reader, signer); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tlog.Debugf(\"Generated SSH host certificate for role %v with principals: %v.\",\n\t\tc.Roles, principals)\n\treturn ssh.MarshalAuthorizedKey(cert), nil\n}", "label": 5}
{"code": "def get_value(*args, **kwargs):\n    \"\"\"Get from config object by exposing Config.get_value method.\n\n    dict.get() method on Config.values\n    \"\"\"\n    global _config\n    if _config is None:\n        raise ValueError('configuration not set; must run figgypy.set_config first')\n    return _config.get_value(*args, **kwargs)", "label": 1}
{"code": "def process_bulk_queue(self, es_bulk_kwargs=None):\n        \"\"\"Process bulk indexing queue.\n\n        :param dict es_bulk_kwargs: Passed to\n            :func:`elasticsearch:elasticsearch.helpers.bulk`.\n        \"\"\"\n        with current_celery_app.pool.acquire(block=True) as conn:\n            consumer = Consumer(\n                connection=conn,\n                queue=self.mq_queue.name,\n                exchange=self.mq_exchange.name,\n                routing_key=self.mq_routing_key,\n            )\n\n            req_timeout = current_app.config['INDEXER_BULK_REQUEST_TIMEOUT']\n\n            es_bulk_kwargs = es_bulk_kwargs or {}\n            count = bulk(\n                self.client,\n                self._actionsiter(consumer.iterqueue()),\n                stats_only=True,\n                request_timeout=req_timeout,\n                **es_bulk_kwargs\n            )\n\n            consumer.close()\n\n        return count", "label": 1}
{"code": "function registerPatternHelpers(options) {\n  const Handlebars = options.handlebars;\n  if (Handlebars.helpers.pattern) {\n    DrizzleError.error(\n      new DrizzleError(\n        '`pattern` helper already registered',\n        DrizzleError.LEVELS.WARN\n      ),\n      options.debug\n    );\n  }\n  /**\n   * The `pattern` helper allows the embedding of patterns anywhere\n   * and they can get their correct local context.\n   */\n  Handlebars.registerHelper('pattern', (id, rootContext, opts) => {\n    const renderedTemplate = renderPatternPartial(\n      id,\n      rootContext.drizzle,\n      Handlebars\n    );\n    return renderedTemplate;\n  });\n\n  if (Handlebars.helpers.patternSource) {\n    DrizzleError.error(\n      new DrizzleError(\n        '`patternSource` helper already registered',\n        DrizzleError.LEVELS.WARN\n      ),\n      options.debug\n    );\n  }\n  /**\n   * Similar to `pattern` but the returned string is HTML-escaped.\n   * Can be used for rendering source in `<pre>` tags.\n   */\n  Handlebars.registerHelper('patternSource', (id, rootContext, opts) => {\n    const renderedTemplate = renderPatternPartial(\n      id,\n      rootContext.drizzle,\n      Handlebars\n    );\n    const sourceMarkup = beautify(renderedTemplate, options.beautifier);\n    return Handlebars.Utils.escapeExpression(sourceMarkup);\n  });\n  return Handlebars;\n}", "label": 3}
{"code": "func doEntityEventArgument(event types.BaseEvent, f func(types.ManagedObjectReference, *types.EntityEventArgument) bool) bool {\n\te := event.GetEvent()\n\n\tif arg := e.Vm; arg != nil {\n\t\tif f(arg.Vm, &arg.EntityEventArgument) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif arg := e.Host; arg != nil {\n\t\tif f(arg.Host, &arg.EntityEventArgument) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif arg := e.ComputeResource; arg != nil {\n\t\tif f(arg.ComputeResource, &arg.EntityEventArgument) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif arg := e.Ds; arg != nil {\n\t\tif f(arg.Datastore, &arg.EntityEventArgument) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif arg := e.Net; arg != nil {\n\t\tif f(arg.Network, &arg.EntityEventArgument) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif arg := e.Dvs; arg != nil {\n\t\tif f(arg.Dvs, &arg.EntityEventArgument) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif arg := e.Datacenter; arg != nil {\n\t\tif f(arg.Datacenter, &arg.EntityEventArgument) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "def exec_redis_cli(self, command, args=[], db=0, redis_cli_opts=[]):\n        \"\"\"\n        Execute a ``redis-cli`` command inside a running container.\n\n        :param command: the command to run\n        :param args: a list of args for the command\n        :param db: the db number to query (default ``0``)\n        :param redis_cli_opts: a list of extra options to pass to ``redis-cli``\n        :returns: a tuple of the command exit code and output\n        \"\"\"\n        cli_opts = ['-n', str(db)] + redis_cli_opts\n        cmd = ['redis-cli'] + cli_opts + [command] + [str(a) for a in args]\n        return self.inner().exec_run(cmd)", "label": 1}
{"code": "def dispatch(message, channel)\n      push(Oj.dump(message, mode: :compat)) unless channel =~ /\\Aslanger:/\n\n      perform_client_webhook!(message)\n    end", "label": 4}
{"code": "function path(d) {\n      return line(dimensions.map(function(p) { return [position(p), y[p](d[p])]; }));\n    }", "label": 3}
{"code": "def onmessage(msg)\n      msg = Oj.strict_load(msg)\n\n      msg['data'] = Oj.strict_load(msg['data']) if msg['data'].is_a? String\n\n      event = msg['event'].gsub(/\\Apusher:/, 'pusher_')\n\n      if event =~ /\\Aclient-/\n        msg['socket_id'] = connection.socket_id\n        Channel.send_client_message msg\n      elsif respond_to? event, true\n        send event, msg\n      end\n\n    rescue JSON::ParserError\n      error({ code: 5001, message: \"Invalid JSON\" })\n    rescue Exception => e\n      error({ code: 500, message: \"#{e.message}\\n #{e.backtrace.join \"\\n\"}\" })\n    end", "label": 4}
{"code": "public function setFixedLikelihood($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dlp\\V2\\Likelihood::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def namespaced_resources(target, opts = {}, &block)\n        if target.include?('/')\n          the_namespace = target[0..target.index('/') - 1]\n          new_target = target[target.index('/') + 1..-1]\n          namespace the_namespace, ROUTE_OPTIONS.fetch(the_namespace, {}) do\n            namespaced_resources(new_target, opts, &block)\n          end\n        else\n          resources target, opts do\n            yield if block_given?\n          end\n        end\n      end", "label": 4}
{"code": "func (c *Manager) ListAttachedTags(ctx context.Context, ref mo.Reference) ([]string, error) {\n\tspec := internal.NewAssociation(ref)\n\turl := internal.URL(c, internal.AssociationPath).WithAction(\"list-attached-tags\")\n\tvar res []string\n\treturn res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "def merge(other)\n      result = Env.new\n      result.env = @env.merge(other.env)\n      return result\n    end", "label": 4}
{"code": "func (c *CertAuthorityV2) GetRotation() Rotation {\n\tif c.Spec.Rotation == nil {\n\t\treturn Rotation{}\n\t}\n\treturn *c.Spec.Rotation\n}", "label": 5}
{"code": "def get(self, query_continue=None, auth=None, continuation=False,\n            **params):\n        \"\"\"Makes an API request with the GET method\n\n        :Parameters:\n            query_continue : `dict`\n                Optionally, the value of a query continuation 'continue' field.\n            auth : mixed\n                Auth tuple or callable to enable Basic/Digest/Custom HTTP Auth.\n            continuation : `bool`\n                If true, a continuation will be attempted and a generator of\n                JSON response documents will be returned.\n            params :\n                Keyword parameters to be sent in the query string.\n\n        :Returns:\n            A response JSON documents (or a generator of documents if\n            `continuation == True`)\n\n        :Raises:\n            :class:`mwapi.errors.APIError` : if the API responds with an error\n        \"\"\"\n\n        return self.request('GET', params=params, auth=auth,\n                            query_continue=query_continue,\n                            continuation=continuation)", "label": 1}
{"code": "public static base_responses delete(nitro_service client, String serverip[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (serverip != null && serverip.length > 0) {\n\t\t\tntpserver deleteresources[] = new ntpserver[serverip.length];\n\t\t\tfor (int i=0;i<serverip.length;i++){\n\t\t\t\tdeleteresources[i] = new ntpserver();\n\t\t\t\tdeleteresources[i].serverip = serverip[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "function expand_code(docset) {\n  var results = [];\n\n  if (docset[\"code\"] && docset[\"code\"][\"members\"]) {\n    _.each(docset[\"code\"][\"members\"], function(m) {\n      if (! (constructor_found && m[\"name\"] == \"Constructor\") )\n        results.push(code_to_docset(m));\n    });\n  }\n\n  return results;\n}", "label": 3}
{"code": "def xpath(source_xml, xpath_expr, req_format='string'):\n    \"\"\" Filter xml based on an xpath expression.\n\n    Purpose: This function applies an Xpath expression to the XML\n           | supplied by source_xml. Returns a string subtree or\n           | subtrees that match the Xpath expression. It can also return\n           | an xml object if desired.\n\n    @param source_xml: Plain text XML that will be filtered\n    @type source_xml: str or lxml.etree.ElementTree.Element object\n    @param xpath_expr: Xpath expression that we will filter the XML by.\n    @type xpath_expr: str\n    @param req_format: the desired format of the response, accepts string or\n                     | xml.\n    @type req_format: str\n\n    @returns: The filtered XML if filtering was successful. Otherwise,\n            | an empty string.\n    @rtype: str or ElementTree\n    \"\"\"\n    tree = source_xml\n    if not isinstance(source_xml, ET.Element):\n        tree = objectify.fromstring(source_xml)\n    # clean up the namespace in the tags, as namespaces appear to confuse\n    # xpath method\n    for elem in tree.getiterator():\n        # beware of factory functions such as Comment\n        if isinstance(elem.tag, basestring):\n            i = elem.tag.find('}')\n            if i >= 0:\n                elem.tag = elem.tag[i+1:]\n\n    # remove unused namespaces\n    objectify.deannotate(tree, cleanup_namespaces=True)\n    filtered_list = tree.xpath(xpath_expr)\n    # Return string from the list of Elements or pure xml\n    if req_format == 'xml':\n        return filtered_list\n    matches = ''.join(etree.tostring(\n        element, pretty_print=True) for element in filtered_list)\n    return matches if matches else \"\"", "label": 1}
{"code": "public static function documentPathName($project, $database, $documentPath)\n    {\n        return self::getDocumentPathNameTemplate()->render([\n            'project' => $project,\n            'database' => $database,\n            'document_path' => $documentPath,\n        ]);\n    }", "label": 2}
{"code": "function()\n  {\n    this.indices = {};\n\n    for (var i = 0, l = this.keys.length; i < l; i++)\n    {\n      this.indices[ this.keys[ i ] ] = i;\n    }\n\n    return this;\n  }", "label": 3}
{"code": "def command(jaide, commands, format=\"text\", xpath=False):\n    \"\"\" Run an operational command.\n\n    @param jaide: The jaide connection to the device.\n    @type jaide: jaide.Jaide object\n    @param commands: the operational commands to send to the device.\n    @type commands: str or list\n    @param format: The desired output format from the device, either 'text'\n                 | or 'xml' is supported.\n    @type format: str\n    @param xpath: The xpath expression to filter the results from the device.\n                | If set, this forces the output to be requested in xml format.\n    @type xpath: str\n\n    @returns: The output from the device, and xpath filtered if desired.\n    @rtype: str\n    \"\"\"\n    output = \"\"\n    for cmd in clean_lines(commands):\n        expression = \"\"\n        output += color('> ' + cmd + '\\n', 'yel')\n        # Get xpath expression from the command, if it is there.\n        # If there is an xpath expr, the output will be xml,\n        # overriding the req_format parameter\n        #\n        # Example command forcing xpath: show route % //rt-entry\n        if len(cmd.split('%')) == 2:\n            expression = cmd.split('%')[1].strip()\n            cmd = cmd.split('%')[0] + '\\n'\n        elif xpath is not False:\n            expression = xpath\n        if expression:\n            try:\n                output += jaide.op_cmd(command=cmd, req_format='xml',\n                                       xpath_expr=expression) + '\\n'\n            except lxml.etree.XMLSyntaxError:\n                output += color('Xpath expression resulted in no response.\\n',\n                                'red')\n        else:\n            output += jaide.op_cmd(cmd, req_format=format) + '\\n'\n    return output", "label": 1}
{"code": "def colors_from_params(match, params)\n      case params\n      when Hash then colors_from_hash(match, params)\n      when Symbol then color_from_symbol(match, params)\n      end\n    end", "label": 4}
{"code": "def unquote(q)\n    q = q[1...-1]\n    a = q.dup # allocate a big enough string\n    # In ruby >= 1.9, a[w] is a codepoint, not a byte.\n    if rubydoesenc?\n      a.force_encoding('UTF-8')\n    end\n    r, w = 0, 0\n    while r < q.length\n      c = q[r]\n      if c == ?\\\\\n        r += 1\n        if r >= q.length\n          raise Error, \"string literal ends with a \\\"\\\\\\\": \\\"#{q}\\\"\"\n        end\n\n        case q[r]\n        when ?\",?\\\\,?/,?'\n          a[w] = q[r]\n          r += 1\n          w += 1\n        when ?b,?f,?n,?r,?t\n          a[w] = Unesc[q[r]]\n          r += 1\n          w += 1\n        when ?u\n          r += 1\n          uchar = begin\n            hexdec4(q[r,4])\n          rescue RuntimeError => e\n            raise Error, \"invalid escape sequence \\\\u#{q[r,4]}: #{e}\"\n          end\n          r += 4\n          if surrogate? uchar\n            if q.length >= r+6\n              uchar1 = hexdec4(q[r+2,4])\n              uchar = subst(uchar, uchar1)\n              if uchar != Ucharerr\n                # A valid pair; consume.\n                r += 6\n              end\n            end\n          end\n          if rubydoesenc?\n            a[w] = '' << uchar\n            w += 1\n          else\n            w += ucharenc(a, w, uchar)\n          end\n        else\n          raise Error, \"invalid escape char #{q[r]} in \\\"#{q}\\\"\"\n        end\n      elsif c == ?\" || c < Spc\n        raise Error, \"invalid character in string literal \\\"#{q}\\\"\"\n      else\n        # Copy anything else byte-for-byte.\n        # Valid UTF-8 will remain valid UTF-8.\n        # Invalid UTF-8 will remain invalid UTF-8.\n        # In ruby >= 1.9, c is a codepoint, not a byte,\n        # in which case this is still what we want.\n        a[w] = c\n        r += 1\n        w += 1\n      end\n    end\n    a[0,w]\n  end", "label": 4}
{"code": "def parse_annotations(annots, fmt, annot_tables, trans_table):\n    \"\"\"\n    parse annotations in either gbk or Prodigal fasta format\n    \"\"\"\n    annotations = {} # annotations[contig] = [features]\n    # gbk format\n    if fmt is False:\n        for contig, feature in parse_gbk(annots):\n            if contig not in annotations:\n                annotations[contig] = []\n            annotations[contig].append(feature)\n    # fasta format\n    else:\n        for contig, feature in parse_fasta_annotations(annots, annot_tables, trans_table):\n            if contig not in annotations:\n                annotations[contig] = []\n            annotations[contig].append(feature)\n    return annotations", "label": 1}
{"code": "public base_response clear_config(Boolean force, String level) throws Exception\n\t{\n\t\tbase_response result = null;\n\t\tnsconfig resource = new nsconfig();\n\t\tif (force)\n\t\t\tresource.set_force(force);\n\n\t\tresource.set_level(level);\n\t\toptions option = new options();\n\t\toption.set_action(\"clear\");\n\t\tresult = resource.perform_operation(this, option);\n\t\treturn result;\n\t}", "label": 0}
{"code": "public AutomatonInstance doClone() {\n\t\tAutomatonInstance clone = new AutomatonInstance(this.automatonEng, this.current, this.instanceId, this.safeGuard);\n\t\tclone.failed = this.failed;\n\t\tclone.transitionCount = this.transitionCount;\n\t\tclone.failCount = this.failCount;\n\t\tclone.iterateCount = this.iterateCount;\n\t\tclone.backtrackCount = this.backtrackCount;\n\t\tclone.trace = new LinkedList<>();\n\t\tfor(StateExploration se:this.trace) {\n\t\t\tclone.trace.add(se.doClone());\n\t\t}\n\t\treturn clone;\n\t}", "label": 0}
{"code": "public void addAttribute(String attributeName, String attributeValue)\r\n    {\r\n        if (attributeName != null && attributeName.startsWith(JDBC_PROPERTY_NAME_PREFIX))\r\n        {\r\n            final String jdbcPropertyName = attributeName.substring(JDBC_PROPERTY_NAME_LENGTH);\r\n            jdbcProperties.setProperty(jdbcPropertyName, attributeValue);\r\n        }\r\n        else if (attributeName != null && attributeName.startsWith(DBCP_PROPERTY_NAME_PREFIX))\r\n        {\r\n            final String dbcpPropertyName = attributeName.substring(DBCP_PROPERTY_NAME_LENGTH);\r\n            dbcpProperties.setProperty(dbcpPropertyName, attributeValue);\r\n        }\r\n        else\r\n        {\r\n            super.addAttribute(attributeName, attributeValue);\r\n        }\r\n    }", "label": 0}
{"code": "public function setSoftwareConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\SoftwareConfig::class);\n        $this->software_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def argsort(self, axis=-1, kind='quicksort', order=None):\n        \"\"\"\n        Returns the indices that would sort an array.\n\n        .. note::\n\n                This method wraps `numpy.argsort`.  This documentation is \n                modified from that of `numpy.argsort`.\n\n        Perform an indirect sort along the given axis using the algorithm \n        specified by the `kind` keyword.  It returns an array of indices of the \n        same shape as the original array that index data along the given axis \n        in sorted order.\n\n        **Parameters**\n\n                **axis** : int or None, optional\n\n                        Axis along which to sort.  The default is -1 (the last \n                        axis). If `None`, the flattened array is used.\n\n                **kind** : {'quicksort', 'mergesort', 'heapsort'}, optional\n\n                        Sorting algorithm.\n\n                **order** : list, optional\n\n                        This argument specifies which fields to compare first, \n                        second, etc.  Not all fields need be specified.\n\n        **Returns**\n\n                **index_array** : ndarray, int\n\n                        Array of indices that sort the tabarray along the \n                        specified axis.  In other words, ``a[index_array]`` \n                        yields a sorted `a`.\n\n                **See Also**\n\n                        sort : Describes sorting algorithms used.\n                        lexsort : Indirect stable sort with multiple keys.\n                        ndarray.sort : Inplace sort.\n\n                **Notes**\n\n                        See `numpy.sort` for notes on the different sorting \n                        algorithms.\n\n                **Examples**\n\n                        Sorting with keys:\n\n                        >>> x = tabarray([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')])\n                        >>> x\n                        tabarray([(1, 0), (0, 1)], \n                              dtype=[('x', '<i4'), ('y', '<i4')])\n\n                        >>> x.argsort(order=('x','y'))\n                        array([1, 0])\n\n                        >>> x.argsort(order=('y','x'))\n                        array([0, 1])\n\n        \"\"\"\n        index_array = np.core.fromnumeric._wrapit(self, 'argsort', axis, \n                                                     kind, order)\n        index_array = index_array.view(np.ndarray)\n        return index_array", "label": 1}
{"code": "public function setDocuments($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1\\Target_DocumentsTarget::class);\n        $this->writeOneof(3, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def retrieve_GTF_field(field,gtf):\n    \"\"\"\n    Returns a field of choice from the attribute column of the GTF\n\n    :param field: field to be retrieved\n    :returns: a Pandas dataframe with one columns containing the field of choice\n\n    \"\"\"\n    inGTF=gtf.copy()\n    def splits(x):\n        l=x.split(\";\")\n        l=[ s.split(\" \") for s in l]\n        res=np.nan\n        for s in l:\n            if field in s:\n                if '\"' in s[-1]:\n                    res=s[-1][1:-1]\n                else:\n                    res=s[-1]\n        return res\n\n    inGTF[field]=inGTF['attribute'].apply(lambda x: splits(x))\n    return inGTF[[field]]", "label": 1}
{"code": "public static Object lookup(String jndiName)\r\n    {\r\n        if(log.isDebugEnabled()) log.debug(\"lookup(\"+jndiName+\") was called\");\r\n        try\r\n        {\r\n            return getContext().lookup(jndiName);\r\n        }\r\n        catch (NamingException e)\r\n        {\r\n            throw new OJBRuntimeException(\"Lookup failed for: \" + jndiName, e);\r\n        }\r\n        catch(OJBRuntimeException e)\r\n        {\r\n            throw e;\r\n        }\r\n    }", "label": 0}
{"code": "def find(*ids)\n      results = chain { criteria.update_options simple: true }.filter { _id == ids.flatten }.to_a\n\n      raise Chewy::DocumentNotFound, \"Could not find documents for ids #{ids.flatten}\" if results.empty?\n      ids.one? && !ids.first.is_a?(Array) ? results.first : results\n    end", "label": 4}
{"code": "func (c *AuthPreferenceV2) GetU2F() (*U2F, error) {\n\tif c.Spec.U2F == nil {\n\t\treturn nil, trace.NotFound(\"U2F configuration not found\")\n\t}\n\treturn c.Spec.U2F, nil\n}", "label": 5}
{"code": "public function update(\n        Context $start_context,\n        Context $end_context,\n        $has_leaving_statements,\n        array $vars_to_update,\n        array &$updated_vars\n    ) {\n        foreach ($start_context->vars_in_scope as $var_id => $old_type) {\n            // this is only true if there was some sort of type negation\n            if (in_array($var_id, $vars_to_update, true)) {\n                // if we're leaving, we're effectively deleting the possibility of the if types\n                $new_type = !$has_leaving_statements && $end_context->hasVariable($var_id)\n                    ? $end_context->vars_in_scope[$var_id]\n                    : null;\n\n                $existing_type = isset($this->vars_in_scope[$var_id]) ? $this->vars_in_scope[$var_id] : null;\n\n                if (!$existing_type) {\n                    if ($new_type) {\n                        $this->vars_in_scope[$var_id] = clone $new_type;\n                        $updated_vars[$var_id] = true;\n                    }\n\n                    continue;\n                }\n\n                // if the type changed within the block of statements, process the replacement\n                // also never allow ourselves to remove all types from a union\n                if ((!$new_type || !$old_type->equals($new_type))\n                    && ($new_type || count($existing_type->getTypes()) > 1)\n                ) {\n                    $existing_type->substitute($old_type, $new_type);\n\n                    if ($new_type && $new_type->from_docblock) {\n                        $existing_type->setFromDocblock();\n                    }\n\n                    $updated_vars[$var_id] = true;\n                }\n            }\n        }\n    }", "label": 2}
{"code": "func GetUnscaledBarcodeDimensions(pdf barcodePdf, code string) (w, h float64) {\n\tbarcodes.Lock()\n\tunscaled, ok := barcodes.cache[code]\n\tbarcodes.Unlock()\n\n\tif !ok {\n\t\terr := errors.New(\"Barcode not found\")\n\t\tpdf.SetError(err)\n\t\treturn\n\t}\n\n\treturn convertFrom96Dpi(pdf, float64(unscaled.Bounds().Dx())),\n\t\tconvertFrom96Dpi(pdf, float64(unscaled.Bounds().Dy()))\n}", "label": 5}
{"code": "def solve(m,c):\n    \"\"\"\n    run the algorithm to find the path list\n    \"\"\"\n    G={ (m,c,1):[] }\n    frontier=[ (m,c,1) ]  # 1 as boat starts on left bank \n    while len(frontier) > 0:\n        hold=list(frontier)\n        for node in hold:\n            newnode=[]\n            frontier.remove(node)\n            newnode.extend(pick_next_boat_trip(node, m,c, frontier))\n            for neighbor in newnode:\n                if neighbor not in G:\n                    G[node].append(neighbor)\n                    G[neighbor]=[node]\n                    frontier.append(neighbor)\n    return mod_plan.find_path_BFS(G,(m,c,1),(0,0,0))", "label": 1}
{"code": "def find_one_and_replace(filter, replacement, options = {})\n      find(filter, options).find_one_and_update(replacement, options)\n    end", "label": 4}
{"code": "func (v *Validate) RegisterValidationCtx(tag string, fn FuncCtx) error {\n\treturn v.registerValidation(tag, fn, false)\n}", "label": 5}
{"code": "def key?(key)\n      # First, check if item is already cached in memory\n      return true if @cache.key?(key)\n      # Otherwise, it might be cached on disk\n      # but we should not consider the disk cache if it is disabled\n      return false unless disk_cache_enabled?\n\n      path = path_to(hash(key))\n      File.file?(path) && File.readable?(path)\n    end", "label": 4}
{"code": "protected static function prepareRequest($url, $parameters = [], $headers = [])\n    {\n        $request = curl_init();\n\n        if ($query = http_build_query($parameters)) {\n            $url .= '?'.$query;\n        }\n\n        curl_setopt($request, CURLOPT_URL, $url);\n        curl_setopt($request, CURLOPT_RETURNTRANSFER, true);\n        curl_setopt($request, CURLOPT_HTTPHEADER, $headers);\n        curl_setopt($request, CURLINFO_HEADER_OUT, true);\n        curl_setopt($request, CURLOPT_SSL_VERIFYPEER, true);\n\n        return $request;\n    }", "label": 2}
{"code": "def read_fastas(input_files):\n    \"\"\"\n    Read the tumor and normal fastas into a joint dict.\n\n    :param dict input_files: A dict containing filename: filepath for T_ and N_ transgened files.\n    :return: The read fastas in a dictionary of tuples\n    :rtype: dict\n    \"\"\"\n    tumor_file = [y for x, y in input_files.items() if x.startswith('T')][0]\n    normal_file = [y for x, y in input_files.items() if x.startswith('N')][0]\n    output_files = defaultdict(list)\n    output_files = _read_fasta(tumor_file, output_files)\n    num_entries = len(output_files)\n    output_files = _read_fasta(normal_file, output_files)\n    assert len(output_files) == num_entries\n    return output_files", "label": 1}
{"code": "def get_xml_parser(encoding=None):\n    \"\"\"Returns an ``etree.ETCompatXMLParser`` instance.\"\"\"\n    parser = etree.ETCompatXMLParser(\n        huge_tree=True,\n        remove_comments=True,\n        strip_cdata=False,\n        remove_blank_text=True,\n        resolve_entities=False,\n        encoding=encoding\n    )\n\n    return parser", "label": 1}
{"code": "def create_role(name: 'new role', colour: 0, hoist: false, mentionable: false, permissions: 104_324_161, reason: nil)\n      colour = colour.respond_to?(:combined) ? colour.combined : colour\n\n      permissions = if permissions.is_a?(Array)\n                      Permissions.bits(permissions)\n                    elsif permissions.respond_to?(:bits)\n                      permissions.bits\n                    else\n                      permissions\n                    end\n\n      response = API::Server.create_role(@bot.token, @id, name, colour, hoist, mentionable, permissions, reason)\n\n      role = Role.new(JSON.parse(response), @bot, self)\n      @roles << role\n      role\n    end", "label": 4}
{"code": "def thumbnail_dimensions(geometry)\n      dimensions = ThumbnailDimensions.new(geometry, image.width, image.height)\n      { width: dimensions.width, height: dimensions.height }\n    end", "label": 4}
{"code": "function parsePatterns(options) {\n  return readFileTree(\n    options.src.patterns,\n    options.keys.patterns,\n    options\n  ).then(patternObj => {\n    return Promise.all(buildCollections(patternObj, options)).then(\n      () => patternObj,\n      error => DrizzleError.error(error, options.debug)\n    );\n  });\n}", "label": 3}
{"code": "private void postcheckMappingConditions(MtasParserObject object,\n      List<Map<String, String>> mappingConditions,\n      Map<String, List<MtasParserObject>> currentList)\n      throws MtasParserException {\n    precheckMappingConditions(object, mappingConditions, currentList);\n    for (Map<String, String> mappingCondition : mappingConditions) {\n      // condition on text\n      if (mappingCondition.get(\"type\")\n          .equals(MtasParserMapping.PARSER_TYPE_TEXT)) {\n        MtasParserObject[] checkObjects = computeObjectFromMappingValue(object,\n            mappingCondition, currentList);\n        if (checkObjects != null) {\n          String textCondition = mappingCondition.get(MAPPING_VALUE_CONDITION);\n          String textValue = object.getText();\n          Boolean notCondition = false;\n          if (mappingCondition.get(\"not\") != null) {\n            notCondition = true;\n          }\n          if ((textCondition == null)\n              && ((textValue == null) || textValue.isEmpty())) {\n            if (!notCondition) {\n              throw new MtasParserException(\"no text available\");\n            }\n          } else if ((textCondition != null) && (textValue == null)) {\n            if (!notCondition) {\n              throw new MtasParserException(\"condition \" + textCondition\n                  + \" on text not matched (is null)\");\n            }\n          } else if (textCondition != null) {\n            if (!notCondition && !textCondition.equals(textValue)) {\n              throw new MtasParserException(\"condition \" + textCondition\n                  + \" on text not matched (is \" + textValue + \")\");\n            } else if (notCondition && textCondition.equals(textValue)) {\n              throw new MtasParserException(\"condition NOT \" + textCondition\n                  + \" on text not matched (is \" + textValue + \")\");\n            }\n          }\n        }\n      }\n    }\n  }", "label": 0}
{"code": "public function setParameters($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dataproc\\V1\\TemplateParameter::class);\n        $this->parameters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (b *GRPCBroker) AcceptAndServe(id uint32, s func([]grpc.ServerOption) *grpc.Server) {\n\tlistener, err := b.Accept(id)\n\tif err != nil {\n\t\tlog.Printf(\"[ERR] plugin: plugin acceptAndServe error: %s\", err)\n\t\treturn\n\t}\n\tdefer listener.Close()\n\n\tvar opts []grpc.ServerOption\n\tif b.tls != nil {\n\t\topts = []grpc.ServerOption{grpc.Creds(credentials.NewTLS(b.tls))}\n\t}\n\n\tserver := s(opts)\n\n\t// Here we use a run group to close this goroutine if the server is shutdown\n\t// or the broker is shutdown.\n\tvar g run.Group\n\t{\n\t\t// Serve on the listener, if shutting down call GracefulStop.\n\t\tg.Add(func() error {\n\t\t\treturn server.Serve(listener)\n\t\t}, func(err error) {\n\t\t\tserver.GracefulStop()\n\t\t})\n\t}\n\t{\n\t\t// block on the closeCh or the doneCh. If we are shutting down close the\n\t\t// closeCh.\n\t\tcloseCh := make(chan struct{})\n\t\tg.Add(func() error {\n\t\t\tselect {\n\t\t\tcase <-b.doneCh:\n\t\t\tcase <-closeCh:\n\t\t\t}\n\t\t\treturn nil\n\t\t}, func(err error) {\n\t\t\tclose(closeCh)\n\t\t})\n\t}\n\n\t// Block until we are done\n\tg.Run()\n}", "label": 5}
{"code": "func NewDecoder(r io.Reader) *Decoder {\n\td := &Decoder{\n\t\tns:       make(map[string]string),\n\t\tnextByte: -1,\n\t\tline:     1,\n\t\tStrict:   true,\n\t}\n\td.switchToReader(r)\n\treturn d\n}", "label": 5}
{"code": "protected <E> E read(Supplier<E> sup) {\n        try {\n            this.lock.readLock().lock();\n            return sup.get();\n        } finally {\n            this.lock.readLock().unlock();\n        }\n    }", "label": 0}
{"code": "public function wait($allowed_methods = null, $non_blocking = false, $timeout = 0)\n    {\n        $this->debug->debug_allowed_methods($allowed_methods);\n\n        $deferred = $this->process_deferred_methods($allowed_methods);\n        if ($deferred['dispatch'] === true) {\n            return $this->dispatch_deferred_method($deferred['queued_method']);\n        }\n\n        // timeouts must be deactivated for non-blocking actions\n        if (true === $non_blocking) {\n            $timeout = null;\n        }\n\n        // No deferred methods?  wait for new ones\n        while (true) {\n            try {\n                list($frame_type, $payload) = $this->next_frame($timeout);\n            } catch (AMQPNoDataException $e) {\n                // no data ready for non-blocking actions - stop and exit\n                break;\n            } catch (AMQPConnectionClosedException $exception) {\n                if ($this instanceof AMQPChannel) {\n                    $this->do_close();\n                }\n                throw $exception;\n            }\n\n            $this->validate_method_frame($frame_type);\n            $this->validate_frame_payload($payload);\n\n            $method_sig = $this->build_method_signature($payload);\n            $args = $this->extract_args($payload);\n\n            $this->debug->debug_method_signature('> %s', $method_sig);\n\n            $amqpMessage = $this->maybe_wait_for_content($method_sig);\n\n            if ($this->should_dispatch_method($allowed_methods, $method_sig)) {\n                return $this->dispatch($method_sig, $args, $amqpMessage);\n            }\n\n            // Wasn't what we were looking for? save it for later\n            $this->debug->debug_method_signature('Queueing for later: %s', $method_sig);\n            $this->method_queue[] = array($method_sig, $args, $amqpMessage);\n\n            if ($non_blocking) {\n                break;\n            }\n        }\n    }", "label": 2}
{"code": "def update_role_positions(role_positions)\n      response = JSON.parse(API::Server.update_role_positions(@bot.token, @id, role_positions))\n      response.each do |data|\n        updated_role = Role.new(data, @bot, self)\n        role(updated_role.id).update_from(updated_role)\n      end\n    end", "label": 4}
{"code": "public static base_response flush(nitro_service client, cacheobject resource) throws Exception {\n\t\tcacheobject flushresource = new cacheobject();\n\t\tflushresource.locator = resource.locator;\n\t\tflushresource.url = resource.url;\n\t\tflushresource.host = resource.host;\n\t\tflushresource.port = resource.port;\n\t\tflushresource.groupname = resource.groupname;\n\t\tflushresource.httpmethod = resource.httpmethod;\n\t\tflushresource.force = resource.force;\n\t\treturn flushresource.perform_operation(client,\"flush\");\n\t}", "label": 0}
{"code": "def update_voice_state(data)\n      @session_id = data['session_id']\n\n      server_id = data['guild_id'].to_i\n      server = server(server_id)\n      return unless server\n\n      user_id = data['user_id'].to_i\n      old_voice_state = server.voice_states[user_id]\n      old_channel_id = old_voice_state.voice_channel.id if old_voice_state\n\n      server.update_voice_state(data)\n\n      old_channel_id\n    end", "label": 4}
{"code": "def get_configs(self):\n        \"\"\"\n        Return an iterable of models.\n        \"\"\"\n        self.bots.check_models_ready()\n        for config in self.configs.values():\n            yield config", "label": 1}
{"code": "function keyupHandler (matchChar, method, evt) {\n  // except for esc, we don't want to fire events when somebody is typing in an input\n  if ((evt.target.tagName !== 'INPUT' && evt.target.tagName !== 'TEXTAREA' && !evt.target.hasAttribute('contenteditable')) || keysMatch(evt, 'esc')) {\n    if (keysMatch(evt, matchChar)) method(evt);\n  }\n}", "label": 3}
{"code": "public function setMissingZones($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->missing_zones = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (p *Process) WithIO() *Process {\n\tp.IO = &ProcessIO{\n\t\tOut: new(bytes.Buffer),\n\t\tErr: new(bytes.Buffer),\n\t}\n\n\treturn p\n}", "label": 5}
{"code": "public function setLocals($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Debugger\\V2\\Variable::class);\n        $this->locals = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def unpause(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Unpause a running result.\n\n        :param id: Result ID as an int.\n        \"\"\"\n        return self.service.post(self.base+str(id)+'/unpause/')", "label": 1}
{"code": "public boolean checkContains(String uri, String[] patterns) {\n\t\tfor (String pattern : patterns) {\n\t\t\tif (pattern.length() > 0) {\n\t\t\t\tif (uri.contains(pattern)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "label": 0}
{"code": "def cache_control_expires(num_hours):\n    \"\"\"\n    Set the appropriate Cache-Control and Expires headers for the given\n    number of hours.\n    \"\"\"\n    num_seconds = int(num_hours * 60 * 60)\n\n    def decorator(func):\n        @wraps(func)\n        def inner(request, *args, **kwargs):\n            response = func(request, *args, **kwargs)\n            patch_response_headers(response, num_seconds)\n            return response\n\n        return inner\n\n    return decorator", "label": 1}
{"code": "def delete_guild_member(data)\n      server_id = data['guild_id'].to_i\n      server = self.server(server_id)\n\n      user_id = data['user']['id'].to_i\n      server.delete_member(user_id)\n    rescue Discordrb::Errors::NoPermission\n      Discordrb::LOGGER.warn(\"delete_guild_member attempted to access a server for which the bot doesn't have permission! Not sure what happened here, ignoring\")\n    end", "label": 4}
{"code": "def write(self, message, flush=False):\n        \"\"\"Write something on the default stream with a prefixed message\"\"\"\n        # this need be threadsafe because the concurrent spinning running on\n        # the stderr\n        with self.lock:\n            self.paralell_stream.erase()\n            super(Clean, self).write(message, flush)", "label": 1}
{"code": "func (ctx *Context) String() string {\n\treturn fmt.Sprintf(\"user %v, resource: %v\", ctx.User, ctx.Resource)\n}", "label": 5}
{"code": "function (output, chunk) {\n                var me = this, stream = me._stream;\n                stream.pause();\n                output.write(chunk).then(function () {\n                    stream.resume();\n                }, me._reject);\n            }", "label": 3}
{"code": "def _proxy_to_logger(self, method_name, event, *event_args,\n                         **event_kw):\n        \"\"\"\n        Propagate a method call to the wrapped logger.\n\n        This is the same as the superclass implementation, except that\n        it also preserves positional arguments in the `event_dict` so\n        that the stdblib's support for format strings can be used.\n        \"\"\"\n\n        if isinstance(event, bytes):\n            event = event.decode('utf-8')\n\n        if event_args:\n            event_kw['positional_args'] = event_args\n\n        return super(BoundLevelLogger, self)._proxy_to_logger(method_name,\n                                                         event=event,\n                                                         **event_kw)", "label": 1}
{"code": "func (tc *TeleportClient) Logout() error {\n\terr := tc.localAgent.DeleteKey()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "private GraphicsDocument createLabelDocument(StringWriter writer, LabelStyleInfo labelStyleInfo)\n\t\t\tthrows RenderException {\n\n\t\tif (TileMetadata.PARAM_SVG_RENDERER.equalsIgnoreCase(renderer)) {\n\t\t\tDefaultSvgDocument document = new DefaultSvgDocument(writer, false);\n\t\t\tdocument.setMaximumFractionDigits(MAXIMUM_FRACTION_DIGITS);\n\t\t\tdocument.registerWriter(InternalTileImpl.class, new SvgLabelTileWriter(getTransformer(), labelStyleInfo,\n\t\t\t\t\tgeoService, textService));\n\t\t\treturn document;\n\t\t} else if (TileMetadata.PARAM_VML_RENDERER.equalsIgnoreCase(renderer)) {\n\t\t\tDefaultVmlDocument document = new DefaultVmlDocument(writer);\n\t\t\tint coordWidth = tile.getScreenWidth();\n\t\t\tint coordHeight = tile.getScreenHeight();\n\t\t\tdocument.registerWriter(InternalFeatureImpl.class, new VmlFeatureWriter(getTransformer(), coordWidth,\n\t\t\t\t\tcoordHeight));\n\t\t\tdocument.registerWriter(InternalTileImpl.class, new VmlLabelTileWriter(coordWidth, coordHeight,\n\t\t\t\t\tgetTransformer(), labelStyleInfo, geoService, textService));\n\t\t\tdocument.setMaximumFractionDigits(MAXIMUM_FRACTION_DIGITS);\n\t\t\treturn document;\n\t\t} else {\n\t\t\tthrow new RenderException(ExceptionCode.RENDERER_TYPE_NOT_SUPPORTED, renderer);\n\t\t}\n\t}", "label": 0}
{"code": "private function resolveMagicCall($method, $by, array $arguments)\n    {\n        if (! $arguments) {\n            throw InvalidMagicMethodCall::onMissingParameter($method . $by);\n        }\n\n        $fieldName = lcfirst(Inflector::classify($by));\n\n        if ($this->class->getProperty($fieldName) === null) {\n            throw InvalidMagicMethodCall::becauseFieldNotFoundIn(\n                $this->entityName,\n                $fieldName,\n                $method . $by\n            );\n        }\n\n        return $this->{$method}([$fieldName => $arguments[0]], ...array_slice($arguments, 1));\n    }", "label": 2}
{"code": "public function generate(ClassMetadataDefinition $definition) : string\n    {\n        $metadata = $this->mappingDriver->loadMetadataForClass(\n            $definition->entityClassName,\n            $definition->parentClassMetadata\n        );\n\n        return $this->metadataExporter->export($metadata);\n    }", "label": 2}
{"code": "def embedded_targets_in_native_target(native_target)\n      native_targets.select do |target|\n        host_targets_for_embedded_target(target).map(&:uuid).include? native_target.uuid\n      end\n    end", "label": 4}
{"code": "function getArguments(req) {\n    const result = req.body || {};\n    for (let i in req.query) {\n        result[i] = req.query[i];\n    }\n    return result;\n}", "label": 3}
{"code": "def read_json_double\n      @context.read(@reader)\n      num = 0\n      if (@reader.peek == @@kJSONStringDelimiter)\n        str = read_json_string(true)\n        # Check for NaN, Infinity and -Infinity\n        if (str == @@kThriftNan)\n          num = (+1.0/0.0)/(+1.0/0.0)\n        elsif (str == @@kThriftInfinity)\n          num = +1.0/0.0\n        elsif (str == @@kThriftNegativeInfinity)\n          num = -1.0/0.0\n        else\n          if (!@context.escapeNum)\n            # Raise exception -- we should not be in a string in this case\n            raise ProtocolException.new(ProtocolException::INVALID_DATA, \"Numeric data unexpectedly quoted\")\n          end\n          begin\n            num = Float(str)\n          rescue\n            raise ProtocolException.new(ProtocolException::INVALID_DATA, \"Expected numeric value; got \\\"#{str}\\\"\")\n          end\n        end\n      else\n        if (@context.escapeNum)\n          # This will throw - we should have had a quote if escapeNum == true\n          read_json_syntax_char(@@kJSONStringDelimiter)\n        end\n        str = read_json_numeric_chars\n        begin\n          num = Float(str)\n        rescue\n          raise ProtocolException.new(ProtocolException::INVALID_DATA, \"Expected numeric value; got \\\"#{str}\\\"\")\n        end\n      end\n      return num\n    end", "label": 4}
{"code": "private function determineSuggestedLevel(array $levelChoices, $suggestedLevel, array $files)\n    {\n        $reasons = [];\n\n        if ($levelChoices !== $this->levels) {\n            $suggestedLevel = array_keys($levelChoices)[0];\n            $reasons[] = 'Another change specified a higher minimum release level.';\n        }\n\n        if (isset($levelChoices[self::LEVEL_MINOR]) && (bool) array_filter($files, function ($file) {\n            $parts = explode('/', $file);\n            return isset($parts[1]) && $parts[1] === 'src' && count($parts) > 2;\n        })) {\n            $suggestedLevel = self::LEVEL_MINOR;\n            $reasons[] = 'There are changes in the component `src` folder.';\n        }\n\n        if (isset($levelChoices[self::LEVEL_MINOR]) && in_array('composer.json', $files)) {\n            $suggestedLevel = self::LEVEL_MINOR;\n            $reasons[] = 'The component `composer.json` file was modified.';\n        }\n\n        if ($suggestedLevel === self::LEVEL_PATCH) {\n            $reasons[] = 'None of the indicators show the commit includes a client-facing code change.';\n        }\n\n        return [$suggestedLevel, $reasons];\n    }", "label": 2}
{"code": "private Class getDynamicProxyClass(Class baseClass) {\r\n        Class[] m_dynamicProxyClassInterfaces;\r\n        if (foundInterfaces.containsKey(baseClass)) {\r\n            m_dynamicProxyClassInterfaces = (Class[])foundInterfaces.get(baseClass);\r\n        } else {\r\n            m_dynamicProxyClassInterfaces = getInterfaces(baseClass);\r\n            foundInterfaces.put(baseClass, m_dynamicProxyClassInterfaces);\r\n        }\r\n\r\n        // return dynymic Proxy Class implementing all interfaces\r\n        Class proxyClazz = Proxy.getProxyClass(baseClass.getClassLoader(), m_dynamicProxyClassInterfaces);\r\n        return proxyClazz;\r\n    }", "label": 0}
{"code": "def set_keep_alive\n      return @keep_alive = false unless @persistent\n\n      @keep_alive =\n        case @parser.http_version\n        when HTTP_1_0 # HTTP/1.0 requires opt in for Keep Alive\n          @parser.headers[Headers::CONNECTION] == KEEP_ALIVE\n        when HTTP_1_1 # HTTP/1.1 is opt-out\n          @parser.headers[Headers::CONNECTION] != CLOSE\n        else # Anything else we assume doesn't supportit\n          false\n        end\n    end", "label": 4}
{"code": "@Override\n\tpublic void visit(FeatureTypeStyle fts) {\n\n\t\tFeatureTypeStyle copy = new FeatureTypeStyleImpl(\n\t\t\t\t(FeatureTypeStyleImpl) fts);\n\t\tRule[] rules = fts.getRules();\n\t\tint length = rules.length;\n\t\tRule[] rulesCopy = new Rule[length];\n\t\tfor (int i = 0; i < length; i++) {\n\t\t\tif (rules[i] != null) {\n\t\t\t\trules[i].accept(this);\n\t\t\t\trulesCopy[i] = (Rule) pages.pop();\n\t\t\t}\n\t\t}\n\t\tcopy.setRules(rulesCopy);\n\t\tif (fts.getTransformation() != null) {\n\t\t\tcopy.setTransformation(copy(fts.getTransformation()));\n\t\t}\n\t\tif (STRICT && !copy.equals(fts)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Was unable to duplicate provided FeatureTypeStyle:\" + fts);\n\t\t}\n\t\tpages.push(copy);\n\t}", "label": 0}
{"code": "public function write_long($n)\n    {\n        if (($n < 0) || ($n > 4294967295)) {\n            throw new AMQPInvalidArgumentException('Long out of range: ' . $n);\n        }\n\n        //Numeric strings >PHP_INT_MAX on 32bit are casted to PHP_INT_MAX, damn PHP\n        if (empty($this->is64bits) && is_string($n)) {\n            $n = (float) $n;\n        }\n        $this->out .= pack('N', $n);\n\n        return $this;\n    }", "label": 2}
{"code": "func BeforeEach(body interface{}, timeout ...float64) bool {\n\tglobalSuite.PushBeforeEachNode(body, codelocation.New(1), parseTimeout(timeout...))\n\treturn true\n}", "label": 5}
{"code": "function(hook, context){\n  var hs = $('#heading-selection');\n  hs.on('change', function(){\n    var value = $(this).val();\n    var intValue = parseInt(value,10);\n    if(!_.isNaN(intValue)){\n      context.ace.callWithAce(function(ace){\n        ace.ace_doInsertHeading(intValue);\n      },'insertheading' , true);\n      hs.val(\"dummy\");\n    }\n  })\n}", "label": 3}
{"code": "def check_for_lounge_upgrade(self, email, password):\n        \"\"\"Check the CDRouter Support Lounge for eligible upgrades using your\n        Support Lounge email & password.\n\n        :param email: CDRouter Support Lounge email as a string.\n        :param password: CDRouter Support Lounge password as a string.\n        :return: :class:`system.Release <system.Release>` object\n        :rtype: system.Release\n        \"\"\"\n        schema = ReleaseSchema()\n        resp = self.service.post(self.base+'lounge/check/',\n                                 json={'email': email, 'password': password})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "def strip_inserts(fasta):\n    \"\"\"\n    remove insertion columns from aligned fasta file\n    \"\"\"\n    for seq in parse_fasta(fasta):\n        seq[1] = ''.join([b for b in seq[1] if b == '-' or b.isupper()])\n        yield seq", "label": 1}
{"code": "public List<GetLocationResult> search(String q, int maxRows, Locale locale)\n\t\t\tthrows Exception {\n\t\tList<GetLocationResult> searchResult = new ArrayList<GetLocationResult>();\n\n\t\tString url = URLEncoder.encode(q, \"UTF8\");\n\t\turl = \"q=select%20*%20from%20geo.placefinder%20where%20text%3D%22\"\n\t\t\t\t+ url + \"%22\";\n\t\tif (maxRows > 0) {\n\t\t\turl = url + \"&count=\" + maxRows;\n\t\t}\n\t\turl = url + \"&flags=GX\";\n\t\tif (null != locale) {\n\t\t\turl = url + \"&locale=\" + locale;\n\t\t}\n\t\tif (appId != null) {\n\t\t\turl = url + \"&appid=\" + appId;\n\t\t}\n\n\t\tInputStream inputStream = connect(url);\n\t\tif (null != inputStream) {\n\t\t\tSAXBuilder parser = new SAXBuilder();\n\t\t\tDocument doc = parser.build(inputStream);\n\n\t\t\tElement root = doc.getRootElement();\n\n\t\t\t// check code for exception\n\t\t\tString message = root.getChildText(\"Error\");\n\t\t\t// Integer errorCode = Integer.parseInt(message);\n\t\t\tif (message != null && Integer.parseInt(message) != 0) {\n\t\t\t\tthrow new Exception(root.getChildText(\"ErrorMessage\"));\n\t\t\t}\n\t\t\tElement results = root.getChild(\"results\");\n\t\t\tfor (Object obj : results.getChildren(\"Result\")) {\n\t\t\t\tElement toponymElement = (Element) obj;\n\t\t\t\tGetLocationResult location = getLocationFromElement(toponymElement);\n\t\t\t\tsearchResult.add(location);\n\t\t\t}\n\t\t}\n\t\treturn searchResult;\n\t}", "label": 0}
{"code": "def get_files_from_filestore(job, files, work_dir, cache=True, docker=False):\n    \"\"\"\n    This is adapted from John Vivian's return_input_paths from the RNA-Seq pipeline.\n\n    Returns the paths of files from the FileStore if they are not present.\n    If docker=True, return the docker path for the file.\n    If the file extension is tar.gz, then tar -zxvf it.\n\n    files is a dict with:\n        keys = the name of the file to be returned in toil space\n        value = the input value for the file (can be toil temp file)\n    work_dir is the location where the file should be stored\n    cache indiciates whether caching should be used\n    \"\"\"\n    for name in files.keys():\n        outfile = job.fileStore.readGlobalFile(files[name], '/'.join([work_dir, name]), cache=cache)\n        # If the file pointed to a tarball, extract it to WORK_DIR\n        if tarfile.is_tarfile(outfile) and file_xext(outfile).startswith('.tar'):\n            untar_name = os.path.basename(strip_xext(outfile))\n            files[untar_name] = untargz(outfile, work_dir)\n            files.pop(name)\n            name = os.path.basename(untar_name)\n        # If the file is gzipped but NOT a tarfile, gunzip it to work_dir. However, the file is\n        # already named x.gz so we need to write to a temporary file x.gz_temp then do a move\n        # operation to overwrite x.gz.\n        elif is_gzipfile(outfile) and file_xext(outfile) == '.gz':\n            ungz_name = strip_xext(outfile)\n            with gzip.open(outfile, 'rb') as gz_in, open(ungz_name, 'w') as ungz_out:\n                shutil.copyfileobj(gz_in, ungz_out)\n            files[os.path.basename(ungz_name)] = outfile\n            files.pop(name)\n            name = os.path.basename(ungz_name)\n        else:\n            files[name] = outfile\n        # If the files will be sent to docker, we will mount work_dir to the container as /data and\n        # we want the /data prefixed path to the file\n        if docker:\n            files[name] = docker_path(files[name])\n    return files", "label": 1}
{"code": "func ExistsNative(table Table, chain string, rule ...string) bool {\n\treturn exists(true, table, chain, rule...)\n}", "label": 5}
{"code": "def write_attribute(name, value)\n      access = database_field_name(name)\n      if attribute_writable?(access)\n        _assigning do\n          validate_attribute_value(access, value)\n          localized = fields[access].try(:localized?)\n          attributes_before_type_cast[name.to_s] = value\n          typed_value = typed_value_for(access, value)\n          unless attributes[access] == typed_value || attribute_changed?(access)\n            attribute_will_change!(access)\n          end\n          if localized\n            attributes[access] ||= {}\n            attributes[access].merge!(typed_value)\n          else\n            attributes[access] = typed_value\n          end\n          typed_value\n        end\n      end\n    end", "label": 4}
{"code": "public static function read_value( $raw_value, $assoc_args = array() ) {\n\t\tif ( \\WP_CLI\\Utils\\get_flag_value( $assoc_args, 'format' ) === 'json' ) {\n\t\t\t$value = json_decode( $raw_value, true );\n\t\t\tif ( null === $value ) {\n\t\t\t\tself::error( sprintf( 'Invalid JSON: %s', $raw_value ) );\n\t\t\t}\n\t\t} else {\n\t\t\t$value = $raw_value;\n\t\t}\n\n\t\treturn $value;\n\t}", "label": 2}
{"code": "def find_field(browser, field, value):\n    \"\"\"Locate an input field of a given value\n\n    This first looks for the value as the id of the element, then\n    the name of the element, then a label for the element.\n\n    \"\"\"\n    return find_field_by_id(browser, field, value) + \\\n        find_field_by_name(browser, field, value) + \\\n        find_field_by_label(browser, field, value)", "label": 1}
{"code": "public void applyXMLDSigAsFirstChild (@Nonnull final PrivateKey aPrivateKey,\n                                        @Nonnull final X509Certificate aCertificate,\n                                        @Nonnull final Document aDocument) throws Exception\n  {\n    ValueEnforcer.notNull (aPrivateKey, \"privateKey\");\n    ValueEnforcer.notNull (aCertificate, \"certificate\");\n    ValueEnforcer.notNull (aDocument, \"document\");\n    ValueEnforcer.notNull (aDocument.getDocumentElement (), \"Document is missing a document element\");\n    if (aDocument.getDocumentElement ().getChildNodes ().getLength () == 0)\n      throw new IllegalArgumentException (\"Document element has no children!\");\n\n    // Check that the document does not contain another Signature element\n    final NodeList aNodeList = aDocument.getElementsByTagNameNS (XMLSignature.XMLNS, XMLDSigSetup.ELEMENT_SIGNATURE);\n    if (aNodeList.getLength () > 0)\n      throw new IllegalArgumentException (\"Document already contains an XMLDSig Signature element!\");\n\n    // Create the XMLSignature, but don't sign it yet.\n    final XMLSignature aXMLSignature = createXMLSignature (aCertificate);\n\n    // Create a DOMSignContext and specify the RSA PrivateKey and\n    // location of the resulting XMLSignature's parent element.\n    // -> The signature is always the first child element of the document\n    // element for ebInterface\n    final DOMSignContext aDOMSignContext = new DOMSignContext (aPrivateKey,\n                                                               aDocument.getDocumentElement (),\n                                                               aDocument.getDocumentElement ().getFirstChild ());\n\n    // The namespace prefix to be used for the signed XML\n    aDOMSignContext.setDefaultNamespacePrefix (DEFAULT_NS_PREFIX);\n\n    // Marshal, generate, and sign the enveloped signature.\n    aXMLSignature.sign (aDOMSignContext);\n  }", "label": 0}
{"code": "function hasChecklist(Class) {\n  var checklist = getChecklist(Class);\n\n  for (var _len2 = arguments.length, items = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n    items[_key2 - 1] = arguments[_key2];\n  }\n\n  if (checklist && items.length) {\n    for (var _i2 = 0; _i2 < items.length; _i2++) {\n      var item = items[_i2];\n\n      if (!checklist[item]) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  return checklist;\n}", "label": 3}
{"code": "public static base_response unset(nitro_service client, cmpparameter resource, String[] args) throws Exception{\n\t\tcmpparameter unsetresource = new cmpparameter();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "public static auditnslogpolicy_systemglobal_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauditnslogpolicy_systemglobal_binding obj = new auditnslogpolicy_systemglobal_binding();\n\t\tobj.set_name(name);\n\t\tauditnslogpolicy_systemglobal_binding response[] = (auditnslogpolicy_systemglobal_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public E argmin(Comparator<E> tieBreaker) {\r\n    int min = Integer.MAX_VALUE;\r\n    E argmin = null;\r\n    for (E key : map.keySet()) {\r\n      int count = getIntCount(key);\r\n      if (argmin == null || count < min || (count == min && tieBreaker.compare(key, argmin) < 0)) {\r\n        min = count;\r\n        argmin = key;\r\n      }\r\n    }\r\n    return argmin;\r\n  }", "label": 0}
{"code": "func Update(path, IP, hostname string) error {\n\tdefer pathLock(path)()\n\n\told, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\tvar re = regexp.MustCompile(fmt.Sprintf(\"(\\\\S*)(\\\\t%s)(\\\\s|\\\\.)\", regexp.QuoteMeta(hostname)))\n\treturn ioutil.WriteFile(path, re.ReplaceAll(old, []byte(IP+\"$2\"+\"$3\")), 0644)\n}", "label": 5}
{"code": "function indexOf(arr, x, comparator)\n{\n  var cmp = comparator || equalsStrict;\n\n  for (var i = 0, n = arr.length; i < n; i++)\n  {\n    if ( cmp( arr[i], x ) )\n    {\n      return i;\n    }\n  }\n\n  return false;\n}", "label": 3}
{"code": "function __err2code(program, err) {\n            if (typeof err.stack !== 'string')\n                return indent(program, 4);\n            var match = /<anonymous>:(\\d+):(\\d+)\\)/.exec(err.stack);\n            if (!match) {\n                return indent(program, 4);\n            }\n            var line = parseInt(match[1], 10)-1,\n                start = line - 3,\n                end = line + 4,\n                lines = program.split(\"\\n\");\n            if (start < 0) start = 0;\n            if (end > lines.length) end = lines.length;\n            var code = [];\n            start = 0; end = lines.length;\n            while (start < end) {\n                code.push(start === line ? \"--> \"+lines[start] : \"    \"+lines[start]);\n                start++;\n            }\n            return indent(code.join('\\n'), 4);\n        }", "label": 3}
{"code": "public static int lookupShaper(String name) {\r\n    if (name == null) {\r\n      return NOWORDSHAPE;\r\n    } else if (name.equalsIgnoreCase(\"dan1\")) {\r\n      return WORDSHAPEDAN1;\r\n    } else if (name.equalsIgnoreCase(\"chris1\")) {\r\n      return WORDSHAPECHRIS1;\r\n    } else if (name.equalsIgnoreCase(\"dan2\")) {\r\n      return WORDSHAPEDAN2;\r\n    } else if (name.equalsIgnoreCase(\"dan2useLC\")) {\r\n      return WORDSHAPEDAN2USELC;\r\n    } else if (name.equalsIgnoreCase(\"dan2bio\")) {\r\n      return WORDSHAPEDAN2BIO;\r\n    } else if (name.equalsIgnoreCase(\"dan2bioUseLC\")) {\r\n      return WORDSHAPEDAN2BIOUSELC;\r\n    } else if (name.equalsIgnoreCase(\"jenny1\")) {\r\n      return WORDSHAPEJENNY1;\r\n    } else if (name.equalsIgnoreCase(\"jenny1useLC\")) {\r\n      return WORDSHAPEJENNY1USELC;\r\n    } else if (name.equalsIgnoreCase(\"chris2\")) {\r\n      return WORDSHAPECHRIS2;\r\n    } else if (name.equalsIgnoreCase(\"chris2useLC\")) {\r\n      return WORDSHAPECHRIS2USELC;\r\n    } else if (name.equalsIgnoreCase(\"chris3\")) {\r\n      return WORDSHAPECHRIS3;\r\n    } else if (name.equalsIgnoreCase(\"chris3useLC\")) {\r\n      return WORDSHAPECHRIS3USELC;\r\n    } else if (name.equalsIgnoreCase(\"chris4\")) {\r\n      return WORDSHAPECHRIS4;\r\n    } else if (name.equalsIgnoreCase(\"digits\")) {\r\n      return WORDSHAPEDIGITS;\r\n    } else {\r\n      return NOWORDSHAPE;\r\n    }\r\n  }", "label": 0}
{"code": "def create(self, no_data=False):\n        \"\"\"Declare materalized view.\"\"\"\n\n        if self.query:\n            ddl_statement = self.compile_create_as()\n        else:\n            ddl_statement = self.compile_create()\n\n        if no_data:\n            ddl_statement += '\\nWITH NO DATA'\n\n        return ddl_statement, self.query_values", "label": 1}
{"code": "function (deltaTime, on, firstChannel, chord, velocity) {\n  var arr = [];\n\n  // Make note event for first note after appropriate time\n  arr.push(makeNoteEvent(deltaTime, on, firstChannel, noteValue(_.first(chord)), velocity));\n\n  // Make note event for rest of the notes\n  _.each(_.rest(chord), function (note, i) {\n    arr.push(makeNoteEvent(0, on, i + firstChannel, noteValue(note), velocity));\n  });\n\n  return Buffer.concat(arr);\n}", "label": 3}
{"code": "func checkRunning() bool {\n\tvar zone string\n\tvar err error\n\n\tif connection != nil {\n\t\terr = connection.sysobj.Call(dbusInterface+\".getDefaultZone\", 0).Store(&zone)\n\t\treturn err == nil\n\t}\n\treturn false\n}", "label": 5}
{"code": "public function setSaveFindings($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Action_SaveFindings::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def reconcile(self, statuses):\n        \"\"\"Allows the framework to query the status for non-terminal tasks.\n\n        This causes the master to send back the latest task status for each task\n        in 'statuses', if possible. Tasks that are no longer known will result\n        in a TASK_LOST update. If statuses is empty, then the master will send\n        the latest status for each task currently known.\n        \"\"\"\n        logging.info('Reconciles task statuses {}'.format(statuses))\n        return self.driver.reconcileTasks(map(encode, statuses))", "label": 1}
{"code": "func (ts *Store) check(id string) (string, error) {\n\ttreepath := ts.GetPath(id)\n\thash, err := ioutil.ReadFile(filepath.Join(treepath, hashfilename))\n\tif err != nil {\n\t\treturn \"\", errwrap.Wrap(ErrReadHashfile, err)\n\t}\n\tcurhash, err := ts.Hash(id)\n\tif err != nil {\n\t\treturn \"\", errwrap.Wrap(errors.New(\"cannot calculate tree hash\"), err)\n\t}\n\tif curhash != string(hash) {\n\t\treturn \"\", fmt.Errorf(\"wrong tree hash: %s, expected: %s\", curhash, hash)\n\t}\n\treturn curhash, nil\n}", "label": 5}
{"code": "public function defaultContent()\n    {\n        $params = ['id' => null];\n        $this->executor->execute(DriverCommand::SWITCH_TO_FRAME, $params);\n\n        return $this->driver;\n    }", "label": 2}
{"code": "public function setPubSub($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Action_PublishToPubSub::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def create(opts = {})\n      operation = { :create => name }.merge(options)\n      operation.delete(:write)\n      server = next_primary\n      if (options[:collation] || options[Operation::COLLATION]) && !server.features.collation_enabled?\n        raise Error::UnsupportedCollation.new\n      end\n      client.send(:with_session, opts) do |session|\n        Operation::Create.new({\n                                selector: operation,\n                                db_name: database.name,\n                                write_concern: write_concern,\n                                session: session\n                                }).execute(server)\n      end\n    end", "label": 4}
{"code": "def stdout_redirector():\n    \"\"\"\n    Simplify redirect of stdout.\n\n    Taken from here: https://eli.thegreenplace.net/2015/redirecting-all-kinds-of-stdout-in-python/\n    \"\"\"\n    old_stdout = sys.stdout\n    sys.stdout = Stream()\n    try:\n        yield sys.stdout\n    finally:\n        sys.stdout.close()\n        sys.stdout = old_stdout", "label": 1}
{"code": "public void addFkToThisClass(String column)\r\n    {\r\n        if (fksToThisClass == null)\r\n        {\r\n            fksToThisClass = new Vector();\r\n        }\r\n        fksToThisClass.add(column);\r\n        fksToThisClassAry = null;\r\n    }", "label": 0}
{"code": "public function parse($text, $context = null)\n    {\n        $parser = $this->getParser($context);\n\n        $this->events->dispatch(new Parsing($parser, $context, $text));\n\n        return $parser->parse($text);\n    }", "label": 2}
{"code": "def to_a\n      @control.all_cookies.map do |e|\n        e.merge(expires: e[:expires] ? e[:expires].to_time : nil)\n      end\n    end", "label": 4}
{"code": "public static SortedSet<String> getIdsFromParameters(SolrParams params,\n      String prefix) {\n    SortedSet<String> ids = new TreeSet<>();\n    Iterator<String> it = params.getParameterNamesIterator();\n    Pattern pattern = Pattern\n        .compile(\"^\" + Pattern.quote(prefix) + \"\\\\.([^\\\\.]+)(\\\\..*|$)\");\n    while (it.hasNext()) {\n      String item = it.next();\n      Matcher m = pattern.matcher(item);\n      if (m.matches()) {\n        ids.add(m.group(1));\n      }\n    }\n    return ids;\n  }", "label": 0}
{"code": "public function download(array $params): string\n    {\n        unset($this->payload['spbill_create_ip']);\n\n        $this->payload = Support::filterPayload($this->payload, $params, true);\n\n        Events::dispatch(Events::METHOD_CALLED, new Events\\MethodCalled('Wechat', 'Download', $this->gateway, $this->payload));\n\n        $result = Support::getInstance()->post(\n            'pay/downloadbill',\n            Support::getInstance()->toXml($this->payload)\n        );\n\n        if (is_array($result)) {\n            throw new GatewayException('Get Wechat API Error: '.$result['return_msg'], $result);\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "func closeContext(key string, val interface{}) {\n\tgo func() {\n\t\tlog.Infof(\"[WEB] closing context %v\", key)\n\t\tctx, ok := val.(*SessionContext)\n\t\tif !ok {\n\t\t\tlog.Warningf(\"warning, not valid value type %T\", val)\n\t\t\treturn\n\t\t}\n\t\tif err := ctx.Close(); err != nil {\n\t\t\tlog.Infof(\"failed to close context: %v\", err)\n\t\t}\n\t}()\n}", "label": 5}
{"code": "func (b *LoginBody) C14N() string {\n\treq, err := xml.Marshal(b.Req)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn string(req)\n}", "label": 5}
{"code": "public function reload(array $options = [])\n    {\n        return $this->info = $this->connection->getDatabase([\n            'name' => $this->name\n        ] + $options);\n    }", "label": 2}
{"code": "def reset(self):\n        \"\"\" Re-initialises the environment.\n        \"\"\"\n        logger.info(\"Reseting environment.\")\n\n        self._step = 0\n\n        # Reset the set-point of each generator to its original value.\n        gs = [g for g in self.case.online_generators if g.bus.type !=REFERENCE]\n        for i, g in enumerate(gs):\n            g.p = self._Pg0[i]\n\n        # Apply load profile to the original demand at each bus.\n        for i, b in enumerate([b for b in self.case.buses if b.type == PQ]):\n            b.p_demand = self._Pd0[i] * self.profile[self._step]\n\n        # Initialise the record of generator set-points.\n        self._Pg = zeros((len(self.case.online_generators), len(self.profile)))\n\n        # Apply the first load profile value.\n#        self.step()\n\n        self.case.reset()", "label": 1}
{"code": "protected static function record(string $type, IncomingEntry $entry)\n    {\n        if (! static::isRecording()) {\n            return;\n        }\n\n        $entry->type($type)->tags(\n            static::$tagUsing ? call_user_func(static::$tagUsing, $entry) : []\n        );\n\n        try {\n            if (Auth::hasUser()) {\n                $entry->user(Auth::user());\n            }\n        } catch (Throwable $e) {\n            // Do nothing.\n        }\n\n        static::withoutRecording(function () use ($entry) {\n            if (collect(static::$filterUsing)->every->__invoke($entry)) {\n                static::$entriesQueue[] = $entry;\n            }\n\n            if (static::$afterRecordingHook) {\n                call_user_func(static::$afterRecordingHook, new static);\n            }\n        });\n    }", "label": 2}
{"code": "def include?(name)\n      name = normalize_header name.to_s\n      @pile.any? { |k, _| k == name }\n    end", "label": 4}
{"code": "public static appfwxmlcontenttype[] get(nitro_service service) throws Exception{\n\t\tappfwxmlcontenttype obj = new appfwxmlcontenttype();\n\t\tappfwxmlcontenttype[] response = (appfwxmlcontenttype[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def reset(db_name):\n    \"\"\"Reset database.\"\"\"\n\n    conn = psycopg2.connect(database='postgres')\n    db = Database(db_name)\n    conn.autocommit = True\n\n    with conn.cursor() as cursor:\n        cursor.execute(db.drop_statement())\n        cursor.execute(db.create_statement())\n    conn.close()", "label": 1}
{"code": "def get_username(identifier):\n    \"\"\"Checks if a string is a email adress or not.\"\"\"\n    pattern = re.compile('.+@\\w+\\..+')\n    if pattern.match(identifier):\n        try:\n            user = User.objects.get(email=identifier)\n        except:\n            raise Http404\n        else:\n            return user.username\n    else:\n        return identifier", "label": 1}
{"code": "def description\n      resource_description = resource.try(:resource_description) || resource.try(:description)\n      return if resource_description.blank?\n\n      resource_description = if resource_description.is_a?(String)\n                               resource_description\n                             elsif resource_description.is_a?(Hash)\n                               translated_attribute(resource_description)\n                             end\n\n      truncate(strip_tags(resource_description), length: 300)\n    end", "label": 4}
{"code": "def run_hook(name, *args)\n      hooks = Resque.send(name)\n      return if hooks.empty?\n      return if name == :before_first_fork && @before_first_fork_hook_ran\n      msg = \"Running #{name} hooks\"\n      msg << \" with #{args.inspect}\" if args.any?\n      log_with_severity :info, msg\n\n      hooks.each do |hook|\n        args.any? ? hook.call(*args) : hook.call\n        @before_first_fork_hook_ran = true if name == :before_first_fork\n      end\n    end", "label": 4}
{"code": "func parseNetworkGenericOptions(data interface{}) (*configuration, error) {\n\tvar (\n\t\terr    error\n\t\tconfig *configuration\n\t)\n\tswitch opt := data.(type) {\n\tcase *configuration:\n\t\tconfig = opt\n\tcase map[string]string:\n\t\tconfig = &configuration{}\n\t\terr = config.fromOptions(opt)\n\tcase options.Generic:\n\t\tvar opaqueConfig interface{}\n\t\tif opaqueConfig, err = options.GenerateFromModel(opt, config); err == nil {\n\t\t\tconfig = opaqueConfig.(*configuration)\n\t\t}\n\tdefault:\n\t\terr = types.BadRequestErrorf(\"unrecognized network configuration format: %v\", opt)\n\t}\n\treturn config, err\n}", "label": 5}
{"code": "function(whenMap, indexMap) {\n      var self = this,\n          events = [];\n      _.each(whenMap, function(whenEvents, whenField) {\n        var substitutedWhenField,\n            qualifiedFields = [whenField],\n            useAtNotation = (whenField.charAt(0) === '@');\n\n        if (whenField !== 'on' || whenField !== 'listenTo') {\n          if (useAtNotation) {\n            whenField = whenField.substring(1);\n            // substitute indices in to \"when\" placeholders\n            // [] -> to all, [0] -> to specific, [x] -> [x's value]\n            substitutedWhenField = self.__substituteIndicesUsingMap(whenField, indexMap);\n            qualifiedFields = _.flatten(self.__generateSubAttributes(substitutedWhenField, self.model));\n          }\n          // For each qualified field\n          _.each(qualifiedFields, function(qualifiedField) {\n            _.each(whenEvents, function(eventType) {\n              var backboneEvent = eventType + ' ' + qualifiedField;\n              if (useAtNotation) {\n                backboneEvent = eventType + ' [data-model=\"' + qualifiedField + '\"]';\n              }\n              events.push(backboneEvent);\n            });\n          });\n        }\n      });\n      return events;\n    }", "label": 3}
{"code": "def string_width(string, font_size)\n      font_scale = font_size / 10.0\n      string.count(Worksheet::THIN_CHARS) * font_scale\n    end", "label": 4}
{"code": "public function get_packages_dir_path() {\n\t\tif ( getenv( 'WP_CLI_PACKAGES_DIR' ) ) {\n\t\t\t$packages_dir = Utils\\trailingslashit( getenv( 'WP_CLI_PACKAGES_DIR' ) );\n\t\t} else {\n\t\t\t$packages_dir = Utils\\get_home_dir() . '/.wp-cli/packages/';\n\t\t}\n\t\treturn $packages_dir;\n\t}", "label": 2}
{"code": "def _validation_error(prop, prop_type, prop_value, expected):\n    \"\"\" Default validation for updated properties \"\"\"\n\n    if prop_type is None:\n        attrib = 'value'\n        assigned = prop_value\n    else:\n        attrib = 'type'\n        assigned = prop_type\n\n    raise ValidationError(\n        'Invalid property {attrib} for {prop}:\\n\\t{attrib}: {assigned}\\n\\texpected: {expected}',\n        attrib=attrib, prop=prop, assigned=assigned, expected=expected,\n        invalid={prop: prop_value} if attrib == 'value' else {}\n    )", "label": 1}
{"code": "def _operation_caveat(cond, ops):\n    ''' Helper for allow_caveat and deny_caveat.\n\n    It checks that all operation names are valid before creating the caveat.\n    '''\n    for op in ops:\n        if op.find(' ') != -1:\n            return error_caveat('invalid operation name \"{}\"'.format(op))\n    return _first_party(cond, ' '.join(ops))", "label": 1}
{"code": "def colour=(value)\n      if value.nil?\n        @colour = nil\n      elsif value.is_a? Integer\n        raise ArgumentError, 'Embed colour must be 24-bit!' if value >= 16_777_216\n\n        @colour = value\n      elsif value.is_a? String\n        self.colour = value.delete('#').to_i(16)\n      elsif value.is_a? Array\n        raise ArgumentError, 'Colour tuple must have three values!' if value.length != 3\n\n        self.colour = value[0] << 16 | value[1] << 8 | value[2]\n      else\n        self.colour = value.to_i\n      end\n    end", "label": 4}
{"code": "func (h *AuthHandlers) HostKeyAuth(addr string, remote net.Addr, key ssh.PublicKey) error {\n\tfingerprint := fmt.Sprintf(\"%v %v\", key.Type(), sshutils.Fingerprint(key))\n\n\t// update entry to include a fingerprint of the key so admins can track down\n\t// the key causing problems\n\th.Entry = log.WithFields(log.Fields{\n\t\ttrace.Component: h.Component,\n\t\ttrace.ComponentFields: log.Fields{\n\t\t\t\"remote\":      remote.String(),\n\t\t\t\"fingerprint\": fingerprint,\n\t\t},\n\t})\n\n\t// Check if the given host key was signed by a Teleport certificate\n\t// authority (CA) or fallback to host key checking if it's allowed.\n\tcertChecker := utils.CertChecker{\n\t\tCertChecker: ssh.CertChecker{\n\t\t\tIsHostAuthority: h.IsHostAuthority,\n\t\t\tHostKeyFallback: h.hostKeyCallback,\n\t\t},\n\t}\n\terr := certChecker.CheckHostKey(addr, remote, key)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function deleteBatch(array $keys)\n    {\n        foreach ($keys as $key) {\n            $this->mutations[] = $this->operation->mutation('delete', $key, Key::class);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *Manager) DeleteLibraryItem(ctx context.Context, item *Item) error {\n\turl := internal.URL(c, internal.LibraryItemPath).WithID(item.ID)\n\treturn c.Do(ctx, url.Request(http.MethodDelete), nil)\n}", "label": 5}
{"code": "public static base_responses add(nitro_service client, cacheselector resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tcacheselector addresources[] = new cacheselector[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new cacheselector();\n\t\t\t\taddresources[i].selectorname = resources[i].selectorname;\n\t\t\t\taddresources[i].rule = resources[i].rule;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (a *LocalKeyAgent) UnloadKey() error {\n\tagents := []agent.Agent{a.Agent}\n\tif a.sshAgent != nil {\n\t\tagents = append(agents, a.sshAgent)\n\t}\n\n\t// iterate over all agents we have and unload keys for this user\n\tfor i, _ := range agents {\n\t\t// get a list of all keys in the agent\n\t\tkeyList, err := agents[i].List()\n\t\tif err != nil {\n\t\t\ta.log.Warnf(\"Unable to communicate with agent and list keys: %v\", err)\n\t\t}\n\n\t\t// remove any teleport keys we currently have loaded in the agent for this user\n\t\tfor _, key := range keyList {\n\t\t\tif key.Comment == fmt.Sprintf(\"teleport:%v\", a.username) {\n\t\t\t\terr = agents[i].Remove(key)\n\t\t\t\tif err != nil {\n\t\t\t\t\ta.log.Warnf(\"Unable to communicate with agent and remove key: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function setCloudWorkspace($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\DevTools\\Source\\V1\\CloudWorkspaceSourceContext::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def put_ops(self, key, time, ops):\n        ''' Put an ops only if not already there, otherwise it's a no op.\n        '''\n        if self._store.get(key) is None:\n            self._store[key] = ops", "label": 1}
{"code": "function (req, res) {\n        let sectionId = req.params.id;\n        if (Utils.isNullOrEmpty(server.state.get('sections[' + sectionId + ']'))) {\n            log.error('Invalid Section Id:', sectionId);\n            Utils.sendMessage(res, HttpStatus.BAD_REQUEST, JSON.stringify({ error: 'invalid section id' }));\n        } else {\n            _deleteSectionById(sectionId);\n            log.info('Successfully deleted section:', sectionId);\n            Utils.sendMessage(res, HttpStatus.OK, JSON.stringify({ ids: [ parseInt(sectionId, 10) ] }));\n        }\n    }", "label": 3}
{"code": "public static vpnvserver_authenticationradiuspolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tvpnvserver_authenticationradiuspolicy_binding obj = new vpnvserver_authenticationradiuspolicy_binding();\n\t\tobj.set_name(name);\n\t\tvpnvserver_authenticationradiuspolicy_binding response[] = (vpnvserver_authenticationradiuspolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (attr, attrName) {\n            if (_.isObject(attr) && !_.isDate(attr) && !_.isBoolean(attr) && !_.isString(attr) && !_.isNumber(attr) && !_.isFunction(attr) && !_.isRegExp(attr) && !_.isArray(attr)) {\n                //attr = _removeAttributes();\n                for (var aIndex in attr) {\n                    attr[aIndex] = _removeAttributes(attr[aIndex], aIndex);\n                }\n                return attr;\n            }\n            else {\n                if (_.indexOf(allowedAttributes, attrName) != -1) {\n                    if (_.isFunction(attr)) {\n                        attr = _functionName(attr);\n                    }\n\n                    return attr;\n                }\n                else {\n                    return;\n                }\n            }\n        }", "label": 3}
{"code": "public static base_response Install(nitro_service client, wipackage resource) throws Exception {\n\t\twipackage Installresource = new wipackage();\n\t\tInstallresource.jre = resource.jre;\n\t\tInstallresource.wi = resource.wi;\n\t\tInstallresource.maxsites = resource.maxsites;\n\t\treturn Installresource.perform_operation(client);\n\t}", "label": 0}
{"code": "def update_cluster_time(result)\n      if cluster_time_doc = result.cluster_time\n        @cluster_time_lock.synchronize do\n          if @cluster_time.nil?\n            @cluster_time = cluster_time_doc\n          elsif cluster_time_doc[CLUSTER_TIME] > @cluster_time[CLUSTER_TIME]\n            @cluster_time = cluster_time_doc\n          end\n        end\n      end\n    end", "label": 4}
{"code": "function tolerancesToString(values, tolerances) {\n    let str = '{';\n    const props = [];\n    if (typeof values !== 'object' && typeof values !== 'undefined') {\n        if (typeof tolerances === 'undefined') {\n            return values;\n        }\n        else if (typeof tolerances !== 'object') {\n            const tolerance = Math.abs(tolerances);\n            return `[${Math.max(values - tolerance, 0)}, ${Math.max(values + tolerance, 0)}]`;\n        }\n    }\n    else {\n        for (const p in values) {\n            if (values.hasOwnProperty(p)) {\n                const value = values[p];\n                let valueStr = '';\n                if (tolerances && typeof tolerances[p] !== 'undefined' && tolerances[p] !== 0) {\n                    const tolerance = Math.abs(tolerances[p]);\n                    valueStr = `[${Math.max(value - tolerance, 0)}, ${Math.max(value + tolerance, 0)}]`;\n                }\n                else {\n                    valueStr = `${value}`;\n                }\n                props.push(`${p}: ${valueStr}`);\n            }\n        }\n    }\n    str += props.join(', ');\n    return `${str}}`;\n}", "label": 3}
{"code": "func (s *Server) CreateSessionV4(p *Packet) (interface{}, error) {\n\tconst SessionMaxPacketSizeValid = 0x1\n\n\treq := new(RequestCreateSessionV4)\n\terr := UnmarshalBinary(p.Payload, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres := &ReplyCreateSessionV4{\n\t\tSessionID:       uint64(rand.Int63()),\n\t\tNumCapabilities: uint32(len(s.Capabilities)),\n\t\tMaxPacketSize:   LargePacketMax,\n\t\tFlags:           SessionMaxPacketSizeValid,\n\t\tCapabilities:    s.Capabilities,\n\t}\n\n\ts.mu.Lock()\n\tdefer s.mu.Unlock()\n\tif len(s.sessions) > maxSessions {\n\t\treturn nil, &Status{Code: StatusTooManySessions}\n\t}\n\n\ts.sessions[res.SessionID] = newSession()\n\n\treturn res, nil\n}", "label": 5}
{"code": "public function run()\n    {\n        foreach ($this->pubsub as $message) {\n            $kind = $message->kind;\n\n            if ($kind !== Consumer::MESSAGE && $kind !== Consumer::PMESSAGE) {\n                if (isset($this->subscriptionCallback)) {\n                    $callback = $this->subscriptionCallback;\n                    call_user_func($callback, $message);\n                }\n\n                continue;\n            }\n\n            if (isset($this->callbacks[$message->channel])) {\n                $callback = $this->callbacks[$message->channel];\n                call_user_func($callback, $message->payload);\n            } elseif (isset($this->defaultCallback)) {\n                $callback = $this->defaultCallback;\n                call_user_func($callback, $message);\n            }\n        }\n    }", "label": 2}
{"code": "func parseKnownHosts(bytes []byte, allowedLogins []string) (services.CertAuthority, services.Role, error) {\n\tmarker, options, pubKey, comment, _, err := ssh.ParseKnownHosts(bytes)\n\tif marker != \"cert-authority\" {\n\t\treturn nil, nil, trace.BadParameter(\"invalid file format. expected '@cert-authority` marker\")\n\t}\n\tif err != nil {\n\t\treturn nil, nil, trace.BadParameter(\"invalid public key\")\n\t}\n\tteleportOpts, err := url.ParseQuery(comment)\n\tif err != nil {\n\t\treturn nil, nil, trace.BadParameter(\"invalid key comment: '%s'\", comment)\n\t}\n\tauthType := services.CertAuthType(teleportOpts.Get(\"type\"))\n\tif authType != services.HostCA && authType != services.UserCA {\n\t\treturn nil, nil, trace.BadParameter(\"unsupported CA type: '%s'\", authType)\n\t}\n\tif len(options) == 0 {\n\t\treturn nil, nil, trace.BadParameter(\"key without cluster_name\")\n\t}\n\tconst prefix = \"*.\"\n\tdomainName := strings.TrimPrefix(options[0], prefix)\n\n\tv1 := &services.CertAuthorityV1{\n\t\tAllowedLogins: utils.CopyStrings(allowedLogins),\n\t\tDomainName:    domainName,\n\t\tType:          authType,\n\t\tCheckingKeys:  [][]byte{ssh.MarshalAuthorizedKey(pubKey)},\n\t}\n\tca, role := services.ConvertV1CertAuthority(v1)\n\treturn ca, role, nil\n}", "label": 5}
{"code": "public static void main(String[] args) throws Exception {\n        Logger logger = Logger.getLogger(\"MASReader.main\");\n\n        Properties beastConfigProperties = new Properties();\n        String beastConfigPropertiesFile = null;\n        if (args.length > 0) {\n            beastConfigPropertiesFile = args[0];\n            beastConfigProperties.load(new FileInputStream(\n                    beastConfigPropertiesFile));\n            logger.info(\"Properties file selected -> \"\n                    + beastConfigPropertiesFile);\n        } else {\n            logger.severe(\"No properties file found. Set the path of properties file as argument.\");\n            throw new BeastException(\n                    \"No properties file found. Set the path of properties file as argument.\");\n        }\n        String loggerConfigPropertiesFile;\n        if (args.length > 1) {\n            Properties loggerConfigProperties = new Properties();\n            loggerConfigPropertiesFile = args[1];\n            try {\n                FileInputStream loggerConfigFile = new FileInputStream(\n                        loggerConfigPropertiesFile);\n                loggerConfigProperties.load(loggerConfigFile);\n                LogManager.getLogManager().readConfiguration(loggerConfigFile);\n                logger.info(\"Logging properties configured successfully. Logger config file: \"\n                        + loggerConfigPropertiesFile);\n            } catch (IOException ex) {\n                logger.warning(\"WARNING: Could not open configuration file\");\n                logger.warning(\"WARNING: Logging not configured (console output only)\");\n            }\n        } else {\n            loggerConfigPropertiesFile = null;\n        }\n\n        MASReader.generateJavaFiles(\n                beastConfigProperties.getProperty(\"requirementsFolder\"), \"\\\"\"\n                        + beastConfigProperties.getProperty(\"MASPlatform\")\n                        + \"\\\"\",\n                beastConfigProperties.getProperty(\"srcTestRootFolder\"),\n                beastConfigProperties.getProperty(\"storiesPackage\"),\n                beastConfigProperties.getProperty(\"caseManagerPackage\"),\n                loggerConfigPropertiesFile,\n                beastConfigProperties.getProperty(\"specificationPhase\"));\n\n    }", "label": 0}
{"code": "private void doDelete(Object obj, boolean ignoreReferences) throws PersistenceBrokerException\n    {\n        //logger.info(\"DELETING \" + obj);\n        // object is not null\n        if (obj != null)\n        {\n            obj = getProxyFactory().getRealObject(obj);\n            /**\n             * Kuali Foundation modification -- 8/24/2007\n             */\n            if ( obj == null ) return;\n            /**\n             * End of Kuali Foundation modification\n             */\n            /**\n             * MBAIRD\n             * 1. if we are marked for delete already, avoid recursing on this object\n             *\n             * arminw:\n             * use object instead Identity object in markedForDelete List,\n             * because using objects we get a better performance. I can't find\n             * side-effects in doing so.\n             */\n            if (markedForDelete.contains(obj))\n            {\n                return;\n            }\n            \n            ClassDescriptor cld = getClassDescriptor(obj.getClass());\n            //BRJ: check for valid pk\n            if (!serviceBrokerHelper().assertValidPkForDelete(cld, obj))\n            {\n                String msg = \"Cannot delete object without valid PKs. \" + obj;\n                logger.error(msg);\n                return;\n            }\n            \n            /**\n             * MBAIRD\n             * 2. register object in markedForDelete map.\n             */\n            markedForDelete.add(obj);\n            Identity oid = serviceIdentity().buildIdentity(cld, obj);\n\n            // Invoke events on PersistenceBrokerAware instances and listeners\n            BEFORE_DELETE_EVENT.setTarget(obj);\n            fireBrokerEvent(BEFORE_DELETE_EVENT);\n            BEFORE_DELETE_EVENT.setTarget(null);\n\n            // now perform deletion\n            performDeletion(cld, obj, oid, ignoreReferences);\n \t  \t \n            // Invoke events on PersistenceBrokerAware instances and listeners\n            AFTER_DELETE_EVENT.setTarget(obj);\n            fireBrokerEvent(AFTER_DELETE_EVENT);\n            AFTER_DELETE_EVENT.setTarget(null);\n \t  \t \t\n            // let the connection manager to execute batch\n            connectionManager.executeBatchIfNecessary();\n        }\n    }", "label": 0}
{"code": "def get_program_list():\n    \"\"\"\n    get a HTML formatted view of all Python programs\n    in all subfolders of AIKIF, including imports and\n    lists of functions and classes\n    \"\"\"\n    colList = ['FileName','FileSize','Functions', 'Imports']\n\n    txt = '<TABLE width=90% border=0>'\n    txt += format_file_table_header(colList)\n    fl = web.GetFileList(aikif_folder, ['*.py'], 'N')\n    for f in fl:\n        if '__init__.py' in f:\n            txt += '<TR><TD colspan=4><HR><H3>' + get_subfolder(f) + '</h3></td></tr>\\n'\n        else:\n            txt += format_file_to_html_row(f, colList)\n    txt += '</TABLE>\\n\\n'\n    return txt", "label": 1}
{"code": "def create!(klass, author, params, extra_log_info = {})\n      perform_action!(:create, klass, author, extra_log_info) do\n        klass.create!(params)\n      end\n    end", "label": 4}
{"code": "def delay=(d)\n      raise ArgumentError, 'delay must be greater than or equal to 0' if Integer(d) < 0\n\n      @images.each { |f| f.delay = Integer(d) }\n    end", "label": 4}
{"code": "private void checkQueryCustomizer(CollectionDescriptorDef collDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (!CHECKLEVEL_STRICT.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n        \r\n        String queryCustomizerName  = collDef.getProperty(PropertyHelper.OJB_PROPERTY_QUERY_CUSTOMIZER);\r\n\r\n        if (queryCustomizerName == null)\r\n        {\r\n            return;\r\n        }\r\n\r\n        try\r\n        {\r\n            InheritanceHelper helper = new InheritanceHelper();\r\n\r\n            if (!helper.isSameOrSubTypeOf(queryCustomizerName, QUERY_CUSTOMIZER_INTERFACE))\r\n            {\r\n                throw new ConstraintException(\"The class \"+queryCustomizerName+\" specified as query-customizer of collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" does not implement the interface \"+QUERY_CUSTOMIZER_INTERFACE);\r\n            }\r\n        }\r\n        catch (ClassNotFoundException ex)\r\n        {\r\n            throw new ConstraintException(\"The class \"+ex.getMessage()+\" specified as query-customizer of collection \"+collDef.getName()+\" in class \"+collDef.getOwner().getName()+\" was not found on the classpath\");\r\n        }\r\n    }", "label": 0}
{"code": "def set_controller_value(self, index_or_name, value):\n        \"\"\"\n        Sets controller value\n\n        :param index_or_name integer index or string name\n        :param value float\n        \"\"\"\n        if not isinstance(index_or_name, int):\n            index = self.get_controller_index(index_or_name)\n        else:\n            index = index_or_name\n        self.dll.SetControllerValue(index, ctypes.c_float(value))", "label": 1}
{"code": "public function roundWeek($weekStartsAt = null)\n    {\n        return $this->closest($this->copy()->floorWeek($weekStartsAt), $this->copy()->ceilWeek($weekStartsAt));\n    }", "label": 2}
{"code": "def search_result_document(search_params)\n        _, document_list = search_results(search_params)\n        return document_list.first unless document_list.empty?\n        document_not_found!\n      end", "label": 4}
{"code": "public function readAll()\n    {\n        $tries = 0;\n        $argumentFunction = $this->argumentFunction;\n        $retryFunction = $this->retryFunction;\n        do {\n            $ex = null;\n            $stream = $this->createExponentialBackoff()->execute($this->apiFunction, $argumentFunction());\n            try {\n                foreach ($stream->readAll() as $item) {\n                    yield $item;\n                }\n            } catch (\\Exception $ex) {\n            }\n            $tries++;\n        } while ((!$this->retryFunction || $retryFunction($ex)) && $tries <= $this->retries);\n        if ($ex !== null) {\n            throw $ex;\n        }\n    }", "label": 2}
{"code": "function runJob(iterator, key, item, callback)\n{\n  var aborter;\n\n  // allow shortcut if iterator expects only two arguments\n  if (iterator.length == 2)\n  {\n    aborter = iterator(item, async(callback));\n  }\n  // otherwise go with full three arguments\n  else\n  {\n    aborter = iterator(item, key, async(callback));\n  }\n\n  return aborter;\n}", "label": 3}
{"code": "func (m *ProcessManager) Stat(u *url.URL) (os.FileInfo, error) {\n\tname := path.Join(\"/proc\", u.Path)\n\n\tinfo, err := os.Stat(name)\n\tif err == nil && info.Size() == 0 {\n\t\t// This is a real /proc file\n\t\treturn &procFileInfo{info}, nil\n\t}\n\n\tdir, file := path.Split(u.Path)\n\n\tpid, err := strconv.ParseInt(path.Base(dir), 10, 64)\n\tif err != nil {\n\t\treturn nil, os.ErrNotExist\n\t}\n\n\tm.mu.Lock()\n\tp := m.entries[pid]\n\tm.mu.Unlock()\n\n\tif p == nil || p.IO == nil {\n\t\treturn nil, os.ErrNotExist\n\t}\n\n\tpf := &ProcessFile{\n\t\tname:   name,\n\t\tCloser: ioutil.NopCloser(nil), // via hgfs, nop for stdout and stderr\n\t}\n\n\tvar r *bytes.Buffer\n\n\tswitch file {\n\tcase \"stdin\":\n\t\tpf.Writer = p.IO.In.Writer\n\t\tpf.Closer = p.IO.In.Closer\n\t\treturn pf, nil\n\tcase \"stdout\":\n\t\tr = p.IO.Out\n\tcase \"stderr\":\n\t\tr = p.IO.Err\n\tdefault:\n\t\treturn nil, os.ErrNotExist\n\t}\n\n\tselect {\n\tcase <-p.ctx.Done():\n\tcase <-time.After(time.Second):\n\t\t// The vmx guest RPC calls are queue based, serialized on the vmx side.\n\t\t// There are 5 seconds between \"ping\" RPC calls and after a few misses,\n\t\t// the vmx considers tools as not running.  In this case, the vmx would timeout\n\t\t// a file transfer after 60 seconds.\n\t\t//\n\t\t// vix.FileAccessError is converted to a CannotAccessFile fault,\n\t\t// so the client can choose to retry the transfer in this case.\n\t\t// Would have preferred vix.ObjectIsBusy (EBUSY), but VC/ESX converts that\n\t\t// to a general SystemErrorFault with nothing but a localized string message\n\t\t// to check against: \"<reason>vix error codes = (5, 0).</reason>\"\n\t\t// Is standard vmware-tools, EACCES is converted to a CannotAccessFile fault.\n\t\treturn nil, vix.Error(vix.FileAccessError)\n\t}\n\n\tpf.Reader = r\n\tpf.size = r.Len()\n\n\treturn pf, nil\n}", "label": 5}
{"code": "function( event ) {\n\n                    var target = event.target\n\n                    // Make sure the target isn\u2019t the root holder so it can bubble up.\n                    if ( target != P.$root.children()[ 0 ] ) {\n\n                        event.stopPropagation()\n\n                        // * For mousedown events, cancel the default action in order to\n                        //   prevent cases where focus is shifted onto external elements\n                        //   when using things like jQuery mobile or MagnificPopup (ref: #249 & #120).\n                        //   Also, for Firefox, don\u2019t prevent action on the `option` element.\n                        if ( event.type == 'mousedown' && !$( target ).is( 'input, select, textarea, button, option' )) {\n\n                            event.preventDefault()\n\n                            // Re-focus onto the root so that users can click away\n                            // from elements focused within the picker.\n                            P.$root[0].focus()\n                        }\n                    }\n                }", "label": 3}
{"code": "def init\n      require 'fileutils'\n      require 'tmpdir'\n\n      unless git_present?\n        msg =  'You need to install the git command line tool to initialize a new project. '\n        msg << \"For help installing git, please refer to GitHub's tutorial at https://help.github.com/articles/set-up-git\"\n        say msg, :red\n        exit 1\n      end\n\n      repo_path, repo_branch = if shortname?(options[:template])\n                                 require 'open-uri'\n                                 require 'json'\n\n                                 api = 'https://directory.middlemanapp.com/api'\n                                 uri = ::URI.parse(\"#{api}/#{options[:template]}.json\")\n\n                                 begin\n                                   data = ::JSON.parse(uri.read)\n                                   is_local_dir = false\n                                   data['links']['github'].split('#')\n                                 rescue ::OpenURI::HTTPError\n                                   say \"Template `#{options[:template]}` not found in Middleman Directory.\"\n                                   say 'Did you mean to use a full `user/repo` path?'\n                                   exit 1\n                                 end\n                               else\n                                 repo_name, repo_branch = options[:template].split('#')\n                                 repo_path, is_local_dir = repository_path(repo_name)\n                                 [repo_path, repo_branch]\n                               end\n\n      begin\n        dir = is_local_dir ? repo_path : clone_repository(repo_path, repo_branch)\n\n        inside(target) do\n          thorfile = File.join(dir, 'Thorfile')\n\n          if File.exist?(thorfile)\n            ::Thor::Util.load_thorfile(thorfile)\n\n            invoke 'middleman:generator'\n          else\n            source_paths << dir\n            directory dir, '.', exclude_pattern: /\\.git\\/|\\.gitignore$/\n          end\n\n          bundle_args = options[:'bundle-path'] ? \" --path=#{options[:'bundle-path']}\" : ''\n          run(\"bundle install#{bundle_args}\") unless ENV['TEST'] || options[:'skip-bundle']\n        end\n      ensure\n        FileUtils.remove_entry(dir) if !is_local_dir && File.directory?(dir)\n      end\n    end", "label": 4}
{"code": "func PgIndicesByIndrelid(db XODB, indrelid pgtypes.Oid) ([]*PgIndex, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, indexrelid, indrelid, indnatts, indisunique, indisprimary, indisexclusion, indimmediate, indisclustered, indisvalid, indcheckxmin, indisready, indislive, indisreplident, indkey, indcollation, indclass, indoption, indexprs, indpred ` +\n\t\t`FROM pg_catalog.pg_index ` +\n\t\t`WHERE indrelid = $1`\n\n\t// run query\n\tXOLog(sqlstr, indrelid)\n\tq, err := db.Query(sqlstr, indrelid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*PgIndex{}\n\tfor q.Next() {\n\t\tpi := PgIndex{}\n\n\t\t// scan\n\t\terr = q.Scan(&pi.Tableoid, &pi.Cmax, &pi.Xmax, &pi.Cmin, &pi.Xmin, &pi.Ctid, &pi.Indexrelid, &pi.Indrelid, &pi.Indnatts, &pi.Indisunique, &pi.Indisprimary, &pi.Indisexclusion, &pi.Indimmediate, &pi.Indisclustered, &pi.Indisvalid, &pi.Indcheckxmin, &pi.Indisready, &pi.Indislive, &pi.Indisreplident, &pi.Indkey, &pi.Indcollation, &pi.Indclass, &pi.Indoption, &pi.Indexprs, &pi.Indpred)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &pi)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "def synchronize! updater\n      source_hash[updater.filename] = source_hash[updater.filename].synchronize(updater)\n    end", "label": 4}
{"code": "func (l VirtualDeviceList) EjectImg(device *types.VirtualFloppy) *types.VirtualFloppy {\n\tl.setDefaultFloppyBacking(device)\n\treturn device\n}", "label": 5}
{"code": "func (cl *Client) WriteStatus(_w io.Writer) {\n\tcl.rLock()\n\tdefer cl.rUnlock()\n\tw := bufio.NewWriter(_w)\n\tdefer w.Flush()\n\tfmt.Fprintf(w, \"Listen port: %d\\n\", cl.LocalPort())\n\tfmt.Fprintf(w, \"Peer ID: %+q\\n\", cl.PeerID())\n\tfmt.Fprintf(w, \"Announce key: %x\\n\", cl.announceKey())\n\tfmt.Fprintf(w, \"Banned IPs: %d\\n\", len(cl.badPeerIPsLocked()))\n\tcl.eachDhtServer(func(s *dht.Server) {\n\t\tfmt.Fprintf(w, \"%s DHT server at %s:\\n\", s.Addr().Network(), s.Addr().String())\n\t\twriteDhtServerStatus(w, s)\n\t})\n\tspew.Fdump(w, cl.stats)\n\tfmt.Fprintf(w, \"# Torrents: %d\\n\", len(cl.torrentsAsSlice()))\n\tfmt.Fprintln(w)\n\tfor _, t := range slices.Sort(cl.torrentsAsSlice(), func(l, r *Torrent) bool {\n\t\treturn l.InfoHash().AsString() < r.InfoHash().AsString()\n\t}).([]*Torrent) {\n\t\tif t.name() == \"\" {\n\t\t\tfmt.Fprint(w, \"<unknown name>\")\n\t\t} else {\n\t\t\tfmt.Fprint(w, t.name())\n\t\t}\n\t\tfmt.Fprint(w, \"\\n\")\n\t\tif t.info != nil {\n\t\t\tfmt.Fprintf(w, \"%f%% of %d bytes (%s)\", 100*(1-float64(t.bytesMissingLocked())/float64(t.info.TotalLength())), t.length, humanize.Bytes(uint64(t.info.TotalLength())))\n\t\t} else {\n\t\t\tw.WriteString(\"<missing metainfo>\")\n\t\t}\n\t\tfmt.Fprint(w, \"\\n\")\n\t\tt.writeStatus(w)\n\t\tfmt.Fprintln(w)\n\t}\n}", "label": 5}
{"code": "public static vpnclientlessaccesspolicy[] get(nitro_service service) throws Exception{\n\t\tvpnclientlessaccesspolicy obj = new vpnclientlessaccesspolicy();\n\t\tvpnclientlessaccesspolicy[] response = (vpnclientlessaccesspolicy[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func GetStateSchema() string {\n\treturn fmt.Sprintf(services.V2SchemaTemplate, services.MetadataSchema, fmt.Sprintf(StateSpecV2Schema, services.RotationSchema), services.DefaultDefinitions)\n}", "label": 5}
{"code": "public function getDebugLocation()\n    {\n        $location = '';\n        if ($this->class && ($this->method || $this->property)) {\n            $location .= $this->fullyQualifiedName($this->class);\n            if ($this->method) {\n                $location .= ($this->static ? '::' : '->') . $this->method . '()';\n            } elseif ($this->property) {\n                $location .= ($this->static ? '::$' : '->') . $this->property;\n            }\n        }\n        if ($this->filename) {\n            if ($location !== '') {\n                $location .= ' in ';\n            }\n            $location .= $this->filename;\n        }\n        if ($this->line) {\n            if ($location !== '') {\n                $location .= ' on';\n            }\n            $location .= ' line ' . $this->line;\n            if ($this->character) {\n                $location .= ':' . $this->character;\n            }\n        }\n\n        return $location;\n    }", "label": 2}
{"code": "func PgRewriteByOid(db XODB, oid pgtypes.Oid) (*PgRewrite, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, rulename, ev_class, ev_type, ev_enabled, is_instead, ev_qual, ev_action ` +\n\t\t`FROM pg_catalog.pg_rewrite ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpr := PgRewrite{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&pr.Tableoid, &pr.Cmax, &pr.Xmax, &pr.Cmin, &pr.Xmin, &pr.Oid, &pr.Ctid, &pr.Rulename, &pr.EvClass, &pr.EvType, &pr.EvEnabled, &pr.IsInstead, &pr.EvQual, &pr.EvAction)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pr, nil\n}", "label": 5}
{"code": "def refresh(self):\n        '''\n        Refresh the list and the screen\n        '''\n        self._screen.force_update()\n        self._screen.refresh()\n        self._update(1)", "label": 1}
{"code": "func StartBees(beeList []BeeConfig) {\n\teventsIn = make(chan Event)\n\tgo handleEvents()\n\n\tfor _, bee := range beeList {\n\t\tStartBee(bee)\n\t}\n}", "label": 5}
{"code": "protected function setEnabled(array $enabled)\n    {\n        $enabled = array_values(array_unique($enabled));\n\n        $this->config->set('extensions_enabled', json_encode($enabled));\n    }", "label": 2}
{"code": "public function update(array $options = [])\n    {\n        $operation = $this->connection->updateInstance([\n            'name' => $this->name,\n        ] + $options);\n\n        return $this->resumeOperation($operation['name'], $operation);\n    }", "label": 2}
{"code": "public static List<String> asListLines(String content) {\n    List<String> retorno = new ArrayList<String>();\n    content = content.replace(CARRIAGE_RETURN, RETURN);\n    content = content.replace(RETURN, CARRIAGE_RETURN);\n    for (String str : content.split(CARRIAGE_RETURN)) {\n      retorno.add(str);\n    }\n    return retorno;\n  }", "label": 0}
{"code": "def prune_tilt_templates!\n      mapping = ::Tilt.default_mapping\n      mapping.lazy_map.each_key do |key|\n        begin\n          mapping[key]\n        rescue LoadError, NameError\n        end\n      end\n      mapping.lazy_map.clear\n    end", "label": 4}
{"code": "public static responderparam get(nitro_service service) throws Exception{\n\t\tresponderparam obj = new responderparam();\n\t\tresponderparam[] response = (responderparam[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "function() {\n    var ret = Ember.A([]);\n    this.forEach(function(o, idx) { ret[idx] = o; });\n    return ret ;\n  }", "label": 3}
{"code": "function () {\n      var srcFiles = path.resolve(\n        this.templatePath('drupal'),\n        options.drupalDistro.id,\n        options.drupalDistroVersion\n      );\n\n      if (gadget.fsExistsSync(srcFiles)) {\n        this.fs.copy(\n          path.resolve(srcFiles),\n          this.destinationRoot(),\n          {\n            globOptions: { dot: true }\n          }\n        );\n      }\n\n      this.composer = options.drupalDistro.loadComposer(this, options);\n    }", "label": 3}
{"code": "public static systemsession[] get(nitro_service service) throws Exception{\n\t\tsystemsession obj = new systemsession();\n\t\tsystemsession[] response = (systemsession[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def included(base = nil, &block)\n      if base.nil?\n        if instance_variable_defined?(:@_included_block)\n          if @_included_block.source_location != block.source_location\n            raise MultipleIncludedBlocks\n          end\n        else\n          @_included_block = block\n        end\n      else\n        super\n      end\n    end", "label": 4}
{"code": "def parse_options(args)\n      config = {}\n      deprecated_args = []\n      flag = /^--/\n\n      args.size.times do\n        break if args.empty?\n        peek = args.first\n        next unless peek && (peek.match(flag) || peek.match(/=/))\n        arg  = args.shift\n        peek = args.first\n        key  = arg\n        if key.match(/=/)\n          deprecated_args << key unless key.match(flag)\n          key, value = key.split('=', 2)\n        elsif peek.nil? || peek.match(flag)\n          value = true\n        else\n          value = args.shift\n        end\n        value = true if value == 'true'\n        config[key.sub(flag, '')] = value\n\n        if !deprecated_args.empty?\n          out_string = deprecated_args.map{|a| \"--#{a}\"}.join(' ')\n          display(\"Warning: non-unix style params have been deprecated, use #{out_string} instead\")\n        end\n      end\n\n      config\n    end", "label": 4}
{"code": "func (c *ClusterConfigV3) String() string {\n\treturn fmt.Sprintf(\"ClusterConfig(SessionRecording=%v, ClusterID=%v, ProxyChecksHostKeys=%v)\",\n\t\tc.Spec.SessionRecording, c.Spec.ClusterID, c.Spec.ProxyChecksHostKeys)\n}", "label": 5}
{"code": "private Expression getExpression(String expressionString) throws ParseException {\n\t\tif (!expressionCache.containsKey(expressionString)) {\n\t\t\tExpression expression;\n\t\t\texpression = parser.parseExpression(expressionString);\n\t\t\texpressionCache.put(expressionString, expression);\n\t\t}\n\t\treturn expressionCache.get(expressionString);\n\n\t}", "label": 0}
{"code": "def write_min_max(self, file):\n        \"\"\" Writes minimum and maximum values to a table.\n        \"\"\"\n        report = CaseReport(self.case)\n\n        col1_header = \"Attribute\"\n        col1_width  = 19\n        col2_header = \"Minimum\"\n        col3_header = \"Maximum\"\n        col_width   = 22\n\n        sep = \"=\"*col1_width +\" \"+ \"=\"*col_width +\" \"+ \"=\"*col_width + \"\\n\"\n\n        # Row headers\n        file.write(sep)\n\n        file.write(\"%s\" % col1_header.center(col1_width))\n        file.write(\" \")\n        file.write(\"%s\" % col2_header.center(col_width))\n        file.write(\" \")\n        file.write(\"%s\" % col3_header.center(col_width))\n        file.write(\"\\n\")\n\n        file.write(sep)\n\n        # Rows\n        min_val, min_i = getattr(report, \"min_v_magnitude\")\n        max_val, max_i = getattr(report, \"max_v_magnitude\")\n        file.write(\"%s %7.3f p.u. @ bus %2d %7.3f p.u. @ bus %2d\\n\" %\n            (\"Voltage Amplitude\".ljust(col1_width),\n             min_val, min_i, max_val, max_i))\n\n        min_val, min_i = getattr(report, \"min_v_angle\")\n        max_val, max_i = getattr(report, \"max_v_angle\")\n        file.write(\"%s %16.3f %16.3f\\n\" %\n            (\"Voltage Phase Angle\".ljust(col1_width), min_val, max_val))\n\n        file.write(sep)\n        file.write(\"\\n\")\n\n        del report", "label": 1}
{"code": "def get(*args)\n      arguments(args, required: [:name])\n      params = arguments.params\n\n      if (media = params.delete('accept'))\n        params['accept'] = media\n        params['raw'] = true\n      end\n\n      get_request(\"/gitignore/templates/#{arguments.name}\", params)\n    end", "label": 4}
{"code": "func AuthGroupPermissionByID(db XODB, id int) (*AuthGroupPermission, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, group_id, permission_id ` +\n\t\t`FROM public.auth_group_permissions ` +\n\t\t`WHERE id = $1`\n\n\t// run query\n\tXOLog(sqlstr, id)\n\tagp := AuthGroupPermission{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, id).Scan(&agp.ID, &agp.GroupID, &agp.PermissionID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &agp, nil\n}", "label": 5}
{"code": "function(depName, depLoad){\n\t\t\t\tvar parsed = baseHelpers.parseModuleName(depLoad.name);\n\t\t\t\tvar res;\n\t\t\t\tif( parsed.packageName !== \"can-util\" ) {\n\t\t\t\t\tres = baseNormalize.apply(this, arguments);\n\t\t\t\t} else {\n\t\t\t\t\tres = \"set-\"+parsed.packageName+\"/\"+parsed.modulePath\n\t\t\t\t}\n\t\t\t\treturn res;\n\t\t\t}", "label": 3}
{"code": "func (c *GithubConnectorV3) SetExpiry(expires time.Time) {\n\tc.Metadata.SetExpiry(expires)\n}", "label": 5}
{"code": "func writeManifest(cfg CommonConfig, img types.Hash, dest string) error {\n\tmb, err := cfg.Store.GetImageManifestJSON(img.String())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdebug(\"Writing image manifest\")\n\tif err := ioutil.WriteFile(filepath.Join(dest, \"manifest\"), mb, common.DefaultRegularFilePerm); err != nil {\n\t\treturn errwrap.Wrap(errors.New(\"error writing image manifest\"), err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def generate_migration_name(self, name, suffix):\n        \"\"\"Returns a name of a new migration. It will usually be a filename with\n        a valid and unique name.\n\n        :param name: human-readable name of a migration\n        :param suffix: file suffix (extension) - eg. 'sql'\n        \"\"\"\n        return os.path.join(self.dir,\n                            'm{datestr}_{name}.{suffix}'.format(\n                                datestr=datetime.datetime.utcnow().strftime('%Y%m%d%H%M%S'),\n                                name=name.replace(' ', '_'),\n                                suffix=suffix))", "label": 1}
{"code": "public function submitItem($identifier, $item)\n    {\n        $job = $this->getJobFromId($identifier);\n        if ($job === null) {\n            throw new \\RuntimeException(\n                \"The identifier does not exist: $identifier\"\n            );\n        }\n        $idNum = $job->id();\n        return $this->processor->submit($item, $idNum);\n    }", "label": 2}
{"code": "function getManagementToken(tenant, config = defaultConfig) {\n  const payload = {\n    service: tenant,\n    username: config.dojot.management.user\n  };\n  return (\n    new Buffer(\"jwt schema\").toString(\"base64\") +\n    \".\" +\n    new Buffer(JSON.stringify(payload)).toString(\"base64\") +\n    \".\" +\n    new Buffer(\"dummy signature\").toString(\"base64\")\n  );\n}", "label": 3}
{"code": "func (f *Fpdf) GetStringWidth(s string) float64 {\n\tif f.err != nil {\n\t\treturn 0\n\t}\n\tw := 0\n\tfor _, ch := range []byte(s) {\n\t\tif ch == 0 {\n\t\t\tbreak\n\t\t}\n\t\tw += f.currentFont.Cw[ch]\n\t}\n\treturn float64(w) * f.fontSize / 1000\n}", "label": 5}
{"code": "public static function ucwords( $string, $delimiters = \" \\n\\t\\r\\0\\x0B-\" ) {\n\t\treturn preg_replace_callback(\n\t\t\t'/[^' . preg_quote( $delimiters, '/' ) . ']+/',\n\t\t\tfunction( $matches ) {\n\t\t\t\treturn ucfirst( $matches[0] );\n\t\t\t},\n\t\t\t$string\n\t\t);\n\t}", "label": 2}
{"code": "def create_guild_role(data)\n      role_data = data['role']\n      server_id = data['guild_id'].to_i\n      server = @servers[server_id]\n      new_role = Role.new(role_data, self, server)\n      existing_role = server.role(new_role.id)\n      if existing_role\n        existing_role.update_from(new_role)\n      else\n        server.add_role(new_role)\n      end\n    end", "label": 4}
{"code": "public static function launch_self( $command, $args = array(), $assoc_args = array(), $exit_on_error = true, $return_detailed = false, $runtime_args = array() ) {\n\t\t$reused_runtime_args = array(\n\t\t\t'path',\n\t\t\t'url',\n\t\t\t'user',\n\t\t\t'allow-root',\n\t\t);\n\n\t\tforeach ( $reused_runtime_args as $key ) {\n\t\t\tif ( isset( $runtime_args[ $key ] ) ) {\n\t\t\t\t$assoc_args[ $key ] = $runtime_args[ $key ];\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t$value = self::get_runner()->config[ $key ];\n\t\t\tif ( $value ) {\n\t\t\t\t$assoc_args[ $key ] = $value;\n\t\t\t}\n\t\t}\n\n\t\t$php_bin = escapeshellarg( Utils\\get_php_binary() );\n\n\t\t$script_path = $GLOBALS['argv'][0];\n\n\t\tif ( getenv( 'WP_CLI_CONFIG_PATH' ) ) {\n\t\t\t$config_path = getenv( 'WP_CLI_CONFIG_PATH' );\n\t\t} else {\n\t\t\t$config_path = Utils\\get_home_dir() . '/.wp-cli/config.yml';\n\t\t}\n\t\t$config_path = escapeshellarg( $config_path );\n\n\t\t$args       = implode( ' ', array_map( 'escapeshellarg', $args ) );\n\t\t$assoc_args = \\WP_CLI\\Utils\\assoc_args_to_str( $assoc_args );\n\n\t\t$full_command = \"WP_CLI_CONFIG_PATH={$config_path} {$php_bin} {$script_path} {$command} {$args} {$assoc_args}\";\n\n\t\treturn self::launch( $full_command, $exit_on_error, $return_detailed );\n\t}", "label": 2}
{"code": "@SuppressWarnings(\"deprecation\")\n\tpublic static boolean isTimeInRange(java.sql.Time start, java.sql.Time end, java.util.Date d) {\n        d = new java.sql.Time(d.getHours(), d.getMinutes(), d.getSeconds());\n\n        if (start == null || end == null) {\n            return false;\n        }\n\n        if (start.before(end) && (!(d.after(start) && d.before(end)))) {\n            return false;\n        }\n\n        if (end.before(start) && (!(d.after(end) || d.before(start)))) {\n            return false;\n        }\n        return true;\n    }", "label": 0}
{"code": "public static function register(StorageClient $client, $protocol = null)\n    {\n        $protocol = $protocol ?: self::DEFAULT_PROTOCOL;\n        if (!in_array($protocol, stream_get_wrappers())) {\n            if (!stream_wrapper_register($protocol, StreamWrapper::class, STREAM_IS_URL)) {\n                throw new \\RuntimeException(\"Failed to register '$protocol://' protocol\");\n            }\n            self::$clients[$protocol] = $client;\n            return true;\n        }\n        return false;\n    }", "label": 2}
{"code": "public function pathEndIdentifierType()\n    {\n        $end = $this->pathEnd();\n\n        if (isset($end['id'])) {\n            return self::TYPE_ID;\n        }\n\n        if (isset($end['name'])) {\n            return self::TYPE_NAME;\n        }\n\n        return null;\n    }", "label": 2}
{"code": "func CopyToken(t Token) Token {\n\tswitch v := t.(type) {\n\tcase CharData:\n\t\treturn v.Copy()\n\tcase Comment:\n\t\treturn v.Copy()\n\tcase Directive:\n\t\treturn v.Copy()\n\tcase ProcInst:\n\t\treturn v.Copy()\n\tcase StartElement:\n\t\treturn v.Copy()\n\t}\n\treturn t\n}", "label": 5}
{"code": "func (m *ProcessManager) ListProcesses(pids []int64) []byte {\n\tw := new(bytes.Buffer)\n\n\tm.mu.Lock()\n\n\tif len(pids) == 0 {\n\t\tfor _, p := range m.entries {\n\t\t\t_, _ = w.WriteString(p.toXML())\n\t\t}\n\t} else {\n\t\tfor _, id := range pids {\n\t\t\tp, ok := m.entries[id]\n\t\t\tif !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t_, _ = w.WriteString(p.toXML())\n\t\t}\n\t}\n\n\tm.mu.Unlock()\n\n\treturn w.Bytes()\n}", "label": 5}
{"code": "def entrypoints(section):\n    \"\"\"\n    Returns the Entry Point for a given Entry Point section.\n\n    :param str section: The section name in the entry point collection\n    :returns:  A dictionary of (Name, Class) pairs stored in the entry point collection.\n    \"\"\"\n    return {ep.name: ep.load() for ep in pkg_resources.iter_entry_points(section)}", "label": 1}
{"code": "def add_permalink_suffix(template, permalink_style)\n      template = template.dup\n\n      case permalink_style\n      when :pretty\n        template << \"/\"\n      when :date, :ordinal, :none\n        template << \":output_ext\"\n      else\n        template << \"/\" if permalink_style.to_s.end_with?(\"/\")\n        template << \":output_ext\" if permalink_style.to_s.end_with?(\":output_ext\")\n      end\n\n      template\n    end", "label": 4}
{"code": "function Api(basePath, options) {\n            this._basePath = basePath;\n            options = options || {};\n            this._options = {\n                enableBatching: options.hasOwnProperty('enableBatching') ?\n                    options.enableBatching :\n                    true,\n                timeout: options.timeout || 0\n            };\n            this._batch = [];\n            this._deferreds = {};\n        }", "label": 3}
{"code": "def parse(source, options = {})\n      @options = options\n      @profiling = options[:profile]\n      @line_numbers = options[:line_numbers] || @profiling\n      parse_context = options.is_a?(ParseContext) ? options : ParseContext.new(options)\n      @root = Document.parse(tokenize(source), parse_context)\n      @warnings = parse_context.warnings\n      self\n    end", "label": 4}
{"code": "function deeplyExtendPkg(a, b) {\n\tif(!a.resolutions) {\n\t\ta.resolutions = {};\n\t}\n\tutils.extend(a.resolutions, b.resolutions || {});\n\n\tif(!a.steal) {\n\t\ta.steal = {};\n\t}\n\tif(!b.steal) {\n\t\tb.steal = {};\n\t}\n\n\tutils.extend(a.steal, b.steal, true);\n}", "label": 3}
{"code": "def to_native(self, value):\n        \"\"\"Return the value as a dict, raising error if conversion to dict is not possible\"\"\"\n        if isinstance(value, dict):\n            return value\n        elif isinstance(value, six.string_types):\n            native_value = json.loads(value)\n            if isinstance(native_value, dict):\n                return native_value\n            else:\n                raise ConversionError(u'Cannot load value as a dict: {}'.format(value))", "label": 1}
{"code": "def find_any_field(browser, field_types, field_name):\n    \"\"\"\n    Find a field of any of the specified types.\n    \"\"\"\n\n    return reduce(\n        operator.add,\n        (find_field(browser, field_type, field_name)\n         for field_type in field_types)\n    )", "label": 1}
{"code": "public void addCorporateGroupId(final String organizationId, final String corporateGroupId) {\n        final DbOrganization dbOrganization = getOrganization(organizationId);\n\n        if(!dbOrganization.getCorporateGroupIdPrefixes().contains(corporateGroupId)){\n            dbOrganization.getCorporateGroupIdPrefixes().add(corporateGroupId);\n            repositoryHandler.store(dbOrganization);\n        }\n\n        repositoryHandler.addModulesOrganization(corporateGroupId, dbOrganization);\n    }", "label": 0}
{"code": "public static <T> IteratorFromReaderFactory<T> getFactory(String delim, Function<String,T> op) {\r\n    return new DelimitRegExIteratorFactory<T>(delim, op);\r\n  }", "label": 0}
{"code": "def parse_config_file(job, config_file):\n    \"\"\"\n    This module will parse the config file withing params and set up the variables that will be\n    passed to the various tools in the pipeline.\n\n    ARGUMENTS\n    config_file: string containing path to a config file.  An example config\n                 file is available at\n                        https://s3-us-west-2.amazonaws.com/pimmuno-references\n                        /input_parameters.list\n\n    RETURN VALUES\n    None\n    \"\"\"\n    job.fileStore.logToMaster('Parsing config file')\n    config_file = os.path.abspath(config_file)\n    if not os.path.exists(config_file):\n        raise ParameterError('The config file was not found at specified location. Please verify ' +\n                             'and retry.')\n    # Initialize variables to hold the sample sets, the universal options, and the per-tool options\n    sample_set = defaultdict()\n    univ_options = defaultdict()\n    tool_options = defaultdict()\n    # Read through the notes and the\n    with open(config_file, 'r') as conf:\n        for line in conf:\n            line = line.strip()\n            if line.startswith('##') or len(line) == 0:\n                continue\n            if line.startswith('BEGIN'):\n                break\n        # The generator function tool_specific_param_generator will yield one group name at a time\n        # along with it's parameters.\n        for groupname, group_params in tool_specific_param_generator(job, conf):\n            if groupname == 'patient':\n                if 'patient_id' not in group_params.keys():\n                    raise ParameterError('A patient group is missing the patient_id flag.')\n                sample_set[group_params['patient_id']] = group_params\n            elif groupname == 'Universal_Options':\n                univ_options = group_params\n                required_options = {'java_Xmx', 'output_folder', 'storage_location'}\n                missing_opts = required_options.difference(set(univ_options.keys()))\n                if len(missing_opts) > 0:\n                    raise ParameterError(' The following options have no arguments in the config '\n                                         'file :\\n' + '\\n'.join(missing_opts))\n                if univ_options['sse_key_is_master']:\n                    assert univ_options['sse_key_is_master'] in ('True', 'true', 'False', 'false')\n                    univ_options['sse_key_is_master'] = \\\n                        univ_options['sse_key_is_master'] in ('True', 'true')\n            # If it isn't any of the above, it's a tool group\n            else:\n                tool_options[groupname] = group_params\n    # Ensure that all tools have been provided options.\n    required_tools = {'cutadapt', 'bwa', 'star', 'phlat', 'transgene', 'mut_callers', 'rsem',\n                      'mhci', 'mhcii', 'snpeff', 'rank_boost'}\n    #                'fusion', 'indels'}\n    missing_tools = required_tools.difference(set(tool_options.keys()))\n    if len(missing_tools) > 0:\n        raise ParameterError(' The following tools have no arguments in the config file : \\n' +\n                             '\\n'.join(missing_tools))\n    # Start a job for each sample in the sample set\n    for patient_id in sample_set.keys():\n        job.addFollowOnJobFn(pipeline_launchpad, sample_set[patient_id], univ_options, tool_options)\n    return None", "label": 1}
{"code": "function (num, totalBytes) {\n  var numBytes = Math.floor(Math.log(num) / Math.log(0xff)) + 1;\n  var buffer = new Buffer(totalBytes);\n\n  buffer.fill(0);\n  buffer.writeUIntBE(num, totalBytes - numBytes, numBytes);\n\n  return buffer;\n}", "label": 3}
{"code": "public static double Magnitude(ComplexNumber z) {\r\n        return Math.sqrt(z.real * z.real + z.imaginary * z.imaginary);\r\n    }", "label": 0}
{"code": "func PgOperatorByOid(db XODB, oid pgtypes.Oid) (*PgOperator, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, oprname, oprnamespace, oprowner, oprkind, oprcanmerge, oprcanhash, oprleft, oprright, oprresult, oprcom, oprnegate, oprcode, oprrest, oprjoin ` +\n\t\t`FROM pg_catalog.pg_operator ` +\n\t\t`WHERE oid = $1`\n\n\t// run query\n\tXOLog(sqlstr, oid)\n\tpo := PgOperator{}\n\n\terr = db.QueryRow(sqlstr, oid).Scan(&po.Tableoid, &po.Cmax, &po.Xmax, &po.Cmin, &po.Xmin, &po.Oid, &po.Ctid, &po.Oprname, &po.Oprnamespace, &po.Oprowner, &po.Oprkind, &po.Oprcanmerge, &po.Oprcanhash, &po.Oprleft, &po.Oprright, &po.Oprresult, &po.Oprcom, &po.Oprnegate, &po.Oprcode, &po.Oprrest, &po.Oprjoin)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &po, nil\n}", "label": 5}
{"code": "function startSkeletonApplication(options) {\n  debug('Starting to create application skeleton');\n  const configWithDefaults = defaults(\n    options, {\n      redirects: {\n        'documentation-from-root': {\n          match: /^\\/$/,\n          target: '/docs',\n        },\n      },\n      ioc: {\n      },\n      customMiddleware: {\n        beforeSwagger: [],\n        afterSwagger: [],\n        beforeController: [],\n      },\n      codegen: {\n        controllerStubFolder: 'controllers',\n        temporaryDirectory: './.temp',\n        templateSet: templates,\n      },\n      service: {\n        listenPort: 10010,\n      },\n      cors: {\n      },\n    });\n\n  // If the swagger input is a string, then load it as a filename\n  const swaggerFile = configWithDefaults.service.swagger;\n  const swagger = typeof swaggerFile === 'string' ?\n    yamljs.load(swaggerFile) : swaggerFile;\n\n  // Create service instances\n  const app = connect();\n  const ioc = connectIoc(configWithDefaults.ioc);\n\n  // Generate custom application code\n  generateApplicationCode(\n    swagger,\n    configWithDefaults.codegen);\n\n  initializeSwagger(swagger, (middleware) => {\n    // Pre-request handling middleware\n    app.use(query());                                    // Query-string parsing\n    app.use(fiddleware.respondJson());                   // res.json(data, status) support.\n    app.use(ioc.middleware);                             // Somersault IoC for controllers.\n    app.use(cors(configWithDefaults.cors));              // Cross-origin\n    app.use(cookieParser());\n    // Custom middleware\n    for (const item of configWithDefaults.customMiddleware.beforeSwagger) {\n      app.use(item);\n    }\n\n    // Swagger-tools middleware\n    app.use(middleware.swaggerMetadata());\n    app.use(middleware.swaggerValidator());\n\n    for (const item of configWithDefaults.customMiddleware.beforeController) {\n      app.use(item);\n    }\n\n    app.use(middleware.swaggerRouter({\n      controllers: path.join(\n        configWithDefaults.codegen.temporaryDirectory,\n        configWithDefaults.codegen.controllerStubFolder),\n    }));\n    app.use(middleware.swaggerUi());\n\n    // Post-request handling middleware\n    app.use(redirect(configWithDefaults.redirects));      // Redirect / to /docs\n\n    // Custom middleware\n    for (const item of configWithDefaults.customMiddleware.afterSwagger) {\n      app.use(item);\n    }\n\n    app.use(errorHandler());                              // When there's an exception.\n\n    const server = app.listen(configWithDefaults.service.listenPort);\n    app.close = function closeServer() {\n      server.close();\n    };\n  });\n\n  return app;\n}", "label": 3}
{"code": "public double getValue(int[] batch) {\n        double value = 0.0;\n        for (int i=0; i<batch.length; i++) {\n            value += getValue(i);\n        }\n        return value;\n    }", "label": 0}
{"code": "function(sourceWasAnError, shouldNotReconnect) {\n      log.error(\"[Endpoint] Connection closed \" + (sourceWasAnError ? 'because of an error:' + sourceWasAnError : ''));\n\n      this.connected = false;\n      this.handshaken = false;\n      this.connecting = false;\n\n      if (!shouldNotReconnect) {\n        log.debug('onClose():: reconnecting...');\n        this.handshakenBackoff.reset();\n        this.reconnectBackoff.backoff();\n      } else {\n        log.debug('onClose():: don\\'t reconnect');\n        this.handshakenBackoff.reset();\n        this.reconnectBackoff.reset();\n      }\n\n      this.emit('close', sourceWasAnError);\n    }", "label": 3}
{"code": "protected function prepareConnection(NodeConnectionInterface $connection)\n    {\n        $parameters = $connection->getParameters();\n\n        if (isset($parameters->password)) {\n            $connection->addConnectCommand(\n                new RawCommand(array('AUTH', $parameters->password))\n            );\n        }\n\n        if (isset($parameters->database)) {\n            $connection->addConnectCommand(\n                new RawCommand(array('SELECT', $parameters->database))\n            );\n        }\n    }", "label": 2}
{"code": "def handle_variable(data_criteria, collapsed_source_data_criteria)\n\n      if data_criteria.is_derived_specific_occurrence_variable\n        data_criteria.handle_derived_specific_occurrence_variable\n        extract_source_data_criteria(data_criteria)\n        return\n      end\n\n      tmp_id = data_criteria.id\n\n      grouper_data_criteria = data_criteria.extract_variable_grouper\n      return unless grouper_data_criteria\n      @data_criteria_references[data_criteria.id] = data_criteria\n      @data_criteria_references[grouper_data_criteria.id] = grouper_data_criteria\n\n      # create a source data criteria for the grouping data critera we just created\n      sdc = SourceDataCriteriaHelper.strip_non_sc_elements(grouper_data_criteria)\n      @source_data_criteria << sdc\n      \n      # check if the original source has been collapsed when generating the SDC list (we need to reference the collapsed version in the sdc list)\n      if collapsed_source_data_criteria[tmp_id]\n        data_criteria.instance_variable_set(:@source_data_criteria, collapsed_source_data_criteria[tmp_id])\n      else\n        # check if we need to add _source suffix (most source data criteria are segmented with '_source' suffixes)\n        data_criteria_sdc = find(@source_data_criteria, :id, \"#{tmp_id}_source\") \n        if data_criteria_sdc\n          data_criteria.instance_variable_set(:@source_data_criteria, data_criteria_sdc.id)\n          data_criteria_sdc.instance_variable_set(:@variable, false)\n        # if it's not a derived data criteria then we may need to strip off temporal references, fields, etc as a new source data criteria\n        elsif !['derived', 'satisfies_any', 'satisfies_all'].include?(data_criteria.definition)\n          extract_source_data_criteria(data_criteria)\n        end\n      end\n\n      @data_criteria << grouper_data_criteria\n    end", "label": 4}
{"code": "def main(argv):\n    \"\"\"This function sets up a command-line option parser and then calls\n    to do all of the real work.\n    \"\"\"\n    import argparse\n    import codecs\n    # have to be ready to deal with utf-8 names\n    out = codecs.getwriter('utf-8')(sys.stdout)\n    description = '''Takes a series of at least 2 OTT ids and reports the OTT of their least inclusive taxonomic ancestor and that taxon's ancestors.'''\n    parser = argparse.ArgumentParser(prog='ot-taxo-mrca-to-root', description=description)\n    parser.add_argument('ids', nargs='+', type=int, help='OTT IDs')\n    args = parser.parse_args(argv)\n    id_list = args.ids\n    last_id = id_list.pop()\n    anc_list = get_taxonomic_ancestor_ids(last_id)\n    common_anc = set(anc_list)\n    for curr_id in id_list:\n        curr_anc_set = set(get_taxonomic_ancestor_ids(curr_id))\n        common_anc &= curr_anc_set\n        if not common_anc:\n            break\n    for anc_id in anc_list:\n        if anc_id in common_anc:\n            out.write('{}\\n'.format(anc_id))", "label": 1}
{"code": "function normalizeTuple(target, path) {\n  var hasThis  = HAS_THIS.test(path),\n      isGlobal = !hasThis && IS_GLOBAL_PATH.test(path),\n      key;\n\n  if (!target || isGlobal) target = Ember.lookup;\n  if (hasThis) path = path.slice(5);\n\n  if (target === Ember.lookup) {\n    key = firstKey(path);\n    target = get(target, key);\n    path   = path.slice(key.length+1);\n  }\n\n  // must return some kind of path to be valid else other things will break.\n  if (!path || path.length===0) throw new Error('Invalid Path');\n\n  return [ target, path ];\n}", "label": 3}
{"code": "def get_plaintext_citations(file):\n    \"\"\"\n    Parse a plaintext file to get a clean list of plaintext citations. The \\\n            file should have one citation per line.\n\n    :param file: Either the path to the plaintext file or the content of a \\\n            plaintext file.\n    :returns:  A list of cleaned plaintext citations.\n    \"\"\"\n    # Handle path or content\n    if os.path.isfile(file):\n        with open(file, 'r') as fh:\n            content = fh.readlines()\n    else:\n        content = file.splitlines()\n    # Clean every line to have plaintext\n    cleaned_citations = [tools.clean_whitespaces(line) for line in content]\n    return cleaned_citations", "label": 1}
{"code": "function loadBootstrap(appPath, modules, type = 'worker') {\n  let bootstrapPath = '';\n  if (modules.length) {\n    bootstrapPath = path.join(appPath, 'common/bootstrap');\n  } else {\n    bootstrapPath = path.join(appPath, 'bootstrap');\n  }\n  const filepath = path.join(bootstrapPath, `${type}.js`);\n  if (helper.isFile(filepath)) {\n    debug(`load file: ${filepath}`);\n    return require(filepath);\n  }\n}", "label": 3}
{"code": "public static appfwhtmlerrorpage get(nitro_service service,  options option) throws Exception{\n\t\tappfwhtmlerrorpage obj = new appfwhtmlerrorpage();\n\t\tappfwhtmlerrorpage[] response = (appfwhtmlerrorpage[])obj.get_resources(service,option);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "public function setNotificationChannel($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\NotificationChannel::class);\n        $this->notification_channel = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def addcols(self, cols, names=None):\n        \"\"\"\n        Add one or more new columns.\n\n        Method wraps::\n\n                tabular.spreadsheet.addcols(self, cols, names)\n\n        \"\"\"\n        data = spreadsheet.addcols(self, cols, names)\n        data = data.view(tabarray)\n        data.coloring = self.coloring\n        return data", "label": 1}
{"code": "def to_h\n      configs = configurations.reverse.inject({}) do |memo, db_config|\n        memo.merge(db_config.to_legacy_hash)\n      end\n\n      Hash[configs.to_a.reverse]\n    end", "label": 4}
{"code": "public function getByName($name)\n    {\n        return isset($this->names[$name]) ? $this->names[$name] : null;\n    }", "label": 2}
{"code": "def worker_class_constantize(klazz = @worker_class)\n      return klazz unless klazz.is_a?(String)\n\n      Object.const_get(klazz)\n    rescue NameError => ex\n      case ex.message\n      when /uninitialized constant/\n        klazz\n      else\n        raise\n      end\n    end", "label": 4}
{"code": "function setValueDisplay() {\n      var value = self.get().toFixed(self.precision);\n      $value.set('value', value);\n      $valuePad.set('innerHTML', value);\n    }", "label": 3}
{"code": "def reek_only_of(smell_type, configuration = Configuration::AppConfiguration.default)\n      ShouldReekOnlyOf.new(smell_type, configuration)\n    end", "label": 4}
{"code": "def hyperlinks\n      links = self.images.select { |a| a.hyperlink.is_a?(Hyperlink) }\n      links.map { |a| a.hyperlink }\n    end", "label": 4}
{"code": "def poll_stack(self):\n        \"\"\"\n        Spin in a loop while the Cloud Formation process either fails or succeeds\n\n        Args:\n            None\n\n        Returns:\n            Good or bad; True or False\n        \"\"\"\n        logging.info('polling stack status, POLL_INTERVAL={}'.format(POLL_INTERVAL))\n        time.sleep(POLL_INTERVAL)\n        completed_states = [\n            'CREATE_COMPLETE',\n            'UPDATE_COMPLETE',\n            'DELETE_COMPLETE'\n        ]\n        stack_name = self._config.get('environment', {}).get('stack_name', None)\n        while True:\n            try:\n                response = self._cloudFormation.describe_stacks(StackName=stack_name)\n                stack = response['Stacks'][0]\n                current_status = stack['StackStatus']\n                logging.info('current status of {}: {}'.format(stack_name, current_status))\n                if current_status.endswith('COMPLETE') or current_status.endswith('FAILED'):\n                    if current_status in completed_states:\n                        return True\n                    else:\n                        return False\n\n                time.sleep(POLL_INTERVAL)\n            except ClientError as wtf:\n                if str(wtf).find('does not exist') == -1:\n                    logging.error('Exception caught in wait_for_stack(): {}'.format(wtf))\n                    traceback.print_exc(file=sys.stdout)\n                    return False\n                else:\n                    logging.info('{} is gone'.format(stack_name))\n                    return True\n            except Exception as wtf:\n                logging.error('Exception caught in wait_for_stack(): {}'.format(wtf))\n                traceback.print_exc(file=sys.stdout)\n                return False", "label": 1}
{"code": "def add_atomic_pull(document)\n      document.flagged_for_destroy = true\n      (delayed_atomic_pulls[document.association_name.to_s] ||= []).push(document)\n    end", "label": 4}
{"code": "public function setEncryptionConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\EncryptionConfig::class);\n        $this->encryption_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def to_document(input, context = {}, result = nil)\n      result = call(input, context, result)\n      HTML::Pipeline.parse(result[:output])\n    end", "label": 4}
{"code": "func (l *LoadBalancer) AddBackend(b NetAddr) {\n\tl.Lock()\n\tdefer l.Unlock()\n\tl.backends = append(l.backends, b)\n\tl.Debugf(\"backends %v\", l.backends)\n}", "label": 5}
{"code": "public static double I(int n, double x) {\r\n        if (n < 0)\r\n            throw new IllegalArgumentException(\"the variable n out of range.\");\r\n        else if (n == 0)\r\n            return I0(x);\r\n        else if (n == 1)\r\n            return I(x);\r\n\r\n        if (x == 0.0)\r\n            return 0.0;\r\n\r\n        double ACC = 40.0;\r\n        double BIGNO = 1.0e+10;\r\n        double BIGNI = 1.0e-10;\r\n\r\n        double tox = 2.0 / Math.abs(x);\r\n        double bip = 0, ans = 0.0;\r\n        double bi = 1.0;\r\n\r\n        for (int j = 2 * (n + (int) Math.sqrt(ACC * n)); j > 0; j--) {\r\n            double bim = bip + j * tox * bi;\r\n            bip = bi;\r\n            bi = bim;\r\n\r\n            if (Math.abs(bi) > BIGNO) {\r\n                ans *= BIGNI;\r\n                bi *= BIGNI;\r\n                bip *= BIGNI;\r\n            }\r\n\r\n            if (j == n)\r\n                ans = bip;\r\n        }\r\n\r\n        ans *= I0(x) / bi;\r\n        return x < 0.0 && n % 2 == 1 ? -ans : ans;\r\n    }", "label": 0}
{"code": "func (m *MockIndex) Func(arg0 func(http.Request) (int, bool)) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"Func\", arg0)\n}", "label": 5}
{"code": "func (f *file) checkContextKeyType(x *ast.CallExpr) {\n\tsel, ok := x.Fun.(*ast.SelectorExpr)\n\tif !ok {\n\t\treturn\n\t}\n\tpkg, ok := sel.X.(*ast.Ident)\n\tif !ok || pkg.Name != \"context\" {\n\t\treturn\n\t}\n\tif sel.Sel.Name != \"WithValue\" {\n\t\treturn\n\t}\n\n\t// key is second argument to context.WithValue\n\tif len(x.Args) != 3 {\n\t\treturn\n\t}\n\tkey := f.pkg.typesInfo.Types[x.Args[1]]\n\n\tif ktyp, ok := key.Type.(*types.Basic); ok && ktyp.Kind() != types.Invalid {\n\t\tf.errorf(x, 1.0, category(\"context\"), fmt.Sprintf(\"should not use basic type %s as key in context.WithValue\", key.Type))\n\t}\n}", "label": 5}
{"code": "func (r *Resource) WithAction(action string) *Resource {\n\tr.u.RawQuery = url.Values{\n\t\t\"~action\": []string{action},\n\t}.Encode()\n\treturn r\n}", "label": 5}
{"code": "func (s *Server) proxy(w http.ResponseWriter, r *http.Request) {\n\tif r.Method != http.MethodConnect {\n\t\thttp.Error(w, \"\", http.StatusMethodNotAllowed)\n\t\treturn\n\t}\n\n\tdst, err := net.Dial(\"tcp\", s.URL.Host)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusBadGateway)\n\t\treturn\n\t}\n\tw.WriteHeader(http.StatusOK)\n\n\tsrc, _, err := w.(http.Hijacker).Hijack()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tgo io.Copy(src, dst)\n\tgo func() {\n\t\t_, _ = io.Copy(dst, src)\n\t\t_ = dst.Close()\n\t\t_ = src.Close()\n\t}()\n}", "label": 5}
{"code": "def remove_population_preconditions(doc)\n      # population sections\n      pop_ids = doc.xpath(\"//cda:populationCriteriaSection/cda:component[@typeCode='COMP']/*/cda:id\",\n                          HQMF2::Document::NAMESPACES)\n      # find the population entries and get their ids\n      pop_ids.each do |p_id|\n        doc.xpath(\"//cda:precondition[./cda:criteriaReference/cda:id[@extension='#{p_id['extension']}' and @root='#{p_id['root']}']]\",\n                  HQMF2::Document::NAMESPACES).remove\n      end\n    end", "label": 4}
{"code": "function parser (content, options, fn) {\n      var jshintrc = path.join(process.env.HOME || process.env.USERPROFILE, '.jshintrc')\n        , jshintninja = configurator(jshintrc)\n        , config = options.jshint;\n\n      // extend all the things\n      config = _.extend(config, jshintninja);\n\n      canihaz.jshint(function lazyload (err, jshint) {\n        if (err) return fn(err);\n\n        var validates = jshint.JSHINT(content, config)\n          , errors;\n\n        if (!validates) errors = formatters.js(jshint.JSHINT.errors);\n        fn(null, errors);\n      });\n    }", "label": 3}
{"code": "function getPath(path, callback) {\n  fs.lstat(path, function(err, stats) {\n    if(err) return callback(err);\n\n    // Check if it's a link\n    if(stats.isSymbolicLink()) fs.readlink(path, callback);\n\n    callback(err, path);\n  });\n}", "label": 3}
{"code": "function _gpfWebGetNamespaceAndName (name) {\n    var EXPECTED_PARTS_COUNT = 2,\n        NAMESPACE_PREFIX = 0,\n        NAME = 1,\n        parts = name.split(\":\");\n    if (parts.length === EXPECTED_PARTS_COUNT) {\n        return {\n            namespace: _gpfWebGetNamespace(parts[NAMESPACE_PREFIX]),\n            name: parts[NAME]\n        };\n    }\n}", "label": 3}
{"code": "func (s *AccessService) DeleteRole(name string) error {\n\tif name == \"\" {\n\t\treturn trace.BadParameter(\"missing role name\")\n\t}\n\terr := s.Delete(context.TODO(), backend.Key(rolesPrefix, name, paramsPrefix))\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn trace.NotFound(\"role %q is not found\", name)\n\t\t}\n\t}\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "function executable(file) {\n  try {\n    fs.accessSync(file, fs.X_OK);\n    return true;\n  } catch (e) {\n    return false;\n  }\n}", "label": 3}
{"code": "def node_on_single_line?(node)\n      return if node.source_range.start_pos.line != node.source_range.end_pos.line\n\n      # The Sass parser reports an incorrect source range if the trailing curly\n      # brace is on the next line, e.g.\n      #\n      #   p {\n      #   }\n      #\n      # Since we don't want to count this as a single line node, check if the\n      # last character on the first line is an opening curly brace.\n      engine.lines[node.line - 1].strip[-1] != '{'\n    end", "label": 4}
{"code": "public static Object newInstance(String className, Class[] types, Object[] args) throws InstantiationException,\r\n                                                                                            IllegalAccessException,\r\n                                                                                            IllegalArgumentException,\r\n                                                                                            InvocationTargetException,\r\n                                                                                            NoSuchMethodException,\r\n                                                                                            SecurityException,\r\n                                                                                            ClassNotFoundException\r\n    {\r\n        return newInstance(getClass(className), types, args);\r\n    }", "label": 0}
{"code": "func (c *Manager) CreateLibraryItem(ctx context.Context, item Item) (string, error) {\n\ttype createItemSpec struct {\n\t\tName        string `json:\"name\"`\n\t\tDescription string `json:\"description\"`\n\t\tLibraryID   string `json:\"library_id,omitempty\"`\n\t\tType        string `json:\"type\"`\n\t}\n\tspec := struct {\n\t\tItem createItemSpec `json:\"create_spec\"`\n\t}{\n\t\tItem: createItemSpec{\n\t\t\tName:        item.Name,\n\t\t\tDescription: item.Description,\n\t\t\tLibraryID:   item.LibraryID,\n\t\t\tType:        item.Type,\n\t\t},\n\t}\n\turl := internal.URL(c, internal.LibraryItemPath)\n\tvar res string\n\treturn res, c.Do(ctx, url.Request(http.MethodPost, spec), &res)\n}", "label": 5}
{"code": "def process_line(line)\n      case line.text[0]\n      when DIV_CLASS; push div(line)\n      when DIV_ID\n        return push plain(line) if %w[{ @ $].include?(line.text[1])\n        push div(line)\n      when ELEMENT; push tag(line)\n      when COMMENT; push comment(line.text[1..-1].lstrip)\n      when SANITIZE\n        return push plain(line.strip!(3), :escape_html) if line.text[1, 2] == '=='\n        return push script(line.strip!(2), :escape_html) if line.text[1] == SCRIPT\n        return push flat_script(line.strip!(2), :escape_html) if line.text[1] == FLAT_SCRIPT\n        return push plain(line.strip!(1), :escape_html) if line.text[1] == ?\\s || line.text[1..2] == '#{'\n        push plain(line)\n      when SCRIPT\n        return push plain(line.strip!(2)) if line.text[1] == SCRIPT\n        line.text = line.text[1..-1]\n        push script(line)\n      when FLAT_SCRIPT; push flat_script(line.strip!(1))\n      when SILENT_SCRIPT\n        return push haml_comment(line.text[2..-1]) if line.text[1] == SILENT_COMMENT\n        push silent_script(line)\n      when FILTER; push filter(line.text[1..-1].downcase)\n      when DOCTYPE\n        return push doctype(line.text) if line.text[0, 3] == '!!!'\n        return push plain(line.strip!(3), false) if line.text[1, 2] == '=='\n        return push script(line.strip!(2), false) if line.text[1] == SCRIPT\n        return push flat_script(line.strip!(2), false) if line.text[1] == FLAT_SCRIPT\n        return push plain(line.strip!(1), false) if line.text[1] == ?\\s || line.text[1..2] == '#{'\n        push plain(line)\n      when ESCAPE\n        line.text = line.text[1..-1]\n        push plain(line)\n      else; push plain(line)\n      end\n    end", "label": 4}
{"code": "function templateServiceFactory(\n    Constants, \n    Promise, \n    _, \n    DbRenderable,\n    Util ) \n{\n    Util.inherits(TemplateService, DbRenderable);\n\n    /**\n     * TemplateService is a singleton object which provides key/value store\n     * access to template files loaded from disk via FileLoader.\n     * @constructor\n     * @extends {FileLoader}\n     */\n    function TemplateService () {\n        DbRenderable.call(this, {\n            directory: Constants.Templates.Directory,\n            collectionName: 'templates'\n        });\n    }\n\n    return new TemplateService();\n}", "label": 3}
{"code": "public static csvserver_cachepolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tcsvserver_cachepolicy_binding obj = new csvserver_cachepolicy_binding();\n\t\tobj.set_name(name);\n\t\tcsvserver_cachepolicy_binding response[] = (csvserver_cachepolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def max_sequence_depth(comma_sequence, current_depth)\n      # Sequence contains interpolation; assume a depth of 1\n      return current_depth + 1 unless comma_sequence\n\n      comma_sequence.members.map { |sequence| sequence_depth(sequence, current_depth) }.max\n    end", "label": 4}
{"code": "def min_version(self):\n        \"\"\"Version with the fewest downloads.\"\"\"\n        data = self.version_downloads\n        if not data:\n            return (None, 0)\n        return min(data.items(), key=lambda item: item[1])", "label": 1}
{"code": "function syncToTmp(tmpfd, msgnumber, cb) {\n\n        // Pass the last msg\n        if (msgnumber > messages.offsets.length) cb();\n\n        // Skip deleted messages\n        else if (messages.offsets[msgnumber] === undefined) syncToTmp(tmpfd, msgnumber + 1, cb);\n        else {\n\n            var buffer = new Buffer(omessages.sizes[msgnumber]);\n\n            fs.read(fd, buffer, 0, omessages.sizes[msgnumber], messages.offsets[msgnumber], function(err, bytesRead, buffer) {\n\n                fs.write(tmpfd, buffer, 0, bytesRead, null, function(err, written, buffer) {\n\n                    syncToTmp(tmpfd, msgnumber + 1, cb);\n\n                });\n            });\n        }\n    }", "label": 3}
{"code": "public function deleteFromColumn($family, $qualifier, array $timeRange = [])\n    {\n        $deleteFromColumn = (new DeleteFromColumn)\n            ->setFamilyName($family)\n            ->setColumnQualifier($qualifier);\n        if (!empty($timeRange)) {\n            $timestampRange = new TimestampRange;\n            if (isset($timeRange['start'])) {\n                $timestampRange->setStartTimestampMicros($timeRange['start']);\n            }\n            if (isset($timeRange['end'])) {\n                $timestampRange->setEndTimestampMicros($timeRange['end']);\n            }\n            $deleteFromColumn->setTimeRange($timestampRange);\n        }\n        $this->mutations[] = (new Mutation)->setDeleteFromColumn($deleteFromColumn);\n        return $this;\n    }", "label": 2}
{"code": "def get_intended_direction(self):\n        \"\"\"\n        returns a Y,X value showing which direction the\n        agent should move in order to get to the target\n        \"\"\"\n        x = 0\n        y = 0\n        if self.target_x == self.current_x and self.target_y == self.current_y:\n            return y,x  # target already acquired\n        if self.target_y > self.current_y:\n            y = 1\n        elif self.target_y < self.current_y:\n            y = -1\n        if self.target_x > self.current_x:\n            x = 1\n        elif self.target_x < self.current_x:\n            x = -1\n        return y,x", "label": 1}
{"code": "function(type, attributes, isCheckable, classAttributes) {\n        return React.createClass(_.extend({\n            mixins: ['modelAware'],\n            render: function() {\n                var props = {};\n                var defaultValue = getModelValue(this);\n                if (isCheckable) {\n                    props.defaultChecked = defaultValue;\n                } else {\n                    props.defaultValue = defaultValue;\n                }\n                return React.DOM[type](_.extend(props, attributes, this.props,\n                    {onChange: twoWayBinding(this)}), this.props.children);\n            },\n            getValue: function() {\n                if (this.isMounted()) {\n                    if (isCheckable) {\n                        var el = this.getDOMNode();\n                        return el.checked ? true : false;\n                    } else {\n                        return getElementValue(this);\n                    }\n                }\n            },\n            getDOMValue: function() {\n                if (this.isMounted()) {\n                    return getElementValue(this);\n                }\n            }\n        }, classAttributes));\n    }", "label": 3}
{"code": "func iterBitmapsDistinct(skip *bitmap.Bitmap, bms ...bitmap.Bitmap) iter.Func {\n\treturn func(cb iter.Callback) {\n\t\tfor _, bm := range bms {\n\t\t\tif !iter.All(func(i interface{}) bool {\n\t\t\t\tskip.Add(i.(int))\n\t\t\t\treturn cb(i)\n\t\t\t}, bitmap.Sub(bm, *skip).Iter) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}", "label": 5}
{"code": "def delete_break_type(id, opts = {})\n      data, _status_code, _headers = delete_break_type_with_http_info(id, opts)\n      return data\n    end", "label": 4}
{"code": "function buildDOM(body,engine,url,callback){\n    if(!body){\n        return callback(new ScrapinodeError('The HTTP response contains an empty body: \"' + body +'\"'));\n    }\n\n    if(engine === 'jsdom' || engine === 'jsdom+zepto'){\n        var library = engine === 'jsdom+zepto' ? zepto : jquery;\n        try{\n            jsdom.env({\n               html: body,\n               src : [library],\n               done : function(err,window){\n                   if(err) return callback(err);\n                   if(!window) return callback(new ScrapinodeError('The \"window\" provides by JSDOM is falsy: ' + window));\n                   window.location.href = url;\n                   callback(err,window);\n                   window.close();\n               }\n            });\n        }catch(err){\n            callback(err);\n        }\n    }else if(engine === 'cheerio'){\n        try{\n            var $ = cheerio.load(body);\n            var window = {\n                $ : $,\n                location : {\n                    href : url\n                }\n            };\n            callback(null,window);\n        }catch(err){\n            callback(err);\n        }\n    }else{\n        callback(new ScrapinodeError('The engine \"' + engine + '\" is not supported. Scrapinode only supports jsdom and cheerio.'));\n    }\n}", "label": 3}
{"code": "func isUnique(fl FieldLevel) bool {\n\n\tfield := fl.Field()\n\tv := reflect.ValueOf(struct{}{})\n\n\tswitch field.Kind() {\n\tcase reflect.Slice, reflect.Array:\n\t\tm := reflect.MakeMap(reflect.MapOf(field.Type().Elem(), v.Type()))\n\n\t\tfor i := 0; i < field.Len(); i++ {\n\t\t\tm.SetMapIndex(field.Index(i), v)\n\t\t}\n\t\treturn field.Len() == m.Len()\n\tcase reflect.Map:\n\t\tm := reflect.MakeMap(reflect.MapOf(field.Type().Elem(), v.Type()))\n\n\t\tfor _, k := range field.MapKeys() {\n\t\t\tm.SetMapIndex(field.MapIndex(k), v)\n\t\t}\n\t\treturn field.Len() == m.Len()\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"Bad field type %T\", field.Interface()))\n\t}\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, transformpolicy resource) throws Exception {\n\t\ttransformpolicy addresource = new transformpolicy();\n\t\taddresource.name = resource.name;\n\t\taddresource.rule = resource.rule;\n\t\taddresource.profilename = resource.profilename;\n\t\taddresource.comment = resource.comment;\n\t\taddresource.logaction = resource.logaction;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "function () {\n        if (!this._tunnel) {\n            return q();\n        }\n\n        var _this = this;\n\n        this._tunnel.kill('SIGTERM');\n        return this._closeDeferred.promise.timeout(3000).fail(function () {\n            _this._tunnel.kill('SIGKILL');\n            return _this._closeTunnel(-1);\n        });\n    }", "label": 3}
{"code": "public function add($unit, $value = 1, $overflow = null)\n    {\n        if (is_string($unit) && func_num_args() === 1) {\n            $unit = CarbonInterval::make($unit);\n        }\n\n        if ($unit instanceof DateInterval) {\n            return parent::add($unit);\n        }\n\n        if (is_numeric($unit)) {\n            $tempUnit = $value;\n            $value = $unit;\n            $unit = $tempUnit;\n        }\n\n        return $this->addUnit($unit, $value, $overflow);\n    }", "label": 2}
{"code": "func (cl *Client) WaitAll() bool {\n\tcl.lock()\n\tdefer cl.unlock()\n\tfor !cl.allTorrentsCompleted() {\n\t\tif cl.closed.IsSet() {\n\t\t\treturn false\n\t\t}\n\t\tcl.event.Wait()\n\t}\n\treturn true\n}", "label": 5}
{"code": "public void registerDropPasteWorker(DropPasteWorkerInterface worker)\r\n    {\r\n        this.dropPasteWorkerSet.add(worker);\r\n        defaultDropTarget.setDefaultActions( \r\n            defaultDropTarget.getDefaultActions() \r\n            | worker.getAcceptableActions(defaultDropTarget.getComponent())\r\n                                           );\r\n    }", "label": 0}
{"code": "def backfill_patient_characteristics_with_codes(codes)\n      \n      [].concat(self.all_data_criteria).concat(self.source_data_criteria).each do |data_criteria|\n        if (data_criteria.type == :characteristic and !data_criteria.property.nil?)\n          if (codes)\n            value_set = codes[data_criteria.code_list_id]\n            puts \"\\tno value set for unknown patient characteristic: #{data_criteria.id}\" unless value_set\n          else\n            puts \"\\tno code set to back fill: #{data_criteria.title}\"\n            next\n          end\n          \n          if (data_criteria.property == :gender)\n            next if value_set.nil?\n            key = value_set.keys[0]\n            data_criteria.value = HQMF::Coded.new('CD','Administrative Sex',value_set[key].first)\n          else\n            data_criteria.inline_code_list = value_set\n          end\n          \n        elsif (data_criteria.type == :characteristic)\n          if (codes)\n            value_set = codes[data_criteria.code_list_id]\n            if (value_set)\n              # this is looking for a birthdate characteristic that is set as a generic characteristic but points to a loinc code set\n              if (value_set['LOINC'] and value_set['LOINC'].first == '21112-8')\n                data_criteria.definition = 'patient_characteristic_birthdate'\n              end\n              # this is looking for a gender characteristic that is set as a generic characteristic\n              gender_key = (value_set.keys.select {|set| set == 'Administrative Sex' || set == 'AdministrativeSex'}).first\n              if (gender_key and ['M','F'].include? value_set[gender_key].first)\n                data_criteria.definition = 'patient_characteristic_gender'\n                data_criteria.value = HQMF::Coded.new('CD','Gender',value_set[gender_key].first)\n              end\n            end\n          end\n\n        end\n      end\n    end", "label": 4}
{"code": "function loadEntityAttribute(Entity, attribute) {\n    expect(arguments).to.have.length(\n      2,\n      'Invalid arguments length when loading an entity attribute in a ' +\n      'MongoAdapter (it has to be passed 2 arguments)'\n    );\n\n    expect(Entity).to.be.a(\n      'function',\n      'Invalid argument \"Entity\" when loading an entity in a ' +\n      'MongoAdapter (it has to be an Entity class)'\n    );\n\n    expect(classes.isGeneral(entity.models.Entity, Entity)).to.be.equal(\n      true,\n      'Invalid argument \"Entity\" when loading an entity attribute in a ' +\n      'MongoAdapter (it has to be an Entity class)'\n    );\n\n    expect(attribute).to.be.an.instanceOf(\n      Attribute,\n      'Invalid argument \"attribute\" when loading an entity attribute in a ' +\n      'MongoAdapter (it has to be an Attribute instance)'\n    );\n\n    var dataName = attribute.getDataName(Entity.adapterName);\n\n    expect(dataName).to.not.match(\n      /^\\$/,\n      'The dataName of an Attribute cannot start with \"$\" in a MongoAdapter'\n    );\n\n    expect(dataName).to.not.contain(\n      '.',\n      'The dataName of an Attribute cannot contain \".\" in a MongoAdapter'\n    );\n\n    expect(dataName).to.not.contain(\n      '\\0',\n      'The dataName of an Attribute cannot contain \"\\0\" in a MongoAdapter'\n    );\n\n    expect(dataName).to.not.equal(\n      'Entity',\n      'The dataName of an Attribute cannot be equal to \"Entity\" in a ' +\n      'MongoAdapter'\n    );\n\n    expect(dataName).to.not.equal(\n      '_id',\n      'The dataName of an Attribute cannot be equal to \"_id\" in a MongoAdapter'\n    );\n\n    expect(_collections).to.have.ownProperty(\n      Entity.dataName,\n      'Failed to load the attribute in an Entity called \"' +\n      Entity.specification.name + '\" because the Entity was not loaded yet'\n    );\n\n    expect(_collections[Entity.dataName]).to.not.contain(\n      dataName,\n      'Failed to load the attribute \"' + attribute.name + '\" in an Entity ' +\n      'called \"' + Entity.specification.name + '\" because it is not ' +\n      'possible to have attributes of the same Entity with duplicated ' +\n      'dataName in a MongoAdapter'\n    );\n\n    _collections[Entity.dataName].push(dataName);\n  }", "label": 3}
{"code": "public function setEntityKey($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\Key::class);\n        $this->entity_key = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function diffInMonths($date = null, $absolute = true)\n    {\n        $date = $this->resolveCarbon($date);\n\n        return $this->diffInYears($date, $absolute) * static::MONTHS_PER_YEAR + (int) $this->diff($date, $absolute)->format('%r%m');\n    }", "label": 2}
{"code": "public IndexDescriptorDef getIndexDescriptor(String name)\r\n    {\r\n        IndexDescriptorDef indexDef = null;\r\n\r\n        for (Iterator it = _indexDescriptors.iterator(); it.hasNext(); )\r\n        {\r\n            indexDef = (IndexDescriptorDef)it.next();\r\n            if (indexDef.getName().equals(name))\r\n            {\r\n                return indexDef;\r\n            }\r\n        }\r\n        return null;\r\n    }", "label": 0}
{"code": "def find_steam_location():\n  \"\"\"\n  Finds the location of the current Steam installation on Windows machines.\n  Returns None for any non-Windows machines, or for Windows machines where\n  Steam is not installed.\n  \"\"\"\n  if registry is None:\n    return None\n\n  key = registry.CreateKey(registry.HKEY_CURRENT_USER,\"Software\\Valve\\Steam\")\n  return registry.QueryValueEx(key,\"SteamPath\")[0]", "label": 1}
{"code": "public static base_responses apply(nitro_service client, nspbr6 resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tnspbr6 applyresources[] = new nspbr6[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tapplyresources[i] = new nspbr6();\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, applyresources,\"apply\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "protected function mergeEagerLoads($transformer, $requestedIncludes)\n    {\n        $includes = array_merge($requestedIncludes, $transformer->getDefaultIncludes());\n\n        $eagerLoads = [];\n\n        foreach ($includes as $key => $value) {\n            $eagerLoads[] = is_string($key) ? $key : $value;\n        }\n\n        if (property_exists($transformer, 'lazyLoadedIncludes')) {\n            $eagerLoads = array_diff($eagerLoads, $transformer->lazyLoadedIncludes);\n        }\n\n        return $eagerLoads;\n    }", "label": 2}
{"code": "def list_bank_accounts(location_id, opts = {})\n      data, _status_code, _headers = list_bank_accounts_with_http_info(location_id, opts)\n      return data\n    end", "label": 4}
{"code": "def change_counter_cache(obj, options)\n      change_counter_column = options.fetch(:counter_column) { counter_cache_name_for(obj) }\n\n      # default to the current foreign key value\n      id_to_change = foreign_key_value(obj, relation, options[:was])\n      # allow overwriting of foreign key value by the caller\n      id_to_change = foreign_key_values.call(id_to_change) if foreign_key_values\n\n      if id_to_change && change_counter_column\n        delta_magnitude = if delta_column\n                            (options[:was] ? attribute_was(obj, delta_column) : obj.public_send(delta_column)) || 0\n                          else\n                            counter_delta_magnitude_for(obj)\n                          end\n        # increment or decrement?\n        operator = options[:increment] ? '+' : '-'\n\n        # we don't use Rails' update_counters because we support changing the timestamp\n        quoted_column = model.connection.quote_column_name(change_counter_column)\n\n        updates = []\n        # this updates the actual counter\n        updates << \"#{quoted_column} = COALESCE(#{quoted_column}, 0) #{operator} #{delta_magnitude}\"\n        # and here we update the timestamp, if so desired\n        if touch\n          current_time = obj.send(:current_time_from_proper_timezone)\n          timestamp_columns = obj.send(:timestamp_attributes_for_update_in_model)\n          timestamp_columns << touch if touch != true\n          timestamp_columns.each do |timestamp_column|\n            updates << \"#{timestamp_column} = '#{current_time.to_formatted_s(:db)}'\"\n          end\n        end\n\n        klass = relation_klass(relation, source: obj, was: options[:was])\n        primary_key = relation_primary_key(relation, source: obj, was: options[:was])\n\n        if @with_papertrail\n          instance = klass.where(primary_key => id_to_change).first\n          if instance\n            if instance.paper_trail.respond_to?(:save_with_version)\n              # touch_with_version is deprecated starting in PaperTrail 9.0.0\n\n              current_time = obj.send(:current_time_from_proper_timezone)\n              timestamp_columns = obj.send(:timestamp_attributes_for_update_in_model)\n              timestamp_columns.each do |timestamp_column|\n                instance.send(\"#{timestamp_column}=\", current_time)\n              end\n\n              instance.paper_trail.save_with_version(validate: false)\n            else\n              instance.paper_trail.touch_with_version\n            end\n          end\n        end\n\n        klass.where(primary_key => id_to_change).update_all updates.join(', ')\n      end\n    end", "label": 4}
{"code": "public void forAllForeignkeys(String template, Properties attributes) throws XDocletException\r\n    {\r\n        for (Iterator it = _curTableDef.getForeignkeys(); it.hasNext(); )\r\n        {\r\n            _curForeignkeyDef = (ForeignkeyDef)it.next();\r\n            generate(template);\r\n        }\r\n        _curForeignkeyDef = null;\r\n    }", "label": 0}
{"code": "func (tc *TeleportClient) AskPassword() (pwd string, err error) {\n\tfmt.Printf(\"Enter password for Teleport user %v:\\n\", tc.Config.Username)\n\tpwd, err = passwordFromConsole()\n\tif err != nil {\n\t\tfmt.Fprintln(tc.Stderr, err)\n\t\treturn \"\", trace.Wrap(err)\n\t}\n\n\treturn pwd, nil\n}", "label": 5}
{"code": "def delete_emoji(emoji, reason: nil)\n      API::Server.delete_emoji(@bot.token, @id, emoji.resolve_id, reason)\n    end", "label": 4}
{"code": "def ssl_context\n        openssl_verify_mode = settings[:openssl_verify_mode]\n\n        if openssl_verify_mode.kind_of?(String)\n          openssl_verify_mode = OpenSSL::SSL.const_get(\"VERIFY_#{openssl_verify_mode.upcase}\")\n        end\n\n        context = Net::SMTP.default_ssl_context\n        context.verify_mode = openssl_verify_mode if openssl_verify_mode\n        context.ca_path = settings[:ca_path] if settings[:ca_path]\n        context.ca_file = settings[:ca_file] if settings[:ca_file]\n        context\n      end", "label": 4}
{"code": "function(sourceOrProgram, filename) {\n        \n        if (!(this instanceof MetaScript)) {\n            __version = Array.prototype.join.call(arguments, '.');\n            return;\n        }\n        \n        // Whether constructing from a meta program or, otherwise, a source\n        var isProgram = (sourceOrProgram+=\"\").substring(0, 11) === 'MetaScript(';\n        \n        /**\n         * Original source.\n         * @type {?string}\n         */\n        this.source = isProgram ? null : sourceOrProgram;\n\n        /**\n         * Original source file name.\n         * @type {string}\n         */\n        this.filename = filename || \"main\";\n\n        /**\n         * The compiled meta program's source.\n         * @type {string}\n         */\n        this.program = isProgram ? sourceOrProgram : MetaScript.compile(sourceOrProgram);\n    }", "label": 3}
{"code": "public function signedUrl($expires, array $options = [])\n    {\n        // May be overridden for testing.\n        $signingHelper = $this->pluck('helper', $options, false)\n            ?: SigningHelper::getHelper();\n\n        $resource = sprintf(\n            '/%s',\n            $this->identity['bucket']\n        );\n\n        return $signingHelper->sign(\n            $this->connection,\n            $expires,\n            $resource,\n            null,\n            $options\n        );\n    }", "label": 2}
{"code": "public static base_responses add(nitro_service client, iptunnel resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tiptunnel addresources[] = new iptunnel[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new iptunnel();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].remote = resources[i].remote;\n\t\t\t\taddresources[i].remotesubnetmask = resources[i].remotesubnetmask;\n\t\t\t\taddresources[i].local = resources[i].local;\n\t\t\t\taddresources[i].protocol = resources[i].protocol;\n\t\t\t\taddresources[i].ipsecprofilename = resources[i].ipsecprofilename;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func setupTapDevice(podID types.UUID) (netlink.Link, error) {\n\t// network device names are limited to 16 characters\n\t// the suffix %d will be replaced by the kernel with a suitable number\n\tnameTemplate := fmt.Sprintf(\"rkt-%s-tap%%d\", podID.String()[0:4])\n\tifName, err := tuntap.CreatePersistentIface(nameTemplate, tuntap.Tap)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"tuntap persist\"), err)\n\t}\n\n\tlink, err := netlink.LinkByName(ifName)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(fmt.Errorf(\"cannot find link %q\", ifName), err)\n\t}\n\n\tif err := netlink.LinkSetUp(link); err != nil {\n\t\treturn nil, errwrap.Wrap(fmt.Errorf(\"cannot set link up %q\", ifName), err)\n\t}\n\treturn link, nil\n}", "label": 5}
{"code": "def indent(value, n=2, character=' '):\n    \"\"\"\n    Indent a value by `n` `character`s\n\n    :param value: string to indent\n    :param n: number of characters to indent by\n    :param character: character to indent with\n    \"\"\"\n\n    prefix = n * character\n    return '\\n'.join(prefix + line for line in value.splitlines())", "label": 1}
{"code": "def can_group_commands(command, next_command):\n    \"\"\"\n    Returns a boolean representing whether these commands can be\n    grouped together or not.\n\n    A few things are taken into account for this decision:\n\n    For ``set`` commands:\n\n    - Are all arguments other than the key/value the same?\n\n    For ``delete`` and ``get`` commands:\n\n    - Are all arguments other than the key the same?\n    \"\"\"\n    multi_capable_commands = ('get', 'set', 'delete')\n\n    if next_command is None:\n        return False\n\n    name = command.get_name()\n\n    # TODO: support multi commands\n    if name not in multi_capable_commands:\n        return False\n\n    if name != next_command.get_name():\n        return False\n\n    # if the shared args (key, or key/value) do not match, we cannot group\n    if grouped_args_for_command(command) != grouped_args_for_command(next_command):\n        return False\n\n    # If the keyword arguments do not much (e.g. key_prefix, or timeout on set)\n    # then we cannot group\n    if command.get_kwargs() != next_command.get_kwargs():\n        return False\n\n    return True", "label": 1}
{"code": "def merge_config(config)\n      @config.deep_merge!(config)\n      complement\n\n      unless @config['epubversion'].nil?\n        case @config['epubversion'].to_i\n        when 2\n          @epub = EPUBMaker::EPUBv2.new(self)\n        when 3\n          @epub = EPUBMaker::EPUBv3.new(self)\n        else\n          raise \"Invalid EPUB version (#{@config['epubversion']}.)\"\n        end\n      end\n      if config['language']\n        ReVIEW::I18n.locale = config['language']\n      end\n      support_legacy_maker\n    end", "label": 4}
{"code": "public static base_response delete(nitro_service client) throws Exception {\n\t\tlocationfile deleteresource = new locationfile();\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def enhance_with_matching_rule(task_name, level=0)\n      fail Rake::RuleRecursionOverflowError,\n        \"Rule Recursion Too Deep\" if level >= 16\n      @rules.each do |pattern, args, extensions, block|\n        if pattern && pattern.match(task_name)\n          task = attempt_rule(task_name, pattern, args, extensions, block, level)\n          return task if task\n        end\n      end\n      nil\n    rescue Rake::RuleRecursionOverflowError => ex\n      ex.add_target(task_name)\n      fail ex\n    end", "label": 4}
{"code": "protected function tlsStreamInitializer(ParametersInterface $parameters)\n    {\n        $resource = $this->tcpStreamInitializer($parameters);\n        $metadata = stream_get_meta_data($resource);\n\n        // Detect if crypto mode is already enabled for this stream (PHP >= 7.0.0).\n        if (isset($metadata['crypto'])) {\n            return $resource;\n        }\n\n        if (is_array($parameters->ssl)) {\n            $options = $parameters->ssl;\n        } else {\n            $options = array();\n        }\n\n        if (!isset($options['crypto_type'])) {\n            $options['crypto_type'] = STREAM_CRYPTO_METHOD_TLS_CLIENT;\n        }\n\n        if (!stream_context_set_option($resource, array('ssl' => $options))) {\n            $this->onConnectionError('Error while setting SSL context options');\n        }\n\n        if (!stream_socket_enable_crypto($resource, true, $options['crypto_type'])) {\n            $this->onConnectionError('Error while switching to encrypted communication');\n        }\n\n        return $resource;\n    }", "label": 2}
{"code": "func (f *Fpdf) UseTemplate(t Template) {\n\tif t == nil {\n\t\tf.SetErrorf(\"template is nil\")\n\t\treturn\n\t}\n\tcorner, size := t.Size()\n\tf.UseTemplateScaled(t, corner, size)\n}", "label": 5}
{"code": "public function url($default = null): ?string\n    {\n        $disk = $this->getAttribute('disk');\n\n        if (Storage::disk($disk)->exists($this->physicalPath())) {\n            return Storage::disk($disk)->url($this->physicalPath());\n        }\n\n        return $default;\n    }", "label": 2}
{"code": "public function applyIniOverrides()\n    {\n        $overrides = config('lfm.php_ini_overrides');\n        if ($overrides && is_array($overrides) && count($overrides) === 0) {\n            return;\n        }\n\n        foreach ($overrides as $key => $value) {\n            if ($value && $value != 'false') {\n                ini_set($key, $value);\n            }\n        }\n    }", "label": 2}
{"code": "def image_fu(image, geometry = nil, options = {})\n      return nil if image.blank?\n\n      thumbnail_args = options.slice(:strip)\n      thumbnail_args[:geometry] = geometry if geometry\n\n      image_tag_args = (image.thumbnail_dimensions(geometry) rescue {})\n      image_tag_args[:alt] = image.respond_to?(:title) ? image.title : image.image_name\n\n      image_tag(image.thumbnail(thumbnail_args).url, image_tag_args.merge(options))\n    end", "label": 4}
{"code": "function (functionName, arguments) {\n                var self = this;\n                var args = self._getArgs(arguments);\n                var callback = self._getCallback(arguments);\n\n                return self._generic(functionName, args)\n                    .nodeify(callback);\n            }", "label": 3}
{"code": "def governor(self, Xgov, Pgov, Vgov):\n        \"\"\" Governor model.\n\n        Based on Governor.m from MatDyn by Stijn Cole, developed at Katholieke\n        Universiteit Leuven. See U{http://www.esat.kuleuven.be/electa/teaching/\n        matdyn/} for more information.\n        \"\"\"\n        governors = self.governors\n        omegas = 2 * pi * self.freq\n\n        F = zeros(Xgov.shape)\n\n        typ1 = [g.generator._i for g in governors if g.model == CONST_POWER]\n        typ2 = [g.generator._i for g in governors if g.model == GENERAL_IEEE]\n\n        # Governor type 1: constant power\n        F[typ1, 0] = 0\n\n        # Governor type 2: IEEE general speed-governing system\n        Pm = Xgov[typ2, 0]\n        P = Xgov[typ2, 1]\n        x = Xgov[typ2, 2]\n        z = Xgov[typ2, 3]\n\n        K = Pgov[typ2, 0]\n        T1 = Pgov[typ2, 1]\n        T2 = Pgov[typ2, 2]\n        T3 = Pgov[typ2, 3]\n        Pup = Pgov[typ2, 4]\n        Pdown = Pgov[typ2, 5]\n        Pmax = Pgov[typ2, 6]\n        Pmin = Pgov[typ2, 7]\n        P0 = Pgov[typ2, 8]\n\n        omega = Vgov[typ2, 0]\n\n        dx = K * (-1 / T1 * x + (1 - T2 / T1) * (omega - omegas))\n        dP = 1 / T1 * x + T2 / T1 * (omega - omegas)\n\n        y = 1 / T3 * (P0 - P - Pm)\n\n        y2 = y\n\n        if sum(flatnonzero(y > Pup)) >= 1:\n            y2 = (1 - flatnonzero(y > Pup)) * y2 + flatnonzero(y > Pup) * Pup\n        if sum(flatnonzero(y < Pdown)) >= 1:\n            y2 = (1 - flatnonzero(y<Pdown)) * y2 + flatnonzero(y<Pdown) * Pdown\n\n        dz = y2\n\n        dPm = y2\n\n        if sum(flatnonzero(z > Pmax)) >= 1:\n            dPm = (1 - flatnonzero(z > Pmax)) * dPm + flatnonzero(z > Pmax) * 0\n        if sum(flatnonzero(z < Pmin)) >= 1:\n            dPm = (1 - flatnonzero(z < Pmin)) * dPm + flatnonzero(z < Pmin) * 0\n\n        F[typ2, :] = c_[dPm, dP, dx, dz]\n\n        # Governor type 3:\n\n        # Governor type 4:\n\n        return F", "label": 1}
{"code": "func (f *Fpdf) BeginLayer(id int) {\n\tf.EndLayer()\n\tif id >= 0 && id < len(f.layer.list) {\n\t\tf.outf(\"/OC /OC%d BDC\", id)\n\t\tf.layer.currentLayer = id\n\t}\n}", "label": 5}
{"code": "def include?(str_or_rx)\n      option(text: str_or_rx).exist? || option(label: str_or_rx).exist?\n    end", "label": 4}
{"code": "function initComparator() {\n    by = 'rating'; // Default to sort by rating.\n    // If the sortBy cookie is set, use that instead.\n    if (document.cookie.length > 0) {\n      var start = document.cookie.indexOf('sortBy=');\n      if (start != -1) {\n        start = start + 7;\n        var end = document.cookie.indexOf(\";\", start);\n        if (end == -1) {\n          end = document.cookie.length;\n          by = unescape(document.cookie.substring(start, end));\n        }\n      }\n    }\n    setComparator();\n  }", "label": 3}
{"code": "def ot_find_tree(arg_dict, exact=True, verbose=False, oti_wrapper=None):\n    \"\"\"Uses a peyotl wrapper around an Open Tree web service to get a list of trees including values `value` for a given property to be searched on `porperty`.\n\n    The oti_wrapper can be None (in which case the default wrapper from peyotl.sugar will be used.\n    All other arguments correspond to the arguments of the web-service call.\n    \"\"\"\n    if oti_wrapper is None:\n        from peyotl.sugar import oti\n        oti_wrapper = oti\n    return oti_wrapper.find_trees(arg_dict,\n                                  exact=exact,\n                                  verbose=verbose,\n                                  wrap_response=True)", "label": 1}
{"code": "private void checkReferenceForeignkeys(ModelDef modelDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (CHECKLEVEL_NONE.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n\r\n        ClassDescriptorDef     classDef;\r\n        ReferenceDescriptorDef refDef;\r\n\r\n        for (Iterator it = modelDef.getClasses(); it.hasNext();)\r\n        {\r\n            classDef = (ClassDescriptorDef)it.next();\r\n            for (Iterator refIt = classDef.getReferences(); refIt.hasNext();)\r\n            {\r\n                refDef = (ReferenceDescriptorDef)refIt.next();\r\n                if (!refDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_IGNORE, false))\r\n                {\r\n                    checkReferenceForeignkeys(modelDef, refDef);\r\n                }\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public static String[] allUpperCase(String... strings){\n\t\tString[] tmp = new String[strings.length];\n\t\tfor(int idx=0;idx<strings.length;idx++){\n\t\t\tif(strings[idx] != null){\n\t\t\t\ttmp[idx] = strings[idx].toUpperCase();\n\t\t\t}\n\t\t}\n\t\treturn tmp;\n\t}", "label": 0}
{"code": "public static base_responses unset(nitro_service client, String trapname[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (trapname != null && trapname.length > 0) {\n\t\t\tsnmpalarm unsetresources[] = new snmpalarm[trapname.length];\n\t\t\tfor (int i=0;i<trapname.length;i++){\n\t\t\t\tunsetresources[i] = new snmpalarm();\n\t\t\t\tunsetresources[i].trapname = trapname[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (r *ReporterConfig) CheckAndSetDefaults() error {\n\tif r.Backend == nil {\n\t\treturn trace.BadParameter(\"missing parameter Backend\")\n\t}\n\tif r.Component == \"\" {\n\t\tr.Component = teleport.ComponentBackend\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public Response getTemplate(String id) throws RequestException, LocalOperationException {\n        Request request = new Request(this);\n        return new Response(request.get(\"/templates/\" + id));\n    }", "label": 0}
{"code": "def _check_or_set_default_params(self):\n        \"\"\"Check key and set default vaule when it does not exists.\"\"\"\n        if not hasattr(self, 'date'):\n            self._set_param('date', datetime.utcnow().strftime('%Y-%m-%d'))\n        if not hasattr(self, 'version'):\n            self._set_param('version', self.default_version)\n        # pylint: disable=no-member\n        if not hasattr(self, 'description') or self.description is None:\n            getattr(self, '_set_param')('description', self.warning_message)", "label": 1}
{"code": "public function jobs(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $job) {\n                    return new Job(\n                        $this->connection,\n                        $job['jobReference']['jobId'],\n                        $this->projectId,\n                        $this->mapper,\n                        $job\n                    );\n                },\n                [$this->connection, 'listJobs'],\n                $options + ['projectId' => $this->projectId],\n                [\n                    'itemsKey' => 'jobs',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "func (h *Handle) IsSet(ordinal uint64) bool {\n\tif err := h.validateOrdinal(ordinal); err != nil {\n\t\treturn false\n\t}\n\th.Lock()\n\t_, _, err := checkIfAvailable(h.head, ordinal)\n\th.Unlock()\n\treturn err != nil\n}", "label": 5}
{"code": "function (index, scaleId) {\n    scales.splice(index, 0, scale.create(chord.root, scaleId));\n  }", "label": 3}
{"code": "public static function copy_overwrite_files( $source, $dest ) {\n\t\t$iterator = new RecursiveIteratorIterator(\n\t\t\tnew RecursiveDirectoryIterator( $source, RecursiveDirectoryIterator::SKIP_DOTS ),\n\t\t\tRecursiveIteratorIterator::SELF_FIRST\n\t\t);\n\n\t\t$error = 0;\n\n\t\tif ( ! is_dir( $dest ) ) {\n\t\t\tmkdir( $dest, 0777, true );\n\t\t}\n\n\t\tforeach ( $iterator as $item ) {\n\n\t\t\t$dest_path = $dest . DIRECTORY_SEPARATOR . $iterator->getSubPathName();\n\n\t\t\tif ( $item->isDir() ) {\n\t\t\t\tif ( ! is_dir( $dest_path ) ) {\n\t\t\t\t\tmkdir( $dest_path );\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif ( file_exists( $dest_path ) && is_writable( $dest_path ) ) {\n\t\t\t\t\tcopy( $item, $dest_path );\n\t\t\t\t} elseif ( ! file_exists( $dest_path ) ) {\n\t\t\t\t\tcopy( $item, $dest_path );\n\t\t\t\t} else {\n\t\t\t\t\t$error = 1;\n\t\t\t\t\tWP_CLI::warning( \"Unable to copy '\" . $iterator->getSubPathName() . \"' to current directory.\" );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif ( $error ) {\n\t\t\tthrow new \\Exception( 'There was an error overwriting existing files.' );\n\t\t}\n\t}", "label": 2}
{"code": "def nontrivial_end_line\n      if (last_child = children.last)\n        last_child.line_numbers.end - 1\n      elsif successor\n        successor.line_numbers.begin - 1\n      else\n        @document.source_lines.count\n      end\n    end", "label": 4}
{"code": "function parseNode(attrNode, parsers, context) {\n    const attrNames = Object.keys(attrNode);\n    const errorContext = context.errorContext;\n\n    Object.keys(parsers).forEach(attrName => {\n        const parser = parsers[attrName];\n\n        context.errorContext = ` (option \"${attrName}\"${errorContext})`;\n        removeValue(attrNames, attrName);\n\n        if (attrName in attrNode && parser !== null) {\n            attrNode[attrName] = parser(attrNode[attrName], context);\n        }\n    });\n\n    context.errorContext = errorContext;\n\n    if (attrNames.length > 0) {\n        throw new ImplementationError(`Invalid option \"${attrNames.join(', ')}\"${context.errorContext}`);\n    }\n}", "label": 3}
{"code": "public IndirectionHandler createIndirectionHandler(PBKey brokerKey, Identity id)\r\n    {\r\n        Object args[] = {brokerKey, id};\r\n\r\n        try\r\n        {\r\n            return (IndirectionHandler) getIndirectionHandlerConstructor().newInstance(args);\r\n        }\r\n        catch(InvocationTargetException ex)\r\n        {\r\n            throw new PersistenceBrokerException(\"Exception while creating a new indirection handler instance\", ex);\r\n        }\r\n        catch(InstantiationException ex)\r\n        {\r\n            throw new PersistenceBrokerException(\"Exception while creating a new indirection handler instance\", ex);\r\n        }\r\n        catch(IllegalAccessException ex)\r\n        {\r\n            throw new PersistenceBrokerException(\"Exception while creating a new indirection handler instance\", ex);\r\n        }\r\n    }", "label": 0}
{"code": "func (r *DrvRegistry) RegisterDriver(ntype string, driver driverapi.Driver, capability driverapi.Capability) error {\n\tif strings.TrimSpace(ntype) == \"\" {\n\t\treturn errors.New(\"network type string cannot be empty\")\n\t}\n\n\tr.Lock()\n\tdd, ok := r.drivers[ntype]\n\tr.Unlock()\n\n\tif ok && dd.driver.IsBuiltIn() {\n\t\treturn driverapi.ErrActiveRegistration(ntype)\n\t}\n\n\tif r.dfn != nil {\n\t\tif err := r.dfn(ntype, driver, capability); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tdData := &driverData{driver, capability}\n\n\tr.Lock()\n\tr.drivers[ntype] = dData\n\tr.Unlock()\n\n\treturn nil\n}", "label": 5}
{"code": "def to_xml_string(str=\"\")\n      serialized_tag('dataBar', str) do\n        value_objects.to_xml_string(str)\n        self.color.to_xml_string(str)\n      end\n    end", "label": 4}
{"code": "func (s *sequence) getAvailableBit(from uint64) (uint64, uint64, error) {\n\tif s.block == blockMAX || s.count == 0 {\n\t\treturn invalidPos, invalidPos, ErrNoBitAvailable\n\t}\n\tbits := from\n\tbitSel := blockFirstBit >> from\n\tfor bitSel > 0 && s.block&bitSel != 0 {\n\t\tbitSel >>= 1\n\t\tbits++\n\t}\n\t// Check if the loop exited because it could not\n\t// find any available bit int block  starting from\n\t// \"from\". Return invalid pos in that case.\n\tif bitSel == 0 {\n\t\treturn invalidPos, invalidPos, ErrNoBitAvailable\n\t}\n\treturn bits / 8, bits % 8, nil\n}", "label": 5}
{"code": "func (s *handler) AttachedObjects(tag vim.VslmTagEntry) ([]vim.ManagedObjectReference, vim.BaseMethodFault) {\n\tt := s.findTag(tag)\n\tif t == nil {\n\t\treturn nil, new(vim.NotFound)\n\t}\n\tvar ids []vim.ManagedObjectReference\n\tfor id := range s.Association[t.ID] {\n\t\tids = append(ids, vim.ManagedObjectReference(id))\n\t}\n\treturn ids, nil\n}", "label": 5}
{"code": "def create_thread_and_abort_on_exception(*args)\n      Thread.new do\n        Thread.current.abort_on_exception = true\n        begin\n          yield(*args)\n        rescue SystemExit\n          raise\n        rescue Exception => e\n          print_exception(nil, e)\n          exit(1)\n        end\n      end\n    end", "label": 4}
{"code": "public function sendBroadcastLocation($targets, $long, $lat, $name = null, $url = null)\n    {\n        if (!is_array($targets)) {\n            $targets = [$targets];\n        }\n        // Return message ID. Make pull request for this.\n        return $this->sendMessageLocation($targets, $long, $lat, $name, $url);\n    }", "label": 2}
{"code": "func (u *UUID) decodeCanonical(t []byte) (err error) {\n\tif t[8] != '-' || t[13] != '-' || t[18] != '-' || t[23] != '-' {\n\t\treturn fmt.Errorf(\"uuid: incorrect UUID format %s\", t)\n\t}\n\n\tsrc := t[:]\n\tdst := u[:]\n\n\tfor i, byteGroup := range byteGroups {\n\t\tif i > 0 {\n\t\t\tsrc = src[1:] // skip dash\n\t\t}\n\t\t_, err = hex.Decode(dst[:byteGroup/2], src[:byteGroup])\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tsrc = src[byteGroup:]\n\t\tdst = dst[byteGroup/2:]\n\t}\n\n\treturn\n}", "label": 5}
{"code": "func (flag *HostConnectFlag) Fault(err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\n\tif f, ok := err.(types.HasFault); ok {\n\t\tswitch fault := f.Fault().(type) {\n\t\tcase *types.SSLVerifyFault:\n\t\t\treturn fmt.Errorf(\"%s thumbprint=%s\", err, fault.Thumbprint)\n\t\t}\n\t}\n\n\treturn err\n}", "label": 5}
{"code": "private function convertToGoogleException(\\Exception $ex)\n    {\n        switch ($ex->getCode()) {\n            case 400:\n                $exception = Exception\\BadRequestException::class;\n                break;\n\n            case 404:\n                $exception = Exception\\NotFoundException::class;\n                break;\n\n            case 409:\n                $exception = Exception\\ConflictException::class;\n                break;\n\n            case 412:\n                $exception = Exception\\FailedPreconditionException::class;\n                break;\n\n            case 500:\n                $exception = Exception\\ServerException::class;\n                break;\n\n            case 504:\n                $exception = Exception\\DeadlineExceededException::class;\n                break;\n\n            default:\n                $exception = Exception\\ServiceException::class;\n                break;\n        }\n\n        return new $exception($this->getExceptionMessage($ex), $ex->getCode(), $ex);\n    }", "label": 2}
{"code": "def get_bibtex(doi):\n    \"\"\"\n    Get a BibTeX entry for a given DOI.\n\n    .. note::\n\n        Adapted from https://gist.github.com/jrsmith3/5513926.\n\n    :param doi: The canonical DOI to get BibTeX from.\n    :returns: A BibTeX string or ``None``.\n\n    >>> get_bibtex('10.1209/0295-5075/111/40005')\n    '@article{Verney_2015,\\\\n\\\\tdoi = {10.1209/0295-5075/111/40005},\\\\n\\\\turl = {http://dx.doi.org/10.1209/0295-5075/111/40005},\\\\n\\\\tyear = 2015,\\\\n\\\\tmonth = {aug},\\\\n\\\\tpublisher = {{IOP} Publishing},\\\\n\\\\tvolume = {111},\\\\n\\\\tnumber = {4},\\\\n\\\\tpages = {40005},\\\\n\\\\tauthor = {Lucas Verney and Lev Pitaevskii and Sandro Stringari},\\\\n\\\\ttitle = {Hybridization of first and second sound in a weakly interacting Bose gas},\\\\n\\\\tjournal = {{EPL}}\\\\n}'\n    \"\"\"\n    try:\n        request = requests.get(to_url(doi),\n                               headers={\"accept\": \"application/x-bibtex\"})\n        request.raise_for_status()\n        assert request.headers.get(\"content-type\") == \"application/x-bibtex\"\n        return request.text\n    except (RequestException, AssertionError):\n        return None", "label": 1}
{"code": "function(ids, options) {\n            options = options || {};\n            options.idsToFetch = _.intersection(ids, this.getTrackedIds());\n            return this.fetch(options);\n          }", "label": 3}
{"code": "public function setAnnotationSpecId($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::STRING);\n        $this->annotation_spec_id = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def read_response(response_class, notification)\n      @logger.debug \"Waiting for response #{@correlation_id} from #{to_s}\"\n\n      data = @decoder.bytes\n      notification[:response_size] = data.bytesize\n\n      buffer = StringIO.new(data)\n      response_decoder = Kafka::Protocol::Decoder.new(buffer)\n\n      correlation_id = response_decoder.int32\n      response = response_class.decode(response_decoder)\n\n      @logger.debug \"Received response #{correlation_id} from #{to_s}\"\n\n      return correlation_id, response\n    rescue Errno::ETIMEDOUT\n      @logger.error \"Timed out while waiting for response #{@correlation_id}\"\n      raise\n    end", "label": 4}
{"code": "def run_on_client(requests,\n                      set_input_stream_done,\n                      set_output_stream_done,\n                      &blk)\n      @enq_th = Thread.new do\n        write_loop(requests, set_output_stream_done: set_output_stream_done)\n      end\n      read_loop(set_input_stream_done, &blk)\n    end", "label": 4}
{"code": "def _create_event(instance, action):\n    \"\"\"\n    Create a new event, getting the use if django-cuser is available.\n    \"\"\"\n    user = None\n    user_repr = repr(user)\n    if CUSER:\n        user = CuserMiddleware.get_user()\n        user_repr = repr(user)\n        if user is not None and user.is_anonymous:\n            user = None\n    return TrackingEvent.objects.create(\n        action=action,\n        object=instance,\n        object_repr=repr(instance),\n        user=user,\n        user_repr=user_repr,\n    )", "label": 1}
{"code": "def add_rule(rule)\n      if rule.is_a? Axlsx::ConditionalFormattingRule\n        @rules << rule\n      elsif rule.is_a? Hash\n        @rules << ConditionalFormattingRule.new(rule)\n      end\n    end", "label": 4}
{"code": "def handle_data(self, data):\n        \"\"\"Handles data between tags.\"\"\"\n        # Only proceed with unignored elements\n        if self.lasttag not in self.ignored_elements:\n            # Remove any predefined linebreaks\n            text = data.replace('\\n', '')\n            # If there's some text left, proceed!\n            if text:\n                if self.lasttag == 'li':\n                    # Use a special prefix for list elements\n                    self.text += '  * '\n                self.text += text\n                if self.lasttag in self.newline_after_elements:\n                    # Add a linebreak at the end of the content\n                    self.text += '\\n'", "label": 1}
{"code": "func (i *IPAMData) UnmarshalJSON(data []byte) error {\n\tvar (\n\t\tm   map[string]interface{}\n\t\terr error\n\t)\n\tif err := json.Unmarshal(data, &m); err != nil {\n\t\treturn err\n\t}\n\ti.AddressSpace = m[\"AddressSpace\"].(string)\n\tif v, ok := m[\"Pool\"]; ok {\n\t\tif i.Pool, err = types.ParseCIDR(v.(string)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif v, ok := m[\"Gateway\"]; ok {\n\t\tif i.Gateway, err = types.ParseCIDR(v.(string)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif v, ok := m[\"AuxAddresses\"]; ok {\n\t\tb, _ := json.Marshal(v)\n\t\tvar am map[string]string\n\t\tif err = json.Unmarshal(b, &am); err != nil {\n\t\t\treturn err\n\t\t}\n\t\ti.AuxAddresses = make(map[string]*net.IPNet, len(am))\n\t\tfor k, v := range am {\n\t\t\tif i.AuxAddresses[k], err = types.ParseCIDR(v); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function prune() {\n\t\tif ( ! $this->enabled ) {\n\t\t\treturn false;\n\t\t}\n\n\t\t/** @var Finder $finder */\n\t\t$finder = $this->get_finder()->sortByName();\n\n\t\t$files_to_delete = array();\n\n\t\tforeach ( $finder as $file ) {\n\t\t\t$pieces    = explode( '-', $file->getBasename( $file->getExtension() ) );\n\t\t\t$timestamp = end( $pieces );\n\n\t\t\t// No way to compare versions, do nothing.\n\t\t\tif ( ! is_numeric( $timestamp ) ) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t$basename_without_timestamp = str_replace( '-' . $timestamp, '', $file->getBasename() );\n\n\t\t\t// There's a file with an older timestamp, delete it.\n\t\t\tif ( isset( $files_to_delete[ $basename_without_timestamp ] ) ) {\n\t\t\t\tunlink( $files_to_delete[ $basename_without_timestamp ] );\n\t\t\t}\n\n\t\t\t$files_to_delete[ $basename_without_timestamp ] = $file->getRealPath();\n\t\t}\n\n\t\treturn true;\n\t}", "label": 2}
{"code": "function () {\n            var chart = charts[hoverChartIndex];\n            if (chart) {\n                chart.pointer.reset();\n                chart.pointer.chartPosition = null; // also reset the chart position, used in #149 fix\n            }\n        }", "label": 3}
{"code": "func AuthUserGroupsByGroupID(db XODB, groupID int) ([]*AuthUserGroup, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, user_id, group_id ` +\n\t\t`FROM django.auth_user_groups ` +\n\t\t`WHERE group_id = ?`\n\n\t// run query\n\tXOLog(sqlstr, groupID)\n\tq, err := db.Query(sqlstr, groupID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*AuthUserGroup{}\n\tfor q.Next() {\n\t\taug := AuthUserGroup{\n\t\t\t_exists: true,\n\t\t}\n\n\t\t// scan\n\t\terr = q.Scan(&aug.ID, &aug.UserID, &aug.GroupID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &aug)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "func (i *IPAMData) MarshalJSON() ([]byte, error) {\n\tm := map[string]interface{}{}\n\tm[\"AddressSpace\"] = i.AddressSpace\n\tif i.Pool != nil {\n\t\tm[\"Pool\"] = i.Pool.String()\n\t}\n\tif i.Gateway != nil {\n\t\tm[\"Gateway\"] = i.Gateway.String()\n\t}\n\tif i.AuxAddresses != nil {\n\t\tam := make(map[string]string, len(i.AuxAddresses))\n\t\tfor k, v := range i.AuxAddresses {\n\t\t\tam[k] = v.String()\n\t\t}\n\t\tm[\"AuxAddresses\"] = am\n\t}\n\treturn json.Marshal(m)\n}", "label": 5}
{"code": "function getFirmware (dataBuffer) {\n  const regexPattern = /v\\d.\\d*.\\d*/;\n  const ret = dataBuffer.toString().match(regexPattern);\n  if (ret) {\n    const elems = ret[0].split('.');\n    return {\n      major: Number(elems[0][1]),\n      minor: Number(elems[1]),\n      patch: Number(elems[2]),\n      raw: ret[0]\n    };\n  } else return ret;\n}", "label": 3}
{"code": "def run_matrix_in_parallel(self, process_data):\n        \"\"\"Running pipelines in parallel.\"\"\"\n        worker_data = [{'matrix': entry, 'pipeline': process_data.pipeline,\n                        'model': process_data.model, 'options': process_data.options,\n                        'hooks': process_data.hooks} for entry in self.matrix\n                       if Matrix.can_process_matrix(entry, process_data.options.matrix_tags)]\n        output = []\n        success = True\n        with closing(multiprocessing.Pool(multiprocessing.cpu_count())) as pool:\n            for result in pool.map(matrix_worker, worker_data):\n                output += result['output']\n                if not result['success']:\n                    success = False\n        return {'success': success, 'output': output}", "label": 1}
{"code": "def save(self):\n        \"\"\"\n        Write data to user config file.\n        \"\"\"\n        with open(self._user_config_file, 'w', encoding='utf-8') as f:\n            self.write(f)", "label": 1}
{"code": "def google_maps_geoloc_link(data):\n    \"\"\"\n    Get a link to google maps pointing on this IP's geolocation.\n\n    Args:\n        data (str/tuple): IP address or (latitude, longitude).\n\n    Returns:\n        str: a link to google maps pointing on this IP's geolocation.\n    \"\"\"\n    if isinstance(data, str):\n        lat_lon = ip_geoloc(data)\n        if lat_lon is None:\n            return ''\n        lat, lon = lat_lon\n    else:\n        lat, lon = data\n    loc = '%s,%s' % (lat, lon)\n    return 'https://www.google.com/maps/place/@%s,17z/' \\\n           'data=!3m1!4b1!4m5!3m4!1s0x0:0x0!8m2!3d%s!4d%s' % (\n            loc, lat, lon)", "label": 1}
{"code": "def encode_www_form(params)\n      if URI.respond_to?(:encode_www_form)\n        URI.encode_www_form(params)\n      else\n        params.map do |k, v|\n          k = CGI.escape(k.to_s)\n          v = CGI.escape(v.to_s)\n          \"#{k}=#{v}\"\n        end.join('&')\n      end\n    end", "label": 4}
{"code": "function() {\n\n                // If it\u2019s already stopped, do nothing.\n                if ( !STATE.start ) return P\n\n                // Then close the picker.\n                P.close()\n\n                // Remove the hidden field.\n                if ( P._hidden ) {\n                    P._hidden.parentNode.removeChild( P._hidden )\n                }\n\n                // Remove the root.\n                P.$root.remove()\n\n                // Remove the input class, remove the stored data, and unbind\n                // the events (after a tick for IE - see `P.close`).\n                $ELEMENT.removeClass( CLASSES.input ).removeData( NAME )\n                setTimeout( function() {\n                    $ELEMENT.off( '.' + STATE.id )\n                }, 0)\n\n                // Restore the element state\n                ELEMENT.type = STATE.type\n                ELEMENT.readOnly = false\n\n                // Trigger the queued \u201cstop\u201d events.\n                P.trigger( 'stop' )\n\n                // Reset the picker states.\n                STATE.methods = {}\n                STATE.start = false\n\n                return P\n            }", "label": 3}
{"code": "public static base_response update(nitro_service client, onlinkipv6prefix resource) throws Exception {\n\t\tonlinkipv6prefix updateresource = new onlinkipv6prefix();\n\t\tupdateresource.ipv6prefix = resource.ipv6prefix;\n\t\tupdateresource.onlinkprefix = resource.onlinkprefix;\n\t\tupdateresource.autonomusprefix = resource.autonomusprefix;\n\t\tupdateresource.depricateprefix = resource.depricateprefix;\n\t\tupdateresource.decrementprefixlifetimes = resource.decrementprefixlifetimes;\n\t\tupdateresource.prefixvalidelifetime = resource.prefixvalidelifetime;\n\t\tupdateresource.prefixpreferredlifetime = resource.prefixpreferredlifetime;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (t *Torrent) seeding() bool {\n\tcl := t.cl\n\tif t.closed.IsSet() {\n\t\treturn false\n\t}\n\tif cl.config.NoUpload {\n\t\treturn false\n\t}\n\tif !cl.config.Seed {\n\t\treturn false\n\t}\n\tif cl.config.DisableAggressiveUpload && t.needData() {\n\t\treturn false\n\t}\n\treturn true\n}", "label": 5}
{"code": "def find_consensus(bases):\n    \"\"\"\n    find consensus base based on nucleotide\n    frequencies\n    \"\"\"\n    nucs = ['A', 'T', 'G', 'C', 'N']\n    total = sum([bases[nuc] for nuc in nucs if nuc in bases])\n    # save most common base as consensus (random nuc if there is a tie)\n    try:\n        top = max([bases[nuc] for nuc in nucs if nuc in bases])\n    except:\n        bases['consensus'] = ('N', 'n/a')\n        bases['consensus frequency'] = 'n/a'\n        bases['reference frequency'] = 'n/a'\n        return bases\n    top = [(nuc, bases[nuc]) for nuc in bases if bases[nuc] == top]\n    if top[0][1] == 0:\n        bases['consensus'] = ('n/a', 0)\n    else:\n        bases['consensus'] = random.choice(top)\n    if total == 0:\n        c_freq = 'n/a'\n        ref_freq = 'n/a'\n    else:\n        c_freq = float(bases['consensus'][1]) / float(total)\n        if bases['ref'] not in bases:\n            ref_freq = 0\n        else:\n            ref_freq = float(bases[bases['ref']]) / float(total)\n    bases['consensus frequency'] = c_freq\n    bases['reference frequency'] = ref_freq\n    return bases", "label": 1}
{"code": "def uploadFileToIM (self, directory, filename, title):\n        \"\"\"\n        Parameters as they look in the form for uploading packages to IM\n        \"\"\"\n        self.logger.debug(\"uploadFileToIM(\" + \"{},{},{})\".format(directory, filename, title))\n        parameters = {'data-filename-placement':'inside',\n                      'title':str(filename),\n                      'filename':str(filename),\n                      'type':'file',\n                      'name':'files',\n                      'id':'fileToUpload',\n                      'multiple':''\n                      }\n        file_dict = {'files':(str(filename), open(directory + filename, 'rb'), 'application/x-rpm')}\n        m = MultipartEncoder(fields=file_dict)\n        \n        temp_username = self._username\n        temp_password = self._password\n        temp_im_api_url = self._im_api_url\n        temp_im_session = requests.Session()\n        temp_im_session.mount('https://', TLS1Adapter())\n        temp_im_verify_ssl = self._im_verify_ssl\n\n        resp = temp_im_session.post(\n            \"{}/{}\".format(temp_im_api_url,\"types/InstallationPackage/instances/uploadPackage\"),\n            auth=HTTPBasicAuth(temp_username, temp_password),\n            #headers = m.content_type,\n            files = file_dict,\n            verify = False,\n            data = parameters\n            )\n        self.logger.info(\"Uploaded: \" + \"{}\".format(filename))\n        self.logger.debug(\"HTTP Response: \" + \"{}\".format(resp.status_code))", "label": 1}
{"code": "protected function authorization()\n    {\n        $this->gate();\n\n        Telescope::auth(function ($request) {\n            return app()->environment('local') ||\n                   Gate::check('viewTelescope', [$request->user()]);\n        });\n    }", "label": 2}
{"code": "def color_mapping(sample_map, header, group_column, color_column=None):\n    \"\"\"\n    Determine color-category mapping. If color_column was specified, then map the category\n    names to color values. Otherwise, use the palettable colors to automatically generate\n    a set of colors for the group values.\n\n    :type sample_map: dict\n    :param unifracFN: Map associating each line of the mapping file with the appropriate\n                      sample ID (each value of the map also contains the sample ID)\n\n    :type header: tuple\n    :param A tuple of header line for mapping file\n\n    :type group_column: str\n    :param group_column: String denoting the column name for sample groups.\n\n    :type color_column: str\n    :param color_column: String denoting the column name for sample colors.\n\n    :type return: dict\n    :param return: {SampleID: Color}\n    \"\"\"\n    group_colors = OrderedDict()\n    group_gather = gather_categories(sample_map, header, [group_column])\n\n    if color_column is not None:\n        color_gather = gather_categories(sample_map, header, [color_column])\n        # match sample IDs between color_gather and group_gather\n        for group in group_gather:\n            for color in color_gather:\n                # allow incomplete assignment of colors, if group sids overlap at\n                # all with the color sids, consider it a match\n                if group_gather[group].sids.intersection(color_gather[color].sids):\n                    group_colors[group] = color\n    else:\n        bcolors = itertools.cycle(Set3_12.hex_colors)\n        for group in group_gather:\n            group_colors[group] = bcolors.next()\n\n    return group_colors", "label": 1}
{"code": "def link_to_add_association(*args, &block)\n      if block_given?\n        link_to_add_association(capture(&block), *args)\n      elsif args.first.respond_to?(:object)\n        association = args.second\n        name = I18n.translate(\"cocoon.#{association}.add\", default: I18n.translate('cocoon.defaults.add'))\n\n        link_to_add_association(name, *args)\n      else\n        name, f, association, html_options = *args\n        html_options ||= {}\n\n        render_options   = html_options.delete(:render_options)\n        render_options ||= {}\n        override_partial = html_options.delete(:partial)\n        wrap_object = html_options.delete(:wrap_object)\n        force_non_association_create = html_options.delete(:force_non_association_create) || false\n        form_parameter_name = html_options.delete(:form_name) || 'f'\n        count = html_options.delete(:count).to_i\n\n        html_options[:class] = [html_options[:class], \"add_fields\"].compact.join(' ')\n        html_options[:'data-association'] = association.to_s.singularize\n        html_options[:'data-associations'] = association.to_s.pluralize\n\n        new_object = create_object(f, association, force_non_association_create)\n        new_object = wrap_object.call(new_object) if wrap_object.respond_to?(:call)\n\n        html_options[:'data-association-insertion-template'] = CGI.escapeHTML(render_association(association, f, new_object, form_parameter_name, render_options, override_partial).to_str).html_safe\n\n        html_options[:'data-count'] = count if count > 0\n\n        link_to(name, '#', html_options)\n      end\n    end", "label": 4}
{"code": "private void updateDefaultTimeAndSizeRollingAppender(final FoundationFileRollingAppender appender) {\n\n\t\tif (appender.getDatePattern().trim().length() == 0) {\n\t\t\tappender.setDatePattern(FoundationLoggerConstants.DEFAULT_DATE_PATTERN.toString());\n\t\t}\n\t\t\n\t\tString maxFileSizeKey = \"log4j.appender.\"+appender.getName()+\".MaxFileSize\";\n\t\tappender.setMaxFileSize(FoundationLogger.log4jConfigProps.getProperty(maxFileSizeKey, FoundationLoggerConstants.Foundation_MAX_FILE_SIZE.toString()));\n\n//\t\tif (appender.getMaxFileSize() == null || appender.getMaxFileSize().equals(FoundationLoggerConstants.DEFAULT_FILE_SIZE.toString())) {\n//\t\t\tappender.setMaxFileSize(FoundationLoggerConstants.Foundation_MAX_FILE_SIZE.toString());\n//\t\t}\n\n\t\tString maxRollCountKey = \"log4j.appender.\"+appender.getName()+\".MaxRollFileCount\";\n\t\tappender.setMaxRollFileCount(Integer.parseInt(FoundationLogger.log4jConfigProps.getProperty(maxRollCountKey,\"100\")));\n\t}", "label": 0}
{"code": "private static function extract_subdir_path( $index_path ) {\n\t\t$index_code = file_get_contents( $index_path );\n\n\t\tif ( ! preg_match( '|^\\s*require\\s*\\(?\\s*(.+?)/wp-blog-header\\.php([\\'\"])|m', $index_code, $matches ) ) {\n\t\t\treturn false;\n\t\t}\n\n\t\t$wp_path_src = $matches[1] . $matches[2];\n\t\t$wp_path_src = Utils\\replace_path_consts( $wp_path_src, $index_path );\n\n\t\t$wp_path = eval( \"return $wp_path_src;\" ); // phpcs:ignore Squiz.PHP.Eval.Discouraged\n\n\t\tif ( ! Utils\\is_path_absolute( $wp_path ) ) {\n\t\t\t$wp_path = dirname( $index_path ) . \"/$wp_path\";\n\t\t}\n\n\t\treturn $wp_path;\n\t}", "label": 2}
{"code": "def decidim_form_slug_url(prepend_path = \"\", value = \"\")\n      prepend_slug_path = if prepend_path.present?\n                            \"/#{prepend_path}/\"\n                          else\n                            \"/\"\n                          end\n      content_tag(:span, class: \"slug-url\") do\n        [\n          request.protocol,\n          request.host_with_port,\n          prepend_slug_path\n        ].join(\"\").html_safe +\n          content_tag(:span, value, class: \"slug-url-value\")\n      end\n    end", "label": 4}
{"code": "public static String changeFirstLetterToCapital(String word) {\n        char[] letras = word.toCharArray();\n        char a = letras[0];\n        letras[0] = Character.toUpperCase(a);\n        return new String(letras);\n    }", "label": 0}
{"code": "def render_body(context, options)\n      if options.key?(:partial)\n        [render_partial(context, options)]\n      else\n        StreamingTemplateRenderer.new(@lookup_context).render(context, options)\n      end\n    end", "label": 4}
{"code": "private function validateNewRow(CellChunk $chunk)\n    {\n        $this->isError(\n            $this->row,\n            'A new row cannot have existing state.'\n        );\n        $this->isError(\n            !$chunk->getRowKey(),\n            'A row key must be set.'\n        );\n        $this->isError(\n            $chunk->getResetRow(),\n            'A new row cannot be reset.'\n        );\n        $this->isError(\n            $this->prevRowKey &&\n            $this->prevRowKey === $chunk->getRowKey(),\n            'A commit happened but the same key followed.'\n        );\n        $this->isError(!$chunk->getFamilyName(), 'A family must be set.');\n        $this->isError(!$chunk->getQualifier(), 'A column qualifier must be set.');\n        $this->validateValueSizeAndCommitRow($chunk);\n    }", "label": 2}
{"code": "def log_retry(e, options = nil)\n      message = if options && options[:message]\n        options[:message]\n      else\n        \"Retry\"\n      end\n      Logger.logger.warn \"#{message} due to: #{e.class.name} #{e.message}\"\n    end", "label": 4}
{"code": "public function setEncodingType($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1\\EncodingType::class);\n        $this->encoding_type = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function createResponse(array $result): Response\n    {\n        if (empty($this->deferred)) {\n            return response($result);\n        }\n\n        return response()->stream(\n            function () use ($result): void {\n                $nested = 1;\n                $this->result = $result;\n                $this->isStreaming = true;\n                $this->stream->stream($result, [], empty($this->deferred));\n\n                if ($executionTime = config('lighthouse.defer.max_execution_ms', 0)) {\n                    $this->maxExecutionTime = microtime(true) + ($executionTime * 1000);\n                }\n\n                // TODO: Allow nested_levels to be set in config\n                // to break out of loop early.\n                while (\n                    count($this->deferred)\n                    && ! $this->executionTimeExpired()\n                    && ! $this->maxNestedFieldsResolved($nested)\n                ) {\n                    $nested++;\n                    $this->executeDeferred();\n                }\n\n                // We've hit the max execution time or max nested levels of deferred fields.\n                // We process remaining deferred fields, but are no longer allowing additional\n                // fields to be deferred.\n                if (count($this->deferred)) {\n                    $this->acceptFurtherDeferring = false;\n                    $this->executeDeferred();\n                }\n            },\n            200,\n            [\n                // TODO: Allow headers to be set in config\n                'X-Accel-Buffering' => 'no',\n                'Content-Type' => 'multipart/mixed; boundary=\"-\"',\n            ]\n        );\n    }", "label": 2}
{"code": "func copyPod(pod *v1alpha.Pod) *v1alpha.Pod {\n\tp := &v1alpha.Pod{\n\t\tId:          pod.Id,\n\t\tManifest:    pod.Manifest,\n\t\tAnnotations: pod.Annotations,\n\t}\n\n\tfor _, app := range pod.Apps {\n\t\tp.Apps = append(p.Apps, &v1alpha.App{\n\t\t\tName:        app.Name,\n\t\t\tImage:       app.Image,\n\t\t\tAnnotations: app.Annotations,\n\t\t})\n\t}\n\treturn p\n}", "label": 5}
{"code": "def update(*args)\n      arguments(args, required: [:user, :repo, :number, :id])\n      params = arguments.params\n\n      params[\"accept\"] ||= PREVIEW_MEDIA\n\n      post_request(\"/repos/#{arguments.user}/#{arguments.repo}/pulls/#{arguments.number}/reviews/#{arguments.id}/events\", params)\n    end", "label": 4}
{"code": "def _interact(self, location, error_info, payload):\n        '''Gathers a macaroon by directing the user to interact with a\n        web page. The error_info argument holds the interaction-required\n        error response.\n        @return DischargeToken, bakery.Macaroon\n        '''\n        if (self._interaction_methods is None or\n                len(self._interaction_methods) == 0):\n            raise InteractionError('interaction required but not possible')\n        # TODO(rogpeppe) make the robust against a wider range of error info.\n        if error_info.info.interaction_methods is None and \\\n                error_info.info.visit_url is not None:\n            # It's an old-style error; deal with it differently.\n            return None, self._legacy_interact(location, error_info)\n        for interactor in self._interaction_methods:\n            found = error_info.info.interaction_methods.get(interactor.kind())\n            if found is None:\n                continue\n            try:\n                token = interactor.interact(self, location, error_info)\n            except InteractionMethodNotFound:\n                continue\n            if token is None:\n                raise InteractionError('interaction method returned an empty '\n                                       'token')\n            return token, None\n\n        raise InteractionError('no supported interaction method')", "label": 1}
{"code": "function () {\n                var\n                    url = this._linkUrl.join(\"\"),\n                    text = this._linkText.join(\"\");\n                if (0 === this._linkType) {\n                    this._output(\"<a href=\\\"\");\n                    this._output(url);\n                    this._output(\"\\\">\");\n                    this._output(text);\n                    this._output(\"</a>\");\n                } else if (1 ===  this._linkType) {\n                    this._output(\"<img src=\\\"\");\n                    this._output(url);\n                    this._output(\"\\\" alt=\\\"\");\n                    this._output(text);\n                    this._output(\"\\\" title=\\\"\");\n                    this._output(text);\n                    this._output(\"\\\">\");\n                }\n                return this._parseContent;\n            }", "label": 3}
{"code": "def attribute_missing?(name)\n      selection = __selected_fields\n      return false unless selection\n      field = fields[name]\n      (selection.values.first == 0 && selection_excluded?(name, selection, field)) ||\n        (selection.values.first == 1 && !selection_included?(name, selection, field))\n    end", "label": 4}
{"code": "def parse_haml_magic_comment(str)\n      scanner = StringScanner.new(str.dup.force_encoding(Encoding::ASCII_8BIT))\n      bom = scanner.scan(/\\xEF\\xBB\\xBF/n)\n      return bom unless scanner.scan(/-\\s*#\\s*/n)\n      if coding = try_parse_haml_emacs_magic_comment(scanner)\n        return bom, coding\n      end\n\n      return bom unless scanner.scan(/.*?coding[=:]\\s*([\\w-]+)/in)\n      return bom, scanner[1]\n    end", "label": 4}
{"code": "protected function addRelationColumn($key, $field, $column)\n    {\n        $relatedColumn = Str::snake(class_basename($field)) . '_id';\n\n        $method = 'integer';\n\n        return \"->{$method}('{$relatedColumn}')\";\n    }", "label": 2}
{"code": "def do_layout(payload, layouts)\n      self.output = _renderer.tap do |renderer|\n        renderer.layouts = layouts\n        renderer.payload = payload\n      end.run\n\n      Jekyll.logger.debug \"Post-Render Hooks:\", relative_path\n      Jekyll::Hooks.trigger hook_owner, :post_render, self\n    ensure\n      @_renderer = nil # this will allow the modifications above to disappear\n    end", "label": 4}
{"code": "function pushTypeResolution(target, propertyName) {\n            var resolutionCycleStartIndex = findResolutionCycleStartIndex(target, propertyName);\n            if (resolutionCycleStartIndex >= 0) {\n                // A cycle was found\n                var length_2 = resolutionTargets.length;\n                for (var i = resolutionCycleStartIndex; i < length_2; i++) {\n                    resolutionResults[i] = false;\n                }\n                return false;\n            }\n            resolutionTargets.push(target);\n            resolutionResults.push(/*items*/ true);\n            resolutionPropertyNames.push(propertyName);\n            return true;\n        }", "label": 3}
{"code": "function getMostRecentRefresh(formLastUpdated, dataLastUpdated) {\n  var formTimestamp = new Date(formLastUpdated).getTime();\n  var dataTimestamp = new Date(dataLastUpdated).getTime();\n\n  if (!dataLastUpdated) {\n    return formLastUpdated;\n  }\n\n  if (dataTimestamp > formTimestamp) {\n    return dataLastUpdated;\n  } else {\n    return formLastUpdated;\n  }\n}", "label": 3}
{"code": "def sign(params)\n      string = params_to_string(params)\n\n      case @sign_type\n      when 'RSA'\n        ::Alipay::Sign::RSA.sign(@app_private_key, string)\n      when 'RSA2'\n        ::Alipay::Sign::RSA2.sign(@app_private_key, string)\n      else\n        raise \"Unsupported sign_type: #{@sign_type}\"\n      end\n    end", "label": 4}
{"code": "def fair_max(x):\n    \"\"\" Takes a single iterable as an argument and returns the same output as\n    the built-in function max with two output parameters, except that where\n    the maximum value occurs at more than one position in the  vector, the\n    index is chosen randomly from these positions as opposed to just choosing\n    the first occurance.\n    \"\"\"\n    value = max(x)\n    # List indexes of max value.\n    i = [x.index(v) for v in x if v == value]\n    # Select index randomly among occurances.\n    idx = random.choice(i)\n\n    return idx, value", "label": 1}
{"code": "protected static boolean createLoggingAction(final Logger logger, final Logger auditor, final TransactionLogger instance) {\n    TransactionLogger oldInstance = getInstance();\n    if (oldInstance == null || oldInstance.finished) {\n      if(loggingKeys == null) {\n        synchronized (TransactionLogger.class) {\n          if (loggingKeys == null) {\n            logger.info(\"Initializing 'LoggingKeysHandler' class\");\n            loggingKeys = new LoggingKeysHandler(keysPropStream);\n          }\n        }\n      }\n      initInstance(instance, logger, auditor);\n      setInstance(instance);\n      return true;\n    }\n    return false; // Really not sure it can happen - since we arrive here in a new thread of transaction I think it's ThreadLocal should be empty. But leaving this code just in case...\n  }", "label": 0}
{"code": "function shuffle(v) {\n  for (var j, x, i = v.length; i; j = parseInt(Math.random() * i), x = v[--i], v[i] = v[j], v[j] = x);\n  return v;\n}", "label": 3}
{"code": "function(properties, value, equals)\n  {\n    var where = createWhere( properties, value, equals );\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var model = this[ i ];\n\n      if ( where( model ) )\n      {\n        return true;\n      }\n    }\n\n    return false;\n  }", "label": 3}
{"code": "func globGetMakeFunction(files []string, suffix string, mode globMode) string {\n\tdirs := map[string]struct{}{}\n\tfor _, file := range files {\n\t\tdirs[filepath.Dir(file)] = struct{}{}\n\t}\n\tmakeWildcards := make([]string, 0, len(dirs))\n\twildcard := globGetMakeSnippet(mode)\n\tfor dir := range dirs {\n\t\tstr := replacePlaceholders(wildcard, \"SUFFIX\", suffix, \"DIR\", dir)\n\t\tmakeWildcards = append(makeWildcards, str)\n\t}\n\treturn replacePlaceholders(globMakeFunction, \"WILDCARDS\", strings.Join(makeWildcards, \" \"))\n}", "label": 5}
{"code": "def stage_import_from_url(self, url, token=None, username=None, password=None, insecure=False):\n        \"\"\"Stage an import from a URL to another CDRouter system.\n\n        :param url: URL to import as string.\n        :param token: (optional) API token to use as string (may be required if importing from a CDRouter 10+ system).\n        :param username: (optional) API username to use as string (may be required if importing from a CDRouter 10+ system).\n        :param password: (optional) API password to use as string (may be required if importing from a CDRouter 10+ system).\n        :param insecure: (optional) Allow insecure HTTPS connections if bool `True`.\n        :return: :class:`imports.Import <imports.Import>` object\n        \"\"\"\n        schema = ImportSchema()\n        resp = self.service.post(self.base,\n                                 params={'url': url, 'token': token, 'username': username, 'password': password, 'insecure': insecure})\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "func (a *AuthServer) ValidateSAMLResponse(samlResponse string) (*SAMLAuthResponse, error) {\n\tre, err := a.validateSAMLResponse(samlResponse)\n\tif err != nil {\n\t\ta.EmitAuditEvent(events.UserSSOLoginFailure, events.EventFields{\n\t\t\tevents.LoginMethod:        events.LoginMethodSAML,\n\t\t\tevents.AuthAttemptSuccess: false,\n\t\t\tevents.AuthAttemptErr:     err.Error(),\n\t\t})\n\t} else {\n\t\ta.EmitAuditEvent(events.UserSSOLogin, events.EventFields{\n\t\t\tevents.EventUser:          re.Username,\n\t\t\tevents.AuthAttemptSuccess: true,\n\t\t\tevents.LoginMethod:        events.LoginMethodSAML,\n\t\t})\n\t}\n\treturn re, err\n}", "label": 5}
{"code": "func PgEnumValues(db XODB, schema string, enum string) ([]*EnumValue, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`e.enumlabel, ` + // ::varchar AS enum_value\n\t\t`e.enumsortorder ` + // ::integer AS const_value\n\t\t`FROM pg_type t ` +\n\t\t`JOIN ONLY pg_namespace n ON n.oid = t.typnamespace ` +\n\t\t`LEFT JOIN pg_enum e ON t.oid = e.enumtypid ` +\n\t\t`WHERE n.nspname = $1 AND t.typname = $2`\n\n\t// run query\n\tXOLog(sqlstr, schema, enum)\n\tq, err := db.Query(sqlstr, schema, enum)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*EnumValue{}\n\tfor q.Next() {\n\t\tev := EnumValue{}\n\n\t\t// scan\n\t\terr = q.Scan(&ev.EnumValue, &ev.ConstValue)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &ev)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "func (tl TypeLoader) LoadProcs(args *ArgType) (map[string]*Proc, error) {\n\tvar err error\n\n\t// not supplied, so bail\n\tif tl.ProcList == nil {\n\t\treturn nil, nil\n\t}\n\n\t// load procs\n\tprocList, err := tl.ProcList(args.DB, args.Schema)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// process procs\n\tprocMap := map[string]*Proc{}\n\tfor _, p := range procList {\n\t\t// fix the name if it starts with one or more underscores\n\t\tname := p.ProcName\n\t\tfor strings.HasPrefix(name, \"_\") {\n\t\t\tname = name[1:]\n\t\t}\n\n\t\t// create template\n\t\tprocTpl := &Proc{\n\t\t\tName:   snaker.SnakeToCamelIdentifier(name),\n\t\t\tSchema: args.Schema,\n\t\t\tParams: []*Field{},\n\t\t\tReturn: &Field{},\n\t\t\tProc:   p,\n\t\t}\n\n\t\t// parse return type into template\n\t\t// TODO: fix this so that nullable types can be returned\n\t\t_, procTpl.Return.NilType, procTpl.Return.Type = tl.ParseType(args, p.ReturnType, false)\n\n\t\t// load proc parameters\n\t\terr = tl.LoadProcParams(args, procTpl)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tprocMap[p.ProcName] = procTpl\n\t}\n\n\t// generate proc templates\n\tfor _, p := range procMap {\n\t\terr = args.ExecuteTemplate(ProcTemplate, \"sp_\"+p.Name, \"\", p)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn procMap, nil\n}", "label": 5}
{"code": "def _registerHandler(self, handler):\n        \"\"\"\n        Registers a handler.\n\n        :param handler:  A handler object.\n        \"\"\"\n        self._logger.addHandler(handler)\n        self._handlers.append(handler)", "label": 1}
{"code": "protected function setModels($models): self\n    {\n        // We can not use the collect() helper here, since we require this\n        // to be an Eloquent Collection\n        $this->models = $models instanceof EloquentCollection\n            ? $models\n            : new EloquentCollection($models);\n\n        return $this;\n    }", "label": 2}
{"code": "def assign_pages!\n      payload[\"page\"] = document.to_liquid\n      payload[\"paginator\"] = (document.pager.to_liquid if document.respond_to?(:pager))\n    end", "label": 4}
{"code": "function init(type) {\n\n    return function(params) {\n        if (!params) {\n            params = {};\n        }\n\n        var settings = {\n            proxyUrl: params.proxyUrl || defaults.proxyUrl,\n            channel: params.channel || defaults.channel,\n            keepalive: parseFalsey(params.keepalive, defaults.keepalive),\n            port: params.port || defaults.port,\n            log: params.log || defaults.log,\n            tcp: parseFalsey(params.tcp, defaults.tcp),\n            udp4: parseFalsey(params.udp4, defaults.udp4),\n            socketio: parseFalsey(params.socketio, defaults.socketio),\n            onlyOneControllerPerChannel: parseFalsey(params.onlyOneControllerPerChannel, defaults.onlyOneControllerPerChannel),\n            onlyOneToyPerChannel: parseFalsey(params.onlyOneToyPerChannel, defaults.onlyOneToyPerChannel),\n            allowObservers: parseFalsey(params.allowObservers, defaults.allowObservers),\n            deviceType: type\n        };\n\n        if (typeof params.log !== 'function') {\n            params.log = defaults.log;\n        }\n\n        switch (type) {\n\n            case 'proxy':\n                if (isBrowser()) {\n                    console.error('Cannot create proxy in browser');\n                }\n                var Proxy = require('./src/Proxy');\n                return new Proxy(settings);\n\n            case 'toy':\n            case 'controller':\n            case 'observer':\n                var connectionModule;\n                if (isBrowser()) {\n                    connectionModule = require('./src/WebClientConnection');\n                    settings.udp4 = false;\n                    settings.tcp = false;\n                    settings.socketio = true;\n                } else {\n                    connectionModule = require('./src/ClientConnection');\n                    settings.socketio = false;\n                }\n                var Device = require('./src/Device');\n                return new Device(settings, connectionModule);\n\n            default:\n                throw new Error('Could not determine server type.');\n        }\n\n    };\n}", "label": 3}
{"code": "function getGlob() {\n\t\t\tif (isNode) {\n\t\t\t\treturn loader.import(\"@node-require\", { name: module.id })\n\t\t\t\t\t.then(function(nodeRequire) {\n\t\t\t\t\t\treturn nodeRequire(\"glob\");\n\t\t\t\t\t});\n\t\t\t}\n\n\t\t\treturn Promise.resolve();\n\t\t}", "label": 3}
{"code": "def to_xml_string(str = '')\n      super(str) do\n        str << '<c:pie3DChart>'\n        str << ('<c:varyColors val=\"' << vary_colors.to_s << '\"/>')\n        @series.each { |ser| ser.to_xml_string(str) }\n        d_lbls.to_xml_string(str) if @d_lbls\n        str << '</c:pie3DChart>'\n      end\n    end", "label": 4}
{"code": "def delete_by_digest(digest)\n      result, elapsed = timed do\n        Scripts.call(:delete_by_digest, nil, keys: [UNIQUE_SET, digest])\n        count\n      end\n\n      log_info(\"#{__method__}(#{digest}) completed in #{elapsed}ms\")\n\n      result\n    end", "label": 4}
{"code": "public void refresh(String[] configLocations) throws GeomajasException {\n\t\ttry {\n\t\t\tsetConfigLocations(configLocations);\n\t\t\trefresh();\n\t\t} catch (Exception e) {\n\t\t\tthrow new GeomajasException(e, ExceptionCode.REFRESH_CONFIGURATION_FAILED);\n\t\t}\n\t}", "label": 0}
{"code": "public function setByteItem($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\ByteContentItem::class);\n        $this->byte_item = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (m *ProcessManager) Open(u *url.URL, mode int32) (hgfs.File, error) {\n\tinfo, err := m.Stat(u)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tpinfo, ok := info.(*ProcessFile)\n\n\tif !ok {\n\t\treturn nil, os.ErrNotExist // fall through to default os.Open\n\t}\n\n\tswitch path.Base(u.Path) {\n\tcase \"stdin\":\n\t\tif mode != hgfs.OpenModeWriteOnly {\n\t\t\treturn nil, vix.Error(vix.InvalidArg)\n\t\t}\n\tcase \"stdout\", \"stderr\":\n\t\tif mode != hgfs.OpenModeReadOnly {\n\t\t\treturn nil, vix.Error(vix.InvalidArg)\n\t\t}\n\t}\n\n\treturn pinfo, nil\n}", "label": 5}
{"code": "public static tmglobal_binding get(nitro_service service) throws Exception{\n\t\ttmglobal_binding obj = new tmglobal_binding();\n\t\ttmglobal_binding response = (tmglobal_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "protected function unixStreamInitializer(ParametersInterface $parameters)\n    {\n        if (!isset($parameters->path)) {\n            throw new \\InvalidArgumentException('Missing UNIX domain socket path.');\n        }\n\n        $flags = STREAM_CLIENT_CONNECT;\n\n        if (isset($parameters->persistent)) {\n            if (false !== $persistent = filter_var($parameters->persistent, FILTER_VALIDATE_BOOLEAN, FILTER_NULL_ON_FAILURE)) {\n                $flags |= STREAM_CLIENT_PERSISTENT;\n\n                if ($persistent === null) {\n                    throw new \\InvalidArgumentException(\n                        'Persistent connection IDs are not supported when using UNIX domain sockets.'\n                    );\n                }\n            }\n        }\n\n        $resource = $this->createStreamSocket($parameters, \"unix://{$parameters->path}\", $flags);\n\n        return $resource;\n    }", "label": 2}
{"code": "public static sslcipher_individualcipher_binding[] get(nitro_service service, String ciphergroupname) throws Exception{\n\t\tsslcipher_individualcipher_binding obj = new sslcipher_individualcipher_binding();\n\t\tobj.set_ciphergroupname(ciphergroupname);\n\t\tsslcipher_individualcipher_binding response[] = (sslcipher_individualcipher_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (l *Handler) Download(ctx context.Context, sessionID session.ID, writer io.WriterAt) error {\n\twritten, err := l.downloader.DownloadWithContext(ctx, writer, &s3.GetObjectInput{\n\t\tBucket: aws.String(l.Bucket),\n\t\tKey:    aws.String(l.path(sessionID)),\n\t})\n\tif err != nil {\n\t\treturn ConvertS3Error(err)\n\t}\n\tif written == 0 {\n\t\treturn trace.NotFound(\"recording for %v is not found\", sessionID)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public final void fatal(Object pObject)\r\n\t{\r\n\t\tgetLogger().log(FQCN, Level.FATAL, pObject, null);\r\n\t}", "label": 0}
{"code": "func uniqueBarcodeName(code string, x, y float64) string {\n\txStr := strconv.FormatFloat(x, 'E', -1, 64)\n\tyStr := strconv.FormatFloat(y, 'E', -1, 64)\n\n\treturn \"barcode-\" + code + \"-\" + xStr + yStr\n}", "label": 5}
{"code": "public static base_responses unset(nitro_service client, rnat resources[],  String[] args) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\trnat unsetresources[] = new rnat[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tunsetresources[i] = new rnat();\n\t\t\t\tunsetresources[i].network = resources[i].network;\n\t\t\t\tunsetresources[i].netmask = resources[i].netmask;\n\t\t\t\tunsetresources[i].td = resources[i].td;\n\t\t\t\tunsetresources[i].aclname = resources[i].aclname;\n\t\t\t\tunsetresources[i].redirectport = resources[i].redirectport;\n\t\t\t\tunsetresources[i].natip = resources[i].natip;\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static base_response add(nitro_service client, nspbr resource) throws Exception {\n\t\tnspbr addresource = new nspbr();\n\t\taddresource.name = resource.name;\n\t\taddresource.action = resource.action;\n\t\taddresource.td = resource.td;\n\t\taddresource.srcip = resource.srcip;\n\t\taddresource.srcipop = resource.srcipop;\n\t\taddresource.srcipval = resource.srcipval;\n\t\taddresource.srcport = resource.srcport;\n\t\taddresource.srcportop = resource.srcportop;\n\t\taddresource.srcportval = resource.srcportval;\n\t\taddresource.destip = resource.destip;\n\t\taddresource.destipop = resource.destipop;\n\t\taddresource.destipval = resource.destipval;\n\t\taddresource.destport = resource.destport;\n\t\taddresource.destportop = resource.destportop;\n\t\taddresource.destportval = resource.destportval;\n\t\taddresource.nexthop = resource.nexthop;\n\t\taddresource.nexthopval = resource.nexthopval;\n\t\taddresource.iptunnel = resource.iptunnel;\n\t\taddresource.iptunnelname = resource.iptunnelname;\n\t\taddresource.srcmac = resource.srcmac;\n\t\taddresource.protocol = resource.protocol;\n\t\taddresource.protocolnumber = resource.protocolnumber;\n\t\taddresource.vlan = resource.vlan;\n\t\taddresource.Interface = resource.Interface;\n\t\taddresource.priority = resource.priority;\n\t\taddresource.msr = resource.msr;\n\t\taddresource.monitor = resource.monitor;\n\t\taddresource.state = resource.state;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def run_bwa(job, fastqs, sample_type, univ_options, bwa_options):\n    \"\"\"\n    This module aligns the SAMPLE_TYPE dna fastqs to the reference\n\n    ARGUMENTS -- <ST> depicts the sample type. Substitute with 'tumor'/'normal'\n    1. fastqs: Dict of list of input WGS/WXS fastqs\n         fastqs\n              +- '<ST>_dna': [<JSid for 1.fastq> , <JSid for 2.fastq>]\n    2. sample_type: string of 'tumor_dna' or 'normal_dna'\n    3. univ_options: Dict of universal arguments used by almost all tools\n         univ_options\n                +- 'dockerhub': <dockerhub to use>\n    4. bwa_options: Dict of parameters specific to bwa\n         bwa_options\n              |- 'index_tar': <JSid for the bwa index tarball>\n              +- 'n': <number of threads to allocate>\n\n    RETURN VALUES\n    1. output_files: Dict of aligned bam + reference (nested return)\n         output_files\n             |- '<ST>_fix_pg_sorted.bam': <JSid>\n             +- '<ST>_fix_pg_sorted.bam.bai': <JSid>\n\n    This module corresponds to nodes 3 and 4 on the tree\n    \"\"\"\n    job.fileStore.logToMaster('Running bwa on %s:%s' % (univ_options['patient'], sample_type))\n    work_dir = job.fileStore.getLocalTempDir()\n    fq_extn = '.gz' if fastqs['gzipped'] else ''\n    input_files = {\n        'dna_1.fastq' + fq_extn: fastqs[sample_type][0],\n        'dna_2.fastq' + fq_extn: fastqs[sample_type][1],\n        'bwa_index.tar.gz': bwa_options['index_tar']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    parameters = ['mem',\n                  '-t', str(bwa_options['n']),\n                  '-v', '1',  # Don't print INFO messages to the stderr\n                  '/'.join([input_files['bwa_index'], 'hg19.fa']),\n                  input_files['dna_1.fastq'],\n                  input_files['dna_2.fastq']]\n    with open(''.join([work_dir, '/', sample_type, '_aligned.sam']), 'w') as samfile:\n        docker_call(tool='bwa', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=samfile)\n    # samfile.name retains the path info\n    output_file = job.fileStore.writeGlobalFile(samfile.name)\n    samfile_processing = job.wrapJobFn(bam_conversion, output_file, sample_type, univ_options,\n                                       disk='60G')\n    job.addChild(samfile_processing)\n    # Return values get passed up the chain to here.  The return value will be a dict with\n    # SAMPLE_TYPE_fix_pg_sorted.bam: jobStoreID\n    # SAMPLE_TYPE_fix_pg_sorted.bam.bai: jobStoreID\n    return samfile_processing.rv()", "label": 1}
{"code": "def show_message(self):\n        \"\"\"Show message updatable.\"\"\"\n        print(\n            'current version: {current_version}\\n'\n            'latest version : {latest_version}'.format(\n                current_version=self.current_version,\n                latest_version=self.latest_version))", "label": 1}
{"code": "public Object get(Object key)\r\n    {\r\n        purge();\r\n        Entry entry = getEntry(key);\r\n        if (entry == null) return null;\r\n        return entry.getValue();\r\n    }", "label": 0}
{"code": "def secondary_characterization_values(term)\n      values = values_for(term)\n      additional_values = values.slice(Hyrax.config.fits_message_length, values.length - Hyrax.config.fits_message_length)\n      return [] unless additional_values\n      truncate_all(additional_values)\n    end", "label": 4}
{"code": "def count_files(admin_sets)\n        file_counts = Hash.new(0)\n        admin_sets.each do |admin_set|\n          query = \"{!join from=file_set_ids_ssim to=id}isPartOf_ssim:#{admin_set.id}\"\n          file_results = ActiveFedora::SolrService.instance.conn.get(\n            ActiveFedora::SolrService.select_path,\n            params: { fq: [query, \"has_model_ssim:FileSet\"],\n                      rows: 0 }\n          )\n          file_counts[admin_set.id] = file_results['response']['numFound']\n        end\n        file_counts\n      end", "label": 4}
{"code": "private static LogPriorType intToType(int intPrior) {\r\n    LogPriorType[] values = LogPriorType.values();\r\n    for (LogPriorType val : values) {\r\n      if (val.ordinal() == intPrior) {\r\n        return val;\r\n      }\r\n    }\r\n    throw new IllegalArgumentException(intPrior + \" is not a legal LogPrior.\");\r\n  }", "label": 0}
{"code": "func (cl *Client) newTorrent(ih metainfo.Hash, specStorage storage.ClientImpl) (t *Torrent) {\n\t// use provided storage, if provided\n\tstorageClient := cl.defaultStorage\n\tif specStorage != nil {\n\t\tstorageClient = storage.NewClient(specStorage)\n\t}\n\n\tt = &Torrent{\n\t\tcl:       cl,\n\t\tinfoHash: ih,\n\t\tpeers: prioritizedPeers{\n\t\t\tom: btree.New(32),\n\t\t\tgetPrio: func(p Peer) peerPriority {\n\t\t\t\treturn bep40PriorityIgnoreError(cl.publicAddr(p.IP), p.addr())\n\t\t\t},\n\t\t},\n\t\tconns: make(map[*connection]struct{}, 2*cl.config.EstablishedConnsPerTorrent),\n\n\t\thalfOpen:          make(map[string]Peer),\n\t\tpieceStateChanges: pubsub.NewPubSub(),\n\n\t\tstorageOpener:       storageClient,\n\t\tmaxEstablishedConns: cl.config.EstablishedConnsPerTorrent,\n\n\t\tnetworkingEnabled: true,\n\t\trequestStrategy:   2,\n\t\tmetadataChanged: sync.Cond{\n\t\t\tL: cl.locker(),\n\t\t},\n\t\tduplicateRequestTimeout: 1 * time.Second,\n\t}\n\tt.logger = cl.logger.Clone().AddValue(t)\n\tt.setChunkSize(defaultChunkSize)\n\treturn\n}", "label": 5}
{"code": "def lookup(self, lookup_url, url_key=None):\n        \"\"\"\n        Looks up the url_ending to obtain information about the short url.\n\n        If it exists, the API will return a dictionary with information, including\n        the long_url that is the destination of the given short url URL.\n\n\n        The lookup object looks like something like this:\n\n        .. code-block:: python\n\n            {\n                'clicks': 42,\n                'created_at':\n                    {\n                        'date': '2017-12-03 00:40:45.000000',\n                        'timezone': 'UTC',\n                        'timezone_type': 3\n                    },\n                'long_url': 'https://stackoverflow.com/questions/tagged/python',\n                'updated_at':\n                    {\n                        'date': '2017-12-24 13:37:00.000000',\n                        'timezone': 'UTC',\n                        'timezone_type': 3\n                    }\n            }\n\n        :param str lookup_url: An url ending or full short url address\n        :param url_key: optional URL ending key for lookups against secret URLs\n        :type url_key: str or None\n        :return: Lookup dictionary containing, among others things, the long url; or None if not existing\n        :rtype: dict or None\n        \"\"\"\n        url_ending = self._get_ending(lookup_url)\n        params = {\n            'url_ending': url_ending,\n            'url_key': url_key\n        }\n        data, r = self._make_request(self.api_lookup_endpoint, params)\n        if r.status_code == 401:\n            if url_key is not None:\n                raise exceptions.UnauthorizedKeyError('given url_key is not valid for secret lookup.')\n            raise exceptions.UnauthorizedKeyError\n        elif r.status_code == 404:\n            return False  # no url found in lookup\n        action = data.get('action')\n        full_url = data.get('result')\n        if action == 'lookup' and full_url is not None:\n            return full_url\n        raise exceptions.DebugTempWarning", "label": 1}
{"code": "def update_photo\n      content_tag = params[:content_tag]\n      # photo = ContentPhoto.find(params[:id])\n      # find would throw error if not found\n      photo = ContentPhoto.find_by_id(params[:id])\n      unless photo\n        if content_tag\n          # where photo has never been set before, associated Content will not exist\n          content = Content.find_by_key(content_tag) || Content.create({ key: content_tag, tag: 'appearance' })\n          photo = ContentPhoto.create\n          if content_tag == \"logo\"\n            # TODO: This is a workaround\n            # need to have a way of determining content that should only have\n            # one photo and enforcing that\n            content.content_photos.destroy_all\n          end\n          content.content_photos.push photo\n        end\n        # TODO: - handle where no photo or content_tag..\n      end\n      if params[:file]\n        photo.image = params[:file]\n      end\n      photo.save!\n      photo.reload\n      render json: photo.to_json\n    end", "label": 4}
{"code": "func NewHandler(cfg Config) (*Handler, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\th := &Handler{\n\t\tEntry: log.WithFields(log.Fields{\n\t\t\ttrace.Component: teleport.Component(teleport.SchemeFile),\n\t\t}),\n\t\tConfig: cfg,\n\t}\n\treturn h, nil\n}", "label": 5}
{"code": "def isValidUnit(self, w):\n        \"\"\"Checks if a string represents a valid quantities unit.\n\n        Args:\n            w (str): A string to be tested against the set of valid\n                quantities units.\n\n        Returns:\n            True if the string can be used as a unit in the quantities\n            module.\n        \"\"\"\n        bad = set(['point', 'a'])\n        if w in bad:\n            return False\n\n        try:\n            pq.Quantity(0.0, w)\n            return True\n        except:\n            return w == '/'", "label": 1}
{"code": "def BLASTcheck(rid,baseURL=\"http://blast.ncbi.nlm.nih.gov\"):\n    \"\"\"\n    Checks the status of a query.\n\n    :param rid: BLAST search request identifier. Allowed values: The Request ID (RID) returned when the search was submitted\n    :param baseURL: server url. Default=http://blast.ncbi.nlm.nih.gov\n\n    :returns status: status for the query.\n    :returns therearehist: yes or no for existing hits on a finished query.\n    \"\"\"\n\n    URL=baseURL+\"/Blast.cgi?\"\n    URL=URL+\"FORMAT_OBJECT=SearchInfo&RID=\"+rid+\"&CMD=Get\"\n    response=requests.get(url = URL)\n    r=response.content.split(\"\\n\")\n    try:\n        status=[ s for s in r if \"Status=\" in s ][0].split(\"=\")[-1]\n        ThereAreHits=[ s for s in r if \"ThereAreHits=\" in s ][0].split(\"=\")[-1]\n    except:\n        status=None\n        ThereAreHits=None\n\n    print(rid, status, ThereAreHits)\n    sys.stdout.flush()\n\n    return status, ThereAreHits", "label": 1}
{"code": "public function VerifyNotificationChannel(\\Google\\Cloud\\Monitoring\\V3\\VerifyNotificationChannelRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.monitoring.v3.NotificationChannelService/VerifyNotificationChannel',\n        $argument,\n        ['\\Google\\Cloud\\Monitoring\\V3\\NotificationChannel', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "public void setModel(Database databaseModel, DescriptorRepository objModel)\r\n    {\r\n        _dbModel       = databaseModel;\r\n        _preparedModel = new PreparedModel(objModel, databaseModel);\r\n    }", "label": 0}
{"code": "def make_copy\n      obj = self.dup\n      obj.local_options = Marshal.load(Marshal.dump(local_options))\n      obj.hooks         = @hooks\n\n      obj\n    end", "label": 4}
{"code": "def method_missing(m, *args, &block)\n      if m.to_s.end_with?('=')\n        raise ArgumentError.new(\"wrong number of arguments (#{args.size} for 1 with #{m}) to method #{m}\") if args.nil? or 1 != args.length\n        m = m[0..-2]\n        return store(m.to_s, args[0]) if has_key?(m.to_s)\n        return store(m.to_sym, args[0]) if has_key?(m.to_sym)\n        return store(m, args[0])\n      else\n        raise ArgumentError.new(\"wrong number of arguments (#{args.size} for 0 with #{m}) to method #{m}\") unless args.nil? or args.empty?\n        return fetch(m, nil) if has_key?(m)\n        return fetch(m.to_s, nil) if has_key?(m.to_s)\n        return fetch(m.to_sym, nil) if has_key?(m.to_sym)\n      end\n      raise NoMethodError.new(\"undefined method #{m}\", m)\n    end", "label": 4}
{"code": "def decidim_form_for(record, options = {}, &block)\n      options[:data] ||= {}\n      options[:data].update(abide: true, \"live-validate\" => true, \"validate-on-blur\" => true)\n\n      options[:html] ||= {}\n      options[:html].update(novalidate: true)\n\n      output = \"\"\n      output += base_error_messages(record).to_s\n      output += form_for(record, options, &block).to_s\n\n      output.html_safe\n    end", "label": 4}
{"code": "func (f *fileFetcher) getVerifiedFile(aciPath string, a *asc) (*os.File, error) {\n\tvar aciFile *os.File // closed on error\n\tvar errClose error   // error signaling to close aciFile\n\n\tf.maybeOverrideAsc(aciPath, a)\n\tascFile, err := a.Get()\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"error opening signature file\"), err)\n\t}\n\tdefer ascFile.Close()\n\n\taciFile, err = os.Open(aciPath)\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"error opening ACI file\"), err)\n\t}\n\n\tdefer func() {\n\t\tif errClose != nil {\n\t\t\taciFile.Close()\n\t\t}\n\t}()\n\n\tvalidator, errClose := newValidator(aciFile)\n\tif errClose != nil {\n\t\treturn nil, errClose\n\t}\n\n\tentity, errClose := validator.ValidateWithSignature(f.Ks, ascFile)\n\tif errClose != nil {\n\t\treturn nil, errwrap.Wrap(fmt.Errorf(\"image %q verification failed\", validator.ImageName()), errClose)\n\t}\n\tprintIdentities(entity)\n\n\treturn aciFile, nil\n}", "label": 5}
{"code": "func decodeCompoundMessage(buf []byte) ([][]byte, error) {\n\tvar cMsg CompoundMessage\n\tif err := proto.Unmarshal(buf, &cMsg); err != nil {\n\t\treturn nil, err\n\t}\n\n\tparts := make([][]byte, 0, len(cMsg.Messages))\n\tfor _, m := range cMsg.Messages {\n\t\tparts = append(parts, m.Payload)\n\t}\n\n\treturn parts, nil\n}", "label": 5}
{"code": "public static int cudnnRestoreDropoutDescriptor(\n        cudnnDropoutDescriptor dropoutDesc, \n        cudnnHandle handle, \n        float dropout, \n        Pointer states, \n        long stateSizeInBytes, \n        long seed)\n    {\n        return checkResult(cudnnRestoreDropoutDescriptorNative(dropoutDesc, handle, dropout, states, stateSizeInBytes, seed));\n    }", "label": 0}
{"code": "function createGetAlias(aliases) {\n    if (isPlainObject(aliases) && !Array.isArray(aliases)) {\n        aliases = Object.keys(aliases).map((key) => { // eslint-disable-line\n            let onlyModule = false;\n            let obj = aliases[key];\n            if (/\\$$/.test(key)) {\n                onlyModule = true;\n                key = key.substr(0, key.length - 1); // eslint-disable-line\n            }\n            if (isString(obj)) {\n                obj = {\n                    alias: obj,\n                };\n            }\n            return {\n                name: key,\n                onlyModule,\n                ...obj,\n            };\n        });\n    }\n\n    return (request) => {\n        for (const alias of aliases) {\n            if ((!alias.onlyModule && request.indexOf(`${alias.name}/`) === 0) || request === alias.name) {\n                if (request.indexOf(`${alias.alias}/`) !== 0 && request !== alias.alias) {\n                    return alias.alias + request.substr(alias.name.length);\n                }\n            }\n        }\n        return request;\n    };\n}", "label": 3}
{"code": "public function instances(array $options = [])\n    {\n        $options += [\n            'filter' => null\n        ];\n\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n        return new ItemIterator(\n            new PageIterator(\n                function (array $instance) {\n                    $name = InstanceAdminClient::parseName($instance['name'])['instance'];\n                    return $this->instance($name, $instance);\n                },\n                [$this->connection, 'listInstances'],\n                ['projectId' => InstanceAdminClient::projectName($this->projectId)] + $options,\n                [\n                    'itemsKey' => 'instances',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "def place_in_layouts(content, payload, info)\n      output = content.dup\n      layout = layouts[document.data[\"layout\"].to_s]\n      validate_layout(layout)\n\n      used = Set.new([layout])\n\n      # Reset the payload layout data to ensure it starts fresh for each page.\n      payload[\"layout\"] = nil\n\n      while layout\n        output = render_layout(output, layout, info)\n        add_regenerator_dependencies(layout)\n\n        next unless (layout = site.layouts[layout.data[\"layout\"]])\n        break if used.include?(layout)\n\n        used << layout\n      end\n      output\n    end", "label": 4}
{"code": "def apply_defaults\n      # If we don't have a better guess use the username.\n      Config[:node_name] ||= Etc.getlogin\n      # If we don't have a key (path or inline) check user.pem and $node_name.pem.\n      unless Config.key?(:client_key) || Config.key?(:client_key_contents)\n        key_path = find_default_key([\"#{Config[:node_name]}.pem\", \"user.pem\"])\n        Config[:client_key] = key_path if key_path\n      end\n      # Similarly look for a validation key file, though this should be less\n      # common these days.\n      unless Config.key?(:validation_key) || Config.key?(:validation_key_contents)\n        key_path = find_default_key([\"#{Config[:validation_client_name]}.pem\", \"validator.pem\", \"validation.pem\"])\n        Config[:validation_key] = key_path if key_path\n      end\n    end", "label": 4}
{"code": "func CreateOptionDNS(dns []string) EndpointOption {\n\treturn func(ep *endpoint) {\n\t\tep.generic[netlabel.DNSServers] = dns\n\t}\n}", "label": 5}
{"code": "func (f *file) lintBlankImports() {\n\t// In package main and in tests, we don't complain about blank imports.\n\tif f.pkg.main || f.isTest() {\n\t\treturn\n\t}\n\n\t// The first element of each contiguous group of blank imports should have\n\t// an explanatory comment of some kind.\n\tfor i, imp := range f.f.Imports {\n\t\tpos := f.fset.Position(imp.Pos())\n\n\t\tif !isBlank(imp.Name) {\n\t\t\tcontinue // Ignore non-blank imports.\n\t\t}\n\t\tif i > 0 {\n\t\t\tprev := f.f.Imports[i-1]\n\t\t\tprevPos := f.fset.Position(prev.Pos())\n\t\t\tif isBlank(prev.Name) && prevPos.Line+1 == pos.Line {\n\t\t\t\tcontinue // A subsequent blank in a group.\n\t\t\t}\n\t\t}\n\n\t\t// This is the first blank import of a group.\n\t\tif imp.Doc == nil && imp.Comment == nil {\n\t\t\tref := \"\"\n\t\t\tf.errorf(imp, 1, link(ref), category(\"imports\"), \"a blank import should be only in a main or test package, or have a comment justifying it\")\n\t\t}\n\t}\n}", "label": 5}
{"code": "private function add($field, $args)\n    {\n        $this->initializeDoctrine();\n\n        $property = $this->cm->getProperty($field);\n\n        if (! $property) {\n            throw new BadMethodCallException(\"no field with name '\" . $field . \"' exists on '\" . $this->cm->getClassName() . \"'\");\n        }\n\n        if (! ($property instanceof ToManyAssociationMetadata)) {\n            throw new BadMethodCallException('There is no method add' . $field . '() on ' . $this->cm->getClassName());\n        }\n\n        $targetClassName = $property->getTargetEntity();\n\n        if (! ($args[0] instanceof $targetClassName)) {\n            throw new InvalidArgumentException(\"Expected persistent object of type '\" . $targetClassName . \"'\");\n        }\n\n        if (! ($this->{$field} instanceof Collection)) {\n            $this->{$field} = new ArrayCollection($this->{$field} ?: []);\n        }\n\n        $this->{$field}->add($args[0]);\n\n        $this->completeOwningSide($property, $args[0]);\n\n        return $this;\n    }", "label": 2}
{"code": "protected function upload($local_file)\n    {\n        if (!is_file($local_file)) {\n            throw new WebDriverException('You may only upload files: ' . $local_file);\n        }\n\n        // Create a temporary file in the system temp directory.\n        $temp_zip = tempnam(sys_get_temp_dir(), 'WebDriverZip');\n        $zip = new ZipArchive();\n        if ($zip->open($temp_zip, ZipArchive::CREATE) !== true) {\n            return false;\n        }\n        $info = pathinfo($local_file);\n        $file_name = $info['basename'];\n        $zip->addFile($local_file, $file_name);\n        $zip->close();\n        $params = [\n            'file' => base64_encode(file_get_contents($temp_zip)),\n        ];\n        $remote_path = $this->executor->execute(\n            DriverCommand::UPLOAD_FILE,\n            $params\n        );\n        unlink($temp_zip);\n\n        return $remote_path;\n    }", "label": 2}
{"code": "function streamFileEntry(params, callback) {\n  params.zipfile.openReadStream(params.entry, function(err, readStream) {\n    if (err) {\n      return callback(err);\n    }\n    // ensure parent directory exists\n    var newFilePath = params.workingDir + \"/\" + params.entry.fileName;\n    mkdirp(path.dirname(newFilePath), function(err) {\n      if (err) {\n        logger.debug(\"Error making directory \" + newFilePath, err);\n        return callback(err);\n      }\n      readStream.pipe(fs.createWriteStream(newFilePath));\n      readStream.on(\"end\", function() {\n        params.zipfile.readEntry();\n        callback();\n      });\n      readStream.on('error', function(err) {\n        callback(err);\n      });\n    });\n  });\n}", "label": 3}
{"code": "@PostConstruct\n\tprotected void buildCopyrightMap() {\n\t\tif (null == declaredPlugins) {\n\t\t\treturn;\n\t\t}\n\t\t// go over all plug-ins, adding copyright info, avoiding duplicates (on object key)\n\t\tfor (PluginInfo plugin : declaredPlugins.values()) {\n\t\t\tfor (CopyrightInfo copyright : plugin.getCopyrightInfo()) {\n\t\t\t\tString key = copyright.getKey();\n\t\t\t\tString msg = copyright.getKey() + \": \" + copyright.getCopyright() + \" : licensed as \" +\n\t\t\t\t\t\tcopyright.getLicenseName() + \", see \" + copyright.getLicenseUrl();\n\t\t\t\tif (null != copyright.getSourceUrl()) {\n\t\t\t\t\tmsg += \" source \" + copyright.getSourceUrl();\n\t\t\t\t}\n\t\t\t\tif (!copyrightMap.containsKey(key)) {\n\t\t\t\t\tlog.info(msg);\n\t\t\t\t\tcopyrightMap.put(key, copyright);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "label": 0}
{"code": "def set_coords(self, x=0, y=0, z=0, t=0):\n        \"\"\"\n        set coords of agent in an arbitrary world\n        \"\"\"\n        self.coords = {}\n        self.coords['x'] = x\n        self.coords['y'] = y\n        self.coords['z'] = z\n        self.coords['t'] = t", "label": 1}
{"code": "def download(url, proxies=None):\n    \"\"\"\n    Download a PDF or DJVU document from a url, eventually using proxies.\n\n    :params url: The URL to the PDF/DJVU document to fetch.\n    :params proxies: An optional list of proxies to use. Proxies will be \\\n            used sequentially. Proxies should be a list of proxy strings. \\\n            Do not forget to include ``\"\"`` (empty string) in the list if \\\n            you want to try direct fetching without any proxy.\n\n    :returns: A tuple of the raw content of the downloaded data and its \\\n            associated content-type. Returns ``(None, None)`` if it was \\\n            unable to download the document.\n\n    >>> download(\"http://arxiv.org/pdf/1312.4006.pdf\") # doctest: +SKIP\n    \"\"\"\n    # Handle default argument\n    if proxies is None:\n        proxies = [\"\"]\n\n    # Loop over all available connections\n    for proxy in proxies:\n        # Handle no proxy case\n        if proxy == \"\":\n            socket.socket = DEFAULT_SOCKET\n        # Handle SOCKS proxy\n        elif proxy.startswith('socks'):\n            if proxy[5] == '4':\n                proxy_type = socks.SOCKS4\n            else:\n                proxy_type = socks.SOCKS5\n            proxy = proxy[proxy.find('://') + 3:]\n            try:\n                proxy, port = proxy.split(':')\n            except ValueError:\n                port = None\n            socks.set_default_proxy(proxy_type, proxy, port)\n            socket.socket = socks.socksocket\n        # Handle generic HTTP proxy\n        else:\n            try:\n                proxy, port = proxy.split(':')\n            except ValueError:\n                port = None\n            socks.set_default_proxy(socks.HTTP, proxy, port)\n            socket.socket = socks.socksocket\n\n        downloaded = _download_helper(url)\n        if downloaded is not None:\n            return downloaded\n\n    # In case of running out of proxies, return (None, None)\n    return (None, None)", "label": 1}
{"code": "function(func, context, args, callback) {\n  try {\n    func.apply(context, args);\n  }\n  catch (err) {}\n\n  if (callback) {\n    callback();\n  }\n}", "label": 3}
{"code": "def send_response(json)\n      UI.verbose(\"sending #{json}\")\n      begin\n        @client.puts(json) # Send some json to the client\n      rescue Errno::EPIPE => e\n        UI.verbose(e)\n        return COMMAND_EXECUTION_STATE[:error]\n      end\n      return COMMAND_EXECUTION_STATE[:ready]\n    end", "label": 4}
{"code": "def migrate_without_lock\n        if invalid_target?\n          raise UnknownMigrationVersionError.new(@target_version)\n        end\n\n        result = runnable.each do |migration|\n          execute_migration_in_transaction(migration, @direction)\n        end\n\n        record_environment\n        result\n      end", "label": 4}
{"code": "public static snmptrap[] get(nitro_service service) throws Exception{\n\t\tsnmptrap obj = new snmptrap();\n\t\tsnmptrap[] response = (snmptrap[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func setRoot() {\n\twdStr, err := os.Getwd()\n\tif err == nil {\n\t\tgofpdfDir = \"\"\n\t\tlist := strings.Split(filepath.ToSlash(wdStr), \"/\")\n\t\tfor j := len(list) - 1; j >= 0 && list[j] != \"gofpdf\"; j-- {\n\t\t\tgofpdfDir = filepath.Join(gofpdfDir, \"..\")\n\t\t}\n\t} else {\n\t\tpanic(err)\n\t}\n}", "label": 5}
{"code": "func (h *Handle) SetAnyInRange(start, end uint64, serial bool) (uint64, error) {\n\tif end < start || end >= h.bits {\n\t\treturn invalidPos, fmt.Errorf(\"invalid bit range [%d, %d]\", start, end)\n\t}\n\tif h.Unselected() == 0 {\n\t\treturn invalidPos, ErrNoBitAvailable\n\t}\n\treturn h.set(0, start, end, true, false, serial)\n}", "label": 5}
{"code": "def revealjs_template():\n    '''Create or update the template presentation demo using task `revealjs`.\n    '''\n    from config import basedir, github_user, github_repo\n\n    run(flo('rm -f {basedir}/index.html'))\n    run(flo('rm -f {basedir}/slides.md'))\n    run(flo('rm -f {basedir}/README.md'))\n    run(flo('rm -rf {basedir}/img/'))\n\n    title = 'reveal.js template'\n    subtitle = '[reveal.js][3] presentation written ' \\\n               'in [markdown][4] set up with [fabric][5] & [fabsetup][6]'\n    description = '''\\\nThis presentation shows how to create a reveal.js presentation which will be\nset up with the fabric task `setup.revealjs` of fabsetup.\n\nAlso, you can use this presentation source as a reveal.js template:\n* Checkout this repo\n* Then set the title in the `index.html` and edit the\n  `slides.md`.'''\n\n    execute(revealjs, basedir, title, subtitle, description,\n            github_user, github_repo)\n\n    # (README.md was removed, but not the github remote repo)\n    print_msg('\\n## Re-add github repo infos into README.md')\n    basename = os.path.basename(basedir)\n    _insert_repo_infos_into_readme(basedir, github_user=_lazy('github_user'),\n                                   github_repo=_lazy('github_repo',\n                                                     default=basename))\n\n    print_msg('\\n## Assure symbolic link not tracked by git exists\\n')\n    run(flo('ln -snf ../reveal.js  {basedir}/reveal.js/reveal.js'))", "label": 1}
{"code": "def _get_external_id(account_info):\n    \"\"\"Get external id from account info.\"\"\"\n    if all(k in account_info for k in ('external_id', 'external_method')):\n        return dict(id=account_info['external_id'],\n                    method=account_info['external_method'])\n    return None", "label": 1}
{"code": "def get_metrics(self):\n        \"\"\"Calculate ratio_comment_to_code and return with the other values\"\"\"\n        if(self.sloc == 0):\n            if(self.comments == 0):\n                ratio_comment_to_code = 0.00\n            else:\n                ratio_comment_to_code = 1.00\n        else:\n            ratio_comment_to_code = float(self.comments) / self.sloc\n        metrics = OrderedDict([('sloc', self.sloc), ('comments', self.comments),\n                               ('ratio_comment_to_code', round(ratio_comment_to_code, 2))])\n        return metrics", "label": 1}
{"code": "func (r *DrvRegistry) RegisterIpamDriver(name string, driver ipamapi.Ipam) error {\n\treturn r.registerIpamDriver(name, driver, &ipamapi.Capability{})\n}", "label": 5}
{"code": "def foldable_comment_block_ranges\n      return [] unless synchronized?\n      result = []\n      grouped = []\n      # @param cmnt [Parser::Source::Comment]\n      @comments.each do |cmnt|\n        if cmnt.document?\n          result.push Range.from_expr(cmnt.loc.expression)\n        elsif code.lines[cmnt.loc.expression.line].strip.start_with?('#')\n          if grouped.empty? || cmnt.loc.expression.line == grouped.last.loc.expression.line + 1\n            grouped.push cmnt\n          else\n            result.push Range.from_to(grouped.first.loc.expression.line, 0, grouped.last.loc.expression.line, 0) unless grouped.length < 3\n            grouped = [cmnt]\n          end\n        else\n          unless grouped.length < 3\n            result.push Range.from_to(grouped.first.loc.expression.line, 0, grouped.last.loc.expression.line, 0)\n          end\n          grouped.clear\n        end\n      end\n      result.push Range.from_to(grouped.first.loc.expression.line, 0, grouped.last.loc.expression.line, 0) unless grouped.length < 3\n      result\n    end", "label": 4}
{"code": "function generatePDF(req, res, next) {\n  req.appformsResultPayload = req.appformsResultPayload || {};\n\n  //If there is already a submission result, render this. This is useful for cases where the submission is fetched from another database and rendered elsewhere.\n  var existingSubmission = req.appformsResultPayload.data;\n\n  var params = {\n    _id: req.params.id,\n    pdfExportDir: req.pdfExportDir,\n    downloadUrl: '' + req.protocol + '://' + req.hostname,\n    existingSubmission: existingSubmission,\n    environment: req.environment,\n    mbaasConf: req.mbaasConf,\n    domain: req.user.domain,\n    filesAreRemote: req.filesAreRemote,\n    fileUriPath: req.fileUriPath,\n    location: req.coreLocation,\n    pdfTemplateLoc: req.pdfTemplateLoc,\n    maxConcurrentPhantomPerWorker: req.maxConcurrentPhantomPerWorker\n  };\n\n  logger.debug(\"Middleware generatePDF \", {params: params});\n\n  forms.generateSubmissionPdf(_.extend(params, req.connectionOptions), function(err, submissionPdfLocation) {\n    if (err) {\n      logger.error(\"Middleware generatePDF\", {error: err});\n      return next(err);\n    }\n\n    logger.debug(\"Middleware generatePDF \", {submissionPdfLocation: submissionPdfLocation});\n\n    //Streaming the file as an attachment\n    res.download(submissionPdfLocation, '' + req.params.id + \".pdf\", function(fileDownloadError) {\n\n      //Download Complete, remove the cached file\n      fs.unlink(submissionPdfLocation, function() {\n        if (fileDownloadError) {\n          logger.error(\"Middleware generatePDF \", {error: fileDownloadError});\n          //If the headers have not been sent to the client, can use the error handler\n          if (!res.headersSent) {\n            return next(fileDownloadError);\n          }\n        }\n      });\n    });\n  });\n}", "label": 3}
{"code": "function (e, req, res, host) {\n\t\tLOG.error('proxy error for host: ' + host + '. remove from active proxy list:', 'SR.Proxy');\n\t\tLOG.error(e, 'SR.Proxy');\n\t\t\n\t\t// remove proxy info from list\n\t\tdelete l_proxies[host];\n\t\t\n\t\t// notify for proxy failure\n\t\tUTIL.safeCall(onProxyFail, host);\n\t\t\n\t\t// send back to client about the proxy error\n\t\tres.writeHead(502, {\n   \t\t\t'Content-Type': 'text/plain'\n\t\t});\n\t\tres.end('PROXY_ERROR: cannot access proxy: ' + host);\t\t\n\t}", "label": 3}
{"code": "public function setTables($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Bigtable\\Admin\\V2\\Table::class);\n        $this->tables = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def call\n      return broadcast(:invalid) unless @form.valid?\n\n      update_personal_data\n      update_avatar\n      update_password\n\n      if @user.valid?\n        @user.save!\n        notify_followers\n        broadcast(:ok, @user.unconfirmed_email.present?)\n      else\n        @form.errors.add :avatar, @user.errors[:avatar] if @user.errors.has_key? :avatar\n        broadcast(:invalid)\n      end\n    end", "label": 4}
{"code": "private void processEncodedPayload() throws IOException {\n    if (!readPayload) {\n      payloadSpanCollector.reset();\n      collect(payloadSpanCollector);\n      Collection<byte[]> originalPayloadCollection = payloadSpanCollector\n          .getPayloads();\n      if (originalPayloadCollection.iterator().hasNext()) {\n        byte[] payload = originalPayloadCollection.iterator().next();\n        if (payload == null) {\n          throw new IOException(\"no payload\");\n        }\n        MtasPayloadDecoder payloadDecoder = new MtasPayloadDecoder();\n        payloadDecoder.init(startPosition(), payload);\n        mtasPosition = payloadDecoder.getMtasPosition();\n      } else {\n        throw new IOException(\"no payload\");\n      }\n    }\n  }", "label": 0}
{"code": "def split_dae_alg(eqs: SYM, dx: SYM) -> Dict[str, SYM]:\n    \"\"\"Split equations into differential algebraic and algebraic only\"\"\"\n    dae = []\n    alg = []\n    for eq in ca.vertsplit(eqs):\n        if ca.depends_on(eq, dx):\n            dae.append(eq)\n        else:\n            alg.append(eq)\n    return {\n        'dae': ca.vertcat(*dae),\n        'alg': ca.vertcat(*alg)\n    }", "label": 1}
{"code": "func SetShutdownPollPeriod(period time.Duration) ServerOption {\n\treturn func(s *Server) error {\n\t\ts.shutdownPollPeriod = period\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "function execList(options) {\n  const deferred = Q.defer();\n\n  const json = options.json !== false;\n  const offline = options.offline !== false;\n  const cwd = options.cwd || process.cwd();\n  const config = {json, offline, cwd};\n\n  bower.commands.list(undefined, config)\n      .on('end', (conf) => {\n        deferred.resolve(flatten(conf));\n      })\n      .on('error', (error) => {\n        deferred.reject(error);\n      });\n\n  return deferred.promise;\n}", "label": 3}
{"code": "def key_callback(type, key)\n      key = key.downcase\n\n      # All key events\n      @events[:key].each do |id, e|\n        e.call(KeyEvent.new(type, key))\n      end\n\n      case type\n      # When key is pressed, fired once\n      when :down\n        @events[:key_down].each do |id, e|\n          e.call(KeyEvent.new(type, key))\n        end\n      # When key is being held down, fired every frame\n      when :held\n        @events[:key_held].each do |id, e|\n          e.call(KeyEvent.new(type, key))\n        end\n      # When key released, fired once\n      when :up\n        @events[:key_up].each do |id, e|\n          e.call(KeyEvent.new(type, key))\n        end\n      end\n    end", "label": 4}
{"code": "public SignedJWT verifyToken(String jwtString) throws ParseException {\n        try {\n            SignedJWT jwt = SignedJWT.parse(jwtString);\n            if (jwt.verify(new MACVerifier(this.jwtSharedSecret))) {\n                return jwt;\n            }\n            return null;\n        } catch (JOSEException e) {\n            throw new RuntimeException(\"Error verifying JSON Web Token\", e);\n        }\n    }", "label": 0}
{"code": "def read_type(field_info)\n      # if field_info is a Fixnum, assume it is a Thrift::Types constant\n      # convert it into a field_info Hash for backwards compatibility\n      if field_info.is_a? Fixnum\n        field_info = {:type => field_info}\n      end\n\n      case field_info[:type]\n      when Types::BOOL\n        read_bool\n      when Types::BYTE\n        read_byte\n      when Types::DOUBLE\n        read_double\n      when Types::I16\n        read_i16\n      when Types::I32\n        read_i32\n      when Types::I64\n        read_i64\n      when Types::STRING\n        if field_info[:binary]\n          read_binary\n        else\n          read_string\n        end\n      else\n        raise NotImplementedError\n      end\n    end", "label": 4}
{"code": "def print_consensus(genomes):\n    \"\"\"\n    print consensensus sequences for each genome and sample\n    \"\"\"\n    # generate consensus sequences\n    cons = {} # cons[genome][sample][contig] = consensus\n    for genome, contigs in list(genomes.items()):\n        cons[genome] = {}\n        for contig, samples in list(contigs.items()):\n            for sample, stats in list(samples.items()):\n                if sample not in cons[genome]:\n                    cons[genome][sample] = {}\n                seq = cons[genome][sample][contig] = []\n                for pos, ps in enumerate(stats['bp_stats'], 1):\n                    ref, consensus = ps['ref'], ps['consensus'][0]\n                    if consensus == 'n/a':\n                        consensus = ref.lower()\n                    seq.append(consensus)\n    # print consensus sequences\n    for genome, samples in cons.items():\n        for sample, contigs in samples.items():\n            fn = '%s.%s.consensus.fa' % (genome, sample)\n            f = open(fn, 'w')\n            for contig, seq in contigs.items():\n                print('>%s' % (contig), file = f)\n                print(''.join(seq), file = f)\n            f.close()\n    return cons", "label": 1}
{"code": "function(context, keys){\n\n\t\t\t\t// If nothing can be found with the keys we are looking for, save the\n\t\t\t\t// first possible match.  This is where we will write to.\n\t\t\t\tif(firstSearchedContext === undefined && !(context instanceof LetContext)) {\n\t\t\t\t\tfirstSearchedContext = context;\n\t\t\t\t}\n\t\t\t\t// If we have multiple keys ...\n\t\t\t\tif(keys.length > 1) {\n\t\t\t\t\t// see if we can find the parent ...\n\t\t\t\t\tvar parentKeys = keys.slice(0, keys.length-1);\n\t\t\t\t\tvar parent = stacheKey.read(context, parentKeys, options).value;\n\n\t\t\t\t\t// If there is a parent, see if it has the last key\n\t\t\t\t\tif( parent != null && canReflect.hasKey(parent, keys[keys.length-1].key ) ) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\tparent: parent,\n\t\t\t\t\t\t\tparentHasKey: true,\n\t\t\t\t\t\t\tvalue: undefined\n\t\t\t\t\t\t};\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn {};\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// If we have only one key, try to find a context with this key\n\t\t\t\telse if(keys.length === 1) {\n\t\t\t\t\tif( canReflect.hasKey(context, keys[0].key ) ) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\tparent: context,\n\t\t\t\t\t\t\tparentHasKey: true,\n\t\t\t\t\t\t\tvalue: undefined\n\t\t\t\t\t\t};\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn {};\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// If we have no keys, we are reading `this`.\n\t\t\t\telse {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tvalue: context\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t}", "label": 3}
{"code": "def parseInt(self, words):\n        \"\"\"Parses words to the integer they describe.\n\n        Args:\n            words (str): Description of the integer.\n\n        Returns:\n            An integer representation of the words.\n        \"\"\"\n        # Remove 'and', case-sensitivity\n        words = words.replace(\" and \", \" \").lower()\n        # 'a' -> 'one'\n        words = re.sub(r'(\\b)a(\\b)', '\\g<1>one\\g<2>', words)\n\n        def textToNumber(s):\n            \"\"\"\n            Converts raw number string to an integer.\n            Based on text2num.py by Greg Hewill.\n            \"\"\"\n            a = re.split(r\"[\\s-]+\", s)\n            n = 0\n            g = 0\n            for w in a:\n                x = NumberService.__small__.get(w, None)\n                if x is not None:\n                    g += x\n                elif w == \"hundred\":\n                    g *= 100\n                else:\n                    x = NumberService.__magnitude__.get(w, None)\n                    if x is not None:\n                        n += g * x\n                        g = 0\n                    else:\n                        raise NumberService.NumberException(\n                            \"Unknown number: \" + w)\n            return n + g\n\n        return textToNumber(words)", "label": 1}
{"code": "func (c *crontime) DurationUntilNextEvent() time.Duration {\n\treturn c.nextEvent().Sub(time.Now())\n}", "label": 5}
{"code": "function logstashLayout(logEvt, fields) {\n    var messageData = logEvt.data[0], \n        log = {\n            '@timestamp': (new Date()).toISOString(),\n            '@fields': {\n                category: logEvt.categoryName,\n                level: logEvt.level.levelStr\n            },\n            '@message' : (toType(messageData) === \"string\") ? messageData : JSON.stringify(messageData)\n        }\n    \n    for (var key in fields) {\n        if (typeof fields[key] !== 'function') {\n            log['@fields'][key] = fields[key];\n        }\n    }\n\n    return JSON.stringify(log) + '\\n';\n}", "label": 3}
{"code": "func (s *Server) EmitAuditEvent(event events.Event, fields events.EventFields) {\n\tauditLog := s.GetAuditLog()\n\tif auditLog != nil {\n\t\tif err := auditLog.EmitAuditEvent(event, fields); err != nil {\n\t\t\ts.log.Error(err)\n\t\t}\n\t} else {\n\t\ts.log.Warn(\"SSH server has no audit log\")\n\t}\n}", "label": 5}
{"code": "function hotswap(currentNode, newNode, ignoreElements) {\n    var newNodeType = newNode.nodeType,\n      currentNodeType = currentNode.nodeType,\n      swapMethod;\n\n    if(newNodeType !== currentNodeType) {\n      $(currentNode).replaceWith(newNode);\n    } else {\n      swapMethod = swapMethods[newNodeType] || swapMethods['default'];\n      swapMethod(currentNode, newNode, ignoreElements);\n    }\n  }", "label": 3}
{"code": "function Evidence(properties) {\n                if (properties)\n                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n                        if (properties[keys[i]] != null)\n                            this[keys[i]] = properties[keys[i]];\n            }", "label": 3}
{"code": "public static int cudnnGetConvolutionNdDescriptor(\n        cudnnConvolutionDescriptor convDesc, \n        int arrayLengthRequested, \n        int[] arrayLength, \n        int[] padA, \n        int[] strideA, \n        int[] dilationA, \n        int[] mode, \n        int[] computeType)/** convolution data type */\n    {\n        return checkResult(cudnnGetConvolutionNdDescriptorNative(convDesc, arrayLengthRequested, arrayLength, padA, strideA, dilationA, mode, computeType));\n    }", "label": 0}
{"code": "private byte[] readStreamCompressed(InputStream stream) throws IOException\r\n    {\r\n        ByteArrayOutputStream bao    = new ByteArrayOutputStream();\r\n        GZIPOutputStream      gos    = new GZIPOutputStream(bao);\r\n        OutputStreamWriter    output = new OutputStreamWriter(gos);\r\n        BufferedReader        input  = new BufferedReader(new InputStreamReader(stream));\r\n        String                line;\r\n\r\n        while ((line = input.readLine()) != null)\r\n        {\r\n            output.write(line);\r\n            output.write('\\n');\r\n        }\r\n        input.close();\r\n        stream.close();\r\n        output.close();\r\n        gos.close();\r\n        bao.close();\r\n        return bao.toByteArray();\r\n    }", "label": 0}
{"code": "def remove_user(user):\n    \"\"\"Remove a action for a user.\"\"\"\n    def processor(action, argument):\n        ActionUsers.query_by_action(action, argument=argument).filter(\n            ActionUsers.user_id == user.id\n        ).delete(synchronize_session=False)\n    return processor", "label": 1}
{"code": "public function setNumber($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Language\\V1beta2\\PartOfSpeech_Number::class);\n        $this->number = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function (res_obj, data, conn) {\n\n\t\t// check if we should return empty response\n\t\tif (typeof res_obj === 'undefined') {\n\t\t\tSR.REST.reply(res, {});\n\t\t\treturn true;\n\t\t}\n\n\t\t// check for special case processing (SR_REDIRECT)\n\t\tif (res_obj[SR.Tags.UPDATE] === 'SR_REDIRECT' && res_obj[SR.Tags.PARA] && res_obj[SR.Tags.PARA].url) {\n\n\t\t\tvar url = res_obj[SR.Tags.PARA].url;\n\t\t\tLOG.warn('redirecting to: ' + url, l_name);\n\n\t\t\t/*\n\t\t\tres.writeHead(302, {\n\t\t\t\t'Location': url\n\t\t\t});\n\t\t\tres.end();\n\t\t\t*/\n\n\t\t\t// redirect by page \n\t\t\t// TODO: merge with same code in FB.js\n\t\t\tvar page =\n\t\t\t\t'<html><body><script>\\n' +\n\t\t\t\t'if (navigator.appName.indexOf(\"Microsoft\") != -1)\\n' +\n\t\t\t\t'    window.top.location.href=\"' + url + '\";\\n' +\n\t\t\t\t'else\\n' +\n\t\t\t\t'\t top.location.href=\"' + url + '\";\\n' +\n\t\t\t\t'</script></body></html>\\n';\n\n\t\t\tres.writeHead(200, {\n\t\t\t\t'Content-Type': 'text/html'\n\t\t\t});\n\t\t\tres.end(page);\n\n\t\t\treturn true;\n\t\t}\n\t\t\n\t\t// check for special case processing (SR_HTML)\n\t\tif (res_obj[SR.Tags.UPDATE] === 'SR_HTML' && res_obj[SR.Tags.PARA].page) {\n\t\t\tres.writeHead(200, {\n\t\t\t\t'Content-Type': 'text/html'\n\t\t\t});\n\t\t\tres.end(res_obj[SR.Tags.PARA].page);\n\t\t\treturn true;\n\t\t}\n\n\t\t// check for special case processing (SR_DOWNLOAD)\n\t\tif (res_obj[SR.Tags.UPDATE] === 'SR_DOWNLOAD' && res_obj[SR.Tags.PARA].data && res_obj[SR.Tags.PARA].filename) {\n\n\t\t\tvar filename = res_obj[SR.Tags.PARA].filename;\n\t\t\tLOG.warn('allow client to download file: ' + filename, l_name);\n\n\t\t\tvar data = res_obj[SR.Tags.PARA].data;\n\t\t\tres.writeHead(200, {\n\t\t\t\t'Content-Type': 'application/octet-stream',\n\t\t\t\t'Content-Disposition': 'attachment; filename=' + filename,\n\t\t\t\t'Content-Length': data.length\n\t\t\t});\n\t\t\tres.end(data);\n\t\t\treturn true;\n\t\t}\n\n\t\t// check for special case processing (SR_RESOURCE)\n\t\tif (res_obj[SR.Tags.UPDATE] === 'SR_RESOURCE' && res_obj[SR.Tags.PARA].address) {\n\n\t\t\tvar file = res_obj[SR.Tags.PARA].address;\n\t\t\t\t\t\t\n\t\t\t// check if resource exists & its states\n\t\t\tSR.fs.stat(file, function (err, stats) {\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\tvar resHeader = typeof res_obj[SR.Tags.PARA].header === 'object' ? res_obj[SR.Tags.PARA].header : {};\n\t\t\t\t\n\t\t\t\tif (err) {\t\t\t\n\t\t\t\t\tLOG.error(err, l_name);\n\t\t\t\t\tres.writeHead(404, resHeader);\n\t\t\t\t\tres.end();\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tvar extFilename = file.match(/[\\W\\w]*\\.([\\W\\w]*)/)[1];\n\t\t\t\tif (typeof extFilename === 'string')\n\t\t\t\t\textFilename = extFilename.toLowerCase();\n\t\t\t\t\n\t\t\t\t// default to 200 status\n\t\t\t\tvar resStatus = 200;\n\t\t\t\tresHeader['Accept-Ranges'] = 'bytes';\n\t\t\t\tresHeader['Cache-Control'] = 'no-cache';\n\t\t\t\tresHeader['Content-Length'] = stats.size;\n\t\t\t\t\n\t\t\t\tif (l_extList[extFilename]) {\n\t\t\t\t\tresHeader['Content-Type'] = l_extList[extFilename];\n\t\t\t\t};\n\t\t\t\t\n\t\t\t\tvar start = undefined;\n\t\t\t\tvar end = undefined;\n\t\t\t\t\n\t\t\t\t// check if request range exists (e.g., streaming media such as webm/mp4) to return 206 status\n\t\t\t\t// see: https://delog.wordpress.com/2011/04/25/stream-webm-file-to-chrome-using-node-js/\t\t\t\t\t\t\n\t\t\t\tif (req.headers.range) {\n\t\t\t\t\tvar range = req.headers.range.split(/bytes=([0-9]*)-([0-9]*)/);\n\t\t\t\t\tresStatus = 206;\n\t\t\t\t\t\n\t\t\t\t\tstart = parseInt(range[1] || 0);\n\t\t\t\t\tend = parseInt(range[2] || stats.size - 1);\n\t\t\t\t\t\n\t\t\t\t\tif (start > end) {\n\t\t\t\t\t\tLOG.error('stream file start > end. start: ' + start + ' end: ' + end, l_name);\n\t\t\t\t\t\tvar resHeader = typeof res_obj[SR.Tags.PARA].header === 'object' ? res_obj[SR.Tags.PARA].header : {};\n\t\t\t\t\t\tres.writeHead(404, resHeader);\n\t\t\t\t\t\tres.end();\n\t\t\t\t\t\treturn;  // abnormal if we've reached here\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tLOG.debug('requesting bytes ' + start + ' to ' + end + ' for file: ' + file, l_name);\n\t\t\t\t\t\t\t \n\t\t\t\t\tresHeader['Connection'] = 'close';\n\t\t\t\t\tresHeader['Content-Length'] = end - start + 1;\n\t\t\t\t\tresHeader['Content-Range'] = 'bytes ' + start + '-' + end + '/' + stats.size;\n\t\t\t\t\tresHeader['Transfer-Encoding'] = 'chunked';\n\t\t\t\t} \n\t\t\t\t// otherwise assume it's a regular file\n\t\t\t\telse if (l_directExt.hasOwnProperty(extFilename)) {\n\t\t\t\t\t// NOTE: code below will cause the file be downloaded in a \"Save As..\" format\n\t\t\t\t\t// (instead of being displayed directly), we only want this behavior for certain file types (such as .zip)\t\t\t\t\n\t\t\t\t\tvar filename = file.replace(/^.*[\\\\\\/]/, '')\n\t\t\t\t\tLOG.warn('requesting a file: ' + filename, l_name);\n\t\t\t\t\tresHeader['Content-Disposition'] = 'attachment; filename=' + filename;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tLOG.sys('SR_RESOURCE header:', l_name);\n\t\t\t\tLOG.sys(resHeader);\n\t\t\t\tres.writeHead(resStatus, resHeader);\n\n\t\t\t\t// start streaming\n\t\t\t\tSR.fs.createReadStream(file, {\n\t\t\t\t\tflags: 'r',\n\t\t\t\t\tstart: start,\n\t\t\t\t\tend: end\n\t\t\t\t}).pipe(res);\t\t\t\n\t\t\t});\n\t\t\t\n\t\t\treturn true;\n\t\t}\n\n\t\tvar origin = _getOrigin(req);\n\n\t\t// send back via res object if hadn't responded yet\n\t\tif (res.headersSent === false) {\n\t\t\t// NOTE: cookie may be undefined;\n\t\t\tSR.REST.reply(res, data, {\n\t\t\t\torigin: origin,\n\t\t\t\tcookie: cookie\n\t\t\t});\n\t\t}\n\t\telse {\n\t\t\tLOG.error('HTTP request has already responded (cannot respond twice)', l_name);\n\t\t\tLOG.stack();\n\t\t}\n\n\t\treturn true;\n\t}", "label": 3}
{"code": "def generate!(requirements, instance_group, job, package, stemcell)\n      # Our assumption here is that package dependency graph\n      # has no cycles: this is being enforced on release upload.\n      # Other than that it's a vanilla Depth-First Search (DFS).\n\n      @logger.info(\"Checking whether package '#{package.desc}' needs to be compiled for stemcell '#{stemcell.desc}'\")\n      requirement_key = [package.id, \"#{stemcell.os}/#{stemcell.version}\"]\n      requirement = requirements[requirement_key]\n\n      if requirement # We already visited this and its dependencies\n        requirement.add_instance_group(instance_group) # But we still need to register with this instance group\n        return requirement\n      end\n\n      package_dependency_manager = PackageDependenciesManager.new(job.release.model)\n\n      requirement = create_requirement(instance_group, job, package, stemcell, package_dependency_manager)\n\n      @logger.info(\"Processing package '#{package.desc}' dependencies\")\n      dependencies = package_dependency_manager.dependencies(package)\n      dependencies.each do |dependency|\n        @logger.info(\"Package '#{package.desc}' depends on package '#{dependency.desc}'\")\n        dependency_requirement = generate!(requirements, instance_group, job, dependency, stemcell)\n        requirement.add_dependency(dependency_requirement)\n      end\n\n      requirements[requirement_key] = requirement\n      requirement\n    end", "label": 4}
{"code": "public static clusterinstance_binding get(nitro_service service, Long clid) throws Exception{\n\t\tclusterinstance_binding obj = new clusterinstance_binding();\n\t\tobj.set_clid(clid);\n\t\tclusterinstance_binding response = (clusterinstance_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (server *Server) readAll(request *http.Request) []byte {\n\tdefer request.Body.Close()\n\tbody, _ := ioutil.ReadAll(request.Body)\n\treturn body\n}", "label": 5}
{"code": "def list_orders(location_id, opts = {})\n      data, _status_code, _headers = list_orders_with_http_info(location_id, opts)\n      return data\n    end", "label": 4}
{"code": "func exportMetricValue(value *core.MetricValue) *types.MetricValue {\n\tif value == nil {\n\t\treturn nil\n\t}\n\n\tif value.ValueType == core.ValueInt64 {\n\t\treturn &types.MetricValue{\n\t\t\tIntValue: &value.IntValue,\n\t\t}\n\t} else {\n\t\tfloatVal := float64(value.FloatValue)\n\t\treturn &types.MetricValue{\n\t\t\tFloatValue: &floatVal,\n\t\t}\n\t}\n}", "label": 5}
{"code": "public function setRiceHashes($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\WebRisk\\V1beta1\\RiceDeltaEncoding::class);\n        $this->rice_hashes = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function checkId(id) {\n  id = id || \"\";\n  id = id.toString();\n  return _.isString(id) && id.length === 24;\n}", "label": 3}
{"code": "public Logger getLogger(String loggerName)\r\n    {\r\n        Logger logger;\r\n        //lookup in the cache first\r\n        logger = (Logger) cache.get(loggerName);\r\n\r\n        if(logger == null)\r\n        {\r\n            try\r\n            {\r\n                // get the configuration (not from the configurator because this is independent)\r\n                logger = createLoggerInstance(loggerName);\r\n                if(getBootLogger().isDebugEnabled())\r\n                {\r\n                    getBootLogger().debug(\"Using logger class '\"\r\n                            + (getConfiguration() != null ? getConfiguration().getLoggerClass() : null)\r\n                            + \"' for \" + loggerName);\r\n                }\r\n                // configure the logger\r\n                getBootLogger().debug(\"Initializing logger instance \" + loggerName);\r\n                logger.configure(conf);\r\n            }\r\n            catch(Throwable t)\r\n            {\r\n                // do reassign check and signal logger creation failure\r\n                reassignBootLogger(true);\r\n                logger = getBootLogger();\r\n                getBootLogger().error(\"[\" + this.getClass().getName()\r\n                            + \"] Could not initialize logger \" + (conf != null ? conf.getLoggerClass() : null), t);\r\n            }\r\n            //cache it so we can get it faster the next time\r\n            cache.put(loggerName, logger);\r\n            // do reassign check\r\n            reassignBootLogger(false);\r\n        }\r\n        return logger;\r\n    }", "label": 0}
{"code": "public static Map<String, String> mapStringToMap(String map) {\r\n    String[] m = map.split(\"[,;]\");\r\n    Map<String, String> res = new HashMap<String, String>();\r\n    for (String str : m) {\r\n      int index = str.lastIndexOf('=');\r\n      String key = str.substring(0, index);\r\n      String val = str.substring(index + 1);\r\n      res.put(key.trim(), val.trim());\r\n    }\r\n    return res;\r\n  }", "label": 0}
{"code": "function initRoutes (ravelInstance, koaRouter) {\n  const proto = Object.getPrototypeOf(this);\n  // handle class-level @mapping decorators\n  const classMeta = Metadata.getClassMeta(proto, '@mapping', Object.create(null));\n  for (const r of Object.keys(classMeta)) {\n    buildRoute(ravelInstance, this, koaRouter, r, classMeta[r]);\n  }\n\n  // handle methods decorated with @mapping\n  const meta = Metadata.getMeta(proto).method;\n  const annotatedMethods = Object.keys(meta);\n  for (const r of annotatedMethods) {\n    const methodMeta = Metadata.getMethodMetaValue(proto, r, '@mapping', 'info');\n    if (methodMeta) {\n      buildRoute(ravelInstance, this, koaRouter, r, methodMeta);\n    }\n  }\n}", "label": 3}
{"code": "function isListElement(parsingContext, inErrorRecovery) {\n            var node = currentNode(parsingContext);\n            if (node) {\n                return true;\n            }\n            switch (parsingContext) {\n                case 0 /* SourceElements */:\n                case 1 /* BlockStatements */:\n                case 3 /* SwitchClauseStatements */:\n                    // If we're in error recovery, then we don't want to treat ';' as an empty statement.\n                    // The problem is that ';' can show up in far too many contexts, and if we see one\n                    // and assume it's a statement, then we may bail out inappropriately from whatever\n                    // we're parsing.  For example, if we have a semicolon in the middle of a class, then\n                    // we really don't want to assume the class is over and we're on a statement in the\n                    // outer module.  We just want to consume and move on.\n                    return !(token() === 23 /* SemicolonToken */ && inErrorRecovery) && isStartOfStatement();\n                case 2 /* SwitchClauses */:\n                    return token() === 71 /* CaseKeyword */ || token() === 77 /* DefaultKeyword */;\n                case 4 /* TypeMembers */:\n                    return lookAhead(isTypeMemberStart);\n                case 5 /* ClassMembers */:\n                    // We allow semicolons as class elements (as specified by ES6) as long as we're\n                    // not in error recovery.  If we're in error recovery, we don't want an errant\n                    // semicolon to be treated as a class member (since they're almost always used\n                    // for statements.\n                    return lookAhead(isClassMemberStart) || (token() === 23 /* SemicolonToken */ && !inErrorRecovery);\n                case 6 /* EnumMembers */:\n                    // Include open bracket computed properties. This technically also lets in indexers,\n                    // which would be a candidate for improved error reporting.\n                    return token() === 19 /* OpenBracketToken */ || isLiteralPropertyName();\n                case 12 /* ObjectLiteralMembers */:\n                    return token() === 19 /* OpenBracketToken */ || token() === 37 /* AsteriskToken */ || isLiteralPropertyName();\n                case 9 /* ObjectBindingElements */:\n                    return token() === 19 /* OpenBracketToken */ || isLiteralPropertyName();\n                case 7 /* HeritageClauseElement */:\n                    // If we see { } then only consume it as an expression if it is followed by , or {\n                    // That way we won't consume the body of a class in its heritage clause.\n                    if (token() === 15 /* OpenBraceToken */) {\n                        return lookAhead(isValidHeritageClauseObjectLiteral);\n                    }\n                    if (!inErrorRecovery) {\n                        return isStartOfLeftHandSideExpression() && !isHeritageClauseExtendsOrImplementsKeyword();\n                    }\n                    else {\n                        // If we're in error recovery we tighten up what we're willing to match.\n                        // That way we don't treat something like \"this\" as a valid heritage clause\n                        // element during recovery.\n                        return isIdentifier() && !isHeritageClauseExtendsOrImplementsKeyword();\n                    }\n                case 8 /* VariableDeclarations */:\n                    return isIdentifierOrPattern();\n                case 10 /* ArrayBindingElements */:\n                    return token() === 24 /* CommaToken */ || token() === 22 /* DotDotDotToken */ || isIdentifierOrPattern();\n                case 17 /* TypeParameters */:\n                    return isIdentifier();\n                case 11 /* ArgumentExpressions */:\n                case 15 /* ArrayLiteralMembers */:\n                    return token() === 24 /* CommaToken */ || token() === 22 /* DotDotDotToken */ || isStartOfExpression();\n                case 16 /* Parameters */:\n                    return isStartOfParameter();\n                case 18 /* TypeArguments */:\n                case 19 /* TupleElementTypes */:\n                    return token() === 24 /* CommaToken */ || isStartOfType();\n                case 20 /* HeritageClauses */:\n                    return isHeritageClause();\n                case 21 /* ImportOrExportSpecifiers */:\n                    return ts.tokenIsIdentifierOrKeyword(token());\n                case 13 /* JsxAttributes */:\n                    return ts.tokenIsIdentifierOrKeyword(token()) || token() === 15 /* OpenBraceToken */;\n                case 14 /* JsxChildren */:\n                    return true;\n                case 22 /* JSDocFunctionParameters */:\n                case 23 /* JSDocTypeArguments */:\n                case 25 /* JSDocTupleTypes */:\n                    return JSDocParser.isJSDocType();\n                case 24 /* JSDocRecordMembers */:\n                    return isSimplePropertyName();\n            }\n            ts.Debug.fail(\"Non-exhaustive case in 'isListElement'.\");\n        }", "label": 3}
{"code": "def join(uri)\n      if !uri.respond_to?(:to_str)\n        raise TypeError, \"Can't convert #{uri.class} into String.\"\n      end\n      if !uri.kind_of?(URI)\n        # Otherwise, convert to a String, then parse.\n        uri = URI.parse(uri.to_str)\n      end\n      if uri.to_s.empty?\n        return self.dup\n      end\n\n      joined_scheme = nil\n      joined_user = nil\n      joined_password = nil\n      joined_host = nil\n      joined_port = nil\n      joined_path = nil\n      joined_query = nil\n      joined_fragment = nil\n\n      # Section 5.2.2 of RFC 3986\n      if uri.scheme != nil\n        joined_scheme = uri.scheme\n        joined_user = uri.user\n        joined_password = uri.password\n        joined_host = uri.host\n        joined_port = uri.port\n        joined_path = URI.normalize_path(uri.path)\n        joined_query = uri.query\n      else\n        if uri.authority != nil\n          joined_user = uri.user\n          joined_password = uri.password\n          joined_host = uri.host\n          joined_port = uri.port\n          joined_path = URI.normalize_path(uri.path)\n          joined_query = uri.query\n        else\n          if uri.path == nil || uri.path.empty?\n            joined_path = self.path\n            if uri.query != nil\n              joined_query = uri.query\n            else\n              joined_query = self.query\n            end\n          else\n            if uri.path[0..0] == SLASH\n              joined_path = URI.normalize_path(uri.path)\n            else\n              base_path = self.path.dup\n              base_path = EMPTY_STR if base_path == nil\n              base_path = URI.normalize_path(base_path)\n\n              # Section 5.2.3 of RFC 3986\n              #\n              # Removes the right-most path segment from the base path.\n              if base_path =~ /\\//\n                base_path.sub!(/\\/[^\\/]+$/, SLASH)\n              else\n                base_path = EMPTY_STR\n              end\n\n              # If the base path is empty and an authority segment has been\n              # defined, use a base path of SLASH\n              if base_path.empty? && self.authority != nil\n                base_path = SLASH\n              end\n\n              joined_path = URI.normalize_path(base_path + uri.path)\n            end\n            joined_query = uri.query\n          end\n          joined_user = self.user\n          joined_password = self.password\n          joined_host = self.host\n          joined_port = self.port\n        end\n        joined_scheme = self.scheme\n      end\n      joined_fragment = uri.fragment\n\n      return self.class.new(\n        :scheme => joined_scheme,\n        :user => joined_user,\n        :password => joined_password,\n        :host => joined_host,\n        :port => joined_port,\n        :path => joined_path,\n        :query => joined_query,\n        :fragment => joined_fragment\n      )\n    end", "label": 4}
{"code": "function validatorDropDown(fieldValue, fieldDefinition, previousFieldValues, cb) {\n      if (typeof(fieldValue) !== \"string\") {\n        return cb(new Error(\"Expected submission to be string but got \" + typeof(fieldValue)));\n      }\n\n      fieldDefinition.fieldOptions = fieldDefinition.fieldOptions || {};\n      fieldDefinition.fieldOptions.definition = fieldDefinition.fieldOptions.definition || {};\n\n      //Check values exists in the field definition\n      if (!fieldDefinition.fieldOptions.definition.options) {\n        return cb(new Error(\"No options exist for field \" + fieldDefinition.name));\n      }\n\n      //Finding the selected option\n      var found = _.find(fieldDefinition.fieldOptions.definition.options, function(dropdownOption) {\n        //check if fieldValue and the label need to be escaped\n        isSafeString(fieldValue) ? null : fieldValue = _.escape(fieldValue);\n        isSafeString(dropdownOption.label) ? null : dropdownOption.label = _.escape(dropdownOption.label);\n        return dropdownOption.label === fieldValue;\n      });\n\n      //Valid option, can return\n      if (found) {\n        return cb();\n      }\n\n      //If the option is empty and the field is required, then the blank option is being submitted\n      //The blank option is not valid for a required field.\n      if (found === \"\" && fieldDefinition.required && fieldDefinition.fieldOptions.definition.include_blank_option) {\n        return cb(new Error(\"The Blank Option is not valid. Please select a value.\"));\n      } else {\n        //Otherwise, it is an invalid option\n        return cb(new Error(\"Invalid option specified: \" + fieldValue));\n      }\n    }", "label": 3}
{"code": "def element_linenumber(element)\n      element = element.options if element.is_a?(Kramdown::Element)\n      element[:location]\n    end", "label": 4}
{"code": "def list(path, options = {})\n      headers = extract_headers!(options)\n      json = client.list(\"/v1/#{encode_path(path)}\", {}, headers)\n      json[:data][:keys] || []\n    rescue HTTPError => e\n      return [] if e.code == 404\n      raise\n    end", "label": 4}
{"code": "func parentExists(ifaceStr string) bool {\n\t_, err := ns.NlHandle().LinkByName(ifaceStr)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "func (l VirtualDeviceList) SelectBootOrder(order []types.BaseVirtualMachineBootOptionsBootableDevice) VirtualDeviceList {\n\tvar devices VirtualDeviceList\n\n\tfor _, bd := range order {\n\t\tfor _, device := range l {\n\t\t\tif kind, ok := bootableDevices[l.Type(device)]; ok {\n\t\t\t\tif reflect.DeepEqual(kind(device), bd) {\n\t\t\t\t\tdevices = append(devices, device)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn devices\n}", "label": 5}
{"code": "protected synchronized void doWriteObjects(boolean isFlush) throws TransactionAbortedException, LockNotGrantedException\r\n    {\r\n        /*\r\n        arminw:\r\n        if broker isn't in PB-tx, start tx\r\n        */\r\n        if (!getBroker().isInTransaction())\r\n        {\r\n            if (log.isDebugEnabled()) log.debug(\"call beginTransaction() on PB instance\");\r\n            broker.beginTransaction();\r\n        }\r\n\r\n        // Notify objects of impending commits.\r\n        performTransactionAwareBeforeCommit();\r\n\r\n        // Now perfom the real work\r\n        objectEnvelopeTable.writeObjects(isFlush);\r\n        // now we have to perform the named objects\r\n        namedRootsMap.performDeletion();\r\n        namedRootsMap.performInsert();\r\n        namedRootsMap.afterWriteCleanup();\r\n    }", "label": 0}
{"code": "def _init_template(self, cls, base_init_template):\n    '''This would be better as an override for Gtk.Widget'''\n\n    # TODO: could disallow using a metaclass.. but this is good enough\n    # .. if you disagree, feel free to fix it and issue a PR :)\n    if self.__class__ is not cls:\n        raise TypeError(\"Inheritance from classes with @GtkTemplate decorators \"\n                        \"is not allowed at this time\")\n\n    connected_signals = set()\n    self.__connected_template_signals__ = connected_signals\n\n    base_init_template(self)\n\n    for name in self.__gtemplate_widgets__:\n        widget = self.get_template_child(cls, name)\n        self.__dict__[name] = widget\n\n        if widget is None:\n            # Bug: if you bind a template child, and one of them was\n            #      not present, then the whole template is broken (and\n            #      it's not currently possible for us to know which\n            #      one is broken either -- but the stderr should show\n            #      something useful with a Gtk-CRITICAL message)\n            raise AttributeError(\"A missing child widget was set using \"\n                                 \"GtkTemplate.Child and the entire \"\n                                 \"template is now broken (widgets: %s)\" %\n                                 ', '.join(self.__gtemplate_widgets__))\n\n    for name in self.__gtemplate_methods__.difference(connected_signals):\n        errmsg = (\"Signal '%s' was declared with @GtkTemplate.Callback \" +\n                  \"but was not present in template\") % name\n        warnings.warn(errmsg, GtkTemplateWarning)", "label": 1}
{"code": "private String computeMorse(BytesRef term) {\n    StringBuilder stringBuilder = new StringBuilder();\n    int i = term.offset + prefixOffset;\n    for (; i < term.length; i++) {\n      if (ALPHABET_MORSE.containsKey(term.bytes[i])) {\n        stringBuilder.append(ALPHABET_MORSE.get(term.bytes[i]) + \" \");\n      } else if(term.bytes[i]!=0x00){\n        return null;\n      } else {\n        break;\n      }\n    }\n    return stringBuilder.toString();\n  }", "label": 0}
{"code": "public static vpnurl get(nitro_service service, String urlname) throws Exception{\n\t\tvpnurl obj = new vpnurl();\n\t\tobj.set_urlname(urlname);\n\t\tvpnurl response = (vpnurl) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def __dfs(self, v, index, layers):\n        \"\"\"\n        we recursively run dfs on each vertices in free_vertex,\n\n        :param v: vertices in free_vertex\n        :return: True if P is not empty (i.e., the maximal set of vertex-disjoint alternating path of length k)\n        and false otherwise.\n        \"\"\"\n        if index == 0:\n            path = [v]\n            while self._dfs_parent[v] != v:\n                path.append(self._dfs_parent[v])\n                v = self._dfs_parent[v]\n            self._dfs_paths.append(path)\n            return True\n        for neighbour in self._graph[v]:  # check the neighbours of vertex\n            if neighbour in layers[index - 1]:\n                # if neighbour is in left, we are traversing unmatched edges..\n                if neighbour in self._dfs_parent:\n                    continue\n                if (neighbour in self._left and (v not in self._matching or neighbour != self._matching[v])) or \\\n                        (neighbour in self._right and (v in self._matching and neighbour == self._matching[v])):\n                    self._dfs_parent[neighbour] = v\n                    if self.__dfs(neighbour, index-1, layers):\n                        return True\n        return False", "label": 1}
{"code": "function subSteps (obj, items) {\n    util.inherits(obj, Ctx);\n\n    var key = \"teamcontacts versions successors predecessors\".split(\" \")\n    ,   propKey = \"team-contacts version-history successor-version predecessor-version\".split(\" \");\n    items.forEach(function (it) {\n        obj.prototype[it] = function () {\n            this.steps.push(it);\n            this.type = \"list\";\n            var i = key.indexOf(it);\n            this.linkKey = (i >= 0) ? propKey[i] : it;\n            return this;\n        };\n    });\n}", "label": 3}
{"code": "func (m HostCertificateManager) CertificateInfo(ctx context.Context) (*HostCertificateInfo, error) {\n\tvar hs mo.HostSystem\n\tvar cm mo.HostCertificateManager\n\n\tpc := property.DefaultCollector(m.Client())\n\n\terr := pc.RetrieveOne(ctx, m.Reference(), []string{\"certificateInfo\"}, &cm)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_ = pc.RetrieveOne(ctx, m.Host.Reference(), []string{\"summary.config.sslThumbprint\"}, &hs)\n\n\treturn &HostCertificateInfo{\n\t\tHostCertificateManagerCertificateInfo: cm.CertificateInfo,\n\t\tThumbprintSHA1:                        hs.Summary.Config.SslThumbprint,\n\t}, nil\n}", "label": 5}
{"code": "function (force) {\n            var series = this,\n              processedXData = series.xData, // copied during slice operation below\n              processedYData = series.yData,\n              dataLength = processedXData.length,\n              croppedData,\n              cropStart = 0,\n              cropped,\n              distance,\n              closestPointRange,\n              xAxis = series.xAxis,\n              i, // loop variable\n              options = series.options,\n              cropThreshold = options.cropThreshold,\n              activePointCount = 0,\n              isCartesian = series.isCartesian,\n              xExtremes,\n              min,\n              max;\n\n            // If the series data or axes haven't changed, don't go through this. Return false to pass\n            // the message on to override methods like in data grouping.\n            if (isCartesian && !series.isDirty && !xAxis.isDirty && !series.yAxis.isDirty && !force) {\n                return false;\n            }\n\n            if (xAxis) {\n                xExtremes = xAxis.getExtremes(); // corrected for log axis (#3053)\n                min = xExtremes.min;\n                max = xExtremes.max;\n            }\n\n            // optionally filter out points outside the plot area\n            if (isCartesian && series.sorted && (!cropThreshold || dataLength > cropThreshold || series.forceCrop)) {\n\n                // it's outside current extremes\n                if (processedXData[dataLength - 1] < min || processedXData[0] > max) {\n                    processedXData = [];\n                    processedYData = [];\n\n                    // only crop if it's actually spilling out\n                } else if (processedXData[0] < min || processedXData[dataLength - 1] > max) {\n                    croppedData = this.cropData(series.xData, series.yData, min, max);\n                    processedXData = croppedData.xData;\n                    processedYData = croppedData.yData;\n                    cropStart = croppedData.start;\n                    cropped = true;\n                    activePointCount = processedXData.length;\n                }\n            }\n\n\n            // Find the closest distance between processed points\n            for (i = processedXData.length - 1; i >= 0; i--) {\n                distance = processedXData[i] - processedXData[i - 1];\n\n                if (!cropped && processedXData[i] > min && processedXData[i] < max) {\n                    activePointCount++;\n                }\n\n                if (distance > 0 && (closestPointRange === UNDEFINED || distance < closestPointRange)) {\n                    closestPointRange = distance;\n\n                    // Unsorted data is not supported by the line tooltip, as well as data grouping and\n                    // navigation in Stock charts (#725) and width calculation of columns (#1900)\n                } else if (distance < 0 && series.requireSorting) {\n                    error(15);\n                }\n            }\n\n            // Record the properties\n            series.cropped = cropped; // undefined or true\n            series.cropStart = cropStart;\n            series.processedXData = processedXData;\n            series.processedYData = processedYData;\n            series.activePointCount = activePointCount;\n\n            if (options.pointRange === null) { // null means auto, as for columns, candlesticks and OHLC\n                series.pointRange = closestPointRange || 1;\n            }\n            series.closestPointRange = closestPointRange;\n\n        }", "label": 3}
{"code": "def after_packaging\n      suffixes = chunk_suffixes\n      first_suffix = \"a\" * suffix_length\n      if suffixes == [first_suffix]\n        FileUtils.mv(\n          File.join(Config.tmp_path, \"#{package.basename}-#{first_suffix}\"),\n          File.join(Config.tmp_path, package.basename)\n        )\n      else\n        package.chunk_suffixes = suffixes\n      end\n    end", "label": 4}
{"code": "public Iterator getAllExtentClasses()\r\n    {\r\n        ArrayList subTypes = new ArrayList();\r\n\r\n        subTypes.addAll(_extents);\r\n\r\n        for (int idx = 0; idx < subTypes.size(); idx++)\r\n        {\r\n            ClassDescriptorDef curClassDef = (ClassDescriptorDef)subTypes.get(idx);\r\n\r\n            for (Iterator it = curClassDef.getExtentClasses(); it.hasNext();)\r\n            {\r\n                ClassDescriptorDef curSubTypeDef = (ClassDescriptorDef)it.next();\r\n\r\n                if (!subTypes.contains(curSubTypeDef))\r\n                {\r\n                    subTypes.add(curSubTypeDef);\r\n                }\r\n            }\r\n        }\r\n        return subTypes.iterator();\r\n    }", "label": 0}
{"code": "public function setView($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Monitoring\\V3\\ListTimeSeriesRequest_TimeSeriesView::class);\n        $this->view = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def tok(s)\n    case s[0]\n    when ?{ then ['{', s[0,1], s[0,1]]\n    when ?} then ['}', s[0,1], s[0,1]]\n    when ?: then [':', s[0,1], s[0,1]]\n    when ?, then [',', s[0,1], s[0,1]]\n    when ?[ then ['[', s[0,1], s[0,1]]\n    when ?] then [']', s[0,1], s[0,1]]\n    when ?n then nulltok(s)\n    when ?t then truetok(s)\n    when ?f then falsetok(s)\n    when ?\" then strtok(s)\n    when Spc, ?\\t, ?\\n, ?\\r then [:space, s[0,1], s[0,1]]\n    else\n      numtok(s)\n    end\n  end", "label": 4}
{"code": "function (item, state) {\n                var\n                    nextItem = this._getItem(state, state.index + 1),\n                    optional;\n                if (this._choice && -1 < state.choice) {\n                    optional = this._optionals[state.choice];\n                } else {\n                    optional = this._optionals[0];\n                }\n                ++state.count;\n                if (0 === item.max()) {\n                    // Unlimited\n                    this._reset(item, state);\n                    if (null !== nextItem && optional > state.index) {\n                        return PatternItem.WRITE_NEED_DATA;\n                    } else {\n                        // Last (or equivalent) so...\n                        return PatternItem.WRITE_MATCH;\n                    }\n                } else if (state.count === item.max()) {\n                    if (null === nextItem) {\n                        return PatternItem.WRITE_FINAL_MATCH;\n                    }\n                    ++state.index;\n                    this._reset(nextItem, state);\n                    if (optional <= state.index) {\n                        return PatternItem.WRITE_MATCH;\n                    }\n                }\n                return PatternItem.WRITE_NEED_DATA;\n            }", "label": 3}
{"code": "def attempt_rule(task_name, task_pattern, args, extensions, block, level)\n      sources = make_sources(task_name, task_pattern, extensions)\n      prereqs = sources.map { |source|\n        trace_rule level, \"Attempting Rule #{task_name} => #{source}\"\n        if File.exist?(source) || Rake::Task.task_defined?(source)\n          trace_rule level, \"(#{task_name} => #{source} ... EXIST)\"\n          source\n        elsif parent = enhance_with_matching_rule(source, level + 1)\n          trace_rule level, \"(#{task_name} => #{source} ... ENHANCE)\"\n          parent.name\n        else\n          trace_rule level, \"(#{task_name} => #{source} ... FAIL)\"\n          return nil\n        end\n      }\n      task = FileTask.define_task(task_name, { args => prereqs }, &block)\n      task.sources = prereqs\n      task\n    end", "label": 4}
{"code": "def main(prog_args=None):\n    \"\"\"\n    What do you expect?\n    \"\"\"\n    if prog_args is None:\n        prog_args = sys.argv\n\n    parser = optparse.OptionParser()\n    parser.usage = \"\"\"Usage: %[prog] [options] [<path>]\"\"\"\n    parser.add_option(\"-t\", \"--test-program\", dest=\"test_program\",\n        default=\"nose\", help=\"specifies the test-program to use. Valid values\"\n        \" include `nose` (or `nosetests`), `django`, `py` (for `py.test`), \"\n        '`symfony`, `jelix` `phpunit` and `tox`')\n    parser.add_option(\"-d\", \"--debug\", dest=\"debug\", action=\"store_true\",\n        default=False)\n    parser.add_option('-s', '--size-max', dest='size_max', default=25,\n        type=\"int\", help=\"Sets the maximum size (in MB) of files.\")\n    parser.add_option('--custom-args', dest='custom_args', default='',\n        type=\"str\",\n        help=\"Defines custom arguments to pass after the test program command\")\n    parser.add_option('--ignore-dirs', dest='ignore_dirs', default='',\n        type=\"str\",\n        help=\"Defines directories to ignore.  Use a comma-separated list.\")\n    parser.add_option('-y', '--quiet', dest='quiet', action=\"store_true\",\n        default=False,\n        help=\"Don't ask for any input.\")\n\n    opt, args = parser.parse_args(prog_args)\n\n    if args[1:]:\n        path = args[1]\n    else:\n        path = '.'\n\n\n    try:\n        watcher = Watcher(path, opt.test_program, opt.debug, opt.custom_args, \n            opt.ignore_dirs, opt.quiet)\n        watcher_file_size = watcher.file_sizes()\n        if watcher_file_size > opt.size_max:\n            message =  \"It looks like the total file size (%dMb) is larger  than the `max size` option (%dMb).\\nThis may slow down the file comparison process, and thus the daemon performances.\\nDo you wish to continue? [y/N] \" % (watcher_file_size, opt.size_max)\n\n            if not opt.quiet and not ask(message):\n                raise CancelDueToUserRequest('Ok, thx, bye...')\n\n        print \"Ready to watch file changes...\"\n        watcher.loop()\n    except (KeyboardInterrupt, SystemExit):\n        # Ignore when you exit via Crtl-C\n        pass\n    except Exception, msg:\n        print msg\n\n    print \"Bye\"", "label": 1}
{"code": "public List<Dependency> getModuleDependencies(final String moduleId, final FiltersHolder filters){\n        final DbModule module = moduleHandler.getModule(moduleId);\n        final DbOrganization organization = moduleHandler.getOrganization(module);\n        filters.setCorporateFilter(new CorporateFilter(organization));\n\n        return getModuleDependencies(module, filters, 1, new ArrayList<String>());\n    }", "label": 0}
{"code": "protected function fillScrutinizer() : self\n    {\n        if (isset($this->env['SCRUTINIZER']) && $this->env['SCRUTINIZER']) {\n            $this->readEnv['CI_JOB_ID'] = $this->env['SCRUTINIZER_INSPECTION_UUID'];\n            $this->readEnv['CI_BRANCH'] = $this->env['SCRUTINIZER_BRANCH'];\n            $this->readEnv['CI_PR_NUMBER'] = $this->env['SCRUTINIZER_PR_NUMBER'] ?? '';\n\n            // backup\n            $this->readEnv['CI_NAME'] = 'Scrutinizer';\n\n            $repo_slug = (string) $this->env['SCRUTINIZER_PROJECT'] ?? '';\n\n            if ($repo_slug) {\n                $slug_parts = explode('/', $repo_slug);\n\n                if ($this->readEnv['CI_PR_NUMBER']) {\n                    $this->readEnv['CI_PR_REPO_OWNER'] = $slug_parts[1];\n                    $this->readEnv['CI_PR_REPO_NAME'] = $slug_parts[2];\n                } else {\n                    $this->readEnv['CI_REPO_OWNER'] = $slug_parts[1];\n                    $this->readEnv['CI_REPO_NAME'] = $slug_parts[2];\n                }\n            }\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "private function sendEntry(Entry $entry)\n    {\n        if ($this->batchEnabled) {\n            $this->batchRunner->submitItem($this->identifier, $entry);\n            return;\n        }\n\n        $this->logger->write($entry);\n    }", "label": 2}
{"code": "func PgTableForeignKeys(db XODB, schema string, table string) ([]*ForeignKey, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`r.conname, ` + // ::varchar AS foreign_key_name\n\t\t`b.attname, ` + // ::varchar AS column_name\n\t\t`i.relname, ` + // ::varchar AS ref_index_name\n\t\t`c.relname, ` + // ::varchar AS ref_table_name\n\t\t`d.attname, ` + // ::varchar AS ref_column_name\n\t\t`0, ` + // ::integer AS key_id\n\t\t`0, ` + // ::integer AS seq_no\n\t\t`'', ` + // ::varchar AS on_update\n\t\t`'', ` + // ::varchar AS on_delete\n\t\t`'' ` + // ::varchar AS match\n\t\t`FROM pg_constraint r ` +\n\t\t`JOIN ONLY pg_class a ON a.oid = r.conrelid ` +\n\t\t`JOIN ONLY pg_attribute b ON b.attisdropped = false AND b.attnum = ANY(r.conkey) AND b.attrelid = r.conrelid ` +\n\t\t`JOIN ONLY pg_class i on i.oid = r.conindid ` +\n\t\t`JOIN ONLY pg_class c on c.oid = r.confrelid ` +\n\t\t`JOIN ONLY pg_attribute d ON d.attisdropped = false AND d.attnum = ANY(r.confkey) AND d.attrelid = r.confrelid ` +\n\t\t`JOIN ONLY pg_namespace n ON n.oid = r.connamespace ` +\n\t\t`WHERE r.contype = 'f' AND n.nspname = $1 AND a.relname = $2 ` +\n\t\t`ORDER BY r.conname, b.attname`\n\n\t// run query\n\tXOLog(sqlstr, schema, table)\n\tq, err := db.Query(sqlstr, schema, table)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer q.Close()\n\n\t// load results\n\tres := []*ForeignKey{}\n\tfor q.Next() {\n\t\tfk := ForeignKey{}\n\n\t\t// scan\n\t\terr = q.Scan(&fk.ForeignKeyName, &fk.ColumnName, &fk.RefIndexName, &fk.RefTableName, &fk.RefColumnName, &fk.KeyID, &fk.SeqNo, &fk.OnUpdate, &fk.OnDelete, &fk.Match)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tres = append(res, &fk)\n\t}\n\n\treturn res, nil\n}", "label": 5}
{"code": "public static tmglobal_tmsessionpolicy_binding[] get(nitro_service service) throws Exception{\n\t\ttmglobal_tmsessionpolicy_binding obj = new tmglobal_tmsessionpolicy_binding();\n\t\ttmglobal_tmsessionpolicy_binding response[] = (tmglobal_tmsessionpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function sinks(array $options = [])\n    {\n        $resultLimit = $this->pluck('resultLimit', $options, false);\n\n        return new ItemIterator(\n            new PageIterator(\n                function (array $sink) {\n                    return new Sink($this->connection, $sink['name'], $this->projectId, $sink);\n                },\n                [$this->connection, 'listSinks'],\n                $options + ['parent' => $this->formattedProjectName],\n                [\n                    'itemsKey' => 'sinks',\n                    'resultLimit' => $resultLimit\n                ]\n            )\n        );\n    }", "label": 2}
{"code": "function _gpfFuncUnsafe (params, source) {\n    var args;\n    if (!params.length) {\n        return _GpfFunc(source);\n    }\n    args = [].concat(params);\n    args.push(source);\n    return _GpfFunc.apply(null, args);\n}", "label": 3}
{"code": "def writeDataTable(self, file, type):\n        \"\"\" Writes agent data to an ReST table.  The 'type' argument may\n        be 'state', 'action' or 'reward'.\n        \"\"\"\n        agents = self.experiment.agents\n        numAgents = len(self.experiment.agents)\n\n        colWidth = 8\n        idxColWidth = 3\n\n        sep = (\"=\" * idxColWidth) + \" \" + \\\n            (\"=\" * colWidth + \" \") * numAgents + \"\\n\"\n\n        file.write(sep)\n\n        # Table column headers.\n        file.write(\"..\".rjust(idxColWidth) + \" \")\n        for agent in agents:\n            # The end of the name is typically the unique part.\n            file.write(agent.name[-colWidth:].center(colWidth) + \" \")\n        file.write(\"\\n\")\n\n        file.write(sep)\n\n        # Table values.\n        if agents:\n            rows, _ = agents[0].history.getField( type ).shape\n        else:\n            rows, _ = (0, 0)\n\n        for sequence in range( min(rows, 999) ):\n            file.write( str(sequence + 1).rjust(idxColWidth) + \" \" )\n\n            for agent in agents:\n                field = agent.history.getField( type )\n                # FIXME: Handle multiple state values.\n                file.write(\"%8.3f \" % field[sequence, 0])\n\n            file.write(\"\\n\")\n\n        file.write(sep)", "label": 1}
{"code": "def constantize( str )\n      str.to_s.split(/[-_]/).map { |v| v.capitalize }.to_s\n    end", "label": 4}
{"code": "func satisfiesPodFilter(pod v1alpha.Pod, filter v1alpha.PodFilter) bool {\n\t// Filter according to the ID.\n\tif len(filter.Ids) > 0 {\n\t\ts := set.NewString(filter.Ids...)\n\t\tif !s.Has(pod.Id) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Filter according to the state.\n\tif len(filter.States) > 0 {\n\t\tfoundState := false\n\t\tfor _, state := range filter.States {\n\t\t\tif pod.State == state {\n\t\t\t\tfoundState = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !foundState {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Filter according to the app names.\n\tif len(filter.AppNames) > 0 {\n\t\ts := set.NewString()\n\t\tfor _, app := range pod.Apps {\n\t\t\ts.Insert(app.Name)\n\t\t}\n\t\tif !s.HasAll(filter.AppNames...) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Filter according to the image IDs.\n\tif len(filter.ImageIds) > 0 {\n\t\ts := set.NewString()\n\t\tfor _, app := range pod.Apps {\n\t\t\ts.Insert(app.Image.Id)\n\t\t}\n\t\tif !s.HasAll(filter.ImageIds...) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Filter according to the network names.\n\tif len(filter.NetworkNames) > 0 {\n\t\ts := set.NewString()\n\t\tfor _, network := range pod.Networks {\n\t\t\ts.Insert(network.Name)\n\t\t}\n\t\tif !s.HasAll(filter.NetworkNames...) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Filter according to the annotations.\n\tif len(filter.Annotations) > 0 {\n\t\tif !containsAllKeyValues(pod.Annotations, filter.Annotations) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Filter according to the cgroup.\n\tif len(filter.Cgroups) > 0 {\n\t\ts := set.NewString(filter.Cgroups...)\n\t\tif !s.Has(pod.Cgroup) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Filter if pod's cgroup is a prefix of the passed in cgroup\n\tif len(filter.PodSubCgroups) > 0 {\n\t\tmatched := false\n\t\tif pod.Cgroup != \"\" {\n\t\t\tfor _, cgroup := range filter.PodSubCgroups {\n\t\t\t\tif strings.HasPrefix(cgroup, pod.Cgroup) {\n\t\t\t\t\tmatched = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif !matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}", "label": 5}
{"code": "function validateRequestParams(req, resource, method, adapter) {\n        req = req || {};\n\n        var params = resource.params || {};\n        var methodParams = _.extend({}, params[method], params[adapter + '.' + method] );\n        var requiredParams = methodParams.required || [];\n        var eitherorParams = methodParams.eitheror || [];\n        var optional = methodParams.optional || [];\n        var eitherorExists, param;\n        var err, reqObj;\n\n        // make sure all the required params are there\n        for (var i = 0; i < requiredParams.length; i++) {\n            param = requiredParams[i];\n\n            if (req[param] === undefined || req[param] === null) {\n                reqObj = _.extend({}, req);\n                delete reqObj.resource;\n                err = new Error('Invalid request');\n                err.code = 'invalid_request_error';\n                err.message = resource.name + ' ' + method + ' missing ' + param +\n                    '. Required params: ' + JSON.stringify(requiredParams) +\n                    ' req is: ' + JSON.stringify(reqObj);\n                return Q.reject(err);\n            }\n        }\n\n        // make sure at least one of the eitheror params are there\n        if (eitherorParams.length) {\n            eitherorExists = false;\n\n            _.each(eitherorParams, function (eitherorParam) {\n                if (req[eitherorParam]) { eitherorExists = true; }\n            });\n\n            if (!eitherorExists) {\n                delete req.caller;\n                delete req.resource;\n                err = new Error('Invalid request');\n                err.code = 'invalid_request_error';\n                err.message = resource.name + ' ' + method +\n                    ' must have one of the following params: ' + JSON.stringify(eitherorParams) +\n                    ' request is ' + JSON.stringify(req);\n                return Q.reject(err);\n            }\n        }\n\n        // now loop through the values and error if invalid param in there; also do JSON parsing if an object\n        var validParams = requiredParams.concat(eitherorParams, optional,\n            ['lang', 'caller', 'resource', 'method', 'auth', 'noemit']);\n        for (var key in req) {\n            if (req.hasOwnProperty(key)) {\n                if (validParams.indexOf(key) < 0) {\n                    delete req.caller;\n                    delete req.resource;\n                    err = new Error('Invalid request');\n                    err.code = 'invalid_request_error';\n                    err.message = 'For ' + resource.name + ' ' + method + ' the key ' +\n                        key + ' is not allowed. Valid params: ' + JSON.stringify(validParams) +\n                        ' request is ' + JSON.stringify(req);\n                    return Q.reject(err);\n                }\n            }\n        }\n\n        // no errors, so return resolved promise\n        return new Q();\n    }", "label": 3}
{"code": "private function killExistingFpm(): void\n    {\n        // Never seen this happen but just in case\n        if (! file_exists(self::PID_FILE)) {\n            unlink(self::SOCKET);\n            return;\n        }\n\n        $pid = (int) file_get_contents(self::PID_FILE);\n\n        // Never seen this happen but just in case\n        if ($pid <= 0) {\n            echo \"PHP-FPM's PID file contained an invalid PID, assuming PHP-FPM isn't running.\\n\";\n            unlink(self::SOCKET);\n            unlink(self::PID_FILE);\n            return;\n        }\n\n        // Check if the process is running\n        if (posix_getpgid($pid) === false) {\n            // PHP-FPM is not running anymore, we can cleanup\n            unlink(self::SOCKET);\n            unlink(self::PID_FILE);\n            return;\n        }\n\n        echo \"PHP-FPM seems to be running already, this might be because Lambda stopped the bootstrap process but didn't leave us an opportunity to stop PHP-FPM. Stopping PHP-FPM now to restart from a blank slate.\\n\";\n\n        // PHP-FPM is running, let's try to kill it properly\n        $result = posix_kill($pid, SIGTERM);\n        if ($result === false) {\n            echo \"PHP-FPM's PID file contained a PID that doesn't exist, assuming PHP-FPM isn't running.\\n\";\n            unlink(self::SOCKET);\n            unlink(self::PID_FILE);\n            return;\n        }\n\n        $this->waitUntilStopped($pid);\n        unlink(self::SOCKET);\n        unlink(self::PID_FILE);\n    }", "label": 2}
{"code": "def pipeline uri, requests, &block # :yields: responses\n    connection_for uri do |connection|\n      connection.http.pipeline requests, &block\n    end\n  end", "label": 4}
{"code": "private function getSigningCredentials(ConnectionInterface $connection, array $options)\n    {\n        $keyFilePath = isset($options['keyFilePath'])\n            ? $options['keyFilePath']\n            : null;\n\n        if ($keyFilePath) {\n            if (!file_exists($keyFilePath)) {\n                throw new \\InvalidArgumentException(sprintf(\n                    'Keyfile path %s does not exist.',\n                    $keyFilePath\n                ));\n            }\n\n            $options['keyFile'] = self::jsonDecode(file_get_contents($keyFilePath), true);\n        }\n\n        $rw = $connection->requestWrapper();\n\n        $keyFile = isset($options['keyFile'])\n            ? $options['keyFile']\n            : null;\n        if ($keyFile) {\n            $scopes = isset($options['scopes'])\n                ? $options['scopes']\n                : $rw->scopes();\n\n            $credentials = CredentialsLoader::makeCredentials($scopes, $keyFile);\n        } else {\n            $credentials = $rw->getCredentialsFetcher();\n        }\n\n        if (!($credentials instanceof SignBlobInterface)) {\n            throw new \\RuntimeException(sprintf(\n                'Credentials object is of type `%s` and is not valid for signing.',\n                get_class($credentials)\n            ));\n        }\n\n        unset(\n            $options['keyFilePath'],\n            $options['keyFile'],\n            $options['scopes']\n        );\n\n        return [$credentials, $options];\n    }", "label": 2}
{"code": "public static void serialize(final File folder, final String content, final String fileName) throws IOException {\n        if (!folder.exists()) {\n            folder.mkdirs();\n        }\n\n        final File output = new File(folder, fileName);\n\n        try (\n                final FileWriter writer = new FileWriter(output);\n        ) {\n            writer.write(content);\n            writer.flush();\n        } catch (Exception e) {\n            throw new IOException(\"Failed to serialize the notification in folder \" + folder.getPath(), e);\n        }\n    }", "label": 0}
{"code": "def license_content_sources(files)\n      paths = Array(files).map do |file|\n        next file[:uri] if file[:uri]\n\n        path = dir_path.join(file[:dir], file[:name])\n        normalize_source_path(path)\n      end\n\n      paths.join(\", \")\n    end", "label": 4}
{"code": "func (c *TokenCommand) List(client auth.ClientI) error {\n\ttokens, err := client.GetTokens()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif len(tokens) == 0 {\n\t\tfmt.Println(\"No active tokens found.\")\n\t\treturn nil\n\t}\n\n\t// Sort by expire time.\n\tsort.Slice(tokens, func(i, j int) bool { return tokens[i].Expiry().Unix() < tokens[j].Expiry().Unix() })\n\n\tif c.format == teleport.Text {\n\t\ttokensView := func() string {\n\t\t\ttable := asciitable.MakeTable([]string{\"Token\", \"Type\", \"Expiry Time (UTC)\"})\n\t\t\tfor _, t := range tokens {\n\t\t\t\texpiry := \"never\"\n\t\t\t\tif t.Expiry().Unix() > 0 {\n\t\t\t\t\texpiry = t.Expiry().Format(time.RFC822)\n\t\t\t\t}\n\t\t\t\ttable.AddRow([]string{t.GetName(), t.GetRoles().String(), expiry})\n\t\t\t}\n\t\t\treturn table.AsBuffer().String()\n\t\t}\n\t\tfmt.Printf(tokensView())\n\t} else {\n\t\tdata, err := json.MarshalIndent(tokens, \"\", \"  \")\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err, \"failed to marshal tokens\")\n\t\t}\n\t\tfmt.Printf(string(data))\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function _gpfDispatchEvent (event, params) {\n    /*jshint validthis:true*/ // will be invoked as an object method\n    var listeners = this._eventDispatcherListeners,\n        eventObj,\n        type,\n        eventListeners;\n    if (!listeners) {\n        return this; // No listeners at all\n    }\n    if (event instanceof _GpfEvent) {\n        eventObj = event;\n        type = event.type;\n    } else {\n        type = event;\n    }\n    eventListeners = this._eventDispatcherListeners[type];\n    if (undefined === eventListeners) {\n        return this; // Nothing listeners for this event\n    }\n    if (!eventObj) {\n        eventObj = new _GpfEvent(type, params, this);\n    }\n    _gpfTriggerListeners(eventObj, eventListeners);\n    return eventObj;\n}", "label": 3}
{"code": "func (c *Call) Return(rets ...interface{}) *Call {\n\tc.t.Helper()\n\n\tmt := c.methodType\n\tif len(rets) != mt.NumOut() {\n\t\tc.t.Fatalf(\"wrong number of arguments to Return for %T.%v: got %d, want %d [%s]\",\n\t\t\tc.receiver, c.method, len(rets), mt.NumOut(), c.origin)\n\t}\n\tfor i, ret := range rets {\n\t\tif got, want := reflect.TypeOf(ret), mt.Out(i); got == want {\n\t\t\t// Identical types; nothing to do.\n\t\t} else if got == nil {\n\t\t\t// Nil needs special handling.\n\t\t\tswitch want.Kind() {\n\t\t\tcase reflect.Chan, reflect.Func, reflect.Interface, reflect.Map, reflect.Ptr, reflect.Slice:\n\t\t\t\t// ok\n\t\t\tdefault:\n\t\t\t\tc.t.Fatalf(\"argument %d to Return for %T.%v is nil, but %v is not nillable [%s]\",\n\t\t\t\t\ti, c.receiver, c.method, want, c.origin)\n\t\t\t}\n\t\t} else if got.AssignableTo(want) {\n\t\t\t// Assignable type relation. Make the assignment now so that the generated code\n\t\t\t// can return the values with a type assertion.\n\t\t\tv := reflect.New(want).Elem()\n\t\t\tv.Set(reflect.ValueOf(ret))\n\t\t\trets[i] = v.Interface()\n\t\t} else {\n\t\t\tc.t.Fatalf(\"wrong type of argument %d to Return for %T.%v: %v is not assignable to %v [%s]\",\n\t\t\t\ti, c.receiver, c.method, got, want, c.origin)\n\t\t}\n\t}\n\n\tc.addAction(func([]interface{}) []interface{} {\n\t\treturn rets\n\t})\n\n\treturn c\n}", "label": 5}
{"code": "def run_cutadapt(job, fastqs, univ_options, cutadapt_options):\n    \"\"\"\n    Runs cutadapt on the input RNA fastq files.\n\n    :param list fastqs: List of fsIDs for input an RNA-Seq fastq pair\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict cutadapt_options: Options specific to cutadapt\n    :return: List of fsIDs of cutadapted fastqs\n    :rtype: list[toil.fileStore.FileID]\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'rna_1.fastq': fastqs[0],\n        'rna_2.fastq': fastqs[1]}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n    # Handle gzipped file\n    gz = '.gz' if is_gzipfile(input_files['rna_1.fastq']) else ''\n    if gz:\n        for read_file in 'rna_1.fastq', 'rna_2.fastq':\n            os.symlink(read_file, read_file + gz)\n            input_files[read_file + gz] = input_files[read_file] + gz\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n    parameters = ['-a', cutadapt_options['a'],  # Fwd read 3' adapter\n                  '-A', cutadapt_options['A'],  # Rev read 3' adapter\n                  '-m', '35',  # Minimum size of read\n                  '-o', docker_path('rna_cutadapt_1.fastq.gz'),  # Output for R1\n                  '-p', docker_path('rna_cutadapt_2.fastq.gz'),  # Output for R2\n                  input_files['rna_1.fastq' + gz],\n                  input_files['rna_2.fastq' + gz]]\n    docker_call(tool='cutadapt', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=cutadapt_options['version'])\n    output_files = []\n    for fastq_file in ['rna_cutadapt_1.fastq.gz', 'rna_cutadapt_2.fastq.gz']:\n        output_files.append(job.fileStore.writeGlobalFile('/'.join([work_dir, fastq_file])))\n    job.fileStore.logToMaster('Ran cutadapt on %s successfully' % univ_options['patient'])\n    return output_files", "label": 1}
{"code": "function Pager(ref, initialCount) {\n\n  if (arguments.length < 1) {\n    throw new Error('Not enough arguments to Pager');\n  }\n\n  this._mainRef = ref.ref();\n  this._resetCurrentOperation();\n\n  this.hasNext = true;\n  this.hasPrevious = false;\n\n  var promise;\n  if (initialCount) {\n    promise = this.next(initialCount);\n  } else {\n    promise = Fireproof.Promise.resolve([]);\n  }\n   \n  this.then = promise.then.bind(promise);\n\n}", "label": 3}
{"code": "def routes(path = nil, &blk)\n      if path or block_given?\n        @routes = Config::Routes.new(root, path, &blk)\n      else\n        @routes\n      end\n    end", "label": 4}
{"code": "public static sslservicegroup_sslcertkey_binding[] get(nitro_service service, String servicegroupname) throws Exception{\n\t\tsslservicegroup_sslcertkey_binding obj = new sslservicegroup_sslcertkey_binding();\n\t\tobj.set_servicegroupname(servicegroupname);\n\t\tsslservicegroup_sslcertkey_binding response[] = (sslservicegroup_sslcertkey_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def tree_at(line, column)\n      # offset = Position.line_char_to_offset(@code, line, column)\n      position = Position.new(line, column)\n      stack = []\n      inner_tree_at @node, position, stack\n      stack\n    end", "label": 4}
{"code": "def write_bus_data(self, file):\n        \"\"\" Writes bus data as CSV.\n        \"\"\"\n        writer = self._get_writer(file)\n        writer.writerow(BUS_ATTRS)\n        for bus in self.case.buses:\n            writer.writerow([getattr(bus, attr) for attr in BUS_ATTRS])", "label": 1}
{"code": "def appium_server_version\n      @core.appium_server_version\n    rescue Selenium::WebDriver::Error::WebDriverError => ex\n      raise ::Appium::Core::Error::ServerError unless ex.message.include?('content-type=\"\"')\n\n      # server (TestObject for instance) does not respond to status call\n      {}\n    end", "label": 4}
{"code": "def run_auto_cmds(run_level)\n      safely do\n        auto_cmds_for(run_level).each { |cmd| cmd.new(self).execute }\n      end\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, cacheselector resource) throws Exception {\n\t\tcacheselector updateresource = new cacheselector();\n\t\tupdateresource.selectorname = resource.selectorname;\n\t\tupdateresource.rule = resource.rule;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (c *Manager) GetLibraryItem(ctx context.Context, id string) (*Item, error) {\n\turl := internal.URL(c, internal.LibraryItemPath).WithID(id)\n\tvar res Item\n\treturn &res, c.Do(ctx, url.Request(http.MethodGet), &res)\n}", "label": 5}
{"code": "func (c *Client) grpc() (proto.AuthServiceClient, error) {\n\t// it's ok to lock here, because Dial below is not locking\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tif c.grpcClient != nil {\n\t\treturn c.grpcClient, nil\n\t}\n\tdialer := grpc.WithDialer(func(addr string, timeout time.Duration) (net.Conn, error) {\n\t\tif c.isClosed() {\n\t\t\treturn nil, trace.ConnectionProblem(nil, \"client is closed\")\n\t\t}\n\t\tc, err := c.DialContext(context.TODO(), \"tcp\", addr)\n\t\tif err != nil {\n\t\t\tlog.Debugf(\"Dial to addr %v failed: %v.\", addr, err)\n\t\t}\n\t\treturn c, err\n\t})\n\ttlsConfig := c.TLS.Clone()\n\ttlsConfig.NextProtos = []string{http2.NextProtoTLS}\n\tlog.Debugf(\"GRPC(): keep alive %v count: %v.\", c.KeepAlivePeriod, c.KeepAliveCount)\n\tconn, err := grpc.Dial(teleport.APIDomain,\n\t\tdialer,\n\t\tgrpc.WithTransportCredentials(credentials.NewTLS(tlsConfig)),\n\t\tgrpc.WithKeepaliveParams(keepalive.ClientParameters{\n\t\t\tTime:    c.KeepAlivePeriod,\n\t\t\tTimeout: c.KeepAlivePeriod * time.Duration(c.KeepAliveCount),\n\t\t}),\n\t)\n\tif err != nil {\n\t\treturn nil, trail.FromGRPC(err)\n\t}\n\tc.conn = conn\n\tc.grpcClient = proto.NewAuthServiceClient(c.conn)\n\n\treturn c.grpcClient, nil\n}", "label": 5}
{"code": "func (process *TeleportProcess) StartShutdown(ctx context.Context) context.Context {\n\tprocess.BroadcastEvent(Event{Name: TeleportExitEvent, Payload: ctx})\n\tlocalCtx, cancel := context.WithCancel(ctx)\n\tgo func() {\n\t\tdefer cancel()\n\t\tprocess.Supervisor.Wait()\n\t\tprocess.Debugf(\"All supervisor functions are completed.\")\n\t\tlocalAuth := process.getLocalAuth()\n\t\tif localAuth != nil {\n\t\t\tif err := process.localAuth.Close(); err != nil {\n\t\t\t\tprocess.Warningf(\"Failed closing auth server: %v.\", err)\n\t\t\t}\n\t\t}\n\t}()\n\tgo process.printShutdownStatus(localCtx)\n\treturn localCtx\n}", "label": 5}
{"code": "func (h *Handle) SetValue(value []byte) error {\n\treturn json.Unmarshal(value, h)\n}", "label": 5}
{"code": "function pluckModels (cell, modelPath, models, cellDefinitions) {\n  cell = extendCell(cell, cellDefinitions)\n  if (_.isObject(cell.model)) {\n    const addedPath = appendModelPath(modelPath.modelPath(), cell.id, cell.internal)\n    models[addedPath] = cell.model\n  } else if (cell.children) { // recurse on objects\n    cell.children.forEach((cell) => {\n      const newPath = typeof cell.model === 'string' ? modelPath.concat(cell.model) : modelPath\n      pluckModels(cell, newPath, models, cellDefinitions)\n    })\n  } else if (cell.arrayOptions) { // recurse on arrays\n    pluckFromArrayOptions(cell, modelPath, models, cellDefinitions)\n  }\n}", "label": 3}
{"code": "def to_bolt_level(level_num)\n      level_str = Log4r::LNAMES[level_num]&.downcase || 'debug'\n      if level_str =~ /debug/\n        :debug\n      else\n        level_str.to_sym\n      end\n    end", "label": 4}
{"code": "public function getElement($className)\n    {\n        if ($this->classCache === null) {\n            $this->initialize();\n        }\n\n        if (isset($this->classCache[$className])) {\n            return $this->classCache[$className];\n        }\n\n        $result = $this->loadMappingFile($this->locator->findMappingFile($className));\n        if (! isset($result[$className])) {\n            throw MappingException::invalidMappingFile($className, str_replace('\\\\', '.', $className) . $this->locator->getFileExtension());\n        }\n\n        $this->classCache[$className] = $result[$className];\n\n        return $result[$className];\n    }", "label": 2}
{"code": "private function getSnapshot(ConnectionInterface $connection, $name, array $options = [])\n    {\n        if (isset($options['readTime'])) {\n            if (!($options['readTime'] instanceof Timestamp)) {\n                throw new \\InvalidArgumentException(sprintf(\n                    '`$options.readTime` must be an instance of %s',\n                    Timestamp::class\n                ));\n            }\n\n            $options['readTime'] = $options['readTime']->formatForApi();\n        }\n\n        $snapshot = $connection->batchGetDocuments([\n            'database' => $this->databaseFromName($name),\n            'documents' => [$name],\n        ] + $options)->current();\n\n        if (!isset($snapshot['found'])) {\n            throw new NotFoundException(sprintf(\n                'Document %s does not exist',\n                $name\n            ));\n        }\n\n        return $snapshot['found'];\n    }", "label": 2}
{"code": "function filterNamedImportOrExportCompletionItems(exportsOfModule, namedImportsOrExports) {\n                var existingImportsOrExports = ts.createMap();\n                for (var _i = 0, namedImportsOrExports_1 = namedImportsOrExports; _i < namedImportsOrExports_1.length; _i++) {\n                    var element = namedImportsOrExports_1[_i];\n                    // If this is the current item we are editing right now, do not filter it out\n                    if (element.getStart() <= position && position <= element.getEnd()) {\n                        continue;\n                    }\n                    var name_41 = element.propertyName || element.name;\n                    existingImportsOrExports[name_41.text] = true;\n                }\n                if (!ts.someProperties(existingImportsOrExports)) {\n                    return ts.filter(exportsOfModule, function (e) { return e.name !== \"default\"; });\n                }\n                return ts.filter(exportsOfModule, function (e) { return e.name !== \"default\" && !existingImportsOrExports[e.name]; });\n            }", "label": 3}
{"code": "function postJson({ url, payload, contentType, useBearer }) {\n  return ajax({\n    url,\n    method: 'post',\n    body: JSON.stringify( payload || {} ),\n    contentType,\n    useBearer\n  })\n}", "label": 3}
{"code": "public static void addJarToClasspath(ClassLoader loader, URL url) throws IOException,\n      IllegalAccessException, IllegalArgumentException, InvocationTargetException,\n      NoSuchMethodException, SecurityException {\n    URLClassLoader sysloader = (URLClassLoader) loader;\n    Class<?> sysclass = URLClassLoader.class;\n\n    Method method =\n        sysclass.getDeclaredMethod(MyClasspathUtils.ADD_URL_METHOD, new Class[] {URL.class});\n    method.setAccessible(true);\n    method.invoke(sysloader, new Object[] {url});\n\n  }", "label": 0}
{"code": "def url(name, *args)\n      Utils::Escape::SafeString.new(@routes.url(name, *args))\n    end", "label": 4}
{"code": "func OptionGeneric(generic map[string]interface{}) SandboxOption {\n\treturn func(sb *sandbox) {\n\t\tif sb.config.generic == nil {\n\t\t\tsb.config.generic = make(map[string]interface{}, len(generic))\n\t\t}\n\t\tfor k, v := range generic {\n\t\t\tsb.config.generic[k] = v\n\t\t}\n\t}\n}", "label": 5}
{"code": "function Client(options) {\n  this.accessID = options.accessID;\n  this.accessKey = options.accessKey;\n  this.signatureMethod = options.signatureMethod || 'HmacSHA1';\n  this.signatureVersion = options.signatureVersion || '1';\n  this.APIVersion = options.APIVersion || '2013-05-10';\n  this.APIHost = options.APIHost || 'http://ots.aliyuncs.com';\n  // protocol: 'http:'\n  // hostname: 'service.ots.aliyun.com'\n  // port: undefined\n  this.APIHostInfo = urlparse(this.APIHost);\n  this.requestAgent = options.agent || null;\n  this.requestTimeout = options.requestTimeout || 5000;\n  var dnsCacheTime = options.dnsCacheTime || 10000;\n  this.dns = CacheDNS.create({cacheTime: dnsCacheTime});\n  this.vip = options.vip;\n}", "label": 3}
{"code": "func (d *Decoder) popEOF() bool {\n\tif d.stk == nil || d.stk.kind != stkEOF {\n\t\treturn false\n\t}\n\td.pop()\n\treturn true\n}", "label": 5}
{"code": "public boolean canBeLinked(D declaration, ServiceReference<S> declarationBinderRef) {\n        // Evaluate the target filter of the ImporterService on the Declaration\n        Filter filter = bindersManager.getTargetFilter(declarationBinderRef);\n        return filter.matches(declaration.getMetadata());\n    }", "label": 0}
{"code": "func PgLargeobjectByLoidPageno(db XODB, loid pgtypes.Oid, pageno int) (*PgLargeobject, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, loid, pageno, data ` +\n\t\t`FROM pg_catalog.pg_largeobject ` +\n\t\t`WHERE loid = $1 AND pageno = $2`\n\n\t// run query\n\tXOLog(sqlstr, loid, pageno)\n\tpl := PgLargeobject{}\n\n\terr = db.QueryRow(sqlstr, loid, pageno).Scan(&pl.Tableoid, &pl.Cmax, &pl.Xmax, &pl.Cmin, &pl.Xmin, &pl.Ctid, &pl.Loid, &pl.Pageno, &pl.Data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pl, nil\n}", "label": 5}
{"code": "protected function basic_get_ok($reader, $message)\n    {\n        $delivery_tag = $reader->read_longlong();\n        $redelivered = $reader->read_bit();\n        $exchange = $reader->read_shortstr();\n        $routing_key = $reader->read_shortstr();\n        $message_count = $reader->read_long();\n\n        $message->delivery_info = array(\n            'delivery_tag' => $delivery_tag,\n            'redelivered' => $redelivered,\n            'exchange' => $exchange,\n            'routing_key' => $routing_key,\n            'message_count' => $message_count\n        );\n\n        return $message;\n    }", "label": 2}
{"code": "function getSymbolScope(symbol) {\n                // If this is the symbol of a named function expression or named class expression,\n                // then named references are limited to its own scope.\n                var valueDeclaration = symbol.valueDeclaration;\n                if (valueDeclaration && (valueDeclaration.kind === 179 /* FunctionExpression */ || valueDeclaration.kind === 192 /* ClassExpression */)) {\n                    return valueDeclaration;\n                }\n                // If this is private property or method, the scope is the containing class\n                if (symbol.flags & (4 /* Property */ | 8192 /* Method */)) {\n                    var privateDeclaration = ts.forEach(symbol.getDeclarations(), function (d) { return (d.flags & 8 /* Private */) ? d : undefined; });\n                    if (privateDeclaration) {\n                        return ts.getAncestor(privateDeclaration, 221 /* ClassDeclaration */);\n                    }\n                }\n                // If the symbol is an import we would like to find it if we are looking for what it imports.\n                // So consider it visible outside its declaration scope.\n                if (symbol.flags & 8388608 /* Alias */) {\n                    return undefined;\n                }\n                // If symbol is of object binding pattern element without property name we would want to\n                // look for property too and that could be anywhere\n                if (isObjectBindingPatternElementWithoutPropertyName(symbol)) {\n                    return undefined;\n                }\n                // if this symbol is visible from its parent container, e.g. exported, then bail out\n                // if symbol correspond to the union property - bail out\n                if (symbol.parent || (symbol.flags & 268435456 /* SyntheticProperty */)) {\n                    return undefined;\n                }\n                var scope;\n                var declarations = symbol.getDeclarations();\n                if (declarations) {\n                    for (var _i = 0, declarations_9 = declarations; _i < declarations_9.length; _i++) {\n                        var declaration = declarations_9[_i];\n                        var container = getContainerNode(declaration);\n                        if (!container) {\n                            return undefined;\n                        }\n                        if (scope && scope !== container) {\n                            // Different declarations have different containers, bail out\n                            return undefined;\n                        }\n                        if (container.kind === 256 /* SourceFile */ && !ts.isExternalModule(container)) {\n                            // This is a global variable and not an external module, any declaration defined\n                            // within this scope is visible outside the file\n                            return undefined;\n                        }\n                        // The search scope is the container node\n                        scope = container;\n                    }\n                }\n                return scope;\n            }", "label": 3}
{"code": "func (s *remoteSite) handleHeartbeat(conn *remoteConn, ch ssh.Channel, reqC <-chan *ssh.Request) {\n\tdefer func() {\n\t\ts.Infof(\"Cluster connection closed.\")\n\t\tconn.Close()\n\t}()\n\tfor {\n\t\tselect {\n\t\tcase <-s.ctx.Done():\n\t\t\ts.Infof(\"closing\")\n\t\t\treturn\n\t\tcase req := <-reqC:\n\t\t\tif req == nil {\n\t\t\t\ts.Infof(\"Cluster agent disconnected.\")\n\t\t\t\tconn.markInvalid(trace.ConnectionProblem(nil, \"agent disconnected\"))\n\t\t\t\tif !s.hasValidConnections() {\n\t\t\t\t\ts.Debugf(\"Deleting connection record.\")\n\t\t\t\t\ts.deleteConnectionRecord()\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t\tvar timeSent time.Time\n\t\t\tvar roundtrip time.Duration\n\t\t\tif req.Payload != nil {\n\t\t\t\tif err := timeSent.UnmarshalText(req.Payload); err == nil {\n\t\t\t\t\troundtrip = s.srv.Clock.Now().Sub(timeSent)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif roundtrip != 0 {\n\t\t\t\ts.WithFields(log.Fields{\"latency\": roundtrip}).Debugf(\"ping <- %v\", conn.conn.RemoteAddr())\n\t\t\t} else {\n\t\t\t\ts.Debugf(\"Ping <- %v.\", conn.conn.RemoteAddr())\n\t\t\t}\n\t\t\ttm := time.Now().UTC()\n\t\t\tconn.setLastHeartbeat(tm)\n\t\t\tgo s.registerHeartbeat(tm)\n\t\t// since we block on select, time.After is re-created everytime we process a request.\n\t\tcase <-time.After(defaults.ReverseTunnelOfflineThreshold):\n\t\t\tconn.markInvalid(trace.ConnectionProblem(nil, \"no heartbeats for %v\", defaults.ReverseTunnelOfflineThreshold))\n\t\t}\n\t}\n}", "label": 5}
{"code": "func (a *HistoricalApi) availablePodMetrics(request *restful.Request, response *restful.Response) {\n\tkey := core.HistoricalKey{\n\t\tObjectType:    core.MetricSetTypePod,\n\t\tNamespaceName: request.PathParameter(\"namespace-name\"),\n\t\tPodName:       request.PathParameter(\"pod-name\"),\n\t}\n\ta.processMetricNamesRequest(key, response)\n}", "label": 5}
{"code": "public function setLabelAnnotations($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Vision\\V1\\EntityAnnotation::class);\n        $this->label_annotations = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def has_layer(fcollection):\n    \"\"\"Returns true for a multi-layer dict of FeatureCollections.\"\"\"\n    for val in six.viewvalues(fcollection):\n        if has_features(val):\n            return True\n    return False", "label": 1}
{"code": "public function decodeType(string $globalID): string\n    {\n        [$type, $id] = self::decode($globalID);\n\n        return $type;\n    }", "label": 2}
{"code": "def RfiltersBM(dataset,database,host=rbiomart_host):\n    \"\"\"\n    Lists BioMart filters through a RPY2 connection.\n\n    :param dataset: a dataset listed in RdatasetsBM()\n    :param database: a database listed in RdatabasesBM()\n    :param host: address of the host server, default='www.ensembl.org'\n\n    :returns: nothing\n\n    \"\"\"\n    biomaRt = importr(\"biomaRt\")\n    ensemblMart=biomaRt.useMart(database, host=host)\n    ensembl=biomaRt.useDataset(dataset, mart=ensemblMart)\n    print(biomaRt.listFilters(ensembl))", "label": 1}
{"code": "func (ph *Placeholders) SetValue(name string, _type string, value interface{}) {\n\tif ph.Value(name) == nil {\n\t\tp := Placeholder{\n\t\t\tName:  name,\n\t\t\tType:  _type,\n\t\t\tValue: value,\n\t\t}\n\t\t*ph = append(*ph, p)\n\t} else {\n\t\tfor i := 0; i < len(*ph); i++ {\n\t\t\tif (*ph)[i].Name == name {\n\t\t\t\t(*ph)[i].Type = _type\n\t\t\t\t(*ph)[i].Value = value\n\t\t\t}\n\t\t}\n\t}\n}", "label": 5}
{"code": "function checkChain(value, chain, baton, callback) {\n  var funs = chain.validators.map(function(i) {\n    return i.func;\n  });\n\n  function _reduce(memo, validator, callback) {\n    validator(memo, baton, function(err, result) {\n      var message;\n      if (err) {\n        if (err.hasOwnProperty(message)) {\n          message = err.message;\n        } else {\n          message = err;\n        }\n        callback(message);\n      } else {\n        callback(null, result);\n      }\n    });\n  }\n\n  async.reduce(funs, value, _reduce, callback);\n}", "label": 3}
{"code": "public function build(Shape $shape, array $args)\n    {\n        $xml = new XMLWriter();\n        $xml->openMemory();\n        $xml->startDocument('1.0', 'UTF-8');\n        $this->format($shape, $shape['locationName'] ?: $shape['name'], $args, $xml);\n        $xml->endDocument();\n\n        return $xml->outputMemory();\n    }", "label": 2}
{"code": "func (fs *FSLocalKeyStore) GetKnownHostKeys(hostname string) ([]ssh.PublicKey, error) {\n\tbytes, err := ioutil.ReadFile(filepath.Join(fs.KeyDir, fileNameKnownHosts))\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn nil, nil\n\t\t}\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar (\n\t\tpubKey    ssh.PublicKey\n\t\tretval    []ssh.PublicKey = make([]ssh.PublicKey, 0)\n\t\thosts     []string\n\t\thostMatch bool\n\t)\n\tfor err == nil {\n\t\t_, hosts, pubKey, _, bytes, err = ssh.ParseKnownHosts(bytes)\n\t\tif err == nil {\n\t\t\thostMatch = (hostname == \"\")\n\t\t\tif !hostMatch {\n\t\t\t\tfor i := range hosts {\n\t\t\t\t\tif hosts[i] == hostname {\n\t\t\t\t\t\thostMatch = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif hostMatch {\n\t\t\t\tretval = append(retval, pubKey)\n\t\t\t}\n\t\t}\n\t}\n\tif err != io.EOF {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn retval, nil\n}", "label": 5}
{"code": "public void run()\r\n    {    \t\r\n    \tSystem.out.println(AsciiSplash.getSplashArt());\r\n        System.out.println(\"Welcome to the OJB PB tutorial application\");\r\n        System.out.println();\r\n        // never stop (there is a special use case to quit the application)\r\n        while (true)\r\n        {\r\n            try\r\n            {\r\n                // select a use case and perform it\r\n                UseCase uc = selectUseCase();\r\n                uc.apply();\r\n            }\r\n            catch (Throwable t)\r\n            {\r\n                broker.close();\r\n                System.out.println(t.getMessage());\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public static boolean toBoolean(String value, boolean defaultValue)\r\n    {\r\n        return \"true\".equals(value) ? true : (\"false\".equals(value) ? false : defaultValue);\r\n    }", "label": 0}
{"code": "func (s *PresenceService) GetAuthServers() ([]services.Server, error) {\n\treturn s.getServers(services.KindAuthServer, authServersPrefix)\n}", "label": 5}
{"code": "function guessUserName(repo) {\n  // extract the host\n  const host = repo.match(/:\\/\\/([^/]+)/)[1];\n  const hostClean = host.replace(/\\./g, '_').toUpperCase();\n  // e.g. GITHUB_COM_CREDENTIALS\n  const envVar = process.env[`${hostClean}_CREDENTIALS`];\n  if (envVar) {\n    return envVar;\n  }\n  return process.env.PHOVEA_GITHUB_CREDENTIALS;\n}", "label": 3}
{"code": "function(value, attr, maxValue, model) {\n        if (!isNumber(value) || value > maxValue) {\n          return this.format(getMessageKey(this.msgKey, defaultMessages.max), this.formatLabel(attr, model), maxValue);\n        }\n      }", "label": 3}
{"code": "def pairparse(ts)\n    (typ, _, k), ts = ts[0], ts[1..-1]\n    if typ != :str\n      raise Error, \"unexpected #{k.inspect}\"\n    end\n    ts = eat(':', ts)\n    v, ts = valparse(ts)\n    [k, v, ts]\n  end", "label": 4}
{"code": "func (p *PortList) Pop() string {\n\tif len(*p) == 0 {\n\t\tpanic(\"list is empty\")\n\t}\n\tval := (*p)[len(*p)-1]\n\t*p = (*p)[:len(*p)-1]\n\treturn val\n}", "label": 5}
{"code": "func DjangoContentTypeByID(db XODB, id int) (*DjangoContentType, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, app_label, model ` +\n\t\t`FROM django_content_type ` +\n\t\t`WHERE id = ?`\n\n\t// run query\n\tXOLog(sqlstr, id)\n\tdct := DjangoContentType{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, id).Scan(&dct.ID, &dct.AppLabel, &dct.Model)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dct, nil\n}", "label": 5}
{"code": "def handle_program_options():\n    \"\"\"Parses the given options passed in at the command line.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Calculate the alpha diversity\\\n                                     of a set of samples using one or more \\\n                                     metrics and output a kernal density \\\n                                     estimator-smoothed histogram of the \\\n                                     results.\")\n    parser.add_argument(\"-m\", \"--map_file\",\n                        help=\"QIIME mapping file.\")\n    parser.add_argument(\"-i\", \"--biom_fp\",\n                        help=\"Path to the BIOM table\")\n    parser.add_argument(\"-c\", \"--category\",\n                        help=\"Specific category from the mapping file.\")\n    parser.add_argument(\"-d\", \"--diversity\", default=[\"shannon\"], nargs=\"+\",\n                        help=\"The alpha diversity metric. Default \\\n                             value is 'shannon', which will calculate the Shannon\\\n                             entropy. Multiple metrics can be specified (space separated).\\\n                             The full list of metrics is available at:\\\n                             http://scikit-bio.org/docs/latest/generated/skbio.diversity.alpha.html.\\\n                             Beta diversity metrics will be supported in the future.\")\n    parser.add_argument(\"--x_label\", default=[None], nargs=\"+\",\n                        help=\"The name of the diversity metric to be displayed on the\\\n                        plot as the X-axis label. If multiple metrics are specified,\\\n                        then multiple entries for the X-axis label should be given.\")\n    parser.add_argument(\"--color_by\",\n                        help=\"A column name in the mapping file containing\\\n                              hexadecimal (#FF0000) color values that will\\\n                              be used to color the groups. Each sample ID must\\\n                              have a color entry.\")\n    parser.add_argument(\"--plot_title\", default=\"\",\n                        help=\"A descriptive title that will appear at the top \\\n                        of the output plot. Surround with quotes if there are\\\n                        spaces in the title.\")\n    parser.add_argument(\"-o\", \"--output_dir\", default=\".\",\n                        help=\"The directory plots will be saved to.\")\n    parser.add_argument(\"--image_type\", default=\"png\",\n                        help=\"The type of image to save: png, svg, pdf, eps, etc...\")\n    parser.add_argument(\"--save_calculations\",\n                        help=\"Path and name of text file to store the calculated \"\n                        \"diversity metrics.\")\n    parser.add_argument(\"--suppress_stats\", action=\"store_true\", help=\"Do not display \"\n                        \"significance testing results which are shown by default.\")\n    parser.add_argument(\"--show_available_metrics\", action=\"store_true\",\n                        help=\"Supply this parameter to see which alpha diversity metrics \"\n                             \" are available for usage. No calculations will be performed\"\n                             \" if this parameter is provided.\")\n    return parser.parse_args()", "label": 1}
{"code": "func splitNetworks(list []*NetworkToSplit) ([]*net.IPNet, error) {\n\tlocalPools := make([]*net.IPNet, 0, len(list))\n\n\tfor _, p := range list {\n\t\t_, b, err := net.ParseCIDR(p.Base)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid base pool %q: %v\", p.Base, err)\n\t\t}\n\t\tones, _ := b.Mask.Size()\n\t\tif p.Size <= 0 || p.Size < ones {\n\t\t\treturn nil, fmt.Errorf(\"invalid pools size: %d\", p.Size)\n\t\t}\n\t\tlocalPools = append(localPools, splitNetwork(p.Size, b)...)\n\t}\n\treturn localPools, nil\n}", "label": 5}
{"code": "def fetch_closed_orders(self, limit: int) -> List[Order]:\n        \"\"\"Fetch latest closed orders, must provide a limit.\"\"\"\n        return self._fetch_orders_limit(self._closed_orders, limit)", "label": 1}
{"code": "def stub_data(operation_name, data = {})\n      Stubbing::StubData.new(config.api.operation(operation_name)).stub(data)\n    end", "label": 4}
{"code": "public function setPayload($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\ExamplePayload::class);\n        $this->payload = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static autoscaleprofile get(nitro_service service, String name) throws Exception{\n\t\tautoscaleprofile obj = new autoscaleprofile();\n\t\tobj.set_name(name);\n\t\tautoscaleprofile response = (autoscaleprofile) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public static function deviceName($project, $location, $registry, $device)\n    {\n        return self::getDeviceNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'registry' => $registry,\n            'device' => $device,\n        ]);\n    }", "label": 2}
{"code": "def push_line(self, tokens):\n        \"\"\" Adds a Branch object to the case.\n        \"\"\"\n        logger.debug(\"Pushing line data: %s\" % tokens)\n\n        from_bus = self.case.buses[tokens[\"fbus\"]-1]\n        to_bus = self.case.buses[tokens[\"tbus\"]-1]\n\n        e = Branch(from_bus=from_bus, to_bus=to_bus)\n        e.r = tokens[\"r\"]\n        e.x = tokens[\"x\"]\n        e.b = tokens[\"b\"]\n        e.rate_a = tokens[\"s_limit\"]\n        e.rate_b = tokens[\"p_limit\"]\n        e.rate_c = tokens[\"i_limit\"]\n        # Optional parameter\n        if tokens[\"tap\"] == 0: #Transmission line\n            e.ratio = 1.0\n        else: # Transformer\n            e.ratio = tokens[\"tap\"]\n        e.phase_shift = tokens[\"shift\"]\n        # Optional parameter\n#        if \"status\" in tokens.keys:\n#        e.online = tokens[\"status\"]\n\n        self.case.branches.append(e)", "label": 1}
{"code": "func (nDB *NetworkDB) Peers(nid string) []PeerInfo {\n\tnDB.RLock()\n\tdefer nDB.RUnlock()\n\tpeers := make([]PeerInfo, 0, len(nDB.networkNodes[nid]))\n\tfor _, nodeName := range nDB.networkNodes[nid] {\n\t\tif node, ok := nDB.nodes[nodeName]; ok {\n\t\t\tpeers = append(peers, PeerInfo{\n\t\t\t\tName: node.Name,\n\t\t\t\tIP:   node.Addr.String(),\n\t\t\t})\n\t\t} else {\n\t\t\t// Added for testing purposes, this condition should never happen else mean that the network list\n\t\t\t// is out of sync with the node list\n\t\t\tpeers = append(peers, PeerInfo{Name: nodeName, IP: \"unknown\"})\n\t\t}\n\t}\n\treturn peers\n}", "label": 5}
{"code": "def copy_file(src, dest):\n\t\"\"\"\n\tcopy single file\n\t\"\"\"\n\ttry:\n\t\tshutil.copy2(src , dest)\n\texcept Exception as ex:\n\t\tprint('ERROR copying file' + str(ex))", "label": 1}
{"code": "private function handleOptionalMigrationOption()\n    {\n        if ($this->option('migration') === true) {\n            $migrationName = 'create_' . $this->createMigrationName() . '_table';\n            $this->call('module:make-migration', ['name' => $migrationName, 'module' => $this->argument('module')]);\n        }\n    }", "label": 2}
{"code": "public static onlinkipv6prefix[] get(nitro_service service, String ipv6prefix[]) throws Exception{\n\t\tif (ipv6prefix !=null && ipv6prefix.length>0) {\n\t\t\tonlinkipv6prefix response[] = new onlinkipv6prefix[ipv6prefix.length];\n\t\t\tonlinkipv6prefix obj[] = new onlinkipv6prefix[ipv6prefix.length];\n\t\t\tfor (int i=0;i<ipv6prefix.length;i++) {\n\t\t\t\tobj[i] = new onlinkipv6prefix();\n\t\t\t\tobj[i].set_ipv6prefix(ipv6prefix[i]);\n\t\t\t\tresponse[i] = (onlinkipv6prefix) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def cmd_exec(self, cmd):\n        \"\"\"\n            Execute commands in automate namespace\n        \"\"\"\n\n        if not cmd:\n            return\n        ns = self.cmd_namespace\n        import copy\n        rval = True\n        nscopy = copy.copy(ns)\n        try:\n            r = eval(cmd, ns)\n            if isinstance(r, SystemObject) and not r.system:\n                r.setup_system(self)\n            if callable(r):\n                r = r()\n                cmd += \"()\"\n            self.logger.info(\"Eval: %s\", cmd)\n            self.logger.info(\"Result: %s\", r)\n        except SyntaxError:\n            r = {}\n            try:\n                exec (cmd, ns)\n                self.logger.info(\"Exec: %s\", cmd)\n            except ExitException:\n                raise\n            except Exception as e:\n                self.logger.info(\"Failed to exec cmd %s: %s.\", cmd, e)\n                rval = False\n            for key, value in list(ns.items()):\n                if key not in nscopy or not value is nscopy[key]:\n                    if key in self.namespace:\n                        del self.namespace[key]\n                    self.namespace[key] = value\n                    r[key] = value\n            self.logger.info(\"Set items in namespace: %s\", r)\n        except ExitException:\n            raise\n        except Exception as e:\n            self.logger.info(\"Failed to eval cmd %s: %s\", cmd, e)\n            return False\n\n        return rval", "label": 1}
{"code": "function Actor(stream) {\n  if (!(this instanceof Actor)) return new Actor(stream);\n  var that = this;\n  this.parser = new amp.Stream;\n  this.parser.on('data', this.onmessage.bind(this));\n  stream.pipe(this.parser);\n  this.stream = stream;\n  this.callbacks = {};\n  this.ids = 0;\n  this.id = ++ids;\n  this.secret_key = null;\n  Actor.emit('actor', this);\n}", "label": 3}
{"code": "@PostConstruct\n\tprotected void init() throws IOException {\n\t\t// base configuration from XML file\n\t\tif (null != configurationFile) {\n\t\t\tlog.debug(\"Get base configuration from {}\", configurationFile);\n\t\t\tmanager = new DefaultCacheManager(configurationFile);\n\t\t} else {\n\t\t\tGlobalConfigurationBuilder builder = new GlobalConfigurationBuilder();\n\t\t\tbuilder.globalJmxStatistics().allowDuplicateDomains(true);\n\t\t\tmanager = new DefaultCacheManager(builder.build());\n\t\t}\n\n\t\tif (listener == null) {\n\t\t\tlistener = new InfinispanCacheListener();\n\t\t}\n\t\tmanager.addListener(listener);\n\n\t\t// cache for caching the cache configurations (hmmm, sounds a bit strange)\n\t\tMap<String, Map<CacheCategory, CacheService>> cacheCache = \n\t\t\t\tnew HashMap<String, Map<CacheCategory, CacheService>>();\n\n\t\t// build default configuration\n\t\tif (null != defaultConfiguration) {\n\t\t\tsetCaches(cacheCache, null, defaultConfiguration);\n\t\t}\n\n\t\t// build layer specific configurations\n\t\tfor (Layer layer : layerMap.values()) {\n\t\t\tCacheInfo ci = configurationService.getLayerExtraInfo(layer.getLayerInfo(), CacheInfo.class);\n\t\t\tif (null != ci) {\n\t\t\t\tsetCaches(cacheCache, layer, ci);\n\t\t\t}\n\t\t}\n\t}", "label": 0}
{"code": "def check_units(node, property, units)\n      allowed_units = allowed_units_for_property(property)\n      return if allowed_units.include?(units)\n\n      add_lint(node,\n               \"#{units} units not allowed on `#{property}`; must be one of \" \\\n               \"(#{allowed_units.to_a.sort.join(', ')})\")\n    end", "label": 4}
{"code": "function getExternalModuleNameFromPath(host, fileName) {\n        var getCanonicalFileName = function (f) { return host.getCanonicalFileName(f); };\n        var dir = ts.toPath(host.getCommonSourceDirectory(), host.getCurrentDirectory(), getCanonicalFileName);\n        var filePath = ts.getNormalizedAbsolutePath(fileName, host.getCurrentDirectory());\n        var relativePath = ts.getRelativePathToDirectoryOrUrl(dir, filePath, dir, getCanonicalFileName, /*isAbsolutePathAnUrl*/ false);\n        return ts.removeFileExtension(relativePath);\n    }", "label": 3}
{"code": "def get_page(search_text):\n    \"\"\"\n    formats the entire search result in a table output\n    \"\"\"\n    lst = search_aikif(search_text)\n    txt = '<table class=\"as-table as-table-zebra as-table-horizontal\">'\n    for result in lst:\n        txt += '<TR><TD>' + result + '</TD></TR>'\n    txt += '</TABLE>\\n\\n'\n    return txt", "label": 1}
{"code": "protected Query buildPrefetchQuery(Collection ids)\r\n    {\r\n        CollectionDescriptor cds = getCollectionDescriptor();\r\n        QueryByCriteria query = buildPrefetchQuery(ids, cds.getForeignKeyFieldDescriptors(getItemClassDescriptor()));\r\n\r\n        // check if collection must be ordered\r\n        if (!cds.getOrderBy().isEmpty())\r\n        {\r\n            Iterator iter = cds.getOrderBy().iterator();\r\n            while (iter.hasNext())\r\n            {\r\n                query.addOrderBy((FieldHelper) iter.next());\r\n            }\r\n        }\r\n\r\n        return query;\r\n    }", "label": 0}
{"code": "function () {\n        return Object.keys(this._attributes).map(function (name) {\n            _gpfWebCheckNamespaceSafe(name);\n            return \" \" + _gpfWebTagAttributeAlias(name)\n                + \"=\\\"\" + _gpfStringEscapeForHtml(this._attributes[name]) + \"\\\"\";\n        }, this).join(\"\");\n    }", "label": 3}
{"code": "def connections\n      response = Discordrb::API::User.connections(@token)\n      JSON.parse(response).map { |e| Connection.new(e, self) }\n    end", "label": 4}
{"code": "private function convertToGoogleException($ex)\n    {\n        switch ($ex->getCode()) {\n            case Code::INVALID_ARGUMENT:\n                $exception = Exception\\BadRequestException::class;\n                break;\n\n            case Code::NOT_FOUND:\n            case Code::UNIMPLEMENTED:\n                $exception = Exception\\NotFoundException::class;\n                break;\n\n            case Code::ALREADY_EXISTS:\n                $exception = Exception\\ConflictException::class;\n                break;\n\n            case Code::FAILED_PRECONDITION:\n                $exception = Exception\\FailedPreconditionException::class;\n                break;\n\n            case Code::UNKNOWN:\n                $exception = Exception\\ServerException::class;\n                break;\n\n            case Code::INTERNAL:\n                $exception = Exception\\ServerException::class;\n                break;\n\n            case Code::ABORTED:\n                $exception = Exception\\AbortedException::class;\n                break;\n\n            case Code::DEADLINE_EXCEEDED:\n                $exception = Exception\\DeadlineExceededException::class;\n                break;\n\n            default:\n                $exception = Exception\\ServiceException::class;\n                break;\n        }\n\n        $metadata = [];\n        if ($ex->getMetadata()) {\n            foreach ($ex->getMetadata() as $type => $binaryValue) {\n                if (!isset($this->metadataTypes[$type])) {\n                    continue;\n                }\n                $metadataElement = new $this->metadataTypes[$type];\n                $metadataElement->mergeFromString($binaryValue[0]);\n                $metadata[] = $this->serializer->encodeMessage($metadataElement);\n            }\n        }\n\n        return new $exception($ex->getMessage(), $ex->getCode(), $ex, $metadata);\n    }", "label": 2}
{"code": "def load_reporter_class(reporter_name)\n      HamlLint::Reporter.const_get(\"#{reporter_name}Reporter\")\n    rescue NameError\n      raise HamlLint::Exceptions::InvalidCLIOption,\n            \"#{reporter_name}Reporter does not exist\"\n    end", "label": 4}
{"code": "private ReferenceDescriptorDef usedByReference(ModelDef modelDef, FieldDescriptorDef fieldDef)\r\n    {\r\n        String                 ownerClassName = ((ClassDescriptorDef)fieldDef.getOwner()).getQualifiedName();\r\n        ClassDescriptorDef     classDef;\r\n        ReferenceDescriptorDef refDef;\r\n        String                 targetClassName;\r\n\r\n        // only relevant for primarykey fields\r\n        if (PropertyHelper.toBoolean(fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_PRIMARYKEY), false))\r\n        {\r\n            for (Iterator classIt = modelDef.getClasses(); classIt.hasNext();)\r\n            {\r\n                classDef = (ClassDescriptorDef)classIt.next();\r\n                for (Iterator refIt = classDef.getReferences(); refIt.hasNext();)\r\n                {\r\n                    refDef          = (ReferenceDescriptorDef)refIt.next();\r\n                    targetClassName = refDef.getProperty(PropertyHelper.OJB_PROPERTY_CLASS_REF).replace('$', '.');\r\n                    if (ownerClassName.equals(targetClassName))\r\n                    {\r\n                        // the field is a primary key of the class referenced by this reference descriptor\r\n                        return refDef;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        return null;\r\n    }", "label": 0}
{"code": "func seccompUnitOptions(opts []*unit.UnitOption, sf *seccompFilter) ([]*unit.UnitOption, error) {\n\tif sf == nil {\n\t\treturn opts, nil\n\t}\n\tif sf.errno != \"\" {\n\t\topts = append(opts, unit.NewUnitOption(\"Service\", \"SystemCallErrorNumber\", sf.errno))\n\t}\n\n\tvar filterPrefix string\n\tswitch sf.mode {\n\tcase ModeWhitelist:\n\t\tfilterPrefix = sdWhitelistPrefix\n\tcase ModeBlacklist:\n\t\tfilterPrefix = sdBlacklistPrefix\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unknown filter mode %v\", sf.mode)\n\t}\n\n\t// SystemCallFilter options are written down one entry per line, because\n\t// filtering sets may be quite large and overlong lines break unit serialization.\n\topts = appendOptionsList(opts, \"Service\", \"SystemCallFilter\", filterPrefix, sf.syscalls...)\n\treturn opts, nil\n}", "label": 5}
{"code": "public static base_response unset(nitro_service client, nsconfig resource, String[] args) throws Exception{\n\t\tnsconfig unsetresource = new nsconfig();\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def resume(service_name, timeout: DEFAULT_TIMEOUT)\n      Puppet.debug _(\"Resuming the %{service_name} service. Timeout set to: %{timeout} seconds\") % { service_name: service_name, timeout: timeout }\n\n      valid_initial_states = [\n        SERVICE_PAUSE_PENDING,\n        SERVICE_PAUSED,\n        SERVICE_CONTINUE_PENDING\n      ]\n\n      transition_service_state(service_name, valid_initial_states, SERVICE_RUNNING, timeout) do |service|\n        # The SERVICE_CONTROL_CONTINUE signal can only be sent when\n        # the service is in the SERVICE_PAUSED state\n        wait_on_pending_state(service, SERVICE_PAUSE_PENDING, timeout)\n\n        send_service_control_signal(service, SERVICE_CONTROL_CONTINUE)\n      end\n\n      Puppet.debug _(\"Successfully resumed the %{service_name} service\") % { service_name: service_name }\n    end", "label": 4}
{"code": "def tearpage_needed(bibtex):\n    \"\"\"\n    Check whether a given paper needs some pages to be teared or not.\n\n    :params bibtex: The bibtex entry associated to the paper, to guess \\\n            whether tearing is needed.\n    :returns: A list of pages to tear.\n    \"\"\"\n    for publisher in BAD_JOURNALS:\n        if publisher in bibtex.get(\"journal\", \"\").lower():\n            # Bad journal is found, add pages to tear\n            return BAD_JOURNALS[publisher]\n\n    # If no bad journals are found, return an empty list\n    return []", "label": 1}
{"code": "func (r *Role) Check() error {\n\tswitch *r {\n\tcase RoleAuth, RoleWeb, RoleNode,\n\t\tRoleAdmin, RoleProvisionToken,\n\t\tRoleTrustedCluster, LegacyClusterTokenType,\n\t\tRoleSignup, RoleProxy, RoleNop:\n\t\treturn nil\n\t}\n\treturn trace.BadParameter(\"role %v is not registered\", *r)\n}", "label": 5}
{"code": "func DjangoAdminLogByID(db XODB, id int) (*DjangoAdminLog, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`id, object_id, object_repr, action_flag, change_message, content_type_id, user_id, action_time ` +\n\t\t`FROM django_admin_log ` +\n\t\t`WHERE id = ?`\n\n\t// run query\n\tXOLog(sqlstr, id)\n\tdal := DjangoAdminLog{\n\t\t_exists: true,\n\t}\n\n\terr = db.QueryRow(sqlstr, id).Scan(&dal.ID, &dal.ObjectID, &dal.ObjectRepr, &dal.ActionFlag, &dal.ChangeMessage, &dal.ContentTypeID, &dal.UserID, &dal.ActionTime)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dal, nil\n}", "label": 5}
{"code": "def add_watch_point(self, string, rating, importance=5):\n        \"\"\"\n        For a log session you can add as many watch points \n        which are used in the aggregation and extraction of\n        key things that happen.\n        Each watch point has a rating (up to you and can range \n        from success to total failure and an importance for \n        finer control of display\n        \"\"\"\n        d = {}\n        d['string'] = string\n        d['rating'] = rating\n        d['importance'] = importance\n        self.watch_points.append(d)", "label": 1}
{"code": "def _add_value_to_dict_bf(d, k, v):\n    \"\"\"Adds the `k`->`v` mapping to `d`, but if a previous element exists it changes\n    the value of for the key to list.\n\n    This is used in the BadgerFish mapping convention.\n\n    This is a simple multi-dict that is only suitable when you know that you'll never\n    store a list or `None` as a value in the dict.\n    \"\"\"\n    prev = d.get(k)\n    if prev is None:\n        d[k] = v\n    elif isinstance(prev, list):\n        if isinstance(v, list):\n            prev.extend(v)\n        else:\n            prev.append(v)\n    else:\n        if isinstance(v, list):\n            x = [prev]\n            x.extend(v)\n            d[k] = x\n        else:\n            d[k] = [prev, v]", "label": 1}
{"code": "public void originalClass(String template, Properties attributes) throws XDocletException\r\n    {\r\n        pushCurrentClass(_curClassDef.getOriginalClass());\r\n        generate(template);\r\n        popCurrentClass();\r\n    }", "label": 0}
{"code": "func (agp *AuthGroupPermission) Save(db XODB) error {\n\tif agp.Exists() {\n\t\treturn agp.Update(db)\n\t}\n\n\treturn agp.Insert(db)\n}", "label": 5}
{"code": "def find_donor_catchments(self, limit=6, dist_limit=500):\n        \"\"\"\n        Return a suitable donor catchment to improve a QMED estimate based on catchment descriptors alone.\n\n        :param limit: maximum number of catchments to return. Default: 6. Set to `None` to return all available\n                      catchments.\n        :type limit: int\n        :param dist_limit: maximum distance in km. between subject and donor catchment. Default: 500 km. Increasing the\n                           maximum distance will increase computation time!\n        :type dist_limit: float or int\n        :return: list of nearby catchments\n        :rtype: :class:`floodestimation.entities.Catchment`\n        \"\"\"\n        if self.gauged_catchments:\n            return self.gauged_catchments.nearest_qmed_catchments(self.catchment, limit, dist_limit)\n        else:\n            return []", "label": 1}
{"code": "def add_uri_option(key, strategy, value, uri_options)\n      target = select_target(uri_options, strategy[:group])\n      value = apply_transform(key, value, strategy[:type])\n      merge_uri_option(target, value, strategy[:name])\n    end", "label": 4}
{"code": "def call_antlr4(arg):\n    \"calls antlr4 on grammar file\"\n    # pylint: disable=unused-argument, unused-variable\n    antlr_path = os.path.join(ROOT_DIR, \"java\", \"antlr-4.7-complete.jar\")\n    classpath = os.pathsep.join([\".\", \"{:s}\".format(antlr_path), \"$CLASSPATH\"])\n    generated = os.path.join(ROOT_DIR, 'src', 'pymoca', 'generated')\n    cmd = \"java -Xmx500M -cp \\\"{classpath:s}\\\" org.antlr.v4.Tool {arg:s}\" \\\n          \" -o {generated:s} -visitor -Dlanguage=Python3\".format(**locals())\n    print(cmd)\n    proc = subprocess.Popen(cmd.split(), cwd=os.path.join(ROOT_DIR, 'src', 'pymoca'))\n    proc.communicate()\n    with open(os.path.join(generated, '__init__.py'), 'w') as fid:\n        fid.write('')", "label": 1}
{"code": "func (c *controller) StopDiagnostic() {\n\tc.Lock()\n\tif c.DiagnosticServer.IsDiagnosticEnabled() {\n\t\tc.DiagnosticServer.DisableDiagnostic()\n\t}\n\tc.Unlock()\n}", "label": 5}
{"code": "def _f(self, x, user_data=None):\n        \"\"\" Evaluates the objective function.\n        \"\"\"\n        p_gen = x[self._Pg.i1:self._Pg.iN + 1] # Active generation in p.u.\n        q_gen = x[self._Qg.i1:self._Qg.iN + 1] # Reactive generation in p.u.\n\n        # Polynomial cost of P and Q.\n        xx = r_[p_gen, q_gen] * self._base_mva\n        if len(self._ipol) > 0:\n            f = sum([g.total_cost(xx[i]) for i,g in enumerate(self._gn)])\n        else:\n            f = 0\n\n        # Piecewise linear cost of P and Q.\n        if self._ny:\n            y = self.om.get_var(\"y\")\n            self._ccost = csr_matrix((ones(self._ny),\n                (range(y.i1, y.iN + 1), zeros(self._ny))),\n                shape=(self._nxyz, 1)).T\n            f = f + self._ccost * x\n        else:\n            self._ccost = zeros((1, self._nxyz))\n        # TODO: Generalised cost term.\n\n        return f", "label": 1}
{"code": "func printStatus(p *pkgPod.Pod) error {\n\tif flagFormat != outputFormatTabbed {\n\t\tpod, err := lib.NewPodFromInternalPod(p)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error converting pod: %v\", err)\n\t\t}\n\t\tswitch flagFormat {\n\t\tcase outputFormatJSON:\n\t\t\tresult, err := json.Marshal(pod)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"error marshaling the pod: %v\", err)\n\t\t\t}\n\t\t\tstdout.Print(string(result))\n\t\tcase outputFormatPrettyJSON:\n\t\t\tresult, err := json.MarshalIndent(pod, \"\", \"\\t\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"error marshaling the pod: %v\", err)\n\t\t\t}\n\t\t\tstdout.Print(string(result))\n\t\t}\n\t\treturn nil\n\t}\n\n\tstate := p.State()\n\tstdout.Printf(\"state=%s\", state)\n\n\tcreated, err := p.CreationTime()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to get creation time for pod %q: %v\", p.UUID, err)\n\t}\n\tcreatedStr := created.Format(defaultTimeLayout)\n\n\tstdout.Printf(\"created=%s\", createdStr)\n\n\tstarted, err := p.StartTime()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to get start time for pod %q: %v\", p.UUID, err)\n\t}\n\tvar startedStr string\n\tif !started.IsZero() {\n\t\tstartedStr = started.Format(defaultTimeLayout)\n\t\tstdout.Printf(\"started=%s\", startedStr)\n\t}\n\n\tif state == pkgPod.Running || state == pkgPod.Exited {\n\t\tstdout.Printf(\"networks=%s\", fmtNets(p.Nets))\n\t}\n\n\tif !(state == pkgPod.Running || state == pkgPod.Deleting || state == pkgPod.ExitedDeleting || state == pkgPod.Exited || state == pkgPod.ExitedGarbage) {\n\t\treturn nil\n\t}\n\n\tif pid, err := p.Pid(); err == nil {\n\t\t// the pid file might not be written yet when the state changes to 'Running'\n\t\t// it may also never be written if systemd never executes (e.g.: a bad command)\n\t\tstdout.Printf(\"pid=%d\", pid)\n\t}\n\tstdout.Printf(\"exited=%t\", (state == pkgPod.Exited || state == pkgPod.ExitedGarbage))\n\n\tif state != pkgPod.Running {\n\t\tstats, err := getExitStatuses(p)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to get exit statuses for pod %q: %v\", p.UUID, err)\n\t\t}\n\t\tfor app, stat := range stats {\n\t\t\tstdout.Printf(\"app-%s=%d\", app, stat)\n\t\t}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func ReadPath(path string) ([]byte, error) {\n\tif path == \"\" {\n\t\treturn nil, trace.NotFound(\"empty path\")\n\t}\n\ts, err := filepath.Abs(path)\n\tif err != nil {\n\t\treturn nil, trace.ConvertSystemError(err)\n\t}\n\tabs, err := filepath.EvalSymlinks(s)\n\tif err != nil {\n\t\treturn nil, trace.ConvertSystemError(err)\n\t}\n\tbytes, err := ioutil.ReadFile(abs)\n\tif err != nil {\n\t\treturn nil, trace.ConvertSystemError(err)\n\t}\n\treturn bytes, nil\n}", "label": 5}
{"code": "def exists(pre_check = 0, post_check = @core.default_wait)\n      # do not uset set_wait here.\n      # it will cause problems with other methods reading the default_wait of 0\n      # which then gets converted to a 1 second wait.\n      @driver.manage.timeouts.implicit_wait = pre_check\n      # the element exists unless an error is raised.\n      exists                                = true\n\n      begin\n        yield # search for element\n      rescue StandardError\n        exists = false # error means it's not there\n      end\n\n      # restore wait\n      @driver.manage.timeouts.implicit_wait = post_check if post_check != pre_check\n\n      exists\n    end", "label": 4}
{"code": "def __cond_from_desc(desc):\n    \"\"\"Get the condition name from the condition description.\"\"\"\n    # '{ 'code': 'conditon', 'detailed', 'exact', 'exact_nl'}\n    for code, [condition, detailed, exact, exact_nl] in __BRCONDITIONS.items():\n        if exact_nl == desc:\n            return {CONDCODE: code,\n                    CONDITION: condition,\n                    DETAILED: detailed,\n                    EXACT: exact,\n                    EXACTNL: exact_nl\n                    }\n    return None", "label": 1}
{"code": "public static appqoepolicy[] get(nitro_service service) throws Exception{\n\t\tappqoepolicy obj = new appqoepolicy();\n\t\tappqoepolicy[] response = (appqoepolicy[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function onError(reason, commands) {\n        if (typeof reason !== 'string' && typeof reason.message === 'string') {\n            reason = reason.message;\n        }\n        return commands._replyFn(`An unexpected error \\`${reason}\\` occured and your commands could not be processed!`);\n    }", "label": 3}
{"code": "public static nstrafficdomain_binding get(nitro_service service, Long td) throws Exception{\n\t\tnstrafficdomain_binding obj = new nstrafficdomain_binding();\n\t\tobj.set_td(td);\n\t\tnstrafficdomain_binding response = (nstrafficdomain_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def render_template_to_string(input, _from_string=False, **context):\n    \"\"\"Render a template from the template folder with the given context.\n\n    Code based on\n    `<https://github.com/mitsuhiko/flask/blob/master/flask/templating.py>`_\n    :param input: the string template, or name of the template to be\n                  rendered, or an iterable with template names\n                  the first one existing will be rendered\n    :param context: the variables that should be available in the\n                    context of the template.\n    :return: a string\n    \"\"\"\n    if _from_string:\n        template = current_app.jinja_env.from_string(input)\n    else:\n        template = current_app.jinja_env.get_or_select_template(input)\n    return template.render(context)", "label": 1}
{"code": "function getProperties(model) {\n    const modelName = model.constructor.name;\n    const properties = typed_conversions_1.hashToArray(exports.propertiesByModel[modelName], \"property\") || [];\n    let parent = Object.getPrototypeOf(model.constructor);\n    while (parent.name) {\n        const subClass = new parent();\n        const subClassName = subClass.constructor.name;\n        properties.push(...typed_conversions_1.hashToArray(exports.propertiesByModel[subClassName], \"property\"));\n        parent = Object.getPrototypeOf(subClass.constructor);\n    }\n    return properties;\n}", "label": 3}
{"code": "def create_function_f_m(self):\n        \"\"\"Discrete state dynamics\"\"\"\n        return ca.Function(\n            'f_m',\n            [self.t, self.x, self.y, self.m, self.p, self.c, self.pre_c, self.ng, self.nu],\n            [self.f_m],\n            ['t', 'x', 'y', 'm', 'p', 'c', 'pre_c', 'ng', 'nu'], ['m'], self.func_opt)", "label": 1}
{"code": "public function getDelete()\n    {\n        $item_names = request('items');\n        $errors = [];\n\n        foreach ($item_names as $name_to_delete) {\n            $file_to_delete = $this->lfm->pretty($name_to_delete);\n            $file_path = $file_to_delete->path();\n\n            event(new ImageIsDeleting($file_path));\n\n            if (is_null($name_to_delete)) {\n                array_push($errors, parent::error('folder-name'));\n                continue;\n            }\n\n            if (! $this->lfm->setName($name_to_delete)->exists()) {\n                array_push($errors, parent::error('folder-not-found', ['folder' => $file_path]));\n                continue;\n            }\n\n            if ($this->lfm->setName($name_to_delete)->isDirectory()) {\n                if (! $this->lfm->setName($name_to_delete)->directoryIsEmpty()) {\n                    array_push($errors, parent::error('delete-folder'));\n                    continue;\n                }\n            } else {\n                if ($file_to_delete->isImage()) {\n                    $this->lfm->setName($name_to_delete)->thumb()->delete();\n                }\n            }\n\n            $this->lfm->setName($name_to_delete)->delete();\n\n            event(new ImageWasDeleted($file_path));\n        }\n\n        if (count($errors) > 0) {\n            return $errors;\n        }\n\n        return parent::$success_response;\n    }", "label": 2}
{"code": "func (tc *TeleportClient) LogoutAll() error {\n\terr := tc.localAgent.DeleteKeys()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func isPacketForwardingEnabled(ipVer ipVersion, iface string) (bool, error) {\n\tswitch ipVer {\n\tcase ipv4, ipv6:\n\t\treturn getKernelBoolParam(getForwardingKernelParam(ipVer, iface))\n\tcase ipvboth:\n\t\tenabled, err := getKernelBoolParam(getForwardingKernelParam(ipv4, \"\"))\n\t\tif err != nil || !enabled {\n\t\t\treturn enabled, err\n\t\t}\n\t\treturn getKernelBoolParam(getForwardingKernelParam(ipv6, iface))\n\tdefault:\n\t\treturn true, nil\n\t}\n}", "label": 5}
{"code": "function (soajs, combo, cb) {\n        soajs.mongoDb.find(combo.collection, combo.condition || {}, combo.fields || null, combo.options || null, cb);\n    }", "label": 3}
{"code": "def get_from_postcode(self, postcode, distance, skip_cache=False):\n        \"\"\"\n        Calls `postcodes.get_from_postcode` but checks correctness of \n        `distance`, and by default utilises a local cache.\n\n        :param skip_cache: optional argument specifying whether to skip \n                           the cache and make an explicit request.\n\n        :raises IllegalPointException: if the latitude or longitude \n                                       are out of bounds.\n\n        :returns: a list of dicts containing postcode data within the \n                  specified distance.\n        \"\"\"\n        distance = float(distance)\n        if distance < 0:\n            raise IllegalDistanceException(\"Distance must not be negative\")\n        # remove spaces and change case here due to caching\n        postcode = postcode.lower().replace(' ', '')\n        return self._lookup(skip_cache, get_from_postcode, postcode, \n                            float(distance))", "label": 1}
{"code": "func FindColor(c Color, palette []Color) Color {\n\tmatch := ColorDefault\n\tdist := float64(0)\n\tr, g, b := c.RGB()\n\tc1 := colorful.Color{\n\t\tR: float64(r) / 255.0,\n\t\tG: float64(g) / 255.0,\n\t\tB: float64(b) / 255.0,\n\t}\n\tfor _, d := range palette {\n\t\tr, g, b = d.RGB()\n\t\tc2 := colorful.Color{\n\t\t\tR: float64(r) / 255.0,\n\t\t\tG: float64(g) / 255.0,\n\t\t\tB: float64(b) / 255.0,\n\t\t}\n\t\t// CIE94 is more accurate, but really really expensive.\n\t\tnd := c1.DistanceCIE76(c2)\n\t\tif math.IsNaN(nd) {\n\t\t\tnd = math.Inf(1)\n\t\t}\n\t\tif match == ColorDefault || nd < dist {\n\t\t\tmatch = d\n\t\t\tdist = nd\n\t\t}\n\t}\n\treturn match\n}", "label": 5}
{"code": "def call(file_name, redis_pool, options = {})\n      execute_script(file_name, redis_pool, options)\n    rescue Redis::CommandError => ex\n      handle_error(ex, file_name) do\n        call(file_name, redis_pool, options)\n      end\n    end", "label": 4}
{"code": "function _gpfEventsFire (event, params, eventsHandler) {\n    /*jshint validthis:true*/ // will be invoked with apply\n    _gpfAssert(_gpfEventsIsValidHandler(eventsHandler), \"Expected a valid event handler\");\n    if (!(event instanceof _GpfEvent)) {\n        event = new gpf.events.Event(event, params, this);\n    }\n    return new Promise(function (resolve/*, reject*/) {\n        // This is used both to limit the number of recursion and increase the efficiency of the algorithm.\n        if (++_gpfEventsFiring > 10) {\n            // Too much recursion, use setTimeout to free some space on the stack\n            setTimeout(_gpfEventsTriggerHandler.bind(null, event, eventsHandler, resolve), 0);\n        } else {\n            _gpfEventsTriggerHandler(event, eventsHandler);\n            resolve(event);\n        }\n        --_gpfEventsFiring;\n    });\n}", "label": 3}
{"code": "def standby(df, resolution='24h', time_window=None):\n    \"\"\"\n    Compute standby power\n\n    Parameters\n    ----------\n    df : pandas.DataFrame or pandas.Series\n        Electricity Power\n    resolution : str, default='d'\n        Resolution of the computation.  Data will be resampled to this resolution (as mean) before computation\n        of the minimum.\n        String that can be parsed by the pandas resample function, example ='h', '15min', '6h'\n    time_window : tuple with start-hour and end-hour, default=None\n        Specify the start-time and end-time for the analysis.\n        Only data within this time window will be considered.\n        Both times have to be specified as string ('01:00', '06:30') or as datetime.time() objects\n\n    Returns\n    -------\n    df : pandas.Series with DateTimeIndex in the given resolution\n    \"\"\"\n\n    if df.empty:\n        raise EmptyDataFrame()\n\n    df = pd.DataFrame(df)  # if df was a pd.Series, convert to DataFrame\n    def parse_time(t):\n        if isinstance(t, numbers.Number):\n            return pd.Timestamp.utcfromtimestamp(t).time()\n        else:\n            return pd.Timestamp(t).time()\n\n\n    # first filter based on the time-window\n    if time_window is not None:\n        t_start = parse_time(time_window[0])\n        t_end = parse_time(time_window[1])\n        if t_start > t_end:\n            # start before midnight\n            df = df[(df.index.time >= t_start) | (df.index.time < t_end)]\n        else:\n            df = df[(df.index.time >= t_start) & (df.index.time < t_end)]\n\n    return df.resample(resolution).min()", "label": 1}
{"code": "public static base_response add(nitro_service client, cachecontentgroup resource) throws Exception {\n\t\tcachecontentgroup addresource = new cachecontentgroup();\n\t\taddresource.name = resource.name;\n\t\taddresource.weakposrelexpiry = resource.weakposrelexpiry;\n\t\taddresource.heurexpiryparam = resource.heurexpiryparam;\n\t\taddresource.relexpiry = resource.relexpiry;\n\t\taddresource.relexpirymillisec = resource.relexpirymillisec;\n\t\taddresource.absexpiry = resource.absexpiry;\n\t\taddresource.absexpirygmt = resource.absexpirygmt;\n\t\taddresource.weaknegrelexpiry = resource.weaknegrelexpiry;\n\t\taddresource.hitparams = resource.hitparams;\n\t\taddresource.invalparams = resource.invalparams;\n\t\taddresource.ignoreparamvaluecase = resource.ignoreparamvaluecase;\n\t\taddresource.matchcookies = resource.matchcookies;\n\t\taddresource.invalrestrictedtohost = resource.invalrestrictedtohost;\n\t\taddresource.polleverytime = resource.polleverytime;\n\t\taddresource.ignorereloadreq = resource.ignorereloadreq;\n\t\taddresource.removecookies = resource.removecookies;\n\t\taddresource.prefetch = resource.prefetch;\n\t\taddresource.prefetchperiod = resource.prefetchperiod;\n\t\taddresource.prefetchperiodmillisec = resource.prefetchperiodmillisec;\n\t\taddresource.prefetchmaxpending = resource.prefetchmaxpending;\n\t\taddresource.flashcache = resource.flashcache;\n\t\taddresource.expireatlastbyte = resource.expireatlastbyte;\n\t\taddresource.insertvia = resource.insertvia;\n\t\taddresource.insertage = resource.insertage;\n\t\taddresource.insertetag = resource.insertetag;\n\t\taddresource.cachecontrol = resource.cachecontrol;\n\t\taddresource.quickabortsize = resource.quickabortsize;\n\t\taddresource.minressize = resource.minressize;\n\t\taddresource.maxressize = resource.maxressize;\n\t\taddresource.memlimit = resource.memlimit;\n\t\taddresource.ignorereqcachinghdrs = resource.ignorereqcachinghdrs;\n\t\taddresource.minhits = resource.minhits;\n\t\taddresource.alwaysevalpolicies = resource.alwaysevalpolicies;\n\t\taddresource.persist = resource.persist;\n\t\taddresource.pinned = resource.pinned;\n\t\taddresource.lazydnsresolve = resource.lazydnsresolve;\n\t\taddresource.hitselector = resource.hitselector;\n\t\taddresource.invalselector = resource.invalselector;\n\t\taddresource.type = resource.type;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def visit(node)\n      # Visit the selector of a rule if parsed rules are available\n      if node.is_a?(Sass::Tree::RuleNode) && node.parsed_rules\n        visit_selector(node.parsed_rules)\n      end\n\n      @comment_processor.before_node_visit(node) if @engine.any_control_commands\n      super\n      @comment_processor.after_node_visit(node) if @engine.any_control_commands\n    end", "label": 4}
{"code": "function _libraryFiles(directory) {\n\treturn new Promise((fulfill) => {\n\t\tconst files = [];\n\t\tklaw(directory)\n\t\t\t.on('data', (item) => {\n\t\t\t\tconst relativePath = path.relative(directory, item.path);\n\t\t\t\tfiles.push(relativePath);\n\t\t\t})\n\t\t\t.on('end', () => {\n\t\t\t\tfulfill(files);\n\t\t\t});\n\t});\n}", "label": 3}
{"code": "def where(attribute, type = nil, **options)\n      attribute, type, options = normalize_arguments(attribute, type, options)\n      @errors.select { |error|\n        error.match?(attribute, type, options)\n      }\n    end", "label": 4}
{"code": "func PgShseclabelByObjoidClassoidProvider(db XODB, objoid pgtypes.Oid, classoid pgtypes.Oid, provider string) (*PgShseclabel, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, ctid, objoid, classoid, provider, label ` +\n\t\t`FROM pg_catalog.pg_shseclabel ` +\n\t\t`WHERE objoid = $1 AND classoid = $2 AND provider = $3`\n\n\t// run query\n\tXOLog(sqlstr, objoid, classoid, provider)\n\tps := PgShseclabel{}\n\n\terr = db.QueryRow(sqlstr, objoid, classoid, provider).Scan(&ps.Tableoid, &ps.Cmax, &ps.Xmax, &ps.Cmin, &ps.Xmin, &ps.Ctid, &ps.Objoid, &ps.Classoid, &ps.Provider, &ps.Label)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &ps, nil\n}", "label": 5}
{"code": "function deviceScan(){\n    shuffle(Object.keys(watchs.boards)).forEach(function(id){\n      plugHandler({event:'plug',device:watchs.boards[id]});\n    });\n  }", "label": 3}
{"code": "private void ensureReferencedPKs(ModelDef modelDef, ReferenceDescriptorDef refDef) throws ConstraintException\r\n    {\r\n        String             targetClassName = refDef.getProperty(PropertyHelper.OJB_PROPERTY_CLASS_REF);\r\n        ClassDescriptorDef targetClassDef  = modelDef.getClass(targetClassName);\r\n\r\n        ensurePKsFromHierarchy(targetClassDef);\r\n    }", "label": 0}
{"code": "func (d *Decoder) space() {\n\tfor {\n\t\tb, ok := d.getc()\n\t\tif !ok {\n\t\t\treturn\n\t\t}\n\t\tswitch b {\n\t\tcase ' ', '\\r', '\\n', '\\t':\n\t\tdefault:\n\t\t\td.ungetc(b)\n\t\t\treturn\n\t\t}\n\t}\n}", "label": 5}
{"code": "public void ifHasName(String template, Properties attributes) throws XDocletException\r\n    {\r\n        String name =  getDefForLevel(attributes.getProperty(ATTRIBUTE_LEVEL)).getName();\r\n\r\n        if ((name != null) && (name.length() > 0))\r\n        {\r\n            generate(template);\r\n        }\r\n    }", "label": 0}
{"code": "func TTL(clock clockwork.Clock, expires time.Time) time.Duration {\n\tttl := expires.Sub(clock.Now())\n\tif ttl < time.Second {\n\t\treturn time.Second\n\t}\n\treturn ttl\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, scpolicy resource) throws Exception {\n\t\tscpolicy addresource = new scpolicy();\n\t\taddresource.name = resource.name;\n\t\taddresource.url = resource.url;\n\t\taddresource.rule = resource.rule;\n\t\taddresource.delay = resource.delay;\n\t\taddresource.maxconn = resource.maxconn;\n\t\taddresource.action = resource.action;\n\t\taddresource.altcontentsvcname = resource.altcontentsvcname;\n\t\taddresource.altcontentpath = resource.altcontentpath;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "func (c *Manager) FailLibraryItemUpdateSession(ctx context.Context, id string) error {\n\turl := internal.URL(c, internal.LibraryItemUpdateSession).WithID(id).WithAction(\"fail\")\n\treturn c.Do(ctx, url.Request(http.MethodPost), nil)\n}", "label": 5}
{"code": "private void init(final List<DbLicense> licenses) {\n        licensesRegexp.clear();\n\n        for (final DbLicense license : licenses) {\n            if (license.getRegexp() == null ||\n                    license.getRegexp().isEmpty()) {\n                licensesRegexp.put(license.getName(), license);\n            } else {\n                licensesRegexp.put(license.getRegexp(), license);\n            }\n        }\n    }", "label": 0}
{"code": "def to_xml\n      template_path = File.join(File.dirname(__FILE__), '..', '..', 'templates', 'schema.xml.erb')\n      template_text = File.read(template_path)\n\n      erb = if RUBY_VERSION >= '2.6'\n        ERB.new(template_text, trim_mode: '-')\n      else\n        ERB.new(template_text, nil, '-')\n      end\n\n      erb.result(binding)\n    end", "label": 4}
{"code": "def include? position\n      position = Position.normalize(position)\n      contain?(position) && !(position.line == start.line && position.character == start.character)\n    end", "label": 4}
{"code": "public function handleSnapshot(array $snapshot)\n    {\n        if (array_key_exists($snapshot['id'], $this->breakpointsById)) {\n            $breakpoint = $this->breakpointsById[$snapshot['id']];\n            $evaluatedExpressions = $snapshot['evaluatedExpressions'];\n            $stackframes = $snapshot['stackframes'];\n            $breakpoint->evaluate($evaluatedExpressions, $stackframes, $this->evaluationOptions);\n            $this->batchRunner->submitItem($this->identifier, [$this->debuggeeId, $breakpoint]);\n        }\n    }", "label": 2}
{"code": "func (s *Server) RegisterFileHandler(scheme string, handler FileHandler) {\n\tif handler == nil {\n\t\tdelete(s.schemes, scheme)\n\t\treturn\n\t}\n\ts.schemes[scheme] = handler\n}", "label": 5}
{"code": "function filter(location) {\n    var file = path.basename(location)\n      , vim = file.charAt(file.length - 1) === '~'\n      , extension = path.extname(location).slice(1);\n\n    // filter out the duplicates\n    if (~changes.indexOf(location) || vim) return;\n\n    changes.push(location);\n    process.nextTick(limited);\n  }", "label": 3}
{"code": "def on_error(t, val, vstack)\n      raise ParseError, sprintf(\"\\nparse error on value %s (%s)\",\n                                val.inspect, token_to_str(t) || '?')\n    end", "label": 4}
{"code": "def safe_cast(invar, totype):\n    \"\"\"Performs a \"safe\" typecast.\n\n    Ensures that `invar` properly casts to `totype`. Checks after\n    casting that the result is actually of type `totype`. Any exceptions raised\n    by the typecast itself are unhandled.\n\n    Parameters\n    ----------\n    invar\n        (arbitrary) -- Value to be typecast.\n\n    totype\n        |type| --  Type to which `invar` is to be cast.\n\n    Returns\n    -------\n    outvar\n        `type 'totype'` --  Typecast version of `invar`\n\n    Raises\n    ------\n    ~exceptions.TypeError\n        If result of typecast is not of type `totype`\n\n    \"\"\"\n\n    # Make the typecast. Just use Python built-in exceptioning\n    outvar = totype(invar)\n\n    # Check that the cast type matches\n    if not isinstance(outvar, totype):\n        raise TypeError(\"Result of cast to '{0}' is '{1}'\"\n                                            .format(totype, type(outvar)))\n    ## end if\n\n    # Success; return the cast value\n    return outvar", "label": 1}
{"code": "function isDirty(attribute) {\n    expect(arguments).to.have.length.below(\n      2,\n      'Invalid arguments length when checking if an Entity attribute is ' +\n      'dirty (it has to be passed less than 2 arguments)'\n    );\n\n    var attributes = this.Entity.attributes;\n\n    if (attribute) {\n      expect(attribute).to.be.a(\n        'string',\n        'Invalid argument \"attribute\" when checking if an Entity attribute ' +\n        'is dirty (it has to be a string)'\n      );\n\n      expect(attributes).to.have.ownProperty(\n        attribute,\n        'Invalid argument \"attribute\" when checking an Entity attribute ' +\n        'is dirty (this attribute does not exist in the Entity)'\n      );\n\n      var newAttributes = {};\n      newAttributes[attribute] = attributes[attribute];\n      attributes = newAttributes;\n    }\n\n    if (this.isNew) {\n      return true;\n    }\n\n    for (var attributeName in attributes) {\n      if (_cleanSet) {\n        if (_attributeIsSet[attributeName]) {\n          if (\n            !_attributeStorageValues.hasOwnProperty(attributeName) ||\n            _attributeStorageValues[attributeName] !== this[attributeName]\n          ) {\n            return true;\n          }\n        }\n      } else {\n        if (\n          !_attributeStorageValues.hasOwnProperty(attributeName) ||\n          _attributeStorageValues[attributeName] !== this[attributeName]\n        ) {\n          return true;\n        }\n      }\n    }\n\n    return false;\n  }", "label": 3}
{"code": "function(canvas, useDevicePixelRatio) {\n    var mult = useDevicePixelRatio ? window.devicePixelRatio : 1;\n    mult = mult || 1;\n    var width  = Math.floor(canvas.clientWidth  * mult);\n    var height = Math.floor(canvas.clientHeight * mult);\n    if (canvas.width !== width ||\n        canvas.height !== height) {\n      canvas.width = width;\n      canvas.height = height;\n      return true;\n    }\n  }", "label": 3}
{"code": "func NewHeartbeat(cfg HeartbeatConfig) (*Heartbeat, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tctx, cancel := context.WithCancel(cfg.Context)\n\th := &Heartbeat{\n\t\tcancelCtx:       ctx,\n\t\tcancel:          cancel,\n\t\tHeartbeatConfig: cfg,\n\t\tEntry: log.WithFields(log.Fields{\n\t\t\ttrace.Component: teleport.Component(cfg.Component, \"beat\"),\n\t\t}),\n\t\tcheckTicker: time.NewTicker(cfg.CheckPeriod),\n\t\tannounceC:   make(chan struct{}, 1),\n\t\tsendC:       make(chan struct{}, 1),\n\t}\n\th.Debugf(\"Starting %v heartbeat with announce period: %v, keep-alive period %v, poll period: %v\", cfg.Mode, cfg.KeepAlivePeriod, cfg.AnnouncePeriod, cfg.CheckPeriod)\n\treturn h, nil\n}", "label": 5}
{"code": "private synchronized void setInitializationMethod(Method newMethod)\r\n    {\r\n        if (newMethod != null)\r\n        {\r\n            // make sure it's a no argument method\r\n            if (newMethod.getParameterTypes().length > 0)\r\n            {\r\n                throw new MetadataException(\r\n                    \"Initialization methods must be zero argument methods: \"\r\n                        + newMethod.getClass().getName()\r\n                        + \".\"\r\n                        + newMethod.getName());\r\n            }\r\n\r\n            // make it accessible if it's not already\r\n            if (!newMethod.isAccessible())\r\n            {\r\n                newMethod.setAccessible(true);\r\n            }\r\n        }\r\n        this.initializationMethod = newMethod;\r\n    }", "label": 0}
{"code": "func (s *Server) HandleConnection(conn net.Conn) {\n\ts.srv.HandleConnection(conn)\n}", "label": 5}
{"code": "@Deprecated\n\tpublic List<Double> getResolutions() {\n\t\tList<Double> resolutions = new ArrayList<Double>();\n\t\tfor (ScaleInfo scale : getZoomLevels()) {\n\t\t\tresolutions.add(1. / scale.getPixelPerUnit());\n\t\t}\n\t\treturn resolutions;\n\t}", "label": 0}
{"code": "def run(self, fetch_image=True, **kwargs):\n        \"\"\"\n        Create the container and start it. Similar to ``docker run``.\n\n        :param fetch_image:\n            Whether to try pull the image if it's not found. The behaviour here\n            is similar to ``docker run`` and this parameter defaults to\n            ``True``.\n        :param **kwargs: Keyword arguments passed to :meth:`.create`.\n        \"\"\"\n        self.create(fetch_image=fetch_image, **kwargs)\n        self.start()", "label": 1}
{"code": "public static <E> Counter<E> linearCombination(Counter<E> c1, double w1, Counter<E> c2, double w2) {\r\n    Counter<E> result = c1.getFactory().create();\r\n    for (E o : c1.keySet()) {\r\n      result.incrementCount(o, c1.getCount(o) * w1);\r\n    }\r\n    for (E o : c2.keySet()) {\r\n      result.incrementCount(o, c2.getCount(o) * w2);\r\n    }\r\n    return result;\r\n  }", "label": 0}
{"code": "func writeYAML(w io.Writer, values interface{}) error {\n\tdata, err := yaml.Marshal(values)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t_, err = w.Write(data)\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "def convertTime(self, time):\n        \"\"\"Convert a datetime object representing a time into a human-ready\n        string that can be read, spoken aloud, etc.\n\n        Args:\n            time (datetime.date): A datetime object to be converted into text.\n\n        Returns:\n            A string representation of the input time, ignoring any day-related\n            information.\n        \"\"\"\n        # if ':00', ignore reporting minutes\n        m_format = \"\"\n        if time.minute:\n            m_format = \":%M\"\n\n        timeString = time.strftime(\"%I\" + m_format + \" %p\")\n\n        # if '07:30', cast to '7:30'\n        if not int(timeString[0]):\n            timeString = timeString[1:]\n\n        return timeString", "label": 1}
{"code": "function readable(file) {\n  if (!exists(file)) {\n    return false;\n  } else {\n    try {\n      fs.accessSync(file, fs.R_OK);\n    } catch (e) {\n      return false;\n    }\n    return true;\n  }\n}", "label": 3}
{"code": "def handle(service)\n      @run_mutex.synchronize do\n        unless @running_state == :not_started\n          fail 'cannot add services if the server has been started'\n        end\n        cls = service.is_a?(Class) ? service : service.class\n        assert_valid_service_class(cls)\n        add_rpc_descs_for(service)\n      end\n    end", "label": 4}
{"code": "def left_overlaps(self, other, min_overlap_size=1):\n        \"\"\"\n        Does this VariantSequence overlap another on the left side?\n        \"\"\"\n\n        if self.alt != other.alt:\n            # allele must match!\n            return False\n\n        if len(other.prefix) > len(self.prefix):\n            # only consider strings that overlap like:\n            #   self: ppppAssss\n            #   other:   ppAsssssss\n            # which excludes cases where the other sequence has a longer\n            # prefix\n            return False\n        elif len(other.suffix) < len(self.suffix):\n            # similarly, we throw away cases where the other sequence is shorter\n            # after the alt nucleotides than this sequence\n            return False\n\n        # is the other sequence a prefix of this sequence?\n        # Example:\n        # p1 a1 s1 = XXXXXXXX Y ZZZZZZ\n        # p2 a2 s2 =       XX Y ZZZZZZZZZ\n        # ...\n        # then we can combine them into a longer sequence\n        sequence_overlaps = (\n            self.prefix.endswith(other.prefix) and\n            other.suffix.startswith(self.suffix)\n        )\n        prefix_overlap_size = min(len(self.prefix), len(other.prefix))\n        suffix_overlap_size = min(len(other.suffix), len(self.suffix))\n        overlap_size = (\n            prefix_overlap_size + suffix_overlap_size + len(self.alt))\n\n        return sequence_overlaps and overlap_size >= min_overlap_size", "label": 1}
{"code": "function getReferenceIndexedByCSS(ref) {\n    var newRef = {};\n    for (var symb in ref.symbolizers) {\n        for (var property in ref.symbolizers[symb]) {\n            newRef[ref.symbolizers[symb][property].css] = ref.symbolizers[symb][property];\n        }\n    }\n    return newRef;\n}", "label": 3}
{"code": "public static Optional<Tag> parse(final String httpTag) {\r\n        Tag result = null;\r\n        boolean weak = false;\r\n        String internal = httpTag;\r\n\r\n        if (internal.startsWith(\"W/\")) {\r\n            weak = true;\r\n            internal = internal.substring(2);\r\n        }\r\n\r\n        if (internal.startsWith(\"\\\"\") && internal.endsWith(\"\\\"\")) {\r\n            result = new Tag(\r\n                    internal.substring(1, internal.length() - 1), weak);\r\n        }\r\n        else if (internal.equals(\"*\")) {\r\n            result = new Tag(\"*\", weak);\r\n        }\r\n\r\n        return Optional.ofNullable(result);\r\n    }", "label": 0}
{"code": "public static function from($target)\n    {\n        return collect((new ReflectionClass($target))->getProperties())\n            ->mapWithKeys(function ($property) use ($target) {\n                $property->setAccessible(true);\n\n                if (($value = $property->getValue($target)) instanceof Model) {\n                    return [$property->getName() => FormatModel::given($value)];\n                } elseif (is_object($value)) {\n                    return [\n                        $property->getName() => [\n                            'class' => get_class($value),\n                            'properties' => json_decode(json_encode($value), true),\n                        ],\n                    ];\n                } else {\n                    return [$property->getName() => json_decode(json_encode($value), true)];\n                }\n            })->toArray();\n    }", "label": 2}
{"code": "final public void addPosition(int position) {\n    if (tokenPosition == null) {\n      tokenPosition = new MtasPosition(position);\n    } else {\n      tokenPosition.add(position);\n    }\n  }", "label": 0}
{"code": "func (o *OIDCConnectorV1) V2() *OIDCConnectorV2 {\n\treturn &OIDCConnectorV2{\n\t\tKind:    KindOIDCConnector,\n\t\tVersion: V2,\n\t\tMetadata: Metadata{\n\t\t\tName: o.ID,\n\t\t},\n\t\tSpec: OIDCConnectorSpecV2{\n\t\t\tIssuerURL:     o.IssuerURL,\n\t\t\tClientID:      o.ClientID,\n\t\t\tClientSecret:  o.ClientSecret,\n\t\t\tRedirectURL:   o.RedirectURL,\n\t\t\tDisplay:       o.Display,\n\t\t\tScope:         o.Scope,\n\t\t\tClaimsToRoles: o.ClaimsToRoles,\n\t\t},\n\t}\n}", "label": 5}
{"code": "def content(options = {}, &block)\n      config.set_page_presenter :index, ActiveAdmin::PagePresenter.new(options, &block)\n    end", "label": 4}
{"code": "protected function sendGetGroupsFiltered($type)\n    {\n        $msgID = $this->nodeId['getgroups'] = $this->createIqId();\n        $child = new ProtocolNode($type, null, null, null);\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgID,\n                'type'  => 'get',\n                'xmlns' => 'w:g2',\n                'to'    => Constants::WHATSAPP_GROUP_SERVER,\n            ], [$child], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "public function setConditionThreshold($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Monitoring\\V3\\AlertPolicy_Condition_MetricThreshold::class);\n        $this->writeOneof(1, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public function exception(string $exception, $closure)\n    {\n        $this->exceptionHandler->register($exception, $this->getCallable($closure));\n    }", "label": 2}
{"code": "function init(loader) {\n  var loaderConfig = loaderUtils.getLoaderConfig(loader, 'web3Loader');\n  web3 = require('./lib/web3')(loaderConfig.provider);\n  config = mergeConfig(loaderConfig);\n  isDebug = loader.debug;\n}", "label": 3}
{"code": "func (s *ClusterConfigurationService) DeleteClusterName() error {\n\terr := s.Delete(context.TODO(), backend.Key(clusterConfigPrefix, namePrefix))\n\tif err != nil {\n\t\tif trace.IsNotFound(err) {\n\t\t\treturn trace.NotFound(\"cluster configuration not found\")\n\t\t}\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "func (r *AddressRange) MarshalJSON() ([]byte, error) {\n\tm := map[string]interface{}{\n\t\t\"Sub\":   r.Sub.String(),\n\t\t\"Start\": r.Start,\n\t\t\"End\":   r.End,\n\t}\n\treturn json.Marshal(m)\n}", "label": 5}
{"code": "public static java.sql.Time toTime(Object value) throws ParseException {\n        if (value == null) {\n            return null;\n        }\n        if (value instanceof java.sql.Time) {\n            return (java.sql.Time) value;\n        }\n        if (value instanceof String) {\n            if (\"\".equals((String) value)) {\n                return null;\n            }\n            return new java.sql.Time(IN_TIME_FORMAT.parse((String) value).getTime());\n        }\n\n        return new java.sql.Time(IN_TIME_FORMAT.parse(value.toString()).getTime());\n    }", "label": 0}
{"code": "func (i *Handle) parseConfig(msg []byte) (*Config, error) {\n\tvar c Config\n\n\t//Remove General header for this message\n\thdr := deserializeGenlMsg(msg)\n\tattrs, err := nl.ParseRouteAttr(msg[hdr.Len():])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, attr := range attrs {\n\t\tattrType := int(attr.Attr.Type)\n\t\tswitch attrType {\n\t\tcase ipvsCmdAttrTimeoutTCP:\n\t\t\tc.TimeoutTCP = time.Duration(native.Uint32(attr.Value)) * time.Second\n\t\tcase ipvsCmdAttrTimeoutTCPFin:\n\t\t\tc.TimeoutTCPFin = time.Duration(native.Uint32(attr.Value)) * time.Second\n\t\tcase ipvsCmdAttrTimeoutUDP:\n\t\t\tc.TimeoutUDP = time.Duration(native.Uint32(attr.Value)) * time.Second\n\t\t}\n\t}\n\n\treturn &c, nil\n}", "label": 5}
{"code": "def delete_customer(customer_id, opts = {})\n      data, _status_code, _headers = delete_customer_with_http_info(customer_id, opts)\n      return data\n    end", "label": 4}
{"code": "func (auup *AuthUserUserPermission) Delete(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !auup._exists {\n\t\treturn nil\n\t}\n\n\t// if deleted, bail\n\tif auup._deleted {\n\t\treturn nil\n\t}\n\n\t// sql query\n\tconst sqlstr = `DELETE FROM public.auth_user_user_permissions WHERE id = $1`\n\n\t// run query\n\tXOLog(sqlstr, auup.ID)\n\t_, err = db.Exec(sqlstr, auup.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// set deleted\n\tauup._deleted = true\n\n\treturn nil\n}", "label": 5}
{"code": "def on(event, &proc)\n      unless @events.has_key? event\n        raise Error, \"`#{event}` is not a valid event type\"\n      end\n      event_id = new_event_key\n      @events[event][event_id] = proc\n      EventDescriptor.new(event, event_id)\n    end", "label": 4}
{"code": "def content_types\n      c_types = base_content_types\n      workbook.drawings.each do |drawing|\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{drawing.pn}\",\n                                       :ContentType => DRAWING_CT)\n      end\n\n      workbook.charts.each do |chart|\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{chart.pn}\",\n                                       :ContentType => CHART_CT)\n      end\n\n      workbook.tables.each do |table|\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{table.pn}\",\n                                       :ContentType => TABLE_CT)\n      end\n\n      workbook.pivot_tables.each do |pivot_table|\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{pivot_table.pn}\",\n                                       :ContentType => PIVOT_TABLE_CT)\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{pivot_table.cache_definition.pn}\",\n                                       :ContentType => PIVOT_TABLE_CACHE_DEFINITION_CT)\n      end\n\n      workbook.comments.each do |comment|\n        if comment.size > 0\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{comment.pn}\",\n                                       :ContentType => COMMENT_CT)\n        end\n      end\n\n      if workbook.comments.size > 0\n        c_types << Axlsx::Default.new(:Extension => \"vml\", :ContentType => VML_DRAWING_CT)\n      end\n\n      workbook.worksheets.each do |sheet|\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{sheet.pn}\",\n                                         :ContentType => WORKSHEET_CT)\n      end\n      exts = workbook.images.map { |image| image.extname.downcase }\n      exts.uniq.each do |ext|\n        ct = if  ['jpeg', 'jpg'].include?(ext)\n               JPEG_CT\n             elsif ext == 'gif'\n               GIF_CT\n             elsif ext == 'png'\n               PNG_CT\n             end\n        c_types << Axlsx::Default.new(:ContentType => ct, :Extension => ext )\n      end\n      if use_shared_strings\n        c_types << Axlsx::Override.new(:PartName => \"/xl/#{SHARED_STRINGS_PN}\",\n                                       :ContentType => SHARED_STRINGS_CT)\n      end\n      c_types\n    end", "label": 4}
{"code": "def run(task, scope_hash = {})\n      Lumberjack.unit_of_work do\n        items = Guard.state.scope.grouped_plugins(scope_hash || {})\n        items.each do |_group, plugins|\n          _run_group_plugins(plugins) do |plugin|\n            _supervise(plugin, task) if plugin.respond_to?(task)\n          end\n        end\n      end\n    end", "label": 4}
{"code": "func (ca *CertAuthorityV2) FirstSigningKey() ([]byte, error) {\n\tif len(ca.Spec.SigningKeys) == 0 {\n\t\treturn nil, trace.NotFound(\"%v has no signing keys\", ca.Metadata.Name)\n\t}\n\treturn ca.Spec.SigningKeys[0], nil\n}", "label": 5}
{"code": "def prepare_fields_attribute(attribute_name, attributes, class_name):\n        \"\"\"Prepare model fields attribute.\"\"\"\n        attribute = attributes.get(attribute_name)\n        if not attribute:\n            attribute = tuple()\n        elif isinstance(attribute, std_collections.Iterable):\n            attribute = tuple(attribute)\n        else:\n            raise errors.Error('{0}.{1} is supposed to be a list of {2}, '\n                               'instead {3} given', class_name, attribute_name,\n                               fields.Field, attribute)\n        return attribute", "label": 1}
{"code": "function (parserOptions) {\n            var me = this;\n            if (parserOptions) {\n                _gpfArrayForEach([\n                    \"header\",\n                    \"separator\",\n                    \"quote\",\n                    \"newLine\"\n                ], function (optionName) {\n                    if (parserOptions[optionName]) {\n                        me[\"_\" + optionName] = parserOptions[optionName];\n                    }\n                });\n            }\n        }", "label": 3}
{"code": "function Adapter() {\n  expect(this).to.be.an(\n    'object',\n    'The Adapter\\'s constructor can be only invoked from specialized' +\n    'classes\\' constructors'\n  );\n\n  expect(this.constructor).to.be.a(\n    'function',\n    'The Adapter\\'s constructor can be only invoked from specialized' +\n    'classes\\' constructors'\n  );\n\n  expect(this.constructor).to.not.equal(\n    Adapter,\n    'The Adapter is an abstract class and cannot be directly initialized'\n  );\n\n  expect(this).to.be.instanceof(\n    Adapter,\n    'The Adapter\\'s constructor can be only invoked from specialized' +\n    'classes\\' constructors'\n  );\n}", "label": 3}
{"code": "protected function convertWrappedDefinitionNode($node, array $wrappers = []): Type\n    {\n        // Recursively unwrap the type and save the wrappers\n        if ($node->kind === NodeKind::NON_NULL_TYPE || $node->kind === NodeKind::LIST_TYPE) {\n            $wrappers[] = $node->kind;\n\n            return $this->convertWrappedDefinitionNode(\n                $node->type,\n                $wrappers\n            );\n        }\n\n        // Re-wrap the type by applying the wrappers in the reversed order\n        return (new Collection($wrappers))\n            ->reverse()\n            ->reduce(\n                function (Type $type, string $kind): Type {\n                    if ($kind === NodeKind::NON_NULL_TYPE) {\n                        return Type::nonNull($type);\n                    }\n\n                    if ($kind === NodeKind::LIST_TYPE) {\n                        return Type::listOf($type);\n                    }\n\n                    return $type;\n                },\n                $this->convertNamedTypeNode($node)\n            );\n    }", "label": 2}
{"code": "public function setRecordSuppress($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\RecordSuppression::class);\n        $this->record_suppress = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setModel($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\Model::class);\n        $this->model = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function bind(el, _ref) {\n      var modifiers = _ref.modifiers;\n\n      var target;\n\n      // Support children's modifier\n      target = modifiers.children ? Array.from(el.children) : el;\n\n      // Add balance text to the element\n      Vue.nextTick(function () {\n        return balanceText(target, {\n          watch: true\n        });\n      });\n      // Manually fire again later, like after styles are injected by Webpack\n      return setTimeout(function () {\n        return balanceText(target);\n      }, 300);\n    }", "label": 3}
{"code": "function parsePages(options) {\n  return readFileTree(options.src.pages, options.keys.pages, options);\n}", "label": 3}
{"code": "def use_two_cell_anchor\n      return if @anchor.is_a?(TwoCellAnchor)\n      new_anchor = TwoCellAnchor.new(@anchor.drawing, :start_at => [@anchor.from.col, @anchor.from.row])\n      swap_anchor(new_anchor)\n    end", "label": 4}
{"code": "public static double Correlation(double[] p, double[] q) {\n\n        double x = 0;\n        double y = 0;\n\n        for (int i = 0; i < p.length; i++) {\n            x += -p[i];\n            y += -q[i];\n        }\n\n        x /= p.length;\n        y /= q.length;\n\n        double num = 0;\n        double den1 = 0;\n        double den2 = 0;\n        for (int i = 0; i < p.length; i++) {\n            num += (p[i] + x) * (q[i] + y);\n\n            den1 += Math.abs(Math.pow(p[i] + x, 2));\n            den2 += Math.abs(Math.pow(q[i] + x, 2));\n        }\n\n        return 1 - (num / (Math.sqrt(den1) * Math.sqrt(den2)));\n\n    }", "label": 0}
{"code": "public static function add_wp_hook( $tag, $function_to_add, $priority = 10, $accepted_args = 1 ) {\n\t\tglobal $wp_filter, $merged_filters;\n\n\t\tif ( function_exists( 'add_filter' ) ) {\n\t\t\tadd_filter( $tag, $function_to_add, $priority, $accepted_args );\n\t\t} else {\n\t\t\t$idx = self::wp_hook_build_unique_id( $tag, $function_to_add, $priority );\n\n\t\t\t// phpcs:ignore WordPress.WP.GlobalVariablesOverride.Prohibited -- This is intentional & the purpose of this function.\n\t\t\t$wp_filter[ $tag ][ $priority ][ $idx ] = array(\n\t\t\t\t'function'      => $function_to_add,\n\t\t\t\t'accepted_args' => $accepted_args,\n\t\t\t);\n\t\t\tunset( $merged_filters[ $tag ] );\n\t\t}\n\n\t\treturn true;\n\t}", "label": 2}
{"code": "protected ClassDescriptor selectClassDescriptor(Map row) throws PersistenceBrokerException\r\n    {\r\n        ClassDescriptor result = m_cld;\r\n        Class ojbConcreteClass = (Class) row.get(OJB_CONCRETE_CLASS_KEY);\r\n        if(ojbConcreteClass != null)\r\n        {\r\n            result = m_cld.getRepository().getDescriptorFor(ojbConcreteClass);\r\n            // if we can't find class-descriptor for concrete class, something wrong with mapping\r\n            if (result == null)\r\n            {\r\n                throw new PersistenceBrokerException(\"Can't find class-descriptor for ojbConcreteClass '\"\r\n                        + ojbConcreteClass + \"', the main class was \" + m_cld.getClassNameOfObject());\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "def get\n      begin\n        easy.http_request(\n          request.base_url.to_s,\n          request.options.fetch(:method, :get),\n          sanitize(request.options)\n        )\n      rescue Ethon::Errors::InvalidOption => e\n        help = provide_help(e.message.match(/:\\s(\\w+)/)[1])\n        raise $!, \"#{$!}#{help}\", $!.backtrace\n      end\n      set_callback\n      easy\n    end", "label": 4}
{"code": "protected boolean _load ()\r\n    {\r\n        java.sql.ResultSet rs = null;\r\n        try\r\n        {\r\n            \r\n            // This synchronization is necessary for Oracle JDBC drivers 8.1.7, 9.0.1, 9.2.0.1\r\n            // The documentation says synchronization is done within the driver, but they\r\n            // must have overlooked something. Without the lock we'd get mysterious error\r\n            // messages.            \r\n            synchronized(getDbMeta())\r\n            {\r\n            \r\n                getDbMetaTreeModel().setStatusBarMessage(\"Reading schemas for catalog \" \r\n                    + this.getAttribute(ATT_CATALOG_NAME));\r\n                rs = getDbMeta().getSchemas();\r\n                final java.util.ArrayList alNew = new java.util.ArrayList();\r\n                int count = 0;\r\n                while (rs.next())\r\n                {\r\n                    getDbMetaTreeModel().setStatusBarMessage(\"Creating schema \" + getCatalogName() + \".\" + rs.getString(\"TABLE_SCHEM\"));\r\n                    alNew.add(new DBMetaSchemaNode(getDbMeta(),\r\n                                                   getDbMetaTreeModel(),\r\n                                                   DBMetaCatalogNode.this, \r\n                                                   rs.getString(\"TABLE_SCHEM\")));\r\n                    count++;\r\n                }\r\n                if (count == 0) \r\n                    alNew.add(new DBMetaSchemaNode(getDbMeta(), \r\n                                                   getDbMetaTreeModel(),\r\n                                                   DBMetaCatalogNode.this, null));\r\n                alChildren = alNew;            \r\n                javax.swing.SwingUtilities.invokeLater(new Runnable()\r\n                {\r\n                    public void run()\r\n                    {\r\n                        getDbMetaTreeModel().nodeStructureChanged(DBMetaCatalogNode.this);\r\n                    }\r\n                });\r\n                rs.close();\r\n            }\r\n        }\r\n        catch (java.sql.SQLException sqlEx)\r\n        {\r\n            getDbMetaTreeModel().reportSqlError(\"Error retrieving schemas\", sqlEx);\r\n            try\r\n            {\r\n                if (rs != null) rs.close ();\r\n            }\r\n            catch (java.sql.SQLException sqlEx2)\r\n            {\r\n                this.getDbMetaTreeModel().reportSqlError(\"Error retrieving schemas\", sqlEx2);\r\n            }                        \r\n            return false;\r\n        }\r\n        return true;\r\n    }", "label": 0}
{"code": "public function encodeValues(array $fields)\n    {\n        $output = [];\n\n        foreach ($fields as $key => $val) {\n            $output[$key] = $this->encodeValue($val);\n        }\n\n        return $output;\n    }", "label": 2}
{"code": "private function getRequestOptions(array $options)\n    {\n        $restOptions = isset($options['restOptions'])\n            ? $options['restOptions']\n            : $this->restOptions;\n        $timeout = isset($options['requestTimeout'])\n            ? $options['requestTimeout']\n            : $this->requestTimeout;\n\n        if ($timeout && !array_key_exists('timeout', $restOptions)) {\n            $restOptions['timeout'] = $timeout;\n        }\n\n        return $restOptions;\n    }", "label": 2}
{"code": "def is_local_branch?(branch)\n      branch_names = self.branches.local.map {|b| b.name}\n      branch_names.include?(branch)\n    end", "label": 4}
{"code": "public function getIamPolicy($resource, array $optionalArgs = [])\n    {\n        $request = new GetIamPolicyRequest();\n        $request->setResource($resource);\n\n        $requestParams = new RequestParamsHeaderDescriptor([\n          'resource' => $request->getResource(),\n        ]);\n        $optionalArgs['headers'] = isset($optionalArgs['headers'])\n            ? array_merge($requestParams->getHeader(), $optionalArgs['headers'])\n            : $requestParams->getHeader();\n\n        return $this->startCall(\n            'GetIamPolicy',\n            Policy::class,\n            $optionalArgs,\n            $request,\n            Call::UNARY_CALL,\n            'google.iam.v1.IAMPolicy'\n        )->wait();\n    }", "label": 2}
{"code": "func getAppName(p *pkgPod.Pod) (*types.ACName, error) {\n\tif flagAppName != \"\" {\n\t\treturn types.NewACName(flagAppName)\n\t}\n\n\t// figure out the app name, or show a list if multiple are present\n\t_, m, err := p.PodManifest()\n\tif err != nil {\n\t\treturn nil, errwrap.Wrap(errors.New(\"error reading pod manifest\"), err)\n\t}\n\n\tswitch len(m.Apps) {\n\tcase 0:\n\t\treturn nil, fmt.Errorf(\"pod contains zero apps\")\n\tcase 1:\n\t\treturn &m.Apps[0].Name, nil\n\tdefault:\n\t}\n\n\tstderr.Print(\"pod contains multiple apps:\")\n\tfor _, ra := range m.Apps {\n\t\tstderr.Printf(\"\\t%v\", ra.Name)\n\t}\n\n\treturn nil, fmt.Errorf(\"specify app using \\\"rkt enter --app= ...\\\"\")\n}", "label": 5}
{"code": "function resolveNewPath(newBase) {\n    return mapSync(file => {\n      file.cwd += newBase;\n      file.base = file.cwd;\n      return file;\n    });\n  }", "label": 3}
{"code": "function focusAtEnd(change) {\n    const { value } = change;\n    const document = value.document;\n    return change.collapseToEndOf(document);\n}", "label": 3}
{"code": "public static lbparameter get(nitro_service service) throws Exception{\n\t\tlbparameter obj = new lbparameter();\n\t\tlbparameter[] response = (lbparameter[])obj.get_resources(service);\n\t\treturn response[0];\n\t}", "label": 0}
{"code": "func (c *Client) GetOIDCConnector(id string, withSecrets bool) (services.OIDCConnector, error) {\n\tif id == \"\" {\n\t\treturn nil, trace.BadParameter(\"missing connector id\")\n\t}\n\tout, err := c.Get(c.Endpoint(\"oidc\", \"connectors\", id),\n\t\turl.Values{\"with_secrets\": []string{fmt.Sprintf(\"%t\", withSecrets)}})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn services.GetOIDCConnectorMarshaler().UnmarshalOIDCConnector(out.Bytes(), services.SkipValidation())\n}", "label": 5}
{"code": "public static scpolicy_stats[] get(nitro_service service) throws Exception{\n\t\tscpolicy_stats obj = new scpolicy_stats();\n\t\tscpolicy_stats[] response = (scpolicy_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def verbatim(parser, token):\n    \"\"\"Tag to render x-tmpl templates with Django template code.\"\"\"\n    text = []\n    while 1:\n        token = parser.tokens.pop(0)\n        if token.contents == 'endverbatim':\n            break\n        if token.token_type == TOKEN_VAR:\n            text.append('{{ ')\n        elif token.token_type == TOKEN_BLOCK:\n            text.append('{%')\n        text.append(token.contents)\n        if token.token_type == TOKEN_VAR:\n            text.append(' }}')\n        elif token.token_type == TOKEN_BLOCK:\n            if not text[-1].startswith('='):\n                text[-1:-1] = [' ']\n            text.append(' %}')\n    return VerbatimNode(''.join(text))", "label": 1}
{"code": "def getScienceMetadataRDF(self, pid):\n        \"\"\" Get science metadata for a resource in XML+RDF format\n\n        :param pid: The HydroShare ID of the resource\n        :raises: HydroShareNotAuthorized if the user is not authorized to view the metadata.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException to signal an HTTP error.\n        :return: A string representing the XML+RDF serialization of science metadata.\n        Example of data XML+RDF returned:\n\n        <?xml version=\"1.0\"?>\n        <!DOCTYPE rdf:RDF PUBLIC \"-//DUBLIN CORE//DCMES DTD 2002/07/31//EN\"\n        \"http://dublincore.org/documents/2002/07/31/dcmes-xml/dcmes-xml-dtd.dtd\">\n        <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:hsterms=\"http://hydroshare.org/terms/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1=\"http://www.w3.org/2001/01/rdf-schema#\">\n          <rdf:Description rdf:about=\"http://www.hydroshare.org/resource/87ffb608900e407ab4b67d30c93b329e\">\n            <dc:title>Great Salt Lake Level and Volume</dc:title>\n            <dc:type rdf:resource=\"http://www.hydroshare.org/terms/GenericResource\"/>\n            <dc:description>\n              <rdf:Description>\n                <dcterms:abstract>Time series of level, area and volume in the Great Salt Lake. Volume and area of the Great Salt Lake are derived from recorded levels</dcterms:abstract>\n              </rdf:Description>\n            </dc:description>\n            <hsterms:awardInfo>\n              <rdf:Description rdf:about=\"http://www.nsf.gov\">\n                <hsterms:fundingAgencyName>National Science Foundation</hsterms:fundingAgencyName>\n                <hsterms:awardTitle>Model Execution Cyberinfrastructure </hsterms:awardTitle>\n                <hsterms:awardNumber>NSF_9087658_2017</hsterms:awardNumber>\n              </rdf:Description>\n            </hsterms:awardInfo>\n            <dc:creator>\n              <rdf:Description>\n                <hsterms:name>John Smith</hsterms:name>\n                <hsterms:creatorOrder>1</hsterms:creatorOrder>\n                <hsterms:organization>Utah State University</hsterms:organization>\n                <hsterms:email>john.smith@gmail.com</hsterms:email>\n                <hsterms:address>Engineering Building, USU, Logan, Utah</hsterms:address>\n                <hsterms:phone rdf:resource=\"tel:435-797-8967\"/>\n              </rdf:Description>\n            </dc:creator>\n            <dc:creator>\n              <rdf:Description>\n                <hsterms:name>Lisa Miller</hsterms:name>\n                <hsterms:creatorOrder>2</hsterms:creatorOrder>\n              </rdf:Description>\n            </dc:creator>\n            <dc:contributor>\n              <rdf:Description>\n                <hsterms:name>Jenny Parker</hsterms:name>\n                <hsterms:organization>Univesity of Utah</hsterms:organization>\n                <hsterms:email>jenny_parker@hotmail.com</hsterms:email>\n              </rdf:Description>\n            </dc:contributor>\n            <dc:coverage>\n              <dcterms:period>\n                <rdf:value>start=2000-01-01T00:00:00; end=2010-12-12T00:00:00; scheme=W3C-DTF</rdf:value>\n              </dcterms:period>\n            </dc:coverage>\n            <dc:date>\n              <dcterms:created>\n                <rdf:value>2017-01-03T17:06:18.932217+00:00</rdf:value>\n              </dcterms:created>\n            </dc:date>\n            <dc:date>\n              <dcterms:modified>\n                <rdf:value>2017-01-03T17:35:34.067279+00:00</rdf:value>\n              </dcterms:modified>\n            </dc:date>\n            <dc:format>image/tiff</dc:format>\n            <dc:identifier>\n              <rdf:Description>\n                <hsterms:hydroShareIdentifier>http://www.hydroshare.org/resource/87ffb608900e407ab4b67d30c93b329e</hsterms:hydroShareIdentifier>\n              </rdf:Description>\n            </dc:identifier>\n            <dc:language>eng</dc:language>\n            <dc:rights>\n              <rdf:Description>\n                <hsterms:rightsStatement>This resource is shared under the Creative Commons Attribution CC BY.</hsterms:rightsStatement>\n                <hsterms:URL rdf:resource=\"http://creativecommons.org/licenses/by/4.0/\"/>\n              </rdf:Description>\n            </dc:rights>\n            <dc:subject>NSF</dc:subject>\n            <dc:subject>Model</dc:subject>\n            <dc:subject>Cyberinfrastructure</dc:subject>\n            <hsterms:extendedMetadata>\n              <rdf:Description>\n                <hsterms:key>model</hsterms:key>\n                <hsterms:value>ueb</hsterms:value>\n              </rdf:Description>\n            </hsterms:extendedMetadata>\n            <hsterms:extendedMetadata>\n              <rdf:Description>\n                <hsterms:key>os</hsterms:key>\n                <hsterms:value>windows</hsterms:value>\n              </rdf:Description>\n            </hsterms:extendedMetadata>\n          </rdf:Description>\n          <rdf:Description rdf:about=\"http://www.hydroshare.org/terms/GenericResource\">\n            <rdfs1:label>Generic</rdfs1:label>\n            <rdfs1:isDefinedBy>http://www.hydroshare.org/terms</rdfs1:isDefinedBy>\n          </rdf:Description>\n        </rdf:RDF>\n        \"\"\"\n\n        url = \"{url_base}/scimeta/{pid}/\".format(url_base=self.url_base, pid=pid)\n        r = self._request('GET', url)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('GET', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'GET', r.status_code))\n\n        return str(r.content)", "label": 1}
{"code": "public function setAssetDiscoveryConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\SecurityCenter\\V1\\OrganizationSettings_AssetDiscoveryConfig::class);\n        $this->asset_discovery_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function DeleteJob(\\Google\\Cloud\\Talent\\V4beta1\\DeleteJobRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.cloud.talent.v4beta1.JobService/DeleteJob',\n        $argument,\n        ['\\Google\\Protobuf\\GPBEmpty', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "func (s *AuthServer) CreateWebSession(user string) (services.WebSession, error) {\n\tsess, err := s.NewWebSession(user)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tif err := s.UpsertWebSession(user, sess); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tsess, err = services.GetWebSessionMarshaler().GenerateWebSession(sess)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn sess, nil\n}", "label": 5}
{"code": "public function RollbackNodePoolUpgrade(\\Google\\Cloud\\Container\\V1\\RollbackNodePoolUpgradeRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.container.v1.ClusterManager/RollbackNodePoolUpgrade',\n        $argument,\n        ['\\Google\\Cloud\\Container\\V1\\Operation', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "func (fst *fileTorrentImplIO) readFileAt(fi metainfo.FileInfo, b []byte, off int64) (n int, err error) {\n\tf, err := os.Open(fst.fts.fileInfoName(fi))\n\tif os.IsNotExist(err) {\n\t\t// File missing is treated the same as a short file.\n\t\terr = io.EOF\n\t\treturn\n\t}\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer f.Close()\n\t// Limit the read to within the expected bounds of this file.\n\tif int64(len(b)) > fi.Length-off {\n\t\tb = b[:fi.Length-off]\n\t}\n\tfor off < fi.Length && len(b) != 0 {\n\t\tn1, err1 := f.ReadAt(b, off)\n\t\tb = b[n1:]\n\t\tn += n1\n\t\toff += int64(n1)\n\t\tif n1 == 0 {\n\t\t\terr = err1\n\t\t\tbreak\n\t\t}\n\t}\n\treturn\n}", "label": 5}
{"code": "public static base_responses delete(nitro_service client, String ciphergroupname[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (ciphergroupname != null && ciphergroupname.length > 0) {\n\t\t\tsslcipher deleteresources[] = new sslcipher[ciphergroupname.length];\n\t\t\tfor (int i=0;i<ciphergroupname.length;i++){\n\t\t\t\tdeleteresources[i] = new sslcipher();\n\t\t\t\tdeleteresources[i].ciphergroupname = ciphergroupname[i];\n\t\t\t}\n\t\t\tresult = delete_bulk_request(client, deleteresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static vpnglobal_auditnslogpolicy_binding[] get_filtered(nitro_service service, filtervalue[] filter) throws Exception{\n\t\tvpnglobal_auditnslogpolicy_binding obj = new vpnglobal_auditnslogpolicy_binding();\n\t\toptions option = new options();\n\t\toption.set_filter(filter);\n\t\tvpnglobal_auditnslogpolicy_binding[] response = (vpnglobal_auditnslogpolicy_binding[]) obj.getfiltered(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (p *printer) marshalInterface(val Marshaler, start StartElement) error {\n\t// Push a marker onto the tag stack so that MarshalXML\n\t// cannot close the XML tags that it did not open.\n\tp.tags = append(p.tags, Name{})\n\tn := len(p.tags)\n\n\terr := val.MarshalXML(p.encoder, start)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Make sure MarshalXML closed all its tags. p.tags[n-1] is the mark.\n\tif len(p.tags) > n {\n\t\treturn fmt.Errorf(\"xml: %s.MarshalXML wrote invalid XML: <%s> not closed\", receiverType(val), p.tags[len(p.tags)-1].Local)\n\t}\n\tp.tags = p.tags[:n-1]\n\treturn nil\n}", "label": 5}
{"code": "def thresholdcoloring(coloring, names):\n    \"\"\"\n    Threshold a coloring dictionary for a given list of column names.\n\n    Threshold `coloring` based on `names`, a list of strings in::\n\n        coloring.values()\n\n    **Parameters**\n\n        **coloring** :  dictionary\n\n            Hierarchical structure on the columns given in the header of the \n            file; an attribute of tabarrays.\n\n            See :func:`tabular.tab.tabarray.__new__` for more information about \n            coloring.\n\n        **names** :  list of strings\n\n            List of strings giving column names.\n\n    **Returns**\n\n        **newcoloring** :  dictionary\n\n            The thresholded coloring dictionary.\n\n    \"\"\"\n    for key in coloring.keys():\n        if len([k for k in coloring[key] if k in names]) == 0:\n            coloring.pop(key)\n        else:\n            coloring[key] = utils.uniqify([k for k in coloring[key] if k in \n                                           names])\n    return coloring", "label": 1}
{"code": "function getApparentTypeOfTypeParameter(type) {\n            if (!type.resolvedApparentType) {\n                var constraintType = getConstraintOfTypeParameter(type);\n                while (constraintType && constraintType.flags & 16384 /* TypeParameter */) {\n                    constraintType = getConstraintOfTypeParameter(constraintType);\n                }\n                type.resolvedApparentType = getTypeWithThisArgument(constraintType || emptyObjectType, type);\n            }\n            return type.resolvedApparentType;\n        }", "label": 3}
{"code": "function validateIfDeprecated (directives) {\n  if (!directives.length) {\n    return false\n  }\n\n  return directives.some(directive => directive.name.value === 'deprecated')\n}", "label": 3}
{"code": "public static base_responses add(nitro_service client, scpolicy resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tscpolicy addresources[] = new scpolicy[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\taddresources[i] = new scpolicy();\n\t\t\t\taddresources[i].name = resources[i].name;\n\t\t\t\taddresources[i].url = resources[i].url;\n\t\t\t\taddresources[i].rule = resources[i].rule;\n\t\t\t\taddresources[i].delay = resources[i].delay;\n\t\t\t\taddresources[i].maxconn = resources[i].maxconn;\n\t\t\t\taddresources[i].action = resources[i].action;\n\t\t\t\taddresources[i].altcontentsvcname = resources[i].altcontentsvcname;\n\t\t\t\taddresources[i].altcontentpath = resources[i].altcontentpath;\n\t\t\t}\n\t\t\tresult = add_bulk_request(client, addresources);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "private Query getQueryByCriteriaCount(QueryByCriteria aQuery)\r\n    {\r\n        Class                 searchClass = aQuery.getSearchClass();\r\n        ReportQueryByCriteria countQuery  = null;\r\n        Criteria              countCrit   = null;\r\n        String[]              columns     = new String[1];\r\n\r\n        // BRJ: copied Criteria without groupby, orderby, and prefetched relationships\r\n        if (aQuery.getCriteria() != null)\r\n        {\r\n            countCrit = aQuery.getCriteria().copy(false, false, false);\r\n        }\r\n\r\n        if (aQuery.isDistinct())\r\n        {\r\n            // BRJ: Count distinct is dbms dependent\r\n            // hsql/sapdb: select count (distinct(person_id || project_id)) from person_project\r\n            // mysql: select count (distinct person_id,project_id) from person_project\r\n            // [tomdz]\r\n            // Some databases have no support for multi-column count distinct (e.g. Derby)\r\n            // Here we use a SELECT count(*) FROM (SELECT DISTINCT ...) instead \r\n            //\r\n            // concatenation of pk-columns is a simple way to obtain a single column\r\n            // but concatenation is also dbms dependent:\r\n            //\r\n            // SELECT count(distinct concat(row1, row2, row3)) mysql\r\n            // SELECT count(distinct (row1 || row2 || row3)) ansi\r\n            // SELECT count(distinct (row1 + row2 + row3)) ms sql-server\r\n\r\n            FieldDescriptor[] pkFields   = m_broker.getClassDescriptor(searchClass).getPkFields();\r\n            String[]          keyColumns = new String[pkFields.length];\r\n\r\n            if (pkFields.length > 1)\r\n            {\r\n                // TODO: Use ColumnName. This is a temporary solution because\r\n                // we cannot yet resolve multiple columns in the same attribute.\r\n                for (int idx = 0; idx < pkFields.length; idx++)\r\n                {\r\n                    keyColumns[idx] = pkFields[idx].getColumnName();\r\n                }\r\n            }\r\n            else\r\n            {\r\n                for (int idx = 0; idx < pkFields.length; idx++)\r\n                {\r\n                    keyColumns[idx] = pkFields[idx].getAttributeName();\r\n                }\r\n            }\r\n            // [tomdz]\r\n            // TODO: Add support for databases that do not support COUNT DISTINCT over multiple columns\r\n//            if (getPlatform().supportsMultiColumnCountDistinct())\r\n//            {\r\n//                columns[0] = \"count(distinct \" + getPlatform().concatenate(keyColumns) + \")\";\r\n//            }\r\n//            else\r\n//            {\r\n//                columns = keyColumns;\r\n//            }\r\n\r\n            columns[0] = \"count(distinct \" + getPlatform().concatenate(keyColumns) + \")\";\r\n        }\r\n        else\r\n        {\r\n            columns[0] = \"count(*)\";\r\n        }\r\n\r\n        // BRJ: we have to preserve indirection table !\r\n        if (aQuery instanceof MtoNQuery)\r\n        {\r\n            MtoNQuery                 mnQuery       = (MtoNQuery)aQuery;\r\n            ReportQueryByMtoNCriteria mnReportQuery = new ReportQueryByMtoNCriteria(searchClass, columns, countCrit);\r\n\r\n            mnReportQuery.setIndirectionTable(mnQuery.getIndirectionTable());\r\n            countQuery = mnReportQuery;\r\n        }\r\n        else\r\n        {\r\n            countQuery = new ReportQueryByCriteria(searchClass, columns, countCrit);\r\n        }\r\n\r\n        // BRJ: we have to preserve outer-join-settings (by Andr\u00e9 Markwalder)\r\n        for (Iterator outerJoinPath = aQuery.getOuterJoinPaths().iterator(); outerJoinPath.hasNext();)\r\n        {\r\n            String path = (String) outerJoinPath.next();\r\n\r\n            if (aQuery.isPathOuterJoin(path))\r\n            {\r\n                countQuery.setPathOuterJoin(path);\r\n            }\r\n        }\r\n\r\n        //BRJ: add orderBy Columns asJoinAttributes\r\n        List orderBy = aQuery.getOrderBy();\r\n\r\n        if ((orderBy != null) && !orderBy.isEmpty())\r\n        {\r\n            String[] joinAttributes = new String[orderBy.size()];\r\n\r\n            for (int idx = 0; idx < orderBy.size(); idx++)\r\n            {\r\n                joinAttributes[idx] = ((FieldHelper)orderBy.get(idx)).name;\r\n            }\r\n            countQuery.setJoinAttributes(joinAttributes);\r\n        }\r\n\r\n        // [tomdz]\r\n        // TODO:\r\n        // For those databases that do not support COUNT DISTINCT over multiple columns\r\n        // we wrap the normal SELECT DISTINCT that we just created, into a SELECT count(*)\r\n        // For this however we need a report query that gets its data from a sub query instead\r\n        // of a table (target class)\r\n//        if (aQuery.isDistinct() && !getPlatform().supportsMultiColumnCountDistinct())\r\n//        {\r\n//        }\r\n\r\n        return countQuery;\r\n    }", "label": 0}
{"code": "function loadTab(loadTabParams, loadTabOptions) {\n      // Load Tab Props\n      var url = loadTabParams.url;\n      var content = loadTabParams.content;\n      var el = loadTabParams.el;\n      var template = loadTabParams.template;\n      var templateUrl = loadTabParams.templateUrl;\n      var component = loadTabParams.component;\n      var componentUrl = loadTabParams.componentUrl;\n      // Component/Template Callbacks\n      function resolve(contentEl) {\n        router.allowPageChange = true;\n        if (!contentEl) { return; }\n        if (typeof contentEl === 'string') {\n          $newTabEl.html(contentEl);\n        } else {\n          $newTabEl.html('');\n          if (contentEl.f7Component) {\n            contentEl.f7Component.$mount(function (componentEl) {\n              $newTabEl.append(componentEl);\n            });\n          } else {\n            $newTabEl.append(contentEl);\n          }\n        }\n        $newTabEl[0].f7RouterTabLoaded = true;\n        onTabLoaded(contentEl);\n      }\n      function reject() {\n        router.allowPageChange = true;\n        return router;\n      }\n\n      if (content) {\n        resolve(content);\n      } else if (template || templateUrl) {\n        try {\n          router.tabTemplateLoader(template, templateUrl, loadTabOptions, resolve, reject);\n        } catch (err) {\n          router.allowPageChange = true;\n          throw err;\n        }\n      } else if (el) {\n        resolve(el);\n      } else if (component || componentUrl) {\n        // Load from component (F7/Vue/React/...)\n        try {\n          router.tabComponentLoader($newTabEl[0], component, componentUrl, loadTabOptions, resolve, reject);\n        } catch (err) {\n          router.allowPageChange = true;\n          throw err;\n        }\n      } else if (url) {\n        // Load using XHR\n        if (router.xhr) {\n          router.xhr.abort();\n          router.xhr = false;\n        }\n        router.xhrRequest(url, loadTabOptions)\n          .then(function (tabContent) {\n            resolve(tabContent);\n          })\n          .catch(function () {\n            router.allowPageChange = true;\n          });\n      }\n    }", "label": 3}
{"code": "def to_s(n_cmds)\n      show_size = n_cmds ? specific_max_size(n_cmds) : default_max_size\n\n      commands = buffer.last(show_size)\n\n      last_ids(show_size).zip(commands).map do |l|\n        format(\"%<position>5d  %<command>s\", position: l[0], command: l[1])\n      end.join(\"\\n\") + \"\\n\"\n    end", "label": 4}
{"code": "function _gpfEnumeratorEach (enumerator, callback, eventsHandler) {\n    var iEnumerator = _gpfI.query(enumerator, _gpfI.IEnumerator),\n        process;\n    function end (event) {\n        _gpfEventsFire.call(enumerator, event, {}, eventsHandler);\n    }\n    if (1 < callback.length) {\n        process = function (event) {\n            if (gpf.events.EVENT_CONTINUE === event.type) {\n                if (!iEnumerator.moveNext(process)) {\n                    return;\n                }\n            } else if (gpf.events.EVENT_STOP === event.type) {\n                return end(gpf.events.EVENT_STOPPED);\n            } else if (gpf.events.EVENT_DATA !== event.type) {\n                return end(event.type);\n            }\n            callback(iEnumerator.current(), process);\n        };\n        if (iEnumerator.moveNext(process)) {\n            callback(iEnumerator.current(), process);\n        }\n\n    } else {\n        process = function (event) {\n            if (gpf.events.EVENT_DATA !== event.type) {\n                return end(event);\n            }\n            do {\n                callback(iEnumerator.current());\n            } while (iEnumerator.moveNext(process));\n        };\n        while (iEnumerator.moveNext(process)) {\n            callback(iEnumerator.current());\n        }\n    }\n}", "label": 3}
{"code": "public function update($update = null, $alias = null)\n    {\n        $this->type = self::UPDATE;\n\n        if (! $update) {\n            return $this;\n        }\n\n        return $this->add('from', new Expr\\From($update, $alias));\n    }", "label": 2}
{"code": "def get_settings(*args)\n      SafeIndex.log_or_throw(:get_settings, @raise_on_failure) do\n        begin\n          @index.get_settings(*args)\n        rescue Algolia::AlgoliaError => e\n          return {} if e.code == 404 # not fatal\n          raise e\n        end\n      end\n    end", "label": 4}
{"code": "function () {\n\n            var chart = this.chart,\n              maxTicks = chart.maxTicks || {},\n              tickPositions = this.tickPositions,\n              key = this._maxTicksKey = [this.coll, this.pos, this.len].join('-');\n\n            if (!this.isLinked && !this.isDatetimeAxis && tickPositions && tickPositions.length > (maxTicks[key] || 0) && this.options.alignTicks !== false) {\n                maxTicks[key] = tickPositions.length;\n            }\n            chart.maxTicks = maxTicks;\n        }", "label": 3}
{"code": "public static wisite_binding[] get(nitro_service service, String sitepath[]) throws Exception{\n\t\tif (sitepath !=null && sitepath.length>0) {\n\t\t\twisite_binding response[] = new wisite_binding[sitepath.length];\n\t\t\twisite_binding obj[] = new wisite_binding[sitepath.length];\n\t\t\tfor (int i=0;i<sitepath.length;i++) {\n\t\t\t\tobj[i] = new wisite_binding();\n\t\t\t\tobj[i].set_sitepath(sitepath[i]);\n\t\t\t\tresponse[i] = (wisite_binding) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "function (cfg, state, n) {\n        return function (err) {\n            if (err.code == \"ENOENT\") {\n                logger.logError(\"Spawn: exited with code ENOENT. PhantomJS executable not found. Make sure to download PhantomJS and add its folder to your system's PATH, or pass the full path directly to Attester via --phantomjs-path.\\nUsed command: '\" + cfg.phantomPath + \"'\");\n            } else {\n                logger.logError(\"Unable to spawn PhantomJS; error code \" + err.code);\n            }\n        };\n    }", "label": 3}
{"code": "def perform!\n      Logger.info \"Creating Archive '#{name}'...\"\n\n      path = File.join(Config.tmp_path, @model.trigger, \"archives\")\n      FileUtils.mkdir_p(path)\n\n      pipeline = Pipeline.new\n      with_files_from(paths_to_package) do |files_from|\n        pipeline.add(\n          \"#{tar_command} #{tar_options} -cPf -#{tar_root} \" \\\n            \"#{paths_to_exclude} #{files_from}\",\n          tar_success_codes\n        )\n\n        extension = \"tar\"\n        if @model.compressor\n          @model.compressor.compress_with do |command, ext|\n            pipeline << command\n            extension << ext\n          end\n        end\n\n        pipeline << \"#{utility(:cat)} > \" \\\n          \"'#{File.join(path, \"#{name}.#{extension}\")}'\"\n        pipeline.run\n      end\n\n      if pipeline.success?\n        Logger.info \"Archive '#{name}' Complete!\"\n      else\n        raise Error, \"Failed to Create Archive '#{name}'\\n\" +\n          pipeline.error_messages\n      end\n    end", "label": 4}
{"code": "function requireWrapper(requireMe, provides, injects, directory) {\n    return  _require(requireMe, provides, injects, directory, simpleWrapper);\n  }", "label": 3}
{"code": "func (p *Decoder) unmarshalPath(tinfo *typeInfo, sv reflect.Value, parents []string, start *StartElement) (consumed bool, err error) {\n\trecurse := false\nLoop:\n\tfor i := range tinfo.fields {\n\t\tfinfo := &tinfo.fields[i]\n\t\tif finfo.flags&fElement == 0 || len(finfo.parents) < len(parents) || finfo.xmlns != \"\" && finfo.xmlns != start.Name.Space {\n\t\t\tcontinue\n\t\t}\n\t\tfor j := range parents {\n\t\t\tif parents[j] != finfo.parents[j] {\n\t\t\t\tcontinue Loop\n\t\t\t}\n\t\t}\n\t\tif len(finfo.parents) == len(parents) && finfo.name == start.Name.Local {\n\t\t\t// It's a perfect match, unmarshal the field.\n\t\t\treturn true, p.unmarshal(finfo.value(sv), start)\n\t\t}\n\t\tif len(finfo.parents) > len(parents) && finfo.parents[len(parents)] == start.Name.Local {\n\t\t\t// It's a prefix for the field. Break and recurse\n\t\t\t// since it's not ok for one field path to be itself\n\t\t\t// the prefix for another field path.\n\t\t\trecurse = true\n\n\t\t\t// We can reuse the same slice as long as we\n\t\t\t// don't try to append to it.\n\t\t\tparents = finfo.parents[:len(parents)+1]\n\t\t\tbreak\n\t\t}\n\t}\n\tif !recurse {\n\t\t// We have no business with this element.\n\t\treturn false, nil\n\t}\n\t// The element is not a perfect match for any field, but one\n\t// or more fields have the path to this element as a parent\n\t// prefix. Recurse and attempt to match these.\n\tfor {\n\t\tvar tok Token\n\t\ttok, err = p.Token()\n\t\tif err != nil {\n\t\t\treturn true, err\n\t\t}\n\t\tswitch t := tok.(type) {\n\t\tcase StartElement:\n\t\t\tconsumed2, err := p.unmarshalPath(tinfo, sv, parents, &t)\n\t\t\tif err != nil {\n\t\t\t\treturn true, err\n\t\t\t}\n\t\t\tif !consumed2 {\n\t\t\t\tif err := p.Skip(); err != nil {\n\t\t\t\t\treturn true, err\n\t\t\t\t}\n\t\t\t}\n\t\tcase EndElement:\n\t\t\treturn true, nil\n\t\t}\n\t}\n}", "label": 5}
{"code": "func (t *Torrent) bytesLeftAnnounce() uint64 {\n\tif t.haveInfo() {\n\t\treturn uint64(t.bytesLeft())\n\t} else {\n\t\treturn math.MaxUint64\n\t}\n}", "label": 5}
{"code": "public function setTrueFilter($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Bigtable\\V2\\RowFilter::class);\n        $this->true_filter = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func fillStaticAppInfo(store *imagestore.Store, pod *pkgPod.Pod, v1pod *v1alpha.Pod) error {\n\tvar errlist []error\n\n\t// Fill static app image info.\n\tfor _, app := range v1pod.Apps {\n\t\t// Fill app's image info.\n\t\tapp.Image = &v1alpha.Image{\n\t\t\tBaseFormat: &v1alpha.ImageFormat{\n\t\t\t\t// Only support appc image now. If it's a docker image, then it\n\t\t\t\t// will be transformed to appc before storing in the disk store.\n\t\t\t\tType:    v1alpha.ImageType_IMAGE_TYPE_APPC,\n\t\t\t\tVersion: schema.AppContainerVersion.String(),\n\t\t\t},\n\t\t\tId: app.Image.Id,\n\t\t\t// Other information are not available because they require the image\n\t\t\t// info from store. Some of it is filled in below if possible.\n\t\t}\n\n\t\tim, err := pod.AppImageManifest(app.Name)\n\t\tif err != nil {\n\t\t\tstderr.PrintE(fmt.Sprintf(\"failed to get image manifests for app %q\", app.Name), err)\n\t\t\terrlist = append(errlist, err)\n\t\t} else {\n\t\t\tapp.Image.Name = im.Name.String()\n\n\t\t\tversion, ok := im.Labels.Get(\"version\")\n\t\t\tif !ok {\n\t\t\t\tversion = \"latest\"\n\t\t\t}\n\t\t\tapp.Image.Version = version\n\t\t}\n\t}\n\n\tif len(errlist) != 0 {\n\t\treturn errs{errlist}\n\t}\n\treturn nil\n}", "label": 5}
{"code": "function resetValidationMessage() {\n  var domCache = privateProps.domCache.get(this);\n\n  if (domCache.validationMessage) {\n    hide(domCache.validationMessage);\n  }\n\n  var input = this.getInput();\n\n  if (input) {\n    input.removeAttribute('aria-invalid');\n    input.removeAttribute('aria-describedBy');\n    removeClass(input, swalClasses.inputerror);\n  }\n}", "label": 3}
{"code": "func (cb *CellBuffer) Dirty(x, y int) bool {\n\tif x >= 0 && y >= 0 && x < cb.w && y < cb.h {\n\t\tc := &cb.cells[(y*cb.w)+x]\n\t\tif c.lastMain == rune(0) {\n\t\t\treturn true\n\t\t}\n\t\tif c.lastMain != c.currMain {\n\t\t\treturn true\n\t\t}\n\t\tif c.lastStyle != c.currStyle {\n\t\t\treturn true\n\t\t}\n\t\tif len(c.lastComb) != len(c.currComb) {\n\t\t\treturn true\n\t\t}\n\t\tfor i := range c.lastComb {\n\t\t\tif c.lastComb[i] != c.currComb[i] {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "function resolveStyleguide(options) {\n  return setupStyleguide(options)\n  .then(function (styleguide) {\n    success('Styleguide.read:', 'start reading ...')\n    return styleguide.read()\n  })\n  .then(function (styleguide) {\n    success('Styleguide.read:', 'finished reading')\n    return Promise.resolve(styleguide)\n  })\n}", "label": 3}
{"code": "public void setFloatAttribute(String name, Float value) {\n\t\tensureValue();\n\t\tAttribute attribute = new FloatAttribute(value);\n\t\tattribute.setEditable(isEditable(name));\n\t\tgetValue().getAllAttributes().put(name, attribute);\n\t}", "label": 0}
{"code": "def reek_of(smell_type,\n                smell_details = {},\n                configuration = Configuration::AppConfiguration.default)\n      ShouldReekOf.new(smell_type, smell_details, configuration)\n    end", "label": 4}
{"code": "public function set($document, array $fields, array $options = [])\n    {\n        $merge = $this->pluck('merge', $options, false) ?: false;\n\n        // Record whether the document is empty before any filtering.\n        $emptyDocument = count($fields) === 0;\n\n        list ($fields, $sentinels, $metadata) = $this->filterFields($fields);\n\n        if (!$merge && $metadata['hasDelete']) {\n            throw new \\InvalidArgumentException('Delete cannot appear in data unless `$options[\\'merge\\']` is set.');\n        }\n\n        // Enqueue a write if any of the following conditions are met\n        // - if there are still fields remaining after sentinels were removed\n        // - if the user provided an empty set to begin with\n        // - if the user provided only transform sentinel values AND did not specify merge behavior\n        // - if the user provided only delete sentinel field values.\n\n        $updateNotRequired = count($fields) === 0\n            && !$emptyDocument\n            && !$metadata['hasUpdateMask']\n            && $metadata['hasTransform'];\n\n        $shouldEnqueueUpdate = $fields\n            || $emptyDocument\n            || ($updateNotRequired && !$merge)\n            || $metadata['hasUpdateMask'];\n\n        if ($shouldEnqueueUpdate) {\n            $write = [\n                'fields' => $this->valueMapper->encodeValues($fields),\n            ];\n\n            if ($merge) {\n                $write['updateMask'] = $this->pathsToStrings($this->encodeFieldPaths($fields), $sentinels);\n            }\n\n            $this->writes[] = $this->createDatabaseWrite(self::TYPE_UPDATE, $document, $write, $options);\n        }\n\n        // document transform operations are enqueued as a separate mutation.\n        $this->enqueueTransforms($document, $sentinels, $options);\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *EventHistoryCollector) entityMatches(event types.BaseEvent, spec *types.EventFilterSpec) bool {\n\te := spec.Entity\n\tif e == nil {\n\t\treturn true\n\t}\n\n\tisRootFolder := c.m.root == e.Entity\n\n\tswitch e.Recursion {\n\tcase types.EventFilterSpecRecursionOptionSelf:\n\t\treturn isRootFolder || eventFilterSelf(event, e.Entity)\n\tcase types.EventFilterSpecRecursionOptionChildren:\n\t\treturn eventFilterChildren(event, e.Entity)\n\tcase types.EventFilterSpecRecursionOptionAll:\n\t\tif isRootFolder || eventFilterSelf(event, e.Entity) {\n\t\t\treturn true\n\t\t}\n\t\treturn eventFilterChildren(event, e.Entity)\n\t}\n\n\treturn false\n}", "label": 5}
{"code": "def angle_iter(self, g_nums, ats_1, ats_2, ats_3, invalid_error=False):\n        \"\"\" Iterator over selected atomic angles.\n\n        Angles are in degrees as with :meth:`angle_single`.\n\n        See `above <toc-generators_>`_ for more information on\n        calling options.\n\n        Parameters\n        ----------\n        g_nums\n            |int| or iterable |int| or |None| --\n            Index of the desired geometry\n\n        ats_1\n            |int| or iterable |int| or |None| --\n            Index of the first atom\n\n        ats_2\n            |int| or iterable |int| or |None| --\n            Index of the second atom\n\n        ats_3\n            |int| or iterable |int| or |None| --\n            Index of the third atom\n\n        invalid_error\n            |bool|, optional --\n            If |False| (the default), |None| values are returned for\n            results corresponding to invalid indices. If |True|,\n            exceptions are raised per normal.\n\n        Yields\n        ------\n        angle\n            |npfloat_| --\n            Spanning angles in degrees between corresponding |br|\n            `ats_1`-`ats_2`-`ats_3`, from geometry/geometries `g_nums`\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an invalid (out-of-range) `g_num` or `at_#` is provided.\n\n        ~exceptions.ValueError\n            If all iterable objects are not the same length.\n\n        ~exceptions.ValueError\n            If any `ats_2` element is equal to either the corresponding `ats_1`\n            or `ats_3` element.\n\n        \"\"\"\n        # Suitability of ats_n indices will be checked within the\n        #  self.angle_single() calls and thus no check is needed here.\n\n        # Import the tuple-generating function\n        from .utils import pack_tups\n\n        # Print the function inputs if debug mode is on\n        if _DEBUG:   # pragma: no cover\n            print(\"g_nums = {0}\".format(g_nums))\n            print(\"ats_1 = {0}\".format(ats_1))\n            print(\"ats_2 = {0}\".format(ats_2))\n            print(\"ats_3 = {0}\".format(ats_3))\n        ## end if\n\n        # Perform the None substitution\n        arglist = self._none_subst(g_nums, ats_1, ats_2, ats_3)\n\n        # Expand/pack the tuples from the inputs\n        tups = pack_tups(*arglist)\n\n        # Dump the results if debug mode is on\n        if _DEBUG:  # pragma: no cover\n            print(tups)\n        ## end if\n\n        # Construct the generator using the packed tuples.\n        for tup in tups:\n            if _DEBUG: # pragma: no cover\n                print(tup)\n            ## end if\n\n            yield self._iter_return(tup, self.angle_single, invalid_error)", "label": 1}
{"code": "def run_somaticsniper_with_merge(job, tumor_bam, normal_bam, univ_options, somaticsniper_options):\n    \"\"\"\n    A wrapper for the the entire SomaticSniper sub-graph.\n\n    :param dict tumor_bam: Dict of bam and bai for tumor DNA-Seq\n    :param dict normal_bam: Dict of bam and bai for normal DNA-Seq\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict somaticsniper_options: Options specific to SomaticSniper\n    :return: fsID to the merged SomaticSniper calls\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    spawn = job.wrapJobFn(run_somaticsniper, tumor_bam, normal_bam, univ_options,\n                          somaticsniper_options, split=False).encapsulate()\n    job.addChild(spawn)\n    return spawn.rv()", "label": 1}
{"code": "def logs_urlpatterns(admin_view=lambda x: x):\n    \"\"\"\n    Return the URL patterns for the logs views.\n\n    Args:\n        admin_view (callable): admin_view method from an AdminSite instance.\n\n    Returns:\n        list: the URL patterns for the logs views.\n    \"\"\"\n    return [\n        url(r'^$',\n            admin_view(LogsMenu.as_view()),\n            name='logs'),\n        url(r'^status_codes$',\n            admin_view(LogsStatusCodes.as_view()),\n            name='logs_status_codes'),\n        url(r'^status_codes_by_date$',\n            admin_view(LogsStatusCodesByDate.as_view()),\n            name='logs_status_codes_by_date'),\n        url(r'^most_visited_pages$',\n            admin_view(LogsMostVisitedPages.as_view()),\n            name='logs_most_visited_pages')\n    ]", "label": 1}
{"code": "def add_dependency(path, dependency)\n      return if metadata[path].nil? || disabled\n\n      unless metadata[path][\"deps\"].include? dependency\n        metadata[path][\"deps\"] << dependency\n        add(dependency) unless metadata.include?(dependency)\n      end\n      regenerate? dependency\n    end", "label": 4}
{"code": "def parse_fields(attributes):\n        \"\"\"Parse model fields.\"\"\"\n        return tuple(field.bind_name(name)\n                     for name, field in six.iteritems(attributes)\n                     if isinstance(field, fields.Field))", "label": 1}
{"code": "public static cacheobject[] get(nitro_service service, cacheobject_args args) throws Exception{\n\t\tcacheobject obj = new cacheobject();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tcacheobject[] response = (cacheobject[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private function normalizeFeatures(array $features)\n    {\n        $result = [];\n\n        foreach ($features as $key => $feature) {\n            $maxResults = $this->maxResult($feature);\n\n            if (array_key_exists($feature, $this->featureShortNames)) {\n                $feature = $this->featureShortNames[$feature];\n            }\n\n            $result[] = array_filter([\n                'type' => $feature,\n                'maxResults' => $maxResults\n            ]);\n        }\n\n        return $result;\n    }", "label": 2}
{"code": "def previous_occurrence(from)\n      from = TimeUtil.match_zone(from, start_time) or raise ArgumentError, \"Time required, got #{from.inspect}\"\n      return nil if from <= start_time\n      enumerate_occurrences(start_time, from - 1).to_a.last\n    end", "label": 4}
{"code": "public void work(RepositoryHandler repoHandler, DbProduct product) {\n        if (!product.getDeliveries().isEmpty()) {\n\n            product.getDeliveries().forEach(delivery -> {\n\n                final Set<Artifact> artifacts = new HashSet<>();\n\n                final DataFetchingUtils utils = new DataFetchingUtils();\n                final DependencyHandler depHandler = new DependencyHandler(repoHandler);\n                final Set<String> deliveryDependencies = utils.getDeliveryDependencies(repoHandler, depHandler, delivery);\n\n                final Set<String> fullGAVCSet = deliveryDependencies.stream().filter(DataUtils::isFullGAVC).collect(Collectors.toSet());\n                final Set<String> shortIdentiferSet = deliveryDependencies.stream().filter(entry -> !DataUtils.isFullGAVC(entry)).collect(Collectors.toSet());\n\n\n                processDependencySet(repoHandler,\n                        shortIdentiferSet,\n                        batch -> String.format(BATCH_TEMPLATE_REGEX, StringUtils.join(batch, '|')),\n                        1,\n                        artifacts::add\n                        );\n\n                processDependencySet(repoHandler,\n                        fullGAVCSet,\n                        batch -> QueryUtils.quoteIds(batch, BATCH_TEMPLATE),\n                        10,\n                        artifacts::add\n                );\n\n                if (!artifacts.isEmpty()) {\n                    delivery.setAllArtifactDependencies(new ArrayList<>(artifacts));\n                }\n            });\n\n            repoHandler.store(product);\n        }\n    }", "label": 0}
{"code": "function (a, b) {\n        var me = this,\n            membersOfA = Object.keys(a);\n        // a members comparison with b\n        if (!membersOfA.every(function (member) {\n            return me.like(a[member], b[member]);\n        })) {\n            return true;\n        }\n        // Difference on members count?\n        return membersOfA.length  !== Object.keys(b).length;\n    }", "label": 3}
{"code": "def validatefeatures(self,features):\n        \"\"\"Returns features in validated form, or raises an Exception. Mostly for internal use\"\"\"\n        validatedfeatures = []\n        for feature in features:\n            if isinstance(feature, int) or isinstance(feature, float):\n                validatedfeatures.append( str(feature) )\n            elif self.delimiter in feature and not self.sklearn:\n                raise ValueError(\"Feature contains delimiter: \" + feature)\n            elif self.sklearn and isinstance(feature, str): #then is sparse added together\n                validatedfeatures.append(feature)\n            else:\n                validatedfeatures.append(feature)\n        return validatedfeatures", "label": 1}
{"code": "def generate_available_uuid_list(count = 100)\n      new_uuids = (0..count).map { SecureRandom.hex(12).upcase }\n      uniques = (new_uuids - (@generated_uuids + uuids))\n      @generated_uuids += uniques\n      @available_uuids += uniques\n    end", "label": 4}
{"code": "func pieceStateRunStatusChars(psr PieceStateRun) (ret string) {\n\tret = fmt.Sprintf(\"%d\", psr.Length)\n\tret += func() string {\n\t\tswitch psr.Priority {\n\t\tcase PiecePriorityNext:\n\t\t\treturn \"N\"\n\t\tcase PiecePriorityNormal:\n\t\t\treturn \".\"\n\t\tcase PiecePriorityReadahead:\n\t\t\treturn \"R\"\n\t\tcase PiecePriorityNow:\n\t\t\treturn \"!\"\n\t\tcase PiecePriorityHigh:\n\t\t\treturn \"H\"\n\t\tdefault:\n\t\t\treturn \"\"\n\t\t}\n\t}()\n\tif psr.Checking {\n\t\tret += \"H\"\n\t}\n\tif psr.Partial {\n\t\tret += \"P\"\n\t}\n\tif psr.Complete {\n\t\tret += \"C\"\n\t}\n\tif !psr.Ok {\n\t\tret += \"?\"\n\t}\n\treturn\n}", "label": 5}
{"code": "protected void load()\r\n    {\r\n        // properties file may be set as a System property.\r\n        // if no property is set take default name.\r\n        String fn = System.getProperty(OJB_PROPERTIES_FILE, OJB_PROPERTIES_FILE);\r\n        setFilename(fn);\r\n        super.load();\r\n\r\n        // default repository & connection descriptor file\r\n        repositoryFilename = getString(\"repositoryFile\", OJB_METADATA_FILE);\r\n\r\n        // object cache class\r\n        objectCacheClass = getClass(\"ObjectCacheClass\", ObjectCacheDefaultImpl.class, ObjectCache.class);\r\n\r\n        // load PersistentField Class\r\n        persistentFieldClass =\r\n                getClass(\"PersistentFieldClass\", PersistentFieldDirectImpl.class, PersistentField.class);\r\n\r\n        // load PersistenceBroker Class\r\n        persistenceBrokerClass =\r\n                getClass(\"PersistenceBrokerClass\", PersistenceBrokerImpl.class, PersistenceBroker.class);\r\n\r\n        // load ListProxy Class\r\n        listProxyClass = getClass(\"ListProxyClass\", ListProxyDefaultImpl.class);\r\n\r\n        // load SetProxy Class\r\n        setProxyClass = getClass(\"SetProxyClass\", SetProxyDefaultImpl.class);\r\n\r\n        // load CollectionProxy Class\r\n        collectionProxyClass = getClass(\"CollectionProxyClass\", CollectionProxyDefaultImpl.class);\r\n\r\n        // load IndirectionHandler Class\r\n        indirectionHandlerClass =\r\n            getClass(\"IndirectionHandlerClass\", IndirectionHandlerJDKImpl.class, IndirectionHandler.class);\r\n        \r\n        // load ProxyFactory Class\r\n        proxyFactoryClass =\r\n            getClass(\"ProxyFactoryClass\", ProxyFactoryJDKImpl.class, ProxyFactory.class);\r\n\r\n        // load configuration for ImplicitLocking parameter:\r\n        useImplicitLocking = getBoolean(\"ImplicitLocking\", false);\r\n\r\n        // load configuration for LockAssociations parameter:\r\n        lockAssociationAsWrites = (getString(\"LockAssociations\", \"WRITE\").equalsIgnoreCase(\"WRITE\"));\r\n\r\n        // load OQL Collection Class\r\n        oqlCollectionClass = getClass(\"OqlCollectionClass\", DListImpl.class, ManageableCollection.class);\r\n\r\n        // set the limit for IN-sql , -1 for no limits\r\n        sqlInLimit = getInteger(\"SqlInLimit\", -1);\r\n\r\n        //load configuration for PB pool\r\n        maxActive = getInteger(PoolConfiguration.MAX_ACTIVE,\r\n                PoolConfiguration.DEFAULT_MAX_ACTIVE);\r\n        maxIdle = getInteger(PoolConfiguration.MAX_IDLE,\r\n                PoolConfiguration.DEFAULT_MAX_IDLE);\r\n        maxWait = getLong(PoolConfiguration.MAX_WAIT,\r\n                PoolConfiguration.DEFAULT_MAX_WAIT);\r\n        timeBetweenEvictionRunsMillis = getLong(PoolConfiguration.TIME_BETWEEN_EVICTION_RUNS_MILLIS,\r\n                PoolConfiguration.DEFAULT_TIME_BETWEEN_EVICTION_RUNS_MILLIS);\r\n        minEvictableIdleTimeMillis = getLong(PoolConfiguration.MIN_EVICTABLE_IDLE_TIME_MILLIS,\r\n                PoolConfiguration.DEFAULT_MIN_EVICTABLE_IDLE_TIME_MILLIS);\r\n        whenExhaustedAction = getByte(PoolConfiguration.WHEN_EXHAUSTED_ACTION,\r\n                PoolConfiguration.DEFAULT_WHEN_EXHAUSTED_ACTION);\r\n\r\n        useSerializedRepository = getBoolean(\"useSerializedRepository\", false);\r\n    }", "label": 0}
{"code": "def __parse_ws_data(content, latitude=52.091579, longitude=5.119734):\n    \"\"\"Parse the buienradar xml and rain data.\"\"\"\n    log.info(\"Parse ws data: latitude: %s, longitude: %s\", latitude, longitude)\n    result = {SUCCESS: False, MESSAGE: None, DATA: None}\n\n    # convert the xml data into a dictionary:\n    try:\n        xmldata = xmltodict.parse(content)[__BRROOT]\n    except (xmltodict.expat.ExpatError, KeyError):\n        result[MESSAGE] = \"Unable to parse content as xml.\"\n        log.exception(result[MESSAGE])\n        return result\n\n    # select the nearest weather station\n    loc_data = __select_nearest_ws(xmldata, latitude, longitude)\n    # process current weather data from selected weatherstation\n    if not loc_data:\n        result[MESSAGE] = 'No location selected.'\n        return result\n\n    if not __is_valid(loc_data):\n        result[MESSAGE] = 'Location data is invalid.'\n        return result\n\n    # add distance to weatherstation\n    log.debug(\"Raw location data: %s\", loc_data)\n    result[DISTANCE] = __get_ws_distance(loc_data, latitude, longitude)\n    result = __parse_loc_data(loc_data, result)\n\n    # extract weather forecast\n    try:\n        fc_data = xmldata[__BRWEERGEGEVENS][__BRVERWACHTING]\n    except (xmltodict.expat.ExpatError, KeyError):\n        result[MESSAGE] = 'Unable to extract forecast data.'\n        log.exception(result[MESSAGE])\n        return result\n\n    if fc_data:\n        # result = __parse_fc_data(fc_data, result)\n        log.debug(\"Raw forecast data: %s\", fc_data)\n        # pylint: disable=unsupported-assignment-operation\n        result[DATA][FORECAST] = __parse_fc_data(fc_data)\n\n    return result", "label": 1}
{"code": "function getOpacityOverride(sceneDrawGroup, isFill) {\n    var opacity;\n    if (isFill) {\n        opacity = sceneDrawGroup._hidden['opacity:fill'];\n    } else {\n        opacity = sceneDrawGroup._hidden['opacity:outline'];\n    }\n    if (sceneDrawGroup._hidden['opacity:general'] !== undefined) {\n        opacity = sceneDrawGroup._hidden['opacity:general'];\n    }\n    return opacity;\n}", "label": 3}
{"code": "function getJsImports(importType) {\n    if (cache.jsImports[importType]) {\n        return cache.jsImports[importType];\n    }\n\n    var unprefixedImports = {};\n\n    if (cache.jsImports._unprefixedImports) {\n        unprefixedImports = cache.jsImports._unprefixedImports;\n    } else {\n        var semanticUiReactPath = getPackagePath('semantic-ui-react');\n        if (!semanticUiReactPath) {\n            error('Package semantic-ui-react could not be found. Install semantic-ui-react or set convertMemberImports ' +\n                'to false.');\n        }\n\n        var srcDirPath = path.resolve(semanticUiReactPath, 'src');\n\n        var searchFolders = [\n            'addons',\n            'behaviors',\n            'collections',\n            'elements',\n            'modules',\n            'views'\n        ];\n\n        searchFolders.forEach(function (searchFolder) {\n            var searchRoot = path.resolve(srcDirPath, searchFolder);\n\n            dirTree(searchRoot, {extensions: /\\.js$/}, function (item) {\n                var basename = path.basename(item.path, '.js');\n\n                // skip files that do not start with an uppercase letter\n                if (/[^A-Z]/.test(basename[0])) {\n                    return;\n                }\n\n                if (unprefixedImports[basename]) {\n                    error('duplicate react component name \\'' + basename + '\\' - probably the plugin needs an update');\n                }\n                unprefixedImports[basename] = item.path.substring(srcDirPath.length).replace(/\\\\/g, '/');\n            });\n        });\n\n        cache.jsImports._unprefixedImports = unprefixedImports;\n    }\n\n    var prefix;\n    if (importType === 'src') {\n        prefix = '/src';\n    } else {\n        prefix = '/dist/' + importType;\n    }\n\n    cache.jsImports[importType] = {};\n    for(var key in unprefixedImports) {\n        if (unprefixedImports.hasOwnProperty(key)) {\n            cache.jsImports[importType][key] = prefix + unprefixedImports[key];\n        }\n    }\n\n    return cache.jsImports[importType];\n}", "label": 3}
{"code": "function createCommentDiv(comment) {\n    if (!comment.displayed && !opts.moderator) {\n      return $('<div class=\"moderate\">Thank you!  Your comment will show up '\n               + 'once it is has been approved by a moderator.</div>');\n    }\n    // Prettify the comment rating.\n    comment.pretty_rating = comment.rating + ' point' +\n      (comment.rating == 1 ? '' : 's');\n    // Make a class (for displaying not yet moderated comments differently)\n    comment.css_class = comment.displayed ? '' : ' moderate';\n    // Create a div for this comment.\n    var context = $.extend({}, opts, comment);\n    var div = $(renderTemplate(commentTemplate, context));\n\n    // If the user has voted on this comment, highlight the correct arrow.\n    if (comment.vote) {\n      var direction = (comment.vote == 1) ? 'u' : 'd';\n      div.find('#' + direction + 'v' + comment.id).hide();\n      div.find('#' + direction + 'u' + comment.id).show();\n    }\n\n    if (opts.moderator || comment.text != '[deleted]') {\n      div.find('a.reply').show();\n      if (comment.proposal_diff)\n        div.find('#sp' + comment.id).show();\n      if (opts.moderator && !comment.displayed)\n        div.find('#cm' + comment.id).show();\n      if (opts.moderator || (opts.username == comment.username))\n        div.find('#dc' + comment.id).show();\n    }\n    return div;\n  }", "label": 3}
{"code": "func (rd *Redirector) Close() error {\n\trd.cancel()\n\tif rd.server != nil {\n\t\trd.server.Close()\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function flushPipeline($send = true)\n    {\n        if ($send && !$this->pipeline->isEmpty()) {\n            $responses = $this->executePipeline($this->getConnection(), $this->pipeline);\n            $this->responses = array_merge($this->responses, $responses);\n        } else {\n            $this->pipeline = new \\SplQueue();\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "func ClientTimeout(timeout time.Duration) roundtrip.ClientParam {\n\treturn func(c *roundtrip.Client) error {\n\t\ttransport, ok := (c.HTTPClient().Transport).(*http.Transport)\n\t\tif !ok {\n\t\t\treturn nil\n\t\t}\n\t\ttransport.IdleConnTimeout = timeout\n\t\ttransport.ResponseHeaderTimeout = timeout\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "def fix_plugin_name(name)\n      name = name.to_s.downcase\n      fixes = {\n        /[\\- ]/ => '_', # dashes and spaces become underscores\n        /[^a-z0-9_]/ => '', # anything other than lower case letters, numbers and underscores is removed\n        /fastlane[_]?/ => '', # 'fastlane' or 'fastlane_' is removed\n        /plugin[_]?/ => '' # 'plugin' or 'plugin_' is removed\n      }\n      fixes.each do |regex, replacement|\n        name = name.gsub(regex, replacement)\n      end\n      name\n    end", "label": 4}
{"code": "func addStage1ImageFlags(flags *pflag.FlagSet) {\n\tfor _, data := range stage1FlagsData {\n\t\twrapper := &stage1ImageLocationFlag{\n\t\t\tloc:  &overriddenStage1Location,\n\t\t\tkind: data.kind,\n\t\t}\n\t\tflags.Var(wrapper, data.flag, data.help)\n\t}\n}", "label": 5}
{"code": "func (al AnnounceList) OverridesAnnounce(announce string) bool {\n\tfor _, tier := range al {\n\t\tfor _, url := range tier {\n\t\t\tif url != \"\" || announce == \"\" {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}", "label": 5}
{"code": "function (ast, setting, debug) {\n        let optimizer = new Optimizer(ast, setting, debug);\n        optimizer.analyze();\n        optimizer.optimize();\n        return ast;\n    }", "label": 3}
{"code": "public function setVoices($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\TextToSpeech\\V1\\Voice::class);\n        $this->voices = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function getLogger(name) {\n\tname = name || '';\n\n\tif (!name) {\n\t\treturn Manager.root;\n\t} else {\n\t\treturn Manager.getLogger(name);\n\t}\n}", "label": 3}
{"code": "public function translateFromUtf8($input)\n    {\n        if ($this->isRunningOnWindows()) {\n            $input = iconv('UTF-8', mb_detect_encoding($input), $input);\n        }\n\n        return $input;\n    }", "label": 2}
{"code": "function makeReflectTypes(uniforms, useIndex) {\n  var obj = {}\n  for(var i=0; i<uniforms.length; ++i) {\n    var n = uniforms[i].name\n    var parts = n.split(\".\")\n    var o = obj\n    for(var j=0; j<parts.length; ++j) {\n      var x = parts[j].split(\"[\")\n      if(x.length > 1) {\n        if(!(x[0] in o)) {\n          o[x[0]] = []\n        }\n        o = o[x[0]]\n        for(var k=1; k<x.length; ++k) {\n          var y = parseInt(x[k])\n          if(k<x.length-1 || j<parts.length-1) {\n            if(!(y in o)) {\n              if(k < x.length-1) {\n                o[y] = []\n              } else {\n                o[y] = {}\n              }\n            }\n            o = o[y]\n          } else {\n            if(useIndex) {\n              o[y] = i\n            } else {\n              o[y] = uniforms[i].type\n            }\n          }\n        }\n      } else if(j < parts.length-1) {\n        if(!(x[0] in o)) {\n          o[x[0]] = {}\n        }\n        o = o[x[0]]\n      } else {\n        if(useIndex) {\n          o[x[0]] = i\n        } else {\n          o[x[0]] = uniforms[i].type\n        }\n      }\n    }\n  }\n  return obj\n}", "label": 3}
{"code": "def print_stats(img):\n    \"\"\" prints stats, remember that img should already have been loaded \"\"\"\n    stat = ImageStat.Stat(img)\n    print(\"extrema    : \", stat.extrema)\n    print(\"count      : \", stat.count)\n    print(\"sum        : \", stat.sum)\n    print(\"sum2       : \", stat.sum2)\n    print(\"mean       : \", stat.mean)\n    print(\"median     : \", stat.median)\n    print(\"rms        : \", stat.rms)\n    print(\"var        : \", stat.var)\n    print(\"stddev     : \", stat.stddev)", "label": 1}
{"code": "def select(conn, query: str, params=None, name=None, itersize=5000):\n    \"\"\"Return a select statement's results as a namedtuple.\n\n    Parameters\n    ----------\n    conn : database connection\n    query : select query string\n    params : query parameters.\n    name : server side cursor name. defaults to client side.\n    itersize : number of records fetched by server.\n    \"\"\"\n\n    with conn.cursor(name, cursor_factory=NamedTupleCursor) as cursor:\n        cursor.itersize = itersize\n        cursor.execute(query, params)\n\n        for result in cursor:\n            yield result", "label": 1}
{"code": "def print_comps(comps):\n    \"\"\"\n    print stats for comparisons\n    \"\"\"\n    if comps == []:\n        print('n/a')\n    else:\n        print('# min: %s, max: %s, mean: %s' % \\\n            (min(comps), max(comps), np.mean(comps)))", "label": 1}
{"code": "func (ns *NodeSession) runShell(callback ShellCreatedCallback) error {\n\treturn ns.interactiveSession(func(s *ssh.Session, shell io.ReadWriteCloser) error {\n\t\t// start the shell on the server:\n\t\tif err := s.Shell(); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\t// call the client-supplied callback\n\t\tif callback != nil {\n\t\t\texit, err := callback(s, ns.NodeClient().Client, shell)\n\t\t\tif exit {\n\t\t\t\treturn trace.Wrap(err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n}", "label": 5}
{"code": "def run(argv = ARGV)\n      Hutch::Config.initialize\n      parse_options(argv)\n\n      daemonise_process\n\n      write_pid if Hutch::Config.pidfile\n\n      Hutch.logger.info \"hutch booted with pid #{::Process.pid}\"\n\n      if load_app && start_work_loop == :success\n        # If we got here, the worker was shut down nicely\n        Hutch.logger.info 'hutch shut down gracefully'\n        exit 0\n      else\n        Hutch.logger.info 'hutch terminated due to an error'\n        exit 1\n      end\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, dospolicy resource) throws Exception {\n\t\tdospolicy updateresource = new dospolicy();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.qdepth = resource.qdepth;\n\t\tupdateresource.cltdetectrate = resource.cltdetectrate;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func AppStatusPathFromStage1Rootfs(rootfs, appName string) string {\n\treturn filepath.Join(AppsStatusesPathFromStage1Rootfs(rootfs), appName)\n}", "label": 5}
{"code": "func NewRedirector(login SSHLogin) (*Redirector, error) {\n\t//clt, proxyURL, err := initClient(login.ProxyAddr, login.Insecure, login.Pool)\n\t//if err != nil {\n\t//\treturn nil, trace.Wrap(err)\n\t//}\n\n\tclt, err := NewCredentialsClient(login.ProxyAddr, login.Insecure, login.Pool)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Create secret key that will be sent with the request and then used the\n\t// decrypt the response from the server.\n\tkey, err := secret.NewKey()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tcontext, cancel := context.WithCancel(login.Context)\n\trd := &Redirector{\n\t\tcontext:     context,\n\t\tcancel:      cancel,\n\t\tproxyClient: clt.clt,\n\t\tproxyURL:    clt.url,\n\t\tSSHLogin:    login,\n\t\tmux:         http.NewServeMux(),\n\t\tkey:         key,\n\t\tshortPath:   \"/\" + uuid.New(),\n\t\tresponseC:   make(chan *auth.SSHLoginResponse, 1),\n\t\terrorC:      make(chan error, 1),\n\t}\n\n\t// callback is a callback URL communicated to the Teleport proxy,\n\t// after SAML/OIDC login, the teleport will redirect user's browser\n\t// to this laptop-local URL\n\trd.mux.Handle(\"/callback\", rd.wrapCallback(rd.callback))\n\t// short path is a link-shortener style URL\n\t// that will redirect to the Teleport-Proxy supplied address\n\trd.mux.HandleFunc(rd.shortPath, func(w http.ResponseWriter, r *http.Request) {\n\t\thttp.Redirect(w, r, rd.redirectURL.Value(), http.StatusFound)\n\t})\n\treturn rd, nil\n}", "label": 5}
{"code": "def start(config=Mail::Configuration.instance, &block)\n        raise ArgumentError.new(\"Mail::Retrievable#imap_start takes a block\") unless block_given?\n\n        if settings[:enable_starttls] && settings[:enable_ssl]\n          raise ArgumentError, \":enable_starttls and :enable_ssl are mutually exclusive. Set :enable_ssl if you're on an IMAPS connection. Set :enable_starttls if you're on an IMAP connection and using STARTTLS for secure TLS upgrade.\"\n        end\n\n        imap = Net::IMAP.new(settings[:address], settings[:port], settings[:enable_ssl], nil, false)\n\n        imap.starttls if settings[:enable_starttls]\n\n        if settings[:authentication].nil?\n          imap.login(settings[:user_name], settings[:password])\n        else\n          # Note that Net::IMAP#authenticate('LOGIN', ...) is not equal with Net::IMAP#login(...)!\n          # (see also http://www.ensta.fr/~diam/ruby/online/ruby-doc-stdlib/libdoc/net/imap/rdoc/classes/Net/IMAP.html#M000718)\n          imap.authenticate(settings[:authentication], settings[:user_name], settings[:password])\n        end\n\n        yield imap\n      ensure\n        if defined?(imap) && imap && !imap.disconnected?\n          imap.disconnect\n        end\n      end", "label": 4}
{"code": "function cmdHelp(command) {\n        let ext = '';\n        if (command.args && command.args.length > 0) {\n            ext = command.args.join(' ');\n        }\n        if (ext && helpTopics[ext]) {\n            const txt = `Help topic for \\`${ext}\\`\\n\\n${helpTopics[ext]}` +\n                '\\n\\nIssue the `help` command without any parameters to see all available commands';\n            command.reply(txt);\n\n        } else {\n            const help = `${getCommandHelps()}\\n\\n\\\\* Help topic available.\\n\\nIssue the \\`help\\` command with an ` +\n                'available help topic as a parameter to read additonal help';\n            command.reply(help);\n        }\n        return Promise.resolve();\n    }", "label": 3}
{"code": "def fetch_deposits(self, limit: int) -> List[Deposit]:\n        \"\"\"Fetch latest deposits, must provide a limit.\"\"\"\n        return self._transactions(self._deposits, 'deposits', limit)", "label": 1}
{"code": "def h6(name, identifier={:index => 0}, &block)\n      standard_methods(name, identifier, 'h6_for', &block)\n      define_method(name) do\n        return platform.h6_text_for identifier.clone unless block_given?\n        self.send(\"#{name}_element\").text\n      end\n    end", "label": 4}
{"code": "function(reducer, initialValue)\n  {\n    for (var i = 0; i < this.length; i++)\n    {\n      initialValue = reducer( initialValue, this[ i ] );\n    }\n\n    return initialValue;\n  }", "label": 3}
{"code": "func (c *ClientConfig) CheckAndSetDefaults() error {\n\tif len(c.Addrs) == 0 && c.DialContext == nil {\n\t\treturn trace.BadParameter(\"set parameter Addrs or DialContext\")\n\t}\n\tif c.TLS == nil {\n\t\treturn trace.BadParameter(\"missing parameter TLS\")\n\t}\n\tif c.KeepAlivePeriod == 0 {\n\t\tc.KeepAlivePeriod = defaults.ServerKeepAliveTTL\n\t}\n\tif c.KeepAliveCount == 0 {\n\t\tc.KeepAliveCount = defaults.KeepAliveCountMax\n\t}\n\tif c.DialContext == nil {\n\t\tc.DialContext = NewAddrDialer(c.Addrs)\n\t}\n\tif c.TLS.ServerName == \"\" {\n\t\tc.TLS.ServerName = teleport.APIDomain\n\t}\n\t// this logic is necessary to force client to always send certificate\n\t// regardless of the server setting, otherwise client may pick\n\t// not to send the client certificate by looking at certificate request\n\tif len(c.TLS.Certificates) != 0 {\n\t\tcert := c.TLS.Certificates[0]\n\t\tc.TLS.Certificates = nil\n\t\tc.TLS.GetClientCertificate = func(_ *tls.CertificateRequestInfo) (*tls.Certificate, error) {\n\t\t\treturn &cert, nil\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function stripPathPrefix(p, prefix, options) {\n  if (!prefix) return p;\n  options = _.sanitize(options, {force: false});\n  p = _fileCleanPath(p);\n  prefix = _fileCleanPath(prefix);\n  if (options.force) {\n    return path.relative(prefix, p);\n  } else {\n    const pathSplit = split(p);\n    const prefixSplit = split(prefix);\n    if (prefixSplit.length > pathSplit.length) return p;\n    let i = 0;\n    for (i = 0; i < prefixSplit.length; i++) {\n      if (pathSplit[i] !== prefixSplit[i]) return p;\n    }\n    return pathSplit.slice(i).join('/');\n  }\n}", "label": 3}
{"code": "func (c *Call) Maybe() *Call {\n\tc.lock()\n\tdefer c.unlock()\n\tc.optional = true\n\treturn c\n}", "label": 5}
{"code": "public function getAllCategories()\n    {\n        $categories = $this->exists ? self::whereNotIn('id', [$this->id])->get() : self::get();\n\n        return $categories->mapWithKeys(function ($item) {\n            return [$item->id => $item->term->GetContent('name')];\n        })->toArray();\n    }", "label": 2}
{"code": "def create_partitions_for(name, num_partitions: 1, timeout: 30)\n      @cluster.create_partitions_for(name, num_partitions: num_partitions, timeout: timeout)\n    end", "label": 4}
{"code": "protected function isCustomIndentStyleRequired()\n    {\n        return $this->isJsonPrettyPrintEnabled() &&\n            isset($this->options['indent_style']) &&\n            in_array($this->options['indent_style'], $this->indentStyles);\n    }", "label": 2}
{"code": "public static base_responses unset(nitro_service client, String certkey[], String args[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (certkey != null && certkey.length > 0) {\n\t\t\tsslcertkey unsetresources[] = new sslcertkey[certkey.length];\n\t\t\tfor (int i=0;i<certkey.length;i++){\n\t\t\t\tunsetresources[i] = new sslcertkey();\n\t\t\t\tunsetresources[i].certkey = certkey[i];\n\t\t\t}\n\t\t\tresult = unset_bulk_request(client, unsetresources,args);\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def audit_hash(path, input)\n      json = client.post(\"/v1/sys/audit-hash/#{encode_path(path)}\", JSON.fast_generate(input: input))\n      json = json[:data] if json[:data]\n      json[:hash]\n    end", "label": 4}
{"code": "public function dispatchEventsFor($entity, User $actor = null)\n    {\n        foreach ($entity->releaseEvents() as $event) {\n            $event->actor = $actor;\n\n            $this->events->dispatch($event);\n        }\n    }", "label": 2}
{"code": "public function setFindings($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\Finding::class);\n        $this->findings = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setStackTrace($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Trace\\V2\\StackTrace::class);\n        $this->stack_trace = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(attr, value) {\n          var self = this,\n              result = {},\n              error;\n          if (_.isArray(attr)) {\n            _.each(attr, function(attr) {\n              error = self.preValidate(attr);\n              if (error) {\n                result[attr] = error;\n              }\n            });\n            return _.isEmpty(result) ? undefined : result;\n          } else if (_.isObject(attr)) {\n            _.each(attr, function(value, key) {\n              error = self.preValidate(key, value);\n              if (error) {\n                result[key] = error;\n              }\n            });\n            return _.isEmpty(result) ? undefined : result;\n          } else {\n            if (_.isUndefined(value) && isNestedModel(this)) {\n              value = this.get(attr);\n            }\n            return validateAttr(this, value, attr);\n          }\n        }", "label": 3}
{"code": "private static void addTimePerComponent(HashMap<String, Long> mapComponentTimes,\tComponent component) {\n    Long currentTimeOfComponent = 0L;\n    String key = component.getComponentType();\n    if (mapComponentTimes.containsKey(key)) {\n      currentTimeOfComponent = mapComponentTimes.get(key);\n    }\n    //when transactions are run in parallel, we should log the longest transaction only to avoid that \n    //for ex 'Total time' would be 100ms and transactions in parallel to hornetQ will be 2000ms \n    Long maxTime =  Math.max(component.getTime(), currentTimeOfComponent);\n    mapComponentTimes.put(key, maxTime);\n  }", "label": 0}
{"code": "def dict2bibtex(data):\n    \"\"\"\n    Convert a single BibTeX entry dict to a BibTeX string.\n\n    :param data: A dict representing BibTeX entry, as the ones from \\\n            ``bibtexparser.BibDatabase.entries`` output.\n    :return: A formatted BibTeX string.\n    \"\"\"\n    bibtex = '@' + data['ENTRYTYPE'] + '{' + data['ID'] + \",\\n\"\n\n    for field in [i for i in sorted(data) if i not in ['ENTRYTYPE', 'ID']]:\n        bibtex += \"\\t\" + field + \"={\" + data[field] + \"},\\n\"\n    bibtex += \"}\\n\\n\"\n    return bibtex", "label": 1}
{"code": "func mapColor2RGB(c Color) uint16 {\n\twinLock.Lock()\n\tif v, ok := winColors[c]; ok {\n\t\tc = v\n\t} else {\n\t\tv = FindColor(c, winPalette)\n\t\twinColors[c] = v\n\t\tc = v\n\t}\n\twinLock.Unlock()\n\n\tif vc, ok := vgaColors[c]; ok {\n\t\treturn vc\n\t}\n\treturn 0\n}", "label": 5}
{"code": "public static base_response add(nitro_service client, dnsaddrec resource) throws Exception {\n\t\tdnsaddrec addresource = new dnsaddrec();\n\t\taddresource.hostname = resource.hostname;\n\t\taddresource.ipaddress = resource.ipaddress;\n\t\taddresource.ttl = resource.ttl;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "def newick_replace_otuids(tree, biomf):\n    \"\"\"\n    Replace the OTU ids in the Newick phylogenetic tree format with truncated\n    OTU names\n    \"\"\"\n    for val, id_, md in biomf.iter(axis=\"observation\"):\n        otu_loc = find_otu(id_, tree)\n        if otu_loc is not None:\n            tree = tree[:otu_loc] + \\\n                   oc.otu_name(md[\"taxonomy\"]) + \\\n                   tree[otu_loc + len(id_):]\n    return tree", "label": 1}
{"code": "func (a *Assertions) NotZero(i interface{}, msgAndArgs ...interface{}) bool {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn NotZero(a.t, i, msgAndArgs...)\n}", "label": 5}
{"code": "function EventEmitter() {\n  this._events = { };\n  this._once   = { };\n  // default to 10 max liseners\n  this._maxListeners = 10;\n\n  this._add = function (event, listener, once) {\n    var entry = { listener: listener };\n    if (once) {\n      entry.once = true;\n    }\n\n    if (this._events[event]) {\n      this._events[event].push(entry);\n    } else {\n      this._events[event] = [ entry ];\n    }\n\n    if (this._maxListeners && this._events[event].count > this._maxListeners && console && console.warn) {\n      console.warn(\"EventEmitter Error: Maximum number of listeners\");\n    }\n\n    return this;\n  };\n\n  this.on = function (event, listener) {\n    return this._add(event, listener);\n  };\n\n  this.addListener = this.on;\n\n  this.once = function (event, listener) {\n    return this._add(event, listener, true);\n  };\n\n  this.removeListener = function (event, listener) {\n    if (!this._events[event]) {\n      return this;\n    }\n\n    for(var i = this._events.length-1; i--;) {\n      if (this._events[i].listener === callback) {\n        this._events.splice(i, 1);\n      }\n    }\n\n    return this;\n  };\n\n  this.removeAllListeners = function (event) {\n    this._events[event] = undefined;\n\n    return this;\n  };\n\n  this.setMaxListeners = function (count) {\n    this._maxListeners = count;\n\n    return this;\n  };\n\n  this.emit = function () {\n    var args = Array.prototype.slice.apply(arguments);\n    var remove = [ ], i;\n\n    if (args.length) {\n      var event = args.shift();\n\n      if (this._events[event]) {\n        for (i = this._events[event].length; i--;) {\n          this._events[event][i].listener.apply(null, args);\n          if (this._events[event][i].once) {\n            remove.push(listener);\n          }\n        }\n      }\n\n      for (i = remove.length; i--;) {\n        this.removeListener(event, remove[i]);\n      }\n    }\n\n    return this;\n  };\n}", "label": 3}
{"code": "def aggregations(params = nil)\n      @_named_aggs ||= _build_named_aggs\n      @_fully_qualified_named_aggs ||= _build_fqn_aggs\n      if params\n        params = {params => @_named_aggs[params]} if params.is_a?(Symbol)\n        params = {params => _get_fully_qualified_named_agg(params)} if params.is_a?(String) && params =~ /\\A\\S+#\\S+\\.\\S+\\z/\n        chain { criteria.update_aggregations params }\n      else\n        _response['aggregations'] || {}\n      end\n    end", "label": 4}
{"code": "public function setNewTransaction($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\TransactionOptions::class);\n        $this->writeOneof(5, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def plot_PCoA(cat_data, otu_name, unifrac, names, colors, xr, yr, outDir,\n              save_as, plot_style):\n    \"\"\"\n    Plot PCoA principal coordinates scaled by the relative abundances of\n    otu_name.\n    \"\"\"\n    fig = plt.figure(figsize=(14, 8))\n    ax = fig.add_subplot(111)\n\n    for i, cat in enumerate(cat_data):\n        plt.scatter(cat_data[cat][\"pc1\"], cat_data[cat][\"pc2\"], cat_data[cat][\"size\"],\n                    color=colors[cat], alpha=0.85, marker=\"o\", edgecolor=\"black\",\n                    label=cat)\n    lgnd = plt.legend(loc=\"best\", scatterpoints=3, fontsize=13)\n    for i in range(len(colors.keys())):\n        lgnd.legendHandles[i]._sizes = [80]  # Change the legend marker size manually\n    plt.title(\" \".join(otu_name.split(\"_\")), style=\"italic\")\n    plt.ylabel(\"PC2 (Percent Explained Variance {:.3f}%)\".format(float(unifrac[\"varexp\"][1])))\n    plt.xlabel(\"PC1 (Percent Explained Variance {:.3f}%)\".format(float(unifrac[\"varexp\"][0])))\n    plt.xlim(round(xr[0]*1.5, 1), round(xr[1]*1.5, 1))\n    plt.ylim(round(yr[0]*1.5, 1), round(yr[1]*1.5, 1))\n    if plot_style:\n        gu.ggplot2_style(ax)\n        fc = \"0.8\"\n    else:\n        fc = \"none\"\n    fig.savefig(os.path.join(outDir, \"_\".join(otu_name.split())) + \".\" + save_as,\n                facecolor=fc, edgecolor=\"none\", format=save_as,\n                bbox_inches=\"tight\", pad_inches=0.2)\n    plt.close(fig)", "label": 1}
{"code": "public static responderpolicy get(nitro_service service, String name) throws Exception{\n\t\tresponderpolicy obj = new responderpolicy();\n\t\tobj.set_name(name);\n\t\tresponderpolicy response = (responderpolicy) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function downloadAsStreamAsync(array $options = [])\n    {\n        return $this->connection->downloadObjectAsync(\n            $this->formatEncryptionHeaders(\n                $options\n                + $this->encryptionData\n                + array_filter($this->identity)\n            )\n        );\n    }", "label": 2}
{"code": "function (obj, octave) {\n  var lastNote = obj.chord[0];\n\n  obj.chord = _.map(obj.chord, function (n) {\n    // Every time a note is \"lower\" than the last note, we're in a new octave\n    if (n.lowerThan(lastNote)) octave += 1;\n\n    // As a side-effect, update the octaves for root and bass\n    if (n.enharmonic(obj.root)) {\n      obj.root = obj.root.inOctave(octave);\n    }\n    if (obj.bass && n.enharmonic(obj.bass)) {\n      obj.bass = obj.bass.inOctave(octave);\n    }\n\n    lastNote = n;\n    return n.inOctave(octave);\n  });\n}", "label": 3}
{"code": "function (tooltip) {\n            var items = this.points || splat(this),\n              series = items[0].series,\n              s;\n\n            // build the header\n            s = [tooltip.tooltipHeaderFormatter(items[0])];\n\n            // build the values\n            each(items, function (item) {\n                series = item.series;\n                s.push((series.tooltipFormatter && series.tooltipFormatter(item)) ||\n                  item.point.tooltipFormatter(series.tooltipOptions.pointFormat));\n            });\n\n            // footer\n            s.push(tooltip.options.footerFormat || '');\n\n            return s.join('');\n        }", "label": 3}
{"code": "function printWeatherForecast() {\n  return weather\n    .dailyForecast('Kiev')\n    .then(forecast => console.log('WEATHER FORECAST:', forecast))\n    .catch(error => console.error(error));\n}", "label": 3}
{"code": "function(key)\n  {\n    var db = this;\n    var model = db.all[ key ];\n\n    if ( db.cache === Cache.All )\n    {\n      return db.destroyLocalCachedModel( model, key );\n    }\n    else\n    {\n      return db.destroyLocalUncachedModel( model, key );\n    }\n  }", "label": 3}
{"code": "def build_item(level, message, exception, extra, context)\n      options = {\n        :level => level,\n        :message => message,\n        :exception => exception,\n        :extra => extra,\n        :configuration => configuration,\n        :logger => logger,\n        :scope => scope_object,\n        :notifier => self,\n        :context => context\n      }\n\n      item = Item.new(options)\n      item.build\n\n      item\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, nsspparams resource) throws Exception {\n\t\tnsspparams updateresource = new nsspparams();\n\t\tupdateresource.basethreshold = resource.basethreshold;\n\t\tupdateresource.throttle = resource.throttle;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func (s *MockStore) Get(key string) (*store.KVPair, error) {\n\tmData := s.db[key]\n\tif mData == nil {\n\t\treturn nil, nil\n\t}\n\treturn &store.KVPair{Value: mData.Data, LastIndex: mData.Index}, nil\n\n}", "label": 5}
{"code": "def keyboard(table, day=None):\r\n    \"\"\"Handler for showing the keyboard statistics page.\"\"\"\r\n    cols, group = \"realkey AS key, COUNT(*) AS count\", \"realkey\"\r\n    where = ((\"day\", day),) if day else ()\r\n    counts_display = counts = db.fetch(table, cols, where, group, \"count DESC\")\r\n    if \"combos\" == table:\r\n        counts_display = db.fetch(table, \"key, COUNT(*) AS count\", where,\r\n                                  \"key\", \"count DESC\")\r\n    events = db.fetch(table, where=where, order=\"stamp\")\r\n    for e in events: e[\"dt\"] = datetime.datetime.fromtimestamp(e[\"stamp\"])\r\n    stats, collatedevents = stats_keyboard(events, table)\r\n    days, input = db.fetch(\"counts\", order=\"day\", type=table), \"keyboard\"\r\n    return bottle.template(\"heatmap.tpl\", locals(), conf=conf)", "label": 1}
{"code": "async def dump_varint(writer, val):\n    \"\"\"\n    Binary dump of the variable size integer\n\n    :param writer:\n    :param val:\n    :return:\n    \"\"\"\n    if val <= 63:\n        return await dump_varint_t(writer, PortableRawSizeMark.BYTE, val)\n    elif val <= 16383:\n        return await dump_varint_t(writer, PortableRawSizeMark.WORD, val)\n    elif val <= 1073741823:\n        return await dump_varint_t(writer, PortableRawSizeMark.DWORD, val)\n    else:\n        if val > 4611686018427387903:\n            raise ValueError('Int too big')\n        return await dump_varint_t(writer, PortableRawSizeMark.INT64, val)", "label": 1}
{"code": "func PDescribe(text string, body func()) bool {\n\tglobalSuite.PushContainerNode(text, body, types.FlagTypePending, codelocation.New(1))\n\treturn true\n}", "label": 5}
{"code": "protected function getApiDocument(User $actor, array $params)\n    {\n        $response = $this->api->send('Flarum\\Api\\Controller\\ShowDiscussionController', $actor, $params);\n        $statusCode = $response->getStatusCode();\n\n        if ($statusCode === 404) {\n            throw new RouteNotFoundException;\n        }\n\n        return json_decode($response->getBody());\n    }", "label": 2}
{"code": "def geom_iter(self, g_nums):\n        \"\"\"Iterator over a subset of geometries.\n\n        The indices of the geometries to be returned are indicated by an\n        iterable of |int|\\\\ s passed as `g_nums`.\n\n        As with :meth:`geom_single`, each geometry is returned as a\n        length-3N |npfloat_| with each atom's x/y/z coordinates\n        grouped together::\n\n            [A1x, A1y, A1z, A2x, A2y, A2z, ...]\n\n        In order to use NumPy `slicing or advanced indexing\n        <http://docs.scipy.org/doc/numpy-1.10.0/reference/\n        arrays.indexing.html>`__, :data:`geoms` must first be\n        explicitly converted to |nparray|, e.g.::\n\n            >>> x = opan.xyz.OpanXYZ(path='...')\n            >>> np.array(x.geoms)[[2,6,9]]\n\n        Parameters\n        ----------\n        g_nums\n            length-R iterable of |int| --\n            Indices of the desired geometries\n\n        Yields\n        ------\n        geom\n            length-3N |npfloat_| --\n            Vectors of the atomic coordinates for each geometry\n            indicated in `g_nums`\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an item in `g_nums` is invalid (out of range)\n\n        \"\"\"\n        # Using the custom coded pack_tups to not have to care whether the\n        #  input is iterable\n        from .utils import pack_tups\n\n        vals = pack_tups(g_nums)\n        for val in vals:\n            yield self.geom_single(val[0])", "label": 1}
{"code": "public function getMember($name)\n    {\n        $members = $this->getMembers();\n\n        if (!isset($members[$name])) {\n            throw new \\InvalidArgumentException('Unknown member ' . $name);\n        }\n\n        return $members[$name];\n    }", "label": 2}
{"code": "private List<String> parseRssFeedForeCast(String feed) {\n        String[] result = feed.split(\"<br />\");\n        List<String> returnList = new ArrayList<String>();\n        String[] result2 = result[2].split(\"<BR />\");\n\n        returnList.add(result2[3] + \"\\n\");\n        returnList.add(result[3] + \"\\n\");\n        returnList.add(result[4] + \"\\n\");\n        returnList.add(result[5] + \"\\n\");\n        returnList.add(result[6] + \"\\n\");\n\n        return returnList;\n    }", "label": 0}
{"code": "public function setPrivateClusterConfig($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Container\\V1\\PrivateClusterConfig::class);\n        $this->private_cluster_config = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function(value, attr, range, model) {\n        if(!isNumber(value) || value < range[0] || value > range[1]) {\n          return this.format(getMessageKey(this.msgKey, defaultMessages.range), this.formatLabel(attr, model), range[0], range[1]);\n        }\n      }", "label": 3}
{"code": "function writePage(resourceId, resourceObj, pathPrefix) {\n  const outputPath = resourcePath(resourceId, pathPrefix);\n  resourceObj.outputPath = outputPath;\n  return write(outputPath, resourceObj.contents);\n}", "label": 3}
{"code": "func (f *DatastoreFile) Tail(n int) error {\n\treturn f.TailFunc(n, func(line int, _ string) bool { return n > line })\n}", "label": 5}
{"code": "def valid?(context = nil)\n      current_context, self.validation_context = validation_context, context\n      errors.clear\n      run_validations!\n    ensure\n      self.validation_context = current_context\n    end", "label": 4}
{"code": "function fast(source) {\n        var i = source.length;\n\n        while (i--) {\n          combinations.push(source.slice(0, i + 1));\n          if (i === 1) fast(source.slice(i));\n        }\n\n        return combinations;\n      }", "label": 3}
{"code": "def retrieve_field_values_model_for_model\n      field_values = {}\n      @field_values.each_pair do |id, val|\n        field_values[id] = val.to_model\n      end\n      @code_list_id ||= code_list_id\n\n      # Model transfers as a field\n      if %w(transfer_to transfer_from).include? @definition\n        field_code_list_id = @code_list_id\n        @code_list_id = nil\n        unless field_code_list_id\n          field_code_list_id = attr_val(\"./#{CRITERIA_GLOB}/cda:outboundRelationship/#{CRITERIA_GLOB}/cda:value/@valueSet\")\n        end\n        field_values[@definition.upcase] = HQMF::Coded.for_code_list(field_code_list_id, title)\n      end\n\n      return field_values unless field_values.empty?\n    end", "label": 4}
{"code": "public function create(DocumentReference $document, array $fields)\n    {\n        $this->writer->create($document->name(), $fields);\n\n        return $this;\n    }", "label": 2}
{"code": "def reconnect!\n      @connecting = true\n      scan!\n      servers.each do |server|\n        server.reconnect!\n      end\n      @periodic_executor.restart!\n      @connecting = false\n      @connected = true\n    end", "label": 4}
{"code": "protected function applyOrderColumn($column, $orderable)\n    {\n        $sql      = $this->columnDef['order'][$column]['sql'];\n        $sql      = str_replace('$1', $orderable['direction'], $sql);\n        $bindings = $this->columnDef['order'][$column]['bindings'];\n        $this->query->orderByRaw($sql, $bindings);\n    }", "label": 2}
{"code": "func AssertExpectationsForObjects(t TestingT, testObjects ...interface{}) bool {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tfor _, obj := range testObjects {\n\t\tif m, ok := obj.(Mock); ok {\n\t\t\tt.Logf(\"Deprecated mock.AssertExpectationsForObjects(myMock.Mock) use mock.AssertExpectationsForObjects(myMock)\")\n\t\t\tobj = &m\n\t\t}\n\t\tm := obj.(assertExpectationser)\n\t\tif !m.AssertExpectations(t) {\n\t\t\tt.Logf(\"Expectations didn't match for Mock: %+v\", reflect.TypeOf(m))\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "label": 5}
{"code": "protected void appendSQLClause(SelectionCriteria c, StringBuffer buf)\r\n    {\r\n        // BRJ : handle SqlCriteria\r\n        if (c instanceof SqlCriteria)\r\n        {\r\n            buf.append(c.getAttribute());\r\n            return;\r\n        }\r\n        \r\n        // BRJ : criteria attribute is a query\r\n        if (c.getAttribute() instanceof Query)\r\n        {\r\n            Query q = (Query) c.getAttribute();\r\n            buf.append(\"(\");\r\n            buf.append(getSubQuerySQL(q));\r\n            buf.append(\")\");\r\n            buf.append(c.getClause());\r\n            appendParameter(c.getValue(), buf);\r\n            return;\r\n        }\r\n\r\n\t\tAttributeInfo attrInfo = getAttributeInfo((String) c.getAttribute(), false, c.getUserAlias(), c.getPathClasses());\r\n        TableAlias alias = attrInfo.tableAlias;\r\n\r\n        if (alias != null)\r\n        {\r\n            boolean hasExtents = alias.hasExtents();\r\n\r\n            if (hasExtents)\r\n            {\r\n                // BRJ : surround with braces if alias has extents\r\n                buf.append(\"(\");\r\n                appendCriteria(alias, attrInfo.pathInfo, c, buf);\r\n\r\n                c.setNumberOfExtentsToBind(alias.extents.size());\r\n                Iterator iter = alias.iterateExtents();\r\n                while (iter.hasNext())\r\n                {\r\n                    TableAlias tableAlias = (TableAlias) iter.next();\r\n                    buf.append(\" OR \");\r\n                    appendCriteria(tableAlias, attrInfo.pathInfo, c, buf);\r\n                }\r\n                buf.append(\")\");\r\n            }\r\n            else\r\n            {\r\n                // no extents\r\n                appendCriteria(alias, attrInfo.pathInfo, c, buf);\r\n            }\r\n        }\r\n        else\r\n        {\r\n            // alias null\r\n            appendCriteria(alias, attrInfo.pathInfo, c, buf);\r\n        }\r\n\r\n    }", "label": 0}
{"code": "function(numberOfDownloaded, finishCallback, allCompletedCallback) {\n    let downloadedItem = 0;\n    return zincGeometry => {\n      downloadedItem = downloadedItem + 1;\n      if (finishCallback != undefined && (typeof finishCallback == 'function'))\n        finishCallback(zincGeometry);\n      if (downloadedItem == numberOfDownloaded)\n        if (allCompletedCallback != undefined && (typeof allCompletedCallback == 'function'))\n          allCompletedCallback();\n    };\n  }", "label": 3}
{"code": "async def load_message(self, msg_type, msg=None):\n        \"\"\"\n        Loads message if the given type from the reader.\n        Supports reading directly to existing message.\n\n        :param msg_type:\n        :param msg:\n        :return:\n        \"\"\"\n        msg = msg_type() if msg is None else msg\n        fields = msg_type.f_specs() if msg_type else msg.__class__.f_specs()\n        for field in fields:\n            await self.message_field(msg, field)\n\n        return msg", "label": 1}
{"code": "def suppress_deg_one_node(self, to_par_edge, nd_id, to_child_edge):\n        \"\"\"Deletes to_par_edge and nd_id. To be used when nd_id is an out-degree= 1 node\"\"\"\n        # circumvent the node with nd_id\n        to_child_edge_id = to_child_edge['@id']\n        par = to_par_edge['@source']\n        self._edge_by_source[par][to_child_edge_id] = to_child_edge\n        to_child_edge['@source'] = par\n        # make it a tip...\n        del self._edge_by_source[nd_id]\n        # delete it\n        self._del_tip(nd_id)", "label": 1}
{"code": "func IsControllerMounted(c string) (bool, error) {\n\tcgroupProcsPath := filepath.Join(\"/sys/fs/cgroup\", c, \"cgroup.procs\")\n\tif _, err := os.Stat(cgroupProcsPath); err != nil {\n\t\tif !os.IsNotExist(err) {\n\t\t\treturn false, err\n\t\t}\n\t\treturn false, nil\n\t}\n\n\treturn true, nil\n}", "label": 5}
{"code": "function highlight(value) {\n        var html = ngPrettyJsonFunctions.syntaxHighlight(value) || \"\";\n        html = html\n        .replace(/\\{/g, \"<span class='sep'>{</span>\")\n        .replace(/\\}/g, \"<span class='sep'>}</span>\")\n        .replace(/\\[/g, \"<span class='sep'>[</span>\")\n        .replace(/\\]/g, \"<span class='sep'>]</span>\")\n        .replace(/\\,/g, \"<span class='sep'>,</span>\");                        \n        return isDefined(value) ? scope.tmplElt.find('pre').html(html) : scope.tmplElt.find('pre').empty();\n      }", "label": 3}
{"code": "public static vpnclientlessaccesspolicy get(nitro_service service, String name) throws Exception{\n\t\tvpnclientlessaccesspolicy obj = new vpnclientlessaccesspolicy();\n\t\tobj.set_name(name);\n\t\tvpnclientlessaccesspolicy response = (vpnclientlessaccesspolicy) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (h *Handle) CheckConsistency() error {\n\tfor {\n\t\th.Lock()\n\t\tstore := h.store\n\t\th.Unlock()\n\n\t\tif store != nil {\n\t\t\tif err := store.GetObject(datastore.Key(h.Key()...), h); err != nil && err != datastore.ErrKeyNotFound {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\th.Lock()\n\t\tnh := h.getCopy()\n\t\th.Unlock()\n\n\t\tif !nh.runConsistencyCheck() {\n\t\t\treturn nil\n\t\t}\n\n\t\tif err := nh.writeToStore(); err != nil {\n\t\t\tif _, ok := err.(types.RetryError); !ok {\n\t\t\t\treturn fmt.Errorf(\"internal failure while fixing inconsistent bitsequence: %v\", err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tlogrus.Infof(\"Fixed inconsistent bit sequence in datastore:\\n%s\\n%s\", h, nh)\n\n\t\th.Lock()\n\t\th.head = nh.head\n\t\th.Unlock()\n\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "public static vpnglobal_binding get(nitro_service service) throws Exception{\n\t\tvpnglobal_binding obj = new vpnglobal_binding();\n\t\tvpnglobal_binding response = (vpnglobal_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def _quadratic_costs(self, generators, ipol, nxyz, base_mva):\n        \"\"\" Returns the quadratic cost components of the objective function.\n        \"\"\"\n        npol = len(ipol)\n        rnpol = range(npol)\n        gpol = [g for g in generators if g.pcost_model == POLYNOMIAL]\n\n        if [g for g in gpol if len(g.p_cost) > 3]:\n            logger.error(\"Order of polynomial cost greater than quadratic.\")\n\n        iqdr = [i for i, g in enumerate(generators)\n                if g.pcost_model == POLYNOMIAL and len(g.p_cost) == 3]\n        ilin = [i for i, g in enumerate(generators)\n                if g.pcost_model == POLYNOMIAL and len(g.p_cost) == 2]\n\n        polycf = zeros((npol, 3))\n        if npol > 0:\n            if len(iqdr) > 0:\n                polycf[iqdr, :] = array([list(g.p_cost)\n                                         for g in generators])#[iqdr, :].T\n            if len(ilin) > 0:\n                polycf[ilin, 1:] = array([list(g.p_cost[:2])\n                                          for g in generators])#[ilin, :].T\n            # Convert to per-unit.\n            polycf = polycf * array([base_mva**2, base_mva, 1])\n            Pg = self.om.get_var(\"Pg\")\n            Npol = csr_matrix((ones(npol), (rnpol, Pg.i1 + array(ipol))),\n                              (npol, nxyz))\n            Hpol = csr_matrix((2 * polycf[:, 0], (rnpol, rnpol)), (npol, npol))\n            Cpol = polycf[:, 1]\n            fparm_pol = (ones(npol) * array([[1], [0], [0], [1]])).T\n        else:\n            Npol = Hpol = None\n            Cpol = array([])\n            fparm_pol = zeros((0, 4))\n\n        return Npol, Hpol, Cpol, fparm_pol, polycf, npol", "label": 1}
{"code": "public function getNames(): array\n    {\n        if (!$this->names) {\n            $this->names = static::all()[$this->code] ?? [\n                'isoName' => $this->code,\n                'nativeName' => $this->code,\n            ];\n        }\n\n        return $this->names;\n    }", "label": 2}
{"code": "function updateSubmissionFile(req, res, next) {\n  var fileUpdateOptions = req.appformsResultPayload.data;\n\n  fileUpdateOptions.submission = {\n    submissionId: req.params.id,\n    fieldId: req.params.fieldId\n  };\n\n  //Remove the cached file when finished\n  fileUpdateOptions.keepFile = false;\n\n  //Adding A New File If Required\n  fileUpdateOptions.addingNewSubmissionFile = req.addingNewSubmissionFile;\n\n  //If not adding a new file, the fileId param is expected to be the file group id\n  if (!fileUpdateOptions.addingNewSubmissionFile) {\n    fileUpdateOptions.fileDetails.groupId = req.params.fileId;\n  } else {\n    fileUpdateOptions.fileDetails.hashName = req.params.fileId;\n  }\n\n  logger.debug(\"Middleware updateSubmissionFile \", {fileUpdateOptions: fileUpdateOptions});\n\n  forms.updateSubmissionFile(_.extend(fileUpdateOptions, req.connectionOptions), submissionsHandler(constants.resultTypes.submissions, req, next));\n}", "label": 3}
{"code": "function startNode(node) {\n            var navNode = emptyNavigationBarNode(node);\n            pushChild(parent, navNode);\n            // Save the old parent\n            parentsStack.push(parent);\n            parent = navNode;\n        }", "label": 3}
{"code": "function importForm(req, res, next) {\n  req.appformsResultPayload = req.appformsResultPayload || {};\n  var formData = (req.appformsResultPayload.data && req.appformsResultPayload.type === constants.resultTypes.formTemplate) ? req.appformsResultPayload.data : undefined ;\n\n  var importFormParams = {\n    form: formData,\n    name: req.body.name,\n    description: req.body.description,\n    userEmail: req.user.email\n  };\n\n  logger.debug(\"Middleware: importForm form: \", {params: importFormParams});\n\n  forms.cloneForm(_.extend(req.connectionOptions, importFormParams), formsResultHandlers(constants.resultTypes.forms, req, next));\n}", "label": 3}
{"code": "def list_logdir(self, id, filter=None, sort=None): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a list of logdir files.\n\n        :param id: Result ID as an int.\n        :param filter: Filter to apply as string.\n        :param sort: Sort field to apply as string.\n        :return: :class:`results.LogDirFile <results.LogDirFile>` list\n        \"\"\"\n        schema = LogDirFileSchema()\n        resp = self.service.list(self.base+str(id)+'/logdir/', filter, sort)\n        return self.service.decode(schema, resp, many=True)", "label": 1}
{"code": "public function setQueryList($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\QueryList::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "private function doDeserializeBaseProperty($type, $value)\n    {\n        $isAnnotationClass = is_string($type) && is_subclass_of(trim($type, '[]'), AbstractAnnotation::class);\n\n        if ($isAnnotationClass) {\n            $isArray = strpos($type, '[') === 0 && substr($type, -1) === ']';\n\n            if ($isArray) {\n                $annotationArr = [];\n                $class = trim($type, '[]');\n\n                foreach ($value as $v) {\n                    $annotationArr[] = $this->doDeserialize($v, $class);\n                }\n                return $annotationArr;\n            }\n\n            return $this->doDeserialize($value, $type);\n        }\n\n        return $value;\n    }", "label": 2}
{"code": "def predict(self, X):\n        \"\"\"\n        Assign classes to test data.\n\n        Parameters\n        ----------\n        X : array\n            Test data, of dimension N times d (rows are examples, columns\n            are data dimensions)\n\n        Returns\n        -------\n        y_predicted : array\n            A vector of length N containing assigned classes. If no inlier\n            classes were specified during training, then 0 denotes an inlier\n            and 1 denotes an outlier. If multiple inlier classes were\n            specified, then each element of y_predicted is either on of\n            those inlier classes, or an outlier class (denoted by the\n            maximum inlier class ID plus 1).\n        \"\"\"\n        predictions_proba = self.predict_proba(X)\n        predictions = []\n        allclasses = copy.copy(self.classes)\n        allclasses.append('anomaly')\n        for i in range(X.shape[0]):\n            predictions.append(allclasses[predictions_proba[i, :].argmax()])\n        return predictions", "label": 1}
{"code": "def title\n      resource_title = resource.try(:resource_title) || resource.try(:title)\n      return if resource_title.blank?\n\n      if resource_title.is_a?(String)\n        resource_title\n      elsif resource_title.is_a?(Hash)\n        translated_attribute(resource_title)\n      end\n    end", "label": 4}
{"code": "private function isDocument($name)\n    {\n        if (!$this->isRelative($name)) {\n            $name = $this->relativeName($name);\n        }\n\n        $parts = $this->splitName($name);\n        return count($parts) > 0 && count($parts) % 2 === 0;\n    }", "label": 2}
{"code": "function ToxError(type, code, message) {\n    this.name = \"ToxError\";\n    this.type = ( type || \"ToxError\" );\n    this.code = ( code || 0 ); // 0 = unsuccessful\n    this.message = ( message || (this.type + \": \" + this.code) );\n    Error.captureStackTrace(this, ToxError);\n}", "label": 3}
{"code": "def new_session\n      app = Rails.application\n      session = ActionDispatch::Integration::Session.new(app)\n      yield session if block_given?\n\n      # This makes app.url_for and app.foo_path available in the console\n      session.extend(app.routes.url_helpers)\n      session.extend(app.routes.mounted_helpers)\n\n      session\n    end", "label": 4}
{"code": "function readScopes (root, kids, cb) {\n  var scopes = kids . filter (function (kid) {\n    return kid . charAt (0) === '@'\n  })\n\n  kids = kids . filter (function (kid) {\n    return kid . charAt (0) !== '@'\n  })\n\n  debug ('scopes=%j', scopes)\n\n  if (scopes . length === 0)\n    dz (cb) (null, kids) // prevent maybe-sync zalgo release\n\n  cb = once (cb)\n  var l = scopes . length\n  scopes . forEach (function (scope) {\n    var scopedir = path . resolve (root, scope)\n    debug ('root=%j scope=%j scopedir=%j', root, scope, scopedir)\n    fs . readdir (scopedir, then . bind (null, scope))\n  })\n\n  function then (scope, er, scopekids) {\n    if (er)\n      return cb (er)\n\n    // XXX: Not sure how old this node bug is. Maybe superstition?\n    scopekids = scopekids . filter (function (scopekid) {\n      return !(scopekid === '.' || scopekid === '..' || !scopekid)\n    })\n\n    kids . push . apply (kids, scopekids . map (function (scopekid) {\n      return scope + '/' + scopekid\n    }))\n\n    debug ('scope=%j scopekids=%j kids=%j', scope, scopekids, kids)\n\n    if (--l === 0)\n      cb (null, kids)\n  }\n}", "label": 3}
{"code": "function () {\n        var namespaces = [\n            this._initialDefinition.$namespace,\n            this._extractRelativeNamespaceFromName()\n        ].filter(function (namespacePart) {\n            return namespacePart;\n        });\n        if (namespaces.length) {\n            this._namespace = namespaces.join(\".\");\n        }\n    }", "label": 3}
{"code": "def authorized(resp, remote):\n    \"\"\"Authorized callback handler for GitHub.\n\n    :param resp: The response.\n    :param remote: The remote application.\n    \"\"\"\n    if resp and 'error' in resp:\n        if resp['error'] == 'bad_verification_code':\n            # See https://developer.github.com/v3/oauth/#bad-verification-code\n            # which recommends starting auth flow again.\n            return redirect(url_for('invenio_oauthclient.login',\n                                    remote_app='github'))\n        elif resp['error'] in ['incorrect_client_credentials',\n                               'redirect_uri_mismatch']:\n            raise OAuthResponseError(\n                'Application mis-configuration in GitHub', remote, resp\n            )\n\n    return authorized_signup_handler(resp, remote)", "label": 1}
{"code": "func (a *CellView) MakeCursorVisible() {\n\tif a.model == nil {\n\t\treturn\n\t}\n\tx, y, enabled, _ := a.model.GetCursor()\n\tif enabled {\n\t\ta.MakeVisible(x, y)\n\t}\n}", "label": 5}
{"code": "func (c *HostCertParams) Check() error {\n\tif c.HostID == \"\" && len(c.Principals) == 0 {\n\t\treturn trace.BadParameter(\"HostID [%q] or Principals [%q] are required\",\n\t\t\tc.HostID, c.Principals)\n\t}\n\tif c.ClusterName == \"\" {\n\t\treturn trace.BadParameter(\"ClusterName [%q] is required\", c.ClusterName)\n\t}\n\n\tif err := c.Roles.Check(); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function _gpfHttpMockAdd (definition) {\n    var method = definition.method.toUpperCase(),\n        id = method + \".\" + _gpfHttpMockLastId++;\n    _gpfHttpMockGetMockedRequests(method).unshift(Object.assign({\n        id: id\n    }, definition));\n    return id;\n}", "label": 3}
{"code": "def trading_fees(self) -> TradingFees:\n        \"\"\"Fetch trading fees.\"\"\"\n        return self._fetch('trading fees', self.market.code)(self._trading_fees)()", "label": 1}
{"code": "public function setDevices($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Iot\\V1\\Device::class);\n        $this->devices = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def get_bias_details(self):\n        \"\"\"\n        returns a string representation of the bias details\n        \"\"\"\n        res = 'Bias File Details\\n'\n        for b in self.bias_details:\n            if len(b) > 2:\n                res += b[0].ljust(35)\n                res += b[1].ljust(35)\n                res += b[2].ljust(9)\n            res += '\\n'\n        return res", "label": 1}
{"code": "def __parse_loc_data(loc_data, result):\n    \"\"\"Parse the xml data from selected weatherstation.\"\"\"\n    result[DATA] = {ATTRIBUTION: ATTRIBUTION_INFO,\n                    FORECAST: [],\n                    PRECIPITATION_FORECAST: None}\n\n    for key, [value, func] in SENSOR_TYPES.items():\n        result[DATA][key] = None\n        try:\n            from buienradar.buienradar import condition_from_code\n            sens_data = loc_data[value]\n            if key == CONDITION:\n                # update weather symbol & status text\n                code = sens_data[__BRID][:1]\n                result[DATA][CONDITION] = condition_from_code(code)\n                result[DATA][CONDITION][IMAGE] = sens_data[__BRTEXT]\n            else:\n                if key == STATIONNAME:\n                    name = sens_data[__BRTEXT].replace(\"Meetstation\", \"\")\n                    name = name.strip()\n                    name += \" (%s)\" % loc_data[__BRSTATIONCODE]\n                    result[DATA][key] = name\n                else:\n                    # update all other data\n                    if func is not None:\n                        result[DATA][key] = func(sens_data)\n                    else:\n                        result[DATA][key] = sens_data\n        except KeyError:\n            if result[MESSAGE] is None:\n                result[MESSAGE] = \"Missing key(s) in br data: \"\n            result[MESSAGE] += \"%s \" % value\n            log.warning(\"Data element with key='%s' \"\n                        \"not loaded from br data!\", key)\n    result[SUCCESS] = True\n    return result", "label": 1}
{"code": "def branch_exists(self, branch):\n        \"\"\"Returns true or false depending on if a branch exists\"\"\"\n        try:\n            git(self.gitdir, self.gitwd, \"rev-parse\", branch)\n        except sh.ErrorReturnCode:\n            return False\n        return True", "label": 1}
{"code": "public function setRiskDetails($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\AnalyzeDataSourceRiskDetails::class);\n        $this->writeOneof(4, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def get_receiver(self, receiver=None, plugin=None):\n        \"\"\"\n        Get one or more receivers.\n\n        :param receiver: Name of the signal\n        :type receiver: str\n        :param plugin: Plugin object, under which the signals where registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if plugin is not None:\n            if receiver is None:\n                receiver_list = {}\n                for key in self.receivers.keys():\n                    if self.receivers[key].plugin == plugin:\n                        receiver_list[key] = self.receivers[key]\n                return receiver_list\n            else:\n                if receiver in self.receivers.keys():\n                    if self.receivers[receiver].plugin == plugin:\n                        return self.receivers[receiver]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if receiver is None:\n                return self.receivers\n            else:\n                if receiver in self.receivers.keys():\n                    return self.receivers[receiver]\n                else:\n                    return None", "label": 1}
{"code": "@SuppressWarnings({ \"unchecked\", \"unused\" })\n  private static void rewriteMergeList(String key, String subKey,\n      NamedList<Object> snl, NamedList<Object> tnl) {\n    for (int i = 0; i < tnl.size(); i++) {\n      Object item = snl.get(tnl.getName(i));\n      if (item != null && tnl.getVal(i) instanceof NamedList) {\n        NamedList<Object> tnnl = (NamedList<Object>) tnl.getVal(i);\n        Object o = tnnl.get(key);\n        NamedList<Object> tnnnl;\n        if (o != null && o instanceof NamedList) {\n          tnnnl = (NamedList<Object>) o;\n        } else {\n          tnnnl = new SimpleOrderedMap<>();\n          tnnl.add(key, tnnnl);\n        }\n        tnnnl.add(subKey, item);\n      }\n    }\n  }", "label": 0}
{"code": "function(code, err) {\n        this.response = {\n            response: {\n                statusCode: code,\n                headers: {},\n            },\n            body: null,\n            err: err,\n        };\n    }", "label": 3}
{"code": "func (g *GRPCServer) SendKeepAlives(stream proto.AuthService_SendKeepAlivesServer) error {\n\tdefer stream.SendAndClose(&empty.Empty{})\n\tauth, err := g.authenticate(stream.Context())\n\tif err != nil {\n\t\treturn trail.ToGRPC(err)\n\t}\n\tg.Debugf(\"Got heartbeat connection from %v.\", auth.User.GetName())\n\tfor {\n\t\tkeepAlive, err := stream.Recv()\n\t\tif err == io.EOF {\n\t\t\tg.Debugf(\"Connection closed.\")\n\t\t\treturn nil\n\t\t}\n\t\tif err != nil {\n\t\t\tg.Debugf(\"Failed to receive heartbeat: %v\", err)\n\t\t\treturn trail.ToGRPC(err)\n\t\t}\n\t\terr = auth.KeepAliveNode(stream.Context(), *keepAlive)\n\t\tif err != nil {\n\t\t\treturn trail.ToGRPC(err)\n\t\t}\n\t}\n}", "label": 5}
{"code": "function(operator, a, b, aOptions, bOptions, evaluateOptions) {\n\t\taOptions = aOptions || {};\n\t\tbOptions = bOptions || {};\n\t\tevaluateOptions = assign({\n\t\t\tevaluateWhere: operator,\n\t\t\tevaluatePaginate: operator,\n\t\t\tevaluateOrder: operator,\n\n\t\t\tshouldEvaluatePaginate: function(aClauseProps, bClauseProps) {\n\t\t\t\treturn aClauseProps.enabled.paginate || bClauseProps.enabled.paginate;\n\t\t\t},\n\t\t\tshouldEvaluateOrder: function(aClauseProps, bClauseProps) {\n\t\t\t\treturn aClauseProps.enabled.order && compare.equal(aClauseProps.order, bClauseProps.order, undefined, undefined, undefined,{},{});\n\t\t\t}\n\t\t\t/* aClauseProps.enabled.order || bClauseProps.enabled.order */\n\t\t}, evaluateOptions||{});\n\n\t\tvar aClauseProps = this.getClauseProperties(a, aOptions),\n\t\t\tbClauseProps = this.getClauseProperties(b, bOptions),\n\t\t\tset = {},\n\t\t\tuseSet;\n\n\t\tvar result = evaluateOptions.evaluateWhere(aClauseProps.where, bClauseProps.where,\n\t\t\tundefined, undefined, undefined, this.clauses.where, {});\n\n\t\tuseSet = this.updateSet(set, \"where\", result, useSet);\n\n\t\t// if success, and either has paginate props\n\t\tif(result && evaluateOptions.shouldEvaluatePaginate(aClauseProps,bClauseProps) ) {\n\n\t\t\t// if they have an order, it has to be true for paginate to be valid\n\t\t\t// this isn't true if a < b, a is paginated, and b is not.\n\t\t\tif( evaluateOptions.shouldEvaluateOrder(aClauseProps,bClauseProps)) {\n\t\t\t\tresult = evaluateOptions.evaluateOrder(aClauseProps.order, bClauseProps.order, undefined,\n\t\t\t\t\tundefined, undefined, {}, {});\n\n\t\t\t\tuseSet = this.updateSet(set, \"order\", result, useSet);\n\t\t\t}\n\n\t\t\tif(result) {\n\t\t\t\tresult = evaluateOptions.evaluatePaginate(aClauseProps.paginate, bClauseProps.paginate,\n\t\t\t\t\tundefined, undefined, undefined, this.clauses.paginate, {});\n\n\t\t\t\tuseSet = this.updateSet(set, \"paginate\", result, useSet);\n\t\t\t}\n\t\t}\n\t\t// if orders are the same keep order!\n\t\telse if( result && evaluateOptions.shouldEvaluateOrder(aClauseProps,bClauseProps) ) {\n\n\t\t\tresult = operator(aClauseProps.order, bClauseProps.order, undefined,\n\t\t\t\tundefined, undefined, {}, {});\n\n\t\t\tuseSet = this.updateSet(set, \"order\", result, useSet);\n\t\t}\n\n\t\t// not checking order here makes it mean that different orders represent the same set?\n\n\t\treturn result && useSet ? set : result;\n\t}", "label": 3}
{"code": "public function setSubstate($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dataproc\\V1\\JobStatus_Substate::class);\n        $this->substate = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def exists?(key, _locale = nil, locale: _locale)\n      locale ||= config.locale\n      raise Disabled.new('exists?') if locale == false\n      raise I18n::ArgumentError if key.is_a?(String) && key.empty?\n      config.backend.exists?(locale, key)\n    end", "label": 4}
{"code": "function processNode(attrNode, context) {\n    const isMainResource = context.attrPath.length === 0;\n\n    // identify/handle options-contexts: resource/sub-resource, nested-attribute, attribute:\n    if (attrNode.dataSources || attrNode.resource || isMainResource) {\n        context.errorContext = getErrorContext(isMainResource ? 'resource' : 'sub-resource', context);\n        context.subAttrPath = [];\n        context.dataSourceAttributes = {};\n\n        if (isMainResource) {\n            parseNode(\n                attrNode,\n                {\n                    dataSources: null,\n                    subFilters: parseSubFilters,\n                    resource: checkResourceName,\n                    primaryKey: parsePrimaryKey,\n                    depends: parseDepends,\n                    deprecated: parseBoolean,\n                    permission: null,\n                    attributes: null,\n                    defaultLimit: parseInteger,\n                    maxLimit: parseInteger,\n                    defaultOrder: requestParser.order\n                },\n                context\n            );\n        } else {\n            parseNode(\n                attrNode,\n                {\n                    dataSources: null,\n                    subFilters: parseSubFilters,\n                    resource: checkResourceName,\n                    primaryKey: parsePrimaryKey,\n                    parentKey: parseRelationKey,\n                    childKey: parseRelationKey,\n                    many: parseBoolean,\n                    depends: parseDepends,\n                    hidden: parseBoolean,\n                    deprecated: parseBoolean,\n                    permission: null,\n                    joinVia: checkIdentifier,\n                    attributes: null,\n                    defaultLimit: parseInteger,\n                    maxLimit: parseInteger,\n                    defaultOrder: requestParser.order\n                },\n                context\n            );\n        }\n\n        handleResourceContext(attrNode, context);\n    } else if (attrNode.attributes) {\n        context.errorContext = getErrorContext('nested-attribute', context);\n\n        parseNode(\n            attrNode,\n            {\n                depends: parseDepends,\n                hidden: parseBoolean,\n                deprecated: parseBoolean,\n                permission: null,\n                attributes: null\n            },\n            context\n        );\n\n        // no context-specific special-cases for nested-attributes\n    } else {\n        context.errorContext = getErrorContext('attribute', context);\n\n        // prepare standard-mapping - except for fixed values and inherited attributes:\n        if (!attrNode.map && !('value' in attrNode) && attrNode.inherit !== 'inherit') {\n            attrNode.map = null; // \"null\" means \"set standard-mapping in parseMap()\"\n        }\n\n        parseNode(\n            attrNode,\n            {\n                type: parseType,\n                multiValued: parseBoolean,\n                storedType: parseStoredType,\n                delimiter: null,\n                map: parseMap,\n                filter: parseFilter,\n                order: parseOrder,\n                value: parseStaticValue,\n                depends: parseDepends,\n                hidden: parseBoolean,\n                deprecated: parseBoolean,\n                permission: null,\n                inherit: parseInherit\n            },\n            context\n        );\n\n        handleAttributeContext(attrNode, context);\n    }\n\n    // recursion:\n    if (attrNode.attributes) {\n        Object.keys(attrNode.attributes).forEach(subAttrName => {\n            const subAttrNode = attrNode.attributes[subAttrName];\n\n            const subContext = Object.assign({}, context);\n            subContext.attrPath = context.attrPath.concat([subAttrName]);\n            subContext.subAttrPath = context.subAttrPath.concat([subAttrName]);\n\n            processNode(subAttrNode, subContext);\n        });\n    }\n\n    if (attrNode.dataSources) {\n        if (attrNode.primaryKey) resolvePrimaryKey(attrNode, context);\n        prepareDataSources(attrNode, context);\n    }\n}", "label": 3}
{"code": "function process(advertiserData) {\n  var data = advertiserData.manufacturerSpecificData.data;\n  var packetType = data.substr(0,2);\n\n  switch(packetType) { // Update when we have manufacturer documentation\n    case '01':\n    default:\n      nearable.process(advertiserData);\n  }\n}", "label": 3}
{"code": "def search_geocode_ban_fr_params(query)\n      params = {\n        q: query.sanitized_text\n      }\n      unless (limit = query.options[:limit]).nil? || !limit_param_is_valid?(limit)\n        params[:limit] = limit.to_i\n      end\n      unless (autocomplete = query.options[:autocomplete]).nil? || !autocomplete_param_is_valid?(autocomplete)\n        params[:autocomplete] = autocomplete.to_s\n      end\n      unless (type = query.options[:type]).nil? || !type_param_is_valid?(type)\n        params[:type] = type.downcase\n      end\n      unless (postcode = query.options[:postcode]).nil? || !code_param_is_valid?(postcode)\n        params[:postcode] = postcode.to_s\n      end\n      unless (citycode = query.options[:citycode]).nil? || !code_param_is_valid?(citycode)\n        params[:citycode] = citycode.to_s\n      end\n      params\n    end", "label": 4}
{"code": "def from_file(filename, mime=False):\n    \"\"\" Opens file, attempts to identify content based\n    off magic number and will return the file extension.\n    If mime is True it will return the mime type instead.\n\n    :param filename: path to file\n    :param mime: Return mime, not extension\n    :return: guessed extension or mime\n    \"\"\"\n\n    head, foot = _file_details(filename)\n    return _magic(head, foot, mime, ext_from_filename(filename))", "label": 1}
{"code": "def expiry_time(ns, cavs):\n    ''' Returns the minimum time of any time-before caveats found\n    in the given list or None if no such caveats were found.\n\n    The ns parameter is\n    :param ns: used to determine the standard namespace prefix - if\n    the standard namespace is not found, the empty prefix is assumed.\n    :param cavs: a list of pymacaroons.Caveat\n    :return: datetime.DateTime or None.\n    '''\n    prefix = ns.resolve(STD_NAMESPACE)\n    time_before_cond = condition_with_prefix(\n        prefix, COND_TIME_BEFORE)\n    t = None\n    for cav in cavs:\n        if not cav.first_party():\n            continue\n        cav = cav.caveat_id_bytes.decode('utf-8')\n        name, rest = parse_caveat(cav)\n        if name != time_before_cond:\n            continue\n        try:\n            et = pyrfc3339.parse(rest, utc=True).replace(tzinfo=None)\n            if t is None or et < t:\n                t = et\n        except ValueError:\n            continue\n    return t", "label": 1}
{"code": "function do_save(id, isnew) {\n        var mement = ent.data$(true, 'string')\n\n        if (undefined !== id) {\n          mement.id = id\n        }\n\n        mement.entity$ = ent.entity$\n\n        entmap[base] = entmap[base] || {}\n        entmap[base][name] = entmap[base][name] || {}\n\n        var prev = entmap[base][name][mement.id]\n        if (isnew && prev) {\n          return reply(error('entity-id-exists', { type: ent.entity$, id: id }))\n        }\n\n        var shouldMerge = true\n        if (options.merge !== false && ent.merge$ === false) {\n          shouldMerge = false\n        }\n        if (options.merge === false && ent.merge$ !== true) {\n          shouldMerge = false\n        }\n\n        mement = _.cloneDeep(mement)\n        if (shouldMerge) {\n          mement = _.assign(prev || {}, mement)\n        }\n        prev = entmap[base][name][mement.id] = mement\n\n        seneca.log.debug(function() {\n          return [\n            'save/' + (create ? 'insert' : 'update'),\n            ent.canon$({ string: 1 }),\n            mement,\n            desc\n          ]\n        })\n\n        reply(null, ent.make$(prev))\n      }", "label": 3}
{"code": "public void printAnswers(List<CoreLabel> doc, PrintWriter out) {\r\n    // boolean tagsMerged = flags.mergeTags;\r\n    // boolean useHead = flags.splitOnHead;\r\n\r\n    if ( ! \"iob1\".equalsIgnoreCase(flags.entitySubclassification)) {\r\n      deEndify(doc);\r\n    }\r\n\r\n    for (CoreLabel fl : doc) {\r\n      String word = fl.word();\r\n      if (word == BOUNDARY) { // Using == is okay, because it is set to constant\r\n        out.println();\r\n      } else {\r\n        String gold = fl.get(OriginalAnswerAnnotation.class);\r\n        if(gold == null) gold = \"\";\r\n        String guess = fl.get(AnswerAnnotation.class);\r\n        // System.err.println(fl.word() + \"\\t\" + fl.get(AnswerAnnotation.class) + \"\\t\" + fl.get(AnswerAnnotation.class));\r\n        String pos = fl.tag();\r\n        String chunk = (fl.get(ChunkAnnotation.class) == null ? \"\" : fl.get(ChunkAnnotation.class));\r\n        out.println(fl.word() + '\\t' + pos + '\\t' + chunk + '\\t' +\r\n                    gold + '\\t' + guess);\r\n      }\r\n    }\r\n  }", "label": 0}
{"code": "public function setDeviceStates($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Iot\\V1\\DeviceState::class);\n        $this->device_states = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function(verificationId) {\n    return new Promise((resolve, reject) => {\n      this._start()\n          .uri('/api/user/verify-email')\n          .urlSegment(verificationId)\n          .post()\n          .go(this._responseHandler(resolve, reject));\n    });\n  }", "label": 3}
{"code": "public function setField($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\Admin\\V1\\Field::class);\n        $this->field = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private static Object getParam(final Object param) {\n\t\tfinal StringBuilder sb = new StringBuilder();\n\t\tif(param instanceof String){\n\t\t\tsb.append(\"'\");\n\t\t\tsb.append((String)param);\n\t\t\tsb.append(\"'\");\n\t\t}\n\t\telse if(param instanceof Boolean){\n\t\t\tsb.append(String.valueOf((Boolean)param));\t\t\t\n\t\t}\n        else if(param instanceof Integer){\n            sb.append(String.valueOf((Integer)param));\n        }\n        else if(param instanceof DBRegExp){\n            sb.append('/');\n            sb.append(((DBRegExp) param).toString());\n            sb.append('/');\n        }\n\t\t\n\t\treturn sb.toString();\n\t}", "label": 0}
{"code": "def add_guild_member(data)\n      server_id = data['guild_id'].to_i\n      server = self.server(server_id)\n\n      member = Member.new(data, server, self)\n      server.add_member(member)\n    end", "label": 4}
{"code": "function _MinHeap(elements) {\n                    var comparator = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : defaultComparator;\n\n                    _classCallCheck(this, _MinHeap);\n\n                    __assertArray(elements);\n                    __assertFunction(comparator);\n                    // we do not wrap elements here since the heapify function does that the moment it encounters elements\n                    this.__elements = elements;\n                    // create comparator that works on heap elements (it also ensures equal elements remain in original order)\n                    this.__comparator = function (a, b) {\n                        var res = comparator(a.__value, b.__value);\n                        if (res !== 0) {\n                            return res;\n                        }\n                        return defaultComparator(a.__index, b.__index);\n                    };\n                    // create heap ordering\n                    this.__createHeap(this.__elements, this.__comparator);\n                }", "label": 3}
{"code": "def attribute_was(attr)\n      attr = database_field_name(attr)\n      attribute_changed?(attr) ? changed_attributes[attr] : attributes[attr]\n    end", "label": 4}
{"code": "public function isColumnSearchable($i, $column_search = true)\n    {\n        if ($column_search) {\n            return\n                (\n                    $this->request->input(\"columns.$i.searchable\", 'true') === 'true'\n                    ||\n                    $this->request->input(\"columns.$i.searchable\", 'true') === true\n                )\n                && $this->columnKeyword($i) != '';\n        }\n\n        return\n            $this->request->input(\"columns.$i.searchable\", 'true') === 'true'\n            ||\n            $this->request->input(\"columns.$i.searchable\", 'true') === true;\n    }", "label": 2}
{"code": "func (self AudioFrame) HasSameFormat(other AudioFrame) bool {\n\tif self.SampleRate != other.SampleRate {\n\t\treturn false\n\t}\n\tif self.ChannelLayout != other.ChannelLayout {\n\t\treturn false\n\t}\n\tif self.SampleFormat != other.SampleFormat {\n\t\treturn false\n\t}\n\treturn true\n}", "label": 5}
{"code": "def for_context(context)\n      contexts = hash.keys.select { |ckey| context.matches?([ckey]) }\n      contexts.map { |exc| hash[exc] }\n    end", "label": 4}
{"code": "function resolveConfig(conf, version = '') {\n\tconf['siteroot'] = conf.baseurl || '/';\n\tif (version) {\n\t\tconf['baseurl'] = path.join(conf.siteroot, version);\n\t}\n\n\tfor (let key in conf) {\n\t\tif (CONFIG_VAR_REGEX.test(conf[key])) {\n\t\t\tconf[key] = resolve(conf[key], conf, [key]);\n\t\t}\n\t}\n\treturn conf;\n}", "label": 3}
{"code": "func (c *Client) ValidateSAMLResponse(re string) (*SAMLAuthResponse, error) {\n\tout, err := c.PostJSON(c.Endpoint(\"saml\", \"requests\", \"validate\"), validateSAMLResponseReq{\n\t\tResponse: re,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar rawResponse *samlAuthRawResponse\n\tif err := json.Unmarshal(out.Bytes(), &rawResponse); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tresponse := SAMLAuthResponse{\n\t\tUsername: rawResponse.Username,\n\t\tIdentity: rawResponse.Identity,\n\t\tCert:     rawResponse.Cert,\n\t\tReq:      rawResponse.Req,\n\t\tTLSCert:  rawResponse.TLSCert,\n\t}\n\tif len(rawResponse.Session) != 0 {\n\t\tsession, err := services.GetWebSessionMarshaler().UnmarshalWebSession(rawResponse.Session)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tresponse.Session = session\n\t}\n\tresponse.HostSigners = make([]services.CertAuthority, len(rawResponse.HostSigners))\n\tfor i, raw := range rawResponse.HostSigners {\n\t\tca, err := services.GetCertAuthorityMarshaler().UnmarshalCertAuthority(raw)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tresponse.HostSigners[i] = ca\n\t}\n\treturn &response, nil\n}", "label": 5}
{"code": "public static java.util.Date getDateTime(Object value) {\n        try {\n            return toDateTime(value);\n        } catch (ParseException pe) {\n            pe.printStackTrace();\n            return null;\n        }\n    }", "label": 0}
{"code": "def get_cycle(plugins, cycle_start)\n      cycle = plugins.drop_while { |plugin| !plugin.eql?(cycle_start) }\n      names = []\n      cycle.each { |plugin| names << plugin.name }\n      names\n    end", "label": 4}
{"code": "function isTime(time) {\n  return time != null && time._manipulate != null && time._date != null;\n}", "label": 3}
{"code": "func (f *file) lintTypeDoc(t *ast.TypeSpec, doc *ast.CommentGroup) {\n\tif !ast.IsExported(t.Name.Name) {\n\t\treturn\n\t}\n\tif doc == nil {\n\t\tf.errorf(t, 1, link(docCommentsLink), category(\"comments\"), \"exported type %v should have comment or be unexported\", t.Name)\n\t\treturn\n\t}\n\n\ts := doc.Text()\n\tarticles := [...]string{\"A\", \"An\", \"The\"}\n\tfor _, a := range articles {\n\t\tif strings.HasPrefix(s, a+\" \") {\n\t\t\ts = s[len(a)+1:]\n\t\t\tbreak\n\t\t}\n\t}\n\tif !strings.HasPrefix(s, t.Name.Name+\" \") {\n\t\tf.errorf(doc, 1, link(docCommentsLink), category(\"comments\"), `comment on exported type %v should be of the form \"%v ...\" (with optional leading article)`, t.Name, t.Name)\n\t}\n}", "label": 5}
{"code": "func (a *AuthServer) DeleteRemoteCluster(clusterName string) error {\n\t// To make sure remote cluster exists - to protect against random\n\t// clusterName requests (e.g. when clusterName is set to local cluster name)\n\t_, err := a.Presence.GetRemoteCluster(clusterName)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\t// delete cert authorities associated with the cluster\n\terr = a.DeleteCertAuthority(services.CertAuthID{\n\t\tType:       services.HostCA,\n\t\tDomainName: clusterName,\n\t})\n\tif err != nil {\n\t\t// this method could have succeeded on the first call,\n\t\t// but then if the remote cluster resource could not be deleted\n\t\t// it would be impossible to delete the cluster after then\n\t\tif !trace.IsNotFound(err) {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\t// there should be no User CA in trusted clusters on the main cluster side\n\t// per standard automation but clean up just in case\n\terr = a.DeleteCertAuthority(services.CertAuthID{\n\t\tType:       services.UserCA,\n\t\tDomainName: clusterName,\n\t})\n\tif err != nil {\n\t\tif !trace.IsNotFound(err) {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\treturn a.Presence.DeleteRemoteCluster(clusterName)\n}", "label": 5}
{"code": "public boolean isServerAvailable(){\n        final Client client = getClient();\n        final ClientResponse response = client.resource(serverURL).get(ClientResponse.class);\n\n        if(ClientResponse.Status.OK.getStatusCode() == response.getStatus()){\n            return true;\n        }\n\n        if(LOG.isErrorEnabled()) {\n            LOG.error(String.format(HTTP_STATUS_TEMPLATE_MSG, \"Failed to reach the targeted Grapes server\", response.getStatus()));\n        }\n        client.destroy();\n\n        return false;\n    }", "label": 0}
{"code": "public SqlStatement getPreparedUpdateStatement(ClassDescriptor cld)\r\n    {\r\n        SqlForClass sfc = getSqlForClass(cld);\r\n        SqlStatement result = sfc.getUpdateSql();\r\n        if(result == null)\r\n        {\r\n            ProcedureDescriptor pd = cld.getUpdateProcedure();\r\n\r\n            if(pd == null)\r\n            {\r\n                result = new SqlUpdateStatement(cld, logger);\r\n            }\r\n            else\r\n            {\r\n                result = new SqlProcedureStatement(pd, logger);\r\n            }\r\n            // set the sql string\r\n            sfc.setUpdateSql(result);\r\n\r\n            if(logger.isDebugEnabled())\r\n            {\r\n                logger.debug(\"SQL:\" + result.getStatement());\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "func (s *PresenceService) DeleteAllReverseTunnels() error {\n\tstartKey := backend.Key(reverseTunnelsPrefix)\n\treturn s.DeleteRange(context.TODO(), startKey, backend.RangeEnd(startKey))\n}", "label": 5}
{"code": "func (d Datastore) Download(ctx context.Context, path string, param *soap.Download) (io.ReadCloser, int64, error) {\n\tu, p, err := d.downloadTicket(ctx, path, param)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\treturn d.Client().Download(ctx, u, p)\n}", "label": 5}
{"code": "def returns(sexp)\n      return returns s(:nil) unless sexp\n\n      case sexp.type\n      when :undef\n        # undef :method_name always returns nil\n        returns s(:begin, sexp, s(:nil))\n      when :break, :next, :redo\n        sexp\n      when :yield\n        sexp.updated(:returnable_yield, nil)\n      when :when\n        *when_sexp, then_sexp = *sexp\n        sexp.updated(nil, [*when_sexp, returns(then_sexp)])\n      when :rescue\n        body_sexp, *resbodies, else_sexp = *sexp\n\n        resbodies = resbodies.map do |resbody|\n          returns(resbody)\n        end\n\n        if else_sexp\n          else_sexp = returns(else_sexp)\n        end\n\n        sexp.updated(\n          nil, [\n            returns(body_sexp),\n            *resbodies,\n            else_sexp\n          ]\n        )\n      when :resbody\n        klass, lvar, body = *sexp\n        sexp.updated(nil, [klass, lvar, returns(body)])\n      when :ensure\n        rescue_sexp, ensure_body = *sexp\n        sexp = sexp.updated(nil, [returns(rescue_sexp), ensure_body])\n        s(:js_return, sexp)\n      when :begin, :kwbegin\n        # Wrapping last expression with s(:js_return, ...)\n        *rest, last = *sexp\n        sexp.updated(nil, [*rest, returns(last)])\n      when :while, :until, :while_post, :until_post\n        sexp\n      when :return, :js_return, :returnable_yield\n        sexp\n      when :xstr\n        sexp.updated(nil, [s(:js_return, *sexp.children)])\n      when :if\n        cond, true_body, false_body = *sexp\n        sexp.updated(\n          nil, [\n            cond,\n            returns(true_body),\n            returns(false_body)\n          ]\n        )\n      else\n        s(:js_return, sexp).updated(\n          nil,\n          nil,\n          location: sexp.loc,\n        )\n      end\n    end", "label": 4}
{"code": "def get_cited_dois(arxiv_id):\n    \"\"\"\n    Get the DOIs of the papers cited in a .bbl file.\n\n    .. note::\n\n        Bulk download of sources from arXiv is not permitted by their API. \\\n                You should have a look at http://arxiv.org/help/bulk_data_s3.\n\n    :param arxiv_id: The arXiv id (e.g. ``1401.2910`` or ``1401.2910v1``) in \\\n            a canonical form.\n    :returns: A dict of cleaned plaintext citations and their associated DOI.\n    \"\"\"\n    dois = {}\n    # Get the list of bbl files for this preprint\n    bbl_files = arxiv.get_bbl(arxiv_id)\n    for bbl_file in bbl_files:\n        # Fetch the cited DOIs for each of the bbl files\n        dois.update(bbl.get_cited_dois(bbl_file))\n    return dois", "label": 1}
{"code": "func (f *Fpdf) Output(w io.Writer) error {\n\tif f.err != nil {\n\t\treturn f.err\n\t}\n\t// dbg(\"Output\")\n\tif f.state < 3 {\n\t\tf.Close()\n\t}\n\t_, err := f.buffer.WriteTo(w)\n\tif err != nil {\n\t\tf.err = err\n\t}\n\treturn f.err\n}", "label": 5}
{"code": "public static boolean isPropertyAllowed(Class defClass, String propertyName)\r\n    {\r\n        HashMap props = (HashMap)_properties.get(defClass);\r\n\r\n        return (props == null ? true : props.containsKey(propertyName));\r\n    }", "label": 0}
{"code": "def new_more_like_this(object, *types, &block)\n      types[0] ||= object.class\n      mlt = Search::MoreLikeThisSearch.new(\n        connection,\n        setup_for_types(types),\n        Query::MoreLikeThisQuery.new(object, types),\n        @config\n      )\n      mlt.build(&block) if block\n      mlt\n    end", "label": 4}
{"code": "func (t *TransportPort) GetCopy() TransportPort {\n\treturn TransportPort{Proto: t.Proto, Port: t.Port}\n}", "label": 5}
{"code": "protected function registerStorageDriver()\n    {\n        $driver = config('telescope.driver');\n\n        if (method_exists($this, $method = 'register'.ucfirst($driver).'Driver')) {\n            $this->$method();\n        }\n    }", "label": 2}
{"code": "func (c *NodeCommand) ListActive(client auth.ClientI) error {\n\tnodes, err := client.GetNodes(c.namespace, services.SkipValidation())\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tcoll := &serverCollection{servers: nodes}\n\tcoll.writeText(os.Stdout)\n\treturn nil\n}", "label": 5}
{"code": "def parse(base_dir: str, timestamp: int = None) -> int:\n        \"\"\"\n        Parse and update from archived cache files. Only accept new content;\n        do not overwrite any existing cache content.\n\n        :param base_dir: archive base directory\n        :param timestamp: epoch time of cache serving as subdirectory, default most recent\n        :return: epoch time of cache serving as subdirectory, None if there is no such archive.\n        \"\"\"\n\n        LOGGER.debug('parse >>> base_dir: %s, timestamp: %s', base_dir, timestamp)\n\n        if not isdir(base_dir):\n            LOGGER.info('No cache archives available: not feeding cache')\n            LOGGER.debug('parse <<< None')\n            return None\n\n        if not timestamp:\n            timestamps = [int(t) for t in listdir(base_dir) if t.isdigit()]\n            if timestamps:\n                timestamp = max(timestamps)\n            else:\n                LOGGER.info('No cache archives available: not feeding cache')\n                LOGGER.debug('parse <<< None')\n                return None\n\n        timestamp_dir = join(base_dir, str(timestamp))\n        if not isdir(timestamp_dir):\n            LOGGER.error('No such archived cache directory: %s', timestamp_dir)\n            LOGGER.debug('parse <<< None')\n            return None\n\n        with SCHEMA_CACHE.lock:\n            with open(join(timestamp_dir, 'schema'), 'r') as archive:\n                schemata = json.loads(archive.read())\n                SCHEMA_CACHE.feed(schemata)\n\n        with CRED_DEF_CACHE.lock:\n            with open(join(timestamp_dir, 'cred_def'), 'r') as archive:\n                cred_defs = json.loads(archive.read())\n                for cd_id in cred_defs:\n                    if cd_id in CRED_DEF_CACHE:\n                        LOGGER.warning('Cred def cache already has cred def on %s: skipping', cd_id)\n                    else:\n                        CRED_DEF_CACHE[cd_id] = cred_defs[cd_id]\n                        LOGGER.info('Cred def cache imported cred def for cred def id %s', cd_id)\n\n        with REVO_CACHE.lock:\n            with open(join(timestamp_dir, 'revocation'), 'r') as archive:\n                rr_cache_entries = json.loads(archive.read())\n                for (rr_id, entry) in rr_cache_entries.items():\n                    if rr_id in REVO_CACHE:\n                        LOGGER.warning('Revocation cache already has entry on %s: skipping', rr_id)\n                    else:\n                        rr_cache_entry = RevoCacheEntry(entry['rev_reg_def'])\n\n                        rr_cache_entry.rr_delta_frames = [\n                            RevRegUpdateFrame(\n                                f['_to'],\n                                f['_timestamp'],\n                                f['_rr_update']) for f in entry['rr_delta_frames']\n                        ]\n                        rr_cache_entry.cull(True)\n\n                        rr_cache_entry.rr_state_frames = [\n                            RevRegUpdateFrame(\n                                f['_to'],\n                                f['_timestamp'],\n                                f['_rr_update']) for f in entry['rr_state_frames']\n                        ]\n                        rr_cache_entry.cull(False)\n\n                        REVO_CACHE[rr_id] = rr_cache_entry\n                        LOGGER.info('Revocation cache imported entry for rev reg id %s', rr_id)\n\n        LOGGER.debug('parse <<< %s', timestamp)\n        return timestamp", "label": 1}
{"code": "public function setExclusionRule($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\ExclusionRule::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "function deploy(req, res, next) {\n  var dataSource = req.body;\n\n  dataSource._id = req.params.id;\n\n  forms.dataSources.deploy(req.connectionOptions, dataSource, dataSourcesHandler(constants.resultTypes.dataSources, req, next));\n}", "label": 3}
{"code": "func (d *Decoder) pushElement(name Name) {\n\ts := d.push(stkStart)\n\ts.name = name\n}", "label": 5}
{"code": "@SuppressWarnings(\"deprecation\")\n\tpublic static boolean dateEquals(java.util.Date d1, java.util.Date d2) {\n        if (d1 == null || d2 == null) {\n            return false;\n        }\n\n        return d1.getDate() == d2.getDate()\n                && d1.getMonth() == d2.getMonth()\n                && d1.getYear() == d2.getYear();\n    }", "label": 0}
{"code": "public function exists(array $options = [])\n    {\n        try {\n            $this->connection->getObject($this->identity + $options + ['fields' => 'name']);\n        } catch (NotFoundException $ex) {\n            return false;\n        }\n\n        return true;\n    }", "label": 2}
{"code": "public static sslaction[] get(nitro_service service) throws Exception{\n\t\tsslaction obj = new sslaction();\n\t\tsslaction[] response = (sslaction[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function formatErrors(\n\t\tAnalysisResult $analysisResult,\n\t\tOutputStyle $style\n\t): int\n\t{\n\t\t$style->writeln('<?xml version=\"1.0\" encoding=\"UTF-8\"?>');\n\t\t$style->writeln('<checkstyle>');\n\n\t\tforeach ($this->groupByFile($analysisResult) as $relativeFilePath => $errors) {\n\t\t\t$style->writeln(sprintf(\n\t\t\t\t'<file name=\"%s\">',\n\t\t\t\t$this->escape($relativeFilePath)\n\t\t\t));\n\n\t\t\tforeach ($errors as $error) {\n\t\t\t\t$style->writeln(sprintf(\n\t\t\t\t\t'  <error line=\"%d\" column=\"1\" severity=\"error\" message=\"%s\" />',\n\t\t\t\t\t$this->escape((string) $error->getLine()),\n\t\t\t\t\t$this->escape((string) $error->getMessage())\n\t\t\t\t));\n\t\t\t}\n\t\t\t$style->writeln('</file>');\n\t\t}\n\n\t\t$notFileSpecificErrors = $analysisResult->getNotFileSpecificErrors();\n\n\t\tif (count($notFileSpecificErrors) > 0) {\n\t\t\t$style->writeln('<file>');\n\n\t\t\tforeach ($notFileSpecificErrors as $error) {\n\t\t\t\t$style->writeln(sprintf('  <error severity=\"error\" message=\"%s\" />', $this->escape($error)));\n\t\t\t}\n\n\t\t\t$style->writeln('</file>');\n\t\t}\n\n\t\t$style->writeln('</checkstyle>');\n\n\t\treturn $analysisResult->hasErrors() ? 1 : 0;\n\t}", "label": 2}
{"code": "public function addAttribute($key, $value)\n    {\n        if (!$this->attributes) {\n            $this->attributes = new Attributes();\n        }\n\n        $this->attributes[$key] = $value;\n    }", "label": 2}
{"code": "function(comparator)\n  {\n    var map = this;\n\n    // Sort this partition!\n    function partition(left, right)\n    {\n      var pivot = map.values[ Math.floor((right + left) / 2) ];\n      var i = left;\n      var j = right;\n\n      while (i <= j)\n      {\n        while (comparator( map.values[i], pivot ) < 0)\n        {\n          i++;\n        }\n        while (comparator( map.values[j], pivot ) > 0)\n        {\n          j--;\n        }\n\n        if (i <= j)\n        {\n          swap( map.values, i, j );\n          swap( map.keys, i, j );\n          i++;\n          j--;\n        }\n      }\n\n      return i;\n    }\n\n    // Quicksort\n    function qsort(left, right)\n    {\n      var index = partition( left, right );\n\n      if (left < index - 1)\n      {\n        qsort( left, index - 1 );\n      }\n\n      if (index < right)\n      {\n        qsort( index, right );\n      }\n    }\n\n    var right = this.size() - 1;\n\n    // Are there elements to sort?\n    if ( right > 0 )\n    {\n      qsort( 0, right );\n\n      this.rebuildIndex();\n    }\n\n    return this;\n  }", "label": 3}
{"code": "function getDepInfo (dep, currFile, customDepResolve) {\n  let depResolve\n\n  if (!customDepResolve) {\n    depResolve = defaultDepResolve\n  } else {\n    depResolve = (dep, currFile) => {\n      // parse defaultResolve as third param\n      return customDepResolve(dep, currFile, defaultDepResolve)\n    }\n  }\n\n  let currType = getParseType(currFile)\n  let type = getParseType(dep) || currType\n  let info = {\n    parent: currFile,     // parent file path\n    type: type,           // current file type (js/css)\n    raw: dep,             // raw dependency name (require('./xxx') => './xxx')\n    name: null,           // formated dependency name ('~@alife/xxx' => '@alife/xxx')\n    module: null,         // module name (only external module)\n    file: null            // resolved file name (only relative file)\n  }\n\n  info.name = depResolve(dep, currFile)\n\n  if (!info.name.startsWith('.')) {\n    if (info.name.startsWith('@')) {\n      info.module = info.name.split('/', 2).join('/')\n    } else {\n      info.module = info.name.split('/', 1)[0]\n    }\n  } else {\n    info.file = fileResolve(info.name, currFile)\n\n    if (!info.file) {\n      throw new ResolveError(info.name, currFile)\n    }\n  }\n\n  return info\n}", "label": 3}
{"code": "public function sendClearDirty($categories)\n    {\n        $msgId = $this->createIqId();\n\n        $catnodes = [];\n        foreach ($categories as $category) {\n            $catnode = new ProtocolNode('clean', ['type' => $category], null, null);\n            $catnodes[] = $catnode;\n        }\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'type'  => 'set',\n                'to'    => Constants::WHATSAPP_SERVER,\n                'xmlns' => 'urn:xmpp:whatsapp:dirty',\n            ], $catnodes, null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "def add_resource_fragment(fragment, include_related)\n      fragment.primary = true\n\n      init_included_relationships(fragment, include_related)\n\n      @fragments[fragment.identity] = fragment\n    end", "label": 4}
{"code": "func New() *Martini {\n\tm := &Martini{Injector: inject.New(), action: func() {}, logger: log.New(os.Stdout, \"[martini] \", 0)}\n\tm.Map(m.logger)\n\tm.Map(defaultReturnHandler())\n\treturn m\n}", "label": 5}
{"code": "def bigtable scope: nil, timeout: nil, credentials: nil, client_config: nil\n      Google::Cloud.bigtable(\n        project_id: @project,\n        credentials: (credentials || @keyfile),\n        scope: scope,\n        timeout: (timeout || @timeout),\n        client_config: client_config\n      )\n    end", "label": 4}
{"code": "def info(request):\n    \"\"\"\n    display some user info to show we have authenticated successfully\n    \"\"\"\n    if check_key(request):\n        api = get_api(request)\n        user = api.users(id='self')\n        print dir(user)\n        return render_to_response('djfoursquare/info.html', {'user': user})\n    else:\n        return HttpResponseRedirect(reverse('main'))", "label": 1}
{"code": "func setupStage1Image(cfg RunConfig, cdir string, useOverlay bool) error {\n\ts1 := common.Stage1ImagePath(cdir)\n\tif useOverlay {\n\t\ttreeStoreID, err := ioutil.ReadFile(filepath.Join(cdir, common.Stage1TreeStoreIDFilename))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// pass an empty appName\n\t\tif err := overlayRender(cfg, string(treeStoreID), cdir, s1, \"\"); err != nil {\n\t\t\treturn errwrap.Wrap(errors.New(\"error rendering overlay filesystem\"), err)\n\t\t}\n\n\t\t// we will later read the status from the upper layer of the overlay fs\n\t\t// force the status directory to be there by touching it\n\t\tstatusPath := filepath.Join(s1, \"rootfs\", \"rkt\", \"status\")\n\t\tif err := os.Chtimes(statusPath, time.Now(), time.Now()); err != nil {\n\t\t\treturn errwrap.Wrap(errors.New(\"error touching status dir\"), err)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def setup_backtrace_cleaner_path\n      return unless Rails.backtrace_cleaner.instance_variable_get(:@root) == '/'\n      Rails.backtrace_cleaner.instance_variable_set :@root, Rails.root.to_s\n    end", "label": 4}
{"code": "def as_tokens(ctx: List[ParserRuleContext]) -> List[str]:\n    \"\"\"Return a stringified list of identifiers in ctx\n\n    :param ctx: JSG parser item with a set of identifiers\n    :return:\n    \"\"\"\n    return [as_token(e) for e in ctx]", "label": 1}
{"code": "private function parseError(\n        array $err,\n        RequestInterface $request,\n        CommandInterface $command,\n        array $stats\n    ) {\n        if (!isset($err['exception'])) {\n            throw new \\RuntimeException('The HTTP handler was rejected without an \"exception\" key value pair.');\n        }\n\n        $serviceError = \"AWS HTTP error: \" . $err['exception']->getMessage();\n\n        if (!isset($err['response'])) {\n            $parts = ['response' => null];\n        } else {\n            try {\n                $parts = call_user_func($this->errorParser, $err['response']);\n                $serviceError .= \" {$parts['code']} ({$parts['type']}): \"\n                    . \"{$parts['message']} - \" . $err['response']->getBody();\n            } catch (ParserException $e) {\n                $parts = [];\n                $serviceError .= ' Unable to parse error information from '\n                    . \"response - {$e->getMessage()}\";\n            }\n\n            $parts['response'] = $err['response'];\n        }\n\n        $parts['exception'] = $err['exception'];\n        $parts['request'] = $request;\n        $parts['connection_error'] = !empty($err['connection_error']);\n        $parts['transfer_stats'] = $stats;\n\n        return new $this->exceptionClass(\n            sprintf(\n                'Error executing \"%s\" on \"%s\"; %s',\n                $command->getName(),\n                $request->getUri(),\n                $serviceError\n            ),\n            $command,\n            $parts,\n            $err['exception']\n        );\n    }", "label": 2}
{"code": "def delete_translation_values\n      field_key = FieldKey.find_by_global_key(params[:i18n_key])\n      field_key.visible = false\n\n      # not convinced it makes sense to delete the associated translations\n      # phrases = I18n::Backend::ActiveRecord::Translation.where(:key => params[:i18n_key])\n      # phrases.destroy_all\n\n      field_key.save!\n      render json: { success: true }\n    end", "label": 4}
{"code": "function _callIfFn(thing, context, properties) {\n  return _.isFunction(thing) ? thing(context, properties) : thing;\n}", "label": 3}
{"code": "def histogram(stat, value, opts=EMPTY_OPTIONS)\n      send_stats stat, value, HISTOGRAM_TYPE, opts\n    end", "label": 4}
{"code": "def find_databases(databases):\n    \"\"\"\n    define ribosomal proteins and location of curated databases\n    \"\"\"\n    # 16 ribosomal proteins in their expected order\n    proteins = ['L15', 'L18', 'L6', 'S8', 'L5', 'L24', 'L14',\n            'S17', 'L16', 'S3', 'L22', 'S19', 'L2', 'L4', 'L3', 'S10']\n    # curated databases\n    protein_databases = {\n                'L14': 'rpL14_JGI_MDM.filtered.faa',\n                'L15': 'rpL15_JGI_MDM.filtered.faa',\n                'L16': 'rpL16_JGI_MDM.filtered.faa',\n                'L18': 'rpL18_JGI_MDM.filtered.faa',\n                'L22': 'rpL22_JGI_MDM.filtered.faa',\n                'L24': 'rpL24_JGI_MDM.filtered.faa',\n                'L2': 'rpL2_JGI_MDM.filtered.faa',\n                'L3': 'rpL3_JGI_MDM.filtered.faa',\n                'L4': 'rpL4_JGI_MDM.filtered.faa',\n                'L5': 'rpL5_JGI_MDM.filtered.faa',\n                'L6': 'rpL6_JGI_MDM.filtered.faa',\n                'S10': 'rpS10_JGI_MDM.filtered.faa',\n                'S17': 'rpS17_JGI_MDM.filtered.faa',\n                'S19': 'rpS19_JGI_MDM.filtered.faa',\n                'S3': 'rpS3_JGI_MDM.filtered.faa',\n                'S8': 'rpS8_JGI_MDM.filtered.faa'}\n    protein_databases = {key: '%s/%s' % (databases, database) \\\n            for key, database in list(protein_databases.items())}\n    return proteins, protein_databases", "label": 1}
{"code": "def inspect_input(input:)\n      [\n        input.class.name,\n        input.helper_method,\n        # Access by method\n        input.string_value,\n        # Access by key:\n        input[:string_value],\n        input.key?(:string_value).to_s,\n        # ~~Access by legacy key~~ # not anymore\n        input[:string_value],\n        input.ensemble,\n        input.key?(:ensemble).to_s,\n      ]\n    end", "label": 4}
{"code": "public function formatEloquentCollection($collection)\n    {\n        if ($collection->isEmpty()) {\n            return $this->encode([]);\n        }\n\n        $model = $collection->first();\n        $key = Str::plural($model->getTable());\n\n        if (! $model::$snakeAttributes) {\n            $key = Str::camel($key);\n        }\n\n        return $this->encode([$key => $collection->toArray()]);\n    }", "label": 2}
{"code": "public function setDerivedInfo($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Talent\\V4beta1\\Job_DerivedInfo::class);\n        $this->derived_info = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def show_config():\n    \"\"\"\n    module intended to be imported in most AIKIF utils\n    to manage folder paths, user settings, etc.\n    Modify the parameters at the top of this file to suit\n    \"\"\"\n    res = ''\n    res += '\\n---------- Folder Locations ---------\\n'\n    for k,v in fldrs.items():\n        res += str(k) + ' = ' + str(v) + '\\n'\n    \n    res += '\\n---------- Logfiles ---------\\n'\n    for k,v in logs.items():\n        res += str(k) + ' = ' + str(v) + '\\n'\n        \n    res += '\\n---------- Parameters ---------\\n'\n    for k,v in params.items():\n        res += str(k) + ' = ' + str(v) + '\\n'\n    print(\"\\nusage from other programs - returns \" + fldr_root())\n    return res", "label": 1}
{"code": "def watch(self, keys, on_watch, filters=None, start_revision=None, return_previous=None):\n        \"\"\"\n        Watch one or more keys or key sets and invoke a callback.\n\n        Watch watches for events happening or that have happened. The entire event history\n        can be watched starting from the last compaction revision.\n\n        :param keys: Watch these keys / key sets.\n        :type keys: list of bytes or list of instance of :class:`txaioetcd.KeySet`\n\n        :param on_watch: The callback to invoke upon receiving\n            a watch event.\n        :type on_watch: callable\n\n        :param filters: Any filters to apply.\n\n        :param start_revision: start_revision is an optional\n            revision to watch from (inclusive). No start_revision is \"now\".\n        :type start_revision: int\n\n        :param return_previous: Flag to request returning previous values.\n\n        :returns: A deferred that just fires when watching has started successfully,\n            or which fires with an error in case the watching could not be started.\n        :rtype: twisted.internet.Deferred\n        \"\"\"\n        d = self._start_watching(keys, on_watch, filters, start_revision, return_previous)\n\n        #\n        #   ODD: Trying to use a parameter instead of *args errors out as soon as the\n        #        parameter is accessed.\n        #\n        def on_err(*args):\n            if args[0].type not in [CancelledError, ResponseFailed]:\n                self.log.warn('etcd watch terminated with \"{error}\"', error=args[0].type)\n                return args[0]\n\n        d.addErrback(on_err)\n        return d", "label": 1}
{"code": "func (sb *sandbox) populateLoadBalancers(ep *endpoint) {\n\t// This is an interface less endpoint. Nothing to do.\n\tif ep.Iface() == nil {\n\t\treturn\n\t}\n\n\tn := ep.getNetwork()\n\teIP := ep.Iface().Address()\n\n\tif n.ingress {\n\t\tif err := addRedirectRules(sb.Key(), eIP, ep.ingressPorts); err != nil {\n\t\t\tlogrus.Errorf(\"Failed to add redirect rules for ep %s (%.7s): %v\", ep.Name(), ep.ID(), err)\n\t\t}\n\t}\n}", "label": 5}
{"code": "public function DeleteCluster(\\Google\\Cloud\\Container\\V1\\DeleteClusterRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.container.v1.ClusterManager/DeleteCluster',\n        $argument,\n        ['\\Google\\Cloud\\Container\\V1\\Operation', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "public static function from($target)\n    {\n        if ($tags = static::explicitTags([$target])) {\n            return $tags;\n        }\n\n        return static::modelsFor([$target])->map(function ($model) {\n            return FormatModel::given($model);\n        })->all();\n    }", "label": 2}
{"code": "function ClassicReadable(stream, options) {\n\tReadable.call(this, options);\n\tclassicMixins.call(this, stream, options);\n\n\t// Readable streams already include a wrapping for Classic Streams\n\tthis.wrap(stream);\n}", "label": 3}
{"code": "public function setInput($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\TextToSpeech\\V1\\SynthesisInput::class);\n        $this->input = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private boolean hasNullifiedFK(FieldDescriptor[] fkFieldDescriptors, Object[] fkValues)\r\n    {\r\n        boolean result = true;\r\n        for (int i = 0; i < fkValues.length; i++)\r\n        {\r\n            if (!pb.serviceBrokerHelper().representsNull(fkFieldDescriptors[i], fkValues[i]))\r\n            {\r\n                result = false;\r\n                break;\r\n            }\r\n        }\r\n        return result;\r\n    }", "label": 0}
{"code": "function indexWidgets() {\n  const { widgets = {} } = getComponentsSettings();\n\n  return index({\n    file: 'widgets.js',\n    config: {\n      type: TYPE_WIDGETS,\n      config: widgets,\n    },\n    ...getIndexLogTranslations(TYPE_WIDGETS),\n  });\n}", "label": 3}
{"code": "def merge_data!(other, source: \"YAML front matter\")\n      merge_categories!(other)\n      Utils.deep_merge_hashes!(data, other)\n      merge_date!(source)\n      data\n    end", "label": 4}
{"code": "function() {\n      var behaviorEvents = _.result(this, 'events');\n      var viewEvents = this.view.events;\n\n      if (!viewEvents) {\n        if (!behaviorEvents) {\n          return;\n        } else {\n          viewEvents = {};\n        }\n      }\n\n      var namespacedEvents = this.__namespaceEvents(behaviorEvents);\n      var boundBehaviorEvents = this.__bindEventCallbacksToBehavior(namespacedEvents);\n\n      if (_.isFunction(viewEvents)) {\n        this.view.events = _.wrap(_.bind(viewEvents, this.view), function(viewEventFunction) {\n          return _.extend(boundBehaviorEvents, viewEventFunction());\n        });\n      } else if (_.isObject(viewEvents)) {\n        this.view.events = _.extend(boundBehaviorEvents, viewEvents);\n      }\n    }", "label": 3}
{"code": "function ArrayType(attrs, opts) {\n  Type.call(this);\n\n  if (!attrs.items) {\n    throw new Error(f('missing array items: %j', attrs));\n  }\n  this._items = createType(attrs.items, opts);\n}", "label": 3}
{"code": "public function sendPong($msgid)\n    {\n        $messageNode = new ProtocolNode('iq',\n            [\n                'to'   => Constants::WHATSAPP_SERVER,\n                'id'   => $msgid,\n                'type' => 'result',\n            ], null, '');\n\n        $this->sendNode($messageNode);\n        $this->eventManager()->fire('onSendPong',\n            [\n                $this->phoneNumber,\n                $msgid,\n            ]);\n    }", "label": 2}
{"code": "def dir_name(name)\n      name = name.dup\n      name.gsub!(\":\", VAGRANT_COLON) if Util::Platform.windows?\n      name.gsub!(\"/\", VAGRANT_SLASH)\n      name\n    end", "label": 4}
{"code": "def download(url, encoding='utf-8'):\n    \"\"\"Returns the text fetched via http GET from URL, read as `encoding`\"\"\"\n    import requests\n    response = requests.get(url)\n    response.encoding = encoding\n    return response.text", "label": 1}
{"code": "def run_active_command\n      require_valid_command\n      if alias? command_name_from_args\n        active_command.run(*(@aliases[command_name_from_args.to_s] + args_without_command_name))\n      else\n        active_command.run(*args_without_command_name)\n      end\n    end", "label": 4}
{"code": "func (l *LiteBackend) Import(ctx context.Context, items []backend.Item) error {\n\tfor i := range items {\n\t\tif items[i].Key == nil {\n\t\t\treturn trace.BadParameter(\"missing parameter key in item %v\", i)\n\t\t}\n\t}\n\terr := l.inTransaction(ctx, func(tx *sql.Tx) error {\n\t\tq, err := tx.PrepareContext(ctx,\n\t\t\t\"SELECT imported from meta LIMIT 1\")\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\tvar imported bool\n\t\trow := q.QueryRowContext(ctx)\n\t\tif err := row.Scan(&imported); err != nil {\n\t\t\tif err != sql.ErrNoRows {\n\t\t\t\treturn trace.Wrap(err)\n\t\t\t}\n\t\t}\n\t\tif imported {\n\t\t\treturn trace.AlreadyExists(\"database has been already imported\")\n\t\t}\n\n\t\tif err := l.putRangeInTransaction(ctx, tx, items, true); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\n\t\tstmt, err := tx.PrepareContext(ctx, \"INSERT INTO meta(version, imported) values(?, ?)\")\n\t\tif err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\n\t\tif _, err := stmt.ExecContext(ctx, schemaVersion, true); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "protected synchronized void releaseBroker(PersistenceBroker broker)\r\n    {\r\n        /*\r\n        arminw:\r\n        only close the broker instance if we get\r\n        it from the PBF, do nothing if we obtain it from\r\n        PBThreadMapping\r\n        */\r\n        if (broker != null && _needsClose)\r\n        {\r\n            _needsClose = false;\r\n            broker.close();\r\n        }\r\n    }", "label": 0}
{"code": "func NewApi(runningInKubernetes bool, metricSink *metricsink.MetricSink, historicalSource core.HistoricalSource, disableMetricExport bool) *Api {\n\tgkeMetrics := make(map[string]core.MetricDescriptor)\n\tgkeLabels := make(map[string]core.LabelDescriptor)\n\tfor _, val := range core.StandardMetrics {\n\t\tgkeMetrics[val.Name] = val.MetricDescriptor\n\t}\n\tfor _, val := range core.LabeledMetrics {\n\t\tgkeMetrics[val.Name] = val.MetricDescriptor\n\t}\n\tgkeMetrics[core.MetricCpuLimit.Name] = core.MetricCpuLimit.MetricDescriptor\n\tgkeMetrics[core.MetricMemoryLimit.Name] = core.MetricMemoryLimit.MetricDescriptor\n\n\tfor _, val := range core.CommonLabels() {\n\t\tgkeLabels[val.Key] = val\n\t}\n\tfor _, val := range core.ContainerLabels() {\n\t\tgkeLabels[val.Key] = val\n\t}\n\tfor _, val := range core.PodLabels() {\n\t\tgkeLabels[val.Key] = val\n\t}\n\n\treturn &Api{\n\t\trunningInKubernetes: runningInKubernetes,\n\t\tmetricSink:          metricSink,\n\t\thistoricalSource:    historicalSource,\n\t\tgkeMetrics:          gkeMetrics,\n\t\tgkeLabels:           gkeLabels,\n\t\tdisabled:            disableMetricExport,\n\t}\n}", "label": 5}
{"code": "public function setConditions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Monitoring\\V3\\AlertPolicy\\Condition::class);\n        $this->conditions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public static <T> T buildInstanceForMap(Class<T> clazz, Map<String, Object> values)\n      throws InstantiationException, IllegalAccessException, IntrospectionException,\n      IllegalArgumentException, InvocationTargetException {\n    return buildInstanceForMap(clazz, values, new MyDefaultReflectionDifferenceHandler());\n  }", "label": 0}
{"code": "func (p *Pod) UpdateManifest(m *schema.PodManifest, path string) error {\n\tif !p.mutable {\n\t\treturn ErrImmutable\n\t}\n\n\tmpath := common.PodManifestPath(path)\n\tmstat, err := os.Stat(mpath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttmpf, err := ioutil.TempFile(path, \"\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer func() {\n\t\ttmpf.Close()\n\t\tos.Remove(tmpf.Name())\n\t}()\n\n\tif err := tmpf.Chmod(mstat.Mode().Perm()); err != nil {\n\t\treturn err\n\t}\n\n\tif err := json.NewEncoder(tmpf).Encode(m); err != nil {\n\t\treturn err\n\t}\n\n\tif err := os.Rename(tmpf.Name(), mpath); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function addFilter(string $filterName, string $filterClassName) : void\n    {\n        $this->filters[$filterName] = $filterClassName;\n    }", "label": 2}
{"code": "protected static void appendHandler(LogRecordHandler parent, LogRecordHandler child){\r\n    RecordHandlerTree p = handlers.find(parent);\r\n    if(p != null){\r\n      p.addChild(child);\r\n    } else {\r\n      throw new IllegalArgumentException(\"No such parent handler: \" + parent);\r\n    }\r\n  }", "label": 0}
{"code": "function client(req, res) {\n  const compiler = webpack(config);\n  compiler.outputFileSystem = fsys;\n\n  compiler.run((err, stats) => {\n    const file = fsys.readFileSync(path.join(__dirname, 'dist', 'client.js'));\n\n    res.setHeader('Content-Length', file.length);\n    res.writeHead(200, { 'Content-Type': 'text/javascript' });\n\n    res.end(file);\n  });\n}", "label": 3}
{"code": "def restore_modified_times\n      @modified_times.each do |file, time|\n        next if Overcommit::Utils.broken_symlink?(file)\n        next unless File.exist?(file)\n        File.utime(time, time, file)\n      end\n    end", "label": 4}
{"code": "public static int ptb2Text(Reader ptbText, Writer w) throws IOException {\r\n    int numTokens = 0;\r\n    PTB2TextLexer lexer = new PTB2TextLexer(ptbText);\r\n    for (String token; (token = lexer.next()) != null; ) {\r\n      numTokens++;\r\n      w.write(token);\r\n    }\r\n    return numTokens;\r\n  }", "label": 0}
{"code": "def state_pop(self):\n        \"\"\"\n        Pop the state of all generators\n        \"\"\"\n        super(Composite,self).state_pop()\n        for gen in self.generators:\n            gen.state_pop()", "label": 1}
{"code": "def callback(*args, &block)\n      @plugin_options ||= nil\n      fail \"callback must be called within a guard block\" unless @plugin_options\n\n      block, events = if args.size > 1\n                        # block must be the first argument in that case, the\n                        # yielded block is ignored\n                        args\n                      else\n                        [block, args[0]]\n                      end\n      @plugin_options[:callbacks] << { events: events, listener: block }\n    end", "label": 4}
{"code": "def variant_matches_reference_sequence(variant, ref_seq_on_transcript, strand):\n    \"\"\"\n    Make sure that reference nucleotides we expect to see on the reference\n    transcript from a variant are the same ones we encounter.\n    \"\"\"\n    if strand == \"-\":\n        ref_seq_on_transcript = reverse_complement_dna(ref_seq_on_transcript)\n    return ref_seq_on_transcript == variant.ref", "label": 1}
{"code": "func (mi MetaInfo) Write(w io.Writer) error {\n\treturn bencode.NewEncoder(w).Encode(mi)\n}", "label": 5}
{"code": "public function createSchema(array $classes)\n    {\n        $createSchemaSql = $this->getCreateSchemaSql($classes);\n        $conn            = $this->em->getConnection();\n\n        foreach ($createSchemaSql as $sql) {\n            try {\n                $conn->executeQuery($sql);\n            } catch (Throwable $e) {\n                throw ToolsException::schemaToolFailure($sql, $e);\n            }\n        }\n    }", "label": 2}
{"code": "def mrai_to_raw(self, amount):\n        \"\"\"\n        Multiply an Mrai amount by the Mrai ratio.\n\n        :param amount: Amount in Mrai to convert to raw\n        :type amount: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.mrai_to_raw(amount=1)\n        1000000000000000000000000000000\n\n        \"\"\"\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('mrai_to_raw', payload)\n\n        return int(resp['amount'])", "label": 1}
{"code": "def directories(directories)\n      directories.each do |dir|\n        fail \"Directory #{dir.inspect} does not exist!\" unless Dir.exist?(dir)\n      end\n      Guard.state.session.watchdirs = directories\n    end", "label": 4}
{"code": "def github_fetch_tags\n      tags        = []\n      page_i      = 0\n      count_pages = calculate_pages(@client, \"tags\", {})\n\n      iterate_pages(@client, \"tags\") do |new_tags|\n        page_i += PER_PAGE_NUMBER\n        print_in_same_line(\"Fetching tags... #{page_i}/#{count_pages * PER_PAGE_NUMBER}\")\n        tags.concat(new_tags)\n      end\n      print_empty_line\n\n      if tags.count == 0\n        Helper.log.warn \"Warning: Can't find any tags in repo. \\\nMake sure, that you push tags to remote repo via 'git push --tags'\"\n      else\n        Helper.log.info \"Found #{tags.count} tags\"\n      end\n      # tags are a Sawyer::Resource. Convert to hash\n      tags.map { |resource| stringify_keys_deep(resource.to_hash) }\n    end", "label": 4}
{"code": "def succeeded(topic, event)\n      subscribers_for(topic).each{ |subscriber| subscriber.succeeded(event) }\n    end", "label": 4}
{"code": "function exists(filepath) {\n  const cached = existsCache.has(filepath);\n\n  // Only return positive to allow for generated files\n  if (cached) return true;\n\n  const filepathExists = fs.existsSync(filepath);\n\n  if (filepathExists) existsCache.add(filepath);\n\n  return filepathExists;\n}", "label": 3}
{"code": "public function updateBatch(array $entities, array $options = [])\n    {\n        $options += [\n            'allowOverwrite' => false\n        ];\n\n        $this->operation->checkOverwrite($entities, $options['allowOverwrite']);\n        foreach ($entities as $entity) {\n            $this->mutations[] = $this->operation->mutation('update', $entity, Entity::class);\n        }\n\n        return $this;\n    }", "label": 2}
{"code": "function parse_balanced(re_open, re_close, re_rest) {\n  result = match(re_rest);\n  while (look(re_open)) {\n    result += match(re_open);\n    result += parse_balanced(re_open, re_close, re_rest);\n    result += match(re_close);\n    result += match(re_rest);\n  }\n  return result;\n}", "label": 3}
{"code": "def comfy_paginate(collection)\n      return unless collection\n      if defined?(WillPaginate)\n        will_paginate collection\n      elsif defined?(Kaminari)\n        paginate collection, theme: \"comfy\"\n      end\n    end", "label": 4}
{"code": "func (c *Client) UpsertNodes(namespace string, servers []services.Server) error {\n\tif namespace == \"\" {\n\t\treturn trace.BadParameter(\"missing node namespace\")\n\t}\n\n\tbytes, err := services.GetServerMarshaler().MarshalServers(servers)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\targs := &upsertNodesReq{\n\t\tNamespace: namespace,\n\t\tNodes:     bytes,\n\t}\n\t_, err = c.PutJSON(c.Endpoint(\"namespaces\", namespace, \"nodes\"), args)\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "function ConsoleHandler(level, grouping, collapsed) {\n\tgrouping = typeof grouping !== 'undefined' ? grouping : true;\n\tcollapsed = typeof collapsed !== 'undefined' ? collapsed : false;\n\n\tHandler.call(this, level);\n\n\tthis._grouping = grouping;\n\tthis._groupMethod = collapsed ? 'groupCollapsed' : 'group';\n\tthis._openGroup = '';\n}", "label": 3}
{"code": "def ws_connect(message):\n    \"\"\"\n    Channels connection setup.\n    Register the current client on the related Group according to the language\n    \"\"\"\n    prefix, language = message['path'].strip('/').split('/')\n    gr = Group('knocker-{0}'.format(language))\n    gr.add(message.reply_channel)\n    message.channel_session['knocker'] = language\n    message.reply_channel.send({\"accept\": True})", "label": 1}
{"code": "public int compareTo(InternalFeature o) {\n\t\tif (null == o) {\n\t\t\treturn -1; // avoid NPE, put null objects at the end\n\t\t}\n\t\tif (null != styleDefinition && null != o.getStyleInfo()) {\n\t\t\tif (styleDefinition.getIndex() > o.getStyleInfo().getIndex()) {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tif (styleDefinition.getIndex() < o.getStyleInfo().getIndex()) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\t}", "label": 0}
{"code": "function getStatus (res) {\n\t\tlet status;\n\t\tconst statusCode = res.statusCode;\n\t\tif (statusCode) {\n\t\t\tstatus = Math.floor(statusCode / 100) * 100;\n\t\t}\n\t\tswitch (status) {\n\t\t\tcase 100:\n\t\t\tcase 200:\n\t\t\tcase 300:\n\t\t\t\treturn 'success';\n\t\t\tdefault:\n\t\t\t\treturn 'failure';\n\t\t}\n\t}", "label": 3}
{"code": "public static appfwprofile_denyurl_binding[] get(nitro_service service, String name) throws Exception{\n\t\tappfwprofile_denyurl_binding obj = new appfwprofile_denyurl_binding();\n\t\tobj.set_name(name);\n\t\tappfwprofile_denyurl_binding response[] = (appfwprofile_denyurl_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def type(assignment_string)\n      # Get location to use in case of error - this produces ruby filename and where call to 'type' occurred\n      # but strips off the rest of the internal \"where\" as it is not meaningful to user.\n      #\n      rb_location = caller[0]\n\n      begin\n        result = parser.parse_string(\"type #{assignment_string}\", nil)\n      rescue StandardError => e\n        rb_location = rb_location.gsub(/:in.*$/, '')\n        # Create a meaningful location for parse errors - show both what went wrong with the parsing\n        # and in which ruby file it was found.\n        raise ArgumentError, _(\"Parsing of 'type \\\"%{assignment_string}\\\"' failed with message: <%{message}>.\\n\" +\n          \"Called from <%{ruby_file_location}>\") % {\n            assignment_string: assignment_string,\n            message: e.message,\n            ruby_file_location: rb_location\n        }\n      end\n      unless result.body.kind_of?(Puppet::Pops::Model::TypeAlias)\n        rb_location = rb_location.gsub(/:in.*$/, '')\n        raise ArgumentError, _(\"Expected a type alias assignment on the form 'AliasType = T', got '%{assignment_string}'.\\n\"+\n        \"Called from <%{ruby_file_location}>\") % {\n          assignment_string: assignment_string,\n          ruby_file_location: rb_location\n        }\n      end\n      @local_types << result.body\n    end", "label": 4}
{"code": "private String addAndEncodeVariable(String originalValue, String newVariable,\n      String newVariableName, boolean encode) {\n    return addAndEncode(originalValue, newVariable, newVariableName, encode);\n  }", "label": 0}
{"code": "function getSubmissionStorage(cb) {\n      //If no stats are required, don't try and do the map-reduce operation.\n      if (options.notStats) {\n        return cb();\n      }\n\n      // NOTE: this function executes in MongoDB rather than Node.js\n      //Need a map-reduce operation to count the files, otherwise would have to load all submissions into memory which is bad.\n      var mapFileSizesFunction = function() {\n        var key = this.formId;\n\n        var formFields = this.formFields || [];\n\n        //Iterating over all form fields\n        for (var formFieldIdx = 0; formFieldIdx < formFields.length; formFieldIdx++) {\n          var formField = formFields[formFieldIdx];\n\n          var fieldValues = formField.fieldValues || [];\n\n          //Iterating over all of the field values\n          for (var fieldValueIdx = 0 ; fieldValueIdx < fieldValues.length ; fieldValueIdx++) {\n            var fieldValue = fieldValues[fieldValueIdx] || {};\n\n            //If the value has a file size associated with it, then emit that file size\n            if (fieldValue.fileSize) {\n              emit(key, fieldValue.fileSize); // eslint-disable-line no-undef\n            }\n          }\n        }\n      };\n\n      // NOTE: this function executes in MongoDB rather than Node.js\n      //Function to sum up all of the file sizes for each submission\n      var reduceFileSizesFunction = function(formId, fileSizes) {\n        var totalFileSizes = 0;\n\n        for (var fileSizeIdx = 0; fileSizeIdx < fileSizes.length ; fileSizeIdx++) {\n          totalFileSizes += fileSizes[fileSizeIdx];\n        }\n\n        return totalFileSizes;\n      };\n\n      logger.debug(\"getSubmissionStorage\", {options: options});\n\n      Promise.race([\n        // Don't wait longer than 30 seconds for mongodb mapReduce.\n        // Note that it should still complete, but if it's not back in\n        // 30 seconds, we continue without it.\n        new Promise(resolve => setTimeout(resolve, 30000)),\n\n        //Map-Reduce Operation to count the file sizes.\n        connections.databaseConnection.collection('formsubmissions').mapReduce(mapFileSizesFunction, reduceFileSizesFunction, {out : {inline: 1}, verbose:true})\n      ])\n\n        .then(out => {\n          fileSizesByForm = out && out.results ? out.results : [];\n          return cb();\n        })\n\n        .catch(err => {\n          //If there are no submissions, then the collection does not\n          //exist. No need to error out of the request.\n          if (err.message.indexOf(\"ns doesn't exist\") > -1) {\n            return cb();\n          } else {\n            return cb(err);\n          }\n        });\n    }", "label": 3}
{"code": "def restore\n      return unless File.exist?(Setting[:histfile])\n\n      File.readlines(Setting[:histfile]).reverse_each { |l| push(l.chomp) }\n    end", "label": 4}
{"code": "private void writeCompressedTexts(File dir, HashMap contents) throws IOException\r\n    {\r\n        String filename;\r\n\r\n        for (Iterator nameIt = contents.keySet().iterator(); nameIt.hasNext();)\r\n        {\r\n            filename = (String)nameIt.next();\r\n            writeCompressedText(new File(dir, filename), (byte[])contents.get(filename));\r\n        }\r\n    }", "label": 0}
{"code": "private function format( $items, $ascii_pre_colorized = false ) {\n\t\t$fields = $this->args['fields'];\n\n\t\tswitch ( $this->args['format'] ) {\n\t\t\tcase 'count':\n\t\t\t\tif ( ! is_array( $items ) ) {\n\t\t\t\t\t$items = iterator_to_array( $items );\n\t\t\t\t}\n\t\t\t\techo count( $items );\n\t\t\t\tbreak;\n\n\t\t\tcase 'ids':\n\t\t\t\tif ( ! is_array( $items ) ) {\n\t\t\t\t\t$items = iterator_to_array( $items );\n\t\t\t\t}\n\t\t\t\techo implode( ' ', $items );\n\t\t\t\tbreak;\n\n\t\t\tcase 'table':\n\t\t\t\tself::show_table( $items, $fields, $ascii_pre_colorized );\n\t\t\t\tbreak;\n\n\t\t\tcase 'csv':\n\t\t\t\t\\WP_CLI\\Utils\\write_csv( STDOUT, $items, $fields );\n\t\t\t\tbreak;\n\n\t\t\tcase 'json':\n\t\t\tcase 'yaml':\n\t\t\t\t$out = array();\n\t\t\t\tforeach ( $items as $item ) {\n\t\t\t\t\t$out[] = \\WP_CLI\\Utils\\pick_fields( $item, $fields );\n\t\t\t\t}\n\n\t\t\t\tif ( 'json' === $this->args['format'] ) {\n\t\t\t\t\tif ( defined( 'JSON_PARTIAL_OUTPUT_ON_ERROR' ) ) {\n\t\t\t\t\t\t// phpcs:ignore PHPCompatibility.Constants.NewConstants.json_partial_output_on_errorFound\n\t\t\t\t\t\techo json_encode( $out, JSON_PARTIAL_OUTPUT_ON_ERROR );\n\t\t\t\t\t} else {\n\t\t\t\t\t\techo json_encode( $out );\n\t\t\t\t\t}\n\t\t\t\t} elseif ( 'yaml' === $this->args['format'] ) {\n\t\t\t\t\techo Spyc::YAMLDump( $out, 2, 0 );\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\t\\WP_CLI::error( 'Invalid format: ' . $this->args['format'] );\n\t\t}\n\t}", "label": 2}
{"code": "protected function safeClose()\n    {\n        try {\n            if (isset($this->input) && $this->input) {\n                $this->close();\n            }\n        } catch (\\Exception $e) {\n            // Nothing here\n        }\n    }", "label": 2}
{"code": "private function subscriptionFactory($name, array $info = [])\n    {\n        return new Subscription(\n            $this->connection,\n            $this->projectId,\n            $name,\n            $this->name,\n            $this->encode,\n            $info\n        );\n    }", "label": 2}
{"code": "public static policydataset[] get(nitro_service service) throws Exception{\n\t\tpolicydataset obj = new policydataset();\n\t\tpolicydataset[] response = (policydataset[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def extract_directives(header)\n        processed_header = String.new(\"\")\n        directives = []\n\n        header.lines.each_with_index do |line, index|\n          if directive = line[DIRECTIVE_PATTERN, 1]\n            name, *args = Shellwords.shellwords(directive)\n            if respond_to?(\"process_#{name}_directive\", true)\n              directives << [index + 1, name, *args]\n              # Replace directive line with a clean break\n              line = \"\\n\"\n            end\n          end\n          processed_header << line\n        end\n\n        processed_header.chomp!\n        # Ensure header ends in a new line like before it was processed\n        processed_header << \"\\n\" if processed_header.length > 0 && header[-1] == \"\\n\"\n\n        return processed_header, directives\n      end", "label": 4}
{"code": "def hash_extractor(name, value)\n      value.split(',').reduce({}) do |set, tag|\n        k, v = tag.split(':')\n        if v.nil?\n          log_warn(\"Invalid hash value for #{name}: #{value}\")\n          return nil\n        end\n\n        set.merge(decode(k).downcase.to_sym => decode(v))\n      end\n    end", "label": 4}
{"code": "func (b *BoxLayout) Widgets() []Widget {\n\tw := make([]Widget, 0, len(b.cells))\n\tfor _, c := range b.cells {\n\t\tw = append(w, c.widget)\n\t}\n\treturn w\n}", "label": 5}
{"code": "def relationships\n      r = Relationships.new\n      r << Relationship.new(cache_definition, PIVOT_TABLE_CACHE_DEFINITION_R, \"../#{cache_definition.pn}\")\n      r\n    end", "label": 4}
{"code": "public static cmpaction[] get(nitro_service service, options option) throws Exception{\n\t\tcmpaction obj = new cmpaction();\n\t\tcmpaction[] response = (cmpaction[])obj.get_resources(service,option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (v VirtualMachine) RemoveDevice(ctx context.Context, keepFiles bool, device ...types.BaseVirtualDevice) error {\n\tfop := types.VirtualDeviceConfigSpecFileOperationDestroy\n\tif keepFiles {\n\t\tfop = \"\"\n\t}\n\treturn v.configureDevice(ctx, types.VirtualDeviceConfigSpecOperationRemove, fop, device...)\n}", "label": 5}
{"code": "def save_csv(self, fd):\n        \"\"\" Saves the case as a series of Comma-Separated Values.\n        \"\"\"\n        from pylon.io.excel import CSVWriter\n        CSVWriter(self).write(fd)", "label": 1}
{"code": "public function setUri($uri): self\n    {\n        $this->uri = $uri instanceof Uri ? $uri : new Uri($uri);\n\n        return $this;\n    }", "label": 2}
{"code": "function loadModal(loadModalParams, loadModalOptions) {\n      // Load Modal Props\n      var url = loadModalParams.url;\n      var content = loadModalParams.content;\n      var template = loadModalParams.template;\n      var templateUrl = loadModalParams.templateUrl;\n      var component = loadModalParams.component;\n      var componentUrl = loadModalParams.componentUrl;\n\n      // Component/Template Callbacks\n      function resolve(contentEl) {\n        if (contentEl) {\n          if (typeof contentEl === 'string') {\n            modalParams.content = contentEl;\n          } else if (contentEl.f7Component) {\n            contentEl.f7Component.$mount(function (componentEl) {\n              modalParams.el = componentEl;\n              app.root.append(componentEl);\n            });\n          } else {\n            modalParams.el = contentEl;\n          }\n          onModalLoaded();\n        }\n      }\n      function reject() {\n        router.allowPageChange = true;\n        return router;\n      }\n\n      if (content) {\n        resolve(content);\n      } else if (template || templateUrl) {\n        try {\n          router.modalTemplateLoader(template, templateUrl, loadModalOptions, resolve, reject);\n        } catch (err) {\n          router.allowPageChange = true;\n          throw err;\n        }\n      } else if (component || componentUrl) {\n        // Load from component (F7/Vue/React/...)\n        try {\n          router.modalComponentLoader(app.root[0], component, componentUrl, loadModalOptions, resolve, reject);\n        } catch (err) {\n          router.allowPageChange = true;\n          throw err;\n        }\n      } else if (url) {\n        // Load using XHR\n        if (router.xhr) {\n          router.xhr.abort();\n          router.xhr = false;\n        }\n        router.xhrRequest(url, loadModalOptions)\n          .then(function (modalContent) {\n            modalParams.content = modalContent;\n            onModalLoaded();\n          })\n          .catch(function () {\n            router.allowPageChange = true;\n          });\n      } else {\n        onModalLoaded();\n      }\n    }", "label": 3}
{"code": "def edit(new_content, new_embed = nil)\n      response = API::Channel.edit_message(@bot.token, @channel.id, @id, new_content, [], new_embed ? new_embed.to_hash : nil)\n      Message.new(JSON.parse(response), @bot)\n    end", "label": 4}
{"code": "function(database, field, options)\n  {\n    applyOptions( this, options, this.getDefaults( database, field, options ) );\n\n    this.database = database;\n    this.name = field;\n    this.options = options;\n    this.initialized = false;\n    this.property = this.property || (indexOf( database.fields, this.name ) !== false);\n    this.discriminated = !isEmpty( this.discriminators );\n\n    if ( this.discriminated )\n    {\n      if ( !Polymorphic )\n      {\n        throw 'Polymorphic feature is required to use the discriminated option.';\n      }\n\n      Class.props( this, Polymorphic );\n    }\n\n    this.setReferences( database, field, options );\n  }", "label": 3}
{"code": "def set_image(self, user, image_path):\n        \"\"\"Sets a custom image for the game. `image_path` should refer to\n        an image file on disk\"\"\"\n        _, ext = os.path.splitext(image_path)\n        shutil.copy(image_path, self._custom_image_path(user, ext))", "label": 1}
{"code": "public function setMessage($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\PubSub\\V1\\PubsubMessage::class);\n        $this->message = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "protected function getBasicProfile($token)\n    {\n        $url = 'https://api.linkedin.com/v2/me?projection=(id,firstName,lastName,profilePicture(displayImage~:playableStreams))';\n\n        $response = $this->getHttpClient()->get($url, [\n            'headers' => [\n                'Authorization' => 'Bearer '.$token,\n                'X-RestLi-Protocol-Version' => '2.0.0',\n            ],\n        ]);\n\n        return (array) json_decode($response->getBody(), true);\n    }", "label": 2}
{"code": "func GetExitStatus(err error) (int, error) {\n\tif err == nil {\n\t\treturn 0, nil\n\t}\n\tif exiterr, ok := err.(*exec.ExitError); ok {\n\t\t// the program has exited with an exit code != 0\n\t\tif status, ok := exiterr.Sys().(syscall.WaitStatus); ok {\n\t\t\treturn status.ExitStatus(), nil\n\t\t}\n\t}\n\treturn -1, err\n}", "label": 5}
{"code": "public function setExplicitAnnotation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\VideoIntelligence\\V1\\ExplicitContentAnnotation::class);\n        $this->explicit_annotation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def remove_numbers(text_string):\n    '''\n    Removes any digit value discovered within text_string and returns the new string as type str.\n\n    Keyword argument:\n\n    - text_string: string instance\n\n    Exceptions raised:\n\n    - InputError: occurs should a non-string argument be passed\n    '''\n    if text_string is None or text_string == \"\":\n        return \"\"\n    elif isinstance(text_string, str):\n        return \" \".join(re.sub(r'\\b[\\d.\\/,]+', \"\", text_string).split())\n    else:\n        raise InputError(\"string not passed as argument\")", "label": 1}
{"code": "def revealjs(basedir=None, title=None, subtitle=None, description=None,\n             github_user=None, github_repo=None):\n    '''Set up or update a reveals.js presentation with slides written in markdown.\n\n    Several reveal.js plugins will be set up, too.\n\n    More info:\n      Demo: https://theno.github.io/revealjs_template\n      http://lab.hakim.se/reveal-js/\n      https://github.com/hakimel/reveal.js\n      plugins:\n        https://github.com/hakimel/reveal.js/wiki/Plugins,-Tools-and-Hardware\n        https://github.com/rajgoel/reveal.js-plugins/\n        https://github.com/e-gor/Reveal.js-TOC-Progress\n        https://github.com/e-gor/Reveal.js-Title-Footer\n    '''\n    basedir = basedir or query_input('Base dir of the presentation?',\n                                     default='~/repos/my_presi')\n    revealjs_repo_name = 'reveal.js'\n    revealjs_dir = flo('{basedir}/{revealjs_repo_name}')\n\n    _lazy_dict['presi_title'] = title\n    _lazy_dict['presi_subtitle'] = subtitle\n    _lazy_dict['presi_description'] = description\n    _lazy_dict['github_user'] = github_user\n    _lazy_dict['github_repo'] = github_repo\n\n    question = flo(\"Base dir already contains a sub dir '{revealjs_repo_name}'.\"\n                   ' Reset (and re-download) reveal.js codebase?')\n    if not exists(revealjs_dir) or query_yes_no(question, default='no'):\n        run(flo('mkdir -p {basedir}'))\n        set_up_revealjs_codebase(basedir, revealjs_repo_name)\n        install_plugins(revealjs_dir)\n        apply_customizations(repo_dir=revealjs_dir)\n    if exists(revealjs_dir):\n        install_files_in_basedir(basedir, repo_dir=revealjs_dir)\n        init_git_repo(basedir)\n        create_github_remote_repo(basedir)\n        setup_npm(revealjs_dir)\n    else:\n        print('abort')", "label": 1}
{"code": "func (f *Fpdf) PointToUnitConvert(pt float64) (u float64) {\n\treturn pt / f.k\n}", "label": 5}
{"code": "public function setLatLongRect($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\LatLongRect::class);\n        $this->lat_long_rect = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function renderTemplateLoader(source) {\n  // Get the loader options object.\n  var options = getOptions(this)\n  // Get the template locals.\n  var locals = getLocals.call(this, options)\n  // Create info object of the filename of the resource being loaded.\n  var info = { filename: this.resourcePath }\n  // Get the engine options to be passed to the engine.\n  var engineOptions = getEngineOptions.call(this, options.engineOptions, info)\n  // Get the template renderer\n  var renderer = getRenderer.call(this, options.engine)\n  // Call options.init.\n  init.call(this, renderer.engine, info, options)\n  // Render the template\n  var result = render(renderer, source, locals, engineOptions)\n  // Assign the tempate to module.exports.\n  return 'module.exports = ' + JSON.stringify(result)\n}", "label": 3}
{"code": "def powerline():\n    '''Install and set up powerline for vim, bash, tmux, and i3.\n\n    It uses pip (python2) and the most up to date powerline version (trunk) from\n    the github repository.\n\n    More infos:\n      https://github.com/powerline/powerline\n      https://powerline.readthedocs.io/en/latest/installation.html\n      https://github.com/powerline/fonts\n      https://youtu.be/_D6RkmgShvU\n      http://www.tecmint.com/powerline-adds-powerful-statuslines-and-prompts-to-vim-and-bash/\n    '''\n    bindings_dir, scripts_dir = install_upgrade_powerline()\n    set_up_powerline_fonts()\n    set_up_powerline_daemon(scripts_dir)\n    powerline_for_vim(bindings_dir)\n    powerline_for_bash_or_powerline_shell(bindings_dir)\n    powerline_for_tmux(bindings_dir)\n    powerline_for_i3(bindings_dir)\n    print('\\nYou may have to reboot for make changes take effect')", "label": 1}
{"code": "public function v2Sign(ConnectionInterface $connection, $expires, $resource, $generation, array $options)\n    {\n        list($credentials, $options) = $this->getSigningCredentials($connection, $options);\n\n        $expires = $this->normalizeExpiration($expires);\n        $resource = $this->normalizeResource($resource);\n        $options = $this->normalizeOptions($options);\n        $headers = $this->normalizeHeaders($options['headers']);\n\n        // Make sure disallowed headers are not included.\n        $illegalHeaders = [\n            'x-goog-encryption-key',\n            'x-goog-encryption-key-sha256'\n        ];\n        if ($illegal = array_intersect_key(array_flip($illegalHeaders), $headers)) {\n            throw new \\InvalidArgumentException(sprintf(\n                '%s %s not allowed in Signed URL headers.',\n                implode(' and ', array_keys($illegal)),\n                count($illegal) === 1 ? 'is' : 'are'\n            ));\n        }\n\n        // Sort headers by name.\n        ksort($headers);\n\n        $toSign = [\n            $options['method'],\n            $options['contentMd5'],\n            $options['contentType'],\n            $expires,\n        ];\n\n        $signedHeaders = [];\n        foreach ($headers as $name => $value) {\n            $signedHeaders[] = $name .':'. $value;\n        }\n\n        // Push the headers onto the end of the signing string.\n        if ($signedHeaders) {\n            $toSign = array_merge($toSign, $signedHeaders);\n        }\n\n        $toSign[] = $resource;\n\n        $stringToSign = $this->createV2CanonicalRequest($toSign);\n\n        $signature = $credentials->signBlob($stringToSign, [\n            'forceOpenssl' => $options['forceOpenssl']\n        ]);\n\n        // Start with user-provided query params and add required parameters.\n        $params = $options['queryParams'];\n        $params['GoogleAccessId'] = $credentials->getClientName();\n        $params['Expires'] = $expires;\n        $params['Signature'] = $signature;\n\n        $params = $this->addCommonParams($generation, $params, $options);\n\n        $queryString = $this->buildQueryString($params);\n\n        $resource = $this->normalizeUriPath($options['cname'], $resource);\n        return 'https://' . $options['cname'] . $resource . '?' . $queryString;\n    }", "label": 2}
{"code": "function(req, res, fromMessage) {\n            var name = req.params.name;\n            var id   = this.toId(req.params.id);\n            if (typeof id === 'undefined' || id === '') {\n                return res.send(400, \"invalid id.\");\n            }\n            var doc   = {};\n            doc._id   = id;\n            doc._time = new Date().getTime();\n            var collection = new mongodb.Collection(this.db, name);\n            if (id === 'all' || id === 'clean') {\n                collection.drop(function (err) {\n                    if(err) {\n                        res.send(400, err);\n                    } else {\n                        var msg = {\n                            method: 'delete',\n                            id: doc._id,\n                            time: doc._time\n                        };\n                        rest.onSuccess(name, msg, fromMessage);\n                        res.send(doc);\n                    }\n                });\n            } else {\n                collection.remove({ \"_id\" : id }, { }, function(err, n){\n                        if(err) {\n                            res.send(400, err);\n                        } else {\n                            if (n==0) {\n                                res.send(404, 'Document not found!');\n                            }\n                            if (n > 0) {\n                                var msg = {\n                                    method: 'delete',\n                                    id: doc._id,\n                                    time: doc._time,\n                                    data: doc\n                                };\n                                rest.onSuccess(name, msg, fromMessage);\n                                res.send(doc);\n                            }\n                        }\n                    }\n                );\n            }\n        }", "label": 3}
{"code": "func (r *Linear) After() <-chan time.Time {\n\tif r.Duration() == 0 {\n\t\treturn r.closedChan\n\t}\n\treturn time.After(r.Duration())\n}", "label": 5}
{"code": "def process(self, pipeline):\n        \"\"\"Processing the whole pipeline definition.\"\"\"\n        output = []\n        for entry in pipeline:\n            key = list(entry.keys())[0]\n            # an environment block can be repeated\n            if key == \"env\":\n                self.data.env_list[0].update(entry[key])\n                self.logger.debug(\"Updating environment at level 0 with %s\",\n                                  self.data.env_list[0])\n                continue\n\n            # after validation it can't be anything else but a stage\n            # and the title is inside the round brackets:\n            stage = Stage(self, re.match(r\"stage\\((?P<title>.*)\\)\", key).group(\"title\"))\n            result = stage.process(entry[key])\n            output += result['output']\n            if not result['success']:\n                return {'success': False, 'output': output}\n\n        # logging the output of the cleanup shell when registered\n        for line in self.cleanup():\n            output.append(line)\n            self.logger.info(\" | %s\", line)\n\n        self.event.succeeded()\n        return {'success': True, 'output': output}", "label": 1}
{"code": "public function setSessions($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Spanner\\V1\\Session::class);\n        $this->sessions = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "function MultiLine( type , fold , applicable , options ) {\n\tthis.type = type ;\n\tthis.fold = !! fold ;\n\tthis.applicable = !! applicable ;\n\tthis.options = options ;\n\tthis.lines = [] ;\n}", "label": 3}
{"code": "public function setMapValue($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1beta1\\MapValue::class);\n        $this->writeOneof(6, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "public void addForeignKeyField(String newField)\r\n    {\r\n        if (m_ForeignKeyFields == null)\r\n        {\r\n            m_ForeignKeyFields = new Vector();\r\n        }\r\n        m_ForeignKeyFields.add(newField);\r\n    }", "label": 0}
{"code": "func (cl *Client) Torrents() []*Torrent {\n\tcl.lock()\n\tdefer cl.unlock()\n\treturn cl.torrentsAsSlice()\n}", "label": 5}
{"code": "def process_rescue(exp, _parent)\n      increase_statement_count_by(exp.children.first)\n      decrease_statement_count\n      process(exp)\n    end", "label": 4}
{"code": "public Object getRealValue()\r\n    {\r\n        if(valueRealSubject != null)\r\n        {\r\n            return valueRealSubject;\r\n        }\r\n        else\r\n        {\r\n            TransactionExt tx = getTransaction();\r\n\r\n            if((tx != null) && tx.isOpen())\r\n            {\r\n                prepareValueRealSubject(tx.getBroker());\r\n            }\r\n            else\r\n            {\r\n                if(getPBKey() != null)\r\n                {\r\n                    PBCapsule capsule = new PBCapsule(getPBKey(), null);\r\n\r\n                    try\r\n                    {\r\n                        prepareValueRealSubject(capsule.getBroker());\r\n                    }\r\n                    finally\r\n                    {\r\n                        capsule.destroy();\r\n                    }\r\n                }\r\n                else\r\n                {\r\n                    getLog().warn(\"No tx, no PBKey - can't materialise value with Identity \" + getKeyOid());\r\n                }\r\n            }\r\n        }\r\n        return valueRealSubject;\r\n    }", "label": 0}
{"code": "def main():\n    \"\"\"Execute main processes.\"\"\"\n    try:\n        pkg_version = Update()\n        if pkg_version.updatable():\n            pkg_version.show_message()\n        metadata = control.retreive_metadata()\n        parser = parse_options(metadata)\n        argvs = sys.argv\n        if len(argvs) <= 1:\n            parser.print_help()\n            sys.exit(1)\n        args = parser.parse_args()\n        control.print_licences(args, metadata)\n        control.check_repository_existence(args)\n        control.check_package_existence(args)\n        control.generate_package(args)\n    except (RuntimeError, BackendFailure, Conflict) as exc:\n        sys.stderr.write('{0}\\n'.format(exc))\n        sys.exit(1)", "label": 1}
{"code": "def TeArraySizeCheck(self):\n    \"\"\"\n    Checks that Te and q0 array sizes are compatible\n    For finite difference solution.\n    \"\"\"\n    # Only if they are both defined and are arrays\n    # Both being arrays is a possible bug in this check routine that I have \n    # intentionally introduced\n    if type(self.Te) == np.ndarray and type(self.qs) == np.ndarray:\n      # Doesn't touch non-arrays or 1D arrays\n      if type(self.Te) is np.ndarray:\n        if (np.array(self.Te.shape) != np.array(self.qs.shape)).any():\n          sys.exit(\"q0 and Te arrays have incompatible shapes. Exiting.\")\n      else:\n        if self.Debug: print(\"Te and qs array sizes pass consistency check\")", "label": 1}
{"code": "function liveAttrsUpdate(newVal) {\n\t\tvar newAttrs = live.getAttributeParts(newVal),\n\t\t\tname;\n\t\tfor (name in newAttrs) {\n\t\t\tvar newValue = newAttrs[name],\n\t\t\t\t// `oldAttrs` was set on the last run of setAttrs in this context\n\t\t\t\t//  (for this element and compute)\n\t\t\t\toldValue = oldAttrs[name];\n\t\t\t// Only fire a callback\n\t\t\t//  if the value of the attribute has changed\n\t\t\tif (newValue !== oldValue) {\n\t\t\t\t// set on DOM attributes (dispatches an \"attributes\" event as well)\n\t\t\t\tdomMutateNode.setAttribute.call(el, name, newValue);\n\t\t\t\t// get registered callback for attribute name and fire\n\t\t\t\tvar callback = viewCallbacks.attr(name);\n\t\t\t\tif (callback) {\n\t\t\t\t\tcallback(el, {\n\t\t\t\t\t\tattributeName: name,\n\t\t\t\t\t\tscope: scope,\n\t\t\t\t\t\toptions: options\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t\t// remove key found in new attrs from old attrs\n\t\t\tdelete oldAttrs[name];\n\t\t}\n\t\t// any attrs left at this point are not set on the element now,\n\t\t// so remove them.\n\t\tfor (name in oldAttrs) {\n\t\t\tdomMutateNode.removeAttribute.call(el, name);\n\t\t}\n\t\toldAttrs = newAttrs;\n\t}", "label": 3}
{"code": "def _subscribe_resp(self, data):\n        \"\"\" Handle a subscribe response.\n\n        :param data: Payload.\n        :returns: State (ON/OFF)\n        \"\"\"\n        if _is_subscribe_response(data):\n            status = bytes([data[23]])\n            _LOGGER.debug(\"Successfully subscribed to %s, state: %s\",\n                          self.host, ord(status))\n            return status", "label": 1}
{"code": "public static nd6ravariables_binding get(nitro_service service, Long vlan) throws Exception{\n\t\tnd6ravariables_binding obj = new nd6ravariables_binding();\n\t\tobj.set_vlan(vlan);\n\t\tnd6ravariables_binding response = (nd6ravariables_binding) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function (context) {\n        var parts = context.parts,\n            startPos = context.startPos,\n            endPos = parts.length - 1,\n            array = this.end,\n            len = array.length,\n            idx;\n        for (idx = 0; idx < len; ++idx) {\n            if (-1 < endPos && this._matchName(array[idx], parts[endPos])) {\n                if (endPos-- < startPos) {\n                    return _GPF_PATHMATCH_KO;\n                }\n            } else {\n                return _GPF_PATHMATCH_KO;\n            }\n        }\n        return _GPF_PATHMATCH_UNKNOWN;\n    }", "label": 3}
{"code": "func (o *OIDCConnectorV2) MapClaims(claims jose.Claims) []string {\n\tvar roles []string\n\tfor _, mapping := range o.Spec.ClaimsToRoles {\n\t\tfor claimName := range claims {\n\t\t\tif claimName != mapping.Claim {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tvar claimValues []string\n\t\t\tclaimValue, ok, _ := claims.StringClaim(claimName)\n\t\t\tif ok {\n\t\t\t\tclaimValues = []string{claimValue}\n\t\t\t} else {\n\t\t\t\tclaimValues, _, _ = claims.StringsClaim(claimName)\n\t\t\t}\n\t\tclaimLoop:\n\t\t\tfor _, claimValue := range claimValues {\n\t\t\t\tfor _, role := range mapping.Roles {\n\t\t\t\t\toutRole, err := utils.ReplaceRegexp(mapping.Value, role, claimValue)\n\t\t\t\t\tswitch {\n\t\t\t\t\tcase err != nil:\n\t\t\t\t\t\tif trace.IsNotFound(err) {\n\t\t\t\t\t\t\tlog.Debugf(\"Failed to match expression %v, replace with: %v input: %v, err: %v\", mapping.Value, role, claimValue, err)\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// this claim value clearly did not match, move on to another\n\t\t\t\t\t\tcontinue claimLoop\n\t\t\t\t\t\t// skip empty replacement or empty role\n\t\t\t\t\tcase outRole == \"\":\n\t\t\t\t\tcase outRole != \"\":\n\t\t\t\t\t\troles = append(roles, outRole)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn utils.Deduplicate(roles)\n}", "label": 5}
{"code": "protected function createTransaction(array $options = null, $callable = null)\n    {\n        $transaction = new MultiExecTransaction($this, $options);\n\n        if (isset($callable)) {\n            return $transaction->execute($callable);\n        }\n\n        return $transaction;\n    }", "label": 2}
{"code": "private function updateUserByOAuthUserResponse(UserInterface $user, UserResponseInterface $response): SyliusUserInterface\n    {\n        /** @var SyliusUserInterface $user */\n        Assert::isInstanceOf($user, SyliusUserInterface::class);\n\n        /** @var UserOAuthInterface $oauth */\n        $oauth = $this->oauthFactory->createNew();\n        $oauth->setIdentifier($response->getUsername());\n        $oauth->setProvider($response->getResourceOwner()->getName());\n        $oauth->setAccessToken($response->getAccessToken());\n        $oauth->setRefreshToken($response->getRefreshToken());\n\n        $user->addOAuthAccount($oauth);\n\n        $this->userManager->persist($user);\n        $this->userManager->flush();\n\n        return $user;\n    }", "label": 2}
{"code": "public Long getOldestTaskCreatedTime(){\n\t    Timer.Context ctx = getOldestTaskTimeTimer.time();\n\t    try {\n    \t    long oldest = Long.MAX_VALUE;\n    \t    \n    \t    /*\n    \t     * I am asking this question first, because if I ask it after I could\n    \t     * miss the oldest time if the oldest is polled and worked on\n    \t     */\n    \t    Long oldestQueueTime = this.taskQueue.getOldestQueueTime();\n    \t    if(oldestQueueTime != null)\n    \t        oldest = oldestQueueTime;\n    \t    \n    \t    //there is a tiny race condition here... but we just want to make our best attempt\n    \t    long inProgressOldestTime = tasksInProgressTracker.getOldestTime();\n    \t    \n    \t    if(inProgressOldestTime < oldest)\n    \t        oldest = inProgressOldestTime;\n    \t    \n    \t    return oldest;\n\t    } finally {\n\t        ctx.stop();\n\t    }\n\t}", "label": 0}
{"code": "function(index)\n  {\n    var key = this.keys[ index ];\n    var lastValue = AP.pop.apply( this.values );\n    var lastKey = AP.pop.apply( this.keys );\n\n    if ( index < this.values.length )\n    {\n      this.values[ index ] = lastValue;\n      this.keys[ index ] = lastKey;\n      this.indices[ lastKey ] = index;\n    }\n\n    delete this.indices[ key ];\n\n    return this;\n  }", "label": 3}
{"code": "private function purgeOrphanedToCreateItems(array &$data)\n    {\n        foreach ($data['toCreate'] as $key => $timestamp) {\n            $time = $this->time();\n\n            if ($timestamp + self::DURATION_TWENTY_MINUTES < $this->time()) {\n                unset($data['toCreate'][$key]);\n            }\n        }\n    }", "label": 2}
{"code": "public void insert(Platform platform, Database model, int batchSize) throws SQLException\r\n    {\r\n        if (batchSize <= 1)\r\n        {\r\n            for (Iterator it = _beans.iterator(); it.hasNext();)\r\n            {\r\n                platform.insert(model, (DynaBean)it.next());\r\n            }\r\n        }\r\n        else\r\n        {\r\n            for (int startIdx = 0; startIdx < _beans.size(); startIdx += batchSize)\r\n            {\r\n                platform.insert(model, _beans.subList(startIdx, startIdx + batchSize));\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public function setSource($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\SecurityCenter\\V1\\Source::class);\n        $this->source = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (r *ActionResponse) AddAction(action *bees.Action) {\n\tr.actions = append(r.actions, action)\n\tr.Actions = append(r.Actions, prepareActionResponse(r.Context, action))\n}", "label": 5}
{"code": "def to_filename(data,\n                mask=DEFAULT_PAPERS_FILENAME_MASK,\n                extra_formatters=None):\n    \"\"\"\n    Convert a bibtex entry to a formatted filename according to a given mask.\n\n    .. note ::\n\n        Available formatters out of the box are:\n            - ``journal``\n            - ``title``\n            - ``year``\n            - ``first`` for the first author\n            - ``last`` for the last author\n            - ``authors`` for the list of authors\n            - ``arxiv_version`` (discarded if no arXiv version in the BibTeX)\n\n        Filename is slugified after applying the masks.\n\n    :param data: A ``bibtexparser.BibDatabase`` object representing a \\\n            BibTeX entry, as the one from ``bibtexparser`` output.\n    :param mask: A Python format string.\n    :param extra_formatters: A dict of format string (in the mask) and \\\n            associated lambdas to perform the formatting.\n\n    :returns: A formatted filename.\n    \"\"\"\n    # Handle default argument\n    if extra_formatters is None:\n        extra_formatters = {}\n\n    entry = data.entries[0]\n    authors = re.split(' and ', entry['author'])\n\n    formatters = {\n        \"journal\": \"\",\n        \"title\": \"\",\n        \"year\": \"\",\n        \"first\": \"\",\n        \"last\": \"\",\n        \"authors\": \"\",\n        \"arxiv_version\": \"\"\n    }\n\n    formatters[\"journal\"] = entry.get(\"journal\", \"\")\n    formatters[\"title\"] = entry.get(\"title\", \"\")\n    formatters[\"year\"] = entry.get(\"year\", \"\")\n\n    formatters[\"first\"] = authors[0].split(',')[0].strip()\n    formatters[\"last\"] = authors[-1].split(',')[0].strip()\n    formatters[\"authors\"] = \", \".join([i.split(',')[0].strip()\n                                       for i in authors])\n\n    for extra_formatter in extra_formatters:\n        formatters[extra_formatter] = extra_formatters[extra_formatter](entry)\n\n    arxiv_version = \"\"\n    if \"eprint\" in entry:\n        arxiv_version = '-' + entry['eprint'][entry['eprint'].rfind('v'):]\n    formatters[\"arxiv_version\"] = arxiv_version\n\n    return tools.slugify(mask.format(**formatters))", "label": 1}
{"code": "public static base_responses enable(nitro_service client, String trapname[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (trapname != null && trapname.length > 0) {\n\t\t\tsnmpalarm enableresources[] = new snmpalarm[trapname.length];\n\t\t\tfor (int i=0;i<trapname.length;i++){\n\t\t\t\tenableresources[i] = new snmpalarm();\n\t\t\t\tenableresources[i].trapname = trapname[i];\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, enableresources,\"enable\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "public static nsip6[] get(nitro_service service) throws Exception{\n\t\tnsip6 obj = new nsip6();\n\t\tnsip6[] response = (nsip6[])obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "private void ensureNoTableInfoIfNoRepositoryInfo(ClassDescriptorDef classDef, String checkLevel)\r\n    {\r\n        if (!classDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_GENERATE_REPOSITORY_INFO, true))\r\n        {\r\n            classDef.setProperty(PropertyHelper.OJB_PROPERTY_GENERATE_TABLE_INFO, \"false\");\r\n        }\r\n    }", "label": 0}
{"code": "func (s *MockStore) WatchTree(prefix string, stopCh <-chan struct{}) (<-chan []*store.KVPair, error) {\n\treturn nil, ErrNotImplemented\n}", "label": 5}
{"code": "public function setUsage($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\ContactInfoUsage::class);\n        $this->usage = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def parse_ggKbase_tables(tables, id_type):\n    \"\"\"\n    convert ggKbase genome info tables to dictionary\n    \"\"\"\n    g2info = {}\n    for table in tables:\n        for line in open(table):\n            line = line.strip().split('\\t')\n            if line[0].startswith('name'):\n                header = line\n                header[4] = 'genome size (bp)'\n                header[12] = '#SCGs'\n                header[13] = '#SCG duplicates'\n                continue\n            name, code, info = line[0], line[1], line\n            info = [to_int(i) for i in info]\n            if id_type is False: # try to use name and code ID\n                if 'UNK' in code or 'unknown' in code:\n                    code = name\n                if (name != code) and (name and code in g2info):\n                    print('# duplicate name or code in table(s)', file=sys.stderr)\n                    print('# %s and/or %s' % (name, code), file=sys.stderr)\n                    exit()\n                if name not in g2info:\n                    g2info[name] = {item:stat for item, stat in zip(header, info)}\n                if code not in g2info:\n                    g2info[code] = {item:stat for item, stat in zip(header, info)}\n            else:\n                if id_type == 'name':\n                    ID = name\n                elif id_type == 'code':\n                    ID = code\n                else:\n                    print('# specify name or code column using -id', file=sys.stderr)\n                    exit()\n                ID = ID.replace(' ', '')\n                g2info[ID] = {item:stat for item, stat in zip(header, info)}\n                if g2info[ID]['genome size (bp)'] == '':\n                    g2info[ID]['genome size (bp)'] = 0\n    return g2info", "label": 1}
{"code": "func (l VirtualDeviceList) ConnectSerialPort(device *types.VirtualSerialPort, uri string, client bool, proxyuri string) *types.VirtualSerialPort {\n\tif strings.HasPrefix(uri, \"[\") {\n\t\tdevice.Backing = &types.VirtualSerialPortFileBackingInfo{\n\t\t\tVirtualDeviceFileBackingInfo: types.VirtualDeviceFileBackingInfo{\n\t\t\t\tFileName: uri,\n\t\t\t},\n\t\t}\n\n\t\treturn device\n\t}\n\n\tdirection := types.VirtualDeviceURIBackingOptionDirectionServer\n\tif client {\n\t\tdirection = types.VirtualDeviceURIBackingOptionDirectionClient\n\t}\n\n\tdevice.Backing = &types.VirtualSerialPortURIBackingInfo{\n\t\tVirtualDeviceURIBackingInfo: types.VirtualDeviceURIBackingInfo{\n\t\t\tDirection:  string(direction),\n\t\t\tServiceURI: uri,\n\t\t\tProxyURI:   proxyuri,\n\t\t},\n\t}\n\n\treturn device\n}", "label": 5}
{"code": "func UTC(t *time.Time) {\n\tif t == nil {\n\t\treturn\n\t}\n\n\tif t.IsZero() {\n\t\t// to fix issue with timezones for tests\n\t\t*t = time.Time{}\n\t\treturn\n\t}\n\t*t = t.UTC()\n}", "label": 5}
{"code": "public static void outputString(final HttpServletResponse response, final Object obj) {\n        try {\n            response.setContentType(\"text/javascript\");\n            response.setCharacterEncoding(\"utf-8\");\n            disableCache(response);\n            response.getWriter().write(obj.toString());\n            response.getWriter().flush();\n            response.getWriter().close();\n        } catch (IOException e) {\n        }\n    }", "label": 0}
{"code": "def entry(env)\n      ttl = (conf = get_conf(env.name)) ? conf.environment_timeout : Puppet.settings.value(:environment_timeout)\n      case ttl\n      when 0\n        NotCachedEntry.new(env)     # Entry that is always expired (avoids syscall to get time)\n      when Float::INFINITY\n        Entry.new(env)              # Entry that never expires (avoids syscall to get time)\n      else\n        TTLEntry.new(env, ttl)\n      end\n    end", "label": 4}
{"code": "public function setAlertPolicies($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Monitoring\\V3\\AlertPolicy::class);\n        $this->alert_policies = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public int decreaseKey(E o) {\r\n    HeapEntry<E> entry = getEntry(o);\r\n    if (o != entry.object) {\r\n      if (cmp.compare(o, entry.object) < 0) {\r\n        entry.object = o;\r\n      }\r\n    }\r\n    return heapifyUp(entry);\r\n  }", "label": 0}
{"code": "function _gpfFunctionDescribe (functionToDescribe) {\n    var result = {};\n    _gpfFunctionDescribeName(functionToDescribe, result);\n    _gpfFunctionDescribeSource(functionToDescribe, result);\n    return result;\n}", "label": 3}
{"code": "function (batch, response) {\n                var data = response.data;\n                for (var i = 0, requestId; i < batch.length; i++) {\n                    requestId = this._getRequestId(batch[i].method, batch[i].params);\n                    this._resolvePromise(this._deferreds[requestId], data[i]);\n                    delete this._deferreds[requestId];\n                }\n            }", "label": 3}
{"code": "func PgForeignServerBySrvname(db XODB, srvname pgtypes.Name) (*PgForeignServer, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, srvname, srvowner, srvfdw, srvtype, srvversion, srvacl, srvoptions ` +\n\t\t`FROM pg_catalog.pg_foreign_server ` +\n\t\t`WHERE srvname = $1`\n\n\t// run query\n\tXOLog(sqlstr, srvname)\n\tpfs := PgForeignServer{}\n\n\terr = db.QueryRow(sqlstr, srvname).Scan(&pfs.Tableoid, &pfs.Cmax, &pfs.Xmax, &pfs.Cmin, &pfs.Xmin, &pfs.Oid, &pfs.Ctid, &pfs.Srvname, &pfs.Srvowner, &pfs.Srvfdw, &pfs.Srvtype, &pfs.Srvversion, &pfs.Srvacl, &pfs.Srvoptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pfs, nil\n}", "label": 5}
{"code": "@Override\n    protected void denyImportDeclaration(ImportDeclaration importDeclaration) {\n        LOG.debug(\"CXFImporter destroy a proxy for \" + importDeclaration);\n        ServiceRegistration serviceRegistration = map.get(importDeclaration);\n        serviceRegistration.unregister();\n\n        // set the importDeclaration has unhandled\n        super.unhandleImportDeclaration(importDeclaration);\n\n        map.remove(importDeclaration);\n    }", "label": 0}
{"code": "public double Function1D(double x) {\n        double frequency = initFrequency;\n        double amplitude = initAmplitude;\n        double sum = 0;\n\n        // octaves\n        for (int i = 0; i < octaves; i++) {\n            sum += SmoothedNoise(x * frequency) * amplitude;\n\n            frequency *= 2;\n            amplitude *= persistence;\n        }\n        return sum;\n    }", "label": 0}
{"code": "function _gpfJsonStringifyPolyfill (value, replacer, space) {\n    return _gpfJsonStringifyMapping[typeof value](value, _gpfJsonStringifyCheckReplacer(replacer),\n        _gpfJsonStringifyCheckSpaceValue(space));\n}", "label": 3}
{"code": "function(win, elems) {\n\t\t\t\tvar i,\n\t\t\t\t\tmode = svgCanvas.getMode();\n\t\t\t\tif (mode === 'select') {\n\t\t\t\t\tsetSelectMode();\n\t\t\t\t}\n\n\t\t\t\tfor (i = 0; i < elems.length; ++i) {\n\t\t\t\t\tvar elem = elems[i];\n\n\t\t\t\t\t// if the element changed was the svg, then it could be a resolution change\n\t\t\t\t\tif (elem && elem.tagName === 'svg') {\n\t\t\t\t\t\tpopulateLayers();\n\t\t\t\t\t\tupdateCanvas();\n\t\t\t\t\t}\n\t\t\t\t\t// Update selectedElement if element is no longer part of the image.\n\t\t\t\t\t// This occurs for the text elements in Firefox\n\t\t\t\t\telse if (elem && selectedElement && selectedElement.parentNode == null) {\n//\t\t\t\t\t\t|| elem && elem.tagName == \"path\" && !multiselected) { // This was added in r1430, but not sure why\n\t\t\t\t\t\tselectedElement = elem;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tEditor.showSaveWarning = true;\n\n\t\t\t\t// we update the contextual panel with potentially new\n\t\t\t\t// positional/sizing information (we DON'T want to update the\n\t\t\t\t// toolbar here as that creates an infinite loop)\n\t\t\t\t// also this updates the history buttons\n\n\t\t\t\t// we tell it to skip focusing the text control if the\n\t\t\t\t// text element was previously in focus\n\t\t\t\tupdateContextPanel();\n\n\t\t\t\t// In the event a gradient was flipped:\n\t\t\t\tif (selectedElement && mode === 'select') {\n\t\t\t\t\tpaintBox.fill.update();\n\t\t\t\t\tpaintBox.stroke.update();\n\t\t\t\t}\n\n\t\t\t\tsvgCanvas.runExtensions('elementChanged', {\n\t\t\t\t\telems: elems\n\t\t\t\t});\n\t\t\t}", "label": 3}
{"code": "public static base_response delete(nitro_service client, String prefix) throws Exception {\n\t\tnsxmlnamespace deleteresource = new nsxmlnamespace();\n\t\tdeleteresource.prefix = prefix;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "async def version(self, tp, params, version=None, elem=None):\n        \"\"\"\n        Symmetric version management\n\n        :param tp:\n        :param params:\n        :param version:\n        :return:\n        \"\"\"\n        if self.writing:\n            return await self.set_version(tp, params, version, elem)\n        else:\n            return await self.get_version(tp, params)", "label": 1}
{"code": "func (dct *DjangoContentType) Save(db XODB) error {\n\tif dct.Exists() {\n\t\treturn dct.Update(db)\n\t}\n\n\treturn dct.Insert(db)\n}", "label": 5}
{"code": "public static appfwpolicy_stats[] get(nitro_service service) throws Exception{\n\t\tappfwpolicy_stats obj = new appfwpolicy_stats();\n\t\tappfwpolicy_stats[] response = (appfwpolicy_stats[])obj.stat_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function setCreateCluster($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\ClusterOperation::class);\n        $this->create_cluster = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def cp(self, local_path, target_path, acl='public-read',\n           del_after_upload=False, overwrite=True, invalidate=False):\n        \"\"\"\n        Copy a file or folder from local to s3.\n\n        Parameters\n        ----------\n\n        local_path : string\n            Path to file or folder. Or if you want to copy only the contents of folder, add /* at the end of folder name\n\n        target_path : string\n            Target path on S3 bucket.\n\n        acl : string, optional\n            File permissions on S3. Default is public-read\n\n            options:\n                - private: Owner gets FULL_CONTROL. No one else has any access rights.\n                - public-read: Owners gets FULL_CONTROL and the anonymous principal is granted READ access.\n                - public-read-write: Owner gets FULL_CONTROL and the anonymous principal is granted READ and WRITE access.\n                - authenticated-read: Owner gets FULL_CONTROL and any principal authenticated as a registered Amazon S3 user is granted READ access\n\n\n        del_after_upload : boolean, optional\n            delete the local file after uploading. This is effectively like moving the file.\n            You can use s3utils.mv instead of s3utils.cp to move files from local to S3.\n            It basically sets this flag to True.\n            default = False\n\n        overwrite : boolean, optional\n            overwrites files on S3 if set to True. Default is True\n\n        invalidate : boolean, optional\n            invalidates the CDN (a.k.a Distribution) cache if the file already exists on S3\n            default = False\n            Note that invalidation might take up to 15 minutes to take place. It is easier and faster to use cache buster\n            to grab lastest version of your file on CDN than invalidation.\n\n        **Returns**\n\n        Nothing on success but it will return what went wrong if something fails.\n\n        Examples\n        --------\n            >>> s3utils.cp(\"path/to/folder\",\"/test/\")\n            copying /path/to/myfolder/test2.txt to test/myfolder/test2.txt\n            copying /path/to/myfolder/test.txt to test/myfolder/test.txt\n            copying /path/to/myfolder/hoho/photo.JPG to test/myfolder/hoho/photo.JPG\n            copying /path/to/myfolder/hoho/haha/ff to test/myfolder/hoho/haha/ff\n\n            >>> # When overwrite is set to False, it returns the file(s) that were already existing on s3 and were not overwritten.\n            >>> s3utils.cp(\"/tmp/test3.txt\", \"test3.txt\", overwrite=False)\n            ERROR:root:test3.txt already exist. Not overwriting.\n            >>> {'existing_files': {'test3.txt'}}\n\n            >>> # To overwrite the files on S3 and invalidate the CDN (cloudfront) cache so the new file goes on CDN:\n            >>> s3utils.cp(\"path/to/folder\",\"/test/\", invalidate=True)\n            copying /path/to/myfolder/test2.txt to test/myfolder/test2.txt\n            copying /path/to/myfolder/test.txt to test/myfolder/test.txt\n            copying /path/to/myfolder/hoho/photo.JPG to test/myfolder/hoho/photo.JPG\n            copying /path/to/myfolder/hoho/haha/ff to test/myfolder/hoho/haha/ff\n\n            >>> # When file does not exist, it returns a dictionary of what went wrong.\n            >>> s3utils.cp(\"/tmp/does_not_exist\", \"somewhere\")\n            ERROR:root:trying to upload to s3 but file doesn't exist: /tmp/does_not_exist\n            >>> {'file_does_not_exist': '/tmp/does_not_exist'}\n        \"\"\"\n        result = None\n        if overwrite:\n            list_of_files = []\n        else:\n            list_of_files = self.ls(folder=target_path, begin_from_file=\"\", num=-1, get_grants=False, all_grant_data=False)\n\n        # copying the contents of the folder and not folder itself\n        if local_path.endswith(\"/*\"):\n            local_path = local_path[:-2]\n            target_path = re.sub(r\"^/|/$\", \"\", target_path)  # Amazon S3 doesn't let the name to begin with /\n        # copying folder too\n        else:\n            local_base_name = os.path.basename(local_path)\n\n            local_path = re.sub(r\"/$\", \"\", local_path)\n            target_path = re.sub(r\"^/\", \"\", target_path)\n\n            if not target_path.endswith(local_base_name):\n                target_path = os.path.join(target_path, local_base_name)\n\n        if os.path.exists(local_path):\n\n            result = self.__find_files_and_copy(local_path, target_path, acl, del_after_upload, overwrite, invalidate, list_of_files)\n\n        else:\n            result = {'file_does_not_exist': local_path}\n            logger.error(\"trying to upload to s3 but file doesn't exist: %s\" % local_path)\n\n        return result", "label": 1}
{"code": "def send_local_content\n        response.headers['Accept-Ranges'] = 'bytes'\n        if request.head?\n          local_content_head\n        elsif request.headers['Range']\n          send_range_for_local_file\n        else\n          send_local_file_contents\n        end\n      end", "label": 4}
{"code": "def download_all(download_xcode_profiles: false)\n      UI.message(\"Starting login with user '#{Sigh.config[:username]}'\")\n      Spaceship.login(Sigh.config[:username], nil)\n      Spaceship.select_team\n      UI.message(\"Successfully logged in\")\n\n      Spaceship.provisioning_profile.all(xcode: download_xcode_profiles).each do |profile|\n        if profile.valid?\n          UI.message(\"Downloading profile '#{profile.name}'...\")\n          download_profile(profile)\n        else\n          UI.important(\"Skipping invalid/expired profile '#{profile.name}'\")\n        end\n      end\n\n      if download_xcode_profiles\n        UI.message(\"This run also included all Xcode managed provisioning profiles, as you used the `--download_xcode_profiles` flag\")\n      else\n        UI.message(\"All Xcode managed provisioning profiles were ignored on this, to include them use the `--download_xcode_profiles` flag\")\n      end\n    end", "label": 4}
{"code": "def sample_chromosomes(job, genome_fai_file):\n    \"\"\"\n    Get a list of chromosomes in the input data.\n\n    :param toil.fileStore.FileID genome_fai_file: Job store file ID for the genome fai file\n    :return: Chromosomes in the sample\n    :rtype: list[str]\n    \"\"\"\n    work_dir = os.getcwd()\n    genome_fai = untargz(job.fileStore.readGlobalFile(genome_fai_file), work_dir)\n    return chromosomes_from_fai(genome_fai)", "label": 1}
{"code": "protected function mergeLastGroupAttributes(array $attributes)\n    {\n        if (empty($this->groupStack)) {\n            return $this->mergeGroup($attributes, []);\n        }\n\n        return $this->mergeGroup($attributes, end($this->groupStack));\n    }", "label": 2}
{"code": "public static base_responses export(nitro_service client, sslfipskey resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tsslfipskey exportresources[] = new sslfipskey[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\texportresources[i] = new sslfipskey();\n\t\t\t\texportresources[i].fipskeyname = resources[i].fipskeyname;\n\t\t\t\texportresources[i].key = resources[i].key;\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, exportresources,\"export\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "func PgDatabaseByDatname(db XODB, datname pgtypes.Name) (*PgDatabase, error) {\n\tvar err error\n\n\t// sql query\n\tconst sqlstr = `SELECT ` +\n\t\t`tableoid, cmax, xmax, cmin, xmin, oid, ctid, datname, datdba, encoding, datcollate, datctype, datistemplate, datallowconn, datconnlimit, datlastsysoid, datfrozenxid, datminmxid, dattablespace, datacl ` +\n\t\t`FROM pg_catalog.pg_database ` +\n\t\t`WHERE datname = $1`\n\n\t// run query\n\tXOLog(sqlstr, datname)\n\tpd := PgDatabase{}\n\n\terr = db.QueryRow(sqlstr, datname).Scan(&pd.Tableoid, &pd.Cmax, &pd.Xmax, &pd.Cmin, &pd.Xmin, &pd.Oid, &pd.Ctid, &pd.Datname, &pd.Datdba, &pd.Encoding, &pd.Datcollate, &pd.Datctype, &pd.Datistemplate, &pd.Datallowconn, &pd.Datconnlimit, &pd.Datlastsysoid, &pd.Datfrozenxid, &pd.Datminmxid, &pd.Dattablespace, &pd.Datacl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &pd, nil\n}", "label": 5}
{"code": "def get_symlink_luid():\n\t\"\"\"\n\tGet the LUID for the SeCreateSymbolicLinkPrivilege\n\t\"\"\"\n\tsymlink_luid = privilege.LUID()\n\tres = privilege.LookupPrivilegeValue(\n\t\tNone, \"SeCreateSymbolicLinkPrivilege\", symlink_luid)\n\tif not res > 0:\n\t\traise RuntimeError(\"Couldn't lookup privilege value\")\n\treturn symlink_luid", "label": 1}
{"code": "public void restoreSecurityContext(CacheContext context) {\n\t\tSavedAuthorization cached = context.get(CacheContext.SECURITY_CONTEXT_KEY, SavedAuthorization.class);\n\t\tif (cached != null) {\n\t\t\tlog.debug(\"Restoring security context {}\", cached);\n\t\t\tsecurityManager.restoreSecurityContext(cached);\n\t\t} else {\n\t\t\tsecurityManager.clearSecurityContext();\n\t\t}\n\t}", "label": 0}
{"code": "def cancel(self, caller):\n        \"\"\"\n            Recursively cancel all threaded background processes of this Callable.\n            This is called automatically for actions if program deactivates.\n        \"\"\"\n        for o in {i for i in self.children if isinstance(i, AbstractCallable)}:\n            o.cancel(caller)", "label": 1}
{"code": "def deliver(event)\n      info do\n        perform_deliveries = event.payload[:perform_deliveries]\n        if perform_deliveries\n          \"Delivered mail #{event.payload[:message_id]} (#{event.duration.round(1)}ms)\"\n        else\n          \"Skipped delivery of mail #{event.payload[:message_id]} as `perform_deliveries` is false\"\n        end\n      end\n\n      debug { event.payload[:mail] }\n    end", "label": 4}
{"code": "def linked_resources_for(resource, type, link_name)\n      linked_resources = resource.linked_resources(type, link_name).group_by { |linked_resource| linked_resource.class.name }\n\n      safe_join(linked_resources.map do |klass, resources|\n        resource_manifest = klass.constantize.resource_manifest\n        content_tag(:div, class: \"section\") do\n          i18n_name = \"#{resource.class.name.demodulize.underscore}_#{resource_manifest.name}\"\n          content_tag(:h3, I18n.t(i18n_name, scope: \"decidim.resource_links.#{link_name}\"), class: \"section-heading\") +\n            render(partial: resource_manifest.template, locals: { resources: resources })\n        end\n      end)\n    end", "label": 4}
{"code": "public void executeUpdate(ClassDescriptor cld, Object obj) throws PersistenceBrokerException\r\n    {\r\n        if (logger.isDebugEnabled())\r\n        {\r\n            logger.debug(\"executeUpdate: \" + obj);\r\n        }\r\n\r\n        // obj with nothing but key fields is not updated\r\n        if (cld.getNonPkRwFields().length == 0)\r\n        {\r\n            return;\r\n        }\r\n\r\n        final StatementManagerIF sm = broker.serviceStatementManager();\r\n        PreparedStatement stmt = null;\r\n        // BRJ: preserve current locking values\r\n        // locking values will be restored in case of exception\r\n        ValueContainer[] oldLockingValues;\r\n        oldLockingValues = cld.getCurrentLockingValues(obj);\r\n        try\r\n        {\r\n            stmt = sm.getUpdateStatement(cld);\r\n            if (stmt == null)\r\n            {\r\n                logger.error(\"getUpdateStatement returned a null statement\");\r\n                throw new PersistenceBrokerException(\"getUpdateStatement returned a null statement\");\r\n            }\r\n\r\n            sm.bindUpdate(stmt, cld, obj);\r\n            if (logger.isDebugEnabled())\r\n                logger.debug(\"executeUpdate: \" + stmt);\r\n\r\n            if ((stmt.executeUpdate() == 0) && cld.isLocking()) //BRJ\r\n            {\r\n                /**\r\n                 * Kuali Foundation modification -- 6/19/2009\r\n                 */\r\n            \tString objToString = \"\";\r\n            \ttry {\r\n            \t\tobjToString = obj.toString();\r\n            \t} catch (Exception ex) {}\r\n                throw new OptimisticLockException(\"Object has been modified by someone else: \" + objToString, obj);\r\n                /**\r\n                 * End of Kuali Foundation modification\r\n                 */\r\n            }\r\n\r\n            // Harvest any return values.\r\n            harvestReturnValues(cld.getUpdateProcedure(), obj, stmt);\r\n        }\r\n        catch (OptimisticLockException e)\r\n        {\r\n            // Don't log as error\r\n            if (logger.isDebugEnabled())\r\n                logger.debug(\r\n                    \"OptimisticLockException during the execution of update: \" + e.getMessage(),\r\n                    e);\r\n            throw e;\r\n        }\r\n        catch (PersistenceBrokerException e)\r\n        {\r\n            // BRJ: restore old locking values\r\n            setLockingValues(cld, obj, oldLockingValues);\r\n\r\n            logger.error(\r\n                \"PersistenceBrokerException during the execution of the update: \" + e.getMessage(),\r\n                e);\r\n            throw e;\r\n        }\r\n        catch (SQLException e)\r\n        {\r\n            final String sql = broker.serviceSqlGenerator().getPreparedUpdateStatement(cld).getStatement();\r\n            throw ExceptionHelper.generateException(e, sql, cld, logger, obj);\r\n        }\r\n        finally\r\n        {\r\n            sm.closeResources(stmt, null);\r\n        }\r\n    }", "label": 0}
{"code": "def pil(self, **params_to_override):\n        \"\"\"Returns a PIL image for this pattern, overriding parameters if provided.\"\"\"\n        from PIL.Image import fromarray\n        nchans = self.num_channels()\n\n        if nchans in [0, 1]:\n            mode, arr = None, self(**params_to_override)\n            arr = (255.0 / arr.max() * (arr - arr.min())).astype(np.uint8)\n\n        elif nchans in [3,4]:\n            mode = 'RGB' if nchans==3 else 'RGBA'\n            arr = np.dstack(self.channels(**params_to_override).values()[1:])\n            arr = (255.0*arr).astype(np.uint8)\n\n        else:\n            raise ValueError(\"Unsupported number of channels\")\n\n        return fromarray(arr, mode)", "label": 1}
{"code": "public function setTransactionOptions($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Datastore\\V1\\TransactionOptions::class);\n        $this->transaction_options = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def delete(stack, region, profile):\n    \"\"\"\n    Delete the given CloudFormation stack.\n    \"\"\"\n    ini_data = {}\n    environment = {}\n\n    environment['stack_name'] = stack\n    if region:\n        environment['region'] = region\n    else:\n        environment['region'] = find_myself()\n\n    if profile:\n        environment['profile'] = profile\n\n    ini_data['environment'] = environment\n\n    if start_smash(ini_data):\n        sys.exit(0)\n    else:\n        sys.exit(1)", "label": 1}
{"code": "function loadUIPart(appName, filePath) {\n    var idx = filePath.indexOf(delim + appName + delim);\n    var modulePath = filePath.substring(idx - 3);\n    return this.pancakes.cook(modulePath);\n}", "label": 3}
{"code": "def _remove_isolated(self, case):\n        \"\"\" Returns non-isolated case components.\n        \"\"\"\n#        case.deactivate_isolated()\n        buses = case.connected_buses\n        branches = case.online_branches\n        gens = case.online_generators\n\n        return buses, branches, gens", "label": 1}
{"code": "def get_from_geo(self, lat, lng, distance, skip_cache=False):\n        \"\"\"\n        Calls `postcodes.get_from_geo` but checks the correctness of \n        all arguments, and by default utilises a local cache.\n\n        :param skip_cache: optional argument specifying whether to skip \n                           the cache and make an explicit request.\n\n        :raises IllegalPointException: if the latitude or longitude \n                                       are out of bounds.\n\n        :returns: a list of dicts containing postcode data within the \n                  specified distance.\n        \"\"\"\n        # remove spaces and change case here due to caching\n        lat, lng, distance = float(lat), float(lng), float(distance)\n        if distance < 0:\n            raise IllegalDistanceException(\"Distance must not be negative\")\n        self._check_point(lat, lng)\n        return self._lookup(skip_cache, get_from_geo, lat, lng, distance)", "label": 1}
{"code": "function createTree (context, folder) {\n  const tree = []\n  const files = []\n\n  let directoryContents = []\n\n  try {\n    directoryContents = fs.readdirSync(path.join(context, folder))\n  } catch (error) {\n    // Throw error if it\u2019s not a permissions error\n    if (error.code !== 'EACCESS') {\n      throw error\n    }\n  }\n\n  // Folders first\n  directoryContents\n    .filter(item => {\n      return fs\n        .lstatSync(path.join(context, folder, item))\n        .isDirectory()\n    })\n    .forEach(item => {\n      const children = createTree(context, path.join(folder, item))\n\n      // Don\u2019t add current directory to tree if it has no children\n      if (children.tree.length) {\n        tree.push({\n          name: formatName(item),\n          children: children.tree\n        })\n      }\n\n      files.push(...children.files)\n    })\n\n  // Files second\n  directoryContents\n    .filter(item => item.endsWith('.njk'))\n    .forEach(item => {\n      const basename = path.basename(item, '.njk')\n      const filePath = formatPath(folder, item)\n      const configPath = path.join(context, folder, basename + '.json')\n\n      let config\n\n      try {\n        config = JSON.parse(fs.readFileSync(configPath))\n      } catch (error) {\n        config = {}\n      }\n\n      // Don\u2019t add current component to tree if it\u2019s hidden\n      if (config.hidden) {\n        return\n      }\n\n      tree.push({\n        name: formatName(basename),\n        path: filePath.slice(0, -4),\n        config\n      })\n\n      files.push(filePath)\n    })\n\n  return { files, tree }\n}", "label": 3}
{"code": "public void addStep(String name, String robot, Map<String, Object> options) {\n        all.put(name, new Step(name, robot, options));\n    }", "label": 0}
{"code": "def write_metadata\n      unless disabled?\n        Jekyll.logger.debug \"Writing Metadata:\", \".jekyll-metadata\"\n        File.binwrite(metadata_file, Marshal.dump(metadata))\n      end\n    end", "label": 4}
{"code": "def validate(self, **kwargs):\n        \"\"\"\n        Validates a submission file\n\n        :param file_path: path to file to be loaded.\n        :param data: pre loaded YAML object (optional).\n        :return: Bool to indicate the validity of the file.\n        \"\"\"\n        try:\n            submission_file_schema = json.load(open(self.default_schema_file, 'r'))\n\n            additional_file_section_schema = json.load(open(self.additional_info_schema, 'r'))\n\n            # even though we are using the yaml package to load,\n            # it supports JSON and YAML\n            data = kwargs.pop(\"data\", None)\n            file_path = kwargs.pop(\"file_path\", None)\n\n            if file_path is None:\n                raise LookupError(\"file_path argument must be supplied\")\n\n            if data is None:\n                data = yaml.load_all(open(file_path, 'r'), Loader=Loader)\n\n            for data_item_index, data_item in enumerate(data):\n                if data_item is None:\n                    continue\n                try:\n                    if not data_item_index and 'data_file' not in data_item:\n                        validate(data_item, additional_file_section_schema)\n                    else:\n                        validate(data_item, submission_file_schema)\n\n                except ValidationError as ve:\n                    self.add_validation_message(\n                            ValidationMessage(file=file_path,\n                                                message=ve.message + ' in ' + str(ve.instance)))\n\n            if self.has_errors(file_path):\n                return False\n            else:\n                return True\n\n        except ScannerError as se:  # pragma: no cover\n            self.add_validation_message(  # pragma: no cover\n                ValidationMessage(file=file_path, message=\n                    'There was a problem parsing the file.  '\n                    'This can be because you forgot spaces '\n                    'after colons in your YAML file for instance.  '\n                    'Diagnostic information follows.\\n' + str(se)))\n            return False\n\n        except Exception as e:\n            self.add_validation_message(ValidationMessage(file=file_path, message=e.__str__()))\n            return False", "label": 1}
{"code": "func (w *BroadcastWriter) Write(p []byte) (n int, err error) {\n\tfor _, writer := range w.writers {\n\t\tn, err = writer.Write(p)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tif n != len(p) {\n\t\t\terr = io.ErrShortWrite\n\t\t\treturn\n\t\t}\n\t}\n\treturn len(p), nil\n}", "label": 5}
{"code": "func getBucketSize(request *restful.Request) (time.Duration, error) {\n\trawSize := request.QueryParameter(\"bucket\")\n\tif rawSize == \"\" {\n\t\treturn 0, nil\n\t}\n\n\tif len(rawSize) < 2 {\n\t\treturn 0, fmt.Errorf(\"unable to parse bucket size: %q is too short to be a duration\", rawSize)\n\t}\n\tvar multiplier time.Duration\n\tvar num string\n\n\tswitch rawSize[len(rawSize)-1] {\n\tcase 's':\n\t\t// could be s or ms\n\t\tif len(rawSize) < 3 || rawSize[len(rawSize)-2] != 'm' {\n\t\t\tmultiplier = time.Second\n\t\t\tnum = rawSize[:len(rawSize)-1]\n\t\t} else {\n\t\t\tmultiplier = time.Millisecond\n\t\t\tnum = rawSize[:len(rawSize)-2]\n\t\t}\n\tcase 'h':\n\t\tmultiplier = time.Hour\n\t\tnum = rawSize[:len(rawSize)-1]\n\tcase 'd':\n\t\tmultiplier = 24 * time.Hour\n\t\tnum = rawSize[:len(rawSize)-1]\n\tcase 'm':\n\t\tmultiplier = time.Minute\n\t\tnum = rawSize[:len(rawSize)-1]\n\tdefault:\n\t\treturn 0, fmt.Errorf(\"unable to parse bucket size: %q has no known duration suffix\", rawSize)\n\t}\n\n\tparsedNum, err := strconv.ParseUint(num, 10, 64)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn time.Duration(parsedNum) * multiplier, nil\n}", "label": 5}
{"code": "func (t *tScreen) parseXtermMouse(buf *bytes.Buffer) (bool, bool) {\n\n\tb := buf.Bytes()\n\n\tstate := 0\n\tbtn := 0\n\tx := 0\n\ty := 0\n\n\tfor i := range b {\n\t\tswitch state {\n\t\tcase 0:\n\t\t\tswitch b[i] {\n\t\t\tcase '\\x1b':\n\t\t\t\tstate = 1\n\t\t\tcase '\\x9b':\n\t\t\t\tstate = 2\n\t\t\tdefault:\n\t\t\t\treturn false, false\n\t\t\t}\n\t\tcase 1:\n\t\t\tif b[i] != '[' {\n\t\t\t\treturn false, false\n\t\t\t}\n\t\t\tstate = 2\n\t\tcase 2:\n\t\t\tif b[i] != 'M' {\n\t\t\t\treturn false, false\n\t\t\t}\n\t\t\tstate++\n\t\tcase 3:\n\t\t\tbtn = int(b[i])\n\t\t\tstate++\n\t\tcase 4:\n\t\t\tx = int(b[i]) - 32 - 1\n\t\t\tstate++\n\t\tcase 5:\n\t\t\ty = int(b[i]) - 32 - 1\n\t\t\tfor i >= 0 {\n\t\t\t\tbuf.ReadByte()\n\t\t\t\ti--\n\t\t\t}\n\t\t\tt.postMouseEvent(x, y, btn)\n\t\t\treturn true, true\n\t\t}\n\t}\n\treturn true, false\n}", "label": 5}
{"code": "def generate_entry_between_tags(older_tag, newer_tag)\n      filtered_issues, filtered_pull_requests = filter_issues_for_tags(newer_tag, older_tag)\n\n      if newer_tag.nil? && filtered_issues.empty? && filtered_pull_requests.empty?\n        # do not generate empty unreleased section\n        return \"\"\n      end\n\n      newer_tag_link, newer_tag_name, newer_tag_time = detect_link_tag_time(newer_tag)\n\n      # If the older tag is nil, go back in time from the latest tag and find\n      # the SHA for the first commit.\n      older_tag_name =\n        if older_tag.nil?\n          @fetcher.oldest_commit[\"sha\"]\n        else\n          older_tag[\"name\"]\n        end\n\n      Entry.new(options).generate_entry_for_tag(filtered_pull_requests, filtered_issues, newer_tag_name, newer_tag_link, newer_tag_time, older_tag_name)\n    end", "label": 4}
{"code": "func (s *v1AlphaAPIServer) getBasicPod(p *pkgPod.Pod) *v1alpha.Pod {\n\tmtime, mtimeErr := getPodManifestModTime(p)\n\tif mtimeErr != nil {\n\t\tstderr.PrintE(fmt.Sprintf(\"failed to read the pod manifest's mtime for pod %q\", p.UUID), mtimeErr)\n\t}\n\n\t// Couldn't use pod.uuid directly as it's a pointer.\n\titemValue, found := s.podCache.Get(p.UUID.String())\n\tif found && mtimeErr == nil {\n\t\tcacheItem := itemValue.(*podCacheItem)\n\n\t\t// Check the mtime to make sure we are not returning stale manifests.\n\t\tif !mtime.After(cacheItem.mtime) {\n\t\t\treturn copyPod(cacheItem.pod)\n\t\t}\n\t}\n\n\tpod, err := s.getBasicPodFromDisk(p)\n\tif mtimeErr != nil || err != nil {\n\t\t// If any error happens or the mtime is unknown,\n\t\t// returns the raw pod directly without adding it to the cache.\n\t\treturn pod\n\t}\n\n\tcacheItem := &podCacheItem{pod, mtime}\n\ts.podCache.Add(p.UUID.String(), cacheItem)\n\n\t// Return a copy of the pod, so the cached pod is not mutated later.\n\treturn copyPod(cacheItem.pod)\n}", "label": 5}
{"code": "public function UpdateGroup(\\Google\\Cloud\\ErrorReporting\\V1beta1\\UpdateGroupRequest $argument,\n      $metadata = [], $options = []) {\n        return $this->_simpleRequest('/google.devtools.clouderrorreporting.v1beta1.ErrorGroupService/UpdateGroup',\n        $argument,\n        ['\\Google\\Cloud\\ErrorReporting\\V1beta1\\ErrorGroup', 'decode'],\n        $metadata, $options);\n    }", "label": 2}
{"code": "def run(options = {})\n      @config = load_applicable_config(options)\n      @files = extract_applicable_files(config, options)\n      @linter_selector = HamlLint::LinterSelector.new(config, options)\n      @fail_fast = options.fetch(:fail_fast, false)\n\n      report(options)\n    end", "label": 4}
{"code": "protected function reset()\n    {\n        $this->valid = true;\n        $this->fetchmore = true;\n        $this->elements = array();\n        $this->position = -1;\n        $this->current = null;\n    }", "label": 2}
{"code": "public function getIamPolicy($resource, array $optionalArgs = [])\n    {\n        $request = new GetIamPolicyRequest();\n        $request->setResource($resource);\n\n        return $this->startCall(\n            'GetIamPolicy',\n            Policy::class,\n            $optionalArgs,\n            $request\n        )->wait();\n    }", "label": 2}
{"code": "def request(community_id, record_id, accept):\n    \"\"\"Request a record acceptance to a community.\"\"\"\n    c = Community.get(community_id)\n    assert c is not None\n    record = Record.get_record(record_id)\n    if accept:\n        c.add_record(record)\n        record.commit()\n    else:\n        InclusionRequest.create(community=c, record=record,\n                                notify=False)\n    db.session.commit()\n    RecordIndexer().index_by_id(record.id)", "label": 1}
{"code": "public function setStoredInfoTypes($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\StoredInfoType::class);\n        $this->stored_info_types = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function setThreat($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\WebRisk\\V1beta1\\SearchUrisResponse_ThreatUri::class);\n        $this->threat = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public function serialize()\n    {\n        return json_encode([\n            'operation_name' => $this->operationName,\n            'channel' => $this->channel,\n            'args' => $this->args,\n            'context' => $this->contextSerializer()->serialize($this->context),\n            'query' => serialize(\n                AST::toArray($this->query)\n            ),\n        ]);\n    }", "label": 2}
{"code": "public function setTargetChange($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Firestore\\V1\\TargetChange::class);\n        $this->writeOneof(2, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "def format\n      if @destroy\n        text = \"\"\n      else\n        text = \"[#{name}]\\n\"\n        @entries.each do |entry|\n          if entry.is_a?(Array)\n            key, value = entry\n            text << \"#{key}=#{value}\\n\" unless value.nil?\n          else\n            text << entry\n          end\n        end\n      end\n      text\n    end", "label": 4}
{"code": "def process_localized_attributes(klass, attrs)\n      klass.localized_fields.keys.each do |name|\n        if value = attrs.delete(name)\n          attrs[\"#{name}_translations\"] = value\n        end\n      end\n      klass.embedded_relations.each do |_, association|\n        next unless attrs.present? && attrs[association.key].present?\n\n        if association.is_a?(Association::Embedded::EmbedsMany)\n          attrs[association.key].each do |attr|\n            embedded_klass = attr.fetch('_type', association.class_name).constantize\n            process_localized_attributes(embedded_klass, attr)\n          end\n        else\n          process_localized_attributes(association.klass, attrs[association.key])\n        end\n      end\n    end", "label": 4}
{"code": "function getAllowedSteps(gradation, units)\n{\n\treturn gradation.filter(({ unit }) => {\n\t\t// If this step has a `unit` defined\n\t\t// then this `unit` must be in the list of `units` allowed.\n\t\tif (unit) {\n\t\t\treturn units.indexOf(unit) >= 0\n\t\t}\n\t\t// A gradation step is not required to specify a `unit`.\n\t\t// E.g. for Twitter gradation it specifies `format()` instead.\n\t\treturn true\n\t})\n}", "label": 3}
{"code": "public boolean absolute(int row) throws PersistenceBrokerException\r\n    {\r\n        boolean retval;\r\n        if (supportsAdvancedJDBCCursorControl())\r\n        {\r\n            retval = absoluteAdvanced(row);\r\n        }\r\n        else\r\n        {\r\n            retval = absoluteBasic(row);\r\n        }\r\n        return retval;\r\n    }", "label": 0}
{"code": "private function normalizeOptions(array $options)\n    {\n        $options += [\n            'method' => 'GET',\n            'cname' => self::DEFAULT_DOWNLOAD_HOST,\n            'contentMd5' => null,\n            'contentType' => null,\n            'headers' => [],\n            'saveAsName' => null,\n            'responseDisposition' => null,\n            'responseType' => null,\n            'keyFile' => null,\n            'keyFilePath' => null,\n            'allowPost' => false,\n            'forceOpenssl' => false,\n            'queryParams' => [],\n            'timestamp' => null\n        ];\n\n        $allowedMethods = ['GET', 'PUT', 'POST', 'DELETE'];\n        $options['method'] = strtoupper($options['method']);\n        if (!in_array($options['method'], $allowedMethods)) {\n            throw new \\InvalidArgumentException('$options.method must be one of `GET`, `PUT` or `DELETE`.');\n        }\n\n        if ($options['method'] === 'POST' && !$options['allowPost']) {\n            throw new \\InvalidArgumentException(\n                'Invalid method. To create an upload URI, use StorageObject::signedUploadUrl().'\n            );\n        }\n        unset($options['allowPost']);\n\n        // For backwards compatibility, strip protocol from cname.\n        $cnameParts = explode('//', $options['cname']);\n        if (count($cnameParts) > 1) {\n            $options['cname'] = $cnameParts[1];\n        }\n\n        $options['cname'] = trim($options['cname'], '/');\n\n        // If a timestamp is provided, use it in place of `now` for v4 URLs only..\n        // This option exists for testing purposes, and should not generally be provided by users.\n        if ($options['timestamp']) {\n            if (!($options['timestamp'] instanceof \\DateTimeInterface)) {\n                if (!is_string($options['timestamp'])) {\n                    throw new \\InvalidArgumentException(\n                        'User-provided timestamps must be a string or instance of `\\DateTimeInterface`.'\n                    );\n                }\n\n                $options['timestamp'] = \\DateTimeImmutable::createFromFormat(\n                    self::V4_TIMESTAMP_FORMAT,\n                    $options['timestamp'],\n                    new \\DateTimeZone('UTC')\n                );\n\n                if (!$options['timestamp']) {\n                    throw new \\InvalidArgumentException(\n                        'Given timestamp string is in an invalid format. Provide timestamp formatted as follows: `' .\n                        self::V4_TIMESTAMP_FORMAT .\n                        '`. Note that timestamps MUST be in UTC.'\n                    );\n                }\n            }\n        } else {\n            $options['timestamp'] = new \\DateTimeImmutable('now', new \\DateTimeZone('UTC'));\n        }\n\n        return $options;\n    }", "label": 2}
{"code": "def require_extensions\n      Gem::Specification.all_names.select{|n| n.match(/^solargraph\\-[a-z0-9_\\-]*?\\-ext\\-[0-9\\.]*$/)}.each do |n|\n        Solargraph::Logging.logger.info \"Loading extension #{n}\"\n        require n.match(/^(solargraph\\-[a-z0-9_\\-]*?\\-ext)\\-[0-9\\.]*$/)[1]\n      end\n    end", "label": 4}
{"code": "def continue_prompt(message=\"\"):\n    \"\"\"Prompt the user to continue or not\n\n    Returns True when the user type Yes.\n\n    :param message: message to display\n    :type message: str\n\n    :rtype: bool\n    \"\"\"\n    answer = False\n    message = message + \"\\n'Yes' or 'No' to continue: \"\n    while answer not in ('Yes', 'No'):\n        answer = prompt(message, eventloop=eventloop())\n        if answer == \"Yes\":\n            answer = True\n            break\n        if answer == \"No\":\n            answer = False\n            break\n    return answer", "label": 1}
{"code": "def response_token_setter(remote, resp):\n    \"\"\"Extract token from response and set it for the user.\n\n    :param remote: The remote application.\n    :param resp: The response.\n    :raises invenio_oauthclient.errors.OAuthClientError: If authorization with\n        remote service failed.\n    :raises invenio_oauthclient.errors.OAuthResponseError: In case of bad\n        authorized request.\n    :returns: The token.\n    \"\"\"\n    if resp is None:\n        raise OAuthRejectedRequestError('User rejected request.', remote, resp)\n    else:\n        if 'access_token' in resp:\n            return oauth2_token_setter(remote, resp)\n        elif 'oauth_token' in resp and 'oauth_token_secret' in resp:\n            return oauth1_token_setter(remote, resp)\n        elif 'error' in resp:\n            # Only OAuth2 specifies how to send error messages\n            raise OAuthClientError(\n                'Authorization with remote service failed.', remote, resp,\n            )\n    raise OAuthResponseError('Bad OAuth authorized request', remote, resp)", "label": 1}
{"code": "public function setValidation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1beta2\\ParameterValidation::class);\n        $this->validation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "private function getClassMetadata($entityName, EntityManagerInterface $entityManager)\n    {\n        try {\n            return $entityManager->getClassMetadata($entityName);\n        } catch (MappingException $e) {\n        }\n\n        $matches = array_filter(\n            $this->getMappedEntities($entityManager),\n            static function ($mappedEntity) use ($entityName) {\n                return preg_match('{' . preg_quote($entityName) . '}', $mappedEntity);\n            }\n        );\n\n        if (! $matches) {\n            throw new InvalidArgumentException(sprintf(\n                'Could not find any mapped Entity classes matching \"%s\"',\n                $entityName\n            ));\n        }\n\n        if (count($matches) > 1) {\n            throw new InvalidArgumentException(sprintf(\n                'Entity name \"%s\" is ambiguous, possible matches: \"%s\"',\n                $entityName,\n                implode(', ', $matches)\n            ));\n        }\n\n        return $entityManager->getClassMetadata(current($matches));\n    }", "label": 2}
{"code": "function inFromVoid(from, to) {\n    return to !== null && to !== 'nofx' && from === 'void' && to !== 'void' ? true : false;\n}", "label": 3}
{"code": "def save\n      @google_api.update_listing_for_language(language: language,\n                                              title: title,\n                                              short_description: short_description,\n                                              full_description: full_description,\n                                              video: video)\n    end", "label": 4}
{"code": "def format_request_email_title(increq, **ctx):\n    \"\"\"Format the email message title for inclusion request notification.\n\n    :param increq: Inclusion request object for which the request is made.\n    :type increq: `invenio_communities.models.InclusionRequest`\n    :param ctx: Optional extra context parameters passed to formatter.\n    :type ctx: dict.\n    :returns: Email message title.\n    :rtype: str\n    \"\"\"\n    template = current_app.config[\"COMMUNITIES_REQUEST_EMAIL_TITLE_TEMPLATE\"],\n    return format_request_email_templ(increq, template, **ctx)", "label": 1}
{"code": "public static nspbr6[] get(nitro_service service, nspbr6_args args) throws Exception{\n\t\tnspbr6 obj = new nspbr6();\n\t\toptions option = new options();\n\t\toption.set_args(nitro_util.object_to_string_withoutquotes(args));\n\t\tnspbr6[] response = (nspbr6[])obj.get_resources(service, option);\n\t\treturn response;\n\t}", "label": 0}
{"code": "func (aSpace *addrSpace) MarshalJSON() ([]byte, error) {\n\taSpace.Lock()\n\tdefer aSpace.Unlock()\n\n\tm := map[string]interface{}{\n\t\t\"Scope\": string(aSpace.scope),\n\t}\n\n\tif aSpace.subnets != nil {\n\t\ts := map[string]*PoolData{}\n\t\tfor k, v := range aSpace.subnets {\n\t\t\ts[k.String()] = v\n\t\t}\n\t\tm[\"Subnets\"] = s\n\t}\n\n\treturn json.Marshal(m)\n}", "label": 5}
{"code": "private function getMessageAckIds(array $messages)\n    {\n        $ackIds = [];\n        foreach ($messages as $message) {\n            $ackIds[] = $message->ackId();\n        }\n\n        return $ackIds;\n    }", "label": 2}
{"code": "public static csvserver_lbvserver_binding[] get(nitro_service service, String name) throws Exception{\n\t\tcsvserver_lbvserver_binding obj = new csvserver_lbvserver_binding();\n\t\tobj.set_name(name);\n\t\tcsvserver_lbvserver_binding response[] = (csvserver_lbvserver_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public function loadPlugins()\n    {\n        $this->checkCache();\n        $this->validatePlugins();\n        $this->countPlugins();\n\n        array_map(static function () {\n            include_once WPMU_PLUGIN_DIR . '/' . func_get_args()[0];\n        }, array_keys(self::$cache['plugins']));\n\n        $this->pluginHooks();\n    }", "label": 2}
{"code": "def source_from_range(source_range) # rubocop:disable Metrics/AbcSize\n      current_line = source_range.start_pos.line - 1\n      last_line    = source_range.end_pos.line - 1\n      start_pos    = source_range.start_pos.offset - 1\n\n      source =\n        if current_line == last_line\n          engine.lines[current_line][start_pos..(source_range.end_pos.offset - 1)]\n        else\n          engine.lines[current_line][start_pos..-1]\n        end\n\n      current_line += 1\n      while current_line < last_line\n        source += engine.lines[current_line].to_s\n        current_line += 1\n      end\n\n      if source_range.start_pos.line != source_range.end_pos.line\n        source += ((engine.lines[current_line] || '')[0...source_range.end_pos.offset]).to_s\n      end\n\n      source\n    end", "label": 4}
{"code": "public static function hydrate(array $data)\n    {\n        return new self(\n            $data['token'],\n            $data['table'],\n            KeySet::fromArray($data['keySet']),\n            $data['columns'],\n            $data['options']\n        );\n    }", "label": 2}
{"code": "def retrieve_customer(customer_id, opts = {})\n      data, _status_code, _headers = retrieve_customer_with_http_info(customer_id, opts)\n      return data\n    end", "label": 4}
{"code": "public static double SquaredEuclidean(double[] x, double[] y) {\n        double d = 0.0, u;\n\n        for (int i = 0; i < x.length; i++) {\n            u = x[i] - y[i];\n            d += u * u;\n        }\n\n        return d;\n    }", "label": 0}
{"code": "private void putToSessionCache(Identity oid, CacheEntry entry, boolean onlyIfNew)\r\n    {\r\n        if(onlyIfNew)\r\n        {\r\n            // no synchronization needed, because session cache was used per broker instance\r\n            if(!sessionCache.containsKey(oid)) sessionCache.put(oid, entry);\r\n        }\r\n        else\r\n        {\r\n            sessionCache.put(oid, entry);\r\n        }\r\n    }", "label": 0}
{"code": "func compareIPMask(ip net.IP, mask net.IPMask) (is int, ms int, err error) {\n\t// Find the effective starting of address and mask\n\tif len(ip) == net.IPv6len && ip.To4() != nil {\n\t\tis = 12\n\t}\n\tif len(ip[is:]) == net.IPv4len && len(mask) == net.IPv6len && bytes.Equal(mask[:12], v4inV6MaskPrefix) {\n\t\tms = 12\n\t}\n\t// Check if address and mask are semantically compatible\n\tif len(ip[is:]) != len(mask[ms:]) {\n\t\terr = fmt.Errorf(\"ip and mask are not compatible: (%#v, %#v)\", ip, mask)\n\t}\n\treturn\n}", "label": 5}
{"code": "function updateTaxis()\n{\n    var ids = [ \"11\", \"22\", \"33\" ];\n    var statuses = [ \"avail\", \"busy\", \"scheduled\" ];\n    var bbox = bkutils.geoBoundingBox(center[0], center[1], 2); // within 2 km from the center\n    var latitude = lib.randomNum(bbox[0], bbox[2], 5);\n    var longitude = lib.randomNum(bbox[1], bbox[3], 5);\n    var id = ids[lib.randomInt(0, ids.length - 1)];\n    var status = statuses[lib.randomInt(0, statuses.length - 1)];\n\n    db.put(\"taxi\", { id: id, status: status, latitude: latitude, longitude: longitude });\n}", "label": 3}
{"code": "func (l VirtualDeviceList) CreateEthernetCard(name string, backing types.BaseVirtualDeviceBackingInfo) (types.BaseVirtualDevice, error) {\n\tctypes := EthernetCardTypes()\n\n\tif name == \"\" {\n\t\tname = ctypes.deviceName(ctypes[0])\n\t}\n\n\tfound := ctypes.Select(func(device types.BaseVirtualDevice) bool {\n\t\treturn l.deviceName(device) == name\n\t})\n\n\tif len(found) == 0 {\n\t\treturn nil, fmt.Errorf(\"unknown ethernet card type '%s'\", name)\n\t}\n\n\tc, ok := found[0].(types.BaseVirtualEthernetCard)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"invalid ethernet card type '%s'\", name)\n\t}\n\n\tc.GetVirtualEthernetCard().Backing = backing\n\n\treturn c.(types.BaseVirtualDevice), nil\n}", "label": 5}
{"code": "function del(path, opts) {\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n\n  keys(path, opts).forEach(key => delete process.env[key]);\n}", "label": 3}
{"code": "public static authenticationvserver_authenticationradiuspolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tauthenticationvserver_authenticationradiuspolicy_binding obj = new authenticationvserver_authenticationradiuspolicy_binding();\n\t\tobj.set_name(name);\n\t\tauthenticationvserver_authenticationradiuspolicy_binding response[] = (authenticationvserver_authenticationradiuspolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "public void registerCollectionSizeGauge(\n\t\t\tCollectionSizeGauge collectionSizeGauge) {\n\t\tString name = createMetricName(LocalTaskExecutorService.class,\n\t\t\t\t\"queue-size\");\n\t\tmetrics.register(name, collectionSizeGauge);\n\t}", "label": 0}
{"code": "function createModal(config) {\n\n    var id = MODAL_JS_ID;\n    var modalClassName = config.modalPrefixClass + MODAL_CLASS_SUFFIX;\n    var modalClassWrapper = config.modalPrefixClass + MODAL_WRAPPER_CLASS_SUFFIX;\n    var buttonCloseClassName = config.modalPrefixClass + MODAL_BUTTON_CLASS_SUFFIX;\n    var buttonCloseInner = config.modalCloseImgPath ? '<img src=\"' + config.modalCloseImgPath + '\" alt=\"' + config.modalCloseText + '\" class=\"' + config.modalPrefixClass + MODAL_CLOSE_IMG_CLASS_SUFFIX + '\" />' : '<span class=\"' + config.modalPrefixClass + MODAL_CLOSE_TEXT_CLASS_SUFFIX + '\">\\n                                          ' + config.modalCloseText + '\\n                                         </span>';\n    var contentClassName = config.modalPrefixClass + MODAL_CONTENT_CLASS_SUFFIX;\n    var titleClassName = config.modalPrefixClass + MODAL_TITLE_CLASS_SUFFIX;\n    var title = config.modalTitle !== '' ? '<h1 id=\"' + MODAL_TITLE_ID + '\" class=\"' + titleClassName + '\">\\n                                          ' + config.modalTitle + '\\n                                         </h1>' : '';\n    var button_close = '<button type=\"button\" class=\"' + MODAL_BUTTON_JS_CLASS + ' ' + buttonCloseClassName + '\" id=\"' + MODAL_BUTTON_JS_ID + '\" title=\"' + config.modalCloseTitle + '\" ' + MODAL_BUTTON_CONTENT_BACK_ID + '=\"' + config.modalContentId + '\" ' + MODAL_BUTTON_FOCUS_BACK_ID + '=\"' + config.modalFocusBackId + '\">\\n                               ' + buttonCloseInner + '\\n                              </button>';\n    var content = config.modalText;\n    var describedById = config.modalDescribedById !== '' ? ATTR_DESCRIBEDBY + '=\"' + config.modalDescribedById + '\"' : '';\n\n    // If there is no content but an id we try to fetch content id\n    if (content === '' && config.modalContentId) {\n      var contentFromId = findById(config.modalContentId);\n      if (contentFromId) {\n        content = '<div id=\"' + MODAL_CONTENT_JS_ID + '\">\\n                              ' + contentFromId.innerHTML + '\\n                             </div';\n        // we remove content from its source to avoid id duplicates, etc.\n        contentFromId.innerHTML = '';\n      }\n    }\n\n    return '<dialog id=\"' + id + '\" class=\"' + modalClassName + '\" ' + ATTR_ROLE + '=\"' + MODAL_ROLE + '\" ' + describedById + ' ' + ATTR_OPEN + ' ' + ATTR_LABELLEDBY + '=\"' + MODAL_TITLE_ID + '\">\\n                    <div role=\"document\" class=\"' + modalClassWrapper + '\">\\n                      ' + button_close + '\\n                      <div class=\"' + contentClassName + '\">\\n                        ' + title + '\\n                        ' + content + '\\n                      </div>\\n                    </div>\\n                  </dialog>';\n  }", "label": 3}
{"code": "function closeStreams(exitCode) {\n\t// default is 0 if not specified\n\texitCode = exitCode === undefined ? 0 : exitCode;\n\n\tif (streams.length) {\n\t\tstreams.forEach(function (logger) {\n\t\t\tlogger.write({ level: bunyan.TRACE, msg: util.format('exited with code %d', exitCode) });\n\t\t\tlogger.stream.end();\n\t\t\t// jscs:disable jsDoc\n\t\t\tlogger.write = function () {};\n\t\t});\n\t}\n}", "label": 3}
{"code": "func Init(dc driverapi.DriverCallback, config map[string]interface{}) error {\n\tc := driverapi.Capability{\n\t\tDataScope:         datastore.LocalScope,\n\t\tConnectivityScope: datastore.LocalScope,\n\t}\n\treturn dc.RegisterDriver(networkType, &driver{}, c)\n}", "label": 5}
{"code": "def add(o)\n      case o\n      when nil\n        raise Error, \"Cannot add '#{o.class}' to window!\"\n      when Array\n        o.each { |x| add_object(x) }\n      else\n        add_object(o)\n      end\n    end", "label": 4}
{"code": "public static function workflowTemplateName($project, $region, $workflowTemplate)\n    {\n        return self::getWorkflowTemplateNameTemplate()->render([\n            'project' => $project,\n            'region' => $region,\n            'workflow_template' => $workflowTemplate,\n        ]);\n    }", "label": 2}
{"code": "function isEmptyDir(dir) {\n  try {\n    return !(fs.readdirSync(dir).length > 0);\n  } catch (e) {\n    if (e.code === 'ENOENT') {\n      // We consider non-existent as empty\n      return true;\n    }\n    throw e;\n  }\n}", "label": 3}
{"code": "func (w *Wrapper) UpsertTunnelConnection(conn services.TunnelConnection) error {\n\treturn w.Write.UpsertTunnelConnection(conn)\n}", "label": 5}
{"code": "def file_path\n      directory_name = Rails.root.join(Decidim::DataPortabilityUploader.new.store_dir)\n      FileUtils.mkdir_p(directory_name) unless File.exist?(directory_name)\n      directory_name + file_name\n    end", "label": 4}
{"code": "public void putInWakeUpQueue(SerialMessage serialMessage) {\r\n\t\tif (this.wakeUpQueue.contains(serialMessage)) {\r\n\t\t\tlogger.debug(\"Message already on the wake-up queue for node {}. Discarding.\", this.getNode().getNodeId());\r\n\t\t\treturn;\r\n\t\t}\r\n\t\t\t\r\n\t\tlogger.debug(\"Putting message in wakeup queue for node {}.\", this.getNode().getNodeId());\r\n\t\tthis.wakeUpQueue.add(serialMessage);\r\n\t}", "label": 0}
{"code": "def get_dbs(self, attr, args, kwargs, **fkwargs):\n        \"\"\"\n        Returns a list of db keys to route the given call to.\n\n        :param attr: Name of attribute being called on the connection.\n        :param args: List of arguments being passed to ``attr``.\n        :param kwargs: Dictionary of keyword arguments being passed to ``attr``.\n\n        >>> redis = Cluster(router=BaseRouter)\n        >>> router = redis.router\n        >>> router.get_dbs('incr', args=('key name', 1))\n        [0,1,2]\n\n        \"\"\"\n        if not self._ready:\n            if not self.setup_router(args=args, kwargs=kwargs, **fkwargs):\n                raise self.UnableToSetupRouter()\n\n        retval = self._pre_routing(attr=attr, args=args, kwargs=kwargs, **fkwargs)\n        if retval is not None:\n            args, kwargs = retval\n\n        if not (args or kwargs):\n            return self.cluster.hosts.keys()\n\n        try:\n            db_nums = self._route(attr=attr, args=args, kwargs=kwargs, **fkwargs)\n        except Exception as e:\n            self._handle_exception(e)\n            db_nums = []\n\n        return self._post_routing(attr=attr, db_nums=db_nums, args=args, kwargs=kwargs, **fkwargs)", "label": 1}
{"code": "func NewMockMatcher(ctrl *gomock.Controller) *MockMatcher {\n\tmock := &MockMatcher{ctrl: ctrl}\n\tmock.recorder = &MockMatcherMockRecorder{mock}\n\treturn mock\n}", "label": 5}
{"code": "func (f *DatastoreFile) Seek(offset int64, whence int) (int64, error) {\n\tswitch whence {\n\tcase io.SeekStart:\n\tcase io.SeekCurrent:\n\t\toffset += f.offset.seek\n\tcase io.SeekEnd:\n\t\tif f.length < 0 {\n\t\t\t_, err := f.Stat()\n\t\t\tif err != nil {\n\t\t\t\treturn 0, err\n\t\t\t}\n\t\t}\n\t\toffset += f.length\n\tdefault:\n\t\treturn 0, errors.New(\"Seek: invalid whence\")\n\t}\n\n\t// allow negative SeekStart for initial Range request\n\tif offset < 0 {\n\t\treturn 0, errors.New(\"Seek: invalid offset\")\n\t}\n\n\tf.offset.seek = offset\n\n\treturn offset, nil\n}", "label": 5}
{"code": "func (sink *influxdbSink) aggregationFunc(aggregationName core.AggregationType, fieldName string) string {\n\tswitch aggregationName {\n\tcase core.AggregationTypeAverage:\n\t\treturn fmt.Sprintf(\"MEAN(%q)\", fieldName)\n\tcase core.AggregationTypeMaximum:\n\t\treturn fmt.Sprintf(\"MAX(%q)\", fieldName)\n\tcase core.AggregationTypeMinimum:\n\t\treturn fmt.Sprintf(\"MIN(%q)\", fieldName)\n\tcase core.AggregationTypeMedian:\n\t\treturn fmt.Sprintf(\"MEDIAN(%q)\", fieldName)\n\tcase core.AggregationTypeCount:\n\t\treturn fmt.Sprintf(\"COUNT(%q)\", fieldName)\n\tcase core.AggregationTypePercentile50:\n\t\treturn fmt.Sprintf(\"PERCENTILE(%q, 50)\", fieldName)\n\tcase core.AggregationTypePercentile95:\n\t\treturn fmt.Sprintf(\"PERCENTILE(%q, 95)\", fieldName)\n\tcase core.AggregationTypePercentile99:\n\t\treturn fmt.Sprintf(\"PERCENTILE(%q, 99)\", fieldName)\n\t}\n\n\t// This should have been checked by the API level, so something's seriously wrong here\n\tpanic(fmt.Sprintf(\"Unknown aggregation type %q\", aggregationName))\n}", "label": 5}
{"code": "def seq_contains_sel_class?(seq, selector_class)\n      seq.members.any? do |simple|\n        simple.is_a?(selector_class)\n      end\n    end", "label": 4}
{"code": "func NewClient(c *Config) (tc *TeleportClient, err error) {\n\t// validate configuration\n\tif c.Username == \"\" {\n\t\tc.Username, err = Username()\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tlog.Infof(\"No teleport login given. defaulting to %s\", c.Username)\n\t}\n\tif c.WebProxyAddr == \"\" {\n\t\treturn nil, trace.BadParameter(\"No proxy address specified, missed --proxy flag?\")\n\t}\n\tif c.HostLogin == \"\" {\n\t\tc.HostLogin, err = Username()\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tlog.Infof(\"no host login given. defaulting to %s\", c.HostLogin)\n\t}\n\tif c.KeyTTL == 0 {\n\t\tc.KeyTTL = defaults.CertDuration\n\t}\n\tc.Namespace = services.ProcessNamespace(c.Namespace)\n\n\ttc = &TeleportClient{Config: *c}\n\n\tif tc.Stdout == nil {\n\t\ttc.Stdout = os.Stdout\n\t}\n\tif tc.Stderr == nil {\n\t\ttc.Stderr = os.Stderr\n\t}\n\tif tc.Stdin == nil {\n\t\ttc.Stdin = os.Stdin\n\t}\n\n\t// Create a buffered channel to hold events that occurred during this session.\n\t// This channel must be buffered because the SSH connection directly feeds\n\t// into it. Delays in pulling messages off the global SSH request channel\n\t// could lead to the connection hanging.\n\ttc.eventsCh = make(chan events.EventFields, 1024)\n\n\t// Create a client that can be used for the initial fetch of credentials.\n\ttc.credClient, err = NewCredentialsClient(\n\t\tc.WebProxyAddr,\n\t\tc.InsecureSkipVerify,\n\t\tloopbackPool(c.WebProxyAddr))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// sometimes we need to use external auth without using local auth\n\t// methods, e.g. in automation daemons\n\tif c.SkipLocalAuth {\n\t\tif len(c.AuthMethods) == 0 {\n\t\t\treturn nil, trace.BadParameter(\"SkipLocalAuth is true but no AuthMethods provided\")\n\t\t}\n\t\t// if the client was passed an agent in the configuration and skip local auth, use\n\t\t// the passed in agent.\n\t\tif c.Agent != nil {\n\t\t\ttc.localAgent = &LocalKeyAgent{Agent: c.Agent}\n\t\t}\n\t} else {\n\t\t// initialize the local agent (auth agent which uses local SSH keys signed by the CA):\n\t\twebProxyHost, _ := tc.WebProxyHostPort()\n\t\ttc.localAgent, err = NewLocalAgent(c.KeysDir, webProxyHost, c.Username)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tif tc.HostKeyCallback == nil {\n\t\t\ttc.HostKeyCallback = tc.localAgent.CheckHostSignature\n\t\t}\n\t}\n\n\treturn tc, nil\n}", "label": 5}
{"code": "function(){\r\n      var self = this; // stored this\r\n      // Handle submit event\r\n      $( this.form ).submit( function( e ) {\r\n        // fields to be controlled transferred to global variable\r\n        FIELDS = this.querySelectorAll('[data-validetta]');\r\n        return self.init( e );\r\n      });\r\n      // real-time option control\r\n      if( this.options.realTime === true ) {\r\n        // handle change event for form elements (without checkbox)\r\n        $( this.form ).find('[data-validetta]').not('[type=checkbox]').on( 'change', function( e ) {\r\n          // field to be controlled transferred to global variable\r\n          FIELDS = $( this );\r\n          return self.init( e );\r\n        });\r\n        // handle click event for checkboxes\r\n        $( this.form ).find('[data-validetta][type=checkbox]').on( 'click', function( e ) {\r\n          // fields to be controlled transferred to global variable\r\n          FIELDS = self.form.querySelectorAll('[data-validetta][type=checkbox][name=\"'+ this.name +'\"]');\r\n          return self.init( e );\r\n        });\r\n      }\r\n      // handle <form> reset button to clear error messages\r\n      $( this.form ).on( 'reset', function() {\r\n        $( self.form.querySelectorAll( '.'+ self.options.errorClass +', .'+ self.options.validClass ) )\r\n          .removeClass( self.options.errorClass +' '+ self.options.validClass );\r\n        return self.reset();\r\n      });\r\n    }", "label": 3}
{"code": "public static base_response add(nitro_service client, dospolicy resource) throws Exception {\n\t\tdospolicy addresource = new dospolicy();\n\t\taddresource.name = resource.name;\n\t\taddresource.qdepth = resource.qdepth;\n\t\taddresource.cltdetectrate = resource.cltdetectrate;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "public function setImagePropertiesAnnotation($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\ImageProperties::class);\n        $this->image_properties_annotation = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "function render(drizzleData) {\n  return Promise.all([\n    renderPages(drizzleData),\n    renderCollections(drizzleData)\n  ]).then(\n    allData => {\n      return {\n        data: drizzleData.data,\n        pages: allData[0],\n        patterns: allData[1],\n        templates: drizzleData.templates,\n        options: drizzleData.options,\n        tree: drizzleData.tree\n      };\n    },\n    error => DrizzleError.error(error, drizzleData.options.debug)\n  );\n}", "label": 3}
{"code": "public void addForeignkey(String relationName, String remoteTable, List localColumns, List remoteColumns)\r\n    {\r\n        ForeignkeyDef foreignkeyDef = new ForeignkeyDef(relationName, remoteTable);\r\n\r\n        // the field arrays have the same length if we already checked the constraints\r\n        for (int idx = 0; idx < localColumns.size(); idx++)\r\n        {\r\n            foreignkeyDef.addColumnPair((String)localColumns.get(idx),\r\n                                        (String)remoteColumns.get(idx));\r\n        }\r\n\r\n        // we got to determine whether this foreignkey is already present \r\n        ForeignkeyDef def = null;\r\n\r\n        for (Iterator it = getForeignkeys(); it.hasNext();)\r\n        {\r\n            def = (ForeignkeyDef)it.next();\r\n            if (foreignkeyDef.equals(def))\r\n            {\r\n                return;\r\n            }\r\n        }\r\n        foreignkeyDef.setOwner(this);\r\n        _foreignkeys.add(foreignkeyDef);\r\n    }", "label": 0}
{"code": "public function setWindow($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Asset\\V1\\TimeWindow::class);\n        $this->window = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def write_pretty_dict_str(out, obj, indent=2):\n    \"\"\"writes JSON indented representation of `obj` to `out`\"\"\"\n    json.dump(obj,\n              out,\n              indent=indent,\n              sort_keys=True,\n              separators=(',', ': '),\n              ensure_ascii=False,\n              encoding=\"utf-8\")", "label": 1}
{"code": "def dynflow_handled_last_sync?(pulp_task_id)\n      task = ForemanTasks::Task::DynflowTask.for_action(::Actions::Katello::Repository::Sync).\n          for_resource(self).order(:started_at).last\n      return task && task.main_action.pulp_task_id == pulp_task_id\n    end", "label": 4}
{"code": "function lagrange(at, x, y){\n\tvar sum = 0,\n\t\tproduct, \n\t\ti, j;\n\t\t\n\tfor(var i=0, len = x.length; i<len; i++){\n\t\tif(!y[i]){\n\t\t\tcontinue; \n\t\t}\n\t\t\t\n\t\tproduct = config.logs[y[i]];\n\t\tfor(var j=0; j<len; j++){\n\t\t\tif(i === j){ continue; }\n\t\t\tif(at === x[j]){ // happens when computing a share that is in the list of shares used to compute it\n\t\t\t\tproduct = -1; // fix for a zero product term, after which the sum should be sum^0 = sum, not sum^1\n\t\t\t\tbreak; \n\t\t\t}\n\t\t\tproduct = ( product + config.logs[at ^ x[j]] - config.logs[x[i] ^ x[j]] + config.max/* to make sure it's not negative */ ) % config.max;\n\t\t}\n\t\t\t\n\t\tsum = product === -1 ? sum : sum ^ config.exps[product]; // though exps[-1]= undefined and undefined ^ anything = anything in chrome, this behavior may not hold everywhere, so do the check\n\t}\n\treturn sum;\n}", "label": 3}
{"code": "func DefaultCollector(c *vim25.Client) *Collector {\n\tp := Collector{\n\t\troundTripper: c,\n\t\treference:    c.ServiceContent.PropertyCollector,\n\t}\n\n\treturn &p\n}", "label": 5}
{"code": "func AcquireLock(ctx context.Context, backend Backend, lockName string, ttl time.Duration) (err error) {\n\tif lockName == \"\" {\n\t\treturn trace.BadParameter(\"missing parameter lock name\")\n\t}\n\tkey := []byte(filepath.Join(locksPrefix, lockName))\n\tfor {\n\t\t// Get will clear TTL on a lock\n\t\tbackend.Get(ctx, key)\n\n\t\t// CreateVal is atomic:\n\t\t_, err = backend.Create(ctx, Item{Key: key, Value: []byte{1}, Expires: backend.Clock().Now().UTC().Add(ttl)})\n\t\tif err == nil {\n\t\t\tbreak // success\n\t\t}\n\t\tif trace.IsAlreadyExists(err) { // locked? wait and repeat:\n\t\t\tbackend.Clock().Sleep(250 * time.Millisecond)\n\t\t\tcontinue\n\t\t}\n\t\treturn trace.ConvertSystemError(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public static sslglobal_sslpolicy_binding[] get(nitro_service service) throws Exception{\n\t\tsslglobal_sslpolicy_binding obj = new sslglobal_sslpolicy_binding();\n\t\tsslglobal_sslpolicy_binding response[] = (sslglobal_sslpolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def interact(self, ctx, location, ir_err):\n        '''Implement Interactor.interact by opening the browser window\n        and waiting for the discharge token'''\n        p = ir_err.interaction_method(self.kind(), WebBrowserInteractionInfo)\n        if not location.endswith('/'):\n            location += '/'\n        visit_url = urljoin(location, p.visit_url)\n        wait_token_url = urljoin(location, p.wait_token_url)\n        self._open_web_browser(visit_url)\n        return self._wait_for_token(ctx, wait_token_url)", "label": 1}
{"code": "func (c *Client) RetrieveOne(ctx context.Context, obj types.ManagedObjectReference, p []string, dst interface{}) error {\n\treturn c.PropertyCollector().RetrieveOne(ctx, obj, p, dst)\n}", "label": 5}
{"code": "public void store(Object obj) throws PersistenceBrokerException\n    {\n        obj = extractObjectToStore(obj);\n        // only do something if obj != null\n        if(obj == null) return;\n\n        ClassDescriptor cld = getClassDescriptor(obj.getClass());\n        /*\n        if one of the PK fields was null, we assume the objects\n        was new and needs insert\n        */\n        boolean insert = serviceBrokerHelper().hasNullPKField(cld, obj);\n        Identity oid = serviceIdentity().buildIdentity(cld, obj);\n        /*\n        if PK values are set, lookup cache or db to see whether object\n        needs insert or update\n        */\n        if (!insert)\n        {\n            insert = objectCache.lookup(oid) == null\n                && !serviceBrokerHelper().doesExist(cld, oid, obj);\n        }\n        store(obj, oid, cld, insert);\n    }", "label": 0}
{"code": "function $listModals() {\n    var node = arguments.length <= 0 || arguments[0] === undefined ? doc : arguments[0];\n    return [].slice.call(node.querySelectorAll('.' + MODAL_JS_CLASS));\n  }", "label": 3}
{"code": "public function setSupportedTiers($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::ENUM, \\Google\\Cloud\\Monitoring\\V3\\ServiceTier::class);\n        $this->supported_tiers = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "func (process *TeleportProcess) newLocalCache(clt auth.ClientI, setupConfig cache.SetupConfigFn, cacheName []string) (auth.AccessPoint, error) {\n\t// if caching is disabled, return access point\n\tif !process.Config.CachePolicy.Enabled {\n\t\treturn clt, nil\n\t}\n\tcache, err := process.newAccessCache(accessCacheConfig{\n\t\tservices:  clt,\n\t\tsetup:     process.setupCachePolicy(setupConfig),\n\t\tcacheName: cacheName,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn auth.NewWrapper(clt, cache), nil\n}", "label": 5}
{"code": "def each_remote_read_then_finish\n      return enum_for(:each_remote_read_then_finish) unless block_given?\n      loop do\n        resp =\n          begin\n            remote_read\n          rescue GRPC::Core::CallError => e\n            GRPC.logger.warn(\"In each_remote_read_then_finish: #{e}\")\n            nil\n          end\n\n        break if resp.nil?  # the last response was received\n        yield resp\n      end\n\n      receive_and_check_status\n    ensure\n      set_input_stream_done\n    end", "label": 4}
{"code": "function(whereProperties, whereValue, whereEquals)\n  {\n    var where = createWhere( whereProperties, whereValue, whereEquals );\n\n    for (var i = 0; i < this.length; i++)\n    {\n      var model = this[ i ];\n\n      if ( where( model ) )\n      {\n        return model;\n      }\n    }\n\n    return null;\n  }", "label": 3}
{"code": "def kill(self, task_id):\n        \"\"\"Kills the specified task.\n\n        Note that attempting to kill a task is currently not reliable.\n        If, for example, a scheduler fails over while it was attempting to kill\n        a task it will need to retry in the future.\n        Likewise, if unregistered / disconnected, the request will be dropped\n        (these semantics may be changed in the future).\n        \"\"\"\n        logging.info('Kills task {}'.format(task_id))\n        return self.driver.killTask(encode(task_id))", "label": 1}
{"code": "func (t *Text) calcX(width, line int) int {\n\tif t.align&HAlignCenter != 0 {\n\t\treturn (width - t.lengths[line]) / 2\n\t}\n\tif t.align&HAlignRight != 0 {\n\t\treturn width - t.lengths[line]\n\t}\n\treturn 0\n}", "label": 5}
{"code": "function getFormDataSources(formJSON) {\n    var dataSources;\n    var pages = formJSON.pages || [];\n    dataSources = _.map(pages, function(page) {\n      var fields = page.fields || [];\n\n      fields = _.map(fields, function(field) {\n        //If the field is defined as a Data Source field, and it has a data source, then return that data source.\n        if (field.dataSourceType === models.FORM_CONSTANTS.DATA_SOURCE_TYPE_DATA_SOURCE && field.dataSource) {\n          return field.dataSource;\n        } else {\n          return undefined;\n        }\n      });\n\n      //Removing any undefined values\n      return _.compact(fields);\n    });\n\n    //Remove all nested arrays\n    dataSources = _.flatten(dataSources);\n\n    logger.debug(\"Got Form Data Sources\", dataSources);\n\n    //Only Want One Of Each Data Source\n    return _.uniq(dataSources);\n  }", "label": 3}
{"code": "function prepend(file, text, options) {\n  options = _.sanitize(options, {encoding: 'utf-8'});\n  const encoding = options.encoding;\n  if (!exists(file)) {\n    write(file, text, {encoding: encoding});\n  } else {\n    const currentText = read(file, {encoding: encoding});\n    write(file, text + currentText, {encoding: encoding});\n  }\n}", "label": 3}
{"code": "function deleteUser(user) {\n  if (!runningAsRoot()) return;\n  if (!user) throw new Error('You must provide an username');\n  if (!userExists(user)) {\n    return;\n  }\n  const userdelBin = _safeLocateBinary('userdel');\n  const deluserBin = _safeLocateBinary('deluser');\n\n  if (isPlatform('linux')) {\n    if (userdelBin !== null) { // most modern systems\n      runProgram(userdelBin, [user]);\n    } else {\n      if (_isBusyboxBinary(deluserBin)) { // busybox-based systems\n        runProgram(deluserBin, [user]);\n      } else {\n        throw new Error(`Don't know how to delete user ${user} on this strange linux`);\n      }\n    }\n  } else if (isPlatform('osx')) {\n    runProgram('dscl', ['.', '-delete', `/Users/${user}`]);\n  } else if (isPlatform('windows')) {\n    throw new Error('Don\\'t know how to delete user in Windows');\n  } else {\n    throw new Error('Don\\'t know how to delete user in current platform');\n  }\n}", "label": 3}
{"code": "def request_version(req_headers):\n    ''' Determines the bakery protocol version from a client request.\n    If the protocol cannot be determined, or is invalid, the original version\n    of the protocol is used. If a later version is found, the latest known\n    version is used, which is OK because versions are backwardly compatible.\n\n    @param req_headers: the request headers as a dict.\n    @return: bakery protocol version (for example macaroonbakery.VERSION_1)\n    '''\n    vs = req_headers.get(BAKERY_PROTOCOL_HEADER)\n    if vs is None:\n        # No header - use backward compatibility mode.\n        return bakery.VERSION_1\n    try:\n        x = int(vs)\n    except ValueError:\n        # Badly formed header - use backward compatibility mode.\n        return bakery.VERSION_1\n    if x > bakery.LATEST_VERSION:\n        # Later version than we know about - use the\n        # latest version that we can.\n        return bakery.LATEST_VERSION\n    return x", "label": 1}
{"code": "protected function checkPreconditions(MultiBulk $iterator)\n    {\n        if ($iterator->getPosition() !== 0) {\n            throw new \\InvalidArgumentException(\n                'Cannot initialize a tuple iterator using an already initiated iterator.'\n            );\n        }\n\n        if (($size = count($iterator)) % 2 !== 0) {\n            throw new \\UnexpectedValueException('Invalid response size for a tuple iterator.');\n        }\n    }", "label": 2}
{"code": "def merge_radia(job, perchrom_rvs):\n    \"\"\"\n    This module will merge the per-chromosome radia files created by spawn_radia into a genome vcf.\n    It will make 2 vcfs, one for PASSing non-germline calls, and one for all calls.\n\n    ARGUMENTS\n    1. perchrom_rvs: REFER RETURN VALUE of spawn_radia()\n\n    RETURN VALUES\n    1. output_files: Dict of outputs\n            output_files\n                |- radia_calls.vcf: <JSid>\n                +- radia_parsed_filter_passing_calls.vcf: <JSid>\n\n    This module corresponds to node 11 on the tree\n    \"\"\"\n    job.fileStore.logToMaster('Running merge_radia')\n    work_dir = job.fileStore.getLocalTempDir()\n    # We need to squash the input dict of dicts to a single dict such that it can be passed to\n    # get_files_from_filestore\n    input_files = {filename: jsid for perchrom_files in perchrom_rvs.values()\n                   for filename, jsid in perchrom_files.items()}\n    input_files = get_files_from_filestore(job, input_files, work_dir,\n                                           docker=False)\n    chromosomes = [''.join(['chr', str(x)]) for x in range(1, 23) + ['X', 'Y']]\n    with open('/'.join([work_dir, 'radia_calls.vcf']), 'w') as radfile, \\\n            open('/'.join([work_dir, 'radia_filter_passing_calls.vcf']), 'w') as radpassfile:\n        for chrom in chromosomes:\n            with open(input_files[''.join(['radia_filtered_', chrom, '.vcf'])], 'r') as filtradfile:\n                for line in filtradfile:\n                    line = line.strip()\n                    if line.startswith('#'):\n                        if chrom == 'chr1':\n                            print(line, file=radfile)\n                            print(line, file=radpassfile)\n                        continue\n                    else:\n                        print(line, file=radfile)\n                        line = line.split('\\t')\n                        if line[6] == 'PASS' and 'MT=GERM' not in line[7]:\n                            print('\\t'.join(line), file=radpassfile)\n    # parse the PASS radia vcf for multiple alt alleles\n    with open(radpassfile.name, 'r') as radpassfile, \\\n            open('/'.join([work_dir, 'radia_parsed_filter_passing_calls.vcf']),\n                 'w') as parsedradfile:\n        parse_radia_multi_alt(radpassfile, parsedradfile)\n    output_files = defaultdict()\n    for radia_file in [radfile.name, parsedradfile.name]:\n        output_files[os.path.basename(radia_file)] = job.fileStore.writeGlobalFile(radia_file)\n    return output_files", "label": 1}
{"code": "def extract_separator\n      if meta_tags[:separator] == false\n        # Special case: if separator is hidden, do not display suffix/prefix\n        prefix = separator = suffix = ''\n      else\n        prefix    = extract_separator_section(:prefix, ' ')\n        separator = extract_separator_section(:separator, '|')\n        suffix    = extract_separator_section(:suffix, ' ')\n      end\n      delete(:separator, :prefix, :suffix)\n\n      TextNormalizer.safe_join([prefix, separator, suffix], '')\n    end", "label": 4}
{"code": "public static base_response add(nitro_service client, ipset resource) throws Exception {\n\t\tipset addresource = new ipset();\n\t\taddresource.name = resource.name;\n\t\taddresource.td = resource.td;\n\t\treturn addresource.add_resource(client);\n\t}", "label": 0}
{"code": "func runInDir(program []byte, dir string) (*model.Package, error) {\n\t// We use TempDir instead of TempFile so we can control the filename.\n\ttmpDir, err := ioutil.TempDir(dir, \"gomock_reflect_\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif err := os.RemoveAll(tmpDir); err != nil {\n\t\t\tlog.Printf(\"failed to remove temp directory: %s\", err)\n\t\t}\n\t}()\n\tconst progSource = \"prog.go\"\n\tvar progBinary = \"prog.bin\"\n\tif runtime.GOOS == \"windows\" {\n\t\t// Windows won't execute a program unless it has a \".exe\" suffix.\n\t\tprogBinary += \".exe\"\n\t}\n\n\tif err := ioutil.WriteFile(filepath.Join(tmpDir, progSource), program, 0600); err != nil {\n\t\treturn nil, err\n\t}\n\n\tcmdArgs := []string{}\n\tcmdArgs = append(cmdArgs, \"build\")\n\tif *buildFlags != \"\" {\n\t\tcmdArgs = append(cmdArgs, *buildFlags)\n\t}\n\tcmdArgs = append(cmdArgs, \"-o\", progBinary, progSource)\n\n\t// Build the program.\n\tcmd := exec.Command(\"go\", cmdArgs...)\n\tcmd.Dir = tmpDir\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tif err := cmd.Run(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn run(filepath.Join(tmpDir, progBinary))\n}", "label": 5}
{"code": "public function setDescription($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Debugger\\V2\\FormatMessage::class);\n        $this->description = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (*TeleportCertAuthorityMarshaler) UnmarshalCertAuthority(bytes []byte, opts ...MarshalOption) (CertAuthority, error) {\n\tcfg, err := collectOptions(opts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tvar h ResourceHeader\n\terr = utils.FastUnmarshal(bytes, &h)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch h.Version {\n\tcase \"\":\n\t\tvar ca CertAuthorityV1\n\t\terr := json.Unmarshal(bytes, &ca)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn ca.V2(), nil\n\tcase V2:\n\t\tvar ca CertAuthorityV2\n\t\tif cfg.SkipValidation {\n\t\t\tif err := utils.FastUnmarshal(bytes, &ca); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t} else {\n\t\t\tif err := utils.UnmarshalWithSchema(GetCertAuthoritySchema(), &ca, bytes); err != nil {\n\t\t\t\treturn nil, trace.BadParameter(err.Error())\n\t\t\t}\n\t\t}\n\t\tif err := ca.CheckAndSetDefaults(); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tif cfg.ID != 0 {\n\t\t\tca.SetResourceID(cfg.ID)\n\t\t}\n\t\treturn &ca, nil\n\t}\n\n\treturn nil, trace.BadParameter(\"cert authority resource version %v is not supported\", h.Version)\n}", "label": 5}
{"code": "def select_dict(conn, query: str, params=None, name=None, itersize=5000):\n    \"\"\"Return a select statement's results as dictionary.\n\n    Parameters\n    ----------\n    conn : database connection\n    query : select query string\n    params : query parameters.\n    name : server side cursor name. defaults to client side.\n    itersize : number of records fetched by server.\n    \"\"\"\n\n    with conn.cursor(name, cursor_factory=RealDictCursor) as cursor:\n        cursor.itersize = itersize\n        cursor.execute(query, params)\n\n        for result in cursor:\n            yield result", "label": 1}
{"code": "func MetadataServicePublicURL(ip net.IP, token string) string {\n\treturn fmt.Sprintf(\"http://%v:%v/%v\", ip, MetadataServicePort, token)\n}", "label": 5}
{"code": "protected function populateRoutes(RouteCollection $routes)\n    {\n        $factory = $this->app->make(RouteHandlerFactory::class);\n\n        $callback = include __DIR__.'/routes.php';\n        $callback($routes, $factory);\n\n        $this->app->make('events')->fire(\n            new ConfigureApiRoutes($routes, $factory)\n        );\n    }", "label": 2}
{"code": "public static function replacePatternWithKeyword(array $subject, $keyword, $pattern = '$1')\n    {\n        $parameters = [];\n        foreach ($subject as $param) {\n            if (is_array($param)) {\n                $parameters[] = self::replacePatternWithKeyword($param, $keyword, $pattern);\n            } else {\n                $parameters[] = str_replace($pattern, $keyword, $param);\n            }\n        }\n\n        return $parameters;\n    }", "label": 2}
{"code": "public function setPlatform($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Dialogflow\\V2\\Intent_Message_Platform::class);\n        $this->platform = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def encrypt(attribute, value)\n      encrypted_attributes[attribute.to_sym][:operation] = :encrypting\n      encrypted_attributes[attribute.to_sym][:value_present] = self.class.not_empty?(value)\n      self.class.encrypt(attribute, value, evaluated_attr_encrypted_options_for(attribute))\n    end", "label": 4}
{"code": "function loadConfig(justJson) {\n    if (!justJson) {\n        const configScript = path.resolve(currentDir, configScriptFileName);\n        if (fs.existsSync(configScript)) {\n            return require(configScript);\n        }\n    }\n\n    const configJson = path.resolve(currentDir, configJsonFileName);\n    if (fs.existsSync(configJson)) {\n        return require(configJson);\n    }\n\n    const errorMessage = [\n        `Specify a ${configScriptFileName} or ${configJsonFileName} file to configure the swagen tool.`,\n        ``,\n        `To create a configuration file in the current directory, use the following command:`,\n        ``,\n        `    swagen init`,\n        ``,\n        `This will ask you a series of questions and generate a configuration file based on your answers.`\n    ].join(os.EOL);\n    throw errorMessage;\n}", "label": 3}
{"code": "public static snmpcommunity get(nitro_service service, String communityname) throws Exception{\n\t\tsnmpcommunity obj = new snmpcommunity();\n\t\tobj.set_communityname(communityname);\n\t\tsnmpcommunity response = (snmpcommunity) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getDeclarationParent(path) {\n  do {\n    if (\n      path.isFunctionDeclaration() ||\n      path.isVariableDeclaration() ||\n      path.isClassDeclaration() ||\n      path.isAssignmentExpression()\n    ) {\n      return path;\n    }\n  } while ((path = path.parentPath));\n}", "label": 3}
{"code": "def validate\n      return if !!@validation_deferred\n      if self.scheme != nil && self.ip_based? &&\n          (self.host == nil || self.host.empty?) &&\n          (self.path == nil || self.path.empty?)\n        raise InvalidURIError,\n          \"Absolute URI missing hierarchical segment: '#{self.to_s}'\"\n      end\n      if self.host == nil\n        if self.port != nil ||\n            self.user != nil ||\n            self.password != nil\n          raise InvalidURIError, \"Hostname not supplied: '#{self.to_s}'\"\n        end\n      end\n      if self.path != nil && !self.path.empty? && self.path[0..0] != SLASH &&\n          self.authority != nil\n        raise InvalidURIError,\n          \"Cannot have a relative path with an authority set: '#{self.to_s}'\"\n      end\n      if self.path != nil && !self.path.empty? &&\n          self.path[0..1] == SLASH + SLASH && self.authority == nil\n        raise InvalidURIError,\n          \"Cannot have a path with two leading slashes \" +\n          \"without an authority set: '#{self.to_s}'\"\n      end\n      unreserved = CharacterClasses::UNRESERVED\n      sub_delims = CharacterClasses::SUB_DELIMS\n      if !self.host.nil? && (self.host =~ /[<>{}\\/\\\\\\?\\#\\@\"[[:space:]]]/ ||\n          (self.host[/^\\[(.*)\\]$/, 1] != nil && self.host[/^\\[(.*)\\]$/, 1] !~\n          Regexp.new(\"^[#{unreserved}#{sub_delims}:]*$\")))\n        raise InvalidURIError, \"Invalid character in host: '#{self.host.to_s}'\"\n      end\n      return nil\n    end", "label": 4}
{"code": "function _gpfClassSuperCreateWeakBoundWithSameSignature (that, $super, superMethod) {\n    var definition = _gpfFunctionDescribe(superMethod);\n    definition.body = \"return _superMethod_.apply(this === _$super_ ? _that_ : this, arguments);\";\n    return _gpfFunctionBuild(definition, {\n        _that_: that,\n        _$super_: $super,\n        _superMethod_: superMethod\n    });\n}", "label": 3}
{"code": "function (event) {\n            var\n                eventsHandler;\n            if (event\n                && event.type() === _gpfI.IWritableStream.EVENT_ERROR) {\n                gpfFireEvent.call(this, event, this._eventsHandler);\n            } else if (0 === this._buffer.length) {\n                eventsHandler = this._eventsHandler;\n                this._eventsHandler = null;\n                gpfFireEvent.call(this, _gpfI.IWritableStream.EVENT_READY, eventsHandler);\n            } else {\n                this._stream.write(this._buffer.shift(), this._flushed.bind(this));\n            }\n        }", "label": 3}
{"code": "func (f *Fpdf) escape(s string) string {\n\ts = strings.Replace(s, \"\\\\\", \"\\\\\\\\\", -1)\n\ts = strings.Replace(s, \"(\", \"\\\\(\", -1)\n\ts = strings.Replace(s, \")\", \"\\\\)\", -1)\n\ts = strings.Replace(s, \"\\r\", \"\\\\r\", -1)\n\treturn s\n}", "label": 5}
{"code": "function _gpfTriggerListeners (eventObj, eventListeners) {\n    var index,\n        length = eventListeners.length;\n    for (index = 0; index < length; ++index) {\n        _gpfEventsFire.call(eventObj.scope, eventObj, {}, eventListeners[index]);\n    }\n}", "label": 3}
{"code": "def next(self):\n        \"\"\"\n        Returns the next element or raises ``StopIteration`` if stopped.\n        \"\"\"\n        # need new iterable?\n        if self.r == self.repeats:\n            self.i = (self.i + 1) % self.lenght\n            self.r = 0\n\n        self.r += 1\n        if self.stopping and self.i == 0 and self.r == 1:\n            self.stopped = True\n        if self.i == 0 and self.stopped:\n            raise StopIteration\n        else:\n            iterator = self.iterators[self.i]\n            return iterator.next()", "label": 1}
{"code": "def find_studies(self, query_dict=None, exact=False, verbose=False, **kwargs):\n        \"\"\"Query on study properties. See documentation for _OTIWrapper class.\"\"\"\n        if self.use_v1:\n            uri = '{p}/singlePropertySearchForStudies'.format(p=self.query_prefix)\n        else:\n            uri = '{p}/find_studies'.format(p=self.query_prefix)\n        return self._do_query(uri,\n                              query_dict=query_dict,\n                              exact=exact,\n                              verbose=verbose,\n                              valid_keys=self.study_search_term_set,\n                              kwargs=kwargs)", "label": 1}
{"code": "def upload_file(self, path=None, stream=None, name=None, **kwargs):\n        \"\"\"\n        Uploads file to WeedFS\n\n        I takes either path or stream and name and upload it\n        to WeedFS server.\n\n        Returns fid of the uploaded file.\n\n        :param string path:\n        :param string stream:\n        :param string name:\n        :rtype: string or None\n\n        \"\"\"\n        params = \"&\".join([\"%s=%s\" % (k, v) for k, v in kwargs.items()])\n        url = \"http://{master_addr}:{master_port}/dir/assign{params}\".format(\n            master_addr=self.master_addr,\n            master_port=self.master_port,\n            params=\"?\" + params if params else ''\n        )\n        data = json.loads(self.conn.get_data(url))\n        if data.get(\"error\") is not None:\n            return None\n        post_url = \"http://{url}/{fid}\".format(\n            url=data['publicUrl' if self.use_public_url else 'url'],\n            fid=data['fid']\n        )\n\n        if path is not None:\n            filename = os.path.basename(path)\n            with open(path, \"rb\") as file_stream:\n                res = self.conn.post_file(post_url, filename, file_stream)\n        # we have file like object and filename\n        elif stream is not None and name is not None:\n            res = self.conn.post_file(post_url, name, stream)\n        else:\n            raise ValueError(\n                \"If `path` is None then *both* `stream` and `name` must not\"\n                \" be None \")\n        response_data = json.loads(res)\n        if \"size\" in response_data:\n            return data.get('fid')\n        return None", "label": 1}
{"code": "def normalize_header(name)\n      return name if name =~ CANONICAL_NAME_RE\n\n      normalized = name.split(/[\\-_]/).each(&:capitalize!).join(\"-\")\n\n      return normalized if normalized =~ COMPLIANT_NAME_RE\n\n      raise HeaderError, \"Invalid HTTP header field name: #{name.inspect}\"\n    end", "label": 4}
{"code": "public static base_response update(nitro_service client, clusternodegroup resource) throws Exception {\n\t\tclusternodegroup updateresource = new clusternodegroup();\n\t\tupdateresource.name = resource.name;\n\t\tupdateresource.strict = resource.strict;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "def setup_desktop():\n    '''Run setup tasks to set up a nicely configured desktop pc.\n\n    This is highly biased on my personal preference.\n\n    The task is defined in file fabsetup_custom/fabfile_addtitions/__init__.py\n    and could be customized by Your own needs.  More info: README.md\n    '''\n    run('sudo apt-get update')\n    install_packages(packages_desktop)\n    execute(custom.latex)\n    execute(setup.ripping_of_cds)\n    execute(setup.regex_repl)\n    execute(setup.i3)\n    execute(setup.solarized)\n    execute(setup.vim)\n    execute(setup.tmux)\n    execute(setup.pyenv)\n    # circumvent circular import, cf. http://stackoverflow.com/a/18486863\n    from fabfile import dfh, check_reboot\n    dfh()\n    check_reboot()", "label": 1}
{"code": "func (s *Service) Start() error {\n\terr := s.startChannel()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ts.wg.Add(1)\n\tgo func() {\n\t\tdefer s.wg.Done()\n\n\t\t// Same polling interval and backoff logic as vmtoolsd.\n\t\t// Required in our case at startup at least, otherwise it is possible\n\t\t// we miss the 1 Capabilities_Register call for example.\n\n\t\t// Note we Send(response) even when nil, to let the VMX know we are here\n\t\tvar response []byte\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-s.stop:\n\t\t\t\ts.stopChannel()\n\t\t\t\treturn\n\t\t\tcase <-time.After(time.Millisecond * 10 * s.delay):\n\t\t\t\tif err = s.checkReset(); err != nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\terr = s.in.Send(response)\n\t\t\t\tresponse = nil\n\t\t\t\tif err != nil {\n\t\t\t\t\ts.delay = resetDelay\n\t\t\t\t\ts.rpcError = true\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\trequest, _ := s.in.Receive()\n\n\t\t\t\tif len(request) > 0 {\n\t\t\t\t\tresponse = s.Dispatch(request)\n\n\t\t\t\t\ts.delay = 0\n\t\t\t\t} else {\n\t\t\t\t\ts.backoff()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn nil\n}", "label": 5}
{"code": "public static int longestCommonContiguousSubstring(String s, String t) {\r\n    if (s.length() == 0 || t.length() == 0) {\r\n      return 0;\r\n    }\r\n    int M = s.length();\r\n    int N = t.length();\r\n    int[][] d = new int[M + 1][N + 1];\r\n    for (int j = 0; j <= N; j++) {\r\n      d[0][j] = 0;\r\n    }\r\n    for (int i = 0; i <= M; i++) {\r\n      d[i][0] = 0;\r\n    }\r\n\r\n    int max = 0;\r\n    for (int i = 1; i <= M; i++) {\r\n      for (int j = 1; j <= N; j++) {\r\n        if (s.charAt(i - 1) == t.charAt(j - 1)) {\r\n          d[i][j] = d[i - 1][j - 1] + 1;\r\n        } else {\r\n          d[i][j] = 0;\r\n        }\r\n\r\n        if (d[i][j] > max) {\r\n          max = d[i][j];\r\n        }\r\n      }\r\n    }\r\n    // System.err.println(\"LCCS(\" + s + \",\" + t + \") = \" + max);\r\n    return max;\r\n  }", "label": 0}
{"code": "func (v mergeVal) Name() string {\n\ttype namedValue interface {\n\t\tName() string\n\t}\n\tif nVal, ok := v.Value.(namedValue); ok {\n\t\treturn nVal.Name()\n\t}\n\treturn v.key\n}", "label": 5}
{"code": "public static base_response unset(nitro_service client, Interface resource, String[] args) throws Exception{\n\t\tInterface unsetresource = new Interface();\n\t\tunsetresource.id = resource.id;\n\t\treturn unsetresource.unset_resource(client,args);\n\t}", "label": 0}
{"code": "def parse(data)\n      if !data.respond_to?(:read)\n        data = StringIO.new(data || \"\")\n      end\n\n      if data.eof?\n        {}\n      else\n        silence_warnings { require \"rexml/document\" } unless defined?(REXML::Document)\n        doc = REXML::Document.new(data)\n\n        if doc.root\n          merge_element!({}, doc.root, XmlMini.depth)\n        else\n          raise REXML::ParseException,\n            \"The document #{doc.to_s.inspect} does not have a valid root\"\n        end\n      end\n    end", "label": 4}
{"code": "public static function alertPolicyConditionName($project, $alertPolicy, $condition)\n    {\n        return self::getAlertPolicyConditionNameTemplate()->render([\n            'project' => $project,\n            'alert_policy' => $alertPolicy,\n            'condition' => $condition,\n        ]);\n    }", "label": 2}
{"code": "public static base_response apply(nitro_service client) throws Exception {\n\t\tnspbr6 applyresource = new nspbr6();\n\t\treturn applyresource.perform_operation(client,\"apply\");\n\t}", "label": 0}
{"code": "def normalized_host\n      return nil unless self.host\n      @normalized_host ||= begin\n        if !self.host.strip.empty?\n          result = ::Addressable::IDNA.to_ascii(\n            URI.unencode_component(self.host.strip.downcase)\n          )\n          if result =~ /[^\\.]\\.$/\n            # Single trailing dots are unnecessary.\n            result = result[0...-1]\n          end\n          result = Addressable::URI.normalize_component(\n            result,\n            CharacterClasses::HOST)\n          result\n        else\n          EMPTY_STR.dup\n        end\n      end\n      # All normalized values should be UTF-8\n      @normalized_host.force_encoding(Encoding::UTF_8) if @normalized_host\n      @normalized_host\n    end", "label": 4}
{"code": "def collect_children\n      children = []\n      embedded_relations.each_pair do |name, association|\n        without_autobuild do\n          child = send(name)\n          Array.wrap(child).each do |doc|\n            children.push(doc)\n            children.concat(doc._children)\n          end if child\n        end\n      end\n      children\n    end", "label": 4}
{"code": "def template_content\n      if File.file?(@template_file) && File.readable?(@template_file)\n        return File.read(@template_file)\n      end\n\n      raise ArgumentError, _(\"'%{template}' is not a readable file\") % { template: @template_file }\n    end", "label": 4}
{"code": "public static transformpolicylabel get(nitro_service service, String labelname) throws Exception{\n\t\ttransformpolicylabel obj = new transformpolicylabel();\n\t\tobj.set_labelname(labelname);\n\t\ttransformpolicylabel response = (transformpolicylabel) obj.get_resource(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "function getObjStoresMeta(db, objStoreNames) {\n    const dbMeta = objStoresMeta.get(db.name);\n    const promises = [];\n\n    objStoreNames.forEach(objStoreName => {\n        if (dbMeta.has(objStoreName)) {\n            return;\n        }\n\n        const promise = new Promise(resolve => {\n            const transaction = db.transaction([objStoreName], TRANSACTION_READWRITE);\n            transaction.oncomplete = resolve;\n            transaction.onabort = resolve;\n\n            const objStore = transaction.objectStore(objStoreName);\n\n            if (objStore.autoIncrement !== undefined) {\n                dbMeta.set(objStoreName, {\n                    autoIncrement: objStore.autoIncrement,\n                    keyPath: objStore.keyPath\n                });\n\n                return;\n            }\n\n            let autoIncrement;\n\n            if (objStore.keyPath !== null) {\n                // if key path is defined it's possible to insert only objects\n                // but if key generator (autoIncrement) is not defined the inserted objects\n                // must contain field(s) described in keyPath value otherwise IDBObjectStore.add op fails\n                // so if we run ODBObjectStore.add with an empty object and it fails, this means that\n                // autoIncrement property was false. Otherwise - true\n                // if key path is array autoIncrement property can't be true\n                if (Array.isArray(objStore.keyPath)) {\n                    autoIncrement = false;\n                } else {\n                    try {\n                        objStore.add({});\n                        autoIncrement = true;\n                    } catch (ex) {\n                        autoIncrement = false;\n                    }\n                }\n            } else {\n                // if key path is not defined it's possible to insert any kind of data\n                // but if key generator (autoIncrement) is not defined you should set it explicitly\n                // so if we run ODBObjectStore.add with one argument and it fails, this means that\n                // autoIncrement property was false. Otherwise - true\n                try {\n                    objStore.add('some value');\n                    autoIncrement = true;\n                } catch (ex) {\n                    autoIncrement = false;\n                }\n            }\n\n            // save meta properties\n            dbMeta.set(objStoreName, {\n                autoIncrement: autoIncrement,\n                keyPath: objStore.keyPath\n            });\n\n            // and abort transaction so that new record is forgotten\n            transaction.abort();\n        });\n\n        promises.push(promise);\n    });\n\n    return Promise.all(promises);\n}", "label": 3}
{"code": "func (process *TeleportProcess) Close() error {\n\tprocess.BroadcastEvent(Event{Name: TeleportExitEvent})\n\n\tprocess.Config.Keygen.Close()\n\n\tvar errors []error\n\tlocalAuth := process.getLocalAuth()\n\tif localAuth != nil {\n\t\terrors = append(errors, process.localAuth.Close())\n\t}\n\n\tif process.storage != nil {\n\t\terrors = append(errors, process.storage.Close())\n\t}\n\n\treturn trace.NewAggregate(errors...)\n}", "label": 5}
{"code": "def _df(self, x, user_data=None):\n        \"\"\" Evaluates the cost gradient.\n        \"\"\"\n        p_gen = x[self._Pg.i1:self._Pg.iN + 1] # Active generation in p.u.\n        q_gen = x[self._Qg.i1:self._Qg.iN + 1] # Reactive generation in p.u.\n\n        # Polynomial cost of P and Q.\n        xx = r_[p_gen, q_gen] * self._base_mva\n\n        iPg = range(self._Pg.i1, self._Pg.iN + 1)\n        iQg = range(self._Qg.i1, self._Qg.iN + 1)\n\n        # Polynomial cost of P and Q.\n        df_dPgQg = zeros((2 * self._ng, 1))        # w.r.t p.u. Pg and Qg\n#            df_dPgQg[ipol] = matrix([g.poly_cost(xx[i], 1) for g in gpol])\n#            for i, g in enumerate(gn):\n#                der = polyder(list(g.p_cost))\n#                df_dPgQg[i] = polyval(der, xx[i]) * base_mva\n        for i in self._ipol:\n            p_cost = list(self._gn[i].p_cost)\n            df_dPgQg[i] = \\\n                self._base_mva * polyval(polyder(p_cost), xx[i])\n\n        df = zeros((self._nxyz, 1))\n        df[iPg] = df_dPgQg[:self._ng]\n        df[iQg] = df_dPgQg[self._ng:self._ng + self._ng]\n\n        # Piecewise linear cost of P and Q.\n        df = df + self._ccost.T\n        # TODO: Generalised cost term.\n\n        return asarray(df).flatten()", "label": 1}
{"code": "protected function peformIndentation($jsonString, $indentChar = \"\\t\", $indentSize = 1, $defaultSpaces = 4)\n    {\n        $pattern = '/(^|\\G) {'.$defaultSpaces.'}/m';\n        $replacement = str_repeat($indentChar, $indentSize).'$1';\n\n        return preg_replace($pattern, $replacement, $jsonString);\n    }", "label": 2}
{"code": "def clean(backtrace, kind = :silent)\n      filtered = filter_backtrace(backtrace)\n\n      case kind\n      when :silent\n        silence(filtered)\n      when :noise\n        noise(filtered)\n      else\n        filtered\n      end\n    end", "label": 4}
{"code": "def get(self, query, sort, page, size):\n        \"\"\"Get a list of all the communities.\n\n        .. http:get:: /communities/(string:id)\n            Returns a JSON list with all the communities.\n            **Request**:\n            .. sourcecode:: http\n                GET /communities HTTP/1.1\n                Accept: application/json\n                Content-Type: application/json\n                Host: localhost:5000\n            :reqheader Content-Type: application/json\n            **Response**:\n            .. sourcecode:: http\n                HTTP/1.0 200 OK\n                Content-Length: 334\n                Content-Type: application/json\n                [\n                    {\n                        \"id\": \"comm1\"\n                    },\n                    {\n                        \"id\": \"comm2\"\n                    }\n                ]\n            :resheader Content-Type: application/json\n            :statuscode 200: no error\n        \"\"\"\n        urlkwargs = {\n            'q': query,\n            'sort': sort,\n            'size': size,\n        }\n\n        communities = Community.filter_communities(query, sort)\n        page = communities.paginate(page, size)\n\n        links = default_links_pagination_factory(page, urlkwargs)\n\n        links_headers = map(lambda key: ('link', 'ref=\"{0}\" href=\"{1}\"'.format(\n            key, links[key])), links)\n\n        return self.make_response(\n            page,\n            headers=links_headers,\n            links_item_factory=default_links_item_factory,\n            page=page,\n            urlkwargs=urlkwargs,\n            links_pagination_factory=default_links_pagination_factory,\n        )", "label": 1}
{"code": "function mkdirSync(dirPath) {\n    // Get relative path to output\n    const relativePath = dirPath.replace(`${CWD}${pathSep}`, '');\n  \tconst dirs = relativePath.split(pathSep);\n  \tlet currentDir = CWD;\n\n    // Check if each dir exists, and if not, create it\n    dirs.forEach(dir => {\n      currentDir = path.resolve(currentDir, dir);\n      if(!fs.existsSync(currentDir)) {\n        fs.mkdirSync(currentDir);\n      }\n    });\n  }", "label": 3}
{"code": "func (*TeleportGithubConnectorMarshaler) Unmarshal(bytes []byte) (GithubConnector, error) {\n\tvar h ResourceHeader\n\tif err := json.Unmarshal(bytes, &h); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tswitch h.Version {\n\tcase V3:\n\t\tvar c GithubConnectorV3\n\t\tif err := utils.UnmarshalWithSchema(GetGithubConnectorSchema(), &c, bytes); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tif err := c.CheckAndSetDefaults(); err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\treturn &c, nil\n\t}\n\treturn nil, trace.BadParameter(\n\t\t\"Github connector resource version %q is not supported\", h.Version)\n}", "label": 5}
{"code": "public function hasMonitoredTag()\n    {\n        if (! empty($this->tags)) {\n            return app(EntriesRepository::class)->isMonitoring($this->tags);\n        }\n\n        return false;\n    }", "label": 2}
{"code": "def groupby(xs, key_fn):\n    \"\"\"\n    Group elements of the list `xs` by keys generated from calling `key_fn`.\n\n    Returns a dictionary which maps keys to sub-lists of `xs`.\n    \"\"\"\n    result = defaultdict(list)\n    for x in xs:\n        key = key_fn(x)\n        result[key].append(x)\n    return result", "label": 1}
{"code": "public void forAllValuePairs(String template, Properties attributes) throws XDocletException\r\n    {\r\n        String name           = attributes.getProperty(ATTRIBUTE_NAME, \"attributes\");\r\n        String defaultValue   = attributes.getProperty(ATTRIBUTE_DEFAULT_RIGHT, \"\");\r\n        String attributePairs = getPropertyValue(attributes.getProperty(ATTRIBUTE_LEVEL), name);\r\n\r\n        if ((attributePairs == null) || (attributePairs.length() == 0))\r\n        {\r\n            return;\r\n        }\r\n\r\n        String token;\r\n        int    pos;\r\n\r\n        for (CommaListIterator it = new CommaListIterator(attributePairs); it.hasNext();)\r\n        {\r\n            token = it.getNext();\r\n            pos   = token.indexOf('=');\r\n            if (pos >= 0)\r\n            {\r\n                _curPairLeft  = token.substring(0, pos);\r\n                _curPairRight = (pos < token.length() - 1 ? token.substring(pos + 1) : defaultValue);\r\n            }\r\n            else\r\n            {\r\n                _curPairLeft  = token;\r\n                _curPairRight = defaultValue;\r\n            }\r\n            if (_curPairLeft.length() > 0)\r\n            {\r\n                generate(template);\r\n            }\r\n        }\r\n        _curPairLeft = null;\r\n        _curPairRight = null;\r\n    }", "label": 0}
{"code": "public static Artifact createArtifact(final String groupId, final String artifactId, final String version, final String classifier, final String type, final String extension, final String origin){\n\t\tfinal Artifact artifact = new Artifact();\n\n\t\tartifact.setGroupId(groupId);\n\t\tartifact.setArtifactId(artifactId);\n\t\tartifact.setVersion(version);\n\n\t\tif(classifier != null){\n\t\t\tartifact.setClassifier(classifier);\n\t\t}\n\n\t\tif(type != null){\n\t\t\tartifact.setType(type);\n\t\t}\n\n\t\tif(extension != null){\n\t\t\tartifact.setExtension(extension);\n\t\t}\n\n\t\tartifact.setOrigin(origin == null ? \"maven\" : origin);\n\n\t\treturn artifact;\n\t}", "label": 0}
{"code": "def report_failed_job(job,exception)\n      log_with_severity :error, \"#{job.inspect} failed: #{exception.inspect}\"\n      begin\n        job.fail(exception)\n      rescue Object => exception\n        log_with_severity :error, \"Received exception when reporting failure: #{exception.inspect}\"\n      end\n      begin\n        failed!\n      rescue Object => exception\n        log_with_severity :error, \"Received exception when increasing failed jobs counter (redis issue) : #{exception.inspect}\"\n      end\n    end", "label": 4}
{"code": "def parse_mentions(mentions, server = nil)\n      array_to_return = []\n      # While possible mentions may be in message\n      while mentions.include?('<') && mentions.include?('>')\n        # Removing all content before the next possible mention\n        mentions = mentions.split('<', 2)[1]\n        # Locate the first valid mention enclosed in `<...>`, otherwise advance to the next open `<`\n        next unless mentions.split('>', 2).first.length < mentions.split('<', 2).first.length\n\n        # Store the possible mention value to be validated with RegEx\n        mention = mentions.split('>', 2).first\n        if /@!?(?<id>\\d+)/ =~ mention\n          array_to_return << user(id) unless user(id).nil?\n        elsif /#(?<id>\\d+)/ =~ mention\n          array_to_return << channel(id, server) unless channel(id, server).nil?\n        elsif /@&(?<id>\\d+)/ =~ mention\n          if server\n            array_to_return << server.role(id) unless server.role(id).nil?\n          else\n            @servers.values.each do |element|\n              array_to_return << element.role(id) unless element.role(id).nil?\n            end\n          end\n        elsif /(?<animated>^[a]|^${0}):(?<name>\\w+):(?<id>\\d+)/ =~ mention\n          array_to_return << (emoji(id) || Emoji.new({ 'animated' => !animated.nil?, 'name' => name, 'id' => id }, self, nil))\n        end\n      end\n      array_to_return\n    end", "label": 4}
{"code": "async def get_cred_def(self, cd_id: str) -> str:\n        \"\"\"\n        Get credential definition from ledger by its identifier.\n\n        Raise AbsentCredDef for no such credential definition, logging any error condition and raising\n        BadLedgerTxn on bad request. Raise ClosedPool if cred def not in cache and pool is closed.\n\n        Retrieve the credential definition from the agent's credential definition cache if it has it; cache it\n        en passant if it does not (and if there is a corresponding credential definition on the ledger).\n\n        :param cd_id: (credential definition) identifier string ('<issuer-did>:3:CL:<schema-seq-no>:<tag>')\n        :return: credential definition json as retrieved from ledger, empty production for no such cred def\n        \"\"\"\n\n        LOGGER.debug('_BaseAgent.get_cred_def >>> cd_id: %s', cd_id)\n\n        rv_json = json.dumps({})\n\n        with CRED_DEF_CACHE.lock:\n            if cd_id in CRED_DEF_CACHE:\n                LOGGER.info('_BaseAgent.get_cred_def: got cred def for %s from cache', cd_id)\n                rv_json = json.dumps(CRED_DEF_CACHE[cd_id])\n                LOGGER.debug('_BaseAgent.get_cred_def <<< %s', rv_json)\n                return rv_json\n\n            req_json = await ledger.build_get_cred_def_request(self.did, cd_id)\n            resp_json = await self._submit(req_json)\n            resp = json.loads(resp_json)\n            if not ('result' in resp and resp['result'].get('data', None)):\n                LOGGER.debug('_BaseAgent.get_cred_def: <!< no cred def exists on %s', cd_id)\n                raise AbsentCredDef('No cred def exists on {}'.format(cd_id))\n            try:\n                (_, rv_json) = await ledger.parse_get_cred_def_response(resp_json)\n            except IndyError:  # ledger replied, but there is no such cred def\n                LOGGER.debug('_BaseAgent.get_cred_def: <!< no cred def exists on %s', cd_id)\n                raise AbsentCredDef('No cred def exists on {}'.format(cd_id))\n            CRED_DEF_CACHE[cd_id] = json.loads(rv_json)\n            LOGGER.info('_BaseAgent.get_cred_def: got cred def %s from ledger', cd_id)\n\n        LOGGER.debug('_BaseAgent.get_cred_def <<< %s', rv_json)\n        return rv_json", "label": 1}
{"code": "public static systembackup[] get(nitro_service service, String filename[]) throws Exception{\n\t\tif (filename !=null && filename.length>0) {\n\t\t\tsystembackup response[] = new systembackup[filename.length];\n\t\t\tsystembackup obj[] = new systembackup[filename.length];\n\t\t\tfor (int i=0;i<filename.length;i++) {\n\t\t\t\tobj[i] = new systembackup();\n\t\t\t\tobj[i].set_filename(filename[i]);\n\t\t\t\tresponse[i] = (systembackup) obj[i].get_resource(service);\n\t\t\t}\n\t\t\treturn response;\n\t\t}\n\t\treturn null;\n\t}", "label": 0}
{"code": "def configure_with_targets(runnable_target, test_target, launch_target: false)\n      if runnable_target\n        add_build_target(runnable_target)\n        set_launch_target(runnable_target) if launch_target\n      end\n      if test_target\n        add_build_target(test_target, false) if test_target != runnable_target\n        add_test_target(test_target)\n      end\n    end", "label": 4}
{"code": "func GetACIInfosWithName(tx *sql.Tx, name string) ([]*ACIInfo, bool, error) {\n\tvar aciinfos []*ACIInfo\n\tfound := false\n\trows, err := tx.Query(\"SELECT * from aciinfo WHERE name == $1\", name)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tdefer rows.Close()\n\tfor rows.Next() {\n\t\tfound = true\n\t\taciinfo := &ACIInfo{}\n\t\tif err := aciinfoRowScan(rows, aciinfo); err != nil {\n\t\t\treturn nil, false, err\n\t\t}\n\t\taciinfos = append(aciinfos, aciinfo)\n\t}\n\tif err := rows.Err(); err != nil {\n\t\treturn nil, false, err\n\t}\n\treturn aciinfos, found, err\n}", "label": 5}
{"code": "func (dal *DjangoAdminLog) Update(db XODB) error {\n\tvar err error\n\n\t// if doesn't exist, bail\n\tif !dal._exists {\n\t\treturn errors.New(\"update failed: does not exist\")\n\t}\n\n\t// if deleted, bail\n\tif dal._deleted {\n\t\treturn errors.New(\"update failed: marked for deletion\")\n\t}\n\n\t// sql query\n\tconst sqlstr = `UPDATE public.django_admin_log SET (` +\n\t\t`action_time, object_id, object_repr, action_flag, change_message, content_type_id, user_id` +\n\t\t`) = ( ` +\n\t\t`$1, $2, $3, $4, $5, $6, $7` +\n\t\t`) WHERE id = $8`\n\n\t// run query\n\tXOLog(sqlstr, dal.ActionTime, dal.ObjectID, dal.ObjectRepr, dal.ActionFlag, dal.ChangeMessage, dal.ContentTypeID, dal.UserID, dal.ID)\n\t_, err = db.Exec(sqlstr, dal.ActionTime, dal.ObjectID, dal.ObjectRepr, dal.ActionFlag, dal.ChangeMessage, dal.ContentTypeID, dal.UserID, dal.ID)\n\treturn err\n}", "label": 5}
{"code": "def ff(items, targets):\n    \"\"\"First-Fit\n\n    This is perhaps the simplest packing heuristic;\n    it simply packs items in the next available bin.\n\n    Complexity O(n^2)\n    \"\"\"\n    bins = [(target, []) for target in targets]\n    skip = []\n\n    for item in items:\n        for target, content in bins:\n            if item <= (target - sum(content)):\n                content.append(item)\n                break\n        else:\n            skip.append(item)\n    return bins, skip", "label": 1}
{"code": "function(obj, area, elementsToSearch) {\n            var view;\n\n            if (obj.getView) {\n                view = obj.getView();\n                if (view) {\n                    return this.locateView(view, area, elementsToSearch);\n                }\n            }\n\n            if (obj.viewUrl) {\n                return this.locateView(obj.viewUrl, area, elementsToSearch);\n            }\n\n            var id = system.getModuleId(obj);\n            if (id) {\n                return this.locateView(this.convertModuleIdToViewId(id), area, elementsToSearch);\n            }\n\n            return this.locateView(this.determineFallbackViewId(obj), area, elementsToSearch);\n        }", "label": 3}
{"code": "def delete_shift(id, opts = {})\n      data, _status_code, _headers = delete_shift_with_http_info(id, opts)\n      return data\n    end", "label": 4}
{"code": "private function applyEtagHeader(array $options, $argName = 'etag')\n    {\n        if (isset($options[$argName])) {\n            if (!isset($options['restOptions'])) {\n                $options['restOptions'] = [];\n            }\n\n            if (!isset($options['restOptions']['headers'])) {\n                $options['restOptions']['headers'] = [];\n            }\n\n            $options['restOptions']['headers']['If-Match'] = $options[$argName];\n        }\n\n        return $options;\n    }", "label": 2}
{"code": "func (a *AuthMiddleware) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tbaseContext := r.Context()\n\tif baseContext == nil {\n\t\tbaseContext = context.TODO()\n\t}\n\tuser, err := a.GetUser(r)\n\tif err != nil {\n\t\ttrace.WriteError(w, err)\n\t\treturn\n\t}\n\n\t// determine authenticated user based on the request parameters\n\trequestWithContext := r.WithContext(context.WithValue(baseContext, ContextUser, user))\n\ta.Handler.ServeHTTP(w, requestWithContext)\n}", "label": 5}
{"code": "public static base_responses reset(nitro_service client, appfwlearningdata resources[]) throws Exception {\n\t\tbase_responses result = null;\n\t\tif (resources != null && resources.length > 0) {\n\t\t\tappfwlearningdata resetresources[] = new appfwlearningdata[resources.length];\n\t\t\tfor (int i=0;i<resources.length;i++){\n\t\t\t\tresetresources[i] = new appfwlearningdata();\n\t\t\t}\n\t\t\tresult = perform_operation_bulk_request(client, resetresources,\"reset\");\n\t\t}\n\t\treturn result;\n\t}", "label": 0}
{"code": "def create_server(name, region = :'eu-central')\n      response = API::Server.create(token, name, region)\n      id = JSON.parse(response)['id'].to_i\n      sleep 0.1 until @servers[id]\n      server = @servers[id]\n      debug \"Successfully created server #{server.id} with name #{server.name}\"\n      server\n    end", "label": 4}
{"code": "def add_icon_widget(self, ref, x=1, y=1, name=\"heart\"):     \n        \n        \"\"\" Add Icon Widget \"\"\"\n        \n        if ref not in self.widgets:   \n            widget = IconWidget(screen=self, ref=ref, x=x, y=y, name=name)\n            self.widgets[ref] = widget\n            return self.widgets[ref]", "label": 1}
{"code": "function apply_autodetected(m, ast, inheritable) {\n  docset = find_docset(ast);\n  var inheritable = inheritable || true;\n  \n  if (!docset || docset[\"type\"] != \"doc_comment\") {\n    if (inheritable)\n      m[\"inheritdoc\"] = {};\n    else\n      m[\"private\"] = true;\n      \n    m[\"autodetected\"] = true;\n  }\n\n  if (docset) {\n    docset[\"code\"] = m;\n    return false;\n  }\n  else {\n    // Get line number from third place at range array.\n    // This third item exists in forked EsprimaJS at\n    // https://github.com/nene/esprima/tree/linenr-in-range\n    m[\"linenr\"] = ast[\"range\"][2];\n    return true;\n  }\n}", "label": 3}
{"code": "func TLSCerts(ca CertAuthority) [][]byte {\n\tpairs := ca.GetTLSKeyPairs()\n\tout := make([][]byte, len(pairs))\n\tfor i, pair := range pairs {\n\t\tout[i] = append([]byte{}, pair.Cert...)\n\t}\n\treturn out\n}", "label": 5}
{"code": "function( name, data ) {\n                var _trigger = function( name ) {\n                    var methodList = STATE.methods[ name ]\n                    if ( methodList ) {\n                        methodList.map( function( method ) {\n                            PickerConstructor._.trigger( method, P, [ data ] )\n                        })\n                    }\n                }\n                _trigger( '_' + name )\n                _trigger( name )\n                return P\n            }", "label": 3}
{"code": "def read(self, file_or_filename):\n        \"\"\" Loads a pickled case.\n        \"\"\"\n        if isinstance(file_or_filename, basestring):\n            fname = os.path.basename(file_or_filename)\n            logger.info(\"Unpickling case file [%s].\" % fname)\n\n            file = None\n            try:\n                file = open(file_or_filename, \"rb\")\n            except:\n                logger.error(\"Error opening %s.\" % fname)\n                return None\n            finally:\n                if file is not None:\n                    case = pickle.load(file)\n                    file.close()\n        else:\n            file = file_or_filename\n            case = pickle.load(file)\n\n        return case", "label": 1}
{"code": "private ReferenceDescriptorDef cloneReference(ReferenceDescriptorDef refDef, String prefix)\r\n    {\r\n        ReferenceDescriptorDef copyRefDef = new ReferenceDescriptorDef(refDef, prefix);\r\n\r\n        copyRefDef.setOwner(this);\r\n        // we remove properties that are only relevant to the class the features are declared in\r\n        copyRefDef.setProperty(PropertyHelper.OJB_PROPERTY_IGNORE, null);\r\n        \r\n        Properties mod = getModification(copyRefDef.getName());\r\n\r\n        if (mod != null)\r\n        {\r\n            if (!PropertyHelper.toBoolean(mod.getProperty(PropertyHelper.OJB_PROPERTY_IGNORE), false) &&\r\n                hasFeature(copyRefDef.getName()))\r\n            {\r\n                LogHelper.warn(true,\r\n                               ClassDescriptorDef.class,\r\n                               \"process\",\r\n                               \"Class \"+getName()+\" has a feature that has the same name as its included reference \"+\r\n                               copyRefDef.getName()+\" from class \"+refDef.getOwner().getName()); \r\n            }\r\n            copyRefDef.applyModifications(mod);\r\n        }\r\n        return copyRefDef;\r\n    }", "label": 0}
{"code": "def __getDummyDateList():\n    \"\"\"\n\tGenerate a dummy date list for testing without \n\thitting the server\n\t\"\"\"\n\n    D = []\n    for y in xrange(2001, 2010):\n        for d in xrange(1, 365, 1):\n            D.append('A%04d%03d' % (y, d))\n\n    return D", "label": 1}
{"code": "function performValidation(field) {\n        return function(rule, cb) {\n            var valueToBeValidated = kontx.args.fields[field._id],\n                validate = validator.get(rule);\n\n            //Undefined values do not need to be validated unless the field is required\n            if (rule.type === 'required' || !_.isUndefined(valueToBeValidated)) {\n                if (_.isArray(valueToBeValidated)) {\n                    q.all(\n                        _.map(valueToBeValidated, function(value) {\n                            return validate(value, rule.options);\n                        })\n                    )\n                        .then(\n                            function() {\n                                cb();\n                            },\n                            function() {\n                                cb(createError(400, validationTemplate({\n                                    label: field.label\n                                })));\n                            }\n                    );\n                } else {\n                    validate(valueToBeValidated, rule.options)\n                        .then(\n                            function() {\n                                cb();\n                            },\n                            function() {\n                                cb(createError(400, validationTemplate({\n                                    label: field.label\n                                })));\n                            }\n                    );\n                }\n            } else {\n                cb();\n            }\n        };\n    }", "label": 3}
{"code": "function handleFileSwagger(profile, profileKey) {\n    const inputFilePath = path.resolve(currentDir, profile.file);\n    console.log(chalk`{green [${profileKey}]} Input swagger file : {cyan ${inputFilePath}}`);\n    fs.readFile(inputFilePath, 'utf8', (error, swagger) => {\n        if (error) {\n            console.log(chalk`{red Cannot read swagger file '{bold ${profile.file}}'.}`);\n            console.log(chalk.red(error));\n        } else {\n            handleSwagger(swagger, profile, profileKey);\n        }\n    });\n}", "label": 3}
{"code": "public static service_dospolicy_binding[] get(nitro_service service, String name) throws Exception{\n\t\tservice_dospolicy_binding obj = new service_dospolicy_binding();\n\t\tobj.set_name(name);\n\t\tservice_dospolicy_binding response[] = (service_dospolicy_binding[]) obj.get_resources(service);\n\t\treturn response;\n\t}", "label": 0}
{"code": "def wait_for_response(client, timeout, path='/', expected_status_code=None):\n    \"\"\"\n    Try make a GET request with an HTTP client against a certain path and\n    return once any response has been received, ignoring any errors.\n\n    :param ContainerHttpClient client:\n        The HTTP client to use to connect to the container.\n    :param timeout:\n        Timeout value in seconds.\n    :param path:\n        HTTP path to request.\n    :param int expected_status_code:\n        If set, wait until a response with this status code is received. If not\n        set, the status code will not be checked.\n    :raises TimeoutError:\n        If a request fails to be made within the timeout period.\n    \"\"\"\n    # We want time.monotonic on Pythons that have it, otherwise time.time will\n    # have to do.\n    get_time = getattr(time, 'monotonic', time.time)\n\n    deadline = get_time() + timeout\n    while True:\n        try:\n            # Don't care what the response is, as long as we get one\n            time_left = deadline - get_time()\n            response = client.get(\n                path, timeout=max(time_left, 0.001), allow_redirects=False)\n\n            if (expected_status_code is None\n                    or response.status_code == expected_status_code):\n                return\n        except requests.exceptions.Timeout:\n            # Requests timed out, our time must be up\n            break\n        except Exception:\n            # Ignore other exceptions\n            pass\n\n        if get_time() >= deadline:\n            break\n        time.sleep(0.1)\n\n    raise TimeoutError('Timeout waiting for HTTP response.')", "label": 1}
{"code": "public function clear($entityName = null)\n    {\n        $this->unitOfWork->clear();\n\n        $this->unitOfWork = new UnitOfWork($this);\n\n        if ($this->eventManager->hasListeners(Events::onClear)) {\n            $this->eventManager->dispatchEvent(Events::onClear, new Event\\OnClearEventArgs($this));\n        }\n    }", "label": 2}
{"code": "public function handle($request, Closure $next)\n    {\n        if ($request instanceof InternalRequest) {\n            return $next($request);\n        }\n\n        $route = $this->router->getCurrentRoute();\n\n        if ($route->hasThrottle()) {\n            $this->handler->setThrottle($route->getThrottle());\n        }\n\n        $this->handler->rateLimitRequest($request, $route->getRateLimit(), $route->getRateLimitExpiration());\n\n        if ($this->handler->exceededRateLimit()) {\n            throw new RateLimitExceededException('You have exceeded your rate limit.', null, $this->getHeaders());\n        }\n\n        $response = $next($request);\n\n        if ($this->handler->requestWasRateLimited()) {\n            return $this->responseWithHeaders($response);\n        }\n\n        return $response;\n    }", "label": 2}
{"code": "protected static function transformRow($row)\n    {\n        foreach ($row as $key => $value) {\n            if ($value instanceof DateTime) {\n                $row[$key] = $value->format('Y-m-d H:i:s');\n            } else {\n                if (is_object($value)) {\n                    $row[$key] = (string) $value;\n                } else {\n                    $row[$key] = $value;\n                }\n            }\n        }\n\n        return $row;\n    }", "label": 2}
{"code": "def iuwt_recomposition(in1, scale_adjust=0, mode='ser', core_count=1, store_on_gpu=False, smoothed_array=None):\n    \"\"\"\n    This function serves as a handler for the different implementations of the IUWT recomposition. It allows the\n    different methods to be used almost interchangeably.\n\n    INPUTS:\n    in1                 (no default):       Array on which the decomposition is to be performed.\n    scale_adjust        (no default):       Number of omitted scales.\n    mode                (default='ser')     Implementation of the IUWT to be used - 'ser', 'mp' or 'gpu'.\n    core_count          (default=1)         Additional option for multiprocessing - specifies core count.\n    store_on_gpu        (default=False):    Boolean specifier for whether the decomposition is stored on the gpu or not.\n\n    OUTPUTS:\n    Returns the recomposition.\n    \"\"\"\n\n    if mode=='ser':\n        return ser_iuwt_recomposition(in1, scale_adjust, smoothed_array)\n    elif mode=='mp':\n        return mp_iuwt_recomposition(in1, scale_adjust, core_count, smoothed_array)\n    elif mode=='gpu':\n        return gpu_iuwt_recomposition(in1, scale_adjust, store_on_gpu, smoothed_array)", "label": 1}
{"code": "function(data) {\n        var TTML_BODY = '',\n            index = 0,\n            splitText,\n            captions = data;\n\n        TTML_BODY += TTML.header.join('\\n') + '\\n';\n        captions.forEach(function(caption) {\n            if (caption.text.length > 0 && validateText(caption.text)) {\n                if ((/&/.test(caption.text)) && !(/&amp;/.test(caption.text))) {\n                    caption.text = caption.text.replace(/&/g, '&amp;');\n                }\n                if ((/</.test(caption.text)) && !(/&lt;/.test(caption.text))) {\n                    caption.text = caption.text.replace(/</g, '&lt;');\n                }\n                if ((/>/.test(caption.text)) && !(/&gt;/.test(caption.text))) {\n                    caption.text = caption.text.replace(/>/g, '&gt;');\n                }\n                if (/\\{break\\}/.test(caption.text)) {\n                    splitText = caption.text.split('{break}');\n                    //TODO this should count for number of breaks and add the appropriate pops where needed.\n                    for (index = 0; index < splitText.length; index++) {\n                        TTML_BODY += TTML.lineTemplate.replace('{region}', 'pop' + (index + 1))\n                            .replace('{startTime}', module.exports.formatTime(caption.startTimeMicro))\n                            .replace('{endTime}', module.exports.formatTime(caption.endTimeMicro))\n                            .replace('{text}', module.exports.renderMacros(macros.fixItalics(macros.cleanMacros(splitText[index])))) + '\\n';\n                    }\n                } else {\n                    TTML_BODY += TTML.lineTemplate.replace('{region}', 'pop1')\n                        .replace('{startTime}', module.exports.formatTime(caption.startTimeMicro))\n                        .replace('{endTime}', module.exports.formatTime(caption.endTimeMicro))\n                        .replace('{text}', module.exports.renderMacros(macros.fixItalics(macros.cleanMacros(caption.text)))) + '\\n';\n                }\n            }\n        });\n\n        return TTML_BODY + TTML.footer.join('\\n') + '\\n';\n    }", "label": 3}
{"code": "public function setApplicationStatusFilters($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Talent\\V4beta1\\ApplicationStatusFilter::class);\n        $this->application_status_filters = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def register(self, signal, description):\n        \"\"\"\n        Registers a new signal.\n        Only registered signals are allowed to be send.\n\n        :param signal: Unique name of the signal\n        :param description: Description of the reason or use case, why this signal is needed.\n                            Used for documentation.\n        \"\"\"\n        return self.__app.signals.register(signal, self._plugin, description)", "label": 1}
{"code": "function install(ids) {\n  if (!ids || !ids.length) return;\n\n  const missingDependencies = ids.filter(id => find(id) == '');\n\n  if (missingDependencies.length) {\n    try {\n      const cmd = useNPM\n        ? `npm --save-dev --save-exact install ${missingDependencies.join(' ')}`\n        : `yarn add --dev --exact ${missingDependencies.join(' ')}`;\n\n      print('installing the following missing dependencies:', 0);\n      missingDependencies.forEach(id => {\n        print(strong(id), 1);\n      });\n      exec(cmd);\n    } catch (err) {\n      error(err);\n    }\n  }\n}", "label": 3}
{"code": "def _get_ssm_parameter(self, p):\n        \"\"\"\n        Get parameters from Simple Systems Manager\n\n        Args:\n            p - a parameter name\n\n        Returns:\n            a value, decrypted if needed, if successful or None if things go\n            sideways.\n        \"\"\"\n        try:\n            response = self._ssm.get_parameter(Name=p, WithDecryption=True)\n            return response.get('Parameter', {}).get('Value', None)\n        except Exception as ruh_roh:\n            logging.error(ruh_roh, exc_info=False)\n\n        return None", "label": 1}
{"code": "private void addIndex(IndexDescriptorDef indexDescDef, TableDef tableDef)\r\n    {\r\n        IndexDef indexDef = tableDef.getIndex(indexDescDef.getName());\r\n\r\n        if (indexDef == null)\r\n        {\r\n            indexDef = new IndexDef(indexDescDef.getName(),\r\n                                    indexDescDef.getBooleanProperty(PropertyHelper.OJB_PROPERTY_UNIQUE, false));\r\n            tableDef.addIndex(indexDef);\r\n        }\r\n\r\n        try\r\n        {\r\n            String             fieldNames = indexDescDef.getProperty(PropertyHelper.OJB_PROPERTY_FIELDS);\r\n            ArrayList          fields     = ((ClassDescriptorDef)indexDescDef.getOwner()).getFields(fieldNames);\r\n            FieldDescriptorDef fieldDef;\r\n\r\n            for (Iterator it = fields.iterator(); it.hasNext();)\r\n            {\r\n                fieldDef = (FieldDescriptorDef)it.next();\r\n                indexDef.addColumn(fieldDef.getProperty(PropertyHelper.OJB_PROPERTY_COLUMN));\r\n            }\r\n        }\r\n        catch (NoSuchFieldException ex)\r\n        {\r\n            // won't happen if we already checked the constraints\r\n        }\r\n    }", "label": 0}
{"code": "public static ComplexNumber Subtract(ComplexNumber z1, double scalar) {\r\n        return new ComplexNumber(z1.real - scalar, z1.imaginary);\r\n    }", "label": 0}
{"code": "func asUint(param string) uint64 {\n\n\ti, err := strconv.ParseUint(param, 0, 64)\n\tpanicIf(err)\n\n\treturn i\n}", "label": 5}
{"code": "@SuppressWarnings(\"rawtypes\")\n  public final Map<String, MtasDataItemNumberComparator> getComparatorList()\n      throws IOException {\n    if (collectorType.equals(DataCollector.COLLECTOR_TYPE_LIST)) {\n      LinkedHashMap<String, MtasDataItemNumberComparator> comparatorList = new LinkedHashMap<>();\n      for (Entry<String, MtasDataItem<T1, T2>> entry : list.entrySet()) {\n        comparatorList.put(entry.getKey(),\n            entry.getValue().getComparableValue());\n      }\n      return comparatorList;\n    } else {\n      throw new IOException(\"type \" + collectorType + \" not supported\");\n    }\n  }", "label": 0}
{"code": "func (h *Handle) ToByteArray() ([]byte, error) {\n\n\th.Lock()\n\tdefer h.Unlock()\n\tba := make([]byte, 16)\n\tbinary.BigEndian.PutUint64(ba[0:], h.bits)\n\tbinary.BigEndian.PutUint64(ba[8:], h.unselected)\n\tbm, err := h.head.toByteArray()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to serialize head: %s\", err.Error())\n\t}\n\tba = append(ba, bm...)\n\n\treturn ba, nil\n}", "label": 5}
{"code": "def _set_instance_prop(self, attr_name, config_prop, value):\n        \"\"\"Set instance property to a value and add it varz if needed\"\"\"\n        setattr(self, attr_name, value)\n\n        # add to varz if it is not private\n        if not config_prop.exclude_from_varz:\n            self.varz[attr_name] = value", "label": 1}
{"code": "public function setOutcome($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Talent\\V4beta1\\Outcome::class);\n        $this->outcome = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def process_fields(self, fields):\n\t\t\"\"\"Process a list of simple string field definitions and assign their order based on prefix.\"\"\"\n\t\t\n\t\tresult = []\n\t\tstrip = ''.join(self.PREFIX_MAP)\n\t\t\n\t\tfor field in fields:\n\t\t\tdirection = self.PREFIX_MAP['']\n\t\t\t\n\t\t\tif field[0] in self.PREFIX_MAP:\n\t\t\t\tdirection = self.PREFIX_MAP[field[0]]\n\t\t\t\tfield = field.lstrip(strip)\n\t\t\t\n\t\t\tresult.append((field, direction))\n\t\t\n\t\treturn result", "label": 1}
{"code": "def stylesheet(*urls)\n      urls << {} unless urls.last.respond_to? :to_hash\n      urls.last[:type] ||= mime_type(:css)\n      link(:stylesheet, *urls)\n    end", "label": 4}
{"code": "def filter_communities(cls, p, so, with_deleted=False):\n        \"\"\"Search for communities.\n\n        Helper function which takes from database only those communities which\n        match search criteria. Uses parameter 'so' to set communities in the\n        correct order.\n\n        Parameter 'page' is introduced to restrict results and return only\n        slice of them for the current page. If page == 0 function will return\n        all communities that match the pattern.\n        \"\"\"\n        query = cls.query if with_deleted else \\\n            cls.query.filter(cls.deleted_at.is_(None))\n\n        if p:\n            p = p.replace(' ', '%')\n            query = query.filter(db.or_(\n                cls.id.ilike('%' + p + '%'),\n                cls.title.ilike('%' + p + '%'),\n                cls.description.ilike('%' + p + '%'),\n            ))\n\n        if so in current_app.config['COMMUNITIES_SORTING_OPTIONS']:\n            order = so == 'title' and db.asc or db.desc\n            query = query.order_by(order(getattr(cls, so)))\n        else:\n            query = query.order_by(db.desc(cls.ranking))\n        return query", "label": 1}
{"code": "def reject_all_values_if_none(source_list)\n      if source_list.length > 1\n        source_list.reject { |value| value == NONE }\n      else\n        source_list\n      end\n    end", "label": 4}
{"code": "function checkCallExpression(node) {\n            // Grammar checking; stop grammar-checking if checkGrammarTypeArguments return true\n            checkGrammarTypeArguments(node, node.typeArguments) || checkGrammarArguments(node, node.arguments);\n            var signature = getResolvedSignature(node);\n            if (node.expression.kind === 95 /* SuperKeyword */) {\n                return voidType;\n            }\n            if (node.kind === 175 /* NewExpression */) {\n                var declaration = signature.declaration;\n                if (declaration &&\n                    declaration.kind !== 148 /* Constructor */ &&\n                    declaration.kind !== 152 /* ConstructSignature */ &&\n                    declaration.kind !== 157 /* ConstructorType */ &&\n                    !ts.isJSDocConstructSignature(declaration)) {\n                    // When resolved signature is a call signature (and not a construct signature) the result type is any, unless\n                    // the declaring function had members created through 'x.prototype.y = expr' or 'this.y = expr' psuedodeclarations\n                    // in a JS file\n                    // Note:JS inferred classes might come from a variable declaration instead of a function declaration.\n                    // In this case, using getResolvedSymbol directly is required to avoid losing the members from the declaration.\n                    var funcSymbol = node.expression.kind === 69 /* Identifier */ ?\n                        getResolvedSymbol(node.expression) :\n                        checkExpression(node.expression).symbol;\n                    if (funcSymbol && funcSymbol.members && (funcSymbol.flags & 16 /* Function */ || ts.isDeclarationOfFunctionExpression(funcSymbol))) {\n                        return getInferredClassType(funcSymbol);\n                    }\n                    else if (compilerOptions.noImplicitAny) {\n                        error(node, ts.Diagnostics.new_expression_whose_target_lacks_a_construct_signature_implicitly_has_an_any_type);\n                    }\n                    return anyType;\n                }\n            }\n            // In JavaScript files, calls to any identifier 'require' are treated as external module imports\n            if (ts.isInJavaScriptFile(node) && ts.isRequireCall(node, /*checkArgumentIsStringLiteral*/ true)) {\n                return resolveExternalModuleTypeByLiteral(node.arguments[0]);\n            }\n            return getReturnTypeOfSignature(signature);\n        }", "label": 3}
{"code": "function(entity, msg) {\n            if (!msg._id) {\n                msg._id = new ObjectID();\n            }\n            var collection = new mongodb.Collection(this.db, \"__msg__\" + entity);\n            if (msg.method === 'delete' && (msg.id === 'all' || msg.id === 'clean')) {\n                collection.remove(function () {\n                    if (msg.id === 'all') {\n                        collection.insert(msg, { safe: false } );\n                    }\n                });\n            } else {\n                collection.insert(msg, { safe: false } );\n            }\n        }", "label": 3}
{"code": "func (o HostNetworkSystem) RefreshNetworkSystem(ctx context.Context) error {\n\treq := types.RefreshNetworkSystem{\n\t\tThis: o.Reference(),\n\t}\n\n\t_, err := methods.RefreshNetworkSystem(ctx, o.c, &req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "public function componentsVersion($componentId = null)\n    {\n        $components = $this->components ?: $this->loadComponents();\n\n        array_walk($components, function (&$component) {\n            $component = $component['version'];\n        });\n\n        return $componentId\n            ? [$componentId => $components[$componentId]]\n            : $components;\n    }", "label": 2}
{"code": "def displ_single(self, g_num, at_1, at_2):\n        \"\"\" Displacement vector between two atoms.\n\n        Returns the displacement vector pointing from `at_1`\n        toward `at_2` from geometry `g_num`.\n        If `at_1` == `at_2` a strict zero vector is returned.\n\n        Displacement vector is returned in units of Bohrs.\n\n        Parameters\n        ----------\n        g_num\n            |int| -- Index of the desired geometry\n\n        at_1\n            |int| -- Index of the first atom\n\n        at_2\n            |int| -- Index of the second atom\n\n        Returns\n        -------\n        displ\n            length-3 |npfloat_| --\n            Displacement vector from `at_1` to `at_2`\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an invalid (out-of-range) `g_num` or `at_#` is provided\n\n        \"\"\"\n\n        # Library imports\n        import numpy as np\n        from .utils import safe_cast as scast\n\n        # The below errors are explicitly thrown since they are multiplied by\n        #  three when they are used as an index and thus give non-intuitive\n        #  errors.\n        # Complain if at_1 is invalid\n        if not (-self.num_atoms <= at_1 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_1' ({0})\".format(at_1))\n\n        # Complain if at_2 is invalid\n        if not (-self.num_atoms <= at_2 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_2' ({0})\".format(at_2))\n\n        # Should never be necessary (save for badly erroneous calling code),\n        #  but coerce at_1 and at_2 to their floor() values.  This is again\n        #  needed since they are multiplied by three in the index expresssions\n        #  below, and can cause funny behavior when truncated by the indexing\n        at_1 = scast(np.floor(at_1), np.int_)\n        at_2 = scast(np.floor(at_2), np.int_)\n\n        # If the atom indices are the same, return trivial zero vector\n        if (at_1 % self.num_atoms) == (at_2 % self.num_atoms):\n            return np.array([0.0, 0.0, 0.0])\n        ## end if\n\n        # Retrieve the geometry; np.float_ type should be retained\n        g = self.geom_single(g_num)\n\n        # Calculate the displacement vector and return\n        displ = np.array([ g[i + 3*at_2] - g[i + 3*at_1] for i in range(3) ])\n\n        # Return the displacement vector\n        return displ", "label": 1}
{"code": "def relevant_rules_for_match(self, action, subject):\n        \"\"\"retrive match action and subject\"\"\"\n        matches = []\n        for rule in self.rules:\n            rule.expanded_actions = self.expand_actions(rule.actions)\n            if rule.is_relevant(action, subject):\n                matches.append(rule)\n\n        return self.optimize(matches[::-1])", "label": 1}
{"code": "public static function wrap(\n        callable $credentialProvider,\n        $options,\n        $region,\n        $service\n    ) {\n        return function (callable $handler) use (\n            $credentialProvider,\n            $options,\n            $region,\n            $service\n        ) {\n            return new static(\n                $handler,\n                $credentialProvider,\n                $options,\n                $region,\n                $service\n            );\n        };\n    }", "label": 2}
{"code": "List getGroupby()\r\n    {\r\n        List result = _getGroupby();\r\n        Iterator iter = getCriteria().iterator();\r\n        Object crit;\r\n\r\n        while (iter.hasNext())\r\n        {\r\n            crit = iter.next();\r\n            if (crit instanceof Criteria)\r\n            {\r\n                result.addAll(((Criteria) crit).getGroupby());\r\n            }\r\n        }\r\n\r\n        return result;\r\n    }", "label": 0}
{"code": "public function render($xml, $context = null, ServerRequestInterface $request = null)\n    {\n        $renderer = $this->getRenderer();\n\n        $this->events->dispatch(new Rendering($renderer, $context, $xml, $request));\n\n        return $renderer->render($xml);\n    }", "label": 2}
{"code": "function(filename){\n    // resolve by symlink if possible\n    for (var from in this.symlinks)\n      if (filename.indexOf(from) === 0 && (filename === from || filename[from.length] === '/'))\n        return this.symlinks[from] + filename.substr(from.length);\n\n    return path.resolve(this.fsBaseURI, filename.replace(/^[\\\\\\/]/, ''));\n  }", "label": 3}
{"code": "func (t *proxySitesSubsys) Start(sconn *ssh.ServerConn, ch ssh.Channel, req *ssh.Request, ctx *srv.ServerContext) error {\n\tlog.Debugf(\"proxysites.start(%v)\", ctx)\n\tremoteSites := t.srv.proxyTun.GetSites()\n\n\t// build an arary of services.Site structures:\n\tretval := make([]services.Site, 0, len(remoteSites))\n\tfor _, s := range remoteSites {\n\t\tretval = append(retval, services.Site{\n\t\t\tName:          s.GetName(),\n\t\t\tStatus:        s.GetStatus(),\n\t\t\tLastConnected: s.GetLastConnected(),\n\t\t})\n\t}\n\t// serialize them into JSON and write back:\n\tdata, err := json.Marshal(retval)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif _, err := ch.Write(data); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "label": 5}
{"code": "public function setQueryScope($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Firestore\\Admin\\V1\\Index_QueryScope::class);\n        $this->query_scope = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func ApplyDefaults(cfg *Config) {\n\t// Get defaults for Cipher, Kex algorithms, and MAC algorithms from\n\t// golang.org/x/crypto/ssh default config.\n\tvar sc ssh.Config\n\tsc.SetDefaults()\n\n\t// Remove insecure and (borderline insecure) cryptographic primitives from\n\t// default configuration. These can still be added back in file configuration by\n\t// users, but not supported by default by Teleport. See #1856 for more\n\t// details.\n\tkex := utils.RemoveFromSlice(sc.KeyExchanges,\n\t\tdefaults.DiffieHellmanGroup1SHA1,\n\t\tdefaults.DiffieHellmanGroup14SHA1)\n\tmacs := utils.RemoveFromSlice(sc.MACs,\n\t\tdefaults.HMACSHA1,\n\t\tdefaults.HMACSHA196)\n\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\thostname = \"localhost\"\n\t\tlog.Errorf(\"Failed to determine hostname: %v.\", err)\n\t}\n\n\t// global defaults\n\tcfg.Hostname = hostname\n\tcfg.DataDir = defaults.DataDir\n\tcfg.Console = os.Stdout\n\tcfg.CipherSuites = utils.DefaultCipherSuites()\n\tcfg.Ciphers = sc.Ciphers\n\tcfg.KEXAlgorithms = kex\n\tcfg.MACAlgorithms = macs\n\n\t// defaults for the auth service:\n\tcfg.Auth.Enabled = true\n\tcfg.Auth.SSHAddr = *defaults.AuthListenAddr()\n\tcfg.Auth.StorageConfig.Type = dir.GetName()\n\tcfg.Auth.StorageConfig.Params = backend.Params{defaults.BackendPath: filepath.Join(cfg.DataDir, defaults.BackendDir)}\n\tcfg.Auth.StaticTokens = services.DefaultStaticTokens()\n\tcfg.Auth.ClusterConfig = services.DefaultClusterConfig()\n\tdefaults.ConfigureLimiter(&cfg.Auth.Limiter)\n\t// set new style default auth preferences\n\tap := &services.AuthPreferenceV2{}\n\tap.CheckAndSetDefaults()\n\tcfg.Auth.Preference = ap\n\tcfg.Auth.LicenseFile = filepath.Join(cfg.DataDir, defaults.LicenseFile)\n\n\t// defaults for the SSH proxy service:\n\tcfg.Proxy.Enabled = true\n\tcfg.Proxy.SSHAddr = *defaults.ProxyListenAddr()\n\tcfg.Proxy.WebAddr = *defaults.ProxyWebListenAddr()\n\tcfg.Proxy.ReverseTunnelListenAddr = *defaults.ReverseTunnellListenAddr()\n\tdefaults.ConfigureLimiter(&cfg.Proxy.Limiter)\n\n\t// defaults for the Kubernetes proxy service\n\tcfg.Proxy.Kube.Enabled = false\n\tcfg.Proxy.Kube.ListenAddr = *defaults.KubeProxyListenAddr()\n\n\t// defaults for the SSH service:\n\tcfg.SSH.Enabled = true\n\tcfg.SSH.Addr = *defaults.SSHServerListenAddr()\n\tcfg.SSH.Shell = defaults.DefaultShell\n\tdefaults.ConfigureLimiter(&cfg.SSH.Limiter)\n\tcfg.SSH.PAM = &pam.Config{Enabled: false}\n}", "label": 5}
{"code": "func processArgs(args *internal.ArgType) error {\n\tvar err error\n\n\t// get working directory\n\tcwd, err := os.Getwd()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// determine out path\n\tif args.Out == \"\" {\n\t\targs.Path = cwd\n\t} else {\n\t\t// determine what to do with Out\n\t\tfi, err := os.Stat(args.Out)\n\t\tif err == nil && fi.IsDir() {\n\t\t\t// out is directory\n\t\t\targs.Path = args.Out\n\t\t} else if err == nil && !fi.IsDir() {\n\t\t\t// file exists (will truncate later)\n\t\t\targs.Path = path.Dir(args.Out)\n\t\t\targs.Filename = path.Base(args.Out)\n\n\t\t\t// error if not split was set, but destination is not a directory\n\t\t\tif !args.SingleFile {\n\t\t\t\treturn errors.New(\"output path is not directory\")\n\t\t\t}\n\t\t} else if _, ok := err.(*os.PathError); ok {\n\t\t\t// path error (ie, file doesn't exist yet)\n\t\t\targs.Path = path.Dir(args.Out)\n\t\t\targs.Filename = path.Base(args.Out)\n\n\t\t\t// error if split was set, but dest doesn't exist\n\t\t\tif !args.SingleFile {\n\t\t\t\treturn errors.New(\"output path must be a directory and already exist when not writing to a single file\")\n\t\t\t}\n\t\t} else {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// check user template path\n\tif args.TemplatePath != \"\" {\n\t\tfi, err := os.Stat(args.TemplatePath)\n\t\tif err == nil && !fi.IsDir() {\n\t\t\treturn errors.New(\"template path is not directory\")\n\t\t} else if err != nil {\n\t\t\treturn errors.New(\"template path must exist\")\n\t\t}\n\t}\n\n\t// fix path\n\tif args.Path == \".\" {\n\t\targs.Path = cwd\n\t}\n\n\t// determine package name\n\tif args.Package == \"\" {\n\t\targs.Package = path.Base(args.Path)\n\t}\n\n\t// determine filename if not previously set\n\tif args.Filename == \"\" {\n\t\targs.Filename = args.Package + args.Suffix\n\t}\n\n\t// if query mode toggled, but no query, read Stdin.\n\tif args.QueryMode && args.Query == \"\" {\n\t\tbuf, err := ioutil.ReadAll(os.Stdin)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\targs.Query = string(buf)\n\t}\n\n\t// query mode parsing\n\tif args.Query != \"\" {\n\t\targs.QueryMode = true\n\t}\n\n\t// check that query type was specified\n\tif args.QueryMode && args.QueryType == \"\" {\n\t\treturn errors.New(\"query type must be supplied for query parsing mode\")\n\t}\n\n\t// query trim\n\tif args.QueryMode && args.QueryTrim {\n\t\targs.Query = strings.TrimSpace(args.Query)\n\t}\n\n\t// escape all\n\tif args.EscapeAll {\n\t\targs.EscapeSchemaName = true\n\t\targs.EscapeTableNames = true\n\t\targs.EscapeColumnNames = true\n\t}\n\n\t// if verbose\n\tif args.Verbose {\n\t\tmodels.XOLog = func(s string, p ...interface{}) {\n\t\t\tfmt.Printf(\"SQL:\\n%s\\nPARAMS:\\n%v\\n\\n\", s, p)\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "function(event/*, arg1...*/) {\n      var events = this._events[event];\n\n      if (events != null) {\n        var args = slice(arguments, 1);\n        each(events, function(event) {\n          event[2].apply(event[1], args);\n        });\n      }\n      return this;\n    }", "label": 3}
{"code": "def find_channel(channel_name, server_name = nil, type: nil)\n      results = []\n\n      if /<#(?<id>\\d+)>?/ =~ channel_name\n        # Check for channel mentions separately\n        return [channel(id)]\n      end\n\n      @servers.values.each do |server|\n        server.channels.each do |channel|\n          results << channel if channel.name == channel_name && (server_name || server.name) == server.name && (!type || (channel.type == type))\n        end\n      end\n\n      results\n    end", "label": 4}
{"code": "public function rows($format = self::RETURN_ASSOCIATIVE)\n    {\n        $bufferedResults = [];\n        $call = $this->call;\n        $generator = null;\n        $shouldRetry = false;\n        $backoff = new ExponentialBackoff($this->retries, function ($ex) {\n            if ($ex instanceof ServiceException) {\n                return $ex->getCode() === Grpc\\STATUS_UNAVAILABLE;\n            }\n\n            return false;\n        });\n\n        $valid = $backoff->execute(function () use ($call, &$generator) {\n            $generator = $call();\n            return $generator->valid();\n        });\n\n        while ($valid) {\n            try {\n                $result = $generator->current();\n                $bufferedResults[] = $result;\n                $this->setResultData($result, $format);\n\n                $empty = false;\n                if (!isset($result['values']) || $this->columnCount === 0) {\n                    $empty = true;\n                }\n\n                $hasResumeToken = $this->isSetAndTrue($result, 'resumeToken');\n                if ($hasResumeToken || count($bufferedResults) >= self::BUFFER_RESULT_LIMIT) {\n                    $chunkedResult = null;\n                    if (!$empty) {\n                        list($yieldableRows, $chunkedResult) = $this->parseRowsFromBufferedResults($bufferedResults);\n\n                        foreach ($yieldableRows as $row) {\n                            yield $this->mapper->decodeValues($this->columns, $row, $format);\n                        }\n                    }\n\n                    // Now that we've yielded all available rows, flush the buffer.\n                    $bufferedResults = [];\n                    $shouldRetry = $hasResumeToken;\n\n                    // If the last item in the buffer had a chunked value let's\n                    // hold on to it so we can stitch it together into a yieldable\n                    // result.\n                    if ($chunkedResult) {\n                        $bufferedResults[] = $chunkedResult;\n                    }\n                }\n\n                $generator->next();\n                $valid = $generator->valid();\n            } catch (ServiceException $ex) {\n                if ($shouldRetry && $ex->getCode() === Grpc\\STATUS_UNAVAILABLE) {\n                    // Attempt to resume using our last stored resume token. If we\n                    // successfully resume, flush the buffer.\n                    $generator = $backoff->execute($call, [$this->resumeToken]);\n                    $bufferedResults = [];\n\n                    continue;\n                }\n\n                throw $ex;\n            }\n        }\n\n        // If there are any results remaining in the buffer, yield them.\n        if ($bufferedResults) {\n            list($yieldableRows, $chunkedResult) = $this->parseRowsFromBufferedResults($bufferedResults);\n\n            foreach ($yieldableRows as $row) {\n                yield $this->mapper->decodeValues($this->columns, $row, $format);\n            }\n        }\n    }", "label": 2}
{"code": "function kepler (m, ecc) {\n  const epsilon = 1e-6\n\n  m = torad(m)\n  let e = m\n  while (1) {\n    const delta = e - ecc * Math.sin(e) - m\n    e -= delta / (1.0 - ecc * Math.cos(e))\n\n    if (Math.abs(delta) <= epsilon) {\n      break\n    }\n  }\n\n  return e\n}", "label": 3}
{"code": "private void registerPrefixIntersection(String field, String prefix,\n      int start, int end,\n      HashMap<String, HashSet<Integer>> docFieldAdministration) {\n    if (!intersectingPrefixes.containsKey(field)) {\n      intersectingPrefixes.put(field, new HashSet<String>());\n    } else if (intersectingPrefixes.get(field).contains(prefix)) {\n      return;\n    }\n    HashSet<Integer> docFieldPrefixAdministration;\n    if (!docFieldAdministration.containsKey(prefix)) {\n      docFieldPrefixAdministration = new HashSet<>();\n      docFieldAdministration.put(prefix, docFieldPrefixAdministration);\n    } else {\n      docFieldPrefixAdministration = docFieldAdministration.get(prefix);\n      // check\n      for (int p = start; p <= end; p++) {\n        if (docFieldPrefixAdministration.contains(p)) {\n          intersectingPrefixes.get(field).add(prefix);\n          docFieldAdministration.remove(prefix);\n          return;\n        }\n      }\n    }\n    // update\n    for (int p = start; p <= end; p++) {\n      docFieldPrefixAdministration.add(p);\n    }\n  }", "label": 0}
{"code": "def enter(self, pub_id, *nodes):\n        '''Agents will try to enter. The pub checks if it is possible'''\n        try:\n            pub = self['pubs'][pub_id]\n        except KeyError:\n            raise ValueError('Pub {} is not available'.format(pub_id))\n        if not pub['open'] or (pub['capacity'] < (len(nodes) + pub['occupancy'])):\n            return False\n        pub['occupancy'] += len(nodes)\n        for node in nodes:\n            node['pub'] = pub_id\n        return True", "label": 1}
{"code": "func GetClusterNameSchema(extensionSchema string) string {\n\tvar clusterNameSchema string\n\tif clusterNameSchema == \"\" {\n\t\tclusterNameSchema = fmt.Sprintf(ClusterNameSpecSchemaTemplate, \"\")\n\t} else {\n\t\tclusterNameSchema = fmt.Sprintf(ClusterNameSpecSchemaTemplate, \",\"+extensionSchema)\n\t}\n\treturn fmt.Sprintf(V2SchemaTemplate, MetadataSchema, clusterNameSchema, DefaultDefinitions)\n}", "label": 5}
{"code": "func (f *Fpdf) SetX(x float64) {\n\tif x >= 0 {\n\t\tf.x = x\n\t} else {\n\t\tf.x = f.w + x\n\t}\n}", "label": 5}
{"code": "def read(self):\n        \"\"\"Reads data from the CSV file.\"\"\"\n        companies = []\n        with open(self.file) as f:\n            reader = unicodecsv.reader(f)\n            for line in reader:\n                if len(line) >= 1:\n                    cnpj = self.format(line[0])\n                    if self.valid(cnpj):\n                        companies.append(cnpj)\n        return companies", "label": 1}
{"code": "function tryGetObjectLikeCompletionSymbols(objectLikeContainer) {\n                // We're looking up possible property names from contextual/inferred/declared type.\n                isMemberCompletion = true;\n                var typeForObject;\n                var existingMembers;\n                if (objectLikeContainer.kind === 171 /* ObjectLiteralExpression */) {\n                    // We are completing on contextual types, but may also include properties\n                    // other than those within the declared type.\n                    isNewIdentifierLocation = true;\n                    // If the object literal is being assigned to something of type 'null | { hello: string }',\n                    // it clearly isn't trying to satisfy the 'null' type. So we grab the non-nullable type if possible.\n                    typeForObject = typeChecker.getContextualType(objectLikeContainer);\n                    typeForObject = typeForObject && typeForObject.getNonNullableType();\n                    existingMembers = objectLikeContainer.properties;\n                }\n                else if (objectLikeContainer.kind === 167 /* ObjectBindingPattern */) {\n                    // We are *only* completing on properties from the type being destructured.\n                    isNewIdentifierLocation = false;\n                    var rootDeclaration = ts.getRootDeclaration(objectLikeContainer.parent);\n                    if (ts.isVariableLike(rootDeclaration)) {\n                        // We don't want to complete using the type acquired by the shape\n                        // of the binding pattern; we are only interested in types acquired\n                        // through type declaration or inference.\n                        // Also proceed if rootDeclaration is a parameter and if its containing function expression/arrow function is contextually typed -\n                        // type of parameter will flow in from the contextual type of the function\n                        var canGetType = !!(rootDeclaration.initializer || rootDeclaration.type);\n                        if (!canGetType && rootDeclaration.kind === 142 /* Parameter */) {\n                            if (ts.isExpression(rootDeclaration.parent)) {\n                                canGetType = !!typeChecker.getContextualType(rootDeclaration.parent);\n                            }\n                            else if (rootDeclaration.parent.kind === 147 /* MethodDeclaration */ || rootDeclaration.parent.kind === 150 /* SetAccessor */) {\n                                canGetType = ts.isExpression(rootDeclaration.parent.parent) && !!typeChecker.getContextualType(rootDeclaration.parent.parent);\n                            }\n                        }\n                        if (canGetType) {\n                            typeForObject = typeChecker.getTypeAtLocation(objectLikeContainer);\n                            existingMembers = objectLikeContainer.elements;\n                        }\n                    }\n                    else {\n                        ts.Debug.fail(\"Root declaration is not variable-like.\");\n                    }\n                }\n                else {\n                    ts.Debug.fail(\"Expected object literal or binding pattern, got \" + objectLikeContainer.kind);\n                }\n                if (!typeForObject) {\n                    return false;\n                }\n                var typeMembers = typeChecker.getPropertiesOfType(typeForObject);\n                if (typeMembers && typeMembers.length > 0) {\n                    // Add filtered items to the completion list\n                    symbols = filterObjectMembersList(typeMembers, existingMembers);\n                }\n                return true;\n            }", "label": 3}
{"code": "public static base_response convert(nitro_service client, sslpkcs8 resource) throws Exception {\n\t\tsslpkcs8 convertresource = new sslpkcs8();\n\t\tconvertresource.pkcs8file = resource.pkcs8file;\n\t\tconvertresource.keyfile = resource.keyfile;\n\t\tconvertresource.keyform = resource.keyform;\n\t\tconvertresource.password = resource.password;\n\t\treturn convertresource.perform_operation(client,\"convert\");\n\t}", "label": 0}
{"code": "def send(email, subject=None,\n         from_email=None, to_email=None,\n         cc=None, bcc=None, reply_to=None,\n         smtp=None):\n    \"\"\"Send markdown email\n\n    Args:\n        email (str/obj): A markdown string or EmailContent object \n        subject (str): subject line\n        from_email (str): sender email address\n        to_email (str/list): recipient email addresses\n        cc (str/list): CC email addresses (string or a list)\n        bcc (str/list): BCC email addresses (string or a list)\n        reply_to (str): Reply-to email address\n        smtp (dict): SMTP configuration (dict)\n\n    Schema of smtp dict:\n        host (str): SMTP server host. Default: localhost\n        port (int): SMTP server port. Default: 25\n        tls (bool): Use TLS. Default: False\n        ssl (bool): Use SSL. Default: False\n        user (bool): SMTP login user. Default empty\n        password (bool): SMTP login password. Default empty\n    \"\"\"\n    if is_string(email):\n        email = EmailContent(email)\n\n    from_email = sanitize_email_address(from_email or email.headers.get('from'))\n    to_email = sanitize_email_address(to_email or email.headers.get('to'))\n    cc = sanitize_email_address(cc or email.headers.get('cc'))\n    bcc = sanitize_email_address(bcc or email.headers.get('bcc'))\n    reply_to = sanitize_email_address(reply_to or email.headers.get('reply-to'))\n\n    message_args = {\n        'html': email.html,\n        'text': email.text,\n        'subject': (subject or email.headers.get('subject', '')),\n        'mail_from': from_email,\n        'mail_to': to_email\n    }\n    if cc:\n        message_args['cc'] = cc\n    if bcc:\n        message_args['bcc'] = bcc\n    if reply_to:\n        message_args['headers'] = {'reply-to': reply_to}\n\n    message = emails.Message(**message_args)\n\n    for filename, data in email.inline_images:\n        message.attach(filename=filename, content_disposition='inline', data=data)\n\n    message.send(smtp=smtp)", "label": 1}
{"code": "private Object toReference(int type, Object referent, int hash)\r\n    {\r\n        switch (type)\r\n        {\r\n            case HARD:\r\n                return referent;\r\n            case SOFT:\r\n                return new SoftRef(hash, referent, queue);\r\n            case WEAK:\r\n                return new WeakRef(hash, referent, queue);\r\n            default:\r\n                throw new Error();\r\n        }\r\n    }", "label": 0}
{"code": "def phylesystem_api_url(self, base_url, study_id):\n        \"\"\"Returns URL and param dict for a GET call to phylesystem_api\n        \"\"\"\n        p = self._phylesystem_api_params()\n        e = self._phylesystem_api_ext()\n        if self.content == 'study':\n            return '{d}/study/{i}{e}'.format(d=base_url, i=study_id, e=e), p\n        elif self.content == 'tree':\n            if self.content_id is None:\n                return '{d}/study/{i}/tree{e}'.format(d=base_url, i=study_id, e=e), p\n            return '{d}/study/{i}/tree/{t}{e}'.format(d=base_url, i=study_id, t=self.content_id, e=e), p\n        elif self.content == 'subtree':\n            assert self.content_id is not None\n            t, n = self.content_id\n            p['subtree_id'] = n\n            return '{d}/study/{i}/subtree/{t}{e}'.format(d=base_url, i=study_id, t=t, e=e), p\n        elif self.content == 'meta':\n            return '{d}/study/{i}/meta{e}'.format(d=base_url, i=study_id, e=e), p\n        elif self.content == 'otus':\n            if self.content_id is None:\n                return '{d}/study/{i}/otus{e}'.format(d=base_url, i=study_id, e=e), p\n            return '{d}/study/{i}/otus/{t}{e}'.format(d=base_url, i=study_id, t=self.content_id, e=e), p\n        elif self.content == 'otu':\n            if self.content_id is None:\n                return '{d}/study/{i}/otu{e}'.format(d=base_url, i=study_id, e=e), p\n            return '{d}/study/{i}/otu/{t}{e}'.format(d=base_url, i=study_id, t=self.content_id, e=e), p\n        elif self.content == 'otumap':\n            return '{d}/otumap/{i}{e}'.format(d=base_url, i=study_id, e=e), p\n        else:\n            assert False", "label": 1}
{"code": "def point_rotate(pt, ax, theta):\n    \"\"\" Rotate a 3-D point around a 3-D axis through the origin.\n\n    Handedness is a counter-clockwise rotation when viewing the rotation\n    axis as pointing at the observer.  Thus, in a right-handed x-y-z frame,\n    a 90deg rotation of (1,0,0) around the z-axis (0,0,1) yields a point at\n    (0,1,0).\n\n    .. todo:: Complete point_rotate docstring\n\n    Raises\n    ------\n    ValueError : If theta is nonscalar\n    ValueError : If pt or ax are not reducible to 3-D vectors\n    ValueError : If norm of ax is too small\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Ensure pt is reducible to 3-D vector.\n    pt = make_nd_vec(pt, nd=3, t=np.float64, norm=False)\n\n    # Calculate the rotation\n    rot_pt = np.dot(mtx_rot(ax, theta, reps=1), pt)\n\n    # Should be ready to return\n    return rot_pt", "label": 1}
{"code": "def bulk_launch(self, jobs=None, filter=None, all=False): # pylint: disable=redefined-builtin\n        \"\"\"Bulk launch a set of jobs.\n\n        :param jobs: :class:`jobs.Job <jobs.Job>` list\n        :param filter: (optional) Filters to apply as a string list.\n        :param all: (optional) Apply to all if bool `True`.\n        \"\"\"\n        json = None\n        if jobs is not None:\n            schema = JobSchema(exclude=('id', 'status', 'package_name', 'config_name', 'device_name', 'result_id', 'user_id', 'created', 'updated', 'automatic'))\n            jobs_json = self.service.encode(schema, jobs, many=True)\n            json = {self.RESOURCE: jobs_json}\n\n        schema = JobSchema()\n        resp = self.service.post(self.base,\n                                 params={'bulk': 'launch', 'filter': filter, 'all': all}, json=json)\n        return self.service.decode(schema, resp, many=True)", "label": 1}
{"code": "def get(*args)\n      arguments(args, required: [:column_id])\n      params = arguments.params\n\n      params[\"accept\"] ||= ::Github::Client::Projects::PREVIEW_MEDIA\n\n      get_request(\"/projects/columns/#{arguments.column_id}\", params)\n    end", "label": 4}
{"code": "public function setWebDetectionParams($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Vision\\V1\\WebDetectionParams::class);\n        $this->web_detection_params = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "func (l *RateLimiter) WrapHandle(h http.Handler) {\n\tl.TokenLimiter.Wrap(h)\n}", "label": 5}
{"code": "def logo_url(self):\n        \"\"\"Get URL to collection logo.\n\n        :returns: Path to community logo.\n        :rtype: str\n        \"\"\"\n        if self.logo_ext:\n            return '/api/files/{bucket}/{key}'.format(\n                bucket=current_app.config['COMMUNITIES_BUCKET_UUID'],\n                key='{0}/logo.{1}'.format(self.id, self.logo_ext),\n            )\n        return None", "label": 1}
{"code": "def page_title(step, title):\n    \"\"\"\n    Check that the page title matches the given one.\n    \"\"\"\n\n    with AssertContextManager(step):\n        assert_equals(world.browser.title, title)", "label": 1}
{"code": "func (d Datastore) URL(ctx context.Context, dc *Datacenter, path string) (*url.URL, error) {\n\treturn d.NewURL(path), nil\n}", "label": 5}
{"code": "public function findOrFail($id, User $actor = null)\n    {\n        return $this->queryVisibleTo($actor)->findOrFail($id);\n    }", "label": 2}
{"code": "def add_chart(chart_type, options)\n      @drawing ||= Drawing.new worksheet\n      drawing.add_chart(chart_type, options)\n    end", "label": 4}
{"code": "func (cli *NetworkCli) CmdServiceInfo(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"info\", \"SERVICE[.NETWORK]\", \"Displays detailed information about a service\", false)\n\tcmd.Require(flag.Min, 1)\n\n\terr := cmd.ParseFlags(args, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsn, nn := parseServiceName(cmd.Arg(0))\n\tserviceID, err := lookupServiceID(cli, nn, sn)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tobj, _, err := readBody(cli.call(\"GET\", \"/services/\"+serviceID, nil, nil))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsr := &serviceResource{}\n\tif err := json.NewDecoder(bytes.NewReader(obj)).Decode(sr); err != nil {\n\t\treturn err\n\t}\n\n\tfmt.Fprintf(cli.out, \"Service Id: %s\\n\", sr.ID)\n\tfmt.Fprintf(cli.out, \"\\tName: %s\\n\", sr.Name)\n\tfmt.Fprintf(cli.out, \"\\tNetwork: %s\\n\", sr.Network)\n\n\treturn nil\n}", "label": 5}
{"code": "def load_password_for_transporter\n      # 3 different sources for the password\n      #   1) ENV variable for application specific password\n      if ENV[TWO_FACTOR_ENV_VARIABLE].to_s.length > 0\n        UI.message(\"Fetching password for transporter from environment variable named `#{TWO_FACTOR_ENV_VARIABLE}`\")\n        return ENV[TWO_FACTOR_ENV_VARIABLE]\n      end\n      #   2) TWO_STEP_HOST_PREFIX from keychain\n      account_manager = CredentialsManager::AccountManager.new(user: @user,\n                                                             prefix: TWO_STEP_HOST_PREFIX,\n                                                               note: \"application-specific\")\n      password = account_manager.password(ask_if_missing: false)\n      return password if password.to_s.length > 0\n      #   3) standard iTC password\n      account_manager = CredentialsManager::AccountManager.new(user: @user)\n      return account_manager.password(ask_if_missing: true)\n    end", "label": 4}
{"code": "func (ds *datastore) PutObject(kvObject KVObject) error {\n\tif ds.sequential {\n\t\tds.Lock()\n\t\tdefer ds.Unlock()\n\t}\n\n\tif kvObject == nil {\n\t\treturn types.BadRequestErrorf(\"invalid KV Object : nil\")\n\t}\n\n\tif kvObject.Skip() {\n\t\tgoto add_cache\n\t}\n\n\tif err := ds.putObjectWithKey(kvObject, kvObject.Key()...); err != nil {\n\t\treturn err\n\t}\n\nadd_cache:\n\tif ds.cache != nil {\n\t\t// If persistent store is skipped, sequencing needs to\n\t\t// happen in cache.\n\t\treturn ds.cache.add(kvObject, kvObject.Skip())\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "func (cli *NetworkCli) CmdServiceLs(chain string, args ...string) error {\n\tcmd := cli.Subcmd(chain, \"ls\", \"SERVICE\", \"Lists all the services on a network\", false)\n\tflNetwork := cmd.String([]string{\"net\", \"-network\"}, \"\", \"Only show the services that are published on the specified network\")\n\tquiet := cmd.Bool([]string{\"q\", \"-quiet\"}, false, \"Only display numeric IDs\")\n\tnoTrunc := cmd.Bool([]string{\"#notrunc\", \"-no-trunc\"}, false, \"Do not truncate the output\")\n\n\terr := cmd.ParseFlags(args, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar obj []byte\n\tif *flNetwork == \"\" {\n\t\tobj, _, err = readBody(cli.call(\"GET\", \"/services\", nil, nil))\n\t} else {\n\t\tobj, _, err = readBody(cli.call(\"GET\", \"/services?network=\"+*flNetwork, nil, nil))\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar serviceResources []serviceResource\n\terr = json.Unmarshal(obj, &serviceResources)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t\treturn err\n\t}\n\n\twr := tabwriter.NewWriter(cli.out, 20, 1, 3, ' ', 0)\n\t// unless quiet (-q) is specified, print field titles\n\tif !*quiet {\n\t\tfmt.Fprintln(wr, \"SERVICE ID\\tNAME\\tNETWORK\\tCONTAINER\\tSANDBOX\")\n\t}\n\n\tfor _, sr := range serviceResources {\n\t\tID := sr.ID\n\t\tbkID, sbID, err := getBackendID(cli, ID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !*noTrunc {\n\t\t\tID = stringid.TruncateID(ID)\n\t\t\tbkID = stringid.TruncateID(bkID)\n\t\t\tsbID = stringid.TruncateID(sbID)\n\t\t}\n\t\tif !*quiet {\n\t\t\tfmt.Fprintf(wr, \"%s\\t%s\\t%s\\t%s\\t%s\\n\", ID, sr.Name, sr.Network, bkID, sbID)\n\t\t} else {\n\t\t\tfmt.Fprintln(wr, ID)\n\t\t}\n\t}\n\twr.Flush()\n\n\treturn nil\n}", "label": 5}
{"code": "def descendants\n      nodes = []\n      children.each do |c|\n        nodes << c\n        nodes << c.descendants\n      end\n      nodes.flatten\n    end", "label": 4}
{"code": "def write_branch_data(self, file):\n        \"\"\" Writes branch data to an Excel spreadsheet.\n        \"\"\"\n        branch_sheet = self.book.add_sheet(\"Branches\")\n\n        for i, branch in enumerate(self.case.branches):\n            for j, attr in enumerate(BRANCH_ATTRS):\n                branch_sheet.write(i, j, getattr(branch, attr))", "label": 1}
{"code": "public function publish($name)\n    {\n        if ($name instanceof Module) {\n            $module = $name;\n        } else {\n            $module = $this->laravel['modules']->findOrFail($name);\n        }\n\n        with(new AssetPublisher($module))\n            ->setRepository($this->laravel['modules'])\n            ->setConsole($this)\n            ->publish();\n\n        $this->line(\"<info>Published</info>: {$module->getStudlyName()}\");\n    }", "label": 2}
{"code": "public static IntRange GetRange( int[] values, double percent ){\n        int total = 0, n = values.length;\n\n        // for all values\n        for ( int i = 0; i < n; i++ )\n        {\n            // accumalate total\n            total += values[i];\n        }\n\n        int min, max, hits;\n        int h = (int) ( total * ( percent + ( 1 - percent ) / 2 ) );\n\n        // get range min value\n        for ( min = 0, hits = total; min < n; min++ )\n        {\n            hits -= values[min];\n            if ( hits < h )\n                break;\n        }\n        // get range max value\n        for ( max = n - 1, hits = total; max >= 0; max-- )\n        {\n            hits -= values[max];\n            if ( hits < h )\n                break;\n        }\n        return new IntRange( min, max );\n    }", "label": 0}
{"code": "func ConstructSSHResponse(response AuthParams) (*url.URL, error) {\n\tu, err := url.Parse(response.ClientRedirectURL)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tconsoleResponse := auth.SSHLoginResponse{\n\t\tUsername:    response.Username,\n\t\tCert:        response.Cert,\n\t\tTLSCert:     response.TLSCert,\n\t\tHostSigners: auth.AuthoritiesToTrustedCerts(response.HostSigners),\n\t}\n\tout, err := json.Marshal(consoleResponse)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// Extract secret out of the request. Look for both \"secret\" which is the\n\t// old format and \"secret_key\" which is the new fomat. If this is not done,\n\t// then users would have to update their callback URL in their identity\n\t// provider.\n\tvalues := u.Query()\n\tsecretV1 := values.Get(\"secret\")\n\tsecretV2 := values.Get(\"secret_key\")\n\tvalues.Set(\"secret\", \"\")\n\tvalues.Set(\"secret_key\", \"\")\n\n\tvar ciphertext []byte\n\n\tswitch {\n\t// AES-GCM based symmetric cipher.\n\tcase secretV2 != \"\":\n\t\tkey, err := secret.ParseKey([]byte(secretV2))\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tciphertext, err = key.Seal(out)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t// NaCl based symmetric cipher (legacy).\n\tcase secretV1 != \"\":\n\t\tsecretKeyBytes, err := lemma_secret.EncodedStringToKey(secretV1)\n\t\tif err != nil {\n\t\t\treturn nil, trace.BadParameter(\"bad secret\")\n\t\t}\n\t\tencryptor, err := lemma_secret.New(&lemma_secret.Config{KeyBytes: secretKeyBytes})\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tsealedBytes, err := encryptor.Seal(out)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tciphertext, err = json.Marshal(sealedBytes)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\tdefault:\n\t\treturn nil, trace.BadParameter(\"missing secret\")\n\t}\n\n\t// Place ciphertext into the response body.\n\tvalues.Set(\"response\", string(ciphertext))\n\n\tu.RawQuery = values.Encode()\n\treturn u, nil\n}", "label": 5}
{"code": "def attachment_image_tag(record, name, *args, fallback: nil, host: nil, prefix: nil, format: nil, **options)\n      file = record && record.public_send(name)\n      classes = [\"attachment\", (record.class.model_name.singular if record), name, *options[:class]]\n\n      if file\n        image_tag(attachment_url(record, name, *args, host: host, prefix: prefix, format: format), options.merge(class: classes))\n      elsif fallback\n        classes << \"fallback\"\n        image_tag(fallback, options.merge(class: classes))\n      end\n    end", "label": 4}
{"code": "function _xmlFileSet(file, element, attributeMapping, options) {\n  const doc = loadXmlFile(file, options);\n  const node = getXmlNode(doc, element);\n  const result = [];\n\n  if (_.isReallyObject(attributeMapping)) {\n    _.each(attributeMapping, (value, attributeName) => {\n      if (_.isFunction(value)) {\n        result.push(value(node.getAttributeNode(attributeName)));\n      } else {\n        if (_.isNull(value)) {\n          node.removeAttribute(attributeName);\n        } else {\n          node.setAttribute(attributeName, value);\n        }\n      }\n    });\n  } else {\n    // still being able to provide the node to pass the node to a given function\n    if (_.isFunction(attributeMapping)) {\n      result.push(attributeMapping(node, doc));\n    } else {\n      if (node.hasChildNodes()) {\n        let i = 0;\n        const nNodes = node.childNodes.length;\n        while (i < nNodes) {\n          node.removeChild(i);\n          i++;\n        }\n      }\n      // if attribute and value == null, delete the node\n      if (_.isNull(attributeMapping)) {\n        node.parentNode.removeChild(node);\n      } else {\n        node.appendChild(doc.createTextNode(attributeMapping));\n      }\n    }\n  }\n  write(file, new XMLSerializer().serializeToString(doc), options);\n  if (!_.isEmpty(result)) {\n    return (result.length > 1) ? result : result[0];\n  }\n}", "label": 3}
{"code": "def tree_iter_nexson_proxy(nexson_proxy):\n    \"\"\"Iterates over NexsonTreeProxy objects in order determined by the nexson blob\"\"\"\n    nexml_el = nexson_proxy._nexml_el\n    tg_order = nexml_el['^ot:treesElementOrder']\n    tgd = nexml_el['treesById']\n    for tg_id in tg_order:\n        tg = tgd[tg_id]\n        tree_order = tg['^ot:treeElementOrder']\n        tbid = tg['treeById']\n        otus = tg['@otus']\n        for k in tree_order:\n            v = tbid[k]\n            yield nexson_proxy._create_tree_proxy(tree_id=k, tree=v, otus=otus)", "label": 1}
{"code": "private function selectSession($context = SessionPoolInterface::CONTEXT_READ, array $options = [])\n    {\n        if ($this->session) {\n            return $this->session;\n        }\n\n        if ($this->sessionPool) {\n            return $this->session = $this->sessionPool->acquire($context);\n        }\n\n        return $this->session = $this->operation->createSession($this->name, $options);\n    }", "label": 2}
{"code": "def register(self, command, description, function, params=[]):\n        \"\"\"\n        Registers a new command for a plugin.\n\n        :param command: Name of the command\n        :param description: Description of the command. Is used as help message on cli\n        :param function: function reference, which gets invoked if command gets called.\n        :param params: list of click options and arguments\n        :return: command object\n        \"\"\"\n        return self.app.commands.register(command, description, function, params, self.plugin)", "label": 1}
{"code": "function pushToStash(config, msg) {\n        var client = net.connect({host: config.host, port: config.port}, function () {\n            client.write(msg);\n            client.end();\n        });\n        //Fail silently\n        client.on('error', function (evt) {\n            if (true === config.debug) {\n                console.log('An error happened in the logstash appender!', evt);\n            }\n        });\n    }", "label": 3}
{"code": "private CollectionDescriptorDef cloneCollection(CollectionDescriptorDef collDef, String prefix)\r\n    {\r\n        CollectionDescriptorDef copyCollDef = new CollectionDescriptorDef(collDef, prefix);\r\n\r\n        copyCollDef.setOwner(this);\r\n        // we remove properties that are only relevant to the class the features are declared in\r\n        copyCollDef.setProperty(PropertyHelper.OJB_PROPERTY_IGNORE, null);\r\n\r\n        Properties mod = getModification(copyCollDef.getName());\r\n\r\n        if (mod != null)\r\n        {\r\n            if (!PropertyHelper.toBoolean(mod.getProperty(PropertyHelper.OJB_PROPERTY_IGNORE), false) &&\r\n                hasFeature(copyCollDef.getName()))\r\n            {\r\n                LogHelper.warn(true,\r\n                               ClassDescriptorDef.class,\r\n                               \"process\",\r\n                               \"Class \"+getName()+\" has a feature that has the same name as its included collection \"+\r\n                               copyCollDef.getName()+\" from class \"+collDef.getOwner().getName()); \r\n            }\r\n            copyCollDef.applyModifications(mod);\r\n        }\r\n        return copyCollDef;\r\n    }", "label": 0}
{"code": "func createMacVlan(containerIfName, parent, macvlanMode string) (string, error) {\n\t// Set the macvlan mode. Default is bridge mode\n\tmode, err := setMacVlanMode(macvlanMode)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"Unsupported %s macvlan mode: %v\", macvlanMode, err)\n\t}\n\t// verify the Docker host interface acting as the macvlan parent iface exists\n\tif !parentExists(parent) {\n\t\treturn \"\", fmt.Errorf(\"the requested parent interface %s was not found on the Docker host\", parent)\n\t}\n\t// Get the link for the master index (Example: the docker host eth iface)\n\tparentLink, err := ns.NlHandle().LinkByName(parent)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error occurred looking up the %s parent iface %s error: %s\", macvlanType, parent, err)\n\t}\n\t// Create a macvlan link\n\tmacvlan := &netlink.Macvlan{\n\t\tLinkAttrs: netlink.LinkAttrs{\n\t\t\tName:        containerIfName,\n\t\t\tParentIndex: parentLink.Attrs().Index,\n\t\t},\n\t\tMode: mode,\n\t}\n\tif err := ns.NlHandle().LinkAdd(macvlan); err != nil {\n\t\t// If a user creates a macvlan and ipvlan on same parent, only one slave iface can be active at a time.\n\t\treturn \"\", fmt.Errorf(\"failed to create the %s port: %v\", macvlanType, err)\n\t}\n\n\treturn macvlan.Attrs().Name, nil\n}", "label": 5}
{"code": "func (g GridType) Y(dataY float64) float64 {\n\treturn g.ym*dataY + g.yb\n}", "label": 5}
{"code": "def for_hook(hook, hook_type = nil)\n      unless hook_type\n        components = hook.class.name.split('::')\n        hook = components.last\n        hook_type = components[-2]\n      end\n\n      # Merge hook configuration with special 'ALL' config\n      hook_config = smart_merge(@hash[hook_type]['ALL'], @hash[hook_type][hook] || {})\n\n      # Need to specially handle `enabled` option since not setting it does not\n      # necessarily mean the hook is disabled\n      hook_config['enabled'] = hook_enabled?(hook_type, hook)\n\n      hook_config.freeze\n    end", "label": 4}
{"code": "func (l *Logger) Errorf(format string, a ...interface{}) {\n\tl.Print(l.formatErr(fmt.Errorf(format, a...), \"\"))\n}", "label": 5}
{"code": "def color_fill_to_border(x, y, fill)\n      color_flood_fill(border_color, fill, x, y, Magick::FillToBorderMethod)\n    end", "label": 4}
{"code": "func (a *AuthWithRoles) DeleteClusterConfig() error {\n\tif err := a.action(defaults.Namespace, services.KindClusterConfig, services.VerbDelete); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.DeleteClusterConfig()\n}", "label": 5}
{"code": "function checkWorkingDir(workingDir, cb) {\n  fs.stat(workingDir, function(err, stats) {\n    var errMessage;\n    if (err) {\n      errMessage = \"The directory \" + workingDir + \" does not exist.\";\n      logger.error(errMessage);\n      return cb(errMessage);\n    }\n\n    //Checking that it is a directory\n    if (!stats.isDirectory()) {\n      errMessage = \"Expected \" + workingDir + \" to be a directory\";\n      logger.error(errMessage);\n      return cb(errMessage);\n    }\n\n    return cb();\n  });\n}", "label": 3}
{"code": "def distance_to(self, other_catchment):\n        \"\"\"\n        Returns the distance between the centroids of two catchments in kilometers.\n\n        :param other_catchment: Catchment to calculate distance to\n        :type other_catchment: :class:`.Catchment`\n        :return: Distance between the catchments in km.\n        :rtype: float\n        \"\"\"\n        try:\n            if self.country == other_catchment.country:\n                try:\n                    return 0.001 * hypot(self.descriptors.centroid_ngr.x - other_catchment.descriptors.centroid_ngr.x,\n                                         self.descriptors.centroid_ngr.y - other_catchment.descriptors.centroid_ngr.y)\n                except TypeError:\n                    # In case no centroid available, just return infinity which is helpful in most cases\n                    return float('+inf')\n            else:\n                # If the catchments are in a different country (e.g. `ni` versus `gb`) then set distance to infinity.\n                return float('+inf')\n        except (TypeError, KeyError):\n            raise InsufficientDataError(\"Catchment `descriptors` attribute must be set first.\")", "label": 1}
{"code": "public function query(GraphQLRequest $request)\n    {\n        $this->eventsDispatcher->dispatch(\n            new StartRequest($request)\n        );\n\n        $result = $request->isBatched()\n            ? $this->executeBatched($request)\n            : $this->graphQL->executeRequest($request);\n\n        $response = $this->createsResponse->createResponse($result);\n\n        // When handling multiple requests during the application lifetime,\n        // for example in tests, we need a new GraphQLRequest instance\n        // for each HTTP request, so we forget the singleton here.\n        $this->container->forgetInstance(GraphQLRequest::class);\n\n        return $response;\n    }", "label": 2}
{"code": "public function sendKeys($keys)\n    {\n        $this->executor->execute(DriverCommand::SEND_KEYS_TO_ACTIVE_ELEMENT, [\n            'value' => WebDriverKeys::encode($keys),\n        ]);\n\n        return $this;\n    }", "label": 2}
{"code": "public function setBlurredLikelihood($var)\n    {\n        GPBUtil::checkEnum($var, \\Google\\Cloud\\Vision\\V1\\Likelihood::class);\n        $this->blurred_likelihood = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "def update(*args)\n      arguments(args, required: [:user, :repo, :ref]) do\n        permit VALID_REF_PARAM_NAMES\n        assert_required %w[ sha ]\n      end\n\n      patch_request(\"/repos/#{arguments.user}/#{arguments.repo}/git/refs/#{arguments.ref}\", arguments.params)\n    end", "label": 4}
{"code": "def watch(pattern, &action)\n      # Allow watches in the global scope (to execute arbitrary commands) by\n      # building a generic Guard::Plugin.\n      @plugin_options ||= nil\n      return guard(:plugin) { watch(pattern, &action) } unless @plugin_options\n\n      @plugin_options[:watchers] << Watcher.new(pattern, action)\n    end", "label": 4}
{"code": "public static <E> List<E> deleteOutofRange(Counter<E> c, int top, int bottom) {\r\n\r\n    List<E> purgedItems = new ArrayList<E>();\r\n    int numToPurge = top + bottom;\r\n    if (numToPurge <= 0) {\r\n      return purgedItems;\r\n    }\r\n\r\n    List<E> l = Counters.toSortedList(c);\r\n    for (int i = 0; i < top; i++) {\r\n      E item = l.get(i);\r\n      purgedItems.add(item);\r\n      c.remove(item);\r\n    }\r\n    int size = c.size();\r\n    for (int i = c.size() - 1; i >= (size - bottom); i--) {\r\n      E item = l.get(i);\r\n      purgedItems.add(item);\r\n      c.remove(item);\r\n    }\r\n    return purgedItems;\r\n  }", "label": 0}
{"code": "function getSiblings(el) {\n    const allSiblings = getPreviousSiblings(el).concat(getNextSiblings(el));\n\n    return allSiblings.filter(filterSibling);\n}", "label": 3}
{"code": "func stat(name string) (*info, error) {\n\tf, err := os.Open(filepath.Clean(name))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar di info\n\n\tvar buf bytes.Buffer\n\n\t_, err = io.CopyN(&buf, f, int64(binary.Size(di.Header)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfi, err := f.Stat()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = f.Close()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = binary.Read(&buf, binary.LittleEndian, &di.Header)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif di.Header.MagicNumber != 0x564d444b { // SPARSE_MAGICNUMBER\n\t\treturn nil, ErrInvalidFormat\n\t}\n\n\tif di.Header.Flags&(1<<16) == 0 { // SPARSEFLAG_COMPRESSED\n\t\t// Needs to be converted, for example:\n\t\t//   vmware-vdiskmanager -r src.vmdk -t 5 dst.vmdk\n\t\t//   qemu-img convert -O vmdk -o subformat=streamOptimized src.vmdk dst.vmdk\n\t\treturn nil, ErrInvalidFormat\n\t}\n\n\tdi.Capacity = di.Header.Capacity * 512 // VMDK_SECTOR_SIZE\n\tdi.Size = fi.Size()\n\tdi.Name = filepath.Base(name)\n\tdi.ImportName = strings.TrimSuffix(di.Name, \".vmdk\")\n\n\treturn &di, nil\n}", "label": 5}
{"code": "public function walkSimpleCaseExpression($simpleCaseExpression)\n    {\n        $sql = 'CASE ' . $this->walkStateFieldPathExpression($simpleCaseExpression->caseOperand);\n\n        foreach ($simpleCaseExpression->simpleWhenClauses as $simpleWhenClause) {\n            $sql .= ' WHEN ' . $this->walkSimpleArithmeticExpression($simpleWhenClause->caseScalarExpression);\n            $sql .= ' THEN ' . $this->walkSimpleArithmeticExpression($simpleWhenClause->thenScalarExpression);\n        }\n\n        $sql .= ' ELSE ' . $this->walkSimpleArithmeticExpression($simpleCaseExpression->elseScalarExpression) . ' END';\n\n        return $sql;\n    }", "label": 2}
{"code": "def local_number\n      return national unless possible?\n      format_match, format_string = formatting_data\n\n      if format_string =~ /^.*[0-9]+.*\\$1/ && format_match\n        format_string.gsub(/^.*\\$2/, '$2')\n          .gsub(/\\$\\d/) { |el| format_match[el[1].to_i] }\n      else\n        national\n      end\n    end", "label": 4}
{"code": "func (s SearchIndex) FindByUuid(ctx context.Context, dc *Datacenter, uuid string, vmSearch bool, instanceUuid *bool) (Reference, error) {\n\treq := types.FindByUuid{\n\t\tThis:         s.Reference(),\n\t\tUuid:         uuid,\n\t\tVmSearch:     vmSearch,\n\t\tInstanceUuid: instanceUuid,\n\t}\n\tif dc != nil {\n\t\tref := dc.Reference()\n\t\treq.Datacenter = &ref\n\t}\n\n\tres, err := methods.FindByUuid(ctx, s.c, &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif res.Returnval == nil {\n\t\treturn nil, nil\n\t}\n\treturn NewReference(s.c, *res.Returnval), nil\n}", "label": 5}
{"code": "func (cs callSet) Remove(call *Call) {\n\tkey := callSetKey{call.receiver, call.method}\n\tcalls := cs.expected[key]\n\tfor i, c := range calls {\n\t\tif c == call {\n\t\t\t// maintain order for remaining calls\n\t\t\tcs.expected[key] = append(calls[:i], calls[i+1:]...)\n\t\t\tcs.exhausted[key] = append(cs.exhausted[key], call)\n\t\t\tbreak\n\t\t}\n\t}\n}", "label": 5}
{"code": "public IndirectionHandler getIndirectionHandler(Object obj)\r\n    {\r\n        if(obj == null)\r\n        {\r\n            return null;\r\n        }\r\n        else if(isNormalOjbProxy(obj))\r\n        {\r\n            return getDynamicIndirectionHandler(obj);\r\n        }\r\n        else if(isVirtualOjbProxy(obj))\r\n        {\r\n            return VirtualProxy.getIndirectionHandler((VirtualProxy) obj);\r\n        }\r\n        else\r\n        {\r\n            return null;\r\n        }\r\n\r\n    }", "label": 0}
{"code": "function ajax( opts ) {\n  const method = (opts.method || 'get').toUpperCase()\n  const {\n    url,\n    body,\n    contentType,\n    extraHeaders,\n    useBearer = true,\n    bearer\n  } = opts || {}\n\n  let requestInit = {\n    method,\n    headers: fetchHeaders({\n      method,\n      contentType,\n      extraHeaders,\n      useBearer,\n      bearer\n    }),\n    credentials: 'same-origin'\n  }\n  if( method != 'GET' && method != 'HEAD' && method != 'OPTIONS') {\n    requestInit.body = body\n  }\n\n  let request = new Request( url, requestInit )\n  return fetch( request )\n    .then( response => {\n      if( !!response.ok ) {\n        if( response.status == 204 ) {\n          return {}\n        }\n        if( typeof TINYAPI_NODE !== 'undefined' && TINYAPI_NODE ) {\n          return response\n        }\n        if( !!response.json ) {\n          return response.json()\n        }\n        else {\n          return response\n        }\n      }\n      if( !!response.json ) {\n        return response.json()\n                       .catch( e => Object({ status: response.status }) )\n                       .then( e => Promise.reject( e ) )\n      }\n      else {\n        return response \n      }\n    })\n}", "label": 3}
{"code": "public static base_response delete(nitro_service client, String serverip) throws Exception {\n\t\tntpserver deleteresource = new ntpserver();\n\t\tdeleteresource.serverip = serverip;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "function () {\n        const crons = _.get(Shared, 'runtimeArgs.cron') || _.get(Shared, 'runtimeArgs.crons');\n        if (crons) {\n            const cronTasks = crons.replace(/\\s/g, '').split(',');\n            return cronTasks.length > 0 ? cronTasks : undefined;\n        }\n        return undefined;\n    }", "label": 3}
{"code": "public function setCreateModelDetails($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\AutoMl\\V1beta1\\CreateModelOperationMetadata::class);\n        $this->writeOneof(10, $var);\n\n        return $this;\n    }", "label": 2}
{"code": "func (c *Client) GetOIDCConnectors(withSecrets bool) ([]services.OIDCConnector, error) {\n\tout, err := c.Get(c.Endpoint(\"oidc\", \"connectors\"),\n\t\turl.Values{\"with_secrets\": []string{fmt.Sprintf(\"%t\", withSecrets)}})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar items []json.RawMessage\n\tif err := json.Unmarshal(out.Bytes(), &items); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tconnectors := make([]services.OIDCConnector, len(items))\n\tfor i, raw := range items {\n\t\tconnector, err := services.GetOIDCConnectorMarshaler().UnmarshalOIDCConnector(raw, services.SkipValidation())\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t\tconnectors[i] = connector\n\t}\n\treturn connectors, nil\n}", "label": 5}
{"code": "function exportProjectConfig(req, res, next) {\n  var options = req.connectionOptions;\n\n  forms.exportAppConfig(options, formsResultHandlers(constants.resultTypes.formProjects, req, next));\n}", "label": 3}
{"code": "def setup_environment\n      store_modified_times\n      Overcommit::GitRepo.store_merge_state\n      Overcommit::GitRepo.store_cherry_pick_state\n\n      if !initial_commit? && any_changes?\n        @stash_attempted = true\n\n        stash_message = \"Overcommit: Stash of repo state before hook run at #{Time.now}\"\n        result = Overcommit::Utils.execute(\n          %w[git -c commit.gpgsign=false stash save --keep-index --quiet] + [stash_message]\n        )\n\n        unless result.success?\n          # Failure to stash in this case is likely due to a configuration\n          # issue (e.g. author/email not set or GPG signing key incorrect)\n          raise Overcommit::Exceptions::HookSetupFailed,\n                \"Unable to setup environment for #{hook_script_name} hook run:\" \\\n                \"\\nSTDOUT:#{result.stdout}\\nSTDERR:#{result.stderr}\"\n        end\n\n        @changes_stashed = `git stash list -1`.include?(stash_message)\n      end\n\n      # While running the hooks make it appear as if nothing changed\n      restore_modified_times\n    end", "label": 4}
{"code": "function deepFreeze(object) {\n    var prop, propKey;\n    Object.freeze(object); // first freeze the object\n    for (propKey in object) {\n      prop = object[propKey];\n      if (!object.hasOwnProperty(propKey) || (typeof prop !== 'object') || Object.isFrozen(prop)) {\n        // If the object is on the prototype, not an object, or is already frozen,\n        // skip it. Note that this might leave an unfrozen reference somewhere in the\n        // object if there is an already frozen object containing an unfrozen object.\n        continue;\n      }\n\n      deepFreeze(prop); // recursively call deepFreeze\n    }\n  }", "label": 3}
{"code": "def get(*args)\n      arguments(args, required: [:name])\n\n      name = arguments.name\n      response = list.body._links[name]\n      if response\n        params = arguments.params\n        params['accept'] = response.type\n        get_request(response.href, params)\n      end\n    end", "label": 4}
{"code": "public static <E> Counter<E> powNormalized(Counter<E> c, double temp) {\r\n    Counter<E> d = c.getFactory().create();\r\n    double total = c.totalCount();\r\n    for (E e : c.keySet()) {\r\n      d.setCount(e, Math.pow(c.getCount(e) / total, temp));\r\n    }\r\n    return d;\r\n  }", "label": 0}
{"code": "func (s SortedTrustedCluster) Less(i, j int) bool {\n\treturn s[i].GetName() < s[j].GetName()\n}", "label": 5}
{"code": "def register(self, name, path, plugin, description=None, final_words=None):\n        \"\"\"\n        Registers a new recipe.\n        \"\"\"\n        if name in self.recipes.keys():\n            raise RecipeExistsException(\"Recipe %s was already registered by %s\" %\n                                        (name, self.recipes[\"name\"].plugin.name))\n\n        self.recipes[name] = Recipe(name, path, plugin, description, final_words)\n        self.__log.debug(\"Recipe %s registered by %s\" % (name, plugin.name))\n        return self.recipes[name]", "label": 1}
{"code": "private Map<String, Entry> readEntries(String mapping, boolean ignoreCase) {\n\t\tMap<String, Entry> entries = new HashMap<>();\n\n\t\ttry {\n\t\t\t// ms, 2010-10-05: try to load the file from the CLASSPATH first\n\t\t\tInputStream is = getClass().getClassLoader().getResourceAsStream(mapping);\n\t\t\t// if not found in the CLASSPATH, load from the file system\n\t\t\tif (is == null) is = new FileInputStream(mapping);\n\t\t\tBufferedReader rd = new BufferedReader(new InputStreamReader(is));\n\n\t\t\tint lineCount = 0;\n\t\t\tfor (String line; (line = rd.readLine()) != null; ) {\n\t\t\t\tlineCount ++;\n\t\t\t\tString[] split = line.split(\"\\t\");\n\t\t\t\tif (split.length < 2 || split.length > 4)\n\t\t\t\t\tthrow new RuntimeException(\"Provided mapping file is in wrong format\");\n\t\t\t\tif (split[1].trim().equalsIgnoreCase(\"AS\")) System.err.println(\"ERRRR \" + mapping + \"|\" + line + \" at \" + lineCount);\n\t\t\t\tString stringLine = split[1].trim();\n\t\t\t\tif (ignoreCase) stringLine = stringLine.toLowerCase();\n\t\t\t\tString[] words = stringLine.split(\"\\\\s+\");\n\t\t\t\tString type = split[0].trim();\n\t\t\t\tSet<String> overwritableTypes = new HashSet<String>();\n\t\t\t\toverwritableTypes.add(flags.backgroundSymbol);\n\t\t\t\toverwritableTypes.add(null);\n\t\t\t\tdouble priority = 0;\n\t\t\t\tList<String> tokens = new ArrayList<String>();\n\n\t\t\t\ttry {\n\t\t\t\t\tif (split.length >= 3)\n\t\t\t\t\t\toverwritableTypes.addAll(Arrays.asList(split[2].trim().split(\",\")));\n\t\t\t\t\tif (split.length == 4)\n\t\t\t\t\t\tpriority = Double.parseDouble(split[3].trim());\n\n\t\t\t\t\tfor (String str : words) {\n\t\t\t\t\t\ttokens.add(str);\n\t\t\t\t\t}\n\t\t\t\t} catch(NumberFormatException e) {\n\t\t\t\t\tSystem.err.println(\"ERROR: Invalid line \" + lineCount + \" in regexner file \" + mapping + \": \\\"\" + line + \"\\\"!\");\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t\taddEntry(words, type, priority, overwritableTypes);\n\t\t\t}\n\t\t\trd.close();\n\t\t\tis.close();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\treturn entries;\n\t}", "label": 0}
{"code": "function ValidationError(\n  validationMessage,\n  entity,\n  attribute,\n  position,\n  innerError\n) {\n  /**\n   * The validation message to be included in the error.\n   * @type {?string}\n   */\n  this.validationMessage = validationMessage;\n  /**\n   * The name of the entity that was not validated.\n   * @type {?string}\n   */\n  this.entity = entity;\n  /**\n   * The name of the attribute that was not validated.\n   * @type {?string}\n   */\n  this.attribute = attribute;\n  /**\n   * The position of the item in the attribute that was not validated.\n   * @type {?(string|number)}\n   */\n  this.position = position;\n  /**\n   * The inner error that generated the current error.\n   * @type {?Error}\n   */\n  this.innerError = innerError;\n\n  expect(arguments).to.have.length.below(\n    6,\n    'Invalid arguments length when creating a new ' +\n    'AttributeTypeNotFoundError (it has to be passed less than 6 arguments)'\n  );\n\n  this.name = 'ValidationError';\n\n  this.message = 'Error when validating an attribute';\n  if (attribute) {\n    expect(attribute).to.be.a(\n      'string',\n      'Invalid argument \"attribute\" when creating a new ValidationError (it ' +\n      'has to be a string)'\n    );\n    this.message += ' called \"' + attribute + '\"';\n  }\n\n  this.message += ' of an entity';\n  if (entity) {\n    expect(entity).to.be.a(\n      'string',\n      'Invalid argument \"entity\" when creating a new ValidationError (it has ' +\n      'to be a string)'\n    );\n    this.message += ' called \"' + entity + '\"';\n  }\n\n  if (position) {\n    expect(['string', 'number']).to.include(\n      typeof position,\n      'Invalid argument \"position\" when creating a new ValidationError (it ' +\n      'has to be a string or a number)'\n    );\n    this.message += ' in position ' + position;\n  }\n\n  if (validationMessage) {\n    expect(validationMessage).to.be.a(\n      'string',\n      'Invalid argument \"validationMessage\" when creating a new ' +\n      'ValidationError (it has to be a string)'\n    );\n    this.message += ': ' + validationMessage;\n  }\n\n  this.stack = (new Error(this.message)).stack;\n  if (innerError) {\n    expect(innerError).to.be.an.instanceof(\n      Error,\n      'Invalid argument \"innerError\" when creating a new ' +\n      'ValidationError (it has to be an Error)'\n    );\n    this.stack += '\\n\\n' + innerError.stack;\n  }\n}", "label": 3}
{"code": "function sum(arr) {\n  var len = arr.length;\n  var num = 0;\n  while (len--) num += Number(arr[len]);\n  return num;\n}", "label": 3}
{"code": "func (s *PresenceService) DeleteAllTunnelConnections() error {\n\tstartKey := backend.Key(tunnelConnectionsPrefix)\n\terr := s.DeleteRange(context.TODO(), startKey, backend.RangeEnd(startKey))\n\treturn trace.Wrap(err)\n}", "label": 5}
{"code": "function _Stream(superObj) {\n\tvar self = this;\n\tthis._zSuperObj = superObj;\n\tthis._isZStream = true;\n\tthis._ignoreStreamError = false;\n\tthis._zStreamId = streamIdCounter++;\n\tthis._currentStreamChain = new StreamChain(true);\n\tthis._currentStreamChain._addStream(this);\n\tthis._zStreamRank = 0;\n\n\tthis.on('error', function(error) {\n\t\t// If there are no other 'error' handlers on this stream, trigger a chainerror\n\t\tif(self.listeners('error').length <= 1) {\n\t\t\tself.triggerChainError(error);\n\t\t}\n\t});\n}", "label": 3}
{"code": "func (s *PresenceService) DeleteAllNamespaces() error {\n\treturn s.DeleteRange(context.TODO(), backend.Key(namespacesPrefix), backend.RangeEnd(backend.Key(namespacesPrefix)))\n}", "label": 5}
{"code": "def render(view, locals, buffer = ActionView::OutputBuffer.new, &block)\n      instrument_render_template do\n        compile!(view)\n        view._run(method_name, self, locals, buffer, &block)\n      end\n    rescue => e\n      handle_render_error(view, e)\n    end", "label": 4}
{"code": "def search_scope_id\n      clean_scope_ids = if scope_id.is_a?(Hash)\n                          scope_id.values\n                        else\n                          [scope_id].flatten\n                        end\n\n      conditions = []\n      conditions << \"decidim_scope_id IS NULL\" if clean_scope_ids.delete(\"global\")\n      conditions.concat([\"? = ANY(decidim_scopes.part_of)\"] * clean_scope_ids.count) if clean_scope_ids.any?\n\n      query.includes(:scope).references(:decidim_scopes).where(conditions.join(\" OR \"), *clean_scope_ids.map(&:to_i))\n    end", "label": 4}
{"code": "private void addDependencyToGraph(final DbDependency dependency, final AbstractGraph graph, final int depth, final String parentId) {\n        // In that case of Axway artifact we will add a module to the graph\n        if (filters.getCorporateFilter().filter(dependency)) {\n            final DbModule dbTarget = repoHandler.getModuleOf(dependency.getTarget());\n\n            // if there is no module, add the artifact to the graph\n            if(dbTarget == null){\n                LOG.error(\"Got missing reference: \" + dependency.getTarget());\n                final DbArtifact dbArtifact = DataUtils.createDbArtifact(dependency.getTarget());\n                final String targetElementId = graph.getId(dbArtifact);\n                graph.addElement(targetElementId, dbArtifact.getVersion(), false);\n                graph.addDependency(parentId, targetElementId, dependency.getScope());\n                return;\n            }\n\n            // Add the element to the graph\n            addModuleToGraph(dbTarget, graph, depth + 1);\n\n            //Add the dependency to the graph\n            final String moduleElementId = graph.getId(dbTarget);\n            graph.addDependency(parentId, moduleElementId, dependency.getScope());\n        }\n        // In case a third-party we will add an artifact\n        else {\n            final DbArtifact dbTarget = repoHandler.getArtifact(dependency.getTarget());\n            if(dbTarget == null){\n                LOG.error(\"Got missing artifact: \" + dependency.getTarget());\n                return;\n            }\n\n            if(!graph.isTreated(graph.getId(dbTarget))){\n                final ModelMapper modelMapper = new ModelMapper(repoHandler);\n                final Artifact target = modelMapper.getArtifact(dbTarget);\n                final String targetElementId = graph.getId(target);\n                graph.addElement(targetElementId, target.getVersion(), false);\n                graph.addDependency(parentId, targetElementId, dependency.getScope());\n            }\n        }\n    }", "label": 0}
{"code": "function() {\n      var parentView = this;\n      this.__injectionSiteMap = {};\n      this.__lastTrackedViews = {};\n      _.each(this.getTrackedViews(), function(view) {\n        if (view.isAttachedToParent() && view.injectionSite) {\n          parentView.__injectionSiteMap[view.injectionSite.attr('inject')] = view;\n        }\n        parentView.__lastTrackedViews[view.cid] = view;\n      });\n    }", "label": 3}
{"code": "def stream(self):\n        \"\"\"Which stream, if any, the client is under\"\"\"\n        stream = self._p4dict.get('stream')\n        if stream:\n            return Stream(stream, self._connection)", "label": 1}
{"code": "def script_score(script, options = {})\n      scoring = {script_score: {script: script}.merge(options)}\n      chain { criteria.update_scores scoring }\n    end", "label": 4}
{"code": "public function setErrors($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Dlp\\V2\\Error::class);\n        $this->errors = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "protected function editColumns($data, $row)\n    {\n        foreach ($this->editColumns as $key => $value) {\n            $value['content'] = Helper::compileContent($value['content'], $data, $row);\n            Arr::set($data, $value['name'], $value['content']);\n        }\n\n        return $data;\n    }", "label": 2}
{"code": "private function configureSnapshotOptions(array &$options, array $previous = [])\n    {\n        $options += [\n            'singleUse' => false,\n            'returnReadTimestamp' => null,\n            'strong' => null,\n            'readTimestamp' => null,\n            'exactStaleness' => null,\n            'minReadTimestamp' => null,\n            'maxStaleness' => null,\n        ];\n\n        $previousOptions = isset($previous['transactionOptions']['readOnly'])\n            ? $previous['transactionOptions']['readOnly']\n            : [];\n\n        // These are only available in single-use transactions.\n        if (!$options['singleUse'] && ($options['maxStaleness'] || $options['minReadTimestamp'])) {\n            throw new \\BadMethodCallException(\n                'maxStaleness and minReadTimestamp are only available in single-use transactions.'\n            );\n        }\n\n        $transactionOptions = [\n            'readOnly' => $this->arrayFilterRemoveNull([\n                'returnReadTimestamp' => $this->pluck('returnReadTimestamp', $options),\n                'strong' => $this->pluck('strong', $options),\n                'minReadTimestamp' => $this->pluck('minReadTimestamp', $options),\n                'maxStaleness' => $this->pluck('maxStaleness', $options),\n                'readTimestamp' => $this->pluck('readTimestamp', $options),\n                'exactStaleness' => $this->pluck('exactStaleness', $options),\n            ]) + $previousOptions\n        ];\n\n        if (empty($transactionOptions['readOnly'])) {\n            $transactionOptions['readOnly']['strong'] = true;\n        }\n\n        $timestampFields = [\n            'minReadTimestamp',\n            'readTimestamp'\n        ];\n\n        $durationFields = [\n            'exactStaleness',\n            'maxStaleness'\n        ];\n\n        foreach ($timestampFields as $tsf) {\n            if (isset($transactionOptions['readOnly'][$tsf]) && !isset($previousOptions[$tsf])) {\n                $field = $transactionOptions['readOnly'][$tsf];\n                if (!($field instanceof Timestamp)) {\n                    throw new \\BadMethodCallException(sprintf(\n                        'Read Only Transaction Configuration Field %s must be an instance of `%s`.',\n                        $tsf,\n                        Timestamp::class\n                    ));\n                }\n\n                $transactionOptions['readOnly'][$tsf] = $field->formatAsString();\n            }\n        }\n\n        foreach ($durationFields as $df) {\n            if (isset($transactionOptions['readOnly'][$df]) && !isset($previousOptions[$df])) {\n                $field = $transactionOptions['readOnly'][$df];\n                if (!($field instanceof Duration)) {\n                    throw new \\BadMethodCallException(sprintf(\n                        'Read Only Transaction Configuration Field %s must be an instance of `%s`.',\n                        $df,\n                        Duration::class\n                    ));\n                }\n\n                $transactionOptions['readOnly'][$df] = $field->get();\n            }\n        }\n\n        return $transactionOptions;\n    }", "label": 2}
{"code": "@RequestMapping(value = \"/legendgraphic\", method = RequestMethod.GET)\n\tpublic ModelAndView getGraphic(@RequestParam(\"layerId\") String layerId,\n\t\t\t@RequestParam(value = \"styleName\", required = false) String styleName,\n\t\t\t@RequestParam(value = \"ruleIndex\", required = false) Integer ruleIndex,\n\t\t\t@RequestParam(value = \"format\", required = false) String format,\n\t\t\t@RequestParam(value = \"width\", required = false) Integer width,\n\t\t\t@RequestParam(value = \"height\", required = false) Integer height,\n\t\t\t@RequestParam(value = \"scale\", required = false) Double scale,\n\t\t\t@RequestParam(value = \"allRules\", required = false) Boolean allRules, HttpServletRequest request)\n\t\t\tthrows GeomajasException {\n\t\tif (!allRules) {\n\t\t\treturn getGraphic(layerId, styleName, ruleIndex, format, width, height, scale);\n\t\t} else {\n\t\t\treturn getGraphics(layerId, styleName, format, width, height, scale);\n\t\t}\n\t}", "label": 0}
{"code": "function getSentinelPosition(stickyElement, sentinel, className) {\n  const stickyStyle = window.getComputedStyle(stickyElement);\n  const parentStyle = window.getComputedStyle(stickyElement.parentElement);\n\n  switch (className) {\n    case ClassName.SENTINEL_TOP:\n      return {\n        top: `calc(${stickyStyle.getPropertyValue('top')} * -1)`,\n        height: 0,\n      };\n\n    case ClassName.SENTINEL_BOTTOM:\n      const parentPadding = parseInt(parentStyle.paddingTop);\n\n      return {\n        bottom: stickyStyle.top,\n        height: `${stickyElement.getBoundingClientRect().height + parentPadding}px`,\n      };\n  }\n}", "label": 3}
{"code": "func (t *TestTLSServer) Stop() error {\n\terr := t.TLSServer.Close()\n\tif t.Listener != nil {\n\t\tt.Listener.Close()\n\t}\n\treturn err\n}", "label": 5}
{"code": "private String jsonifyData(Map<String, ? extends Object> data) {\n        JSONObject jsonData = new JSONObject(data);\n\n        return jsonData.toString();\n    }", "label": 0}
{"code": "func FromBytes(input []byte) (u UUID, err error) {\n\terr = u.UnmarshalBinary(input)\n\treturn\n}", "label": 5}
{"code": "def ot_tnrs_match_names(name_list,\n                        context_name=None,\n                        do_approximate_matching=True,\n                        include_dubious=False,\n                        include_deprecated=True,\n                        tnrs_wrapper=None):\n    \"\"\"Uses a peyotl wrapper around an Open Tree web service to get a list of OTT IDs matching\n    the `name_list`.\n    The tnrs_wrapper can be None (in which case the default wrapper from peyotl.sugar will be used.\n    All other arguments correspond to the arguments of the web-service call.\n    A ValueError will be raised if the `context_name` does not match one of the valid names for a\n        taxonomic context.\n    This uses the wrap_response option to create and return a TNRSRespose object around the response.\n    \"\"\"\n    if tnrs_wrapper is None:\n        from peyotl.sugar import tnrs\n        tnrs_wrapper = tnrs\n    match_obj = tnrs_wrapper.match_names(name_list,\n                                         context_name=context_name,\n                                         do_approximate_matching=do_approximate_matching,\n                                         include_deprecated=include_deprecated,\n                                         include_dubious=include_dubious,\n                                         wrap_response=True)\n    return match_obj", "label": 1}
{"code": "def tokenize(self, string):\n        '''Yield tokens from the input string or throw ConfigParseError'''\n        pos = 0\n        while pos < len(string):\n            m = SKIP_RE.match(string, pos=pos)\n            if m:\n                skip_lines = m.group(0).split('\\n')\n                if len(skip_lines) > 1:\n                    self.row += len(skip_lines) - 1\n                    self.column = 1 + len(skip_lines[-1])\n                else:\n                    self.column += len(skip_lines[0])\n\n                pos = m.end()\n                continue\n\n            for cls, type, regex in self.token_map:\n                m = regex.match(string, pos=pos)\n                if m:\n                    yield cls(type, m.group(0),\n                              self.filename, self.row, self.column)\n                    self.column += len(m.group(0))\n                    pos = m.end()\n                    break\n            else:\n                raise ConfigParseError(\n                    \"Couldn't load config in %r row %d, column %d: %r\" %\n                    (self.filename, self.row, self.column,\n                     string[pos:pos+20]))", "label": 1}
{"code": "public function getShippingTotal(): int\n    {\n        $shippingTotal = $this->getAdjustmentsTotal(AdjustmentInterface::SHIPPING_ADJUSTMENT);\n        $shippingTotal += $this->getAdjustmentsTotal(AdjustmentInterface::ORDER_SHIPPING_PROMOTION_ADJUSTMENT);\n        $shippingTotal += $this->getAdjustmentsTotal(AdjustmentInterface::TAX_ADJUSTMENT);\n\n        return $shippingTotal;\n    }", "label": 2}
{"code": "public void cache(Identity oid, Object obj)\r\n    {\r\n        if (oid != null && obj != null)\r\n        {\r\n            ObjectCache cache = getCache(oid, obj, METHOD_CACHE);\r\n            if (cache != null)\r\n            {\r\n                cache.cache(oid, obj);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "func (cb *CellBuffer) Invalidate() {\n\tfor i := range cb.cells {\n\t\tcb.cells[i].lastMain = rune(0)\n\t}\n}", "label": 5}
{"code": "function requireGlob(pattern) {\n    return _.map(glob.sync(pattern), function (file) {\n        var required = require(file);\n\n        resolveProvide(required);\n        resolveInjects(required);\n\n        return required;\n    });\n  }", "label": 3}
{"code": "def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (\n                                    cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            self.authed_view = initkwargs.get('authed_view')\n            self.authed_view_kwargs = initkwargs.get('authed_view_kwargs')\n            self.anonymous_view = initkwargs.get('anonymous_view')\n            self.anonymous_view_kwargs = initkwargs.get(\n                'anonymous_view_kwargs')\n            return self.dispatch(request, *args, **kwargs)\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view", "label": 1}
{"code": "function createAttributeWrapper(gl, program, attributes, doLink) {\n  var obj = {}\n  for(var i=0, n=attributes.length; i<n; ++i) {\n    var a = attributes[i]\n    var name = a.name\n    var type = a.type\n    var location = gl.getAttribLocation(program, name)\n    \n    switch(type) {\n      case 'bool':\n      case 'int':\n      case 'float':\n        addVectorAttribute(gl, program, location, 1, obj, name, doLink)\n      break\n      \n      default:\n        if(type.indexOf('vec') >= 0) {\n          var d = type.charCodeAt(type.length-1) - 48\n          if(d < 2 || d > 4) {\n            throw new Error('gl-shader: Invalid data type for attribute ' + name + ': ' + type)\n          }\n          addVectorAttribute(gl, program, location, d, obj, name, doLink)\n        } else {\n          throw new Error('gl-shader: Unknown data type for attribute ' + name + ': ' + type)\n        }\n      break\n    }\n  }\n  return obj\n}", "label": 3}
{"code": "private function convertJoinTableAnnotationToJoinTableMetadata(\n        Annotation\\JoinTable $joinTableAnnot\n    ) : Mapping\\JoinTableMetadata {\n        $joinTable = new Mapping\\JoinTableMetadata();\n\n        if (! empty($joinTableAnnot->name)) {\n            $joinTable->setName($joinTableAnnot->name);\n        }\n\n        if (! empty($joinTableAnnot->schema)) {\n            $joinTable->setSchema($joinTableAnnot->schema);\n        }\n\n        foreach ($joinTableAnnot->joinColumns as $joinColumnAnnot) {\n            $joinColumn = $this->convertJoinColumnAnnotationToJoinColumnMetadata($joinColumnAnnot);\n\n            $joinTable->addJoinColumn($joinColumn);\n        }\n\n        foreach ($joinTableAnnot->inverseJoinColumns as $joinColumnAnnot) {\n            $joinColumn = $this->convertJoinColumnAnnotationToJoinColumnMetadata($joinColumnAnnot);\n\n            $joinTable->addInverseJoinColumn($joinColumn);\n        }\n\n        return $joinTable;\n    }", "label": 2}
{"code": "public function setWrites($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Firestore\\V1beta1\\Write::class);\n        $this->writes = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public void setInRGB(IntRange inRGB) {\r\n        this.inRed = inRGB;\r\n        this.inGreen = inRGB;\r\n        this.inBlue = inRGB;\r\n\r\n        CalculateMap(inRGB, outRed, mapRed);\r\n        CalculateMap(inRGB, outGreen, mapGreen);\r\n        CalculateMap(inRGB, outBlue, mapBlue);\r\n    }", "label": 0}
{"code": "func (c *Manager) ListLibraryItemFiles(ctx context.Context, id string) ([]File, error) {\n\turl := internal.URL(c, internal.LibraryItemFilePath).WithParameter(\"library_item_id\", id)\n\tvar res []File\n\treturn res, c.Do(ctx, url.Request(http.MethodGet), &res)\n}", "label": 5}
{"code": "function () {\n    var self = this;\n\n    // See how much capacity we have left to fill.\n    var launchCount = this.concurrency - Object.keys(this.active).length;\n\n    // Identify up to launchCount eligible tasks, giving priority to those earlier in the queue.\n    var offset = 0;\n    var launchTasks = [];\n    while (launchTasks.length < launchCount && this.tasks.length > offset) {\n      var task = this.tasks[offset];\n\n      if (task.key in this.active) {\n        // This task cannot run right now, so skip it.\n        offset += 1;\n      } else {\n        // This task is eligible to run. Remove it from the queue and prepare it to launch.\n        this.tasks.splice(offset, 1);\n        launchTasks.push(task);\n      }\n    }\n\n    // Create a task completion callback. Remove the task from the active set, invoke the tasks'\n    // push() callback, then drain() again to see if another task is ready to run.\n    function makeTaskHandler(task) {\n      return function (err) {\n        delete self.active[task.key];\n\n        task.callback(err);\n\n        // Defer the next drain() call again in case the task's callback was synchronous.\n        process.nextTick(self.drain.bind(self));\n      };\n    }\n\n    // Launch the queue handler for each chosen task.\n    for (var i = 0; i < launchTasks.length; i++) {\n      var each = launchTasks[i];\n\n      this.active[each.key] = each;\n\n      this.handler(each.job, each.config, makeTaskHandler(each));\n    }\n\n    // Fire and unset the drain callback if one has been registered.\n    if (this.drainCallback) {\n      var lastCallback = this.drainCallback;\n      this.drainCallback = null;\n      lastCallback();\n    }\n  }", "label": 3}
{"code": "def init_orm_hooks!\n      sorcery_adapter.define_callback :before, :validation, :encrypt_password, if: proc { |record|\n        record.send(sorcery_config.password_attribute_name).present?\n      }\n\n      sorcery_adapter.define_callback :after, :save, :clear_virtual_password, if: proc { |record|\n        record.send(sorcery_config.password_attribute_name).present?\n      }\n\n      attr_accessor sorcery_config.password_attribute_name\n    end", "label": 4}
{"code": "func (p *PoolData) MarshalJSON() ([]byte, error) {\n\tm := map[string]interface{}{\n\t\t\"ParentKey\": p.ParentKey,\n\t\t\"RefCount\":  p.RefCount,\n\t}\n\tif p.Pool != nil {\n\t\tm[\"Pool\"] = p.Pool.String()\n\t}\n\tif p.Range != nil {\n\t\tm[\"Range\"] = p.Range\n\t}\n\treturn json.Marshal(m)\n}", "label": 5}
{"code": "public void normalize() {\n        double lenSqr = x * x + y * y + z * z;\n        double err = lenSqr - 1;\n        if (err > (2 * DOUBLE_PREC) || err < -(2 * DOUBLE_PREC)) {\n            double len = Math.sqrt(lenSqr);\n            x /= len;\n            y /= len;\n            z /= len;\n        }\n    }", "label": 0}
{"code": "def rc_stats(stats):\n    \"\"\"\n    reverse completement stats\n    \"\"\"\n    rc_nucs = {'A':'T', 'T':'A', 'G':'C', 'C':'G', 'N':'N'}\n    rcs = []\n    for pos in reversed(stats):\n        rc = {}\n        rc['reference frequencey'] = pos['reference frequency']\n        rc['consensus frequencey'] = pos['consensus frequency']\n        rc['In'] = pos['In']\n        rc['Del'] = pos['Del']\n        rc['ref'] = rc_nucs[pos['ref']]\n        rc['consensus'] = (rc_nucs[pos['consensus'][0]], pos['consensus'][1])\n        for base, stat in list(pos.items()):\n            if base in rc_nucs:\n                rc[rc_nucs[base]] = stat\n        rcs.append(rc)\n    return rcs", "label": 1}
{"code": "public function sendGroupsLeave($gjids)\n    {\n        $msgId = $this->nodeId['leavegroup'] = $this->createIqId();\n\n        if (!is_array($gjids)) {\n            $gjids = [$this->getJID($gjids)];\n        }\n\n        $nodes = [];\n        foreach ($gjids as $gjid) {\n            $nodes[] = new ProtocolNode('group',\n                [\n                    'id' => $this->getJID($gjid),\n                ], null, null);\n        }\n\n        $leave = new ProtocolNode('leave',\n            [\n                'action' => 'delete',\n            ], $nodes, null);\n\n        $node = new ProtocolNode('iq',\n            [\n                'id'    => $msgId,\n                'to'    => Constants::WHATSAPP_GROUP_SERVER,\n                'type'  => 'set',\n                'xmlns' => 'w:g2',\n            ], [$leave], null);\n\n        $this->sendNode($node);\n    }", "label": 2}
{"code": "func loadConfig() Config {\n\tconfig := Config{}\n\n\tj, err := ioutil.ReadFile(configFile)\n\tif err == nil {\n\t\terr = json.Unmarshal(j, &config)\n\t\tif err != nil {\n\t\t\tlog.Fatal(\"Error parsing config file: \", err)\n\t\t}\n\t}\n\n\treturn config\n}", "label": 5}
{"code": "def raise_error_if_failed!(result)\n      return if result.status.statusCode == 0\n      error_message = result.status.errorMessage || 'Execution failed!'\n      raise RBHive::TCLIConnectionError.new(error_message)\n    end", "label": 4}
{"code": "@Override\r\n    public ImageSource apply(ImageSource source) {\r\n        if (radius != 0) {\r\n            if (source.isGrayscale()) {\r\n                return applyGrayscale(source, radius);\r\n            } else {\r\n                return applyRGB(source, radius);\r\n            }\r\n        } else {\r\n            if (source.isGrayscale()) {\r\n                return applyGrayscale(source, kernel);\r\n            } else {\r\n                return applyRGB(source, kernel);\r\n            }\r\n        }\r\n    }", "label": 0}
{"code": "public function targetId(): self\n    {\n        $this->set('target', 'id');\n\n        $this->addBeforeRender(function () {\n            $value = (string) $this->get('value');\n\n            if (! ctype_digit($value)) {\n                return;\n            }\n\n            /** @var Attachment $attach */\n            $attach = Dashboard::model(Attachment::class);\n\n            $url = optional($attach::find($value))->url();\n\n            $this->set('url', $url);\n        });\n\n        return $this;\n    }", "label": 2}
{"code": "func (tc *TeleportClient) ExecuteSCP(ctx context.Context, cmd scp.Command) (err error) {\n\t// connect to proxy first:\n\tif !tc.Config.ProxySpecified() {\n\t\treturn trace.BadParameter(\"proxy server is not specified\")\n\t}\n\n\tproxyClient, err := tc.ConnectToProxy(ctx)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tdefer proxyClient.Close()\n\n\tclusterInfo, err := proxyClient.currentCluster()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// which nodes are we executing this commands on?\n\tnodeAddrs, err := tc.getTargetNodes(ctx, proxyClient)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif len(nodeAddrs) == 0 {\n\t\treturn trace.BadParameter(\"no target host specified\")\n\t}\n\n\tnodeClient, err := proxyClient.ConnectToNode(\n\t\tctx,\n\t\tnodeAddrs[0]+\"@\"+tc.Namespace+\"@\"+clusterInfo.Name,\n\t\ttc.Config.HostLogin,\n\t\tfalse)\n\tif err != nil {\n\t\ttc.ExitStatus = 1\n\t\treturn trace.Wrap(err)\n\t}\n\n\terr = nodeClient.ExecuteSCP(cmd)\n\tif err != nil {\n\t\t// converts SSH error code to tc.ExitStatus\n\t\texitError, _ := trace.Unwrap(err).(*ssh.ExitError)\n\t\tif exitError != nil {\n\t\t\ttc.ExitStatus = exitError.ExitStatus()\n\t\t}\n\t\treturn err\n\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "def get_user_tables(conn):\n    \"\"\"Retrieve all user tables.\"\"\"\n\n    query_string = \"select schemaname, relname from pg_stat_user_tables;\"\n    with conn.cursor() as cursor:\n        cursor.execute(query_string)\n        tables = cursor.fetchall()\n\n    return tables", "label": 1}
{"code": "public static base_response enable(nitro_service client, Long clid) throws Exception {\n\t\tclusterinstance enableresource = new clusterinstance();\n\t\tenableresource.clid = clid;\n\t\treturn enableresource.perform_operation(client,\"enable\");\n\t}", "label": 0}
{"code": "public static function cryptoKeyVersionName($project, $location, $keyRing, $cryptoKey, $cryptoKeyVersion)\n    {\n        return self::getCryptoKeyVersionNameTemplate()->render([\n            'project' => $project,\n            'location' => $location,\n            'key_ring' => $keyRing,\n            'crypto_key' => $cryptoKey,\n            'crypto_key_version' => $cryptoKeyVersion,\n        ]);\n    }", "label": 2}
{"code": "function buildSample (sampleNumber, rawData, sendCounts) {\n  let sample;\n  if (sendCounts) {\n    sample = newSampleNoScale(sampleNumber);\n    sample.channelDataCounts = rawData;\n  } else {\n    sample = newSample(sampleNumber);\n    for (let j = 0; j < k.OBCINumberOfChannelsGanglion; j++) {\n      sample.channelData.push(rawData[j] * k.OBCIGanglionScaleFactorPerCountVolts);\n    }\n  }\n  sample.timestamp = Date.now();\n  return sample;\n}", "label": 3}
{"code": "public static base_response delete(nitro_service client, String mappolicyname) throws Exception {\n\t\tpolicymap deleteresource = new policymap();\n\t\tdeleteresource.mappolicyname = mappolicyname;\n\t\treturn deleteresource.delete_resource(client);\n\t}", "label": 0}
{"code": "def move_changes\n      @previous_changes = changes\n      Atomic::UPDATES.each do |update|\n        send(update).clear\n      end\n      changed_attributes.clear\n    end", "label": 4}
{"code": "public byte[] getMessageBuffer() {\n\t\tByteArrayOutputStream resultByteBuffer = new ByteArrayOutputStream();\n\t\tbyte[] result;\n\t\tresultByteBuffer.write((byte)0x01);\n\t\tint messageLength = messagePayload.length + \n\t\t\t\t(this.messageClass == SerialMessageClass.SendData && \n\t\t\t\tthis.messageType == SerialMessageType.Request ? 5 : 3); // calculate and set length\n\t\t\n\t\tresultByteBuffer.write((byte) messageLength);\n\t\tresultByteBuffer.write((byte) messageType.ordinal());\n\t\tresultByteBuffer.write((byte) messageClass.getKey());\n\t\t\n\t\ttry {\n\t\t\tresultByteBuffer.write(messagePayload);\n\t\t} catch (IOException e) {\n\t\t\t\n\t\t}\n\n\t\t// callback ID and transmit options for a Send Data message.\n\t\tif (this.messageClass == SerialMessageClass.SendData && this.messageType == SerialMessageType.Request) {\n\t\t\tresultByteBuffer.write(transmitOptions);\n\t\t\tresultByteBuffer.write(callbackId);\n\t\t}\n\t\t\n\t\tresultByteBuffer.write((byte) 0x00);\n\t\tresult = resultByteBuffer.toByteArray();\n\t\tresult[result.length - 1] = 0x01;\n\t\tresult[result.length - 1] = calculateChecksum(result);\n\t\tlogger.debug(\"Assembled message buffer = \" + SerialMessage.bb2hex(result));\n\t\treturn result;\n\t}", "label": 0}
{"code": "func (d *Decoder) getc() (b byte, ok bool) {\n\tif d.err != nil {\n\t\treturn 0, false\n\t}\n\tif d.nextByte >= 0 {\n\t\tb = byte(d.nextByte)\n\t\td.nextByte = -1\n\t} else {\n\t\tb, d.err = d.r.ReadByte()\n\t\tif d.err != nil {\n\t\t\treturn 0, false\n\t\t}\n\t\tif d.saved != nil {\n\t\t\td.saved.WriteByte(b)\n\t\t}\n\t}\n\tif b == '\\n' {\n\t\td.line++\n\t}\n\treturn b, true\n}", "label": 5}
{"code": "public static function fromRequest(Request $request)\n    {\n        return (new static)\n                ->batchId($request->batch_id)\n                ->uuids($request->uuids)\n                ->beforeSequence($request->before)\n                ->tag($request->tag)\n                ->familyHash($request->family_hash)\n                ->limit($request->take ?? 50);\n    }", "label": 2}
{"code": "def store!\n      storage_results = storages.map do |storage|\n        begin\n          storage.perform!\n        rescue => ex\n          ex\n        end\n      end\n\n      first_exception, *other_exceptions = storage_results.select { |result| result.is_a? Exception }\n\n      if first_exception\n        other_exceptions.each do |exception|\n          Logger.error exception.to_s\n          Logger.error exception.backtrace.join('\\n')\n        end\n        raise first_exception\n      else\n        true\n      end\n    end", "label": 4}
{"code": "func NewCertAuthority(caType CertAuthType, clusterName string, signingKeys, checkingKeys [][]byte, roles []string) CertAuthority {\n\treturn &CertAuthorityV2{\n\t\tKind:    KindCertAuthority,\n\t\tVersion: V2,\n\t\tSubKind: string(caType),\n\t\tMetadata: Metadata{\n\t\t\tName:      clusterName,\n\t\t\tNamespace: defaults.Namespace,\n\t\t},\n\t\tSpec: CertAuthoritySpecV2{\n\t\t\tRoles:        roles,\n\t\t\tType:         caType,\n\t\t\tClusterName:  clusterName,\n\t\t\tCheckingKeys: checkingKeys,\n\t\t\tSigningKeys:  signingKeys,\n\t\t},\n\t}\n}", "label": 5}
{"code": "def process_jpeg_bytes(bytes_in, quality=DEFAULT_JPEG_QUALITY):\n    \"\"\"Generates an optimized JPEG from JPEG-encoded bytes.\n\n    :param bytes_in: the input image's bytes\n    :param quality: the output JPEG quality (default 95)\n\n    :returns: Optimized JPEG bytes\n    :rtype: bytes\n\n    :raises ValueError: Guetzli was not able to decode the image (the image is\n                        probably corrupted or is not a JPEG)\n\n    .. code:: python\n\n        import pyguetzli\n\n        input_jpeg_bytes = open(\"./test/image.jpg\", \"rb\").read()\n        optimized_jpeg = pyguetzli.process_jpeg_bytes(input_jpeg_bytes)\n    \"\"\"\n    bytes_out_p = ffi.new(\"char**\")\n    bytes_out_p_gc = ffi.gc(bytes_out_p, lib.guetzli_free_bytes)\n\n    length = lib.guetzli_process_jpeg_bytes(\n            bytes_in,\n            len(bytes_in),\n            bytes_out_p_gc,\n            quality\n            )\n\n    if length == 0:\n        raise ValueError(\"Invalid JPEG: Guetzli was not able to decode the image\")  # noqa\n\n    bytes_out = ffi.cast(\"char*\", bytes_out_p_gc[0])\n    return ffi.unpack(bytes_out, length)", "label": 1}
{"code": "function index(options) {\n  const {\n    file,\n    config,\n    logStart,\n    logNotFound,\n    logEnd,\n    defaultContent = defaultFileContent,\n  } = options;\n\n  logger.log(logStart);\n\n  return readConfig(config)\n    .then(input => validateExtensions(input))\n    .then(input => createStrings(input))\n    .then(input => writeExtensionFile({\n      input,\n      file,\n      defaultContent,\n      logNotFound,\n      logEnd,\n    }));\n}", "label": 3}
{"code": "def methods_available?(obj)\n      methods.each do |m|\n        if obj.is_a?(Class)\n          return false unless obj.public_method_defined?(m)\n        else\n          return false unless obj.respond_to?(m)\n        end\n      end\n      true\n    end", "label": 4}
{"code": "public function setInstances($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Bigtable\\Admin\\V2\\Instance::class);\n        $this->instances = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "def plugins_info_by_type(type, opts={})\n      array = all_plugins.select {|pe|\n        (pe.config['@type'] == type) rescue nil\n      }\n      array.map {|pe|\n        get_monitor_info(pe, opts)\n      }\n    end", "label": 4}
{"code": "func libraryPath(l *library.Library, id string) string {\n\t// DatastoreID (moref) format is \"$local-path@$ds-folder-id\",\n\t// see simulator.HostDatastoreSystem.CreateLocalDatastore\n\tds := strings.SplitN(l.Storage[0].DatastoreID, \"@\", 2)[0]\n\treturn path.Join(append([]string{ds, \"contentlib-\" + l.ID}, id)...)\n}", "label": 5}
{"code": "def matching_body_hashes?(query_parameters, pattern, content_type)\n      return false unless query_parameters.is_a?(Hash)\n      return false unless query_parameters.keys.sort == pattern.keys.sort\n      query_parameters.each do |key, actual|\n        expected = pattern[key]\n\n        if actual.is_a?(Hash) && expected.is_a?(Hash)\n          return false unless matching_body_hashes?(actual, expected, content_type)\n        else\n          expected = WebMock::Util::ValuesStringifier.stringify_values(expected) if url_encoded_body?(content_type)\n          return false unless expected === actual\n        end\n      end\n      true\n    end", "label": 4}
{"code": "public void setFirstOccurence(int min, int max) throws ParseException {\n    if (fullCondition == null) {\n      if ((min < 0) || (min > max) || (max < 1)) {\n        throw new ParseException(\"Illegal number {\" + min + \",\" + max + \"}\");\n      }\n      if (min == 0) {\n        firstOptional = true;\n      }\n      firstMinimumOccurence = Math.max(1, min);\n      firstMaximumOccurence = max;\n    } else {\n      throw new ParseException(\"fullCondition already generated\");\n    }\n  }", "label": 0}
{"code": "protected function getUnreadNotifications()\n    {\n        static $cached = null;\n\n        if (is_null($cached)) {\n            $cached = $this->notifications()\n                ->whereIn('type', $this->getAlertableNotificationTypes())\n                ->whereNull('read_at')\n                ->where('is_deleted', false)\n                ->whereSubjectVisibleTo($this)\n                ->get();\n        }\n\n        return $cached;\n    }", "label": 2}
{"code": "private void processProperties() {\n        state = true;\n        try {\n            exporterServiceFilter = getFilter(exporterServiceFilterProperty);\n        } catch (InvalidFilterException invalidFilterException) {\n            LOG.debug(\"The value of the Property \" + FILTER_EXPORTERSERVICE_PROPERTY + \" is invalid,\"\n                    + \" the recuperation of the Filter has failed. The instance gonna stop.\", invalidFilterException);\n            state = false;\n            return;\n        }\n\n        try {\n            exportDeclarationFilter = getFilter(exportDeclarationFilterProperty);\n        } catch (InvalidFilterException invalidFilterException) {\n            LOG.debug(\"The value of the Property \" + FILTER_EXPORTDECLARATION_PROPERTY + \" is invalid,\"\n                    + \" the recuperation of the Filter has failed. The instance gonna stop.\", invalidFilterException);\n            state = false;\n            return;\n        }\n    }", "label": 0}
{"code": "public function setDeleteCluster($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dataproc\\V1\\ClusterOperation::class);\n        $this->delete_cluster = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "public static base_response update(nitro_service client, Interface resource) throws Exception {\n\t\tInterface updateresource = new Interface();\n\t\tupdateresource.id = resource.id;\n\t\tupdateresource.speed = resource.speed;\n\t\tupdateresource.duplex = resource.duplex;\n\t\tupdateresource.flowctl = resource.flowctl;\n\t\tupdateresource.autoneg = resource.autoneg;\n\t\tupdateresource.hamonitor = resource.hamonitor;\n\t\tupdateresource.tagall = resource.tagall;\n\t\tupdateresource.trunk = resource.trunk;\n\t\tupdateresource.lacpmode = resource.lacpmode;\n\t\tupdateresource.lacpkey = resource.lacpkey;\n\t\tupdateresource.lagtype = resource.lagtype;\n\t\tupdateresource.lacppriority = resource.lacppriority;\n\t\tupdateresource.lacptimeout = resource.lacptimeout;\n\t\tupdateresource.ifalias = resource.ifalias;\n\t\tupdateresource.throughput = resource.throughput;\n\t\tupdateresource.bandwidthhigh = resource.bandwidthhigh;\n\t\tupdateresource.bandwidthnormal = resource.bandwidthnormal;\n\t\treturn updateresource.update_resource(client);\n\t}", "label": 0}
{"code": "func isTCP4AddrResolvable(fl FieldLevel) bool {\n\n\tif !isIP4Addr(fl) {\n\t\treturn false\n\t}\n\n\t_, err := net.ResolveTCPAddr(\"tcp4\", fl.Field().String())\n\treturn err == nil\n}", "label": 5}
{"code": "func NewForwarder(cfg ForwarderConfig) (*Forwarder, error) {\n\tif err := cfg.CheckAndSetDefaults(); err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tdiskLogger, err := NewDiskSessionLogger(DiskSessionLoggerConfig{\n\t\tSessionID:      cfg.SessionID,\n\t\tDataDir:        cfg.DataDir,\n\t\tRecordSessions: cfg.RecordSessions,\n\t\tNamespace:      cfg.Namespace,\n\t\tServerID:       cfg.ServerID,\n\t\tClock:          cfg.Clock,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &Forwarder{\n\t\tForwarderConfig: cfg,\n\t\tsessionLogger:   diskLogger,\n\t}, nil\n}", "label": 5}
{"code": "func (h *Handler) AuthenticateRequest(w http.ResponseWriter, r *http.Request, checkBearerToken bool) (*SessionContext, error) {\n\tconst missingCookieMsg = \"missing session cookie\"\n\tlogger := log.WithFields(log.Fields{\n\t\t\"request\": fmt.Sprintf(\"%v %v\", r.Method, r.URL.Path),\n\t})\n\tcookie, err := r.Cookie(\"session\")\n\tif err != nil || (cookie != nil && cookie.Value == \"\") {\n\t\tif err != nil {\n\t\t\tlogger.Warn(err)\n\t\t}\n\t\treturn nil, trace.AccessDenied(missingCookieMsg)\n\t}\n\td, err := DecodeCookie(cookie.Value)\n\tif err != nil {\n\t\tlogger.Warningf(\"failed to decode cookie: %v\", err)\n\t\treturn nil, trace.AccessDenied(\"failed to decode cookie\")\n\t}\n\tctx, err := h.auth.ValidateSession(d.User, d.SID)\n\tif err != nil {\n\t\tlogger.Warningf(\"invalid session: %v\", err)\n\t\tClearSession(w)\n\t\treturn nil, trace.AccessDenied(\"need auth\")\n\t}\n\tif checkBearerToken {\n\t\tcreds, err := roundtrip.ParseAuthHeaders(r)\n\t\tif err != nil {\n\t\t\tlogger.Warningf(\"no auth headers %v\", err)\n\t\t\treturn nil, trace.AccessDenied(\"need auth\")\n\t\t}\n\n\t\tif subtle.ConstantTimeCompare([]byte(creds.Password), []byte(ctx.GetWebSession().GetBearerToken())) != 1 {\n\t\t\tlogger.Warningf(\"Request failed: bad bearer token.\")\n\t\t\treturn nil, trace.AccessDenied(\"bad bearer token\")\n\t\t}\n\t}\n\treturn ctx, nil\n}", "label": 5}
{"code": "def download\n      return io if io.is_a?(Tempfile)\n\n      Tempfile.new(id, binmode: true).tap do |tempfile|\n        IO.copy_stream(io, tempfile)\n        tempfile.rewind\n        tempfile.fsync\n      end\n    end", "label": 4}
{"code": "public function setThreats($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\WebRisk\\V1beta1\\SearchHashesResponse\\ThreatHash::class);\n        $this->threats = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public void addRow(final String... cells){\n        final Row row = new Row((Object[]) cells);\n\n        if(!rows.contains(row)){\n            rows.add(row);\n        }\n    }", "label": 0}
{"code": "function assertArguments(options, argnames) {\n  if (!argnames) return;\n  if (!options) throw new TypeError('missing arguments: ' + argnames);\n  argnames.forEach(function (argname) {\n    if (!options.hasOwnProperty(argname)) {\n      throw new TypeError('missing argument: ' + argname);\n    }\n  });\n}", "label": 3}
{"code": "func (v *ViewPort) ScrollUp(rows int) {\n\tv.viewy -= rows\n\tv.ValidateViewY()\n}", "label": 5}
{"code": "def iter_list(self, *args, **kwargs):\n        \"\"\"Get a list of configs.  Whereas ``list`` fetches a single page of\n        configs according to its ``limit`` and ``page`` arguments,\n        ``iter_list`` returns all configs by internally making\n        successive calls to ``list``.\n\n        :param args: Arguments that ``list`` takes.\n        :param kwargs: Optional arguments that ``list`` takes.\n        :return: :class:`configs.Config <configs.Config>` list\n\n        \"\"\"\n        return self.service.iter_list(self.list, *args, **kwargs)", "label": 1}
{"code": "public function respondToAccessTokenRequest(ServerRequestInterface $request, ResponseInterface $response)\n    {\n        foreach ($this->enabledGrantTypes as $grantType) {\n            if (!$grantType->canRespondToAccessTokenRequest($request)) {\n                continue;\n            }\n            $tokenResponse = $grantType->respondToAccessTokenRequest(\n                $request,\n                $this->getResponseType(),\n                $this->grantTypeAccessTokenTTL[$grantType->getIdentifier()]\n            );\n\n            if ($tokenResponse instanceof ResponseTypeInterface) {\n                return $tokenResponse->generateHttpResponse($response);\n            }\n        }\n\n        throw OAuthServerException::unsupportedGrantType();\n    }", "label": 2}
{"code": "func CheckMdsAvailability() error {\n\tif conn, err := net.Dial(\"unix\", common.MetadataServiceRegSock); err != nil {\n\t\treturn errUnreachable\n\t} else {\n\t\tconn.Close()\n\t\treturn nil\n\t}\n}", "label": 5}
{"code": "function(req) {\n\n    var pk = module.exports.parsePk(req);\n\n    // Validate the required `id` parameter\n    if (!pk) {\n\n      var err = new Error(\n        'No `id` parameter provided.' +\n        '(Note: even if the model\\'s primary key is not named `id`- ' +\n        '`id` should be used as the name of the parameter- it will be ' +\n        'mapped to the proper primary key name)'\n      );\n      err.status = 400;\n      throw err;\n    }\n\n    return pk;\n  }", "label": 3}
{"code": "public function setMetrics($var)\n    {\n        $arr = GPBUtil::checkRepeatedField($var, \\Google\\Protobuf\\Internal\\GPBType::MESSAGE, \\Google\\Cloud\\Logging\\V2\\LogMetric::class);\n        $this->metrics = $arr;\n\n        return $this;\n    }", "label": 2}
{"code": "public function addLink(Link $link)\n    {\n        if (!$this->links) {\n            $this->links = [];\n        }\n        $this->links[] = $link;\n    }", "label": 2}
{"code": "def options\n      exclude = %w[\n        docs\n        spec\n        vendor\n        core.rb\n        .js\n        templates\n        commands\n        internal\n        support\n        Dockerfile\n        Dockerfile.base\n        Gemfile\n        Gemfile.lock\n        Guardfile\n        LICENSE\n        Procfile\n        Rakefile\n        bin\n      ]\n      exclude = exclude.map { |word| ['-x', word] }.flatten\n      [\"-m\", \"README.md\", \"--markup\", \"tomdoc\"] + exclude\n    end", "label": 4}
{"code": "def expired?(service_name)\n      if entry = @record_cache[service_name]\n        return Time.now > (entry.resolution_time + entry.ttl)\n      else\n        return true\n      end\n    end", "label": 4}
{"code": "public static String makeAsciiTable(Object[][] table, Object[] rowLabels, Object[] colLabels, int padLeft, int padRight, boolean tsv) {\r\n    StringBuilder buff = new StringBuilder();\r\n    // top row\r\n    buff.append(makeAsciiTableCell(\"\", padLeft, padRight, tsv)); // the top left cell\r\n    for (int j = 0; j < table[0].length; j++) { // assume table is a rectangular matrix\r\n      buff.append(makeAsciiTableCell(colLabels[j], padLeft, padRight, (j != table[0].length - 1) && tsv));\r\n    }\r\n    buff.append('\\n');\r\n    // all other rows\r\n    for (int i = 0; i < table.length; i++) {\r\n      // one row\r\n      buff.append(makeAsciiTableCell(rowLabels[i], padLeft, padRight, tsv));\r\n      for (int j = 0; j < table[i].length; j++) {\r\n        buff.append(makeAsciiTableCell(table[i][j], padLeft, padRight, (j != table[0].length - 1) && tsv));\r\n      }\r\n      buff.append('\\n');\r\n    }\r\n    return buff.toString();\r\n  }", "label": 0}
{"code": "func (proxy *ProxyClient) FindServersByLabels(ctx context.Context, namespace string, labels map[string]string) ([]services.Server, error) {\n\tif namespace == \"\" {\n\t\treturn nil, trace.BadParameter(auth.MissingNamespaceError)\n\t}\n\tnodes := make([]services.Server, 0)\n\tsite, err := proxy.CurrentClusterAccessPoint(ctx, false)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tsiteNodes, err := site.GetNodes(namespace, services.SkipValidation())\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// look at every node on this site and see which ones match:\n\tfor _, node := range siteNodes {\n\t\tif node.MatchAgainst(labels) {\n\t\t\tnodes = append(nodes, node)\n\t\t}\n\t}\n\treturn nodes, nil\n}", "label": 5}
{"code": "def default_description\n      description = 'Run `scss-lint'\n      description += \" --config #{config}\" if config\n      description += \" #{args}\" if args\n      description += \" #{files.join(' ')}\" if files.any?\n      description += ' [files...]`'\n      description\n    end", "label": 4}
{"code": "def get(self, key):  \n        \"\"\" get a set of keys from redis \"\"\"\n        res = self.connection.get(key)\n        print(res)\n        return res", "label": 1}
{"code": "function (state, ev) {\n    if(state.dirtyTs + 200 < ev.ts && state.queue) {\n      state.cleanTs = ev.ts\n      state.writing = true\n      state.dirty = false\n      return {state: state, effects: {type: 'write'}}\n    }\n    return state\n  }", "label": 3}
{"code": "private FieldDescriptor getFldFromReference(TableAlias aTableAlias, ObjectReferenceDescriptor anOrd)\r\n    {\r\n        FieldDescriptor fld = null;\r\n\r\n        if (aTableAlias == getRoot())\r\n        {\r\n            // no path expression\r\n            FieldDescriptor[] fk = anOrd.getForeignKeyFieldDescriptors(aTableAlias.cld);\r\n            if (fk.length > 0)\r\n            {\r\n                fld = fk[0];\r\n            }\r\n        }\r\n        else\r\n        {\r\n            // attribute with path expression\r\n            /**\r\n             * MBAIRD\r\n             * potentially people are referring to objects, not to the object's primary key, \r\n             * and then we need to take the primary key attribute of the referenced object \r\n             * to help them out.\r\n             */\r\n            ClassDescriptor cld = aTableAlias.cld.getRepository().getDescriptorFor(anOrd.getItemClass());\r\n            if (cld != null)\r\n            {\r\n                fld = aTableAlias.cld.getFieldDescriptorByName(cld.getPkFields()[0].getPersistentField().getName());\r\n            }\r\n        }\r\n\r\n        return fld;\r\n    }", "label": 0}
{"code": "func (a *AuthWithRoles) SetClusterConfig(c services.ClusterConfig) error {\n\tif err := a.action(defaults.Namespace, services.KindClusterConfig, services.VerbCreate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := a.action(defaults.Namespace, services.KindClusterConfig, services.VerbUpdate); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn a.authServer.SetClusterConfig(c)\n}", "label": 5}
{"code": "func (c *EventHistoryCollector) typeMatches(event types.BaseEvent, spec *types.EventFilterSpec) bool {\n\tif len(spec.EventTypeId) == 0 {\n\t\treturn true\n\t}\n\n\tmatches := func(name string) bool {\n\t\tfor _, id := range spec.EventTypeId {\n\t\t\tif id == name {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t\treturn false\n\t}\n\tkind := reflect.ValueOf(event).Elem().Type()\n\n\tif matches(kind.Name()) {\n\t\treturn true // concrete type\n\t}\n\n\tfield, ok := kind.FieldByNameFunc(matches)\n\tif ok {\n\t\treturn field.Anonymous // base type (embedded field)\n\t}\n\treturn false\n}", "label": 5}
{"code": "func exportTimestampedAggregationValue(values []core.TimestampedAggregationValue) types.MetricAggregationResult {\n\tresult := types.MetricAggregationResult{\n\t\tBuckets:    make([]types.MetricAggregationBucket, 0, len(values)),\n\t\tBucketSize: 0,\n\t}\n\tfor _, value := range values {\n\t\t// just use the largest bucket size, since all bucket sizes should be uniform\n\t\t// (except for the last one, which may be smaller)\n\t\tif result.BucketSize < value.BucketSize {\n\t\t\tresult.BucketSize = value.BucketSize\n\t\t}\n\n\t\tbucket := types.MetricAggregationBucket{\n\t\t\tTimestamp: value.Timestamp,\n\n\t\t\tCount: value.Count,\n\n\t\t\tAverage: extractMetricValue(&value.AggregationValue, core.AggregationTypeAverage),\n\t\t\tMaximum: extractMetricValue(&value.AggregationValue, core.AggregationTypeMaximum),\n\t\t\tMinimum: extractMetricValue(&value.AggregationValue, core.AggregationTypeMinimum),\n\t\t\tMedian:  extractMetricValue(&value.AggregationValue, core.AggregationTypeMedian),\n\n\t\t\tPercentiles: make(map[string]types.MetricValue, 3),\n\t\t}\n\n\t\tif val, ok := value.Aggregations[core.AggregationTypePercentile50]; ok {\n\t\t\tbucket.Percentiles[\"50\"] = *exportMetricValue(&val)\n\t\t}\n\t\tif val, ok := value.Aggregations[core.AggregationTypePercentile95]; ok {\n\t\t\tbucket.Percentiles[\"95\"] = *exportMetricValue(&val)\n\t\t}\n\t\tif val, ok := value.Aggregations[core.AggregationTypePercentile99]; ok {\n\t\t\tbucket.Percentiles[\"99\"] = *exportMetricValue(&val)\n\t\t}\n\n\t\tresult.Buckets = append(result.Buckets, bucket)\n\t}\n\treturn result\n}", "label": 5}
{"code": "public function setLikelihoodAdjustment($var)\n    {\n        GPBUtil::checkMessage($var, \\Google\\Cloud\\Dlp\\V2\\CustomInfoType_DetectionRule_LikelihoodAdjustment::class);\n        $this->likelihood_adjustment = $var;\n\n        return $this;\n    }", "label": 2}
{"code": "protected OJBIterator getIteratorFromQuery(Query query, ClassDescriptor cld) throws PersistenceBrokerException\n    {\n        RsIteratorFactory factory = RsIteratorFactoryImpl.getInstance();\n        OJBIterator result = getRsIteratorFromQuery(query, cld, factory);\n\n        if (query.usePaging())\n        {\n            result = new PagingIterator(result, query.getStartAtIndex(), query.getEndAtIndex());\n        }\n        return result;\n    }", "label": 0}
{"code": "func (sink *influxdbSink) checkSanitizedMetricLabels(labels map[string]string) error {\n\t// label names have the same restrictions as metric names, here\n\tfor k, v := range labels {\n\t\tif !metricAllowedChars.MatchString(k) {\n\t\t\treturn fmt.Errorf(\"Invalid label name %q\", k)\n\t\t}\n\n\t\t// for metric values, we're somewhat more permissive.  We allow any\n\t\t// Printable unicode character, except quotation marks, which are used\n\t\t// to delimit things.\n\t\tif strings.ContainsRune(v, '\"') || strings.ContainsRune(v, '\\'') {\n\t\t\treturn fmt.Errorf(\"Invalid label value %q\", v)\n\t\t}\n\n\t\tfor _, runeVal := range v {\n\t\t\tif !unicode.IsPrint(runeVal) {\n\t\t\t\treturn fmt.Errorf(\"Invalid label value %q\", v)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "label": 5}
{"code": "private void checkInitializationMethod(ClassDescriptorDef classDef, String checkLevel) throws ConstraintException\r\n    {\r\n        if (!CHECKLEVEL_STRICT.equals(checkLevel))\r\n        {\r\n            return;\r\n        }\r\n        \r\n        String initMethodName = classDef.getProperty(PropertyHelper.OJB_PROPERTY_INITIALIZATION_METHOD);\r\n\r\n        if (initMethodName == null)\r\n        {\r\n            return;\r\n        }\r\n\r\n        Class  initClass;\r\n        Method initMethod;\r\n\r\n        try\r\n        {\r\n            initClass = InheritanceHelper.getClass(classDef.getName());\r\n        }\r\n        catch (ClassNotFoundException ex)\r\n        {\r\n            throw new ConstraintException(\"The class \"+classDef.getName()+\" was not found on the classpath\");\r\n        }\r\n        try\r\n        {\r\n            initMethod = initClass.getDeclaredMethod(initMethodName, new Class[0]);\r\n        }\r\n        catch (NoSuchMethodException ex)\r\n        {\r\n            initMethod = null;\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            throw new ConstraintException(\"Exception while checking the class \"+classDef.getName()+\": \"+ex.getMessage());\r\n        }\r\n        if (initMethod == null)\r\n        {    \r\n            try\r\n            {\r\n                initMethod = initClass.getMethod(initMethodName, new Class[0]);\r\n            }\r\n            catch (NoSuchMethodException ex)\r\n            {\r\n                throw new ConstraintException(\"No suitable initialization-method \"+initMethodName+\" found in class \"+classDef.getName());\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                throw new ConstraintException(\"Exception while checking the class \"+classDef.getName()+\": \"+ex.getMessage());\r\n            }\r\n        }\r\n\r\n        // checking modifiers\r\n        int mods = initMethod.getModifiers();\r\n\r\n        if (Modifier.isStatic(mods) || Modifier.isAbstract(mods))\r\n        {\r\n            throw new ConstraintException(\"The initialization-method \"+initMethodName+\" in class \"+classDef.getName()+\" must be a concrete instance method\");\r\n        }\r\n    }", "label": 0}
{"code": "def update_employee_role(role_id, body, opts = {})\n      data, _status_code, _headers = update_employee_role_with_http_info(role_id, body, opts)\n      return data\n    end", "label": 4}
{"code": "function buildFormFileSizes(submissions) {\n  //Grouping By Form Id\n  var fileSizesByForm = _.groupBy(submissions, 'formId');\n\n  //Getting all files associated with the submissions\n  fileSizesByForm = _.mapObject(fileSizesByForm, function(formSubs) {\n\n    //Getting File Sizes For All Entries In All Submissions Related To formId\n    var allSubmissionSizes = _.map(formSubs, function(submission) {\n\n      //For a single submission, get all file sizes\n      var submissionFileSizes = _.map(submission.formFields, function(formField) {\n        return _.map(_.compact(formField.fieldValues), function(fieldValue) {\n          return fieldValue.fileSize;\n        });\n      });\n\n      var totalSize = _.compact(_.flatten(submissionFileSizes));\n\n      //Adding all the file sizes for a single submission.\n      return _.reduce(totalSize, function(memo, fileSize) {\n        return memo + fileSize;\n      }, 0);\n    });\n\n    //Adding all file sizes for all submissions\n    return _.reduce(_.flatten(allSubmissionSizes), function(memo, fileSize) {\n      return memo + fileSize;\n    }, 0);\n  });\n\n  return fileSizesByForm;\n}", "label": 3}
{"code": "def create_or_edit(self, id, seq, resource): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Create or edit a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param resource: :class:`highlights.Highlight <highlights.Highlight>` object\n        :return: :class:`highlights.Highlight <highlights.Highlight>` object\n        :rtype: highlights.Highlight\n        \"\"\"\n        schema = HighlightSchema(exclude=('id', 'seq'))\n        json = self.service.encode(schema, resource)\n\n        schema = HighlightSchema()\n        resp = self.service.edit(self._base(id, seq), resource.line, json)\n        return self.service.decode(schema, resp)", "label": 1}
{"code": "function loadPlugin(pluginRoot, noUI) {\n  // noUI flag is used for loading dev plugins whose ui is from webpack dev server\n  try {\n    // const pkgJson = require(paths.join(pluginRoot, 'package.json'));\n    const pluginInstance = {};\n    // Core part\n    const coreIndex = paths.join(pluginRoot, 'core/index.js');\n    if (fs.existsSync(coreIndex)) {\n      Object.assign(pluginInstance, require(coreIndex));\n    }\n\n    // UI part\n    if (!noUI && fs.existsSync(path.join(pluginRoot, 'build/main.js'))) {\n      pluginInstance.ui = {\n        root: path.join(pluginRoot, 'build'),\n      };\n    }\n\n    // Plugin meta defined in package.json\n    const pkgJsonPath = path.join(pluginRoot, 'package.json');\n    let pkgJson = null;\n    if (fs.existsSync(pkgJsonPath)) {\n      pkgJson = fs.readJsonSync(pkgJsonPath);\n      ['appType', 'name', 'featureFiles'].forEach(key => {\n        if (!pluginInstance.hasOwnProperty(key) && pkgJson.hasOwnProperty(key)) {\n          if (key === 'name') {\n            let name = pkgJson.name;\n            if (name.startsWith('rekit-plugin')) name = name.replace('rekit-plugin-', '');\n            pluginInstance.name = name;\n          } else {\n            pluginInstance[key] = pkgJson[key] || null;\n          }\n        }\n      });\n      if (pkgJson.rekitPlugin) {\n        Object.keys(pkgJson.rekitPlugin).forEach(key => {\n          if (!pluginInstance.hasOwnProperty(key)) {\n            pluginInstance[key] = pkgJson.rekitPlugin[key];\n          }\n        });\n      }\n    }\n    return pluginInstance;\n  } catch (e) {\n    logger.warn(`Failed to load plugin: ${pluginRoot}`, e);\n  }\n\n  return null;\n}", "label": 3}
